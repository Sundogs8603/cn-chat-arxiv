<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20027;&#21160;&#25512;&#26029;&#26159;&#19968;&#31181;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30830;&#23450;&#26368;&#26377;&#21033;&#20110;&#26631;&#35760;&#30340;&#25968;&#25454;&#28857;&#26469;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#65292;&#23454;&#29616;&#27604;&#29616;&#26377;&#22522;&#32447;&#26356;&#23569;&#26679;&#26412;&#30340;&#30456;&#21516;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.03208</link><description>&lt;p&gt;
&#20027;&#21160;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Active Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03208
&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#25512;&#26029;&#26159;&#19968;&#31181;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30830;&#23450;&#26368;&#26377;&#21033;&#20110;&#26631;&#35760;&#30340;&#25968;&#25454;&#28857;&#26469;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#65292;&#23454;&#29616;&#27604;&#29616;&#26377;&#22522;&#32447;&#26356;&#23569;&#26679;&#26412;&#30340;&#30456;&#21516;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20027;&#21160;&#23398;&#20064;&#27010;&#24565;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20027;&#21160;&#25512;&#26029;&#8212;&#8212;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#25968;&#25454;&#25910;&#38598;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#20551;&#35774;&#23545;&#21487;&#25910;&#38598;&#30340;&#26631;&#31614;&#25968;&#37327;&#26377;&#39044;&#31639;&#38480;&#21046;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30830;&#23450;&#21738;&#20123;&#25968;&#25454;&#28857;&#26368;&#26377;&#21033;&#20110;&#26631;&#35760;&#65292;&#20174;&#32780;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;&#20854;&#36816;&#20316;&#26041;&#24335;&#22522;&#20110;&#19968;&#31181;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#30452;&#35273;&#65306;&#20248;&#20808;&#25910;&#38598;&#27169;&#22411;&#34920;&#29616;&#20986;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#28857;&#30340;&#26631;&#31614;&#65292;&#24182;&#22312;&#27169;&#22411;&#34920;&#29616;&#20986;&#33258;&#20449;&#26102;&#20381;&#36182;&#20110;&#20854;&#39044;&#27979;&#12290;&#20027;&#21160;&#25512;&#26029;&#26500;&#24314;&#20102;&#21487;&#35777;&#26126;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20551;&#35774;&#26816;&#39564;&#65292;&#21516;&#26102;&#21033;&#29992;&#20219;&#20309;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24182;&#22788;&#29702;&#20219;&#20309;&#25968;&#25454;&#20998;&#24067;&#12290;&#20851;&#38190;&#28857;&#22312;&#20110;&#65292;&#23427;&#33021;&#20197;&#27604;&#20381;&#36182;&#20110;&#38750;&#33258;&#36866;&#24212;&#25910;&#38598;&#25968;&#25454;&#30340;&#29616;&#26377;&#22522;&#32447;&#26356;&#23569;&#30340;&#26679;&#26412;&#36798;&#21040;&#30456;&#21516;&#27700;&#24179;&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#23545;&#20110;&#30456;&#21516;&#25968;&#37327;&#30340;&#26679;&#26412;&#65292;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03208v1 Announce Type: cross  Abstract: Inspired by the concept of active learning, we propose active inference$\unicode{x2013}$a methodology for statistical inference with machine-learning-assisted data collection. Assuming a budget on the number of labels that can be collected, the methodology uses a machine learning model to identify which data points would be most beneficial to label, thus effectively utilizing the budget. It operates on a simple yet powerful intuition: prioritize the collection of labels for data points where the model exhibits uncertainty, and rely on the model's predictions where it is confident. Active inference constructs provably valid confidence intervals and hypothesis tests while leveraging any black-box machine learning model and handling any data distribution. The key point is that it achieves the same level of accuracy with far fewer samples than existing baselines relying on non-adaptively-collected data. This means that for the same number 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;</title><link>https://arxiv.org/abs/2402.17106</link><description>&lt;p&gt;
&#25968;&#25454;&#38598;&#20844;&#24179;&#24615;&#65306;&#22312;&#24744;&#30340;&#25968;&#25454;&#19978;&#23454;&#29616;&#20855;&#26377;&#25928;&#29992;&#20445;&#35777;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Dataset Fairness: Achievable Fairness on Your Data With Utility Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17106
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#29305;&#24615;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#35745;&#31639;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20943;&#36731;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#24182;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20844;&#24179;&#24615;&#20013;&#65292;&#35757;&#32451;&#33021;&#22815;&#26368;&#23567;&#21270;&#19981;&#21516;&#25935;&#24863;&#32676;&#20307;&#20043;&#38388;&#24046;&#24322;&#30340;&#27169;&#22411;&#36890;&#24120;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#12290;&#36825;&#31181;&#26435;&#34913;&#30340;&#20005;&#37325;&#31243;&#24230;&#22522;&#26412;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#29305;&#24615;&#65292;&#22914;&#25968;&#25454;&#38598;&#30340;&#19981;&#22343;&#34913;&#25110;&#20559;&#35265;&#12290;&#22240;&#27492;&#65292;&#22312;&#25968;&#25454;&#38598;&#20043;&#38388;&#20351;&#29992;&#32479;&#19968;&#30340;&#20844;&#24179;&#24615;&#35201;&#27714;&#20173;&#28982;&#20540;&#24471;&#24576;&#30097;&#65292;&#24182;&#19988;&#24448;&#24448;&#20250;&#23548;&#33268;&#25928;&#29992;&#26497;&#20302;&#30340;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21333;&#20010;&#25968;&#25454;&#38598;&#37327;&#36523;&#23450;&#21046;&#30340;&#36817;&#20284;&#20844;&#24179;&#24615;-&#20934;&#30830;&#24615;&#26435;&#34913;&#26354;&#32447;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25903;&#25345;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;You-Only-Train-Once&#65288;YOTO&#65289;&#26694;&#26550;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20943;&#36731;&#20102;&#22312;&#36924;&#36817;&#26435;&#34913;&#26354;&#32447;&#26102;&#38656;&#35201;&#35757;&#32451;&#22810;&#20010;&#27169;&#22411;&#30340;&#35745;&#31639;&#36127;&#25285;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#35813;&#26354;&#32447;&#21608;&#22260;&#24341;&#20837;&#32622;&#20449;&#21306;&#38388;&#26469;&#37327;&#21270;&#25105;&#20204;&#36817;&#20284;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17106v1 Announce Type: cross  Abstract: In machine learning fairness, training models which minimize disparity across different sensitive groups often leads to diminished accuracy, a phenomenon known as the fairness-accuracy trade-off. The severity of this trade-off fundamentally depends on dataset characteristics such as dataset imbalances or biases. Therefore using a uniform fairness requirement across datasets remains questionable and can often lead to models with substantially low utility. To address this, we present a computationally efficient approach to approximate the fairness-accuracy trade-off curve tailored to individual datasets, backed by rigorous statistical guarantees. By utilizing the You-Only-Train-Once (YOTO) framework, our approach mitigates the computational burden of having to train multiple models when approximating the trade-off curve. Moreover, we quantify the uncertainty in our approximation by introducing confidence intervals around this curve, offe
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#26368;&#23567;&#26497;&#23567;&#36951;&#25022;&#30340;&#22810;&#23545;&#25968;&#32553;&#25918;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#23454;&#29616;&#23545;&#35774;&#35745;&#30697;&#38453;&#29305;&#24449;&#20540;&#20851;&#31995;&#30340;&#25511;&#21046;&#65292;&#23454;&#29616;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#23545;&#25968;&#32553;&#25918;&#12290;</title><link>https://arxiv.org/abs/2402.12042</link><description>&lt;p&gt;
&#20855;&#26377;&#22810;&#23545;&#25968;&#26497;&#23567;&#26497;&#23567;&#36951;&#25022;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Linear bandits with polylogarithmic minimax regret
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12042
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#26368;&#23567;&#26497;&#23567;&#36951;&#25022;&#30340;&#22810;&#23545;&#25968;&#32553;&#25918;&#38382;&#39064;&#65292;&#36890;&#36807;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#23454;&#29616;&#23545;&#35774;&#35745;&#30697;&#38453;&#29305;&#24449;&#20540;&#20851;&#31995;&#30340;&#25511;&#21046;&#65292;&#23454;&#29616;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#23545;&#25968;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#26426;&#30340;&#22122;&#22768;&#27169;&#22411;&#65292;&#23545;&#20110;&#35813;&#27169;&#22411;&#65292;&#24403;&#25105;&#20204;&#36873;&#25321;&#36234;&#26469;&#36234;&#25509;&#36817;&#26410;&#30693;&#21521;&#37327;&#30340;&#21333;&#20301;&#29699;&#19978;&#30340;&#21160;&#20316;&#26102;&#65292;&#20122;&#39640;&#26031;&#22122;&#22768;&#21442;&#25968;&#20197;&#32447;&#24615;&#26041;&#24335;&#28040;&#22833;&#12290;&#25105;&#20204;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#24341;&#20837;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20854;&#22312;&#26102;&#38388;&#38271;&#24230;$T$&#30340;&#24773;&#20917;&#19979;&#21576;&#23545;&#25968;$^3&#65288;T&#65289;$&#30340;&#26368;&#23567;&#36951;&#25022;&#32553;&#25918;&#65292;&#19982;&#20856;&#22411;&#36172;&#21338;&#26426;&#31639;&#27861;&#30340;&#24179;&#26041;&#26681;&#36951;&#25022;&#32553;&#25918;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#22522;&#20110;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#20960;&#20309;&#35770;&#35777;&#23454;&#29616;&#20102;&#35774;&#35745;&#30697;&#38453;$V_t$&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;$t$&#22788;&#30340;&#29305;&#24449;&#20540;&#20851;&#31995;$\lambda_{\min} ( V_t ) = \Omega (\sqrt{\lambda_{\max}(V_t ) })$&#65292;&#36825;&#20123;&#20960;&#20309;&#35770;&#35777;&#19982;&#22122;&#22768;&#27169;&#22411;&#26080;&#20851;&#65292;&#24182;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20005;&#26684;&#25511;&#21046;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#26399;&#26395;&#36951;&#25022;&#20026;$O(\frac1{t})$&#30340;&#25968;&#37327;&#32423;&#65292;&#20174;&#32780;&#23548;&#33268;&#32047;&#31215;&#36951;&#25022;&#30340;&#23545;&#25968;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12042v1 Announce Type: cross  Abstract: We study a noise model for linear stochastic bandits for which the subgaussian noise parameter vanishes linearly as we select actions on the unit sphere closer and closer to the unknown vector. We introduce an algorithm for this problem that exhibits a minimax regret scaling as $\log^3(T)$ in the time horizon $T$, in stark contrast the square root scaling of this regret for typical bandit algorithms. Our strategy, based on weighted least-squares estimation, achieves the eigenvalue relation $\lambda_{\min} ( V_t ) = \Omega (\sqrt{\lambda_{\max}(V_t ) })$ for the design matrix $V_t$ at each time step $t$ through geometrical arguments that are independent of the noise model and might be of independent interest. This allows us to tightly control the expected regret in each time step to be of the order $O(\frac1{t})$, leading to the logarithmic scaling of the cumulative regret.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#28085;&#30422;&#25152;&#26377;&#23454;&#38469;&#24773;&#20917;&#30340;Wasserstein&#20998;&#24067;&#40065;&#26834;&#27169;&#22411;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;&#65292;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20256;&#36755;&#25104;&#26412;&#20989;&#25968;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.11981</link><description>&lt;p&gt;
Wasserstein&#20998;&#24067;&#40065;&#26834;&#27169;&#22411;&#30340;&#36890;&#29992;&#27867;&#21270;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Universal Generalization Guarantees for Wasserstein Distributionally Robust Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#28085;&#30422;&#25152;&#26377;&#23454;&#38469;&#24773;&#20917;&#30340;Wasserstein&#20998;&#24067;&#40065;&#26834;&#27169;&#22411;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;&#65292;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#20256;&#36755;&#25104;&#26412;&#20989;&#25968;&#21644;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#28145;&#24230;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#31283;&#20581;&#20248;&#21270;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#35757;&#32451;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21560;&#24341;&#20154;&#26041;&#24335;&#65292;&#33021;&#22815;&#25429;&#25417;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#26368;&#36817;&#30340;&#32479;&#35745;&#20998;&#26512;&#35777;&#26126;&#65292;&#22522;&#20110;Wasserstein&#27169;&#31946;&#38598;&#26500;&#24314;&#30340;&#40065;&#26834;&#27169;&#22411;&#20855;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#25171;&#30772;&#20102;&#32500;&#24230;&#28798;&#38590;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#26159;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#33719;&#24471;&#30340;&#65292;&#20197;&#36817;&#20284;&#20195;&#20215;&#33719;&#24471;&#65292;&#25110;&#32773;&#22312;&#23454;&#36341;&#20013;&#38590;&#20197;&#39564;&#35777;&#30340;&#20551;&#35774;&#19979;&#33719;&#24471;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#24314;&#31435;&#20102;&#28085;&#30422;&#25152;&#26377;&#23454;&#38469;&#24773;&#20917;&#30340;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;&#65292;&#21253;&#25324;&#20219;&#20309;&#20256;&#36755;&#25104;&#26412;&#20989;&#25968;&#21644;&#20219;&#20309;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#33021;&#26159;&#38750;&#20984;&#21644;&#38750;&#24179;&#28369;&#30340;&#24773;&#20917;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#65292;&#32780;&#19981;&#38656;&#35201;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#23558;&#38750;&#24179;&#28369;&#20998;&#26512;&#29702;&#35770;&#19982;&#32463;&#20856;&#38598;&#20013;&#32467;&#26524;&#30456;&#32467;&#21512;&#30340;&#26032;&#39062;&#35777;&#26126;&#25216;&#26415;&#26469;&#23454;&#29616;&#36825;&#19968;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36275;&#22815;&#36890;&#29992;&#65292;&#21487;&#20197;&#25299;&#23637;&#33267;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11981v1 Announce Type: cross  Abstract: Distributionally robust optimization has emerged as an attractive way to train robust machine learning models, capturing data uncertainty and distribution shifts. Recent statistical analyses have proved that robust models built from Wasserstein ambiguity sets have nice generalization guarantees, breaking the curse of dimensionality. However, these results are obtained in specific cases, at the cost of approximations, or under assumptions difficult to verify in practice. In contrast, we establish, in this article, exact generalization guarantees that cover all practical cases, including any transport cost function and any loss function, potentially non-convex and nonsmooth. For instance, our result applies to deep learning, without requiring restrictive assumptions. We achieve this result through a novel proof technique that combines nonsmooth analysis rationale with classical concentration results. Our approach is general enough to ext
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#21033;&#29992;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#31435;&#20307;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07868</link><description>&lt;p&gt;
&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#30340;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Nesting Particle Filters for Experimental Design in Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#21033;&#29992;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#31435;&#20307;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#20132;&#25442;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20869;&#22806;SMC^2&#31639;&#27861;&#65292;&#20351;&#29992;&#23884;&#22871;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#65288;SMC&#65289;&#20272;&#35745;&#22120;&#26469;&#39044;&#27979;&#26399;&#26395;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#23558;&#20854;&#23884;&#20837;&#21040;&#31890;&#23376;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;pMCMC&#65289;&#26694;&#26550;&#20013;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;&#19982;&#26368;&#36817;&#20381;&#36182;&#20110;&#20559;&#20272;&#35745;&#22120;&#26469;&#25674;&#38144;&#20808;&#21069;&#23398;&#20064;&#35774;&#35745;&#31574;&#30053;&#30340;&#25104;&#26412;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#22312;&#19968;&#32452;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#20540;&#39564;&#35777;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel approach to Bayesian Experimental Design (BED) for non-exchangeable data that formulates it as risk-sensitive policy optimization. We develop the Inside-Out SMC^2 algorithm that uses a nested sequential Monte Carlo (SMC) estimator of the expected information gain and embeds it into a particle Markov chain Monte Carlo (pMCMC) framework to perform gradient-based policy optimization. This is in contrast to recent approaches that rely on biased estimators of the expected information gain (EIG) to amortize the cost of experiments by learning a design policy in advance. Numerical validation on a set of dynamical systems showcases the efficacy of our method in comparison to other state-of-the-art strategies.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#22312;&#22270;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19981;&#21516;&#20960;&#20309;&#32467;&#26500;&#30340;&#22270;&#19978;&#27010;&#29575;&#27979;&#24230;&#20256;&#36755;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#36229;&#21147; Wassestein&#65288;OW&#65289;&#30340;&#27010;&#24565;&#65292;&#20026;&#26576;&#20123;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#21457;&#23637;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;</title><link>https://arxiv.org/abs/2402.04516</link><description>&lt;p&gt;
&#22270;&#19978;&#27010;&#29575;&#27979;&#24230;&#30340;&#24191;&#20041; Sobolev &#20256;&#36755;
&lt;/p&gt;
&lt;p&gt;
Generalized Sobolev Transport for Probability Measures on a Graph
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04516
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#22312;&#22270;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19981;&#21516;&#20960;&#20309;&#32467;&#26500;&#30340;&#22270;&#19978;&#27010;&#29575;&#27979;&#24230;&#20256;&#36755;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#36229;&#21147; Wassestein&#65288;OW&#65289;&#30340;&#27010;&#24565;&#65292;&#20026;&#26576;&#20123;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#21457;&#23637;&#24102;&#26469;&#20102;&#26032;&#30340;&#26426;&#36935;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#25903;&#25345;&#22312;&#22270;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;Le &#31561;&#20154;&#65288;2022&#65289;&#21033;&#29992;&#22270;&#32467;&#26500;&#25552;&#20986;&#20102;&#19968;&#31181; OT &#30340;&#21464;&#20307;&#65292;&#31216;&#20026; Sobolev &#20256;&#36755;&#65288;ST&#65289;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#38381;&#24335;&#34920;&#36798;&#24335;&#29992;&#20110;&#24555;&#36895;&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;ST &#30340;&#23450;&#20041;&#20013;&#23454;&#36136;&#19978;&#19982; $L^p$ &#20960;&#20309;&#32467;&#26500;&#32806;&#21512;&#22312;&#19968;&#36215;&#65292;&#36825;&#20351;&#24471;&#22312;&#20854;&#20182;&#20808;&#39564;&#32467;&#26500;&#20013;&#21033;&#29992; ST &#21464;&#24471;&#38750;&#24120;&#22256;&#38590;&#12290;&#30456;&#21453;&#65292;&#32463;&#20856;&#30340; OT &#36890;&#36807;&#20462;&#25913;&#24213;&#23618;&#25104;&#26412;&#20989;&#25968;&#20855;&#26377;&#36866;&#24212;&#21508;&#31181;&#20960;&#20309;&#32467;&#26500;&#30340;&#28789;&#27963;&#24615;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#20363;&#23376;&#26159;&#36229;&#21147; Wassestein&#65288;OW&#65289;&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;\emph{Orlicz &#20960;&#20309;&#32467;&#26500;}&#36229;&#36234;&#20102; $L^p$ &#32467;&#26500;&#12290;&#19982;&#20351;&#29992;&#26631;&#20934; $p$-&#38454; Wassestein &#30456;&#27604;&#65292;OW &#26174;&#33879;&#25552;&#39640;&#20102;&#26576;&#20123;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#20004;&#23618;&#20248;&#21270; formulation&#65292;OW &#22312;&#20854;&#35745;&#31639;&#19978;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#19968;&#31867;&#29305;&#23450;&#30340;&#20984;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the optimal transport (OT) problem for measures supported on a graph metric space. Recently, Le et al. (2022) leverage the graph structure and propose a variant of OT, namely Sobolev transport (ST), which yields a closed-form expression for a fast computation. However, ST is essentially coupled with the $L^p$ geometric structure within its definition which makes it nontrivial to utilize ST for other prior structures. In contrast, the classic OT has the flexibility to adapt to various geometric structures by modifying the underlying cost function. An important instance is the Orlicz-Wasserstein (OW) which moves beyond the $L^p$ structure by leveraging the \emph{Orlicz geometric structure}. Comparing to the usage of standard $p$-order Wasserstein, OW remarkably helps to advance certain machine learning approaches. Nevertheless, OW brings up a new challenge on its computation due to its two-level optimization formulation. In this work, we leverage a specific class of convex funct
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23398;&#20064;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#26356;&#28789;&#27963;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;&#65292;&#20801;&#35768;&#26356;&#28789;&#27963;&#30340;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#65292;&#25552;&#20379;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21487;&#36866;&#29992;&#20110;&#20998;&#26512;&#21644;&#35774;&#35745;&#21508;&#31181;&#20803;&#23398;&#20064;&#26426;&#21046;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#39044;&#27979;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.04054</link><description>&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#26356;&#28789;&#27963;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
More Flexible PAC-Bayesian Meta-Learning by Learning Learning Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04054
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#23398;&#20064;&#31639;&#27861;&#65292;&#23454;&#29616;&#26356;&#28789;&#27963;&#30340;PAC-Bayesian&#20803;&#23398;&#20064;&#65292;&#20801;&#35768;&#26356;&#28789;&#27963;&#30340;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#65292;&#25552;&#20379;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21487;&#36866;&#29992;&#20110;&#20998;&#26512;&#21644;&#35774;&#35745;&#21508;&#31181;&#20803;&#23398;&#20064;&#26426;&#21046;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#25913;&#21892;&#20102;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#30740;&#31350;&#20803;&#23398;&#20064;&#26041;&#27861;&#30340;&#26032;&#26694;&#26550;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#20854;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#23427;&#20801;&#35768;&#22312;&#20219;&#21153;&#20043;&#38388;&#30340;&#30693;&#35782;&#36716;&#31227;&#20013;&#26356;&#20855;&#28789;&#27963;&#24615;&#12290;&#20197;&#24448;&#30340;&#26041;&#27861;&#21482;&#33021;&#36890;&#36807;&#23398;&#20064;&#27169;&#22411;&#30340;&#20808;&#39564;&#20998;&#24067;&#38388;&#25509;&#21457;&#29983;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#26356;&#30452;&#25509;&#22320;&#34920;&#36798;&#20102;&#20803;&#23398;&#20064;&#30340;&#36807;&#31243;&#65292;&#21363;&#23398;&#20064;&#36866;&#29992;&#20110;&#23558;&#26469;&#20219;&#21153;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#20351;&#20854;&#36866;&#29992;&#20110;&#20998;&#26512;&#21508;&#31181;&#20803;&#23398;&#20064;&#26426;&#21046;&#29978;&#33267;&#35774;&#35745;&#26032;&#30340;&#26426;&#21046;&#12290;&#38500;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#36129;&#29486;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#23454;&#38469;&#20803;&#23398;&#20064;&#26426;&#21046;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#25552;&#39640;&#20102;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new framework for studying meta-learning methods using PAC-Bayesian theory. Its main advantage over previous work is that it allows for more flexibility in how the transfer of knowledge between tasks is realized. For previous approaches, this could only happen indirectly, by means of learning prior distributions over models. In contrast, the new generalization bounds that we prove express the process of meta-learning much more directly as learning the learning algorithm that should be used for future tasks. The flexibility of our framework makes it suitable to analyze a wide range of meta-learning mechanisms and even design new mechanisms. Other than our theoretical contributions we also show empirically that our framework improves the prediction quality in practical meta-learning mechanisms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#30340;&#26032;&#30340;&#39640;&#25928;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.03664</link><description>&lt;p&gt;
&#39640;&#25928;&#27714;&#35299;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Efficient Solvers for Partial Gromov-Wasserstein
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#30340;&#26032;&#30340;&#39640;&#25928;&#27714;&#35299;&#22120;&#26469;&#35299;&#20915;&#20559;&#24046;Gromov-Wasserstein&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#24046;Gromov-Wasserstein&#65288;PGW&#65289;&#38382;&#39064;&#21487;&#20197;&#27604;&#36739;&#20855;&#26377;&#19981;&#22343;&#21248;&#36136;&#37327;&#30340;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#65292;&#20174;&#32780;&#23454;&#29616;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;&#19981;&#24179;&#34913;&#21644;&#37096;&#20998;&#21305;&#37197;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#21487;&#20197;&#36716;&#21270;&#20026;Gromov-Wasserstein&#38382;&#39064;&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#31867;&#20284;&#20110;&#25226;&#20559;&#24046;&#26368;&#20248;&#36816;&#36755;&#38382;&#39064;&#36716;&#21270;&#20026;&#26368;&#20248;&#36816;&#36755;&#38382;&#39064;&#12290;&#36825;&#20010;&#36716;&#21270;&#23548;&#33268;&#20102;&#20004;&#20010;&#26032;&#30340;&#27714;&#35299;&#22120;&#65292;&#22522;&#20110;Frank-Wolfe&#31639;&#27861;&#65292;&#25968;&#23398;&#21644;&#35745;&#31639;&#19978;&#31561;&#20215;&#65292;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;PGW&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;PGW&#38382;&#39064;&#26500;&#25104;&#20102;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#30340;&#24230;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19982;&#29616;&#26377;&#22522;&#32447;&#26041;&#27861;&#22312;&#24418;&#29366;&#21305;&#37197;&#21644;&#27491;&#26679;&#26412;&#26410;&#26631;&#35760;&#23398;&#20064;&#38382;&#39064;&#19978;&#30340;&#35745;&#31639;&#26102;&#38388;&#21644;&#24615;&#33021;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#27714;&#35299;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The partial Gromov-Wasserstein (PGW) problem facilitates the comparison of measures with unequal masses residing in potentially distinct metric spaces, thereby enabling unbalanced and partial matching across these spaces. In this paper, we demonstrate that the PGW problem can be transformed into a variant of the Gromov-Wasserstein problem, akin to the conversion of the partial optimal transport problem into an optimal transport problem. This transformation leads to two new solvers, mathematically and computationally equivalent, based on the Frank-Wolfe algorithm, that provide efficient solutions to the PGW problem. We further establish that the PGW problem constitutes a metric for metric measure spaces. Finally, we validate the effectiveness of our proposed solvers in terms of computation time and performance on shape-matching and positive-unlabeled learning problems, comparing them against existing baselines.
&lt;/p&gt;</description></item><item><title>&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#25193;&#25955;&#27169;&#22411;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#26377;&#25928;&#22320;&#20174;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03008</link><description>&lt;p&gt;
&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Diffusive Gibbs Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03008
&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#25193;&#25955;&#27169;&#22411;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#65292;&#26377;&#25928;&#22320;&#20174;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#65292;&#24182;&#22312;&#22810;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#26041;&#27861;&#22312;&#22810;&#27169;&#24577;&#20998;&#24067;&#30340;&#28151;&#21512;&#19981;&#36275;&#26041;&#38754;&#23384;&#22312;&#30528;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#8212;&#8212;&#25193;&#25955;&#21513;&#24067;&#26031;&#37319;&#26679;&#65288;DiGS&#65289;&#65292;&#29992;&#20110;&#26377;&#25928;&#37319;&#26679;&#20855;&#26377;&#36828;&#31243;&#21644;&#26029;&#24320;&#27169;&#24577;&#29305;&#24449;&#30340;&#20998;&#24067;&#12290;DiGS&#38598;&#25104;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#21033;&#29992;&#39640;&#26031;&#21367;&#31215;&#21019;&#24314;&#19968;&#20010;&#36741;&#21161;&#22122;&#22768;&#20998;&#24067;&#65292;&#20197;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#36830;&#25509;&#23396;&#31435;&#30340;&#27169;&#24577;&#65292;&#24182;&#24212;&#29992;&#21513;&#24067;&#26031;&#37319;&#26679;&#20174;&#20004;&#20010;&#31354;&#38388;&#20013;&#20132;&#26367;&#25277;&#21462;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#37319;&#26679;&#22810;&#27169;&#24577;&#20998;&#24067;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#24182;&#34892;&#28201;&#24230;&#27861;&#31561;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#22909;&#30340;&#28151;&#21512;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12289;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
The inadequate mixing of conventional Markov Chain Monte Carlo (MCMC) methods for multi-modal distributions presents a significant challenge in practical applications such as Bayesian inference and molecular dynamics. Addressing this, we propose Diffusive Gibbs Sampling (DiGS), an innovative family of sampling methods designed for effective sampling from distributions characterized by distant and disconnected modes. DiGS integrates recent developments in diffusion models, leveraging Gaussian convolution to create an auxiliary noisy distribution that bridges isolated modes in the original space and applying Gibbs sampling to alternately draw samples from both spaces. Our approach exhibits a better mixing property for sampling multi-modal distributions than state-of-the-art methods such as parallel tempering. We demonstrate that our sampler attains substantially improved results across various tasks, including mixtures of Gaussians, Bayesian neural networks and molecular dynamics.
&lt;/p&gt;</description></item><item><title>&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.00809</link><description>&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#30340;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00809
&lt;/p&gt;
&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#30340;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#20154;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#28041;&#21450;&#22823;&#35268;&#27169;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20219;&#21153;&#20013;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#26356;&#24191;&#27867;&#30340;&#35270;&#35282;&#25581;&#31034;&#20102;&#35768;&#22810;&#34987;&#24573;&#35270;&#30340;&#24230;&#37327;&#26631;&#20934;&#12289;&#20219;&#21153;&#21644;&#25968;&#25454;&#31867;&#22411;&#65292;&#22914;&#19981;&#30830;&#23450;&#24615;&#12289;&#20027;&#21160;&#21644;&#25345;&#32493;&#23398;&#20064;&#20197;&#21450;&#31185;&#23398;&#25968;&#25454;&#65292;&#36825;&#20123;&#26041;&#38754;&#38656;&#35201;&#20851;&#27880;&#12290;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#65288;BDL&#65289;&#26159;&#19968;&#26465;&#26377;&#21069;&#26223;&#30340;&#36947;&#36335;&#65292;&#21487;&#20197;&#22312;&#36825;&#20123;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#25552;&#20379;&#20248;&#21183;&#12290;&#26412;&#25991;&#35748;&#20026;BDL&#21487;&#20197;&#25552;&#21319;&#28145;&#24230;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#23427;&#37325;&#26032;&#23457;&#35270;&#20102;BDL&#30340;&#20248;&#21183;&#12289;&#25215;&#35748;&#20102;&#29616;&#26377;&#30340;&#25361;&#25112;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;&#19968;&#20123;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#30340;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#23637;&#26395;&#26410;&#26469;&#65292;&#35752;&#35770;&#38598;&#20013;&#22312;&#21487;&#33021;&#30340;&#26041;&#24335;&#19978;&#65292;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;BDL&#30456;&#32467;&#21512;&#65292;&#20197;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#21452;&#23556;&#20223;&#23556;&#21464;&#25442;&#26469;&#25913;&#21892;Markov Chain Monte Carlo&#37319;&#26679;&#22120;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#24182;&#29992;&#25143;&#21451;&#22909;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#20223;&#23556;&#21464;&#25442;&#30340;&#26041;&#26696;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30456;&#32467;&#21512;&#20135;&#29983;&#30340;&#26679;&#26412;&#20855;&#26377;&#39640;&#36136;&#37327;&#19988;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2401.16567</link><description>&lt;p&gt;
&#24182;&#34892;&#20223;&#23556;&#21464;&#25442;&#35843;&#25972;Markov Chain Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Parallel Affine Transformation Tuning of Markov Chain Monte Carlo. (arXiv:2401.16567v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#21452;&#23556;&#20223;&#23556;&#21464;&#25442;&#26469;&#25913;&#21892;Markov Chain Monte Carlo&#37319;&#26679;&#22120;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#24182;&#29992;&#25143;&#21451;&#22909;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#20223;&#23556;&#21464;&#25442;&#30340;&#26041;&#26696;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30456;&#32467;&#21512;&#20135;&#29983;&#30340;&#26679;&#26412;&#20855;&#26377;&#39640;&#36136;&#37327;&#19988;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Markov Chain Monte Carlo&#37319;&#26679;&#22120;&#30340;&#24615;&#33021;&#24378;&#28872;&#20381;&#36182;&#20110;&#30446;&#26631;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#22914;&#20854;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#27010;&#29575;&#36136;&#37327;&#30340;&#20301;&#32622;&#21644;&#23614;&#37096;&#34892;&#20026;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#20351;&#29992;&#26679;&#26412;&#31354;&#38388;&#30340;&#21452;&#23556;&#20223;&#23556;&#21464;&#25442;&#26469;&#25913;&#21892;&#30446;&#26631;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#20174;&#32780;&#25552;&#39640;&#22312;&#21464;&#25442;&#31354;&#38388;&#20013;&#36816;&#34892;&#30340;&#37319;&#26679;&#22120;&#30340;&#24615;&#33021;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#19988;&#29992;&#25143;&#21451;&#22909;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#33258;&#36866;&#24212;&#23398;&#20064;&#37319;&#26679;&#36807;&#31243;&#20013;&#30340;&#20223;&#23556;&#21464;&#25442;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#26696;&#19982;Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30340;&#32452;&#21512;&#22312;&#20960;&#20010;&#22522;&#20110;&#30495;&#23454;&#25968;&#25454;&#30340;&#22330;&#26223;&#20013;&#26174;&#31034;&#20986;&#20197;&#30456;&#23545;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#20135;&#29983;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The performance of Markov chain Monte Carlo samplers strongly depends on the properties of the target distribution such as its covariance structure, the location of its probability mass and its tail behavior. We explore the use of bijective affine transformations of the sample space to improve the properties of the target distribution and thereby the performance of samplers running in the transformed space. In particular, we propose a flexible and user-friendly scheme for adaptively learning the affine transformation during sampling. Moreover, the combination of our scheme with Gibbsian polar slice sampling is shown to produce samples of high quality at comparatively low computational cost in several settings based on real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#23398;&#20064;&#29575;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#26174;&#31034;&#20986;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#65292;&#23558;&#36845;&#20195;&#26397;&#30528;&#27604;&#26799;&#24230;&#19979;&#38477;&#21457;&#29616;&#30340;&#26356;&#24179;&#32531;&#30340;&#26497;&#23567;&#20540;&#26041;&#21521;&#25512;&#36827;&#12290;</title><link>http://arxiv.org/abs/2311.15051</link><description>&lt;p&gt;
&#24102;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#30340;&#22823;&#22411;&#24377;&#23556;&#27010;&#24565;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large Catapults in Momentum Gradient Descent with Warmup: An Empirical Study. (arXiv:2311.15051v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.15051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#23398;&#20064;&#29575;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#26174;&#31034;&#20986;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#65292;&#23558;&#36845;&#20195;&#26397;&#30528;&#27604;&#26799;&#24230;&#19979;&#38477;&#21457;&#29616;&#30340;&#26356;&#24179;&#32531;&#30340;&#26497;&#23567;&#20540;&#26041;&#21521;&#25512;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#22312;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#23545;&#20854;&#23545;&#35757;&#32451;&#36712;&#36857;&#30340;&#24433;&#21709;&#30340;&#20855;&#20307;&#29702;&#35299;&#20173;&#28982;&#38590;&#20197;&#25417;&#25720;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#21644;&#23398;&#20064;&#29575;&#39044;&#28909;&#30340;&#21160;&#37327;&#26799;&#24230;&#19979;&#38477;&#26174;&#31034;&#20986;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#65292;&#23558;&#36845;&#20195;&#26397;&#30528;&#27604;&#26799;&#24230;&#19979;&#38477;&#21457;&#29616;&#30340;&#26356;&#24179;&#32531;&#30340;&#26497;&#23567;&#20540;&#26041;&#21521;&#25512;&#36827;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#35777;&#35777;&#25454;&#21644;&#29702;&#35770;&#30452;&#35273;&#65292;&#34920;&#26126;&#22823;&#22411;&#24377;&#23556;&#25928;&#24212;&#26159;&#30001;&#20110;&#21160;&#37327;&#8220;&#25918;&#22823;&#8221;&#20102;&#33258;&#31283;&#23450;&#25928;&#24212;&#65288;Damian&#31561;&#65292;2023&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although gradient descent with momentum is widely used in modern deep learning, a concrete understanding of its effects on the training trajectory still remains elusive. In this work, we empirically show that momentum gradient descent with a large learning rate and learning rate warmup displays large catapults, driving the iterates towards flatter minima than those found by gradient descent. We then provide empirical evidence and theoretical intuition that the large catapult is caused by momentum "amplifying" the self-stabilization effect (Damian et al., 2023).B.1
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18913</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#21435;&#38500;&#20559;&#35265;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27491;&#22312;&#25104;&#20026;&#21508;&#31181;&#35821;&#35328;&#20219;&#21153;&#30340;&#39318;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23481;&#37327;&#30340;&#22686;&#38271;&#65292;&#27169;&#22411;&#24456;&#23481;&#26131;&#20381;&#36182;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#21051;&#26495;&#21360;&#35937;&#25152;&#20135;&#29983;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#27169;&#22411;&#32452;&#20214;&#65292;&#24182;&#21457;&#29616;&#20013;&#19978;&#23618;&#21069;&#39304;&#23618;&#26368;&#23481;&#26131;&#20256;&#36882;&#20559;&#35265;&#12290;&#26681;&#25454;&#20998;&#26512;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#25237;&#24433;&#23558;&#36825;&#20123;&#23618;&#20056;&#20197;&#27169;&#22411;&#36827;&#34892;&#36866;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;DAMA&#36890;&#36807;&#21508;&#31181;&#24230;&#37327;&#25351;&#26631;&#26126;&#26174;&#20943;&#23569;&#20102;&#20559;&#35265;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#22312;&#21518;&#32493;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#20195;&#30721;&#65292;&#36890;&#36807;&#37325;&#26032;&#35757;&#32451;&#65292;&#20445;&#25345;&#20102;LLaMA&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21516;&#26102;&#20559;&#35265;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26469;&#28304;&#21644;&#32622;&#20449;&#24230;&#65292;&#24182;&#21033;&#29992;&#25913;&#32534;&#21518;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#31561;&#26041;&#27861;&#26469;&#27979;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.12842</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#27169;&#22411;&#26080;&#20851;&#21464;&#37327;&#37325;&#35201;&#24615;&#65306;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model-agnostic variable importance for predictive uncertainty: an entropy-based approach. (arXiv:2310.12842v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20013;&#30340;&#39044;&#27979;&#26469;&#28304;&#21644;&#32622;&#20449;&#24230;&#65292;&#24182;&#21033;&#29992;&#25913;&#32534;&#21518;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#31561;&#26041;&#27861;&#26469;&#27979;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#30456;&#20449;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#24517;&#39035;&#29702;&#35299;&#23548;&#33268;&#36825;&#20123;&#39044;&#27979;&#30340;&#22240;&#32032;&#12290;&#23545;&#20110;&#27010;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#27169;&#22411;&#26469;&#35828;&#65292;&#19981;&#20165;&#38656;&#35201;&#29702;&#35299;&#39044;&#27979;&#26412;&#36523;&#30340;&#21407;&#22240;&#65292;&#36824;&#35201;&#29702;&#35299;&#27169;&#22411;&#23545;&#36825;&#20123;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#29616;&#26377;&#30340;&#35299;&#37322;&#24615;&#26041;&#27861;&#25193;&#23637;&#21040;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#27169;&#22411;&#65292;&#24182;&#22914;&#20309;&#21033;&#29992;&#36825;&#20123;&#25193;&#23637;&#26469;&#29702;&#35299;&#27169;&#22411;&#39044;&#27979;&#20998;&#24067;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#29305;&#21035;&#26159;&#36890;&#36807;&#25913;&#32534;&#25490;&#21015;&#29305;&#24449;&#37325;&#35201;&#24615;&#12289;&#37096;&#20998;&#20381;&#36182;&#22270;&#21644;&#20010;&#20307;&#26465;&#20214;&#26399;&#26395;&#22270;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#33719;&#24471;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#26032;&#35265;&#35299;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#26469;&#34913;&#37327;&#29305;&#24449;&#23545;&#39044;&#27979;&#20998;&#24067;&#30340;&#29109;&#21644;&#22522;&#20110;&#35813;&#20998;&#24067;&#30340;&#30495;&#23454;&#26631;&#31614;&#30340;&#23545;&#25968;&#20284;&#28982;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to trust the predictions of a machine learning algorithm, it is necessary to understand the factors that contribute to those predictions. In the case of probabilistic and uncertainty-aware models, it is necessary to understand not only the reasons for the predictions themselves, but also the model's level of confidence in those predictions. In this paper, we show how existing methods in explainability can be extended to uncertainty-aware models and how such extensions can be used to understand the sources of uncertainty in a model's predictive distribution. In particular, by adapting permutation feature importance, partial dependence plots, and individual conditional expectation plots, we demonstrate that novel insights into model behaviour may be obtained and that these methods can be used to measure the impact of features on both the entropy of the predictive distribution and the log-likelihood of the ground truth labels under that distribution. With experiments using both s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#32454;&#20998;&#24067;&#23478;&#26063;&#26469;&#35299;&#20915;&#29616;&#26377;&#20114;&#20449;&#24687;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25506;&#31350;&#20102;&#31070;&#32463;&#25209;&#35780;&#23478;&#22312;&#21464;&#20998;&#20272;&#35745;&#22120;&#20013;&#30340;&#34892;&#20026;&#65292;&#20197;&#21450;&#23454;&#39564;&#24322;&#24120;&#20540;&#23545;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19988;&#38656;&#35201;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.10240</link><description>&lt;p&gt;
&#28151;&#21512;&#29289;&#19982;&#31070;&#32463;&#25209;&#35780;&#23478;&#65306;&#20851;&#20110;&#31934;&#32454;&#20998;&#24067;&#30340;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Mixtures and the Neural Critics: On the Pointwise Mutual Information Profiles of Fine Distributions. (arXiv:2310.10240v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#32454;&#20998;&#24067;&#23478;&#26063;&#26469;&#35299;&#20915;&#29616;&#26377;&#20114;&#20449;&#24687;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25506;&#31350;&#20102;&#31070;&#32463;&#25209;&#35780;&#23478;&#22312;&#21464;&#20998;&#20272;&#35745;&#22120;&#20013;&#30340;&#34892;&#20026;&#65292;&#20197;&#21450;&#23454;&#39564;&#24322;&#24120;&#20540;&#23545;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19988;&#38656;&#35201;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#20449;&#24687;&#37327;&#21270;&#20102;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#22312;&#24494;&#20998;&#21516;&#32986;&#19979;&#20445;&#25345;&#19981;&#21464;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#36825;&#26159;&#20114;&#20449;&#24687;&#30340;&#25512;&#24191;&#24418;&#24335;&#65292;&#20445;&#25345;&#20102;&#36825;&#31181;&#19981;&#21464;&#24615;&#12290;&#25105;&#20204;&#22312;&#35299;&#26512;&#19978;&#25551;&#36848;&#20102;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#30340;&#29305;&#24449;&#65292;&#24182;&#24341;&#20837;&#20102;&#32454;&#20998;&#24067;&#23478;&#26063;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#36924;&#36817;&#36825;&#31181;&#29305;&#24449;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#32454;&#20998;&#24067;&#26469;&#30740;&#31350;&#29616;&#26377;&#20114;&#20449;&#24687;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#35843;&#26597;&#22312;&#21464;&#20998;&#20272;&#35745;&#22120;&#20013;&#20351;&#29992;&#30340;&#31070;&#32463;&#25209;&#35780;&#23478;&#30340;&#34892;&#20026;&#65292;&#24182;&#20102;&#35299;&#23454;&#39564;&#24322;&#24120;&#20540;&#23545;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#32454;&#20998;&#24067;&#26469;&#33719;&#24471;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#20114;&#20449;&#24687;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#21487;&#29992;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19988;&#38656;&#35201;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mutual information quantifies the dependence between two random variables and remains invariant under diffeomorphisms. In this paper, we explore the pointwise mutual information profile, an extension of mutual information that maintains this invariance. We analytically describe the profiles of multivariate normal distributions and introduce the family of fine distributions, for which the profile can be accurately approximated using Monte Carlo methods. We then show how fine distributions can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how fine distributions can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#30340;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;</title><link>http://arxiv.org/abs/2310.04283</link><description>&lt;p&gt;
&#20851;&#20110;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#22312;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#35823;&#24046;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
On the Error-Propagation of Inexact Deflation for Principal Component Analysis. (arXiv:2310.04283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04283
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#30340;&#35823;&#24046;&#20256;&#25773;&#38382;&#39064;&#65292;&#32473;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#25968;&#25454;&#20998;&#26512;&#20013;&#24120;&#29992;&#30340;&#24037;&#20855;&#65292;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#25968;&#25454;&#24773;&#20917;&#19979;&#12290;PCA&#26088;&#22312;&#25214;&#21040;&#30001;&#25152;&#35859;&#8220;&#20027;&#25104;&#20998;&#8221;&#25152;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#65292;&#36825;&#20123;&#20027;&#25104;&#20998;&#26368;&#33021;&#35299;&#37322;&#25968;&#25454;&#38598;&#30340;&#26041;&#24046;&#12290;&#28040;&#38500;&#27861;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20803;&#31639;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#36825;&#26679;&#30340;&#23376;&#31354;&#38388;&#65292;&#23427;&#20174;&#26368;&#37325;&#35201;&#30340;&#20027;&#25104;&#20998;&#24320;&#22987;&#39034;&#24207;&#22320;&#25214;&#21040;&#27599;&#20010;&#20027;&#25104;&#20998;&#65292;&#30452;&#21040;&#25214;&#21040;&#36739;&#19981;&#37325;&#35201;&#30340;&#20027;&#25104;&#20998;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#39034;&#24207;&#24615;&#36136;&#65292;&#30001;&#20110;&#19981;&#23436;&#20840;&#20272;&#35745;&#20027;&#25104;&#20998;&#24341;&#20837;&#30340;&#25968;&#20540;&#35823;&#24046; - &#20363;&#22914;&#65292;&#30001;&#20110;&#27492;&#36807;&#31243;&#20013;&#30340;&#25968;&#20540;&#36817;&#20284; - &#20250;&#38543;&#30528;&#28040;&#38500;&#30340;&#36827;&#34892;&#32780;&#20256;&#25773;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#31687;&#22312;&#25968;&#23398;&#19978;&#23545;&#19981;&#31934;&#30830;&#28040;&#38500;&#27861;&#30340;&#35823;&#24046;&#20256;&#25773;&#36827;&#34892;&#20102;&#29305;&#24615;&#21270;&#30340;&#24037;&#20316;&#65292;&#36825;&#26159;&#26412;&#25991;&#30340;&#20851;&#38190;&#36129;&#29486;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#65306;$ i&#65289;$&#24403;&#29992;&#20110;&#26597;&#25214;&#20027;&#35201;&#29305;&#24449;&#21521;&#37327;&#30340;&#23376;&#20363;&#31243;&#26159;&#27867;&#22411;&#30340;&#26102;&#20505;&#65292;&#20197;&#21450;$ ii&#65289;$
&lt;/p&gt;
&lt;p&gt;
Principal Component Analysis (PCA) is a popular tool in data analysis, especially when the data is high-dimensional. PCA aims to find subspaces, spanned by the so-called \textit{principal components}, that best explain the variance in the dataset. The deflation method is a popular meta-algorithm -used to discover such subspaces -- that sequentially finds individual principal components, starting from the most important one and working its way towards the less important ones. However, due to its sequential nature, the numerical error introduced by not estimating principal components exactly -- e.g., due to numerical approximations through this process -- propagates, as deflation proceeds. To the best of our knowledge, this is the first work that mathematically characterizes the error propagation of the inexact deflation method, and this is the key contribution of this paper. We provide two main results: $i)$ when the sub-routine for finding the leading eigenvector is generic, and $ii)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#19982;&#26680;&#26041;&#27861;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#34429;&#28982;&#22312;&#21512;&#25104;&#26550;&#26500;&#20013;&#23637;&#31034;&#20102;&#19968;&#20123;&#20248;&#21183;&#65292;&#22914;&#26356;&#24555;&#30340;&#20248;&#21270;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#23454;&#38469;&#30456;&#20851;&#30340;&#26550;&#26500;&#38656;&#35201;&#27604;&#28145;&#24230;&#22823;&#24456;&#22810;&#20493;&#30340;&#23485;&#24230;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.00137</link><description>&lt;p&gt;
&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#19982;&#23454;&#36341;&#30340;&#33073;&#33410;
&lt;/p&gt;
&lt;p&gt;
On the Disconnect Between Theory and Practice of Overparametrized Neural Networks. (arXiv:2310.00137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#19982;&#26680;&#26041;&#27861;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#34429;&#28982;&#22312;&#21512;&#25104;&#26550;&#26500;&#20013;&#23637;&#31034;&#20102;&#19968;&#20123;&#20248;&#21183;&#65292;&#22914;&#26356;&#24555;&#30340;&#20248;&#21270;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20294;&#23454;&#38469;&#30456;&#20851;&#30340;&#26550;&#26500;&#38656;&#35201;&#27604;&#28145;&#24230;&#22823;&#24456;&#22810;&#20493;&#30340;&#23485;&#24230;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#30340;&#26080;&#31351;&#23485;&#24230;&#26497;&#38480;&#20316;&#20026;&#20998;&#26512;&#22823;&#35268;&#27169;&#12289;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#34892;&#20026;&#30340;&#29702;&#35770;&#26694;&#26550;&#24050;&#32463;&#24341;&#36215;&#20102;&#37325;&#35201;&#20851;&#27880;&#12290;&#36890;&#36807;&#25509;&#36817;&#26080;&#38480;&#23485;&#24230;&#65292;NNs&#21487;&#20197;&#26377;&#25928;&#22320;&#25910;&#25947;&#21040;&#19968;&#20010;&#20855;&#26377;&#30001;&#31070;&#32463;&#20999;&#32447;&#26680;(NTK)&#29305;&#24449;&#21270;&#30340;&#32447;&#24615;&#27169;&#22411;&#12290;&#36825;&#24314;&#31435;&#20102;NNs&#21644;&#26680;&#26041;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#21518;&#32773;&#26159;&#34987;&#20805;&#20998;&#29702;&#35299;&#30340;&#12290;&#22522;&#20110;&#36825;&#31181;&#32852;&#31995;&#65292;&#24050;&#32463;&#20551;&#35774;&#24182;&#22312;&#21512;&#25104;&#26550;&#26500;&#20013;&#20174;&#29702;&#35770;&#19978;&#21644;&#31639;&#27861;&#19978;&#39564;&#35777;&#20102;&#19968;&#20123;&#20248;&#21183;&#12290;&#36825;&#20123;&#20248;&#21183;&#21253;&#25324;&#26356;&#24555;&#30340;&#20248;&#21270;&#12289;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#25913;&#36827;&#30340;&#25345;&#32493;&#23398;&#20064;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#37327;&#21270;&#21521;&#26680;&#24515;&#39046;&#22495;&#25910;&#25947;&#36895;&#24230;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21033;&#29992;&#36825;&#20123;&#20248;&#21183;&#38656;&#35201;&#27604;&#28145;&#24230;&#22823;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#26550;&#26500;&#12290;&#36825;&#20010;&#20551;&#35774;&#24341;&#21457;&#20102;&#23545;&#23454;&#38469;&#30456;&#20851;&#26550;&#26500;&#26159;&#21542;&#34920;&#29616;&#22914;&#39044;&#27979;&#30340;&#25285;&#24551;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinite-width limit of neural networks (NNs) has garnered significant attention as a theoretical framework for analyzing the behavior of large-scale, overparametrized networks. By approaching infinite width, NNs effectively converge to a linear model with features characterized by the neural tangent kernel (NTK). This establishes a connection between NNs and kernel methods, the latter of which are well understood. Based on this link, theoretical benefits and algorithmic improvements have been hypothesized and empirically demonstrated in synthetic architectures. These advantages include faster optimization, reliable uncertainty quantification and improved continual learning. However, current results quantifying the rate of convergence to the kernel regime suggest that exploiting these benefits requires architectures that are orders of magnitude wider than they are deep. This assumption raises concerns that practically relevant architectures do not exhibit behavior as predicted via 
&lt;/p&gt;</description></item><item><title>SGD&#22312;&#35757;&#32451;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#26102;&#65292;&#20250;&#38543;&#26426;&#22320;&#23558;&#21160;&#24577;&#21560;&#24341;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#36825;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#33021;&#22815;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.04251</link><description>&lt;p&gt;
&#38543;&#26426;&#22349;&#32553;&#65306;&#22914;&#20309;&#21033;&#29992;&#26799;&#24230;&#22122;&#22768;&#20351;SGD&#21160;&#24577;&#36235;&#21521;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks. (arXiv:2306.04251v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04251
&lt;/p&gt;
&lt;p&gt;
SGD&#22312;&#35757;&#32451;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#26102;&#65292;&#20250;&#38543;&#26426;&#22320;&#23558;&#21160;&#24577;&#21560;&#24341;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#36825;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#33021;&#22815;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#19968;&#20010;&#24378;&#28872;&#38544;&#24335;&#20559;&#22909;&#65292;&#23427;&#23558;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#39537;&#21160;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#20102;&#29420;&#31435;&#21442;&#25968;&#30340;&#25968;&#37327;&#65292;&#24182;&#25552;&#39640;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#25581;&#31034;&#36825;&#20010;&#20559;&#22909;&#65292;&#25105;&#20204;&#35782;&#21035;&#20102;&#19981;&#21464;&#38598;&#65292;&#25110;&#32773;&#35828;&#26159;SGD&#26410;&#20462;&#25913;&#30340;&#21442;&#25968;&#31354;&#38388;&#30340;&#23376;&#38598;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20004;&#31867;&#19981;&#21464;&#38598;&#65292;&#23427;&#20204;&#23545;&#24212;&#20110;&#29616;&#20195;&#26550;&#26500;&#20013;&#24120;&#35265;&#30340;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;SGD&#22312;&#36825;&#20123;&#31616;&#21333;&#19981;&#21464;&#38598;&#26041;&#38754;&#20855;&#26377;&#38543;&#26426;&#21560;&#24341;&#24615;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#26681;&#25454;&#25439;&#22833;&#26223;&#35266;&#22312;&#19981;&#21464;&#38598;&#21608;&#22260;&#30340;&#26354;&#29575;&#21644;&#38543;&#26426;&#26799;&#24230;&#24341;&#20837;&#30340;&#22122;&#22768;&#20043;&#38388;&#30340;&#31454;&#20105;&#24314;&#31435;&#20102;&#19968;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22686;&#21152;&#22122;&#22768;&#27700;&#24179;&#20250;&#22686;&#24378;&#21560;&#24341;&#21147;&#65292;&#23548;&#33268;&#19982;&#38797;&#28857;&#25110;&#35757;&#32451;&#25439;&#22833;&#30340;&#23616;&#37096;&#26497;&#22823;&#20540;&#30456;&#20851;&#30340;&#21560;&#24341;&#19981;&#21464;&#38598;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we reveal a strong implicit bias of stochastic gradient descent (SGD) that drives overly expressive networks to much simpler subnetworks, thereby dramatically reducing the number of independent parameters, and improving generalization. To reveal this bias, we identify invariant sets, or subsets of parameter space that remain unmodified by SGD. We focus on two classes of invariant sets that correspond to simpler subnetworks and commonly appear in modern architectures. Our analysis uncovers that SGD exhibits a property of stochastic attractivity towards these simpler invariant sets. We establish a sufficient condition for stochastic attractivity based on a competition between the loss landscape's curvature around the invariant set and the noise introduced by stochastic gradients. Remarkably, we find that an increased level of noise strengthens attractivity, leading to the emergence of attractive invariant sets associated with saddle-points or local maxima of the train loss.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.16905</link><description>&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65306;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#39640;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference. (arXiv:2305.16905v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#40657;&#30418;&#24615;&#36136;&#38459;&#30861;&#20102;&#35299;&#37322;&#24615;&#12290;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;NAM&#65289;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#20998;&#20026;&#21152;&#24615;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#20351;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#20114;&#21464;&#24471;&#26126;&#26174;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#65306;a&#65289;&#23427;&#36890;&#36807;&#20272;&#35745;&#23376;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#19981;&#30830;&#23450;&#24615;&#20026;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65307;b&#65289;&#23427;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#36807;&#31243;&#25191;&#34892;&#29305;&#24449;&#30340;&#38544;&#24335;&#36873;&#25321;&#65307;c&#65289;&#23427;&#21487;&#29992;&#20110;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#65292;&#20316;&#20026;&#31934;&#32454;&#35843;&#25972;&#30340;&#20132;&#20114;&#27169;&#22411;&#20505;&#36873;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;LA-NAM&#65289;&#25552;&#39640;&#20102;NAM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#23376;&#32593;&#32476;&#30340;&#20132;&#20114;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38750;&#23545;&#25968;&#20984;&#20998;&#24067;&#36827;&#34892;&#36817;&#20284;&#25277;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807; Langevin Monte Carlo &#31639;&#27861;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#36825;&#20123;&#20219;&#21153;&#28304;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#22270;&#20687;&#21453;&#38382;&#39064;&#12290;&#25968;&#20540;&#27169;&#25311;&#27604;&#36739;&#20102;&#26368;&#24120;&#29992;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15988</link><description>&lt;p&gt;
&#38750;&#23545;&#25968;&#20984;&#21644;&#38750;&#20809;&#28369;&#37319;&#26679;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-Log-Concave and Nonsmooth Sampling via Langevin Monte Carlo Algorithms. (arXiv:2305.15988v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38750;&#23545;&#25968;&#20984;&#20998;&#24067;&#36827;&#34892;&#36817;&#20284;&#25277;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807; Langevin Monte Carlo &#31639;&#27861;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#36825;&#20123;&#20219;&#21153;&#28304;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#22270;&#20687;&#21453;&#38382;&#39064;&#12290;&#25968;&#20540;&#27169;&#25311;&#27604;&#36739;&#20102;&#26368;&#24120;&#29992;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38750;&#23545;&#25968;&#20984;&#20998;&#24067;&#65288;&#20363;&#22914;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65289;&#36827;&#34892;&#36817;&#20284;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#31163;&#25955;&#36807;&#24230;&#38459;&#23612; Langevin &#25193;&#25955;&#25152;&#23548;&#20986;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#31216;&#20026; Langevin Monte Carlo &#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#20854;&#20013;&#24050;&#32463;&#24320;&#21457;&#20102;&#22823;&#37327;&#30340;&#36817;&#31471; MCMC &#26041;&#27861;&#65306;(i) &#32771;&#34385;&#21040;&#38750;&#20809;&#28369;&#30340;&#20808;&#39564;&#21644;&#39640;&#26031;&#28151;&#21512;&#20284;&#28982;&#65307;(ii) &#25289;&#26222;&#25289;&#26031;&#28151;&#21512;&#20998;&#24067;&#12290;&#36825;&#26679;&#30340;&#38750;&#20809;&#28369;&#21644;&#38750;&#23545;&#25968;&#20984;&#37319;&#26679;&#20219;&#21153;&#28304;&#20110;&#24191;&#27867;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#22270;&#20687;&#21453;&#38382;&#39064;&#65292;&#22914;&#22270;&#20687;&#21453;&#35126;&#31215;&#20013;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#27169;&#25311;&#20197;&#27604;&#36739;&#26368;&#24120;&#29992;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of approximate sampling from non-log-concave distributions, e.g., Gaussian mixtures, which is often challenging even in low dimensions due to their multimodality. We focus on performing this task via Markov chain Monte Carlo (MCMC) methods derived from discretizations of the overdamped Langevin diffusions, which are commonly known as Langevin Monte Carlo algorithms. Furthermore, we are also interested in two nonsmooth cases for which a large class of proximal MCMC methods have been developed: (i) a nonsmooth prior is considered with a Gaussian mixture likelihood; (ii) a Laplacian mixture distribution. Such nonsmooth and non-log-concave sampling tasks arise from a wide range of applications to Bayesian inference and imaging inverse problems such as image deconvolution. We perform numerical simulations to compare the performance of most commonly used Langevin Monte Carlo algorithms.
&lt;/p&gt;</description></item><item><title>MRCpy&#26159;&#19968;&#31181;&#29992;&#20110;&#23454;&#29616;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;Python&#24211;&#65292;&#23427;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#21033;&#29992;0-1&#25439;&#22833;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#20998;&#31867;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20123;&#25552;&#20379;&#20102;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2108.01952</link><description>&lt;p&gt;
MRCpy&#65306;&#19968;&#31181;&#29992;&#20110;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#24211;
&lt;/p&gt;
&lt;p&gt;
MRCpy: A Library for Minimax Risk Classifiers. (arXiv:2108.01952v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.01952
&lt;/p&gt;
&lt;p&gt;
MRCpy&#26159;&#19968;&#31181;&#29992;&#20110;&#23454;&#29616;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;Python&#24211;&#65292;&#23427;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#21033;&#29992;0-1&#25439;&#22833;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#20998;&#31867;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20123;&#25552;&#20379;&#20102;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#29616;&#26377;&#30340;&#30417;&#30563;&#20998;&#31867;&#24211;&#37117;&#26159;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20351;&#29992;&#20195;&#29702;&#25439;&#22833;&#25216;&#26415;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;MRCpy&#24211;&#65292;&#35813;&#24211;&#23454;&#29616;&#20102;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRC&#65289;&#65292;&#24182;&#21487;&#21033;&#29992;0-1&#25439;&#22833;&#12290;&#36825;&#31181;&#25216;&#26415;&#20135;&#29983;&#20102;&#35768;&#22810;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;MRCpy&#20026;&#19981;&#21516;&#21464;&#37327;&#30340;MRC&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#25509;&#21475;&#65292;&#24182;&#36981;&#24490;&#27969;&#34892;Python&#24211;&#30340;&#26631;&#20934;&#12290;&#27492;&#22806;&#65292;MRCpy&#36824;&#25552;&#20379;&#20102;&#23454;&#29616;&#19968;&#20123;&#27969;&#34892;&#25216;&#26415;&#30340;&#21151;&#33021;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#30475;&#20316;&#26159;MRC&#65292;&#20363;&#22914;L1&#27491;&#21017;&#21270;&#36923;&#36753;&#22238;&#24402;&#65292;0-1&#23545;&#25239;&#24615;&#21644;&#26368;&#22823;&#29109;&#26426;&#12290;&#27492;&#22806;&#65292;MRCpy&#36824;&#23454;&#29616;&#20102;&#26368;&#36817;&#30340;&#29305;&#24449;&#26144;&#23556;&#65292;&#22914;&#20613;&#37324;&#21494;&#65292;ReLU&#21644;&#38408;&#20540;&#29305;&#24449;&#12290;&#35813;&#24211;&#37319;&#29992;&#38754;&#21521;&#23545;&#35937;&#30340;&#26041;&#27861;&#35774;&#35745;&#65292;&#26041;&#20415;&#21327;&#20316;&#32773;&#21644;&#29992;&#25143;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing libraries for supervised classification implement techniques that are based on empirical risk minimization and utilize surrogate losses. We present MRCpy library that implements minimax risk classifiers (MRCs) that are based on robust risk minimization and can utilize 0-1-loss. Such techniques give rise to a manifold of classification methods that can provide tight bounds on the expected loss. MRCpy provides a unified interface for different variants of MRCs and follows the standards of popular Python libraries. The presented library also provides implementation for popular techniques that can be seen as MRCs such as L1-regularized logistic regression, zero-one adversarial, and maximum entropy machines. In addition, MRCpy implements recent feature mappings such as Fourier, ReLU, and threshold features. The library is designed with an object-oriented approach that facilitates collaborators and users.
&lt;/p&gt;</description></item></channel></rss>