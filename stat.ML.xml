<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#24102;&#26469;&#26032;&#39062;&#35270;&#35282;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#26631;&#20934;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#20989;&#25968;&#36924;&#36817;&#30340;&#21306;&#21035;&#12290;</title><link>https://arxiv.org/abs/2403.09621</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#20998;&#24067;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09621
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#24102;&#26469;&#26032;&#39062;&#35270;&#35282;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#26631;&#20934;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#20989;&#25968;&#36924;&#36817;&#30340;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#23547;&#27714;&#38024;&#23545;&#29615;&#22659;&#25200;&#21160;&#30340;&#40065;&#26834;&#31574;&#30053;&#35757;&#32451;&#65292;&#36890;&#36807;&#24314;&#27169;&#21160;&#24577;&#19981;&#30830;&#23450;&#24615;&#26469;&#35843;&#29992;&#20989;&#25968;&#36924;&#36817;&#65292;&#24403;&#38754;&#23545;&#24222;&#22823;&#30340;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#26102;&#65292;&#36825;&#31181;RL&#38656;&#35201;&#32771;&#34385;&#21040;&#21160;&#24577;&#19981;&#30830;&#23450;&#24615;&#65292;&#24341;&#20837;&#20102;&#22522;&#26412;&#30340;&#38750;&#32447;&#24615;&#21644;&#35745;&#31639;&#36127;&#25285;&#65292;&#36825;&#32473;&#20998;&#26512;&#21644;&#23454;&#38469;&#24212;&#29992;&#20989;&#25968;&#36924;&#36817;&#25552;&#20986;&#20102;&#29420;&#29305;&#25361;&#25112;&#12290;&#22312;&#22522;&#26412;&#35774;&#32622;&#19979;&#65292;&#25552;&#35758;&#26368;&#23567;&#21270;&#26368;&#20248;&#21644;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20989;&#25968;&#36924;&#36817;&#65292;&#24182;&#22312;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#32972;&#26223;&#19979;&#21551;&#21160;&#23545;&#23454;&#20363;&#30456;&#20851;&#27425;&#20248;&#24615;&#20998;&#26512;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#40065;&#26834;&#31163;&#32447;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#26412;&#36136;&#19978;&#19982;&#26631;&#20934;&#31163;&#32447;RL&#20013;&#30340;&#20989;&#25968;&#36924;&#36817;&#26377;&#26126;&#26174;&#21306;&#21035;&#65292;&#21487;&#33021;&#26356;&#21152;&#22256;&#38590;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#29702;&#35770;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#22320;&#20381;&#36182;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09621v1 Announce Type: cross  Abstract: Distributionally robust offline reinforcement learning (RL), which seeks robust policy training against environment perturbation by modeling dynamics uncertainty, calls for function approximations when facing large state-action spaces. However, the consideration of dynamics uncertainty introduces essential nonlinearity and computational burden, posing unique challenges for analyzing and practically employing function approximation. Focusing on a basic setting where the nominal model and perturbed models are linearly parameterized, we propose minimax optimal and computationally efficient algorithms realizing function approximation and initiate the study on instance-dependent suboptimality analysis in the context of robust offline RL. Our results uncover that function approximation in robust offline RL is essentially distinct from and probably harder than that in standard offline RL. Our algorithms and theoretical results crucially depen
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#21512;&#21464;&#37327;&#30340;&#26497;&#31471;&#22270;&#27169;&#22411;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#24674;&#22797;&#26465;&#20214;&#22270;&#21644;&#28508;&#21464;&#37327;&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.09604</link><description>&lt;p&gt;
&#28151;&#21512;&#21464;&#37327;&#30340;&#26497;&#31471;&#22270;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Extremal graphical modeling with latent variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09604
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#21512;&#21464;&#37327;&#30340;&#26497;&#31471;&#22270;&#27169;&#22411;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#24674;&#22797;&#26465;&#20214;&#22270;&#21644;&#28508;&#21464;&#37327;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26497;&#31471;&#22270;&#27169;&#22411;&#32534;&#30721;&#22810;&#21464;&#37327;&#26497;&#31471;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#65292;&#24182;&#20026;&#37327;&#21270;&#32597;&#35265;&#20107;&#20214;&#39118;&#38505;&#25552;&#20379;&#24378;&#22823;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38754;&#21521;&#28508;&#21464;&#37327;&#30340;&#21487;&#24310;&#20280;&#22270;&#27169;&#22411;&#30340;&#21487;&#34892;&#20984;&#35268;&#21010;&#26041;&#27861;&#65292;&#23558; H\"usler-Reiss &#31934;&#24230;&#30697;&#38453;&#20998;&#35299;&#20026;&#32534;&#30721;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22270;&#32467;&#26500;&#30340;&#31232;&#30095;&#37096;&#20998;&#21644;&#32534;&#30721;&#23569;&#37327;&#28508;&#21464;&#37327;&#23545;&#35266;&#23519;&#21464;&#37327;&#30340;&#24433;&#21709;&#30340;&#20302;&#31209;&#37096;&#20998;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;\texttt{eglatent}&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#23427;&#33021;&#19968;&#33268;&#22320;&#24674;&#22797;&#26465;&#20214;&#22270;&#20197;&#21450;&#28508;&#21464;&#37327;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09604v1 Announce Type: cross  Abstract: Extremal graphical models encode the conditional independence structure of multivariate extremes and provide a powerful tool for quantifying the risk of rare events. Prior work on learning these graphs from data has focused on the setting where all relevant variables are observed. For the popular class of H\"usler-Reiss models, we propose the \texttt{eglatent} method, a tractable convex program for learning extremal graphical models in the presence of latent variables. Our approach decomposes the H\"usler-Reiss precision matrix into a sparse component encoding the graphical structure among the observed variables after conditioning on the latent variables, and a low-rank component encoding the effect of a few latent variables on the observed variables. We provide finite-sample guarantees of \texttt{eglatent} and show that it consistently recovers the conditional graph as well as the number of latent variables. We highlight the improved 
&lt;/p&gt;</description></item><item><title>VISA&#26041;&#27861;&#36890;&#36807;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#22312;&#35745;&#31639;&#23494;&#38598;&#22411;&#27169;&#22411;&#20013;&#23454;&#29616;&#36817;&#20284;&#25512;&#26029;&#65292;&#33021;&#22815;&#22312;&#20445;&#23432;&#36873;&#25321;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#20197;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26631;&#20934;&#26041;&#27861;&#30456;&#24403;&#30340;&#36924;&#36817;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.09429</link><description>&lt;p&gt;
&#20855;&#26377;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Inference with Sequential Sample-Average Approximations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09429
&lt;/p&gt;
&lt;p&gt;
VISA&#26041;&#27861;&#36890;&#36807;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#22312;&#35745;&#31639;&#23494;&#38598;&#22411;&#27169;&#22411;&#20013;&#23454;&#29616;&#36817;&#20284;&#25512;&#26029;&#65292;&#33021;&#22815;&#22312;&#20445;&#23432;&#36873;&#25321;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#20197;&#36739;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26631;&#20934;&#26041;&#27861;&#30456;&#24403;&#30340;&#36924;&#36817;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#39034;&#24207;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#65288;VISA&#65289;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#35745;&#31639;&#23494;&#38598;&#22411;&#27169;&#22411;&#20013;&#36827;&#34892;&#36817;&#20284;&#25512;&#26029;&#65292;&#20363;&#22914;&#22522;&#20110;&#25968;&#20540;&#27169;&#25311;&#30340;&#27169;&#22411;&#12290;VISA&#36890;&#36807;&#37319;&#29992;&#19968;&#31995;&#21015;&#26679;&#26412;&#22343;&#20540;&#36924;&#36817;&#26469;&#25193;&#23637;&#37325;&#35201;&#24615;&#21152;&#26435;&#30340;&#21069;&#21521;KL&#21464;&#20998;&#25512;&#26029;&#65292;&#36825;&#20123;&#36924;&#36817;&#22312;&#20449;&#20219;&#21306;&#22495;&#20869;&#34987;&#35270;&#20026;&#26377;&#25928;&#12290;&#36825;&#20351;&#24471;&#21487;&#20197;&#22312;&#22810;&#20010;&#26799;&#24230;&#27493;&#39588;&#20013;&#37325;&#22797;&#20351;&#29992;&#27169;&#22411;&#35780;&#20272;&#65292;&#20174;&#32780;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#39640;&#26031;&#20998;&#24067;&#12289;Lotka-Volterra&#21160;&#21147;&#23398;&#21644;Pickover&#21560;&#24341;&#23376;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;VISA&#21487;&#20197;&#22312;&#36873;&#25321;&#20445;&#23432;&#30340;&#23398;&#20064;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#20004;&#20493;&#25110;&#26356;&#39640;&#30340;&#35745;&#31639;&#33410;&#32422;&#36798;&#21040;&#19982;&#26631;&#20934;&#37325;&#35201;&#24615;&#21152;&#26435;&#21069;&#21521;KL&#21464;&#20998;&#25512;&#26029;&#30456;&#24403;&#30340;&#36924;&#36817;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09429v1 Announce Type: cross  Abstract: We present variational inference with sequential sample-average approximation (VISA), a method for approximate inference in computationally intensive models, such as those based on numerical simulations. VISA extends importance-weighted forward-KL variational inference by employing a sequence of sample-average approximations, which are considered valid inside a trust region. This makes it possible to reuse model evaluations across multiple gradient steps, thereby reducing computational cost. We perform experiments on high-dimensional Gaussians, Lotka-Volterra dynamics, and a Pickover attractor, which demonstrate that VISA can achieve comparable approximation accuracy to standard importance-weighted forward-KL variational inference with computational savings of a factor two or more for conservatively chosen learning rates.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;Metropolis-within-Gibbs&#26041;&#26696;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24314;&#31435;&#20102;&#19982;&#25968;&#20540;&#35777;&#25454;&#23494;&#20999;&#19968;&#33268;&#30340;&#19982;&#32500;&#24230;&#26080;&#20851;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#22312;&#20108;&#20803;&#22238;&#24402;&#21644;&#31163;&#25955;&#35266;&#23519;&#25193;&#25955;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.09416</link><description>&lt;p&gt;
Metropolis-within-Gibbs&#26041;&#26696;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;
&lt;/p&gt;
&lt;p&gt;
Scalability of Metropolis-within-Gibbs schemes for high-dimensional Bayesian models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09416
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;Metropolis-within-Gibbs&#26041;&#26696;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24314;&#31435;&#20102;&#19982;&#25968;&#20540;&#35777;&#25454;&#23494;&#20999;&#19968;&#33268;&#30340;&#19982;&#32500;&#24230;&#26080;&#20851;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#22312;&#20108;&#20803;&#22238;&#24402;&#21644;&#31163;&#25955;&#35266;&#23519;&#25193;&#25955;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#33324;&#30340;&#22352;&#26631;&#36880;&#27493;MCMC&#26041;&#26696;&#65288;&#22914;Metropolis-within-Gibbs&#25277;&#26679;&#22120;&#65289;&#65292;&#36825;&#20123;&#26041;&#26696;&#36890;&#24120;&#29992;&#20110;&#25311;&#21512;&#36125;&#21494;&#26031;&#38750;&#20849;&#36717;&#20998;&#23618;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#36136;&#19982;&#30456;&#24212;&#30340;&#65288;&#21487;&#33021;&#26080;&#27861;&#23454;&#29616;&#30340;&#65289;Gibbs&#25277;&#26679;&#22120;&#30340;&#27010;&#24565;&#32852;&#31995;&#36215;&#26469;&#65292;&#36890;&#36807;&#26465;&#20214;&#23548;&#32435;&#30340;&#27010;&#24565;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#30740;&#31350;&#27969;&#34892;&#30340;Metropolis-within-Gibbs&#26041;&#26696;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65288;&#25968;&#25454;&#28857;&#21644;&#21442;&#25968;&#21516;&#26102;&#22686;&#21152;&#65289;&#30340;&#38750;&#20849;&#36717;&#20998;&#23618;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#32473;&#23450;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#25968;&#20540;&#35777;&#25454;&#23494;&#20999;&#19968;&#33268;&#30340;&#19982;&#32500;&#24230;&#26080;&#20851;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;&#36824;&#35752;&#35770;&#20102;&#22312;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#20108;&#20803;&#22238;&#24402;&#36125;&#21494;&#26031;&#27169;&#22411;&#21644;&#31163;&#25955;&#35266;&#23519;&#25193;&#25955;&#26041;&#38754;&#30340;&#24212;&#29992;&#12290;&#21463;&#36825;&#31867;&#32479;&#35745;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#20851;&#20110;&#36817;&#20284;&#23548;&#32435;&#21644;&#25200;&#21160;&#30340;&#29420;&#31435;&#20852;&#36259;&#30340;&#36741;&#21161;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09416v1 Announce Type: cross  Abstract: We study general coordinate-wise MCMC schemes (such as Metropolis-within-Gibbs samplers), which are commonly used to fit Bayesian non-conjugate hierarchical models. We relate their convergence properties to the ones of the corresponding (potentially not implementable) Gibbs sampler through the notion of conditional conductance. This allows us to study the performances of popular Metropolis-within-Gibbs schemes for non-conjugate hierarchical models, in high-dimensional regimes where both number of datapoints and parameters increase. Given random data-generating assumptions, we establish dimension-free convergence results, which are in close accordance with numerical evidences. Applications to Bayesian models for binary regression with unknown hyperparameters and discretely observed diffusions are also discussed. Motivated by such statistical applications, auxiliary results of independent interest on approximate conductances and perturba
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;pantypes&#65292;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#19968;&#32452;&#31232;&#30095;&#23545;&#35937;&#25429;&#33719;&#36755;&#20837;&#20998;&#24067;&#30340;&#20840;&#37096;&#22810;&#26679;&#24615;&#30340;&#21407;&#22411;&#23545;&#35937;&#23478;&#26063;&#65292;&#21487;&#20197;&#22823;&#22823;&#22686;&#24378;&#21407;&#22411;&#33258;&#35299;&#37322;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.09383</link><description>&lt;p&gt;
Pantypes: &#20195;&#34920;&#21508;&#31181;&#31867;&#22411;&#30340;&#33258;&#35299;&#37322;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Pantypes: Diverse Representatives for Self-Explainable Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09383
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;pantypes&#65292;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#19968;&#32452;&#31232;&#30095;&#23545;&#35937;&#25429;&#33719;&#36755;&#20837;&#20998;&#24067;&#30340;&#20840;&#37096;&#22810;&#26679;&#24615;&#30340;&#21407;&#22411;&#23545;&#35937;&#23478;&#26063;&#65292;&#21487;&#20197;&#22823;&#22823;&#22686;&#24378;&#21407;&#22411;&#33258;&#35299;&#37322;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#26085;&#30410;&#22686;&#38271;&#30340;&#38656;&#27714;&#65292;&#21407;&#22411;&#33258;&#35299;&#37322;&#20998;&#31867;&#22120;&#24050;&#32463;&#20986;&#29616;&#12290;&#36825;&#20123;&#20998;&#31867;&#22120;&#26088;&#22312;&#36890;&#36807;&#22522;&#20110;&#19982;&#23398;&#20064;&#30340;&#21407;&#22411;&#23545;&#35937;&#30340;&#30456;&#20284;&#24615;&#36827;&#34892;&#25512;&#29702;&#65292;&#20197;&#22312;&#20915;&#31574;&#20013;&#34701;&#20837;&#39640;&#36879;&#26126;&#24230;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#22312;&#35774;&#35745;&#26102;&#32771;&#34385;&#20102;&#22810;&#26679;&#24615;&#65292;&#20294;&#23398;&#20064;&#30340;&#21407;&#22411;&#23545;&#35937;&#36890;&#24120;&#24182;&#19981;&#36275;&#20197;&#20805;&#20998;&#20195;&#34920;&#25152;&#26377;&#36755;&#20837;&#20998;&#24067;&#30340;&#26041;&#38754;&#65292;&#23588;&#20854;&#26159;&#20302;&#23494;&#24230;&#21306;&#22495;&#20013;&#30340;&#26041;&#38754;&#12290;&#36825;&#31181;&#19981;&#36275;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#21363;&#34920;&#31034;&#20559;&#24046;&#65292;&#24050;&#32463;&#19982;&#19982;&#26426;&#22120;&#23398;&#20064;&#22810;&#26679;&#24615;&#21644;&#20844;&#24179;&#24615;&#30456;&#20851;&#30340;&#21508;&#31181;&#26377;&#23475;&#29305;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;pantypes&#65292;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#19968;&#32452;&#31232;&#30095;&#23545;&#35937;&#25429;&#33719;&#36755;&#20837;&#20998;&#24067;&#30340;&#20840;&#37096;&#22810;&#26679;&#24615;&#30340;&#21407;&#22411;&#23545;&#35937;&#23478;&#26063;&#12290;&#25105;&#20204;&#23637;&#31034;pantypes&#21487;&#20197;&#36890;&#36807;&#21344;&#25454;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#19981;&#21516;&#21306;&#22495;&#26469;&#22686;&#24378;&#21407;&#22411;&#33258;&#35299;&#37322;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09383v1 Announce Type: cross  Abstract: Prototypical self-explainable classifiers have emerged to meet the growing demand for interpretable AI systems. These classifiers are designed to incorporate high transparency in their decisions by basing inference on similarity with learned prototypical objects. While these models are designed with diversity in mind, the learned prototypes often do not sufficiently represent all aspects of the input distribution, particularly those in low density regions. Such lack of sufficient data representation, known as representation bias, has been associated with various detrimental properties related to machine learning diversity and fairness. In light of this, we introduce pantypes, a new family of prototypical objects designed to capture the full diversity of the input distribution through a sparse set of objects. We show that pantypes can empower prototypical self-explainable models by occupying divergent regions of the latent space and thu
&lt;/p&gt;</description></item><item><title>&#21487;&#31227;&#38500;&#21464;&#37327;&#30340;&#27010;&#24565;&#20801;&#35768;&#36882;&#24402;&#26041;&#27861;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#65292;&#36890;&#36807;&#36880;&#27493;&#20943;&#23569;&#38382;&#39064;&#35268;&#27169;&#26469;&#24110;&#21161;&#35299;&#20915;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.09300</link><description>&lt;p&gt;
&#36882;&#24402;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Recursive Causal Discovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09300
&lt;/p&gt;
&lt;p&gt;
&#21487;&#31227;&#38500;&#21464;&#37327;&#30340;&#27010;&#24565;&#20801;&#35768;&#36882;&#24402;&#26041;&#27861;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#65292;&#36890;&#36807;&#36880;&#27493;&#20943;&#23569;&#38382;&#39064;&#35268;&#27169;&#26469;&#24110;&#21161;&#35299;&#20915;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#20027;&#35201;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09300v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032;&#25688;&#35201;&#65306;&#22240;&#26524;&#21457;&#29616;&#65292;&#21363;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#22270;&#65292;&#36890;&#24120;&#26159;&#35782;&#21035;&#21644;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#30340;&#31532;&#19968;&#27493;&#65292;&#36825;&#26159;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#30340;&#20851;&#38190;&#35201;&#27714;&#12290;&#22240;&#26524;&#21457;&#29616;&#38754;&#20020;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#65306;&#26377;&#38480;&#30340;&#25968;&#25454;&#23548;&#33268;&#32479;&#35745;&#26816;&#39564;&#38169;&#35823;&#65292;&#23398;&#20064;&#20219;&#21153;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20196;&#20154;&#26395;&#32780;&#21364;&#27493;&#12290;&#26412;&#25991;&#22522;&#20110;&#24182;&#25193;&#23637;&#20102;&#25105;&#20204;&#20808;&#21069;&#21457;&#34920;&#30340;&#22235;&#31687;&#35770;&#25991;&#65288;Mokhtarian&#31561;&#65292;2021&#24180;&#65307;Akbari&#31561;&#65292;2021&#24180;&#65307;Mokhtarian&#31561;&#65292;2022&#24180;&#65292;2023a&#24180;&#65289;&#12290;&#36825;&#20123;&#20316;&#21697;&#24341;&#20837;&#20102;&#21487;&#31227;&#38500;&#21464;&#37327;&#30340;&#27010;&#24565;&#65292;&#36825;&#20123;&#21464;&#37327;&#26159;&#21807;&#19968;&#21487;&#20197;&#36882;&#24402;&#31227;&#38500;&#29992;&#20110;&#22240;&#26524;&#21457;&#29616;&#30340;&#21464;&#37327;&#12290;&#21487;&#31227;&#38500;&#21464;&#37327;&#30340;&#23384;&#22312;&#21644;&#35782;&#21035;&#20801;&#35768;&#22240;&#26524;&#21457;&#29616;&#30340;&#36882;&#24402;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#36880;&#27493;&#20943;&#23569;&#38382;&#39064;&#35268;&#27169;&#26469;&#24110;&#21161;&#35299;&#20915;&#21069;&#36848;&#25361;&#25112;&#12290;&#36825;&#31181;&#32553;&#20943;&#19981;&#20165;&#22312;&#27599;&#20010;&#26465;&#20214;&#35774;&#32622;&#20013;&#26368;&#23567;&#21270;&#20102;&#26465;&#20214;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09300v1 Announce Type: new  Abstract: Causal discovery, i.e., learning the causal graph from data, is often the first step toward the identification and estimation of causal effects, a key requirement in numerous scientific domains. Causal discovery is hampered by two main challenges: limited data results in errors in statistical testing and the computational complexity of the learning task is daunting. This paper builds upon and extends four of our prior publications (Mokhtarian et al., 2021; Akbari et al., 2021; Mokhtarian et al., 2022, 2023a). These works introduced the concept of removable variables, which are the only variables that can be removed recursively for the purpose of causal discovery. Presence and identification of removable variables allow recursive approaches for causal discovery, a promising solution that helps to address the aforementioned challenges by reducing the problem size successively. This reduction not only minimizes conditioning sets in each con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#19977;&#23618;&#32447;&#24615;&#32467;&#26500;&#30340;&#37096;&#20998;CBM&#20013;&#25581;&#31034;&#20102;&#36125;&#21494;&#26031;&#27010;&#21270;&#38169;&#35823;&#30340;&#19978;&#30028;&#65292;&#36827;&#19968;&#27493;&#35777;&#26126;&#37096;&#20998;CBM&#20248;&#20110;&#26420;&#32032;CBM&#12290;</title><link>https://arxiv.org/abs/2403.09206</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#27010;&#21270;&#38169;&#35823;&#22312;&#37096;&#20998;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#20013;&#30340;&#19978;&#30028;&#65306;&#37096;&#20998;CBM&#32988;&#36807;&#26420;&#32032;CBM
&lt;/p&gt;
&lt;p&gt;
Upper Bound of Bayesian Generalization Error in Partial Concept Bottleneck Model (CBM): Partial CBM outperforms naive CBM
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#19977;&#23618;&#32447;&#24615;&#32467;&#26500;&#30340;&#37096;&#20998;CBM&#20013;&#25581;&#31034;&#20102;&#36125;&#21494;&#26031;&#27010;&#21270;&#38169;&#35823;&#30340;&#19978;&#30028;&#65292;&#36827;&#19968;&#27493;&#35777;&#26126;&#37096;&#20998;CBM&#20248;&#20110;&#26420;&#32032;CBM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv&#65306;2403.09206v1 &#31867;&#22411;&#36890;&#21578;&#65306;&#20132;&#21449;&#25688;&#35201;&#65306;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBM&#65289;&#26159;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#22312;CBM&#20013;&#65292;&#23545;&#24212;&#20110;&#36755;&#20986;&#21407;&#22240;&#30340;&#27010;&#24565;&#34987;&#25554;&#20837;&#21040;&#26368;&#21518;&#19968;&#20010;&#20013;&#38388;&#23618;&#20316;&#20026;&#35266;&#23519;&#20540;&#12290;&#20154;&#20204;&#39044;&#26399;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#36755;&#20986;&#21644;&#27010;&#24565;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#31867;&#20284;&#20110;&#32447;&#24615;&#22238;&#24402;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35299;&#37322;&#38656;&#35201;&#35266;&#23519;&#25152;&#26377;&#27010;&#24565;&#65292;&#24182;&#19988;&#38477;&#20302;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#37096;&#20998;CBM&#65288;PCBM&#65289;&#20351;&#29992;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#22256;&#38590;&#12290;&#23613;&#31649;&#19968;&#20123;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;PCBM&#30340;&#27867;&#21270;&#24615;&#33021;&#20960;&#20046;&#19982;&#21407;&#22987;&#31070;&#32463;&#32593;&#32476;&#19968;&#26679;&#39640;&#65292;&#20294;&#30001;&#20110;PCBM&#26159;&#22855;&#24322;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#20854;&#27867;&#21270;&#38169;&#35823;&#30340;&#29702;&#35770;&#34892;&#20026;&#23578;&#26410;&#26126;&#30830;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20855;&#26377;&#19977;&#23618;&#32447;&#24615;&#26550;&#26500;&#30340;PCBM&#20013;&#30340;&#36125;&#21494;&#26031;&#27867;&#21270;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09206v1 Announce Type: cross  Abstract: Concept Bottleneck Model (CBM) is a methods for explaining neural networks. In CBM, concepts which correspond to reasons of outputs are inserted in the last intermediate layer as observed values. It is expected that we can interpret the relationship between the output and concept similar to linear regression. However, this interpretation requires observing all concepts and decreases the generalization performance of neural networks. Partial CBM (PCBM), which uses partially observed concepts, has been devised to resolve these difficulties. Although some numerical experiments suggest that the generalization performance of PCBMs is almost as high as that of the original neural networks, the theoretical behavior of its generalization error has not been yet clarified since PCBM is singular statistical model. In this paper, we reveal the Bayesian generalization error in PCBM with a three-layered and linear architecture. The result indcates t
&lt;/p&gt;</description></item><item><title>&#22312;&#20449;&#21495;&#21152;&#38543;&#26426;&#39640;&#26031;&#22122;&#22768;&#30697;&#38453;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25193;&#23637;&#20102;&#23545;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#23376;&#31354;&#38388;&#25200;&#21160;&#30340;Wedin-Davis-Kahan&#23450;&#29702;&#65292;&#33719;&#24471;&#20102;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#23376;&#31354;&#38388;&#30340;&#32454;&#31890;&#24230;&#20998;&#26512;&#32467;&#26524;&#65292;&#24182;&#25506;&#32034;&#20102;&#19982;&#22855;&#24322;&#21521;&#37327;&#30456;&#20851;&#30340;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#20989;&#25968;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#36825;&#20123;&#21457;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#23376;&#30697;&#38453;&#23450;&#20301;&#38382;&#39064;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.09170</link><description>&lt;p&gt;
&#38543;&#26426;&#25200;&#21160;&#19979;&#22855;&#24322;&#23376;&#31354;&#38388;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of singular subspaces under random perturbations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09170
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#21495;&#21152;&#38543;&#26426;&#39640;&#26031;&#22122;&#22768;&#30697;&#38453;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25193;&#23637;&#20102;&#23545;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#23376;&#31354;&#38388;&#25200;&#21160;&#30340;Wedin-Davis-Kahan&#23450;&#29702;&#65292;&#33719;&#24471;&#20102;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#23376;&#31354;&#38388;&#30340;&#32454;&#31890;&#24230;&#20998;&#26512;&#32467;&#26524;&#65292;&#24182;&#25506;&#32034;&#20102;&#19982;&#22855;&#24322;&#21521;&#37327;&#30456;&#20851;&#30340;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#20989;&#25968;&#65292;&#21516;&#26102;&#25506;&#35752;&#20102;&#36825;&#20123;&#21457;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#23376;&#30697;&#38453;&#23450;&#20301;&#38382;&#39064;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20449;&#21495;&#21152;&#38543;&#26426;&#39640;&#26031;&#22122;&#22768;&#30697;&#38453;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#23545;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#23376;&#31354;&#38388;&#30340;&#25200;&#21160;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#12290;&#20551;&#35774;&#19968;&#20010;&#20302;&#31209;&#20449;&#21495;&#30697;&#38453;&#65292;&#25105;&#20204;&#20197;&#19968;&#31181;&#23436;&#20840;&#27867;&#21270;&#30340;&#26041;&#24335;&#25193;&#23637;&#20102;Wedin-Davis-Kahan&#23450;&#29702;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#37193;&#19981;&#21464;&#30697;&#38453;&#33539;&#25968;&#65292;&#25193;&#23637;&#20102;O'Rourke&#12289;Vu&#21644;&#20316;&#32773;&#20043;&#21069;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#33719;&#24471;&#20102;&#32454;&#31890;&#24230;&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;&#21253;&#25324;&#22855;&#24322;&#21521;&#37327;&#30340;$\ell_\infty$&#20998;&#26512;&#65292;&#22855;&#24322;&#23376;&#31354;&#38388;&#30340;$\ell_{2,\infty}$&#20998;&#26512;&#65292;&#20197;&#21450;&#19982;&#22855;&#24322;&#21521;&#37327;&#30456;&#20851;&#30340;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#20989;&#25968;&#30340;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#20123;&#21457;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#23376;&#30697;&#38453;&#23450;&#20301;&#38382;&#39064;&#30340;&#23454;&#38469;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09170v1 Announce Type: cross  Abstract: We present a comprehensive analysis of singular vector and singular subspace perturbations in the context of the signal plus random Gaussian noise matrix model. Assuming a low-rank signal matrix, we extend the Wedin-Davis-Kahan theorem in a fully generalized manner, applicable to any unitarily invariant matrix norm, extending previous results of O'Rourke, Vu and the author. We also obtain the fine-grained results, which encompass the $\ell_\infty$ analysis of singular vectors, the $\ell_{2, \infty}$ analysis of singular subspaces, as well as the exploration of linear and bilinear functions related to the singular vectors. Moreover, we explore the practical implications of these findings, in the context of the Gaussian mixture model and the submatrix localization problem.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#21644;PCR&#29305;&#23450;&#22122;&#22768;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#22312;&#38750;&#33258;&#36866;&#24212;&#35774;&#32622;&#20013;&#20934;&#30830;&#25512;&#26029;&#29616;&#23454;&#30149;&#27602;&#36733;&#37327;&#20449;&#21495;&#65292;&#20026;&#20855;&#26377;&#20020;&#24202;&#37325;&#35201;&#24615;&#30340;&#30149;&#27602;&#36733;&#37327;&#27979;&#23450;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09130</link><description>&lt;p&gt;
&#38750;&#33258;&#36866;&#24212;&#27744;&#21270;&#26816;&#27979;&#20013;&#30340;&#30149;&#27602;&#36733;&#37327;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Viral Load Inference in Non-Adaptive Pooled Testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09130
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#21644;PCR&#29305;&#23450;&#22122;&#22768;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#22312;&#38750;&#33258;&#36866;&#24212;&#35774;&#32622;&#20013;&#20934;&#30830;&#25512;&#26029;&#29616;&#23454;&#30149;&#27602;&#36733;&#37327;&#20449;&#21495;&#65292;&#20026;&#20855;&#26377;&#20020;&#24202;&#37325;&#35201;&#24615;&#30340;&#30149;&#27602;&#36733;&#37327;&#27979;&#23450;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#23398;&#35786;&#26029;&#27979;&#35797;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#27744;&#21270;&#27979;&#35797;&#21327;&#35758;&#26174;&#30528;&#25552;&#39640;&#25928;&#29575;&#12290;&#36825;&#20123;&#21327;&#35758;&#36890;&#24120;&#38656;&#35201;&#31232;&#30095;&#30340;&#24863;&#26579;&#20449;&#21495;&#65292;&#24182;&#20351;&#29992;O(1)&#30340;&#20108;&#36827;&#21046;&#25110;&#23454;&#20540;&#26465;&#30446;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#19981;&#20801;&#35768;&#25512;&#26029;&#28085;&#30422;&#22810;&#20010;&#25968;&#37327;&#32423;&#30340;&#30149;&#27602;&#36733;&#37327;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#32467;&#21512;PCR&#65288;&#32858;&#21512;&#37238;&#38142;&#21453;&#24212;&#65289;&#29305;&#23450;&#30340;&#22122;&#22768;&#20989;&#25968;&#65292;&#20197;&#20801;&#35768;&#20934;&#30830;&#25512;&#26029;&#29616;&#23454;&#30149;&#27602;&#36733;&#37327;&#20449;&#21495;&#12290;&#36825;&#39033;&#24037;&#20316;&#26159;&#22312;&#38750;&#33258;&#36866;&#24212;&#35774;&#32622;&#20013;&#36827;&#34892;&#30340;&#65292;&#24182;&#21487;&#33021;&#20026;&#30149;&#27602;&#36733;&#37327;&#27979;&#23450;&#22312;&#20020;&#24202;&#19978;&#37325;&#35201;&#30340;&#26377;&#25928;&#31579;&#26597;&#25552;&#20379;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09130v1 Announce Type: cross  Abstract: Medical diagnostic testing can be made significantly more efficient using pooled testing protocols. These typically require a sparse infection signal and use either binary or real-valued entries of O(1). However, existing methods do not allow for inferring viral loads which span many orders of magnitude. We develop a message passing algorithm coupled with a PCR (Polymerase Chain Reaction) specific noise function to allow accurate inference of realistic viral load signals. This work is in the non-adaptive setting and could open the possibility of efficient screening where viral load determination is clinically important.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25361;&#25112;&#30340;&#26368;&#20248;Top-Two&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.09123</link><description>&lt;p&gt;
&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;&#27969;&#20307;&#20998;&#26512;&#30340;&#26368;&#20248;Top-Two&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Top-Two Method for Best Arm Identification and Fluid Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09123
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25361;&#25112;&#30340;&#26368;&#20248;Top-Two&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Top-2&#26041;&#27861;&#22312;&#35299;&#20915;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#20013;&#21464;&#24471;&#27969;&#34892;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#31639;&#27861;&#35782;&#21035;&#26368;&#20339;&#33218;&#65292;&#21363;&#22312;&#26377;&#38480;&#25968;&#37327;&#33218;&#20013;&#20855;&#26377;&#26368;&#22823;&#22343;&#20540;&#30340;&#33218;&#65292;&#35813;&#31639;&#27861;&#22312;&#20219;&#20309;&#39034;&#24207;&#27493;&#39588;&#20013;&#29420;&#31435;&#22320;&#20197;&#22266;&#23450;&#27010;&#29575; &#946; &#25289;&#21160;&#32463;&#39564;&#26368;&#20339;&#33218;&#65292;&#24182;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#25289;&#21160;&#26368;&#20339;&#25361;&#25112;&#32773;&#33218;&#12290;&#36873;&#25321;&#38169;&#35823;&#30340;&#27010;&#29575;&#20445;&#35777;&#22312;&#25351;&#23450;&#30340;&#948; &gt;0&#20197;&#19979;&#12290;&#23545;&#20110;BAI&#38382;&#39064;&#65292;&#24050;&#30693;&#20449;&#24687;&#29702;&#35770;&#19979;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#948; &#8594; 0&#26102;&#19982;&#35745;&#31639;&#35201;&#27714;&#39640;&#30340;&#25554;&#20214;&#26041;&#27861;&#28176;&#36817;&#21305;&#37197;&#12290; &#23545;&#20110;&#20219;&#20309; &#946; &#8712;&#65288;0,1&#65289;&#30340;&#19978;&#36848;Top 2&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#22987;&#32456;&#20445;&#25345;&#22312;&#19979;&#30028;&#30340;&#24120;&#25968;&#33539;&#22260;&#20869;&#12290;&#28982;&#32780;&#65292;&#30830;&#23450;&#19982;&#19979;&#30028;&#21305;&#37197;&#30340;&#26368;&#20339; &#946; &#24050;&#34987;&#35777;&#26126;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26368;&#20248;&#30340;Top-2&#31867;&#22411;&#31639;&#27861;&#12290;&#25105;&#20204;&#32771;&#34385;&#20998;&#37197;&#38170;&#28857;&#30340;&#19968;&#20010;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09123v1 Announce Type: new  Abstract: Top-$2$ methods have become popular in solving the best arm identification (BAI) problem. The best arm, or the arm with the largest mean amongst finitely many, is identified through an algorithm that at any sequential step independently pulls the empirical best arm, with a fixed probability $\beta$, and pulls the best challenger arm otherwise. The probability of incorrect selection is guaranteed to lie below a specified $\delta &gt;0$. Information theoretic lower bounds on sample complexity are well known for BAI problem and are matched asymptotically as $\delta \rightarrow 0$ by computationally demanding plug-in methods. The above top 2 algorithm for any $\beta \in (0,1)$ has sample complexity within a constant of the lower bound. However, determining the optimal $\beta$ that matches the lower bound has proven difficult. In this paper, we address this and propose an optimal top-2 type algorithm. We consider a function of allocations anchor
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20026;&#20102;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#25512;&#26029;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#35757;&#32451;&#26368;&#22823;&#21270;&#19982;&#25512;&#26029;&#27169;&#22411;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#25512;&#26029;&#27169;&#22411;&#36817;&#20284;&#19981;&#20934;&#30830;&#23548;&#33268;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08941</link><description>&lt;p&gt;
&#38754;&#21521;&#27169;&#22411;&#26080;&#20851;&#21518;&#39564;&#36924;&#36817;&#30340;&#24555;&#36895;&#20934;&#30830;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Towards Model-Agnostic Posterior Approximation for Fast and Accurate Variational Autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08941
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20026;&#20102;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#25512;&#26029;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#35757;&#32451;&#26368;&#22823;&#21270;&#19982;&#25512;&#26029;&#27169;&#22411;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#25512;&#26029;&#27169;&#22411;&#36817;&#20284;&#19981;&#20934;&#30830;&#23548;&#33268;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#25512;&#26029;&#21253;&#25324;&#23398;&#20064;&#20004;&#20010;&#27169;&#22411;&#65306;&#65288;1&#65289;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#28508;&#22312;&#31354;&#38388;&#19978;&#30340;&#31616;&#21333;&#20998;&#24067;&#36716;&#25442;&#20026;&#35266;&#27979;&#25968;&#25454;&#20998;&#24067;&#65292;&#20197;&#21450;&#65288;2&#65289;&#25512;&#26029;&#27169;&#22411;&#65292;&#36817;&#20284;&#32473;&#23450;&#25968;&#25454;&#30340;&#28508;&#22312;&#32534;&#30721;&#21518;&#39564;&#12290;&#36825;&#20004;&#20010;&#32452;&#20214;&#36890;&#36807;&#23545;&#29983;&#25104;&#27169;&#22411;&#23545;&#25968;&#36793;&#38469;&#20284;&#28982;&#30340;&#19979;&#30028;&#36827;&#34892;&#32852;&#21512;&#23398;&#20064;&#12290;&#22312;&#32852;&#21512;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#25512;&#26029;&#27169;&#22411;&#24456;&#24046;&#22320;&#36817;&#20284;&#20102;&#28508;&#22312;&#32534;&#30721;&#21518;&#39564;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#23548;&#33268;&#20248;&#21270;&#38519;&#20837;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#23545;&#23398;&#20064;&#21040;&#30340;&#29983;&#25104;&#27169;&#22411;&#36896;&#25104;&#36127;&#38754;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#24314;&#35758;&#36890;&#36807;&#36845;&#20195;&#35757;&#32451;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#25512;&#26029;&#27169;&#22411;&#65306;&#30456;&#23545;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#27599;&#27425;&#26356;&#26032;&#20043;&#21069;&#26368;&#22823;&#21270;&#19982;&#25512;&#26029;&#27169;&#22411;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36845;&#20195;&#35757;&#32451;&#25928;&#29575;&#20302;&#65292;&#38656;&#35201;&#21551;&#21457;&#24335;&#26631;&#20934;&#26469;&#20174;&#36845;&#20195;&#20013;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08941v1 Announce Type: cross  Abstract: Inference for Variational Autoencoders (VAEs) consists of learning two models: (1) a generative model, which transforms a simple distribution over a latent space into the distribution over observed data, and (2) an inference model, which approximates the posterior of the latent codes given data. The two components are learned jointly via a lower bound to the generative model's log marginal likelihood. In early phases of joint training, the inference model poorly approximates the latent code posteriors. Recent work showed that this leads optimization to get stuck in local optima, negatively impacting the learned generative model. As such, recent work suggests ensuring a high-quality inference model via iterative training: maximizing the objective function relative to the inference model before every update to the generative model. Unfortunately, iterative training is inefficient, requiring heuristic criteria for reverting from iterative
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#28385;&#36275;&#19968;&#23450;&#26680;&#29305;&#24449;&#20540;&#20998;&#35299;&#30340;&#35889;&#21644;&#38598;&#20013;&#24615;&#36136;&#30340;&#19968;&#33324;&#31867;&#38382;&#39064;&#65292;&#20855;&#26377;&#19968;&#31181;&#38750;&#28176;&#36817;&#30830;&#23450;&#24615;&#36817;&#20284;&#30340;&#31561;&#20215;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.08938</link><description>&lt;p&gt;
Kernel Ridge Regression&#30340;&#38750;&#28176;&#36817;&#29702;&#35770;&#65306;&#30830;&#23450;&#24615;&#31561;&#20215;&#65292;&#27979;&#35797;&#35823;&#24046;&#21644;GCV&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
A non-asymptotic theory of Kernel Ridge Regression: deterministic equivalents, test error, and GCV estimator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08938
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#28385;&#36275;&#19968;&#23450;&#26680;&#29305;&#24449;&#20540;&#20998;&#35299;&#30340;&#35889;&#21644;&#38598;&#20013;&#24615;&#36136;&#30340;&#19968;&#33324;&#31867;&#38382;&#39064;&#65292;&#20855;&#26377;&#19968;&#31181;&#38750;&#28176;&#36817;&#30830;&#23450;&#24615;&#36817;&#20284;&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#23398;&#20064;&#26410;&#30693;&#30446;&#26631;&#20989;&#25968;$f_*$&#65292;&#32473;&#23450;i.i.d.&#25968;&#25454;$(u_i,y_i)$&#65292;$i\leq n$&#65292;&#20854;&#20013;$u_i \in U$&#26159;&#19968;&#20010;&#21327;&#21464;&#37327;&#21521;&#37327;&#65292;$y_i = f_* (u_i) +\varepsilon_i \in \mathbb{R}$&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#36830;&#32493;&#34920;&#26126;&#65292;KRR&#30340;&#27979;&#35797;&#35823;&#24046;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#20174;&#26680;&#31639;&#23376;&#30340;&#35889;&#20381;&#36182;&#30340;&#31561;&#20215;&#24207;&#21015;&#27169;&#22411;&#23548;&#20986;&#30340;&#23553;&#38381;&#24418;&#24335;&#20272;&#35745;&#24456;&#22909;&#22320;&#36817;&#20284;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#27492;&#31561;&#20215;&#24615;&#30340;&#29702;&#35770;&#35777;&#26126;&#36804;&#20170;&#20026;&#27490;&#35201;&#20040;&#20381;&#36182;&#20110;&#38480;&#21046;&#24615;&#20551;&#35774;--&#22914;&#27425;&#39640;&#26031;&#29420;&#31435;&#26412;&#24449;&#20989;&#25968;--&#65292;&#35201;&#20040;&#23545;&#39640;&#32500;&#20855;&#20307;&#26680;&#36827;&#34892;&#28176;&#36817;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08938v1 Announce Type: cross  Abstract: We consider learning an unknown target function $f_*$ using kernel ridge regression (KRR) given i.i.d. data $(u_i,y_i)$, $i\leq n$, where $u_i \in U$ is a covariate vector and $y_i = f_* (u_i) +\varepsilon_i \in \mathbb{R}$. A recent string of work has empirically shown that the test error of KRR can be well approximated by a closed-form estimate derived from an `equivalent' sequence model that only depends on the spectrum of the kernel operator. However, a theoretical justification for this equivalence has so far relied either on restrictive assumptions -- such as subgaussian independent eigenfunctions -- , or asymptotic derivations for specific kernels in high dimensions.   In this paper, we prove that this equivalence holds for a general class of problems satisfying some spectral and concentration properties on the kernel eigendecomposition. Specifically, we establish in this setting a non-asymptotic deterministic approximation for 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Moment Pooling&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Deep Sets&#20013;&#30340;&#27714;&#21644;&#27867;&#21270;&#20026;&#20219;&#24847;&#30340;&#22810;&#21464;&#37327;&#30697;&#65292;&#26174;&#33879;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#32593;&#32476;&#30340;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#65292;&#22312;&#22266;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#26377;&#25928;&#28508;&#22312;&#32500;&#24230;&#65292;&#20174;&#32780;&#21487;&#20197;&#30452;&#25509;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#20869;&#37096;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2403.08854</link><description>&lt;p&gt;
&#28165;&#26224;&#30636;&#38388;&#65306;&#20351;&#29992;Moment Pooling&#31616;&#21270;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#28508;&#22312;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Moments of Clarity: Streamlining Latent Spaces in Machine Learning using Moment Pooling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08854
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Moment Pooling&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;Deep Sets&#20013;&#30340;&#27714;&#21644;&#27867;&#21270;&#20026;&#20219;&#24847;&#30340;&#22810;&#21464;&#37327;&#30697;&#65292;&#26174;&#33879;&#38477;&#20302;&#26426;&#22120;&#23398;&#20064;&#32593;&#32476;&#30340;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#65292;&#22312;&#22266;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#26377;&#25928;&#28508;&#22312;&#32500;&#24230;&#65292;&#20174;&#32780;&#21487;&#20197;&#30452;&#25509;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#20869;&#37096;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#28041;&#21450;&#23398;&#20064;&#25968;&#25454;&#30340;&#28508;&#22312;&#34920;&#31034;&#65292;&#36890;&#24120;&#26159;&#39640;&#32500;&#19988;&#38590;&#20197;&#30452;&#25509;&#35299;&#37322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;Moment Pooling&#8221;&#65292;&#36825;&#26159;Deep Sets&#32593;&#32476;&#30340;&#19968;&#20010;&#33258;&#28982;&#24310;&#20280;&#65292;&#21487;&#22823;&#24133;&#20943;&#23569;&#36825;&#20123;&#32593;&#32476;&#30340;&#28508;&#22312;&#31354;&#38388;&#32500;&#24230;&#65292;&#21516;&#26102;&#32500;&#25345;&#29978;&#33267;&#25552;&#39640;&#24615;&#33021;&#12290;Moment Pooling&#23558;Deep Sets&#20013;&#30340;&#27714;&#21644;&#27867;&#21270;&#20026;&#20219;&#24847;&#30340;&#22810;&#21464;&#37327;&#30697;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#22312;&#22266;&#23450;&#30340;&#28508;&#22312;&#32500;&#24230;&#19979;&#23454;&#29616;&#26356;&#39640;&#30340;&#26377;&#25928;&#28508;&#22312;&#32500;&#24230;&#12290;&#25105;&#20204;&#23558;Moment Pooling&#24212;&#29992;&#20110;&#22840;&#20811;/&#33014;&#23376;&#21943;&#27880;&#20998;&#31867;&#30340;&#23545;&#25758;&#26426;&#29289;&#29702;&#20219;&#21153;&#65292;&#36890;&#36807;&#23558;Energy Flow Networks&#65288;EFNs&#65289;&#25193;&#23637;&#20026;Moment EFNs&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20855;&#26377;&#23567;&#33267;1&#30340;&#28508;&#22312;&#32500;&#24230;&#30340;Moment EFNs&#34920;&#29616;&#19982;&#20855;&#26377;&#36739;&#39640;&#28508;&#22312;&#32500;&#24230;&#30340;&#26222;&#36890;EFNs&#31867;&#20284;&#12290;&#36825;&#31181;&#23567;&#28508;&#22312;&#32500;&#24230;&#20351;&#20869;&#37096;&#34920;&#31034;&#21487;&#20197;&#30452;&#25509;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08854v1 Announce Type: cross  Abstract: Many machine learning applications involve learning a latent representation of data, which is often high-dimensional and difficult to directly interpret. In this work, we propose "Moment Pooling", a natural extension of Deep Sets networks which drastically decrease latent space dimensionality of these networks while maintaining or even improving performance. Moment Pooling generalizes the summation in Deep Sets to arbitrary multivariate moments, which enables the model to achieve a much higher effective latent dimensionality for a fixed latent dimension. We demonstrate Moment Pooling on the collider physics task of quark/gluon jet classification by extending Energy Flow Networks (EFNs) to Moment EFNs. We find that Moment EFNs with latent dimensions as small as 1 perform similarly to ordinary EFNs with higher latent dimension. This small latent dimension allows for the internal representation to be directly visualized and interpreted, w
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#24490;&#29615;&#25968;&#25454;&#24182;&#34892;&#24615;&#65292;&#36890;&#36807;&#23558;&#24494;&#25209;&#37327;&#25191;&#34892;&#20174;&#21516;&#26102;&#25913;&#20026;&#39034;&#24207;&#25191;&#34892;&#65292;&#20197;&#35299;&#20915;&#25968;&#25454;&#24182;&#34892;&#21270;&#20013;&#28608;&#27963;&#20869;&#23384;&#23792;&#20540;&#21644;&#26799;&#24230;&#24179;&#22343;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#33021;&#20943;&#23569;&#25152;&#38656;GPU&#25968;&#37327;&#12290;</title><link>https://arxiv.org/abs/2403.08837</link><description>&lt;p&gt;
&#29992;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39640;&#25928;&#24182;&#34892;&#21270;&#30340;&#24490;&#29615;&#25968;&#25454;&#24182;&#34892;&#24615;
&lt;/p&gt;
&lt;p&gt;
Cyclic Data Parallelism for Efficient Parallelism of Deep Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08837
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#24490;&#29615;&#25968;&#25454;&#24182;&#34892;&#24615;&#65292;&#36890;&#36807;&#23558;&#24494;&#25209;&#37327;&#25191;&#34892;&#20174;&#21516;&#26102;&#25913;&#20026;&#39034;&#24207;&#25191;&#34892;&#65292;&#20197;&#35299;&#20915;&#25968;&#25454;&#24182;&#34892;&#21270;&#20013;&#28608;&#27963;&#20869;&#23384;&#23792;&#20540;&#21644;&#26799;&#24230;&#24179;&#22343;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#33021;&#20943;&#23569;&#25152;&#38656;GPU&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#22823;&#22411;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#24182;&#34892;&#21270;&#25216;&#26415;&#20197;&#25193;&#23637;&#35268;&#27169;&#12290;&#22312;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#22914;&#25968;&#25454;&#24182;&#34892;&#24615;&#25110;ZeRO-DP&#65292;&#24494;&#25209;&#37327;&#25968;&#25454;&#34987;&#24182;&#34892;&#22788;&#29702;&#65292;&#36825;&#20135;&#29983;&#20102;&#20004;&#20010;&#32570;&#28857;&#65306;&#22312;&#21069;&#21521;&#20256;&#36882;&#32467;&#26463;&#26102;&#27169;&#22411;&#28608;&#27963;&#25152;&#38656;&#30340;&#24635;&#20869;&#23384;&#23792;&#20540;&#65292;&#24182;&#19988;&#26799;&#24230;&#24517;&#39035;&#22312;&#21453;&#21521;&#20256;&#25773;&#27493;&#39588;&#32467;&#26463;&#26102;&#21516;&#26102;&#24179;&#22343;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24490;&#29615;&#25968;&#25454;&#24182;&#34892;&#24615;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#33539;&#24335;&#65292;&#23558;&#24494;&#25209;&#37327;&#30340;&#25191;&#34892;&#20174;&#21516;&#26102;&#21464;&#20026;&#39034;&#24207;&#25191;&#34892;&#65292;&#24102;&#26377;&#22343;&#21248;&#30340;&#24310;&#36831;&#12290;&#20197;&#30053;&#24494;&#26799;&#24230;&#24310;&#36831;&#20026;&#20195;&#20215;&#65292;&#28608;&#27963;&#25152;&#21344;&#30340;&#24635;&#20869;&#23384;&#26159;&#24658;&#23450;&#30340;&#65292;&#24182;&#19988;&#26799;&#24230;&#36890;&#20449;&#22312;&#35757;&#32451;&#27493;&#39588;&#26399;&#38388;&#26159;&#24179;&#34913;&#30340;&#12290;&#36890;&#36807;&#27169;&#22411;&#24182;&#34892;&#24615;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#20943;&#23569;&#20102;&#25152;&#38656;&#30340;GPU&#25968;&#37327;&#65292;&#36890;&#36807;&#22312;&#24494;&#25209;&#37327;&#20043;&#38388;&#20849;&#20139;GPU&#12290;&#22312;ZeRO-DP&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#20801;&#35768;&#20351;&#29992;&#28857;&#23545;&#28857;&#25805;&#20316;&#36827;&#34892;&#27169;&#22411;&#29366;&#24577;&#30340;&#36890;&#20449;&#65292;&#32780;&#38750; t
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08837v1 Announce Type: cross  Abstract: Training large deep learning models requires parallelization techniques to scale. In existing methods such as Data Parallelism or ZeRO-DP, micro-batches of data are processed in parallel, which creates two drawbacks: the total memory required to store the model's activations peaks at the end of the forward pass, and gradients must be simultaneously averaged at the end of the backpropagation step. We propose Cyclic Data Parallelism, a novel paradigm shifting the execution of the micro-batches from simultaneous to sequential, with a uniform delay. At the cost of a slight gradient delay, the total memory taken by activations is constant, and the gradient communications are balanced during the training step. With Model Parallelism, our technique reduces the number of GPUs needed, by sharing GPUs across micro-batches. Within the ZeRO-DP framework, our technique allows communication of the model states with point-to-point operations rather t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#33021;&#26368;&#20248;&#30340;&#26368;&#31616;&#21333;&#31639;&#27861;&#65306;&#36820;&#22238;&#19977;&#20010;ERM&#20998;&#31867;&#22120;&#30340;&#22810;&#25968;&#25237;&#31080;&#65292;&#35777;&#26126;&#20854;&#23454;&#29616;&#20102;&#38169;&#35823;&#30340;&#26399;&#26395;&#26368;&#20248;&#36793;&#30028;&#65292;&#24182;&#24471;&#20986;&#36817;&#20046;&#26368;&#20248;&#27010;&#29575;&#36793;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.08831</link><description>&lt;p&gt;
&#22810;&#25968;&#19977;&#32773;&#65306;&#26368;&#31616;&#21333;&#30340;&#26368;&#20248;&#23398;&#20064;&#22120;&#65311;
&lt;/p&gt;
&lt;p&gt;
Majority-of-Three: The Simplest Optimal Learner?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08831
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#33021;&#26368;&#20248;&#30340;&#26368;&#31616;&#21333;&#31639;&#27861;&#65306;&#36820;&#22238;&#19977;&#20010;ERM&#20998;&#31867;&#22120;&#30340;&#22810;&#25968;&#25237;&#31080;&#65292;&#35777;&#26126;&#20854;&#23454;&#29616;&#20102;&#38169;&#35823;&#30340;&#26399;&#26395;&#26368;&#20248;&#36793;&#30028;&#65292;&#24182;&#24471;&#20986;&#36817;&#20046;&#26368;&#20248;&#27010;&#29575;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#29616;&#25968;&#25454;&#35774;&#32622;&#19979;&#21457;&#23637;&#26368;&#20339;&#30340;PAC&#23398;&#20064;&#31639;&#27861;&#26159;&#23398;&#20064;&#29702;&#35770;&#20013;&#20960;&#21313;&#24180;&#26469;&#30340;&#19968;&#20010;&#37325;&#22823;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#20854;&#20013;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#26159;&#27425;&#20248;&#30340;&#12290;&#20960;&#24180;&#21069;&#65292;Hanneke&#32456;&#20110;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;Hanneke&#30340;&#31639;&#27861;&#30456;&#24403;&#22797;&#26434;&#65292;&#22240;&#20026;&#23427;&#36820;&#22238;&#35768;&#22810;&#32463;&#36807;&#31934;&#24515;&#36873;&#25321;&#30340;&#25968;&#25454;&#23376;&#38598;&#19978;&#35757;&#32451;&#30340;ERM&#20998;&#31867;&#22120;&#30340;&#22810;&#25968;&#25237;&#31080;&#12290;&#22240;&#27492;&#65292;&#26368;&#33258;&#28982;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#26368;&#31616;&#21333;&#30340;&#26368;&#20248;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21487;&#33021;&#26368;&#20248;&#30340;&#26368;&#31616;&#21333;&#31639;&#27861;&#65306;&#36820;&#22238;&#19977;&#20010;ERM&#20998;&#31867;&#22120;&#30340;&#22810;&#25968;&#25237;&#31080;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#31639;&#27861;&#23454;&#29616;&#20102;&#20854;&#38169;&#35823;&#30340;&#26399;&#26395;&#26368;&#20248;&#36793;&#30028;&#65292;&#36825;&#26174;&#28982;&#26159;&#21333;&#20010;ERM&#20998;&#31867;&#22120;&#26080;&#27861;&#36798;&#21040;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#38169;&#35823;&#30340;&#36817;&#20046;&#26368;&#20248;&#27010;&#29575;&#36793;&#30028;&#12290;&#25105;&#20204;&#25512;&#27979;&#26356;&#22909;&#30340;&#20998;&#26512;&#23558;&#35777;&#26126;&#36825;&#20010;&#31639;&#27861;&#23454;&#38469;&#19978;&#22312;&#39640;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08831v1 Announce Type: cross  Abstract: Developing an optimal PAC learning algorithm in the realizable setting, where empirical risk minimization (ERM) is suboptimal, was a major open problem in learning theory for decades. The problem was finally resolved by Hanneke a few years ago. Unfortunately, Hanneke's algorithm is quite complex as it returns the majority vote of many ERM classifiers that are trained on carefully selected subsets of the data. It is thus a natural goal to determine the simplest algorithm that is optimal. In this work we study the arguably simplest algorithm that could be optimal: returning the majority vote of three ERM classifiers. We show that this algorithm achieves the optimal in-expectation bound on its error which is provably unattainable by a single ERM classifier. Furthermore, we prove a near-optimal high-probability bound on this algorithm's error. We conjecture that a better analysis will prove that this algorithm is in fact optimal in the hig
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26657;&#20934;&#26041;&#27861;THERMOMETER&#65292;&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#20219;&#21153;&#25968;&#25454;&#30340;&#36741;&#21161;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#20934;&#30830;&#24615;&#20445;&#25345;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#21709;&#24212;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.08819</link><description>&lt;p&gt;
&#28201;&#24230;&#35745;&#65306;&#38754;&#21521;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#36890;&#29992;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Thermometer: Towards Universal Calibration for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08819
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26657;&#20934;&#26041;&#27861;THERMOMETER&#65292;&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#20219;&#21153;&#25968;&#25454;&#30340;&#36741;&#21161;&#27169;&#22411;&#65292;&#23454;&#29616;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#20934;&#30830;&#24615;&#20445;&#25345;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#21709;&#24212;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20013;&#30340;&#26657;&#20934;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#24120;&#35265;&#30340;&#24178;&#39044;&#25514;&#26045;&#22914;&#25351;&#20196;&#35843;&#25972;&#36890;&#24120;&#20250;&#23548;&#33268;&#26657;&#20934;&#19981;&#20339;&#30340;LLMs&#12290;&#23613;&#31649;&#26657;&#20934;&#22312;&#20256;&#32479;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#25506;&#35752;&#65292;&#20294;&#23545;LLMs&#36827;&#34892;&#26657;&#20934;&#20855;&#26377;&#29420;&#29305;&#25361;&#25112;&#12290;&#36825;&#20123;&#25361;&#25112;&#19981;&#20165;&#26469;&#33258;LLMs&#30340;&#20005;&#26684;&#35745;&#31639;&#35201;&#27714;&#65292;&#20063;&#26469;&#33258;&#23427;&#20204;&#30340;&#22810;&#21151;&#33021;&#24615;&#65292;&#20351;&#23427;&#20204;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;LLMs&#30340;&#26657;&#20934;&#26041;&#27861;THERMOMETER&#12290;THERMOMETER&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#22810;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#30340;&#36741;&#21161;&#27169;&#22411;&#65292;&#29992;&#20110;&#26657;&#20934;LLM&#12290;&#23427;&#22312;&#35745;&#31639;&#19978;&#25928;&#29575;&#39640;&#65292;&#20445;&#25345;&#20102;LLM&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20026;&#26032;&#20219;&#21153;&#20135;&#29983;&#20102;&#26356;&#22909;&#30340;&#26657;&#20934;&#21709;&#24212;&#12290;&#23545;&#21508;&#31181;&#22522;&#20934;&#30340;&#24191;&#27867;&#23454;&#35777;&#35780;&#20272;&#26174;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08819v1 Announce Type: cross  Abstract: We consider the issue of calibration in large language models (LLM). Recent studies have found that common interventions such as instruction tuning often result in poorly calibrated LLMs. Although calibration is well-explored in traditional applications, calibrating LLMs is uniquely challenging. These challenges stem as much from the severe computational requirements of LLMs as from their versatility, which allows them to be applied to diverse tasks. Addressing these challenges, we propose THERMOMETER, a calibration approach tailored to LLMs. THERMOMETER learns an auxiliary model, given data from multiple tasks, for calibrating a LLM. It is computationally efficient, preserves the accuracy of the LLM, and produces better-calibrated responses for new tasks. Extensive empirical evaluations across various benchmarks demonstrate the effectiveness of the proposed method.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28909;&#25193;&#25955;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#25628;&#32034;&#20840;&#23616;&#26368;&#20248;&#26102;&#25928;&#29575;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08757</link><description>&lt;p&gt;
&#36890;&#36807;&#28909;&#25193;&#25955;&#23454;&#29616;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Efficient Combinatorial Optimization via Heat Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08757
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28909;&#25193;&#25955;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#25628;&#32034;&#20840;&#23616;&#26368;&#20248;&#26102;&#25928;&#29575;&#26377;&#38480;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25506;&#35752;&#20102;&#36890;&#36807;&#28909;&#25193;&#25955;&#26469;&#23454;&#29616;&#39640;&#25928;&#30340;&#32452;&#21512;&#20248;&#21270;&#12290;&#38024;&#23545;&#29616;&#26377;&#26041;&#27861;&#21482;&#33021;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#35775;&#38382;&#35299;&#31354;&#38388;&#30340;&#19968;&#23567;&#37096;&#20998;&#36825;&#19968;&#38480;&#21046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#26469;&#35299;&#20915;&#19968;&#33324;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#19968;&#31995;&#21015;&#26368;&#20855;&#25361;&#25112;&#24615;&#21644;&#24191;&#27867;&#36935;&#21040;&#30340;&#32452;&#21512;&#20248;&#21270;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08757v1 Announce Type: cross  Abstract: Combinatorial optimization problems are widespread but inherently challenging due to their discrete nature.The primary limitation of existing methods is that they can only access a small fraction of the solution space at each iteration, resulting in limited efficiency for searching the global optimal. To overcome this challenge, diverging from conventional efforts of expanding the solver's search scope, we focus on enabling information to actively propagate to the solver through heat diffusion. By transforming the target function while preserving its optima, heat diffusion facilitates information flow from distant regions to the solver, providing more efficient navigation. Utilizing heat diffusion, we propose a framework for solving general combinatorial optimization problems. The proposed methodology demonstrates superior performance across a range of the most challenging and widely encountered combinatorial optimizations. Echoing rec
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#23558;&#33258;&#36866;&#24212;&#27493;&#38271;&#24341;&#20837;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#20174;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#25910;&#25947;&#21040;&#27491;&#30830;&#30340;&#20998;&#24067;&#12290;</title><link>https://arxiv.org/abs/2403.08609</link><description>&lt;p&gt;
&#28145;&#24230;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#21487;&#25193;&#23637;&#25193;&#25955;&#37319;&#26679;&#26041;&#27861;&#30340;&#25910;&#25947;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of Locally Adaptive and Scalable Diffusion-Based Sampling Methods for Deep Bayesian Neural Network Posteriors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#23558;&#33258;&#36866;&#24212;&#27493;&#38271;&#24341;&#20837;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#20174;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#25910;&#25947;&#21040;&#27491;&#30830;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#35768;&#22810;&#28145;&#24230;&#23398;&#20064;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#22914;&#21307;&#23398;&#25104;&#20687;&#20013;&#38656;&#35201;&#35780;&#20272;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21487;&#38752;&#24615;&#12290;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26159;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#19981;&#30830;&#23450;&#24615;&#24314;&#27169;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20174;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#26397;&#30528;&#36825;&#20010;&#26041;&#21521;&#30340;&#19968;&#20010;&#37325;&#35201;&#36827;&#23637;&#23558;&#26159;&#23558;&#31867;&#20284;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#22120;&#30340;&#33258;&#36866;&#24212;&#27493;&#38271;&#32435;&#20837;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#32780;&#19981;&#20250;&#26174;&#33879;&#22686;&#21152;&#35745;&#31639;&#38656;&#27714;&#12290;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#19968;&#20123;&#35770;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#23454;&#29616;&#36825;&#19968;&#23646;&#24615;&#30340;&#37319;&#26679;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#26159;&#21542;&#30830;&#23454;&#25910;&#25947;&#21040;&#27491;&#30830;&#30340;&#20998;&#24067;&#21602;&#65311;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#36825;&#19968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08609v1 Announce Type: new  Abstract: Achieving robust uncertainty quantification for deep neural networks represents an important requirement in many real-world applications of deep learning such as medical imaging where it is necessary to assess the reliability of a neural network's prediction. Bayesian neural networks are a promising approach for modeling uncertainties in deep neural networks. Unfortunately, generating samples from the posterior distribution of neural networks is a major challenge. One significant advance in that direction would be the incorporation of adaptive step sizes, similar to modern neural network optimizers, into Monte Carlo Markov chain sampling algorithms without significantly increasing computational demand. Over the past years, several papers have introduced sampling algorithms with claims that they achieve this property. However, do they indeed converge to the correct distribution? In this paper, we demonstrate that these methods can have a 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.05811</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Statistical Efficiency of Distributional Temporal Difference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05811
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;&#26102;&#38388;&#24046;&#20998;&#30340;&#32479;&#35745;&#25928;&#29575;&#21644;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;(DRL)&#20851;&#27880;&#30340;&#26159;&#36820;&#22238;&#30340;&#23436;&#25972;&#20998;&#24067;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22343;&#20540;&#65292;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#32463;&#39564;&#25104;&#21151;&#12290;&#39046;&#22495;DRL&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#20043;&#19968;&#26159;&#20998;&#24067;&#24335;&#31574;&#30053;&#35780;&#20272;&#65292;&#28041;&#21450;&#20272;&#35745;&#32473;&#23450;&#31574;&#30053;pi&#30340;&#36820;&#22238;&#20998;&#24067;&#951;^pi&#12290;&#30456;&#24212;&#22320;&#25552;&#20986;&#20102;&#20998;&#24067;&#26102;&#38388;&#24046;&#20998;(TD)&#31639;&#27861;&#65292;&#36825;&#26159;&#32463;&#20856;RL&#25991;&#29486;&#20013;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;&#30340;&#24310;&#20280;&#12290;&#22312;&#34920;&#26684;&#26696;&#20363;&#20013;&#65292;citet{rowland2018analysis}&#21644;citet{rowland2023analysis}&#20998;&#21035;&#35777;&#26126;&#20102;&#20004;&#20010;&#20998;&#24067;&#24335;TD&#23454;&#20363;&#21363;&#20998;&#31867;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(CTD)&#21644;&#20998;&#20301;&#25968;&#26102;&#38388;&#24046;&#20998;&#31639;&#27861;(QTD)&#30340;&#28176;&#36817;&#25910;&#25947;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#20998;&#24067;&#24335;TD&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;&#20026;&#20102;&#20419;&#36827;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340; dis
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05811v1 Announce Type: cross  Abstract: Distributional reinforcement learning (DRL), which cares about the full distribution of returns instead of just the mean, has achieved empirical success in various domains. One of the core tasks in the field of DRL is distributional policy evaluation, which involves estimating the return distribution $\eta^\pi$ for a given policy $\pi$. A distributional temporal difference (TD) algorithm has been accordingly proposed, which is an extension of the temporal difference algorithm in the classic RL literature. In the tabular case, \citet{rowland2018analysis} and \citet{rowland2023analysis} proved the asymptotic convergence of two instances of distributional TD, namely categorical temporal difference algorithm (CTD) and quantile temporal difference algorithm (QTD), respectively. In this paper, we go a step further and analyze the finite-sample performance of distributional TD. To facilitate theoretical analysis, we propose non-parametric dis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20869;&#22312;&#32467;&#26500;&#21644;jets&#20960;&#20309;&#27010;&#24565;&#30340;&#20272;&#35745;Koopman&#31639;&#23376;&#30340;&#26032;&#26041;&#27861;JetDMD&#65292;&#36890;&#36807;&#26126;&#30830;&#30340;&#35823;&#24046;&#30028;&#21644;&#25910;&#25947;&#29575;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#65292;&#20026;Koopman&#31639;&#23376;&#30340;&#25968;&#20540;&#20272;&#35745;&#25552;&#20379;&#20102;&#26356;&#31934;&#30830;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#35013;&#37197;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#25193;&#23637;Koopman&#31639;&#23376;&#30340;&#27010;&#24565;&#65292;&#26377;&#21161;&#20110;&#28145;&#20837;&#29702;&#35299;&#20272;&#35745;&#30340;Koopman&#29305;&#24449;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.02524</link><description>&lt;p&gt;
&#22312;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20855;&#26377;&#20869;&#22312;&#21487;&#35266;&#27979;&#24615;&#30340;Koopman&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Koopman operators with intrinsic observables in rigged reproducing kernel Hilbert spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02524
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20869;&#22312;&#32467;&#26500;&#21644;jets&#20960;&#20309;&#27010;&#24565;&#30340;&#20272;&#35745;Koopman&#31639;&#23376;&#30340;&#26032;&#26041;&#27861;JetDMD&#65292;&#36890;&#36807;&#26126;&#30830;&#30340;&#35823;&#24046;&#30028;&#21644;&#25910;&#25947;&#29575;&#35777;&#26126;&#20854;&#20248;&#36234;&#24615;&#65292;&#20026;Koopman&#31639;&#23376;&#30340;&#25968;&#20540;&#20272;&#35745;&#25552;&#20379;&#20102;&#26356;&#31934;&#30830;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#35013;&#37197;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#25193;&#23637;Koopman&#31639;&#23376;&#30340;&#27010;&#24565;&#65292;&#26377;&#21161;&#20110;&#28145;&#20837;&#29702;&#35299;&#20272;&#35745;&#30340;Koopman&#29305;&#24449;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#35013;&#37197;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#23450;&#20041;&#30340;Koopman&#31639;&#23376;&#21450;&#20854;&#35889;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;Jet Dynamic Mode Decomposition&#65288;JetDMD&#65289;&#65292;&#21033;&#29992;RKHS&#30340;&#20869;&#22312;&#32467;&#26500;&#21644;&#31216;&#20026;jets&#30340;&#20960;&#20309;&#27010;&#24565;&#26469;&#22686;&#24378;Koopman&#31639;&#23376;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#31934;&#30830;&#24230;&#19978;&#20248;&#21270;&#20102;&#20256;&#32479;&#30340;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#65292;&#29305;&#21035;&#26159;&#22312;&#29305;&#24449;&#20540;&#30340;&#25968;&#20540;&#20272;&#35745;&#26041;&#38754;&#12290;&#26412;&#25991;&#36890;&#36807;&#26126;&#30830;&#30340;&#35823;&#24046;&#30028;&#21644;&#29305;&#27530;&#27491;&#23450;&#20869;&#26680;&#30340;&#25910;&#25947;&#29575;&#35777;&#26126;&#20102;JetDMD&#30340;&#20248;&#36234;&#24615;&#65292;&#20026;&#20854;&#24615;&#33021;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#25105;&#20204;&#36824;&#28145;&#20837;&#25506;&#35752;&#20102;Koopman&#31639;&#23376;&#30340;&#35889;&#20998;&#26512;&#65292;&#22312;&#35013;&#37197;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#25193;&#23637;Koopman&#31639;&#23376;&#30340;&#27010;&#24565;&#12290;&#36825;&#20010;&#27010;&#24565;&#26377;&#21161;&#20110;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20272;&#35745;&#30340;Koopman&#29305;&#24449;&#20989;&#25968;&#24182;&#25429;&#25417;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02524v1 Announce Type: cross  Abstract: This paper presents a novel approach for estimating the Koopman operator defined on a reproducing kernel Hilbert space (RKHS) and its spectra. We propose an estimation method, what we call Jet Dynamic Mode Decomposition (JetDMD), leveraging the intrinsic structure of RKHS and the geometric notion known as jets to enhance the estimation of the Koopman operator. This method refines the traditional Extended Dynamic Mode Decomposition (EDMD) in accuracy, especially in the numerical estimation of eigenvalues. This paper proves JetDMD's superiority through explicit error bounds and convergence rate for special positive definite kernels, offering a solid theoretical foundation for its performance. We also delve into the spectral analysis of the Koopman operator, proposing the notion of extended Koopman operator within a framework of rigged Hilbert space. This notion leads to a deeper understanding of estimated Koopman eigenfunctions and captu
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00666</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharp bounds for the max-sliced Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00666
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#22312;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20174;$n$&#20010;&#26679;&#26412;&#20013;&#33719;&#24471;&#30340;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#26399;&#26395;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;Banach&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00666v1 Announce Type: cross  Abstract: We obtain sharp upper and lower bounds for the expected max-sliced 1-Wasserstein distance between a probability measure on a separable Hilbert space and its empirical distribution from $n$ samples. A version of this result for probability measures on Banach spaces is also obtained.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#26159;&#26080;&#27861;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#30340;&#27425;&#20248;&#24615;&#20056;&#27861;&#22686;&#21152;&#30340;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.10898</link><description>&lt;p&gt;
&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;
&lt;/p&gt;
&lt;p&gt;
The Price of Adaptivity in Stochastic Convex Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10898
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#26159;&#26080;&#27861;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21442;&#25968;&#30340;&#27425;&#20248;&#24615;&#20056;&#27861;&#22686;&#21152;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#36866;&#24212;&#24615;&#30340;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#12290;&#32473;&#23450;&#19968;&#32452;&#25105;&#20204;&#24076;&#26395;&#36866;&#24212;&#30340;&#38382;&#39064;&#21442;&#25968;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#8220;&#36866;&#24212;&#24615;&#30340;&#20195;&#20215;&#8221;&#65288;PoA&#65289;&#65292;&#31895;&#30053;&#22320;&#35828;&#65292;&#23427;&#34913;&#37327;&#20102;&#30001;&#20110;&#36825;&#20123;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#32780;&#23548;&#33268;&#30340;&#27425;&#20248;&#24615;&#30340;&#20056;&#27861;&#22686;&#21152;&#12290;&#24403;&#21021;&#22987;&#36317;&#31163;&#26368;&#20248;&#35299;&#26410;&#30693;&#20294;&#26799;&#24230;&#33539;&#25968;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;PoA&#33267;&#23569;&#23545;&#20110;&#26399;&#26395;&#27425;&#20248;&#24615;&#26159;&#23545;&#25968;&#32423;&#21035;&#65292;&#23545;&#20110;&#20013;&#20301;&#25968;&#27425;&#20248;&#24615;&#26159;&#21452;&#23545;&#25968;&#32423;&#21035;&#12290;&#24403;&#36317;&#31163;&#21644;&#26799;&#24230;&#33539;&#25968;&#37117;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;PoA&#24517;&#39035;&#26159;&#19982;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#22810;&#39033;&#24335;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#20960;&#20046;&#19982;&#29616;&#26377;&#30340;&#19978;&#30028;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#30830;&#23450;&#20102;&#27809;&#26377;&#26080;&#21442;&#25968;&#21320;&#39184;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10898v1 Announce Type: cross  Abstract: We prove impossibility results for adaptivity in non-smooth stochastic convex optimization. Given a set of problem parameters we wish to adapt to, we define a "price of adaptivity" (PoA) that, roughly speaking, measures the multiplicative increase in suboptimality due to uncertainty in these parameters. When the initial distance to the optimum is unknown but a gradient norm bound is known, we show that the PoA is at least logarithmic for expected suboptimality, and double-logarithmic for median suboptimality. When there is uncertainty in both distance and gradient norm, we show that the PoA must be polynomial in the level of uncertainty. Our lower bounds nearly match existing upper bounds, and establish that there is no parameter-free lunch.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#20915;&#31574;&#30456;&#20851;&#38382;&#39064;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#65292;&#31639;&#27861;&#30340;&#24179;&#22343;&#36845;&#20195;&#19982;&#35299;&#20043;&#38388;&#30340;&#20559;&#24046;&#26159;&#27491;&#24577;&#30340;&#65292;&#24182;&#19988;&#31639;&#27861;&#30340;&#24615;&#33021;&#22312;&#23616;&#37096;&#36798;&#21040;&#20102;&#26368;&#20248;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2207.04173</link><description>&lt;p&gt;
&#20855;&#26377;&#20915;&#31574;&#30456;&#20851;&#20998;&#24067;&#30340;&#38543;&#26426;&#36924;&#36817;&#65306;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Stochastic Approximation with Decision-Dependent Distributions: Asymptotic Normality and Optimality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.04173
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#20915;&#31574;&#30456;&#20851;&#38382;&#39064;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#65292;&#31639;&#27861;&#30340;&#24179;&#22343;&#36845;&#20195;&#19982;&#35299;&#20043;&#38388;&#30340;&#20559;&#24046;&#26159;&#27491;&#24577;&#30340;&#65292;&#24182;&#19988;&#31639;&#27861;&#30340;&#24615;&#33021;&#22312;&#23616;&#37096;&#36798;&#21040;&#20102;&#26368;&#20248;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#20915;&#31574;&#30456;&#20851;&#38382;&#39064;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#20854;&#20013;&#31639;&#27861;&#20351;&#29992;&#30340;&#25968;&#25454;&#20998;&#24067;&#27839;&#30528;&#36845;&#20195;&#24207;&#21015;&#28436;&#21464;&#12290;&#36825;&#31867;&#38382;&#39064;&#30340;&#20027;&#35201;&#20363;&#23376;&#20986;&#29616;&#22312;&#25191;&#34892;&#24615;&#39044;&#27979;&#21450;&#20854;&#22810;&#20154;&#28216;&#25103;&#25193;&#23637;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#31639;&#27861;&#30340;&#24179;&#22343;&#36845;&#20195;&#19982;&#35299;&#20043;&#38388;&#30340;&#20559;&#24046;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#27491;&#24577;&#30340;&#65292;&#21327;&#26041;&#24046;&#28165;&#26224;&#22320;&#20998;&#35299;&#20102;&#26799;&#24230;&#22122;&#22768;&#21644;&#20998;&#24067;&#21464;&#21270;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;H\'ajek&#21644;Le Cam&#30340;&#24037;&#20316;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24102;&#26377;&#24179;&#22343;&#30340;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#22312;&#23616;&#37096;&#26159;&#23616;&#37096;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2207.04173v3 Announce Type: replace-cross  Abstract: We analyze a stochastic approximation algorithm for decision-dependent problems, wherein the data distribution used by the algorithm evolves along the iterate sequence. The primary examples of such problems appear in performative prediction and its multiplayer extensions. We show that under mild assumptions, the deviation between the average iterate of the algorithm and the solution is asymptotically normal, with a covariance that clearly decouples the effects of the gradient noise and the distributional shift. Moreover, building on the work of H\'ajek and Le Cam, we show that the asymptotic performance of the algorithm with averaging is locally minimax optimal.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181; VAns (Variable Ansatz) &#21487;&#21464;&#32467;&#26500;&#26041;&#27861;&#26469;&#26500;&#24314; VQAs &#30340;&#20551;&#35774;&#65292;&#36890;&#36807;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#20197;&#19968;&#31181;&#29087;&#24713;&#30340;&#26041;&#24335;&#22686;&#38271;&#21644;&#31227;&#38500;&#37327;&#23376;&#38376;&#26469;&#25104;&#21151;&#32531;&#35299;&#20102;&#21487;&#35757;&#32451;&#24615;&#21644;&#22122;&#38899;&#30456;&#20851;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2103.06712</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#21487;&#21464;&#32467;&#26500;&#30340;&#21322;&#19981;&#21487;&#30693;&#20551;&#35774;&#29992;&#20110;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
A semi-agnostic ansatz with variable structure for quantum machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2103.06712
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181; VAns (Variable Ansatz) &#21487;&#21464;&#32467;&#26500;&#26041;&#27861;&#26469;&#26500;&#24314; VQAs &#30340;&#20551;&#35774;&#65292;&#36890;&#36807;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#20197;&#19968;&#31181;&#29087;&#24713;&#30340;&#26041;&#24335;&#22686;&#38271;&#21644;&#31227;&#38500;&#37327;&#23376;&#38376;&#26469;&#25104;&#21151;&#32531;&#35299;&#20102;&#21487;&#35757;&#32451;&#24615;&#21644;&#22122;&#38899;&#30456;&#20851;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Quantum machine learning -- and specifically Variational Quantum Algorithms (VQAs) -- offers a powerful, flexible paradigm for programming near-term quantum computers, with applications in chemistry, metrology, materials science, data science, and mathematics. Here, one trains an ansatz, in the form of a parameterized quantum circuit, to accomplish a task of interest. However, challenges have recently emerged suggesting that deep ansatzes are difficult to train, due to flat training landscapes caused by randomness or by hardware noise. This motivates our work, where we present a variable structure approach to build ansatzes for VQAs. Our approach, called VAns (Variable Ansatz), applies a set of rules to both grow and (crucially) remove quantum gates in an informed manner during the optimization. Consequently, VAns is ideally suited to mitigate trainability and noise-related issues by keeping the ansatz shallow. We employ VAns i
&lt;/p&gt;
&lt;p&gt;
arXiv:2103.06712v4 Announce Type: replace-cross  Abstract: Quantum machine learning -- and specifically Variational Quantum Algorithms (VQAs) -- offers a powerful, flexible paradigm for programming near-term quantum computers, with applications in chemistry, metrology, materials science, data science, and mathematics. Here, one trains an ansatz, in the form of a parameterized quantum circuit, to accomplish a task of interest. However, challenges have recently emerged suggesting that deep ansatzes are difficult to train, due to flat training landscapes caused by randomness or by hardware noise. This motivates our work, where we present a variable structure approach to build ansatzes for VQAs. Our approach, called VAns (Variable Ansatz), applies a set of rules to both grow and (crucially) remove quantum gates in an informed manner during the optimization. Consequently, VAns is ideally suited to mitigate trainability and noise-related issues by keeping the ansatz shallow. We employ VAns i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;LDReg&#30340;&#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#32500;&#24230;&#22349;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#22686;&#21152;&#23616;&#37096;&#20869;&#22312;&#32500;&#24230;&#65292;LDReg&#33021;&#22815;&#25913;&#21892;&#34920;&#31034;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.10474</link><description>&lt;p&gt;
LDReg: &#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LDReg: Local Dimensionality Regularized Self-Supervised Learning. (arXiv:2401.10474v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;LDReg&#30340;&#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#32500;&#24230;&#22349;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#22686;&#21152;&#23616;&#37096;&#20869;&#22312;&#32500;&#24230;&#65292;LDReg&#33021;&#22815;&#25913;&#21892;&#34920;&#31034;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#23398;&#20064;&#30340;&#34920;&#31034;&#21487;&#33021;&#23481;&#26131;&#20986;&#29616;&#32500;&#24230;&#22349;&#32553;&#65292;&#20854;&#20013;&#23398;&#20064;&#30340;&#34920;&#31034;&#23376;&#31354;&#38388;&#32500;&#24230;&#26497;&#20302;&#65292;&#22240;&#27492;&#26080;&#27861;&#34920;&#31034;&#23436;&#25972;&#30340;&#25968;&#25454;&#20998;&#24067;&#21644;&#27169;&#24577;&#12290;&#32500;&#24230;&#22349;&#32553;&#20063;&#34987;&#31216;&#20026;&#8220;&#22635;&#20805;&#19981;&#36275;&#8221;&#29616;&#35937;&#65292;&#26159;&#19979;&#28216;&#20219;&#21153;&#24615;&#33021;&#19979;&#38477;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#22312;&#20840;&#23616;&#23618;&#38754;&#19978;&#30740;&#31350;&#20102;SSL&#30340;&#32500;&#24230;&#22349;&#32553;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#34920;&#31034;&#21487;&#20197;&#22312;&#20840;&#23616;&#19978;&#35206;&#30422;&#39640;&#32500;&#31354;&#38388;&#65292;&#20294;&#22312;&#23616;&#37096;&#19978;&#20250;&#22349;&#32553;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#26412;&#22320;&#32500;&#24230;&#27491;&#21017;&#21270;&#65288;LDReg&#65289;&#8221;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20844;&#24335;&#26159;&#22522;&#20110;Fisher-Rao&#24230;&#37327;&#30340;&#25512;&#23548;&#65292;&#29992;&#20110;&#27604;&#36739;&#21644;&#20248;&#21270;&#27599;&#20010;&#25968;&#25454;&#28857;&#22312;&#28176;&#36827;&#23567;&#21322;&#24452;&#22788;&#30340;&#23616;&#37096;&#36317;&#31163;&#20998;&#24067;&#12290;&#36890;&#36807;&#22686;&#21152;&#23616;&#37096;&#20869;&#22312;&#32500;&#24230;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#35777;&#26126;LDReg&#21487;&#20197;&#25913;&#21892;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representations learned via self-supervised learning (SSL) can be susceptible to dimensional collapse, where the learned representation subspace is of extremely low dimensionality and thus fails to represent the full data distribution and modalities. Dimensional collapse also known as the "underfilling" phenomenon is one of the major causes of degraded performance on downstream tasks. Previous work has investigated the dimensional collapse problem of SSL at a global level. In this paper, we demonstrate that representations can span over high dimensional space globally, but collapse locally. To address this, we propose a method called $\textit{local dimensionality regularization (LDReg)}$. Our formulation is based on the derivation of the Fisher-Rao metric to compare and optimize local distance distributions at an asymptotically small radius for each data point. By increasing the local intrinsic dimensionality, we demonstrate through a range of experiments that LDReg improves the repres
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#22312;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#20013;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;&#30340;&#38382;&#39064;&#65292;&#24403;&#27169;&#22411;&#19979;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#32531;&#24930;&#12290;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.20703</link><description>&lt;p&gt;
&#24378;&#21270;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Vanishing Gradients in Reinforcement Finetuning of Language Models. (arXiv:2310.20703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#22312;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#20013;&#23384;&#22312;&#26799;&#24230;&#28040;&#22833;&#30340;&#38382;&#39064;&#65292;&#24403;&#27169;&#22411;&#19979;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#32531;&#24930;&#12290;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#24378;&#21270;&#24494;&#35843;&#65288;RFT&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#21644;&#19979;&#28216;&#20219;&#21153;&#23545;&#40784;&#65292;&#21363;&#20351;&#29992;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#26368;&#22823;&#21270;&#65288;&#21487;&#33021;&#26159;&#23398;&#20064;&#24471;&#21040;&#30340;&#65289;&#22870;&#21169;&#20989;&#25968;&#12290;&#26412;&#30740;&#31350;&#21457;&#29616;&#20102;RFT&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#30340;&#20248;&#21270;&#38556;&#30861;&#65306;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#27169;&#22411;&#19979;&#30340;&#22870;&#21169;&#26631;&#20934;&#24046;&#36739;&#23567;&#26102;&#65292;&#36755;&#20837;&#30340;&#26399;&#26395;&#26799;&#24230;&#20250;&#28040;&#22833;&#65292;&#21363;&#20351;&#26399;&#26395;&#22870;&#21169;&#36828;&#31163;&#26368;&#20248;&#35299;&#12290;&#36890;&#36807;&#22312;RFT&#22522;&#20934;&#21644;&#25511;&#21046;&#29615;&#22659;&#20013;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#21450;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;&#20110;&#23567;&#30340;&#22870;&#21169;&#26631;&#20934;&#24046;&#23548;&#33268;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#26222;&#36941;&#23384;&#22312;&#19988;&#26377;&#23475;&#65292;&#23548;&#33268;&#22870;&#21169;&#26368;&#22823;&#21270;&#26497;&#20854;&#32531;&#24930;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#20811;&#26381;RFT&#20013;&#26799;&#24230;&#28040;&#22833;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#21021;&#22987;&#30417;&#30563;&#24494;&#35843;&#65288;SFT&#65289;&#38454;&#27573;&#26159;&#26368;&#26377;&#24076;&#26395;&#30340;&#20505;&#36873;&#26041;&#27861;&#65292;&#24182;&#19988;&#25581;&#31034;&#20102;&#23427;&#22312;RFT&#27969;&#31243;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#30456;&#23545;&#36739;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;SFT&#38454;&#27573;&#21487;&#20197;&#26377;&#25928;&#20811;&#26381;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small num
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2310.17467</link><description>&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#35745;&#28909;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#24778;&#20154;&#30340;&#34920;&#29616;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#30340;&#22522;&#26412;&#24605;&#24819;&#26469;&#33258;&#38750;&#24179;&#34913;&#29289;&#29702;&#23398;&#65292;&#20294;&#26412;&#25991;&#20013;&#25105;&#20204;&#34920;&#26126;&#65292;&#21487;&#20197;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#26469;&#29702;&#35299;&#36825;&#20123;&#27169;&#22411;&#30340;&#35768;&#22810;&#26041;&#38754;&#12290;&#21033;&#29992;&#36825;&#31181;&#37325;&#26500;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#32463;&#21382;&#20102;&#19982;&#23545;&#31216;&#24615;&#30772;&#32570;&#29616;&#35937;&#30456;&#23545;&#24212;&#30340;&#20108;&#38454;&#30456;&#21464;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#65292;&#23427;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#26680;&#24515;&#65292;&#24182;&#21487;&#20197;&#29992;&#19968;&#32452;&#24179;&#22343;&#22330;&#20020;&#30028;&#25351;&#25968;&#26469;&#25551;&#36848;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#28909;&#21147;&#23398;&#30340;&#20844;&#24335;&#20998;&#26512;&#20102;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#20851;&#32852;&#35760;&#24518;&#32593;&#32476;&#36830;&#25509;&#30340;&#26368;&#36817;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative diffusion models have achieved spectacular performance in many areas of generative modeling. While the fundamental ideas behind these models come from non-equilibrium physics, in this paper we show that many aspects of these models can be understood using the tools of equilibrium statistical mechanics. Using this reformulation, we show that generative diffusion models undergo second-order phase transitions corresponding to symmetry breaking phenomena. We argue that this lead to a form of instability that lies at the heart of their generative capabilities and that can be described by a set of mean field critical exponents. We conclude by analyzing recent work connecting diffusion models and associative memory networks in view of the thermodynamic formulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#20855;&#26377;&#26080;&#35823;&#24046;&#19988;&#21487;&#24494;&#20998;&#30340;&#20132;&#25442;&#20989;&#25968;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#32622;&#25442;&#31561;&#21464;Transformer&#32593;&#32476;&#26469;&#25429;&#25417;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25490;&#24207;&#22522;&#20934;&#19978;&#34920;&#29616;&#20248;&#20110;&#25110;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2310.07174</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#35823;&#24046;&#30340;&#21487;&#24494;&#20998;&#20132;&#25442;&#20989;&#25968;&#30340;&#24191;&#20041;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Generalized Neural Sorting Networks with Error-Free Differentiable Swap Functions. (arXiv:2310.07174v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07174
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;&#65292;&#20854;&#20013;&#37319;&#29992;&#20102;&#20855;&#26377;&#26080;&#35823;&#24046;&#19988;&#21487;&#24494;&#20998;&#30340;&#20132;&#25442;&#20989;&#25968;&#65292;&#21516;&#26102;&#20351;&#29992;&#20102;&#32622;&#25442;&#31561;&#21464;Transformer&#32593;&#32476;&#26469;&#25429;&#25417;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25490;&#24207;&#22522;&#20934;&#19978;&#34920;&#29616;&#20248;&#20110;&#25110;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#24207;&#26159;&#25152;&#26377;&#35745;&#31639;&#26426;&#31995;&#32479;&#30340;&#22522;&#26412;&#25805;&#20316;&#65292;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#30340;&#37325;&#35201;&#30740;&#31350;&#35838;&#39064;&#12290;&#38500;&#20102;&#20256;&#32479;&#25490;&#24207;&#31639;&#27861;&#30340;&#38382;&#39064;&#34920;&#36848;&#65292;&#25105;&#20204;&#36890;&#36807;&#31070;&#32463;&#25490;&#24207;&#32593;&#32476;&#32771;&#34385;&#20102;&#26356;&#25277;&#35937;&#20294;&#20855;&#26377;&#34920;&#36798;&#21147;&#30340;&#36755;&#20837;&#65292;&#20363;&#22914;&#22810;&#20301;&#25968;&#23383;&#22270;&#20687;&#21644;&#22270;&#20687;&#29255;&#27573;&#12290;&#20026;&#20102;&#23398;&#20064;&#20174;&#39640;&#32500;&#36755;&#20837;&#21040;&#27425;&#24207;&#21464;&#37327;&#30340;&#26144;&#23556;&#65292;&#38656;&#35201;&#20445;&#35777;&#25490;&#24207;&#32593;&#32476;&#30340;&#21487;&#24494;&#20998;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#21487;&#24494;&#20998;&#30340;&#20132;&#25442;&#20989;&#25968;&#23450;&#20041;&#19968;&#20010;&#26580;&#21270;&#35823;&#24046;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26080;&#35823;&#24046;&#30340;&#20132;&#25442;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#28385;&#36275;&#38750;&#20943;&#21644;&#21487;&#24494;&#20998;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#37319;&#29992;&#20102;&#20855;&#26377;&#22810;&#22836;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#32622;&#25442;&#31561;&#21464;Transformer&#32593;&#32476;&#65292;&#20197;&#25429;&#25417;&#32473;&#23450;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#21033;&#29992;&#20854;&#33258;&#27880;&#24847;&#21147;&#30340;&#27169;&#22411;&#33021;&#21147;&#12290;&#22312;&#22810;&#26679;&#30340;&#25490;&#24207;&#22522;&#20934;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#25110;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sorting is a fundamental operation of all computer systems, having been a long-standing significant research topic. Beyond the problem formulation of traditional sorting algorithms, we consider sorting problems for more abstract yet expressive inputs, e.g., multi-digit images and image fragments, through a neural sorting network. To learn a mapping from a high-dimensional input to an ordinal variable, the differentiability of sorting networks needs to be guaranteed. In this paper we define a softening error by a differentiable swap function, and develop an error-free swap function that holds non-decreasing and differentiability conditions. Furthermore, a permutation-equivariant Transformer network with multi-head attention is adopted to capture dependency between given inputs and also leverage its model capacity with self-attention. Experiments on diverse sorting benchmarks show that our methods perform better than or comparable to baseline methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Leave-One-Out&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#31283;&#23450;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#26680;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#21644;&#30041;&#19968;&#27861;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20934;&#21017;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#23494;&#24230;&#19981;&#22343;&#21248;&#22256;&#38590;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#21487;&#23398;&#20064;&#26435;&#37325;&#25193;&#23637;&#27169;&#22411;&#65292;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.03556</link><description>&lt;p&gt;
&#20351;&#29992;Leave-One-Out&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#31283;&#23450;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Leave-One-Out&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#31283;&#23450;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#26680;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#21644;&#30041;&#19968;&#27861;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20934;&#21017;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#23494;&#24230;&#19981;&#22343;&#21248;&#22256;&#38590;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#21487;&#23398;&#20064;&#26435;&#37325;&#25193;&#23637;&#27169;&#22411;&#65292;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#21644;&#35268;&#21010;&#36807;&#31243;&#30340;&#27010;&#29575;&#24314;&#27169;&#20381;&#36182;&#20110;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#36825;&#38656;&#35201;&#36275;&#22815;&#22823;&#30340;&#25968;&#25454;&#38598;&#12290;&#24403;&#21382;&#21490;&#25968;&#25454;&#19981;&#36275;&#26102;&#65292;&#24076;&#26395;&#23558;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#24314;&#27169;&#20026;&#27010;&#29575;&#20998;&#24067;&#65292;&#20197;&#35780;&#20272;&#25968;&#25454;&#36136;&#37327;&#24182;&#29983;&#25104;&#26356;&#22810;&#25968;&#25454;&#12290;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#30340;&#27169;&#22411;&#26159;&#36825;&#19968;&#20219;&#21153;&#30340;&#24120;&#29992;&#36873;&#25321;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#36866;&#24212;&#23494;&#24230;&#19981;&#22343;&#21248;&#30340;&#25968;&#25454;&#21306;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#37319;&#29992;&#33258;&#36866;&#24212;KDE&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#27169;&#22411;&#20013;&#30340;&#27599;&#20010;&#26680;&#20989;&#25968;&#20855;&#26377;&#29420;&#31435;&#30340;&#24102;&#23485;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#30041;&#19968;&#27861;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#65288;LOO-MLL&#65289;&#20934;&#21017;&#65292;&#20197;&#38450;&#27490;&#24120;&#35268;&#30340;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20934;&#21017;&#20135;&#29983;&#22855;&#24322;&#35299;&#65292;&#24182;&#35777;&#26126;LOO-MLL&#21487;&#20197;&#38450;&#27490;&#36825;&#31181;&#24773;&#20917;&#12290;&#22312;&#27492;&#20445;&#35777;&#30340;&#40065;&#26834;&#24615;&#22522;&#30784;&#19978;&#65292;&#36890;&#36807;&#20026;&#26680;&#20989;&#25968;&#20998;&#37197;&#21487;&#23398;&#20064;&#26435;&#37325;&#25193;&#23637;&#20102;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#25913;&#36827;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#26469;&#21152;&#36895;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic modelling of power systems operation and planning processes depends on data-driven methods, which require sufficiently large datasets. When historical data lacks this, it is desired to model the underlying data generation mechanism as a probability distribution to assess the data quality and generate more data, if needed. Kernel density estimation (KDE) based models are popular choices for this task, but they fail to adapt to data regions with varying densities. In this paper, an adaptive KDE model is employed to circumvent this, where each kernel in the model has an individual bandwidth. The leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to prevent the singular solutions that the regular MLL criterion gives rise to, and it is proven that LOO-MLL prevents these. Relying on this guaranteed robustness, the model is extended by assigning learnable weights to the kernels. In addition, a modified expectation-maximization algorithm is employed to accelerat
&lt;/p&gt;</description></item><item><title>Delta-AI&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#22270;&#27169;&#22411;&#30340;&#25674;&#36824;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#37096;&#20449;&#29992;&#20998;&#37197;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#21152;&#24555;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.02423</link><description>&lt;p&gt;
Delta-AI: &#31232;&#30095;&#22270;&#27169;&#22411;&#30340;&#25674;&#36824;&#25512;&#29702;&#20013;&#30340;&#23616;&#37096;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Delta-AI: Local objectives for amortized inference in sparse graphical models. (arXiv:2310.02423v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02423
&lt;/p&gt;
&lt;p&gt;
Delta-AI&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31232;&#30095;&#22270;&#27169;&#22411;&#30340;&#25674;&#36824;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#37096;&#20449;&#29992;&#20998;&#37197;&#21644;&#31163;&#31574;&#30053;&#35757;&#32451;&#21152;&#24555;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#27010;&#29575;&#22270;&#27169;&#22411;&#65288;PGMs&#65289;&#30340;&#25674;&#36824;&#25512;&#29702;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;Delta-AI&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#36825;&#26679;&#30340;&#35266;&#23519;&#65306;&#24403;PGM&#20013;&#30340;&#21464;&#37327;&#37319;&#26679;&#34987;&#35270;&#20026;&#19968;&#20010;&#20195;&#29702;&#20154;&#37319;&#21462;&#30340;&#21160;&#20316;&#24207;&#21015;&#26102;&#65292;PGM&#30340;&#31232;&#30095;&#24615;&#20351;&#24471;&#20195;&#29702;&#20154;&#30340;&#31574;&#30053;&#23398;&#20064;&#30446;&#26631;&#33021;&#22815;&#36827;&#34892;&#23616;&#37096;&#20449;&#29992;&#20998;&#37197;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#23616;&#37096;&#32422;&#26463;&#65292;&#21487;&#20197;&#36716;&#21270;&#20026;&#31867;&#20284;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#20013;&#30340;&#23616;&#37096;&#25439;&#22833;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#31163;&#31574;&#30053;&#35757;&#32451;&#65292;&#20294;&#36991;&#20813;&#20102;&#27599;&#20010;&#21442;&#25968;&#26356;&#26032;&#38656;&#35201;&#23454;&#20363;&#21270;&#25152;&#26377;&#38543;&#26426;&#21464;&#37327;&#30340;&#38656;&#27714;&#65292;&#20174;&#32780;&#22823;&#22823;&#21152;&#24555;&#20102;&#35757;&#32451;&#36895;&#24230;&#12290;Delta-AI&#30446;&#26631;&#19982;&#19968;&#20010;&#21487;&#35745;&#31639;&#30340;&#23398;&#20064;&#37319;&#26679;&#22120;&#20013;&#30340;&#21464;&#37327;&#32473;&#23450;&#20854;&#39532;&#23572;&#21487;&#22827;&#27631;&#23376;&#30340;&#26465;&#20214;&#20998;&#24067;&#30456;&#21305;&#37197;&#65292;&#35813;&#37319;&#26679;&#22120;&#30340;&#32467;&#26500;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#65292;&#22312;&#30446;&#26631;PGM&#19979;&#20855;&#26377;&#30456;&#21516;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#35757;&#32451;&#21518;&#30340;&#37319;&#26679;&#22120;&#21487;&#20197;&#24674;&#22797;&#24863;&#20852;&#36259;&#21464;&#37327;&#30340;&#36793;&#38469;&#20998;&#24067;&#21644;&#26465;&#20214;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new algorithm for amortized inference in sparse probabilistic graphical models (PGMs), which we call $\Delta$-amortized inference ($\Delta$-AI). Our approach is based on the observation that when the sampling of variables in a PGM is seen as a sequence of actions taken by an agent, sparsity of the PGM enables local credit assignment in the agent's policy learning objective. This yields a local constraint that can be turned into a local loss in the style of generative flow networks (GFlowNets) that enables off-policy training but avoids the need to instantiate all the random variables for each parameter update, thus speeding up training considerably. The $\Delta$-AI objective matches the conditional distribution of a variable given its Markov blanket in a tractable learned sampler, which has the structure of a Bayesian network, with the same conditional distribution under the target PGM. As such, the trained sampler recovers marginals and conditional distributions of intere
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.12833</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Model-based causal feature selection for general response types. (arXiv:2309.12833v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#27169;&#22411;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#21709;&#24212;&#31867;&#22411;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#19981;&#21464;&#24615;&#20551;&#35774;&#20174;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#20013;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#35299;&#20915;&#20102;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#39033;&#22522;&#26412;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26576;&#20123;&#24212;&#29992;&#20013;&#65292;&#20165;&#23398;&#20064;&#32473;&#23450;&#21709;&#24212;&#21464;&#37327;&#30340;&#22240;&#26524;&#29305;&#24449;&#21487;&#33021;&#24050;&#32463;&#36275;&#22815;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#25972;&#20010;&#28508;&#22312;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#19981;&#21464;&#22240;&#26524;&#39044;&#27979;&#65288;ICP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#38656;&#35201;&#26469;&#33258;&#24322;&#36136;&#29615;&#22659;&#30340;&#25968;&#25454;&#12290;ICP&#20551;&#35774;&#20174;&#30452;&#25509;&#21407;&#22240;&#29983;&#25104;&#21709;&#24212;&#30340;&#26426;&#21046;&#22312;&#25152;&#26377;&#29615;&#22659;&#20013;&#37117;&#30456;&#21516;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#19981;&#21464;&#24615;&#36755;&#20986;&#19968;&#37096;&#20998;&#22240;&#26524;&#29305;&#24449;&#30340;&#23376;&#38598;&#12290;ICP&#30340;&#26694;&#26550;&#24050;&#32463;&#25193;&#23637;&#21040;&#19968;&#33324;&#30340;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#65292;&#20351;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#12290;&#28982;&#32780;&#65292;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#32463;&#24120;&#21463;&#21040;&#20302;&#21151;&#29575;&#65288;&#25110;&#36739;&#24046;&#30340;&#31867;&#22411;I&#38169;&#35823;&#25511;&#21046;&#65289;&#30340;&#22256;&#25200;&#65292;&#24182;&#19988;&#19978;&#36848;&#21442;&#25968;&#27169;&#22411;&#19981;&#36866;&#29992;&#20110;&#21709;&#24212;&#19981;&#26159;&#22312;&#36830;&#32493;&#21051;&#24230;&#19978;&#27979;&#37327;&#30340;&#24212;&#29992;&#24773;&#20917;&#65292;&#32780;&#26159;&#21453;&#26144;&#20102;&#20998;&#31867;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discovering causal relationships from observational data is a fundamental yet challenging task. In some applications, it may suffice to learn the causal features of a given response variable, instead of learning the entire underlying causal structure. Invariant causal prediction (ICP, Peters et al., 2016) is a method for causal feature selection which requires data from heterogeneous settings. ICP assumes that the mechanism for generating the response from its direct causes is the same in all settings and exploits this invariance to output a subset of the causal features. The framework of ICP has been extended to general additive noise models and to nonparametric settings using conditional independence testing. However, nonparametric conditional independence testing often suffers from low power (or poor type I error control) and the aforementioned parametric models are not suitable for applications in which the response is not measured on a continuous scale, but rather reflects categor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#24182;&#19988;&#26500;&#24314;&#20102;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#30830;&#23450;&#20102;&#21508;&#31181;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.10639</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#21644;&#20840;&#23616;${\mathcal L}^2$&#26368;&#23567;&#21270;&#22120;&#30340;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers. (arXiv:2309.10639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#24182;&#19988;&#26500;&#24314;&#20102;&#20840;&#23616;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#30830;&#23450;&#20102;&#21508;&#31181;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#32593;&#32476;&#32467;&#26500;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#35813;&#32593;&#32476;&#20855;&#26377;$L$&#20010;&#38544;&#34255;&#23618;&#65292;&#26012;&#22369;&#28608;&#27963;&#20989;&#25968;&#65292;${\mathcal L}^2$ Schatten&#31867;&#65288;&#25110;Hilbert-Schmidt&#65289;&#25104;&#26412;&#20989;&#25968;&#65292;&#20197;&#21450;&#30456;&#31561;&#32500;&#24230;$Q\geq1$&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;${\mathbb R}^Q$&#12290;&#38544;&#34255;&#23618;&#20063;&#23450;&#20041;&#22312;${\mathbb R}^{Q}$&#30340;&#31354;&#38388;&#19978;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#26368;&#26032;&#30340;&#20851;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26524;&#65292;&#22312;$L\geq Q$&#30340;&#24773;&#20917;&#19979;&#26500;&#36896;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#26368;&#23567;&#21270;&#22120;&#26063;&#65292;&#35813;&#26063;&#33021;&#22815;&#20840;&#23616;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#26063;&#26159;&#36864;&#21270;&#30340;&#12290;&#22312;&#36825;&#37324;&#25552;&#21040;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;DL&#32593;&#32476;&#30340;&#38544;&#34255;&#23618;&#36890;&#36807;&#23545;&#35757;&#32451;&#36755;&#20837;&#30340;&#36882;&#24402;&#25130;&#26029;&#26144;&#23556;&#30340;&#24212;&#29992;&#26469;&#8220;&#25972;&#29702;&#8221;&#35757;&#32451;&#36755;&#20837;&#65292;&#20197;&#26368;&#23567;&#21270;&#22122;&#22768;&#19982;&#20449;&#21495;&#30340;&#27604;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;$2^Q-1$&#20010;&#19981;&#21516;&#30340;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\mathbb R}^Q$ with equal dimension $Q\geq1$. The hidden layers are defined on spaces ${\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network "curate" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;$\pi$-KRVI&#30340;&#20048;&#35266;&#20462;&#25913;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12290;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#65292;&#24182;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20248;&#32467;&#26524;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#22810;&#39033;&#24335;&#20302;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2306.07745</link><description>&lt;p&gt;
&#26680;&#21270;&#24378;&#21270;&#23398;&#20064;&#21450;&#20854;&#36817;&#20284;&#26041;&#27861;&#30340;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Kernelized Reinforcement Learning with Order Optimal Regret Bounds. (arXiv:2306.07745v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07745
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;$\pi$-KRVI&#30340;&#20048;&#35266;&#20462;&#25913;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12290;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#65292;&#24182;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20248;&#32467;&#26524;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#22810;&#39033;&#24335;&#20302;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#21508;&#31181;&#20855;&#26377;&#22797;&#26434;&#27169;&#22411;&#21644;&#22823;&#29366;&#24577;-&#34892;&#20026;&#31354;&#38388;&#30340;&#23454;&#38469;&#22330;&#26223;&#20013;&#26174;&#31034;&#20986;&#20102;&#23454;&#35777;&#30340;&#25104;&#21151;&#12290;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#32467;&#26524;&#36890;&#24120;&#38598;&#20013;&#20110;&#20855;&#26377;&#23569;&#37327;&#29366;&#24577;-&#34892;&#20026;&#25110;&#31616;&#21333;&#27169;&#22411;&#65288;&#20363;&#22914;&#32447;&#24615;&#24314;&#27169;&#29366;&#24577;-&#34892;&#20026;&#20540;&#20989;&#25968;&#65289;&#30340;&#35774;&#32622;&#12290; &#20026;&#20102;&#25512;&#23548;&#26377;&#25928;&#22788;&#29702;&#26356;&#24191;&#27867;&#20540;&#20989;&#25968;&#30340;&#22823;&#29366;&#24577;-&#34892;&#20026;&#31354;&#38388;&#30340;RL&#31574;&#30053;&#65292;&#19968;&#20123;&#26368;&#26032;&#24037;&#20316;&#32771;&#34385;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#36827;&#34892;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#31216;&#20026;$\pi$-KRVI&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#30340;&#19968;&#31181;&#20048;&#35266;&#20462;&#25913;&#65292;&#24403;&#29366;&#24577;-&#34892;&#20026;&#20540;&#20989;&#25968;&#30001;RKHS&#34920;&#31034;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#22312;&#35768;&#22810;&#20855;&#26377;&#39640;&#24230;&#38750;&#20809;&#28369;&#20869;&#26680;&#65288;&#20363;&#22914;&#31070;&#32463;&#20999;&#21521;&#20869;&#26680;&#25110;&#26576;&#20123;Mat\'ern&#20869;&#26680;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#26368;&#20248;&#32467;&#26524;&#65292;&#23384;&#22312;&#26174;&#30528;&#30340;&#22810;&#39033;&#24335;&#20302;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has shown empirical success in various real world settings with complex models and large state-action spaces. The existing analytical results, however, typically focus on settings with a small number of state-actions or simple models such as linearly modeled state-action value functions. To derive RL policies that efficiently handle large state-action spaces with more general value functions, some recent works have considered nonlinear function approximation using kernel ridge regression. We propose $\pi$-KRVI, an optimistic modification of least-squares value iteration, when the state-action value function is represented by an RKHS. We prove the first order-optimal regret guarantees under a general setting. Our results show a significant polynomial in the number of episodes improvement over the state of the art. In particular, with highly non-smooth kernels (such as Neural Tangent kernel or some Mat\'ern kernels) the existing results lead to trivial (superl
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#65292;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#26368;&#26032;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65307;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#36827;&#34892;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.13991</link><description>&lt;p&gt;
&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Expressive Losses for Verified Robustness via Convex Combinations. (arXiv:2305.13991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13991
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#65292;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#26368;&#26032;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65307;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#36827;&#34892;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#36890;&#36807;&#65288;&#25200;&#21160;&#21306;&#22495;&#30340;&#23376;&#38598;&#65289;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#38480;&#65292;&#25110;&#22312;&#23545;&#25239;&#35757;&#32451;&#20043;&#19978;&#24341;&#20837;&#21487;&#39564;&#35777;&#24615;&#26469;&#35757;&#32451;&#20855;&#26377;&#24050;&#39564;&#35777;&#40065;&#26834;&#24615;&#30340;&#32593;&#32476;&#12290;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20851;&#38190;&#22312;&#20110;&#25152;&#20351;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23427;&#24212;&#35813;&#33021;&#22815;&#21305;&#37197;&#35757;&#32451;&#21518;&#35201;&#20351;&#29992;&#30340;&#39564;&#35777;&#22120;&#30340;&#32039;&#23494;&#24230;&#12290;&#25105;&#20204;&#24418;&#24335;&#21270;&#23450;&#20041;&#20102;&#34920;&#36798;&#21147;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#26469;&#28385;&#36275;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;CC-IBP&#21644;MTL-IBP&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#22343;&#21487;&#20197;&#20135;&#29983;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#23613;&#31649;&#20854;&#27010;&#24565;&#19978;&#26159;&#31616;&#21333;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;TinyImageNet&#21644;&#32553;&#23567;&#30340;ImageNet&#19978;&#65292;&#23545;&#20110;&#21322;&#24452;&#20026;$ \frac{1} {255} $&#30340;$ \ell_ \infty $&#25200;&#21160;&#65292;MTL-IBP&#21487;&#20197;&#23558;&#25991;&#29486;&#20013;&#26368;&#20339;&#26631;&#20934;&#21644;&#39564;&#35777;&#20934;&#30830;&#24615;&#20174;$1.98\%$&#25552;&#39640;&#21040;$3.92\%$&#65292;&#21516;&#26102;&#20165;&#20381;&#36182;&#20110;&#21333;&#27493;&#33258;&#36866;&#24212;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\ell_\infty$ perturbations of radius $\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\%$ to $3.92\%$ points while only relying on single-step ad
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#65288;SPG&#65289;&#24378;&#21270;&#23398;&#20064;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#36890;&#36947;&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;&#65292;&#33021;&#22815;&#20256;&#36755;&#24847;&#20041;&#32780;&#38750;&#31934;&#30830;&#29256;&#26412;&#65292;&#36798;&#21040;&#20102;&#20449;&#24687;&#36895;&#29575;&#33410;&#30465;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.03571</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#30340;&#27169;&#22411;&#26080;&#20851;&#35821;&#20041;&#36890;&#20449;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Model-free Reinforcement Learning of Semantic Communication by Stochastic Policy Gradient. (arXiv:2305.03571v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#65288;SPG&#65289;&#24378;&#21270;&#23398;&#20064;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#36890;&#36947;&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;&#65292;&#33021;&#22815;&#20256;&#36755;&#24847;&#20041;&#32780;&#38750;&#31934;&#30830;&#29256;&#26412;&#65292;&#36798;&#21040;&#20102;&#20449;&#24687;&#36895;&#29575;&#33410;&#30465;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#22312;&#26080;&#32447;&#36890;&#20449;&#26041;&#38754;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#38886;&#24343;&#65288;Weaver&#65289;&#20110;1949&#24180;&#25552;&#20986;&#30340;&#35821;&#20041;&#36890;&#20449;&#27010;&#24565;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#23427;&#25171;&#30772;&#20102;&#39321;&#20892;&#32463;&#20856;&#30340;&#35774;&#35745;&#33539;&#20363;&#65292;&#26088;&#22312;&#20256;&#36755;&#28040;&#24687;&#30340;&#24847;&#20041;&#65292;&#21363;&#35821;&#20041;&#65292;&#32780;&#19981;&#26159;&#31934;&#30830;&#29256;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#20449;&#24687;&#36895;&#29575;&#33410;&#30465;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#65288;SPG&#65289;&#26469;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;&#65292;&#19981;&#38656;&#35201;&#24050;&#30693;&#25110;&#21487;&#24494;&#20998;&#36890;&#36947;&#27169;&#22411;&#65292;&#36825;&#26159;&#23454;&#38469;&#37096;&#32626;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#26368;&#22823;&#21270;&#25509;&#25910;&#21644;&#30446;&#26631;&#21464;&#37327;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#20986;&#21457;&#65292;&#28608;&#21457;&#20102;&#23558;SPG&#29992;&#20110;&#32463;&#20856;&#21644;&#35821;&#20041;&#36890;&#20449;&#30340;&#21160;&#26426;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36798;&#21040;&#20102;&#19982;&#22522;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#24039;&#30340;&#27169;&#22411;&#24863;&#30693;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#23613;&#31649;&#25910;&#25947;&#36895;&#24230;&#26377;&#25152;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the recent success of Machine Learning tools in wireless communications, the idea of semantic communication by Weaver from 1949 has gained attention. It breaks with Shannon's classic design paradigm by aiming to transmit the meaning, i.e., semantics, of a message instead of its exact version, allowing for information rate savings. In this work, we apply the Stochastic Policy Gradient (SPG) to design a semantic communication system by reinforcement learning, not requiring a known or differentiable channel model a crucial step towards deployment in practice. Further, we motivate the use of SPG for both classic and semantic communication from the maximization of the mutual information between received and target variables. Numerical results show that our approach achieves comparable performance to a model-aware approach based on the reparametrization trick, albeit with a decreased convergence rate.
&lt;/p&gt;</description></item></channel></rss>