<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23558;$\varepsilon$-greedy&#31574;&#30053;&#24341;&#20837;Thompson&#37319;&#26679;&#20197;&#25913;&#36827;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#24320;&#21457;&#21151;&#33021;&#65292;&#24182;&#23454;&#35777;&#34920;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00540</link><description>&lt;p&gt;
Epsilon-Greedy Thompson Sampling&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Epsilon-Greedy Thompson Sampling to Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00540
&lt;/p&gt;
&lt;p&gt;
&#23558;$\varepsilon$-greedy&#31574;&#30053;&#24341;&#20837;Thompson&#37319;&#26679;&#20197;&#25913;&#36827;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#24320;&#21457;&#21151;&#33021;&#65292;&#24182;&#23454;&#35777;&#34920;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Thompson&#37319;&#26679;&#65288;TS&#65289;&#34987;&#35748;&#20026;&#26159;&#35299;&#20915;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24320;&#21457;-&#25506;&#32034;&#22256;&#22659;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290; &#34429;&#28982;&#23427;&#36890;&#36807;&#38543;&#26426;&#29983;&#25104;&#21644;&#26368;&#22823;&#21270;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#21518;&#39564;&#30340;&#26679;&#26412;&#36335;&#24452;&#26469;&#20248;&#20808;&#36827;&#34892;&#25506;&#32034;&#65292;&#20294;TS&#22312;&#27599;&#27425;&#25191;&#34892;&#25506;&#32034;&#21518;&#36890;&#36807;&#25910;&#38598;&#20851;&#20110;&#30495;&#23454;&#30446;&#26631;&#20989;&#25968;&#30340;&#20449;&#24687;&#26469;&#24369;&#21270;&#20854;&#24320;&#21457;&#21151;&#33021;&#12290; &#26412;&#30740;&#31350;&#23558;&#22312;TS&#20013;&#24341;&#20837;$\varepsilon$-greedy&#31574;&#30053;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#30340;&#36873;&#25321;&#31574;&#30053;&#65292;&#20197;&#25913;&#36827;&#20854;&#24320;&#21457;&#21151;&#33021;&#12290; &#25105;&#20204;&#39318;&#20808;&#25551;&#36848;&#20102;TS&#24212;&#29992;&#20110;BO&#30340;&#20004;&#20010;&#26497;&#31471;&#65292;&#21363;&#36890;&#29992;TS&#21644;&#26679;&#26412;&#24179;&#22343;TS&#12290;&#21069;&#32773;&#21644;&#21518;&#32773;&#20998;&#21035;&#25552;&#20513;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290; &#28982;&#21518;&#25105;&#20204;&#20351;&#29992;$\varepsilon$-greedy&#31574;&#30053;&#22312;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#38543;&#26426;&#20999;&#25442;&#12290; $\varepsilon \in (0,1)$&#30340;&#23567;&#20540;&#20248;&#20808;&#32771;&#34385;&#24320;&#21457;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290; &#25105;&#20204;&#23454;&#35777;&#34920;&#26126;$\varepsilon$-greedy T
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00540v1 Announce Type: new  Abstract: Thompson sampling (TS) serves as a solution for addressing the exploitation-exploration dilemma in Bayesian optimization (BO). While it prioritizes exploration by randomly generating and maximizing sample paths of Gaussian process (GP) posteriors, TS weakly manages its exploitation by gathering information about the true objective function after each exploration is performed. In this study, we incorporate the epsilon-greedy ($\varepsilon$-greedy) policy, a well-established selection strategy in reinforcement learning, into TS to improve its exploitation. We first delineate two extremes of TS applied for BO, namely the generic TS and a sample-average TS. The former and latter promote exploration and exploitation, respectively. We then use $\varepsilon$-greedy policy to randomly switch between the two extremes. A small value of $\varepsilon \in (0,1)$ prioritizes exploitation, and vice versa. We empirically show that $\varepsilon$-greedy T
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#31639;&#27861;&#65288;GEnBP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#39640;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#31561;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2402.08193</link><description>&lt;p&gt;
&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#30340;&#39640;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08193
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#31639;&#27861;&#65288;GEnBP&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#31995;&#32479;&#20013;&#39640;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#31561;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#39640;&#25928;&#25512;&#26029;&#20173;&#28982;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#39640;&#26031;&#27169;&#22411;&#38598;&#25104;&#32622;&#20449;&#20256;&#25773;&#65288;GEnBP&#65289;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#38598;&#25104;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#39640;&#26031;&#32622;&#20449;&#20256;&#25773;&#65288;GaBP&#65289;&#26041;&#27861;&#30340;&#32467;&#21512;&#12290;GEnBP&#36890;&#36807;&#22312;&#22270;&#27169;&#22411;&#32467;&#26500;&#20013;&#20256;&#36882;&#20302;&#31209;&#26412;&#22320;&#20449;&#24687;&#26469;&#26356;&#26032;&#38598;&#25104;&#27169;&#22411;&#12290;&#36825;&#31181;&#32452;&#21512;&#32487;&#25215;&#20102;&#27599;&#31181;&#26041;&#27861;&#30340;&#26377;&#21033;&#29305;&#24615;&#12290;&#38598;&#25104;&#25216;&#26415;&#20351;&#24471;GEnBP&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#12289;&#21442;&#25968;&#21644;&#22797;&#26434;&#30340;&#12289;&#22024;&#26434;&#30340;&#40657;&#31665;&#29983;&#25104;&#36807;&#31243;&#12290;&#22312;&#22270;&#27169;&#22411;&#32467;&#26500;&#20013;&#20351;&#29992;&#26412;&#22320;&#20449;&#24687;&#30830;&#20445;&#20102;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20998;&#24067;&#24335;&#35745;&#31639;&#65292;&#24182;&#33021;&#39640;&#25928;&#22320;&#22788;&#29702;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;&#24403;&#38598;&#25104;&#22823;&#23567;&#36828;&#23567;&#20110;&#25512;&#26029;&#32500;&#24230;&#26102;&#65292;GEnBP&#29305;&#21035;&#26377;&#20248;&#21183;&#12290;&#36825;&#31181;&#24773;&#20917;&#22312;&#31354;&#26102;&#24314;&#27169;&#12289;&#22270;&#20687;&#22788;&#29702;&#21644;&#29289;&#29702;&#27169;&#22411;&#21453;&#28436;&#31561;&#39046;&#22495;&#32463;&#24120;&#20986;&#29616;&#12290;GEnBP&#21487;&#20197;&#24212;&#29992;&#20110;&#19968;&#33324;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficient inference in high-dimensional models remains a central challenge in machine learning. This paper introduces the Gaussian Ensemble Belief Propagation (GEnBP) algorithm, a fusion of the Ensemble Kalman filter and Gaussian belief propagation (GaBP) methods. GEnBP updates ensembles by passing low-rank local messages in a graphical model structure. This combination inherits favourable qualities from each method. Ensemble techniques allow GEnBP to handle high-dimensional states, parameters and intricate, noisy, black-box generation processes. The use of local messages in a graphical model structure ensures that the approach is suited to distributed computing and can efficiently handle complex dependence structures. GEnBP is particularly advantageous when the ensemble size is considerably smaller than the inference dimension. This scenario often arises in fields such as spatiotemporal modelling, image processing and physical model inversion. GEnBP can be applied to general problem s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21307;&#30103;AI&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#20013;&#30340;&#31639;&#27861;&#20559;&#20506;&#65292;&#36890;&#36807;&#37319;&#29992;CART&#31639;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#20559;&#20506;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#21644;&#30495;&#23454;&#20020;&#24202;&#29615;&#22659;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2312.02959</link><description>&lt;p&gt;
&#22312;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#26816;&#27979;&#31639;&#27861;&#20559;&#20506;
&lt;/p&gt;
&lt;p&gt;
Detecting algorithmic bias in medical AI-models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02959
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21307;&#30103;AI&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#20013;&#30340;&#31639;&#27861;&#20559;&#20506;&#65292;&#36890;&#36807;&#37319;&#29992;CART&#31639;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#20559;&#20506;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#21644;&#30495;&#23454;&#20020;&#24202;&#29615;&#22659;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#21307;&#30103;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#26085;&#30410;&#26222;&#21450;&#65292;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#20197;&#20844;&#24179;&#12289;&#20844;&#27491;&#30340;&#26041;&#24335;&#25552;&#20379;&#24739;&#32773;&#32467;&#26524;&#21464;&#24471;&#21516;&#26679;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21307;&#30103;AI&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#20013;&#30340;&#31639;&#27861;&#20559;&#20506;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#37319;&#29992;&#20998;&#31867;&#19982;&#22238;&#24402;&#26641;&#65288;CART&#65289;&#31639;&#27861;&#65292;&#22312;&#33043;&#27602;&#30151;&#39044;&#27979;&#32972;&#26223;&#19979;&#26377;&#25928;&#22320;&#35782;&#21035;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#20559;&#20506;&#12290;&#25105;&#20204;&#36890;&#36807;&#36827;&#34892;&#19968;&#31995;&#21015;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#21463;&#25511;&#29615;&#22659;&#20013;&#20934;&#30830;&#20272;&#35745;&#20559;&#20506;&#21306;&#22495;&#30340;&#33021;&#21147;&#12290;&#36825;&#19968;&#27010;&#24565;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#20351;&#29992;&#20122;&#29305;&#20848;&#22823;&#20052;&#27835;&#20122;&#24030;&#26684;&#38647;&#36842;&#32426;&#24565;&#21307;&#38498;&#30340;&#30005;&#23376;&#30149;&#21382;&#36827;&#34892;&#23454;&#39564;&#36827;&#19968;&#27493;&#24471;&#21040;&#39564;&#35777;&#12290;&#36825;&#20123;&#27979;&#35797;&#23637;&#31034;&#20102;&#25105;&#20204;&#31574;&#30053;&#22312;&#20020;&#24202;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02959v3 Announce Type: replace-cross  Abstract: With the growing prevalence of machine learning and artificial intelligence-based medical decision support systems, it is equally important to ensure that these systems provide patient outcomes in a fair and equitable fashion. This paper presents an innovative framework for detecting areas of algorithmic bias in medical-AI decision support systems. Our approach efficiently identifies potential biases in medical-AI models, specifically in the context of sepsis prediction, by employing the Classification and Regression Trees (CART) algorithm. We verify our methodology by conducting a series of synthetic data experiments, showcasing its ability to estimate areas of bias in controlled settings precisely. The effectiveness of the concept is further validated by experiments using electronic medical records from Grady Memorial Hospital in Atlanta, Georgia. These tests demonstrate the practical implementation of our strategy in a clini
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ROME&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#20272;&#35745;&#25972;&#20307;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#20272;&#35745;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.10566</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Multi-Modal Density Estimation. (arXiv:2401.10566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ROME&#30340;&#40065;&#26834;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#20272;&#35745;&#25972;&#20307;&#20998;&#24067;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#20272;&#35745;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#27010;&#29575;&#39044;&#27979;&#27169;&#22411;&#30340;&#21457;&#23637;&#24341;&#21457;&#20102;&#23545;&#32508;&#21512;&#35780;&#20272;&#25351;&#26631;&#30340;&#38656;&#27714;&#12290;&#34429;&#28982;&#26377;&#20960;&#20010;&#25351;&#26631;&#21487;&#20197;&#34920;&#24449;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65288;&#20363;&#22914;&#65292;&#36127;&#23545;&#25968;&#20284;&#28982;&#12289;Jensen-Shannon&#25955;&#24230;&#65289;&#65292;&#20294;&#36825;&#20123;&#25351;&#26631;&#36890;&#24120;&#20316;&#29992;&#20110;&#27010;&#29575;&#23494;&#24230;&#19978;&#12290;&#22240;&#27492;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#32431;&#31929;&#22522;&#20110;&#26679;&#26412;&#30340;&#39044;&#27979;&#27169;&#22411;&#38656;&#35201;&#20272;&#35745;&#24213;&#23618;&#23494;&#24230;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#26041;&#27861;&#22914;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#40065;&#26834;&#24615;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#32780;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#22312;&#22810;&#27169;&#24577;&#20272;&#35745;&#38382;&#39064;&#20013;&#23578;&#26410;&#24471;&#21040;&#35780;&#20272;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;ROME&#65288;RObust Multi-modal density Estimator&#65289;&#65292;&#23427;&#35299;&#20915;&#20102;&#20272;&#35745;&#22810;&#27169;&#24577;&#12289;&#38750;&#27491;&#24577;&#21644;&#39640;&#30456;&#20851;&#20998;&#24067;&#30340;&#25361;&#25112;&#12290;ROME&#21033;&#29992;&#32858;&#31867;&#23558;&#22810;&#27169;&#24577;&#26679;&#26412;&#38598;&#20998;&#21106;&#25104;&#22810;&#20010;&#21333;&#27169;&#24577;&#26679;&#26412;&#38598;&#65292;&#28982;&#21518;&#32467;&#21512;&#31616;&#21333;&#30340;KDE&#20272;&#35745;&#26469;&#24471;&#21040;&#24635;&#20307;&#30340;&#20272;&#35745;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Development of multi-modal, probabilistic prediction models has lead to a need for comprehensive evaluation metrics. While several metrics can characterize the accuracy of machine-learned models (e.g., negative log-likelihood, Jensen-Shannon divergence), these metrics typically operate on probability densities. Applying them to purely sample-based prediction models thus requires that the underlying density function is estimated. However, common methods such as kernel density estimation (KDE) have been demonstrated to lack robustness, while more complex methods have not been evaluated in multi-modal estimation problems. In this paper, we present ROME (RObust Multi-modal density Estimator), a non-parametric approach for density estimation which addresses the challenge of estimating multi-modal, non-normal, and highly correlated distributions. ROME utilizes clustering to segment a multi-modal set of samples into multiple uni-modal ones and then combines simple KDE estimates obtained for i
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#31350;&#22312;&#22810;&#27969;&#24418;&#27169;&#22411;&#19979;&#65292;&#23398;&#20064;&#30340;&#34920;&#31034;&#20309;&#26102;&#21487;&#20197;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#25968;&#25454;&#22686;&#24378;&#26041;&#38754;&#30340;&#39069;&#22806;&#22909;&#22788;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#32447;&#24615;&#20998;&#31163;&#33021;&#21147;&#30340;&#20449;&#24687;&#35770;&#26368;&#20248;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19041</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#32447;&#24615;&#20998;&#31163;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Linear Separation Capacity of Self-Supervised Representation Learning. (arXiv:2310.19041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#31350;&#22312;&#22810;&#27969;&#24418;&#27169;&#22411;&#19979;&#65292;&#23398;&#20064;&#30340;&#34920;&#31034;&#20309;&#26102;&#21487;&#20197;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#25968;&#25454;&#22686;&#24378;&#26041;&#38754;&#30340;&#39069;&#22806;&#22909;&#22788;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#32447;&#24615;&#20998;&#31163;&#33021;&#21147;&#30340;&#20449;&#24687;&#35770;&#26368;&#20248;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#24378;&#35843;&#20102;&#25968;&#25454;&#22686;&#24378;&#22312;&#20174;&#26080;&#26631;&#31614;&#25968;&#25454;&#20013;&#23398;&#20064;&#25968;&#25454;&#34920;&#31034;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#36825;&#20123;&#22686;&#24378;&#34920;&#31034;&#20043;&#19978;&#35757;&#32451;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#29087;&#32451;&#30340;&#20998;&#31867;&#22120;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#26159;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#23558;&#38750;&#32447;&#24615;&#25968;&#25454;&#32467;&#26500;&#35299;&#24320;&#20026;&#32447;&#24615;&#21487;&#20998;&#31163;&#34920;&#31034;&#30340;&#26426;&#21046;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#30740;&#31350;&#22312;&#20174;&#22810;&#27969;&#24418;&#27169;&#22411;&#20013;&#32472;&#21046;&#25968;&#25454;&#26102;&#65292;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#22312;&#20309;&#31181;&#26465;&#20214;&#19979;&#21487;&#20197;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#26469;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#25968;&#25454;&#22686;&#24378;&#38500;&#20102;&#25552;&#20379;&#35266;&#23519;&#25968;&#25454;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#21487;&#20197;&#25913;&#21892;&#32447;&#24615;&#20998;&#31163;&#23481;&#37327;&#30340;&#20449;&#24687;&#35770;&#26368;&#20248;&#36895;&#29575;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#33258;&#30417;&#30563;&#23398;&#20064;&#21487;&#20197;&#20197;&#27604;&#26080;&#30417;&#30563;&#23398;&#20064;&#26356;&#23567;&#30340;&#36317;&#31163;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#65292;&#31361;&#26174;&#20102;&#25968;&#25454;&#22686;&#24378;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in self-supervised learning have highlighted the efficacy of data augmentation in learning data representation from unlabeled data. Training a linear model atop these enhanced representations can yield an adept classifier. Despite the remarkable empirical performance, the underlying mechanisms that enable data augmentation to unravel nonlinear data structures into linearly separable representations remain elusive. This paper seeks to bridge this gap by investigating under what conditions learned representations can linearly separate manifolds when data is drawn from a multi-manifold model. Our investigation reveals that data augmentation offers additional information beyond observed data and can thus improve the information-theoretic optimal rate of linear separation capacity. In particular, we show that self-supervised learning can linearly separate manifolds with a smaller distance than unsupervised learning, underscoring the additional benefits of data augmentation. 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#65292;&#39044;&#27979;&#20102;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.03789</link><description>&lt;p&gt;
&#22909;&#34920;&#31034;&#30340;&#28082;&#28404;&#65306;&#22312;&#20004;&#23618;&#32593;&#32476;&#20013; grokking &#20316;&#20026;&#19968;&#38454;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Droplets of Good Representations: Grokking as a First Order Phase Transition in Two Layer Networks. (arXiv:2310.03789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#65292;&#39044;&#27979;&#20102;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#30340;&#24615;&#36136;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476; (DNN) &#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#33021;&#22815;&#23398;&#20064;&#26032;&#30340;&#29305;&#24449;&#12290;&#36825;&#31181;&#28145;&#24230;&#23398;&#20064;&#30340;&#26377;&#36259;&#26041;&#38754;&#22312;&#26368;&#36817;&#25253;&#36947;&#30340; Grokking &#29616;&#35937;&#20013;&#34920;&#29616;&#24471;&#26368;&#20026;&#26126;&#26174;&#12290;&#34429;&#28982;&#20027;&#35201;&#20307;&#29616;&#20026;&#27979;&#35797;&#20934;&#30830;&#24615;&#30340;&#31361;&#21464;&#22686;&#21152;&#65292;&#20294; Grokking &#20063;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#36229;&#36234;&#25042;&#24816;&#23398;&#20064;/&#39640;&#26031;&#36807;&#31243; (GP) &#30340;&#29616;&#35937;&#65292;&#28041;&#21450;&#29305;&#24449;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23558;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#33258;&#36866;&#24212;&#26680;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#20855;&#26377;&#31435;&#26041;&#22810;&#39033;&#24335;&#21644;&#27169;&#21152;&#27861;&#25945;&#24072;&#30340;&#20004;&#20010;&#24072;&#29983;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#36825;&#20123;&#27169;&#22411;&#19978;&#25552;&#20379;&#20102;&#20851;&#20110;&#29305;&#24449;&#23398;&#20064;&#21644; Grokking &#24615;&#36136;&#30340;&#20998;&#26512;&#39044;&#27979;&#65292;&#24182;&#23637;&#31034;&#20102; Grokking &#19982;&#30456;&#21464;&#29702;&#35770;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312; Grokking &#20043;&#21518;&#65292;DNN &#30340;&#29366;&#24577;&#31867;&#20284;&#20110;&#19968;&#38454;&#30456;&#21464;&#21518;&#30340;&#28151;&#21512;&#30456;&#12290;&#22312;&#36825;&#20010;&#28151;&#21512;&#30456;&#20013;&#65292;DNN &#29983;&#25104;&#20102;&#19982;&#20043;&#21069;&#26126;&#26174;&#19981;&#21516;&#30340;&#25945;&#24072;&#30340;&#26377;&#29992;&#20869;&#37096;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key property of deep neural networks (DNNs) is their ability to learn new features during training. This intriguing aspect of deep learning stands out most clearly in recently reported Grokking phenomena. While mainly reflected as a sudden increase in test accuracy, Grokking is also believed to be a beyond lazy-learning/Gaussian Process (GP) phenomenon involving feature learning. Here we apply a recent development in the theory of feature learning, the adaptive kernel approach, to two teacher-student models with cubic-polynomial and modular addition teachers. We provide analytical predictions on feature learning and Grokking properties of these models and demonstrate a mapping between Grokking and the theory of phase transitions. We show that after Grokking, the state of the DNN is analogous to the mixed phase following a first-order phase transition. In this mixed phase, the DNN generates useful internal representations of the teacher that are sharply distinct from those before the 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;Softmax&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#30340;&#32452;&#21512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#21442;&#25968;&#36827;&#34892;&#21453;&#21521;&#35757;&#32451;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#30456;&#20851;&#24615;&#32467;&#26500;&#65292;&#23454;&#29616;&#21521;&#20840;&#23616;&#26368;&#20248;&#20540;&#30340;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2310.02671</link><description>&lt;p&gt;
&#36229;&#36234;&#31283;&#23450;&#24615;&#65306;&#38543;&#26426;Softmax&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;Softmax&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#30340;&#32452;&#21512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#21442;&#25968;&#36827;&#34892;&#21453;&#21521;&#35757;&#32451;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#30456;&#20851;&#24615;&#32467;&#26500;&#65292;&#23454;&#29616;&#21521;&#20840;&#23616;&#26368;&#20248;&#20540;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#26159;&#19968;&#31181;&#24418;&#24335;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#21644;&#35299;&#20915;&#24207;&#36143;&#20915;&#31574;&#38382;&#39064;&#12290;&#22312;&#26377;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#65292;&#36825;&#20123;&#38382;&#39064;&#19982;&#26368;&#20248;&#20572;&#27490;&#25110;&#29305;&#23450;&#20379;&#24212;&#38142;&#38382;&#39064;&#20197;&#21450;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35757;&#32451;&#30456;&#20851;&#12290;&#19982;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;MDP&#19981;&#21516;&#65292;&#26368;&#20248;&#31574;&#30053;&#24182;&#19981;&#26159;&#31283;&#23450;&#30340;&#65292;&#31574;&#30053;&#24517;&#39035;&#22312;&#27599;&#20010;&#26102;&#26399;&#21333;&#29420;&#36827;&#34892;&#23398;&#20064;&#12290;&#23454;&#38469;&#19978;&#65292;&#24448;&#24448;&#21516;&#26102;&#35757;&#32451;&#25152;&#26377;&#21442;&#25968;&#65292;&#24573;&#35270;&#20102;&#21160;&#24577;&#35268;&#21010;&#25152;&#26263;&#31034;&#30340;&#20869;&#22312;&#32467;&#26500;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#21644;&#31574;&#30053;&#26799;&#24230;&#30340;&#32452;&#21512;&#26041;&#27861;&#65292;&#31216;&#20026;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#65292;&#20854;&#20013;&#21442;&#25968;&#22312;&#26102;&#38388;&#19978;&#20197;&#21453;&#21521;&#26041;&#24335;&#36827;&#34892;&#35757;&#32451;&#12290;&#23545;&#20110;&#34920;&#26684;Softmax&#21442;&#25968;&#21270;&#65292;&#25105;&#20204;&#23545;&#21516;&#26102;&#21644;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#22312;&#31934;&#30830;&#26799;&#24230;&#21644;&#37319;&#26679;&#26799;&#24230;&#35774;&#32622;&#19979;&#21521;&#20840;&#23616;&#26368;&#20248;&#20540;&#36827;&#34892;&#20102;&#25910;&#25947;&#20998;&#26512;&#65292;&#19988;&#27809;&#26377;&#24341;&#20837;&#27491;&#21017;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#30456;&#20851;&#24615;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov Decision Processes (MDPs) are a formal framework for modeling and solving sequential decision-making problems. In finite-time horizons such problems are relevant for instance for optimal stopping or specific supply chain problems, but also in the training of large language models. In contrast to infinite horizon MDPs optimal policies are not stationary, policies must be learned for every single epoch. In practice all parameters are often trained simultaneously, ignoring the inherent structure suggested by dynamic programming. This paper introduces a combination of dynamic programming and policy gradient called dynamic policy gradient, where the parameters are trained backwards in time. For the tabular softmax parametrisation we carry out the convergence analysis for simultaneous and dynamic policy gradient towards global optima, both in the exact and sampled gradient settings without regularisation. It turns out that the use of dynamic policy gradient training much better exploi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2310.00809</link><description>&lt;p&gt;
&#25351;&#21521;&#22240;&#26524;&#22522;&#30784;&#27169;&#22411;: &#22240;&#26524;&#25512;&#26029;&#19982;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Towards Causal Foundation Model: on Duality between Causal Inference and Attention. (arXiv:2310.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00809
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#20043;&#38388;&#30340;&#23545;&#20598;&#36830;&#25509;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#29702;&#35770;&#19978;&#23436;&#22791;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#20010;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#30417;&#30563;&#22240;&#26524;&#23398;&#20064;&#65292;&#24182;&#22312;&#26032;&#25968;&#25454;&#30340;&#26410;&#35265;&#20219;&#21153;&#19978;&#23454;&#29616;&#38646;&#26679;&#26412;&#22240;&#26524;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation models have brought changes to the landscape of machine learning, demonstrating sparks of human-level intelligence across a diverse array of tasks. However, a gap persists in complex tasks such as causal inference, primarily due to challenges associated with intricate reasoning steps and high numerical precision requirements. In this work, we take a first step towards building causally-aware foundation models for complex tasks. We propose a novel, theoretically sound method called Causal Inference with Attention (CInA), which utilizes multiple unlabeled datasets to perform self-supervised causal learning, and subsequently enables zero-shot causal inference on unseen tasks with new data. This is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention, facilitating zero-shot causal inference through the final layer of a trained transformer-type architecture. We demonstrate empirically that our approach
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#21644;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#32416;&#27491;&#22240;&#27835;&#30103;&#21464;&#37327;&#19981;&#20934;&#30830;&#27979;&#37327;&#24341;&#36215;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20559;&#24046;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#21644;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.10614</link><description>&lt;p&gt;
&#24102;&#26377;&#22024;&#26434;&#27835;&#30103;&#21644;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#30340;&#21487;&#35782;&#21035;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Identifiable causal inference with noisy treatment and no side information. (arXiv:2306.10614v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#21644;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#32416;&#27491;&#22240;&#27835;&#30103;&#21464;&#37327;&#19981;&#20934;&#30830;&#27979;&#37327;&#24341;&#36215;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20559;&#24046;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#21644;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26576;&#20123;&#22240;&#26524;&#25512;&#26029;&#22330;&#26223;&#20013;&#65292;&#27835;&#30103;&#65288;&#21363;&#21407;&#22240;&#65289;&#21464;&#37327;&#30340;&#27979;&#37327;&#23384;&#22312;&#19981;&#20934;&#30830;&#24615;&#65292;&#20363;&#22914;&#22312;&#27969;&#34892;&#30149;&#23398;&#25110;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#12290;&#26410;&#33021;&#32416;&#27491;&#27979;&#37327;&#35823;&#24046;&#30340;&#24433;&#21709;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#27809;&#26377;&#20174;&#22240;&#26524;&#35270;&#35282;&#30740;&#31350;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20801;&#35768;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#24182;&#19988;&#19981;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#20391;&#38754;&#20449;&#24687;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#22330;&#26223;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#23427;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#36830;&#32493;&#30340;&#27835;&#30103;&#21464;&#37327;&#65292;&#35813;&#21464;&#37327;&#27979;&#37327;&#19981;&#20934;&#30830;&#12290;&#24314;&#31435;&#22312;&#29616;&#26377;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#21363;&#20351;&#27809;&#26377;&#27979;&#37327;&#35823;&#24046;&#26041;&#24046;&#25110;&#20854;&#20182;&#20391;&#38754;&#20449;&#24687;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#65292;&#20854;&#20013;&#39640;&#26031;&#26465;&#20214;&#30001;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#26469;&#35757;&#32451;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In some causal inference scenarios, the treatment (i.e. cause) variable is measured inaccurately, for instance in epidemiology or econometrics. Failure to correct for the effect of this measurement error can lead to biased causal effect estimates. Previous research has not studied methods that address this issue from a causal viewpoint while allowing for complex nonlinear dependencies and without assuming access to side information. For such as scenario, this paper proposes a model that assumes a continuous treatment variable which is inaccurately measured. Building on existing results for measurement error models, we prove that our model's causal effect estimates are identifiable, even without knowledge of the measurement error variance or other side information. Our method relies on a deep latent variable model where Gaussian conditionals are parameterized by neural networks, and we develop an amortized importance-weighted variational objective for training the model. Empirical resul
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;VAE&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#24471;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;</title><link>http://arxiv.org/abs/2306.02568</link><description>&lt;p&gt;
Gumbel&#20256;&#25773;&#19979;&#30340;&#28508;&#22312;&#26368;&#20248;&#36335;&#24452;&#21464;&#20998;&#36125;&#21494;&#26031;&#21160;&#24577;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Latent Optimal Paths by Gumbel Propagation for Variational Bayesian Dynamic Programming. (arXiv:2306.02568v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02568
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;VAE&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#24471;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#20197;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#26041;&#27861;&#65292;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#21644;Gumbel&#20256;&#25773;&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#33719;&#21462;&#32467;&#26500;&#21270;&#31232;&#30095;&#26368;&#20248;&#36335;&#24452;&#12290;&#25105;&#20204;&#36890;&#36807;&#27010;&#29575;&#36719;&#21270;&#35299;&#65292;&#21363;&#38543;&#26426;&#26368;&#20248;&#36335;&#24452;&#65292;&#26469;&#35299;&#20915;&#32463;&#20856;&#26368;&#20248;&#36335;&#24452;&#38382;&#39064;&#65292;&#24182;&#23558;&#24191;&#27867;&#30340;DP&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#21521;&#26080;&#29615;&#22270;&#65292;&#20854;&#20013;&#25152;&#26377;&#21487;&#33021;&#30340;&#36335;&#24452;&#36981;&#24490;Gibbs&#20998;&#24067;&#12290;&#25105;&#20204;&#36890;&#36807;Gumbel&#20998;&#24067;&#30340;&#23646;&#24615;&#26174;&#31034;Gibbs&#20998;&#24067;&#19982;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#30340;&#31561;&#20215;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#25152;&#38656;&#30340;&#25152;&#26377;&#35201;&#32032;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33719;&#21462;&#20102;&#28508;&#22312;&#26368;&#20248;&#36335;&#24452;&#65292;&#20351;&#29983;&#25104;&#20219;&#21153;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#20013;&#27169;&#22411;&#20381;&#36182;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#32467;&#26500;&#29305;&#24449;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20004;&#20010;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#30340;&#36866;&#29992;&#24615;&#65306;&#25991;&#26412;&#36716;&#35821;&#38899;&#21644;&#27468;&#22768;&#21512;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a unified approach to obtain structured sparse optimal paths in the latent space of a variational autoencoder (VAE) using dynamic programming and Gumbel propagation. We solve the classical optimal path problem by a probability softening solution, called the stochastic optimal path, and transform a wide range of DP problems into directed acyclic graphs in which all possible paths follow a Gibbs distribution. We show the equivalence of the Gibbs distribution to a message-passing algorithm by the properties of the Gumbel distribution and give all the ingredients required for variational Bayesian inference. Our approach obtaining latent optimal paths enables end-to-end training for generative tasks in which models rely on the information of unobserved structural features. We validate the behavior of our approach and showcase its applicability in two real-world applications: text-to-speech and singing voice synthesis.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23454;&#20540;&#20989;&#25968;&#20013;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#24615;&#65292;&#21457;&#29616;&#26377;&#38480;&#32982;&#25240;&#23556;&#32500;&#30340;&#31867;&#26082;&#21487;&#20197;&#22312;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#34987;&#23398;&#20064;&#65292;&#20984;&#20989;&#25968;&#31867;&#21487;&#20197;&#27491;&#30830;&#23398;&#20064;&#65292;&#32780;&#19968;&#20123;&#38750;&#20984;&#20989;&#25968;&#31867;&#38656;&#35201;&#19981;&#27491;&#24403;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.12977</link><description>&lt;p&gt;
&#22312;&#23454;&#20540;&#20989;&#25968;&#20013;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adversarially Robust PAC Learnability of Real-Valued Functions. (arXiv:2206.12977v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12977
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23454;&#20540;&#20989;&#25968;&#20013;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#24615;&#65292;&#21457;&#29616;&#26377;&#38480;&#32982;&#25240;&#23556;&#32500;&#30340;&#31867;&#26082;&#21487;&#20197;&#22312;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#34987;&#23398;&#20064;&#65292;&#20984;&#20989;&#25968;&#31867;&#21487;&#20197;&#27491;&#30830;&#23398;&#20064;&#65292;&#32780;&#19968;&#20123;&#38750;&#20984;&#20989;&#25968;&#31867;&#38656;&#35201;&#19981;&#27491;&#24403;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;$\ell_p$&#25439;&#22833;&#21644;&#20219;&#24847;&#25200;&#21160;&#38598;&#30340;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#23545;&#27979;&#35797;&#26102;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#21738;&#20123;&#20989;&#25968;&#31867;&#26159;PAC&#21487;&#23398;&#20064;&#30340;&#12290;&#25105;&#20204;&#34920;&#26126;&#26377;&#38480;&#32982;&#25240;&#23556;&#32500;&#30340;&#31867;&#26082;&#21487;&#20197;&#22312;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#34987;&#23398;&#20064;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#20984;&#20989;&#25968;&#31867;&#65292;&#23427;&#20204;&#29978;&#33267;&#21487;&#20197;&#27491;&#30830;&#23398;&#20064;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#19968;&#20123;&#38750;&#20984;&#20989;&#25968;&#31867;&#26174;&#28982;&#38656;&#35201;&#19981;&#27491;&#24403;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#22522;&#20110;&#26500;&#24314;&#19968;&#20010;&#30001;&#32982;&#25240;&#23556;&#32500;&#20915;&#23450;&#22823;&#23567;&#30340;&#20855;&#26377;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#38754;&#21521;&#23454;&#20540;&#20989;&#25968;&#30340;&#19981;&#21487;&#30693;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study robustness to test-time adversarial attacks in the regression setting with $\ell_p$ losses and arbitrary perturbation sets. We address the question of which function classes are PAC learnable in this setting. We show that classes of finite fat-shattering dimension are learnable in both realizable and agnostic settings. Moreover, for convex function classes, they are even properly learnable. In contrast, some non-convex function classes provably require improper learning algorithms. Our main technique is based on a construction of an adversarially robust sample compression scheme of a size determined by the fat-shattering dimension. Along the way, we introduce a novel agnostic sample compression scheme for real-valued functions, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#27979;&#26469;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2206.09821</link><description>&lt;p&gt;
&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#29992;&#20110;&#26174;&#33879;&#27874;&#39640;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Exceedance Probability Forecasting via Regression for Significant Wave Height Prediction. (arXiv:2206.09821v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#27979;&#26469;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26174;&#33879;&#27874;&#39640;&#39044;&#27979;&#26159;&#28023;&#27915;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#23545;&#20110;&#20272;&#35745;&#27874;&#33021;&#20135;&#29983;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#27492;&#22806;&#65292;&#21450;&#26102;&#39044;&#27979;&#22823;&#28010;&#30340;&#21040;&#26469;&#23545;&#20110;&#30830;&#20445;&#33322;&#28023;&#20316;&#19994;&#30340;&#23433;&#20840;&#24456;&#37325;&#35201;&#12290;&#25105;&#20204;&#23558;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#30340;&#26497;&#31471;&#20540;&#20316;&#20026;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#20272;&#35745;&#26174;&#33879;&#27874;&#39640;&#23558;&#36229;&#36807;&#39044;&#23450;&#20041;&#38408;&#20540;&#30340;&#27010;&#29575;&#12290;&#36890;&#24120;&#20351;&#29992;&#27010;&#29575;&#20108;&#20998;&#31867;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#26410;&#26469;&#35266;&#27979;&#30340;&#39044;&#27979;&#26469;&#26681;&#25454;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#12290;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#21152;&#25343;&#22823;&#21704;&#21033;&#27861;&#20811;&#26031;&#28023;&#23736;&#30340;&#28014;&#26631;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Significant wave height forecasting is a key problem in ocean data analytics. Predicting the significant wave height is crucial for estimating the energy production from waves. Moreover, the timely prediction of large waves is important to ensure the safety of maritime operations, e.g. passage of vessels. We frame the task of predicting extreme values of significant wave height as an exceedance probability forecasting problem. Accordingly, we aim at estimating the probability that the significant wave height will exceed a predefined threshold. This task is usually solved using a probabilistic binary classification model. Instead, we propose a novel approach based on a forecasting model. The method leverages the forecasts for the upcoming observations to estimate the exceedance probability according to the cumulative distribution function. We carried out experiments using data from a buoy placed in the coast of Halifax, Canada. The results suggest that the proposed methodology is better
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#19979;&#30340;&#26377;&#31181;&#23376;&#22270;&#21305;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#34920;&#26126;&#65292;&#20351;&#29992;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#65288;PPM&#65289;&#20316;&#20026;&#22270;&#21305;&#37197;&#31639;&#27861;&#21487;&#20197;&#22312;&#32473;&#23450;&#25509;&#36817;&#30495;&#23454;&#21305;&#37197;&#30340;&#31181;&#23376;&#30340;&#24773;&#20917;&#19979;&#39640;&#27010;&#29575;&#22320;&#25913;&#36827;&#31181;&#23376;&#24182;&#24674;&#22797;&#30495;&#23454;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2204.04099</link><description>&lt;p&gt;
&#36890;&#36807;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#36827;&#34892;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#30340;&#26377;&#31181;&#23376;&#22270;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Seeded graph matching for the correlated Wigner model via the projected power method. (arXiv:2204.04099v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.04099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#19979;&#30340;&#26377;&#31181;&#23376;&#22270;&#21305;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#34920;&#26126;&#65292;&#20351;&#29992;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#65288;PPM&#65289;&#20316;&#20026;&#22270;&#21305;&#37197;&#31639;&#27861;&#21487;&#20197;&#22312;&#32473;&#23450;&#25509;&#36817;&#30495;&#23454;&#21305;&#37197;&#30340;&#31181;&#23376;&#30340;&#24773;&#20917;&#19979;&#39640;&#27010;&#29575;&#22320;&#25913;&#36827;&#31181;&#23376;&#24182;&#24674;&#22797;&#30495;&#23454;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22270;&#21305;&#37197;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#20004;&#20010;&#22270;G&#21644;H&#65292;&#24182;&#36890;&#36807;&#26368;&#22823;&#21270;&#36793;&#21327;&#35758;&#30340;&#19968;&#20123;&#24230;&#37327;&#26469;&#25214;&#21040;&#23427;&#20204;&#39030;&#28857;&#20043;&#38388;&#30340;&#36171;&#20540;&#65288;&#25110;&#21305;&#37197;&#65289;&#12290;&#25105;&#20204;&#20551;&#35774;&#35266;&#23519;&#21040;&#30340;&#22270;&#23545;G&#21644;H&#26159;&#20174;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#20013;&#25277;&#21462;&#30340;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#30456;&#20851;&#21152;&#26435;&#22270;&#30340;&#27969;&#34892;&#27169;&#22411;&#65292;&#20854;&#20013;G&#21644;H&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#20803;&#32032;&#26159;&#29420;&#31435;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;G&#30340;&#27599;&#26465;&#36793;&#19982;H&#30340;&#20854;&#20013;&#19968;&#26465;&#36793;&#65288;&#30001;&#26410;&#30693;&#30340;&#21305;&#37197;&#30830;&#23450;&#65289;&#30456;&#20851;&#32852;&#65292;&#36793;&#30456;&#20851;&#24615;&#30001;&#21442;&#25968;&#963;&#8712;[0,1)&#25551;&#36848;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20316;&#20026;&#8220;&#26377;&#31181;&#23376;&#8221;&#30340;&#22270;&#21305;&#37197;&#31639;&#27861;&#30340;&#8220;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#8221;&#65288;PPM&#65289;&#30340;&#24615;&#33021;&#65292;&#20854;&#20013;&#25105;&#20204;&#25552;&#20379;&#19968;&#20010;&#37096;&#20998;&#27491;&#30830;&#30340;&#21021;&#22987;&#21305;&#37197;&#65288;&#31216;&#20026;&#31181;&#23376;&#65289;&#20316;&#20026;&#38468;&#21152;&#20449;&#24687;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#31181;&#23376;&#36275;&#22815;&#25509;&#36817;&#30495;&#23454;&#21305;&#37197;&#65292;&#21017;PPM&#22312;&#39640;&#27010;&#29575;&#19979;&#20250;&#36845;&#20195;&#25913;&#36827;&#31181;&#23376;&#24182;&#24674;&#22797;&#30495;&#23454;&#21305;&#37197;&#65288;&#25110;&#24674;&#22797;&#26368;&#22823;&#21270;&#36793;&#21327;&#35758;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the \emph{graph matching} problem we observe two graphs $G,H$ and the goal is to find an assignment (or matching) between their vertices such that some measure of edge agreement is maximized. We assume in this work that the observed pair $G,H$ has been drawn from the correlated Wigner model -- a popular model for correlated weighted graphs -- where the entries of the adjacency matrices of $G$ and $H$ are independent Gaussians and each edge of $G$ is correlated with one edge of $H$ (determined by the unknown matching) with the edge correlation described by a parameter $\sigma\in [0,1)$. In this paper, we analyse the performance of the \emph{projected power method} (PPM) as a \emph{seeded} graph matching algorithm where we are given an initial partially correct matching (called the seed) as side information. We prove that if the seed is close enough to the ground-truth matching, then with high probability, PPM iteratively improves the seed and recovers the ground-truth matching (eithe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#23545;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#27169;&#22411;&#19979;&#37051;&#25509;&#30697;&#38453;&#30340;&#21463;&#38480;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.07831</link><description>&lt;p&gt;
&#22270;&#24418;&#31070;&#32463;&#32593;&#32476;&#22312;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network Sensitivity Under Probabilistic Error Model. (arXiv:2203.07831v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#23545;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#27169;&#22411;&#19979;&#37051;&#25509;&#30697;&#38453;&#30340;&#21463;&#38480;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21487;&#20197;&#36890;&#36807;&#22270;&#21367;&#31215;&#25104;&#21151;&#23398;&#20064;&#22270;&#20449;&#21495;&#34920;&#31034;&#12290;&#22270;&#21367;&#31215;&#20381;&#36182;&#20110;&#22270;&#28388;&#27874;&#22120;&#65292;&#20854;&#20013;&#21253;&#21547;&#25968;&#25454;&#30340;&#25299;&#25169;&#20381;&#36182;&#20851;&#31995;&#24182;&#20256;&#25773;&#25968;&#25454;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#22312;&#20256;&#25773;&#30697;&#38453;&#65288;&#20363;&#22914;&#37051;&#25509;&#30697;&#38453;&#65289;&#20013;&#30340;&#20272;&#35745;&#35823;&#24046;&#21487;&#33021;&#23545;&#22270;&#28388;&#27874;&#22120;&#21644;GCNs&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#26412;&#25991;&#30740;&#31350;&#27010;&#29575;&#22270;&#35823;&#24046;&#27169;&#22411;&#23545;GCN&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#37051;&#25509;&#30697;&#38453;&#21463;&#21040;&#22270;&#22823;&#23567;&#21644;&#35823;&#24046;&#27010;&#29575;&#20989;&#25968;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#24102;&#26377;&#33258;&#24490;&#29615;&#30340;&#24402;&#19968;&#21270;&#37051;&#25509;&#30697;&#38453;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#23454;&#39564;&#26469;&#35828;&#26126;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#31616;&#21333;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;</title><link>http://arxiv.org/abs/2111.11694</link><description>&lt;p&gt;
MARS via LASSO.&#65288;arXiv:2111.11694v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
MARS via LASSO. (arXiv:2111.11694v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.11694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#30340;MARS&#26041;&#27861;&#65292;&#36890;&#36807;&#20943;&#23569;&#23545;&#32500;&#24230;&#30340;&#20381;&#36182;&#26469;&#33719;&#24471;&#25910;&#25947;&#29575;&#65292;&#24182;&#19982;&#20351;&#29992;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#32852;&#31995;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;Multivariate Adaptive Regression Splines&#65292;MARS&#65289;&#26159;Friedman&#22312;1991&#24180;&#25552;&#20986;&#30340;&#19968;&#31181;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;MARS&#23558;&#31616;&#21333;&#30340;&#38750;&#32447;&#24615;&#21644;&#38750;&#21152;&#24615;&#20989;&#25968;&#25311;&#21512;&#21040;&#22238;&#24402;&#25968;&#25454;&#19978;&#12290;&#26412;&#25991;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;MARS&#26041;&#27861;&#30340;&#19968;&#31181;&#33258;&#28982;lasso&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#36890;&#36807;&#32771;&#34385;MARS&#22522;&#30784;&#20989;&#25968;&#30340;&#26080;&#38480;&#32500;&#32447;&#24615;&#32452;&#21512;&#24182;&#24378;&#21152;&#22522;&#20110;&#21464;&#20998;&#30340;&#22797;&#26434;&#24230;&#32422;&#26463;&#26465;&#20214;&#26469;&#33719;&#24471;&#20989;&#25968;&#30340;&#20984;&#31867;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20272;&#35745;&#26159;&#23450;&#20041;&#20026;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#65292;&#20294;&#20854;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#32500;&#20984;&#20248;&#21270;&#26469;&#35745;&#31639;&#12290;&#22312;&#19968;&#20123;&#26631;&#20934;&#35774;&#35745;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20165;&#22312;&#32500;&#24230;&#19978;&#23545;&#25968;&#25910;&#25947;&#65292;&#22240;&#27492;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36991;&#20813;&#20102;&#36890;&#24120;&#30340;&#32500;&#24230;&#28798;&#38590;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#22320;&#19982;&#22522;&#20110;&#24179;&#28369;&#24615;&#32422;&#26463;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#25216;&#26415;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate adaptive regression splines (MARS) is a popular method for nonparametric regression introduced by Friedman in 1991. MARS fits simple nonlinear and non-additive functions to regression data. We propose and study a natural lasso variant of the MARS method. Our method is based on least squares estimation over a convex class of functions obtained by considering infinite-dimensional linear combinations of functions in the MARS basis and imposing a variation based complexity constraint. Our estimator can be computed via finite-dimensional convex optimization, although it is defined as a solution to an infinite-dimensional optimization problem. Under a few standard design assumptions, we prove that our estimator achieves a rate of convergence that depends only logarithmically on dimension and thus avoids the usual curse of dimensionality to some extent. We also show that our method is naturally connected to nonparametric estimation techniques based on smoothness constraints. We i
&lt;/p&gt;</description></item></channel></rss>