<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#21387;&#32553;&#26679;&#26412;&#21644;&#21015;&#34920;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#25105;&#20204;&#23545;&#39640;&#26031;&#20998;&#24067;&#20197;&#21450;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#36827;&#34892;&#20102;&#23398;&#20064;&#19978;&#38480;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#19981;&#21487;&#30693;&#23398;&#20064;&#21644;&#20998;&#24067;&#21464;&#21270;&#25269;&#25239;&#23398;&#20064;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.06239</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#65306;&#22522;&#20110;&#26679;&#26412;&#21387;&#32553;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Private Distribution Learning with Public Data: The View from Sample Compression. (arXiv:2308.06239v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#21387;&#32553;&#26679;&#26412;&#21644;&#21015;&#34920;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#25105;&#20204;&#23545;&#39640;&#26031;&#20998;&#24067;&#20197;&#21450;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#36827;&#34892;&#20102;&#23398;&#20064;&#19978;&#38480;&#30340;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#19981;&#21487;&#30693;&#23398;&#20064;&#21644;&#20998;&#24067;&#21464;&#21270;&#25269;&#25239;&#23398;&#20064;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21487;&#20197;&#35775;&#38382;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#30340;&#31169;&#26377;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20844;&#31169;&#23398;&#20064;&#65292;&#23398;&#20064;&#22120;&#34987;&#32473;&#20104;&#26469;&#33258;&#26410;&#30693;&#20998;&#24067;p&#30340;&#23646;&#20110;&#31867;$\mathcal Q$&#30340;&#20844;&#20849;&#26679;&#26412;&#21644;&#31169;&#26377;&#26679;&#26412;&#65292;&#30446;&#26631;&#26159;&#36755;&#20986;&#19968;&#20010;&#23545;p&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#36981;&#23432;&#19982;&#31169;&#26377;&#26679;&#26412;&#30456;&#20851;&#30340;&#38544;&#31169;&#32422;&#26463;&#65288;&#36825;&#37324;&#26159;&#32431;&#24046;&#20998;&#38544;&#31169;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31867;$\mathcal Q$&#30340;&#20844;&#31169;&#21487;&#23398;&#20064;&#24615;&#19982;$\mathcal Q$&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#20197;&#21450;&#20013;&#38388;&#27010;&#24565;&#8212;&#8212;&#21015;&#34920;&#23398;&#20064;&#30340;&#23384;&#22312;&#24615;&#26377;&#20851;&#12290;&#21033;&#29992;&#36825;&#20010;&#32852;&#31995;&#65306;&#65288;1&#65289;&#36817;&#20284;&#24674;&#22797;&#20102;&#20851;&#20110;$\mathbb R^d$&#19978;&#39640;&#26031;&#20998;&#24067;&#30340;&#20808;&#21069;&#32467;&#26524;&#65307;&#65288;2&#65289;&#24471;&#20986;&#20102;&#26032;&#30340;&#32467;&#26524;&#65292;&#21253;&#25324;&#23545;&#20219;&#24847;$k$-&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#22312;$\mathbb R^d$&#19978;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#30028;&#65292;&#20197;&#21450;&#23545;&#19981;&#21487;&#30693;&#21644;&#20998;&#24067;&#21464;&#21270;&#25269;&#25239;&#23398;&#20064;&#22120;&#30340;&#32467;&#26524;&#65292;&#20197;&#21450;&#20844;&#31169;&#21487;&#23398;&#20064;&#24615;&#30340;&#38381;&#21253;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of private distribution learning with access to public data. In this setup, which we refer to as public-private learning, the learner is given public and private samples drawn from an unknown distribution $p$ belonging to a class $\mathcal Q$, with the goal of outputting an estimate of $p$ while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.  We show that the public-private learnability of a class $\mathcal Q$ is connected to the existence of a sample compression scheme for $\mathcal Q$, as well as to an intermediate notion we refer to as list learning. Leveraging this connection: (1) approximately recovers previous results on Gaussians over $\mathbb R^d$; and (2) leads to new ones, including sample complexity upper bounds for arbitrary $k$-mixtures of Gaussians over $\mathbb R^d$, results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#20013;&#20351;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#32622;&#25442;&#26469;&#24230;&#37327;&#21151;&#33021;&#36830;&#25509;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#27599;&#20010;&#32622;&#25442;&#30340;&#26041;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;&#22312;&#19982;&#20854;&#20182;&#25216;&#26415;&#30340;&#27604;&#36739;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.06220</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#32622;&#25442;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Permuted Granger Causality. (arXiv:2308.06220v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06220
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#20013;&#20351;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#32622;&#25442;&#26469;&#24230;&#37327;&#21151;&#33021;&#36830;&#25509;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#27599;&#20010;&#32622;&#25442;&#30340;&#26041;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;&#22312;&#19982;&#20854;&#20182;&#25216;&#26415;&#30340;&#27604;&#36739;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26684;&#20848;&#26480;&#22240;&#26524;&#25512;&#26029;&#26159;&#20174;&#32463;&#27982;&#23398;&#21040;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#24191;&#27867;&#20351;&#29992;&#30340;&#19968;&#31181;&#26377;&#20105;&#35758;&#30340;&#26041;&#27861;&#12290;&#21407;&#22987;&#23450;&#20041;&#22522;&#20110;&#25351;&#23450;&#27169;&#22411;&#26465;&#20214;&#19979;&#24314;&#31435;&#22240;&#26524;&#20851;&#31995;&#30340;&#26102;&#38388;&#24207;&#21015;&#27010;&#24565;&#12290;&#23558;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#24212;&#29992;&#20110;&#38750;&#32447;&#24615;&#25968;&#25454;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#35768;&#22810;&#26041;&#27861;&#20351;&#29992;&#26679;&#26412;&#20869;&#27979;&#35797;&#65292;&#19981;&#33021;&#32435;&#20837;&#26679;&#26412;&#22806;&#30340;&#21487;&#39044;&#27979;&#24615;&#65292;&#23548;&#33268;&#27169;&#22411;&#36807;&#25311;&#21512;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#36827;&#34892;&#26679;&#26412;&#22806;&#27604;&#36739;&#65292;&#25105;&#20204;&#26126;&#30830;&#22320;&#23450;&#20041;&#20102;&#20351;&#29992;&#21327;&#21464;&#37327;&#38598;&#30340;&#32622;&#25442;&#26469;&#34920;&#31034;&#21151;&#33021;&#36830;&#25509;&#24615;&#30340;&#24230;&#37327;&#12290;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25968;&#25454;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#29992;&#20110;&#36817;&#20284;&#20219;&#20309;&#20219;&#24847;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#22312;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#21644;&#27169;&#22411;&#27531;&#24046;&#30340;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#35777;&#26126;&#23545;&#27599;&#20010;&#32622;&#25442;&#30340;&#26041;&#24046;&#36827;&#34892;&#20102;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#27169;&#25311;&#27604;&#36739;&#20102;&#32622;&#25442;&#26041;&#27861;&#19982;&#24809;&#32602;&#30446;&#26631;&#12289;&#22825;&#30495;&#26367;&#20195;&#21644;&#36951;&#28431;&#25216;&#26415;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Granger causal inference is a contentious but widespread method used in fields ranging from economics to neuroscience. The original definition addresses the notion of causality in time series by establishing functional dependence conditional on a specified model. Adaptation of Granger causality to nonlinear data remains challenging, and many methods apply in-sample tests that do not incorporate out-of-sample predictability leading to concerns of model overfitting. To allow for out-of-sample comparison, we explicitly define a measure of functional connectivity using permutations of the covariate set. Artificial neural networks serve as featurizers of the data to approximate any arbitrary, nonlinear relationship, and under certain conditions on the featurization process and the model residuals, we prove consistent estimation of the variance for each permutation. Performance of the permutation method is compared to penalized objective, naive replacement, and omission techniques via simula
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27010;&#24565;&#22120;&#30697;&#38453;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#29305;&#24449;&#21160;&#24577;&#65292;&#24182;&#21033;&#29992;&#21333;&#21464;&#37327;&#37327;&#21270;&#26469;&#35782;&#21035;&#21464;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;&#26465;&#20214;&#21644;&#26080;&#26465;&#20214;&#30340;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#21487;&#20197;&#25552;&#20379;&#28508;&#22312;&#30340;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24863;&#20852;&#36259;&#20301;&#32622;&#12290;</title><link>http://arxiv.org/abs/2308.06213</link><description>&lt;p&gt;
&#20351;&#29992;&#27010;&#24565;&#22120;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Change Point Detection With Conceptors. (arXiv:2308.06213v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06213
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27010;&#24565;&#22120;&#30697;&#38453;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#29305;&#24449;&#21160;&#24577;&#65292;&#24182;&#21033;&#29992;&#21333;&#21464;&#37327;&#37327;&#21270;&#26469;&#35782;&#21035;&#21464;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;&#26465;&#20214;&#21644;&#26080;&#26465;&#20214;&#30340;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#21487;&#20197;&#25552;&#20379;&#28508;&#22312;&#30340;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24863;&#20852;&#36259;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#21464;&#28857;&#26816;&#27979;&#26088;&#22312;&#35782;&#21035;&#26102;&#38388;&#24207;&#21015;&#20013;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#21457;&#29983;&#21464;&#21270;&#30340;&#28857;&#12290;&#23545;&#20110;&#21333;&#21464;&#37327;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#36825;&#20010;&#38382;&#39064;&#24050;&#32463;&#24471;&#21040;&#20102;&#36739;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;&#38543;&#30528;&#32500;&#24230;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#22686;&#21152;&#65292;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#38024;&#23545;&#33267;&#22810;&#19968;&#20010;&#21464;&#28857;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#27010;&#24565;&#22120;&#30697;&#38453;&#26469;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#25351;&#23450;&#35757;&#32451;&#31383;&#21475;&#30340;&#29305;&#24449;&#21160;&#24577;&#12290;&#30456;&#20851;&#30340;&#38543;&#26426;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25968;&#25454;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#24182;&#19988;&#36890;&#36807;&#35745;&#31639;&#29305;&#24449;&#21270;&#19982;&#20195;&#34920;&#24615;&#27010;&#24565;&#22120;&#30697;&#38453;&#25152;&#24352;&#25104;&#31354;&#38388;&#20043;&#38388;&#30340;&#36317;&#31163;&#30340;&#21333;&#21464;&#37327;&#37327;&#21270;&#26469;&#35782;&#21035;&#21464;&#28857;&#12290;&#36825;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#21487;&#20197;&#25552;&#31034;&#21487;&#33021;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24863;&#20852;&#36259;&#30340;&#20301;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#30495;&#23454;&#21464;&#28857;&#30340;&#19968;&#33268;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#23545;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#31227;&#21160;&#22359;&#33258;&#21161;&#27861;&#20135;&#29983;&#32479;&#35745;&#37327;&#30340;&#20998;&#20301;&#25968;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#26465;&#20214;&#21644;&#26080;&#26465;&#20214;&#30340;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on si
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22240;&#26524;&#24615;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#26426;&#22120;&#20154;&#22534;&#31215;&#26041;&#22359;&#20219;&#21153;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#32467;&#21512;&#22240;&#26524;&#25512;&#26029;&#65292;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#29702;&#35299;&#12289;&#25512;&#29702;&#21644;&#35299;&#37322;&#20854;&#29615;&#22659;&#12290;</title><link>http://arxiv.org/abs/2308.06203</link><description>&lt;p&gt;
&#20026;&#26426;&#22120;&#20154;&#22534;&#31215;&#26041;&#22359;&#20219;&#21153;&#26500;&#24314;&#22240;&#26524;&#24615;&#27010;&#29575;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Towards a Causal Probabilistic Framework for Prediction, Action-Selection &amp; Explanations for Robot Block-Stacking Tasks. (arXiv:2308.06203v1 [cs.RO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06203
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22240;&#26524;&#24615;&#27010;&#29575;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#26426;&#22120;&#20154;&#22534;&#31215;&#26041;&#22359;&#20219;&#21153;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#32467;&#21512;&#22240;&#26524;&#25512;&#26029;&#65292;&#20351;&#26426;&#22120;&#20154;&#33021;&#22815;&#29702;&#35299;&#12289;&#25512;&#29702;&#21644;&#35299;&#37322;&#20854;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#24847;&#21619;&#30528;&#31995;&#32479;&#35774;&#35745;&#32773;&#26080;&#27861;&#39044;&#27979;&#24182;&#26126;&#30830;&#35774;&#35745;&#20986;&#26426;&#22120;&#20154;&#21487;&#33021;&#36935;&#21040;&#30340;&#25152;&#26377;&#22330;&#26223;&#12290;&#22240;&#27492;&#65292;&#20197;&#36825;&#31181;&#26041;&#24335;&#35774;&#35745;&#30340;&#26426;&#22120;&#20154;&#22312;&#39640;&#24230;&#21463;&#25511;&#30340;&#29615;&#22659;&#20043;&#22806;&#23481;&#26131;&#20986;&#29616;&#25925;&#38556;&#12290;&#22240;&#26524;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#21407;&#21017;&#24615;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#32534;&#30721;&#26426;&#22120;&#20154;&#19982;&#20854;&#29615;&#22659;&#30456;&#20114;&#20316;&#29992;&#30340;&#22240;&#26524;&#20851;&#31995;&#30340;&#24418;&#24335;&#21270;&#30693;&#35782;&#65292;&#24182;&#32467;&#21512;&#29616;&#23454;&#19990;&#30028;&#26426;&#22120;&#20154;&#36890;&#24120;&#36935;&#21040;&#30340;&#22122;&#22768;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#27010;&#29575;&#34920;&#31034;&#12290;&#32467;&#21512;&#22240;&#26524;&#25512;&#26029;&#65292;&#36825;&#20123;&#27169;&#22411;&#20351;&#33258;&#20027;&#20195;&#29702;&#33021;&#22815;&#29702;&#35299;&#12289;&#25512;&#29702;&#21644;&#35299;&#37322;&#20854;&#29615;&#22659;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#26426;&#22120;&#20154;&#22534;&#31215;&#26041;&#22359;&#20219;&#21153;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#23637;&#31034;&#20102;&#35768;&#22810;&#24212;&#29992;&#25152;&#38656;&#30340;&#22522;&#26412;&#24863;&#30693;&#21644;&#25805;&#20316;&#33021;&#21147;&#65292;&#21253;&#25324;&#20179;&#24211;&#29289;&#27969;&#21644;&#23478;&#24237;&#20154;&#24037;&#25903;&#25345;&#26426;&#22120;&#20154;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#22240;&#26524;&#24615;&#27010;&#29575;&#26694;&#26550;&#65292;&#23558;&#29289;&#29702;&#27169;&#25311;&#21151;&#33021;&#23884;&#20837;&#21040;&#36825;&#20010;&#20219;&#21153;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainties in the real world mean that is impossible for system designers to anticipate and explicitly design for all scenarios that a robot might encounter. Thus, robots designed like this are fragile and fail outside of highly-controlled environments. Causal models provide a principled framework to encode formal knowledge of the causal relationships that govern the robot's interaction with its environment, in addition to probabilistic representations of noise and uncertainty typically encountered by real-world robots. Combined with causal inference, these models permit an autonomous agent to understand, reason about, and explain its environment. In this work, we focus on the problem of a robot block-stacking task due to the fundamental perception and manipulation capabilities it demonstrates, required by many applications including warehouse logistics and domestic human support robotics. We propose a novel causal probabilistic framework to embed a physics simulation capability int
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#29992;&#20110;&#36817;&#20284;&#26368;&#22823;&#29109;&#20998;&#24067;&#20013;&#30340;&#25289;&#26684;&#26391;&#26085;&#20056;&#23376;&#65292;&#36890;&#36807;&#20248;&#21270;&#36229;&#21442;&#25968;&#26469;&#23454;&#29616;&#25968;&#25454;&#39537;&#21160;&#30340;&#26368;&#22823;&#29109;&#38381;&#21512;&#12290;&#36890;&#36807;&#23545;&#27604;&#22810;&#20010;&#27979;&#35797;&#26696;&#20363;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.06149</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#29992;&#20110;&#26368;&#22823;&#29109;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Regression for Maximum Entropy Distribution. (arXiv:2308.06149v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#29992;&#20110;&#36817;&#20284;&#26368;&#22823;&#29109;&#20998;&#24067;&#20013;&#30340;&#25289;&#26684;&#26391;&#26085;&#20056;&#23376;&#65292;&#36890;&#36807;&#20248;&#21270;&#36229;&#21442;&#25968;&#26469;&#23454;&#29616;&#25968;&#25454;&#39537;&#21160;&#30340;&#26368;&#22823;&#29109;&#38381;&#21512;&#12290;&#36890;&#36807;&#23545;&#27604;&#22810;&#20010;&#27979;&#35797;&#26696;&#20363;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#29109;&#20998;&#24067;&#25552;&#20379;&#20102;&#19968;&#31867;&#36866;&#29992;&#20110;&#30697;&#38381;&#21512;&#38382;&#39064;&#30340;&#21560;&#24341;&#20154;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#25214;&#21040;&#21442;&#25968;&#21270;&#36825;&#20123;&#20998;&#24067;&#30340;&#25289;&#26684;&#26391;&#26085;&#20056;&#23376;&#23545;&#20110;&#23454;&#38469;&#38381;&#21512;&#35774;&#32622;&#26469;&#35828;&#21364;&#26159;&#19968;&#20010;&#35745;&#31639;&#29942;&#39048;&#12290;&#21463;&#21040;&#39640;&#26031;&#36807;&#31243;&#30340;&#26368;&#36817;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#39640;&#26031;&#20808;&#39564;&#26469;&#36817;&#20284;&#25289;&#26684;&#26391;&#26085;&#20056;&#23376;&#20316;&#20026;&#32473;&#23450;&#19968;&#32452;&#30697;&#30340;&#26144;&#23556;&#30340;&#36866;&#29992;&#24615;&#12290;&#36890;&#36807;&#26368;&#22823;&#21270;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#20248;&#21270;&#20102;&#21508;&#31181;&#26680;&#20989;&#25968;&#30340;&#36229;&#21442;&#25968;&#12290;&#30740;&#31350;&#20102;&#25152;&#35774;&#35745;&#30340;&#25968;&#25454;&#39537;&#21160;&#26368;&#22823;&#29109;&#38381;&#21512;&#22312;&#21253;&#25324;&#30001;Bhatnagar-Gross-Krook&#21644;Boltzmann&#21160;&#21147;&#23398;&#26041;&#31243;&#25511;&#21046;&#30340;&#38750;&#24179;&#34913;&#20998;&#24067;&#26494;&#24347;&#30340;&#20960;&#20010;&#27979;&#35797;&#26696;&#20363;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum-Entropy Distributions offer an attractive family of probability densities suitable for moment closure problems. Yet finding the Lagrange multipliers which parametrize these distributions, turns out to be a computational bottleneck for practical closure settings. Motivated by recent success of Gaussian processes, we investigate the suitability of Gaussian priors to approximate the Lagrange multipliers as a map of a given set of moments. Examining various kernel functions, the hyperparameters are optimized by maximizing the log-likelihood. The performance of the devised data-driven Maximum-Entropy closure is studied for couple of test cases including relaxation of non-equilibrium distributions governed by Bhatnagar-Gross-Krook and Boltzmann kinetic equations.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#25104;&#21151;&#39044;&#27979;&#20102;&#38156;&#29983;&#20135;&#21387;&#21147;&#36807;&#28388;&#36807;&#31243;&#20013;&#30340;&#28388;&#39292;&#21547;&#27700;&#29575;&#65292;&#20026;&#38156;&#29983;&#20135;&#24037;&#33402;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#39044;&#27979;&#25163;&#27573;&#12290;</title><link>http://arxiv.org/abs/2308.06138</link><description>&lt;p&gt;
&#24212;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30740;&#31350;&#21387;&#21147;&#36807;&#28388;&#24615;&#33021;&#30340;&#25506;&#32034;&#21644;&#38156;&#28024;&#20986;&#28388;&#39292;&#21547;&#27700;&#29575;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Application of Artificial Neural Networks for Investigation of Pressure Filtration Performance, a Zinc Leaching Filter Cake Moisture Modeling. (arXiv:2308.06138v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06138
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#25104;&#21151;&#39044;&#27979;&#20102;&#38156;&#29983;&#20135;&#21387;&#21147;&#36807;&#28388;&#36807;&#31243;&#20013;&#30340;&#28388;&#39292;&#21547;&#27700;&#29575;&#65292;&#20026;&#38156;&#29983;&#20135;&#24037;&#33402;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#39044;&#27979;&#25163;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26159;&#26448;&#26009;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#33021;&#22815;&#25552;&#20379;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#38156;&#29983;&#20135;&#30340;&#21387;&#21147;&#36807;&#28388;&#36807;&#31243;&#20013;&#30340;&#28388;&#39292;&#21547;&#27700;&#29575;&#12290;&#28388;&#39292;&#21547;&#27700;&#29575;&#21463;&#21040;&#19971;&#20010;&#21442;&#25968;&#30340;&#24433;&#21709;&#65306;&#28201;&#24230;&#65288;35&#25668;&#27663;&#24230;&#21644;65&#25668;&#27663;&#24230;&#65289;&#65292;&#22266;&#20307;&#27987;&#24230;&#65288;0.2&#20811;/&#21319;&#21644;0.38&#20811;/&#21319;&#65289;&#65292;pH&#20540;&#65288;2&#12289;3.5&#21644;5&#65289;&#65292;&#21561;&#27668;&#26102;&#38388;&#65288;2&#20998;&#38047;&#12289;10&#20998;&#38047;&#21644;15&#20998;&#38047;&#65289;&#65292;&#28388;&#39292;&#21402;&#24230;&#65288;14&#27627;&#31859;&#12289;20&#27627;&#31859;&#12289;26&#27627;&#31859;&#21644;34&#27627;&#31859;&#65289;&#65292;&#21387;&#21147;&#21644;&#36807;&#28388;&#26102;&#38388;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#20004;&#31181;&#31867;&#22411;&#30340;&#32455;&#29289;&#36827;&#34892;&#20102;288&#27425;&#27979;&#35797;&#65306;&#32858;&#19993;&#28911;&#65288;S1&#65289;&#21644;&#28068;&#32438;&#65288;S2&#65289;&#12290;&#36890;&#36807;&#20915;&#23450;&#31995;&#25968;&#65288;R2&#65289;&#12289;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#21644;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#25351;&#26631;&#35780;&#20272;&#20102;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22312;&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#23545;&#20110;S1&#21644;S2&#65292;R2&#20540;&#20998;&#21035;&#20026;0.88&#21644;0.83&#65292;MSE&#20540;&#20998;&#21035;&#20026;6.243x10-07&#21644;1.086x10-06&#65292;MAE&#20540;&#20998;&#21035;&#20026;0.00056&#21644;0.00088&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) is a powerful tool for material science applications. Artificial Neural Network (ANN) is a machine learning technique that can provide high prediction accuracy. This study aimed to develop an ANN model to predict the cake moisture of the pressure filtration process of zinc production. The cake moisture was influenced by seven parameters: temperature (35 and 65 Celsius), solid concentration (0.2 and 0.38 g/L), pH (2, 3.5, and 5), air-blow time (2, 10, and 15 min), cake thickness (14, 20, 26, and 34 mm), pressure, and filtration time. The study conducted 288 tests using two types of fabrics: polypropylene (S1) and polyester (S2). The ANN model was evaluated by the Coefficient of determination (R2), the Mean Square Error (MSE), and the Mean Absolute Error (MAE) metrics for both datasets. The results showed R2 values of 0.88 and 0.83, MSE values of 6.243x10-07 and 1.086x10-06, and MAE values of 0.00056 and 0.00088 for S1 and S2, respectively. These results indicated t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#22312;&#36328;&#22478;&#24066;&#20132;&#36890;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#23384;&#22312;&#30340;UQ&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#29992;&#20110;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.06129</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#20687;&#30340;&#36328;&#22478;&#24066;&#20132;&#36890;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification for Image-based Traffic Prediction across Cities. (arXiv:2308.06129v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#22312;&#36328;&#22478;&#24066;&#20132;&#36890;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#23384;&#22312;&#30340;UQ&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#29992;&#20110;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#20132;&#36890;&#39044;&#27979;&#26041;&#38754;&#20855;&#26377;&#36739;&#24378;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#30001;&#20110;&#35299;&#37322;&#24615;&#30340;&#32570;&#20047;&#65292;&#23427;&#20204;&#22312;&#23454;&#38469;&#26234;&#33021;&#20132;&#36890;&#31995;&#32479;&#20013;&#30340;&#26222;&#36941;&#37096;&#32626;&#21463;&#21040;&#20102;&#38480;&#21046;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#24341;&#20837;&#27010;&#29575;&#25512;&#29702;&#12289;&#25913;&#36827;&#20915;&#31574;&#21644;&#25552;&#39640;&#27169;&#22411;&#37096;&#32626;&#28508;&#21147;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#20840;&#38754;&#20102;&#35299;&#29616;&#26377;UQ&#26041;&#27861;&#22312;&#20132;&#36890;&#39044;&#27979;&#20013;&#30340;&#26377;&#29992;&#24615;&#20197;&#21450;&#33719;&#24471;&#30340;&#19981;&#30830;&#23450;&#24615;&#19982;&#22478;&#24066;&#33539;&#22260;&#20869;&#20132;&#36890;&#21160;&#24577;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#23545;&#36328;&#36234;&#22810;&#20010;&#22478;&#24066;&#21644;&#26102;&#38388;&#27573;&#30340;&#22823;&#35268;&#27169;&#22522;&#20110;&#22270;&#20687;&#30340;&#20132;&#36890;&#25968;&#25454;&#38598;&#24212;&#29992;&#20102;&#36825;&#20123;&#26041;&#27861;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#20004;&#31181;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21644;&#20004;&#31181;&#37325;&#35201;&#24615;&#19981;&#30830;&#23450;&#24615;UQ&#26041;&#27861;&#22312;&#26102;&#38388;&#21644;&#26102;&#31354;&#36716;&#25442;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#65292;&#24182;&#21457;&#29616;&#21487;&#20197;&#33719;&#24471;&#26377;&#24847;&#20041;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26469;&#36827;&#34892;&#22478;&#24066;&#20132;&#36890;&#21160;&#24577;&#21464;&#21270;&#30340;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#22478;&#24066;&#20132;&#36890;&#21160;&#24577;&#21464;&#21270;&#26041;&#38754;&#21457;&#29616;&#24322;&#24120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the strong predictive performance of deep learning models for traffic prediction, their widespread deployment in real-world intelligent transportation systems has been restrained by a lack of interpretability. Uncertainty quantification (UQ) methods provide an approach to induce probabilistic reasoning, improve decision-making and enhance model deployment potential. To gain a comprehensive picture of the usefulness of existing UQ methods for traffic prediction and the relation between obtained uncertainties and city-wide traffic dynamics, we investigate their application to a large-scale image-based traffic dataset spanning multiple cities and time periods. We compare two epistemic and two aleatoric UQ methods on both temporal and spatio-temporal transfer tasks, and find that meaningful uncertainty estimates can be recovered. We further demonstrate how uncertainty estimates can be employed for unsupervised outlier detection on changes in city traffic dynamics. We find that our 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38669;&#20811;&#26031;&#36807;&#31243;&#30340;&#24310;&#36831;&#26684;&#20848;&#26480;&#22240;&#26524;&#25928;&#24212;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#22320;&#24314;&#27169;&#26102;&#38388;&#24310;&#36831;&#65292;&#22686;&#21152;&#20102;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#65292;&#24182;&#25512;&#26029;&#20986;&#26102;&#38388;&#24310;&#36831;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#26377;&#21161;&#20110;&#36861;&#36394;&#21407;&#22987;&#22240;&#26524;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2308.06106</link><description>&lt;p&gt;
&#24310;&#36831;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#30340;&#38669;&#20811;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Hawkes Processes with Delayed Granger Causality. (arXiv:2308.06106v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06106
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38669;&#20811;&#26031;&#36807;&#31243;&#30340;&#24310;&#36831;&#26684;&#20848;&#26480;&#22240;&#26524;&#25928;&#24212;&#27169;&#22411;&#65292;&#36890;&#36807;&#26174;&#24335;&#22320;&#24314;&#27169;&#26102;&#38388;&#24310;&#36831;&#65292;&#22686;&#21152;&#20102;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#65292;&#24182;&#25512;&#26029;&#20986;&#26102;&#38388;&#24310;&#36831;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#26377;&#21161;&#20110;&#36861;&#36394;&#21407;&#22987;&#22240;&#26524;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26088;&#22312;&#22522;&#20110;&#22810;&#20803;&#38669;&#20811;&#26031;&#36807;&#31243;&#26126;&#30830;&#22320;&#24314;&#27169;&#24310;&#36831;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#25928;&#24212;&#12290;&#36825;&#20010;&#24819;&#27861;&#30340;&#28789;&#24863;&#26469;&#33258;&#20110;&#22240;&#26524;&#20107;&#20214;&#36890;&#24120;&#38656;&#35201;&#19968;&#20123;&#26102;&#38388;&#25165;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#30740;&#31350;&#36825;&#20010;&#26102;&#38388;&#24310;&#36831;&#26412;&#36523;&#23601;&#24456;&#26377;&#24847;&#20041;&#12290;&#22312;&#25552;&#20986;&#30340;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#26465;&#20214;&#19979;&#30340;&#24310;&#36831;&#21442;&#25968;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#22312;&#22797;&#26434;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20272;&#35745;&#26041;&#27861;&#65292;&#20854;&#20013;&#25105;&#20204;&#24076;&#26395;&#25512;&#26029;&#20986;&#26102;&#38388;&#24310;&#36831;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20102;&#35299;&#35813;&#20998;&#24067;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#23558;&#26102;&#38388;&#24310;&#36831;&#35270;&#20026;&#28508;&#22312;&#21464;&#37327;&#65292;&#24182;&#21046;&#23450;&#20102;&#19968;&#20010;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#31639;&#27861;&#26469;&#36817;&#20284;&#26102;&#38388;&#24310;&#36831;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#36890;&#36807;&#26126;&#30830;&#22320;&#24314;&#27169;&#38669;&#20811;&#26031;&#36807;&#31243;&#20013;&#30340;&#26102;&#38388;&#24310;&#36831;&#65292;&#25105;&#20204;&#20026;&#27169;&#22411;&#22686;&#21152;&#20102;&#28789;&#27963;&#24615;&#12290;&#25512;&#26029;&#20986;&#30340;&#26102;&#38388;&#24310;&#36831;&#21518;&#39564;&#20998;&#24067;&#20855;&#26377;&#31185;&#23398;&#24847;&#20041;&#65292;&#24182;&#26377;&#21161;&#20110;&#36861;&#36394;&#25903;&#25345;&#26681;&#26412;&#21407;&#22240;&#20998;&#26512;&#30340;&#21407;&#22987;&#22240;&#26524;&#26102;&#38388;&#12290;&#25105;&#20204;&#23545;&#27169;&#22411;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We aim to explicitly model the delayed Granger causal effects based on multivariate Hawkes processes. The idea is inspired by the fact that a causal event usually takes some time to exert an effect. Studying this time lag itself is of interest. Given the proposed model, we first prove the identifiability of the delay parameter under mild conditions. We further investigate a model estimation method under a complex setting, where we want to infer the posterior distribution of the time lags and understand how this distribution varies across different scenarios. We treat the time lags as latent variables and formulate a Variational Auto-Encoder (VAE) algorithm to approximate the posterior distribution of the time lags. By explicitly modeling the time lags in Hawkes processes, we add flexibility to the model. The inferred time-lag posterior distributions are of scientific meaning and help trace the original causal time that supports the root cause analysis. We empirically evaluate our model
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;AdaSPS&#21644;AdaSLS&#20004;&#31181;&#26032;&#30340;&#21464;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;SGD&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#19979;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#24182;&#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#20445;&#25345;&#32447;&#24615;&#21644;&#20122;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.06058</link><description>&lt;p&gt;
&#24102;&#26377;Polyak&#27493;&#38271;&#21644;&#32447;&#24615;&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;SGD: &#40065;&#26834;&#25910;&#25947;&#21644;&#26041;&#24046;&#20943;&#23567;
&lt;/p&gt;
&lt;p&gt;
Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction. (arXiv:2308.06058v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;AdaSPS&#21644;AdaSLS&#20004;&#31181;&#26032;&#30340;&#21464;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;SGD&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#19979;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#24182;&#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#20445;&#25345;&#32447;&#24615;&#21644;&#20122;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#30340;&#38543;&#26426;Polyak&#27493;&#38271; (SPS) &#21644;&#38543;&#26426;&#32447;&#24615;&#25628;&#32034; (SLS) &#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#26174;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#21482;&#33021;&#20445;&#35777;&#25910;&#25947;&#21040;&#19968;&#20010;&#35299;&#30340;&#37051;&#22495;&#65292;&#21487;&#33021;&#23548;&#33268;&#27604;&#21021;&#22987;&#29468;&#27979;&#26356;&#24046;&#30340;&#36755;&#20986;&#32467;&#26524;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#20154;&#20026;&#20943;&#23567;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064; (Orvieto et al. [2022])&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#20984;&#20989;&#25968;&#21644;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#21464;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20570;&#20986;&#20102;&#20004;&#20010;&#36129;&#29486;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SPS&#21644;SLS&#21464;&#31181;&#65292;&#20998;&#21035;&#31216;&#20026;AdaSPS&#21644;AdaSLS&#65292;&#23427;&#20204;&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#20013;&#20445;&#35777;&#25910;&#25947;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#20445;&#25345;&#20984;&#20989;&#25968;&#21644;&#24378;&#20984;&#20989;&#25968;&#30340;&#20122;&#32447;&#24615;&#21644;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;AdaSLS&#19981;&#38656;&#35201;&#23545;&#38382;&#39064;&#30456;&#20851;&#21442;&#25968;&#30340;&#20102;&#35299;&#65292;&#32780;AdaSPS&#21482;&#38656;&#35201;&#26368;&#20248;&#20989;&#25968;&#20540;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al. [2022]), this approach results in slower convergence rates for convex and over-parameterized models. In this work, we make two contributions: Firstly, we propose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which guarantee convergence in non-interpolation settings and maintain sub-linear and linear convergence rates for convex and strongly convex functions when training over-parameterized models. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#39640;&#38454;HSIC&#30340;&#26041;&#27861;&#65292;&#22312;&#23398;&#20064;Bayesian&#32593;&#32476;&#20013;&#35299;&#20915;&#20102;&#23616;&#37096;&#21464;&#37327;&#21516;&#26102;&#20855;&#26377;&#30452;&#25509;&#21644;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#30830;&#23450;&#23376;&#38598;&#21644;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#36827;&#34892;&#23616;&#37096;&#20462;&#27491;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.05969</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#38454;HSIC&#23398;&#20064;&#20855;&#26377;&#22686;&#37327;&#20449;&#24687;&#30340;&#38750;&#21442;&#25968;DAGs
&lt;/p&gt;
&lt;p&gt;
Learning nonparametric DAGs with incremental information via high-order HSIC. (arXiv:2308.05969v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#39640;&#38454;HSIC&#30340;&#26041;&#27861;&#65292;&#22312;&#23398;&#20064;Bayesian&#32593;&#32476;&#20013;&#35299;&#20915;&#20102;&#23616;&#37096;&#21464;&#37327;&#21516;&#26102;&#20855;&#26377;&#30452;&#25509;&#21644;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#30830;&#23450;&#23376;&#38598;&#21644;&#20004;&#38454;&#27573;&#31639;&#27861;&#26469;&#36827;&#34892;&#23616;&#37096;&#20462;&#27491;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#23398;&#20064;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BN&#65289;&#30340;&#22522;&#20110;&#35780;&#20998;&#30340;&#26041;&#27861;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#20840;&#23616;&#35780;&#20998;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#23616;&#37096;&#21464;&#37327;&#21516;&#26102;&#20855;&#26377;&#30452;&#25509;&#21644;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#65292;&#37027;&#20040;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#23558;&#24573;&#30053;&#20855;&#26377;&#38388;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#21464;&#37327;&#20043;&#38388;&#30340;&#36793;&#32536;&#65292;&#20854;&#24471;&#20998;&#23567;&#20110;&#20855;&#26377;&#30452;&#25509;&#20381;&#36182;&#20851;&#31995;&#30340;&#36793;&#32536;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#30830;&#23450;&#23376;&#38598;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#20197;&#35782;&#21035;&#28508;&#22312;&#30340;DAG&#12290;&#36890;&#36807;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#21363;&#26368;&#20248;&#35843;&#25972;&#65288;OT&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#20840;&#23616;&#20248;&#21270;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#23616;&#37096;&#20462;&#27491;&#12290;&#22312;&#26368;&#20248;&#38454;&#27573;&#65292;&#22522;&#20110;&#19968;&#38454;Hilbert-Schmidt&#29420;&#31435;&#24615;&#20934;&#21017;&#65288;HSIC&#65289;&#30340;&#20248;&#21270;&#38382;&#39064;&#32473;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#30340;&#39592;&#26550;&#20316;&#20026;&#21021;&#22987;&#30830;&#23450;&#30340;&#29238;&#33410;&#28857;&#23376;&#38598;&#12290;&#22312;&#35843;&#25972;&#38454;&#27573;&#65292;&#26681;&#25454;&#39640;&#38454;HSIC&#30340;&#29702;&#35770;&#35777;&#26126;&#22686;&#37327;&#29305;&#24615;&#65292;&#23545;&#39592;&#26550;&#36827;&#34892;&#23616;&#37096;&#35843;&#25972;&#65292;&#21253;&#25324;&#21024;&#38500;&#12289;&#28155;&#21152;&#21644;DAG&#26684;&#24335;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based methods for learning Bayesain networks(BN) aim to maximizing the global score functions. However, if local variables have direct and indirect dependence simultaneously, the global optimization on score functions misses edges between variables with indirect dependent relationship, of which scores are smaller than those with direct dependent relationship. In this paper, we present an identifiability condition based on a determined subset of parents to identify the underlying DAG. By the identifiability condition, we develop a two-phase algorithm namely optimal-tuning (OT) algorithm to locally amend the global optimization. In the optimal phase, an optimization problem based on first-order Hilbert-Schmidt independence criterion (HSIC) gives an estimated skeleton as the initial determined parents subset. In the tuning phase, the skeleton is locally tuned by deletion, addition and DAG-formalization strategies using the theoretically proved incremental properties of high-order HS
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ARGEW&#30340;&#22686;&#24378;&#38543;&#26426;&#28216;&#36208;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#33021;&#22815;&#26356;&#22909;&#21453;&#26144;&#33410;&#28857;&#20043;&#38388;&#36793;&#26435;&#37325;&#30340;&#33410;&#28857;&#23884;&#20837;&#12290;</title><link>http://arxiv.org/abs/2308.05957</link><description>&lt;p&gt;
&#24102;&#26377;ARGEW&#30340;&#21516;&#36136;&#22270;&#33410;&#28857;&#23884;&#20837;&#65306;&#36890;&#36807;&#22270;&#36793;&#26435;&#37325;&#22686;&#24378;&#30340;&#38543;&#26426;&#28216;&#36208;
&lt;/p&gt;
&lt;p&gt;
Node Embedding for Homophilous Graphs with ARGEW: Augmentation of Random walks by Graph Edge Weights. (arXiv:2308.05957v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05957
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ARGEW&#30340;&#22686;&#24378;&#38543;&#26426;&#28216;&#36208;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#33021;&#22815;&#26356;&#22909;&#21453;&#26144;&#33410;&#28857;&#20043;&#38388;&#36793;&#26435;&#37325;&#30340;&#33410;&#28857;&#23884;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#32593;&#32476;&#20013;&#30340;&#33410;&#28857;&#34920;&#31034;&#20026;&#23494;&#38598;&#21521;&#37327;&#33410;&#28857;&#23884;&#20837;&#23545;&#20110;&#29702;&#35299;&#32473;&#23450;&#32593;&#32476;&#21644;&#35299;&#20915;&#35768;&#22810;&#19979;&#28216;&#20219;&#21153;&#38750;&#24120;&#37325;&#35201;&#12290;&#29305;&#21035;&#26159;&#23545;&#20110;&#26435;&#37325;&#21516;&#36136;&#22270;&#65292;&#20854;&#20013;&#20855;&#26377;&#30456;&#20284;&#33410;&#28857;&#30340;&#36793;&#32536;&#26435;&#37325;&#36739;&#22823;&#65292;&#25105;&#20204;&#24076;&#26395;&#33410;&#28857;&#23884;&#20837;&#20013;&#20855;&#26377;&#24378;&#26435;&#37325;&#30340;&#33410;&#28857;&#23545;&#20855;&#26377;&#26356;&#25509;&#36817;&#30340;&#23884;&#20837;&#12290;&#34429;&#28982;&#22522;&#20110;&#38543;&#26426;&#28216;&#36208;&#30340;&#33410;&#28857;&#23884;&#20837;&#26041;&#27861;&#65292;&#22914;node2vec&#21644;node2vec+&#65292;&#36890;&#36807;&#23558;&#36793;&#26435;&#37325;&#21253;&#21547;&#22312;&#34892;&#36208;&#36716;&#31227;&#27010;&#29575;&#20013;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#21152;&#26435;&#32593;&#32476;&#65292;&#20294;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#23884;&#20837;&#32467;&#26524;&#19981;&#36275;&#20197;&#21453;&#26144;&#36793;&#26435;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ARGEW&#65288;&#36890;&#36807;&#22270;&#36793;&#26435;&#37325;&#22686;&#24378;&#30340;&#38543;&#26426;&#28216;&#36208;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#28216;&#36208;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#25193;&#23637;&#35821;&#26009;&#24211;&#20351;&#20855;&#26377;&#36739;&#22823;&#36793;&#26435;&#37325;&#30340;&#33410;&#28857;&#26368;&#32456;&#20855;&#26377;&#26356;&#25509;&#36817;&#30340;&#23884;&#20837;&#12290;ARGEW&#21487;&#20197;&#19982;&#20219;&#20309;&#22522;&#20110;&#38543;&#26426;&#28216;&#36208;&#30340;&#33410;&#28857;&#23884;&#20837;&#26041;&#27861;&#19968;&#36215;&#20351;&#29992;&#65292;&#22240;&#20026;&#23427;&#29420;&#31435;&#20110;&#38543;&#26426;&#37319;&#26679;&#31574;&#30053;&#26412;&#36523;&#24182;&#22312;&#24050;&#26377;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representing nodes in a network as dense vectors node embeddings is important for understanding a given network and solving many downstream tasks. In particular, for weighted homophilous graphs where similar nodes are connected with larger edge weights, we desire node embeddings where node pairs with strong weights have closer embeddings. Although random walk based node embedding methods like node2vec and node2vec+ do work for weighted networks via including edge weights in the walk transition probabilities, our experiments show that the embedding result does not adequately reflect edge weights. In this paper, we propose ARGEW (Augmentation of Random walks by Graph Edge Weights), a novel augmentation method for random walks that expands the corpus in such a way that nodes with larger edge weights end up with closer embeddings. ARGEW can work with any random walk based node embedding method, because it is independent of the random sampling strategy itself and works on top of the already
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#36136;&#37327;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#26041;&#27861;&#21644;&#25351;&#26631;&#23545;&#19981;&#21516;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#36825;&#20123;&#20272;&#35745;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.05903</link><description>&lt;p&gt;
&#27604;&#36739;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#38382;&#39064;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
Comparing the quality of neural network uncertainty estimates for classification problems. (arXiv:2308.05903v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#36136;&#37327;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#26041;&#27861;&#21644;&#25351;&#26631;&#23545;&#19981;&#21516;&#26041;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#30740;&#31350;&#23637;&#31034;&#20102;&#36825;&#20123;&#20272;&#35745;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26159;&#24378;&#22823;&#30340;&#20998;&#31867;&#22120;&#65292;&#20294;&#35768;&#22810;&#26041;&#27861;&#27809;&#26377;&#25552;&#20379;&#23545;&#20854;&#20272;&#35745;&#32467;&#26524;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26041;&#27861;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#20915;&#31574;&#20013;&#30340;&#26377;&#29992;&#24615;&#24341;&#36215;&#20102;&#25991;&#29486;&#20013;&#30340;&#20851;&#27880;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#39640;&#39118;&#38505;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#36825;&#20123;&#26041;&#27861;&#30340;&#36136;&#37327;&#35780;&#20272;&#30740;&#31350;&#24456;&#23569;&#12290;&#25105;&#20204;&#20351;&#29992;&#32463;&#39564;&#20027;&#20041;&#32622;&#20449;&#21306;&#38388;&#35206;&#30422;&#29575;&#21644;&#21306;&#38388;&#23485;&#24230;&#30340;&#32479;&#35745;&#26041;&#27861;&#26469;&#35780;&#20272;&#32622;&#20449;&#21306;&#38388;&#30340;&#36136;&#37327;&#65292;&#24182;&#20351;&#29992;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#35780;&#20272;&#20998;&#31867;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#19981;&#21516;&#30340;UQ&#26041;&#27861;&#24212;&#29992;&#20110;&#20351;&#29992;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#21644;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#25311;&#21512;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#65292;&#33258;&#21161;&#24335;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#65292;&#28145;&#24230;&#38598;&#25104;&#65288;DE&#65289;&#21644;&#33945;&#29305;&#21345;&#27931;&#65288;MC&#65289;dropout&#30340;&#39640;&#20809;&#35889;&#22270;&#20687;&#30446;&#26631;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#19981;&#21516;&#26041;&#27861;&#32467;&#26524;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional deep learning (DL) models are powerful classifiers, but many approaches do not provide uncertainties for their estimates. Uncertainty quantification (UQ) methods for DL models have received increased attention in the literature due to their usefulness in decision making, particularly for high-consequence decisions. However, there has been little research done on how to evaluate the quality of such methods. We use statistical methods of frequentist interval coverage and interval width to evaluate the quality of credible intervals, and expected calibration error to evaluate classification predicted confidence. These metrics are evaluated on Bayesian neural networks (BNN) fit using Markov Chain Monte Carlo (MCMC) and variational inference (VI), bootstrapped neural networks (NN), Deep Ensembles (DE), and Monte Carlo (MC) dropout. We apply these different UQ for DL methods to a hyperspectral image target detection problem and show the inconsistency of the different methods' resu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie &#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20391;&#20449;&#24687;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#22312;&#32771;&#34385;&#20102;&#36741;&#21161;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27491;&#24577;&#22343;&#20540;&#30340;&#22797;&#21512;&#20272;&#35745;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05883</link><description>&lt;p&gt;
&#20351;&#29992;&#20391;&#20449;&#24687;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#65306;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie &#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Empirical Bayes Estimation with Side Information: A Nonparametric Integrative Tweedie Approach. (arXiv:2308.05883v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie &#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20391;&#20449;&#24687;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#22312;&#32771;&#34385;&#20102;&#36741;&#21161;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27491;&#24577;&#22343;&#20540;&#30340;&#22797;&#21512;&#20272;&#35745;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32771;&#34385;&#21040;&#20391;&#20449;&#24687;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#27491;&#24577;&#22343;&#20540;&#30340;&#22797;&#21512;&#20272;&#35745;&#38382;&#39064;&#12290;&#21033;&#29992;&#32463;&#39564;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#32508;&#21512; Tweedie&#65288;NIT&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#22810;&#21464;&#37327;&#36741;&#21161;&#25968;&#25454;&#20013;&#32534;&#30721;&#30340;&#32467;&#26500;&#30693;&#35782;&#21512;&#24182;&#21040;&#22797;&#21512;&#20272;&#35745;&#30340;&#31934;&#24230;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#20984;&#20248;&#21270;&#24037;&#20855;&#30452;&#25509;&#20272;&#35745;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65292;&#20174;&#32780;&#33021;&#22815;&#23558;&#32467;&#26500;&#32422;&#26463;&#32435;&#20837;&#32771;&#34385;&#12290;&#25105;&#20204;&#23545; NIT &#30340;&#28176;&#36817;&#39118;&#38505;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#30830;&#23450;&#20102; NIT &#25910;&#25947;&#21040; Oracle &#20272;&#35745;&#22120;&#30340;&#36895;&#29575;&#12290;&#38543;&#30528;&#36741;&#21161;&#25968;&#25454;&#30340;&#32500;&#24230;&#22686;&#21152;&#65292;&#25105;&#20204;&#20934;&#30830;&#22320;&#37327;&#21270;&#20102;&#20272;&#35745;&#39118;&#38505;&#30340;&#25913;&#21892;&#20197;&#21450;&#25910;&#25947;&#36895;&#24230;&#30340;&#24694;&#21270;&#12290;&#36890;&#36807;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102; NIT &#30340;&#25968;&#20540;&#24615;&#33021;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the problem of compound estimation of normal means while accounting for the presence of side information. Leveraging the empirical Bayes framework, we develop a nonparametric integrative Tweedie (NIT) approach that incorporates structural knowledge encoded in multivariate auxiliary data to enhance the precision of compound estimation. Our approach employs convex optimization tools to estimate the gradient of the log-density directly, enabling the incorporation of structural constraints. We conduct theoretical analyses of the asymptotic risk of NIT and establish the rate at which NIT converges to the oracle estimator. As the dimension of the auxiliary data increases, we accurately quantify the improvements in estimation risk and the associated deterioration in convergence rate. The numerical performance of NIT is illustrated through the analysis of both simulated and real data, demonstrating its superiority over existing methods.
&lt;/p&gt;</description></item><item><title>SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.04365</link><description>&lt;p&gt;
SLEM&#65306;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#36335;&#24452;&#24314;&#27169;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04365
&lt;/p&gt;
&lt;p&gt;
SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26159;&#31185;&#23398;&#30340;&#20851;&#38190;&#30446;&#26631;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#36890;&#36807;&#35266;&#23519;&#25968;&#25454;&#24471;&#20986;&#20851;&#20110;&#23545;&#20551;&#23450;&#24178;&#39044;&#30340;&#39044;&#27979;&#30340;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;&#36335;&#24452;&#27169;&#22411;&#12289;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;(SEMs)&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#33021;&#22815;&#26126;&#30830;&#22320;&#25351;&#23450;&#20851;&#20110;&#29616;&#35937;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#30340;&#20551;&#35774;&#12290;&#19982;DAGs&#19981;&#21516;&#65292;SEMs&#20551;&#35774;&#32447;&#24615;&#20851;&#31995;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#20989;&#25968;&#38169;&#35823;&#35268;&#33539;&#65292;&#20174;&#32780;&#38459;&#30861;&#30740;&#31350;&#20154;&#21592;&#36827;&#34892;&#21487;&#38752;&#30340;&#25928;&#26524;&#22823;&#23567;&#20272;&#35745;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;&#65288;SLEM&#65289;&#65292;&#19968;&#31181;&#38598;&#25104;&#20102;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#38598;&#25104;&#30340;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;SLEM&#33021;&#22815;&#25552;&#20379;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#22312;&#19982;SEMs&#36827;&#34892;&#32447;&#24615;&#27169;&#22411;&#27604;&#36739;&#26102;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#20248;&#20110;SEMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20284;&#28982;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35266;&#27979;&#27169;&#22411;&#19979;&#35299;&#20915;A-&#26368;&#20248;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#26080;&#38656;&#23545;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25110;&#31215;&#20998;&#12290;</title><link>http://arxiv.org/abs/2306.17615</link><description>&lt;p&gt;
&#26080;&#38656;&#23545;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Scalable method for Bayesian experimental design without integrating over posterior distribution. (arXiv:2306.17615v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20284;&#28982;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35266;&#27979;&#27169;&#22411;&#19979;&#35299;&#20915;A-&#26368;&#20248;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#26080;&#38656;&#23545;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25110;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35266;&#27979;&#27169;&#22411;&#20013;&#27714;&#35299;A-&#26368;&#20248;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#26102;&#30340;&#35745;&#31639;&#25928;&#29575;&#38382;&#39064;&#65292;&#30001;&#20110;&#38656;&#35201;&#35745;&#31639;&#22797;&#26434;&#65292;A-&#26368;&#20248;&#24615;&#26159;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#12289;&#26131;&#20110;&#35299;&#37322;&#30340;&#26631;&#20934;&#12290;&#35813;&#26631;&#20934;&#36890;&#36807;&#26368;&#23567;&#21270;&#39044;&#26399;&#26465;&#20214;&#26041;&#24046;&#65292;&#20063;&#31216;&#20026;&#39044;&#26399;&#21518;&#39564;&#26041;&#24046;&#65292;&#26469;&#23547;&#27714;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#12290;&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26080;&#20284;&#28982;&#26041;&#27861;&#65292;&#29992;&#20110;&#23547;&#25214;A-&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#65292;&#32780;&#26080;&#38656;&#23545;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25110;&#31215;&#20998;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#24635;&#26041;&#24046;&#23450;&#29702;&#65292;&#36890;&#36807;&#26465;&#20214;&#26399;&#26395;&#30340;&#26041;&#24046;&#26469;&#33719;&#24471;&#39044;&#26399;&#26465;&#20214;&#26041;&#24046;&#65292;&#21516;&#26102;&#21033;&#29992;&#27491;&#20132;&#25237;&#24433;&#24615;&#36136;&#26469;&#36817;&#20284;&#26465;&#20214;&#26399;&#26395;&#12290;&#36890;&#36807;&#28176;&#36817;&#35823;&#24046;&#20272;&#35745;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#39564;&#19981;&#21487;&#35745;&#31639;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the computational efficiency in solving the A-optimal Bayesian design of experiments problems for which the observational model is based on partial differential equations and, consequently, is computationally expensive to evaluate. A-optimality is a widely used and easy-to-interpret criterion for the Bayesian design of experiments. The criterion seeks the optimal experiment design by minimizing the expected conditional variance, also known as the expected posterior variance. This work presents a novel likelihood-free method for seeking the A-optimal design of experiments without sampling or integrating the Bayesian posterior distribution. In our approach, the expected conditional variance is obtained via the variance of the conditional expectation using the law of total variance, while we take advantage of the orthogonal projection property to approximate the conditional expectation. Through an asymptotic error estimation, we show that the intractability of the posterior doe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#20855;&#26377;&#21333;&#23618;&#32447;&#24615;&#33258;&#27880;&#24847;&#23618;&#30340;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#19978;&#36890;&#36807;&#26799;&#24230;&#27969;&#36827;&#34892;&#35757;&#32451;&#30340;ICL&#26426;&#21046;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#27969;&#20855;&#26377;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.09927</link><description>&lt;p&gt;
&#35757;&#32451;&#22909;&#30340;Transformer&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#20855;&#26377;&#21333;&#23618;&#32447;&#24615;&#33258;&#27880;&#24847;&#23618;&#30340;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#19978;&#36890;&#36807;&#26799;&#24230;&#27969;&#36827;&#34892;&#35757;&#32451;&#30340;ICL&#26426;&#21046;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#27969;&#20855;&#26377;&#25214;&#21040;&#30446;&#26631;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20363;&#22914;Transformers&#65292;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#65288;ICL&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#38750;&#20961;&#30340;&#33021;&#21147;&#65306;&#32473;&#23450;&#19968;&#20010;&#26469;&#33258;&#26410;&#35265;&#36807;&#30340;&#20219;&#21153;&#30340;&#30701;&#35821;&#24207;&#21015;&#30340;&#25552;&#31034;&#65292;&#23427;&#20204;&#21487;&#20197;&#21046;&#23450;&#30456;&#20851;&#30340;&#27599;&#20010;&#20196;&#29260;&#21644;&#19979;&#19968;&#20010;&#20196;&#29260;&#30340;&#39044;&#27979;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#21442;&#25968;&#26356;&#26032;&#12290;&#36890;&#36807;&#23558;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#26410;&#26631;&#35760;&#30340;&#27979;&#35797;&#25968;&#25454;&#24207;&#21015;&#23884;&#20837;&#21040;&#25552;&#31034;&#20013;&#65292;&#36825;&#20351;&#24471;Transformer&#34920;&#29616;&#24471;&#20687;&#26377;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#12290;&#20107;&#23454;&#19978;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#22312;&#38543;&#26426;&#23454;&#20363;&#19978;&#35757;&#32451;Transformer&#20307;&#31995;&#32467;&#26500;&#30340;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#26102;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#39044;&#27979;&#20250;&#27169;&#20223;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models' predictions mimic those of ordinary least squares.  Towards understanding the mechanisms underlying this phenomenon, we investigate the dynamics of ICL in transformers with a single linear self-attention layer trained by gradient flow on linear regression tasks. We show that despite non-convexity, gradient flow with a suitable random initialization finds a global minimum of the objective function. At this 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20197;&#32852;&#37030;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#21327;&#20316;&#20272;&#35745;&#36275;&#22815;&#32500;&#25968;&#30340;&#38477;&#32500;&#23376;&#31354;&#38388;&#20197;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#19981;&#34987;&#26292;&#38706;&#65292;&#21516;&#26102;&#37319;&#29992;&#22810;&#31181;&#25200;&#21160;&#31574;&#30053;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#65292;&#36824;&#33021;&#33258;&#28982;&#22320;&#32467;&#21512;&#21327;&#20316;&#21464;&#37327;&#31579;&#36873;&#27493;&#39588;&#20197;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2306.06324</link><description>&lt;p&gt;
&#20197;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#20026;&#22522;&#30784;&#30340;&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Differentially private sliced inverse regression in the federated paradigm. (arXiv:2306.06324v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20197;&#32852;&#37030;&#23398;&#20064;&#20026;&#22522;&#30784;&#30340;&#24046;&#20998;&#38544;&#31169;&#20999;&#29255;&#36870;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#21327;&#20316;&#20272;&#35745;&#36275;&#22815;&#32500;&#25968;&#30340;&#38477;&#32500;&#23376;&#31354;&#38388;&#20197;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#19981;&#34987;&#26292;&#38706;&#65292;&#21516;&#26102;&#37319;&#29992;&#22810;&#31181;&#25200;&#21160;&#31574;&#30053;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#65292;&#36824;&#33021;&#33258;&#28982;&#22320;&#32467;&#21512;&#21327;&#20316;&#21464;&#37327;&#31579;&#36873;&#27493;&#39588;&#20197;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#24191;&#21463;&#27426;&#36814;&#30340;&#20999;&#29255;&#36870;&#22238;&#24402;&#25193;&#23637;&#21040;&#21435;&#35299;&#20915;&#20998;&#25955;&#24335;&#25968;&#25454;&#12289;&#20248;&#20808;&#20445;&#25252;&#38544;&#31169;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#34987;&#31216;&#20026;&#32852;&#37030;&#20999;&#29255;&#36870;&#22238;&#24402;&#65288;FSIR&#65289;&#65292;&#20415;&#20110;&#22810;&#20010;&#23458;&#25143;&#31471;&#20043;&#38388;&#21327;&#20316;&#20272;&#35745;&#36275;&#22815;&#32500;&#25968;&#30340;&#38477;&#32500;&#23376;&#31354;&#38388;&#65292;&#21482;&#20849;&#20139;&#26412;&#22320;&#20272;&#35745;&#65292;&#20197;&#20445;&#25252;&#25935;&#24863;&#25968;&#25454;&#19981;&#34987;&#26292;&#38706;&#12290;&#20026;&#20102;&#38450;&#33539;&#28508;&#22312;&#30340;&#25915;&#20987;&#65292;FSIR&#36824;&#37319;&#29992;&#20102;&#22810;&#31181;&#25200;&#21160;&#31574;&#30053;&#65292;&#21253;&#25324;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20803;&#39640;&#26031;&#26426;&#21046;&#65292;&#20197;&#20302;&#25104;&#26412;&#30340;&#32479;&#35745;&#31934;&#24230;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;&#12290;&#27492;&#22806;&#65292;FSIR&#33258;&#28982;&#22320;&#32467;&#21512;&#20102;&#21327;&#20316;&#21464;&#37327;&#31579;&#36873;&#27493;&#39588;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#23458;&#25143;&#31471;&#25968;&#25454;&#12290;FSIR&#30340;&#29702;&#35770;&#24615;&#36136;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#35777;&#23454;&#65292;&#24182;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#25968;&#23383;&#23454;&#39564;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend the celebrated sliced inverse regression to address the challenges of decentralized data, prioritizing privacy and communication efficiency. Our approach, federated sliced inverse regression (FSIR), facilitates collaborative estimation of the sufficient dimension reduction subspace among multiple clients, solely sharing local estimates to protect sensitive datasets from exposure. To guard against potential adversary attacks, FSIR further employs diverse perturbation strategies, including a novel multivariate Gaussian mechanism that guarantees differential privacy at a low cost of statistical accuracy. Additionally, FSIR naturally incorporates a collaborative variable screening step, enabling effective handling of high-dimensional client data. Theoretical properties of FSIR are established for both low-dimensional and high-dimensional settings, supported by extensive numerical experiments and real data analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#20154;&#26426;&#36741;&#21161;&#30340;&#21327;&#21516;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26234;&#33021;&#35774;&#22791;&#32676;&#19982;&#26080;&#20154;&#26426;&#21327;&#21516;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#32771;&#34385;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#36890;&#20449;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#23548;&#20986;&#20102;&#21327;&#21516;&#23398;&#20064;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#26080;&#20154;&#26426;&#36712;&#36857;&#26469;&#25552;&#39640;&#35757;&#32451;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.02266</link><description>&lt;p&gt;
&#37319;&#29992;&#26426;&#36733;&#21327;&#35843;&#22120;&#36827;&#34892;&#21327;&#21516;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Collaborative Learning with a Drone Orchestrator. (arXiv:2303.02266v2 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#20154;&#26426;&#36741;&#21161;&#30340;&#21327;&#21516;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26234;&#33021;&#35774;&#22791;&#32676;&#19982;&#26080;&#20154;&#26426;&#21327;&#21516;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#22312;&#32771;&#34385;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#36890;&#20449;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#23548;&#20986;&#20102;&#21327;&#21516;&#23398;&#20064;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#26080;&#20154;&#26426;&#36712;&#36857;&#26469;&#25552;&#39640;&#35757;&#32451;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#26080;&#20154;&#26426;&#36741;&#21161;&#21327;&#21516;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#31181;&#22330;&#26223;&#19979;&#65292;&#26234;&#33021;&#26080;&#32447;&#35774;&#22791;&#32676;&#36890;&#36807;&#26080;&#20154;&#26426;&#20849;&#21516;&#35757;&#32451;&#19968;&#20010;&#20849;&#20139;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#27599;&#20010;&#35774;&#22791;&#20351;&#29992;&#20854;&#20256;&#24863;&#22120;&#35760;&#24405;&#26469;&#33258;&#29615;&#22659;&#30340;&#26679;&#26412;&#65292;&#20197;&#33719;&#21462;&#29992;&#20110;&#35757;&#32451;&#30340;&#26412;&#22320;&#25968;&#25454;&#38598;&#12290;&#30001;&#20110;&#21508;&#35774;&#22791;&#30340;&#25968;&#25454;&#37327;&#21644;&#20256;&#24863;&#22120;&#22122;&#22768;&#27700;&#24179;&#19981;&#21516;&#65292;&#35757;&#32451;&#25968;&#25454;&#20855;&#26377;&#20005;&#37325;&#30340;&#24322;&#36136;&#24615;&#12290;&#26234;&#33021;&#35774;&#22791;&#23545;&#20854;&#26412;&#22320;&#25968;&#25454;&#38598;&#36827;&#34892;&#36845;&#20195;&#35757;&#32451;&#65292;&#24182;&#23558;&#27169;&#22411;&#21442;&#25968;&#19982;&#26080;&#20154;&#26426;&#36827;&#34892;&#20132;&#25442;&#20197;&#36827;&#34892;&#32858;&#21512;&#12290;&#22312;&#32771;&#34385;&#25968;&#25454;&#24322;&#36136;&#24615;&#12289;&#20256;&#24863;&#22120;&#22122;&#22768;&#27700;&#24179;&#21644;&#36890;&#20449;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#65292;&#23548;&#20986;&#20102;&#21327;&#21516;&#23398;&#20064;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#33719;&#24471;&#20102;&#26368;&#22823;&#21270;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#32456;&#20934;&#30830;&#29575;&#30340;&#26080;&#20154;&#26426;&#36712;&#36857;&#12290;&#25152;&#25552;&#20986;&#30340;&#36712;&#36857;&#20248;&#21270;&#26041;&#27861;&#32771;&#34385;&#20102;&#35774;&#22791;&#30340;&#25968;&#25454;&#29305;&#24615;&#65288;&#21363;&#26412;&#22320;&#25968;&#25454;&#38598;&#22823;&#23567;&#21644;&#22122;&#22768;&#27700;&#24179;&#65289;&#20197;&#21450;&#20854;&#26080;&#32447;&#36890;&#20449;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, the problem of drone-assisted collaborative learning is considered. In this scenario, swarm of intelligent wireless devices train a shared neural network (NN) model with the help of a drone. Using its sensors, each device records samples from its environment to gather a local dataset for training. The training data is severely heterogeneous as various devices have different amount of data and sensor noise level. The intelligent devices iteratively train the NN on their local datasets and exchange the model parameters with the drone for aggregation. For this system, the convergence rate of collaborative learning is derived while considering data heterogeneity, sensor noise levels, and communication errors, then, the drone trajectory that maximizes the final accuracy of the trained NN is obtained. The proposed trajectory optimization approach is aware of both the devices data characteristics (i.e., local dataset size and noise level) and their wireless channel conditions, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.13349</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#23454;&#29616;&#26080;&#32422;&#26463;&#21160;&#24577;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#22312;&#20004;&#20010;&#38382;&#39064;&#32467;&#26500;&#30340;&#32806;&#21512;&#19979;&#30340;&#24773;&#20917;&#65306;&#22495;&#26080;&#30028;&#65292;&#32780;&#31639;&#27861;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#26469;&#34913;&#37327;&#30340;&#12290;&#22788;&#29702;&#20219;&#19968;&#38382;&#39064;&#37117;&#35201;&#27714;&#36951;&#25022;&#30028;&#38480;&#20381;&#36182;&#20110;&#27604;&#36739;&#24207;&#21015;&#30340;&#26576;&#20123;&#22797;&#26434;&#24230;&#37327;&#24230; - &#29305;&#21035;&#26159;&#26080;&#32422;&#26463;OLO&#20013;&#30340;&#27604;&#36739;&#22120;&#33539;&#25968;&#65292;&#20197;&#21450;&#21160;&#24577;&#36951;&#25022;&#20013;&#30340;&#36335;&#24452;&#38271;&#24230;&#12290;&#19982;&#26368;&#36817;&#19968;&#31687;&#25991;&#31456;(Jacobsen&amp; Cutkosky&#65292;2022)&#36866;&#24212;&#36825;&#20004;&#20010;&#22797;&#26434;&#24230;&#37327;&#24230;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#12290;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;&#23454;&#29616;&#36866;&#24212;&#24615;&#65292;&#36825;&#20010;&#26694;&#26550;&#33258;&#28982;&#22320;&#21033;&#29992;&#20102;&#29615;&#22659;&#26356;&#22797;&#26434;&#30340;&#21069;&#32622;&#30693;&#35782;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38745;&#24577;&#26080;&#32422;&#26463;OLO&#26799;&#24230;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#26426;&#21046;&#35774;&#35745;&#12290;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen &amp; Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#8212;&#8212;&#36870;&#26680;&#20998;&#35299;&#65288;IKD&#65289;&#65292;&#36890;&#36807;&#29305;&#24449;&#20540;&#20998;&#35299;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#23454;&#29616;&#12290;&#35813;&#26041;&#27861;&#21463;&#21040;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;GPLVMs&#65289;&#30340;&#21551;&#21457;&#65292;&#24182;&#22312;&#22788;&#29702;&#22122;&#22768;&#25968;&#25454;&#26041;&#38754;&#25552;&#20379;&#20102;&#20004;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.05961</link><description>&lt;p&gt;
&#21453;&#21521;&#26680;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Inverse Kernel Decomposition. (arXiv:2211.05961v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#8212;&#8212;&#36870;&#26680;&#20998;&#35299;&#65288;IKD&#65289;&#65292;&#36890;&#36807;&#29305;&#24449;&#20540;&#20998;&#35299;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#23454;&#29616;&#12290;&#35813;&#26041;&#27861;&#21463;&#21040;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;GPLVMs&#65289;&#30340;&#21551;&#21457;&#65292;&#24182;&#22312;&#22788;&#29702;&#22122;&#22768;&#25968;&#25454;&#26041;&#38754;&#25552;&#20379;&#20102;&#20004;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#38477;&#32500;&#26041;&#27861;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#22797;&#26434;&#30340;&#20248;&#21270;&#36807;&#31243;&#12290;&#32780;&#20165;&#38656;&#29305;&#24449;&#20540;&#20998;&#35299;&#30340;&#38381;&#24335;&#26041;&#27861;&#22312;&#22797;&#26434;&#24615;&#21644;&#38750;&#32447;&#24615;&#26041;&#38754;&#19981;&#22815;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#8212;&#8212;&#36870;&#26680;&#20998;&#35299;&#65288;IKD&#65289;&#65292;&#22522;&#20110;&#25968;&#25454;&#30340;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#20998;&#35299;&#12290;&#35813;&#26041;&#27861;&#21463;&#21040;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;GPLVMs&#65289;&#30340;&#21551;&#21457;&#65292;&#20855;&#26377;&#19982;GPLVMs&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#22788;&#29702;&#20855;&#26377;&#36739;&#24369;&#30456;&#20851;&#24615;&#30340;&#22122;&#22768;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#35299;&#20915;&#26041;&#26696;&#8212;&#8212;&#20998;&#22359;&#21644;&#27979;&#22320;&#32447;&#8212;&#8212;&#20197;&#21033;&#29992;&#23616;&#37096;&#30456;&#20851;&#30340;&#25968;&#25454;&#28857;&#24182;&#25552;&#20379;&#26356;&#22909;&#21644;&#25968;&#20540;&#19978;&#26356;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#20272;&#35745;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#34920;&#26126;&#65292;IKD&#26159;&#19968;&#31181;&#27604;&#20854;&#20182;&#22522;&#20110;&#29305;&#24449;&#20540;&#20998;&#35299;&#30340;&#26041;&#27861;&#26356;&#22909;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#20248;&#21270;&#26041;&#27861;&#26041;&#38754;&#20855;&#26377;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The state-of-the-art dimensionality reduction approaches largely rely on complicated optimization procedures. On the other hand, closed-form approaches requiring merely eigen-decomposition do not have enough sophistication and nonlinearity. In this paper, we propose a novel nonlinear dimensionality reduction method -- Inverse Kernel Decomposition (IKD) -- based on an eigen-decomposition of the sample covariance matrix of data. The method is inspired by Gaussian process latent variable models (GPLVMs) and has comparable performance with GPLVMs. To deal with very noisy data with weak correlations, we propose two solutions -- blockwise and geodesic -- to make use of locally correlated data points and provide better and numerically more stable latent estimations. We use synthetic datasets and four real-world datasets to show that IKD is a better dimensionality reduction method than other eigen-decomposition-based methods, and achieves comparable performance against optimization-based metho
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#23398;&#20064;&#20013;&#23384;&#22312;&#19968;&#20010;&#31616;&#21333;&#32780;&#23450;&#37327;&#30340;&#25968;&#25454;&#20998;&#31163;&#23450;&#24459;&#65292;&#27599;&#19968;&#23618;&#37117;&#20197;&#24658;&#23450;&#30340;&#20960;&#20309;&#36895;&#29575;&#25913;&#21892;&#25968;&#25454;&#30340;&#20998;&#31163;&#31243;&#24230;&#12290;&#36825;&#20010;&#23450;&#24459;&#20026;&#26550;&#26500;&#35774;&#35745;&#12289;&#25552;&#39640;&#27169;&#22411;&#30340;&#20581;&#22766;&#24615;&#21644;&#26679;&#26412;&#22806;&#24615;&#33021;&#20197;&#21450;&#39044;&#27979;&#30340;&#35299;&#37322;&#25552;&#20379;&#20102;&#23454;&#38469;&#30340;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2210.17020</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25968;&#25454;&#20998;&#31163;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
A Law of Data Separation in Deep Learning. (arXiv:2210.17020v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17020
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#23384;&#22312;&#19968;&#20010;&#31616;&#21333;&#32780;&#23450;&#37327;&#30340;&#25968;&#25454;&#20998;&#31163;&#23450;&#24459;&#65292;&#27599;&#19968;&#23618;&#37117;&#20197;&#24658;&#23450;&#30340;&#20960;&#20309;&#36895;&#29575;&#25913;&#21892;&#25968;&#25454;&#30340;&#20998;&#31163;&#31243;&#24230;&#12290;&#36825;&#20010;&#23450;&#24459;&#20026;&#26550;&#26500;&#35774;&#35745;&#12289;&#25552;&#39640;&#27169;&#22411;&#30340;&#20581;&#22766;&#24615;&#21644;&#26679;&#26412;&#22806;&#24615;&#33021;&#20197;&#21450;&#39044;&#27979;&#30340;&#35299;&#37322;&#25552;&#20379;&#20102;&#23454;&#38469;&#30340;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#28145;&#24230;&#23398;&#20064;&#22312;&#31185;&#23398;&#30340;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#20854;&#40657;&#30418;&#29305;&#24615;&#38459;&#30861;&#20102;&#26410;&#26469;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#30340;&#26550;&#26500;&#35774;&#35745;&#21644;&#39640;&#39118;&#38505;&#20915;&#31574;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20013;&#38388;&#23618;&#20013;&#22914;&#20309;&#22788;&#29702;&#25968;&#25454;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26159;&#19968;&#20010;&#31616;&#21333;&#32780;&#23450;&#37327;&#30340;&#23450;&#24459;&#65292;&#23427;&#35268;&#23450;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#26681;&#25454;&#31867;&#21035;&#25104;&#21592;&#23558;&#25968;&#25454;&#22312;&#25152;&#26377;&#23618;&#20013;&#20998;&#31163;&#20986;&#26469;&#36827;&#34892;&#20998;&#31867;&#12290;&#36825;&#20010;&#23450;&#24459;&#34920;&#26126;&#65292;&#27599;&#19968;&#23618;&#37117;&#20197;&#24658;&#23450;&#30340;&#20960;&#20309;&#36895;&#29575;&#25913;&#21892;&#25968;&#25454;&#30340;&#20998;&#31163;&#31243;&#24230;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#20102;&#23427;&#30340;&#20986;&#29616;&#65292;&#26080;&#35770;&#26159;&#22312;&#19968;&#31995;&#21015;&#32593;&#32476;&#26550;&#26500;&#36824;&#26159;&#25968;&#25454;&#38598;&#19978;&#12290;&#36825;&#20010;&#23450;&#24459;&#20026;&#26550;&#26500;&#35774;&#35745;&#12289;&#25552;&#39640;&#27169;&#22411;&#30340;&#20581;&#22766;&#24615;&#21644;&#26679;&#26412;&#22806;&#24615;&#33021;&#20197;&#21450;&#39044;&#27979;&#30340;&#35299;&#37322;&#25552;&#20379;&#20102;&#23454;&#38469;&#30340;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
While deep learning has enabled significant advances in many areas of science, its black-box nature hinders architecture design for future artificial intelligence applications and interpretation for high-stakes decision makings. We addressed this issue by studying the fundamental question of how deep neural networks process data in the intermediate layers. Our finding is a simple and quantitative law that governs how deep neural networks separate data according to class membership throughout all layers for classification. This law shows that each layer improves data separation at a constant geometric rate, and its emergence is observed in a collection of network architectures and datasets during training. This law offers practical guidelines for designing architectures, improving model robustness and out-of-sample performance, as well as interpreting the predictions.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;-&#23545;&#25239;&#31232;&#30095;&#24615;&#65292;&#23427;&#37327;&#21270;&#20102;&#25104;&#21151;&#25200;&#21160;&#30340;&#38590;&#24230;&#12290;&#31232;&#30095;&#24615;&#25581;&#31034;&#20102;&#40065;&#26834;&#27169;&#22411;&#20043;&#38388;&#30340;&#37325;&#35201;&#24046;&#24322;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.04129</link><description>&lt;p&gt;
&#36825;&#20010;&#27169;&#22411;&#26377;&#22810;&#23569;&#25200;&#21160;&#20250;&#30772;&#22351;&#23427;&#65311;&#35780;&#20272;&#36229;&#36234;&#23545;&#25239;&#20934;&#30830;&#24230;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
How many perturbations break this model? Evaluating robustness beyond adversarial accuracy. (arXiv:2207.04129v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04129
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#35780;&#20272;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;-&#23545;&#25239;&#31232;&#30095;&#24615;&#65292;&#23427;&#37327;&#21270;&#20102;&#25104;&#21151;&#25200;&#21160;&#30340;&#38590;&#24230;&#12290;&#31232;&#30095;&#24615;&#25581;&#31034;&#20102;&#40065;&#26834;&#27169;&#22411;&#20043;&#38388;&#30340;&#37325;&#35201;&#24046;&#24322;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#36890;&#24120;&#36890;&#36807;&#23545;&#25239;&#20934;&#30830;&#24230;&#26469;&#35780;&#20272;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#24230;&#37327;&#26631;&#20934;&#24182;&#19981;&#33021;&#23436;&#20840;&#25429;&#25417;&#21040;&#40065;&#26834;&#24615;&#30340;&#25152;&#26377;&#26041;&#38754;&#65292;&#23588;&#20854;&#26159;&#24573;&#30053;&#20102;&#38024;&#23545;&#27599;&#20010;&#25968;&#25454;&#28857;&#21487;&#20197;&#25214;&#21040;&#22810;&#23569;&#25200;&#21160;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#21363;&#23545;&#25239;&#31232;&#30095;&#24615;&#65292;&#23427;&#37327;&#21270;&#20102;&#22312;&#32473;&#23450;&#36755;&#20837;&#28857;&#21644;&#25200;&#21160;&#26041;&#21521;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#25104;&#21151;&#25200;&#21160;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31232;&#30095;&#24615;&#22312;&#22810;&#20010;&#26041;&#38754;&#23545;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#23519;&#21147;&#65306;&#20363;&#22914;&#65292;&#23427;&#25581;&#31034;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#40065;&#26834;&#27169;&#22411;&#20043;&#38388;&#30340;&#37325;&#35201;&#24046;&#24322;&#65292;&#36825;&#26159;&#31934;&#30830;&#24230;&#20998;&#26512;&#25152;&#19981;&#20855;&#22791;&#30340;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#25552;&#39640;&#23427;&#20204;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#12290;&#24403;&#24212;&#29992;&#23545;&#24369;&#25915;&#20987;&#26377;&#25928;&#20294;&#23545;&#24378;&#25915;&#20987;&#26080;&#25928;&#30340;&#30772;&#35299;&#38450;&#24481;&#26102;&#65292;&#31232;&#30095;&#24615;&#21487;&#20197;&#21306;&#20998;&#23436;&#20840;&#26080;&#25928;&#21644;&#37096;&#20998;&#26377;&#25928;&#30340;&#38450;&#24481;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#31232;&#30095;&#24615;&#65292;&#25105;&#20204;&#21487;&#20197;&#24230;&#37327;&#40065;&#26834;&#24615;&#30340;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robustness to adversarial attacks is typically evaluated with adversarial accuracy. While essential, this metric does not capture all aspects of robustness and in particular leaves out the question of how many perturbations can be found for each point. In this work, we introduce an alternative approach, adversarial sparsity, which quantifies how difficult it is to find a successful perturbation given both an input point and a constraint on the direction of the perturbation. We show that sparsity provides valuable insight into neural networks in multiple ways: for instance, it illustrates important differences between current state-of-the-art robust models them that accuracy analysis does not, and suggests approaches for improving their robustness. When applying broken defenses effective against weak attacks but not strong ones, sparsity can discriminate between the totally ineffective and the partially effective defenses. Finally, with sparsity we can measure increases in robustness th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#21644;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#20132;&#20998;&#35299;&#24314;&#27169;&#22810;&#35270;&#22270;&#29305;&#24449;&#36873;&#25321;&#65292;&#24212;&#29992;&#36328;&#31354;&#38388;&#23616;&#37096;&#20445;&#25345;&#36827;&#34892;&#32858;&#31867;&#32467;&#26500;&#23398;&#20064;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2204.08247</link><description>&lt;p&gt;
&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#19982;&#22270;&#23398;&#20064;&#30340;&#32852;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Joint Multi-view Unsupervised Feature Selection and Graph Learning. (arXiv:2204.08247v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.08247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#21644;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#20132;&#20998;&#35299;&#24314;&#27169;&#22810;&#35270;&#22270;&#29305;&#24449;&#36873;&#25321;&#65292;&#24212;&#29992;&#36328;&#31354;&#38388;&#23616;&#37096;&#20445;&#25345;&#36827;&#34892;&#32858;&#31867;&#32467;&#26500;&#23398;&#20064;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21462;&#24471;&#20102;&#19968;&#23450;&#30340;&#36827;&#23637;&#65292;&#20294;&#20043;&#21069;&#30340;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20027;&#35201;&#23384;&#22312;&#20004;&#20010;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#23427;&#20204;&#36890;&#24120;&#20351;&#29992;&#32858;&#31867;&#32467;&#26500;&#25110;&#30456;&#20284;&#24615;&#32467;&#26500;&#26469;&#25351;&#23548;&#29305;&#24449;&#36873;&#25321;&#65292;&#24573;&#30053;&#20102;&#32852;&#21512;&#20844;&#24335;&#21487;&#33021;&#24102;&#26469;&#30340;&#20114;&#24800;&#25928;&#30410;&#12290;&#20854;&#27425;&#65292;&#23427;&#20204;&#36890;&#24120;&#36890;&#36807;&#20840;&#23616;&#32467;&#26500;&#23398;&#20064;&#25110;&#23616;&#37096;&#32467;&#26500;&#23398;&#20064;&#26469;&#23398;&#20064;&#30456;&#20284;&#24615;&#32467;&#26500;&#65292;&#32570;&#20047;&#21516;&#26102;&#20855;&#22791;&#20840;&#23616;&#21644;&#23616;&#37096;&#32467;&#26500;&#24863;&#30693;&#30340;&#22270;&#23398;&#20064;&#33021;&#21147;&#12290;&#37492;&#20110;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#22810;&#35270;&#22270;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#21644;&#22270;&#23398;&#20064;&#30340;&#26041;&#27861;&#65288;JMVFG&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#37319;&#29992;&#27491;&#20132;&#20998;&#35299;&#23545;&#22810;&#35270;&#22270;&#29305;&#24449;&#36873;&#25321;&#36827;&#34892;&#24314;&#27169;&#65292;&#20854;&#20013;&#27599;&#20010;&#30446;&#26631;&#30697;&#38453;&#34987;&#20998;&#35299;&#20026;&#19968;&#20010;&#35270;&#22270;&#29305;&#23450;&#30340;&#22522;&#30697;&#38453;&#21644;&#19968;&#20010;&#35270;&#22270;&#19968;&#33268;&#30340;&#32858;&#31867;&#25351;&#31034;&#22120;&#12290;&#36328;&#31354;&#38388;&#23616;&#37096;&#20445;&#25345;&#34987;&#24212;&#29992;&#20110;&#22312;&#25237;&#24433;&#31354;&#38388;&#20013;&#36827;&#34892;&#32858;&#31867;&#32467;&#26500;&#23398;&#20064;&#21644;&#30456;&#20284;&#24615;&#23398;&#20064;&#30340;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite significant progress, previous multi-view unsupervised feature selection methods mostly suffer from two limitations. First, they generally utilize either cluster structure or similarity structure to guide the feature selection, which neglect the possibility of a joint formulation with mutual benefits. Second, they often learn the similarity structure by either global structure learning or local structure learning, which lack the capability of graph learning with both global and local structural awareness. In light of this, this paper presents a joint multi-view unsupervised feature selection and graph learning (JMVFG) approach. Particularly, we formulate the multi-view feature selection with orthogonal decomposition, where each target matrix is decomposed into a view-specific basis matrix and a view-consistent cluster indicator. The cross-space locality preservation is incorporated to bridge the cluster structure learning in the projected space and the similarity learning (i.e.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#23545;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#27169;&#22411;&#19979;&#37051;&#25509;&#30697;&#38453;&#30340;&#21463;&#38480;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.07831</link><description>&lt;p&gt;
&#22270;&#24418;&#31070;&#32463;&#32593;&#32476;&#22312;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Network Sensitivity Under Probabilistic Error Model. (arXiv:2203.07831v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.07831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#23545;&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20102;&#35823;&#24046;&#27169;&#22411;&#19979;&#37051;&#25509;&#30697;&#38453;&#30340;&#21463;&#38480;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#31181;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#20102;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21487;&#20197;&#36890;&#36807;&#22270;&#21367;&#31215;&#25104;&#21151;&#23398;&#20064;&#22270;&#20449;&#21495;&#34920;&#31034;&#12290;&#22270;&#21367;&#31215;&#20381;&#36182;&#20110;&#22270;&#28388;&#27874;&#22120;&#65292;&#20854;&#20013;&#21253;&#21547;&#25968;&#25454;&#30340;&#25299;&#25169;&#20381;&#36182;&#20851;&#31995;&#24182;&#20256;&#25773;&#25968;&#25454;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#22312;&#20256;&#25773;&#30697;&#38453;&#65288;&#20363;&#22914;&#37051;&#25509;&#30697;&#38453;&#65289;&#20013;&#30340;&#20272;&#35745;&#35823;&#24046;&#21487;&#33021;&#23545;&#22270;&#28388;&#27874;&#22120;&#21644;GCNs&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#26412;&#25991;&#30740;&#31350;&#27010;&#29575;&#22270;&#35823;&#24046;&#27169;&#22411;&#23545;GCN&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#37051;&#25509;&#30697;&#38453;&#21463;&#21040;&#22270;&#22823;&#23567;&#21644;&#35823;&#24046;&#27010;&#29575;&#20989;&#25968;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#24102;&#26377;&#33258;&#24490;&#29615;&#30340;&#24402;&#19968;&#21270;&#37051;&#25509;&#30697;&#38453;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#23454;&#39564;&#26469;&#35828;&#26126;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#30740;&#31350;&#31616;&#21333;GCN&#22312;&#36825;&#31181;&#27010;&#29575;&#35823;&#24046;&#27169;&#22411;&#19979;&#30340;&#20934;&#30830;&#24615;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph convolutional networks (GCNs) can successfully learn the graph signal representation by graph convolution. The graph convolution depends on the graph filter, which contains the topological dependency of data and propagates data features. However, the estimation errors in the propagation matrix (e.g., the adjacency matrix) can have a significant impact on graph filters and GCNs. In this paper, we study the effect of a probabilistic graph error model on the performance of the GCNs. We prove that the adjacency matrix under the error model is bounded by a function of graph size and error probability. We further analytically specify the upper bound of a normalized adjacency matrix with self-loop added. Finally, we illustrate the error bounds by running experiments on a synthetic dataset and study the sensitivity of a simple GCN under this probabilistic error model on accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#21028;&#21035;&#24471;&#20998;&#30340;&#32479;&#19968;&#26041;&#27861;&#65292;&#29992;&#20110;&#36873;&#25321;&#32858;&#31867;&#25968;&#30446;&#12289;&#32858;&#31867;&#27169;&#22411;&#21644;&#31639;&#27861;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#22522;&#20110;&#20108;&#27425;&#21028;&#21035;&#24471;&#20998;&#20989;&#25968;&#21644;&#21442;&#25968;&#30340;&#21442;&#32771;&#32858;&#31867;&#27010;&#24565;&#65292;&#24182;&#24320;&#21457;&#20102;&#20004;&#20010;&#19968;&#33268;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#21487;&#20197;&#36890;&#36807;&#20108;&#27425;&#25110;&#32447;&#24615;&#36793;&#30028;&#24456;&#22909;&#20998;&#38548;&#30340;&#32676;&#32452;&#65292;&#23545;&#20110;&#24212;&#29992;&#20013;&#23547;&#25214;&#36825;&#31181;&#31867;&#22411;&#30340;&#32676;&#32452;&#24456;&#26377;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2111.02302</link><description>&lt;p&gt;
&#36873;&#25321;&#32858;&#31867;&#25968;&#30446;&#12289;&#32858;&#31867;&#27169;&#22411;&#21644;&#31639;&#27861;&#65306;&#22522;&#20110;&#20108;&#27425;&#21028;&#21035;&#24471;&#20998;&#30340;&#32479;&#19968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Selecting the number of clusters, clustering models, and algorithms. A unifying approach based on the quadratic discriminant score. (arXiv:2111.02302v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.02302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#21028;&#21035;&#24471;&#20998;&#30340;&#32479;&#19968;&#26041;&#27861;&#65292;&#29992;&#20110;&#36873;&#25321;&#32858;&#31867;&#25968;&#30446;&#12289;&#32858;&#31867;&#27169;&#22411;&#21644;&#31639;&#27861;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#22522;&#20110;&#20108;&#27425;&#21028;&#21035;&#24471;&#20998;&#20989;&#25968;&#21644;&#21442;&#25968;&#30340;&#21442;&#32771;&#32858;&#31867;&#27010;&#24565;&#65292;&#24182;&#24320;&#21457;&#20102;&#20004;&#20010;&#19968;&#33268;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#21487;&#20197;&#36890;&#36807;&#20108;&#27425;&#25110;&#32447;&#24615;&#36793;&#30028;&#24456;&#22909;&#20998;&#38548;&#30340;&#32676;&#32452;&#65292;&#23545;&#20110;&#24212;&#29992;&#20013;&#23547;&#25214;&#36825;&#31181;&#31867;&#22411;&#30340;&#32676;&#32452;&#24456;&#26377;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#20998;&#26512;&#38656;&#35201;&#20570;&#20986;&#35768;&#22810;&#20915;&#31574;&#65306;&#32858;&#31867;&#26041;&#27861;&#21644;&#38544;&#21547;&#30340;&#21442;&#32771;&#27169;&#22411;&#12289;&#32858;&#31867;&#25968;&#30446;&#65292;&#20197;&#21450;&#36890;&#24120;&#36824;&#26377;&#19968;&#20123;&#36229;&#21442;&#25968;&#21644;&#31639;&#27861;&#30340;&#35843;&#25972;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#20250;&#24471;&#21040;&#22810;&#20010;&#21010;&#20998;&#65292;&#26368;&#32456;&#26681;&#25454;&#39564;&#35777;&#25110;&#36873;&#25321;&#20934;&#21017;&#36873;&#25321;&#19968;&#20010;&#26368;&#32456;&#30340;&#21010;&#20998;&#12290;&#23384;&#22312;&#22823;&#37327;&#30340;&#39564;&#35777;&#26041;&#27861;&#65292;&#23427;&#20204;&#38544;&#24335;&#25110;&#26174;&#24335;&#22320;&#20551;&#35774;&#26576;&#31181;&#32858;&#31867;&#27010;&#24565;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#24120;&#24120;&#34987;&#38480;&#21046;&#22312;&#29305;&#23450;&#26041;&#27861;&#24471;&#21040;&#30340;&#21010;&#20998;&#19978;&#36827;&#34892;&#25805;&#20316;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#21487;&#20197;&#36890;&#36807;&#20108;&#27425;&#25110;&#32447;&#24615;&#36793;&#30028;&#24456;&#22909;&#20998;&#38548;&#30340;&#32676;&#32452;&#12290;&#22522;&#20110;&#20108;&#27425;&#21028;&#21035;&#24471;&#20998;&#20989;&#25968;&#21644;&#25551;&#36848;&#32858;&#31867;&#22823;&#23567;&#12289;&#20013;&#24515;&#21644;&#25955;&#24067;&#30340;&#21442;&#25968;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#21442;&#32771;&#32858;&#31867;&#27010;&#24565;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#20010;&#32858;&#31867;&#36136;&#37327;&#20934;&#21017;&#65292;&#31216;&#20026;&#20108;&#27425;&#24471;&#20998;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20934;&#21017;&#19982;&#19968;&#33324;&#31867;&#21035;&#30340;&#26925;&#22278;&#23545;&#31216;&#20998;&#24067;&#29983;&#25104;&#30340;&#32676;&#32452;&#19968;&#33268;&#12290;&#22312;&#24212;&#29992;&#20013;&#65292;&#23547;&#25214;&#36825;&#31181;&#31867;&#22411;&#30340;&#32676;&#32452;&#26159;&#24120;&#35265;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cluster analysis requires many decisions: the clustering method and the implied reference model, the number of clusters and, often, several hyper-parameters and algorithms' tunings. In practice, one produces several partitions, and a final one is chosen based on validation or selection criteria. There exist an abundance of validation methods that, implicitly or explicitly, assume a certain clustering notion. Moreover, they are often restricted to operate on partitions obtained from a specific method. In this paper, we focus on groups that can be well separated by quadratic or linear boundaries. The reference cluster concept is defined through the quadratic discriminant score function and parameters describing clusters' size, center and scatter. We develop two cluster-quality criteria called quadratic scores. We show that these criteria are consistent with groups generated from a general class of elliptically-symmetric distributions. The quest for this type of groups is common in applic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#23545;&#20110;&#20855;&#26377;&#20004;&#20010;&#20219;&#21153;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#24120;&#29992;&#20272;&#35745;&#37327;&#30340;&#36229;&#39069;&#39118;&#38505;&#36827;&#34892;&#20102;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2010.11750</link><description>&lt;p&gt;
&#37327;&#21270;&#24322;&#26500;&#36716;&#31227;&#30340;&#31934;&#30830;&#39640;&#32500;&#28176;&#36817;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Precise High-Dimensional Asymptotics for Quantifying Heterogeneous Transfers. (arXiv:2010.11750v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.11750
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#23545;&#20110;&#20855;&#26377;&#20004;&#20010;&#20219;&#21153;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#24120;&#29992;&#20272;&#35745;&#37327;&#30340;&#36229;&#39069;&#39118;&#38505;&#36827;&#34892;&#20102;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#26102;&#20351;&#29992;&#26469;&#33258;&#21478;&#19968;&#20010;&#20219;&#21153;&#30340;&#26679;&#26412;&#30340;&#38382;&#39064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#20160;&#20040;&#26102;&#20505;&#23558;&#26469;&#33258;&#20004;&#20010;&#20219;&#21153;&#30340;&#25968;&#25454;&#21512;&#24182;&#27604;&#21333;&#29420;&#23398;&#20064;&#19968;&#20010;&#20219;&#21153;&#26356;&#22909;&#65311;&#30452;&#35266;&#19978;&#65292;&#20174;&#19968;&#20010;&#20219;&#21153;&#21040;&#21478;&#19968;&#20010;&#20219;&#21153;&#30340;&#36716;&#31227;&#25928;&#24212;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#36716;&#31227;&#65292;&#22914;&#26679;&#26412;&#22823;&#23567;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#28982;&#32780;&#65292;&#37327;&#21270;&#36825;&#31181;&#36716;&#31227;&#25928;&#24212;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#38656;&#35201;&#27604;&#36739;&#32852;&#21512;&#23398;&#20064;&#21644;&#21333;&#20219;&#21153;&#23398;&#20064;&#20043;&#38388;&#30340;&#39118;&#38505;&#65292;&#24182;&#19988;&#19968;&#20010;&#20219;&#21153;&#26159;&#21542;&#27604;&#21478;&#19968;&#20010;&#20219;&#21153;&#20855;&#26377;&#27604;&#36739;&#20248;&#21183;&#21462;&#20915;&#20110;&#20004;&#20010;&#20219;&#21153;&#20043;&#38388;&#30830;&#20999;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#31867;&#22411;&#12290;&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#22312;&#20855;&#26377;&#20004;&#20010;&#20219;&#21153;&#30340;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#35299;&#20915;&#20102;&#36825;&#19968;&#25361;&#25112;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#19968;&#20123;&#24120;&#29992;&#20272;&#35745;&#37327;&#30340;&#36229;&#39069;&#39118;&#38505;&#30340;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#65292;&#24403;&#26679;&#26412;&#22823;&#23567;&#19982;&#29305;&#24449;&#32500;&#24230;&#25104;&#27604;&#20363;&#22686;&#21152;&#26102;&#65292;&#22266;&#23450;&#27604;&#20363;&#12290;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#20197;&#26679;&#26412;&#22823;&#23567;&#30340;&#20989;&#25968;&#24418;&#24335;&#32473;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of learning one task with samples from another task has received much interest recently. In this paper, we ask a fundamental question: when is combining data from two tasks better than learning one task alone? Intuitively, the transfer effect from one task to another task depends on dataset shifts such as sample sizes and covariance matrices. However, quantifying such a transfer effect is challenging since we need to compare the risks between joint learning and single-task learning, and the comparative advantage of one over the other depends on the exact kind of dataset shift between both tasks. This paper uses random matrix theory to tackle this challenge in a linear regression setting with two tasks. We give precise asymptotics about the excess risks of some commonly used estimators in the high-dimensional regime, when the sample sizes increase proportionally with the feature dimension at fixed ratios. The precise asymptotics is provided as a function of the sample sizes 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36867;&#36920;&#35757;&#32451;GAN&#20013;&#30340;&#26497;&#38480;&#21608;&#26399;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#31163;&#24515;&#21152;&#36895;&#24230;&#31639;&#27861;&#65288;PCAA&#65289;&#21644;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#31639;&#27861;&#65288;Adam&#65289;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#25913;&#21892;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#26497;&#38480;&#21608;&#26399;&#34892;&#20026;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2010.03322</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36867;&#36920;&#35757;&#32451;GAN&#20013;&#30340;&#26497;&#38480;&#21608;&#26399;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A method for escaping limit cycles in training GANs. (arXiv:2010.03322v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.03322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36867;&#36920;&#35757;&#32451;GAN&#20013;&#30340;&#26497;&#38480;&#21608;&#26399;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#31163;&#24515;&#21152;&#36895;&#24230;&#31639;&#27861;&#65288;PCAA&#65289;&#21644;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#31639;&#27861;&#65288;Adam&#65289;&#30456;&#32467;&#21512;&#65292;&#26377;&#25928;&#25913;&#21892;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#26497;&#38480;&#21608;&#26399;&#34892;&#20026;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#39044;&#27979;&#31163;&#24515;&#21152;&#36895;&#24230;&#31639;&#27861;&#65288;PCAA&#65289;&#65292;&#23545;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#20013;&#26497;&#38480;&#21608;&#26399;&#34892;&#20026;&#38382;&#39064;&#36827;&#34892;&#28145;&#20837;&#30740;&#31350;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;PCAA&#22312;&#19968;&#33324;&#21452;&#32447;&#24615;&#21338;&#24328;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#36895;&#29575;&#30340;&#19978;&#19979;&#30028;&#65292;&#22312;&#19978;&#30028;&#26041;&#38754;&#24471;&#21040;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;PCAA&#19982;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#31639;&#27861;&#65288;Adam&#65289;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35757;&#32451;GANs&#30340;&#23454;&#29992;&#26041;&#27861;PCAA-Adam&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21452;&#32447;&#24615;&#21338;&#24328;&#12289;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#21644;CelebA&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper mainly conducts further research to alleviate the issue of limit cycling behavior in training generative adversarial networks (GANs) through the proposed predictive centripetal acceleration algorithm (PCAA). Specifically, we first derive the upper and lower bounds on the last-iterate convergence rates of PCAA for the general bilinear game, with the upper bound notably improving upon previous results. Then, we combine PCAA with the adaptive moment estimation algorithm (Adam) to propose PCAA-Adam, a practical approach for training GANs. Finally, we validate the effectiveness of the proposed algorithm through experiments conducted on bilinear games, multivariate Gaussian distributions, and the CelebA dataset, respectively.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20154;&#24037;&#31070;&#32463;&#20803;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#31070;&#32463;&#20803;&#23398;&#20064;&#38750;&#32447;&#24615;&#20915;&#31574;&#36793;&#30028;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2003.03229</link><description>&lt;p&gt;
&#20855;&#26377;&#31867;&#20154;&#31867;&#26641;&#31361;&#28608;&#27963;&#30340;&#38750;&#32447;&#24615;&#31070;&#32463;&#20803;
&lt;/p&gt;
&lt;p&gt;
Non-linear Neurons with Human-like Apical Dendrite Activations. (arXiv:2003.03229v4 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2003.03229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20154;&#24037;&#31070;&#32463;&#20803;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#31070;&#32463;&#20803;&#23398;&#20064;&#38750;&#32447;&#24615;&#20915;&#31574;&#36793;&#30028;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23545;&#32447;&#24615;&#19981;&#21487;&#20998;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#36890;&#24120;&#23558;&#31070;&#32463;&#20803;&#32452;&#32455;&#25104;&#33267;&#23569;&#21253;&#21547;&#19968;&#20010;&#38544;&#34255;&#23618;&#30340;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#21463;&#31070;&#32463;&#31185;&#23398;&#30340;&#19968;&#20123;&#26368;&#26032;&#21457;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20154;&#24037;&#31070;&#32463;&#20803;&#27169;&#22411;&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20351;&#29992;&#21333;&#20010;&#31070;&#32463;&#20803;&#23398;&#20064;&#38750;&#32447;&#24615;&#20915;&#31574;&#36793;&#30028;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#26631;&#20934;&#31070;&#32463;&#20803;&#25509;&#19978;&#25105;&#20204;&#30340;&#26032;&#22411;&#26641;&#31361;&#28608;&#27963;&#20989;&#25968;&#65288;ADA&#65289;&#21487;&#20197;&#20197;100%&#30340;&#20934;&#30830;&#29575;&#23398;&#20064;XOR&#36923;&#36753;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#20845;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#21363;MOROCO&#12289;UTKFace&#12289;CREMA-D&#12289;Fashion-MNIST&#12289;Tiny ImageNet&#21644;ImageNet&#65292;&#32467;&#26524;&#26174;&#31034;ADA&#21644;&#28431;&#30005;ADA&#20989;&#25968;&#22312;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65288;&#22914;&#19968;&#23618;&#25110;&#20004;&#23618;&#38544;&#34255;&#23618;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65289;&#19978;&#20248;&#20110;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#12289;&#28431;&#30005;ReLU&#12289;&#24452;&#21521;&#22522;&#20989;&#25968;&#65288;RBF&#65289;&#21644;Swish&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to classify linearly non-separable data, neurons are typically organized into multi-layer neural networks that are equipped with at least one hidden layer. Inspired by some recent discoveries in neuroscience, we propose a new model of artificial neuron along with a novel activation function enabling the learning of nonlinear decision boundaries using a single neuron. We show that a standard neuron followed by our novel apical dendrite activation (ADA) can learn the XOR logical function with 100% accuracy. Furthermore, we conduct experiments on six benchmark data sets from computer vision, signal processing and natural language processing, i.e. MOROCO, UTKFace, CREMA-D, Fashion-MNIST, Tiny ImageNet and ImageNet, showing that the ADA and the leaky ADA functions provide superior results to Rectified Linear Units (ReLU), leaky ReLU, RBF and Swish, for various neural network architectures, e.g. one-hidden-layer or two-hidden-layer multi-layer perceptrons (MLPs) and convolutional ne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;B&#20301;&#37327;&#21270;&#30340;&#38750;&#21442;&#25968;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#23545;&#26679;&#26412;&#36827;&#34892;&#37327;&#21270;&#22788;&#29702;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;B&#36229;&#36807;&#38408;&#20540;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26679;&#26465;&#27169;&#22411;&#20013;&#33021;&#22815;&#36798;&#21040;&#32463;&#20856;&#26497;&#23567;&#26497;&#20540;&#29575;&#30340;&#27979;&#35797;&#27700;&#24179;&#12290;&#21478;&#22806;&#65292;&#26412;&#25991;&#36824;&#25299;&#23637;&#20102;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#21253;&#25324;&#38750;&#21442;&#25968;&#30452;&#32447;&#24615;&#26816;&#39564;&#21644;&#33258;&#36866;&#24212;&#38750;&#21442;&#25968;&#26816;&#39564;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/1901.08571</link><description>&lt;p&gt;
B&#20301;&#37327;&#21270;&#19979;&#30340;&#38750;&#21442;&#25968;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Inference under B-bits Quantization. (arXiv:1901.08571v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1901.08571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;B&#20301;&#37327;&#21270;&#30340;&#38750;&#21442;&#25968;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#23545;&#26679;&#26412;&#36827;&#34892;&#37327;&#21270;&#22788;&#29702;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;B&#36229;&#36807;&#38408;&#20540;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26679;&#26465;&#27169;&#22411;&#20013;&#33021;&#22815;&#36798;&#21040;&#32463;&#20856;&#26497;&#23567;&#26497;&#20540;&#29575;&#30340;&#27979;&#35797;&#27700;&#24179;&#12290;&#21478;&#22806;&#65292;&#26412;&#25991;&#36824;&#25299;&#23637;&#20102;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#21253;&#25324;&#38750;&#21442;&#25968;&#30452;&#32447;&#24615;&#26816;&#39564;&#21644;&#33258;&#36866;&#24212;&#38750;&#21442;&#25968;&#26816;&#39564;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#21495;/&#22270;&#20687;&#22788;&#29702;&#12289;&#21307;&#23398;&#22270;&#20687;&#23384;&#20648;&#12289;&#36965;&#24863;&#12289;&#20449;&#21495;&#20256;&#36755;&#31561;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#24120;&#24120;&#38656;&#35201;&#22522;&#20110;&#26377;&#25439;&#25110;&#19981;&#23436;&#25972;&#26679;&#26412;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32463;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#23545;&#26679;&#26412;&#36827;&#34892;B&#20301;&#37327;&#21270;&#30340;&#38750;&#21442;&#25968;&#26816;&#39564;&#31243;&#24207;&#12290;&#22312;&#19968;&#20123;&#28201;&#21644;&#25216;&#26415;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#26816;&#39564;&#21151;&#29575;&#22312;B&#22686;&#21152;&#26102;&#30340;&#21464;&#21270;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#34920;&#26126;&#22914;&#26524;B&#36229;&#36807;&#26576;&#20010;&#38408;&#20540;&#65292;&#21017;&#25152;&#25552;&#20986;&#30340;&#38750;&#21442;&#25968;&#26816;&#39564;&#31243;&#24207;&#22312;&#26679;&#26465;&#27169;&#22411;&#20013;&#23454;&#29616;&#20102;&#32463;&#20856;&#26497;&#23567;&#26497;&#20540;&#29575;&#30340;&#27979;&#35797;&#65288;Shang&#21644;Cheng&#65292;2015&#65289;&#12290;&#25105;&#20204;&#36824;&#36827;&#19968;&#27493;&#23558;&#29702;&#35770;&#30740;&#31350;&#25193;&#23637;&#21040;&#20102;&#38750;&#21442;&#25968;&#30452;&#32447;&#24615;&#26816;&#39564;&#21644;&#33258;&#36866;&#24212;&#38750;&#21442;&#25968;&#26816;&#39564;&#65292;&#25299;&#23637;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#26469;&#35777;&#26126;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical inference based on lossy or incomplete samples is often needed in research areas such as signal/image processing, medical image storage, remote sensing, signal transmission. In this paper, we propose a nonparametric testing procedure based on samples quantized to $B$ bits through a computationally efficient algorithm. Under mild technical conditions, we establish the asymptotic properties of the proposed test statistic and investigate how the testing power changes as $B$ increases. In particular, we show that if $B$ exceeds a certain threshold, the proposed nonparametric testing procedure achieves the classical minimax rate of testing (Shang and Cheng, 2015) for spline models. We further extend our theoretical investigations to a nonparametric linearity test and an adaptive nonparametric test, expanding the applicability of the proposed methods. Extensive simulation studies {together with a real-data analysis} are used to demonstrate the validity and effectiveness of the pr
&lt;/p&gt;</description></item></channel></rss>