<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#21160;&#21147;&#31995;&#32479;&#20013;&#23398;&#20064;&#39044;&#27979;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#26469;&#37327;&#21270;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.06614</link><description>&lt;p&gt;
&#21160;&#21147;&#31995;&#32479;&#20013;&#39034;&#24207;&#39044;&#27979;&#30340;&#22797;&#26434;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Complexity of Sequential Prediction in Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06614
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#21160;&#21147;&#31995;&#32479;&#20013;&#23398;&#20064;&#39044;&#27979;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#26469;&#37327;&#21270;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24213;&#23618;&#28436;&#21270;&#20989;&#25968;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#39044;&#27979;&#21160;&#21147;&#31995;&#32479;&#19979;&#19968;&#29366;&#24577;&#30340;&#38382;&#39064;&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#23545;&#21160;&#21147;&#31995;&#32479;&#27809;&#26377;&#21442;&#25968;&#20551;&#35774;&#65292;&#24182;&#20174;&#23398;&#20064;&#29702;&#35770;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#35813;&#38382;&#39064;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#26032;&#30340;&#32452;&#21512;&#24230;&#37327;&#21644;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#21644;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#30340;&#26368;&#20339;&#38169;&#35823;&#21644;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning to predict the next state of a dynamical system when the underlying evolution function is unknown. Unlike previous work, we place no parametric assumptions on the dynamical system, and study the problem from a learning theory perspective. We define new combinatorial measures and dimensions and show that they quantify the optimal mistake and regret bounds in the realizable and agnostic setting respectively.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#22522;&#20110;&#32806;&#21512;&#30340;&#26631;&#20934;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#24067;&#26222;&#36866;&#24615;&#23450;&#29702;&#26469;&#20811;&#26381;&#20197;&#21069;&#24037;&#20316;&#30340;&#38480;&#21046;&#12290;&#36825;&#20123;&#32467;&#26524;&#25903;&#25345;&#32806;&#21512;&#26550;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#24357;&#34917;&#20102;&#23454;&#35777;&#32467;&#26524;&#21644;&#29702;&#35770;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.06578</link><description>&lt;p&gt;
&#20851;&#20110;&#22522;&#20110;&#32806;&#21512;&#30340;&#26631;&#20934;&#21270;&#27969;&#30340;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Universality of Coupling-based Normalizing Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06578
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#22522;&#20110;&#32806;&#21512;&#30340;&#26631;&#20934;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20998;&#24067;&#26222;&#36866;&#24615;&#23450;&#29702;&#26469;&#20811;&#26381;&#20197;&#21069;&#24037;&#20316;&#30340;&#38480;&#21046;&#12290;&#36825;&#20123;&#32467;&#26524;&#25903;&#25345;&#32806;&#21512;&#26550;&#26500;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#24357;&#34917;&#20102;&#23454;&#35777;&#32467;&#26524;&#21644;&#29702;&#35770;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#22522;&#20110;&#32806;&#21512;&#30340;&#26631;&#20934;&#21270;&#27969;&#65288;&#22914;RealNVP&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23613;&#31649;&#32806;&#21512;&#27969;&#22312;&#31185;&#23398;&#24212;&#29992;&#20013;&#24456;&#26222;&#36941;&#65292;&#20294;&#30001;&#20110;&#20854;&#21463;&#38480;&#30340;&#26550;&#26500;&#65292;&#23545;&#20110;&#32806;&#21512;&#27969;&#30340;&#20840;&#38754;&#29702;&#35299;&#20173;&#28982;&#22256;&#38590;&#12290;&#29616;&#26377;&#30340;&#23450;&#29702;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#23384;&#22312;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20351;&#29992;&#20219;&#24847;&#30149;&#24577;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36825;&#20123;&#32467;&#26500;&#26412;&#36136;&#19978;&#23548;&#33268;&#20307;&#31215;&#20445;&#25345;&#27969;&#65292;&#36825;&#26159;&#19968;&#20010;&#38480;&#21046;&#34920;&#36798;&#33021;&#21147;&#30340;&#22522;&#26412;&#32422;&#26463;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20998;&#24067;&#30340;&#32806;&#21512;&#26631;&#20934;&#21270;&#27969;&#26222;&#36866;&#24615;&#23450;&#29702;&#65292;&#20811;&#26381;&#20102;&#20197;&#21069;&#24037;&#20316;&#30340;&#20960;&#20010;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25903;&#25345;&#32806;&#21512;&#26550;&#26500;&#20855;&#26377;&#34920;&#36798;&#33021;&#21147;&#30340;&#26222;&#36941;&#32463;&#39564;&#65292;&#24182;&#20026;&#36873;&#25321;&#32806;&#21512;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#25552;&#20379;&#20102;&#32454;&#33268;&#20837;&#24494;&#30340;&#35266;&#28857;&#65292;&#22635;&#34917;&#20102;&#23454;&#35777;&#32467;&#26524;&#21644;&#29702;&#35770;&#29702;&#35299;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel theoretical framework for understanding the expressive power of coupling-based normalizing flows such as RealNVP. Despite their prevalence in scientific applications, a comprehensive understanding of coupling flows remains elusive due to their restricted architectures. Existing theorems fall short as they require the use of arbitrarily ill-conditioned neural networks, limiting practical applicability. Additionally, we demonstrate that these constructions inherently lead to volume-preserving flows, a property which we show to be a fundamental constraint for expressivity. We propose a new distributional universality theorem for coupling-based normalizing flows, which overcomes several limitations of prior work. Our results support the general wisdom that the coupling architecture is expressive and provide a nuanced view for choosing the expressivity of coupling functions, bridging a gap between empirical results and theoretical understanding.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#24378;&#30423;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#21644;&#29992;&#20110;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#22810;&#31181;&#24037;&#20855;&#12290;&#34429;&#28982;&#27809;&#26377;&#22826;&#22810;&#21019;&#26032;&#65292;&#20294;&#36890;&#36807;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#29616;&#26377;&#24037;&#20855;&#65292;&#33719;&#24471;&#20102;&#26032;&#30340;&#31639;&#27861;&#21644;&#25913;&#36827;&#20102;&#19968;&#20123;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.06535</link><description>&lt;p&gt;
Bandit Convex Optimisation&#65288;&#24378;&#30423;&#20984;&#20248;&#21270;&#65289;
&lt;/p&gt;
&lt;p&gt;
Bandit Convex Optimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06535
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#24378;&#30423;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#21644;&#29992;&#20110;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#22810;&#31181;&#24037;&#20855;&#12290;&#34429;&#28982;&#27809;&#26377;&#22826;&#22810;&#21019;&#26032;&#65292;&#20294;&#36890;&#36807;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#29616;&#26377;&#24037;&#20855;&#65292;&#33719;&#24471;&#20102;&#26032;&#30340;&#31639;&#27861;&#21644;&#25913;&#36827;&#20102;&#19968;&#20123;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#30423;&#20984;&#20248;&#21270;&#26159;&#30740;&#31350;&#38646;&#38454;&#20984;&#20248;&#21270;&#30340;&#22522;&#26412;&#26694;&#26550;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#29992;&#20110;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#35768;&#22810;&#24037;&#20855;&#65292;&#21253;&#25324;&#20999;&#24179;&#38754;&#26041;&#27861;&#12289;&#20869;&#28857;&#26041;&#27861;&#12289;&#36830;&#32493;&#25351;&#25968;&#26435;&#37325;&#12289;&#26799;&#24230;&#19979;&#38477;&#21644;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;&#12290;&#35299;&#37322;&#20102;&#35768;&#22810;&#20551;&#35774;&#21644;&#35774;&#32622;&#20043;&#38388;&#30340;&#32454;&#24494;&#24046;&#21035;&#12290;&#23613;&#31649;&#22312;&#36825;&#37324;&#27809;&#26377;&#22826;&#22810;&#30495;&#27491;&#26032;&#30340;&#19996;&#35199;&#65292;&#20294;&#19968;&#20123;&#29616;&#26377;&#24037;&#20855;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#24212;&#29992;&#20110;&#33719;&#24471;&#26032;&#31639;&#27861;&#12290;&#19968;&#20123;&#30028;&#38480;&#31245;&#24494;&#25913;&#36827;&#20102;&#19968;&#20123;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bandit convex optimisation is a fundamental framework for studying zeroth-order convex optimisation. These notes cover the many tools used for this problem, including cutting plane methods, interior point methods, continuous exponential weights, gradient descent and online Newton step. The nuances between the many assumptions and setups are explained. Although there is not much truly new here, some existing tools are applied in novel ways to obtain new algorithms. A few bounds are improved in minor ways.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#22312;&#29702;&#35770;&#19978;&#30340;&#23616;&#38480;&#65292;&#25552;&#20986;&#22270;&#21367;&#31215;&#28145;&#24230;&#20869;&#26680;&#26426;&#65288;graph convolutional deep kernel machine&#65289;&#26469;&#30740;&#31350;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06525</link><description>&lt;p&gt;
&#28789;&#27963;&#30340;&#26080;&#38480;&#23485;&#22270;&#21367;&#31215;&#32593;&#32476;&#21450;&#34920;&#31034;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Flexible infinite-width graph convolutional networks and the importance of representation learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06525
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#22312;&#29702;&#35770;&#19978;&#30340;&#23616;&#38480;&#65292;&#25552;&#20986;&#22270;&#21367;&#31215;&#28145;&#24230;&#20869;&#26680;&#26426;&#65288;graph convolutional deep kernel machine&#65289;&#26469;&#30740;&#31350;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#31181;&#24120;&#35265;&#29702;&#35770;&#26041;&#27861;&#26159;&#36827;&#34892;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#65292;&#27492;&#26102;&#36755;&#20986;&#25104;&#20026;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20998;&#24067;&#12290;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#12290;&#28982;&#32780;&#65292;NNGP&#20869;&#26680;&#26159;&#22266;&#23450;&#30340;&#65292;&#21482;&#33021;&#36890;&#36807;&#23569;&#37327;&#36229;&#21442;&#25968;&#36827;&#34892;&#35843;&#33410;&#65292;&#28040;&#38500;&#20102;&#20219;&#20309;&#34920;&#31034;&#23398;&#20064;&#30340;&#21487;&#33021;&#24615;&#12290;&#36825;&#19982;&#26377;&#38480;&#23485;&#24230;&#30340;&#31070;&#32463;&#32593;&#32476;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#36890;&#24120;&#34987;&#35748;&#20026;&#33021;&#22815;&#34920;&#29616;&#33391;&#22909;&#65292;&#27491;&#26159;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#23398;&#20064;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#31616;&#21270;&#31070;&#32463;&#32593;&#32476;&#20197;&#20351;&#20854;&#22312;&#29702;&#35770;&#19978;&#21487;&#22788;&#29702;&#30340;&#21516;&#26102;&#65292;NNGP&#21487;&#33021;&#20250;&#28040;&#38500;&#20351;&#20854;&#24037;&#20316;&#33391;&#22909;&#30340;&#22240;&#32032;&#65288;&#34920;&#31034;&#23398;&#20064;&#65289;&#12290;&#36825;&#28608;&#21457;&#20102;&#25105;&#20204;&#23545;&#19968;&#31995;&#21015;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#34920;&#31034;&#23398;&#20064;&#26159;&#21542;&#24517;&#35201;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#24037;&#20855;&#26469;&#23436;&#25104;&#36825;&#20010;&#20219;&#21153;&#65292;&#21363;&#22270;&#21367;&#31215;&#28145;&#24230;&#20869;&#26680;&#26426;&#65288;graph convolutional deep kernel machine&#65289;&#12290;&#36825;&#19982;NNGP&#38750;&#24120;&#30456;&#20284;&#65292;&#22240;&#20026;&#23427;&#26159;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#24182;&#20351;&#29992;&#20869;&#26680;&#65292;&#20294;&#23427;&#24102;&#26377;&#19968;&#20010;&#8220;&#26059;&#38062;&#8221;&#26469;&#25511;&#21046;&#34920;&#31034;&#23398;&#20064;&#30340;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common theoretical approach to understanding neural networks is to take an infinite-width limit, at which point the outputs become Gaussian process (GP) distributed. This is known as a neural network Gaussian process (NNGP). However, the NNGP kernel is fixed, and tunable only through a small number of hyperparameters, eliminating any possibility of representation learning. This contrasts with finite-width NNs, which are often believed to perform well precisely because they are able to learn representations. Thus in simplifying NNs to make them theoretically tractable, NNGPs may eliminate precisely what makes them work well (representation learning). This motivated us to understand whether representation learning is necessary in a range of graph classification tasks. We develop a precise tool for this task, the graph convolutional deep kernel machine. This is very similar to an NNGP, in that it is an infinite width limit and uses kernels, but comes with a `knob' to control the amount 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SeqRF&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#30452;&#32447;&#21270;&#27010;&#29575;&#27969;&#26469;&#20943;&#23567;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#24182;&#20197;&#27492;&#21152;&#36895;&#21462;&#26679;&#21644;&#25552;&#39640;&#32508;&#21512;&#36136;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.06461</link><description>&lt;p&gt;
&#39034;&#24207;&#27969;&#21305;&#37197;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Sequential Flow Matching for Generative Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06461
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SeqRF&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#30452;&#32447;&#21270;&#27010;&#29575;&#27969;&#26469;&#20943;&#23567;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#24182;&#20197;&#27492;&#21152;&#36895;&#21462;&#26679;&#21644;&#25552;&#39640;&#32508;&#21512;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30452;&#25509;&#24341;&#23548;&#36830;&#32493;&#26102;&#38388;&#29983;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;&#25193;&#25955;&#27169;&#22411;&#25110;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#65289;&#30340;&#27010;&#29575;&#27969;&#26159;&#36890;&#36807;&#25968;&#20540;&#35299;&#31639;&#22120;&#24555;&#36895;&#21462;&#26679;&#30340;&#20851;&#38190;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#30452;&#25509;&#29983;&#25104;&#22122;&#22768;&#21644;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#32852;&#21512;&#20998;&#24067;&#30340;&#27010;&#29575;&#36335;&#24452;&#26469;&#23398;&#20064;&#32447;&#24615;&#36335;&#24452;&#12290;ODE&#27169;&#22411;&#30340;&#20223;&#30495;&#36895;&#24230;&#24930;&#30340;&#19968;&#20010;&#37325;&#35201;&#21407;&#22240;&#26159;ODE&#36712;&#36857;&#30340;&#39640;&#26354;&#29575;&#23548;&#33268;&#30340;ODE&#27714;&#35299;&#22120;&#30340;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#36825;&#20250;&#22312;&#20302;NFE&#33539;&#22260;&#20869;&#25918;&#22823;&#25968;&#20540;&#35299;&#31639;&#22120;&#30340;&#25130;&#26029;&#35823;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;SeqRF&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#23398;&#20064;&#25216;&#26415;&#65292;&#29992;&#20110;&#30452;&#32447;&#21270;&#27010;&#29575;&#27969;&#20197;&#20943;&#23567;&#20840;&#23616;&#25130;&#26029;&#35823;&#24046;&#65292;&#20174;&#32780;&#21152;&#36895;&#21462;&#26679;&#24182;&#25552;&#39640;&#32508;&#21512;&#36136;&#37327;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#39318;&#20808;&#35266;&#23519;&#21040;&#20102;SeqRF&#30340;&#30452;&#32447;&#21270;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Straightening the probability flow of the continuous-time generative models, such as diffusion models or flow-based models, is the key to fast sampling through the numerical solvers, existing methods learn a linear path by directly generating the probability path the joint distribution between the noise and data distribution. One key reason for the slow sampling speed of the ODE-based solvers that simulate these generative models is the global truncation error of the ODE solver, caused by the high curvature of the ODE trajectory, which explodes the truncation error of the numerical solvers in the low-NFE regime. To address this challenge, We propose a novel method called SeqRF, a learning technique that straightens the probability flow to reduce the global truncation error and hence enable acceleration of sampling and improve the synthesis quality. In both theoretical and empirical studies, we first observe the straightening property of our SeqRF. Through empirical evaluations via SeqR
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#29615;&#22659;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06434</link><description>&lt;p&gt;
&#30495;&#30456;&#22312;&#21738;&#37324;&#65311;&#22312;&#36830;&#32493;&#30340;&#19990;&#30028;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Where is the Truth? The Risk of Getting Confounded in a Continual World
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06434
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#29615;&#22659;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#19968;&#20010;&#25968;&#25454;&#38598;&#36890;&#36807;&#19968;&#20010;&#34394;&#20551;&#30456;&#20851;&#24615;&#26469;&#35299;&#20915;&#65292;&#32780;&#36825;&#31181;&#30456;&#20851;&#24615;&#26080;&#27861;&#27867;&#21270;&#21040;&#26032;&#25968;&#25454;&#65292;&#35813;&#25968;&#25454;&#38598;&#23601;&#26159;&#28151;&#28102;&#30340;&#12290;&#25105;&#20204;&#23558;&#23637;&#31034;&#65292;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#30340;&#29615;&#22659;&#20013;&#65292;&#28151;&#28102;&#22240;&#32032;&#21487;&#33021;&#38543;&#30528;&#20219;&#21153;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#65292;&#23548;&#33268;&#30340;&#25361;&#25112;&#36828;&#36828;&#36229;&#36807;&#36890;&#24120;&#32771;&#34385;&#30340;&#36951;&#24536;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20174;&#25968;&#23398;&#19978;&#25512;&#23548;&#20102;&#36825;&#31181;&#28151;&#28102;&#22240;&#32032;&#23545;&#19968;&#32452;&#28151;&#28102;&#20219;&#21153;&#30340;&#26377;&#25928;&#32852;&#21512;&#35299;&#31354;&#38388;&#30340;&#24433;&#21709;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#65292;&#22312;&#35768;&#22810;&#36825;&#26679;&#30340;&#36830;&#32493;&#25968;&#25454;&#38598;&#20013;&#65292;&#24403;&#20219;&#21153;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#26102;&#65292;&#34394;&#20551;&#30456;&#20851;&#24615;&#24456;&#23481;&#26131;&#34987;&#24573;&#30053;&#65292;&#20294;&#26159;&#22312;&#39034;&#24207;&#32771;&#34385;&#20219;&#21153;&#26102;&#65292;&#36991;&#20813;&#28151;&#28102;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#36825;&#26679;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#26631;&#20934;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#32780;&#21516;&#26102;&#23545;&#25152;&#26377;&#20219;&#21153;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#21017;&#26159;&#25104;&#21151;&#30340;&#12290;&#25105;&#20204;&#30340;&#36830;&#32493;&#28151;&#28102;&#25968;&#25454;&#38598;ConCon&#22522;&#20110;CLEVR&#22270;&#20687;&#65292;&#35777;&#26126;&#20102;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26469;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a continual learning setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such continual datasets, spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard continual learning methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for continual learning methods with more robust b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MARINA-P&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31995;&#21015;&#30456;&#20851;&#21387;&#32553;&#22120;&#65292;&#20248;&#21270;&#20102;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;MARINA-P&#22312;&#31639;&#27861;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#21487;&#20197;&#20316;&#20026;&#25903;&#25345;&#21452;&#21521;&#21387;&#32553;&#30340;&#36215;&#28857;&#12290;&#36890;&#36807;&#19982;&#19978;&#34892;&#21387;&#32553;&#21644;&#21160;&#37327;&#27493;&#39588;&#30340;&#32467;&#21512;&#65292;M3&#26041;&#27861;&#23454;&#29616;&#20102;&#21452;&#21521;&#21387;&#32553;&#65292;&#24182;&#22312;&#24635;&#36890;&#20449;&#22797;&#26434;&#24230;&#19978;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.06412</link><description>&lt;p&gt;
&#25552;&#39640;&#38750;&#20984;&#20998;&#24067;&#24335;&#20248;&#21270;&#22312;&#20989;&#25968;&#30456;&#20284;&#24615;&#19979;&#30340;&#26368;&#22351;&#24773;&#20917;&#21452;&#21521;&#36890;&#20449;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MARINA-P&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31995;&#21015;&#30456;&#20851;&#21387;&#32553;&#22120;&#65292;&#20248;&#21270;&#20102;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;MARINA-P&#22312;&#31639;&#27861;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#24182;&#21487;&#20197;&#20316;&#20026;&#25903;&#25345;&#21452;&#21521;&#21387;&#32553;&#30340;&#36215;&#28857;&#12290;&#36890;&#36807;&#19982;&#19978;&#34892;&#21387;&#32553;&#21644;&#21160;&#37327;&#27493;&#39588;&#30340;&#32467;&#21512;&#65292;M3&#26041;&#27861;&#23454;&#29616;&#20102;&#21452;&#21521;&#21387;&#32553;&#65292;&#24182;&#22312;&#24635;&#36890;&#20449;&#22797;&#26434;&#24230;&#19978;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26381;&#21153;&#22120;&#21644;&#24037;&#20316;&#33410;&#28857;&#20043;&#38388;&#30340;&#26377;&#25928;&#36890;&#20449;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#26412;&#25991;&#20027;&#35201;&#20851;&#27880;&#20248;&#21270;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#65292;&#24182;&#25581;&#31034;&#20102;&#24403;&#21069;&#27969;&#34892;&#30340;&#19979;&#34892;&#21387;&#32553;&#26041;&#27861;&#20013;&#30340;&#20302;&#25928;&#24615;&#12290;&#39318;&#20808;&#32771;&#34385;&#19978;&#34892;&#36890;&#20449;&#25104;&#26412;&#21487;&#24573;&#30053;&#30340;&#32431;&#31929;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;MARINA-P&#65292;&#19968;&#31181;&#20351;&#29992;&#19968;&#31995;&#21015;&#30456;&#20851;&#21387;&#32553;&#22120;&#30340;&#26032;&#22411;&#19979;&#34892;&#21387;&#32553;&#26041;&#27861;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#65292;&#20351;&#29992;&#25490;&#21015;&#21387;&#32553;&#22120;&#30340;MARINA-P&#21487;&#20197;&#23454;&#29616;&#26381;&#21153;&#22120;&#21040;&#24037;&#20316;&#33410;&#28857;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#38543;&#24037;&#20316;&#33410;&#28857;&#25968;&#37327;&#25552;&#39640;&#65292;&#22240;&#27492;&#22312;&#31639;&#27861;&#19978;&#21487;&#35777;&#26126;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;MARINA-P&#21487;&#20197;&#20316;&#20026;&#25903;&#25345;&#21452;&#21521;&#21387;&#32553;&#30340;&#26041;&#27861;&#30340;&#36215;&#28857;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;M3&#65292;&#36825;&#26159;&#19968;&#31181;&#23558;MARINA-P&#19982;&#19978;&#34892;&#21387;&#32553;&#21644;&#21160;&#37327;&#27493;&#39588;&#32452;&#21512;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#23454;&#29616;&#21452;&#21521;&#21387;&#32553;&#65292;&#24182;&#22312;&#24635;&#36890;&#20449;&#22797;&#26434;&#24230;&#19978;&#35777;&#26126;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective communication between the server and workers plays a key role in distributed optimization. In this paper, we focus on optimizing the server-to-worker communication, uncovering inefficiencies in prevalent downlink compression approaches. Considering first the pure setup where the uplink communication costs are negligible, we introduce MARINA-P, a novel method for downlink compression, employing a collection of correlated compressors. Theoretical analyses demonstrates that MARINA-P with permutation compressors can achieve a server-to-worker communication complexity improving with the number of workers, thus being provably superior to existing algorithms. We further show that MARINA-P can serve as a starting point for extensions such as methods supporting bidirectional compression. We introduce M3, a method combining MARINA-P with uplink compression and a momentum step, achieving bidirectional compression with provable improvements in total communication complexity as the number
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.06388</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#21450;&#20854;&#22312;&#20462;&#25913;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#30340;&#31574;&#30053;&#26799;&#24230;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Convergence Rate of the Stochastic Gradient Descent (SGD) and application to a modified policy gradient for the Multi Armed Bandit
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06388
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#25353;&#29031;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#24212;&#29992;&#20110;&#20462;&#25913;&#30340;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#24403;&#23398;&#20064;&#36895;&#29575;&#36981;&#24490;&#36870;&#26102;&#38388;&#34928;&#20943;&#35268;&#21017;&#26102;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;&#65307;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#24212;&#29992;&#20110;&#24102;&#26377;L2&#27491;&#21017;&#21270;&#30340;&#20462;&#25913;&#30340;&#31574;&#30053;&#26799;&#24230;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a self-contained proof of the convergence rate of the Stochastic Gradient Descent (SGD) when the learning rate follows an inverse time decays schedule; we next apply the results to the convergence of a modified form of policy gradient Multi-Armed Bandit (MAB) with $L2$ regularization.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25552;&#21319;&#26041;&#27861;&#26500;&#24314;&#22810;&#20010;&#20803;&#26641;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25913;&#36827;&#20915;&#31574;&#26641;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06386</link><description>&lt;p&gt;
&#22522;&#20110;Boosting&#30340;&#39034;&#24207;&#20803;&#26641;&#38598;&#25104;&#26500;&#24314;&#20197;&#25913;&#36827;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
Boosting-Based Sequential Meta-Tree Ensemble Construction for Improved Decision Trees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06386
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25552;&#21319;&#26041;&#27861;&#26500;&#24314;&#22810;&#20010;&#20803;&#26641;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25913;&#36827;&#20915;&#31574;&#26641;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#26159;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23427;&#23384;&#22312;&#36807;&#24230;&#21152;&#28145;&#26641;&#24418;&#32467;&#26500;&#23548;&#33268;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#36817;&#26399;&#26377;&#20154;&#25552;&#20986;&#20102;&#20803;&#26641;&#26469;&#35299;&#20915;&#36807;&#24230;&#21152;&#28145;&#26641;&#24418;&#32467;&#26500;&#23548;&#33268;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#65292;&#20803;&#26641;&#33021;&#22815;&#20445;&#35777;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#24615;&#12290;&#22240;&#27492;&#65292;&#30456;&#36739;&#20110;&#20915;&#31574;&#26641;&#65292;&#25105;&#20204;&#26399;&#26395;&#20803;&#26641;&#34920;&#29616;&#26356;&#22909;&#12290;&#19982;&#21333;&#20010;&#20915;&#31574;&#26641;&#30456;&#27604;&#65292;&#24050;&#30693;&#30001;&#25552;&#21319;&#31639;&#27861;&#26500;&#36896;&#30340;&#20915;&#31574;&#26641;&#38598;&#25104;&#22312;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#26356;&#20026;&#26377;&#25928;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26399;&#26395;&#30001;&#20803;&#26641;&#38598;&#25104;&#26469;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#27604;&#21333;&#20010;&#20803;&#26641;&#26356;&#26377;&#25928;&#65292;&#24182;&#19988;&#20197;&#21069;&#27809;&#26377;&#30740;&#31350;&#20351;&#29992;&#25552;&#21319;&#26041;&#27861;&#26500;&#24314;&#22810;&#20010;&#20803;&#26641;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#25552;&#21319;&#26041;&#27861;&#26500;&#24314;&#22810;&#20010;&#20803;&#26641;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A decision tree is one of the most popular approaches in machine learning fields. However, it suffers from the problem of overfitting caused by overly deepened trees. Then, a meta-tree is recently proposed. It solves the problem of overfitting caused by overly deepened trees. Moreover, the meta-tree guarantees statistical optimality based on Bayes decision theory. Therefore, the meta-tree is expected to perform better than the decision tree. In contrast to a single decision tree, it is known that ensembles of decision trees, which are typically constructed boosting algorithms, are more effective in improving predictive performance. Thus, it is expected that ensembles of meta-trees are more effective in improving predictive performance than a single meta-tree, and there are no previous studies that construct multiple meta-trees in boosting. Therefore, in this study, we propose a method to construct multiple meta-trees using a boosting approach. Through experiments with synthetic and ben
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#26368;&#20248;&#31639;&#27861;&#65292;&#22312;&#23398;&#20064;&#39640;&#26031;&#26641;&#21644;&#39640;&#26031;&#22810;&#39033;&#24335;&#26641;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#35777;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06380</link><description>&lt;p&gt;
&#39640;&#26031;&#65288;&#22810;&#39033;&#24335;&#65289;&#26641;&#30340;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal estimation of Gaussian (poly)trees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06380
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#26368;&#20248;&#31639;&#27861;&#65292;&#22312;&#23398;&#20064;&#39640;&#26031;&#26641;&#21644;&#39640;&#26031;&#22810;&#39033;&#24335;&#26641;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25104;&#26524;&#65292;&#24182;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#35777;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#21521;&#39640;&#26031;&#26641;&#21644;&#26377;&#21521;&#39640;&#26031;&#22810;&#39033;&#24335;&#26641;&#30340;&#26368;&#20248;&#31639;&#27861;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20998;&#24067;&#23398;&#20064;&#65288;&#21363;KL&#36317;&#31163;&#65289;&#21644;&#32467;&#26500;&#23398;&#20064;&#65288;&#21363;&#31934;&#30830;&#24674;&#22797;&#65289;&#30340;&#20004;&#20010;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#22522;&#20110;Chow-Liu&#31639;&#27861;&#65292;&#26377;&#25928;&#22320;&#23398;&#20064;&#26368;&#20248;&#30340;&#26641;&#29366;&#20998;&#24067;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#23545;&#29992;&#20110;&#22810;&#39033;&#24335;&#26641;&#30340;PC&#31639;&#27861;&#30340;&#20462;&#25913;&#65292;&#23427;&#20351;&#29992;&#20559;&#30456;&#20851;&#20316;&#20026;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#22120;&#36827;&#34892;&#22522;&#20110;&#32422;&#26463;&#30340;&#32467;&#26500;&#23398;&#20064;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#26174;&#24335;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#25512;&#23548;&#21305;&#37197;&#30340;&#19979;&#30028;&#35777;&#26126;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#26159;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#27604;&#36739;&#20102;&#21508;&#31181;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#25552;&#20379;&#20102;&#36827;&#19968;&#27493;&#30340;&#27934;&#23519;&#21644;&#32463;&#39564;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop optimal algorithms for learning undirected Gaussian trees and directed Gaussian polytrees from data. We consider both problems of distribution learning (i.e. in KL distance) and structure learning (i.e. exact recovery). The first approach is based on the Chow-Liu algorithm, and learns an optimal tree-structured distribution efficiently. The second approach is a modification of the PC algorithm for polytrees that uses partial correlation as a conditional independence tester for constraint-based structure learning. We derive explicit finite-sample guarantees for both approaches, and show that both approaches are optimal by deriving matching lower bounds. Additionally, we conduct numerical experiments to compare the performance of various algorithms, providing further insights and empirical evidence.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#32447;&#30340;&#20844;&#24179;RMAB&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#33218;&#30340;&#25289;&#21462;&#19982;&#20854;&#20248;&#21183;&#25104;&#27604;&#20363;&#65292;&#23454;&#29616;&#20102;&#20844;&#24179;&#30340;&#26333;&#20809;&#12290;&#31639;&#27861;&#22312;&#21333;&#27425;&#25289;&#21462;&#30340;&#20844;&#24179;&#24615;&#36951;&#25022;&#26041;&#38754;&#21462;&#24471;&#20102;&#27425;&#32447;&#24615;&#30340;&#32467;&#26524;$O(\sqrt{T\ln T})$&#12290;</title><link>https://arxiv.org/abs/2402.06348</link><description>&lt;p&gt;
&#22312;&#32447;&#19981;&#24179;&#34913;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;&#26333;&#20809;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fairness of Exposure in Online Restless Multi-armed Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06348
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#32447;&#30340;&#20844;&#24179;RMAB&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#33218;&#30340;&#25289;&#21462;&#19982;&#20854;&#20248;&#21183;&#25104;&#27604;&#20363;&#65292;&#23454;&#29616;&#20102;&#20844;&#24179;&#30340;&#26333;&#20809;&#12290;&#31639;&#27861;&#22312;&#21333;&#27425;&#25289;&#21462;&#30340;&#20844;&#24179;&#24615;&#36951;&#25022;&#26041;&#38754;&#21462;&#24471;&#20102;&#27425;&#32447;&#24615;&#30340;&#32467;&#26524;$O(\sqrt{T\ln T})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#24179;&#34913;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;RMAB&#65289;&#25512;&#24191;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#20854;&#20013;&#27599;&#20010;&#33218;&#23637;&#31034;&#39532;&#23572;&#21487;&#22827;&#34892;&#20026;&#65292;&#24182;&#26681;&#25454;&#20854;&#36807;&#28193;&#21160;&#24577;&#36827;&#34892;&#36716;&#25442;&#12290;&#38024;&#23545;RMAB&#30340;&#35299;&#20915;&#26041;&#26696;&#23384;&#22312;&#20110;&#31163;&#32447;&#21644;&#22312;&#32447;&#24773;&#20917;&#19979;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#27809;&#26377;&#32771;&#34385;&#33218;&#20043;&#38388;&#30340;&#25289;&#21462;&#20998;&#24067;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#20248;&#31574;&#30053;&#20250;&#23548;&#33268;&#19981;&#20844;&#24179;&#65292;&#20854;&#20013;&#19968;&#20123;&#33218;&#19981;&#22815;&#26292;&#38706;&#12290;&#29616;&#26377;&#30340;RMAB&#20844;&#24179;&#24615;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#31163;&#32447;&#26696;&#20363;&#20013;&#65292;&#36825;&#38477;&#20302;&#20102;&#23427;&#20204;&#22312;&#29615;&#22659;&#22823;&#37096;&#20998;&#19981;&#30693;&#36947;&#30340;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#24212;&#29992;&#12290;&#22312;&#22312;&#32447;&#22330;&#26223;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20844;&#24179;&#30340;RMAB&#26694;&#26550;&#65292;&#20854;&#20013;&#27599;&#20010;&#33218;&#25509;&#25910;&#30340;&#25289;&#21462;&#19982;&#20854;&#20248;&#21183;&#25104;&#27604;&#20363;&#12290;&#25105;&#20204;&#23558;&#33218;&#30340;&#20248;&#21183;&#23450;&#20041;&#20026;&#20854;&#31283;&#24577;&#22870;&#21169;&#20998;&#24067;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21333;&#27425;&#25289;&#21462;&#30340;&#20844;&#24179;&#24615;&#36951;&#25022;&#26041;&#38754;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#32467;&#26524;$O(\sqrt{T\ln T})$&#65292;&#20854;&#20013;$T$&#26159;&#24635;&#30340;&#23581;&#35797;&#27425;&#25968;&#12290;&#32463;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#22810;&#27425;&#25289;&#21462;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Restless multi-armed bandits (RMABs) generalize the multi-armed bandits where each arm exhibits Markovian behavior and transitions according to their transition dynamics. Solutions to RMAB exist for both offline and online cases. However, they do not consider the distribution of pulls among the arms. Studies have shown that optimal policies lead to unfairness, where some arms are not exposed enough. Existing works in fairness in RMABs focus heavily on the offline case, which diminishes their application in real-world scenarios where the environment is largely unknown. In the online scenario, we propose the first fair RMAB framework, where each arm receives pulls in proportion to its merit. We define the merit of an arm as a function of its stationary reward distribution. We prove that our algorithm achieves sublinear fairness regret in the single pull case $O(\sqrt{T\ln T})$, with $T$ being the total number of episodes. Empirically, we show that our algorithm performs well in the multi
&lt;/p&gt;</description></item><item><title>&#22312;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#21487;&#20197;&#20135;&#29983;&#38750;&#22343;&#21248;&#20559;&#24046;&#65292;&#22240;&#27492;&#36890;&#24120;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20250;&#19982;&#31364;&#25945;&#24072;NN&#19968;&#26679;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2402.06323</link><description>&lt;p&gt;
&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#22914;&#20309;&#24341;&#36215;&#19981;&#22343;&#21248;&#20559;&#24046;&#65306;&#20856;&#22411;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#19982;&#31364;&#25945;&#24072;&#30340;&#26222;&#36941;&#24615;
&lt;/p&gt;
&lt;p&gt;
How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06323
&lt;/p&gt;
&lt;p&gt;
&#22312;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#22343;&#21248;&#38543;&#26426;&#26435;&#37325;&#21487;&#20197;&#20135;&#29983;&#38750;&#22343;&#21248;&#20559;&#24046;&#65292;&#22240;&#27492;&#36890;&#24120;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#20250;&#19982;&#31364;&#25945;&#24072;NN&#19968;&#26679;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#12290;&#19968;&#20010;&#20027;&#35201;&#30340;&#29702;&#35770;&#38590;&#39064;&#26159;&#24403;&#31070;&#32463;&#32593;&#32476;&#34987;&#35757;&#32451;&#21040;&#38646;&#35823;&#24046;&#65288;&#21363;&#25554;&#20540;&#25968;&#25454;&#65289;&#26102;&#65292;&#20026;&#20160;&#20040;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#36890;&#24120;&#65292;NN&#26159;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25110;&#20854;&#21464;&#31181;&#20043;&#19968;&#35757;&#32451;&#30340;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23454;&#35777;&#30740;&#31350;&#26816;&#39564;&#20102;&#20174;&#30475;&#20284;&#22343;&#21248;&#30340;&#21442;&#25968;&#20808;&#39564;&#20013;&#37319;&#26679;&#30340;&#38543;&#26426;NN&#23545;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65306;&#35813;NN&#23545;&#35757;&#32451;&#38598;&#36827;&#34892;&#20102;&#23436;&#32654;&#20998;&#31867;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#26679;&#30340;NN&#26679;&#26412;&#36890;&#24120;&#20687;SGD&#35757;&#32451;&#30340;NN&#19968;&#26679;&#27867;&#21270;&#33391;&#22909;&#12290;&#36129;&#29486;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22914;&#26524;&#23384;&#22312;&#19982;&#26631;&#31614;&#19968;&#33268;&#30340;&#31364;&#8220;&#25945;&#24072;NN&#8221;&#65292;&#37027;&#20040;&#36825;&#26679;&#30340;&#38543;&#26426;NN&#25554;&#20540;&#22120;&#36890;&#24120;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;NN&#21442;&#25968;&#21270;&#20013;&#30340;&#8220;&#24179;&#22374;&#8221;&#20808;&#39564;&#36890;&#36807;NN&#32467;&#26500;&#20013;&#30340;&#20887;&#20313;&#24341;&#20837;&#20102;&#20016;&#23500;&#30340;NN&#20989;&#25968;&#20808;&#39564;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20250;&#23545;&#36739;&#31616;&#21333;&#30340;&#20989;&#25968;&#20135;&#29983;&#20559;&#21521;&#65292;&#36825;&#20123;&#20989;&#25968;&#38656;&#35201;&#36739;&#23569;&#30340;&#30456;&#20851;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background. A main theoretical puzzle is why over-parameterized Neural Networks (NNs) generalize well when trained to zero loss (i.e., so they interpolate the data). Usually, the NN is trained with Stochastic Gradient Descent (SGD) or one of its variants. However, recent empirical work examined the generalization of a random NN that interpolates the data: the NN was sampled from a seemingly uniform prior over the parameters, conditioned on that the NN perfectly classifying the training set. Interestingly, such a NN sample typically generalized as well as SGD-trained NNs.   Contributions. We prove that such a random NN interpolator typically generalizes well if there exists an underlying narrow ``teacher NN" that agrees with the labels. Specifically, we show that such a `flat' prior over the NN parametrization induces a rich prior over the NN functions, due to the redundancy in the NN structure. In particular, this creates a bias towards simpler functions, which require less relevant pa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;&#65288;PDDS&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#21407;&#22987;&#36845;&#20195;&#31890;&#23376;&#26041;&#26696;&#21644;&#26032;&#39062;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#23545;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#36827;&#34892;&#37319;&#26679;&#21644;&#35745;&#31639;&#35268;&#33539;&#21270;&#24120;&#25968;&#12290;&#19982;&#26631;&#20934;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;PDDS &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#28176;&#36817;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.06320</link><description>&lt;p&gt;
&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Particle Denoising Diffusion Sampler
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;&#65288;PDDS&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#21407;&#22987;&#36845;&#20195;&#31890;&#23376;&#26041;&#26696;&#21644;&#26032;&#39062;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#23545;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#36827;&#34892;&#37319;&#26679;&#21644;&#35745;&#31639;&#35268;&#33539;&#21270;&#24120;&#25968;&#12290;&#19982;&#26631;&#20934;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;PDDS &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#28176;&#36817;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#23558;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#28982;&#21518;&#36890;&#36807;&#20351;&#29992;&#24471;&#20998;&#21305;&#37197;&#24605;&#24819;&#20272;&#35745;&#36825;&#31181;&#25193;&#25955;&#30340;&#26102;&#38388;&#21453;&#28436;&#26469;&#33719;&#24471;&#26469;&#33258;&#25968;&#25454;&#20998;&#24067;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#37319;&#29992;&#31867;&#20284;&#30340;&#31574;&#30053;&#26469;&#20174;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#23427;&#20204;&#30340;&#35268;&#33539;&#21270;&#24120;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#37324;&#65292;&#26102;&#38388;&#21453;&#28436;&#25193;&#25955;&#26159;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#26032;&#39062;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#21407;&#22987;&#36845;&#20195;&#31890;&#23376;&#26041;&#26696;&#26469;&#27169;&#25311;&#30340;&#12290;&#19982;&#26631;&#20934;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#32467;&#26524;&#30340;&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120; (PDDS) &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#28176;&#36817;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#22810;&#27169;&#24577;&#21644;&#39640;&#32500;&#37319;&#26679;&#20219;&#21153;&#19978;&#28436;&#31034;&#20102; PDDS&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models have become ubiquitous for generative modeling. The core idea is to transport the data distribution to a Gaussian by using a diffusion. Approximate samples from the data distribution are then obtained by estimating the time-reversal of this diffusion using score matching ideas. We follow here a similar strategy to sample from unnormalized probability densities and compute their normalizing constants. However, the time-reversed diffusion is here simulated by using an original iterative particle scheme relying on a novel score matching loss. Contrary to standard denoising diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS) provides asymptotically consistent estimates under mild assumptions. We demonstrate PDDS on multimodal and high dimensional sampling tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26465;&#20214;&#27969;&#36827;&#34892;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#27169;&#22411;ProFITi&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#26465;&#20214;&#19979;&#26410;&#26469;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#65292;&#32780;&#19981;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#30340;&#22266;&#23450;&#24418;&#29366;&#12290;&#36890;&#36807;&#24341;&#20837;&#21487;&#36870;&#19977;&#35282;&#24418;&#27880;&#24847;&#21147;&#23618;&#21644;&#21487;&#36870;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#35813;&#27169;&#22411;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06293</link><description>&lt;p&gt;
&#36890;&#36807;&#26465;&#20214;&#27969;&#36827;&#34892;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Forecasting of Irregular Time Series via Conditional Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06293
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26465;&#20214;&#27969;&#36827;&#34892;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#27169;&#22411;ProFITi&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#26465;&#20214;&#19979;&#26410;&#26469;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#65292;&#32780;&#19981;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#30340;&#22266;&#23450;&#24418;&#29366;&#12290;&#36890;&#36807;&#24341;&#20837;&#21487;&#36870;&#19977;&#35282;&#24418;&#27880;&#24847;&#21147;&#23618;&#21644;&#21487;&#36870;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#35813;&#27169;&#22411;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#27010;&#29575;&#39044;&#27979;&#26159;&#35768;&#22810;&#39046;&#22495;&#30340;&#37325;&#35201;&#38382;&#39064;&#65292;&#21253;&#25324;&#21307;&#30103;&#20445;&#20581;&#12289;&#22825;&#25991;&#23398;&#21644;&#27668;&#20505;&#23398;&#12290;&#30446;&#21069;&#35813;&#20219;&#21153;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#20165;&#20272;&#35745;&#21333;&#20010;&#36890;&#36947;&#21644;&#21333;&#20010;&#26102;&#38388;&#28857;&#19978;&#35266;&#27979;&#20540;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#20551;&#35774;&#20102;&#19968;&#20010;&#22266;&#23450;&#24418;&#29366;&#30340;&#21442;&#25968;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;ProFITi&#65292;&#29992;&#20110;&#20351;&#29992;&#26465;&#20214;&#24402;&#19968;&#21270;&#27969;&#23545;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#23398;&#20064;&#20102;&#22312;&#36807;&#21435;&#35266;&#27979;&#21644;&#26597;&#35810;&#30340;&#36890;&#36947;&#21644;&#26102;&#38388;&#19978;&#26465;&#20214;&#19979;&#26102;&#38388;&#24207;&#21015;&#26410;&#26469;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#32780;&#19981;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#30340;&#22266;&#23450;&#24418;&#29366;&#12290;&#20316;&#20026;&#27169;&#22411;&#32452;&#20214;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#36870;&#19977;&#35282;&#24418;&#27880;&#24847;&#21147;&#23618;&#21644;&#19968;&#20010;&#21487;&#36870;&#30340;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#33021;&#22815;&#22312;&#25972;&#20010;&#23454;&#25968;&#32447;&#19978;&#36827;&#34892;&#36716;&#25442;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#25552;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic forecasting of irregularly sampled multivariate time series with missing values is an important problem in many fields, including health care, astronomy, and climate. State-of-the-art methods for the task estimate only marginal distributions of observations in single channels and at single timepoints, assuming a fixed-shape parametric distribution. In this work, we propose a novel model, ProFITi, for probabilistic forecasting of irregularly sampled time series with missing values using conditional normalizing flows. The model learns joint distributions over the future values of the time series conditioned on past observations and queried channels and times, without assuming any fixed shape of the underlying distribution. As model components, we introduce a novel invertible triangular attention layer and an invertible non-linear activation function on and onto the whole real line. We conduct extensive experiments on four datasets and demonstrate that the proposed model pro
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23433;&#20840;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#12290;&#36890;&#36807;&#21160;&#24577;&#25506;&#32034;&#36755;&#20837;&#31354;&#38388;&#24182;&#26681;&#25454;&#23433;&#20840;&#35201;&#27714;&#21644;&#36807;&#21435;&#35266;&#23519;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#36712;&#36857;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29616;&#23454;&#25216;&#26415;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06276</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#19979;&#23433;&#20840;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#30340;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Safe Active Learning for Time-Series Modeling with Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23433;&#20840;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#12290;&#36890;&#36807;&#21160;&#24577;&#25506;&#32034;&#36755;&#20837;&#31354;&#38388;&#24182;&#26681;&#25454;&#23433;&#20840;&#35201;&#27714;&#21644;&#36807;&#21435;&#35266;&#23519;&#30340;&#36755;&#20837;&#21644;&#36755;&#20986;&#36712;&#36857;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29616;&#23454;&#25216;&#26415;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#22914;&#27169;&#25311;&#21644;&#39044;&#27979;&#37117;&#26159;&#26377;&#29992;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#32771;&#34385;&#32473;&#23450;&#30340;&#23433;&#20840;&#24615;&#32422;&#26463;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#20027;&#21160;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#20855;&#26377;&#38750;&#32447;&#24615;&#22806;&#37096;&#36755;&#20837;&#32467;&#26500;&#30340;&#39640;&#26031;&#36807;&#31243;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#21160;&#24577;&#22320;&#25506;&#32034;&#36755;&#20837;&#31354;&#38388;&#26469;&#29983;&#25104;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#23398;&#20064;&#30340;&#25968;&#25454;&#65292;&#21363;&#36755;&#20837;&#21644;&#36755;&#20986;&#36712;&#36857;&#12290;&#35813;&#26041;&#27861;&#23558;&#36755;&#20837;&#36712;&#36857;&#21442;&#25968;&#21270;&#20026;&#36830;&#32493;&#30340;&#36712;&#36857;&#37096;&#20998;&#65292;&#36825;&#20123;&#37096;&#20998;&#26159;&#26681;&#25454;&#23433;&#20840;&#35201;&#27714;&#21644;&#36807;&#21435;&#30340;&#35266;&#23519;&#36880;&#27493;&#30830;&#23450;&#30340;&#12290;&#25105;&#20204;&#23545;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#36827;&#34892;&#20998;&#26512;&#65292;&#24182;&#22312;&#25216;&#26415;&#24212;&#29992;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#32467;&#26524;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29616;&#23454;&#25216;&#26415;&#20351;&#29992;&#26696;&#20363;&#19979;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning time-series models is useful for many applications, such as simulation and forecasting. In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account. For time-series modeling we employ a Gaussian process with a nonlinear exogenous input structure. The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space. The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations. We analyze the proposed algorithm and evaluate it empirically on a technical application. The results show the effectiveness of our approach in a realistic technical use case.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28508;&#22312;&#37096;&#20998;&#22240;&#26524;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#22312;&#35782;&#21035;&#28508;&#22312;&#32806;&#21512;&#21464;&#37327;&#26041;&#38754;&#30340;&#20248;&#31168;&#33021;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#36890;&#36807;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.06223</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37096;&#20998;&#22240;&#26524;&#27169;&#22411;&#25581;&#31034;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Revealing Multimodal Contrastive Representation Learning through Latent Partial Causal Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06223
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#37096;&#20998;&#22240;&#26524;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#22312;&#35782;&#21035;&#28508;&#22312;&#32806;&#21512;&#21464;&#37327;&#26041;&#38754;&#30340;&#20248;&#31168;&#33021;&#21147;&#65292;&#24182;&#25581;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#36890;&#36807;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#30001;&#20110;&#23427;&#20204;&#33021;&#22815;&#29983;&#25104;&#22797;&#26434;&#29616;&#35937;&#30340;&#26377;&#24847;&#20041;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#20026;&#20102;&#22686;&#24378;&#23545;&#36825;&#20123;&#33719;&#24471;&#30340;&#34920;&#31034;&#30340;&#28145;&#24230;&#20998;&#26512;&#21644;&#29702;&#35299;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#21035;&#38024;&#23545;&#22810;&#27169;&#24577;&#25968;&#25454;&#35774;&#35745;&#30340;&#32479;&#19968;&#22240;&#26524;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#36825;&#20010;&#27169;&#22411;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#27169;&#24335;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#22312;&#35782;&#21035;&#22312;&#25552;&#20986;&#30340;&#32479;&#19968;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#32806;&#21512;&#21464;&#37327;&#26041;&#38754;&#30340;&#20248;&#31168;&#33021;&#21147;&#65292;&#21363;&#20351;&#22312;&#19981;&#21516;&#20551;&#35774;&#19979;&#23548;&#33268;&#30340;&#32447;&#24615;&#25110;&#32622;&#25442;&#21464;&#25442;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25581;&#31034;&#20102;&#39044;&#35757;&#32451;&#30340;&#22810;&#27169;&#24577;&#27169;&#22411;&#65288;&#22914;CLIP&#65289;&#36890;&#36807;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#36825;&#19968;&#20196;&#20154;&#24778;&#35766;&#30340;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#24037;&#20855;&#23398;&#20064;&#20998;&#31163;&#34920;&#31034;&#30340;&#28508;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#21457;&#29616;&#30340;&#40065;&#26834;&#24615;&#65292;&#21363;&#20351;&#22312;&#34987;&#36829;&#21453;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#22312;&#23398;&#20064;&#30142;&#30149;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal contrastive representation learning methods have proven successful across a range of domains, partly due to their ability to generate meaningful shared representations of complex phenomena. To enhance the depth of analysis and understanding of these acquired representations, we introduce a unified causal model specifically designed for multimodal data. By examining this model, we show that multimodal contrastive representation learning excels at identifying latent coupled variables within the proposed unified model, up to linear or permutation transformations resulting from different assumptions. Our findings illuminate the potential of pre-trained multimodal models, eg, CLIP, in learning disentangled representations through a surprisingly simple yet highly effective tool: linear independent component analysis. Experiments demonstrate the robustness of our findings, even when the assumptions are violated, and validate the effectiveness of the proposed method in learning dise
&lt;/p&gt;</description></item><item><title>SMC&#24182;&#34892;&#25193;&#23637;&#26041;&#27861;pSMC&#20855;&#26377;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#20855;&#26377;&#26377;&#30028;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#35201;&#27714;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06173</link><description>&lt;p&gt;
SMC&#23601;&#26159;&#20320;&#38656;&#35201;&#30340;&#65306;&#24182;&#34892;&#24378;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
SMC Is All You Need: Parallel Strong Scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06173
&lt;/p&gt;
&lt;p&gt;
SMC&#24182;&#34892;&#25193;&#23637;&#26041;&#27861;pSMC&#20855;&#26377;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#20855;&#26377;&#26377;&#30028;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#35201;&#27714;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#19968;&#33324;&#26694;&#26550;&#20013;&#65292;&#30446;&#26631;&#20998;&#24067;&#21482;&#33021;&#25353;&#27604;&#20363;&#24120;&#25968;&#36827;&#34892;&#35780;&#20272;&#12290;&#20256;&#32479;&#30340;&#19968;&#33268;Bayesian&#26041;&#27861;&#65292;&#22914;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;(SMC)&#21644;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;(MCMC)&#65292;&#20855;&#26377;&#26080;&#30028;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#35201;&#27714;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#24182;&#34892;&#30340;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;(pSMC)&#26041;&#27861;&#65292;&#21487;&#20197;&#35777;&#26126;&#23427;&#20855;&#26377;&#24182;&#34892;&#24378;&#25193;&#23637;&#24615;&#65292;&#21363;&#22914;&#26524;&#20801;&#35768;&#24322;&#27493;&#36827;&#31243;&#25968;&#37327;&#22686;&#38271;&#65292;&#26102;&#38388;&#22797;&#26434;&#24615;(&#21644;&#27599;&#20010;&#33410;&#28857;&#30340;&#20869;&#23384;)&#20173;&#28982;&#20445;&#25345;&#26377;&#30028;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;pSMC&#20855;&#26377;MSE$=O(1/NR)$&#30340;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$N$&#34920;&#31034;&#27599;&#20010;&#22788;&#29702;&#22120;&#20013;&#30340;&#36890;&#20449;&#26679;&#26412;&#25968;&#37327;&#65292;$R$&#34920;&#31034;&#22788;&#29702;&#22120;&#25968;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#36866;&#24403;&#22823;&#30340;&#38382;&#39064;&#30456;&#20851;$N$&#65292;&#24403;$R\rightarrow \infty$&#26102;&#65292;&#35813;&#26041;&#27861;&#20197;&#22266;&#23450;&#26377;&#38480;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;Cost$=O(1)$&#25910;&#25947;&#21040;&#26080;&#31351;&#23567;&#31934;&#24230;MSE$=O(\varepsilon^2)$&#65292;&#27809;&#26377;&#25928;&#29575;&#27844;&#28431;&#65292;&#21363;&#35745;&#31639;&#22797;&#26434;&#24615;Cost$=O(\varepsilon)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the general framework of Bayesian inference, the target distribution can only be evaluated up-to a constant of proportionality. Classical consistent Bayesian methods such as sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC) have unbounded time complexity requirements. We develop a fully parallel sequential Monte Carlo (pSMC) method which provably delivers parallel strong scaling, i.e. the time complexity (and per-node memory) remains bounded if the number of asynchronous processes is allowed to grow. More precisely, the pSMC has a theoretical convergence rate of MSE$ = O(1/NR)$, where $N$ denotes the number of communicating samples in each processor and $R$ denotes the number of processors. In particular, for suitably-large problem-dependent $N$, as $R \rightarrow \infty$ the method converges to infinitesimal accuracy MSE$=O(\varepsilon^2)$ with a fixed finite time-complexity Cost$=O(1)$ and with no efficiency leakage, i.e. computational complexity Cost$=O(\varepsilon
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#65292;&#36890;&#36807;Wasserstein&#36817;&#31471;&#31639;&#23376;&#21644;&#24179;&#22343;&#22330;&#21338;&#24328;&#21487;&#20197;&#25551;&#36848;&#29983;&#25104;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36890;&#36807;&#35299;&#32806;&#21512;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#21487;&#20197;&#33719;&#24471;&#20248;&#21270;&#26465;&#20214;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#26680;&#30340;&#24471;&#20998;&#20989;&#25968;&#27169;&#22411;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.06162</link><description>&lt;p&gt;
Wasserstein&#36817;&#31471;&#31639;&#23376;&#25551;&#36848;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#24182;&#35299;&#20915;&#35760;&#24518;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Wasserstein proximal operators describe score-based generative models and resolve memorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06162
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#65292;&#36890;&#36807;Wasserstein&#36817;&#31471;&#31639;&#23376;&#21644;&#24179;&#22343;&#22330;&#21338;&#24328;&#21487;&#20197;&#25551;&#36848;&#29983;&#25104;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36890;&#36807;&#35299;&#32806;&#21512;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#21487;&#20197;&#33719;&#24471;&#20248;&#21270;&#26465;&#20214;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#26680;&#30340;&#24471;&#20998;&#20989;&#25968;&#27169;&#22411;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20851;&#27880;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#30340;&#22522;&#26412;&#25968;&#23398;&#32467;&#26500;&#12290;&#25105;&#20204;&#39318;&#20808;&#29992;Wasserstein&#36817;&#31471;&#31639;&#23376;&#65288;WPO&#65289;&#26469;&#26500;&#24314;SGMs&#65292;&#24182;&#35777;&#26126;&#36890;&#36807;&#24179;&#22343;&#22330;&#21338;&#24328;&#65288;MFGs&#65289;&#65292;WPO&#30340;&#32467;&#26500;&#25581;&#31034;&#20102;&#25551;&#36848;&#25193;&#25955;&#21644;&#22522;&#20110;&#20998;&#25968;&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#25968;&#23398;&#32467;&#26500;&#12290;&#29305;&#21035;&#26159;&#65292;MFGs&#20197;&#19968;&#23545;&#32806;&#21512;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24418;&#24335;&#32473;&#20986;&#20102;&#26368;&#20248;&#24615;&#26465;&#20214;&#65306;&#19968;&#31181;&#21069;&#21521;&#25511;&#21046;&#30340;Fokker-Planck&#65288;FP&#65289;&#26041;&#31243;&#21644;&#19968;&#31181;&#21521;&#21518;&#30340;Hamilton-Jacobi-Bellman&#65288;HJB&#65289;&#26041;&#31243;&#12290;&#36890;&#36807;Cole-Hopf&#21464;&#25442;&#24182;&#21033;&#29992;&#20132;&#21449;&#29109;&#21487;&#20197;&#19982;&#23494;&#24230;&#30340;&#32447;&#24615;&#27867;&#20989;&#30456;&#20851;&#32852;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;HJB&#26041;&#31243;&#26159;&#19968;&#31181;&#26080;&#25511;&#21046;&#30340;FP&#26041;&#31243;&#12290;&#20854;&#27425;&#65292;&#21033;&#29992;&#25163;&#22836;&#30340;&#25968;&#23398;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#22522;&#20110;&#26680;&#30340;&#24471;&#20998;&#20989;&#25968;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;SGMs&#22312;&#35757;&#32451;&#26679;&#26412;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on the fundamental mathematical structure of score-based generative models (SGMs). We first formulate SGMs in terms of the Wasserstein proximal operator (WPO) and demonstrate that, via mean-field games (MFGs), the WPO formulation reveals mathematical structure that describes the inductive bias of diffusion and score-based models. In particular, MFGs yield optimality conditions in the form of a pair of coupled partial differential equations: a forward-controlled Fokker-Planck (FP) equation, and a backward Hamilton-Jacobi-Bellman (HJB) equation. Via a Cole-Hopf transformation and taking advantage of the fact that the cross-entropy can be related to a linear functional of the density, we show that the HJB equation is an uncontrolled FP equation. Second, with the mathematical structure at hand, we present an interpretable kernel-based model for the score function which dramatically improves the performance of SGMs in terms of training samples and training time. In addition, the WP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#26469;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06160</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#26469;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#29616;&#20195;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#65292;&#20854;&#20013;&#36890;&#36807;&#26368;&#23567;&#21270;&#29305;&#23450;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35757;&#32451;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20197;&#23398;&#20064;&#39044;&#27979;&#20998;&#24067;&#19978;&#30340;&#20803;&#20998;&#24067;&#12290;&#23613;&#31649;&#29616;&#26377;&#26041;&#27861;&#22312;&#32463;&#39564;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#24378;&#22823;&#65292;&#20294;Bengs&#31561;&#20154;&#30340;&#26368;&#36817;&#30740;&#31350;&#21457;&#29616;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19968;&#20010;&#26681;&#26412;&#32570;&#38519;&#65306;&#21363;&#20351;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#65292;&#23398;&#20064;&#21040;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#12290;&#36890;&#36807;&#25552;&#20379;&#25991;&#29486;&#20013;&#19968;&#31867;&#24191;&#27867;&#20351;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36825;&#20010;&#35266;&#23519;&#30340;&#35777;&#23454;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;EDL&#26041;&#27861;&#26412;&#36136;&#19978;&#36890;&#36807;&#26368;&#23567;&#21270;&#20998;&#24067;&#19982;&#19982;&#26679;&#26412;&#22823;&#23567;&#26080;&#20851;&#30340;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#29305;&#23450;&#24046;&#24322;&#24230;&#37327;&#26469;&#35757;&#32451;&#20803;&#20998;&#24067;&#65292;&#20174;&#32780;&#20135;&#29983;&#38169;&#35823;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#29702;&#35770;&#21407;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#23558;&#20854;&#24314;&#27169;&#20026;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#28151;&#21512;&#29289;&#26469;&#23398;&#20064;&#19968;&#33268;&#30446;&#26631;&#20998;&#24067;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;EDL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a sample-size-independent target distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and lear
&lt;/p&gt;</description></item><item><title>POTEC&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#31574;&#30053;&#20998;&#35299;&#30340;&#31639;&#27861;&#65292;&#22312;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#20013;&#26377;&#25928;&#36827;&#34892;&#31163;&#31574;&#30053;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#32858;&#31867;&#36873;&#25321;&#31532;&#19968;&#38454;&#27573;&#31574;&#30053;&#65292;&#24182;&#21033;&#29992;&#22238;&#24402;&#26041;&#27861;&#36873;&#25321;&#27599;&#20010;&#32858;&#31867;&#20869;&#30340;&#20855;&#20307;&#21160;&#20316;&#12290;</title><link>https://arxiv.org/abs/2402.06151</link><description>&lt;p&gt;
POTEC:&#36890;&#36807;&#20004;&#38454;&#27573;&#31574;&#30053;&#20998;&#35299;&#30340;&#22823;&#21160;&#20316;&#31354;&#38388;&#31163;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
POTEC: Off-Policy Learning for Large Action Spaces via Two-Stage Policy Decomposition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06151
&lt;/p&gt;
&lt;p&gt;
POTEC&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#31574;&#30053;&#20998;&#35299;&#30340;&#31639;&#27861;&#65292;&#22312;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#20013;&#26377;&#25928;&#36827;&#34892;&#31163;&#31574;&#30053;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#32858;&#31867;&#36873;&#25321;&#31532;&#19968;&#38454;&#27573;&#31574;&#30053;&#65292;&#24182;&#21033;&#29992;&#22238;&#24402;&#26041;&#27861;&#36873;&#25321;&#27599;&#20010;&#32858;&#31867;&#20869;&#30340;&#20855;&#20307;&#21160;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#30340;&#24773;&#22659;&#21534;&#22124;&#26426;&#21046;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;(OPL)&#65292;&#29616;&#26377;&#26041;&#27861;&#22823;&#22810;&#20381;&#36182;&#20110;&#22238;&#24402;&#27169;&#22411;&#25110;&#37325;&#35201;&#24615;&#21152;&#26435;&#31574;&#30053;&#26799;&#24230;&#65292;&#20294;&#30001;&#20110;&#36807;&#39640;&#30340;&#20559;&#24046;&#25110;&#26041;&#24046;&#32780;&#22833;&#36133;&#12290;&#20026;&#20102;&#20811;&#26381;OPL&#20013;&#30340;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#65292;&#31216;&#20026;&#20004;&#38454;&#27573;&#31574;&#30053;&#20998;&#35299;&#30340;&#31574;&#30053;&#20248;&#21270;(POTEC)&#12290;&#23427;&#21033;&#29992;&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#32858;&#31867;&#65292;&#24182;&#20998;&#21035;&#36890;&#36807;&#22522;&#20110;&#31574;&#30053;&#21644;&#22238;&#24402;&#30340;&#26041;&#27861;&#23398;&#20064;&#20004;&#31181;&#19981;&#21516;&#30340;&#31574;&#30053;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#20302;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#22522;&#20110;&#31574;&#30053;&#30340;&#26041;&#27861;&#39640;&#25928;&#22320;&#23398;&#20064;&#31532;&#19968;&#38454;&#27573;&#31574;&#30053;&#20197;&#36873;&#25321;&#32858;&#31867;&#12290;&#20026;&#20102;&#22312;&#31532;&#19968;&#38454;&#27573;&#31574;&#30053;&#37319;&#26679;&#30340;&#32858;&#31867;&#20013;&#36873;&#25321;&#29305;&#23450;&#21160;&#20316;&#65292;POTEC&#22312;&#27599;&#20010;&#32858;&#31867;&#20013;&#20351;&#29992;&#26469;&#33258;&#22238;&#24402;&#26041;&#27861;&#30340;&#31532;&#20108;&#38454;&#27573;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#23616;&#37096;&#27491;&#30830;&#24615;&#26465;&#20214;&#65292;&#35813;&#26465;&#20214;&#20165;&#35201;&#27714;&#22238;&#24402;&#27169;&#22411;&#20445;&#25345;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study off-policy learning (OPL) of contextual bandit policies in large discrete action spaces where existing methods -- most of which rely crucially on reward-regression models or importance-weighted policy gradients -- fail due to excessive bias or variance. To overcome these issues in OPL, we propose a novel two-stage algorithm, called Policy Optimization via Two-Stage Policy Decomposition (POTEC). It leverages clustering in the action space and learns two different policies via policy- and regression-based approaches, respectively. In particular, we derive a novel low-variance gradient estimator that enables to learn a first-stage policy for cluster selection efficiently via a policy-based approach. To select a specific action within the cluster sampled by the first-stage policy, POTEC uses a second-stage policy derived from a regression-based approach within each cluster. We show that a local correctness condition, which only requires that the regression model preserves the rela
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEAK&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#30340;&#26816;&#39564;&#12290;PEAK&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.06122</link><description>&lt;p&gt;
&#20351;&#29992;PEAK&#36827;&#34892;&#31397;&#25506;&#65306;&#22810;&#20010;&#25968;&#25454;&#27969;&#22343;&#20540;&#30340;&#39034;&#24207;&#12289;&#38750;&#21442;&#25968;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEAK&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#30340;&#26816;&#39564;&#12290;PEAK&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21517;&#20026;PEAK&#65288;&#22522;&#20110;&#26399;&#26395;&#24179;&#22343;&#36164;&#20135;&#30340;&#31397;&#25506;&#65289;&#65292;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#30340;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#27979;&#35797;&#12290;PEAK&#22312;&#35745;&#31639;&#19978;&#21487;&#34892;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#25105;&#20204;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;&#38408;&#20540;&#35782;&#21035;&#20219;&#21153;&#20013;&#23545;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, \emph{peeking with expectation-based averaged capital} (PEAK), builds upon the testing-as-betting framework and provides a non-asymptotic $\alpha$-level test across any stopping time. PEAK is computationally tractable and efficiently rejects hypotheses that are incorrect across all potential distributions that satisfy our nonparametric assumption, enabling joint composite hypothesis testing on multiple streams of data. We numerically validate our theoretical findings under the best arm identification and threshold identification in the bandit setting, illustrating the computational efficiency of our method against state-of-the-art testing methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;&#31639;&#27861;&#30340;&#26032;&#39062;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33021;&#37327;&#20989;&#25968;&#21644;&#26799;&#24230;&#36827;&#34892;&#35757;&#32451;&#65292;&#26080;&#38656;&#25968;&#25454;&#26679;&#26412;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#29983;&#25104;&#32479;&#35745;&#29420;&#31435;&#30340;&#26679;&#26412;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#24230;&#19978;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#25193;&#25955;&#30340;&#24555;&#36895;&#27169;&#24335;&#28151;&#21512;&#34892;&#20026;&#65292;&#23454;&#29616;&#20102;&#23545;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#28369;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#21644;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2402.06121</link><description>&lt;p&gt;
&#36890;&#36807;&#36845;&#20195;&#21435;&#22122;&#33021;&#37327;&#21305;&#37197;&#20174;&#29627;&#23572;&#20857;&#26364;&#23494;&#24230;&#20013;&#36827;&#34892;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Iterated Denoising Energy Matching for Sampling from Boltzmann Densities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06121
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;&#31639;&#27861;&#30340;&#26032;&#39062;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#33021;&#37327;&#20989;&#25968;&#21644;&#26799;&#24230;&#36827;&#34892;&#35757;&#32451;&#65292;&#26080;&#38656;&#25968;&#25454;&#26679;&#26412;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#29983;&#25104;&#32479;&#35745;&#29420;&#31435;&#30340;&#26679;&#26412;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#24230;&#19978;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#25193;&#25955;&#30340;&#24555;&#36895;&#27169;&#24335;&#28151;&#21512;&#34892;&#20026;&#65292;&#23454;&#29616;&#20102;&#23545;&#33021;&#37327;&#26223;&#35266;&#30340;&#24179;&#28369;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#21644;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#22320;&#20174;&#26410;&#26631;&#20934;&#21270;&#30340;&#27010;&#29575;&#20998;&#24067;&#20013;&#29983;&#25104;&#32479;&#35745;&#29420;&#31435;&#30340;&#26679;&#26412;&#65292;&#27604;&#22914;&#22810;&#20307;&#31995;&#32479;&#30340;&#24179;&#34913;&#26679;&#26412;&#65292;&#26159;&#31185;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#30784;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36845;&#20195;&#21435;&#22122;&#33021;&#37327;&#21305;&#37197;&#65288;iDEM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36845;&#20195;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#65292;&#20165;&#20351;&#29992;&#33021;&#37327;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230; - &#32780;&#19981;&#26159;&#25968;&#25454;&#26679;&#26412; - &#26469;&#35757;&#32451;&#25193;&#25955;&#22522;&#30784;&#30340;&#37319;&#26679;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;iDEM&#22312;&#20197;&#19979;&#20004;&#20010;&#27493;&#39588;&#20043;&#38388;&#20132;&#26367;&#36827;&#34892;&#65306;&#65288;I&#65289;&#20174;&#25193;&#25955;&#22522;&#30784;&#30340;&#37319;&#26679;&#22120;&#20013;&#37319;&#26679;&#39640;&#27169;&#22411;&#23494;&#24230;&#30340;&#21306;&#22495;&#65292;&#21644;&#65288;II&#65289;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#22312;&#25105;&#20204;&#30340;&#38543;&#26426;&#21305;&#37197;&#30446;&#26631;&#20013;&#36827;&#19968;&#27493;&#25913;&#36827;&#37319;&#26679;&#22120;&#12290;iDEM&#22312;&#39640;&#32500;&#24230;&#19978;&#26159;&#21487;&#25193;&#23637;&#30340;&#65292;&#20869;&#37096;&#21305;&#37197;&#30446;&#26631;&#26159;&#26080;&#38656;&#27169;&#25311;&#30340;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;MCMC&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21033;&#29992;&#25193;&#25955;&#30340;&#24555;&#36895;&#27169;&#24335;&#28151;&#21512;&#34892;&#20026;&#65292;iDEM&#24179;&#28369;&#20102;&#33021;&#37327;&#32972;&#26223;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#25506;&#32034;&#21644;&#23398;&#20064;&#30340;&#20998;&#25674;&#37319;&#26679;&#22120;&#12290;&#25105;&#20204;&#23545;&#19968;&#31995;&#21015;&#20219;&#21153;&#36827;&#34892;&#20102;iDEM&#30340;&#35780;&#20272;...
&lt;/p&gt;
&lt;p&gt;
Efficiently generating statistically independent samples from an unnormalized probability distribution, such as equilibrium samples of many-body systems, is a foundational problem in science. In this paper, we propose Iterated Denoising Energy Matching (iDEM), an iterative algorithm that uses a novel stochastic score matching objective leveraging solely the energy function and its gradient -- and no data samples -- to train a diffusion-based sampler. Specifically, iDEM alternates between (I) sampling regions of high model density from a diffusion-based sampler and (II) using these samples in our stochastic matching objective to further improve the sampler. iDEM is scalable to high dimensions as the inner matching objective, is simulation-free, and requires no MCMC samples. Moreover, by leveraging the fast mode mixing behavior of diffusion, iDEM smooths out the energy landscape enabling efficient exploration and learning of an amortized sampler. We evaluate iDEM on a suite of tasks rang
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20174;&#31639;&#23376;&#23398;&#20064;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#26144;&#23556;&#65292;&#25552;&#20986;&#20102;&#36866;&#24212;&#26377;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#20613;&#37324;&#21494;&#31070;&#32463;&#26144;&#23556;&#26694;&#26550;&#65292;&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#26469;&#25903;&#25345;&#35813;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23398;&#20064;PtO&#26144;&#23556;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#21644;&#20808;&#23398;&#20064;&#35299;&#31639;&#23376;&#20877;&#35745;&#31639;&#21487;&#35266;&#27979;&#20540;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06031</link><description>&lt;p&gt;
&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#26144;&#23556;&#30340;&#31639;&#23376;&#23398;&#20064;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
An operator learning perspective on parameter-to-observable maps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06031
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20174;&#31639;&#23376;&#23398;&#20064;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#26144;&#23556;&#65292;&#25552;&#20986;&#20102;&#36866;&#24212;&#26377;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#20613;&#37324;&#21494;&#31070;&#32463;&#26144;&#23556;&#26694;&#26550;&#65292;&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#26469;&#25903;&#25345;&#35813;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23398;&#20064;PtO&#26144;&#23556;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#21644;&#20808;&#23398;&#20064;&#35299;&#31639;&#23376;&#20877;&#35745;&#31639;&#21487;&#35266;&#27979;&#20540;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#39640;&#25928;&#30340;&#21442;&#25968;&#21270;&#29289;&#29702;&#27169;&#22411;&#26367;&#20195;&#21697;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#31639;&#23376;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#21487;&#20197;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#36827;&#34892;&#26144;&#23556;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;&#21482;&#26377;&#26377;&#38480;&#32500;&#30340;&#27169;&#22411;&#36755;&#20837;&#21442;&#25968;&#21270;&#25110;&#26377;&#38480;&#32500;&#30340;&#27169;&#22411;&#36755;&#20986;&#21487;&#35266;&#27979;&#25968;&#25454;&#21487;&#29992;&#65292;&#32780;&#19981;&#26159;&#20840;&#22330;&#27979;&#37327;&#25968;&#25454;&#12290;&#26412;&#25991;&#22522;&#20110;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#65292;&#24341;&#20837;&#20102;&#20613;&#37324;&#21494;&#31070;&#32463;&#26144;&#23556;&#65288;Fourier Neural Mappings&#65292;FNMs&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#36866;&#24212;&#36825;&#26679;&#30340;&#26377;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#12290;&#26412;&#25991;&#20026;&#35813;&#26041;&#27861;&#21457;&#23637;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#12290;&#27492;&#22806;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#24213;&#23618;&#30340;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#65288;PtO&#65289;&#26144;&#23556;&#26159;&#36890;&#36807;&#26080;&#31351;&#32500;&#31639;&#23376;&#26469;&#38544;&#24335;&#23450;&#20041;&#30340;&#65292;&#20363;&#22914;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#31639;&#23376;&#12290;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#26159;&#65292;&#26159;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;PtO&#26144;&#23556;&#30340;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#36824;&#26159;&#39318;&#20808;&#23398;&#20064;&#35299;&#31639;&#23376;&#65292;&#28982;&#21518;&#35745;&#31639;&#21487;&#35266;&#27979;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computationally efficient surrogates for parametrized physical models play a crucial role in science and engineering. Operator learning provides data-driven surrogates that map between function spaces. However, instead of full-field measurements, often the available data are only finite-dimensional parametrizations of model inputs or finite observables of model outputs. Building off of Fourier Neural Operators, this paper introduces the Fourier Neural Mappings (FNMs) framework that is able to accommodate such finite-dimensional inputs and outputs. The paper develops universal approximation theorems for the method. Moreover, in many applications the underlying parameter-to-observable (PtO) map is defined implicitly through an infinite-dimensional operator, such as the solution operator of a partial differential equation. A natural question is whether it is more data-efficient to learn the PtO map end-to-end or first learn the solution operator and subsequently compute the observable fro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#36719;&#20214;Gurobi&#35299;&#20915;&#36275;&#22815;&#20998;&#25955;&#26465;&#20214;&#26816;&#39564;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#21487;&#20197;&#22312;&#21512;&#29702;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#36827;&#34892;&#26816;&#26597;&#12290;</title><link>https://arxiv.org/abs/2402.06019</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#36719;&#20214;&#26816;&#39564;&#36275;&#22815;&#20998;&#25955;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
Checking the Sufficiently Scattered Condition using a Global Non-Convex Optimization Software
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#36719;&#20214;Gurobi&#35299;&#20915;&#36275;&#22815;&#20998;&#25955;&#26465;&#20214;&#26816;&#39564;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#21487;&#20197;&#22312;&#21512;&#29702;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#36827;&#34892;&#26816;&#26597;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36275;&#22815;&#20998;&#25955;&#26465;&#20214;&#65288;SSC&#65289;&#26159;&#30740;&#31350;&#21508;&#31181;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;&#30340;&#21487;&#36776;&#35782;&#24615;&#30340;&#20851;&#38190;&#26465;&#20214;&#65292;&#21253;&#25324;&#38750;&#36127;&#12289;&#26368;&#23567;&#20307;&#31215;&#12289;&#23545;&#31216;&#12289;&#21333;&#32431;&#32467;&#26500;&#21644;&#22810;&#38754;&#20307;&#30697;&#38453;&#20998;&#35299;&#12290;&#36275;&#22815;&#20998;&#25955;&#26465;&#20214;&#21487;&#20197;&#30830;&#20445;&#35745;&#31639;&#24471;&#21040;&#30340;&#30697;&#38453;&#20998;&#35299;&#26159;&#21807;&#19968;&#21487;&#36776;&#35782;&#30340;&#65292;&#38500;&#20102;&#24179;&#20961;&#30340;&#27169;&#31946;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#26465;&#20214;&#26159;NP&#38590;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#22312;&#30697;&#38453;&#30340;&#31209;&#19981;&#22826;&#22823;&#26102;&#65292;&#23427;&#21487;&#20197;&#22312;&#21512;&#29702;&#30340;&#26102;&#38388;&#20869;&#36827;&#34892;&#26816;&#26597;&#65292;&#23558;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#38750;&#20984;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#27714;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#36719;&#20214;Gurobi&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#23454;&#38469;&#19990;&#30028;&#30340;&#39640;&#20809;&#35889;&#22270;&#20687;&#19978;&#23637;&#31034;&#20102;&#35813;&#20195;&#30721;&#30340;&#21487;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sufficiently scattered condition (SSC) is a key condition in the study of identifiability of various matrix factorization problems, including nonnegative, minimum-volume, symmetric, simplex-structured, and polytopic matrix factorizations. The SSC allows one to guarantee that the computed matrix factorization is unique/identifiable, up to trivial ambiguities. However, this condition is NP-hard to check in general. In this paper, we show that it can however be checked in a reasonable amount of time in realistic scenarios, when the factorization rank is not too large. This is achieved by formulating the problem as a non-convex quadratic optimization problem over a bounded set. We use the global non-convex optimization software Gurobi, and showcase the usefulness of this code on synthetic data sets and on real-world hyperspectral images.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;&#38750;&#24182;&#34892;&#25903;&#25345;&#21521;&#37327;&#20998;&#31867;&#22120;(NPSVCs)&#30340;&#20998;&#31867;&#22120;&#23478;&#26063;&#65292;&#25552;&#20986;&#20102;NPSVC++&#65292;&#22522;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;NPSVC++&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#23454;&#29616;&#20102;NPSVC&#21450;&#20854;&#29305;&#24449;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#65292;&#36861;&#27714;&#24085;&#32047;&#25176;&#26368;&#20248;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#29305;&#24449;&#27425;&#20248;&#21644;&#31867;&#21035;&#20381;&#36182;&#30340;&#38382;&#39064;&#65292;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06010</link><description>&lt;p&gt;
NPSVC++: &#38750;&#24182;&#34892;&#20998;&#31867;&#22120;&#36935;&#21040;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
NPSVC++: Nonparallel Classifiers Encounter Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;&#38750;&#24182;&#34892;&#25903;&#25345;&#21521;&#37327;&#20998;&#31867;&#22120;(NPSVCs)&#30340;&#20998;&#31867;&#22120;&#23478;&#26063;&#65292;&#25552;&#20986;&#20102;NPSVC++&#65292;&#22522;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;NPSVC++&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#23454;&#29616;&#20102;NPSVC&#21450;&#20854;&#29305;&#24449;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#65292;&#36861;&#27714;&#24085;&#32047;&#25176;&#26368;&#20248;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#29305;&#24449;&#27425;&#20248;&#21644;&#31867;&#21035;&#20381;&#36182;&#30340;&#38382;&#39064;&#65292;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20391;&#37325;&#20110;&#19968;&#31181;&#29305;&#23450;&#30340;&#20998;&#31867;&#22120;&#23478;&#26063;&#65292;&#31216;&#20026;&#38750;&#24182;&#34892;&#25903;&#25345;&#21521;&#37327;&#20998;&#31867;&#22120;(NPSVCs)&#12290;&#19982;&#20856;&#22411;&#30340;&#20998;&#31867;&#22120;&#19981;&#21516;&#65292;NPSVC&#30340;&#35757;&#32451;&#28041;&#21450;&#22810;&#30446;&#26631;&#30340;&#26368;&#23567;&#21270;&#65292;&#23548;&#33268;&#29305;&#24449;&#27425;&#20248;&#21644;&#31867;&#21035;&#20381;&#36182;&#30340;&#28508;&#22312;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#23578;&#26410;&#24314;&#31435;&#26377;&#25928;&#30340;&#23398;&#20064;&#26041;&#26696;&#26469;&#36890;&#36807;&#34920;&#31034;&#23398;&#20064;&#65292;&#29305;&#21035;&#26159;&#28145;&#24230;&#23398;&#20064;&#26469;&#25913;&#21892;NPSVC&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#31361;&#30772;&#36825;&#19968;&#29942;&#39048;&#65292;&#25105;&#20204;&#22522;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#24320;&#21457;&#20102;NPSVC++&#65292;&#23454;&#29616;&#20102;NPSVC&#21450;&#20854;&#29305;&#24449;&#30340;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;&#36890;&#36807;&#36861;&#27714;&#24085;&#32047;&#25176;&#26368;&#20248;&#65292;NPSVC++&#22312;&#29702;&#35770;&#19978;&#30830;&#20445;&#20102;&#36328;&#31867;&#21035;&#30340;&#29305;&#24449;&#20248;&#21270;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#20811;&#26381;&#20102;&#19978;&#36848;&#20004;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#20598;&#20248;&#21270;&#30340;&#36890;&#29992;&#23398;&#20064;&#36807;&#31243;&#65292;&#24182;&#22522;&#20110;&#27492;&#25552;&#20379;&#20102;&#20004;&#20010;&#21487;&#24212;&#29992;&#30340;&#23454;&#20363;&#65292;K-NPSVC++&#21644;D-NPSVC++&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#29616;&#26377;&#26041;&#27861;&#19978;&#30340;&#20248;&#36234;&#24615;&#65292;&#24182;&#39564;&#35777;&#20102;NPSVC++&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on a specific family of classifiers called nonparallel support vector classifiers (NPSVCs). Different from typical classifiers, the training of an NPSVC involves the minimization of multiple objectives, resulting in the potential concerns of feature suboptimality and class dependency. Consequently, no effective learning scheme has been established to improve NPSVCs' performance through representation learning, especially deep learning. To break this bottleneck, we develop NPSVC++ based on multi-objective optimization, enabling the end-to-end learning of NPSVC and its features. By pursuing Pareto optimality, NPSVC++ theoretically ensures feature optimality across classes, hence effectively overcoming the two issues above. A general learning procedure via duality optimization is proposed, based on which we provide two applicable instances, K-NPSVC++ and D-NPSVC++. The experiments show their superiority over the existing methods and verify the efficacy of NPSVC++.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#24863;&#30693;&#30340;&#28151;&#21512;&#31209;&#21387;&#32553;&#31574;&#30053;&#26469;&#25552;&#39640;&#35270;&#35273;Transformer&#30340;&#20869;&#23384;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#36873;&#25321;&#24615;&#20302;&#31209;&#26435;&#37325;&#24352;&#37327;&#36817;&#20284;&#21644;&#23618;&#38388;&#35823;&#24046;&#34917;&#20607;&#25216;&#26415;&#26469;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#12290;&#36825;&#31181;&#31574;&#30053;&#36991;&#20813;&#20102;&#27973;&#23618;&#23616;&#37096;&#26368;&#23567;&#20540;&#38519;&#38449;&#65292;&#21516;&#26102;&#21462;&#24471;&#20102;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06004</link><description>&lt;p&gt;
&#20869;&#23384;&#39640;&#25928;&#30340;&#35270;&#35273;Transformer&#65306;&#19968;&#31181;&#28608;&#27963;&#24863;&#30693;&#30340;&#28151;&#21512;&#31209;&#21387;&#32553;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Memory-Efficient Vision Transformers: An Activation-Aware Mixed-Rank Compression Strategy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28608;&#27963;&#24863;&#30693;&#30340;&#28151;&#21512;&#31209;&#21387;&#32553;&#31574;&#30053;&#26469;&#25552;&#39640;&#35270;&#35273;Transformer&#30340;&#20869;&#23384;&#25928;&#29575;&#65292;&#24182;&#36890;&#36807;&#36873;&#25321;&#24615;&#20302;&#31209;&#26435;&#37325;&#24352;&#37327;&#36817;&#20284;&#21644;&#23618;&#38388;&#35823;&#24046;&#34917;&#20607;&#25216;&#26415;&#26469;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#12290;&#36825;&#31181;&#31574;&#30053;&#36991;&#20813;&#20102;&#27973;&#23618;&#23616;&#37096;&#26368;&#23567;&#20540;&#38519;&#38449;&#65292;&#21516;&#26102;&#21462;&#24471;&#20102;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35270;&#35273;Transformer&#65288;ViTs&#65289;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#19981;&#26029;&#21047;&#26032;&#26368;&#26032;&#35760;&#24405;&#65292;&#23427;&#20204;&#22312;&#25512;&#29702;&#24341;&#25806;&#19978;&#30340;&#23454;&#38469;&#37096;&#32626;&#24448;&#24448;&#21463;&#21040;&#26174;&#33879;&#30340;&#20869;&#23384;&#24102;&#23485;&#21644;&#65288;&#33455;&#29255;&#20869;&#65289;&#20869;&#23384;&#21344;&#29992;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#28608;&#27963;&#24863;&#30693;&#30340;&#27169;&#22411;&#21387;&#32553;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#19968;&#20869;&#23384;&#38480;&#21046;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#19981;&#21516;&#23618;&#30340;&#36873;&#25321;&#24615;&#20302;&#31209;&#26435;&#37325;&#24352;&#37327;&#36817;&#20284;&#26469;&#20943;&#23569;ViTs&#30340;&#21442;&#25968;&#25968;&#37327;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#26435;&#37325;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#21442;&#25968;&#39640;&#25928;&#30340;&#24352;&#37327;&#20043;&#21644;&#65292;&#21516;&#26102;&#23558;&#36755;&#20837;&#28608;&#27963;&#19982;&#21407;&#22987;&#26435;&#37325;&#24352;&#37327;&#30340;&#20056;&#31215;&#19982;&#36755;&#20837;&#28608;&#27963;&#19982;&#36817;&#20284;&#24352;&#37327;&#20043;&#21644;&#30340;&#20056;&#31215;&#20043;&#38388;&#30340;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;&#36890;&#36807;&#37319;&#29992;&#26377;&#25928;&#30340;&#36880;&#23618;&#35823;&#24046;&#34917;&#20607;&#25216;&#26415;&#65292;&#21033;&#29992;&#23618;&#36755;&#20986;&#25439;&#22833;&#30340;&#26799;&#24230;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#36825;&#31181;&#36817;&#20284;&#12290;&#36825;&#20123;&#25216;&#26415;&#30340;&#32452;&#21512;&#22312;&#36991;&#20813;&#38519;&#20837;&#27973;&#23618;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#21516;&#26102;&#21462;&#24471;&#20102;&#20248;&#31168;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
As Vision Transformers (ViTs) increasingly set new benchmarks in computer vision, their practical deployment on inference engines is often hindered by their significant memory bandwidth and (on-chip) memory footprint requirements. This paper addresses this memory limitation by introducing an activation-aware model compression methodology that uses selective low-rank weight tensor approximations of different layers to reduce the parameter count of ViTs. The key idea is to decompose the weight tensors into a sum of two parameter-efficient tensors while minimizing the error between the product of the input activations with the original weight tensor and the product of the input activations with the approximate tensor sum. This approximation is further refined by adopting an efficient layer-wise error compensation technique that uses the gradient of the layer's output loss. The combination of these techniques achieves excellent results while it avoids being trapped in a shallow local minim
&lt;/p&gt;</description></item><item><title>&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65288;BCI&#65289;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#21033;&#29992;&#22810;&#27493;&#39044;&#27979;&#26469;&#25552;&#20379;&#26657;&#20934;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21306;&#38388;&#12290;BCI&#22312;&#20219;&#24847;&#20998;&#24067;&#36716;&#25442;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#19979;&#23454;&#29616;&#20102;&#38271;&#26399;&#35206;&#30422;&#65292;&#19988;&#22312;&#27874;&#21160;&#29575;&#39044;&#27979;&#38382;&#39064;&#19978;&#29983;&#25104;&#26356;&#30701;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;</title><link>https://arxiv.org/abs/2402.05203</link><description>&lt;p&gt;
&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65306;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#39044;&#27979;&#21306;&#38388;&#30340;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Bellman Conformal Inference: Calibrating Prediction Intervals For Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05203
&lt;/p&gt;
&lt;p&gt;
&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65288;BCI&#65289;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#21033;&#29992;&#22810;&#27493;&#39044;&#27979;&#26469;&#25552;&#20379;&#26657;&#20934;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21306;&#38388;&#12290;BCI&#22312;&#20219;&#24847;&#20998;&#24067;&#36716;&#25442;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#19979;&#23454;&#29616;&#20102;&#38271;&#26399;&#35206;&#30422;&#65292;&#19988;&#22312;&#27874;&#21160;&#29575;&#39044;&#27979;&#38382;&#39064;&#19978;&#29983;&#25104;&#26356;&#30701;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65288;BCI&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22260;&#32469;&#20219;&#20309;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#25552;&#20379;&#26657;&#20934;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;BCI&#33021;&#22815;&#21033;&#29992;&#22810;&#27493;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#35299;&#20915;&#19968;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65288;SCP&#65289;&#26469;&#26174;&#24335;&#20248;&#21270;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#26469;&#25214;&#21040;SCP&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20219;&#24847;&#20998;&#24067;&#36716;&#25442;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#19979;&#65292;BCI&#33021;&#22815;&#23454;&#29616;&#38271;&#26399;&#35206;&#30422;&#65292;&#21363;&#20351;&#22810;&#27493;&#39044;&#27979;&#36739;&#24046;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#20013;&#21457;&#29616;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;BCI&#36991;&#20813;&#20102;&#26080;&#20449;&#24687;&#21306;&#38388;&#65288;&#38271;&#24230;&#26080;&#38480;&#65289;&#30340;&#29983;&#25104;&#65292;&#24182;&#22312;&#27874;&#21160;&#29575;&#39044;&#27979;&#38382;&#39064;&#19978;&#29983;&#25104;&#20102;&#26126;&#26174;&#26356;&#30701;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Bellman Conformal Inference (BCI), a framework that wraps around any time series forecasting models and provides calibrated prediction intervals. Unlike the existing methods, BCI is able to leverage multi-step ahead forecasts and explicitly optimize the average interval lengths by solving a one-dimensional stochastic control problem (SCP) at each time step. In particular, we use the dynamic programming algorithm to find the optimal policy for the SCP. We prove that BCI achieves long-term coverage under arbitrary distribution shifts and temporal dependence, even with poor multi-step ahead forecasts. We find empirically that BCI avoids uninformative intervals that have infinite lengths and generates substantially shorter prediction intervals on volatility forecasting problems when compared with existing methods.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#24863;&#30693;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#29992;&#20110;predict-then-optimize&#26694;&#26550;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#35777;&#25454;&#35777;&#23454;&#20102;&#20854;&#22312;&#35823;&#35774;&#32622;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.03256</link><description>&lt;p&gt;
&#23398;&#20064;Predict-then-Optimize&#26694;&#26550;&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning Best-in-Class Policies for the Predict-then-Optimize Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03256
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#24863;&#30693;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#29992;&#20110;predict-then-optimize&#26694;&#26550;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#35777;&#25454;&#35777;&#23454;&#20102;&#20854;&#22312;&#35823;&#35774;&#32622;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20915;&#31574;&#24863;&#30693;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#65292;&#31216;&#20026;Perturbation Gradient&#65288;PG&#65289;&#25439;&#22833;&#65292;&#29992;&#20110;predict-then-optimize&#26694;&#26550;&#12290;&#36825;&#20123;&#25439;&#22833;&#30452;&#25509;&#36817;&#20284;&#20102;&#19979;&#28216;&#20915;&#31574;&#25439;&#22833;&#65292;&#24182;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#20248;&#21270;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#19982;&#29616;&#26377;&#30340;&#26367;&#20195;&#25439;&#22833;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;PG&#25439;&#22833;&#30340;&#36817;&#20284;&#35823;&#24046;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#28040;&#22833;&#12290;&#36825;&#24847;&#21619;&#30528;&#20248;&#21270;&#25105;&#20204;&#30340;&#26367;&#20195;&#25439;&#22833;&#21487;&#20197;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#24471;&#21040;&#26368;&#20339;&#31574;&#30053;&#65292;&#21363;&#20351;&#22312;&#35823;&#35774;&#32622;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#35823;&#35774;&#32622;&#19979;&#30340;&#36825;&#26679;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#35777;&#25454;&#35777;&#23454;&#20102;&#24403;&#22522;&#30784;&#27169;&#22411;&#35823;&#35774;&#32622;&#19988;&#22122;&#22768;&#19981;&#26159;&#20013;&#24515;&#23545;&#31216;&#26102;&#65292;&#25105;&#20204;&#30340;PG&#25439;&#22833;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#30340;&#25552;&#26696;&#12290;&#37492;&#20110;&#22312;&#23454;&#36341;&#20013;&#35823;&#35774;&#32622;&#24456;&#24120;&#35265;--&#29305;&#21035;&#26159;&#24403;&#25105;&#20204;&#21487;&#33021;&#26356;&#21916;&#27426;&#19968;&#20010;&#26356;&#31616;&#21333;&#12289;&#26356;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#26102;--PG&#25439;&#22833;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#29702;&#35770;&#19978;&#26377;&#20381;&#25454;&#30340;&#12289;&#21487;&#35745;&#31639;&#30340;&#20915;&#31574;&#24863;&#30693;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel family of decision-aware surrogate losses, called Perturbation Gradient (PG) losses, for the predict-then-optimize framework. These losses directly approximate the downstream decision loss and can be optimized using off-the-shelf gradient-based methods. Importantly, unlike existing surrogate losses, the approximation error of our PG losses vanishes as the number of samples grows. This implies that optimizing our surrogate loss yields a best-in-class policy asymptotically, even in misspecified settings. This is the first such result in misspecified settings and we provide numerical evidence confirming our PG losses substantively outperform existing proposals when the underlying model is misspecified and the noise is not centrally symmetric. Insofar as misspecification is commonplace in practice -- especially when we might prefer a simpler, more interpretable model -- PG losses offer a novel, theoretically justified, method for computationally tractable decision-aware 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20844;&#24179;&#30340;Wasserstein&#26680;&#24515;&#38598;(FWC)&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#22987;&#25968;&#25454;&#38598;&#19982;&#21152;&#26435;&#21512;&#25104;&#26679;&#26412;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#65292;&#24182;&#24378;&#21046;&#23454;&#29616;&#20154;&#21475;&#24179;&#31561;&#65292;&#29983;&#25104;&#20844;&#24179;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#21487;&#29992;&#20110;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2311.05436</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#23454;&#29616;&#20844;&#24179;&#30340;&#26680;&#24515;&#38598;
&lt;/p&gt;
&lt;p&gt;
Fair Coresets via Optimal Transport
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.05436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20844;&#24179;&#30340;Wasserstein&#26680;&#24515;&#38598;(FWC)&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#22987;&#25968;&#25454;&#38598;&#19982;&#21152;&#26435;&#21512;&#25104;&#26679;&#26412;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#65292;&#24182;&#24378;&#21046;&#23454;&#29616;&#20154;&#21475;&#24179;&#31561;&#65292;&#29983;&#25104;&#20844;&#24179;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#21487;&#29992;&#20110;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31934;&#28860;&#21644;&#26680;&#24515;&#38598;&#24050;&#25104;&#20026;&#29983;&#25104;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#30340;&#36739;&#23567;&#20195;&#34920;&#24615;&#26679;&#26412;&#38598;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#26426;&#22120;&#23398;&#20064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#31038;&#20250;&#23618;&#38754;&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#20351;&#24471;&#27169;&#22411;&#26500;&#24314;&#32773;&#24517;&#39035;&#35299;&#20915;&#23384;&#22312;&#20110;&#25968;&#25454;&#20013;&#30340;&#23376;&#32676;&#20307;&#30340;&#22266;&#26377;&#20559;&#35265;&#38382;&#39064;&#12290;&#24403;&#21069;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#30456;&#23545;&#20110;&#21407;&#22987;&#26679;&#26412;&#30340;&#23616;&#37096;&#23646;&#24615;&#26469;&#21019;&#24314;&#20844;&#24179;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#20294;&#20854;&#23545;&#19979;&#28216;&#23398;&#20064;&#36807;&#31243;&#30340;&#24433;&#21709;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20844;&#24179;&#30340;Wasserstein&#26680;&#24515;&#38598;&#65288;FWC&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#24515;&#38598;&#26041;&#27861;&#65292;&#23427;&#29983;&#25104;&#26082;&#20855;&#26377;&#20844;&#24179;&#24615;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#21448;&#20855;&#26377;&#29992;&#20110;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#30340;&#26679;&#26412;&#32423;&#26435;&#37325;&#12290;FWC&#26368;&#23567;&#21270;&#21407;&#22987;&#25968;&#25454;&#38598;&#19982;&#21152;&#26435;&#21512;&#25104;&#26679;&#26412;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#65292;&#21516;&#26102;&#24378;&#21046;&#23454;&#29616;&#20154;&#21475;&#24179;&#31561;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;FWC&#30340;&#26080;&#32422;&#26463;&#29256;&#26412;&#31561;&#20215;&#20110;&#36890;&#24120;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;FWC&#30340;&#26377;&#25928;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. Current approaches create fair synthetic representative samples by optimizing local properties relative to the original samples, but their effect on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC minimizes the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equiv
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#23398;&#20064;&#36807;&#31243;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#28508;&#22312;&#23384;&#22312;&#37325;&#23614;&#39118;&#38505;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20351;&#29992;CVaR&#25110;DRO&#39118;&#38505;&#31561;&#26367;&#20195;&#26631;&#20934;&#24471;&#21040;&#30340;&#26368;&#20339;&#20505;&#36873;&#26041;&#26696;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2301.11584</link><description>&lt;p&gt;
&#20855;&#26377;&#21516;&#26102;&#35843;&#25972;&#23610;&#24230;&#30340;&#20581;&#22766;&#26041;&#24046;&#27491;&#21017;&#21270;&#39118;&#38505;&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust variance-regularized risk minimization with concomitant scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.11584
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#23398;&#20064;&#36807;&#31243;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#28508;&#22312;&#23384;&#22312;&#37325;&#23614;&#39118;&#38505;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20351;&#29992;CVaR&#25110;DRO&#39118;&#38505;&#31561;&#26367;&#20195;&#26631;&#20934;&#24471;&#21040;&#30340;&#26368;&#20339;&#20505;&#36873;&#26041;&#26696;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28508;&#22312;&#23384;&#22312;&#37325;&#23614;&#39118;&#38505;&#30340;&#25439;&#22833;&#20989;&#25968;&#19979;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26368;&#23567;&#21270;&#25439;&#22833;&#22343;&#20540;&#21644;&#26631;&#20934;&#24046;&#20043;&#21644;&#30340;&#20219;&#21153;&#65292;&#32780;&#26080;&#38656;&#31934;&#30830;&#20272;&#35745;&#26041;&#24046;&#12290;&#36890;&#36807;&#20462;&#25913;&#19968;&#31181;&#26080;&#26041;&#24046;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#25216;&#26415;&#20197;&#36866;&#24212;&#25105;&#20204;&#30340;&#38382;&#39064;&#35774;&#23450;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#31616;&#21333;&#30340;&#23398;&#20064;&#36807;&#31243;&#65292;&#21487;&#20197;&#19982;&#26631;&#20934;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#27714;&#35299;&#22120;&#36731;&#26494;&#32467;&#21512;&#65292;&#29992;&#20110;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#31243;&#20013;&#12290;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#23613;&#31649;&#31616;&#21333;&#65292;&#20294;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20351;&#29992;CVaR&#25110;DRO&#39118;&#38505;&#31561;&#26367;&#20195;&#26631;&#20934;&#24471;&#21040;&#30340;&#26368;&#20339;&#20505;&#36873;&#26041;&#26696;&#30456;&#24403;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;</title><link>https://arxiv.org/abs/2212.04382</link><description>&lt;p&gt;
&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#65306;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Structure of Classifier Boundaries: Case Study for a Naive Bayes Classifier
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.04382
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22270;&#24418;&#36755;&#20837;&#31354;&#38388;&#20013;&#65292;&#20998;&#31867;&#22120;&#36793;&#30028;&#30340;&#32467;&#26500;&#12290;&#36890;&#36807;&#21019;&#24314;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#26159;&#24040;&#22823;&#19988;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#35770;&#22522;&#20110;&#27169;&#22411;&#12289;&#35757;&#32451;&#25968;&#25454;&#36824;&#26159;&#20108;&#32773;&#32452;&#21512;&#65292;&#20998;&#31867;&#22120;&#23558;&#65288;&#21487;&#33021;&#22797;&#26434;&#30340;&#65289;&#36755;&#20837;&#25968;&#25454;&#24402;&#20837;&#30456;&#23545;&#36739;&#23569;&#30340;&#36755;&#20986;&#31867;&#21035;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312;&#36755;&#20837;&#31354;&#38388;&#20026;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36793;&#30028;&#30340;&#32467;&#26500;&#8212;&#8212;&#37027;&#20123;&#34987;&#20998;&#31867;&#20026;&#19981;&#21516;&#31867;&#21035;&#30340;&#37051;&#36817;&#28857;&#8212;&#8212;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#30340;&#31185;&#23398;&#32972;&#26223;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#26420;&#32032;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#30001;&#19979;&#19968;&#20195;&#27979;&#24207;&#20202;&#29983;&#25104;&#30340;DNA&#35835;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36793;&#30028;&#26082;&#26159;&#24040;&#22823;&#30340;&#65292;&#21448;&#20855;&#26377;&#22797;&#26434;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#31216;&#20026;&#37051;&#23621;&#30456;&#20284;&#24230;&#65292;&#23427;&#23558;&#19968;&#20010;&#28857;&#30340;&#32467;&#26524;&#19982;&#20854;&#37051;&#23621;&#30340;&#32467;&#26524;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#12290;&#36825;&#20010;&#24230;&#37327;&#19981;&#20165;&#36861;&#36394;&#20102;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#20004;&#20010;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#36824;&#21487;&#20197;&#22312;&#27809;&#26377;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#30340;&#20998;&#31867;&#22120;&#19978;&#23454;&#29616;&#65292;&#20294;&#38656;&#35201;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whether based on models, training data or a combination, classifiers place (possibly complex) input data into one of a relatively small number of output categories. In this paper, we study the structure of the boundary--those points for which a neighbor is classified differently--in the context of an input space that is a graph, so that there is a concept of neighboring inputs, The scientific setting is a model-based naive Bayes classifier for DNA reads produced by Next Generation Sequencers. We show that the boundary is both large and complicated in structure. We create a new measure of uncertainty, called Neighbor Similarity, that compares the result for a point to the distribution of results for its neighbors. This measure not only tracks two inherent uncertainty measures for the Bayes classifier, but also can be implemented, at a computational cost, for classifiers without inherent measures of uncertainty.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#28508;&#22312;&#24230;&#37327;&#27169;&#22411;&#20174;&#25968;&#25454;&#20013;&#24471;&#20986;&#20102;&#20016;&#23500;&#32780;&#22797;&#26434;&#30340;&#27969;&#24418;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#37322;&#27969;&#24418;&#20551;&#35774;&#30340;&#32479;&#35745;&#35299;&#37322;&#12290;&#35813;&#30740;&#31350;&#20026;&#21457;&#29616;&#21644;&#35299;&#37322;&#39640;&#32500;&#25968;&#25454;&#30340;&#20960;&#20309;&#32467;&#26500;&#20197;&#21450;&#25506;&#32034;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2208.11665</link><description>&lt;p&gt;
&#32479;&#35745;&#23545;&#27969;&#24418;&#20551;&#35774;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Statistical exploration of the Manifold Hypothesis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.11665
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#28508;&#22312;&#24230;&#37327;&#27169;&#22411;&#20174;&#25968;&#25454;&#20013;&#24471;&#20986;&#20102;&#20016;&#23500;&#32780;&#22797;&#26434;&#30340;&#27969;&#24418;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#37322;&#27969;&#24418;&#20551;&#35774;&#30340;&#32479;&#35745;&#35299;&#37322;&#12290;&#35813;&#30740;&#31350;&#20026;&#21457;&#29616;&#21644;&#35299;&#37322;&#39640;&#32500;&#25968;&#25454;&#30340;&#20960;&#20309;&#32467;&#26500;&#20197;&#21450;&#25506;&#32034;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#20551;&#35774;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24191;&#20026;&#25509;&#21463;&#30340;&#29702;&#35770;&#65292;&#23427;&#35748;&#20026;&#21517;&#20041;&#19978;&#30340;&#39640;&#32500;&#25968;&#25454;&#23454;&#38469;&#19978;&#38598;&#20013;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#20013;&#12290;&#36825;&#31181;&#29616;&#35937;&#22312;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#30340;&#24773;&#20917;&#20013;&#32463;&#39564;&#24615;&#22320;&#35266;&#23519;&#21040;&#65292;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#24050;&#32463;&#23548;&#33268;&#20102;&#22810;&#31181;&#32479;&#35745;&#26041;&#27861;&#30340;&#21457;&#23637;&#65292;&#24182;&#34987;&#35748;&#20026;&#26159;&#29616;&#20195;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36890;&#36807;&#28508;&#22312;&#24230;&#37327;&#27169;&#22411;&#36825;&#31181;&#36890;&#29992;&#19988;&#38750;&#24120;&#31616;&#21333;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#29983;&#25104;&#20016;&#23500;&#32780;&#26377;&#26102;&#22797;&#26434;&#30340;&#27969;&#24418;&#32467;&#26500;&#65292;&#36890;&#36807;&#28508;&#21464;&#37327;&#12289;&#30456;&#20851;&#24615;&#21644;&#24179;&#31283;&#24615;&#31561;&#22522;&#26412;&#27010;&#24565;&#12290;&#36825;&#20026;&#20026;&#20160;&#20040;&#27969;&#24418;&#20551;&#35774;&#22312;&#36825;&#20040;&#22810;&#24773;&#20917;&#19979;&#20284;&#20046;&#25104;&#31435;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#32479;&#35745;&#35299;&#37322;&#12290;&#22312;&#28508;&#22312;&#24230;&#37327;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21457;&#29616;&#21644;&#35299;&#37322;&#39640;&#32500;&#25968;&#25454;&#20960;&#20309;&#32467;&#26500;&#20197;&#21450;&#25506;&#32034;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Manifold Hypothesis is a widely accepted tenet of Machine Learning which asserts that nominally high-dimensional data are in fact concentrated near a low-dimensional manifold, embedded in high-dimensional space. This phenomenon is observed empirically in many real world situations, has led to development of a wide range of statistical methods in the last few decades, and has been suggested as a key factor in the success of modern AI technologies. We show that rich and sometimes intricate manifold structure in data can emerge from a generic and remarkably simple statistical model -- the Latent Metric Model -- via elementary concepts such as latent variables, correlation and stationarity. This establishes a general statistical explanation for why the Manifold Hypothesis seems to hold in so many situations. Informed by the Latent Metric Model we derive procedures to discover and interpret the geometry of high-dimensional data, and explore hypotheses about the data generating mechanism
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#22312;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23569;&#31867;&#21035;&#22270;&#20687;&#20998;&#31867;&#26102;&#29983;&#25104;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#12290;&#20854;&#20013;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#21457;&#23637;&#20102;&#38024;&#23545;&#20989;&#25968;&#31354;&#38388;&#21644;&#20855;&#26377;&#19968;&#33324;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;CNNs&#30340;&#26032;&#30340;Talagrand&#21387;&#32553;&#24341;&#29702;&#12290;</title><link>https://arxiv.org/abs/2208.04284</link><description>&lt;p&gt;
&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#28145;&#24230;&#23398;&#20064;&#19968;&#33324;&#21270;&#30028;&#38480;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Rademacher Complexity-based Generalization Bounds for Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.04284
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#22312;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23569;&#31867;&#21035;&#22270;&#20687;&#20998;&#31867;&#26102;&#29983;&#25104;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#12290;&#20854;&#20013;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#21457;&#23637;&#20102;&#38024;&#23545;&#20989;&#25968;&#31354;&#38388;&#21644;&#20855;&#26377;&#19968;&#33324;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;CNNs&#30340;&#26032;&#30340;Talagrand&#21387;&#32553;&#24341;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;Rademacher&#22797;&#26434;&#24230;&#30340;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#36827;&#34892;&#20998;&#31867;&#23569;&#37327;&#31867;&#21035;&#22270;&#20687;&#38750;&#31354;&#27867;&#21270;&#30028;&#38480;&#12290;&#26032;&#30340;Talagrand&#21387;&#32553;&#24341;&#29702;&#30340;&#21457;&#23637;&#23545;&#20110;&#39640;&#32500;&#26144;&#23556;&#20989;&#25968;&#31354;&#38388;&#21644;&#20855;&#26377;&#19968;&#33324;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;CNNs&#26159;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;Rademacher&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;CNNs&#30340;&#32593;&#32476;&#38271;&#24230;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35832;&#22914;ReLU&#65292;Leaky ReLU&#65292;Parametric Rectifier Linear Unit&#65292;Sigmoid&#21644;Tanh&#31561;&#29305;&#23450;&#31867;&#22411;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that the Rademacher complexity-based approach can generate non-vacuous generalisation bounds on Convolutional Neural Networks (CNNs) for classifying a small number of classes of images. The development of new Talagrand's contraction lemmas for high-dimensional mappings between function spaces and CNNs for general Lipschitz activation functions is a key technical contribution. Our results show that the Rademacher complexity does not depend on the network length for CNNs with some special types of activation functions such as ReLU, Leaky ReLU, Parametric Rectifier Linear Unit, Sigmoid, and Tanh.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#26080;&#30028;&#22495;&#20013;&#26500;&#24314;&#33258;&#36866;&#24212;&#21644;&#26080;&#21442;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26694;&#26550;&#65292;&#24182;&#20197;&#27492;&#20026;&#22522;&#30784;&#24320;&#21457;&#20102;&#20855;&#26377;&#26368;&#20248;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#26080;&#32422;&#26463;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;Follow-the-Regularized-Leader&#30340;&#31574;&#30053;&#26080;&#27861;&#36798;&#21040;&#31867;&#20284;&#25928;&#26524;&#65292;&#27492;&#22806;&#36824;&#24212;&#29992;&#38236;&#20687;&#19979;&#38477;&#26694;&#26550;&#26500;&#24314;&#20102;&#26032;&#30340;&#26080;&#21442;&#38544;&#24335;&#26356;&#26032;&#20197;&#21450;&#31616;&#21270;&#21644;&#25913;&#36827;&#30340;&#26080;&#32422;&#26463;&#26080;&#26631;&#24230;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2203.00444</link><description>&lt;p&gt;
&#26080;&#21442;&#38236;&#20687;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Parameter-free Mirror Descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.00444
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#26080;&#30028;&#22495;&#20013;&#26500;&#24314;&#33258;&#36866;&#24212;&#21644;&#26080;&#21442;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26694;&#26550;&#65292;&#24182;&#20197;&#27492;&#20026;&#22522;&#30784;&#24320;&#21457;&#20102;&#20855;&#26377;&#26368;&#20248;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#26080;&#32422;&#26463;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;Follow-the-Regularized-Leader&#30340;&#31574;&#30053;&#26080;&#27861;&#36798;&#21040;&#31867;&#20284;&#25928;&#26524;&#65292;&#27492;&#22806;&#36824;&#24212;&#29992;&#38236;&#20687;&#19979;&#38477;&#26694;&#26550;&#26500;&#24314;&#20102;&#26032;&#30340;&#26080;&#21442;&#38544;&#24335;&#26356;&#26032;&#20197;&#21450;&#31616;&#21270;&#21644;&#25913;&#36827;&#30340;&#26080;&#32422;&#26463;&#26080;&#26631;&#24230;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#21518;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#22312;&#26080;&#30028;&#22495;&#20013;&#26500;&#24314;&#33258;&#36866;&#24212;&#21644;&#26080;&#21442;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#25216;&#26415;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#26080;&#32422;&#26463;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#36827;&#19968;&#27493;&#35777;&#26126;&#22522;&#20110;Follow-the-Regularized-Leader&#30340;&#33258;&#28982;&#31574;&#30053;&#26080;&#27861;&#36798;&#21040;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#38236;&#20687;&#19979;&#38477;&#26694;&#26550;&#24212;&#29992;&#20110;&#26500;&#24314;&#26080;&#21442;&#38544;&#24335;&#26356;&#26032;&#65292;&#20197;&#21450;&#19968;&#20010;&#31616;&#21270;&#21644;&#25913;&#36827;&#30340;&#26080;&#32422;&#26463;&#26080;&#26631;&#24230;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a modified online mirror descent framework that is suitable for building adaptive and parameter-free algorithms in unbounded domains. We leverage this technique to develop the first unconstrained online linear optimization algorithm achieving an optimal dynamic regret bound, and we further demonstrate that natural strategies based on Follow-the-Regularized-Leader are unable to achieve similar results. We also apply our mirror descent framework to build new parameter-free implicit updates, as well as a simplified and improved unconstrained scale-free algorithm.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#26681;&#25454;&#21754;&#20083;&#21160;&#29289;&#30382;&#36136;&#20013;&#30340;&#27169;&#25311;&#32416;&#38169;&#30721;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#29289;&#32416;&#38169;&#30721;&#30340;&#36890;&#29992;&#23481;&#38169;&#31070;&#32463;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#21487;&#38752;&#35745;&#31639;&#65307;&#21457;&#29616;&#20102;&#20174;&#25925;&#38556;&#21040;&#23481;&#38169;&#31070;&#32463;&#35745;&#31639;&#30340;&#30456;&#21464;&#65292;&#20026;&#29702;&#35299;&#22024;&#26434;&#27169;&#25311;&#31995;&#32479;&#25552;&#20379;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;</title><link>https://arxiv.org/abs/2202.12887</link><description>&lt;p&gt;
&#20174;&#29983;&#29289;&#32416;&#38169;&#30721;&#21040;&#23481;&#38169;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Fault-Tolerant Neural Networks from Biological Error Correction Codes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2202.12887
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#26681;&#25454;&#21754;&#20083;&#21160;&#29289;&#30382;&#36136;&#20013;&#30340;&#27169;&#25311;&#32416;&#38169;&#30721;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#29289;&#32416;&#38169;&#30721;&#30340;&#36890;&#29992;&#23481;&#38169;&#31070;&#32463;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#21487;&#38752;&#35745;&#31639;&#65307;&#21457;&#29616;&#20102;&#20174;&#25925;&#38556;&#21040;&#23481;&#38169;&#31070;&#32463;&#35745;&#31639;&#30340;&#30456;&#21464;&#65292;&#20026;&#29702;&#35299;&#22024;&#26434;&#27169;&#25311;&#31995;&#32479;&#25552;&#20379;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#26159;&#21542;&#21487;&#33021;&#23454;&#29616;&#23481;&#38169;&#35745;&#31639;&#19968;&#30452;&#26159;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#65306;&#26159;&#21542;&#21487;&#20197;&#20165;&#20351;&#29992;&#19981;&#21487;&#38752;&#30340;&#31070;&#32463;&#20803;&#23454;&#29616;&#20219;&#24847;&#21487;&#38752;&#30340;&#35745;&#31639;&#65311;&#22312;&#21754;&#20083;&#21160;&#29289;&#30382;&#36136;&#30340;&#32593;&#26684;&#32454;&#32990;&#20013;&#65292;&#35266;&#23519;&#21040;&#20102;&#27169;&#25311;&#32416;&#38169;&#30721;&#20445;&#25252;&#29366;&#24577;&#20813;&#21463;&#31070;&#32463;&#23556;&#39057;&#22122;&#22768;&#30340;&#29616;&#35937;&#65292;&#20294;&#20854;&#22312;&#20449;&#24687;&#22788;&#29702;&#20013;&#30340;&#20316;&#29992;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#29983;&#29289;&#32416;&#38169;&#30721;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#23481;&#38169;&#31070;&#32463;&#32593;&#32476;&#65292;&#22914;&#26524;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#25925;&#38556;&#24615;&#37117;&#20302;&#20110;&#19968;&#20010;&#20005;&#26684;&#30340;&#38408;&#20540;&#65292;&#21017;&#33021;&#22815;&#23454;&#29616;&#21487;&#38752;&#30340;&#35745;&#31639;&#65307;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22024;&#26434;&#30340;&#29983;&#29289;&#31070;&#32463;&#20803;&#20302;&#20110;&#36825;&#20010;&#38408;&#20540;&#12290;&#20174;&#25925;&#38556;&#21040;&#23481;&#38169;&#31070;&#32463;&#35745;&#31639;&#30340;&#30456;&#21464;&#30340;&#21457;&#29616;&#65292;&#25581;&#31034;&#20102;&#30382;&#36136;&#20013;&#21487;&#38752;&#35745;&#31639;&#30340;&#26426;&#21046;&#65292;&#20026;&#29702;&#35299;&#19982;&#20154;&#24037;&#26234;&#33021;&#21644;&#31070;&#32463;&#24418;&#24577;&#35745;&#31639;&#26377;&#20851;&#30340;&#22024;&#26434;&#27169;&#25311;&#31995;&#32479;&#25171;&#24320;&#20102;&#19968;&#26465;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
It has been an open question in deep learning if fault-tolerant computation is possible: can arbitrarily reliable computation be achieved using only unreliable neurons? In the grid cells of the mammalian cortex, analog error correction codes have been observed to protect states against neural spiking noise, but their role in information processing is unclear. Here, we use these biological error correction codes to develop a universal fault-tolerant neural network that achieves reliable computation if the faultiness of each neuron lies below a sharp threshold; remarkably, we find that noisy biological neurons fall below this threshold. The discovery of a phase transition from faulty to fault-tolerant neural computation suggests a mechanism for reliable computation in the cortex and opens a path towards understanding noisy analog systems relevant to artificial intelligence and neuromorphic computing.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#38750;&#32447;&#24615;&#25511;&#21046;&#29702;&#35770;&#35299;&#37322;&#20102;&#28145;&#24230;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20805;&#20998;&#26465;&#20214;&#65292;&#22312;&#28608;&#27963;&#20989;&#25968;&#28385;&#36275;&#20108;&#27425;&#24494;&#20998;&#26041;&#31243;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#36275;&#22815;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#22312;&#32039;&#38598;&#21512;&#19978;&#36924;&#36817;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2007.06007</link><description>&lt;p&gt;
&#28145;&#24230;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#38750;&#32447;&#24615;&#25511;&#21046;&#29702;&#35770;&#23454;&#29616;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Universal Approximation Power of Deep Residual Neural Networks via Nonlinear Control Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.06007
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#38750;&#32447;&#24615;&#25511;&#21046;&#29702;&#35770;&#35299;&#37322;&#20102;&#28145;&#24230;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20805;&#20998;&#26465;&#20214;&#65292;&#22312;&#28608;&#27963;&#20989;&#25968;&#28385;&#36275;&#20108;&#27425;&#24494;&#20998;&#26041;&#31243;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#36275;&#22815;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#22312;&#32039;&#38598;&#21512;&#19978;&#36924;&#36817;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20960;&#20309;&#38750;&#32447;&#24615;&#25511;&#21046;&#26469;&#35299;&#37322;&#28145;&#24230;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#12290;&#21463;&#21040;&#26368;&#36817;&#24314;&#31435;&#27531;&#24046;&#32593;&#32476;&#21644;&#25511;&#21046;&#31995;&#32479;&#20043;&#38388;&#32852;&#31995;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#35201;&#27714;&#28608;&#27963;&#20989;&#25968;&#25110;&#20854;&#23548;&#25968;&#20043;&#19968;&#28385;&#36275;&#19968;&#20010;&#20108;&#27425;&#24494;&#20998;&#26041;&#31243;&#65292;&#20197;&#20351;&#27531;&#24046;&#32593;&#32476;&#20855;&#26377;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#12290;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;&#35768;&#22810;&#28608;&#27963;&#20989;&#25968;&#28385;&#36275;&#36825;&#20010;&#20551;&#35774;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#23646;&#24615;&#36275;&#20197;&#35753;&#19968;&#20010;&#36275;&#22815;&#28145;&#30340;&#20855;&#26377;$n+1$&#31070;&#32463;&#20803;&#27599;&#23618;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#32039;&#38598;&#21512;&#19978;&#30456;&#23545;&#20110;&#26368;&#22823;&#33539;&#25968;&#36924;&#36817;&#20219;&#24847;&#36830;&#32493;&#30340;&#20174;$\mathbb{R}^n$&#21040;$\mathbb{R}^n$&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#36825;&#20010;&#32467;&#26524;&#36866;&#29992;&#20110;&#38750;&#24120;&#31616;&#21333;&#30340;&#26550;&#26500;&#65292;&#21482;&#38656;&#35201;&#26435;&#37325;&#21462;&#20004;&#20010;&#20540;&#12290;&#31532;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#23558;&#36890;&#29992;&#36924;&#36817;&#19982;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#38750;&#32447;&#24615;&#25511;&#21046;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explain the universal approximation capabilities of deep residual neural networks through geometric nonlinear control. Inspired by recent work establishing links between residual networks and control systems, we provide a general sufficient condition for a residual network to have the power of universal approximation by asking the activation function, or one of its derivatives, to satisfy a quadratic differential equation. Many activation functions used in practice satisfy this assumption, exactly or approximately, and we show this property to be sufficient for an adequately deep neural network with $n+1$ neurons per layer to approximate arbitrarily well, on a compact set and with respect to the supremum norm, any continuous function from $\mathbb{R}^n$ to $\mathbb{R}^n$. We further show this result to hold for very simple architectures for which the weights only need to assume two values. The first key technical contribution consists of relating the universal approxi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#21033;&#29992;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#23398;&#20064;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#21450;&#39069;&#22806;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23545;&#22122;&#22768;&#26631;&#31614;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#22120;&#22122;&#22768;&#19981;&#21464;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#25552;&#39640;PU&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#21033;&#29992;PU&#20998;&#31867;&#22120;&#39044;&#27979;&#30340;&#26631;&#31614;&#21644;&#39069;&#22806;&#25968;&#25454;&#26469;&#24110;&#21161;&#29983;&#25104;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2006.07841</link><description>&lt;p&gt;
&#21516;&#26102;&#36827;&#34892;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#23398;&#20064;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#65292;&#21033;&#29992;&#39069;&#22806;&#25968;&#25454;&#26469;&#20998;&#31867;&#21644;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Classify and Generate Reciprocally: Simultaneous Positive-Unlabelled Learning and Conditional Generation with Extra Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.07841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#21033;&#29992;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#23398;&#20064;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#20197;&#21450;&#39069;&#22806;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23545;&#22122;&#22768;&#26631;&#31614;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#22120;&#22122;&#22768;&#19981;&#21464;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#25552;&#39640;PU&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#21033;&#29992;PU&#20998;&#31867;&#22120;&#39044;&#27979;&#30340;&#26631;&#31614;&#21644;&#39069;&#22806;&#25968;&#25454;&#26469;&#24110;&#21161;&#29983;&#25104;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#26631;&#35760;&#31867;&#21035;&#25968;&#25454;&#30340;&#31232;&#32570;&#24615;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#29942;&#39048;&#12290;&#34429;&#28982;&#23384;&#22312;&#20016;&#23500;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#24182;&#25552;&#20379;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#21033;&#29992;&#23427;&#20204;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#21516;&#26102;&#21033;&#29992;&#27491;&#25968;&#25454;-&#26080;&#26631;&#31614;&#65288;Positive-Unlabeled&#65292;PU&#65289;&#20998;&#31867;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#65292;&#20197;&#21450;&#39069;&#22806;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35757;&#32451;&#26694;&#26550;&#65292;&#20351;&#24471;&#22312;&#38754;&#23545;&#39069;&#22806;&#25968;&#25454;&#65288;&#23588;&#20854;&#26159;&#20998;&#24067;&#22806;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#65289;&#26102;&#65292;&#21516;&#26102;&#36827;&#34892;PU&#20998;&#31867;&#21644;&#26377;&#26465;&#20214;&#29983;&#25104;&#25104;&#20026;&#21487;&#33021;&#65292;&#36890;&#36807;&#25506;&#32034;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65306;1&#65289;&#36890;&#36807;&#19968;&#20010;&#23545;&#22122;&#22768;&#26631;&#31614;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#26032;&#22411;&#20998;&#31867;&#22120;&#22122;&#22768;&#19981;&#21464;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;Classifier-Noise-Invariant Conditional GAN&#65292;CNI-CGAN&#65289;&#26469;&#25552;&#39640;PU&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;2&#65289;&#21033;&#29992;PU&#20998;&#31867;&#22120;&#39044;&#27979;&#30340;&#26631;&#31614;&#21644;&#39069;&#22806;&#25968;&#25454;&#26469;&#24110;&#21161;&#29983;&#25104;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;CNI-CGAN&#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#36890;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#26469;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scarcity of class-labeled data is a ubiquitous bottleneck in many machine learning problems. While abundant unlabeled data typically exist and provide a potential solution, it is highly challenging to exploit them. In this paper, we address this problem by leveraging Positive-Unlabeled~(PU) classification and the conditional generation with extra unlabeled data \emph{simultaneously}. In particular, we present a novel training framework to jointly target both PU classification and conditional generation when exposed to extra data, especially out-of-distribution unlabeled data, by exploring the interplay between them: 1) enhancing the performance of PU classifiers with the assistance of a novel Classifier-Noise-Invariant Conditional GAN~(CNI-CGAN) that is robust to noisy labels, 2) leveraging extra data with predicted labels from a PU classifier to help the generation. Theoretically, we prove the optimal condition of CNI-CGAN, and experimentally, we conducted extensive evaluations on
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;Syntax&#65292;&#19968;&#20010;&#20855;&#26377;&#21512;&#25104;&#23545;&#29031;&#32452;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#20122;&#32676;&#20307;&#20013;&#35782;&#21035;&#20986;&#20855;&#26377;&#27491;&#38754;&#27835;&#30103;&#25928;&#26524;&#30340;&#20122;&#32676;&#20307;&#65292;&#23545;&#20110;&#22810;&#26679;&#21270;&#24739;&#32773;&#21453;&#24212;&#30340;&#20020;&#24202;&#35797;&#39564;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.17205</link><description>&lt;p&gt;
&#20855;&#26377;&#21512;&#25104;&#23545;&#29031;&#32452;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experiment Design with Synthetic Controls. (arXiv:2401.17205v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17205
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;Syntax&#65292;&#19968;&#20010;&#20855;&#26377;&#21512;&#25104;&#23545;&#29031;&#32452;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#20122;&#32676;&#20307;&#20013;&#35782;&#21035;&#20986;&#20855;&#26377;&#27491;&#38754;&#27835;&#30103;&#25928;&#26524;&#30340;&#20122;&#32676;&#20307;&#65292;&#23545;&#20110;&#22810;&#26679;&#21270;&#24739;&#32773;&#21453;&#24212;&#30340;&#20020;&#24202;&#35797;&#39564;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#36890;&#24120;&#29992;&#20110;&#20102;&#35299;&#26032;&#27835;&#30103;&#23545;&#32473;&#23450;&#24739;&#32773;&#32676;&#20307;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22823;&#35268;&#27169;&#32676;&#20307;&#20013;&#30340;&#24739;&#32773;&#24456;&#23569;&#20197;&#30456;&#21516;&#30340;&#26041;&#24335;&#23545;&#24453;&#30456;&#21516;&#30340;&#27835;&#30103;&#20570;&#20986;&#21453;&#24212;&#12290;&#24739;&#32773;&#21453;&#24212;&#30340;&#22810;&#26679;&#24615;&#38656;&#35201;&#36827;&#34892;&#22810;&#20010;&#20122;&#32676;&#20307;&#30340;&#25928;&#26524;&#30740;&#31350; - &#23588;&#20854;&#26159;&#24403;&#27835;&#30103;&#23545;&#25972;&#20307;&#32676;&#20307;&#27809;&#26377;&#25110;&#20960;&#20046;&#27809;&#26377;&#30410;&#22788;&#65292;&#32780;&#23545;&#29305;&#23450;&#20122;&#32676;&#20307;&#21487;&#33021;&#20855;&#26377;&#26174;&#33879;&#30340;&#30410;&#22788;&#26102;&#12290;&#22522;&#20110;&#36825;&#31181;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Syntax&#65292;&#19968;&#31181;&#25506;&#32034;&#24615;&#35797;&#39564;&#35774;&#35745;&#65292;&#22312;&#20247;&#22810;&#20122;&#32676;&#20307;&#20013;&#35782;&#21035;&#20855;&#26377;&#27491;&#38754;&#27835;&#30103;&#25928;&#26524;&#30340;&#20122;&#32676;&#20307;&#12290;Syntax&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#65292;&#22240;&#20026;&#23427;(i) &#33258;&#36866;&#24212;&#25307;&#21215;&#21644;&#20998;&#37197;&#24739;&#32773;&#65292;(ii) &#36890;&#36807;&#21512;&#25104;&#23545;&#29031;&#32452;&#24418;&#25104;&#27599;&#20010;&#20122;&#32676;&#20307;&#30340;&#25511;&#21046;&#26679;&#26412;&#65292;&#20174;&#32780;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;Syntax&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#23427;&#20309;&#26102;&#21487;&#33021;&#20248;&#20110;&#20256;&#32479;&#35797;&#39564;&#35774;&#35745;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations - especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through e
&lt;/p&gt;</description></item><item><title>FairWASP&#26159;&#19968;&#31181;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#38598;&#26469;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#21516;&#26102;&#28385;&#36275;&#20154;&#21475;&#24179;&#31561;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2311.00109</link><description>&lt;p&gt;
FairWASP&#65306;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
FairWASP: Fast and Optimal Fair Wasserstein Pre-processing. (arXiv:2311.00109v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00109
&lt;/p&gt;
&lt;p&gt;
FairWASP&#26159;&#19968;&#31181;&#24555;&#36895;&#21644;&#26368;&#20248;&#30340;&#20844;&#24179;Wasserstein&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#38598;&#26469;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#21516;&#26102;&#28385;&#36275;&#20154;&#21475;&#24179;&#31561;&#24615;&#20934;&#21017;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#24555;&#36895;&#21457;&#23637;&#26088;&#22312;&#20943;&#23569;&#19981;&#21516;&#23376;&#32676;&#20307;&#20043;&#38388;&#27169;&#22411;&#36755;&#20986;&#30340;&#19981;&#24179;&#31561;&#24615;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#25968;&#25454;&#21487;&#33021;&#20250;&#34987;&#19981;&#21516;&#29992;&#25143;&#22312;&#22810;&#20010;&#19979;&#28216;&#24212;&#29992;&#20013;&#20351;&#29992;&#65292;&#36825;&#24847;&#21619;&#30528;&#23545;&#35757;&#32451;&#25968;&#25454;&#26412;&#36523;&#36827;&#34892;&#24178;&#39044;&#21487;&#33021;&#26159;&#26368;&#26377;&#25928;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39044;&#22788;&#29702;&#26041;&#27861;FairWASP&#65292;&#26088;&#22312;&#20943;&#23569;&#20998;&#31867;&#25968;&#25454;&#38598;&#20013;&#30340;&#19981;&#24179;&#31561;&#24615;&#65292;&#32780;&#19981;&#20250;&#20462;&#25913;&#21407;&#22987;&#25968;&#25454;&#12290;FairWASP&#36820;&#22238;&#26679;&#26412;&#32423;&#26435;&#37325;&#65292;&#20351;&#37325;&#26032;&#21152;&#26435;&#30340;&#25968;&#25454;&#38598;&#26368;&#23567;&#21270;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#30340;Wasserstein&#36317;&#31163;&#65292;&#21516;&#26102;&#28385;&#36275;&#65288;&#32463;&#39564;&#29256;&#26412;&#30340;&#65289;&#20154;&#21475;&#24179;&#31561;&#24615;&#65292;&#36825;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20844;&#24179;&#24615;&#20934;&#21017;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25972;&#25968;&#26435;&#37325;&#30340;&#26368;&#20248;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#31561;&#21516;&#22320;&#29702;&#35299;&#20026;&#22797;&#21046;&#25110;&#21024;&#38500;&#26679;&#26412;&#12290;&#22240;&#27492;&#65292;FairWASP&#21487;&#29992;&#20110;&#26500;&#24314;&#21487;&#20197;&#36755;&#20837;&#20219;&#20309;&#20998;&#31867;&#26041;&#27861;&#30340;&#25968;&#25454;&#38598;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#25509;&#21463;&#26679;&#26412;&#26435;&#37325;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen a surge of machine learning approaches aimed at reducing disparities in model outputs across different subgroups. In many settings, training data may be used in multiple downstream applications by different users, which means it may be most effective to intervene on the training data itself. In this work, we present FairWASP, a novel pre-processing approach designed to reduce disparities in classification datasets without modifying the original data. FairWASP returns sample-level weights such that the reweighted dataset minimizes the Wasserstein distance to the original dataset while satisfying (an empirical version of) demographic parity, a popular fairness criterion. We show theoretically that integer weights are optimal, which means our method can be equivalently understood as duplicating or eliminating samples. FairWASP can therefore be used to construct datasets which can be fed into any classification method, not just methods which accept sample weights. Ou
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24341;&#20837;Effective width&#21442;&#25968;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#65292;&#24182;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19064</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting the Learnability of Apple Tasting. (arXiv:2310.19064v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19064
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24341;&#20837;Effective width&#21442;&#25968;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#65292;&#24182;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#20108;&#20803;&#20998;&#31867;&#20013;&#65292;&#23398;&#20064;&#32773;&#21482;&#26377;&#22312;&#39044;&#27979;&#20026;"1"&#26102;&#35266;&#23519;&#21040;&#30495;&#23454;&#26631;&#31614;&#12290;&#26412;&#25991;&#37325;&#26032;&#30740;&#31350;&#20102;&#36825;&#31181;&#32463;&#20856;&#30340;&#37096;&#20998;&#21453;&#39304;&#35774;&#32622;&#65292;&#24182;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19981;&#21487;&#30693;&#35774;&#32622;&#19979;&#65292;Littlestone&#32500;&#24230;&#20173;&#28982;&#26159;&#33529;&#26524;&#21697;&#23581;&#30340;&#32039;&#23494;&#23450;&#37327;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;\cite{helmbold2000apple}&#25552;&#20986;&#30340;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32452;&#21512;&#21442;&#25968;&#65292;&#31216;&#20026;&#26377;&#25928;&#23485;&#24230;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#12290;&#20316;&#20026;&#25512;&#35770;&#65292;&#25105;&#20204;&#20351;&#29992;&#26377;&#25928;&#23485;&#24230;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#65292;&#20219;&#20309;&#23398;&#20064;&#32773;&#22312;&#33529;&#26524;&#21697;&#23581;&#21453;&#39304;&#19979;&#30340;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#21482;&#33021;&#26159;$\Theta(1), \Theta(\sqrt{T})$, &#25110; $\Theta(T)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In online binary classification under \textit{apple tasting} feedback, the learner only observes the true label if it predicts "1". First studied by \cite{helmbold2000apple}, we revisit this classical partial-feedback setting and study online learnability from a combinatorial perspective. We show that the Littlestone dimension continues to prove a tight quantitative characterization of apple tasting in the agnostic setting, closing an open question posed by \cite{helmbold2000apple}. In addition, we give a new combinatorial parameter, called the Effective width, that tightly quantifies the minimax expected mistakes in the realizable setting. As a corollary, we use the Effective width to establish a \textit{trichotomy} of the minimax expected number of mistakes in the realizable setting. In particular, we show that in the realizable setting, the expected number of mistakes for any learner under apple tasting feedback can only be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.07665</link><description>&lt;p&gt;
&#28145;&#24230;&#22238;&#28335;&#23545;&#22240;&#26524;&#19968;&#33268;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Deep Backtracking Counterfactuals for Causally Compliant Explanations. (arXiv:2310.07665v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#12290;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#29983;&#25104;&#21453;&#20107;&#23454;&#65292;&#24182;&#19988;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#20855;&#22791;&#20102;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#31526;&#21512;&#22240;&#26524;&#20851;&#31995;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#29702;&#21487;&#20197;&#36890;&#36807;&#22238;&#31572;&#22312;&#25913;&#21464;&#24773;&#20917;&#19979;&#20250;&#35266;&#23519;&#21040;&#20160;&#20040;&#26469;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#65292;&#26465;&#20214;&#26159;&#26681;&#25454;&#23454;&#38469;&#35266;&#23519;&#12290;&#34429;&#28982;&#32463;&#20856;&#30340;&#20171;&#20837;&#24335;&#35299;&#37322;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#22238;&#28335;&#21407;&#21017;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#20445;&#25345;&#25152;&#26377;&#22240;&#26524;&#23450;&#24459;&#23436;&#25972;&#24615;&#30340;&#26367;&#20195;&#21746;&#23398;&#65292;&#20294;&#20854;&#30740;&#31350;&#36739;&#23569;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22312;&#30001;&#28145;&#24230;&#29983;&#25104;&#32452;&#20214;&#32452;&#25104;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20013;&#35745;&#31639;&#22238;&#28335;&#21453;&#20107;&#23454;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23545;&#32467;&#26500;&#20998;&#37197;&#26045;&#21152;&#20102;&#26465;&#20214;&#65292;&#36890;&#36807;&#22312;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21270;&#28508;&#22312;&#31354;&#38388;&#20013;&#35299;&#20915;&#19968;&#20010;&#21487;&#34892;&#30340;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#26469;&#29983;&#25104;&#21453;&#20107;&#23454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#19982;&#21453;&#20107;&#23454;&#35299;&#37322;&#39046;&#22495;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#19982;&#36825;&#20123;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20195;&#34920;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#12289;&#27169;&#22359;&#21270;&#21644;&#36981;&#23432;&#22240;&#26524;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#22238;&#24402;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#65288;ARS&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#32771;&#34385;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#65292;&#21516;&#26102;&#20272;&#35745;&#28436;&#21270;&#20989;&#25968;&#21644;&#32570;&#22833;&#21464;&#37327;&#65292;&#29992;&#20110;&#39044;&#27979;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#20013;&#32570;&#22833;&#21464;&#37327;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2306.16593</link><description>&lt;p&gt;
&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#30340;&#21457;&#23637;&#39044;&#27979;&#22312;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#30340;&#24110;&#21161;&#19979;
&lt;/p&gt;
&lt;p&gt;
Forecasting of the development of a partially-observed dynamical time series with the aid of time-invariance and linearity. (arXiv:2306.16593v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#22238;&#24402;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#65288;ARS&#65289;&#27169;&#22411;&#65292;&#36890;&#36807;&#32771;&#34385;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#65292;&#21516;&#26102;&#20272;&#35745;&#28436;&#21270;&#20989;&#25968;&#21644;&#32570;&#22833;&#21464;&#37327;&#65292;&#29992;&#20110;&#39044;&#27979;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#20013;&#32570;&#22833;&#21464;&#37327;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#31995;&#32479;&#20135;&#29983;&#19968;&#31181;&#20381;&#36182;&#22810;&#20803;&#24207;&#21015;&#65292;&#31216;&#20026;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#65292;&#36890;&#36807;&#28436;&#21270;&#20989;&#25968;&#21457;&#23637;&#32780;&#26469;&#12290;&#30001;&#20110;&#24403;&#21069;&#26102;&#38388;&#28857;&#30340;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#21464;&#37327;&#36890;&#24120;&#20381;&#36182;&#20110;&#21069;&#19968;&#20010;&#26102;&#38388;&#28857;&#30340;&#25152;&#26377;&#21464;&#37327;&#65292;&#29616;&#26377;&#30740;&#31350;&#36890;&#36807;&#20272;&#35745;&#28436;&#21270;&#20989;&#25968;&#26469;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#28857;&#30340;&#21464;&#37327;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#21160;&#24577;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#19968;&#20123;&#21464;&#37327;&#26159;&#32570;&#22833;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#22238;&#24402;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#65288;ARS&#65289;&#27169;&#22411;&#12290;ARS&#27169;&#22411;&#28041;&#21450;&#28436;&#21270;&#20989;&#25968;&#21644;&#20316;&#20026;&#26494;&#24347;&#26102;&#38388;&#24207;&#21015;&#30340;&#28508;&#22312;&#32570;&#22833;&#21464;&#37327;&#30340;&#21516;&#26102;&#20272;&#35745;&#65292;&#20511;&#21161;&#20110;&#21160;&#24577;&#31995;&#32479;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#21644;&#32447;&#24615;&#24615;&#12290;&#26412;&#30740;&#31350;&#23454;&#35777;&#20102;&#25552;&#20986;&#30340;ARS&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A dynamical system produces a dependent multivariate sequence called dynamical time series, developed with an evolution function. As variables in the dynamical time series at the current time-point usually depend on the whole variables in the previous time-point, existing studies forecast the variables at the future time-point by estimating the evolution function. However, some variables in the dynamical time-series are missing in some practical situations. In this study, we propose an autoregressive with slack time series (ARS) model. ARS model involves the simultaneous estimation of the evolution function and the underlying missing variables as a slack time series, with the aid of the time-invariance and linearity of the dynamical system. This study empirically demonstrates the effectiveness of the proposed ARS model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#21521;&#29983;&#25104;&#22120;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;KL&#25955;&#24230;&#39033;&#30340;&#26041;&#27861;&#65292;&#26469;&#20445;&#35777;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#20998;&#24067;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#24212;&#20998;&#24067;&#37325;&#21512;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10943</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#30495;&#23454;&#25968;&#25454;&#21644;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#30340;&#27010;&#29575;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Probabilistic matching of real and generated data statistics in generative adversarial networks. (arXiv:2306.10943v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#21521;&#29983;&#25104;&#22120;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;KL&#25955;&#24230;&#39033;&#30340;&#26041;&#27861;&#65292;&#26469;&#20445;&#35777;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#20998;&#24067;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#24212;&#20998;&#24067;&#37325;&#21512;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#12290;&#34429;&#28982;&#29983;&#25104;&#26679;&#26412;&#24448;&#24448;&#38590;&#20197;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#65292;&#20294;&#19981;&#33021;&#20445;&#35777;&#23427;&#20204;&#36981;&#24490;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#30830;&#20445;&#26576;&#20123;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#20998;&#24067;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#24212;&#20998;&#24067;&#37325;&#21512;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#29983;&#25104;&#22120;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;&#20102;Kullback-Leibler&#39033;&#65306;KL&#25955;&#24230;&#26159;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20174;&#23567;&#25209;&#37327;&#20540;&#33719;&#24471;&#30340;&#30456;&#24212;&#29983;&#25104;&#20998;&#24067;&#21644;&#30001;&#26465;&#20214;&#33021;&#37327;&#27169;&#22411;&#34920;&#31034;&#30340;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks constitute a powerful approach to generative modeling. While generated samples often are indistinguishable from real data, there is no guarantee that they will follow the true data distribution. In this work, we propose a method to ensure that the distributions of certain generated data statistics coincide with the respective distributions of the real data. In order to achieve this, we add a Kullback-Leibler term to the generator loss function: the KL divergence is taken between the true distributions as represented by a conditional energy-based model, and the corresponding generated distributions obtained from minibatch values at each iteration. We evaluate the method on a synthetic dataset and two real-world datasets and demonstrate improved performance of our method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08598</link><description>&lt;p&gt;
&#26680;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#24178;&#25200;&#21442;&#25968;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26631;&#37327;&#30446;&#26631;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#37319;&#29992;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#65289;&#26367;&#25442;&#26410;&#30693;&#24178;&#25200;&#21442;&#25968;&#26159;&#26041;&#20415;&#30340;&#65292;&#20294;&#22240;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#32780;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#36991;&#20813;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#30340;&#27425;&#20248;&#36873;&#25321;&#65292;&#29616;&#20195;&#26041;&#27861;&#20250;&#36827;&#34892;&#25554;&#20540;&#39044;&#20272;&#30340;&#21435;&#20559;&#24046;&#25805;&#20316;&#65292;&#22914;&#26377;&#30446;&#26631;&#26368;&#23567;&#25439;&#22833;&#20272;&#35745;&#65288;TMLE&#65289;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#31561;&#12290;&#29616;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#38656;&#35201;&#23558;&#30446;&#26631;&#21442;&#25968;&#30340;&#24433;&#21709;&#20989;&#25968;&#65288;IF&#65289;&#20316;&#20026;&#36755;&#20837;&#65292;&#28982;&#32780;&#65292;IF&#30340;&#25512;&#23548;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#25554;&#20837;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#65288;i&#65289;&#39640;&#25928;&#12289;&#65288;ii&#65289;&#19981;&#38656;&#35201;&#23454;&#29616;IF&#12289;&#65288;iii&#65289;&#21487;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26032;&#39062;&#30340;Voronoi Loss&#20989;&#25968;&#26469;&#35299;&#20915;&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#65292;&#24182;&#22312;&#20004;&#31181;&#19981;&#21516;&#30340;&#38376;&#25511;&#32593;&#32476;&#19979;&#25552;&#20379;&#29702;&#35770;&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2305.07572</link><description>&lt;p&gt;
&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts. (arXiv:2305.07572v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26032;&#39062;&#30340;Voronoi Loss&#20989;&#25968;&#26469;&#35299;&#20915;&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#38382;&#39064;&#65292;&#24182;&#22312;&#20004;&#31181;&#19981;&#21516;&#30340;&#38376;&#25511;&#32593;&#32476;&#19979;&#25552;&#20379;&#29702;&#35770;&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#22240;&#20854;&#22312;&#38598;&#25104;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#32780;&#34987;&#24341;&#20837;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#36817;&#24180;&#26469;&#25104;&#20026;&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#22788;&#29702;&#24322;&#26500;&#25968;&#25454;&#20998;&#26512;&#30340;&#22522;&#26412;&#26500;&#20214;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#26031;&#38376;&#25511;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#34892;&#20026;&#30340;&#29702;&#35299;&#36824;&#19981;&#20805;&#20998;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#26032;&#39062;&#30340;Voronoi Loss&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#25910;&#25947;&#36895;&#29575;&#30340;&#35777;&#26126;&#65292;&#25581;&#31034;&#20102;&#22312;&#20004;&#31181;&#20998;&#31163;&#30340;&#38376;&#25511;&#32593;&#32476;&#19979;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#30340;&#19981;&#21516;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications, including those in machine learning, statistics, bioinformatics, economics, and medicine. Despite its popularity in practice, a satisfactory level of understanding of the convergence behavior of Gaussian-gated MoE parameter estimation is far from complete. The underlying reason for this challenge is the inclusion of covariates in the Gaussian gating and expert networks, which leads to their intrinsically complex interactions via partial differential equations with respect to their parameters. We address these issues by designing novel Voronoi loss functions to accurately capture heterogeneity in the maximum likelihood estimator (MLE) for resolving parameter estimation in these models. Our results reveal distinct behaviors of the MLE under two se
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.12522</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#20855;&#26377;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria for Robust Phase Retrieval. (arXiv:2304.12522v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#35270;&#20026;&#19968;&#20010;&#38750;&#20809;&#28369;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#20854;&#20013;&#23376;&#38382;&#39064;&#34987;&#19981;&#31934;&#30830;&#27714;&#35299;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#20026;&#23376;&#38382;&#39064;&#25552;&#20986;&#20102;&#20004;&#31181;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#65292;&#20363;&#22914;&#21407;&#22987;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#21644;&#27425;&#26799;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the robust phase retrieval problem, which can be cast as a nonsmooth and nonconvex optimization problem. We propose a new inexact proximal linear algorithm with the subproblem being solved inexactly. Our contributions are two adaptive stopping criteria for the subproblem. The convergence behavior of the proposed methods is analyzed. Through experiments on both synthetic and real datasets, we demonstrate that our methods are much more efficient than existing methods, such as the original proximal linear algorithm and the subgradient method.
&lt;/p&gt;</description></item></channel></rss>