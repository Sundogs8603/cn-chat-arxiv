<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.05376</link><description>&lt;p&gt;
ChemCrow:&#29992;&#21270;&#23398;&#24037;&#20855;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChemCrow: Augmenting large-language models with chemistry tools. (arXiv:2304.05376v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#36328;&#39046;&#22495;&#30340;&#20219;&#21153;&#34920;&#29616;&#20986;&#19968;&#23450;&#30340;&#20248;&#21183;&#65292;&#20294;&#22312;&#21270;&#23398;&#30456;&#20851;&#38382;&#39064;&#19978;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27169;&#22411;&#32570;&#20047;&#35775;&#38382;&#22806;&#37096;&#30693;&#35782;&#28304;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#26088;&#22312;&#23436;&#25104;&#26377;&#26426;&#21512;&#25104;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#26448;&#26009;&#35774;&#35745;&#31561;&#20219;&#21153;&#12290;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#65292;ChemCrow&#25552;&#39640;&#20102;LLM&#22312;&#21270;&#23398;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#20135;&#29983;&#20102;&#26032;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#65292;&#21253;&#25324;LLM&#21644;&#20154;&#31867;&#19987;&#23478;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;ChemCrow&#22312;&#33258;&#21160;&#21270;&#21508;&#31181;&#21270;&#23398;&#20219;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-4&#20316;&#20026;&#35780;&#20272;&#22120;&#26080;&#27861;&#21306;&#20998;&#26126;&#26174;&#38169;&#35823;&#30340;GPT-4&#23436;&#25104;&#21644;GPT-4 + ChemCrow&#24615;&#33021;&#12290;&#36825;&#31181;&#24037;&#20855;&#30340;&#28389;&#29992;&#26377;&#24456;&#22823;&#30340;&#39118;&#38505;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#28508;&#22312;&#21361;&#23475;&#12290;&#22312;&#36127;&#36131;&#20219;&#30340;&#24773;&#20917;&#19979;&#65292;ChemCrow&#19981;&#20165;&#21487;&#20197;&#24110;&#21161;&#19987;&#19994;&#21270;&#23398;&#23478;&#24182;&#38477;&#20302;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-language models (LLMs) have recently shown strong performance in tasks across domains, but struggle with chemistry-related problems. Moreover, these models lack access to external knowledge sources, limiting their usefulness in scientific applications. In this study, we introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery, and materials design. By integrating 13 expert-designed tools, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our evaluation, including both LLM and expert human assessments, demonstrates ChemCrow's effectiveness in automating a diverse set of chemical tasks. Surprisingly, we find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4 completions and GPT-4 + ChemCrow performance. There is a significant risk of misuse of tools like ChemCrow and we discuss their potential harms. Employed responsibly, ChemCrow not only aids expert chemists and lowers ba
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38416;&#36848;&#20102;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#24402;&#32435;&#20559;&#24046;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#31639;&#27861;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#20559;&#22909;&#19982;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20998;&#24067;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2304.05366</link><description>&lt;p&gt;
&#12298;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#12289;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827;&#22797;&#26434;&#24615;&#21450;&#24402;&#32435;&#20559;&#24046;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12299;
&lt;/p&gt;
&lt;p&gt;
The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning. (arXiv:2304.05366v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38416;&#36848;&#20102;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#38480;&#21046;&#65292;&#35777;&#26126;&#20102;&#24402;&#32435;&#20559;&#24046;&#21487;&#20197;&#25552;&#39640;&#23398;&#20064;&#31639;&#27861;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#20559;&#22909;&#19982;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20998;&#24067;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#30340;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#25351;&#20986;&#65292;&#27809;&#26377;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#35299;&#20915;&#25152;&#26377;&#38382;&#39064;&#65292;&#25110;&#32773;&#25152;&#26377;&#23398;&#20064;&#31639;&#27861;&#22312;&#22343;&#21248;&#20998;&#24067;&#30340;&#23398;&#20064;&#38382;&#39064;&#19978;&#24179;&#22343;&#31934;&#24230;&#36798;&#21040;&#23436;&#20840;&#30456;&#21516;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#23450;&#29702;&#32463;&#24120;&#34987;&#24341;&#29992;&#26469;&#25903;&#25345;&#20010;&#21035;&#38382;&#39064;&#38656;&#35201;&#29305;&#21035;&#23450;&#21046;&#30340;&#24402;&#32435;&#20559;&#24046;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#20960;&#20046;&#25152;&#26377;&#22343;&#21248;&#37319;&#26679;&#30340;&#25968;&#25454;&#38598;&#20855;&#26377;&#39640;&#22797;&#26434;&#24615;&#65292;&#20294;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#38382;&#39064;&#19981;&#25104;&#27604;&#20363;&#22320;&#20135;&#29983;&#20302;&#22797;&#26434;&#24230;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#25105;&#20204;&#35748;&#20026;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20063;&#20855;&#26377;&#21516;&#26679;&#30340;&#20559;&#22909;&#65292;&#36825;&#31181;&#20559;&#22909;&#20351;&#29992;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827;&#22797;&#26434;&#24230;&#36827;&#34892;&#20102;&#24418;&#24335;&#21270;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20026;&#29305;&#23450;&#39046;&#22495;&#35774;&#35745;&#30340;&#20307;&#31995;&#32467;&#26500;&#65292;&#20363;&#22914;&#35745;&#31639;&#26426;&#35270;&#35273;&#65292;&#21487;&#20197;&#21387;&#32553;&#21508;&#31181;&#30475;&#20284;&#19981;&#30456;&#20851;&#30340;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#39044;&#20808;&#35757;&#32451;&#21644;&#21363;&#20351;&#26159;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#35821;&#35328;&#27169;&#22411;&#37117;&#26356;&#21916;&#27426;&#29983;&#25104;&#20302;&#22797;&#26434;&#24230;&#30340;&#24207;&#21015;&#12290;&#23613;&#31649;&#26080;&#20813;&#36153;&#21320;&#39184;&#23450;&#29702;&#20284;&#20046;&#34920;&#26126;&#21508;&#20010;&#38382;&#39064;&#38656;&#35201;&#19987;&#38376;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20294;&#25105;&#20204;&#35299;&#37322;&#35828;&#65292;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#32534;&#30721;&#20851;&#20110;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20998;&#24067;&#30340;&#20808;&#21069;&#30693;&#35782;&#30340;&#24402;&#32435;&#20559;&#24046;&#26469;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
No free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. Accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. While virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using Kolmogorov complexity. Notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. Our experiments show that pre-trained and even randomly initialized language models prefer to generate low-complexity sequences. Whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we exp
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2304.05365</link><description>&lt;p&gt;
&#25105;&#20204;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#21527;&#65311;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20010;&#24615;&#21270;&#27835;&#30103;&#24207;&#21015;&#20197;&#25903;&#25345;&#29992;&#25143;&#37319;&#21462;&#26356;&#20581;&#24247;&#30340;&#34892;&#20026;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#31181;&#36830;&#32493;&#20915;&#31574;&#38382;&#39064;&#28041;&#21450;&#21040;&#22522;&#20110;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#20808;&#21069;&#30340;&#27963;&#21160;&#27700;&#24179;&#12289;&#20301;&#32622;&#31561;&#65289;&#22312;&#20309;&#26102;&#27835;&#30103;&#20197;&#21450;&#22914;&#20309;&#27835;&#30103;&#30340;&#20915;&#23450;&#12290;&#22312;&#32447;RL&#31639;&#27861;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22522;&#20110;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#30693;&#35782;&#20010;&#24615;&#21270;&#36825;&#20123;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#35201;&#20915;&#23450;&#26159;&#21542;&#24212;&#22312;&#23454;&#38469;&#37096;&#32626;&#30340;&#8220;&#20248;&#21270;&#8221;&#24178;&#39044;&#20013;&#21253;&#21547;RL&#31639;&#27861;&#65292;&#25105;&#20204;&#24517;&#39035;&#35780;&#20272;&#25968;&#25454;&#35777;&#25454;&#65292;&#34920;&#26126;RL&#31639;&#27861;&#23454;&#38469;&#19978;&#27491;&#22312;&#23558;&#27835;&#30103;&#20010;&#24615;&#21270;&#36866;&#24212;&#20854;&#29992;&#25143;&#12290;&#30001;&#20110;RL&#31639;&#27861;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#23545;&#20854;&#22312;&#26576;&#20123;&#29366;&#24577;&#19979;&#30340;&#23398;&#20064;&#24182;&#20351;&#29992;&#27492;&#23398;&#20064;&#26469;&#25552;&#20379;&#29305;&#23450;&#27835;&#30103;&#30340;&#33021;&#21147;&#20135;&#29983;&#35823;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#24037;&#20316;&#23450;&#20041;&#30340;&#20010;&#24615;&#21270;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#37325;&#22797;&#37319;&#26679;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#32447;RL&#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#20010;&#24615;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21019;&#24314;&#32422;&#26463;&#22495;&#30340;&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#22522;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#35825;&#23548;&#30340;&#23545;&#25968;&#38556;&#30861;&#24230;&#37327;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#12290;&#36825;&#20123;&#26041;&#27861;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#24212;&#29992;&#33539;&#22260;&#25193;&#23637;&#21040;&#20102;&#26426;&#22120;&#20154;&#21644;&#34507;&#30333;&#35774;&#35745;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2304.05364</link><description>&lt;p&gt;
&#32422;&#26463;&#22495;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models for Constrained Domains. (arXiv:2304.05364v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21019;&#24314;&#32422;&#26463;&#22495;&#30340;&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#22522;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#35825;&#23548;&#30340;&#23545;&#25968;&#38556;&#30861;&#24230;&#37327;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#12290;&#36825;&#20123;&#26041;&#27861;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#24212;&#29992;&#33539;&#22260;&#25193;&#23637;&#21040;&#20102;&#26426;&#22120;&#20154;&#21644;&#34507;&#30333;&#35774;&#35745;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#26159;&#26032;&#36817;&#28044;&#29616;&#30340;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#22312;&#26080;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#35821;&#38899;&#29983;&#25104;&#31561;&#20247;&#22810;&#39046;&#22495;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25104;&#26524;&#12290;&#23427;&#20204;&#30001;&#30772;&#22351;&#25968;&#25454;&#30340;&#21152;&#22122;&#36807;&#31243;&#21644;&#23450;&#20041;&#20026;&#21152;&#22122;&#25193;&#25955;&#30340;&#26102;&#38388;&#21453;&#28436;&#30340;&#21518;&#21521;&#38454;&#27573;&#32452;&#25104;&#12290;&#20197;&#36825;&#20123;&#25104;&#21151;&#20026;&#22522;&#30784;&#65292;&#25193;&#25955;&#27169;&#22411;&#26368;&#36817;&#25193;&#23637;&#21040;&#20102;&#40654;&#26364;&#27969;&#24418;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#40654;&#26364;&#25193;&#25955;&#27169;&#22411;&#35201;&#27714;&#22312;&#25152;&#26377;&#26102;&#38388;&#19978;&#23450;&#20041;&#27979;&#22320;&#32447;&#12290;&#34429;&#28982;&#35813;&#35774;&#32622;&#21253;&#25324;&#35768;&#22810;&#37325;&#35201;&#24212;&#29992;&#65292;&#20294;&#19981;&#21253;&#25324;&#30001;&#19981;&#31561;&#24335;&#32422;&#26463;&#38598;&#23450;&#20041;&#30340;&#27969;&#24418;&#65292;&#36825;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#65292;&#22914;&#26426;&#22120;&#20154;&#21644;&#34507;&#30333;&#35774;&#35745;&#20013;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#35825;&#23548;&#30340;&#23545;&#25968;&#38556;&#30861;&#24230;&#37327;&#30340;&#21152;&#22122;&#36807;&#31243;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#30340;&#21152;&#22122;&#36807;&#31243;&#12290;&#30001;&#20110;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#32422;&#26463;&#22495;&#65292;&#22240;&#27492;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21019;&#24314;&#32422;&#26463;&#22495;&#30340;&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a recent class of generative models which achieve state-of-the-art results in many domains such as unconditional image generation and text-to-speech tasks. They consist of a noising process destroying the data and a backward stage defined as the time-reversal of the noising diffusion. Building on their success, diffusion models have recently been extended to the Riemannian manifold setting. Yet, these Riemannian diffusion models require geodesics to be defined for all times. While this setting encompasses many important applications, it does not include manifolds defined via a set of inequality constraints, which are ubiquitous in many scientific domains such as robotics and protein design. In this work, we introduce two methods to bridge this gap. First, we design a noising process based on the logarithmic barrier metric induced by the inequality constraints. Second, we introduce a noising process based on the reflected Brownian motion. As existing diffu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#23618;&#24352;&#37327;&#33609;&#22270;&#26469;&#36817;&#20284;&#39640;&#32500;&#27010;&#29575;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#25216;&#26415;&#35299;&#20915;&#32447;&#24615;&#26041;&#31243;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20854;&#31639;&#27861;&#22797;&#26434;&#24230;&#22312;&#39640;&#32500;&#23494;&#24230;&#32500;&#24230;&#19978;&#21576;&#32447;&#24615;&#35268;&#27169;&#12290;</title><link>http://arxiv.org/abs/2304.05305</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#23618;&#24352;&#37327;&#33609;&#22270;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling via Hierarchical Tensor Sketching. (arXiv:2304.05305v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05305
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#23618;&#24352;&#37327;&#33609;&#22270;&#26469;&#36817;&#20284;&#39640;&#32500;&#27010;&#29575;&#23494;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#25216;&#26415;&#35299;&#20915;&#32447;&#24615;&#26041;&#31243;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20854;&#31639;&#27861;&#22797;&#26434;&#24230;&#22312;&#39640;&#32500;&#23494;&#24230;&#32500;&#24230;&#19978;&#21576;&#32447;&#24615;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32463;&#39564;&#20998;&#24067;&#26469;&#36817;&#20284;&#39640;&#32500;&#27010;&#29575;&#23494;&#24230;&#30340;&#20998;&#23618;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#25216;&#26415;&#65292;&#24182;&#28041;&#21450;&#22312;&#35813;&#24352;&#37327;&#32593;&#32476;&#20013;&#35299;&#32447;&#24615;&#26041;&#31243;&#20197;&#33719;&#24471;&#24352;&#37327;&#26680;&#24515;&#12290;&#35813;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#22312;&#39640;&#32500;&#23494;&#24230;&#30340;&#32500;&#24230;&#19978;&#21576;&#32447;&#24615;&#35268;&#27169;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#23545;&#20272;&#35745;&#35823;&#24046;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#27492;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a hierarchical tensor-network approach for approximating high-dimensional probability density via empirical distribution. This leverages randomized singular value decomposition (SVD) techniques and involves solving linear equations for tensor cores in this tensor network. The complexity of the resulting algorithm scales linearly in the dimension of the high-dimensional density. An analysis of estimation error demonstrates the effectiveness of this method through several numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.05294</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#36873;&#25321;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#24378;&#20581;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery. (arXiv:2304.05294v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#20581;&#30340;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#21019;&#24314;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#39046;&#22495;&#30693;&#35782;&#26377;&#38480;&#12289;&#28508;&#22312;&#20132;&#20114;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#32479;&#35745;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#36873;&#25321;&#26368;&#20248;&#29305;&#24449;&#38598;&#36890;&#24120;&#24456;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#65288;M&#65289;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#24182;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Tigramite Python&#21253;&#20013;&#23454;&#29616;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;PC1&#25110;PCMCI&#12290;&#36825;&#20123;&#31639;&#27861;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#25512;&#26029;&#22240;&#26524;&#22270;&#30340;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#23558;&#21097;&#20313;&#22240;&#26524;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#20256;&#36882;&#32473;ML&#27169;&#22411;&#65288;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#65292;&#38543;&#26426;&#26862;&#26519;&#65289;&#39044;&#27979;&#30446;&#26631;&#20043;&#21069;&#65292;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#39044;&#27979;&#35199;&#22826;&#24179;&#27915;&#28909;&#24102;&#22320;&#21306;&#30340;&#22320;&#38663;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust feature selection is vital for creating reliable and interpretable Machine Learning (ML) models. When designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. To mitigate this issue, we introduce a Multidata (M) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. This approach uses the causal discovery algorithms PC1 or PCMCI that are implemented in the Tigramite Python package. These algorithms utilize conditional independence tests to infer parts of the causal graph. Our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ML models (Multiple linear regression, Random Forest) that predict the targets. We apply our framework to the statistical intensity prediction of Western Pacific Tropical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#21487;&#21516;&#26102;&#36827;&#34892;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#65292;&#24182;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.05223</link><description>&lt;p&gt;
&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#19981;&#22343;&#21248;&#22270;&#36235;&#21183;&#36807;&#28388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inhomogeneous graph trend filtering via a l2,0 cardinality penalty. (arXiv:2304.05223v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#21487;&#21516;&#26102;&#36827;&#34892;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#65292;&#24182;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#20272;&#35745;&#20998;&#27573;&#24179;&#28369;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;$\ell_{2,0}$-&#33539;&#25968;&#24809;&#32602;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#21516;&#26102;&#26159;&#22522;&#20110;&#33410;&#28857;&#19978;&#30340;&#20449;&#21495;&#30340;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20854;&#20013;&#32858;&#31867;&#21644;&#21106;&#20849;&#20139;&#30456;&#21516;&#30340;&#20998;&#37197;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#65306;&#19968;&#31181;&#26159;&#22522;&#20110;&#35889;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#26159;&#22522;&#20110;&#27169;&#25311;&#36864;&#28779;&#30340;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#19988;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#35299;&#20915;&#20102;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study estimation of piecewise smooth signals over a graph. We propose a $\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate piecewise smooth graph signals that exhibits inhomogeneous levels of smoothness across the nodes. We prove that the proposed GTF model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. We propose two methods to solve the proposed GTF model: a spectral decomposition method and a method based on simulated annealing. In the experiment on synthetic and real-world datasets, we show that the proposed GTF model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. We also show that the proposed GTF model can be solved more efficiently than existing models for the dataset with a large edge set.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#20449;&#24687;&#23450;&#20041;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#19968;&#38454;&#20248;&#21270;&#22120; - &#33258;&#21160;&#26799;&#24230;&#19979;&#38477;&#12290;&#35813;&#31639;&#27861;&#22312;&#28145;&#24230;&#20840;&#36830;&#25509;&#32593;&#32476;&#21644;&#21367;&#31215;&#32593;&#32476;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#25163;&#21160;&#35843;&#25972;&#20248;&#21270;&#22120;&#30456;&#24403;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.05187</link><description>&lt;p&gt;
&#33258;&#21160;&#26799;&#24230;&#19979;&#38477;&#65306;&#26080;&#36229;&#21442;&#25968;&#30340;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Automatic Gradient Descent: Deep Learning without Hyperparameters. (arXiv:2304.05187v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#20449;&#24687;&#23450;&#20041;&#20248;&#21270;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#26080;&#38656;&#25163;&#21160;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#19968;&#38454;&#20248;&#21270;&#22120; - &#33258;&#21160;&#26799;&#24230;&#19979;&#38477;&#12290;&#35813;&#31639;&#27861;&#22312;&#28145;&#24230;&#20840;&#36830;&#25509;&#32593;&#32476;&#21644;&#21367;&#31215;&#32593;&#32476;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#25163;&#21160;&#35843;&#25972;&#20248;&#21270;&#22120;&#30456;&#24403;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#27966;&#29983;&#29305;&#23450;&#20110;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26080;&#36229;&#21442;&#25968;&#30340;&#19968;&#38454;&#20248;&#21270;&#22120;&#65292;&#31216;&#20026;&#8220;&#33258;&#21160;&#26799;&#24230;&#19979;&#38477;&#8221;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#31070;&#32463;&#20307;&#31995;&#32467;&#26500;&#26174;&#24335;&#22320;&#23450;&#20041;&#32593;&#32476;&#32467;&#26500;&#21442;&#25968;&#26469;&#20248;&#21270;&#28145;&#24230;&#20840;&#36830;&#25509;&#32593;&#32476;&#21644;&#21367;&#31215;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#19982;&#25163;&#21160;&#35843;&#25972;&#20248;&#21270;&#22120;&#25928;&#26524;&#30456;&#24403;&#12290;&#35813;&#31639;&#27861;&#25193;&#23637;&#20102;&#38236;&#20687;&#19979;&#38477;&#26041;&#27861;&#20197;&#22788;&#29702;&#38750;&#20984;&#24615;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The architecture of a deep neural network is defined explicitly in terms of the number of layers, the width of each layer and the general network topology. Existing optimisation frameworks neglect this information in favour of implicit architectural information (e.g. second-order methods) or architecture-agnostic distance functions (e.g. mirror descent). Meanwhile, the most popular optimiser in practice, Adam, is based on heuristics. This paper builds a new framework for deriving optimisation algorithms that explicitly leverage neural architecture. The theory extends mirror descent to non-convex composite objective functions: the idea is to transform a Bregman divergence to account for the non-linear structure of neural architecture. Working through the details for deep fully-connected networks yields automatic gradient descent: a first-order optimiser without any hyperparameters. Automatic gradient descent trains both fully-connected and convolutional networks out-of-the-box and at Im
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Schr{\"o}dinger bridge&#30340;&#26102;&#24207;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#29109;&#25554;&#20540;&#26368;&#20248;&#20256;&#36755;&#26469;&#22788;&#29702;&#21442;&#32771;&#36335;&#24452;&#31354;&#38388;&#19978;&#30340;&#21442;&#32771;&#27010;&#29575;&#20998;&#24067;&#21644;&#30446;&#26631;&#27979;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#27169;&#22411;&#30340;&#35299;&#30001;&#26377;&#38480;&#26102;&#38388;&#21306;&#38388;&#20869;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21644;&#30001;&#25968;&#25454;&#20272;&#35745;&#30340;&#36335;&#24452;&#20381;&#36182;&#28418;&#31227;&#20989;&#25968;&#32452;&#25104;&#65292;&#36890;&#36807;&#27169;&#25311;SB&#25193;&#25955;&#36807;&#31243;&#20135;&#29983;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#26679;&#26412;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#29609;&#20855;&#33258;&#22238;&#24402;&#27169;&#22411;&#12289;GARCH&#27169;&#22411;&#21644;&#20998;&#24418;&#24067;&#26391;&#36816;&#21160;&#26041;&#38754;&#20855;&#26377;&#24456;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.05093</link><description>&lt;p&gt;
&#22522;&#20110;Schr{\"o}dinger bridge&#30340;&#26102;&#24207;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative modeling for time series via Schr{\"o}dinger bridge. (arXiv:2304.05093v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Schr{\"o}dinger bridge&#30340;&#26102;&#24207;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#29109;&#25554;&#20540;&#26368;&#20248;&#20256;&#36755;&#26469;&#22788;&#29702;&#21442;&#32771;&#36335;&#24452;&#31354;&#38388;&#19978;&#30340;&#21442;&#32771;&#27010;&#29575;&#20998;&#24067;&#21644;&#30446;&#26631;&#27979;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#27169;&#22411;&#30340;&#35299;&#30001;&#26377;&#38480;&#26102;&#38388;&#21306;&#38388;&#20869;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21644;&#30001;&#25968;&#25454;&#20272;&#35745;&#30340;&#36335;&#24452;&#20381;&#36182;&#28418;&#31227;&#20989;&#25968;&#32452;&#25104;&#65292;&#36890;&#36807;&#27169;&#25311;SB&#25193;&#25955;&#36807;&#31243;&#20135;&#29983;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#26679;&#26412;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#29609;&#20855;&#33258;&#22238;&#24402;&#27169;&#22411;&#12289;GARCH&#27169;&#22411;&#21644;&#20998;&#24418;&#24067;&#26391;&#36816;&#21160;&#26041;&#38754;&#20855;&#26377;&#24456;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Schr{\"o}dinger bridge (SB)&#26041;&#27861;&#30340;&#26102;&#24207;&#29983;&#25104;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#29109;&#25554;&#20540;&#26368;&#20248;&#20256;&#36755;&#26469;&#22788;&#29702;&#21442;&#32771;&#36335;&#24452;&#31354;&#38388;&#19978;&#30340;&#21442;&#32771;&#27010;&#29575;&#20998;&#24067;&#21644;&#19982;&#26102;&#38388;&#24207;&#21015;&#30340;&#32852;&#21512;&#25968;&#25454;&#20998;&#24067;&#19968;&#33268;&#30340;&#30446;&#26631;&#27979;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#27169;&#22411;&#30340;&#35299;&#30001;&#26377;&#38480;&#26102;&#38388;&#21306;&#38388;&#20869;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21644;&#36335;&#24452;&#20381;&#36182;&#28418;&#31227;&#20989;&#25968;&#32452;&#25104;&#65292;&#22240;&#27492;&#33021;&#24456;&#22909;&#22320;&#20445;&#25345;&#26102;&#38388;&#24207;&#21015;&#20998;&#24067;&#30340;&#26102;&#22495;&#29305;&#24615;&#12290;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#26680;&#22238;&#24402;&#26041;&#27861;&#25110;LSTM&#31070;&#32463;&#32593;&#32476;&#20174;&#25968;&#25454;&#26679;&#26412;&#20013;&#20272;&#35745;&#28418;&#31227;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;SB&#25193;&#25955;&#36807;&#31243;&#20135;&#29983;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#26679;&#26412;&#12290;&#25991;&#31456;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#23454;&#39564;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#29992;&#29609;&#20855;&#33258;&#22238;&#24402;&#27169;&#22411;&#12289;GARCH&#27169;&#22411;&#21644;&#20998;&#24418;&#24067;&#26391;&#36816;&#21160;&#26469;&#27979;&#35797;&#65292;&#29992;&#36793;&#38469;&#21644;&#26102;&#38388;&#20381;&#36182;&#24230;&#37327;&#25105;&#20204;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel generative model for time series based on Schr{\"o}dinger bridge (SB) approach. This consists in the entropic interpolation via optimal transport between a reference probability measure on path space and a target measure consistent with the joint data distribution of the time series. The solution is characterized by a stochastic differential equation on finite horizon with a path-dependent drift function, hence respecting the temporal dynamics of the time series distribution. We can estimate the drift function from data samples either by kernel regression methods or with LSTM neural networks, and the simulation of the SB diffusion yields new synthetic data samples of the time series. The performance of our generative model is evaluated through a series of numerical experiments. First, we test with a toy autoregressive model, a GARCH Model, and the example of fractional Brownian motion, and measure the accuracy of our algorithm with marginal and temporal dependencies 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36328;&#39046;&#22495;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#31867;&#65292;&#21033;&#29992;&#32039;&#25903;&#25745;B&#26679;&#26465;&#22522;&#20989;&#25968;&#65292;&#21487;&#20197;&#20351;&#29992;&#31232;&#30095;&#32447;&#24615;&#20195;&#25968;&#26469;&#26174;&#33879;&#21152;&#24555;&#30697;&#38453;&#36816;&#31639;&#65292; &#23454;&#29616;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19979;&#24555;&#36895;&#39640;&#25928;&#22320;&#24314;&#27169;&#24555;&#36895;&#21464;&#21270;&#30340;&#31354;&#38388;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2304.05091</link><description>&lt;p&gt;
&#23454;&#38469;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Actually Sparse Variational Gaussian Processes. (arXiv:2304.05091v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05091
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36328;&#39046;&#22495;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#31867;&#65292;&#21033;&#29992;&#32039;&#25903;&#25745;B&#26679;&#26465;&#22522;&#20989;&#25968;&#65292;&#21487;&#20197;&#20351;&#29992;&#31232;&#30095;&#32447;&#24615;&#20195;&#25968;&#26469;&#26174;&#33879;&#21152;&#24555;&#30697;&#38453;&#36816;&#31639;&#65292; &#23454;&#29616;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19979;&#24555;&#36895;&#39640;&#25928;&#22320;&#24314;&#27169;&#24555;&#36895;&#21464;&#21270;&#30340;&#31354;&#38388;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#36890;&#24120;&#22240;&#35745;&#31639;&#21644;&#20869;&#23384;&#38656;&#27714;&#30340;&#19981;&#21033;&#25193;&#23637;&#32780;&#21463;&#21040;&#25209;&#35780;&#12290;&#23545;&#20110;&#22823;&#37327;&#25968;&#25454;&#38598;&#65292;&#31232;&#30095; GP &#36890;&#36807;&#22312;&#23569;&#37327;&#24863;&#24212;&#21464;&#37327;&#30340;&#26465;&#20214;&#19979;&#23545;&#25968;&#25454;&#36827;&#34892;&#24635;&#32467;&#26469;&#20943;&#23569;&#36825;&#20123;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#22312;&#38656;&#35201;&#35768;&#22810;&#24863;&#24212;&#21464;&#37327;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#65288;&#20363;&#22914;&#20302;&#38271;&#24230;&#23610;&#24230;&#31354;&#38388;&#25968;&#25454;&#65289;&#20013;&#65292;&#21363;&#20351;&#26159;&#31232;&#30095; GP &#20063;&#21487;&#33021;&#21464;&#24471;&#35745;&#31639;&#26114;&#36149;&#65292;&#21463;&#20351;&#29992;&#24863;&#24212;&#21464;&#37327;&#30340;&#25968;&#37327;&#30340;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36328;&#39046;&#22495;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#31867;&#65292;&#36890;&#36807;&#23558; GP &#25237;&#24433;&#21040;&#19968;&#32452;&#32039;&#25903;&#25745; B &#26679;&#26465;&#22522;&#20989;&#25968;&#19978;&#26469;&#26500;&#24314;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#20851;&#38190;&#20248;&#21183;&#22312;&#20110;&#65292;B &#26679;&#26465;&#22522;&#20989;&#25968;&#30340;&#32039;&#25903;&#25745;&#20801;&#35768;&#20351;&#29992;&#31232;&#30095;&#32447;&#24615;&#20195;&#25968;&#26469;&#26174;&#33879;&#21152;&#24555;&#30697;&#38453;&#36816;&#31639;&#65292;&#24182;&#22823;&#22823;&#20943;&#23569;&#23384;&#20648;&#21344;&#29992;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#25968;&#20197;&#19975;&#35745;&#30340;&#24863;&#24212;&#21464;&#37327;&#38750;&#24120;&#26377;&#25928;&#22320;&#24314;&#27169;&#24555;&#36895;&#21464;&#21270;&#30340;&#31354;&#38388;&#29616;&#35937;&#65292;&#32780;&#20808;&#21069;&#30340;&#26041;&#27861;&#30001;&#20110;&#24863;&#24212;&#21464;&#37327;&#30340;&#20351;&#29992;&#38480;&#21046;&#32780;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GPs) are typically criticised for their unfavourable scaling in both computational and memory requirements. For large datasets, sparse GPs reduce these demands by conditioning on a small set of inducing variables designed to summarise the data. In practice however, for large datasets requiring many inducing variables, such as low-lengthscale spatial data, even sparse GPs can become computationally expensive, limited by the number of inducing variables one can use. In this work, we propose a new class of inter-domain variational GP, constructed by projecting a GP onto a set of compactly supported B-spline basis functions. The key benefit of our approach is that the compact support of the B-spline basis functions admits the use of sparse linear algebra to significantly speed up matrix operations and drastically reduce the memory footprint. This allows us to very efficiently model fast-varying spatial phenomena with tens of thousands of inducing variables, where previo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#26469;&#38477;&#20302;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#30340;&#20272;&#35745;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#20808;&#21033;&#29992;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#65292;&#28982;&#21518;&#29992;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#37325;&#35201;&#30340;&#29366;&#24577;&#32858;&#21512;&#65292;&#26368;&#32456;&#21033;&#29992;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.04916</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#29992;&#20110;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models. (arXiv:2304.04916v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#26469;&#38477;&#20302;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#30340;&#20272;&#35745;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#20808;&#21033;&#29992;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#65292;&#28982;&#21518;&#29992;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#37325;&#35201;&#30340;&#29366;&#24577;&#32858;&#21512;&#65292;&#26368;&#32456;&#21033;&#29992;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#26159;&#20351;&#29992;&#20195;&#29702;&#34892;&#20026;&#25968;&#25454;&#20272;&#35745;&#20195;&#29702;&#22870;&#21169;&#20989;&#25968;&#65288;&#20063;&#31216;&#20026;&#8220;&#32467;&#26500;&#21442;&#25968;&#8221;&#65289;&#30340;&#21442;&#25968;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#38656;&#35201;&#21160;&#24577;&#35268;&#21010;&#65292;&#36825;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#26469;&#36873;&#25321;&#21644;&#32858;&#21512;&#29366;&#24577;&#65292;&#38477;&#20302;&#20102;&#20272;&#35745;&#30340;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20998;&#20004;&#20010;&#38454;&#27573;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28789;&#27963;&#30340;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#20272;&#35745;&#30340;Q&#20989;&#25968;&#65292;&#20197;&#21450;&#19968;&#20010;&#32858;&#31867;&#31639;&#27861;&#65292;&#36873;&#25321;&#20102;&#19968;&#20123;&#26368;&#20026;&#37325;&#35201;&#30340;&#29366;&#24577;&#65292;&#36825;&#20123;&#29366;&#24577;&#23545;&#20110;&#39537;&#21160;Q&#20989;&#25968;&#30340;&#21464;&#21270;&#26368;&#20026;&#20851;&#38190;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#21033;&#29992;&#36825;&#20123;&#34987;&#36873;&#25321;&#30340;&#8220;&#32858;&#21512;&#8221;&#29366;&#24577;&#65292;&#25105;&#20204;&#20351;&#29992;&#24120;&#29992;&#30340;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#20108;&#38454;&#27573;&#26041;&#27861;&#23454;&#29616;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We study dynamic discrete choice models, where a commonly studied problem involves estimating parameters of agent reward functions (also known as "structural" parameters), using agent behavioral data. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. In the first stage, we use a flexible inverse reinforcement learning approach to estimate agent Q-functions. We use these estimated Q-functions, along with a clustering algorithm, to select a subset of states that are the most pivotal for driving changes in Q-functions. In the second stage, with these selected "aggregated" states, we conduct maximum likelihood estimation using a commonly used nested fixed-point algorithm. The proposed two-stage approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#19981;&#30830;&#23450;&#24615;&#24402;&#22240;&#26041;&#27861;&#26469;&#30830;&#23450;&#23548;&#33268;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#20855;&#38382;&#39064;&#24615;&#30340;&#36755;&#20837;&#21306;&#22495;&#65292;&#20174;&#32780;&#23454;&#29616;&#21487;&#35299;&#37322;&#21644;&#21487;&#25805;&#20316;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2304.04824</link><description>&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#30340;&#19981;&#30830;&#23450;&#24615;&#24402;&#22240;&#20110;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Gradient-based Uncertainty Attribution for Explainable Bayesian Deep Learning. (arXiv:2304.04824v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26799;&#24230;&#30340;&#19981;&#30830;&#23450;&#24615;&#24402;&#22240;&#26041;&#27861;&#26469;&#30830;&#23450;&#23548;&#33268;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#20855;&#38382;&#39064;&#24615;&#30340;&#36755;&#20837;&#21306;&#22495;&#65292;&#20174;&#32780;&#23454;&#29616;&#21487;&#35299;&#37322;&#21644;&#21487;&#25805;&#20316;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25152;&#20316;&#20986;&#30340;&#39044;&#27979;&#23481;&#26131;&#21463;&#21040;&#25968;&#25454;&#25200;&#21160;&#12289;&#23545;&#25239;&#25915;&#20987;&#21644;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#36755;&#20837;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#26500;&#24314;&#19968;&#20010;&#21487;&#20449;&#36182;&#30340;AI&#31995;&#32479;&#65292;&#20934;&#30830;&#37327;&#21270;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#24403;&#21069;&#30340;&#24037;&#20316;&#37325;&#28857;&#26159;&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#20294;&#26377;&#24517;&#35201;&#30830;&#23450;&#19981;&#30830;&#23450;&#24615;&#28304;&#24182;&#37319;&#21462;&#25514;&#26045;&#20943;&#36731;&#23545;&#39044;&#27979;&#30340;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24320;&#21457;&#21487;&#35299;&#37322;&#21644;&#21487;&#25805;&#20316;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26469;&#19981;&#20165;&#36827;&#34892;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#32780;&#19988;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#12289;&#30830;&#23450;&#20854;&#26469;&#28304;&#24182;&#25552;&#20986;&#20943;&#36731;&#19981;&#30830;&#23450;&#24615;&#24433;&#21709;&#30340;&#31574;&#30053;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#19981;&#30830;&#23450;&#24615;&#24402;&#22240;&#26041;&#27861;&#26469;&#30830;&#23450;&#26368;&#20855;&#38382;&#39064;&#24615;&#30340;&#36755;&#20837;&#21306;&#22495;&#65292;&#20174;&#32780;&#23548;&#33268;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;UA-Backprop&#26041;&#27861;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24615;&#12289;&#26494;&#24347;&#30340;&#20551;&#35774;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictions made by deep learning models are prone to data perturbations, adversarial attacks, and out-of-distribution inputs. To build a trusted AI system, it is therefore critical to accurately quantify the prediction uncertainties. While current efforts focus on improving uncertainty quantification accuracy and efficiency, there is a need to identify uncertainty sources and take actions to mitigate their effects on predictions. Therefore, we propose to develop explainable and actionable Bayesian deep learning methods to not only perform accurate uncertainty quantification but also explain the uncertainties, identify their sources, and propose strategies to mitigate the uncertainty impacts. Specifically, we introduce a gradient-based uncertainty attribution method to identify the most problematic regions of the input that contribute to the prediction uncertainty. Compared to existing methods, the proposed UA-Backprop has competitive accuracy, relaxed assumptions, and high efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24847;&#22270;&#24314;&#27169;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#34987;&#21160;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#65292;&#24182;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#20215;&#20540;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2304.04782</link><description>&lt;p&gt;
&#36890;&#36807;&#28508;&#22312;&#24847;&#22270;&#20174;&#34987;&#21160;&#25968;&#25454;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Passive Data via Latent Intentions. (arXiv:2304.04782v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24847;&#22270;&#24314;&#27169;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#34987;&#21160;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#65292;&#24182;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#20215;&#20540;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34987;&#21160;&#35266;&#23519;&#25968;&#25454;&#20016;&#23500;&#32780;&#23500;&#26377;&#20449;&#24687;&#65292;&#28982;&#32780;&#24403;&#21069;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#24456;&#23569;&#33021;&#22815;&#21033;&#29992;&#35813;&#25968;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24314;&#27169;&#24847;&#22270;&#20174;&#34987;&#21160;&#25968;&#25454;&#20013;&#36827;&#34892;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#34913;&#37327;&#24403;&#26234;&#33021;&#20307;&#20026;&#23454;&#29616;&#29305;&#23450;&#20219;&#21153;&#32780;&#37319;&#21462;&#34892;&#21160;&#26102;&#26410;&#26469;&#32467;&#26524;&#30340;&#21487;&#33021;&#24615;&#22914;&#20309;&#21464;&#21270;&#26469;&#23398;&#20064;&#24847;&#22270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26102;&#24046;&#23398;&#20064;&#30446;&#26631;&#26469;&#23398;&#20064;&#24847;&#22270;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#31867;&#20284;&#20110;&#20256;&#32479;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#20294;&#26159;&#23436;&#20840;&#26159;&#20174;&#34987;&#21160;&#25968;&#25454;&#20013;&#23398;&#20064;&#24471;&#21040;&#30340;&#12290;&#36890;&#36807;&#20248;&#21270;&#35813;&#30446;&#26631;&#65292;&#25105;&#20204;&#30340;&#26234;&#33021;&#20307;&#21487;&#20197;&#21516;&#26102;&#20174;&#21407;&#22987;&#30340;&#35266;&#23519;&#25968;&#25454;&#20013;&#23398;&#20064;&#20986;&#29366;&#24577;&#12289;&#31574;&#30053;&#21644;&#29615;&#22659;&#19979;&#30340;&#21487;&#33021;&#32467;&#26524;&#12290;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#19978;&#30475;&#65292;&#35813;&#26041;&#27861;&#23398;&#20064;&#20986;&#30340;&#29305;&#24449;&#21487;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#30340;&#20215;&#20540;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Passive observational data, such as human videos, is abundant and rich in information, yet remains largely untapped by current RL methods. Perhaps surprisingly, we show that passive data, despite not having reward or action labels, can still be used to learn features that accelerate downstream RL. Our approach learns from passive data by modeling intentions: measuring how the likelihood of future outcomes change when the agent acts to achieve a particular task. We propose a temporal difference learning objective to learn about intentions, resulting in an algorithm similar to conventional RL, but which learns entirely from passive data. When optimizing this objective, our agent simultaneously learns representations of states, of policies, and of possible outcomes in an environment, all from raw observational data. Both theoretically and empirically, this scheme learns features amenable for value prediction for downstream tasks, and our experiments demonstrate the ability to learn from m
&lt;/p&gt;</description></item><item><title>StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2304.03853</link><description>&lt;p&gt;
StepMix: &#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;
&lt;/p&gt;
&lt;p&gt;
StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables. (arXiv:2304.03853v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03853
&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#24191;&#20041;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;(&#28508;&#22312;&#21078;&#38754;&#21644;&#28508;&#22312;&#31867;&#20998;&#26512;)&#19982;&#22806;&#37096;&#21464;&#37327;(&#21327;&#21464;&#37327;&#21644;&#36828;&#31243;&#32467;&#26524;)&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;(&#21333;&#27493;&#12289;&#20004;&#27493;&#21644;&#19977;&#27493;&#26041;&#27861;)&#30340;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;&#22312;&#35768;&#22810;&#31038;&#20250;&#31185;&#23398;&#30340;&#24212;&#29992;&#20013;&#65292;&#20027;&#35201;&#30446;&#26631;&#19981;&#20165;&#26159;&#23558;&#20010;&#20307;&#32858;&#31867;&#25104;&#28508;&#22312;&#31867;&#21035;&#65292;&#36824;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#31867;&#21035;&#26469;&#24320;&#21457;&#26356;&#22797;&#26434;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20998;&#20026;&#19968;&#20010;&#23558;&#28508;&#22312;&#31867;&#21035;&#19982;&#35266;&#23519;&#25351;&#26631;&#30456;&#20851;&#32852;&#30340;&#27979;&#37327;&#27169;&#22411;&#21644;&#19968;&#20010;&#23558;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#19982;&#28508;&#22312;&#31867;&#21035;&#30456;&#20851;&#32852;&#30340;&#32467;&#26500;&#27169;&#22411;&#12290;&#27979;&#37327;&#21644;&#32467;&#26500;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#25152;&#35859;&#30340;&#19968;&#27493;&#27861;&#20849;&#21516;&#20272;&#35745;&#65292;&#20063;&#21487;&#20197;&#20351;&#29992;&#36880;&#27493;&#26041;&#27861;&#36880;&#27493;&#20272;&#35745;&#65292;&#23545;&#20110;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#28508;&#22312;&#31867;&#21035;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#38500;&#20102;&#19968;&#27493;&#27861;&#65292;StepMix&#36824;&#23454;&#29616;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#26368;&#37325;&#35201;&#30340;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#21451;&#22909;&#30340;&#30028;&#38754;&#65292;&#26041;&#20415;&#27169;&#22411;&#30340;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
StepMix is an open-source software package for the pseudo-likelihood estimation (one-, two- and three-step approaches) of generalized finite mixture models (latent profile and latent class analysis) with external variables (covariates and distal outcomes). In many applications in social sciences, the main objective is not only to cluster individuals into latent classes, but also to use these classes to develop more complex statistical models. These models generally divide into a measurement model that relates the latent classes to observed indicators, and a structural model that relates covariates and outcome variables to the latent classes. The measurement and structural models can be estimated jointly using the so-called one-step approach or sequentially using stepwise methods, which present significant advantages for practitioners regarding the interpretability of the estimated latent classes. In addition to the one-step approach, StepMix implements the most important stepwise estim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;</title><link>http://arxiv.org/abs/2303.16372</link><description>&lt;p&gt;
&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#30340;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Lower Bounds For Training Data Reconstruction. (arXiv:2303.16372v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19987;&#19994;&#23545;&#25163;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#25915;&#20987;&#26102;&#31169;&#26377;&#23398;&#20064;&#31639;&#27861;&#30340;&#35821;&#20041;&#20445;&#35777;&#24378;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36827;&#37327;&#32423;&#19979;&#30028;&#26469;&#30740;&#31350;&#20102;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21644;&#24230;&#37327;&#38544;&#31169;&#65288;mDP&#65289;&#30340;&#23398;&#20064;&#22120;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#23545;mDP&#30340;&#20998;&#26512;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#12290;&#26412;&#25991;&#36827;&#19968;&#27493;&#23545;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;DP-SGD&#21644;Projected Noisy SGD&#36827;&#34892;&#20102;&#24230;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#25193;&#23637;&#38544;&#31169;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate semantic guarantees of private learning algorithms for their resilience to training Data Reconstruction Attacks (DRAs) by informed adversaries. To this end, we derive non-asymptotic minimax lower bounds on the adversary's reconstruction error against learners that satisfy differential privacy (DP) and metric differential privacy (mDP). Furthermore, we demonstrate that our lower bound analysis for the latter also covers the high dimensional regime, wherein, the input data dimensionality may be larger than the adversary's query budget. Motivated by the theoretical improvements conferred by metric DP, we extend the privacy analysis of popular deep learning algorithms such as DP-SGD and Projected Noisy SGD to cover the broader notion of metric differential privacy.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20849;&#20139;&#36890;&#20449;&#21407;&#29702;&#30340;&#36890;&#20449;&#39640;&#25928;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PAO-Fed&#65289;&#31574;&#30053;&#65292;&#33021;&#22815;&#22788;&#29702;&#24322;&#26500;&#21644;&#24310;&#36831;&#35774;&#22791;&#65292;&#23454;&#29616;&#21442;&#19982;&#23398;&#20064;&#20219;&#21153;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.15226</link><description>&lt;p&gt;
&#24102;&#26377;&#38477;&#20302;&#36890;&#20449;&#35201;&#27714;&#30340;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Asynchronous Online Federated Learning with Reduced Communication Requirements. (arXiv:2303.15226v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15226
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20849;&#20139;&#36890;&#20449;&#21407;&#29702;&#30340;&#36890;&#20449;&#39640;&#25928;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PAO-Fed&#65289;&#31574;&#30053;&#65292;&#33021;&#22815;&#22788;&#29702;&#24322;&#26500;&#21644;&#24310;&#36831;&#35774;&#22791;&#65292;&#23454;&#29616;&#21442;&#19982;&#23398;&#20064;&#20219;&#21153;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#20351;&#24471;&#22320;&#29702;&#20998;&#24067;&#30340;&#35774;&#22791;&#21487;&#20197;&#20174;&#26412;&#22320;&#30340;&#27969;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#20840;&#23616;&#20849;&#20139;&#27169;&#22411;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;&#22312;&#32447;FL&#30340;&#25991;&#29486;&#37117;&#32771;&#34385;&#20102;&#26368;&#20339;&#24773;&#20917;&#19979;&#30340;&#21442;&#19982;&#23458;&#25143;&#31471;&#21644;&#36890;&#20449;&#28192;&#36947;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20551;&#35774;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#36890;&#24120;&#26080;&#27861;&#28385;&#36275;&#12290;&#24322;&#27493;&#35774;&#32622;&#21487;&#20197;&#21453;&#26144;&#20986;&#26356;&#29616;&#23454;&#30340;&#29615;&#22659;&#65292;&#20363;&#22914;&#30001;&#20110;&#21487;&#29992;&#30340;&#35745;&#31639;&#33021;&#21147;&#21644;&#30005;&#27744;&#38480;&#21046;&#32780;&#21457;&#29983;&#30340;&#24322;&#26500;&#23458;&#25143;&#31471;&#21442;&#19982;&#65292;&#20197;&#21450;&#30001;&#36890;&#20449;&#28192;&#36947;&#25110;&#33853;&#21518;&#35774;&#22791;&#24341;&#36215;&#30340;&#24310;&#36831;&#12290;&#27492;&#22806;&#65292;&#22312;&#22823;&#22810;&#25968;&#24212;&#29992;&#20013;&#65292;&#24517;&#39035;&#32771;&#34385;&#33021;&#28304;&#25928;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20849;&#20139;&#36890;&#20449;&#21407;&#29702;&#30340;&#36890;&#20449;&#39640;&#25928;&#24322;&#27493;&#22312;&#32447;&#32852;&#37030;&#23398;&#20064;&#65288;PAO-Fed&#65289;&#31574;&#30053;&#65292;&#36890;&#36807;&#20943;&#23569;&#21442;&#19982;&#32773;&#30340;&#36890;&#20449;&#24320;&#38144;&#65292;&#25552;&#39640;&#20102;&#21442;&#19982;&#23398;&#20064;&#20219;&#21153;&#30340;&#21487;&#35775;&#38382;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#24322;&#26500;&#21644;&#24310;&#36831;&#35774;&#22791;&#65292;&#20351;&#20854;&#26356;&#36866;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online federated learning (FL) enables geographically distributed devices to learn a global shared model from locally available streaming data. Most online FL literature considers a best-case scenario regarding the participating clients and the communication channels. However, these assumptions are often not met in real-world applications. Asynchronous settings can reflect a more realistic environment, such as heterogeneous client participation due to available computational power and battery constraints, as well as delays caused by communication channels or straggler devices. Further, in most applications, energy efficiency must be taken into consideration. Using the principles of partial-sharing-based communications, we propose a communication-efficient asynchronous online federated learning (PAO-Fed) strategy. By reducing the communication overhead of the participants, the proposed method renders participation in the learning task more accessible and efficient. In addition, the prop
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#28431;&#27934;&#22914;&#20309;&#21462;&#20915;&#20110;&#21463;&#38480;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#23376;&#31354;&#38388;&#32500;&#25968;&#65292;&#21516;&#26102;&#38024;&#23545;&#26631;&#20934;PGD&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#25104;&#21151;&#29575;&#25552;&#20986;&#20102;&#21333;&#35843;&#36882;&#22686;&#20989;&#25968;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2303.14173</link><description>&lt;p&gt;
&#25214;&#21040;&#23545;&#25239;&#26679;&#26412;&#38656;&#35201;&#22810;&#23569;&#32500;&#24230;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many dimensions are required to find an adversarial example?. (arXiv:2303.14173v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#28431;&#27934;&#22914;&#20309;&#21462;&#20915;&#20110;&#21463;&#38480;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#23376;&#31354;&#38388;&#32500;&#25968;&#65292;&#21516;&#26102;&#38024;&#23545;&#26631;&#20934;PGD&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#25104;&#21151;&#29575;&#25552;&#20986;&#20102;&#21333;&#35843;&#36882;&#22686;&#20989;&#25968;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#25506;&#32034;&#23545;&#25239;&#24615;&#28431;&#27934;&#30340;&#30740;&#31350;&#37117;&#30528;&#30524;&#20110;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#27169;&#22411;&#36755;&#20837;&#30340;&#25152;&#26377;&#32500;&#24230;&#30340;&#24773;&#20917;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#32771;&#34385;&#20197;&#19979;&#24773;&#20917;&#65306;&#65288;i&#65289;&#23545;&#25163;&#21487;&#20197;&#25200;&#21160;&#26377;&#38480;&#25968;&#37327;&#30340;&#36755;&#20837;&#21442;&#25968;&#25110;&#65288;ii&#65289;&#22810;&#27169;&#24577;&#38382;&#39064;&#20013;&#30340;&#27169;&#24577;&#23376;&#38598;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#23545;&#25239;&#24615;&#26679;&#26412;&#26377;&#25928;&#22320;&#21463;&#38480;&#20110;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#23376;&#31354;&#38388;$V$&#12290;&#20986;&#20110;&#36825;&#20010;&#21160;&#26426;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#28431;&#27934;&#22914;&#20309;&#21462;&#20915;&#20110;$V$&#30340;&#32500;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;PGD&#25915;&#20987;&#30340;&#23545;&#25239;&#24615;&#25104;&#21151;&#29575;&#22914;&#20309;&#34920;&#29616;&#20026;$\epsilon (\frac{\dim(V)}{\dim \mathcal{X}})^{\frac{1}{q}}$&#30340;&#21333;&#35843;&#36882;&#22686;&#20989;&#25968;&#65292;&#20854;&#20013;$\epsilon$&#26159;&#25200;&#21160;&#39044;&#31639;&#65292;$\frac{1}{p}+\frac{q}{q}=1$&#65292;&#21482;&#35201;$p&gt;1$&#65288;&#24403;$p=1$&#26102;&#20250;&#20986;&#29616;&#39069;&#22806;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#25105;&#20204;&#23545;&#27492;&#36827;&#34892;&#20102;&#35814;&#32454;&#30340;&#20998;&#26512;&#65289;&#12290;&#36825;&#20010;&#20989;&#25968;&#24418;&#24335;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Past work exploring adversarial vulnerability have focused on situations where an adversary can perturb all dimensions of model input. On the other hand, a range of recent works consider the case where either (i) an adversary can perturb a limited number of input parameters or (ii) a subset of modalities in a multimodal problem. In both of these cases, adversarial examples are effectively constrained to a subspace $V$ in the ambient input space $\mathcal{X}$. Motivated by this, in this work we investigate how adversarial vulnerability depends on $\dim(V)$. In particular, we show that the adversarial success of standard PGD attacks with $\ell^p$ norm constraints behaves like a monotonically increasing function of $\epsilon (\frac{\dim(V)}{\dim \mathcal{X}})^{\frac{1}{q}}$ where $\epsilon$ is the perturbation budget and $\frac{1}{p} + \frac{1}{q} =1$, provided $p &gt; 1$ (the case $p=1$ presents additional subtleties which we analyze in some detail). This functional form can be easily deriv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31070;&#32463;&#25289;&#26222;&#25289;&#26031;&#25511;&#21046;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#19981;&#35268;&#21017;&#29366;&#24577;&#35266;&#27979;&#21644;&#26410;&#30693;&#24310;&#36831;&#30340;&#36830;&#32493;&#26102;&#38388;&#29615;&#22659;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.12604</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24310;&#36831;&#31995;&#32479;&#30340;&#31070;&#32463;&#25289;&#26222;&#25289;&#26031;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Neural Laplace Control for Continuous-time Delayed Systems. (arXiv:2302.12604v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12604
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31070;&#32463;&#25289;&#26222;&#25289;&#26031;&#25511;&#21046;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#19981;&#35268;&#21017;&#29366;&#24577;&#35266;&#27979;&#21644;&#26410;&#30693;&#24310;&#36831;&#30340;&#36830;&#32493;&#26102;&#38388;&#29615;&#22659;&#19979;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23454;&#38469;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#21253;&#25324;&#20855;&#26377;&#24310;&#36831;&#30340;&#36830;&#32493;&#26102;&#38388;&#29615;&#22659;&#12290;&#36825;&#20123;&#29615;&#22659;&#20855;&#26377;&#20004;&#20010;&#26174;&#33879;&#29305;&#28857;&#65306;&#39318;&#20808;&#65292;&#35266;&#23519;&#21040;&#30340;&#29366;&#24577;x(t)&#22312;&#19981;&#35268;&#21017;&#30340;&#26102;&#38388;&#38388;&#38548;&#20869;&#36827;&#34892;&#35266;&#23519;&#65307;&#20854;&#27425;&#65292;&#24403;&#21069;&#34892;&#21160;a(t)&#20165;&#22312;&#26410;&#30693;&#24310;&#36831;g &gt; 0 &#30340;&#24773;&#20917;&#19979;&#24433;&#21709;&#26410;&#26469;&#29366;&#24577;x(t+g)&#12290;&#36825;&#26679;&#30340;&#29615;&#22659;&#30340;&#19968;&#20010;&#20856;&#22411;&#20363;&#23376;&#26159;&#21355;&#26143;&#25511;&#21046;&#65292;&#20854;&#20013;&#22320;&#29699;&#21644;&#21355;&#26143;&#20043;&#38388;&#30340;&#36890;&#20449;&#38142;&#36335;&#20250;&#36896;&#25104;&#35266;&#27979;&#19981;&#35268;&#21017;&#21644;&#24310;&#36831;&#12290;&#29616;&#26377;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;&#20855;&#26377;&#26102;&#38388;&#19981;&#35268;&#21017;&#35266;&#27979;&#25110;&#24050;&#30693;&#24310;&#36831;&#30340;&#29615;&#22659;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#28041;&#21450;&#26102;&#38388;&#19981;&#35268;&#21017;&#35266;&#27979;&#21644;&#26410;&#30693;&#24310;&#36831;&#30340;&#29615;&#22659;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31070;&#32463;&#25289;&#26222;&#25289;&#26031;&#25511;&#21046;&#65292;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#23558;&#31070;&#32463;&#25289;&#26222;&#25289;&#26031;&#21160;&#21147;&#23398;&#27169;&#22411;&#19982;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#65288;MPC&#65289;&#35268;&#21010;&#22120;&#30456;&#32467;&#21512;&#65292;&#24182;&#33021;&#22815;&#20174;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world offline reinforcement learning (RL) problems involve continuous-time environments with delays. Such environments are characterized by two distinctive features: firstly, the state x(t) is observed at irregular time intervals, and secondly, the current action a(t) only affects the future state x(t + g) with an unknown delay g &gt; 0. A prime example of such an environment is satellite control where the communication link between earth and a satellite causes irregular observations and delays. Existing offline RL algorithms have achieved success in environments with irregularly observed states in time or known delays. However, environments involving both irregular observations in time and unknown delays remains an open and challenging problem. To this end, we propose Neural Laplace Control, a continuous-time model-based offline RL method that combines a Neural Laplace dynamics model with a model predictive control (MPC) planner--and is able to learn from an offline dataset sam
&lt;/p&gt;</description></item><item><title>&#20462;&#27491;&#30340;&#26465;&#20214;t-SNE&#31639;&#27861;&#36890;&#36807;&#23545;&#39640;&#32500;&#30456;&#20284;&#24230;&#36827;&#34892;&#26465;&#20214;&#38480;&#21046;&#65292;&#35299;&#20915;&#20102;&#22312;&#25968;&#25454;&#32463;&#36807;&#26631;&#31614;&#33391;&#22909;&#32858;&#31867;&#26102;&#65292;&#26465;&#20214;t-SNE&#31639;&#27861;&#30340;&#19981;&#36275;&#12290;&#24182;&#36890;&#36807;&#23545;&#30456;&#20284;&#24230;&#30697;&#38453;&#23384;&#20648;&#30340;&#25913;&#21464;&#25552;&#39640;&#20102;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.03493</link><description>&lt;p&gt;
&#20462;&#27491;&#30340;&#26465;&#20214;t-SNE&#31639;&#27861;&#65306;&#36229;&#36234;&#26368;&#36817;&#37051;&#36817;&#30340;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Revised Conditional t-SNE: Looking Beyond the Nearest Neighbors. (arXiv:2302.03493v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03493
&lt;/p&gt;
&lt;p&gt;
&#20462;&#27491;&#30340;&#26465;&#20214;t-SNE&#31639;&#27861;&#36890;&#36807;&#23545;&#39640;&#32500;&#30456;&#20284;&#24230;&#36827;&#34892;&#26465;&#20214;&#38480;&#21046;&#65292;&#35299;&#20915;&#20102;&#22312;&#25968;&#25454;&#32463;&#36807;&#26631;&#31614;&#33391;&#22909;&#32858;&#31867;&#26102;&#65292;&#26465;&#20214;t-SNE&#31639;&#27861;&#30340;&#19981;&#36275;&#12290;&#24182;&#36890;&#36807;&#23545;&#30456;&#20284;&#24230;&#30697;&#38453;&#23384;&#20648;&#30340;&#25913;&#21464;&#25552;&#39640;&#20102;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;t-SNE&#65288;ct-SNE&#65289;&#26159;t-SNE&#30340;&#26368;&#26032;&#25193;&#23637;&#65292;&#23427;&#20801;&#35768;&#20174;&#23884;&#20837;&#20013;&#21024;&#38500;&#24050;&#30693;&#30340;&#32858;&#31867;&#20449;&#24687;&#65292;&#20197;&#33719;&#24471;&#25581;&#31034;&#26631;&#31614;&#20449;&#24687;&#20043;&#22806;&#30340;&#32467;&#26500;&#30340;&#21487;&#35270;&#21270;&#32467;&#26524;&#12290;&#36825;&#22312;&#38656;&#35201;&#28040;&#38500;&#19968;&#32452;&#31867;&#20043;&#38388;&#19981;&#24819;&#35201;&#30340;&#24046;&#24322;&#26102;&#38750;&#24120;&#26377;&#29992;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#35768;&#22810;&#29616;&#23454;&#24773;&#20917;&#19979;&#65292;ct-SNE&#30340;&#34920;&#29616;&#24182;&#19981;&#29702;&#24819;&#65292;&#23588;&#20854;&#26159;&#24403;&#25968;&#25454;&#22312;&#21407;&#22987;&#30340;&#39640;&#32500;&#31354;&#38388;&#20013;&#25353;&#26631;&#31614;&#36827;&#34892;&#33391;&#22909;&#30340;&#32858;&#31867;&#26102;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#39640;&#32500;&#30456;&#20284;&#24230;&#36827;&#34892;&#26465;&#20214;&#38480;&#21046;&#65292;&#24182;&#23558;&#22522;&#20110;&#26631;&#31614;&#30340;&#26368;&#36817;&#37051;&#21644;&#36328;&#26631;&#31614;&#30340;&#26368;&#36817;&#37051;&#23384;&#20648;&#22312;&#19981;&#21516;&#30340;&#30697;&#38453;&#20013;&#12290;&#36825;&#36824;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;t-SNE&#21152;&#36895;&#25216;&#26415;&#65292;&#25552;&#39640;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#20174;&#21512;&#25104;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#32771;&#34385;&#30340;&#38382;&#39064;&#65292;&#24182;&#25913;&#21892;&#20102;&#23884;&#20837;&#36136;&#37327;&#12290;&#20294;&#26159;&#22312;&#21253;&#21547;&#25209;&#27425;&#25928;&#24212;&#30340;&#23454;&#38469;&#25968;&#25454;&#20013;&#65292;&#39044;&#26399;&#30340;&#25913;&#36827;&#24182;&#19981;&#24635;&#26159;&#23384;&#22312;&#12290;&#25105;&#20204;&#35748;&#20026;&#32463;&#36807;&#20462;&#35746;&#30340;ct-SNE&#36739;&#21407;&#22987;&#30340;&#31639;&#27861;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional t-SNE (ct-SNE) is a recent extension to t-SNE that allows removal of known cluster information from the embedding, to obtain a visualization revealing structure beyond label information. This is useful, for example, when one wants to factor out unwanted differences between a set of classes. We show that ct-SNE fails in many realistic settings, namely if the data is well clustered over the labels in the original high-dimensional space. We introduce a revised method by conditioning the high-dimensional similarities instead of the low-dimensional similarities and storing within- and across-label nearest neighbors separately. This also enables the use of recently proposed speedups for t-SNE, improving the scalability. From experiments on synthetic data, we find that our proposed method resolves the considered problems and improves the embedding quality. On real data containing batch effects, the expected improvement is not always there. We argue revised ct-SNE is preferable ove
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#27969;&#27169;&#22411;&#8212;&#8212;&#20027;&#35201;&#27969;&#65288;PF&#65289;&#65292;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#29305;&#24449;&#20998;&#35299;&#30340;&#20381;&#36182;&#65292;&#25429;&#25417;&#21040;&#20102;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#21457;&#25955;&#21644;&#25391;&#33633;&#34892;&#20026;&#12289;&#36867;&#36920;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#38797;&#28857;&#30340;&#36830;&#32493;&#24615;&#27969;&#65292;&#24182;&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#12290;&#36890;&#36807;&#23545;&#19981;&#31283;&#23450;&#24615;&#30340;&#26032;&#29702;&#35299;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#29575;&#36866;&#24212;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#27979;&#35797;&#38598;&#35780;&#20272;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2302.01952</link><description>&lt;p&gt;
&#20851;&#20110;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#21644;&#28145;&#24230;&#23398;&#20064;&#19981;&#31283;&#23450;&#24615;&#30340;&#36830;&#32493;&#26102;&#38388;&#27169;&#22411;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On a continuous time model of gradient descent dynamics and instability in deep learning. (arXiv:2302.01952v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01952
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#27969;&#27169;&#22411;&#8212;&#8212;&#20027;&#35201;&#27969;&#65288;PF&#65289;&#65292;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#29305;&#24449;&#20998;&#35299;&#30340;&#20381;&#36182;&#65292;&#25429;&#25417;&#21040;&#20102;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#21457;&#25955;&#21644;&#25391;&#33633;&#34892;&#20026;&#12289;&#36867;&#36920;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#38797;&#28857;&#30340;&#36830;&#32493;&#24615;&#27969;&#65292;&#24182;&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#12290;&#36890;&#36807;&#23545;&#19981;&#31283;&#23450;&#24615;&#30340;&#26032;&#29702;&#35299;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#29575;&#36866;&#24212;&#26041;&#27861;&#65292;&#21487;&#20197;&#25511;&#21046;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#27979;&#35797;&#38598;&#35780;&#20272;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#25104;&#21151;&#30340;&#31192;&#35776;&#22312;&#20110;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#30340;&#32467;&#21512;&#12290;&#28982;&#32780;&#65292;&#29702;&#35299;&#26799;&#24230;&#19979;&#38477;&#30340;&#34892;&#20026;&#65292;&#29305;&#21035;&#26159;&#20854;&#19981;&#31283;&#23450;&#24615;&#65292;&#33853;&#21518;&#20110;&#20854;&#32463;&#39564;&#25104;&#21151;&#12290;&#20026;&#20102;&#22686;&#21152;&#30740;&#31350;&#26799;&#24230;&#19979;&#38477;&#30340;&#29702;&#35770;&#24037;&#20855;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20027;&#35201;&#27969;&#65288;PF&#65289;&#65292;&#19968;&#31181;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;PF&#26159;&#21807;&#19968;&#25429;&#25417;&#21040;&#26799;&#24230;&#19979;&#38477;&#30340;&#21457;&#25955;&#21644;&#25391;&#33633;&#34892;&#20026;&#65292;&#21253;&#25324;&#36867;&#36920;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#38797;&#28857;&#30340;&#36830;&#32493;&#24615;&#27969;&#12290;&#36890;&#36807;&#20854;&#23545;&#20110;Hessian&#29305;&#24449;&#20998;&#35299;&#30340;&#20381;&#36182;&#65292;PF&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#12290;&#36890;&#36807;&#23545;&#19981;&#31283;&#23450;&#24615;&#30340;&#26032;&#29702;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#29575;&#36866;&#24212;&#26041;&#27861;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#25511;&#21046;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#27979;&#35797;&#38598;&#35780;&#20272;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26799;&#24230;&#20248;&#21270;&#26041;&#27861;SAM&#65292;&#21457;&#29616;&#22312;&#20984;&#20108;&#27425;&#30446;&#26631;&#20013;&#23427;&#20250;&#22312;&#26368;&#23567;&#20540;&#20004;&#20391;&#26469;&#22238;&#25391;&#33633;&#65292;&#20294;&#22312;&#38750;&#20108;&#27425;&#24773;&#20917;&#20013;&#20174;&#20809;&#35889;&#33539;&#25968;&#30340;&#35282;&#24230;&#25191;&#34892;&#26799;&#24230;&#19979;&#38477;&#65292;&#26356;&#26032;&#26041;&#24335;&#34987;&#35748;&#20026;&#26159;Hessian&#30697;&#38453;&#22312;&#39046;&#20808;&#29305;&#24449;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#23548;&#25968;&#65292;&#40723;&#21169;&#28418;&#31227;&#21521;&#26356;&#23485;&#30340;&#26497;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2210.01513</link><description>&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#30340;&#21160;&#24577;&#65306;&#20174;&#23777;&#35895;&#21453;&#24377;&#21040;&#28418;&#21521;&#23485;&#26497;&#23567;&#20540;
&lt;/p&gt;
&lt;p&gt;
The Dynamics of Sharpness-Aware Minimization: Bouncing Across Ravines and Drifting Towards Wide Minima. (arXiv:2210.01513v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26799;&#24230;&#20248;&#21270;&#26041;&#27861;SAM&#65292;&#21457;&#29616;&#22312;&#20984;&#20108;&#27425;&#30446;&#26631;&#20013;&#23427;&#20250;&#22312;&#26368;&#23567;&#20540;&#20004;&#20391;&#26469;&#22238;&#25391;&#33633;&#65292;&#20294;&#22312;&#38750;&#20108;&#27425;&#24773;&#20917;&#20013;&#20174;&#20809;&#35889;&#33539;&#25968;&#30340;&#35282;&#24230;&#25191;&#34892;&#26799;&#24230;&#19979;&#38477;&#65292;&#26356;&#26032;&#26041;&#24335;&#34987;&#35748;&#20026;&#26159;Hessian&#30697;&#38453;&#22312;&#39046;&#20808;&#29305;&#24449;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#23548;&#25968;&#65292;&#40723;&#21169;&#28418;&#31227;&#21521;&#26356;&#23485;&#30340;&#26497;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#21517;&#20026;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#65288;SAM&#65289;&#30340;&#26799;&#24230;&#20248;&#21270;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#21644;&#35821;&#35328;&#39044;&#27979;&#38382;&#39064;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;SAM&#24212;&#29992;&#20110;&#20984;&#20108;&#27425;&#30446;&#26631;&#26102;&#65292;&#38024;&#23545;&#22823;&#22810;&#25968;&#38543;&#26426;&#21021;&#22987;&#21270;&#65292;&#23427;&#20250;&#25910;&#25947;&#20110;&#22312;&#27839;&#30528;&#20027;&#26354;&#29575;&#26368;&#22823;&#26041;&#21521;&#30340;&#26368;&#23567;&#20540;&#20004;&#20391;&#26469;&#22238;&#25391;&#33633;&#30340;&#24490;&#29615;&#65292;&#24182;&#32473;&#20986;&#20102;&#25910;&#25947;&#29575;&#30340;&#30028;&#38480;&#12290;&#22312;&#38750;&#20108;&#27425;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#34920;&#26126;&#36825;&#31181;&#25391;&#33633;&#23454;&#36136;&#19978;&#26159;&#22312;Hessian&#30697;&#38453;&#30340;&#20809;&#35889;&#33539;&#25968;&#19978;&#20197;&#26356;&#23567;&#30340;&#27493;&#38271;&#25191;&#34892;&#26799;&#24230;&#19979;&#38477;&#65292;SAM&#30340;&#26356;&#26032;&#21487;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#19977;&#38454;&#23548;&#25968; - &#21363;Hessian&#30697;&#38453;&#22312;&#39046;&#20808;&#30340;&#29305;&#24449;&#21521;&#37327;&#26041;&#21521;&#19978;&#30340;&#23548;&#25968;&#65292;&#23427;&#40723;&#21169;&#26397;&#30528;&#26356;&#23485;&#30340;&#26497;&#23567;&#20540;&#28418;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider Sharpness-Aware Minimization (SAM), a gradient-based optimization method for deep networks that has exhibited performance improvements on image and language prediction problems. We show that when SAM is applied with a convex quadratic objective, for most random initializations it converges to a cycle that oscillates between either side of the minimum in the direction with the largest curvature, and we provide bounds on the rate of convergence.  In the non-quadratic case, we show that such oscillations effectively perform gradient descent, with a smaller step-size, on the spectral norm of the Hessian. In such cases, SAM's update may be regarded as a third derivative -the derivative of the Hessian in the leading eigenvector direction -- that encourages drift toward wider minima.
&lt;/p&gt;</description></item><item><title>&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#20998;&#26512;&#19981;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#29992;&#20840;&#25209;&#27425;&#25110;&#22823;&#25209;&#27425;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#65292;Cohen&#31561;&#20154;(2021)&#21457;&#29616;&#30340;&#26799;&#24230;&#19979;&#38477;&#36793;&#32536;&#31283;&#23450;&#24615;&#29616;&#35937;&#34920;&#26126;&#65292;&#24403;&#38160;&#24230;&#36798;&#21040;&#19981;&#31283;&#23450;&#24615;&#25130;&#27490;&#20540;$2/\eta$&#26102;&#65292;&#36845;&#20195;&#20855;&#26377;&#33258;&#31283;&#23450;&#24615;&#65292;&#24182;&#34920;&#29616;&#20986;&#38544;&#24335;&#20559;&#21521;&#31283;&#23450;&#36793;&#32536;&#35299;&#30340;&#20559;&#24046;&#65292;&#36825;&#31181;&#29616;&#35937;&#36890;&#36807;&#25429;&#33719;&#20108;&#38454;&#21644;&#19977;&#38454;&#23548;&#25968;&#30340;&#27604;&#20363;&#31995;&#25968;&#24471;&#21040;&#20102;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2209.15594</link><description>&lt;p&gt;
&#33258;&#31283;&#23450;&#24615;&#65306;&#26799;&#24230;&#19979;&#38477;&#22312;&#31283;&#23450;&#36793;&#32536;&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Self-Stabilization: The Implicit Bias of Gradient Descent at the Edge of Stability. (arXiv:2209.15594v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15594
&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#20998;&#26512;&#19981;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#29992;&#20840;&#25209;&#27425;&#25110;&#22823;&#25209;&#27425;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#65292;Cohen&#31561;&#20154;(2021)&#21457;&#29616;&#30340;&#26799;&#24230;&#19979;&#38477;&#36793;&#32536;&#31283;&#23450;&#24615;&#29616;&#35937;&#34920;&#26126;&#65292;&#24403;&#38160;&#24230;&#36798;&#21040;&#19981;&#31283;&#23450;&#24615;&#25130;&#27490;&#20540;$2/\eta$&#26102;&#65292;&#36845;&#20195;&#20855;&#26377;&#33258;&#31283;&#23450;&#24615;&#65292;&#24182;&#34920;&#29616;&#20986;&#38544;&#24335;&#20559;&#21521;&#31283;&#23450;&#36793;&#32536;&#35299;&#30340;&#20559;&#24046;&#65292;&#36825;&#31181;&#29616;&#35937;&#36890;&#36807;&#25429;&#33719;&#20108;&#38454;&#21644;&#19977;&#38454;&#23548;&#25968;&#30340;&#27604;&#20363;&#31995;&#25968;&#24471;&#21040;&#20102;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;Hessian&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65292;&#20063;&#31216;&#20026;&#38160;&#24230;$S(\theta)$&#65292;&#34987;$2/\eta$&#38480;&#21046;&#26102;&#65292;&#35757;&#32451;&#26159;&#8220;&#31283;&#23450;&#30340;&#8221;&#65292;&#35757;&#32451;&#25439;&#22833;&#21333;&#35843;&#19979;&#38477;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#24403;&#29992;&#20840;&#25209;&#37327;&#25110;&#22823;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#36825;&#31181;&#20551;&#35774;&#19981;&#25104;&#31435;&#12290;&#26368;&#36817;&#65292;Cohen&#31561;&#20154;(2021)&#35266;&#23519;&#21040;&#20102;&#20004;&#20010;&#37325;&#35201;&#29616;&#35937;&#12290;&#31532;&#19968;&#20010;&#29616;&#35937;&#34987;&#31216;&#20026;&#28176;&#36827;&#38160;&#21270;&#65292;&#22312;&#35757;&#32451;&#26399;&#38388;&#38160;&#24230;&#31283;&#27493;&#22686;&#21152;&#65292;&#30452;&#21040;&#36798;&#21040;&#19981;&#31283;&#23450;&#24615;&#25130;&#27490;&#20540;$2/\eta$&#12290;&#31532;&#20108;&#20010;&#29616;&#35937;&#34987;&#31216;&#20026;&#31283;&#23450;&#36793;&#32536;&#65292;&#22312;&#21097;&#20313;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#38160;&#24230;&#20572;&#30041;&#22312;$2/\eta$&#65292;&#32780;&#25439;&#22833;&#21017;&#25345;&#32493;&#19979;&#38477;&#65292;&#23613;&#31649;&#19981;&#26159;&#21333;&#35843;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#31283;&#23450;&#36793;&#32536;&#22788;&#65292;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#21487;&#20197;&#30001;&#19968;&#20010;&#19977;&#27425;&#27888;&#21202;&#23637;&#24320;&#24335;&#25429;&#33719;:&#24403;&#36845;&#20195;&#22312;Hessian&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#21521;&#37327;&#26041;&#21521;&#19978;&#21457;&#25955;&#26102;&#65292;&#38160;&#24230;&#21576;&#20108;&#27425;&#22686;&#38271;&#65292;&#27604;&#20363;&#31995;&#25968;&#30001;&#25439;&#22833;&#30340;&#20108;&#38454;&#21644;&#19977;&#38454;&#23548;&#25968;&#20915;&#23450;&#12290;&#24403;&#38160;&#24230;&#31934;&#30830;&#20026;$2/\eta$&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#36845;&#20195;&#30340;&#33258;&#31283;&#23450;&#24615;&#21487;&#20197;&#27704;&#20037;&#22320;&#20445;&#25345;&#22312;&#31283;&#23450;&#36793;&#32536;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#33258;&#31283;&#23450;&#29616;&#35937;&#20351;&#26799;&#24230;&#19979;&#38477;&#20855;&#26377;&#38544;&#24335;&#20559;&#21521;&#31283;&#23450;&#36793;&#32536;&#35299;&#30340;&#20559;&#24046;&#65292;&#32780;&#31283;&#23450;&#36793;&#32536;&#26159;&#25439;&#22833;&#26126;&#26174;&#20302;&#20110;&#31283;&#23450;&#21306;&#22495;&#30340;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional analyses of gradient descent show that when the largest eigenvalue of the Hessian, also known as the sharpness $S(\theta)$, is bounded by $2/\eta$, training is "stable" and the training loss decreases monotonically. Recent works, however, have observed that this assumption does not hold when training modern neural networks with full batch or large batch gradient descent. Most recently, Cohen et al. (2021) observed two important phenomena. The first, dubbed progressive sharpening, is that the sharpness steadily increases throughout training until it reaches the instability cutoff $2/\eta$. The second, dubbed edge of stability, is that the sharpness hovers at $2/\eta$ for the remainder of training while the loss continues decreasing, albeit non-monotonically. We demonstrate that, far from being chaotic, the dynamics of gradient descent at the edge of stability can be captured by a cubic Taylor expansion: as the iterates diverge in direction of the top eigenvector of the Hessi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35299;&#32806;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;&#65288;DIET&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36793;&#38469;&#29420;&#31435;&#32479;&#35745;&#37327;&#27979;&#35797;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#22823;&#37327;&#39044;&#27979;&#27169;&#22411;&#30340;&#25311;&#21512;&#21644;&#30456;&#20114;&#20316;&#29992;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#25152;&#23548;&#33268;&#30340;&#25439;&#22833;&#21151;&#29575;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2208.08579</link><description>&lt;p&gt;
DIET: &#21033;&#29992;&#21097;&#20313;&#20449;&#24687;&#30340;&#36793;&#38469;&#30456;&#20851;&#24230;&#37327;&#36827;&#34892;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
DIET: Conditional independence testing with marginal dependence measures of residual information. (arXiv:2208.08579v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35299;&#32806;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;&#65288;DIET&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36793;&#38469;&#29420;&#31435;&#32479;&#35745;&#37327;&#27979;&#35797;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#22823;&#37327;&#39044;&#27979;&#27169;&#22411;&#30340;&#25311;&#21512;&#21644;&#30456;&#20114;&#20316;&#29992;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#25152;&#23548;&#33268;&#30340;&#25439;&#22833;&#21151;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#38543;&#26426;&#21270;&#26816;&#39564;&#65288;CRT&#65289;&#29992;&#20110;&#35780;&#20272;&#21464;&#37327;$x$&#22312;&#24050;&#30693;&#21327;&#21464;&#37327;$z$&#30340;&#24773;&#20917;&#19979;&#23545;&#21478;&#19968;&#20010;&#21464;&#37327;$y$&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;CRT&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#39044;&#27979;&#27169;&#22411;&#30340;&#25311;&#21512;&#65292;&#36825;&#36890;&#24120;&#26159;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#36890;&#24120;&#23558;&#25968;&#25454;&#38598;&#20998;&#25104;&#35757;&#32451;&#21644;&#27979;&#35797;&#37096;&#20998;&#65292;&#25110;&#20381;&#38752;&#30456;&#20114;&#20316;&#29992;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#20250;&#23548;&#33268;&#21151;&#29575;&#25439;&#22833;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#35299;&#32806;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;&#65288;DIET&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#36793;&#38469;&#29420;&#31435;&#32479;&#35745;&#37327;&#27979;&#35797;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#65292;&#36991;&#20813;&#20102;&#36825;&#20004;&#31181;&#38382;&#39064;&#12290;DIET&#27979;&#35797;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#36793;&#38469;&#29420;&#31435;&#24615;&#65306;$F(x \mid z)$&#21644;$F(y \mid z)$&#20854;&#20013;$F(\cdot \mid z)$&#26159;&#26465;&#20214;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#65288;CDF&#65289;&#65292;&#36825;&#20123;&#21464;&#37327;&#34987;&#31216;&#20026;&#8220;&#20449;&#24687;&#27531;&#24046;&#8221;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;DIET&#23454;&#29616;&#26377;&#38480;&#26679;&#26412;&#30340;&#31867;&#22411;1&#38169;&#35823;&#25511;&#21046;&#21644;&#21151;&#29575;&#22823;&#20110;&#31867;&#22411;1&#38169;&#35823;&#29575;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;DIET&#24212;&#29992;&#26102;&#65292;&#25968;&#25454;&#30340;&#20998;&#24067;&#19981;&#38656;&#35201;&#28385;&#36275;&#20219;&#20309;&#29305;&#23450;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional randomization tests (CRTs) assess whether a variable $x$ is predictive of another variable $y$, having observed covariates $z$. CRTs require fitting a large number of predictive models, which is often computationally intractable. Existing solutions to reduce the cost of CRTs typically split the dataset into a train and test portion, or rely on heuristics for interactions, both of which lead to a loss in power. We propose the decoupled independence test (DIET), an algorithm that avoids both of these issues by leveraging marginal independence statistics to test conditional independence relationships. DIET tests the marginal independence of two random variables: $F(x \mid z)$ and $F(y \mid z)$ where $F(\cdot \mid z)$ is a conditional cumulative distribution function (CDF). These variables are termed "information residuals." We give sufficient conditions for DIET to achieve finite sample type-1 error control and power greater than the type-1 error rate. We then prove that when 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#24310;&#36831;&#22870;&#21169;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#20048;&#35266;&#31639;&#27861;&#65292;&#21487;&#23454;&#29616;&#19968;&#20010;&#29420;&#31435;&#20110;&#26102;&#38388;&#30340;&#24809;&#32602;&#20989;&#25968;&#65292;&#38477;&#20302;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#38543;&#30528;&#26102;&#38388;&#22686;&#38271;&#32780;&#22686;&#21152;&#30340;&#24809;&#32602;&#20989;&#25968;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2207.10786</link><description>&lt;p&gt;
&#24310;&#36831;&#21453;&#39304;&#22312;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#30740;&#31350;&#20877;&#35775;
&lt;/p&gt;
&lt;p&gt;
Delayed Feedback in Generalised Linear Bandits Revisited. (arXiv:2207.10786v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.10786
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#24310;&#36831;&#22870;&#21169;&#29616;&#35937;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#20048;&#35266;&#31639;&#27861;&#65292;&#21487;&#23454;&#29616;&#19968;&#20010;&#29420;&#31435;&#20110;&#26102;&#38388;&#30340;&#24809;&#32602;&#20989;&#25968;&#65292;&#38477;&#20302;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#38543;&#30528;&#26102;&#38388;&#22686;&#38271;&#32780;&#22686;&#21152;&#30340;&#24809;&#32602;&#20989;&#25968;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#22870;&#21169;&#20960;&#20046;&#24635;&#26159;&#34987;&#24310;&#36831;&#65292;&#23548;&#33268;&#35201;&#27714;&#21363;&#26102;&#22870;&#21169;&#30340;&#27169;&#22411;&#38590;&#20197;&#24212;&#29992;&#12290;&#26412;&#25991;&#23558;&#30740;&#31350;&#22312;&#24191;&#20041;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24310;&#36831;&#22870;&#21169;&#30340;&#29616;&#35937;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#20048;&#35266;&#31639;&#27861;&#36866;&#24212;&#24310;&#36831;&#21453;&#39304;&#39046;&#22495;&#33021;&#22815;&#26377;&#19968;&#20010;&#19982;&#26102;&#38388;&#26080;&#20851;&#30340;&#24809;&#32602;&#20989;&#25968;&#12290;&#36825;&#27604;&#29616;&#26377;&#30340;&#24037;&#20316;&#26174;&#33879;&#30340;&#25552;&#39640;&#20102;&#65292;&#22240;&#20026;&#26368;&#20339;&#30340;&#24050;&#30693;&#30340;&#24809;&#32602;&#20989;&#25968;&#30340;&#30028;&#38480;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic generalised linear bandit is a well-understood model for sequential decision-making problems, with many algorithms achieving near-optimal regret guarantees under immediate feedback. However, the stringent requirement for immediate rewards is unmet in many real-world applications where the reward is almost always delayed. We study the phenomenon of delayed rewards in generalised linear bandits in a theoretical manner. We show that a natural adaptation of an optimistic algorithm to the delayed feedback achieves a regret bound where the penalty for the delays is independent of the horizon. This result significantly improves upon existing work, where the best known regret bound has the delay penalty increasing with the horizon. We verify our theoretical results through experiments on simulated data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#38024;&#23545;&#20855;&#26377;&#23616;&#37096;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#21152;&#36895;&#19968;&#38454;&#26041;&#27861;&#65292;&#20998;&#21035;&#25552;&#20986;&#20102;&#26080;&#32422;&#26463;&#20984;&#20248;&#21270;&#30340;&#21152;&#36895;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;(APG)&#20197;&#21450;&#32422;&#26463;&#20984;&#20248;&#21270;&#30340;&#19968;&#38454;&#36817;&#31471;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#20123;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#22320;&#23547;&#25214;&#20986;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2206.01209</link><description>&lt;p&gt;
&#20855;&#26377;&#23616;&#37096;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#20984;&#20248;&#21270;&#30340;&#21152;&#36895;&#19968;&#38454;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accelerated first-order methods for convex optimization with locally Lipschitz continuous gradient. (arXiv:2206.01209v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#38024;&#23545;&#20855;&#26377;&#23616;&#37096;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#21152;&#36895;&#19968;&#38454;&#26041;&#27861;&#65292;&#20998;&#21035;&#25552;&#20986;&#20102;&#26080;&#32422;&#26463;&#20984;&#20248;&#21270;&#30340;&#21152;&#36895;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;(APG)&#20197;&#21450;&#32422;&#26463;&#20984;&#20248;&#21270;&#30340;&#19968;&#38454;&#36817;&#31471;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#20123;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#22320;&#23547;&#25214;&#20986;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#23616;&#37096;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#21152;&#36895;&#30340;&#19968;&#38454;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#20855;&#26377;LLCG&#30340;&#26080;&#32422;&#26463;&#20984;&#20248;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#21152;&#36895;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;(APG)&#26469;&#35299;&#20915;&#23427;&#12290;&#25152;&#25552;&#20986;&#30340;APG&#26041;&#27861;&#20855;&#26377;&#21487;&#39564;&#35777;&#30340;&#32456;&#27490;&#20934;&#21017;&#65292;&#24182;&#19988;&#22312;&#23547;&#25214;&#26080;&#32422;&#26463;&#20984;&#20248;&#21270;&#21644;&#24378;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#949;-&#27531;&#24046;&#35299;&#26102;&#65292;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;${\cal O}(\varepsilon^{-1/2}\log \varepsilon^{-1})$&#21644;${\cal O}(\log \varepsilon^{-1})$&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;LLCG&#30340;&#32422;&#26463;&#20984;&#20248;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#19968;&#38454;&#36817;&#31471;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#26469;&#35299;&#20915;&#23427;&#65292;&#36890;&#36807;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;APG&#26041;&#27861;&#24212;&#29992;&#20110;&#36817;&#20284;&#27714;&#35299;&#19968;&#31995;&#21015;&#36817;&#31471;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#23376;&#38382;&#39064;&#12290;&#30001;&#27492;&#24471;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#21487;&#39564;&#35777;&#30340;&#32456;&#27490;&#20934;&#21017;&#65292;&#24182;&#19988;&#20855;&#26377;&#24555;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we develop accelerated first-order methods for convex optimization with locally Lipschitz continuous gradient (LLCG), which is beyond the well-studied class of convex optimization with Lipschitz continuous gradient. In particular, we first consider unconstrained convex optimization with LLCG and propose accelerated proximal gradient (APG) methods for solving it. The proposed APG methods are equipped with a verifiable termination criterion and enjoy an operation complexity of ${\cal O}(\varepsilon^{-1/2}\log \varepsilon^{-1})$ and ${\cal O}(\log \varepsilon^{-1})$ for finding an $\varepsilon$-residual solution of an unconstrained convex and strongly convex optimization problem, respectively. We then consider constrained convex optimization with LLCG and propose an first-order proximal augmented Lagrangian method for solving it by applying one of our proposed APG methods to approximately solve a sequence of proximal augmented Lagrangian subproblems. The resulting method is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#21517;&#20026;NN-GPR&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#36827;&#34892;&#22810;&#20010;&#27668;&#20505;&#27169;&#22411;&#30340;&#38598;&#25104;&#20998;&#26512;&#65292;&#24182;&#22312;&#34920;&#38754;&#28201;&#24230;&#21644;&#38477;&#27700;&#39044;&#27979;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#33021;&#22815;&#20445;&#30041;&#22810;&#20010;&#23610;&#24230;&#30340;&#22320;&#29702;&#31354;&#38388;&#20449;&#21495;&#21644;&#25429;&#25417;&#24180;&#38469;&#21464;&#21270;&#65292;&#29305;&#21035;&#22312;&#39640;&#21464;&#24322;&#21306;&#22495;&#20855;&#26377;&#25913;&#36827;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#33021;&#12290;</title><link>http://arxiv.org/abs/2202.04152</link><description>&lt;p&gt;
&#37319;&#29992;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#30340;&#22810;&#27169;&#22411;&#38598;&#25104;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Multi-model Ensemble Analysis with Neural Network Gaussian Processes. (arXiv:2202.04152v4 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04152
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#21517;&#20026;NN-GPR&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#22320;&#36827;&#34892;&#22810;&#20010;&#27668;&#20505;&#27169;&#22411;&#30340;&#38598;&#25104;&#20998;&#26512;&#65292;&#24182;&#22312;&#34920;&#38754;&#28201;&#24230;&#21644;&#38477;&#27700;&#39044;&#27979;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#33021;&#22815;&#20445;&#30041;&#22810;&#20010;&#23610;&#24230;&#30340;&#22320;&#29702;&#31354;&#38388;&#20449;&#21495;&#21644;&#25429;&#25417;&#24180;&#38469;&#21464;&#21270;&#65292;&#29305;&#21035;&#22312;&#39640;&#21464;&#24322;&#21306;&#22495;&#20855;&#26377;&#25913;&#36827;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#22411;&#38598;&#25104;&#20998;&#26512;&#23558;&#22810;&#20010;&#27668;&#20505;&#27169;&#22411;&#30340;&#20449;&#24687;&#38598;&#25104;&#21040;&#19968;&#20010;&#32479;&#19968;&#30340;&#39044;&#27979;&#20013;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#27169;&#22411;&#24179;&#22343;&#30340;&#38598;&#25104;&#26041;&#27861;&#21487;&#33021;&#20250;&#31232;&#37322;&#32454;&#31890;&#24230;&#30340;&#31354;&#38388;&#20449;&#24687;&#65292;&#24182;&#22312;&#37325;&#26032;&#32553;&#25918;&#20302;&#20998;&#36776;&#29575;&#27668;&#20505;&#27169;&#22411;&#26102;&#24341;&#20837;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;NN-GPR&#65292;&#20351;&#29992;&#20855;&#26377;&#26080;&#38480;&#23485;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#12290;NN-GPR&#23545;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#31995;&#19981;&#38656;&#35201;&#20219;&#20309;&#20551;&#35774;&#65292;&#19981;&#38656;&#35201;&#36890;&#36807;&#25554;&#20540;&#21040;&#20844;&#20849;&#32593;&#26684;&#26469;&#32479;&#19968;&#65292;&#19981;&#38656;&#35201;&#32771;&#34385;&#24179;&#31283;&#24615;&#20551;&#35774;&#65292;&#24182;&#19988;&#20854;&#39044;&#27979;&#31639;&#27861;&#33258;&#21160;&#36827;&#34892;&#38477;&#23610;&#24230;&#22788;&#29702;&#12290;&#27169;&#22411;&#23454;&#39564;&#34920;&#26126;&#65292;NN-GPR&#22312;&#20445;&#30041;&#22810;&#20010;&#23610;&#24230;&#30340;&#22320;&#29702;&#31354;&#38388;&#20449;&#21495;&#21644;&#25429;&#25417;&#24180;&#38469;&#21464;&#21270;&#26041;&#38754;&#22312;&#34920;&#38754;&#28201;&#24230;&#21644;&#38477;&#27700;&#39044;&#27979;&#26041;&#38754;&#21487;&#20197;&#38750;&#24120;&#29087;&#32451;&#12290;&#25105;&#20204;&#30340;&#39044;&#27979;&#29305;&#21035;&#26174;&#31034;&#22312;&#39640;&#21464;&#24322;&#21306;&#22495;&#20855;&#26377;&#25913;&#36827;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#33021;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20415;&#23452;&#22320;&#35780;&#20272;&#27668;&#20505;&#21464;&#21270;&#23545;&#29983;&#24577;&#31995;&#32479;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-model ensemble analysis integrates information from multiple climate models into a unified projection. However, existing integration approaches based on model averaging can dilute fine-scale spatial information and incur bias from rescaling low-resolution climate models. We propose a statistical approach, called NN-GPR, using Gaussian process regression (GPR) with an infinitely wide deep neural network based covariance function. NN-GPR requires no assumptions about the relationships between models, no interpolation to a common grid, no stationarity assumptions, and automatically downscales as part of its prediction algorithm. Model experiments show that NN-GPR can be highly skillful at surface temperature and precipitation forecasting by preserving geospatial signals at multiple scales and capturing inter-annual variability. Our projections particularly show improved accuracy and uncertainty quantification skill in regions of high variability, which allows us to cheaply assess ta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#24314;&#31435;&#20102;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#19982;&#38750;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#32852;&#31995;&#65292;&#22312;&#38271;&#26102;&#38388;&#26497;&#38480;&#19979;&#25512;&#23548;&#20986;&#20102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#27169;&#22411;&#20013;&#26368;&#20248;&#31574;&#30053;&#21644;&#26368;&#20248;&#21160;&#24577;&#30340;&#31934;&#30830;&#35299;&#26512;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#26512;&#21644;&#35745;&#31639;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2106.03931</link><description>&lt;p&gt;
&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#30340;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Entropy Regularized Reinforcement Learning Using Large Deviation Theory. (arXiv:2106.03931v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03931
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#24314;&#31435;&#20102;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#19982;&#38750;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#32852;&#31995;&#65292;&#22312;&#38271;&#26102;&#38388;&#26497;&#38480;&#19979;&#25512;&#23548;&#20986;&#20102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#27169;&#22411;&#20013;&#26368;&#20248;&#31574;&#30053;&#21644;&#26368;&#20248;&#21160;&#24577;&#30340;&#31934;&#30830;&#35299;&#26512;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#20998;&#26512;&#21644;&#35745;&#31639;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#24212;&#29992;&#20110;&#29289;&#29702;&#23398;&#20013;&#30340;&#22797;&#26434;&#20248;&#21270;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#29289;&#29702;&#23398;&#20013;&#30340;&#27010;&#24565;&#20063;&#20026;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#22914;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#38024;&#23545;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#20013;&#20248;&#21270;&#30340;&#35299;&#26512;&#35299;&#30446;&#21069;&#26159;&#19968;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#19982;&#38750;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#32852;&#31995;&#65292;&#37325;&#28857;&#20851;&#27880;&#22312;&#32597;&#35265;&#20107;&#20214;&#26465;&#20214;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#12290;&#22312;&#38271;&#26102;&#38388;&#26497;&#38480;&#19979;&#65292;&#25105;&#20204;&#24212;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#30340;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#27169;&#22411;&#20013;&#26368;&#20248;&#31574;&#30053;&#21644;&#26368;&#20248;&#21160;&#24577;&#30340;&#31934;&#30830;&#35299;&#26512;&#32467;&#26524;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#29109;&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#30340;&#20998;&#26512;&#21644;&#35745;&#31639;&#26694;&#26550;&#65292;&#32463;&#36807;&#27169;&#25311;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) is an important field of research in machine learning that is increasingly being applied to complex optimization problems in physics. In parallel, concepts from physics have contributed to important advances in RL with developments such as entropy-regularized RL. While these developments have led to advances in both fields, obtaining analytical solutions for optimization in entropy-regularized RL is currently an open problem. In this paper, we establish a mapping between entropy-regularized RL and research in non-equilibrium statistical mechanics focusing on Markovian processes conditioned on rare events. In the long-time limit, we apply approaches from large deviation theory to derive exact analytical results for the optimal policy and optimal dynamics in Markov Decision Process (MDP) models of reinforcement learning. The results obtained lead to a novel analytical and computational framework for entropy-regularized RL which is validated by simulations. The
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MCRP&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#35745;&#31639;&#29305;&#24449;&#30456;&#20851;&#24615;&#20998;&#24067;&#65292;&#20197;&#35780;&#20272;&#29305;&#24449;&#30456;&#20851;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#24863;&#30693;&#21644;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2008.01468</link><description>&lt;p&gt;
&#29305;&#24449;&#30456;&#20851;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#33945;&#29305;&#21345;&#32599;Dropout&#37319;&#26679;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Feature Relevance Uncertainty: A Monte Carlo Dropout Sampling Approach. (arXiv:2008.01468v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.01468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;MCRP&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#35745;&#31639;&#29305;&#24449;&#30456;&#20851;&#24615;&#20998;&#24067;&#65292;&#20197;&#35780;&#20272;&#29305;&#24449;&#30456;&#20851;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#24863;&#30693;&#21644;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#20915;&#31574;&#26159;&#23454;&#29616;&#26234;&#33021;&#31995;&#32479;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#65292;&#28982;&#32780;&#36825;&#20123;&#31995;&#32479;&#19981;&#36879;&#26126;&#30340;&#20915;&#31574;&#36807;&#31243;&#22312;&#38656;&#35201;&#35299;&#37322;&#24615;&#30340;&#24773;&#20917;&#19979;&#26159;&#19981;&#21033;&#30340;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#65292;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#36817;&#24180;&#26469;&#24341;&#20837;&#20102;&#35768;&#22810;&#29305;&#24449;&#35299;&#37322;&#25216;&#26415;&#65292;&#24182;&#25104;&#20026;&#39564;&#35777;&#20854;&#25512;&#29702;&#33021;&#21147;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#24182;&#19981;&#20801;&#35768;&#20851;&#20110;&#29305;&#24449;&#30456;&#20851;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#38472;&#36848;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#30340;&#29305;&#24449;&#30456;&#20851;&#24615;&#20998;&#24067;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#21363;Monte Carlo Relevance Propagation (MCRP)&#29992;&#20110;&#29305;&#24449;&#30456;&#20851;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20197;&#35745;&#31639;&#29305;&#24449;&#30456;&#20851;&#24615;&#19981;&#30830;&#23450;&#24615;&#20998;&#25968;&#65292;&#20174;&#32780;&#28145;&#20837;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#24863;&#30693;&#21644;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding decisions made by neural networks is key for the deployment of intelligent systems in real world applications. However, the opaque decision making process of these systems is a disadvantage where interpretability is essential. Many feature-based explanation techniques have been introduced over the last few years in the field of machine learning to better understand decisions made by neural networks and have become an important component to verify their reasoning capabilities. However, existing methods do not allow statements to be made about the uncertainty regarding a feature's relevance for the prediction. In this paper, we introduce Monte Carlo Relevance Propagation (MCRP) for feature relevance uncertainty estimation. A simple but powerful method based on Monte Carlo estimation of the feature relevance distribution to compute feature relevance uncertainty scores that allow a deeper understanding of a neural network's perception and reasoning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#36827;&#34892;iEEG&#30340;&#30315;&#30187;&#21457;&#20316;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#36991;&#20813;&#25552;&#21462;&#25163;&#24037;&#29305;&#24449;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#26222;&#36941;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/1811.00915</link><description>&lt;p&gt;
&#29992;&#20110;&#30315;&#30187;&#21457;&#20316;&#39044;&#27979;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Convolutional Neural Networks for Epileptic Seizure Prediction. (arXiv:1811.00915v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1811.00915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#36827;&#34892;iEEG&#30340;&#30315;&#30187;&#21457;&#20316;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#36991;&#20813;&#25552;&#21462;&#25163;&#24037;&#29305;&#24449;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#26222;&#36941;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30315;&#30187;&#26159;&#26368;&#24120;&#35265;&#30340;&#31070;&#32463;&#31995;&#32479;&#30142;&#30149;&#65292;&#20934;&#30830;&#39044;&#27979;&#30315;&#30187;&#21457;&#20316;&#23558;&#26377;&#21161;&#20110;&#20811;&#26381;&#24739;&#32773;&#30340;&#19981;&#30830;&#23450;&#21644;&#26080;&#21161;&#24863;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39045;&#20869;&#33041;&#30005;&#22270;&#65288;iEEG&#65289;&#36827;&#34892;&#30315;&#30187;&#21457;&#20316;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#25299;&#25169;&#32467;&#26500;&#36827;&#34892;&#20449;&#21495;&#29305;&#24449;&#30340;&#30830;&#23450;&#21644;&#39044;ictal&#21644;interictal&#27573;&#30340;&#20108;&#20803;&#20998;&#31867;&#12290;&#25105;&#20204;&#23545;&#26469;&#33258;&#22235;&#21482;&#29399;&#21644;&#19977;&#21517;&#24739;&#32773;&#30340;&#38271;&#26399;&#35760;&#24405;&#36827;&#34892;&#20102;&#19977;&#20010;&#19981;&#21516;&#27169;&#22411;&#30340;&#35780;&#20272;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#20102;&#26041;&#27861;&#30340;&#26222;&#36941;&#36866;&#29992;&#24615;&#12290;&#26412;&#30740;&#31350;&#36824;&#35752;&#35770;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Epilepsy is the most common neurological disorder and an accurate forecast of seizures would help to overcome the patient's uncertainty and helplessness. In this contribution, we present and discuss a novel methodology for the classification of intracranial electroencephalography (iEEG) for seizure prediction. Contrary to previous approaches, we categorically refrain from an extraction of hand-crafted features and use a convolutional neural network (CNN) topology instead for both the determination of suitable signal characteristics and the binary classification of preictal and interictal segments. Three different models have been evaluated on public datasets with long-term recordings from four dogs and three patients. Overall, our findings demonstrate the general applicability. In this work we discuss the strengths and limitations of our methodology.
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;SBM&#27169;&#22411;&#65292;&#21452;&#37325;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;PCABM&#27169;&#22411;&#28155;&#21152;&#20102;&#20851;&#20110;&#33410;&#28857;&#38388;&#20851;&#31995;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;SCWA&#31639;&#27861;&#23545;PCABM&#27169;&#22411;&#36827;&#34892;&#20102;&#39640;&#25928;&#27714;&#35299;&#12290;&#27169;&#25311;&#23454;&#39564;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#34920;&#26126;PCABM&#27169;&#22411;&#20855;&#26377;&#20248;&#24322;&#30340;&#24615;&#33021;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/1807.03469</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#37325;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#22359;&#27169;&#22411;&#29992;&#20110;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Pairwise Covariates-adjusted Block Model for Community Detection. (arXiv:1807.03469v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1807.03469
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;SBM&#27169;&#22411;&#65292;&#21452;&#37325;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;PCABM&#27169;&#22411;&#28155;&#21152;&#20102;&#20851;&#20110;&#33410;&#28857;&#38388;&#20851;&#31995;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;SCWA&#31639;&#27861;&#23545;PCABM&#27169;&#22411;&#36827;&#34892;&#20102;&#39640;&#25928;&#27714;&#35299;&#12290;&#27169;&#25311;&#23454;&#39564;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#34920;&#26126;PCABM&#27169;&#22411;&#20855;&#26377;&#20248;&#24322;&#30340;&#24615;&#33021;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#32593;&#32476;&#30740;&#31350;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#38543;&#26426;&#22359;&#27169;&#22411;(SBM)&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#27169;&#22411;&#65292;&#24050;&#24320;&#21457;&#20986;&#21508;&#31181;&#20272;&#35745;&#26041;&#27861;&#24182;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#31038;&#21306;&#26816;&#27979;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;&#20294;&#26159;&#65292;SBM&#21463;&#21040;&#19968;&#31181;&#20551;&#35774;&#30340;&#38480;&#21046;&#65292;&#21363;&#21516;&#19968;&#31038;&#21306;&#20013;&#30340;&#25152;&#26377;&#33410;&#28857;&#37117;&#26159;&#38543;&#26426;&#31561;&#20215;&#30340;&#65292;&#36825;&#21487;&#33021;&#19981;&#36866;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;(PCABM)&#65292;&#21363;&#23558;&#21452;&#37325;&#21327;&#21464;&#37327;&#20449;&#24687;&#21512;&#24182;&#21040;SBM&#20013;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21327;&#21464;&#37327;&#31995;&#25968;&#21644;&#31038;&#21306;&#20998;&#37197;&#30340;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#20540;&#12290;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#30340;&#31232;&#30095;&#26465;&#20214;&#19979;&#65292;&#21327;&#21464;&#37327;&#31995;&#25968;&#20272;&#35745;&#21644;&#31038;&#21306;&#20998;&#37197;&#22343;&#19968;&#33268;&#12290;&#20171;&#32461;&#20102;&#19968;&#31181;&#24102;&#26377;&#35843;&#25972;&#30340;&#35889;&#32858;&#31867;&#65288;SCWA&#65289;&#65292;&#20197;&#39640;&#25928;&#22320;&#35299;&#20915;PCABM&#38382;&#39064;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;SCWA&#26816;&#27979;&#31038;&#21306;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#33021;&#22815;&#23454;&#29616;&#31934;&#30830;&#30340;&#31038;&#21306;&#24674;&#22797;&#12290;&#25968;&#20540;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#34920;&#26126;PCABM&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the most fundamental problems in network study is community detection. The stochastic block model (SBM) is a widely used model, for which various estimation methods have been developed with their community detection consistency results unveiled. However, the SBM is restricted by the strong assumption that all nodes in the same community are stochastically equivalent, which may not be suitable for practical applications. We introduce a pairwise covariates-adjusted stochastic block model (PCABM), a generalization of SBM that incorporates pairwise covariate information. We study the maximum likelihood estimates of the coefficients for the covariates as well as the community assignments. It is shown that both the coefficient estimates of the covariates and the community assignments are consistent under suitable sparsity conditions. Spectral clustering with adjustment (SCWA) is introduced to efficiently solve PCABM. Under certain conditions, we derive the error bound of community det
&lt;/p&gt;</description></item></channel></rss>