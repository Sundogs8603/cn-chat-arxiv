<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#36870;&#38382;&#39064;&#30340;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#25910;&#25947;&#24615;&#38382;&#39064;&#30340;&#19968;&#33324;&#21270;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36890;&#36807;&#19968;&#31867;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#23454;&#29616;&#21487;&#20197;&#36798;&#21040;&#25910;&#25947;&#65292;&#24182;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#20013;&#23454;&#29616;&#20102;&#23545;&#35745;&#31639;&#26426;&#23618;&#26512;&#25104;&#20687;&#20013;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#22120;&#24615;&#33021;&#30340;&#25552;&#39640;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01052</link><description>&lt;p&gt;
&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#22312;&#36870;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#65306;&#20020;&#30028;&#28857;&#21644;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#30340;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Weakly Convex Regularisers for Inverse Problems: Convergence of Critical Points and Primal-Dual Optimisation
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#36870;&#38382;&#39064;&#30340;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#25910;&#25947;&#24615;&#38382;&#39064;&#30340;&#19968;&#33324;&#21270;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36890;&#36807;&#19968;&#31867;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#23454;&#29616;&#21487;&#20197;&#36798;&#21040;&#25910;&#25947;&#65292;&#24182;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#20013;&#23454;&#29616;&#20102;&#23545;&#35745;&#31639;&#26426;&#23618;&#26512;&#25104;&#20687;&#20013;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#22120;&#24615;&#33021;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#27491;&#21017;&#21270;&#26159;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#26368;&#36817;&#26377;&#24456;&#22810;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#35299;&#20915;&#36825;&#31181;&#27491;&#21017;&#21270;&#25910;&#25947;&#24615;&#30340;&#38382;&#39064;&#19978;&#65292;&#24456;&#23569;&#26377;&#20851;&#20110;&#20020;&#30028;&#28857;&#25910;&#25947;&#24615;&#30340;&#32467;&#26524;&#65292;&#32780;&#38750;&#20840;&#23616;&#26497;&#23567;&#20540;&#28857;&#30340;&#25910;&#25947;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20020;&#30028;&#28857;&#25910;&#25947;&#24615;&#30340;&#19968;&#33324;&#21270;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#26159;&#36890;&#36807;&#19968;&#31867;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#30456;&#20851;&#21464;&#20998;&#38382;&#39064;&#30456;&#20851;&#30340;&#21407;&#22987;-&#23545;&#20598;&#28151;&#21512;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#32473;&#23450;Kurdyka-Lojasiewicz&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#26126;&#20102;O(log(k)/k)&#30340;&#36951;&#20256;&#25910;&#25947;&#36895;&#24230;&#12290;&#26368;&#21518;&#65292;&#23558;&#36825;&#20010;&#29702;&#35770;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36755;&#20837;&#20026;&#24369;&#20984;&#31070;&#32463;&#32593;&#32476;&#65288;IWCNN&#65289;&#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;IWCNN&#21487;&#20197;&#25552;&#39640;&#35745;&#31639;&#26426;&#23618;&#26512;&#25104;&#20687;&#20013;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational regularisation is the primary method for solving inverse problems, and recently there has been considerable work leveraging deeply learned regularisation for enhanced performance. However, few results exist addressing the convergence of such regularisation, particularly within the context of critical points as opposed to global minima. In this paper, we present a generalised formulation of convergent regularisation in terms of critical points, and show that this is achieved by a class of weakly convex regularisers. We prove convergence of the primal-dual hybrid gradient method for the associated variational problem, and, given a Kurdyka-Lojasiewicz condition, an $\mathcal{O}(\log{k}/k)$ ergodic convergence rate. Finally, applying this theory to learned regularisation, we prove universal approximation for input weakly convex neural networks (IWCNN), and show empirically that IWCNNs can lead to improved performance of learned adversarial regularisers for computed tomography (
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#31232;&#30095;&#21407;&#21017;&#65292;&#24314;&#31435;&#20102;&#20004;&#20010;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65292;&#20026;&#32447;&#24615;&#28151;&#21512;&#20989;&#25968;&#21644;&#20998;&#27573;&#32447;&#24615;&#28151;&#21512;&#20989;&#25968;&#35774;&#32622;&#20102;&#22522;&#30784;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.08335</link><description>&lt;p&gt;
&#37096;&#20998;&#21487;&#35266;&#27979;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#31232;&#30095;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Sparsity Principle for Partially Observable Causal Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08335
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#31232;&#30095;&#21407;&#21017;&#65292;&#24314;&#31435;&#20102;&#20004;&#20010;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65292;&#20026;&#32447;&#24615;&#28151;&#21512;&#20989;&#25968;&#21644;&#20998;&#27573;&#32447;&#24615;&#28151;&#21512;&#20989;&#25968;&#35774;&#32622;&#20102;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26088;&#22312;&#20174;&#24863;&#30693;&#25968;&#25454;&#20013;&#35782;&#21035;&#39640;&#23618;&#27425;&#30340;&#22240;&#26524;&#21464;&#37327;&#12290;&#26412;&#25991;&#32771;&#34385;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#65292;&#20854;&#20013;&#27599;&#27425;&#27979;&#37327;&#20165;&#25552;&#20379;&#20851;&#20110;&#28508;&#22312;&#22240;&#26524;&#29366;&#24577;&#23376;&#38598;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20174;&#25968;&#25454;&#38598;&#20013;&#19981;&#37197;&#23545;&#35266;&#23519;&#23398;&#20064;&#65292;&#20854;&#20013;&#23384;&#22312;&#23454;&#20363;&#30456;&#20851;&#30340;&#37096;&#20998;&#21487;&#35266;&#27979;&#27169;&#24335;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#20026;&#35813;&#35774;&#32622;&#24314;&#31435;&#20004;&#20010;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65306;&#19968;&#20010;&#26159;&#20851;&#20110;&#32447;&#24615;&#28151;&#21512;&#20989;&#25968;&#30340;&#32467;&#26524;&#65292;&#26080;&#38656;&#23545;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20570;&#21442;&#25968;&#20551;&#35774;&#65292;&#21478;&#19968;&#20010;&#26159;&#23545;&#20855;&#26377;&#39640;&#26031;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#30340;&#20998;&#27573;&#32447;&#24615;&#28151;&#21512;&#20989;&#25968;&#30340;&#32467;&#26524;&#12290;&#22522;&#20110;&#36825;&#20123;&#35265;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20272;&#35745;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08335v1 Announce Type: cross  Abstract: Causal representation learning aims at identifying high-level causal variables from perceptual data. Most methods assume that all latent causal variables are captured in the high-dimensional observations. We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state. Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents. Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern. Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables. Based on these insights, we propose two methods for estimating the underlying causal variab
&lt;/p&gt;</description></item><item><title>NIFTy.re&#37325;&#26032;&#26500;&#24314;&#20102;NIFTy&#30340;&#24314;&#27169;&#21407;&#21017;&#21644;&#25512;&#26029;&#31574;&#30053;&#65292;&#36890;&#36807;&#22806;&#21253;&#32321;&#37325;&#24037;&#20316;&#32473;JAX&#65292;&#21152;&#36895;&#20102;&#27169;&#22411;&#30340;&#36895;&#24230;&#65292;&#25552;&#21319;&#20102;&#21487;&#32500;&#25252;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#19982;JAX&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#30340;&#20114;&#25805;&#20316;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.16683</link><description>&lt;p&gt;
&#37325;&#26032;&#26500;&#24819;&#25968;&#20540;&#20449;&#24687;&#22330;&#29702;&#35770;&#65288;NIFTy.re&#65289;&#65306;&#39640;&#26031;&#36807;&#31243;&#21644;&#21464;&#20998;&#25512;&#26029;&#24211;
&lt;/p&gt;
&lt;p&gt;
Re-Envisioning Numerical Information Field Theory (NIFTy.re): A Library for Gaussian Processes and Variational Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16683
&lt;/p&gt;
&lt;p&gt;
NIFTy.re&#37325;&#26032;&#26500;&#24314;&#20102;NIFTy&#30340;&#24314;&#27169;&#21407;&#21017;&#21644;&#25512;&#26029;&#31574;&#30053;&#65292;&#36890;&#36807;&#22806;&#21253;&#32321;&#37325;&#24037;&#20316;&#32473;JAX&#65292;&#21152;&#36895;&#20102;&#27169;&#22411;&#30340;&#36895;&#24230;&#65292;&#25552;&#21319;&#20102;&#21487;&#32500;&#25252;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#19982;JAX&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#30340;&#20114;&#25805;&#20316;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#26500;&#24314;&#27169;&#21407;&#21017;&#12289;&#25193;&#23637;&#25512;&#26029;&#31574;&#30053;&#65292;&#20197;&#21450;&#23558;&#22823;&#37096;&#20998;&#32321;&#37325;&#24037;&#20316;&#22806;&#21253;&#32473;JAX&#65292;&#37325;&#26032;&#21152;&#36895;&#32534;&#20889;&#22312;NIFTy&#20013;&#30340;&#27169;&#22411;&#65292;&#22880;&#23450;&#20102;&#26032;&#31867;&#22411;&#25512;&#29702;&#26426;&#21046;&#30340;&#22522;&#30784;&#65292;&#25552;&#39640;&#20102;&#21487;&#32500;&#25252;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;NIFTy&#19982;JAX&#26426;&#22120;&#23398;&#20064;&#29983;&#24577;&#31995;&#32479;&#20043;&#38388;&#30340;&#20114;&#25805;&#20316;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16683v1 Announce Type: cross  Abstract: Imaging is the process of transforming noisy, incomplete data into a space that humans can interpret. NIFTy is a Bayesian framework for imaging and has already successfully been applied to many fields in astrophysics. Previous design decisions held the performance and the development of methods in NIFTy back. We present a rewrite of NIFTy, coined NIFTy.re, which reworks the modeling principle, extends the inference strategies, and outsources much of the heavy lifting to JAX. The rewrite dramatically accelerates models written in NIFTy, lays the foundation for new types of inference machineries, improves maintainability, and enables interoperability between NIFTy and the JAX machine learning ecosystem.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.14090</link><description>&lt;p&gt;
&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Social Environment Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14090
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#21046;&#23450;&#30340;&#25216;&#26415;&#20855;&#26377;&#28508;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#19982;&#24378;&#21270;&#23398;&#20064;&#12289;&#32463;&#27982;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#31038;&#21306;&#30456;&#36830;&#25509;&#12290;&#35813;&#26694;&#26550;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#21253;&#25324;&#23545;&#25919;&#31574;&#30446;&#26631;&#30340;&#25237;&#31080;&#65292;&#24182;&#20026;&#36890;&#36807;AI&#27169;&#25311;&#23545;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#25552;&#20379;&#25351;&#23548;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#24320;&#25918;&#38382;&#39064;&#12290;&#36890;&#36807;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24076;&#26395;&#23454;&#29616;&#21508;&#31181;&#31038;&#20250;&#31119;&#21033;&#30446;&#26631;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#20855;&#36947;&#24503;&#21644;&#36127;&#36131;&#20219;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14090v1 Announce Type: new  Abstract: Artificial Intelligence (AI) holds promise as a technology that can be used to improve government and economic policy-making. This paper proposes a new research agenda towards this end by introducing Social Environment Design, a general framework for the use of AI for automated policy-making that connects with the Reinforcement Learning, EconCS, and Computational Social Choice communities. The framework seeks to capture general economic environments, includes voting on policy objectives, and gives a direction for the systematic analysis of government and economic policy through AI simulation. We highlight key open problems for future research in AI-based policy-making. By solving these challenges, we hope to achieve various social welfare objectives, thereby promoting more ethical and responsible decision making.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22810;&#23618;&#24863;&#30693;&#26426;&#20869;&#31215;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#20316;&#20026;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#33021;&#21147;&#12290;&#24471;&#21040;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#20851;&#31995;&#20989;&#25968;&#36924;&#36817;&#25152;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08856</link><description>&lt;p&gt;
&#20851;&#20110;&#20851;&#31995;&#20989;&#25968;&#21644;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximation of relation functions and attention mechanisms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08856
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22810;&#23618;&#24863;&#30693;&#26426;&#20869;&#31215;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#20316;&#20026;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#33021;&#21147;&#12290;&#24471;&#21040;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#20851;&#31995;&#20989;&#25968;&#36924;&#36817;&#25152;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#26144;&#23556;&#30340;&#20869;&#31215;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#20013;&#34987;&#29992;&#20110;&#24314;&#27169;&#36755;&#20837;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#31215;&#30340;&#36817;&#20284;&#24615;&#36136;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22810;&#23618;&#24863;&#30693;&#26426;&#33258;&#36523;&#30340;&#20869;&#31215;&#26159;&#23545;&#31216;&#27491;&#23450;&#20851;&#31995;&#20989;&#25968;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#12290;&#23545;&#20110;&#38750;&#23545;&#31216;&#20851;&#31995;&#20989;&#25968;&#65292;&#19981;&#21516;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#30340;&#20869;&#31215;&#26159;&#19968;&#20010;&#36890;&#29992;&#36924;&#36817;&#22120;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#37117;&#24471;&#21040;&#20102;&#36798;&#21040;&#32473;&#23450;&#36924;&#36817;&#31934;&#24230;&#25152;&#38656;&#30340;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#30028;&#38480;&#12290;&#23545;&#31216;&#24773;&#20917;&#19979;&#65292;&#20989;&#25968;&#31867;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#26680;&#20989;&#25968;&#65292;&#32780;&#23545;&#31216;&#24773;&#20917;&#19979;&#20989;&#25968;&#31867;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20877;&#29983;&#26680;&#24052;&#25343;&#36203;&#31354;&#38388;&#20013;&#30340;&#26680;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#36825;&#20123;&#36924;&#36817;&#32467;&#26524;&#34987;&#24212;&#29992;&#20110;&#20998;&#26512;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08856v1 Announce Type: new Abstract: Inner products of neural network feature maps arises in a wide variety of machine learning frameworks as a method of modeling relations between inputs. This work studies the approximation properties of inner products of neural networks. It is shown that the inner product of a multi-layer perceptron with itself is a universal approximator for symmetric positive-definite relation functions. In the case of asymmetric relation functions, it is shown that the inner product of two different multi-layer perceptrons is a universal approximator. In both cases, a bound is obtained on the number of neurons required to achieve a given accuracy of approximation. In the symmetric case, the function class can be identified with kernels of reproducing kernel Hilbert spaces, whereas in the asymmetric case the function class can be identified with kernels of reproducing kernel Banach spaces. Finally, these approximation results are applied to analyzing the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35780;&#20272;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#24230;&#20026;$O(1/n)$&#30340;&#19978;&#30028;&#65292;&#20026;&#25105;&#20204;&#23545;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.07025</link><description>&lt;p&gt;
&#22343;&#22330;&#26497;&#38480;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Generalization Error of Graph Neural Networks in the Mean-field Regime
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07025
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#35780;&#20272;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#24230;&#20026;$O(1/n)$&#30340;&#19978;&#30028;&#65292;&#20026;&#25105;&#20204;&#23545;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#21363;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#31867;&#22411;&#65306;&#22270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21644;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#26412;&#30740;&#31350;&#20043;&#21069;&#65292;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#27867;&#21270;&#35823;&#24046;&#30340;&#29616;&#26377;&#30028;&#38480;&#32570;&#20047;&#20449;&#24687;&#65292;&#38480;&#21046;&#20102;&#25105;&#20204;&#23545;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#24615;&#33021;&#30340;&#29702;&#35299;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#26041;&#27861;&#26159;&#22312;&#22343;&#22330;&#26497;&#38480;&#19979;&#25512;&#23548;&#20986;&#19978;&#30028;&#65292;&#20197;&#35780;&#20272;&#36825;&#20123;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20197;$O(1/n)$&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#65292;&#20854;&#20013;$n$&#26159;&#22270;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;&#36825;&#20123;&#19978;&#30028;&#20026;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#32593;&#32476;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#20445;&#35777;&#65292;&#20174;&#32780;&#23545;&#25105;&#20204;&#30340;&#29702;&#35299;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work provides a theoretical framework for assessing the generalization error of graph classification tasks via graph neural networks in the over-parameterized regime, where the number of parameters surpasses the quantity of data points. We explore two widely utilized types of graph neural networks: graph convolutional neural networks and message passing graph neural networks. Prior to this study, existing bounds on the generalization error in the over-parametrized regime were uninformative, limiting our understanding of over-parameterized network performance. Our novel approach involves deriving upper bounds within the mean-field regime for evaluating the generalization error of these graph neural networks. We establish upper bounds with a convergence rate of $O(1/n)$, where $n$ is the number of graph samples. These upper bounds offer a theoretical assurance of the networks' performance on unseen data in the challenging over-parameterized regime and overall contribute to our under
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#29615;&#22659;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06434</link><description>&lt;p&gt;
&#30495;&#30456;&#22312;&#21738;&#37324;&#65311;&#22312;&#36830;&#32493;&#30340;&#19990;&#30028;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Where is the Truth? The Risk of Getting Confounded in a Continual World
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06434
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#29615;&#22659;&#20013;&#36973;&#36935;&#28151;&#28102;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#19968;&#20010;&#25968;&#25454;&#38598;&#36890;&#36807;&#19968;&#20010;&#34394;&#20551;&#30456;&#20851;&#24615;&#26469;&#35299;&#20915;&#65292;&#32780;&#36825;&#31181;&#30456;&#20851;&#24615;&#26080;&#27861;&#27867;&#21270;&#21040;&#26032;&#25968;&#25454;&#65292;&#35813;&#25968;&#25454;&#38598;&#23601;&#26159;&#28151;&#28102;&#30340;&#12290;&#25105;&#20204;&#23558;&#23637;&#31034;&#65292;&#22312;&#19968;&#20010;&#36830;&#32493;&#23398;&#20064;&#30340;&#29615;&#22659;&#20013;&#65292;&#28151;&#28102;&#22240;&#32032;&#21487;&#33021;&#38543;&#30528;&#20219;&#21153;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#65292;&#23548;&#33268;&#30340;&#25361;&#25112;&#36828;&#36828;&#36229;&#36807;&#36890;&#24120;&#32771;&#34385;&#30340;&#36951;&#24536;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#20174;&#25968;&#23398;&#19978;&#25512;&#23548;&#20102;&#36825;&#31181;&#28151;&#28102;&#22240;&#32032;&#23545;&#19968;&#32452;&#28151;&#28102;&#20219;&#21153;&#30340;&#26377;&#25928;&#32852;&#21512;&#35299;&#31354;&#38388;&#30340;&#24433;&#21709;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#39044;&#27979;&#65292;&#22312;&#35768;&#22810;&#36825;&#26679;&#30340;&#36830;&#32493;&#25968;&#25454;&#38598;&#20013;&#65292;&#24403;&#20219;&#21153;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#26102;&#65292;&#34394;&#20551;&#30456;&#20851;&#24615;&#24456;&#23481;&#26131;&#34987;&#24573;&#30053;&#65292;&#20294;&#26159;&#22312;&#39034;&#24207;&#32771;&#34385;&#20219;&#21153;&#26102;&#65292;&#36991;&#20813;&#28151;&#28102;&#35201;&#22256;&#38590;&#24471;&#22810;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#36825;&#26679;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#26631;&#20934;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#24573;&#30053;&#28151;&#28102;&#65292;&#32780;&#21516;&#26102;&#23545;&#25152;&#26377;&#20219;&#21153;&#36827;&#34892;&#32852;&#21512;&#35757;&#32451;&#21017;&#26159;&#25104;&#21151;&#30340;&#12290;&#25105;&#20204;&#30340;&#36830;&#32493;&#28151;&#28102;&#25968;&#25454;&#38598;ConCon&#22522;&#20110;CLEVR&#22270;&#20687;&#65292;&#35777;&#26126;&#20102;&#38656;&#35201;&#26356;&#24378;&#22823;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26469;&#22788;&#29702;&#28151;&#28102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A dataset is confounded if it is most easily solved via a spurious correlation which fails to generalize to new data. We will show that, in a continual learning setting where confounders may vary in time across tasks, the resulting challenge far exceeds the standard forgetting problem normally considered. In particular, we derive mathematically the effect of such confounders on the space of valid joint solutions to sets of confounded tasks. Interestingly, our theory predicts that for many such continual datasets, spurious correlations are easily ignored when the tasks are trained on jointly, but it is far harder to avoid confounding when they are considered sequentially. We construct such a dataset and demonstrate empirically that standard continual learning methods fail to ignore confounders, while training jointly on all tasks is successful. Our continually confounded dataset, ConCon, is based on CLEVR images and demonstrates the need for continual learning methods with more robust b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;&#65288;PDDS&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#21407;&#22987;&#36845;&#20195;&#31890;&#23376;&#26041;&#26696;&#21644;&#26032;&#39062;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#23545;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#36827;&#34892;&#37319;&#26679;&#21644;&#35745;&#31639;&#35268;&#33539;&#21270;&#24120;&#25968;&#12290;&#19982;&#26631;&#20934;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;PDDS &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#28176;&#36817;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.06320</link><description>&lt;p&gt;
&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Particle Denoising Diffusion Sampler
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120;&#65288;PDDS&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#21407;&#22987;&#36845;&#20195;&#31890;&#23376;&#26041;&#26696;&#21644;&#26032;&#39062;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#23545;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#36827;&#34892;&#37319;&#26679;&#21644;&#35745;&#31639;&#35268;&#33539;&#21270;&#24120;&#25968;&#12290;&#19982;&#26631;&#20934;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;PDDS &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#28176;&#36817;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#24050;&#32463;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#36890;&#36807;&#20351;&#29992;&#25193;&#25955;&#23558;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#28982;&#21518;&#36890;&#36807;&#20351;&#29992;&#24471;&#20998;&#21305;&#37197;&#24605;&#24819;&#20272;&#35745;&#36825;&#31181;&#25193;&#25955;&#30340;&#26102;&#38388;&#21453;&#28436;&#26469;&#33719;&#24471;&#26469;&#33258;&#25968;&#25454;&#20998;&#24067;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#37319;&#29992;&#31867;&#20284;&#30340;&#31574;&#30053;&#26469;&#20174;&#38750;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#23427;&#20204;&#30340;&#35268;&#33539;&#21270;&#24120;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#37324;&#65292;&#26102;&#38388;&#21453;&#28436;&#25193;&#25955;&#26159;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#26032;&#39062;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#30340;&#21407;&#22987;&#36845;&#20195;&#31890;&#23376;&#26041;&#26696;&#26469;&#27169;&#25311;&#30340;&#12290;&#19982;&#26631;&#20934;&#30340;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#32467;&#26524;&#30340;&#31890;&#23376;&#21435;&#22122;&#25193;&#25955;&#37319;&#26679;&#22120; (PDDS) &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#28176;&#36817;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#22810;&#27169;&#24577;&#21644;&#39640;&#32500;&#37319;&#26679;&#20219;&#21153;&#19978;&#28436;&#31034;&#20102; PDDS&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models have become ubiquitous for generative modeling. The core idea is to transport the data distribution to a Gaussian by using a diffusion. Approximate samples from the data distribution are then obtained by estimating the time-reversal of this diffusion using score matching ideas. We follow here a similar strategy to sample from unnormalized probability densities and compute their normalizing constants. However, the time-reversed diffusion is here simulated by using an original iterative particle scheme relying on a novel score matching loss. Contrary to standard denoising diffusion models, the resulting Particle Denoising Diffusion Sampler (PDDS) provides asymptotically consistent estimates under mild assumptions. We demonstrate PDDS on multimodal and high dimensional sampling tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#26041;&#24335;&#30740;&#31350;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26550;&#26500;&#65292;&#27604;&#36739;&#20102;&#20107;&#21518;&#35299;&#37322;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#37322;&#30340;&#24046;&#24322;&#65292;&#21457;&#29616;&#23613;&#31649;&#26377;&#23616;&#38480;&#24615;&#65292;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#33021;&#22815;&#25429;&#33719;&#27604;&#20165;&#20165;&#26816;&#26597;&#27880;&#24847;&#21147;&#26435;&#37325;&#26356;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;</title><link>https://arxiv.org/abs/2402.03485</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#19982;&#20107;&#21518;&#21487;&#35299;&#37322;&#24615;&#30456;&#36935;&#65306;&#25968;&#23398;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Attention Meets Post-hoc Interpretability: A Mathematical Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#26041;&#24335;&#30740;&#31350;&#20102;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26550;&#26500;&#65292;&#27604;&#36739;&#20102;&#20107;&#21518;&#35299;&#37322;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#37322;&#30340;&#24046;&#24322;&#65292;&#21457;&#29616;&#23613;&#31649;&#26377;&#23616;&#38480;&#24615;&#65292;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#33021;&#22815;&#25429;&#33719;&#27604;&#20165;&#20165;&#26816;&#26597;&#27880;&#24847;&#21147;&#26435;&#37325;&#26356;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#26426;&#21046;&#22522;&#20110;transformer&#31561;&#26550;&#26500;&#65292;&#25104;&#20026;&#20102;&#25216;&#26415;&#38761;&#21629;&#30340;&#26680;&#24515;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#38500;&#20102;&#24110;&#21161;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#20043;&#22806;&#65292;&#27880;&#24847;&#21147;&#26426;&#21046;&#26412;&#36523;&#36824;&#25552;&#20379;&#20102;&#20851;&#20110;&#27169;&#22411;&#20869;&#37096;&#34892;&#20026;&#30340;&#26377;&#24847;&#20041;&#27934;&#23519;&#12290;&#36825;&#20123;&#27934;&#23519;&#26159;&#21542;&#21487;&#20197;&#29992;&#20316;&#35299;&#37322;&#65311;&#20851;&#20110;&#27492;&#20105;&#35770;&#19981;&#26029;&#12290;&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#26041;&#24335;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26550;&#26500;&#65292;&#24182;&#20934;&#30830;&#23450;&#20301;&#20102;&#20107;&#21518;&#35299;&#37322;&#21644;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#37322;&#20043;&#38388;&#30340;&#21306;&#21035;&#12290;&#25105;&#20204;&#34920;&#26126;&#23427;&#20204;&#25552;&#20379;&#20102;&#30456;&#24403;&#19981;&#21516;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#23613;&#31649;&#26377;&#20854;&#23616;&#38480;&#24615;&#65292;&#20107;&#21518;&#35299;&#37322;&#26041;&#27861;&#33021;&#22815;&#25429;&#33719;&#27604;&#20165;&#20165;&#26816;&#26597;&#27880;&#24847;&#21147;&#26435;&#37325;&#26356;&#26377;&#29992;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based architectures, in particular transformers, are at the heart of a technological revolution. Interestingly, in addition to helping obtain state-of-the-art results on a wide range of applications, the attention mechanism intrinsically provides meaningful insights on the internal behavior of the model. Can these insights be used as explanations? Debate rages on. In this paper, we mathematically study a simple attention-based architecture and pinpoint the differences between post-hoc and attention-based explanations. We show that they provide quite different results, and that, despite their limitations, post-hoc methods are capable of capturing more useful insights than merely examining the attention weights.
&lt;/p&gt;</description></item><item><title>$\textsf{DynaBRO}$&#26159;&#19968;&#31181;&#21160;&#24577;&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36866;&#24212;&#20999;&#25442;&#25308;&#21344;&#24237;&#24037;&#20316;&#26426;&#21046;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#19978;&#19982;&#38745;&#24577;&#24773;&#20917;&#30456;&#21305;&#37197;&#12290;&#36890;&#36807;&#22810;&#32423;&#33945;&#29305;&#21345;&#27931;&#28176;&#21464;&#20272;&#35745;&#25216;&#26415;&#12289;&#24378;&#40065;&#26834;&#24037;&#20316;&#26426;&#21046;&#26356;&#26032;&#30340;&#32858;&#21512;&#21644;&#25925;&#38556;&#23433;&#20840;&#36807;&#28388;&#22120;&#30340;&#24341;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#32463;&#21463;&#20303;$\mathcal{O}(\sqrt{T})$&#36718;&#25308;&#21344;&#24237;&#36523;&#20221;&#30340;&#25913;&#21464;&#12290;&#21478;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#30334;&#20998;&#27604;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2402.02951</link><description>&lt;p&gt;
&#21160;&#24577;&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#65306;&#36866;&#24212;&#20999;&#25442;&#25308;&#21344;&#24237;&#24037;&#20316;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Dynamic Byzantine-Robust Learning: Adapting to Switching Byzantine Workers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02951
&lt;/p&gt;
&lt;p&gt;
$\textsf{DynaBRO}$&#26159;&#19968;&#31181;&#21160;&#24577;&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36866;&#24212;&#20999;&#25442;&#25308;&#21344;&#24237;&#24037;&#20316;&#26426;&#21046;&#65292;&#24182;&#19988;&#22312;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#19978;&#19982;&#38745;&#24577;&#24773;&#20917;&#30456;&#21305;&#37197;&#12290;&#36890;&#36807;&#22810;&#32423;&#33945;&#29305;&#21345;&#27931;&#28176;&#21464;&#20272;&#35745;&#25216;&#26415;&#12289;&#24378;&#40065;&#26834;&#24037;&#20316;&#26426;&#21046;&#26356;&#26032;&#30340;&#32858;&#21512;&#21644;&#25925;&#38556;&#23433;&#20840;&#36807;&#28388;&#22120;&#30340;&#24341;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#32463;&#21463;&#20303;$\mathcal{O}(\sqrt{T})$&#36718;&#25308;&#21344;&#24237;&#36523;&#20221;&#30340;&#25913;&#21464;&#12290;&#21478;&#22806;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#30334;&#20998;&#27604;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25308;&#21344;&#24237;-&#24378;&#40065;&#26834;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#31361;&#20986;&#30340;&#23481;&#38169;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#24050;&#32463;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#25216;&#26415;&#32771;&#34385;&#30340;&#26159;&#38745;&#24577;&#24773;&#20917;&#65292;&#20854;&#20013;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#25308;&#21344;&#24237;&#26426;&#22120;&#30340;&#36523;&#20221;&#20445;&#25345;&#19981;&#21464;&#12290;&#36825;&#31181;&#20551;&#35774;&#19981;&#33021;&#25429;&#25417;&#21040;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#21160;&#24577;&#25308;&#21344;&#24237;&#34892;&#20026;&#65292;&#21487;&#33021;&#21253;&#25324;&#30701;&#26242;&#25925;&#38556;&#25110;&#26377;&#38024;&#23545;&#24615;&#30340;&#26102;&#38388;&#25915;&#20987;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;$\textsf{DynaBRO}$&#65292;&#23427;&#33021;&#22815;&#32463;&#21463;&#20303;$\mathcal{O}(\sqrt{T})$&#36718;&#25308;&#21344;&#24237;&#36523;&#20221;&#30340;&#25913;&#21464;&#65288;&#20854;&#20013;$T$&#26159;&#24635;&#35757;&#32451;&#36718;&#25968;&#65289;&#65292;&#21516;&#26102;&#19982;&#38745;&#24577;&#24773;&#20917;&#19979;&#30340;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#22810;&#32423;&#33945;&#29305;&#21345;&#27931;&#65288;MLMC&#65289;&#28176;&#21464;&#20272;&#35745;&#25216;&#26415;&#19982;&#24037;&#20316;&#26426;&#21046;&#26356;&#26032;&#30340;&#24378;&#40065;&#26834;&#32858;&#21512;&#30456;&#32467;&#21512;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#25925;&#38556;&#23433;&#20840;&#36807;&#28388;&#22120;&#26469;&#38480;&#21046;&#21160;&#24577;&#25308;&#21344;&#24237;&#31574;&#30053;&#30340;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21033;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#30334;&#20998;&#27604;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Byzantine-robust learning has emerged as a prominent fault-tolerant distributed machine learning framework. However, most techniques consider the static setting, wherein the identity of Byzantine machines remains fixed during the learning process. This assumption does not capture real-world dynamic Byzantine behaviors, which may include transient malfunctions or targeted temporal attacks. Addressing this limitation, we propose $\textsf{DynaBRO}$ -- a new method capable of withstanding $\mathcal{O}(\sqrt{T})$ rounds of Byzantine identity alterations (where $T$ is the total number of training rounds), while matching the asymptotic convergence rate of the static setting. Our method combines a multi-level Monte Carlo (MLMC) gradient estimation technique with robust aggregation of worker updates and incorporates a fail-safe filter to limit bias from dynamic Byzantine strategies. Additionally, by leveraging an adaptive learning rate, our approach eliminates the need for knowing the percentag
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2401.16986</link><description>&lt;p&gt;
&#29992;&#20110;&#25104;&#26412;&#25928;&#30410;&#20248;&#21270;&#30340;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#22312;&#21457;&#23637;&#25588;&#21161;&#20998;&#37197;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Causal Machine Learning for Cost-Effective Allocation of Development Aid. (arXiv:2401.16986v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#22269;&#30340;&#21487;&#25345;&#32493;&#21457;&#23637;&#30446;&#26631;&#25552;&#20379;&#20102;&#8220;&#26080;&#20154;&#34987;&#36951;&#24323;&#8221;&#30340;&#26356;&#32654;&#22909;&#26410;&#26469;&#34013;&#22270;&#65292;&#20026;&#20102;&#22312;2030&#24180;&#20043;&#21069;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#36139;&#31351;&#22269;&#23478;&#38656;&#35201;&#22823;&#37327;&#30340;&#21457;&#23637;&#25588;&#21161;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#65288;i&#65289;&#19968;&#20010;&#24179;&#34913;&#33258;&#32534;&#30721;&#22120;&#65292;&#21033;&#29992;&#34920;&#31034;&#23398;&#20064;&#23558;&#39640;&#32500;&#22269;&#23478;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#35299;&#20915;&#27835;&#30103;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65307;&#65288;ii&#65289;&#19968;&#20010;&#21453;&#20107;&#23454;&#29983;&#25104;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19981;&#21516;&#25588;&#21161;&#35268;&#27169;&#19979;&#30340;&#21453;&#20107;&#23454;&#32467;&#26524;&#65292;&#20197;&#35299;&#20915;&#23567;&#26679;&#26412;&#38382;&#39064;&#65307;&#65288;iii&#65289;&#19968;&#20010;&#25512;&#26029;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#24322;&#36136;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26354;&#32447;&#12290;&#25105;&#20204;&#20351;&#29992;105&#20010;&#22269;&#23478;&#25112;&#30053;&#24615;&#21457;&#23637;&#25588;&#21161;&#25968;&#25454;&#65288;&#24635;&#39069;&#36229;&#36807;52&#20159;&#32654;&#20803;&#65289;&#65292;&#20197;&#32467;&#26463;HIV/AIDS&#20026;&#30446;&#26631;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sustainable Development Goals (SDGs) of the United Nations provide a blueprint of a better future by 'leaving no one behind', and, to achieve the SDGs by 2030, poor countries require immense volumes of development aid. In this paper, we develop a causal machine learning framework for predicting heterogeneous treatment effects of aid disbursements to inform effective aid allocation. Specifically, our framework comprises three components: (i) a balancing autoencoder that uses representation learning to embed high-dimensional country characteristics while addressing treatment selection bias; (ii) a counterfactual generator to compute counterfactual outcomes for varying aid volumes to address small sample-size settings; and (iii) an inference model that is used to predict heterogeneous treatment-response curves. We demonstrate the effectiveness of our framework using data with official development aid earmarked to end HIV/AIDS in 105 countries, amounting to more than USD 5.2 billion. F
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#27861;&#65292;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#65288;BiPE&#65289;&#65292;&#36890;&#36807;&#23558;&#20998;&#27573;&#20869;&#32534;&#30721;&#21644;&#20998;&#27573;&#38388;&#32534;&#30721;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#35821;&#20041;&#20449;&#24687;&#30340;&#25429;&#25417;&#21644;&#25512;&#27979;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BiPE&#22312;&#19981;&#21516;&#25991;&#26412;&#27169;&#24577;&#30340;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#38271;&#24230;&#25512;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.16421</link><description>&lt;p&gt;
&#20004;&#31181;&#30707;&#22836;&#20987;&#25171;&#19968;&#21482;&#40479;&#65306;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#20197;&#26356;&#22909;&#22320;&#25512;&#27979;&#38271;&#24230;
&lt;/p&gt;
&lt;p&gt;
Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation. (arXiv:2401.16421v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#27861;&#65292;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#65288;BiPE&#65289;&#65292;&#36890;&#36807;&#23558;&#20998;&#27573;&#20869;&#32534;&#30721;&#21644;&#20998;&#27573;&#38388;&#32534;&#30721;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#35821;&#20041;&#20449;&#24687;&#30340;&#25429;&#25417;&#21644;&#25512;&#27979;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BiPE&#22312;&#19981;&#21516;&#25991;&#26412;&#27169;&#24577;&#30340;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#38271;&#24230;&#25512;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#35821;&#35328;&#24207;&#21015;&#30340;&#20869;&#22312;&#20998;&#21106;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#27861;&#65292;&#31216;&#20026;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#65288;BiPE&#65289;&#12290;&#23545;&#20110;&#27599;&#20010;&#20301;&#32622;&#65292;&#25105;&#20204;&#30340;BiPE&#23558;&#20998;&#27573;&#20869;&#32534;&#30721;&#21644;&#20998;&#27573;&#38388;&#32534;&#30721;&#34701;&#21512;&#22312;&#19968;&#36215;&#12290;&#20998;&#27573;&#20869;&#32534;&#30721;&#29992;&#20110;&#35782;&#21035;&#27573;&#20869;&#20301;&#32622;&#65292;&#24182;&#36890;&#36807;&#32477;&#23545;&#20301;&#32622;&#32534;&#30721;&#24110;&#21161;&#27169;&#22411;&#25429;&#25417;&#20854;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#12290;&#20998;&#27573;&#38388;&#32534;&#30721;&#21017;&#29992;&#20110;&#25351;&#23450;&#27573;&#32034;&#24341;&#65292;&#24314;&#27169;&#27573;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#26088;&#22312;&#36890;&#36807;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#25552;&#39640;&#25512;&#27979;&#33021;&#21147;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#20301;&#32622;&#20449;&#24687;&#30340;&#35299;&#32806;&#20351;&#23398;&#20064;&#26356;&#21152;&#26377;&#25928;&#12290;&#32463;&#39564;&#32467;&#26524;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;BiPE&#22312;&#19981;&#21516;&#25991;&#26412;&#27169;&#24577;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#38271;&#24230;&#25512;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we leverage the intrinsic segmentation of language sequences and design a new positional encoding method called Bilevel Positional Encoding (BiPE). For each position, our BiPE blends an intra-segment encoding and an inter-segment encoding. The intra-segment encoding identifies the locations within a segment and helps the model capture the semantic information therein via absolute positional encoding. The inter-segment encoding specifies the segment index, models the relationships between segments, and aims to improve extrapolation capabilities via relative positional encoding. Theoretical analysis shows this disentanglement of positional information makes learning more effective. The empirical results also show that our BiPE has superior length extrapolation capabilities across a wide range of tasks in diverse text modalities.
&lt;/p&gt;</description></item><item><title>AFS-BM&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#35757;&#32451;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.11250</link><description>&lt;p&gt;
AFS-BM:&#36890;&#36807;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#20108;&#20540;&#23631;&#34109;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking. (arXiv:2401.11250v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11250
&lt;/p&gt;
&lt;p&gt;
AFS-BM&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#35757;&#32451;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#29305;&#24449;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#35813;&#39046;&#22495;&#20013;&#26368;&#20851;&#38190;&#30340;&#20027;&#39064;&#20043;&#19968;&#12290;&#23613;&#31649;&#23384;&#22312;&#35768;&#22810;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#26159;&#36825;&#20123;&#26041;&#27861;&#38754;&#20020;&#21487;&#25193;&#23637;&#24615;&#12289;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12289;&#22788;&#29702;&#30456;&#20851;&#29305;&#24449;&#12289;&#36866;&#24212;&#21487;&#21464;&#29305;&#24449;&#37325;&#35201;&#24615;&#21644;&#25972;&#21512;&#39046;&#22495;&#30693;&#35782;&#31561;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#20108;&#20540;&#23631;&#34109;&#8221;(AFS-BM)&#12290;AFS-BM&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#26469;&#21516;&#26102;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#35757;&#32451;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#21644;&#20108;&#20540;&#23631;&#34109;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25345;&#32493;&#35843;&#25972;&#29305;&#24449;&#38598;&#21644;&#27169;&#22411;&#21442;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;AFS-BM&#19982;&#24050;&#26377;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of feature selection in general machine learning (ML) context, which is one of the most critical subjects in the field. Although, there exist many feature selection methods, however, these methods face challenges such as scalability, managing high-dimensional data, dealing with correlated features, adapting to variable feature importance, and integrating domain knowledge. To this end, we introduce the ``Adaptive Feature Selection with Binary Masking" (AFS-BM) which remedies these problems. AFS-BM achieves this by joint optimization for simultaneous feature selection and model training. In particular, we do the joint optimization and binary masking to continuously adapt the set of features and model parameters during the training process. This approach leads to significant improvements in model accuracy and a reduction in computational requirements. We provide an extensive set of experiments where we compare AFS-BM with the established feature selection methods usin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#65288;SPIN&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#33258;&#25105;&#23545;&#24328;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#20174;&#20013;&#20248;&#21270;&#27169;&#22411;&#31574;&#30053;&#65292;&#20174;&#32780;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#36716;&#21270;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2401.01335</link><description>&lt;p&gt;
&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#21487;&#20197;&#23558;&#20854;&#36716;&#21270;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#65288;SPIN&#65289;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#33258;&#25105;&#23545;&#24328;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#20174;&#20013;&#20248;&#21270;&#27169;&#22411;&#31574;&#30053;&#65292;&#20174;&#32780;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#36716;&#21270;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#32454;&#35843;&#65288;SFT&#65289;&#21033;&#29992;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#30340;&#21147;&#37327;&#23545;&#20110;&#25512;&#36827;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19981;&#38656;&#35201;&#33719;&#21462;&#39069;&#22806;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#21457;&#23637;&#25104;&#20026;&#24378;&#35821;&#35328;&#27169;&#22411;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#32454;&#35843;&#65288;SPIN&#65289;&#30340;&#26032;&#30340;&#32454;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20174;&#19968;&#20010;&#32463;&#36807;&#30417;&#30563;&#32454;&#35843;&#30340;&#27169;&#22411;&#24320;&#22987;&#12290;SPIN&#30340;&#26680;&#24515;&#26159;&#33258;&#25105;&#23545;&#24369;&#35821;&#35328;&#27169;&#22411;&#30340;&#26426;&#21046;&#65292;&#20854;&#20013;&#24369;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#19982;&#33258;&#36523;&#30340;&#23454;&#20363;&#23545;&#24328;&#26469;&#25552;&#21319;&#33258;&#24049;&#30340;&#33021;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24369;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#29983;&#25104;&#33258;&#24049;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#20248;&#21270;&#33258;&#36523;&#31574;&#30053;&#65292;&#36890;&#36807;&#21306;&#20998;&#33258;&#25105;&#29983;&#25104;&#30340;&#22238;&#24212;&#19982;&#26469;&#33258;&#20154;&#31867;&#26631;&#27880;&#25968;&#25454;&#30340;&#22238;&#24212;&#26469;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36880;&#27493;&#23558;&#24369;&#35821;&#35328;&#27169;&#22411;&#25552;&#21319;&#20026;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#20805;&#20998;&#21457;&#25496;&#20154;&#31867;&#26631;&#27880;&#31034;&#33539;&#25968;&#25454;&#22312;SFT&#20013;&#30340;&#28508;&#21147;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#35757;&#32451;&#30446;&#26631;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#26159;&#21487;&#20197;&#36798;&#21040;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achiev
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#40065;&#26834;&#30340;&#39640;&#26031;&#36807;&#31243;&#22343;&#21248;&#35823;&#24046;&#30028;&#38480;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#35774;&#32622;&#20013;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#22312;&#32447;&#20248;&#21270;&#20013;&#36229;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.07281</link><description>&lt;p&gt;
&#23433;&#20840;&#30340;&#22810;&#20219;&#21153;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Safe Multi-Task Bayesian Optimization. (arXiv:2312.07281v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.07281
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#40065;&#26834;&#30340;&#39640;&#26031;&#36807;&#31243;&#22343;&#21248;&#35823;&#24046;&#30028;&#38480;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#35774;&#32622;&#20013;&#65292;&#20197;&#35299;&#20915;&#23433;&#20840;&#22312;&#32447;&#20248;&#21270;&#20013;&#36229;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#24050;&#25104;&#20026;&#23433;&#20840;&#22312;&#32447;&#31995;&#32479;&#20248;&#21270;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#22240;&#20854;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#22122;&#22768;&#20581;&#22766;&#24615;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21152;&#24555;&#36807;&#31243;&#65292;&#21487;&#20197;&#23558;&#20943;&#23569;&#30340;&#29289;&#29702;&#27169;&#22411;&#32435;&#20837;&#20248;&#21270;&#36807;&#31243;&#20013;&#20197;&#21152;&#36895;&#36807;&#31243;&#65292;&#22240;&#20026;&#36825;&#20123;&#27169;&#22411;&#33021;&#22815;&#25552;&#20379;&#23545;&#23454;&#38469;&#31995;&#32479;&#30340;&#36817;&#20284;&#65292;&#24182;&#19988;&#20174;&#20013;&#36827;&#34892;&#37319;&#26679;&#35201;&#20415;&#23452;&#24471;&#22810;&#12290;&#27169;&#22411;&#19982;&#29616;&#23454;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#30001;&#39069;&#22806;&#30340;&#36229;&#21442;&#25968;&#34920;&#31034;&#65292;&#24182;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#23398;&#20064;&#12290;&#23433;&#20840;&#24615;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#31561;&#22312;&#32447;&#20248;&#21270;&#26041;&#27861;&#30340;&#37325;&#35201;&#26631;&#20934;&#65292;&#26368;&#36817;&#30340;&#25991;&#29486;&#24050;&#32463;&#35299;&#20915;&#20102;&#27492;&#38382;&#39064;&#65292;&#24182;&#22312;&#24050;&#30693;&#36229;&#21442;&#25968;&#30340;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#23433;&#20840;&#20445;&#38556;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#36825;&#26159;&#19981;&#36866;&#29992;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#40065;&#26834;&#39640;&#26031;&#36807;&#31243;&#22343;&#21248;&#35823;&#24046;&#30028;&#38480;&#65292;&#20197;&#28385;&#36275;&#22810;&#20219;&#21153;&#35774;&#32622;&#65292;&#20854;&#20013;&#28041;&#21450;&#20174;&#36229;&#21442;&#25968;&#21518;&#39564;&#20998;&#24067;&#35745;&#31639;&#32622;&#20449;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization has become a powerful tool for safe online optimization of systems, due to its high sample efficiency and noise robustness. For further speed-up reduced physical models of the system can be incorporated into the optimization to accelerate the process, since the models are able to offer an approximation of the actual system, and sampling from them is significantly cheaper. The similarity between model and reality is represented by additional hyperparameters and learned within the optimization process. Safety is an important criteria for online optimization methods like Bayesian optimization, which has been addressed by recent literature, which provide safety guarantees under the assumption of known hyperparameters. However, in practice this is not applicable. Therefore, we extend the robust Gaussian process uniform error bounds to meet the multi-task setting, which involves the calculation of a confidence region from the hyperparameter posterior distribution utiliz
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#65292;&#22312;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#22522;&#30784;&#19978;&#65292;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#20272;&#35745;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#25269;&#25239;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#20851;&#38190;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.15330</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#32852;&#37030;&#23398;&#20064;&#65306;&#20855;&#26377;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#24322;&#26500;&#28151;&#21512;&#27169;&#22411;&#30340;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Federated Learning: A Federated Gradient EM Algorithm for Heterogeneous Mixture Models with Robustness against Adversarial Attacks. (arXiv:2310.15330v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15330
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#65292;&#22312;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#22522;&#30784;&#19978;&#65292;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#36827;&#34892;&#20102;&#20855;&#20307;&#30340;&#20272;&#35745;&#35823;&#24046;&#20998;&#26512;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#25269;&#25239;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#31561;&#20851;&#38190;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26377;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#26080;&#30417;&#30563;&#30340;&#32852;&#37030;&#23398;&#20064;&#39046;&#22495;&#30456;&#23545;&#36739;&#23569;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#24102;&#26377;&#24322;&#26500;&#28151;&#21512;&#27604;&#20363;&#30340;&#28151;&#21512;&#27169;&#22411;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26032;&#22411;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#26222;&#36890;&#28151;&#21512;&#27169;&#22411;&#30340;&#20840;&#38754;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#65292;&#28982;&#21518;&#23558;&#36825;&#19968;&#36890;&#29992;&#29702;&#35770;&#24212;&#29992;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#21644;&#28151;&#21512;&#22238;&#24402;&#65288;MoRs&#65289;&#20197;&#25551;&#36848;&#27169;&#22411;&#21442;&#25968;&#21644;&#28151;&#21512;&#27604;&#20363;&#30340;&#26174;&#24335;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#32852;&#37030;&#26799;&#24230;EM&#31639;&#27861;&#20855;&#26377;&#20197;&#19979;&#20960;&#20010;&#20851;&#38190;&#20248;&#21183;&#65306;&#36866;&#24212;&#26410;&#30693;&#20219;&#21153;&#30456;&#20284;&#24615;&#12289;&#23545;&#23569;&#37096;&#20998;&#25968;&#25454;&#28304;&#30340;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#24377;&#24615;&#12289;&#20445;&#25252;&#26412;&#22320;&#25968;&#25454;&#38544;&#31169;&#20197;&#21450;&#35745;&#31639;&#21644;&#36890;&#20449;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised federated learning approaches have enjoyed significant success, the domain of unsupervised federated learning remains relatively underexplored. In this paper, we introduce a novel federated gradient EM algorithm designed for the unsupervised learning of mixture models with heterogeneous mixture proportions across tasks. We begin with a comprehensive finite-sample theory that holds for general mixture models, then apply this general theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions (MoRs) to characterize the explicit estimation error of model parameters and mixture proportions. Our proposed federated gradient EM algorithm demonstrates several key advantages: adaptability to unknown task similarity, resilience against adversarial attacks on a small fraction of data sources, protection of local data privacy, and computational and communication efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#31574;&#30053;&#35780;&#20272;&#65292;&#22312;&#22312;&#32447;&#25512;&#26029;&#20013;&#33719;&#24471;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.14286</link><description>&lt;p&gt;
&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Analysis of the Temporal Difference Learning. (arXiv:2310.14286v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#24046;&#24322;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#31574;&#30053;&#35780;&#20272;&#65292;&#22312;&#22312;&#32447;&#25512;&#26029;&#20013;&#33719;&#24471;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#32447;&#31574;&#30053;&#35780;&#20272;&#20013;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#26102;&#38388;&#24046;&#24322;(TD)&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36890;&#29992;&#19988;&#19982;&#23454;&#20363;&#26080;&#20851;&#30340;&#27493;&#38271;&#21644;Polyak-Ruppert&#23614;&#24179;&#22343;&#65292;&#21487;&#20197;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#39033;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#24039;&#22522;&#20110;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#30340;&#31934;&#30830;&#35823;&#24046;&#30028;&#38480;&#20197;&#21450;TD&#31867;&#22411;&#36882;&#24402;&#20135;&#29983;&#30340;&#38543;&#26426;&#30697;&#38453;&#20056;&#31215;&#30340;&#26032;&#31283;&#23450;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider the problem of obtaining sharp bounds for the performance of temporal difference (TD) methods with linear functional approximation for policy evaluation in discounted Markov Decision Processes. We show that a simple algorithm with a universal and instance-independent step size together with Polyak-Ruppert tail averaging is sufficient to obtain near-optimal variance and bias terms. We also provide the respective sample complexity bounds. Our proof technique is based on refined error bounds for linear stochastic approximation together with the novel stability result for the product of random matrices that arise from the TD-type recurrence.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2310.11914</link><description>&lt;p&gt;
&#36864;&#28779;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
A connection between Tempering and Entropic Mirror Descent. (arXiv:2310.11914v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11914
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#36864;&#28779;&#65288;&#38024;&#23545;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;; SMC&#65289;&#21644;&#29109;&#38236;&#20687;&#19979;&#38477;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20197;&#20174;&#24050;&#30693;&#26410;&#24402;&#19968;&#21270;&#27010;&#29575;&#23494;&#24230;&#30340;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36864;&#28779;SMC&#26159;&#24212;&#29992;&#20110;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#29109;&#38236;&#20687;&#19979;&#38477;&#30340;&#25968;&#20540;&#36817;&#20284;&#65292;&#24182;&#33719;&#24471;&#20102;&#36864;&#28779;&#36845;&#20195;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20174;&#20248;&#21270;&#35282;&#24230;&#25512;&#21160;&#20102;&#36864;&#28779;&#36845;&#20195;&#65292;&#34920;&#26126;&#36864;&#28779;&#21487;&#20197;&#29992;&#20316;Langevin&#31639;&#27861;&#30340;&#26367;&#20195;&#36873;&#25321;&#65292;&#20197;&#26368;&#23567;&#21270;KL&#25955;&#24230;&#12290;&#25105;&#20204;&#21033;&#29992;&#36864;&#28779;&#21644;&#38236;&#20687;&#19979;&#38477;&#36845;&#20195;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#35777;&#26126;SMC&#20013;&#24120;&#35265;&#30340;&#20570;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#25991;&#29486;&#20013;&#31639;&#27861;&#30340;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between tempering (for Sequential Monte Carlo; SMC) and entropic mirror descent to sample from a target probability distribution whose unnormalized density is known.  We establish that tempering SMC is a numerical approximation of entropic mirror descent applied to the Kullback-Leibler (KL) divergence and obtain convergence rates for the tempering iterates.  Our result motivates the tempering iterates from an optimization point of view, showing that tempering can be used as an alternative to Langevin-based algorithms to minimize the KL divergence.  We exploit the connection between tempering and mirror descent iterates to justify common practices in SMC and propose improvements to algorithms in literature.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;</title><link>http://arxiv.org/abs/2310.07891</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Theory of Non-Linear Feature Learning with One Gradient Step in Two-Layer Neural Networks. (arXiv:2310.07891v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07891
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#36890;&#36807;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#36807;&#31243;&#20013;&#24341;&#20837;&#19981;&#21516;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#21040;&#30446;&#26631;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#32780;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#21017;&#30001;&#36825;&#20123;&#29305;&#24449;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#23398;&#20064;&#34987;&#35748;&#20026;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#30340;&#22522;&#26412;&#21407;&#22240;&#20043;&#19968;&#12290;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#24050;&#32463;&#20005;&#26684;&#35777;&#26126;&#65292;&#22312;&#20004;&#23618;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#31532;&#19968;&#23618;&#36827;&#34892;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#65292;&#28982;&#21518;&#22312;&#31532;&#20108;&#23618;&#36827;&#34892;&#23725;&#22238;&#24402;&#21487;&#20197;&#23548;&#33268;&#29305;&#24449;&#23398;&#20064;&#65307;&#29305;&#24449;&#30697;&#38453;&#30340;&#35889;&#20013;&#20250;&#20986;&#29616;&#20998;&#31163;&#30340;&#19968;&#32500;&#32452;&#20214;&#65292;&#31216;&#20026;&#8220;spike&#8221;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#22266;&#23450;&#26799;&#24230;&#19979;&#38477;&#27493;&#38271;&#26102;&#65292;&#36825;&#20010;&#8220;spike&#8221;&#20165;&#25552;&#20379;&#20102;&#30446;&#26631;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#20214;&#30340;&#20449;&#24687;&#65292;&#22240;&#27492;&#23398;&#20064;&#38750;&#32447;&#24615;&#32452;&#20214;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23398;&#20064;&#29575;&#38543;&#26679;&#26412;&#22823;&#23567;&#22686;&#38271;&#26102;&#65292;&#36825;&#26679;&#30340;&#35757;&#32451;&#23454;&#38469;&#19978;&#24341;&#20837;&#20102;&#22810;&#20010;&#19968;&#32500;&#32452;&#20214;&#65292;&#27599;&#20010;&#32452;&#20214;&#23545;&#24212;&#19968;&#20010;&#29305;&#23450;&#30340;&#22810;&#39033;&#24335;&#29305;&#24449;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#26356;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#22823;&#32500;&#24230;&#21644;&#22823;&#26679;&#26412;&#35757;&#32451;&#21644;&#27979;&#35797;&#35823;&#24046;&#23436;&#20840;&#30001;&#36825;&#20123;&#8220;spike&#8221;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature learning is thought to be one of the fundamental reasons for the success of deep neural networks. It is rigorously known that in two-layer fully-connected neural networks under certain conditions, one step of gradient descent on the first layer followed by ridge regression on the second layer can lead to feature learning; characterized by the appearance of a separated rank-one component -- spike -- in the spectrum of the feature matrix. However, with a constant gradient descent step size, this spike only carries information from the linear component of the target function and therefore learning non-linear components is impossible. We show that with a learning rate that grows with the sample size, such training in fact introduces multiple rank-one components, each corresponding to a specific polynomial feature. We further prove that the limiting large-dimensional and large sample training and test errors of the updated neural networks are fully characterized by these spikes. By 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#21464;&#21270;&#19979;&#20855;&#26377;&#19981;&#21464;&#24615;&#21644;&#31283;&#20581;&#24615;&#30340;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#19979;&#65292;&#20219;&#24847;&#20998;&#24067;&#20559;&#31227;&#19968;&#33324;&#19981;&#20855;&#26377;&#19981;&#21464;&#21644;&#31283;&#20581;&#30340;&#27010;&#29575;&#39044;&#27979;&#65292;&#36890;&#36807;&#38480;&#21046;&#20998;&#24067;&#20559;&#31227;&#31867;&#21035;&#21644;&#36873;&#25321;&#35780;&#20272;&#25351;&#26631;&#65292;&#21487;&#20197;&#22312;&#29305;&#23450;&#27169;&#22411;&#20013;&#23454;&#29616;&#19981;&#21464;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.10083</link><description>&lt;p&gt;
&#19981;&#21464;&#30340;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Invariant Probabilistic Prediction. (arXiv:2309.10083v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10083
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#21464;&#21270;&#19979;&#20855;&#26377;&#19981;&#21464;&#24615;&#21644;&#31283;&#20581;&#24615;&#30340;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#19979;&#65292;&#20219;&#24847;&#20998;&#24067;&#20559;&#31227;&#19968;&#33324;&#19981;&#20855;&#26377;&#19981;&#21464;&#21644;&#31283;&#20581;&#30340;&#27010;&#29575;&#39044;&#27979;&#65292;&#36890;&#36807;&#38480;&#21046;&#20998;&#24067;&#20559;&#31227;&#31867;&#21035;&#21644;&#36873;&#25321;&#35780;&#20272;&#25351;&#26631;&#65292;&#21487;&#20197;&#22312;&#29305;&#23450;&#27169;&#22411;&#20013;&#23454;&#29616;&#19981;&#21464;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#20998;&#24067;&#21464;&#21270;&#19979;&#34920;&#29616;&#31283;&#20581;&#30340;&#32479;&#35745;&#26041;&#27861;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#12290;&#34429;&#28982;&#22823;&#37096;&#20998;&#30456;&#20851;&#30740;&#31350;&#38598;&#20013;&#22312;&#20351;&#29992;&#24179;&#26041;&#35823;&#24046;&#25439;&#22833;&#30340;&#28857;&#39044;&#27979;&#19978;&#65292;&#20294;&#26412;&#25991;&#23558;&#28966;&#28857;&#36716;&#21521;&#20102;&#27010;&#29575;&#39044;&#27979;&#65292;&#26088;&#22312;&#20840;&#38754;&#37327;&#21270;&#32473;&#23450;&#21327;&#21464;&#37327;&#30340;&#32467;&#26524;&#21464;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#22522;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27010;&#29575;&#39044;&#27979;&#22312;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#19979;&#30340;&#19981;&#21464;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#24847;&#20998;&#24067;&#20559;&#31227;&#19968;&#33324;&#19981;&#20855;&#26377;&#19981;&#21464;&#21644;&#31283;&#20581;&#30340;&#27010;&#29575;&#39044;&#27979;&#65292;&#19982;&#28857;&#39044;&#27979;&#30340;&#24773;&#20917;&#30456;&#21453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;&#35780;&#20272;&#25351;&#26631;&#24182;&#38480;&#21046;&#20998;&#24067;&#20559;&#31227;&#31867;&#21035;&#65292;&#20197;&#23454;&#29616;&#21407;&#22411;&#39640;&#26031;&#24322;&#26041;&#24046;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#19981;&#21464;&#24615;&#12290;&#22312;&#36825;&#20123;&#21457;&#29616;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20135;&#29983;&#19981;&#21464;&#30340;&#27010;&#29575;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a growing interest in statistical methods that exhibit robust performance under distribution changes between training and test data. While most of the related research focuses on point predictions with the squared error loss, this article turns the focus towards probabilistic predictions, which aim to comprehensively quantify the uncertainty of an outcome variable given covariates. Within a causality-inspired framework, we investigate the invariance and robustness of probabilistic predictions with respect to proper scoring rules. We show that arbitrary distribution shifts do not, in general, admit invariant and robust probabilistic predictions, in contrast to the setting of point prediction. We illustrate how to choose evaluation metrics and restrict the class of distribution shifts to allow for identifiability and invariance in the prototypical Gaussian heteroscedastic linear model. Motivated by these findings, we propose a method to yield invariant pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21516;&#36136;&#31181;&#32676;&#30340;&#38543;&#26426;&#23454;&#39564;&#20013;&#36873;&#25321;&#26368;&#20248;&#30340;&#20195;&#29702;&#25351;&#26631;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#23558;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#30340;&#26500;&#24314;&#36827;&#34892;&#20102;&#24402;&#32422;&#65292;&#24182;&#23545;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#25928;&#26524;&#36827;&#34892;&#20102;&#38477;&#22122;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.07893</link><description>&lt;p&gt;
&#20174;&#36807;&#21435;&#30340;&#23454;&#39564;&#20013;&#36873;&#25321;&#20195;&#29702;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Choosing a Proxy Metric from Past Experiments. (arXiv:2309.07893v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21516;&#36136;&#31181;&#32676;&#30340;&#38543;&#26426;&#23454;&#39564;&#20013;&#36873;&#25321;&#26368;&#20248;&#30340;&#20195;&#29702;&#25351;&#26631;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#23558;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#30340;&#26500;&#24314;&#36827;&#34892;&#20102;&#24402;&#32422;&#65292;&#24182;&#23545;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#25928;&#26524;&#36827;&#34892;&#20102;&#38477;&#22122;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#38543;&#26426;&#23454;&#39564;&#20013;&#65292;&#24448;&#24448;&#24456;&#38590;&#25110;&#19981;&#21487;&#34892;&#22320;&#27979;&#37327;&#38271;&#26399;&#25351;&#26631;&#65288;&#21363;&#24863;&#20852;&#36259;&#30340;&#20027;&#35201;&#32467;&#26524;&#65289;&#12290;&#36825;&#20123;&#38271;&#26399;&#25351;&#26631;&#24448;&#24448;&#21453;&#24212;&#21464;&#21270;&#36739;&#24930;&#65292;&#19988;&#22122;&#22768;&#36739;&#22823;&#65292;&#20351;&#24471;&#22312;&#30701;&#26399;&#23454;&#39564;&#20013;&#38590;&#20197;&#20934;&#30830;&#20272;&#35745;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#26367;&#20195;&#26041;&#27861;&#26159;&#27979;&#37327;&#20960;&#20010;&#30701;&#26399;&#20195;&#29702;&#25351;&#26631;&#65292;&#24076;&#26395;&#23427;&#20204;&#33021;&#22815;&#32039;&#23494;&#36861;&#36394;&#38271;&#26399;&#25351;&#26631;&#65292;&#20174;&#32780;&#22312;&#36817;&#26399;&#26377;&#25928;&#22320;&#25351;&#23548;&#20915;&#31574;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#29992;&#20110;&#23450;&#20041;&#21644;&#26500;&#24314;&#19968;&#20010;&#36866;&#29992;&#20110;&#21516;&#36136;&#31181;&#32676;&#38543;&#26426;&#23454;&#39564;&#30340;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#23558;&#32473;&#23450;&#23454;&#39564;&#20013;&#26368;&#20248;&#20195;&#29702;&#25351;&#26631;&#30340;&#26500;&#24314;&#24402;&#32422;&#20026;&#19968;&#20010;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21462;&#20915;&#20110;&#32771;&#34385;&#20013;&#23454;&#39564;&#30340;&#30495;&#23454;&#28508;&#22312;&#27835;&#30103;&#25928;&#26524;&#21644;&#22122;&#22768;&#27700;&#24179;&#12290;&#28982;&#21518;&#25105;&#20204;&#23545;&#38271;&#26399;&#25351;&#26631;&#21644;&#19968;&#32452;&#20195;&#29702;&#30340;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#25928;&#26524;&#36827;&#34892;&#38477;&#22122;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many randomized experiments, the treatment effect of the long-term metric (i.e. the primary outcome of interest) is often difficult or infeasible to measure. Such long-term metrics are often slow to react to changes and sufficiently noisy they are challenging to faithfully estimate in short-horizon experiments. A common alternative is to measure several short-term proxy metrics in the hope they closely track the long-term metric -- so they can be used to effectively guide decision-making in the near-term. We introduce a new statistical framework to both define and construct an optimal proxy metric for use in a homogeneous population of randomized experiments. Our procedure first reduces the construction of an optimal proxy metric in a given experiment to a portfolio optimization problem which depends on the true latent treatment effects and noise level of experiment under consideration. We then denoise the observed treatment effects of the long-term metric and a set of proxies in a 
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#25945;&#31243;&#20171;&#32461;&#20102;&#31995;&#32479;&#35782;&#21035;&#20013;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#28176;&#36817;&#26041;&#27861;&#12289;&#24378;&#35843;&#20102;&#35206;&#30422;&#25216;&#26415;&#12289;Hanson-Wright&#19981;&#31561;&#24335;&#21644;&#33258;&#26631;&#20934;&#21270;&#39532;&#19969;&#26684;&#23572;&#27861;&#31561;&#24037;&#20855;&#30340;&#24212;&#29992;&#12289;&#24182;&#32473;&#20986;&#20102;&#21033;&#29992;&#36825;&#20123;&#24037;&#20855;&#31616;&#21270;&#35777;&#26126;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#21442;&#25968;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#12289;&#26368;&#21518;&#20171;&#32461;&#20102;&#23558;&#36825;&#20123;&#24605;&#24819;&#25193;&#23637;&#21040;&#26576;&#20123;&#38750;&#32447;&#24615;&#35782;&#21035;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.03873</link><description>&lt;p&gt;
&#31995;&#32479;&#35782;&#21035;&#30340;&#38750;&#28176;&#36817;&#29702;&#35770;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A Tutorial on the Non-Asymptotic Theory of System Identification. (arXiv:2309.03873v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03873
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#25945;&#31243;&#20171;&#32461;&#20102;&#31995;&#32479;&#35782;&#21035;&#20013;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#28176;&#36817;&#26041;&#27861;&#12289;&#24378;&#35843;&#20102;&#35206;&#30422;&#25216;&#26415;&#12289;Hanson-Wright&#19981;&#31561;&#24335;&#21644;&#33258;&#26631;&#20934;&#21270;&#39532;&#19969;&#26684;&#23572;&#27861;&#31561;&#24037;&#20855;&#30340;&#24212;&#29992;&#12289;&#24182;&#32473;&#20986;&#20102;&#21033;&#29992;&#36825;&#20123;&#24037;&#20855;&#31616;&#21270;&#35777;&#26126;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#21442;&#25968;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#12289;&#26368;&#21518;&#20171;&#32461;&#20102;&#23558;&#36825;&#20123;&#24605;&#24819;&#25193;&#23637;&#21040;&#26576;&#20123;&#38750;&#32447;&#24615;&#35782;&#21035;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#25945;&#31243;&#20171;&#32461;&#26368;&#36817;&#21457;&#23637;&#30340;&#38750;&#28176;&#36817;&#26041;&#27861;&#22312;&#20027;&#35201;&#32447;&#24615;&#31995;&#32479;&#35782;&#21035;&#29702;&#35770;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#24378;&#35843;&#19968;&#20123;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#29305;&#21035;&#26377;&#29992;&#30340;&#24037;&#20855;&#65292;&#22914;&#35206;&#30422;&#25216;&#26415;&#12289;Hanson-Wright&#19981;&#31561;&#24335;&#21644;&#33258;&#26631;&#20934;&#21270;&#39532;&#19969;&#26684;&#23572;&#27861;&#12290;&#28982;&#21518;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#24037;&#20855;&#26469;&#32473;&#20986;&#19968;&#20123;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#30340;&#31616;&#21270;&#35777;&#26126;&#65292;&#29992;&#20110;&#35782;&#21035;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#22914;&#20309;&#23558;&#25152;&#21576;&#29616;&#30340;&#24605;&#24819;&#25193;&#23637;&#21040;&#26576;&#20123;&#38750;&#32447;&#24615;&#35782;&#21035;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This tutorial serves as an introduction to recently developed non-asymptotic methods in the theory of -- mainly linear -- system identification. We emphasize tools we deem particularly useful for a range of problems in this domain, such as the covering technique, the Hanson-Wright Inequality and the method of self-normalized martingales. We then employ these tools to give streamlined proofs of the performance of various least-squares based estimators for identifying the parameters in autoregressive models. We conclude by sketching out how the ideas presented herein can be extended to certain nonlinear identification problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.00079</link><description>&lt;p&gt;
&#20851;&#20110;Adam&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
On the Implicit Bias of Adam. (arXiv:2309.00079v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20197;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#21518;&#21521;&#35823;&#24046;&#20998;&#26512;&#34987;&#29992;&#26469;&#25214;&#21040;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#12290;&#21457;&#29616;&#26377;&#38480;&#27493;&#38271;&#20250;&#38544;&#24335;&#22320;&#35268;&#33539;&#21270;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#20986;&#29616;&#22312;ODE&#20013;&#30340;&#39033;&#20250;&#24809;&#32602;&#25439;&#22833;&#26799;&#24230;&#30340;&#20108;&#33539;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#20013;&#26159;&#21542;&#23384;&#22312;&#31867;&#20284;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#21462;&#20915;&#20110;&#23427;&#20204;&#30340;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#20294;&#28041;&#21450;&#30340;&#8220;&#33539;&#25968;&#8221;&#19981;&#21516;&#65306;&#23545;&#24212;&#30340;ODE&#39033;&#35201;&#20040;&#24809;&#32602;&#65288;&#25200;&#21160;&#30340;&#65289;&#25439;&#22833;&#26799;&#24230;&#30340;&#19968;&#33539;&#25968;&#65292;&#35201;&#20040;&#30456;&#21453;&#22320;&#38459;&#27490;&#20854;&#20943;&#23567;&#65288;&#21518;&#19968;&#31181;&#24773;&#20917;&#26159;&#20856;&#22411;&#30340;&#65289;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different "norm" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, on the contrary, hinder its decrease (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#20855;&#26377;&#26368;&#36817;&#37051;&#30340;$Q$&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#19979;&#25910;&#25947;&#36895;&#24230;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.01490</link><description>&lt;p&gt;
&#20855;&#26377;&#26368;&#36817;&#37051;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;$Q$&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal $Q$ Learning with Nearest Neighbors. (arXiv:2308.01490v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#20855;&#26377;&#26368;&#36817;&#37051;&#30340;$Q$&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#19979;&#25910;&#25947;&#36895;&#24230;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$Q$&#23398;&#20064;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#22823;&#37096;&#20998;&#24037;&#20316;&#38598;&#20013;&#22312;&#20998;&#26512;&#26377;&#38480;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;$Q$&#23398;&#20064;&#12290;&#22914;&#26524;&#29366;&#24577;&#31354;&#38388;&#26159;&#36830;&#32493;&#30340;&#65292;&#37027;&#20040;&#21407;&#22987;&#30340;$Q$&#23398;&#20064;&#26041;&#27861;&#23601;&#26080;&#27861;&#30452;&#25509;&#20351;&#29992;&#12290;(Shah and Xie, 2018) &#25552;&#20986;&#20102;&#21407;&#22987;$Q$&#23398;&#20064;&#26041;&#27861;&#30340;&#20462;&#25913;&#29256;&#65292;&#29992;&#26368;&#36817;&#37051;&#26041;&#27861;&#20272;&#35745;$Q$&#20540;&#12290;&#36825;&#31181;&#20462;&#25913;&#20351;&#24471;$Q$&#23398;&#20064;&#36866;&#29992;&#20110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#12290;&#35813;&#35770;&#25991;&#25351;&#20986;&#20272;&#35745;$Q$&#20989;&#25968;&#30340;&#25910;&#25947;&#36895;&#24230;&#20026;$\tilde{O}(T^{-1/(d+3)})$&#65292;&#27604;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;$\tilde{\Omega}(T^{-1/(d+2)})$&#24930;&#65292;&#35828;&#26126;&#35813;&#26041;&#27861;&#25928;&#29575;&#19981;&#39640;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;$Q$&#23398;&#20064;&#26041;&#27861;&#65292;&#26469;&#24357;&#21512;(Shah and Xie, 2018)&#20013;&#30340;&#25910;&#25947;&#36895;&#24230;&#24046;&#36317;&#65292;&#20854;&#20013;&#19968;&#31181;&#26159;&#31163;&#32447;&#30340;&#65292;&#21478;&#19968;&#31181;&#26159;&#22312;&#32447;&#30340;&#12290;&#23613;&#31649;&#25105;&#20204;&#20173;&#28982;&#20351;&#29992;&#26368;&#36817;&#37051;&#26041;&#27861;&#26469;&#20272;&#35745;$Q$&#20989;&#25968;&#65292;&#20294;&#31639;&#27861;&#19982;(Shah and Xie, 2018)&#26377;&#26174;&#33879;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
$Q$ learning is a popular model free reinforcement learning method. Most of existing works focus on analyzing $Q$ learning for finite state and action spaces. If the state space is continuous, then the original $Q$ learning method can not be directly used. A modification of the original $Q$ learning method was proposed in (Shah and Xie, 2018), which estimates $Q$ values with nearest neighbors. Such modification makes $Q$ learning suitable for continuous state space. (Shah and Xie, 2018) shows that the convergence rate of estimated $Q$ function is $\tilde{O}(T^{-1/(d+3)})$, which is slower than the minimax lower bound $\tilde{\Omega}(T^{-1/(d+2)})$, indicating that this method is not efficient. This paper proposes two new $Q$ learning methods to bridge the gap of convergence rates in (Shah and Xie, 2018), with one of them being offline, while the other is online. Despite that we still use nearest neighbor approach to estimate $Q$ function, the algorithms are crucially different from (Sh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.06092</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#37327;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#20854;&#20013;&#38544;&#34255;&#23618;&#23485;&#24230;&#19982;&#22823;&#24120;&#25968; $n$ &#25104;&#27604;&#20363;&#12290;&#22312;&#38750;&#32447;&#24615;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#23545;&#20110;&#26377;&#38480;&#32500;&#20998;&#24067;&#36824;&#26159;&#25972;&#20010;&#36807;&#31243;&#65292;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#65288;&#21450;&#20854;&#23548;&#25968;&#65289;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#37117;&#20250;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#20854;&#20013; $\gamma&gt;0$&#65292;&#25351;&#25968;&#21462;&#20915;&#20110;&#29992;&#20110;&#24230;&#37327;&#24046;&#24322;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#27604;&#25991;&#29486;&#20013;&#20197;&#21069;&#25552;&#20379;&#30340;&#20219;&#20309;&#30028;&#38480;&#37117;&#35201;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#29366;&#24577;&#30340;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#30340;&#27169;&#22359;&#25512;&#29702;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#32771;&#34385;&#25968;&#25454;&#20013;&#30340;&#29366;&#24577;&#38388;&#21644;&#29366;&#24577;&#20869;&#20851;&#31995;&#65292;&#24182;&#20801;&#35768;&#29366;&#24577;&#20043;&#38388;&#30340;&#20250;&#35805;&#35745;&#25968;&#21644;&#25345;&#32493;&#26102;&#38388;&#30340;&#24046;&#24322;&#12290;&#23427;&#21487;&#20197;&#25552;&#21462;&#38750;&#27491;&#20132;&#32452;&#20214;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#29305;&#23450;&#29366;&#24577;&#19982;&#29366;&#24577;&#38750;&#29305;&#23450;&#27169;&#22359;&#12290;</title><link>http://arxiv.org/abs/2306.04817</link><description>&lt;p&gt;
SiBBlInGS: &#20351;&#29992;&#36328;&#29366;&#24577;&#30340;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#27169;&#22359;&#25512;&#29702;&#30340;&#24314;&#27169;&#22359;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SiBBlInGS: Similarity-driven Building-Block Inference using Graphs across States. (arXiv:2306.04817v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36328;&#29366;&#24577;&#30340;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#30340;&#27169;&#22359;&#25512;&#29702;&#26694;&#26550;&#65292;&#21487;&#20197;&#21516;&#26102;&#32771;&#34385;&#25968;&#25454;&#20013;&#30340;&#29366;&#24577;&#38388;&#21644;&#29366;&#24577;&#20869;&#20851;&#31995;&#65292;&#24182;&#20801;&#35768;&#29366;&#24577;&#20043;&#38388;&#30340;&#20250;&#35805;&#35745;&#25968;&#21644;&#25345;&#32493;&#26102;&#38388;&#30340;&#24046;&#24322;&#12290;&#23427;&#21487;&#20197;&#25552;&#21462;&#38750;&#27491;&#20132;&#32452;&#20214;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#29305;&#23450;&#29366;&#24577;&#19982;&#29366;&#24577;&#38750;&#29305;&#23450;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22810;&#32500;&#26102;&#38388;&#24207;&#21015;&#26469;&#35828;&#65292;&#25552;&#21462;&#26377;&#24847;&#20041;&#30340;&#27169;&#22359;&#26159;&#21457;&#29616;&#22797;&#26434;&#31995;&#32479;&#20013;&#26377;&#20215;&#20540;&#35265;&#35299;&#30340;&#20851;&#38190;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24418;&#30456;&#20284;&#24615;&#39537;&#21160;&#30340;&#27169;&#22359;&#25512;&#29702;&#26694;&#26550;(SiBBlInGS)&#65292;&#29992;&#20110;&#21457;&#29616;&#27169;&#22359;&#65292;&#21516;&#26102;&#32771;&#34385;&#21040;&#25968;&#25454;&#20013;&#30340;&#29366;&#24577;&#38388;&#21644;&#29366;&#24577;&#20869;&#20851;&#31995;&#65292;&#33021;&#22815;&#25552;&#21462;&#38750;&#27491;&#20132;&#32452;&#20214;&#65292;&#24182;&#20801;&#35768;&#29366;&#24577;&#20043;&#38388;&#30340;&#20250;&#35805;&#35745;&#25968;&#21644;&#25345;&#32493;&#26102;&#38388;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;SiBBlInGS&#36824;&#20801;&#35768;&#36328;&#29366;&#24577;&#21464;&#21270;&#27169;&#22359;&#32467;&#26500;&#21644;&#27599;&#27425;&#35797;&#39564;&#30340;&#26102;&#38388;&#21464;&#24322;&#65292;&#24182;&#21487;&#35782;&#21035;&#29305;&#23450;&#29366;&#24577;&#19982;&#29366;&#24577;&#38750;&#29305;&#23450;&#27169;&#22359;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretable methods for extracting meaningful building blocks (BBs) underlying multi-dimensional time series are vital for discovering valuable insights in complex systems. Existing techniques, however, encounter limitations that restrict their applicability to real-world systems, like reliance on orthogonality assumptions, inadequate incorporation of inter- and intra-state variability, and incapability to handle sessions of varying duration. Here, we present a framework for Similarity-driven Building Block Inference using Graphs across States (SiBBlInGS). SiBBlInGS employs a graph-based dictionary learning approach for BB discovery, simultaneously considers both inter- and intra-state relationships in the data, can extract non-orthogonal components, and allows for variations in session counts and duration across states. Additionally, SiBBlInGS allows for cross-state variations in BB structure and per-trial temporal variability, can identify state-specific vs state-invariant BBs, and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.15742</link><description>&lt;p&gt;
&#26102;&#38388;&#21464;&#21270;&#22788;&#29702;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#24179;&#22343;&#22240;&#26524;&#25928;&#24212;&#26159;&#27979;&#35797;&#26032;&#30103;&#27861;&#30340;&#24120;&#29992;&#20570;&#27861;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#25928;&#24212;&#20250;&#25513;&#30422;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#37325;&#35201;&#30340;&#20010;&#20307;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#24341;&#36215;&#23433;&#20840;&#12289;&#20844;&#24179;&#21644;&#36947;&#24503;&#26041;&#38754;&#30340;&#25285;&#24551;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26102;&#38388;&#35774;&#32622;&#20013;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#22788;&#29702;&#26159;&#26102;&#24207;&#30340;&#21644;&#26102;&#21464;&#30340;&#65292;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#20135;&#29983;&#20102;&#38169;&#32508;&#22797;&#26434;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#20197;&#25429;&#33719;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#20801;&#35768;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#36825;&#20351;&#24471;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#36890;&#36807;&#36793;&#38469;&#32467;&#26500;&#27169;&#22411;&#35880;&#24910;&#22320;&#35299;&#20915;&#20102;&#35266;&#23519;&#25968;&#25454;&#21644;&#30446;&#26631;&#21453;&#20107;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35780;&#35770;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861; SHAP &#21644; LIME &#36827;&#34892;&#20102;&#35780;&#36848;&#21644;&#27604;&#36739;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#19988;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02012</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#35780;&#36848;&#65306;SHAP &#21644; LIME
&lt;/p&gt;
&lt;p&gt;
Commentary on explainable artificial intelligence methods: SHAP and LIME. (arXiv:2305.02012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02012
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35780;&#35770;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861; SHAP &#21644; LIME &#36827;&#34892;&#20102;&#35780;&#36848;&#21644;&#27604;&#36739;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#19988;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#24050;&#32463;&#21457;&#23637;&#20986;&#26469;&#65292;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#40657;&#21283;&#23376;&#36716;&#21270;&#20026;&#26356;&#26131;&#29702;&#35299;&#30340;&#24418;&#24335;&#12290;&#36825;&#20123;&#26041;&#27861;&#26377;&#21161;&#20110;&#20256;&#36798;&#27169;&#22411;&#30340;&#24037;&#20316;&#21407;&#29702;&#65292;&#26088;&#22312;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26356;&#36879;&#26126;&#65292;&#24182;&#22686;&#21152;&#26368;&#32456;&#29992;&#25143;&#23545;&#20854;&#36755;&#20986;&#30340;&#20449;&#20219;&#12290; SHapley Additive exPlanations&#65288;SHAP&#65289;&#21644;Local Interpretable Model Agnostic Explanation&#65288;LIME&#65289;&#26159;&#20004;&#31181;&#22312;&#34920;&#26684;&#25968;&#25454;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;XAI&#26041;&#27861;&#12290;&#22312;&#36825;&#31687;&#35780;&#35770;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#21487;&#35299;&#37322;&#24615;&#24230;&#37327;&#26159;&#22914;&#20309;&#29983;&#25104;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#37322;&#23427;&#20204;&#36755;&#20986;&#30340;&#26694;&#26550;&#65292;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
eXplainable artificial intelligence (XAI) methods have emerged to convert the black box of machine learning models into a more digestible form. These methods help to communicate how the model works with the aim of making machine learning models more transparent and increasing the trust of end-users into their output. SHapley Additive exPlanations (SHAP) and Local Interpretable Model Agnostic Explanation (LIME) are two widely used XAI methods particularly with tabular data. In this commentary piece, we discuss the way the explainability metrics of these two methods are generated and propose a framework for interpretation of their outputs, highlighting their weaknesses and strengths.
&lt;/p&gt;</description></item></channel></rss>