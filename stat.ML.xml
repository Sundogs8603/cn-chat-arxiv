<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;</title><link>http://arxiv.org/abs/2304.08424</link><description>&lt;p&gt;
&#29992;TiDE&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#65306;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Long-term Forecasting with TiDE: Time-series Dense Encoder. (arXiv:2304.08424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08424
&lt;/p&gt;
&lt;p&gt;
TiDE&#26159;&#19968;&#31181;&#22522;&#20110;MLP&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20855;&#22791;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#65292;&#30456;&#36739;&#20110;&#26368;&#20339;&#30340;Transformer&#27169;&#22411;&#65292;&#36895;&#24230;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;&#22522;&#20110;Transformer&#30340;&#26041;&#27861;&#65292;&#31616;&#21333;&#30340;&#32447;&#24615;&#27169;&#22411;&#22312;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#23618;&#24863;&#30693;&#26426;(MLP)&#30340;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#21363;&#26102;&#38388;&#24207;&#21015;&#31264;&#23494;&#32534;&#30721;&#22120;(TiDE)&#65292;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;&#23427;&#26082;&#20139;&#26377;&#32447;&#24615;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#21644;&#36895;&#24230;&#65292;&#21448;&#33021;&#22788;&#29702;&#21327;&#21464;&#37327;&#21644;&#38750;&#32447;&#24615;&#20381;&#36182;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#30340;&#26368;&#31616;&#32447;&#24615;&#31867;&#27604;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#21487;&#20197;&#36798;&#21040;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;(LDS)&#30340;&#36817;&#20046;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#27969;&#34892;&#30340;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22522;&#20934;&#27979;&#35797;&#20013;&#21305;&#37197;&#25110;&#32988;&#36807;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#27604;&#26368;&#20339;&#30340;&#22522;&#20110;Transformer&#30340;&#27169;&#22411;&#24555;5-10&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that simple linear models can outperform several Transformer based approaches in long term time-series forecasting. Motivated by this, we propose a Multi-layer Perceptron (MLP) based encoder-decoder model, Time-series Dense Encoder (TiDE), for long-term time-series forecasting that enjoys the simplicity and speed of linear models while also being able to handle covariates and non-linear dependencies. Theoretically, we prove that the simplest linear analogue of our model can achieve near optimal error rate for linear dynamical systems (LDS) under some assumptions. Empirically, we show that our method can match or outperform prior approaches on popular long-term time-series forecasting benchmarks while being 5-10x faster than the best Transformer based model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;NF-ULA&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#23398;&#20064;&#27491;&#21017;&#21270;&#27969;&#20316;&#20026;&#20808;&#39564;&#65292;&#29992;&#20110;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#31639;&#27861;&#65292;&#19988;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#19977;&#20010;&#25104;&#20687;&#36870;&#38382;&#39064;&#19978;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2304.08342</link><description>&lt;p&gt;
&#24102;&#26377;&#27491;&#21017;&#21270;&#27969;&#20808;&#39564;&#30340;Langevin Monte Carlo&#29992;&#20110;&#25104;&#20687;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems. (arXiv:2304.08342v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;NF-ULA&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#23398;&#20064;&#27491;&#21017;&#21270;&#27969;&#20316;&#20026;&#20808;&#39564;&#65292;&#29992;&#20110;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#31639;&#27861;&#65292;&#19988;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#19977;&#20010;&#25104;&#20687;&#36870;&#38382;&#39064;&#19978;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#26041;&#27861;&#26159;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#19968;&#31181;&#24378;&#22823;&#26367;&#20195;&#26041;&#26696;&#65292;&#22240;&#20026;&#36125;&#21494;&#26031;&#26041;&#27861;&#25552;&#20379;&#20102;&#38382;&#39064;&#30340;&#27010;&#29575;&#25551;&#36848;&#24182;&#33021;&#22815;&#37327;&#21270;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#23581;&#35797;&#23558;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#24182;&#20837;&#22522;&#20110;Langevin&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#31639;&#27861;&#20013;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;NF-ULA&#65288;&#36890;&#36807;&#27491;&#21017;&#21270;&#27969;&#30340;&#26410;&#35843;&#25972;Langevin&#31639;&#27861;&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#23398;&#20064;&#27491;&#21017;&#21270;&#27969;&#20316;&#20026;&#20808;&#39564;&#12290;&#25105;&#20204;&#36890;&#36807;&#35843;&#26597;&#36125;&#21494;&#26031;&#35299;&#30340;&#33391;&#22909;&#24615;&#21644;NF-ULA&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#24615;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25104;&#20687;&#36870;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#22270;&#20687;&#21435;&#27169;&#31946;&#65292;&#36229;&#20998;&#36776;&#29575;&#21644;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#65288;CT&#65289;&#37325;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach gives a probabilistic description of the problems and offers the ability to quantify the uncertainty in the solution. Meanwhile, solving inverse problems by data-driven techniques also proves to be successful, due to the increasing representation ability of data-based models. In this work, we try to incorporate the data-based models into a class of Langevin-based sampling algorithms in Bayesian inference. Loosely speaking, we introduce NF-ULA (Unadjusted Langevin algorithms by Normalizing Flows), which involves learning a normalizing flow as the prior. In particular, our algorithm only requires a pre-trained normalizing flow, which is independent of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness of the Bayesian solution and the non-asymptotic convergence of the NF-ULA algorithm. The effica
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#21270;Laplace&#36924;&#36817;(LLA)&#22312;Bayesian optimization&#20013;&#30340;&#24212;&#29992;&#12290;&#34429;&#28982;LLA&#22312;&#26500;&#24314;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26102;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#65292;&#20294;&#26159;&#22312;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#38656;&#35201;&#32771;&#34385;&#20854;&#21487;&#33021;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.08309</link><description>&lt;p&gt;
Bayesian Optimization&#20013;&#32447;&#24615;&#21270;Laplace&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Promises and Pitfalls of the Linearized Laplace in Bayesian Optimization. (arXiv:2304.08309v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#21270;Laplace&#36924;&#36817;(LLA)&#22312;Bayesian optimization&#20013;&#30340;&#24212;&#29992;&#12290;&#34429;&#28982;LLA&#22312;&#26500;&#24314;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26102;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#65292;&#20294;&#26159;&#22312;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#38656;&#35201;&#32771;&#34385;&#20854;&#21487;&#33021;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#21270;Laplace&#36924;&#36817;(LLA)&#24050;&#34987;&#35777;&#26126;&#22312;&#26500;&#24314;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26102;&#26377;&#25928;&#19988;&#39640;&#25928;&#12290;&#23427;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#20855;&#26377;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#26368;&#22823;&#21518;&#39564;&#39044;&#27979;&#20989;&#25968;&#26368;&#22823;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24179;&#22343;&#20989;&#25968;&#65292;&#24182;&#19988;&#30001;&#32463;&#39564;&#31070;&#32463;&#26354;&#38754;&#26680;&#35825;&#23548;&#30340;&#21327;&#26041;&#24046;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24050;&#32463;&#30740;&#31350;&#36807;&#20854;&#22312;&#22270;&#20687;&#20998;&#31867;&#31561;&#22823;&#35268;&#27169;&#20219;&#21153;&#20013;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;&#35832;&#22914;Bayesian optimization&#36825;&#26679;&#30340;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#20013;&#23578;&#26410;&#23545;&#20854;&#36827;&#34892;&#30740;&#31350;&#65292;&#20854;&#20013;&#39640;&#26031;&#36807;&#31243;&#26159;&#40664;&#35748;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#20855;&#26377;&#31616;&#21333;&#30340;&#24179;&#22343;&#20989;&#25968;&#21644;&#26680;&#20989;&#25968;&#65292;&#20363;&#22914;&#24452;&#21521;&#22522;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLA&#22312;Bayesian optimization&#20013;&#30340;&#26377;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#24378;&#35843;&#20854;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21487;&#33021;&#20986;&#29616;&#30340;&#19968;&#20123;&#38382;&#39064;&#21644;&#19968;&#20010;LLA&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#21363;&#24403;&#25628;&#32034;&#31354;&#38388;&#26159;&#26080;&#30028;&#30340;&#26102;&#20505;&#12290;
&lt;/p&gt;
&lt;p&gt;
The linearized-Laplace approximation (LLA) has been shown to be effective and efficient in constructing Bayesian neural networks. It is theoretically compelling since it can be seen as a Gaussian process posterior with the mean function given by the neural network's maximum-a-posteriori predictive function and the covariance function induced by the empirical neural tangent kernel. However, while its efficacy has been studied in large-scale tasks like image classification, it has not been studied in sequential decision-making problems like Bayesian optimization where Gaussian processes -- with simple mean functions and kernels such as the radial basis function -- are the de-facto surrogate models. In this work, we study the usefulness of the LLA in Bayesian optimization and highlight its strong performance and flexibility. However, we also present some pitfalls that might arise and a potential problem with the LLA when the search space is unbounded.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#20998;&#35299;PC&#30340;&#34920;&#31034;&#27861;md-vtrees&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#36825;&#31181;&#34920;&#31034;&#27861;&#30340;PC&#26550;&#26500;MDNets&#65292;&#39318;&#27425;&#25512;&#23548;&#20986;&#20102;&#36739;&#20026;&#39640;&#25928;&#30340;&#22522;&#20110;PC&#30340;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.08278</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#22788;&#29702;&#30005;&#36335;&#27169;&#22411;&#36827;&#34892;&#32452;&#21512;&#27010;&#29575;&#21644;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Compositional Probabilistic and Causal Inference using Tractable Circuit Models. (arXiv:2304.08278v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#20998;&#35299;PC&#30340;&#34920;&#31034;&#27861;md-vtrees&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#36825;&#31181;&#34920;&#31034;&#27861;&#30340;PC&#26550;&#26500;MDNets&#65292;&#39318;&#27425;&#25512;&#23548;&#20986;&#20102;&#36739;&#20026;&#39640;&#25928;&#30340;&#22522;&#20110;PC&#30340;&#22240;&#26524;&#25512;&#26029;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#30005;&#36335; (Probabilistic circuits, PCs) &#26159;&#19968;&#31867;&#21487;&#22788;&#29702;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#20855;&#26377;&#39640;&#25928;&#30340;&#25512;&#26029;&#20363;&#31243;&#65292;&#21462;&#20915;&#20110;&#23427;&#20204;&#30340;&#32467;&#26500;&#23646;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102; md-vtrees&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#32467;&#26500;&#21270;&#20998;&#35299; PC &#20013;&#65288;&#36793;&#32536;&#65289;&#20915;&#23450;&#35770;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#23427;&#25512;&#24191;&#20102;&#20808;&#21069;&#25552;&#20986;&#30340;&#31867;&#21035;&#65292;&#20363;&#22914;&#27010;&#29575;&#31526;&#21495;&#20915;&#31574;&#22270;&#12290;&#20851;&#38190;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#21512;&#29702;&#21644;&#21487;&#25512;&#24191;&#30340;&#26041;&#24335;&#20013;&#20351;&#29992; md-vtrees &#25512;&#23548;&#20986;&#21487;&#22788;&#29702;&#30340;&#26465;&#20214;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#34920;&#31034;&#22522;&#26412;&#27010;&#29575;&#25805;&#20316;&#30340;&#20219;&#24847;&#32452;&#21512;&#65292;&#20363;&#22914;&#36793;&#32536;&#21270;&#12289;&#20056;&#27861;&#21644;&#20498;&#25968;&#31561;&#39640;&#32423;&#25512;&#26029;&#26597;&#35810;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20026;&#22522;&#20110; PC &#30340;&#22240;&#26524;&#25512;&#26029;&#26597;&#35810;&#65292;&#22914;&#21453;&#21521;&#38376;&#25511;&#35843;&#25972; (backdoor adjustment)&#65292;&#25512;&#23548;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#20316;&#20026;&#26694;&#26550;&#30340;&#23454;&#38469;&#23454;&#20363;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; MDNets&#65292;&#36825;&#26159;&#19968;&#31181;&#20351;&#29992; md-vtrees &#30340;&#26032;&#22411; PC &#26550;&#26500;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic circuits (PCs) are a class of tractable probabilistic models, which admit efficient inference routines depending on their structural properties. In this paper, we introduce md-vtrees, a novel structural formulation of (marginal) determinism in structured decomposable PCs, which generalizes previously proposed classes such as probabilistic sentential decision diagrams. Crucially, we show how mdvtrees can be used to derive tractability conditions and efficient algorithms for advanced inference queries expressed as arbitrary compositions of basic probabilistic operations, such as marginalization, multiplication and reciprocals, in a sound and generalizable manner. In particular, we derive the first polytime algorithms for causal inference queries such as backdoor adjustment on PCs. As a practical instantiation of the framework, we propose MDNets, a novel PC architecture using md-vtrees, and empirically demonstrate their application to causal inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;&#39044;&#26399;&#39044;&#27979;&#20449;&#24687;&#22686;&#30410;&#65288;EPIG&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#31354;&#38388;&#32780;&#19981;&#26159;&#21442;&#25968;&#31354;&#38388;&#20013;&#27979;&#37327;&#20449;&#24687;&#22686;&#30410;&#65292;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.08151</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#27979;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Prediction-Oriented Bayesian Active Learning. (arXiv:2304.08151v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#36125;&#21494;&#26031;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#21363;&#39044;&#26399;&#39044;&#27979;&#20449;&#24687;&#22686;&#30410;&#65288;EPIG&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#31354;&#38388;&#32780;&#19981;&#26159;&#21442;&#25968;&#31354;&#38388;&#20013;&#27979;&#37327;&#20449;&#24687;&#22686;&#30410;&#65292;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#35770;&#26041;&#27861;&#36890;&#24120;&#38598;&#20013;&#20110;&#26368;&#22823;&#21270;&#20851;&#20110;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24687;&#65292;&#22312;&#20248;&#21270; BALD &#20998;&#25968;&#26041;&#38754;&#12290;&#25105;&#20204;&#24378;&#35843;&#20174;&#39044;&#27979;&#24615;&#33021;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#21487;&#33021;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#26399;&#39044;&#27979;&#20449;&#24687;&#22686;&#30410;&#65288;EPIG&#65289;&#65292;&#19968;&#31181;&#22312;&#39044;&#27979;&#31354;&#38388;&#32780;&#19981;&#26159;&#21442;&#25968;&#31354;&#38388;&#20013;&#27979;&#37327;&#20449;&#24687;&#22686;&#30410;&#30340;&#25910;&#38598;&#20989;&#25968;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#20351;&#29992; EPIG &#19982; BALD &#30456;&#27604;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#24378;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#22240;&#27492;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information-theoretic approaches to active learning have traditionally focused on maximising the information gathered about the model parameters, most commonly by optimising the BALD score. We highlight that this can be suboptimal from the perspective of predictive performance. For example, BALD lacks a notion of an input distribution and so is prone to prioritise data of limited relevance. To address this we propose the expected predictive information gain (EPIG), an acquisition function that measures information gain in the space of predictions rather than parameters. We find that using EPIG leads to stronger predictive performance compared with BALD across a range of datasets and models, and thus provides an appealing drop-in replacement.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#36229;&#22270;&#20013;&#26816;&#27979;&#23494;&#38598;&#23376;&#36229;&#22270;&#30340;&#23384;&#22312;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#26131;&#20110;&#23454;&#29616;&#21644;&#22256;&#38590;&#30340;&#38382;&#39064;&#20043;&#38388;&#30340;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2304.08135</link><description>&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#26816;&#27979;&#23494;&#38598;&#23376;&#36229;&#22270;
&lt;/p&gt;
&lt;p&gt;
Detection of Dense Subhypergraphs by Low-Degree Polynomials. (arXiv:2304.08135v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08135
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#36229;&#22270;&#20013;&#26816;&#27979;&#23494;&#38598;&#23376;&#36229;&#22270;&#30340;&#23384;&#22312;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#26131;&#20110;&#23454;&#29616;&#21644;&#22256;&#38590;&#30340;&#38382;&#39064;&#20043;&#38388;&#30340;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#22270;&#20013;&#25506;&#27979;&#19968;&#20010;&#34987;&#23433;&#32622;&#30340;&#23494;&#38598;&#23376;&#22270;&#26159;&#19968;&#20010;&#22522;&#26412;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#38382;&#39064;&#65292;&#36817;&#24180;&#26469;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#35813;&#38382;&#39064;&#30340;&#19968;&#20010;&#36229;&#22270;&#29256;&#26412;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#19968;&#20010;$G^r(n, n^{-\beta})$&#30340;&#36229;&#22270;&#20013;&#25506;&#27979;&#19968;&#20010;&#34987;&#23433;&#32622;&#30340;$G^r(n^\gamma, n^{-\alpha})$&#30340;&#23494;&#38598;&#23376;&#36229;&#22270;&#30340;&#23384;&#22312;&#65292;&#20854;&#20013;$0&lt;\alpha&lt;\beta&lt;r-1$ and $0&lt;\gamma&lt;1$&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#36890;&#36807;&#37051;&#25509;&#24352;&#37327;&#30340;$n^{o(1)}$&#27425;&#22810;&#39033;&#24335;&#30340;&#27979;&#35797;&#26131;&#20110;&#23454;&#29616;&#21644;&#22256;&#38590;&#30340;&#38382;&#39064;&#20043;&#38388;&#30340;&#38408;&#20540;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24050;&#32463;&#26159;$r=2$&#30340;&#22270;&#24773;&#24418;&#20013;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detection of a planted dense subgraph in a random graph is a fundamental statistical and computational problem that has been extensively studied in recent years. We study a hypergraph version of the problem. Let $G^r(n,p)$ denote the $r$-uniform Erd\H{o}s-R\'enyi hypergraph model with $n$ vertices and edge density $p$. We consider detecting the presence of a planted $G^r(n^\gamma, n^{-\alpha})$ subhypergraph in a $G^r(n, n^{-\beta})$ hypergraph, where $0&lt; \alpha &lt; \beta &lt; r-1$ and $0 &lt; \gamma &lt; 1$. Focusing on tests that are degree-$n^{o(1)}$ polynomials of the entries of the adjacency tensor, we determine the threshold between the easy and hard regimes for the detection problem. More precisely, for $0 &lt; \gamma &lt; 1/2$, the threshold is given by $\alpha = \beta \gamma$, and for $1/2 \le \gamma &lt; 1$, the threshold is given by $\alpha = \beta/2 + r(\gamma - 1/2)$.  Our results are already new in the graph case $r=2$, as we consider the subtle log-density regime where hardness based on ave
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102; Fed-MIWAE&#65292;&#36825;&#26159;&#22522;&#20110;&#32852;&#37030;&#27169;&#22411;&#30340; MIWAE &#32570;&#22833;&#25968;&#25454;&#22635;&#34917;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#36890;&#36807;&#32463;&#20856;&#32852;&#37030;&#32858;&#21512;&#22120;&#36827;&#34892;&#31616;&#21333;&#35757;&#32451;&#65292;&#24182;&#20855;&#26377;&#22788;&#29702; MAR &#25968;&#25454;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.08054</link><description>&lt;p&gt;
Fed-MIWAE: &#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#32852;&#37030;&#22635;&#34917;&#26410;&#23436;&#25972;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Fed-MIWAE: Federated Imputation of Incomplete Data via Deep Generative Models. (arXiv:2304.08054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102; Fed-MIWAE&#65292;&#36825;&#26159;&#22522;&#20110;&#32852;&#37030;&#27169;&#22411;&#30340; MIWAE &#32570;&#22833;&#25968;&#25454;&#22635;&#34917;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#23427;&#33021;&#22815;&#36890;&#36807;&#32463;&#20856;&#32852;&#37030;&#32858;&#21512;&#22120;&#36827;&#34892;&#31616;&#21333;&#35757;&#32451;&#65292;&#24182;&#20855;&#26377;&#22788;&#29702; MAR &#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#20801;&#35768;&#22312;&#19981;&#38656;&#35201;&#26126;&#30830;&#25968;&#25454;&#20132;&#25442;&#30340;&#24773;&#20917;&#19979;&#23545;&#22810;&#20010;&#20998;&#25955;&#30340;&#26412;&#22320;&#25968;&#25454;&#38598;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#39044;&#22788;&#29702;&#65292;&#21253;&#25324;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#31574;&#30053;&#65292;&#20173;&#28982;&#26159;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#37096;&#32626;&#20013;&#30340;&#19968;&#20010;&#37325;&#22823;&#29942;&#39048;&#65292;&#24182;&#19988;&#36890;&#24120;&#26159;&#22312;&#26412;&#22320;&#25191;&#34892;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32852;&#37030;&#27169;&#22411;&#26356;&#19968;&#33268;&#30340;&#26041;&#27861;&#36827;&#34892;&#25968;&#25454;&#26631;&#20934;&#21270;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; Fed-MIWAE&#65292;&#36825;&#26159; MIWAE &#30340;&#32852;&#37030;&#29256;&#26412;&#65292;&#23427;&#26159;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32570;&#22833;&#25968;&#25454;&#22635;&#34917;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#12290;MIWAE &#20855;&#26377;&#20351;&#29992;&#32463;&#20856;&#32852;&#37030;&#32858;&#21512;&#22120;&#36827;&#34892;&#31616;&#21333;&#35757;&#32451;&#30340;&#24040;&#22823;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#23427;&#33021;&#22815;&#22788;&#29702; MAR&#65288;&#38543;&#26426;&#26410;&#20986;&#29616;&#65289;&#25968;&#25454;&#65292;&#36825;&#26159;&#19968;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#32570;&#22833;&#25968;&#25454;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning allows for the training of machine learning models on multiple decentralized local datasets without requiring explicit data exchange. However, data pre-processing, including strategies for handling missing data, remains a major bottleneck in real-world federated learning deployment, and is typically performed locally. This approach may be biased, since the subpopulations locally observed at each center may not be representative of the overall one. To address this issue, this paper first proposes a more consistent approach to data standardization through a federated model. Additionally, we propose Fed-MIWAE, a federated version of the state-of-the-art imputation method MIWAE, a deep latent variable model for missing data imputation based on variational autoencoders. MIWAE has the great advantage of being easily trainable with classical federated aggregators. Furthermore, it is able to deal with MAR (Missing At Random) data, a more challenging missing-data mechanism th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;INDEED&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#30340;&#25805;&#20316;&#31526;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#19988;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2304.07993</link><description>&lt;p&gt;
&#20869;&#22312;&#19978;&#19979;&#25991;&#31639;&#23376;&#23398;&#20064;&#29992;&#20110;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
In-Context Operator Learning for Differential Equation Problems. (arXiv:2304.07993v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;INDEED&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#30340;&#25805;&#20316;&#31526;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#19988;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#8212;&#8212;IN-context Differential Equation Encoder-Decoder&#65288;INDEED&#65289;&#65292;&#29992;&#20110;&#20174;&#25968;&#25454;&#20013;&#21516;&#26102;&#23398;&#20064;&#25805;&#20316;&#31526;&#24182;&#22312;&#25512;&#29702;&#38454;&#27573;&#23558;&#20854;&#24212;&#29992;&#20110;&#26032;&#38382;&#39064;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#26435;&#37325;&#26356;&#26032;&#12290;&#29616;&#26377;&#26041;&#27861;&#23616;&#38480;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36924;&#36817;&#29305;&#23450;&#30340;&#26041;&#31243;&#35299;&#25110;&#29305;&#23450;&#30340;&#25805;&#20316;&#31526;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#26041;&#31243;&#30340;&#26032;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25805;&#20316;&#31526;&#23398;&#20064;&#22120;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#25670;&#33073;&#20026;&#26032;&#38382;&#39064;&#37325;&#26032;&#35757;&#32451;&#65288;&#29978;&#33267;&#24494;&#35843;&#65289;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#25200;&#65292;&#36824;&#21487;&#20197;&#21033;&#29992;&#25805;&#20316;&#31526;&#20043;&#38388;&#20849;&#20139;&#30340;&#20849;&#21516;&#28857;&#65292;&#36825;&#26679;&#22312;&#23398;&#20064;&#26032;&#30340;&#25805;&#20316;&#31526;&#26102;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#21363;&#21487;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#23569;&#26679;&#26412;&#23398;&#20064;&#22120;&#30340;&#33021;&#21147;&#65292;&#29992;&#20110;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#65292;&#21253;&#25324;ODE&#21644;PDE&#30340;&#27491;&#21521;&#21644;&#21453;&#21521;&#38382;&#39064;&#65292;&#21516;&#26102;&#26174;&#31034;&#23427;&#21487;&#20197;&#25512;&#24191;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new neural-network-based approach, namely IN-context Differential Equation Encoder-Decoder (INDEED), to simultaneously learn operators from data and apply it to new questions during the inference stage, without any weight update. Existing methods are limited to using a neural network to approximate a specific equation solution or a specific operator, requiring retraining when switching to a new problem with different equations. By training a single neural network as an operator learner, we can not only get rid of retraining (even fine-tuning) the neural network for new problems, but also leverage the commonalities shared across operators so that only a few demos are needed when learning a new operator. Our numerical results show the neural network's capability as a few-shot operator learner for a diversified type of differential equation problems, including forward and inverse problems of ODEs and PDEs, and also show that it can generalize its learning capabilit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25299;&#23637;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#30340;&#26399;&#26395;&#19968;&#33324;&#20449;&#24687;&#22686;&#30410;&#21644;&#26399;&#26395;&#37492;&#21035;&#20449;&#24687;&#20316;&#20026;&#20934;&#21017;&#65292;&#29992;&#26469;&#24230;&#37327;&#27169;&#22411;&#24046;&#24322;&#31283;&#20581;&#24615;&#21644;&#23454;&#39564;&#26816;&#27979;&#27169;&#22411;&#24046;&#24322;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.07949</link><description>&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Metrics for Bayesian Optimal Experiment Design under Model Misspecification. (arXiv:2304.07949v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25299;&#23637;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#30340;&#26399;&#26395;&#19968;&#33324;&#20449;&#24687;&#22686;&#30410;&#21644;&#26399;&#26395;&#37492;&#21035;&#20449;&#24687;&#20316;&#20026;&#20934;&#21017;&#65292;&#29992;&#26469;&#24230;&#37327;&#27169;&#22411;&#24046;&#24322;&#31283;&#20581;&#24615;&#21644;&#23454;&#39564;&#26816;&#27979;&#27169;&#22411;&#24046;&#24322;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#23454;&#39564;&#35774;&#35745;&#30340;&#20256;&#32479;&#26041;&#27861;&#26159;&#22312;&#21487;&#33021;&#30340;&#23454;&#39564;&#20013;&#25628;&#32034;&#65292;&#20197;&#36873;&#25321;&#26368;&#22823;&#21270;&#25351;&#23450;&#25928;&#29992;&#20989;&#25968;&#30340;&#35774;&#35745;&#12290;&#26399;&#26395;&#26159;&#23545;&#25152;&#37319;&#38598;&#25968;&#25454;&#30340;&#32479;&#35745;&#27169;&#22411;&#25152;&#34164;&#21547;&#30340;&#25152;&#26377;&#26410;&#30693;&#21464;&#37327;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#25928;&#29992;&#20989;&#25968;&#23450;&#20041;&#20102;&#23454;&#39564;&#30340;&#30446;&#26631;&#65292;&#20854;&#20013;&#24120;&#35265;&#30340;&#25928;&#29992;&#20989;&#25968;&#26159;&#20449;&#24687;&#22686;&#30410;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#36229;&#36234;&#20102;&#20256;&#32479;&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#20934;&#21017;&#65292;&#24182;&#24341;&#20837;&#20102;&#27979;&#37327;&#27169;&#22411;&#24046;&#24322;&#31283;&#20581;&#24615;&#30340;&#26399;&#26395;&#19968;&#33324;&#20449;&#24687;&#22686;&#30410;&#21644;&#37327;&#21270;&#23454;&#39564;&#26816;&#27979;&#27169;&#22411;&#24046;&#24322;&#33021;&#21147;&#30340;&#26399;&#26395;&#37492;&#21035;&#20449;&#24687;&#20316;&#20026;&#20934;&#21017;&#12290;&#35813;&#26694;&#26550;&#30340;&#21151;&#33021;&#36890;&#36807;&#20854;&#22312;&#28041;&#21450;&#32447;&#24615;&#24377;&#31783;&#36136;&#37327;&#38459;&#23612;&#31995;&#32479;&#21644;F-16&#27169;&#22411;&#30340;&#24773;&#26223;&#20013;&#30340;&#24212;&#29992;&#36827;&#34892;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
The conventional approach to Bayesian decision-theoretic experiment design involves searching over possible experiments to select a design that maximizes the expected value of a specified utility function. The expectation is over the joint distribution of all unknown variables implied by the statistical model that will be used to analyze the collected data. The utility function defines the objective of the experiment where a common utility function is the information gain. This article introduces an expanded framework for this process, where we go beyond the traditional Expected Information Gain criteria and introduce the Expected General Information Gain which measures robustness to the model discrepancy and Expected Discriminatory Information as a criterion to quantify how well an experiment can detect model discrepancy. The functionality of the framework is showcased through its application to a scenario involving a linearized spring mass damper system and an F-16 model where the mo
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27010;&#29575;&#30340; 3D &#24863;&#30693; 2D &#22270;&#20687;&#29983;&#25104;&#27169;&#22411; NeRF-LEBM&#65292;&#23427;&#32467;&#21512; NeRF &#21644;&#21487;&#24494;&#20998;&#20307;&#31215;&#28210;&#26579;&#23454;&#29616;&#20102; 3D &#34920;&#31034;&#24182;&#20837; 2D &#25104;&#20687;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25512;&#26029;&#21644;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#27169;&#22411;&#33021;&#22815;&#20174; 2D &#22270;&#20687;&#20013;&#25512;&#26029;&#20986; 3D &#23545;&#35937;&#32467;&#26500;&#65292;&#29983;&#25104;&#20855;&#26377;&#26032;&#35270;&#35282;&#21644;&#23545;&#35937;&#30340; 2D &#22270;&#20687;&#65292;&#23398;&#20064;&#19981;&#23436;&#25972;&#30340; 2D &#22270;&#20687;&#65292;&#20197;&#21450;&#20174;&#24050;&#30693;&#25110;&#26410;&#30693;&#30456;&#26426;&#23039;&#21183;&#30340; 2D &#22270;&#20687;&#20013;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2304.07918</link><description>&lt;p&gt;
&#22522;&#20110;&#27010;&#29575;&#30340;&#21019;&#26032;&#36752;&#23556;&#22330;&#21644;&#20855;&#26377;&#28508;&#22312;&#31354;&#38388;&#33021;&#37327;&#27169;&#22411;&#30340; 3D &#24863;&#30693;&#35299;&#32806;&#22270;&#20687;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Likelihood-Based Generative Radiance Field with Latent Space Energy-Based Model for 3D-Aware Disentangled Image Representation. (arXiv:2304.07918v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07918
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27010;&#29575;&#30340; 3D &#24863;&#30693; 2D &#22270;&#20687;&#29983;&#25104;&#27169;&#22411; NeRF-LEBM&#65292;&#23427;&#32467;&#21512; NeRF &#21644;&#21487;&#24494;&#20998;&#20307;&#31215;&#28210;&#26579;&#23454;&#29616;&#20102; 3D &#34920;&#31034;&#24182;&#20837; 2D &#25104;&#20687;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25512;&#26029;&#21644;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#27169;&#22411;&#33021;&#22815;&#20174; 2D &#22270;&#20687;&#20013;&#25512;&#26029;&#20986; 3D &#23545;&#35937;&#32467;&#26500;&#65292;&#29983;&#25104;&#20855;&#26377;&#26032;&#35270;&#35282;&#21644;&#23545;&#35937;&#30340; 2D &#22270;&#20687;&#65292;&#23398;&#20064;&#19981;&#23436;&#25972;&#30340; 2D &#22270;&#20687;&#65292;&#20197;&#21450;&#20174;&#24050;&#30693;&#25110;&#26410;&#30693;&#30456;&#26426;&#23039;&#21183;&#30340; 2D &#22270;&#20687;&#20013;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181; NeRF-LEBM&#65292;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#33258;&#39030;&#21521;&#19979; 3D &#24863;&#30693; 2D &#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#31070;&#32463;&#36752;&#23556;&#22330; (NeRF) &#21644;&#21487;&#24494;&#20998;&#20307;&#31215;&#28210;&#26579;&#23558; 3D &#34920;&#31034;&#24182;&#20837; 2D &#25104;&#20687;&#36807;&#31243;&#12290;&#35813;&#27169;&#22411;&#23558;&#22270;&#20687;&#34920;&#31034;&#20026;&#20174; 3D &#23545;&#35937;&#21040; 2D &#22270;&#20687;&#30340;&#28210;&#26579;&#36807;&#31243;&#65292;&#26465;&#20214;&#26159;&#19968;&#20123;&#20195;&#34920;&#23545;&#35937;&#29305;&#24449;&#30340;&#28508;&#21464;&#37327;&#65292;&#20551;&#35774;&#23427;&#20204;&#36981;&#24490;&#20449;&#24687;&#21487;&#35757;&#32451;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#20808;&#39564;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#23398;&#20064;&#26694;&#26550;&#26469;&#35757;&#32451; NeRF-LEBM&#65306;(i)&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25512;&#26029;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;(ii)&#21464;&#20998;&#25512;&#26029;&#21644;&#37325;&#21442;&#25968;&#21270;&#25216;&#24039;&#12290;&#25105;&#20204;&#22312;&#24050;&#30693;&#21644;&#26410;&#30693;&#30456;&#26426;&#23039;&#21183;&#30340;&#22330;&#26223;&#20013;&#30740;&#31350;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;NeRF-LEBM &#21487;&#20197;&#20174; 2D &#22270;&#20687;&#20013;&#25512;&#26029;&#20986; 3D &#23545;&#35937;&#32467;&#26500;&#65292;&#29983;&#25104;&#20855;&#26377;&#26032;&#35270;&#35282;&#21644;&#23545;&#35937;&#30340; 2D &#22270;&#20687;&#65292;&#20174;&#19981;&#23436;&#25972;&#30340; 2D &#22270;&#20687;&#20013;&#23398;&#20064;&#65292;&#20197;&#21450;&#20174;&#24050;&#30693;&#25110;&#26410;&#30693;&#30456;&#26426;&#23039;&#21183;&#30340; 2D &#22270;&#20687;&#20013;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose the NeRF-LEBM, a likelihood-based top-down 3D-aware 2D image generative model that incorporates 3D representation via Neural Radiance Fields (NeRF) and 2D imaging process via differentiable volume rendering. The model represents an image as a rendering process from 3D object to 2D image and is conditioned on some latent variables that account for object characteristics and are assumed to follow informative trainable energy-based prior models. We propose two likelihood-based learning frameworks to train the NeRF-LEBM: (i) maximum likelihood estimation with Markov chain Monte Carlo-based inference and (ii) variational inference with the reparameterization trick. We study our models in the scenarios with both known and unknown camera poses. Experiments on several benchmark datasets demonstrate that the NeRF-LEBM can infer 3D object structures from 2D images, generate 2D images with novel views and objects, learn from incomplete 2D images, and learn from 2D images with known or 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#19977;&#31181;Lasso&#25512;&#26029;&#26041;&#27861;&#24212;&#29992;&#20110;&#35843;&#26597;&#25968;&#25454;&#30340;&#25512;&#26029;&#65292;&#35777;&#26126;&#22312;&#20855;&#26377;&#35843;&#26597;&#26435;&#37325;&#21644;/&#25110;&#24322;&#26041;&#24046;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#25512;&#26029;&#31243;&#24207;&#28176;&#36817;&#26377;&#25928;&#24615;&#65292; &#24182;&#23558;&#36825;&#20123;&#26041;&#27861;&#25512;&#24191;&#21040;&#23545;&#38750;&#32447;&#24615;&#21442;&#25968;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#65292;&#20363;&#22914;&#22312;&#35843;&#26597;logit&#27169;&#22411;&#20013;&#30340;&#24179;&#22343;&#36793;&#38469;&#25928;&#24212;</title><link>http://arxiv.org/abs/2304.07855</link><description>&lt;p&gt;
&#35843;&#26597;&#25968;&#25454;&#30340;&#24809;&#32602;&#20284;&#28982;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Penalized Likelihood Inference with Survey Data. (arXiv:2304.07855v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07855
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#19977;&#31181;Lasso&#25512;&#26029;&#26041;&#27861;&#24212;&#29992;&#20110;&#35843;&#26597;&#25968;&#25454;&#30340;&#25512;&#26029;&#65292;&#35777;&#26126;&#22312;&#20855;&#26377;&#35843;&#26597;&#26435;&#37325;&#21644;/&#25110;&#24322;&#26041;&#24046;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#25512;&#26029;&#31243;&#24207;&#28176;&#36817;&#26377;&#25928;&#24615;&#65292; &#24182;&#23558;&#36825;&#20123;&#26041;&#27861;&#25512;&#24191;&#21040;&#23545;&#38750;&#32447;&#24615;&#21442;&#25968;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#65292;&#20363;&#22914;&#22312;&#35843;&#26597;logit&#27169;&#22411;&#20013;&#30340;&#24179;&#22343;&#36793;&#38469;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#19977;&#31181;Lasso&#25512;&#26029;&#26041;&#27861;&#65292;Debiased Lasso&#12289;$C(\alpha)$&#21644;Selective Inference&#25512;&#24191;&#21040;&#35843;&#26597;&#25968;&#25454;&#30340;&#29615;&#22659;&#20013;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#35843;&#26597;&#26435;&#37325;&#21644;/&#25110;&#24322;&#26041;&#24046;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#25512;&#26029;&#31243;&#24207;&#30340;&#28176;&#36817;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#25512;&#24191;&#21040;&#23545;&#38750;&#32447;&#24615;&#21442;&#25968;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#65292;&#20363;&#22914;&#22312;&#35843;&#26597;logit&#27169;&#22411;&#20013;&#30340;&#24179;&#22343;&#36793;&#38469;&#25928;&#24212;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#25968;&#25454;&#21644;&#21152;&#25343;&#22823;2020&#24180;&#20114;&#32852;&#32593;&#20351;&#29992;&#35843;&#26597;&#25968;&#25454;&#26469;&#35828;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper extends three Lasso inferential methods, Debiased Lasso, $C(\alpha)$ and Selective Inference to a survey environment. We establish the asymptotic validity of the inference procedures in generalized linear models with survey weights and/or heteroskedasticity. Moreover, we generalize the methods to inference on nonlinear parameter functions e.g. the average marginal effect in survey logit models. We illustrate the effectiveness of the approach in simulated data and Canadian Internet Use Survey 2020 data.
&lt;/p&gt;</description></item><item><title>Data-OOB&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;out-of-bag&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.07718</link><description>&lt;p&gt;
Data-OOB:&#20197;&#26080;&#38656;&#39069;&#22806;&#35745;&#31639;&#30340;Out-of-bag&#20272;&#35745;&#20026;&#20934;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value. (arXiv:2304.07718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07718
&lt;/p&gt;
&lt;p&gt;
Data-OOB&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;out-of-bag&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#35780;&#20272;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20026;&#27169;&#22411;&#35757;&#32451;&#25552;&#20379;&#32479;&#35745;&#27934;&#23519;&#21147;&#65292;&#20197;&#21306;&#20998;&#21738;&#20123;&#25968;&#25454;&#23545;&#20110;&#27169;&#22411;&#35757;&#32451;&#26159;&#26377;&#30410;&#30340;&#65292;&#21738;&#20123;&#26159;&#26377;&#23475;&#30340;&#12290;&#32437;&#35266;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#35768;&#22810;&#20197;Shapley&#20026;&#22522;&#30784;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#22343;&#26174;&#31034;&#20986;&#20102;&#24456;&#26377;&#21069;&#36884;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#38656;&#35201;&#35757;&#32451;&#22823;&#37327;&#30340;&#27169;&#22411;&#65292;&#22240;&#27492;&#20247;&#25152;&#21608;&#30693;&#65292;&#36825;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#23558;&#27492;&#24212;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Data-OOB&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;bagging&#27169;&#22411;&#65292;&#23427;&#21033;&#29992;&#20102;out-of-bag&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#24369;&#23398;&#20064;&#22120;&#26469;&#25193;&#23637;&#21040;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24403;&#35780;&#20272;100&#20010;&#36755;&#20837;&#32500;&#24230;&#19988;&#23384;&#22312;$10^6$&#20010;&#26679;&#26412;&#26102;&#65292;Data-OOB&#20165;&#38656;&#35201;&#22312;&#21333;&#20010;CPU&#22788;&#29702;&#22120;&#19978;&#25191;&#34892;&#19981;&#21040;2.25&#20010;&#23567;&#26102;&#12290;&#27492;&#22806;&#65292;Data-OOB&#22312;&#29702;&#35770;&#19978;&#26377;&#22362;&#23454;&#30340;&#35299;&#37322;&#65292;&#24403;&#20004;&#20010;&#31163;&#24046;&#20540;&#20989;&#25968;&#30456;&#21516;&#26102;&#65292;&#20854;&#35782;&#21035;&#20855;&#26377;&#30456;&#21516;&#37325;&#35201;&#24615;&#30340;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than 2.25 hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is 100. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Deep Metric Learning&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;&#65292;&#33021;&#22815;&#26377;&#25928;&#30340;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07689</link><description>&lt;p&gt;
&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#29992;&#20110;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Deep Metric Learning&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;&#65292;&#33021;&#22815;&#26377;&#25928;&#30340;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25216;&#26415;&#24050;&#24212;&#29992;&#20110;&#21508;&#31181;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#65292;&#36890;&#36807;&#28145;&#24230;&#32593;&#32476;&#23398;&#20064;&#26679;&#26412;&#23884;&#20837;&#26469;&#36827;&#34892;&#35270;&#35273;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#26041;&#27861;&#37319;&#29992;&#22266;&#23450;&#36317;&#31163;&#24230;&#37327;&#20316;&#20026;&#20004;&#20010;&#23884;&#20837;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20989;&#25968;&#65292;&#21487;&#33021;&#23548;&#33268;&#25429;&#25417;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#26368;&#20248;&#24615;&#33021;&#12290;Bregman&#25955;&#24230;&#27010;&#25324;&#20102;&#21508;&#31181;&#36317;&#31163;&#24230;&#37327;&#30340;&#24230;&#37327;&#65292;&#24182;&#22312;&#35768;&#22810;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#39046;&#22495;&#20013;&#20135;&#29983;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#22914;&#20309;&#20174;Bregman&#25955;&#24230;&#33719;&#24471;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25439;&#22833;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#35774;&#32622;&#23545;Bregman&#25955;&#24230;&#19979;&#30340;&#20984;&#20989;&#25968;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#20854;&#20182;SOTA&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20116;&#20010;&#27969;&#34892;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#29305;&#21035;&#26159;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#36125;&#21494;&#26031;&#20998;&#23618;&#24314;&#27169;&#65292;&#21160;&#24577;&#24179;&#34913;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20197;&#26356;&#22909;&#22320;&#26597;&#35810;&#25968;&#25454;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.07665</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#23618;&#24314;&#27169;&#20013;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#20013;&#30340;&#21160;&#24577;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Dynamic Exploration-Exploitation Trade-Off in Active Learning Regression with Bayesian Hierarchical Modeling. (arXiv:2304.07665v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#36125;&#21494;&#26031;&#20998;&#23618;&#24314;&#27169;&#65292;&#21160;&#24577;&#24179;&#34913;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20197;&#26356;&#22909;&#22320;&#26597;&#35810;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#37319;&#26679;&#26368;&#20855;&#20449;&#24687;&#30340;&#23454;&#39564;&#20197;&#23398;&#20064;&#26410;&#30693;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#26694;&#26550;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#20998;&#23618;&#26041;&#27861;&#26469;&#21160;&#24577;&#24179;&#34913;&#25506;&#32034;-&#24320;&#21457;&#26435;&#34913;&#65292;&#20197;&#26356;&#22909;&#22320;&#26597;&#35810;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active learning provides a framework to adaptively sample the most informative experiments towards learning an unknown black-box function. Various approaches of active learning have been proposed in the literature, however, they either focus on exploration or exploitation in the design space. Methods that do consider exploration-exploitation simultaneously employ fixed or ad-hoc measures to control the trade-off that may not be optimal. In this paper, we develop a Bayesian hierarchical approach to dynamically balance the exploration-exploitation trade-off as more data points are queried. We subsequently formulate an approximate Bayesian computation approach based on the linear dependence of data samples in the feature space to sample from the posterior distribution of the trade-off parameter obtained from the Bayesian hierarchical model. Simulated and real-world examples show the proposed approach achieves at least 6% and 11% average improvement when compared to pure exploration and ex
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ProbDR&#21464;&#20998;&#26694;&#26550;&#65292;&#23558;&#32463;&#20856;&#38477;&#32500;&#31639;&#27861;&#35299;&#37322;&#20026;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#23436;&#25104;&#25512;&#26029;&#25805;&#20316;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#21487;&#20197;&#23436;&#25104;&#24120;&#35268;&#38477;&#32500;&#31639;&#27861;&#65292;&#36824;&#25903;&#25345;&#20351;&#29992;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#38477;&#32500;&#25805;&#20316;&#65292;&#20855;&#26377;&#24378;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.07658</link><description>&lt;p&gt;
&#20316;&#20026;&#27010;&#29575;&#25512;&#26029;&#30340;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dimensionality Reduction as Probabilistic Inference. (arXiv:2304.07658v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07658
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ProbDR&#21464;&#20998;&#26694;&#26550;&#65292;&#23558;&#32463;&#20856;&#38477;&#32500;&#31639;&#27861;&#35299;&#37322;&#20026;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#23436;&#25104;&#25512;&#26029;&#25805;&#20316;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#21487;&#20197;&#23436;&#25104;&#24120;&#35268;&#38477;&#32500;&#31639;&#27861;&#65292;&#36824;&#25903;&#25345;&#20351;&#29992;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#38477;&#32500;&#25805;&#20316;&#65292;&#20855;&#26377;&#24378;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#32500;&#31639;&#27861;&#23558;&#39640;&#32500;&#25968;&#25454;&#21387;&#32553;&#21040;&#20302;&#32500;&#34920;&#31034;&#20013;&#65292;&#21516;&#26102;&#20445;&#30041;&#25968;&#25454;&#30340;&#37325;&#35201;&#29305;&#24449;&#12290;&#38477;&#32500;&#26159;&#35768;&#22810;&#20998;&#26512;&#27969;&#31243;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#22240;&#20026;&#23427;&#23454;&#29616;&#20102;&#25968;&#25454;&#30340;&#21487;&#35270;&#21270;&#12289;&#22122;&#22768;&#38477;&#20302;&#21644;&#39640;&#25928;&#30340;&#19979;&#28216;&#22788;&#29702;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ProbDR&#21464;&#20998;&#26694;&#26550;&#65292;&#23558;&#24191;&#27867;&#30340;&#32463;&#20856;DR&#31639;&#27861;&#35299;&#37322;&#20026;&#35813;&#26694;&#26550;&#20013;&#30340;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#12290;ProbDR&#21253;&#25324;PCA&#12289;CMDS&#12289;LLE&#12289;LE&#12289;MVU&#12289;&#25193;&#25955;&#26144;&#23556;&#12289;kPCA&#12289;Isomap&#12289;(t-)SNE&#21644;UMAP&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#19968;&#20010;&#20302;&#32500;&#28508;&#21464;&#37327;&#29992;&#20110;&#26500;&#24314;&#21327;&#26041;&#24046;&#12289;&#31934;&#24230;&#25110;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#21487;&#20197;&#20316;&#20026;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#19968;&#37096;&#20998;&#12290;&#25512;&#26029;&#26159;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#23436;&#25104;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#20869;&#37096;&#19968;&#33268;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#25903;&#25345;&#20351;&#29992;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#65288;PPL&#65289;&#36827;&#34892;DR&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26694;&#26550;&#21487;&#20197;&#23436;&#25104;&#24120;&#35268;DR&#31639;&#27861;&#30340;&#25805;&#20316;&#65292;&#24182;&#36171;&#20104;&#20102;&#23427;&#36890;&#36807;&#27010;&#29575;&#21464;&#20998;&#25512;&#26029;&#30340;&#24378;&#22823;&#34920;&#36798;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimensionality reduction (DR) algorithms compress high-dimensional data into a lower dimensional representation while preserving important features of the data. DR is a critical step in many analysis pipelines as it enables visualisation, noise reduction and efficient downstream processing of the data. In this work, we introduce the ProbDR variational framework, which interprets a wide range of classical DR algorithms as probabilistic inference algorithms in this framework. ProbDR encompasses PCA, CMDS, LLE, LE, MVU, diffusion maps, kPCA, Isomap, (t-)SNE, and UMAP. In our framework, a low-dimensional latent variable is used to construct a covariance, precision, or a graph Laplacian matrix, which can be used as part of a generative model for the data. Inference is done by optimizing an evidence lower bound. We demonstrate the internal consistency of our framework and show that it enables the use of probabilistic programming languages (PPLs) for DR. Additionally, we illustrate that the f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;SVRS&#21644;AccSVRS&#65292;&#38024;&#23545;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#20854;&#20013;&#65292;AccSVRS&#31639;&#27861;&#23454;&#29616;&#20102;&#23436;&#20840;&#26080;&#24179;&#28369;&#24615;&#65292;&#36890;&#20449;&#22797;&#26434;&#24230;&#26356;&#26159;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.07504</link><description>&lt;p&gt;
&#22522;&#20110;&#24179;&#22343;&#20108;&#38454;&#30456;&#20284;&#24615;&#30340;&#38543;&#26426;&#20998;&#24067;&#24335;&#20248;&#21270;&#65306;&#31639;&#27861;&#19982;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;SVRS&#21644;AccSVRS&#65292;&#38024;&#23545;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#20854;&#20013;&#65292;AccSVRS&#31639;&#27861;&#23454;&#29616;&#20102;&#23436;&#20840;&#26080;&#24179;&#28369;&#24615;&#65292;&#36890;&#20449;&#22797;&#26434;&#24230;&#26356;&#26159;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;$n$&#20010;&#23458;&#25143;&#31471;&#30340;&#26377;&#38480;&#21644;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#65292;&#28385;&#36275;&#27969;&#34892;&#30340;$\delta$-&#30456;&#20284;&#24615;&#26465;&#20214;&#21644;$\mu$-&#24378;&#20984;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;&#65306;SVRS&#21644;AccSVRS&#65292;&#21551;&#21457;&#33258;&#20808;&#21069;&#30340;&#24037;&#20316;&#12290;&#38750;&#21152;&#36895;&#30340;SVRS&#26041;&#27861;&#32467;&#21512;&#20102;&#26799;&#24230;&#28369;&#21160;&#21644;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;$\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$&#65292;&#19982;&#29616;&#26377;&#30340;&#38750;&#21152;&#36895;&#31639;&#27861;&#30456;&#27604;&#26377;&#25152;&#25552;&#39640;&#12290;&#24212;&#29992;Katyusha X&#25552;&#20986;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#21517;&#20026;AccSVRS&#30340;&#30452;&#25509;&#21152;&#36895;&#23454;&#38469;&#29256;&#26412;&#65292;&#20854;&#23436;&#20840;&#26080;&#24179;&#28369;&#24615;&#65292;&#36890;&#20449;&#22797;&#26434;&#24230;&#20026;$\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$&#65292;&#22312;&#30149;&#24577;&#24773;&#20917;&#19979;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#25509;&#36817;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#30340;AccSVRS&#26041;&#27861;&#30340;&#32039;&#23494;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study finite-sum distributed optimization problems with $n$-clients under popular $\delta$-similarity condition and $\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SVD-QCQP&#21407;&#22987;&#23545;&#20598;&#31639;&#27861;&#30340;&#39640;&#25928;&#20869;&#26680;&#23398;&#20064;&#23454;&#29616;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#20998;&#31163;&#26680;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.07472</link><description>&lt;p&gt;
&#36890;&#29992;&#26680;&#23398;&#20064;&#30340;&#39640;&#25928;&#20984;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Convex Algorithms for Universal Kernel Learning. (arXiv:2304.07472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SVD-QCQP&#21407;&#22987;&#23545;&#20598;&#31639;&#27861;&#30340;&#39640;&#25928;&#20869;&#26680;&#23398;&#20064;&#23454;&#29616;&#65292;&#29992;&#20110;&#23398;&#20064;&#21322;&#20998;&#31163;&#26680;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26680;&#20248;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#21462;&#20915;&#20110;&#23427;&#20204;&#33021;&#22815;&#20248;&#21270;&#30340;&#26680;&#38598;&#12290;&#29702;&#24819;&#30340;&#26680;&#38598;&#24212;&#35813;&#65306;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21270;&#65288;&#20197;&#20415;&#20110;&#21487;&#22788;&#29702;&#24615;&#65289;&#65307;&#22312;&#25152;&#26377;&#26680;&#38598;&#20013;&#23494;&#38598;&#65288;&#20197;&#20415;&#20110;&#40065;&#26834;&#24615;&#65289;&#65307;&#26159;&#36890;&#29992;&#30340;&#65288;&#20197;&#20415;&#20110;&#20934;&#30830;&#24615;&#65289;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#20351;&#29992;&#27491;&#23450;&#30697;&#38453;&#26469;&#21442;&#25968;&#21270;&#19968;&#31867;&#27491;&#21322;&#20998;&#31163;&#26680;&#12290;&#23613;&#31649;&#27492;&#31867;&#26680;&#33021;&#22815;&#28385;&#36275;&#25152;&#26377;&#19977;&#20010;&#26631;&#20934;&#65292;&#20294;&#20043;&#21069;&#29992;&#20110;&#20248;&#21270;&#27492;&#31867;&#26680;&#30340;&#31639;&#27861;&#20165;&#38480;&#20110;&#20998;&#31867;&#65292;&#24182;&#19988;&#36824;&#20381;&#36182;&#20110;&#35745;&#31639;&#22797;&#26434;&#30340;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23398;&#20064;&#21322;&#20998;&#31163;&#26680;&#30340;&#38382;&#39064;&#20316;&#20026;&#26497;&#23567;&#21270;&#26497;&#22823;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;SVD-QCQP&#21407;&#22987;&#23545;&#20598;&#31639;&#27861;&#65292;&#20854;&#19982;&#20043;&#21069;&#22522;&#20110;SDP&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20869;&#26680;&#23398;&#20064;&#23454;&#29616;&#65292;&#24182;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The accuracy and complexity of machine learning algorithms based on kernel optimization are determined by the set of kernels over which they are able to optimize. An ideal set of kernels should: admit a linear parameterization (for tractability); be dense in the set of all kernels (for robustness); be universal (for accuracy). Recently, a framework was proposed for using positive matrices to parameterize a class of positive semi-separable kernels. Although this class can be shown to meet all three criteria, previous algorithms for optimization of such kernels were limited to classification and furthermore relied on computationally complex Semidefinite Programming (SDP) algorithms. In this paper, we pose the problem of learning semiseparable kernels as a minimax optimization problem and propose a SVD-QCQP primal-dual algorithm which dramatically reduces the computational complexity as compared with previous SDP-based approaches. Furthermore, we provide an efficient implementation of thi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31232;&#30095;&#27491;&#21017;&#21270;&#22312;&#32508;&#21512;&#20998;&#26512;&#20013;&#30340;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#26041;&#27861;&#24320;&#21457;&#20102;&#20854;&#35745;&#31639;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20174;&#22810;&#20010;&#29420;&#31435;&#25968;&#25454;&#38598;&#20013;&#27719;&#38598;&#26377;&#29992;&#20449;&#24687;&#24182;&#27604;&#21333;&#20010;&#25968;&#25454;&#38598;&#20998;&#26512;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.07451</link><description>&lt;p&gt;
&#31232;&#30095;&#27491;&#21017;&#21270;&#22312;&#32508;&#21512;&#20998;&#26512;&#20013;&#30340;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Multivariate regression modeling in integrative analysis via sparse regularization. (arXiv:2304.07451v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31232;&#30095;&#27491;&#21017;&#21270;&#22312;&#32508;&#21512;&#20998;&#26512;&#20013;&#30340;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#26041;&#27861;&#24320;&#21457;&#20102;&#20854;&#35745;&#31639;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#21487;&#20174;&#22810;&#20010;&#29420;&#31435;&#25968;&#25454;&#38598;&#20013;&#27719;&#38598;&#26377;&#29992;&#20449;&#24687;&#24182;&#27604;&#21333;&#20010;&#25968;&#25454;&#38598;&#20998;&#26512;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#22238;&#24402;&#27169;&#22411;&#22522;&#26412;&#19978;&#25552;&#20379;&#20102;&#23545;&#20855;&#26377;&#22810;&#20010;&#21709;&#24212;&#30340;&#21333;&#20010;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#12290;&#20294;&#26159;&#65292;&#36825;&#31181;&#21333;&#19968;&#25968;&#25454;&#38598;&#20998;&#26512;&#36890;&#24120;&#20250;&#23548;&#33268;&#20196;&#20154;&#19981;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#32508;&#21512;&#20998;&#26512;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20174;&#22810;&#20010;&#29420;&#31435;&#25968;&#25454;&#38598;&#20013;&#27719;&#38598;&#26377;&#29992;&#20449;&#24687;&#65292;&#24182;&#27604;&#21333;&#20010;&#25968;&#25454;&#38598;&#20998;&#26512;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20803;&#22238;&#24402;&#24314;&#27169;&#30340;&#32508;&#21512;&#20998;&#26512;&#26041;&#27861;&#12290;&#38598;&#25104;&#26159;&#36890;&#36807;&#31232;&#30095;&#20272;&#35745;&#23454;&#29616;&#30340;&#65292;&#35813;&#20272;&#35745;&#25191;&#34892;&#21464;&#37327;&#21644;&#32452;&#36873;&#25321;&#12290;&#22522;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#26041;&#27861;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20854;&#35745;&#31639;&#31639;&#27861;&#65292;&#21487;&#20139;&#26377;&#25910;&#25947;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#21644;&#20998;&#26512;&#24102;&#26377;&#24494;&#29983;&#29289;&#27979;&#37327;&#20540;&#30340;&#24223;&#27700;&#22788;&#29702;&#25968;&#25454;&#26469;&#21152;&#20197;&#35770;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The multivariate regression model basically offers the analysis of a single dataset with multiple responses. However, such a single-dataset analysis often leads to unsatisfactory results. Integrative analysis is an effective method to pool useful information from multiple independent datasets and provides better performance than single-dataset analysis. In this study, we propose a multivariate regression modeling in integrative analysis. The integration is achieved by sparse estimation that performs variable and group selection. Based on the idea of alternating direction method of multipliers, we develop its computational algorithm that enjoys the convergence property. The performance of the proposed method is demonstrated through Monte Carlo simulation and analyzing wastewater treatment data with microbe measurements.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#32467;&#26500;&#26469;&#22788;&#29702;&#26410;&#30693;&#20195;&#29702;&#22870;&#21169;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#26159;&#28176;&#36827;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2304.07407</link><description>&lt;p&gt;
&#26410;&#35266;&#27979;&#21040;&#20195;&#29702;&#22870;&#21169;&#30340;&#37325;&#22797;&#36127;&#36131;&#20154;&#20195;&#29702;&#21338;&#24328;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents. (arXiv:2304.07407v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21033;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#32467;&#26500;&#26469;&#22788;&#29702;&#26410;&#30693;&#20195;&#29702;&#22870;&#21169;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#26159;&#28176;&#36827;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#20013;&#30340;&#37325;&#22797;&#36127;&#36131;&#20154;&#20195;&#29702;&#21338;&#24328;&#22330;&#26223;&#65292;&#20854;&#20013;&#20195;&#29702;&#36873;&#25321;&#19968;&#31181;&#32769;&#34382;&#26426;&#21518;&#20250;&#33719;&#24471;&#22870;&#21169;&#21644;&#28608;&#21169;&#65292;&#20294;&#36127;&#36131;&#20154;&#21482;&#33021;&#35266;&#23519;&#21040;&#20195;&#29702;&#36873;&#25321;&#20102;&#21738;&#20010;&#32769;&#34382;&#26426;&#20197;&#21450;&#20195;&#29702;&#30456;&#24212;&#30340;&#28608;&#21169;&#65292;&#32780;&#24819;&#35201;&#35774;&#35745;&#19968;&#31181;&#21512;&#36866;&#30340;&#31574;&#30053;&#21364;&#20805;&#28385;&#20102;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#33218;&#32769;&#34382;&#26426;&#26694;&#26550;&#32467;&#26500;&#26469;&#22788;&#29702;&#26410;&#30693;&#20195;&#29702;&#22870;&#21169;&#30340;&#31574;&#30053;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#26159;&#28176;&#36827;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by a number of real-world applications from domains like healthcare and sustainable transportation, in this paper we study a scenario of repeated principal-agent games within a multi-armed bandit (MAB) framework, where: the principal gives a different incentive for each bandit arm, the agent picks a bandit arm to maximize its own expected reward plus incentive, and the principal observes which arm is chosen and receives a reward (different than that of the agent) for the chosen arm. Designing policies for the principal is challenging because the principal cannot directly observe the reward that the agent receives for their chosen actions, and so the principal cannot directly learn the expected reward using existing estimation techniques. As a result, the problem of designing policies for this scenario, as well as similar ones, remains mostly unexplored. In this paper, we construct a policy that achieves a low regret (i.e., square-root regret up to a log factor) in this scenar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;P300 BCI&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;GLASS&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;&#33041;&#26426;&#25509;&#21475;&#24212;&#29992;&#20013;&#25968;&#25454;&#38598;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#21644;&#26131;&#20110;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07401</link><description>&lt;p&gt;
&#22522;&#20110;GLASS&#27169;&#22411;&#30340;&#33041;&#26426;&#25509;&#21475;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference on Brain-Computer Interface using the GLASS Model. (arXiv:2304.07401v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;P300 BCI&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;GLASS&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;&#33041;&#26426;&#25509;&#21475;&#24212;&#29992;&#20013;&#25968;&#25454;&#38598;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#21644;&#26131;&#20110;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33041;&#26426;&#25509;&#21475;&#65288;BCI&#65289;&#20351;&#37325;&#24230;&#27531;&#30142;&#20154;&#22763;&#19982;&#19990;&#30028;&#36827;&#34892;&#20132;&#27969;&#12290;BCI&#23558;&#23454;&#26102;&#30340;&#33041;&#27963;&#21160;&#36716;&#21270;&#20026;&#35745;&#31639;&#26426;&#25351;&#20196;&#65292;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#20998;&#31867;&#38382;&#39064;&#65292;&#35745;&#31639;&#31070;&#32463;&#31185;&#23398;&#25552;&#20379;&#20102;&#26426;&#36935;&#21644;&#25361;&#25112;&#12290;&#26412;&#25991;&#38598;&#20013;&#22312;&#20351;&#29992;&#20107;&#20214;&#30456;&#20851;&#30005;&#20301;&#65288;ERP&#65289;BCI&#35774;&#35745;&#30340;P300 BCI&#19978;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20855;&#26377;&#31232;&#30095;&#26102;&#21464;&#25928;&#24212;&#30340;&#39640;&#26031;&#28508;&#22312;&#32452;&#27169;&#22411;&#65288;GLASS&#65289;&#65292;&#29992;&#20110;&#22312;P300 BCI&#19978;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;GLASS&#37319;&#29992;&#22810;&#39033;&#24335;&#22238;&#24402;&#26694;&#26550;&#65292;&#30452;&#25509;&#35299;&#20915;&#20102;BCI&#24212;&#29992;&#20013;&#30340;&#25968;&#25454;&#38598;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;&#20808;&#39564;&#35268;&#33539;&#20419;&#36827;&#20102;i&#65289;&#20351;&#29992;&#36719;&#38408;&#20540;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#22122;&#22768;&#38477;&#20302;&#65292;ii&#65289;&#20351;&#29992;&#20840;&#23616;&#25910;&#32553;&#23545;&#26102;&#21464;&#25928;&#24212;&#36827;&#34892;&#24179;&#28369;&#22788;&#29702;&#65292;iii&#65289;&#23545;&#28508;&#22312;&#32452;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#20943;&#36731;EEG&#25968;&#25454;&#30340;&#39640;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#22270;&#27169;&#22411;&#31639;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#35745;&#31639;&#21644;&#27169;&#22411;&#36873;&#25321;&#12290;&#25152;&#25552;&#20986;&#30340;GLASS&#27169;&#22411;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#25152;&#25512;&#26029;&#30340;&#26465;&#20214;&#30456;&#20851;&#26102;&#31354;&#27169;&#24335;&#30340;&#26131;&#20110;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The brain-computer interface (BCI) enables individuals with severe physical impairments to communicate with the world. BCIs offer computational neuroscience opportunities and challenges in converting real-time brain activities to computer commands and are typically framed as a classification problem. This article focuses on the P300 BCI that uses the event-related potential (ERP) BCI design, where the primary challenge is classifying target/non-target stimuli. We develop a novel Gaussian latent group model with sparse time-varying effects (GLASS) for making Bayesian inferences on the P300 BCI. GLASS adopts a multinomial regression framework that directly addresses the dataset imbalance in BCI applications. The prior specifications facilitate i) feature selection and noise reduction using soft-thresholding, ii) smoothing of the time-varying effects using global shrinkage, and iii) clustering of latent groups to alleviate high spatial correlations of EEG data. We develop an efficient gra
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#22810;&#20219;&#21153;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#25193;&#25955;&#31639;&#27861;&#30340;&#25512;&#24191;&#65292;&#24182;&#22312;&#32593;&#32476;&#20013;&#36827;&#34892;&#23376;&#31354;&#38388;&#32422;&#26463;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#36817;&#20284;&#25237;&#24433;&#30340;&#26041;&#27861;&#65292;&#20854;&#24615;&#33021;&#24471;&#21040;&#20102;&#26126;&#26174;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2304.07358</link><description>&lt;p&gt;
&#20998;&#24067;&#21270;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#31934;&#30830;&#23376;&#31354;&#38388;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
Exact Subspace Diffusion for Decentralized Multitask Learning. (arXiv:2304.07358v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07358
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#22810;&#20219;&#21153;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#31934;&#30830;&#25193;&#25955;&#31639;&#27861;&#30340;&#25512;&#24191;&#65292;&#24182;&#22312;&#32593;&#32476;&#20013;&#36827;&#34892;&#23376;&#31354;&#38388;&#32422;&#26463;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#36817;&#20284;&#25237;&#24433;&#30340;&#26041;&#27861;&#65292;&#20854;&#24615;&#33021;&#24471;&#21040;&#20102;&#26126;&#26174;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#32852;&#37030;&#23398;&#20064;&#25110;&#20998;&#25955;&#24335;&#26799;&#24230;&#19979;&#38477;&#65292;&#37319;&#29992;&#20849;&#35782;&#26426;&#21046;&#26469;&#24378;&#21046;&#23454;&#29616;&#20195;&#29702;&#20043;&#38388;&#30340;&#21516;&#36136;&#24615;&#12290;&#34429;&#28982;&#36825;&#20123;&#31574;&#30053;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#22330;&#26223;&#19979;&#34987;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#22312;&#20195;&#29702;&#36981;&#24490;&#24322;&#26500;&#30446;&#26631;&#25110;&#25968;&#25454;&#26102;&#65292;&#23427;&#20204;&#21487;&#33021;&#23548;&#33268;&#20005;&#37325;&#30340;&#24615;&#33021;&#38477;&#20302;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#20998;&#24067;&#24335;&#31574;&#30053;&#20197;&#26356;&#21152;&#24494;&#22937;&#30340;&#26041;&#24335;&#22312;&#20195;&#29702;&#20043;&#38388;&#24314;&#31435;&#20851;&#31995;&#65292;&#24182;&#40723;&#21169;&#21327;&#20316;&#32780;&#19981;&#26159;&#24378;&#21046;&#20849;&#35782;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#29992;&#20110;&#36890;&#36807;&#32593;&#32476;&#36827;&#34892;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#31934;&#30830;&#25193;&#25955;&#31639;&#27861;&#30340;&#25512;&#24191;&#65292;&#24182;&#23548;&#20986;&#20102;&#22312;&#21033;&#29992;&#22122;&#22768;&#26799;&#24230;&#36924;&#36817;&#26102;&#20854;&#22343;&#26041;&#20559;&#24046;&#30340;&#20934;&#30830;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#22312;&#25968;&#20540;&#19978;&#39564;&#35777;&#20102;&#39044;&#27979;&#24615;&#33021;&#34920;&#36798;&#24335;&#30340;&#20934;&#30830;&#24615;&#65292;&#20197;&#21450;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#22522;&#20110;&#36817;&#20284;&#25237;&#24433;&#30340;&#20854;&#20182;&#26041;&#27861;&#30340;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical paradigms for distributed learning, such as federated or decentralized gradient descent, employ consensus mechanisms to enforce homogeneity among agents. While these strategies have proven effective in i.i.d. scenarios, they can result in significant performance degradation when agents follow heterogeneous objectives or data. Distributed strategies for multitask learning, on the other hand, induce relationships between agents in a more nuanced manner, and encourage collaboration without enforcing consensus. We develop a generalization of the exact diffusion algorithm for subspace constrained multitask learning over networks, and derive an accurate expression for its mean-squared deviation when utilizing noisy gradient approximations. We verify numerically the accuracy of the predicted performance expressions, as well as the improved performance of the proposed approach over alternatives based on approximate projections.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#23450;&#38181;&#20013;&#30340;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#30340;&#21487;&#25193;&#23637;&#20960;&#20309;&#26694;&#26550;&#65292;&#21033;&#29992;&#26497;&#24191;&#20041;&#29305;&#24449;&#20540;&#26377;&#25928;&#22320;&#20998;&#26512;&#21644;&#22788;&#29702;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#25968;&#25454;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#27492;&#20960;&#20309;&#26041;&#27861;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#22411; SPD &#30697;&#38453;&#36845;&#20195;&#24179;&#22343;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07347</link><description>&lt;p&gt;
&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#26497;&#20540;&#29305;&#24449;&#20540;&#24046;&#20998;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Differential geometry with extreme eigenvalues in the positive semidefinite cone. (arXiv:2304.07347v1 [math.DG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#23450;&#38181;&#20013;&#30340;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#30340;&#21487;&#25193;&#23637;&#20960;&#20309;&#26694;&#26550;&#65292;&#21033;&#29992;&#26497;&#24191;&#20041;&#29305;&#24449;&#20540;&#26377;&#25928;&#22320;&#20998;&#26512;&#21644;&#22788;&#29702;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#25968;&#25454;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#27492;&#20960;&#20309;&#26041;&#27861;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#22411; SPD &#30697;&#38453;&#36845;&#20195;&#24179;&#22343;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#27491;&#23450;&#30697;&#38453; (SPD) &#25968;&#25454;&#30340;&#24494;&#20998;&#20960;&#20309;&#26041;&#27861;&#24050;&#34987;&#25104;&#21151;&#24212;&#29992;&#20110;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#21307;&#23398;&#25104;&#20687;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#20960;&#20309;&#33539;&#24335;&#30340;&#35889;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#38590;&#20197;&#22312;&#39640;&#32500;&#24230;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#19979;&#23454;&#29616;&#12290;&#26412;&#25991;&#22522;&#20110;&#21322;&#23450;&#38181;&#30340;&#24076;&#23572;&#20271;&#29305;&#21644;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#25552;&#20986;&#20102;&#35745;&#31639;&#26497;&#24191;&#20041;&#29305;&#24449;&#20540;&#30340;&#21487;&#25193;&#23637;&#20960;&#20309;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#22522;&#20110;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#30340;&#27979;&#22320;&#31354;&#38388;&#32467;&#26500;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26500;&#30340;&#22810;&#20010;&#23646;&#24615;&#12290;&#27492;&#22806;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#22522;&#20110;&#35813;&#20960;&#20309;&#26041;&#27861;&#30340;&#26032;&#22411; SPD &#30697;&#38453;&#36845;&#20195;&#24179;&#22343;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#26377;&#38480;&#20010; SPD &#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#20854;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential geometric approaches to the analysis and processing of data in the form of symmetric positive definite (SPD) matrices have had notable successful applications to numerous fields including computer vision, medical imaging, and machine learning. The dominant geometric paradigm for such applications has consisted of a few Riemannian geometries associated with spectral computations that are costly at high scale and in high dimensions. We present a route to a scalable geometric framework for the analysis and processing of SPD-valued data based on the efficient computation of extreme generalized eigenvalues through the Hilbert and Thompson geometries of the semidefinite cone. We explore a particular geodesic space structure based on Thompson geometry in detail and establish several properties associated with this structure. Furthermore, we define a novel iterative mean of SPD matrices based on this geometry and prove its existence and uniqueness for a given finite collection of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#26500;&#24314;&#21487;&#38752;&#12289;&#20540;&#24471;&#20449;&#36182;&#30340;&#38081;&#36335;&#20449;&#21495;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#39118;&#38505;&#25511;&#21046;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#26377;&#28508;&#21147;&#20026;&#23454;&#29616;&#27491;&#24335;&#20445;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#36793;&#30028;&#25552;&#20379;&#23454;&#29992;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2304.06052</link><description>&lt;p&gt;
&#22522;&#20110;&#31526;&#21512;&#24615;&#39044;&#27979;&#21644;&#31526;&#21512;&#24615;&#39118;&#38505;&#25511;&#21046;&#30340;&#26377;&#20449;&#24515;&#29289;&#20307;&#26816;&#27979;&#65306;&#38081;&#36335;&#20449;&#21495;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Confident Object Detection via Conformal Prediction and Conformal Risk Control: an Application to Railway Signaling. (arXiv:2304.06052v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#26500;&#24314;&#21487;&#38752;&#12289;&#20540;&#24471;&#20449;&#36182;&#30340;&#38081;&#36335;&#20449;&#21495;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#39118;&#38505;&#25511;&#21046;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#26377;&#28508;&#21147;&#20026;&#23454;&#29616;&#27491;&#24335;&#20445;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#36793;&#30028;&#25552;&#20379;&#23454;&#29992;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#35748;&#35777;&#31995;&#32479;&#20013;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#25552;&#20379;&#33021;&#22815;&#20934;&#30830;&#21453;&#26144;&#19981;&#30830;&#23450;&#24615;&#30340;&#32622;&#20449;&#24230;&#20272;&#35745;&#12290;&#26412;&#25991;&#28436;&#31034;&#20102;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#26500;&#24314;&#21487;&#38752;&#30340;&#12289;&#20540;&#24471;&#20449;&#36182;&#30340;&#26816;&#27979;&#38081;&#36335;&#20449;&#21495;&#30340;&#39044;&#27979;&#22120;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#21253;&#21547;&#28779;&#36710;&#25805;&#20316;&#21592;&#35270;&#35282;&#19979;&#30340;&#22270;&#20687;&#21644;&#26368;&#20808;&#36827;&#30340;&#29289;&#20307;&#26816;&#27979;&#22120;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#20960;&#31181;&#31526;&#21512;&#24615;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#39118;&#38505;&#25511;&#21046;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#31526;&#21512;&#24615;&#39044;&#27979;&#26694;&#26550;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#21644;&#25552;&#20379;&#27491;&#24335;&#20445;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#36793;&#30028;&#20855;&#26377;&#28508;&#21147;&#65292;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#25552;&#20379;&#20102;&#23454;&#29992;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. In this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. Our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. We test several conformal approaches and introduce a new method based on conformal risk control. Our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2304.05365</link><description>&lt;p&gt;
&#25105;&#20204;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#21527;&#65311;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20010;&#24615;&#21270;&#27835;&#30103;&#24207;&#21015;&#20197;&#25903;&#25345;&#29992;&#25143;&#37319;&#21462;&#26356;&#20581;&#24247;&#30340;&#34892;&#20026;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#31181;&#36830;&#32493;&#20915;&#31574;&#38382;&#39064;&#28041;&#21450;&#21040;&#22522;&#20110;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#20808;&#21069;&#30340;&#27963;&#21160;&#27700;&#24179;&#12289;&#20301;&#32622;&#31561;&#65289;&#22312;&#20309;&#26102;&#27835;&#30103;&#20197;&#21450;&#22914;&#20309;&#27835;&#30103;&#30340;&#20915;&#23450;&#12290;&#22312;&#32447;RL&#31639;&#27861;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22522;&#20110;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#30693;&#35782;&#20010;&#24615;&#21270;&#36825;&#20123;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#35201;&#20915;&#23450;&#26159;&#21542;&#24212;&#22312;&#23454;&#38469;&#37096;&#32626;&#30340;&#8220;&#20248;&#21270;&#8221;&#24178;&#39044;&#20013;&#21253;&#21547;RL&#31639;&#27861;&#65292;&#25105;&#20204;&#24517;&#39035;&#35780;&#20272;&#25968;&#25454;&#35777;&#25454;&#65292;&#34920;&#26126;RL&#31639;&#27861;&#23454;&#38469;&#19978;&#27491;&#22312;&#23558;&#27835;&#30103;&#20010;&#24615;&#21270;&#36866;&#24212;&#20854;&#29992;&#25143;&#12290;&#30001;&#20110;RL&#31639;&#27861;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#23545;&#20854;&#22312;&#26576;&#20123;&#29366;&#24577;&#19979;&#30340;&#23398;&#20064;&#24182;&#20351;&#29992;&#27492;&#23398;&#20064;&#26469;&#25552;&#20379;&#29305;&#23450;&#27835;&#30103;&#30340;&#33021;&#21147;&#20135;&#29983;&#35823;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#24037;&#20316;&#23450;&#20041;&#30340;&#20010;&#24615;&#21270;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#37325;&#22797;&#37319;&#26679;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#32447;RL&#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#20010;&#24615;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11582</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#36866;&#24212;&#24615;&#23454;&#39564;&#65306;&#28789;&#27963;&#25209;&#22788;&#29702;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#20551;&#23450;&#25345;&#32493;&#37325;&#26032;&#20998;&#37197;&#27979;&#37327;&#24037;&#20316;&#65292;&#36825;&#22312;&#23454;&#29616;&#36807;&#31243;&#20013;&#23384;&#22312;&#24310;&#36831;&#21453;&#39304;&#21644;&#22522;&#30784;&#35774;&#26045;/&#32452;&#32455;&#38590;&#39064;&#31561;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#20165;&#26377;&#23569;&#25968;&#37325;&#26032;&#20998;&#37197;&#38454;&#27573;&#30340;&#23454;&#38469;&#24773;&#20917;&#65292;&#20854;&#20013;&#27979;&#37327;&#32467;&#26524;&#26159;&#20197;&#25209;&#22788;&#29702;&#24418;&#24335;&#27979;&#37327;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#24212;&#24615;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#26159;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#26222;&#36941;&#20351;&#29992;&#30340;&#27491;&#24577;&#36817;&#20284;&#20063;&#21487;&#20197;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#12290;&#36890;&#36807;&#25512;&#23548;&#28176;&#36827;&#39034;&#24207;&#23454;&#39564;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#65292;&#21487;&#20197;&#21033;&#29992;&#24179;&#22343;&#22238;&#25253;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#21160;&#24577;&#35268;&#21010;&#30340;&#29366;&#24577;&#36716;&#31227;&#30456;&#23545;&#20110;&#37319;&#26679;&#20998;&#37197;&#26159;&#21487;&#24494;&#30340;&#65292;&#20801;&#35768;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#35268;&#21010;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36845;&#20195;&#35268;&#21010;&#26041;&#27861;&#65292;&#21363;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#65292;&#36890;&#36807;&#20248;&#21270;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#35268;&#21010;&#30446;&#26631;&#26469;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#27979;&#35797;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#26377;&#27169;&#22359;&#21270;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20551;&#35774;&#65292;&#26377;&#25928;&#22320;&#21253;&#21547;&#20102;&#21407;&#22987;&#31070;&#32463;&#22349;&#22604;&#65292;&#24182;&#23558;&#20854;&#20998;&#35299;&#20026;&#20004;&#20010;&#30446;&#26631;&#65306;&#26368;&#23567;&#21270;&#31867;&#20869;&#21464;&#24322;&#24615;&#21644;&#26368;&#22823;&#21270;&#31867;&#38388;&#21487;&#20998;&#24615;&#12290;&#20351;&#29992;&#36229;&#29699;&#32479;&#19968;&#24615;&#20316;&#20026;&#37327;&#21270;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30446;&#26631;&#8212;&#8212;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#65288;HUG&#65289;&#65292;&#23427;&#30001;&#31867;&#38388;&#21644;&#31867;&#20869;&#36229;&#29699;&#32479;&#19968;&#24615;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#12290;</title><link>http://arxiv.org/abs/2303.06484</link><description>&lt;p&gt;
&#36890;&#36807;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#22635;&#34917;&#31070;&#32463;&#22349;&#22604;&#30340;&#27867;&#21270;&#21644;&#35299;&#32806;
&lt;/p&gt;
&lt;p&gt;
Generalizing and Decoupling Neural Collapse via Hyperspherical Uniformity Gap. (arXiv:2303.06484v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20551;&#35774;&#65292;&#26377;&#25928;&#22320;&#21253;&#21547;&#20102;&#21407;&#22987;&#31070;&#32463;&#22349;&#22604;&#65292;&#24182;&#23558;&#20854;&#20998;&#35299;&#20026;&#20004;&#20010;&#30446;&#26631;&#65306;&#26368;&#23567;&#21270;&#31867;&#20869;&#21464;&#24322;&#24615;&#21644;&#26368;&#22823;&#21270;&#31867;&#38388;&#21487;&#20998;&#24615;&#12290;&#20351;&#29992;&#36229;&#29699;&#32479;&#19968;&#24615;&#20316;&#20026;&#37327;&#21270;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30446;&#26631;&#8212;&#8212;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#65288;HUG&#65289;&#65292;&#23427;&#30001;&#31867;&#38388;&#21644;&#31867;&#20869;&#36229;&#29699;&#32479;&#19968;&#24615;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a generalized neural collapse hypothesis that effectively subsumes the original neural collapse and decomposes it into two objectives: minimizing intra-class variability and maximizing inter-class separability. The authors use hyperspherical uniformity as a unified framework to quantify these objectives and propose a general objective, hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical uniformity.
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#22349;&#22604;&#29616;&#35937;&#25551;&#36848;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24213;&#23618;&#20960;&#20309;&#23545;&#31216;&#24615;&#65292;&#20854;&#20013;&#28145;&#24230;&#23398;&#20064;&#30340;&#29305;&#24449;&#21644;&#20998;&#31867;&#22120;&#37117;&#25910;&#25947;&#20110;&#19968;&#20010;&#31561;&#35282;&#32039;&#26694;&#26550;&#12290;&#24050;&#32463;&#35777;&#26126;&#65292;&#20132;&#21449;&#29109;&#25439;&#22833;&#21644;&#22343;&#26041;&#35823;&#24046;&#37117;&#21487;&#20197;&#23548;&#33268;&#31070;&#32463;&#22349;&#22604;&#12290;&#25105;&#20204;&#28040;&#38500;&#20102;&#31070;&#32463;&#22349;&#22604;&#23545;&#29305;&#24449;&#32500;&#24230;&#21644;&#31867;&#21035;&#25968;&#37327;&#30340;&#20851;&#38190;&#20551;&#35774;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20551;&#35774;&#65292;&#26377;&#25928;&#22320;&#21253;&#21547;&#20102;&#21407;&#22987;&#31070;&#32463;&#22349;&#22604;&#12290;&#21463;&#31070;&#32463;&#22349;&#22604;&#25551;&#36848;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30446;&#26631;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#24191;&#20041;&#31070;&#32463;&#22349;&#22604;&#20998;&#35299;&#20026;&#20004;&#20010;&#30446;&#26631;&#65306;&#26368;&#23567;&#21270;&#31867;&#20869;&#21464;&#24322;&#24615;&#21644;&#26368;&#22823;&#21270;&#31867;&#38388;&#21487;&#20998;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36229;&#29699;&#32479;&#19968;&#24615;&#65288;&#23427;&#25551;&#36848;&#20102;&#21333;&#20301;&#36229;&#29699;&#19978;&#22343;&#21248;&#24615;&#30340;&#31243;&#24230;&#65289;&#20316;&#20026;&#37327;&#21270;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30446;&#26631;&#8212;&#8212;&#36229;&#29699;&#32479;&#19968;&#24615;&#24046;&#65288;HUG&#65289;&#65292;&#23427;&#30001;&#31867;&#38388;&#21644;&#31867;&#20869;&#36229;&#29699;&#32479;&#19968;&#24615;&#20043;&#38388;&#30340;&#24046;&#24322;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
The neural collapse (NC) phenomenon describes an underlying geometric symmetry for deep neural networks, where both deeply learned features and classifiers converge to a simplex equiangular tight frame. It has been shown that both cross-entropy loss and mean square error can provably lead to NC. We remove NC's key assumption on the feature dimension and the number of classes, and then present a generalized neural collapse (GNC) hypothesis that effectively subsumes the original NC. Inspired by how NC characterizes the training target of neural networks, we decouple GNC into two objectives: minimal intra-class variability and maximal inter-class separability. We then use hyperspherical uniformity (which characterizes the degree of uniformity on the unit hypersphere) as a unified framework to quantify these two objectives. Finally, we propose a general objective -- hyperspherical uniformity gap (HUG), which is defined by the difference between inter-class and intra-class hyperspherical un
&lt;/p&gt;</description></item><item><title>BLiE&#26159;&#19968;&#31181;&#29992;&#20110;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#21482;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;BLiE&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#25628;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.01539</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36830;&#32493;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;Lipschitz&#20048;&#35266;&#31574;&#30053;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lipschitz Bandits Approach for Continuous Hyperparameter Optimization. (arXiv:2302.01539v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01539
&lt;/p&gt;
&lt;p&gt;
BLiE&#26159;&#19968;&#31181;&#29992;&#20110;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#21482;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;BLiE&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#25628;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#36229;&#21442;&#25968;&#20248;&#21270;&#65288;HPO&#65289;&#26159;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#22240;&#20026;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#23545;&#26368;&#32456;&#27169;&#22411;&#30340;&#24615;&#33021;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#34429;&#28982;&#26377;&#35768;&#22810;HPO&#31639;&#27861;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#35201;&#20040;&#38656;&#35201;&#24378;&#30340;&#20551;&#35774;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;BLiE&#8212;&#8212;&#19968;&#31181;&#22522;&#20110;Lipschitz&#20048;&#35266;&#31574;&#30053;&#30340;HPO&#31639;&#27861;&#65292;&#23427;&#21482;&#20551;&#35774;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;BLiE&#21033;&#29992;&#30446;&#26631;&#20989;&#25968;&#30340;&#26223;&#35266;&#20197;&#33258;&#36866;&#24212;&#22320;&#25628;&#32034;&#36229;&#21442;&#25968;&#31354;&#38388;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$(i)$ BLiE&#21457;&#29616;&#20855;&#26377;$O(\frac{1}{\epsilon})^{d_z+\beta}$&#20010;&#24635;&#39044;&#31639;&#30340;$\epsilon$&#26368;&#20248;&#36229;&#21442;&#25968;&#65292;&#20854;&#20013;$d_z$&#21644;$\beta$&#26159;&#38382;&#39064;&#20869;&#22312;&#30340;&#65307;$(ii)$ BLiE&#20855;&#26377;&#39640;&#24230;&#21487;&#24182;&#34892;&#24615;&#12290;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;BLiE&#22312;&#22522;&#20934;&#20219;&#21153;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;HPO&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#24212;&#29992;BLiE&#25628;&#32034;&#25193;&#25955;&#27169;&#22411;&#30340;&#22122;&#22768;&#35843;&#24230;&#12290;&#19982;&#40664;&#35748;&#35843;&#24230;&#30456;&#27604;&#36739;&#65292;BLiE&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the most critical problems in machine learning is HyperParameter Optimization (HPO), since choice of hyperparameters has a significant impact on final model performance. Although there are many HPO algorithms, they either have no theoretical guarantees or require strong assumptions. To this end, we introduce BLiE -- a Lipschitz-bandit-based algorithm for HPO that only assumes Lipschitz continuity of the objective function. BLiE exploits the landscape of the objective function to adaptively search over the hyperparameter space. Theoretically, we show that $(i)$ BLiE finds an $\epsilon$-optimal hyperparameter with $O \left( \frac{1}{\epsilon} \right)^{d_z + \beta}$ total budgets, where $d_z$ and $\beta$ are problem intrinsic; $(ii)$ BLiE is highly parallelizable. Empirically, we demonstrate that BLiE outperforms the state-of-the-art HPO algorithms on benchmark tasks. We also apply BLiE to search for noise schedule of diffusion models. Comparison with the default schedule shows tha
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20687;&#35782;&#21035;&#30340;&#30417;&#30563;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#20197;&#28151;&#21512;&#26041;&#27861;&#23398;&#20064;&#26356;&#22909;&#30340;&#36317;&#31163;&#34920;&#31034;&#12290;&#36890;&#36807;&#25511;&#21046;&#20960;&#20309;&#36817;&#37051;&#21644;&#27010;&#29575;&#36817;&#37051;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20174;&#22270;&#20687;&#25968;&#25454;&#20013;&#23398;&#20064;&#36890;&#29992;&#30340;&#28151;&#21512;&#30456;&#20284;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2301.13459</link><description>&lt;p&gt;
&#23398;&#20064;&#29992;&#20110;&#22270;&#20687;&#35782;&#21035;&#30340;&#24191;&#20041;&#28151;&#21512;&#36317;&#31163;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Generalized Hybrid Proximity Representation for Image Recognition. (arXiv:2301.13459v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13459
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#20687;&#35782;&#21035;&#30340;&#30417;&#30563;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#20197;&#28151;&#21512;&#26041;&#27861;&#23398;&#20064;&#26356;&#22909;&#30340;&#36317;&#31163;&#34920;&#31034;&#12290;&#36890;&#36807;&#25511;&#21046;&#20960;&#20309;&#36817;&#37051;&#21644;&#27010;&#29575;&#36817;&#37051;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20174;&#22270;&#20687;&#25968;&#25454;&#20013;&#23398;&#20064;&#36890;&#29992;&#30340;&#28151;&#21512;&#30456;&#20284;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25216;&#26415;&#21463;&#21040;&#20851;&#27880;&#65292;&#22240;&#20026;&#23398;&#20064;&#21040;&#30340;&#36317;&#31163;&#34920;&#31034;&#21487;&#29992;&#20110;&#25429;&#25417;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20851;&#31995;&#65292;&#24182;&#36827;&#19968;&#27493;&#25552;&#39640;&#21508;&#31181;&#30417;&#30563;&#25110;&#26080;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#23398;&#20064;&#20960;&#20309;&#21644;&#27010;&#29575;&#31354;&#38388;&#20013;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#29992;&#20110;&#22270;&#20687;&#35782;&#21035;&#12290;&#19982;&#20808;&#21069;&#30340;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#20391;&#37325;&#20110;&#23398;&#20064;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#30340;&#36317;&#31163;&#24230;&#37327;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#20197;&#28151;&#21512;&#26041;&#27861;&#23398;&#20064;&#26356;&#22909;&#30340;&#36317;&#31163;&#34920;&#31034;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24191;&#20041;&#28151;&#21512;&#24230;&#37327;&#25439;&#22833;&#65288;GHM-Loss&#65289;&#26469;&#36890;&#36807;&#25511;&#21046;&#20960;&#20309;&#36817;&#37051;&#21644;&#27010;&#29575;&#36817;&#37051;&#20043;&#38388;&#30340;&#26435;&#34913;&#20174;&#22270;&#20687;&#25968;&#25454;&#20013;&#23398;&#20064;&#36890;&#29992;&#30340;&#28151;&#21512;&#30456;&#20284;&#29305;&#24449;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#29702;&#35770;&#25512;&#23548;&#21644;&#35777;&#26126;&#65292;&#28982;&#21518;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#30340;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, deep metric learning techniques received attention, as the learned distance representations are useful to capture the similarity relationship among samples and further improve the performance of various of supervised or unsupervised learning tasks. We propose a novel supervised metric learning method that can learn the distance metrics in both geometric and probabilistic space for image recognition. In contrast to the previous metric learning methods which usually focus on learning the distance metrics in Euclidean space, our proposed method is able to learn better distance representation in a hybrid approach. To achieve this, we proposed a Generalized Hybrid Metric Loss (GHM-Loss) to learn the general hybrid proximity features from the image data by controlling the trade-off between geometric proximity and probabilistic proximity. To evaluate the effectiveness of our method, we first provide theoretical derivations and proofs of the proposed loss function, then we perform ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;Boltzmann&#23494;&#24230;&#21464;&#24418;&#36712;&#36857;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#25554;&#20540;&#33021;&#37327;&#20989;&#25968;&#31561;&#23454;&#29616;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#65292;&#28982;&#21518;&#25214;&#21040;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#65292;&#20854;&#34920;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#27604;KL-&#21453;&#25955;&#24230;&#26356;&#20855;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2301.07388</link><description>&lt;p&gt;
&#23398;&#20064;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Learning Deformation Trajectories of Boltzmann Densities. (arXiv:2301.07388v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;Boltzmann&#23494;&#24230;&#21464;&#24418;&#36712;&#36857;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#36890;&#36807;&#25554;&#20540;&#33021;&#37327;&#20989;&#25968;&#31561;&#23454;&#29616;Boltzmann&#23494;&#24230;&#30340;&#21464;&#24418;&#65292;&#28982;&#21518;&#25214;&#21040;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#65292;&#20854;&#34920;&#29616;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#27604;KL-&#21453;&#25955;&#24230;&#26356;&#20855;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#27809;&#26377;&#26679;&#26412;&#20294;&#23384;&#22312;&#33021;&#37327;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#33021;&#37327;&#20989;&#25968;$f_1$&#21644;&#24191;&#20041;&#39640;&#26031;&#20989;&#25968;$f_0$&#20043;&#38388;&#30340;&#39044;&#23450;&#25110;&#23398;&#20064;&#25554;&#20540;$f_t$&#12290;&#33021;&#37327;&#20989;&#25968;&#30340;&#25554;&#20540;&#24341;&#36215;Boltzmann&#23494;&#24230;$p_t\propto e^{-f_t}$&#30340;&#25554;&#20540;&#65292;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#19968;&#20010;&#27839;&#30528;&#26063;$p_t$&#30340;&#26102;&#38388;&#20381;&#36182;&#21521;&#37327;&#22330;$V_t$&#65292;&#23558;&#26679;&#26412;&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#12290;&#23558;&#26679;&#26412;&#27839;&#30528;&#26063;$p_t$&#20174;&#19968;&#20010;&#20998;&#24067;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20998;&#24067;&#30340;&#26465;&#20214;&#21487;&#20197;&#36716;&#21270;&#20026;$V_t$&#21644;$f_t$&#20043;&#38388;&#30340;PDE&#65292;&#25105;&#20204;&#20248;&#21270;$V_t$&#21644;$f_t$&#20197;&#28385;&#36275;&#27492;PDE&#12290;&#25105;&#20204;&#22312;&#39640;&#26031;&#28151;&#21512;&#21644;&#21452;&#20117;&#21183;&#30340;&#37327;&#23376;&#21147;&#23398;&#31890;&#23376;&#30340;Boltzmann&#23494;&#24230;&#19978;&#23454;&#39564;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#30340;&#35757;&#32451;&#30446;&#26631;&#19982;KL-&#21453;&#25955;&#24230;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a training objective for continuous normalizing flows that can be used in the absence of samples but in the presence of an energy function. Our method relies on either a prescribed or a learnt interpolation $f_t$ of energy functions between the target energy $f_1$ and the energy function of a generalized Gaussian $f_0(x) = ||x/\sigma||_p^p$. The interpolation of energy functions induces an interpolation of Boltzmann densities $p_t \propto e^{-f_t}$ and we aim to find a time-dependent vector field $V_t$ that transports samples along the family $p_t$ of densities. The condition of transporting samples along the family $p_t$ can be translated to a PDE between $V_t$ and $f_t$ and we optimize $V_t$ and $f_t$ to satisfy this PDE. We experimentally compare the proposed training objective to the reverse KL-divergence on Gaussian mixtures and on the Boltzmann density of a quantum mechanical particle in a double-well potential.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20999;&#29255;&#30340;&#26041;&#24335;&#23450;&#20041;&#20102;&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#36317;&#31163;&#12290;</title><link>http://arxiv.org/abs/2212.08049</link><description>&lt;p&gt;
&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;
&lt;/p&gt;
&lt;p&gt;
Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20999;&#29255;&#30340;&#26041;&#24335;&#23450;&#20041;&#20102;&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#24050;&#32463;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#25968;&#25454;&#31185;&#23398;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21464;&#24471;&#26497;&#20854;&#27969;&#34892;&#12290;OT&#38382;&#39064;&#30340;&#26680;&#24515;&#20551;&#35774;&#26159;&#28304;&#21644;&#30446;&#26631;&#27979;&#24230;&#30340;&#24635;&#36136;&#37327;&#30456;&#31561;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#30340;&#24212;&#29992;&#12290;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#65288;OPT&#65289;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#30340;&#26041;&#27861;&#12290;&#19982;OT&#38382;&#39064;&#31867;&#20284;&#65292;OPT&#30340;&#35745;&#31639;&#20381;&#36182;&#20110;&#35299;&#20915;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65288;&#36890;&#24120;&#22312;&#39640;&#32500;&#24230;&#20013;&#65289;&#65292;&#36825;&#21487;&#33021;&#20250;&#21464;&#24471;&#35745;&#31639;&#19978;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;OPT&#38382;&#39064;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#36981;&#24490;&#20999;&#29255;OT&#36317;&#31163;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#21033;&#29992;&#20999;&#29255;&#23450;&#20041;&#20102;&#20999;&#29255;OPT&#36317;&#31163;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20999;&#29255;OPT-based&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#20540;&#23454;&#39564;&#20013;&#30340;&#35745;&#31639;&#21644;&#31934;&#24230;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;Sliced-OPT&#22312;&#22122;&#22768;&#28857;&#20113;&#37197;&#20934;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#32452;&#20844;&#24179;&#32422;&#26463;&#30340;&#21487;&#25193;&#23637;&#35889;&#32858;&#31867;&#31639;&#27861; s-FairSC&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#30697;&#38453;&#21521;&#37327;&#20056;&#31215;&#26469;&#20805;&#20998;&#21033;&#29992;&#20854;&#31232;&#30095;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.16435</link><description>&lt;p&gt;
&#24102;&#26377;&#32452;&#20844;&#24179;&#32422;&#26463;&#30340;&#21487;&#25193;&#23637;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Scalable Spectral Clustering with Group Fairness Constraints. (arXiv:2210.16435v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#32452;&#20844;&#24179;&#32422;&#26463;&#30340;&#21487;&#25193;&#23637;&#35889;&#32858;&#31867;&#31639;&#27861; s-FairSC&#65292;&#24182;&#36890;&#36807;&#31232;&#30095;&#30697;&#38453;&#21521;&#37327;&#20056;&#31215;&#26469;&#20805;&#20998;&#21033;&#29992;&#20854;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#24314;&#27169;&#20844;&#24179;&#24615;&#21644;&#32416;&#27491;&#31639;&#27861;&#20559;&#24046;&#30340;&#30740;&#31350;&#20852;&#36259;&#21644;&#24037;&#19994;&#23454;&#36341;&#21327;&#21516;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#32452;&#20844;&#24179;&#32422;&#26463;&#30340;&#21487;&#25193;&#23637;&#35889;&#32858;&#31867;&#65288;SC&#65289;&#31639;&#27861;&#12290;&#32452;&#20844;&#24179;&#20063;&#34987;&#31216;&#20026;&#32479;&#35745;&#24179;&#31561;&#65292;&#21363;&#22312;&#27599;&#20010;&#31751;&#20013;&#65292;&#27599;&#20010;&#21463;&#20445;&#25252;&#30340;&#32452;&#21035;&#20197;&#19982;&#25972;&#20307;&#30456;&#21516;&#30340;&#27604;&#20363;&#34920;&#31034;&#12290;&#25105;&#20204;&#36890;&#36807;&#32467;&#21512;&#38646;&#31354;&#38388;&#25237;&#24433;&#21644;&#38669;&#29305;&#26519;&#30340;&#32553;&#20943;&#30340;&#26032;&#30340;&#35889;&#35745;&#31639;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026; s-FairSC &#30340;&#31639;&#27861;&#65292;&#23427;&#21482;&#28041;&#21450;&#31232;&#30095;&#30340;&#30697;&#38453;&#21521;&#37327;&#20056;&#31215;&#65292;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#20844;&#24179; SC &#27169;&#22411;&#30340;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
There are synergies of research interests and industrial efforts in modeling fairness and correcting algorithmic bias in machine learning. In this paper, we present a scalable algorithm for spectral clustering (SC) with group fairness constraints. Group fairness is also known as statistical parity where in each cluster, each protected group is represented with the same proportion as in the entirety. While FairSC algorithm (Kleindessner et al., 2019) is able to find the fairer clustering, it is compromised by high costs due to the kernels of computing nullspaces and the square roots of dense matrices explicitly. We present a new formulation of underlying spectral computation by incorporating nullspace projection and Hotelling's deflation such that the resulting algorithm, called s-FairSC, only involves the sparse matrix-vector products and is able to fully exploit the sparsity of the fair SC model. The experimental results on the modified stochastic block model demonstrate that s-FairSC
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#35777;&#26126;&#20256;&#32479;&#30340;&#36890;&#29992;&#23545;&#25239;&#24178;&#25200; (UAPs) &#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20043;&#38388;&#36716;&#31227;&#24615;&#26159;&#27425;&#20248;&#30340;&#65292;&#20026;&#27492;&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#29992;&#23545;&#25239;&#26041;&#21521; (UADs)&#65292;&#21482;&#22266;&#23450;&#36890;&#29992;&#26041;&#21521;&#65292;&#20197;&#20415;&#20811;&#26381;&#22312;&#36328;DNN&#26550;&#26500;&#19978;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2210.15997</link><description>&lt;p&gt;
&#36890;&#29992;&#23545;&#25239;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Universal Adversarial Directions. (arXiv:2210.15997v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15997
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#35777;&#26126;&#20256;&#32479;&#30340;&#36890;&#29992;&#23545;&#25239;&#24178;&#25200; (UAPs) &#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20043;&#38388;&#36716;&#31227;&#24615;&#26159;&#27425;&#20248;&#30340;&#65292;&#20026;&#27492;&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#29992;&#23545;&#25239;&#26041;&#21521; (UADs)&#65292;&#21482;&#22266;&#23450;&#36890;&#29992;&#26041;&#21521;&#65292;&#20197;&#20415;&#20811;&#26381;&#22312;&#36328;DNN&#26550;&#26500;&#19978;&#36716;&#31227;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#35782;&#21035;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#35266;&#23519;&#21040;&#23427;&#20204;&#23481;&#26131;&#21463;&#21040;&#36890;&#29992;&#23545;&#25239;&#24178;&#25200; (UAPs) &#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#24178;&#25200;&#20351;&#29992;&#21333;&#20010;&#25200;&#21160;&#21521;&#37327;&#24178;&#25200;&#25152;&#26377;&#36755;&#20837;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;UAPs&#22312;&#36328;DNN&#26550;&#26500;&#36716;&#31227;&#26102;&#36890;&#24120;&#24456;&#22256;&#38590;&#24182;&#23548;&#33268;&#25361;&#25112;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;UAP&#30340;&#21487;Transfer&#24615;&#65292;&#36890;&#36807;&#20998;&#26512;&#20998;&#31867;&#22120;&#21644;UAP&#23545;&#25163;&#29609;&#23478;&#20043;&#38388;&#22312;&#36890;&#29992;&#23545;&#25239;&#31034;&#20363;&#21338;&#24328;&#20013;&#30340;&#22343;&#34913;&#24773;&#20917;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#36890;&#29992;&#23545;&#25239;&#31034;&#20363;&#21338;&#24328;&#32570;&#20047;&#19968;&#20010;&#32431;&#32435;&#20160;&#22343;&#34913;&#65292;&#36825;&#34920;&#26126;UAPs&#22312;DNN&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#36716;&#31227;&#24615;&#26159;&#27425;&#20248;&#30340;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#29992;&#23545;&#25239;&#26041;&#21521; (UADs)&#65292;&#21482;&#22266;&#23450;&#23545;&#25239;&#24178;&#25200;&#30340;&#36890;&#29992;&#26041;&#21521;&#65292;&#20801;&#35768;&#36328;&#26679;&#26412;&#33258;&#30001;&#36873;&#25321;&#24178;&#25200;&#30340;&#24133;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;UAD&#23545;&#25239;&#31034;&#20363;&#21338;&#24328;&#21487;&#20197;&#20855;&#26377;&#32435;&#20160;&#22343;&#34913;&#19988;&#35813;&#22343;&#34913;&#29366;&#24577;&#32431;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure U
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20449;&#24687;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#39044;&#35757;&#32451;&#22270;&#21367;&#31215;&#32593;&#32476;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#30340;&#22522;&#22240;&#34920;&#36798;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;&#26469;&#39640;&#25928;&#20272;&#35745;&#36793;&#32536;&#24178;&#25200;&#25928;&#24212;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00116</link><description>&lt;p&gt;
&#21033;&#29992;&#21464;&#20998;&#22240;&#26524;&#25512;&#26029;&#21644;&#31934;&#32454;&#20851;&#31995;&#20449;&#24687;&#39044;&#27979;&#32454;&#32990;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00116
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#20449;&#24687;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#39044;&#35757;&#32451;&#22270;&#21367;&#31215;&#32593;&#32476;&#20197;&#26356;&#22909;&#22320;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#30340;&#22522;&#22240;&#34920;&#36798;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#40065;&#26834;&#30340;&#20272;&#35745;&#22120;&#26469;&#39640;&#25928;&#20272;&#35745;&#36793;&#32536;&#24178;&#25200;&#25928;&#24212;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#32454;&#32990;&#22312;&#24178;&#25200;&#19979;&#30340;&#21709;&#24212;&#21487;&#33021;&#20026;&#33647;&#29289;&#30740;&#21457;&#21644;&#20010;&#24615;&#21270;&#27835;&#30103;&#24102;&#26469;&#37325;&#35201;&#22909;&#22788;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#21464;&#20998;&#36125;&#21494;&#26031;&#22240;&#26524;&#25512;&#26029;&#26694;&#26550;&#65292;&#39044;&#27979;&#32454;&#32990;&#22312;&#21453;&#20107;&#23454;&#24178;&#25200;&#19979;&#65288;&#21363;&#32454;&#32990;&#26410;&#30495;&#23454;&#25509;&#25910;&#30340;&#24178;&#25200;&#65289;&#30340;&#22522;&#22240;&#34920;&#36798;&#65292;&#21033;&#29992;&#20195;&#34920;&#29983;&#29289;&#23398;&#30693;&#35782;&#30340;&#22522;&#22240;&#35843;&#25511;&#32593;&#32476;&#65288;GRN&#65289;&#20449;&#24687;&#26469;&#36741;&#21161;&#20010;&#24615;&#21270;&#32454;&#32990;&#21709;&#24212;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#25968;&#25454;&#33258;&#36866;&#24212;GRN&#24320;&#21457;&#20102;&#37051;&#25509;&#30697;&#38453;&#26356;&#26032;&#25216;&#26415;&#29992;&#20110;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#39044;&#35757;&#32451;&#65292;&#22312;&#27169;&#22411;&#24615;&#33021;&#19978;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#22522;&#22240;&#20851;&#31995;&#27934;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advanta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#25193;&#23637;&#20026;&#20801;&#35768;&#39532;&#23572;&#21487;&#22827;&#38142;&#35266;&#27979;&#65292;&#30740;&#31350;&#20102;&#30456;&#24212;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#31867;&#27604;&#31639;&#27861;&#65292;&#24182;&#23454;&#29616;&#20102;&#30456;&#24212;&#30340;&#28388;&#27874;&#21644;Viterbi&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.06368</link><description>&lt;p&gt;
&#39532;&#23572;&#31185;&#22827;&#35266;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Markov Observation Models. (arXiv:2208.06368v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#25193;&#23637;&#20026;&#20801;&#35768;&#39532;&#23572;&#21487;&#22827;&#38142;&#35266;&#27979;&#65292;&#30740;&#31350;&#20102;&#30456;&#24212;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#31867;&#27604;&#31639;&#27861;&#65292;&#24182;&#23454;&#29616;&#20102;&#30456;&#24212;&#30340;&#28388;&#27874;&#21644;Viterbi&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#25193;&#23637;&#20026;&#20801;&#35768;&#39532;&#23572;&#21487;&#22827;&#38142;&#35266;&#27979;&#12290;&#29305;&#21035;&#22320;&#65292;&#20551;&#35774;&#35266;&#27979;&#20540;&#26159;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#30340;&#38142;&#65292;&#20854;&#19968;&#27493;&#36716;&#31227;&#27010;&#29575;&#20381;&#36182;&#20110;&#38544;&#34255;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#38024;&#23545;&#36825;&#31181;&#26356;&#21152;&#26222;&#36941;&#30340;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#19982;Baum-Welch&#31639;&#27861;&#30340;&#31867;&#27604;&#31639;&#27861;&#65292;&#20197;&#20272;&#35745;&#38544;&#34255;&#29366;&#24577;&#21644;&#35266;&#27979;&#24207;&#21015;&#30340;&#36716;&#31227;&#27010;&#29575;&#65292;&#20197;&#21450;&#20272;&#35745;&#21021;&#22987;&#32852;&#21512;&#38544;&#34255;&#29366;&#24577;-&#35266;&#27979;&#20998;&#24067;&#30340;&#27010;&#29575;&#12290;&#20174;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#30340;&#35745;&#31639;&#20013;&#24471;&#20986;&#20102;&#20449;&#24565;&#29366;&#24577;&#25110;&#28388;&#27874;&#24615;&#36882;&#25512;&#26469;&#36319;&#36394;&#38544;&#34255;&#30340;&#29366;&#24577;&#12290;&#21516;&#26102;&#65292;&#36824;&#24320;&#21457;&#20102;&#21160;&#24577;&#35268;&#21010;&#31867;&#27604;&#30340;Viterbi&#31639;&#27861;&#65292;&#20197;&#20272;&#35745;&#32473;&#23450;&#35266;&#27979;&#24207;&#21015;&#30340;&#26368;&#21487;&#33021;&#30340;&#38544;&#34255;&#29366;&#24577;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Herein, the Hidden Markov Model is expanded to allow for Markov chain observations. In particular, the observations are assumed to be a Markov chain whose one step transition probabilities depend upon the hidden Markov chain. An Expectation-Maximization analog to the Baum-Welch algorithm is developed for this more general model to estimate the transition probabilities for both the hidden state and for the observations as well as to estimate the probabilities for the initial joint hidden-state-observation distribution. A believe state or filter recursion to track the hidden state then arises from the calculations of this Expectation-Maximization algorithm. A dynamic programming analog to the Viterbi algorithm is also developed to estimate the most likely sequence of hidden states given the sequence of observations.
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#35777;&#26126;&#26426;&#21046;PoL&#23384;&#22312;&#19981;&#23569;&#38382;&#39064;&#65292;&#30001;&#20110;&#29616;&#26377;&#30340;&#27450;&#39575;&#31574;&#30053;&#24456;&#23481;&#26131;&#34987;&#25171;&#36133;&#25110;&#26080;&#27861;&#37325;&#29616;&#65292;&#22240;&#27492;&#23545;&#23545;&#25163;&#30340;&#23433;&#20840;&#20445;&#38556;&#19981;&#31283;&#20581;&#12290;&#26032;&#30340;&#27450;&#39575;&#31574;&#30053;&#24341;&#20837;&#21487;&#20197;&#25171;&#30772;PoL&#30340;&#26368;&#26032;&#38450;&#24481;&#26041;&#27861;&#65292;&#20294;&#25104;&#26412;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2208.03567</link><description>&lt;p&gt;
&#23398;&#20064;&#35777;&#26126;&#26426;&#21046;&#30446;&#21069;&#23384;&#22312;&#35768;&#22810;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Proof-of-Learning is Currently More Broken Than You Think. (arXiv:2208.03567v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.03567
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#35777;&#26126;&#26426;&#21046;PoL&#23384;&#22312;&#19981;&#23569;&#38382;&#39064;&#65292;&#30001;&#20110;&#29616;&#26377;&#30340;&#27450;&#39575;&#31574;&#30053;&#24456;&#23481;&#26131;&#34987;&#25171;&#36133;&#25110;&#26080;&#27861;&#37325;&#29616;&#65292;&#22240;&#27492;&#23545;&#23545;&#25163;&#30340;&#23433;&#20840;&#20445;&#38556;&#19981;&#31283;&#20581;&#12290;&#26032;&#30340;&#27450;&#39575;&#31574;&#30053;&#24341;&#20837;&#21487;&#20197;&#25171;&#30772;PoL&#30340;&#26368;&#26032;&#38450;&#24481;&#26041;&#27861;&#65292;&#20294;&#25104;&#26412;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#35777;&#26126;&#65288;PoL&#65289;&#25552;&#20986;&#65292;&#27169;&#22411;&#25152;&#26377;&#32773;&#35760;&#24405;&#35757;&#32451;&#26816;&#26597;&#28857;&#65292;&#20197;&#24314;&#31435;&#20026;&#35757;&#32451;&#32791;&#36153;&#30340;&#35745;&#31639;&#25552;&#20379;&#35777;&#26126;&#12290; PoL&#30340;&#20316;&#32773;&#25918;&#24323;&#20102;&#21152;&#23494;&#26041;&#27861;&#65292;&#20197;&#25442;&#21462;&#28145;&#24230;&#23398;&#20064;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#20174;&#32780;&#25442;&#21462;&#20102;&#20005;&#26684;&#30340;&#23433;&#20840;&#20445;&#35777;&#12290;&#20182;&#20204;&#36890;&#36807;&#23637;&#31034;&#30423;&#29992;&#27169;&#22411;&#30340;&#35745;&#31639;&#35777;&#26126;--&#35745;&#31639;&#20599;&#26469;&#30340;&#27169;&#22411;&#30340;&#35777;&#26126;&#65292;&#21644;&#30495;&#27491;&#22320;&#35757;&#32451;&#27169;&#22411;&#25152;&#38656;&#35201;&#30340;&#35777;&#26126;&#19968;&#26679;&#26114;&#36149;&#26469;&#23454;&#35777;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#20294;&#26159;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#20010;&#21453;&#20363;&#65292;&#20174;&#32780;&#20351;&#36825;&#20010;&#35266;&#23519;&#22833;&#25928;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#23613;&#31649;&#24403;&#21069;PoL&#39564;&#35777;&#23545;&#20110;&#23545;&#25163;&#26469;&#35828;&#19981;&#31283;&#20581;&#26159;&#30495;&#23454;&#30340;&#65292;&#20294;&#26159;&#26368;&#36817;&#30340;&#24037;&#20316;&#22823;&#22823;&#20302;&#20272;&#20102;&#36825;&#31181;&#32570;&#20047;&#31283;&#20581;&#24615;&#12290;&#36825;&#26159;&#22240;&#20026;&#29616;&#26377;&#30340;&#27450;&#39575;&#31574;&#30053;&#35201;&#20040;&#19981;&#21487;&#37325;&#29616;&#65292;&#35201;&#20040;&#38024;&#23545;PoL&#30340;&#21066;&#24369;&#24418;&#24335;--&#36825;&#24847;&#21619;&#30528;&#23427;&#20204;&#24456;&#23481;&#26131;&#34987;&#26356;&#25913;&#39564;&#35777;&#30340;&#36229;&#21442;&#25968;&#26469;&#25387;&#36133;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#25209;&#27450;&#39575;&#31574;&#30053;&#65292;&#23427;&#20204;&#21487;&#20197;&#25171;&#30772;&#36866;&#29992;&#20110;PoL&#30340;&#26368;&#26032;&#38450;&#24481;&#26041;&#27861;&#65292;&#20294;&#20195;&#20215;&#24456;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proof-of-Learning (PoL) proposes that a model owner logs training checkpoints to establish a proof of having expended the computation necessary for training. The authors of PoL forego cryptographic approaches and trade rigorous security guarantees for scalability to deep learning. They empirically argued the benefit of this approach by showing how spoofing--computing a proof for a stolen model--is as expensive as obtaining the proof honestly by training the model. However, recent work has provided a counter-example and thus has invalidated this observation.  In this work we demonstrate, first, that while it is true that current PoL verification is not robust to adversaries, recent work has largely underestimated this lack of robustness. This is because existing spoofing strategies are either unreproducible or target weakened instantiations of PoL--meaning they are easily thwarted by changing hyperparameters of the verification. Instead, we introduce the first spoofing strategies that c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#29992;&#25143;&#20043;&#38388;&#30340;&#22522;&#20110;&#20869;&#26680;&#30340;&#36172;&#21338;&#26426;&#21327;&#21516;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20195;&#29702;&#39640;&#26031;&#36827;&#31243;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#20197;&#38477;&#20302;&#36890;&#20449;&#24320;&#38144;&#65292;&#33719;&#24471;&#27425;&#20248;&#36951;&#25022;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2207.07948</link><description>&lt;p&gt;
&#22522;&#20110;&#20869;&#26680;&#30340;&#36172;&#21338;&#26426;&#21327;&#21516;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Collaborative Learning in Kernel-based Bandits for Distributed Users. (arXiv:2207.07948v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.07948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#29992;&#25143;&#20043;&#38388;&#30340;&#22522;&#20110;&#20869;&#26680;&#30340;&#36172;&#21338;&#26426;&#21327;&#21516;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20195;&#29702;&#39640;&#26031;&#36827;&#31243;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#20197;&#38477;&#20302;&#36890;&#20449;&#24320;&#38144;&#65292;&#33719;&#24471;&#27425;&#20248;&#36951;&#25022;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#20013;&#22830;&#26381;&#21153;&#22120;&#21327;&#35843;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#21327;&#21516;&#23398;&#20064;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#37117;&#24076;&#26395;&#26368;&#22823;&#21270;&#20854;&#20010;&#24615;&#21270;&#30446;&#26631;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#26159;&#20854;&#26412;&#22320;&#30446;&#26631;&#20989;&#25968;&#21644;&#20840;&#23616;&#30446;&#26631;&#20989;&#25968;&#30340;&#21152;&#26435;&#21644;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#30452;&#25509;&#35775;&#38382;&#20854;&#26412;&#22320;&#30446;&#26631;&#20989;&#25968;&#30340;&#38543;&#26426;&#36172;&#21338;&#21453;&#39304;&#65292;&#20294;&#21482;&#26377;&#23545;&#20840;&#23616;&#30446;&#26631;&#20989;&#25968;&#30340;&#37096;&#20998;&#35270;&#22270;&#65292;&#24182;&#23545;&#20854;&#20182;&#23458;&#25143;&#31471;&#36827;&#34892;&#20449;&#24687;&#20132;&#27969;&#20197;&#36827;&#34892;&#21327;&#21516;&#23398;&#20064;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20869;&#26680;&#30340;&#36172;&#21338;&#26426;&#26694;&#26550;&#65292;&#20854;&#20013;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20195;&#29702;&#39640;&#26031;&#36827;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#65288;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#20869;&#65289;&#30340;&#27425;&#20248;&#36951;&#25022;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#21487;&#20197;&#37319;&#29992;GP&#27169;&#22411;&#30340;&#31232;&#30095;&#36924;&#36817;&#26469;&#20943;&#23569;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study collaborative learning among distributed clients facilitated by a central server. Each client is interested in maximizing a personalized objective function that is a weighted sum of its local objective and a global objective. Each client has direct access to random bandit feedback on its local objective, but only has a partial view of the global objective and relies on information exchange with other clients for collaborative learning. We adopt the kernel-based bandit framework where the objective functions belong to a reproducing kernel Hilbert space. We propose an algorithm based on surrogate Gaussian process (GP) models and establish its order-optimal regret performance (up to polylogarithmic factors). We also show that the sparse approximations of the GP models can be employed to reduce the communication overhead across clients.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20195;&#29702;&#21464;&#37327;&#24754;&#35266;&#31574;&#30053;&#20248;&#21270; (P3O) &#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26500;&#24314;&#24754;&#35266;&#32622;&#20449;&#21306;&#38388;&#32806;&#21512;&#24207;&#21015;&#35299;&#20915;&#20102;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#28151;&#28102;&#20559;&#24046;&#21644;&#26368;&#20248;&#31574;&#30053;&#19982;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.13589</link><description>&lt;p&gt;
&#38754;&#23545;&#28151;&#28102;&#22240;&#32032;&#30340;&#24754;&#35266;&#24773;&#32490;&#65306;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#35777;&#26126;&#26377;&#25928;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes. (arXiv:2205.13589v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20195;&#29702;&#21464;&#37327;&#24754;&#35266;&#31574;&#30053;&#20248;&#21270; (P3O) &#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26500;&#24314;&#24754;&#35266;&#32622;&#20449;&#21306;&#38388;&#32806;&#21512;&#24207;&#21015;&#35299;&#20915;&#20102;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#28151;&#28102;&#20559;&#24046;&#21644;&#26368;&#20248;&#31574;&#30053;&#19982;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26088;&#22312;&#20174;&#30001;&#34892;&#20026;&#31574;&#30053;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21487;&#33021;&#21462;&#20915;&#20110;&#28508;&#22312;&#29366;&#24577;&#12290;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#22312;&#28151;&#28102;&#24847;&#20041;&#19978;&#21516;&#26102;&#24433;&#21709;&#34892;&#21160;&#21644;&#35266;&#27979;&#20540;&#65292;&#36825;&#23545;&#20110;&#29616;&#26377;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35828;&#26159;&#31105;&#27490;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#26500;&#24314;&#30340;&#24754;&#35266;&#32622;&#20449;&#21306;&#38388;&#32806;&#21512;&#24207;&#21015;&#30340;&#20195;&#29702;&#21464;&#37327;&#24754;&#35266;&#31574;&#30053;&#20248;&#21270;&#65288;P3O&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#24191;&#20041;&#20989;&#25968;&#36924;&#36817;&#30340;&#19978;&#19979;&#25991;&#20013;&#35299;&#20915;&#20102;&#28151;&#28102;&#20559;&#24046;&#21644;&#26368;&#20248;&#31574;&#30053;&#19982;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28151;&#28102;&#25968;&#25454;&#38598;&#30340;&#37096;&#20998;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;P3O&#21487;&#20197;&#23454;&#29616;n^{-1/2}&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;TSCI&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25506;&#32034;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;&#65292;&#24182;&#35843;&#25972;&#19981;&#21516;&#24418;&#24335;&#30340;&#20854;&#20182;&#24037;&#20855;&#21464;&#37327;&#20551;&#35774;&#36829;&#32972;&#65292;&#29992;&#20110;&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.12808</link><description>&lt;p&gt;
&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;: &#25506;&#32034;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Causal Inference with Invalid Instruments: Exploring Nonlinear Treatment Models with Machine Learning. (arXiv:2203.12808v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.12808
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;TSCI&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25506;&#32034;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;&#65292;&#24182;&#35843;&#25972;&#19981;&#21516;&#24418;&#24335;&#30340;&#20854;&#20182;&#24037;&#20855;&#21464;&#37327;&#20551;&#35774;&#36829;&#32972;&#65292;&#29992;&#20110;&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#30340;&#35266;&#27979;&#30740;&#31350;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20004;&#38454;&#27573;&#26354;&#29575;&#35782;&#21035;&#8221;(TSCI)&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25506;&#32034;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;&#65292;&#24182;&#35843;&#25972;&#19981;&#21516;&#24418;&#24335;&#30340;&#20854;&#20182;&#24037;&#20855;&#21464;&#37327;&#20551;&#35774;&#36829;&#32972;&#12290;TSCI&#30340;&#25104;&#21151;&#38656;&#35201;&#24037;&#20855;&#21464;&#37327;&#23545;&#27835;&#30103;&#30340;&#24433;&#21709;&#19982;&#20854;&#36829;&#32972;&#24418;&#24335;&#19981;&#21516;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#27493;&#26032;&#39062;&#30340;&#20559;&#24046;&#26657;&#27491;&#26469;&#28040;&#38500;&#21487;&#33021;&#39640;&#22797;&#26434;&#24230;&#26426;&#22120;&#23398;&#20064;&#25152;&#36896;&#25104;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;TSCI&#20272;&#35745;&#22120;&#21363;&#20351;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#19981;&#33021;&#19968;&#33268;&#22320;&#20272;&#35745;&#27835;&#30103;&#27169;&#22411;&#65292;&#20063;&#34987;&#35777;&#26126;&#26159;&#28176;&#36827;&#26080;&#20559;&#21644;&#27491;&#24577;&#30340;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#25968;&#25454;&#20381;&#36182;&#26041;&#27861;&#26469;&#36873;&#25321;&#20960;&#20010;&#20505;&#36873;&#36829;&#32972;&#24418;&#24335;&#20013;&#30340;&#26368;&#20339;&#24418;&#24335;&#12290;&#25105;&#20204;&#24212;&#29992;TSCI&#30740;&#31350;&#20102;&#25945;&#32946;&#23545;&#25910;&#20837;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We discuss causal inference for observational studies with possibly invalid instrumental variables. We propose a novel methodology called two-stage curvature identification (TSCI), which explores the nonlinear treatment model with machine learning and adjusts for different forms of violating the instrumental variable assumptions. The success of TSCI requires the instrumental variable's effect on treatment to differ from its violation form. A novel bias correction step is implemented to remove bias resulting from potentially high complexity of machine learning. Our proposed TSCI estimator is shown to be asymptotically unbiased and normal even if the machine learning algorithm does not consistently estimate the treatment model. We design a data-dependent method to choose the best among several candidate violation forms. We apply TSCI to study the effect of education on earnings.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.11740</link><description>&lt;p&gt;
&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#23545;&#20851;&#38190;&#26399;&#30340;&#31070;&#32463;&#21487;&#22609;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#23454;&#29616;&#31361;&#35302;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#12290;&#65288;arXiv: 2203.11740v12 [cs.NE] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#31361;&#35302;&#20849;&#20139;&#36830;&#25509;&#26435;&#37325;&#20043;&#22806;&#65292;PNN&#36824;&#21253;&#25324;&#31361;&#35302;&#26377;&#25928;&#33539;&#22260;&#30340;&#26435;&#37325;[14-25]&#12290;PNN&#32771;&#34385;&#31361;&#35302;&#24378;&#24230;&#24179;&#34913;&#22312;&#31361;&#35302;&#21534;&#22124;&#30340;&#21160;&#24577;&#21644;&#38271;&#24230;&#24120;&#25968;&#20043;&#21644;&#30340;&#38745;&#24577;&#20013;[14]&#65292;&#24182;&#21253;&#21547;&#20102;&#40060;&#32676;&#34892;&#20026;&#30340;&#20808;&#23548;&#34892;&#20026;&#12290;&#31361;&#35302;&#24418;&#25104;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#20250;&#25233;&#21046;&#26641;&#31361;&#29983;&#25104;[15]&#12290;&#31867;&#20284;&#20110;Spring Boot&#20013;&#30340;&#24378;&#21046;&#38887;&#24615;&#65292;&#21453;&#21521;&#22238;&#36335;&#30340;&#35760;&#24518;&#25345;&#20037;&#24230;&#26799;&#24230;&#20063;&#23384;&#22312;&#12290;&#30456;&#23545;&#36739;&#22909;&#21644;&#36739;&#24046;&#30340;&#26799;&#24230;&#20449;&#24687;&#23384;&#20648;&#22312;&#31867;&#20284;&#20110;&#33041;&#35126;&#30340;&#35760;&#24518;&#30165;&#36857;&#32454;&#32990;&#20013;&#65292;&#22312;&#21453;&#21521;&#22238;&#36335;&#30340;&#31361;&#35302;&#24418;&#25104;&#20013;&#12290;&#20105;&#35758;&#35748;&#20026;&#20154;&#31867;&#28023;&#39532;&#31070;&#32463;&#20803;&#30340;&#20877;&#29983;&#33021;&#21147;&#26159;&#21542;&#25345;&#32493;&#21040;&#32769;&#24180;&#65292;&#24182;&#21487;&#33021;&#22312;&#21518;&#26399;&#36845;&#20195;&#20013;&#24418;&#25104;&#26032;&#30340;&#26356;&#38271;&#30340;&#22238;&#36335;[17,18]&#12290;&#20851;&#38381;&#20851;&#38190;&#26399;&#20250;&#23548;&#33268;&#31070;&#32463;&#32010;&#20081;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;[19]&#12290;&#32771;&#34385;&#21040;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#28608;&#27963;&#31361;&#35302;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#22238;&#24402;&#26694;&#26550;&#20013;&#30340;&#38477;&#32500;&#19982;Wasserstein&#31283;&#23450;&#24615;&#24212;&#29992;&#65292;&#38024;&#23545;&#22312;&#25200;&#21160;&#36755;&#20837;&#25968;&#25454;&#29992;&#20110;&#25311;&#21512;&#22238;&#24402;&#20989;&#25968;&#26102;&#20986;&#29616;&#30340;&#35823;&#24046;&#25512;&#23548;&#20102;&#31283;&#23450;&#24615;&#32467;&#26524;&#65292;&#24182;&#21033;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#26680;&#22238;&#24402;&#25991;&#29486;&#20013;&#30340;&#20272;&#35745;&#65292;&#25512;&#23548;&#20102;&#20004;&#27493;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2203.09347</link><description>&lt;p&gt;
&#38477;&#32500;&#19982;Wasserstein&#31283;&#23450;&#24615;&#22312;&#26680;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#22238;&#24402;&#26694;&#26550;&#20013;&#30340;&#38477;&#32500;&#19982;Wasserstein&#31283;&#23450;&#24615;&#24212;&#29992;&#65292;&#38024;&#23545;&#22312;&#25200;&#21160;&#36755;&#20837;&#25968;&#25454;&#29992;&#20110;&#25311;&#21512;&#22238;&#24402;&#20989;&#25968;&#26102;&#20986;&#29616;&#30340;&#35823;&#24046;&#25512;&#23548;&#20102;&#31283;&#23450;&#24615;&#32467;&#26524;&#65292;&#24182;&#21033;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#26680;&#22238;&#24402;&#25991;&#29486;&#20013;&#30340;&#20272;&#35745;&#65292;&#25512;&#23548;&#20102;&#20004;&#27493;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#22238;&#24402;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#26420;&#32032;&#30340;&#20004;&#27493;&#27861;&#65292;&#39318;&#20808;&#38477;&#20302;&#36755;&#20837;&#21464;&#37327;&#30340;&#32500;&#25968;&#65292;&#20877;&#20351;&#29992;&#26680;&#22238;&#24402;&#26469;&#39044;&#27979;&#36755;&#20986;&#21464;&#37327;&#12290;&#20026;&#20102;&#20998;&#26512;&#30001;&#27492;&#20135;&#29983;&#30340;&#22238;&#24402;&#35823;&#24046;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#38024;&#23545;Wasserstein&#36317;&#31163;&#30340;&#26032;&#30340;&#26680;&#22238;&#24402;&#31283;&#23450;&#24615;&#32467;&#26524;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#38480;&#21046;&#24403;&#25200;&#21160;&#36755;&#20837;&#25968;&#25454;&#29992;&#20110;&#25311;&#21512;&#22238;&#24402;&#20989;&#25968;&#26102;&#20986;&#29616;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#36890;&#29992;&#30340;&#31283;&#23450;&#24615;&#32467;&#26524;&#24212;&#29992;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#65292;&#21033;&#29992;&#24050;&#30693;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#26680;&#22238;&#24402;&#25991;&#29486;&#20013;&#30340;&#20272;&#35745;&#65292;&#25512;&#23548;&#20986;&#20102;&#20004;&#27493;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#21518;&#32773;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#20013;&#29305;&#21035;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a high-dimensional regression framework, we study consequences of the naive two-step procedure where first the dimension of the input variables is reduced and second, the reduced input variables are used to predict the output variable with kernel regression. In order to analyze the resulting regression errors, a novel stability result for kernel regression with respect to the Wasserstein distance is derived. This allows us to bound errors that occur when perturbed input data is used to fit the regression function. We apply the general stability result to principal component analysis (PCA). Exploiting known estimates from the literature on both principal component analysis and kernel regression, we deduce convergence rates for the two-step procedure. The latter turns out to be particularly useful in a semi-supervised setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24207;&#21015;&#23454;&#39564;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#65292;&#20351;&#29992;&#38750;&#21442;&#25968;&#26041;&#27861;&#23545;&#21453;&#20107;&#23454;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2202.06891</link><description>&lt;p&gt;
&#24207;&#21015;&#23454;&#39564;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference for sequential experiments. (arXiv:2202.06891v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.06891
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24207;&#21015;&#23454;&#39564;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#65292;&#20351;&#29992;&#38750;&#21442;&#25968;&#26041;&#27861;&#23545;&#21453;&#20107;&#23454;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#38024;&#23545;&#36830;&#32493;&#35774;&#35745;&#23454;&#39564;&#36827;&#34892;&#30340;&#20107;&#21518;&#32479;&#35745;&#25512;&#26029;&#65292;&#22312;&#27492;&#23454;&#39564;&#20013;&#65292;&#22810;&#20010;&#21333;&#20301;&#22312;&#22810;&#20010;&#26102;&#38388;&#28857;&#19978;&#20998;&#37197;&#27835;&#30103;&#65292;&#24182;&#20351;&#29992;&#38543;&#26102;&#38388;&#32780;&#36866;&#24212;&#30340;&#27835;&#30103;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#23545;&#36866;&#24212;&#24615;&#27835;&#30103;&#31574;&#30053;&#20570;&#20986;&#26368;&#23569;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#26368;&#23567;&#21487;&#33021;&#35268;&#27169;&#30340;&#21453;&#20107;&#23454;&#22343;&#20540;&#25552;&#20379;&#25512;&#26029;&#20445;&#35777;&#65292;&#21363;&#22312;&#27599;&#20010;&#21333;&#20301;&#21644;&#27599;&#20010;&#26102;&#38388;&#19979;&#65292;&#38024;&#23545;&#19981;&#21516;&#27835;&#30103;&#30340;&#24179;&#22343;&#32467;&#26524;&#12290;&#22312;&#27809;&#26377;&#23545;&#21453;&#20107;&#23454;&#22343;&#20540;&#36827;&#34892;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#22240;&#20026;&#26410;&#30693;&#21464;&#37327;&#27604;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#28857;&#36824;&#22810;&#12290;&#20026;&#20102;&#21462;&#24471;&#36827;&#23637;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#29992;&#20110;&#21453;&#20107;&#23454;&#22343;&#20540;&#19978;&#65292;&#35813;&#27169;&#22411;&#20316;&#20026;&#38750;&#21442;&#25968;&#24418;&#24335;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#20197;&#21069;&#24037;&#20316;&#20013;&#32771;&#34385;&#30340;&#21452;&#32447;&#24615;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#20351;&#29992;&#38750;&#21442;&#25968;&#26041;&#27861;&#36827;&#34892;&#20272;&#35745;&#65292;&#21363;&#26368;&#36817;&#37051;&#30340;&#21464;&#20307;&#65292;&#24182;&#20026;&#27599;&#20010;&#21333;&#20301;&#21644;&#27599;&#20010;&#26102;&#38388;&#30340;&#21453;&#20107;&#23454;&#22343;&#20540;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#39640;&#27010;&#29575;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider after-study statistical inference for sequentially designed experiments wherein multiple units are assigned treatments for multiple time points using treatment policies that adapt over time. Our goal is to provide inference guarantees for the counterfactual mean at the smallest possible scale -- mean outcome under different treatments for each unit and each time -- with minimal assumptions on the adaptive treatment policy. Without any structural assumptions on the counterfactual means, this challenging task is infeasible due to more unknowns than observed data points. To make progress, we introduce a latent factor model over the counterfactual means that serves as a non-parametric generalization of the non-linear mixed effects model and the bilinear latent factor model considered in prior works. For estimation, we use a non-parametric method, namely a variant of nearest neighbors, and establish a non-asymptotic high probability error bound for the counterfactual mean for ea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#21892;&#24847;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#25552;&#20379;&#20102;&#38750;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#39044;&#27979;&#22120;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#20559;&#21521;&#20110;&#19981;&#19968;&#33268;&#35299;&#30340;&#35777;&#26126;&#65292;&#20174;&#32780;&#35828;&#26126;&#21892;&#24847;&#36807;&#25311;&#21512;&#19981;&#20250;&#21457;&#29983;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#20934;&#32447;&#24615;&#22238;&#24402;&#20197;&#22806;&#12290;</title><link>http://arxiv.org/abs/2201.11489</link><description>&lt;p&gt;
&#21892;&#24847;&#36807;&#25311;&#21512;&#30340;&#38544;&#24615;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
The Implicit Bias of Benign Overfitting. (arXiv:2201.11489v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.11489
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#21892;&#24847;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#25552;&#20379;&#20102;&#38750;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#39044;&#27979;&#22120;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#20559;&#21521;&#20110;&#19981;&#19968;&#33268;&#35299;&#30340;&#35777;&#26126;&#65292;&#20174;&#32780;&#35828;&#26126;&#21892;&#24847;&#36807;&#25311;&#21512;&#19981;&#20250;&#21457;&#29983;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#20934;&#32447;&#24615;&#22238;&#24402;&#20197;&#22806;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#25311;&#21512;&#29616;&#35937;&#20013;&#30340;&#21892;&#24847;&#36807;&#25311;&#21512;&#65292;&#25351;&#30340;&#26159;&#20998;&#31867;&#22120;&#23436;&#32654;&#22320;&#25311;&#21512;&#20102;&#24102;&#26377;&#22122;&#22768;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#21516;&#26102;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#30340;&#26399;&#26395;&#25439;&#22833;&#12290;&#36817;&#24180;&#26469;&#65292;&#36825;&#19968;&#29616;&#35937;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#38500;&#20102;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#22806;&#65292;&#20173;&#28982;&#27809;&#26377;&#24471;&#21040;&#20805;&#20998;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#65292;&#25552;&#20379;&#20102;&#20851;&#20110;&#20309;&#26102;&#21487;&#20197;&#25110;&#19981;&#33021;&#26399;&#26395;&#21892;&#24847;&#36807;&#25311;&#21512;&#21457;&#29983;&#30340;&#33509;&#24178;&#26032;&#32467;&#26524;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20856;&#22411;&#19988;&#30456;&#24403;&#36890;&#29992;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#21892;&#24847;&#36807;&#25311;&#21512;&#25968;&#25454;&#27169;&#22411;&#65292;&#20854;&#20013;&#23558;&#26576;&#20010;&#22266;&#23450;&#32500;&#24230; $k$ &#30340;&#20219;&#24847;&#36755;&#20837;&#20998;&#24067;&#19982;&#39640;&#32500;&#20998;&#24067;&#36830;&#25509;&#22312;&#19968;&#36215;&#12290;&#23545;&#20110;&#38750;&#24517;&#39035;&#32463;&#36807;&#33391;&#22909;&#35268;&#23450;&#30340;&#32447;&#24615;&#22238;&#24402;&#65292;&#25105;&#20204;&#35777;&#26126;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#39044;&#27979;&#22120;&#65288;&#26631;&#20934;&#35757;&#32451;&#26041;&#27861;&#25152;&#25910;&#25947;&#21040;&#30340;&#65289;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;&#20559;&#21521;&#20110;&#19981;&#19968;&#33268;&#30340;&#35299;&#30340;&#65292;&#22240;&#27492;&#36890;&#24120;&#19981;&#20250;&#21457;&#29983;&#21892;&#24847;&#36807;&#25311;&#21512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#19968;&#31181;&#26041;&#27861;&#23558;&#20854;&#25193;&#23637;&#21040;&#26631;&#20934;&#32447;&#24615;&#22238;&#24402;&#20197;&#22806;&#12290;
&lt;/p&gt;
&lt;p&gt;
The phenomenon of benign overfitting, where a predictor perfectly fits noisy training data while attaining near-optimal expected loss, has received much attention in recent years, but still remains not fully understood beyond well-specified linear regression setups. In this paper, we provide several new results on when one can or cannot expect benign overfitting to occur, for both regression and classification tasks. We consider a prototypical and rather generic data model for benign overfitting of linear predictors, where an arbitrary input distribution of some fixed dimension $k$ is concatenated with a high-dimensional distribution. For linear regression which is not necessarily well-specified, we show that the minimum-norm interpolating predictor (that standard training methods converge to) is biased towards an inconsistent solution in general, hence benign overfitting will generally not occur. Moreover, we show how this can be extended beyond standard linear regression, by an argum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30417;&#30563;&#24335;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;ML4C&#65292;&#37319;&#29992;&#20102;&#26032;&#39062;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#20998;&#31867;&#26410;&#23631;&#34109;&#19977;&#20803;&#32452;&#26159;&#21542;&#26159;v-&#32467;&#26500;&#65292;&#24182;&#26500;&#24314;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2110.00637</link><description>&lt;p&gt;
ML4C: &#36890;&#36807;&#28508;&#22312;&#37051;&#22495;&#35266;&#23519;&#22240;&#26524;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
ML4C: Seeing Causality Through Latent Vicinity. (arXiv:2110.00637v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.00637
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#30417;&#30563;&#24335;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;ML4C&#65292;&#37319;&#29992;&#20102;&#26032;&#39062;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#20998;&#31867;&#26410;&#23631;&#34109;&#19977;&#20803;&#32452;&#26159;&#21542;&#26159;v-&#32467;&#26500;&#65292;&#24182;&#26500;&#24314;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#24335;&#22240;&#26524;&#23398;&#20064;&#65288;SCL&#65289;&#26088;&#22312;&#36890;&#36807;&#35775;&#38382;&#19982;&#22320;&#38754;&#30495;&#23454;&#22240;&#26524;&#20851;&#31995;&#30456;&#20851;&#30340;&#20808;&#21069;&#30475;&#21040;&#30340;&#25968;&#25454;&#38598;&#65292;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#39318;&#27425;&#23581;&#35797;&#35299;&#20915;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#30417;&#30563;&#30340;&#22909;&#22788;&#26159;&#20160;&#20040;&#65292;&#20197;&#21450;&#22914;&#20309;&#21463;&#30410;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38754;&#21521;&#22240;&#26524;&#23398;&#20064;&#30340;&#21452;&#38454;&#27573;&#33539;&#20363;&#65292;&#36890;&#36807;&#26174;&#24335;&#32771;&#34385;&#32467;&#26500;&#21487;&#35782;&#21035;&#24615;&#26469;&#35299;&#20915;SCL&#38382;&#39064;&#12290;&#25353;&#29031;&#36825;&#20010;&#33539;&#20363;&#65292;&#25105;&#20204;&#38024;&#23545;&#31163;&#25955;&#25968;&#25454;&#30340;SCL&#38382;&#39064;&#25552;&#20986;&#20102;ML4C&#12290;ML4C&#30340;&#26680;&#24515;&#26159;&#19968;&#20010;&#20108;&#20803;&#20998;&#31867;&#22120;&#65292;&#20854;&#26032;&#39062;&#30340;&#23398;&#20064;&#30446;&#26631;&#26159;&#20998;&#31867;&#26410;&#23631;&#34109;&#19977;&#20803;&#32452;&#65288;UT&#65289;&#26159;&#21542;&#26159;v-&#32467;&#26500;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20174;&#25552;&#20379;&#20102;&#30456;&#24212;&#39592;&#26550;&#30340;&#36755;&#20837;&#25968;&#25454;&#38598;&#24320;&#22987;&#65292;ML4C&#22312;&#23558;UT&#20998;&#31867;&#20026;v-&#32467;&#26500;&#21518;&#23545;&#20854;&#36827;&#34892;&#21462;&#21521;&#12290;&#36825;&#20123;v-&#32467;&#26500;&#19968;&#36215;&#29992;&#20110;&#26500;&#24314;&#26368;&#32456;&#36755;&#20986;&#12290;&#20026;&#35299;&#20915;&#22522;&#26412;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#30446;&#26631;&#65292;&#31216;&#20026;&#28508;&#22312;&#37051;&#22495;&#35782;&#21035;&#65292;&#36890;&#36807;&#23545;UT&#36827;&#34892;&#20998;&#31867;&#65292;&#26368;&#32456;&#33719;&#24471;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised Causal Learning (SCL) aims to learn causal relations from observational data by accessing previously seen datasets associated with ground truth causal relations. This paper presents a first attempt at addressing a fundamental question: What are the benefits from supervision and how does it benefit? Starting from seeing that SCL is not better than random guessing if the learning target is non-identifiable a priori, we propose a two-phase paradigm for SCL by explicitly considering structure identifiability. Following this paradigm, we tackle the problem of SCL on discrete data and propose ML4C. The core of ML4C is a binary classifier with a novel learning target: it classifies whether an Unshielded Triple (UT) is a v-structure or not. Specifically, starting from an input dataset with the corresponding skeleton provided, ML4C orients each UT once it is classified as a v-structure. These v-structures are together used to construct the final output. To address the fundamental que
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#21457;&#30005;&#35745;&#21010;&#38382;&#39064;&#20013;&#30340;&#20928;&#38656;&#27714;&#39044;&#27979;&#20915;&#31574;&#35268;&#21017;&#65292;&#24182;&#32771;&#34385;&#20102;&#31995;&#32479;&#30340;&#25104;&#26412;&#32467;&#26500;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#32463;&#36807;&#25968;&#20540;&#27979;&#35797;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2108.01003</link><description>&lt;p&gt;
&#20004;&#38454;&#27573;&#30005;&#21147;&#21457;&#30005;&#35745;&#21010;&#30340;&#20928;&#38656;&#27714;&#39044;&#27979;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Prescribing net demand for two-stage electricity generation scheduling. (arXiv:2108.01003v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.01003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#21457;&#30005;&#35745;&#21010;&#38382;&#39064;&#20013;&#30340;&#20928;&#38656;&#27714;&#39044;&#27979;&#20915;&#31574;&#35268;&#21017;&#65292;&#24182;&#32771;&#34385;&#20102;&#31995;&#32479;&#30340;&#25104;&#26412;&#32467;&#26500;&#21644;&#19981;&#30830;&#23450;&#24615;&#65292;&#32463;&#36807;&#25968;&#20540;&#27979;&#35797;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32771;&#34385;&#20102;&#30001;&#21069;&#21521;&#27966;&#36963;&#21644;&#23454;&#26102;&#37325;&#26032;&#35843;&#24230;&#32452;&#25104;&#30340;&#20004;&#38454;&#27573;&#21457;&#30005;&#35745;&#21010;&#38382;&#39064;&#12290;&#21069;&#32773;&#24517;&#39035;&#38754;&#23545;&#21253;&#25324;&#19981;&#21487;&#35843;&#24230;&#30005;&#21147;&#28040;&#36153;&#21644;&#21487;&#20877;&#29983;&#33021;&#28304;&#21457;&#30005;&#22312;&#20869;&#30340;&#19981;&#30830;&#23450;&#20928;&#38656;&#27714;&#12290;&#21518;&#32773;&#36890;&#36807;&#22312;&#31995;&#32479;&#23454;&#38469;&#36816;&#34892;&#26399;&#38388;&#21033;&#29992;&#24179;&#34913;&#30005;&#21147;&#24212;&#23545;&#30456;&#23545;&#20110;&#21069;&#21521;&#35745;&#21010;&#30340;&#21512;&#29702;&#20559;&#24046;&#12290;&#26631;&#20934;&#24037;&#19994;&#23454;&#36341;&#36890;&#36807;&#29992;&#20854;&#26465;&#20214;&#26399;&#26395;&#30340;&#33391;&#22909;&#20272;&#35745;&#20540;&#65288;&#36890;&#24120;&#31216;&#20026;&#28857;&#39044;&#27979;&#65289;&#26367;&#25442;&#19981;&#30830;&#23450;&#30340;&#20928;&#38656;&#27714;&#26469;&#22788;&#29702;&#21069;&#21521;&#38454;&#27573;&#30340;&#19981;&#30830;&#23450;&#20928;&#38656;&#27714;&#65292;&#20197;&#26368;&#23567;&#21270;&#23454;&#26102;&#24179;&#34913;&#30005;&#21147;&#30340;&#38656;&#27714;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#30005;&#21147;&#31995;&#32479;&#30340;&#25104;&#26412;&#32467;&#26500;&#39640;&#24230;&#19981;&#23545;&#31216;&#24182;&#19988;&#20381;&#36182;&#20110;&#20854;&#36816;&#34892;&#28857;&#65292;&#22240;&#27492;&#26368;&#23567;&#21270;&#30005;&#21147;&#19981;&#24179;&#34913;&#37327;&#24182;&#19981;&#19968;&#23450;&#19982;&#26368;&#23567;&#21270;&#25805;&#20316;&#25104;&#26412;&#19968;&#33268;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#23618;&#26041;&#26696;&#26469;&#26500;&#24314;&#19968;&#20010;&#20915;&#31574;&#35268;&#21017;&#65292;&#26681;&#25454;&#31995;&#32479;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#19981;&#23545;&#31216;&#25104;&#26412;&#32467;&#26500;&#65292;&#22312;&#21069;&#21521;&#27966;&#36963;&#38454;&#27573;&#39044;&#27979;&#20928;&#38656;&#27714;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a two-stage generation scheduling problem comprising a forward dispatch and a real-time re-dispatch. The former must be conducted facing an uncertain net demand that includes non-dispatchable electricity consumption and renewable power generation. The latter copes with the plausible deviations with respect to the forward schedule by making use of balancing power during the actual operation of the system. Standard industry practice deals with the uncertain net demand in the forward stage by replacing it with a good estimate of its conditional expectation (usually referred to as a point forecast), so as to minimize the need for balancing power in real time. However, it is well known that the cost structure of a power system is highly asymmetric and dependent on its operating point, with the result that minimizing the amount of power imbalances is not necessarily aligned with minimizing operating costs. In this paper, we propose a bilevel program to construct, from the availab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#22522;&#20110;&#19978;&#19979;&#25991;&#26641;&#30340;&#20351;&#29992;&#24182;&#21253;&#21547;&#20102;&#19968;&#32452;&#26377;&#25928;&#31639;&#27861;&#24037;&#20855;&#65292;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#27169;&#22411;&#31867;&#19968;&#36215;&#20351;&#29992;&#65292;&#26500;&#24314;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2106.03023</link><description>&lt;p&gt;
&#24102;&#23618;&#27425;&#28151;&#21512;&#27169;&#22411;&#30340;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#19978;&#19979;&#25991;&#26641;&#21152;&#26435;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Context-tree weighting for real-valued time series: Bayesian inference with hierarchical mixture models. (arXiv:2106.03023v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#22522;&#20110;&#19978;&#19979;&#25991;&#26641;&#30340;&#20351;&#29992;&#24182;&#21253;&#21547;&#20102;&#19968;&#32452;&#26377;&#25928;&#31639;&#27861;&#24037;&#20855;&#65292;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#27169;&#22411;&#31867;&#19968;&#36215;&#20351;&#29992;&#65292;&#26500;&#24314;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#38750;&#24120;&#26222;&#36941;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23618;&#27425;&#36125;&#21494;&#26031;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#26102;&#38388;&#24207;&#21015;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#19978;&#19979;&#25991;&#26641;&#30340;&#20351;&#29992;&#65292;&#24182;&#21253;&#25324;&#19968;&#32452;&#26377;&#25928;&#30340;&#23398;&#20064;&#21644;&#25512;&#26029;&#31639;&#27861;&#24037;&#20855;&#12290;&#20026;&#27599;&#20010;&#26679;&#26412;&#25552;&#21462;&#19968;&#20010;&#31163;&#25955;&#19978;&#19979;&#25991;&#65288;&#25110;&#8220;&#29366;&#24577;&#8221;&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#20854;&#20043;&#21069;&#30340;&#19968;&#20123;&#26368;&#26032;&#35266;&#27979;&#30340;&#31163;&#25955;&#21270;&#29256;&#26412;&#12290;&#25152;&#26377;&#30456;&#20851;&#19978;&#19979;&#25991;&#30340;&#38598;&#21512;&#34920;&#31034;&#20026;&#31163;&#25955;&#19978;&#19979;&#25991;&#26641;&#12290;&#22312;&#26368;&#24213;&#23618;&#65292;&#23558;&#19981;&#21516;&#30340;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19982;&#27599;&#20010;&#19978;&#19979;&#25991;&#29366;&#24577;&#65288;&#21363;&#26641;&#30340;&#27599;&#20010;&#21494;&#23376;&#65289;&#30456;&#20851;&#32852;&#12290;&#36825;&#23450;&#20041;&#20102;&#19968;&#20010;&#38750;&#24120;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#19982;&#20219;&#20309;&#29616;&#26377;&#27169;&#22411;&#31867;&#19968;&#36215;&#20351;&#29992;&#65292;&#20197;&#26500;&#24314;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#25193;&#23637;&#19978;&#19979;&#25991;&#26641;&#21152;&#26435;&#30340;&#24819;&#27861;&#20250;&#23548;&#33268;&#19968;&#20123;&#31639;&#27861;&#65292;&#20801;&#35768;&#22312;&#27492;&#35774;&#32622;&#20013;&#36827;&#34892;&#39640;&#25928;&#12289;&#30830;&#20999;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-valued time series are ubiquitous in the sciences and engineering. In this work, a general, hierarchical Bayesian modelling framework is developed for building mixture models for times series. This development is based, in part, on the use of context trees, and it includes a collection of effective algorithmic tools for learning and inference. A discrete context (or 'state') is extracted for each sample, consisting of a discretised version of some of the most recent observations preceding it. The set of all relevant contexts are represented as a discrete context-tree. At the bottom level, a different real-valued time series model is associated with each context-state, i.e., with each leaf of the tree. This defines a very general framework that can be used in conjunction with any existing model class to build flexible and interpretable mixture models. Extending the idea of context-tree weighting leads to algorithms that allow for efficient, exact Bayesian inference in this setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#26041;&#27861;Balanced Entropy Acquisition&#65288;BalEntAcq&#65289;&#65292;&#36890;&#36807;&#25429;&#25417;&#28508;&#22312;softmax&#27010;&#29575;&#21644;&#26631;&#31614;&#21464;&#37327;&#30340;&#20449;&#24687;&#24179;&#34913;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#24179;&#34913;&#29109;&#23398;&#20064;&#20934;&#21017;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2105.14559</link><description>&lt;p&gt;
&#22522;&#20110;&#24179;&#34913;&#29109;&#23398;&#20064;&#20934;&#21017;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle. (arXiv:2105.14559v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.14559
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#26041;&#27861;Balanced Entropy Acquisition&#65288;BalEntAcq&#65289;&#65292;&#36890;&#36807;&#25429;&#25417;&#28508;&#22312;softmax&#27010;&#29575;&#21644;&#26631;&#31614;&#21464;&#37327;&#30340;&#20449;&#24687;&#24179;&#34913;&#65292;&#23454;&#29616;&#20102;&#22522;&#20110;&#24179;&#34913;&#29109;&#23398;&#20064;&#20934;&#21017;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20855;&#26377;&#26377;&#38480;&#39044;&#31639;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#33719;&#21462;&#26631;&#35760;&#25968;&#25454;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20027;&#21160;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#24182;&#36890;&#36807;&#20943;&#23569;&#26631;&#35760;&#25104;&#26412;&#26469;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#30340;&#36807;&#31243;&#12290;&#20449;&#24687;&#26368;&#22823;&#21270;&#23398;&#20064;&#21407;&#21017;&#65288;&#20363;&#22914; BALD&#65289;&#26368;&#22823;&#21270;&#30456;&#20114;&#20449;&#24687;&#24050;&#32463;&#22312;&#21508;&#31181;&#20027;&#21160;&#23398;&#20064;&#24212;&#29992;&#20013;&#25104;&#21151;&#22320;&#24191;&#27867;&#37319;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#29305;&#23450;&#20110;&#27744;&#30340;&#30446;&#26631;&#26412;&#36136;&#19978;&#24341;&#20837;&#20102;&#20887;&#20313;&#36873;&#25321;&#65292;&#24182;&#36827;&#19968;&#27493;&#38656;&#35201;&#39640;&#35745;&#31639;&#25104;&#26412;&#36827;&#34892;&#25209;&#22788;&#29702;&#36873;&#25321;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#26041;&#27861;Balanced Entropy Acquisition&#65288;BalEntAcq&#65289;&#65292;&#23427;&#25429;&#25417;&#20102;&#28508;&#22312;softmax&#27010;&#29575;&#21644;&#26631;&#31614;&#21464;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#20043;&#38388;&#30340;&#20449;&#24687;&#24179;&#34913;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;Beta&#20998;&#24067;&#36924;&#36817;&#27599;&#20010;&#36793;&#32536;&#20998;&#24067;&#12290;Beta&#36924;&#36817;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;BalEntAcq&#21046;&#23450;&#20026;&#22686;&#24378;&#29109;&#21644;&#36793;&#32536;&#32852;&#21512;&#29109;&#20043;&#38388;&#30340;&#27604;&#29575;&#12290;&#25152;&#24471;&#21040;&#30340;BalEntAcq&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#21487;&#20197;&#39640;&#25928;&#22320;&#35745;&#31639;&#24182;&#19982;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#22312;&#21253;&#25324;&#22270;&#20687;&#20998;&#31867;&#65292;&#30446;&#26631;&#26816;&#27979;&#21644;&#35821;&#20041;&#20998;&#21106;&#20219;&#21153;&#22312;&#20869;&#30340;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26174;&#33879;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#21516;&#26102;&#65292;&#36798;&#21040;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information such as BALD has been successful and widely adapted in various active learning applications. However, this pool-based specific objective inherently introduces a redundant selection and further requires a high computational cost for batch selection. In this paper, we design and propose a new uncertainty measure, Balanced Entropy Acquisition (BalEntAcq), which captures the information balance between the uncertainty of underlying softmax probability and the label variable. To do this, we approximate each marginal distribution by Beta distribution. Beta approximation enables us to formulate BalEntAcq as a ratio between an augmented entropy and the marginalized joint entropy. The closed-form expr
&lt;/p&gt;</description></item><item><title>CogDL&#26159;&#19968;&#20010;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#32508;&#21512;&#24211;&#65292;&#38024;&#23545;&#22270;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#21644;&#22797;&#26434;&#20219;&#21153;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35757;&#32451;&#21644;&#35780;&#20272;&#35774;&#35745;&#21644;&#22810;&#31181;&#35757;&#32451;&#25216;&#26415;&#65292;&#21253;&#25324;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#29616;&#21644;&#23454;&#29992;&#24037;&#20855;&#65292;&#26159;&#36827;&#34892;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2103.00959</link><description>&lt;p&gt;
CogDL&#65306;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#32508;&#21512;&#24211;
&lt;/p&gt;
&lt;p&gt;
CogDL: A Comprehensive Library for Graph Deep Learning. (arXiv:2103.00959v4 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.00959
&lt;/p&gt;
&lt;p&gt;
CogDL&#26159;&#19968;&#20010;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#32508;&#21512;&#24211;&#65292;&#38024;&#23545;&#22270;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#21644;&#22797;&#26434;&#20219;&#21153;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35757;&#32451;&#21644;&#35780;&#20272;&#35774;&#35745;&#21644;&#22810;&#31181;&#35757;&#32451;&#25216;&#26415;&#65292;&#21253;&#25324;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#23454;&#29616;&#21644;&#23454;&#29992;&#24037;&#20855;&#65292;&#26159;&#36827;&#34892;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#22312;&#22270;&#23398;&#20064;&#31038;&#21306;&#20013;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#37319;&#29992;&#65292;&#27604;&#22914;&#31038;&#20132;&#32593;&#32476;&#21644;&#29983;&#29289;&#22270;&#12290;&#28982;&#32780;&#65292;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#23384;&#22312;&#19968;&#20123;&#26032;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;&#22270;&#25968;&#25454;&#31232;&#30095;&#24615;&#12289;GNN&#22797;&#26434;&#30340;&#35757;&#32451;&#21644;&#22270;&#20219;&#21153;&#30340;&#38750;&#26631;&#20934;&#35780;&#20272;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CogDL&#65292;&#19968;&#20010;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#32508;&#21512;&#24211;&#65292;&#20801;&#35768;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#36731;&#26494;&#39640;&#25928;&#22320;&#36827;&#34892;&#23454;&#39564;&#12289;&#27604;&#36739;&#26041;&#27861;&#21644;&#26500;&#24314;&#24212;&#29992;&#12290;&#22312;CogDL&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#20110;&#21508;&#31181;&#22270;&#20219;&#21153;&#30340;GNN&#27169;&#22411;&#35757;&#32451;&#21644;&#35780;&#20272;&#30340;&#32479;&#19968;&#35774;&#35745;&#65292;&#20351;&#20854;&#22312;&#29616;&#26377;&#30340;&#22270;&#23398;&#20064;&#24211;&#20013;&#29420;&#26641;&#19968;&#24092;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#20010;&#32479;&#19968;&#30340;&#35757;&#32451;&#22120;&#65292;CogDL&#21487;&#20197;&#20248;&#21270;GNN&#35757;&#32451;&#24490;&#29615;&#65292;&#37319;&#29992;&#28151;&#21512;&#31934;&#24230;&#35757;&#32451;&#31561;&#22810;&#31181;&#35757;&#32451;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38024;&#23545;&#21508;&#31181;GNN&#27169;&#22411;&#24320;&#21457;&#20102;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#30340;&#23454;&#29616;&#65292;&#21253;&#25324;&#32463;&#20856;&#27169;&#22411;&#21644;&#26368;&#26032;&#30340;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;CogDL&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#30340;&#23454;&#29992;&#24037;&#20855;&#21644;&#24037;&#20855;&#65292;&#25903;&#25345;&#22270;&#28145;&#24230;&#23398;&#20064;&#30340;&#24320;&#21457;&#65292;&#22914;&#25968;&#25454;&#21152;&#36733;&#22120;&#21644;&#35780;&#20272;&#25351;&#26631;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#22312;&#27969;&#34892;&#22270;&#25968;&#25454;&#38598;&#19978;&#30340;&#24191;&#27867;&#23454;&#39564;&#35777;&#26126;&#20102;CogDL&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#20026;&#21508;&#31181;&#22270;&#20219;&#21153;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have attracted tremendous attention from the graph learning community in recent years. It has been widely adopted in various real-world applications from diverse domains, such as social networks and biological graphs. The research and applications of graph deep learning present new challenges, including the sparse nature of graph data, complicated training of GNNs, and non-standard evaluation of graph tasks. To tackle the issues, we present CogDL, a comprehensive library for graph deep learning that allows researchers and practitioners to conduct experiments, compare methods, and build applications with ease and efficiency. In CogDL, we propose a unified design for the training and evaluation of GNN models for various graph tasks, making it unique among existing graph learning libraries. By utilizing this unified trainer, CogDL can optimize the GNN training loop with several training techniques, such as mixed precision training. Moreover, we develop efficie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#32858;&#21512;&#26465;&#20214;&#20998;&#20301;&#25968;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#33021;&#22815;&#24212;&#29992;&#20110;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#24037;&#20855;&#21253;&#30340;&#22810;&#31181;&#27169;&#22411;&#65292;&#23545;&#35768;&#22810;&#20174;&#19994;&#32773;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2103.00083</link><description>&lt;p&gt;
&#28789;&#27963;&#30340;&#27169;&#22411;&#32858;&#21512;&#26041;&#27861;&#29992;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Flexible Model Aggregation for Quantile Regression. (arXiv:2103.00083v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.00083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#32858;&#21512;&#26465;&#20214;&#20998;&#20301;&#25968;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#33021;&#22815;&#24212;&#29992;&#20110;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#24037;&#20855;&#21253;&#30340;&#22810;&#31181;&#27169;&#22411;&#65292;&#23545;&#35768;&#22810;&#20174;&#19994;&#32773;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#20301;&#25968;&#22238;&#24402;&#26159;&#19968;&#31181;&#29992;&#20110;&#32479;&#35745;&#23398;&#20064;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#26088;&#22312;&#37327;&#21270;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25110;&#22312;&#19981;&#36807;&#24230;&#31616;&#21270;&#30340;&#24773;&#20917;&#19979;&#23545;&#22810;&#26679;&#21270;&#20154;&#32676;&#24314;&#27169;&#12290;&#26412;&#25991;&#30740;&#31350;&#32858;&#21512;&#20219;&#24847;&#25968;&#37327;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#24182;&#32771;&#34385;&#26435;&#37325;&#38598;&#25104;&#65292;&#26435;&#37325;&#19981;&#20165;&#21487;&#20197;&#21464;&#21270;&#20110;&#21333;&#20010;&#27169;&#22411;&#65292;&#36824;&#21487;&#20197;&#21464;&#21270;&#20110;&#20998;&#20301;&#25968;&#27700;&#24179;&#21644;&#29305;&#24449;&#20540;&#12290;&#26412;&#25991;&#25152;&#32771;&#34385;&#30340;&#25152;&#26377;&#27169;&#22411;&#22343;&#21487;&#20351;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#24037;&#20855;&#21253;&#25311;&#21512;&#65292;&#22240;&#27492;&#23545;&#35768;&#22810;&#20174;&#19994;&#32773;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65288;&#20174;&#23454;&#29616;&#30340;&#35282;&#24230;&#26469;&#30475;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile regression is a fundamental problem in statistical learning motivated by a need to quantify uncertainty in predictions, or to model a diverse population without being overly reductive. For instance, epidemiological forecasts, cost estimates, and revenue predictions all benefit from being able to quantify the range of possible values accurately. As such, many models have been developed for this problem over many years of research in statistics, machine learning, and related fields. Rather than proposing yet another (new) algorithm for quantile regression we adopt a meta viewpoint: we investigate methods for aggregating any number of conditional quantile models, in order to improve accuracy and robustness. We consider weighted ensembles where weights may vary over not only individual models, but also over quantile levels, and feature values. All of the models we consider in this paper can be fit using modern deep learning toolkits, and hence are widely accessible (from an implem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#23545;&#25239;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19968;&#32452;&#19982;&#21487;&#29992;&#30693;&#35782;&#30456;&#23481;&#30340;&#20808;&#39564;&#20998;&#24067;&#20013;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340; Bayes &#39118;&#38505;&#30340; Gamma-Minimax &#20272;&#35745;&#22120;&#65292;&#25991;&#20013;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31867;&#29992;&#20110;&#25552;&#20379;&#20272;&#35745;&#22120;&#31867;&#65292;&#20197;&#21450;&#20004;&#20010;&#23454;&#39564;&#29615;&#33410;&#29992;&#20110;&#35828;&#26126;&#35813;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2012.05465</link><description>&lt;p&gt;
&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#30340; Gamma-Minimax &#20272;&#35745;&#22120;&#30340;&#23545;&#25239;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarial Meta-Learning of Gamma-Minimax Estimators That Leverage Prior Knowledge. (arXiv:2012.05465v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#23545;&#25239;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19968;&#32452;&#19982;&#21487;&#29992;&#30693;&#35782;&#30456;&#23481;&#30340;&#20808;&#39564;&#20998;&#24067;&#20013;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340; Bayes &#39118;&#38505;&#30340; Gamma-Minimax &#20272;&#35745;&#22120;&#65292;&#25991;&#20013;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31867;&#29992;&#20110;&#25552;&#20379;&#20272;&#35745;&#22120;&#31867;&#65292;&#20197;&#21450;&#20004;&#20010;&#23454;&#39564;&#29615;&#33410;&#29992;&#20110;&#35828;&#26126;&#35813;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20272;&#35745;&#25552;&#20379;&#20102;&#19968;&#31181;&#23558;&#33021;&#22815;&#20197;&#21333;&#20010;&#20808;&#39564;&#20998;&#24067;&#30340;&#24418;&#24335;&#34920;&#36798;&#30340;&#20808;&#39564;&#30693;&#35782;&#32467;&#21512;&#36215;&#26469;&#30340;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#24403;&#36825;&#31181;&#30693;&#35782;&#22826;&#27169;&#31946;&#65292;&#26080;&#27861;&#29992;&#21333;&#20010;&#20808;&#39564;&#34920;&#31034;&#26102;&#65292;&#23601;&#38656;&#35201;&#21478;&#19968;&#31181;&#26041;&#27861;&#12290;Gamma-minimax &#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#36825;&#26679;&#19968;&#31181;&#26041;&#27861;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#23558;&#22312;&#19982;&#21487;&#29992;&#30693;&#35782;&#30456;&#23481;&#30340;&#19968;&#32452;&#20808;&#39564;&#20998;&#24067; $\Gamma$ &#19978;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#30340; Bayes &#39118;&#38505;&#12290;&#20256;&#32479;&#19978;&#65292;Gamma-minimax &#24615;&#36136;&#26159;&#20026;&#21442;&#25968;&#27169;&#22411;&#23450;&#20041;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#19968;&#33324;&#27169;&#22411;&#23450;&#20041; Gamma-minimax &#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#21033;&#29992;&#19968;&#33324;&#21270;&#30697;&#38480;&#21046;&#30340;&#23545;&#25239;&#20803;&#23398;&#20064;&#31639;&#27861;&#26469;&#35745;&#31639;&#23427;&#20204;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#31867;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#20016;&#23500;&#20294;&#26377;&#38480;&#32500;&#24230;&#30340;&#20272;&#35745;&#22120;&#31867;&#65292;&#21487;&#20197;&#20174;&#20013;&#36873;&#25321; Gamma-minimax &#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#29615;&#33410;&#20013;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21363;&#20272;&#35745;&#26410;&#30693;&#25903;&#25345;&#20998;&#24067;&#30340;&#26679;&#26412;&#29109;&#21644;&#21518;&#20998;&#23618;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayes estimators are well known to provide a means to incorporate prior knowledge that can be expressed in terms of a single prior distribution. However, when this knowledge is too vague to express with a single prior, an alternative approach is needed. Gamma-minimax estimators provide such an approach. These estimators minimize the worst-case Bayes risk over a set $\Gamma$ of prior distributions that are compatible with the available knowledge. Traditionally, Gamma-minimaxity is defined for parametric models. In this work, we define Gamma-minimax estimators for general models and propose adversarial meta-learning algorithms to compute them when the set of prior distributions is constrained by generalized moments. Accompanying convergence guarantees are also provided. We also introduce a neural network class that provides a rich, but finite-dimensional, class of estimators from which a Gamma-minimax estimator can be selected. We illustrate our method in two settings, namely entropy est
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#32467;&#26500;&#65292;&#21457;&#29616;&#23427;&#20204;&#37117;&#20849;&#20139;&#19968;&#31181;&#24120;&#35265;&#32467;&#26500;&#32780;&#37096;&#20998;&#30830;&#23450;&#20102;&#30495;&#27491;&#30340;&#20301;&#32622;&#28151;&#21512;&#29289;&#30340;&#31751;&#20013;&#24515;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#28385;&#36275;&#26576;&#31181;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#20063;&#36866;&#29992;&#20110;&#25104;&#20998;&#25968;&#37327;&#36807;&#22810;&#25110;&#36807;&#23569;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2009.13040</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#23616;&#37096;&#26497;&#23567;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Local Minima Structures in Gaussian Mixture Models. (arXiv:2009.13040v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.13040
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#32467;&#26500;&#65292;&#21457;&#29616;&#23427;&#20204;&#37117;&#20849;&#20139;&#19968;&#31181;&#24120;&#35265;&#32467;&#26500;&#32780;&#37096;&#20998;&#30830;&#23450;&#20102;&#30495;&#27491;&#30340;&#20301;&#32622;&#28151;&#21512;&#29289;&#30340;&#31751;&#20013;&#24515;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#28385;&#36275;&#26576;&#31181;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#20063;&#36866;&#29992;&#20110;&#25104;&#20998;&#25968;&#37327;&#36807;&#22810;&#25110;&#36807;&#23569;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#20154;&#21475;&#26497;&#38480;&#30340;&#24773;&#20917;&#19979;&#35843;&#26597;&#20102;&#28151;&#21512;&#25104;&#20998;&#27169;&#22411;&#65288;GMM&#65289;&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#25506;&#35752;&#20102;&#20855;&#26377;&#19968;&#33324;&#25104;&#20998;&#25968;&#37327;&#30340;GMM&#30340;&#36127;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#32467;&#26500;&#12290;&#30001;&#20110;&#30446;&#26631;&#20989;&#25968;&#26159;&#38750;&#20984;&#30340;&#65292;&#21363;&#20351;&#23545;&#20110;&#20998;&#31163;&#33391;&#22909;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#20063;&#21487;&#33021;&#23384;&#22312;&#19981;&#26159;&#20840;&#23616;&#26368;&#20248;&#30340;&#22810;&#20010;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#25152;&#26377;&#23616;&#37096;&#26497;&#23567;&#20540;&#37117;&#20849;&#20139;&#19968;&#31181;&#24120;&#35265;&#32467;&#26500;&#65292;&#35813;&#32467;&#26500;&#37096;&#20998;&#30830;&#23450;&#20102;&#30495;&#27491;&#30340;&#20301;&#32622;&#28151;&#21512;&#29289;&#65288;&#21363;&#39640;&#26031;&#25104;&#20998;&#30340;&#22343;&#20540;&#65289;&#30340;&#31751;&#20013;&#24515;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#27599;&#20010;&#23616;&#37096;&#26497;&#23567;&#20540;&#21487;&#20197;&#34920;&#31034;&#20026;&#20004;&#31181;&#31867;&#22411;&#23376;&#37197;&#32622;&#30340;&#38750;&#37325;&#21472;&#32452;&#21512;&#65306;&#23558;&#21333;&#20010;&#22343;&#20540;&#20272;&#35745;&#19982;&#22810;&#20010;&#39640;&#26031;&#20998;&#37327;&#25311;&#21512;&#25110;&#23558;&#22810;&#20010;&#20272;&#35745;&#25311;&#21512;&#21040;&#21333;&#20010;&#30495;&#23454;&#20998;&#37327;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#30495;&#23454;&#28151;&#21512;&#32452;&#20998;&#28385;&#36275;&#26576;&#31181;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#22312;&#25104;&#20998;&#25968;&#37327;&#36807;&#22810;&#25110;&#36807;&#23569;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#26377;&#25928;&#30340;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#19968;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#35774;&#32622;&#25552;&#20379;&#20102;&#26356;&#31934;&#32454;&#30340;&#20998;&#26512;&#65292;&#36890;&#36807;&#32467;&#26500;&#35745;&#25968;&#35770;&#35777;&#23548;&#20986;&#20102;&#36825;&#20123;&#38750;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#31934;&#30830;&#25968;&#37327;&#21644;&#23427;&#20204;&#23545;&#24212;&#30340;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the landscape of the negative log-likelihood function of Gaussian Mixture Models (GMMs) with a general number of components in the population limit. As the objective function is non-convex, there can be multiple local minima that are not globally optimal, even for well-separated mixture models. Our study reveals that all local minima share a common structure that partially identifies the cluster centers (i.e., means of the Gaussian components) of the true location mixture. Specifically, each local minimum can be represented as a non-overlapping combination of two types of sub-configurations: fitting a single mean estimate to multiple Gaussian components or fitting multiple estimates to a single true component. These results apply to settings where the true mixture components satisfy a certain separation condition, and are valid even when the number of components is overor under-specified. We also present a more fine-grained analysis for the setting of one-dimensional G
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#21644;&#31561;&#24335;&#38480;&#21046;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#26410;&#30693;&#30340;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;</title><link>http://arxiv.org/abs/2006.09587</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;IV&#27169;&#22411;&#20013;&#30340;&#33258;&#36866;&#24212;&#39640;&#25928;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Adaptive, Rate-Optimal Hypothesis Testing in Nonparametric IV Models. (arXiv:2006.09587v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.09587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#21644;&#31561;&#24335;&#38480;&#21046;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36866;&#24212;&#26410;&#30693;&#30340;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#24182;&#36798;&#21040;&#20102;&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#65288;NPIV&#65289;&#27169;&#22411;&#20013;&#32467;&#26500;&#20989;&#25968;&#30340;&#19981;&#31561;&#24335;&#65288;&#22914;&#21333;&#35843;&#24615;&#12289;&#20984;&#24615;&#65289;&#21644;&#31561;&#24335;&#65288;&#22914;&#21442;&#25968;&#12289;&#21322;&#21442;&#25968;&#65289;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#22522;&#20110;&#20462;&#25913;&#29256;&#30340;&#30041;&#19968;&#27861;&#26679;&#26412;&#27169;&#25311;&#65292;&#35745;&#31639;&#21463;&#38480;&#21644;&#19981;&#21463;&#38480;&#31579;&#23376;NPIV&#20272;&#35745;&#37327;&#38388;&#30340;&#20108;&#27425;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35745;&#31639;&#31616;&#21333;&#12289;&#25968;&#25454;&#39537;&#21160;&#30340;&#31579;&#23376;&#35843;&#21442;&#21644;Bonferroni&#35843;&#25972;&#21345;&#26041;&#20020;&#30028;&#20540;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#26816;&#39564;&#36866;&#24212;&#26410;&#30693;&#30340;&#20869;&#29983;&#24615;&#24179;&#28369;&#24230;&#21644;&#24037;&#20855;&#24378;&#24230;&#65292;&#36798;&#21040;&#20102;$L^2$&#26368;&#23567;&#20540;&#29575;&#30340;&#33258;&#36866;&#24212;&#26368;&#20248;&#26816;&#39564;&#29575;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#22797;&#21512;&#38646;&#20551;&#35774;&#19979;&#20854;&#31867;&#22411;I&#35823;&#24046;&#30340;&#24635;&#20307;&#21644;&#20854;&#31867;&#22411;II&#35823;&#24046;&#30340;&#24635;&#20307;&#22343;&#19981;&#33021;&#34987;&#20219;&#20309;&#20854;&#20182;NPIV&#27169;&#22411;&#30340;&#20551;&#35774;&#26816;&#39564;&#25152;&#25552;&#39640;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new adaptive hypothesis test for inequality (e.g., monotonicity, convexity) and equality (e.g., parametric, semiparametric) restrictions on a structural function in a nonparametric instrumental variables (NPIV) model. Our test statistic is based on a modified leave-one-out sample analog of a quadratic distance between the restricted and unrestricted sieve NPIV estimators. We provide computationally simple, data-driven choices of sieve tuning parameters and Bonferroni adjusted chi-squared critical values. Our test adapts to the unknown smoothness of alternative functions in the presence of unknown degree of endogeneity and unknown strength of the instruments. It attains the adaptive minimax rate of testing in $L^2$.  That is, the sum of its type I error uniformly over the composite null and its type II error uniformly over nonparametric alternative models cannot be improved by any other hypothesis test for NPIV models of unknown regularities. Data-driven confidence sets in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#8212;&#8212;&#25200;&#21160;&#27169;&#22411;&#39537;&#21160;&#31639;&#27861;&#21644;&#20445;&#23432;&#27169;&#22411;&#39537;&#21160;&#31639;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#27169;&#22411;&#22312;&#36739;&#23567;&#30340;&#26679;&#26412;&#22823;&#23567;&#19979;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26497;&#23567;&#21270;&#26368;&#22823;&#31639;&#27861;&#20248;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2005.12900</link><description>&lt;p&gt;
&#29992;&#29983;&#25104;&#27169;&#22411;&#31361;&#30772;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26679;&#26412;&#22823;&#23567;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.12900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#8212;&#8212;&#25200;&#21160;&#27169;&#22411;&#39537;&#21160;&#31639;&#27861;&#21644;&#20445;&#23432;&#27169;&#22411;&#39537;&#21160;&#31639;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#27169;&#22411;&#22312;&#36739;&#23567;&#30340;&#26679;&#26412;&#22823;&#23567;&#19979;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26497;&#23567;&#21270;&#26368;&#22823;&#31639;&#27861;&#20248;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30528;&#30524;&#20110;&#22312;&#26377;&#29983;&#25104;&#27169;&#22411;&#65288;&#25110;&#27169;&#25311;&#22120;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#22686;&#24378;&#23398;&#20064;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#39318;&#20808;&#65292;&#32771;&#34385;&#24102;&#26377;&#25240;&#25187;&#30340;&#26080;&#38480;&#26102;&#38388;&#27493;&#38271;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#65292;&#20854;&#29366;&#24577;&#31354;&#38388;&#20026;$\mathcal{S}$&#65292;&#21160;&#20316;&#31354;&#38388;&#20026;$\mathcal{A}$&#12290;&#23613;&#31649;&#26377;&#35768;&#22810;&#20808;&#21069;&#30340;&#30740;&#31350;&#22312;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#26159;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#32479;&#35745;&#31934;&#24230;&#20043;&#38388;&#26435;&#34913;&#30340;&#23436;&#25972;&#22270;&#26223;&#23578;&#26410;&#30830;&#23450;&#12290;&#29305;&#21035;&#26159;&#65292;&#25152;&#26377;&#30340;&#20808;&#21069;&#32467;&#26524;&#37117;&#21463;&#21040;&#20005;&#37325;&#30340;&#26679;&#26412;&#22823;&#23567;&#38556;&#30861;&#65292;&#22240;&#20026;&#23427;&#20204;&#22768;&#31216;&#30340;&#32479;&#35745;&#20445;&#35777;&#20165;&#22312;&#26679;&#26412;&#22823;&#23567;&#36229;&#36807;&#33267;&#23569;$\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$&#26102;&#25165;&#25104;&#31435;&#12290;&#26412;&#25991;&#36890;&#36807;&#35777;&#26126;&#20004;&#20010;&#31639;&#27861;&#8212;&#8212;&#25200;&#21160;&#27169;&#22411;&#39537;&#21160;&#31639;&#27861;&#21644;&#20445;&#23432;&#27169;&#22411;&#39537;&#21160;&#31639;&#27861;&#8212;&#8212;&#22312;&#26679;&#26412;&#22823;&#23567;&#36229;&#36807;$\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$&#30340;&#24773;&#20917;&#19979;&#23601;&#33021;&#35777;&#26126;&#23427;&#20204;&#30340;&#26497;&#23567;&#21270;&#26368;&#22823;&#31639;&#27861;&#20248;&#21270;&#24615;&#33021;&#65288;&#20960;&#20046;&#31526;&#21512;&#19968;&#20123;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#38500;&#20102;&#26080;&#38480;&#26102;&#38388;&#27493;&#38271;M&#35299;&#20915;&#26041;&#26696;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#26377;&#38480;&#26679;&#26412;&#21644;&#36817;&#20284;&#20215;&#20540;&#36845;&#20195;&#38382;&#39064;&#65292;&#20197;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#31639;&#27861;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with the sample efficiency of reinforcement learning, assuming access to a generative model (or simulator). We first consider $\gamma$-discounted infinite-horizon Markov decision processes (MDPs) with state space $\mathcal{S}$ and action space $\mathcal{A}$. Despite a number of prior works tackling this problem, a complete picture of the trade-offs between sample complexity and statistical accuracy is yet to be determined. In particular, all prior results suffer from a severe sample size barrier, in the sense that their claimed statistical guarantees hold only when the sample size exceeds at least $\frac{|\mathcal{S}||\mathcal{A}|}{(1-\gamma)^2}$. The current paper overcomes this barrier by certifying the minimax optimality of two algorithms -- a perturbed model-based algorithm and a conservative model-based algorithm -- as soon as the sample size exceeds the order of $\frac{|\mathcal{S}||\mathcal{A}|}{1-\gamma}$ (modulo some log factor). Moving beyond infinite-
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#22522;&#30784;&#23454;&#29616;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#19982;&#31574;&#30053;&#32593;&#32476;&#32467;&#21512;&#65292;&#20351;&#31574;&#30053;&#32593;&#32476;&#33021;&#22815;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#23646;&#24615;&#32452;&#21512;&#19978;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;RL/IL&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2004.07200</link><description>&lt;p&gt;
&#36890;&#36807;&#35821;&#35328;&#22522;&#30784;&#23454;&#29616;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Compositional Policy Learning via Language Grounding. (arXiv:2004.07200v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.07200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35821;&#35328;&#22522;&#30784;&#23454;&#29616;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#19982;&#31574;&#30053;&#32593;&#32476;&#32467;&#21512;&#65292;&#20351;&#31574;&#30053;&#32593;&#32476;&#33021;&#22815;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#23646;&#24615;&#32452;&#21512;&#19978;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;RL/IL&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#21644;&#27169;&#20223;&#23398;&#20064;&#65288;IL&#65289;&#22312;&#26368;&#36817;&#37117;&#26377;&#20102;&#31361;&#30772;&#65292;&#20294;&#29616;&#26377;&#31639;&#27861;&#26080;&#27861;&#22312;&#35757;&#32451;&#29615;&#22659;&#20043;&#22806;&#36827;&#34892;&#25512;&#24191;&#12290;&#23454;&#38469;&#19978;&#65292;&#20154;&#31867;&#33021;&#22815;&#36890;&#36807;&#21033;&#29992;&#20808;&#21069;&#20851;&#20110;&#19990;&#30028;&#65288;&#22914;&#35821;&#35328;&#25551;&#36848;&#65289;&#30340;&#30693;&#35782;&#26469;&#24555;&#36895;&#36866;&#24212;&#26032;&#20219;&#21153;&#12290;&#20026;&#20102;&#20419;&#36827;&#24102;&#26377;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#35821;&#35328;&#24341;&#23548;&#20195;&#29702;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#39033;&#26032;&#30340;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#20219;&#21153;&#65292;&#20854;&#20013;&#29615;&#22659;&#34987;&#25551;&#36848;&#20026;&#19981;&#21516;&#23646;&#24615;&#30340;&#32452;&#21512;&#12290;&#30001;&#20110;&#27809;&#26377;&#20844;&#20849;&#29615;&#22659;&#25903;&#25345;&#36825;&#39033;&#30740;&#31350;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#24179;&#21488;BabyAI++&#65292;&#20854;&#20013;&#29615;&#22659;&#30340;&#21160;&#21147;&#23398;&#19982;&#35270;&#35273;&#22806;&#35266;&#35299;&#32806;&#12290;&#22312;&#27599;&#20010;&#22238;&#21512;&#20013;&#65292;BabyAI++&#25552;&#20379;&#20102;&#21508;&#31181;&#35270;&#35273;&#21160;&#21147;&#23398;&#32452;&#21512;&#20197;&#21450;&#30456;&#24212;&#30340;&#25551;&#36848;&#24615;&#25991;&#26412;&#12290;&#20026;&#20102;&#35780;&#20272;&#25152;&#23398;&#20195;&#29702;&#30340;&#33258;&#36866;&#24212;&#33021;&#21147;&#65292;&#19968;&#32452;&#35270;&#35273;&#21160;&#21147;&#23398;&#37197;&#23545;&#34987;&#20445;&#30041;&#22312;BabyAI++&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;&#19981;&#20986;&#25152;&#26009;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#21069;&#30340;&#35821;&#35328;&#24341;&#23548;RL/IL&#26041;&#27861;&#26080;&#27861;&#35299;&#20915;&#36825;&#20010;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#24341;&#23548;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#19982;&#31574;&#30053;&#32593;&#32476;&#32467;&#21512;&#65292;&#20351;&#31574;&#30053;&#32593;&#32476;&#33021;&#22815;&#25512;&#24191;&#21040;&#26410;&#35265;&#36807;&#30340;&#23646;&#24615;&#32452;&#21512;&#19978;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35821;&#35328;&#22522;&#30784;&#27169;&#22359;&#65292;&#23558;&#31526;&#21495;&#23646;&#24615;&#34920;&#31034;&#21644;&#33258;&#28982;&#35821;&#35328;&#36755;&#20837;&#38598;&#25104;&#21040;&#31574;&#30053;&#32593;&#32476;&#20013;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#38646;&#26679;&#26412;&#32452;&#21512;&#31574;&#30053;&#23398;&#20064;&#20219;&#21153;&#19978;&#26174;&#33879;&#20248;&#20110;&#29616;&#26377;&#30340;RL/IL&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite recent breakthroughs in reinforcement learning (RL) and imitation learning (IL), existing algorithms fail to generalize beyond the training environments. In reality, humans can adapt to new tasks quickly by leveraging prior knowledge about the world such as language descriptions. To facilitate the research on language-guided agents with domain adaption, we propose a novel zero-shot compositional policy learning task, where the environments are characterized as a composition of different attributes. Since there are no public environments supporting this study, we introduce a new research platform BabyAI++ in which the dynamics of environments are disentangled from visual appearance. At each episode, BabyAI++ provides varied vision-dynamics combinations along with corresponding descriptive texts. To evaluate the adaption capability of learned agents, a set of vision-dynamics pairings are held-out for testing on BabyAI++. Unsurprisingly, we find that current language-guided RL/IL 
&lt;/p&gt;</description></item><item><title>Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2002.01368</link><description>&lt;p&gt;
&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#25193;&#23637;&#31867;&#21035;&#30340;&#24320;&#25918;&#38598;&#23398;&#20064;&#65288;Open-LACU&#65289;
&lt;/p&gt;
&lt;p&gt;
Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.01368
&lt;/p&gt;
&lt;p&gt;
Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#21644;&#24320;&#25918;&#24335;&#35782;&#21035;&#65288;OSR&#65289;&#65292;&#24050;&#32463;&#36827;&#34892;&#20102;&#35768;&#22810;&#23581;&#35797;&#20197;&#21512;&#25104;&#21333;&#20010;&#35757;&#32451;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#27599;&#27425;&#23581;&#35797;&#37117;&#36829;&#21453;&#20102;&#24320;&#25918;&#38598;&#23450;&#20041;&#65292;&#22240;&#20026;&#36825;&#20123;&#26041;&#27861;&#22312;&#26410;&#26631;&#35760;&#30340;&#35757;&#32451;&#38598;&#20013;&#21253;&#21547;&#26032;&#39062;&#30340;&#31867;&#21035;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#20854;&#20013;&#20998;&#31867;&#22120;&#33021;&#22815;&#22312;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#36827;&#34892;&#25512;&#24191;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#32972;&#26223;&#31867;&#21035;&#21644;&#26410;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#26410;&#30693;&#31867;&#21035;&#12290;&#36890;&#36807;&#20998;&#31867;&#36825;&#20004;&#31181;&#26032;&#39062;&#31867;&#21035;&#30340;&#26041;&#24335;&#65292;Open-LACU&#33021;&#22815;&#25552;&#39640;&#35757;&#32451;&#30340;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#24182;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#36127;&#26680;&#22238;&#24402;&#30340;&#31639;&#27861;&#26469;&#26500;&#24314;&#26356;&#22909;&#30340;&#37051;&#22495;&#21644;&#22270;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#31034;&#20986;&#20854;&#20248;&#36234;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/1910.09383</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#36127;&#26680;&#22238;&#24402;&#26500;&#24314;&#37051;&#22495;&#21644;&#22270;
&lt;/p&gt;
&lt;p&gt;
Neighborhood and Graph Constructions using Non-Negative Kernel Regression. (arXiv:1910.09383v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.09383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#36127;&#26680;&#22238;&#24402;&#30340;&#31639;&#27861;&#26469;&#26500;&#24314;&#26356;&#22909;&#30340;&#37051;&#22495;&#21644;&#22270;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23637;&#31034;&#20986;&#20854;&#20248;&#36234;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#37051;&#22495;&#23450;&#20041;&#21644;&#22270;&#26500;&#24314;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#24212;&#29992;&#20013;&#32463;&#24120;&#20351;&#29992;&#12290;k&#36817;&#37051;&#65288;kNN&#65289;&#21644; $\epsilon$-&#37051;&#22495;&#26041;&#27861;&#26159;&#26368;&#24120;&#29992;&#30340;&#37051;&#22495;&#36873;&#25321;&#26041;&#27861;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#35745;&#31639;&#31616;&#21333;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#25152;&#28041;&#21450;&#30340;&#21442;&#25968;&#36873;&#25321;&#65292;&#22914; k &#21644; $\epsilon$&#65292;&#20173;&#28982;&#26159;&#20020;&#26102;&#30340;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#20027;&#35201;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37051;&#22495;&#36873;&#25321;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#20854;&#20013;&#25105;&#20204;&#34920;&#26126;&#37051;&#22495;&#26500;&#36896;&#31561;&#21516;&#20110;&#19968;&#20010;&#31232;&#30095;&#20449;&#21495;&#36924;&#36817;&#38382;&#39064;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#38750;&#36127;&#26680;&#22238;&#24402;&#65288;NNK&#65289;&#65292;&#29992;&#20110;&#33719;&#24471;&#26356;&#22909;&#30340;&#31232;&#30095;&#34920;&#31034;&#30340;&#37051;&#22495;&#12290;NNK&#19982;&#20449;&#21495;&#34920;&#31034;&#30340;&#27491;&#20132;&#21305;&#37197;&#36861;&#36394;&#26041;&#27861;&#30456;&#20284;&#65292;&#24182;&#20855;&#26377;&#33391;&#22909;&#30340;&#20960;&#20309;&#21644;&#29702;&#35770;&#24615;&#36136;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#65288;i&#65289;NNK&#31639;&#27861;&#22312;&#37051;&#22495;&#21644;&#22270;&#26500;&#24314;&#20013;&#30340;&#40065;&#26834;&#24615;&#65292;&#65288;ii&#65289;NNK&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20248;&#20110;&#20854;&#20182;&#27969;&#34892;&#30340;&#37051;&#22495;&#36873;&#25321;&#26041;&#27861;&#65292;&#20197;&#21450;&#65288;iii&#65289;NNK&#22312;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#20219;&#21153;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven neighborhood definitions and graph constructions are often used in machine learning and signal processing applications. k-nearest neighbor~(kNN) and $\epsilon$-neighborhood methods are among the most common methods used for neighborhood selection, due to their computational simplicity. However, the choice of parameters associated with these methods, such as k and $\epsilon$, is still ad hoc. We make two main contributions in this paper. First, we present an alternative view of neighborhood selection, where we show that neighborhood construction is equivalent to a sparse signal approximation problem. Second, we propose an algorithm, non-negative kernel regression~(NNK), for obtaining neighborhoods that lead to better sparse representation. NNK draws similarities to the orthogonal matching pursuit approach to signal representation and possesses desirable geometric and theoretical properties. Experiments demonstrate (i) the robustness of the NNK algorithm for neighborhood and 
&lt;/p&gt;</description></item></channel></rss>