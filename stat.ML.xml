<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#27169;&#22411;&#20013;&#30340;&#26435;&#37325;&#37327;&#21270;&#26041;&#27861;&#21450;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;&#36890;&#36807;&#20856;&#22411;&#26696;&#20363;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20302;&#20301;&#25968;&#21644;&#22823;&#37327;&#21270;&#23485;&#24230;&#20250;&#23548;&#33268;&#19981;&#31283;&#23450;&#30340;&#36229;&#21442;&#25968;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2401.17269</link><description>&lt;p&gt;
&#26435;&#37325;&#37327;&#21270;&#23545;&#20856;&#22411;&#26696;&#20363;&#20998;&#26512;&#20013;&#23398;&#20064;&#27169;&#22411;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Effect of Weight Quantization on Learning Models by Typical Case Analysis. (arXiv:2401.17269v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17269
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#27169;&#22411;&#20013;&#30340;&#26435;&#37325;&#37327;&#21270;&#26041;&#27861;&#21450;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;&#36890;&#36807;&#20856;&#22411;&#26696;&#20363;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20302;&#20301;&#25968;&#21644;&#22823;&#37327;&#21270;&#23485;&#24230;&#20250;&#23548;&#33268;&#19981;&#31283;&#23450;&#30340;&#36229;&#21442;&#25968;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#27169;&#22411;&#20013;&#20351;&#29992;&#30340;&#37327;&#21270;&#26041;&#27861;&#21450;&#20854;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;&#38543;&#30528;&#25968;&#25454;&#20998;&#26512;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#35745;&#31639;&#36164;&#28304;&#38656;&#27714;&#26174;&#33879;&#22686;&#21152;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#65288;&#22914;&#28145;&#24230;&#23398;&#20064;&#65289;&#20013;&#65292;&#37327;&#21270;&#27169;&#22411;&#26435;&#37325;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#24120;&#35265;&#30340;&#20570;&#27861;&#12290;&#23545;&#20110;&#22312;&#35745;&#31639;&#36164;&#28304;&#26377;&#38480;&#30340;&#35774;&#22791;&#19978;&#37096;&#32626;&#22823;&#22411;&#27169;&#22411;&#65292;&#37327;&#21270;&#23588;&#20026;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#37327;&#21270;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#22914;&#20301;&#25968;&#21644;&#26435;&#37325;&#37327;&#21270;&#30340;&#20540;&#33539;&#22260;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#32463;&#20805;&#20998;&#30740;&#31350;&#30340;&#39046;&#22495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#20856;&#22411;&#26696;&#20363;&#20998;&#26512;&#26041;&#27861;&#65292;&#20855;&#20307;&#26159;&#37325;&#22797;&#26041;&#27861;&#65292;&#26469;&#25506;&#32034;&#36229;&#21442;&#25968;&#23545;&#31616;&#21333;&#23398;&#20064;&#27169;&#22411;&#37327;&#21270;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24471;&#20986;&#20102;&#19977;&#20010;&#20851;&#38190;&#21457;&#29616;&#65306;&#65288;i&#65289;&#23567;&#20301;&#25968;&#21644;&#22823;&#37327;&#21270;&#23485;&#24230;&#20250;&#23548;&#33268;&#19981;&#31283;&#23450;&#30340;&#36229;&#21442;&#25968;&#38454;&#27573;&#65292;&#21363;&#37325;&#22797;&#23545;&#31216;&#24615;&#30772;&#32570;&#65307;&#65288;ii&#65289;
&lt;/p&gt;
&lt;p&gt;
This paper examines the quantization methods used in large-scale data analysis models and their hyperparameter choices. The recent surge in data analysis scale has significantly increased computational resource requirements. To address this, quantizing model weights has become a prevalent practice in data analysis applications such as deep learning. Quantization is particularly vital for deploying large models on devices with limited computational resources. However, the selection of quantization hyperparameters, like the number of bits and value range for weight quantization, remains an underexplored area. In this study, we employ the typical case analysis from statistical physics, specifically the replica method, to explore the impact of hyperparameters on the quantization of simple learning models. Our analysis yields three key findings: (i) an unstable hyperparameter phase, known as replica symmetry breaking, occurs with a small number of bits and a large quantization width; (ii) t
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;Syntax&#65292;&#19968;&#20010;&#20855;&#26377;&#21512;&#25104;&#23545;&#29031;&#32452;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#20122;&#32676;&#20307;&#20013;&#35782;&#21035;&#20986;&#20855;&#26377;&#27491;&#38754;&#27835;&#30103;&#25928;&#26524;&#30340;&#20122;&#32676;&#20307;&#65292;&#23545;&#20110;&#22810;&#26679;&#21270;&#24739;&#32773;&#21453;&#24212;&#30340;&#20020;&#24202;&#35797;&#39564;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.17205</link><description>&lt;p&gt;
&#20855;&#26377;&#21512;&#25104;&#23545;&#29031;&#32452;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experiment Design with Synthetic Controls. (arXiv:2401.17205v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17205
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;Syntax&#65292;&#19968;&#20010;&#20855;&#26377;&#21512;&#25104;&#23545;&#29031;&#32452;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#20122;&#32676;&#20307;&#20013;&#35782;&#21035;&#20986;&#20855;&#26377;&#27491;&#38754;&#27835;&#30103;&#25928;&#26524;&#30340;&#20122;&#32676;&#20307;&#65292;&#23545;&#20110;&#22810;&#26679;&#21270;&#24739;&#32773;&#21453;&#24212;&#30340;&#20020;&#24202;&#35797;&#39564;&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#35797;&#39564;&#36890;&#24120;&#29992;&#20110;&#20102;&#35299;&#26032;&#27835;&#30103;&#23545;&#32473;&#23450;&#24739;&#32773;&#32676;&#20307;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22823;&#35268;&#27169;&#32676;&#20307;&#20013;&#30340;&#24739;&#32773;&#24456;&#23569;&#20197;&#30456;&#21516;&#30340;&#26041;&#24335;&#23545;&#24453;&#30456;&#21516;&#30340;&#27835;&#30103;&#20570;&#20986;&#21453;&#24212;&#12290;&#24739;&#32773;&#21453;&#24212;&#30340;&#22810;&#26679;&#24615;&#38656;&#35201;&#36827;&#34892;&#22810;&#20010;&#20122;&#32676;&#20307;&#30340;&#25928;&#26524;&#30740;&#31350; - &#23588;&#20854;&#26159;&#24403;&#27835;&#30103;&#23545;&#25972;&#20307;&#32676;&#20307;&#27809;&#26377;&#25110;&#20960;&#20046;&#27809;&#26377;&#30410;&#22788;&#65292;&#32780;&#23545;&#29305;&#23450;&#20122;&#32676;&#20307;&#21487;&#33021;&#20855;&#26377;&#26174;&#33879;&#30340;&#30410;&#22788;&#26102;&#12290;&#22522;&#20110;&#36825;&#31181;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Syntax&#65292;&#19968;&#31181;&#25506;&#32034;&#24615;&#35797;&#39564;&#35774;&#35745;&#65292;&#22312;&#20247;&#22810;&#20122;&#32676;&#20307;&#20013;&#35782;&#21035;&#20855;&#26377;&#27491;&#38754;&#27835;&#30103;&#25928;&#26524;&#30340;&#20122;&#32676;&#20307;&#12290;Syntax&#20855;&#26377;&#26679;&#26412;&#25928;&#29575;&#65292;&#22240;&#20026;&#23427;(i) &#33258;&#36866;&#24212;&#25307;&#21215;&#21644;&#20998;&#37197;&#24739;&#32773;&#65292;(ii) &#36890;&#36807;&#21512;&#25104;&#23545;&#29031;&#32452;&#24418;&#25104;&#27599;&#20010;&#20122;&#32676;&#20307;&#30340;&#25511;&#21046;&#26679;&#26412;&#65292;&#20174;&#32780;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;Syntax&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#23427;&#20309;&#26102;&#21487;&#33021;&#20248;&#20110;&#20256;&#32479;&#35797;&#39564;&#35774;&#35745;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations - especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#28508;&#22312;&#29366;&#24577;&#26469;&#23398;&#20064;&#20010;&#20307;&#29305;&#23450;&#30340;&#35745;&#25968;&#36807;&#31243;&#24378;&#24230;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36275;&#22815;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#22312;&#31614;&#21517;&#31354;&#38388;&#20013;&#32447;&#24615;&#21270;&#27169;&#22411;&#65292;&#24471;&#21040;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#30340;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#23545;&#37329;&#34701;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#21644;&#39135;&#21697;&#20379;&#24212;&#38142;&#31649;&#29702;&#31561;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.17077</link><description>&lt;p&gt;
&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#19982;&#25511;&#21046;&#28508;&#22312;&#29366;&#24577;
&lt;/p&gt;
&lt;p&gt;
Dynamical Survival Analysis with Controlled Latent States. (arXiv:2401.17077v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#28508;&#22312;&#29366;&#24577;&#26469;&#23398;&#20064;&#20010;&#20307;&#29305;&#23450;&#30340;&#35745;&#25968;&#36807;&#31243;&#24378;&#24230;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36275;&#22815;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#22312;&#31614;&#21517;&#31354;&#38388;&#20013;&#32447;&#24615;&#21270;&#27169;&#22411;&#65292;&#24471;&#21040;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#30340;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#23545;&#37329;&#34701;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#21644;&#39135;&#21697;&#20379;&#24212;&#38142;&#31649;&#29702;&#31561;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#19968;&#32452;&#38745;&#24577;&#21464;&#37327;&#21644;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#23398;&#20064;&#20010;&#20307;&#29305;&#23450;&#30340;&#35745;&#25968;&#36807;&#31243;&#24378;&#24230;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#20854;&#20013;&#24378;&#24230;&#26159;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#26469;&#35774;&#35745;&#19968;&#20010;&#31070;&#32463;&#20272;&#35745;&#22120;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36275;&#22815;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#31614;&#21517;&#31354;&#38388;&#20013;&#32447;&#24615;&#21270;&#65292;&#24471;&#21040;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#30340;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;CoxSig&#12290;&#25105;&#20204;&#20026;&#36825;&#20004;&#31181;&#20272;&#35745;&#22120;&#25552;&#20379;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#37329;&#34701;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#21644;&#39135;&#21697;&#20379;&#24212;&#38142;&#31649;&#29702;&#31561;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of learning individual-specific intensities of counting processes from a set of static variables and irregularly sampled time series. We introduce a novel modelization approach in which the intensity is the solution to a controlled differential equation. We first design a neural estimator by building on neural controlled differential equations. In a second time, we show that our model can be linearized in the signature space under sufficient regularity conditions, yielding a signature-based estimator which we call CoxSig. We provide theoretical learning guarantees for both estimators, before showcasing the performance of our models on a vast array of simulated and real-world datasets from finance, predictive maintenance and food supply chain management.
&lt;/p&gt;</description></item><item><title>Gower&#30456;&#20284;&#31995;&#25968;&#26159;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#28151;&#21512;&#31867;&#22411;&#21464;&#37327;&#30340;&#26368;&#21463;&#27426;&#36814;&#30340;&#19981;&#30456;&#20284;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22788;&#29702;&#32570;&#22833;&#20540;&#24182;&#20801;&#35768;&#29992;&#25143;&#23450;&#20041;&#21152;&#26435;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.17041</link><description>&lt;p&gt;
Gower&#30456;&#20284;&#31995;&#25968;&#19982;&#33258;&#21160;&#26435;&#37325;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Gower's similarity coefficients with automatic weight selection. (arXiv:2401.17041v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17041
&lt;/p&gt;
&lt;p&gt;
Gower&#30456;&#20284;&#31995;&#25968;&#26159;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#28151;&#21512;&#31867;&#22411;&#21464;&#37327;&#30340;&#26368;&#21463;&#27426;&#36814;&#30340;&#19981;&#30456;&#20284;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22788;&#29702;&#32570;&#22833;&#20540;&#24182;&#20801;&#35768;&#29992;&#25143;&#23450;&#20041;&#21152;&#26435;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#37051;&#26041;&#27861;&#22312;&#32479;&#35745;&#23398;&#20013;&#21464;&#24471;&#27969;&#34892;&#36215;&#26469;&#65292;&#24182;&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#26368;&#36817;&#37051;&#26041;&#27861;&#20013;&#30340;&#37325;&#35201;&#20915;&#31574;&#28041;&#21450;&#35201;&#20351;&#29992;&#30340;&#21464;&#37327;&#65288;&#24403;&#23384;&#22312;&#35768;&#22810;&#28508;&#22312;&#20505;&#36873;&#21464;&#37327;&#26102;&#65289;&#20197;&#21450;&#22914;&#20309;&#27979;&#37327;&#21333;&#20301;&#20043;&#38388;&#30340;&#19981;&#30456;&#20284;&#24615;&#12290;&#31532;&#19968;&#20010;&#20915;&#31574;&#21462;&#20915;&#20110;&#24212;&#29992;&#30340;&#33539;&#22260;&#65292;&#32780;&#31532;&#20108;&#20010;&#20915;&#31574;&#20027;&#35201;&#21462;&#20915;&#20110;&#21464;&#37327;&#30340;&#31867;&#22411;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30456;&#23545;&#36739;&#23569;&#30340;&#36873;&#39033;&#21487;&#20197;&#22788;&#29702;&#28151;&#21512;&#31867;&#22411;&#30340;&#21464;&#37327;&#65292;&#36825;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#32463;&#24120;&#36935;&#21040;&#12290;&#28151;&#21512;&#31867;&#22411;&#21464;&#37327;&#30340;&#26368;&#21463;&#27426;&#36814;&#30340;&#19981;&#30456;&#20284;&#24615;&#26159;&#20316;&#20026;Gower&#30456;&#20284;&#31995;&#25968;&#30340;&#34917;&#38598;&#25512;&#23548;&#32780;&#26469;&#12290;&#23427;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#23427;&#30340;&#21462;&#20540;&#33539;&#22260;&#22312;0&#21644;1&#20043;&#38388;&#65292;&#26159;&#21464;&#37327;&#20043;&#38388;&#32553;&#25918;&#30340;&#19981;&#30456;&#20284;&#24615;&#30340;&#24179;&#22343;&#20540;&#65292;&#21487;&#20197;&#22788;&#29702;&#32570;&#22833;&#20540;&#65292;&#24182;&#19988;&#22312;&#24179;&#22343;&#19981;&#30456;&#20284;&#24615;&#26102;&#20801;&#35768;&#29992;&#25143;&#23450;&#20041;&#30340;&#21152;&#26435;&#26041;&#26696;&#12290;&#26377;&#20851;&#21152;&#26435;&#26041;&#26696;&#30340;&#35752;&#35770;&#26377;&#26102;&#20250;&#24341;&#23548;&#20154;&#20204;&#38169;&#35823;&#30340;&#35748;&#35782;&#65292;&#22240;&#20026;&#23427;&#32463;&#24120;&#24573;&#30053;&#20102;&#19981;&#21152;&#26435;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nearest-neighbor methods have become popular in statistics and play a key role in statistical learning. Important decisions in nearest-neighbor methods concern the variables to use (when many potential candidates exist) and how to measure the dissimilarity between units. The first decision depends on the scope of the application while second depends mainly on the type of variables. Unfortunately, relatively few options permit to handle mixed-type variables, a situation frequently encountered in practical applications. The most popular dissimilarity for mixed-type variables is derived as the complement to one of the Gower's similarity coefficient. It is appealing because ranges between 0 and 1, being an average of the scaled dissimilarities calculated variable by variable, handles missing values and allows for a user-defined weighting scheme when averaging dissimilarities. The discussion on the weighting schemes is sometimes misleading since it often ignores that the unweighted "standar
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25955;&#20081;&#25968;&#25454;&#36924;&#36817;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#38543;&#26426;&#25506;&#32034;&#27493;&#39588;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#22635;&#20805;&#36317;&#31163;&#30340;&#36895;&#29575;&#34928;&#20943;&#12290;&#35813;&#31639;&#27861;&#22312;&#23454;&#29616;&#30340;&#26131;&#29992;&#24615;&#21644;&#32047;&#31215;&#36951;&#25022;&#36793;&#30028;&#30340;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;GP-UCB&#31639;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#31034;&#20363;&#20013;&#20248;&#20110;&#20854;&#20182;&#36125;&#21494;&#26031;&#20248;&#21270;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2401.17037</link><description>&lt;p&gt;
&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65306;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#25913;&#21892;&#36951;&#25022;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Noise-Free Observations: Improved Regret Bounds via Random Exploration. (arXiv:2401.17037v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17037
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25955;&#20081;&#25968;&#25454;&#36924;&#36817;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#38543;&#26426;&#25506;&#32034;&#27493;&#39588;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#22635;&#20805;&#36317;&#31163;&#30340;&#36895;&#29575;&#34928;&#20943;&#12290;&#35813;&#31639;&#27861;&#22312;&#23454;&#29616;&#30340;&#26131;&#29992;&#24615;&#21644;&#32047;&#31215;&#36951;&#25022;&#36793;&#30028;&#30340;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;GP-UCB&#31639;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#31034;&#20363;&#20013;&#20248;&#20110;&#20854;&#20182;&#36125;&#21494;&#26031;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26080;&#22122;&#22768;&#35266;&#27979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#22522;&#20110;&#25955;&#20081;&#25968;&#25454;&#36924;&#36817;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#27493;&#39588;&#30830;&#20445;&#26597;&#35810;&#28857;&#30340;&#22635;&#20805;&#36317;&#31163;&#20197;&#25509;&#36817;&#26368;&#20248;&#30340;&#36895;&#29575;&#34928;&#20943;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20445;&#30041;&#20102;&#32463;&#20856;&#30340;GP-UCB&#31639;&#27861;&#30340;&#26131;&#23454;&#29616;&#24615;&#65292;&#24182;&#28385;&#36275;&#20102;&#20960;&#20046;&#19982;arXiv:2002.05096&#20013;&#30340;&#29468;&#24819;&#30456;&#21305;&#37197;&#30340;&#32047;&#31215;&#36951;&#25022;&#36793;&#30028;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;COLT&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#26032;&#31639;&#27861;&#22312;&#20960;&#20010;&#31034;&#20363;&#20013;&#20248;&#20110;GP-UCB&#21644;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies Bayesian optimization with noise-free observations. We introduce new algorithms rooted in scattered data approximation that rely on a random exploration step to ensure that the fill-distance of query points decays at a near-optimal rate. Our algorithms retain the ease of implementation of the classical GP-UCB algorithm and satisfy cumulative regret bounds that nearly match those conjectured in arXiv:2002.05096, hence solving a COLT open problem. Furthermore, the new algorithms outperform GP-UCB and other popular Bayesian optimization strategies in several examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2401.16986</link><description>&lt;p&gt;
&#29992;&#20110;&#25104;&#26412;&#25928;&#30410;&#20248;&#21270;&#30340;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#22312;&#21457;&#23637;&#25588;&#21161;&#20998;&#37197;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Causal Machine Learning for Cost-Effective Allocation of Development Aid. (arXiv:2401.16986v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#21512;&#22269;&#30340;&#21487;&#25345;&#32493;&#21457;&#23637;&#30446;&#26631;&#25552;&#20379;&#20102;&#8220;&#26080;&#20154;&#34987;&#36951;&#24323;&#8221;&#30340;&#26356;&#32654;&#22909;&#26410;&#26469;&#34013;&#22270;&#65292;&#20026;&#20102;&#22312;2030&#24180;&#20043;&#21069;&#23454;&#29616;&#36825;&#20123;&#30446;&#26631;&#65292;&#36139;&#31351;&#22269;&#23478;&#38656;&#35201;&#22823;&#37327;&#30340;&#21457;&#23637;&#25588;&#21161;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#25588;&#21161;&#20998;&#37197;&#30340;&#24322;&#36136;&#21270;&#27835;&#30103;&#25928;&#26524;&#65292;&#20197;&#25903;&#25345;&#26377;&#25928;&#30340;&#25588;&#21161;&#20998;&#37197;&#20915;&#31574;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#32452;&#25104;&#37096;&#20998;&#65306;&#65288;i&#65289;&#19968;&#20010;&#24179;&#34913;&#33258;&#32534;&#30721;&#22120;&#65292;&#21033;&#29992;&#34920;&#31034;&#23398;&#20064;&#23558;&#39640;&#32500;&#22269;&#23478;&#29305;&#24449;&#23884;&#20837;&#65292;&#21516;&#26102;&#35299;&#20915;&#27835;&#30103;&#36873;&#25321;&#20559;&#24046;&#38382;&#39064;&#65307;&#65288;ii&#65289;&#19968;&#20010;&#21453;&#20107;&#23454;&#29983;&#25104;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#22312;&#19981;&#21516;&#25588;&#21161;&#35268;&#27169;&#19979;&#30340;&#21453;&#20107;&#23454;&#32467;&#26524;&#65292;&#20197;&#35299;&#20915;&#23567;&#26679;&#26412;&#38382;&#39064;&#65307;&#65288;iii&#65289;&#19968;&#20010;&#25512;&#26029;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#24322;&#36136;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26354;&#32447;&#12290;&#25105;&#20204;&#20351;&#29992;105&#20010;&#22269;&#23478;&#25112;&#30053;&#24615;&#21457;&#23637;&#25588;&#21161;&#25968;&#25454;&#65288;&#24635;&#39069;&#36229;&#36807;52&#20159;&#32654;&#20803;&#65289;&#65292;&#20197;&#32467;&#26463;HIV/AIDS&#20026;&#30446;&#26631;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sustainable Development Goals (SDGs) of the United Nations provide a blueprint of a better future by 'leaving no one behind', and, to achieve the SDGs by 2030, poor countries require immense volumes of development aid. In this paper, we develop a causal machine learning framework for predicting heterogeneous treatment effects of aid disbursements to inform effective aid allocation. Specifically, our framework comprises three components: (i) a balancing autoencoder that uses representation learning to embed high-dimensional country characteristics while addressing treatment selection bias; (ii) a counterfactual generator to compute counterfactual outcomes for varying aid volumes to address small sample-size settings; and (iii) an inference model that is used to predict heterogeneous treatment-response curves. We demonstrate the effectiveness of our framework using data with official development aid earmarked to end HIV/AIDS in 105 countries, amounting to more than USD 5.2 billion. F
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21516;&#26102;&#25551;&#36848;&#22810;&#31181;&#25910;&#30410;&#29575;&#26354;&#32447;&#21160;&#24577;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#33258;&#27880;&#24847;&#26426;&#21046;&#21644;&#38750;&#21442;&#25968;&#20998;&#20301;&#25968;&#22238;&#24402;&#65292;&#29983;&#25104;&#26410;&#26469;&#25910;&#30410;&#29575;&#30340;&#28857;&#39044;&#27979;&#21644;&#21306;&#38388;&#39044;&#27979;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#28145;&#24230;&#38598;&#25104;&#21644;&#36801;&#31227;&#23398;&#20064;&#30340;&#25193;&#23637;&#21644;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.16985</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#22810;&#31181;&#25910;&#30410;&#29575;&#26354;&#32447;&#24314;&#27169;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Multiple Yield Curve Modeling and Forecasting using Deep Learning. (arXiv:2401.16985v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16985
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21516;&#26102;&#25551;&#36848;&#22810;&#31181;&#25910;&#30410;&#29575;&#26354;&#32447;&#21160;&#24577;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#33258;&#27880;&#24847;&#26426;&#21046;&#21644;&#38750;&#21442;&#25968;&#20998;&#20301;&#25968;&#22238;&#24402;&#65292;&#29983;&#25104;&#26410;&#26469;&#25910;&#30410;&#29575;&#30340;&#28857;&#39044;&#27979;&#21644;&#21306;&#38388;&#39044;&#27979;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#28145;&#24230;&#38598;&#25104;&#21644;&#36801;&#31227;&#23398;&#20064;&#30340;&#25193;&#23637;&#21644;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21516;&#26102;&#25551;&#36848;&#22810;&#31181;&#25910;&#30410;&#29575;&#26354;&#32447;&#21160;&#24577;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#26088;&#22312;&#23398;&#20064;&#37329;&#34701;&#24066;&#22330;&#20840;&#29699;&#21270;&#24341;&#36215;&#30340;&#19981;&#21516;&#25910;&#30410;&#29575;&#26354;&#32447;&#20043;&#38388;&#30340;&#20381;&#36182;&#32467;&#26500;&#65292;&#24182;&#21033;&#29992;&#23427;&#26469;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#36890;&#36807;&#32467;&#21512;&#33258;&#27880;&#24847;&#26426;&#21046;&#21644;&#38750;&#21442;&#25968;&#20998;&#20301;&#25968;&#22238;&#24402;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#26410;&#26469;&#25910;&#30410;&#29575;&#30340;&#28857;&#39044;&#27979;&#21644;&#21306;&#38388;&#39044;&#27979;&#12290;&#35813;&#26694;&#26550;&#30340;&#35774;&#35745;&#26088;&#22312;&#36991;&#20813;&#24433;&#21709;&#22810;&#20010;&#20998;&#20301;&#25968;&#22238;&#24402;&#27169;&#22411;&#30340;&#20998;&#20301;&#25968;&#20132;&#21449;&#38382;&#39064;&#12290;&#23545;&#20004;&#20010;&#19981;&#21516;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#32467;&#21512;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#21644;&#36801;&#31227;&#23398;&#20064;&#26426;&#21046;&#65292;&#25506;&#35752;&#20102;&#28508;&#22312;&#30340;&#25193;&#23637;&#21644;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This manuscript introduces deep learning models that simultaneously describe the dynamics of several yield curves. We aim to learn the dependence structure among the different yield curves induced by the globalization of financial markets and exploit it to produce more accurate forecasts. By combining the self-attention mechanism and nonparametric quantile regression, our model generates both point and interval forecasts of future yields. The architecture is designed to avoid quantile crossing issues affecting multiple quantile regression models. Numerical experiments conducted on two different datasets confirm the effectiveness of our approach. Finally, we explore potential extensions and enhancements by incorporating deep ensemble methods and transfer learning mechanisms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#65292;&#36827;&#34892;&#27169;&#22411;&#25490;&#24207;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20854;&#20182;&#31639;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.16943</link><description>&lt;p&gt;
&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#25512;&#29702;&#20013;&#30340;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Dynamical System Identification, Model Selection and Model Uncertainty Quantification by Bayesian Inference. (arXiv:2401.16943v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#65292;&#36827;&#34892;&#27169;&#22411;&#25490;&#24207;&#21644;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#20854;&#20182;&#31639;&#27861;&#30340;&#27604;&#36739;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (MAP) &#26694;&#26550;&#30340;&#21160;&#21147;&#31995;&#32479;&#35782;&#21035;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#24674;&#22797;&#31995;&#32479;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31561;&#20215;&#20110;&#24191;&#20041;&#30340;&#38646;&#38454; Tikhonov &#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36127;&#23545;&#25968;&#20284;&#28982;&#21644;&#20808;&#39564;&#20998;&#24067;&#26469;&#21512;&#29702;&#36873;&#25321;&#27531;&#24046;&#21644;&#27491;&#21017;&#21270;&#39033;&#12290;&#38500;&#20102;&#20272;&#35745;&#27169;&#22411;&#31995;&#25968;&#22806;&#65292;&#36125;&#21494;&#26031;&#35299;&#37322;&#36824;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#24037;&#20855;&#65292;&#21253;&#25324;&#27169;&#22411;&#25490;&#24207;&#12289;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;&#24102;&#26377;&#22122;&#22768;&#30340;&#20960;&#20010;&#21160;&#21147;&#31995;&#32479;&#65292;&#27604;&#36739;&#20102;&#20004;&#31181;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#21363;&#32852;&#21512;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (JMAP) &#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284; (VBA)&#65292;&#19982;&#27969;&#34892;&#30340;&#38408;&#20540;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#31639;&#27861;SINDy&#12290;&#23545;&#20110;&#22810;&#20803;&#39640;&#26031;&#20284;&#28982;&#21644;&#20808;&#39564;&#20998;&#24067;&#65292;
&lt;/p&gt;
&lt;p&gt;
This study presents a Bayesian maximum \textit{a~posteriori} (MAP) framework for dynamical system identification from time-series data. This is shown to be equivalent to a generalized zeroth-order Tikhonov regularization, providing a rational justification for the choice of the residual and regularization terms, respectively, from the negative logarithms of the likelihood and prior distributions. In addition to the estimation of model coefficients, the Bayesian interpretation gives access to the full apparatus for Bayesian inference, including the ranking of models, the quantification of model uncertainties and the estimation of unknown (nuisance) hyperparameters. Two Bayesian algorithms, joint maximum \textit{a~posteriori} (JMAP) and variational Bayesian approximation (VBA), are compared to the popular SINDy algorithm for thresholded least-squares regression, by application to several dynamical systems with added noise. For multivariate Gaussian likelihood and prior distributions, the
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#36798;&#21040;&#19982;&#30495;&#23454;&#25968;&#25454;&#30456;&#20284;&#30340;&#30693;&#35782;&#36861;&#36394;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16832</link><description>&lt;p&gt;
&#23545;&#21512;&#25104;&#23398;&#29983;&#25968;&#25454;&#30340;&#30693;&#35782;&#36861;&#36394;&#24615;&#33021;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of Knowledge Tracing performance on synthesised student data. (arXiv:2401.16832v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16832
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#36798;&#21040;&#19982;&#30495;&#23454;&#25968;&#25454;&#30456;&#20284;&#30340;&#30693;&#35782;&#36861;&#36394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#36861;&#36394;&#26088;&#22312;&#36890;&#36807;&#36319;&#36394;&#23398;&#29983;&#30340;&#30693;&#35782;&#29366;&#24577;&#30340;&#21457;&#23637;&#26469;&#39044;&#27979;&#20182;&#20204;&#26410;&#26469;&#30340;&#34920;&#29616;&#12290;&#23613;&#31649;&#22312;&#36825;&#19968;&#39046;&#22495;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#25968;&#25454;&#20445;&#25252;&#38382;&#39064;&#65292;KT&#27169;&#22411;&#22312;&#25945;&#32946;&#31995;&#32479;&#20013;&#30340;&#24212;&#29992;&#20173;&#21463;&#21040;&#25968;&#25454;&#38480;&#21046;&#65306;1&#65289;&#30001;&#20110;&#25968;&#25454;&#20445;&#25252;&#38382;&#39064;&#65292;&#26080;&#27861;&#33719;&#24471;&#29616;&#23454;&#29983;&#27963;&#25968;&#25454;&#65307;2&#65289;&#20844;&#20849;&#25968;&#25454;&#38598;&#20013;&#32570;&#20047;&#22810;&#26679;&#24615;&#65307;3&#65289;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#37325;&#22797;&#35760;&#24405;&#30340;&#22122;&#38899;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#19977;&#31181;&#22522;&#20110;&#20844;&#20849;&#25968;&#25454;&#38598;&#30340;&#32479;&#35745;&#31574;&#30053;&#27169;&#25311;&#20102;&#23398;&#29983;&#25968;&#25454;&#65292;&#24182;&#27979;&#35797;&#20102;&#23427;&#20204;&#22312;&#20004;&#20010;KT&#22522;&#20934;&#19978;&#30340;&#24615;&#33021;&#12290;&#34429;&#28982;&#25105;&#20204;&#35266;&#23519;&#21040;&#39069;&#22806;&#30340;&#21512;&#25104;&#25968;&#25454;&#21482;&#24102;&#26469;&#20102;&#36731;&#24494;&#30340;&#24615;&#33021;&#25913;&#36827;&#65292;&#20294;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20165;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#36798;&#21040;&#19982;&#30495;&#23454;&#25968;&#25454;&#30456;&#20284;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge Tracing (KT) aims to predict the future performance of students by tracking the development of their knowledge states. Despite all the recent progress made in this field, the application of KT models in education systems is still restricted from the data perspectives: 1) limited access to real life data due to data protection concerns, 2) lack of diversity in public datasets, 3) noises in benchmark datasets such as duplicate records. To resolve these problems, we simulated student data with three statistical strategies based on public datasets and tested their performance on two KT baselines. While we observe only minor performance improvement with additional synthetic data, our work shows that using only synthetic data for training can lead to similar performance as real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#35299;&#20915;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#20013;&#30340;&#23884;&#22871;&#26399;&#26395;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2401.16776</link><description>&lt;p&gt;
&#21033;&#29992;&#23884;&#22871;MLMC&#23545;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#36827;&#34892;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Leveraging Nested MLMC for Sequential Neural Posterior Estimation with Intractable Likelihoods. (arXiv:2401.16776v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#35299;&#20915;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#20013;&#30340;&#23884;&#22871;&#26399;&#26395;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#20102;&#39034;&#24207;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;SNPE&#65289;&#25216;&#26415;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#27169;&#22411;&#12290;&#23427;&#20204;&#33268;&#21147;&#20110;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#33258;&#36866;&#24212;&#22320;&#29983;&#25104;&#30340;&#27169;&#25311;&#26469;&#23398;&#20064;&#21518;&#39564;&#12290;&#20316;&#20026;&#19968;&#31181;SNPE&#25216;&#26415;&#65292;Greenberg&#31561;&#20154;&#65288;2019&#65289;&#25552;&#20986;&#30340;&#33258;&#21160;&#21518;&#39564;&#21464;&#25442;&#65288;APT&#65289;&#26041;&#27861;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;APT&#26041;&#27861;&#21253;&#21547;&#35745;&#31639;&#38590;&#20197;&#22788;&#29702;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#23545;&#25968;&#30340;&#26399;&#26395;&#65292;&#21363;&#23884;&#22871;&#26399;&#26395;&#12290;&#23613;&#31649;&#21407;&#23376;APT&#36890;&#36807;&#31163;&#25955;&#21270;&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#20998;&#26512;&#23398;&#20064;&#30340;&#25910;&#25947;&#24615;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;APT&#26041;&#27861;&#26469;&#20272;&#35745;&#30456;&#20851;&#30340;&#23884;&#22871;&#26399;&#26395;&#12290;&#36825;&#26377;&#21161;&#20110;&#24314;&#31435;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#30001;&#20110;&#25439;&#22833;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#30340;&#23884;&#22871;&#20272;&#35745;&#26159;&#26377;&#20559;&#30340;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. They are devoted to learning the posterior from adaptively proposed simulations using neural network-based conditional density estimators. As a SNPE technique, the automatic posterior transformation (APT) method proposed by Greenberg et al. (2019) performs notably and scales to high dimensional data. However, the APT method bears the computation of an expectation of the logarithm of an intractable normalizing constant, i.e., a nested expectation. Although atomic APT was proposed to solve this by discretizing the normalizing constant, it remains challenging to analyze the convergence of learning. In this paper, we propose a nested APT method to estimate the involved nested expectation instead. This facilitates establishing the convergence analysis. Since the nested estimators for the loss function and its gradient are biased, we make
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#23398;&#20064;&#30340;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#39640;&#32500;&#38543;&#26426;&#31995;&#32479;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#36890;&#36807;&#22312;Grassmann&#27969;&#24418;&#19978;&#36827;&#34892;&#20027;&#27979;&#22320;&#20998;&#26512;&#65292;&#35782;&#21035;&#20986;&#19968;&#32452;&#28508;&#22312;&#30340;&#20302;&#32500;&#25551;&#36848;&#31526;&#65292;&#28982;&#21518;&#21033;&#29992;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26500;&#24314;&#26144;&#23556;&#12290;</title><link>http://arxiv.org/abs/2401.16683</link><description>&lt;p&gt;
&#22312;&#20027;&#27979;&#22320;Grassmannian&#23376;&#27969;&#24418;&#19978;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#29992;&#20110;&#20195;&#29702;&#24314;&#27169;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Polynomial Chaos Expansions on Principal Geodesic Grassmannian Submanifolds for Surrogate Modeling and Uncertainty Quantification. (arXiv:2401.16683v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#23398;&#20064;&#30340;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#39640;&#32500;&#38543;&#26426;&#31995;&#32479;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#36890;&#36807;&#22312;Grassmann&#27969;&#24418;&#19978;&#36827;&#34892;&#20027;&#27979;&#22320;&#20998;&#26512;&#65292;&#35782;&#21035;&#20986;&#19968;&#32452;&#28508;&#22312;&#30340;&#20302;&#32500;&#25551;&#36848;&#31526;&#65292;&#28982;&#21518;&#21033;&#29992;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26500;&#24314;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#23398;&#20064;&#30340;&#20195;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#39640;&#32500;&#38543;&#26426;&#31995;&#32479;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#39318;&#35201;&#30446;&#26631;&#26159;&#23545;&#21487;&#29992;&#30340;&#27169;&#25311;&#25968;&#25454;&#36827;&#34892;&#25968;&#25454;&#25366;&#25496;&#65292;&#20197;&#30830;&#23450;&#33021;&#22815;&#39640;&#25928;&#21442;&#25968;&#21270;&#39640;&#32500;&#35745;&#31639;&#27169;&#22411;&#21709;&#24212;&#30340;&#19968;&#32452;&#20302;&#32500;&#65288;&#28508;&#22312;&#65289;&#25551;&#36848;&#31526;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#37319;&#29992;Grassmann&#27969;&#24418;&#19978;&#30340;&#20027;&#27979;&#22320;&#20998;&#26512;&#65292;&#35782;&#21035;&#20986;&#19968;&#32452;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#32500;&#24230;&#30340;&#19981;&#30456;&#20132;&#20027;&#27979;&#22320;&#23376;&#27969;&#24418;&#65292;&#20197;&#25429;&#25417;&#25968;&#25454;&#30340;&#21464;&#21270;&#12290;&#30001;&#20110;Grassmann&#19978;&#30340;&#25805;&#20316;&#38656;&#35201;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Riemanniann K-means&#21644;Grassmann&#27969;&#24418;&#19978;&#26679;&#26412;Frechet&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#20195;&#34920;&#21442;&#25968;&#31354;&#38388;&#20013;&#19981;&#21516;&#31995;&#32479;&#34892;&#20026;&#30340;&#8220;&#26412;&#22320;&#8221;&#20027;&#27979;&#22320;&#23376;&#27969;&#24418;&#12290;&#28982;&#21518;&#20351;&#29992;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26500;&#24314;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
In this work we introduce a manifold learning-based surrogate modeling framework for uncertainty quantification in high-dimensional stochastic systems. Our first goal is to perform data mining on the available simulation data to identify a set of low-dimensional (latent) descriptors that efficiently parameterize the response of the high-dimensional computational model. To this end, we employ Principal Geodesic Analysis on the Grassmann manifold of the response to identify a set of disjoint principal geodesic submanifolds, of possibly different dimension, that captures the variation in the data. Since operations on the Grassmann require the data to be concentrated, we propose an adaptive algorithm based on Riemanniann K-means and the minimization of the sample Frechet variance on the Grassmann manifold to identify "local" principal geodesic submanifolds that represent different system behavior across the parameter space. Polynomial chaos expansion is then used to construct a mapping bet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#36716;&#21270;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#27492;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.16655</link><description>&lt;p&gt;
&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#26500;&#24314;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rademacher Complexity of Neural ODEs via Chen-Fliess Series. (arXiv:2401.16655v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#36716;&#21270;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#27492;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#20351;&#29992;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#12290;&#22312;&#36825;&#20010;&#32593;&#32476;&#20013;&#65292;&#36755;&#20986;&#30340;&#8220;&#26435;&#37325;&#8221;&#26469;&#33258;&#25511;&#21046;&#36755;&#20837;&#30340;&#29305;&#24449;&#24207;&#21015;&#65292;&#23427;&#30001;&#25511;&#21046;&#36755;&#20837;&#22312;&#21333;&#32431;&#24418;&#19978;&#30340;&#36845;&#20195;&#31215;&#20998;&#26500;&#25104;&#12290;&#32780;&#8220;&#29305;&#24449;&#8221;&#21017;&#22522;&#20110;&#21463;&#25511;ODE&#27169;&#22411;&#20013;&#36755;&#20986;&#20989;&#25968;&#30456;&#23545;&#20110;&#21521;&#37327;&#22330;&#30340;&#36845;&#20195;&#26446;&#23548;&#25968;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#24212;&#29992;&#36825;&#20010;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;&#36825;&#19968;&#32467;&#26524;&#21033;&#29992;&#20102;&#21333;&#23618;&#32467;&#26500;&#25152;&#24102;&#26469;&#30340;&#30452;&#25509;&#20998;&#26512;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20123;&#20855;&#20307;&#31995;&#32479;&#30340;&#20363;&#23376;&#23454;&#20363;&#21270;&#35813;&#30028;&#65292;&#24182;&#35752;&#35770;&#20102;&#21487;&#33021;&#30340;&#21518;&#32493;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how continuous-depth neural ODE models can be framed as single-layer, infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs. In this net, the output ''weights'' are taken from the signature of the control input -- a tool used to represent infinite-dimensional paths as a sequence of tensors -- which comprises iterated integrals of the control input over a simplex. The ''features'' are taken to be iterated Lie derivatives of the output function with respect to the vector fields in the controlled ODE model. The main result of this work applies this framework to derive compact expressions for the Rademacher complexity of ODE models that map an initial condition to a scalar output at some terminal time. The result leverages the straightforward analysis afforded by single-layer architectures. We conclude with some examples instantiating the bound for some specific systems and discuss potential follow-up work.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36125;&#21494;&#26031;&#20272;&#35745;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36870;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24314;&#27169;&#21644;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.16612</link><description>&lt;p&gt;
&#22312;&#36870;&#38382;&#39064;&#20013;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#29289;&#36827;&#34892;&#31232;&#30095;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Learning a Gaussian Mixture for Sparsity Regularization in Inverse Problems. (arXiv:2401.16612v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36125;&#21494;&#26031;&#20272;&#35745;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36870;&#38382;&#39064;&#20013;&#30340;&#31232;&#30095;&#24314;&#27169;&#21644;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36870;&#38382;&#39064;&#20013;&#65292;&#24191;&#27867;&#35748;&#20026;&#24341;&#20837;&#31232;&#30095;&#20808;&#39564;&#23545;&#35299;&#20915;&#26041;&#26696;&#20855;&#26377;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#26159;&#22522;&#20110;&#19968;&#20010;&#20808;&#39564;&#20551;&#35774;&#65292;&#21363;&#26410;&#30693;&#37327;&#21487;&#20197;&#22312;&#19968;&#20010;&#26377;&#38480;&#25968;&#37327;&#30340;&#26174;&#33879;&#25104;&#20998;&#30340;&#22522;&#30784;&#19978;&#36866;&#24403;&#34920;&#31034;&#65292;&#32780;&#22823;&#22810;&#25968;&#31995;&#25968;&#25509;&#36817;&#20110;&#38646;&#12290;&#36825;&#31181;&#24773;&#20917;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#27604;&#22914;&#20998;&#27573;&#24179;&#28369;&#20449;&#21495;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#39640;&#26031;&#36864;&#21270;&#28151;&#21512;&#29289;&#24418;&#24335;&#34920;&#36848;&#30340;&#27010;&#29575;&#31232;&#30095;&#20808;&#39564;&#65292;&#33021;&#22815;&#23545;&#20110;&#20219;&#24847;&#22522;&#36827;&#34892;&#31232;&#30095;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21487;&#20197;&#35299;&#37322;&#20026;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#30340;&#35757;&#32451;&#31574;&#30053;&#26469;&#20272;&#35745;&#36825;&#20010;&#32593;&#32476;&#30340;&#21442;&#25968;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19982;&#24120;&#29992;&#30340;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#30340;&#25968;&#20540;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
In inverse problems, it is widely recognized that the incorporation of a sparsity prior yields a regularization effect on the solution. This approach is grounded on the a priori assumption that the unknown can be appropriately represented in a basis with a limited number of significant components, while most coefficients are close to zero. This occurrence is frequently observed in real-world scenarios, such as with piecewise smooth signals. In this study, we propose a probabilistic sparsity prior formulated as a mixture of degenerate Gaussians, capable of modeling sparsity with respect to a generic basis. Under this premise, we design a neural network that can be interpreted as the Bayes estimator for linear inverse problems. Additionally, we put forth both a supervised and an unsupervised training strategy to estimate the parameters of this network. To evaluate the effectiveness of our approach, we conduct a numerical comparison with commonly employed sparsity-promoting regularization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;Ising&#27169;&#22411;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#21516;&#20276;&#25928;&#24212;&#20272;&#35745;&#31639;&#27861;&#65292;&#33021;&#22815;&#31934;&#30830;&#20272;&#35745;&#33258;&#28982;&#21442;&#25968;&#24182;&#20445;&#25252;&#20010;&#20307;&#20195;&#29702;&#32467;&#26524;&#30340;&#38544;&#31169;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#29616;&#23454;&#19990;&#30028;&#32593;&#32476;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16596</link><description>&lt;p&gt;
PrIsing: &#36890;&#36807;Ising&#27169;&#22411;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#21516;&#20276;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model. (arXiv:2401.16596v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16596
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;Ising&#27169;&#22411;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#30340;&#21516;&#20276;&#25928;&#24212;&#20272;&#35745;&#31639;&#27861;&#65292;&#33021;&#22815;&#31934;&#30830;&#20272;&#35745;&#33258;&#28982;&#21442;&#25968;&#24182;&#20445;&#25252;&#20010;&#20307;&#20195;&#29702;&#32467;&#26524;&#30340;&#38544;&#31169;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#29616;&#23454;&#19990;&#30028;&#32593;&#32476;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Ising&#27169;&#22411;&#26368;&#21021;&#20316;&#20026;&#38081;&#30913;&#20803;&#32032;&#33258;&#26059;&#27169;&#22411;&#32780;&#24320;&#21457;&#65292;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25429;&#25417;&#20195;&#29702;&#36755;&#20986;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#30340;&#32593;&#32476;&#27169;&#22411;&#12290;&#23427;&#22312;&#21307;&#30103;&#20445;&#20581;&#21644;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#30340;&#19981;&#26029;&#24212;&#29992;&#24341;&#21457;&#20102;&#20851;&#20110;&#20195;&#29702;&#21709;&#24212;&#26426;&#23494;&#24615;&#30340;&#38544;&#31169;&#25285;&#24551;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$(\varepsilon,\delta)$-&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#20445;&#25252;&#20010;&#20307;&#20195;&#29702;&#32467;&#26524;&#30340;&#38544;&#31169;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#30446;&#26631;&#25200;&#21160;&#25216;&#26415;&#65292;&#20801;&#35768;&#23545;&#33258;&#28982;&#21442;&#25968;&#20351;&#29992;&#21333;&#19968;&#32593;&#32476;&#36827;&#34892;&#31934;&#30830;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#35813;&#31639;&#27861;&#24314;&#31435;&#20102;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#32593;&#32476;&#19978;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#65306;&#19968;&#20010;&#28041;&#21450;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;HIV&#29366;&#20917;&#65292;&#21478;&#19968;&#20010;&#28041;&#21450;&#22312;&#32447;&#21338;&#23458;&#30340;&#25919;&#27835;&#20542;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Ising model, originally developed as a spin-glass model for ferromagnetic elements, has gained popularity as a network-based model for capturing dependencies in agents' outputs. Its increasing adoption in healthcare and the social sciences has raised privacy concerns regarding the confidentiality of agents' responses. In this paper, we present a novel $(\varepsilon,\delta)$-differentially private algorithm specifically designed to protect the privacy of individual agents' outcomes. Our algorithm allows for precise estimation of the natural parameter using a single network through an objective perturbation technique. Furthermore, we establish regret bounds for this algorithm and assess its performance on synthetic datasets and two real-world networks: one involving HIV status in a social network and the other concerning the political leaning of online blogs.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#23454;&#29616;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#25968;&#20540;&#24615;&#33021;&#65292;&#24212;&#29992;&#20110;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#21518;&#20063;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2401.16571</link><description>&lt;p&gt;
&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#20272;&#35745;&#20010;&#20307;&#21270;&#22810;&#27835;&#30103;&#21453;&#24212;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons. (arXiv:2401.16571v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16571
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#23454;&#29616;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#25968;&#20540;&#24615;&#33021;&#65292;&#24212;&#29992;&#20110;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#21518;&#20063;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26159;&#31934;&#30830;&#21307;&#23398;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20852;&#36259;&#22312;&#20110;&#22522;&#20110;&#19968;&#20123;&#22806;&#37096;&#21327;&#21464;&#37327;&#65292;&#30830;&#23450;&#19981;&#21516;&#27835;&#30103;&#26041;&#24335;&#30340;&#24046;&#24322;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#25105;&#20204;&#23545;&#21709;&#24212;&#26354;&#32447;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#20381;&#36182;&#20110;&#24102;&#26377;&#20849;&#20139;&#38544;&#34255;&#31070;&#32463;&#20803;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#65288;RBF&#65289;&#32593;&#32476;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26377;&#21161;&#20110;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#12290;&#25105;&#20204;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#24320;&#21457;&#20102;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#39640;&#25928;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#36827;&#34892;&#23454;&#29616;&#65292;&#36866;&#24403;&#22320;&#22788;&#29702;&#20102;&#20998;&#26512;&#21508;&#20010;&#26041;&#38754;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;MIMIC&#25968;&#25454;&#21518;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#19981;&#21516;&#27835;&#30103;&#31574;&#30053;&#23545;ICU&#20303;&#38498;&#26102;&#38388;&#21644;12&#23567;&#26102;SOFA&#35780;&#20998;&#30340;&#24433;&#21709;&#30340;&#19968;&#20123;&#26377;&#36259;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous treatment effect estimation is an important problem in precision medicine. Specific interests lie in identifying the differential effect of different treatments based on some external covariates. We propose a novel non-parametric treatment effect estimation method in a multi-treatment setting. Our non-parametric modeling of the response curves relies on radial basis function (RBF)-nets with shared hidden neurons. Our model thus facilitates modeling commonality among the treatment outcomes. The estimation and inference schemes are developed under a Bayesian framework and implemented via an efficient Markov chain Monte Carlo algorithm, appropriately accommodating uncertainty in all aspects of the analysis. The numerical performance of the method is demonstrated through simulation experiments. Applying our proposed method to MIMIC data, we obtain several interesting findings related to the impact of different treatment strategies on the length of ICU stay and 12-hour SOFA sc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#21452;&#23556;&#20223;&#23556;&#21464;&#25442;&#26469;&#25913;&#21892;Markov Chain Monte Carlo&#37319;&#26679;&#22120;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#24182;&#29992;&#25143;&#21451;&#22909;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#20223;&#23556;&#21464;&#25442;&#30340;&#26041;&#26696;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30456;&#32467;&#21512;&#20135;&#29983;&#30340;&#26679;&#26412;&#20855;&#26377;&#39640;&#36136;&#37327;&#19988;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2401.16567</link><description>&lt;p&gt;
&#24182;&#34892;&#20223;&#23556;&#21464;&#25442;&#35843;&#25972;Markov Chain Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Parallel Affine Transformation Tuning of Markov Chain Monte Carlo. (arXiv:2401.16567v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#21452;&#23556;&#20223;&#23556;&#21464;&#25442;&#26469;&#25913;&#21892;Markov Chain Monte Carlo&#37319;&#26679;&#22120;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#24182;&#29992;&#25143;&#21451;&#22909;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#20223;&#23556;&#21464;&#25442;&#30340;&#26041;&#26696;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30456;&#32467;&#21512;&#20135;&#29983;&#30340;&#26679;&#26412;&#20855;&#26377;&#39640;&#36136;&#37327;&#19988;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Markov Chain Monte Carlo&#37319;&#26679;&#22120;&#30340;&#24615;&#33021;&#24378;&#28872;&#20381;&#36182;&#20110;&#30446;&#26631;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#22914;&#20854;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#27010;&#29575;&#36136;&#37327;&#30340;&#20301;&#32622;&#21644;&#23614;&#37096;&#34892;&#20026;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#20351;&#29992;&#26679;&#26412;&#31354;&#38388;&#30340;&#21452;&#23556;&#20223;&#23556;&#21464;&#25442;&#26469;&#25913;&#21892;&#30446;&#26631;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#20174;&#32780;&#25552;&#39640;&#22312;&#21464;&#25442;&#31354;&#38388;&#20013;&#36816;&#34892;&#30340;&#37319;&#26679;&#22120;&#30340;&#24615;&#33021;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#19988;&#29992;&#25143;&#21451;&#22909;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#33258;&#36866;&#24212;&#23398;&#20064;&#37319;&#26679;&#36807;&#31243;&#20013;&#30340;&#20223;&#23556;&#21464;&#25442;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#26696;&#19982;Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30340;&#32452;&#21512;&#22312;&#20960;&#20010;&#22522;&#20110;&#30495;&#23454;&#25968;&#25454;&#30340;&#22330;&#26223;&#20013;&#26174;&#31034;&#20986;&#20197;&#30456;&#23545;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#20135;&#29983;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The performance of Markov chain Monte Carlo samplers strongly depends on the properties of the target distribution such as its covariance structure, the location of its probability mass and its tail behavior. We explore the use of bijective affine transformations of the sample space to improve the properties of the target distribution and thereby the performance of samplers running in the transformed space. In particular, we propose a flexible and user-friendly scheme for adaptively learning the affine transformation during sampling. Moreover, the combination of our scheme with Gibbsian polar slice sampling is shown to produce samples of high quality at comparatively low computational cost in several settings based on real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#19981;&#21487;&#38752;&#23494;&#24230;&#20272;&#35745;&#26816;&#27979;P&#22411;&#20998;&#23700;&#30340;&#26041;&#27861;&#65292;&#24182;&#27604;&#36739;&#20102;&#20960;&#31181;&#22797;&#21046;&#21407;&#22987;&#25345;&#20037;&#21270;&#22270;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.16563</link><description>&lt;p&gt;
&#29992;&#19981;&#21487;&#38752;&#26680;&#23494;&#24230;&#26816;&#27979;&#29616;&#35937;&#23398;&#20998;&#23700;
&lt;/p&gt;
&lt;p&gt;
Topological Detection of Phenomenological Bifurcations with Unreliable Kernel Densities. (arXiv:2401.16563v1 [math.AT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#19981;&#21487;&#38752;&#23494;&#24230;&#20272;&#35745;&#26816;&#27979;P&#22411;&#20998;&#23700;&#30340;&#26041;&#27861;&#65292;&#24182;&#27604;&#36739;&#20102;&#20960;&#31181;&#22797;&#21046;&#21407;&#22987;&#25345;&#20037;&#21270;&#22270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#35937;&#23398;&#65288;P&#22411;&#65289;&#20998;&#23700;&#26159;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#23450;&#24615;&#21464;&#21270;&#65292;&#20854;&#20013;&#31283;&#24577;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDF&#65289;&#25913;&#21464;&#20102;&#20854;&#25299;&#25169;&#32467;&#26500;&#12290;&#30446;&#21069;&#26816;&#27979;&#36825;&#20123;&#20998;&#23700;&#30340;&#25216;&#26415;&#38656;&#35201;&#21487;&#38752;&#30340;&#26680;&#23494;&#24230;&#20272;&#35745;&#65292;&#32780;&#36825;&#38656;&#35201;&#20174;&#31995;&#32479;&#23454;&#29616;&#38598;&#21512;&#20013;&#35745;&#31639;&#24471;&#21040;&#12290;&#28982;&#32780;&#65292;&#22312;&#19968;&#20123;&#30495;&#23454;&#19990;&#30028;&#30340;&#20449;&#21495;&#20013;&#65292;&#27604;&#22914;&#22823;&#25968;&#25454;&#65292;&#21482;&#26377;&#19968;&#20010;&#31995;&#32479;&#23454;&#29616;&#21487;&#29992;&#65292;&#22240;&#27492;&#26080;&#27861;&#20272;&#35745;&#21487;&#38752;&#30340;&#26680;&#23494;&#24230;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#19981;&#21487;&#38752;&#23494;&#24230;&#20272;&#35745;&#26816;&#27979;P&#22411;&#20998;&#23700;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#19968;&#31181;&#31216;&#20026;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65288;TDA&#65289;&#30340;&#25216;&#26415;&#20174;&#31995;&#32479;&#30340;&#21333;&#20010;&#23454;&#29616;&#20013;&#21019;&#24314;&#20102;&#19968;&#20010;&#23545;&#35937;&#38598;&#21512;&#65292;&#24182;&#23545;&#32467;&#26524;&#38598;&#36827;&#34892;&#32479;&#35745;&#20998;&#26512;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22797;&#21046;&#21407;&#22987;&#25345;&#20037;&#21270;&#22270;&#30340;&#20960;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;Gibbs&#28857;&#36807;&#31243;&#24314;&#27169;&#12289;&#25104;&#23545;&#20132;&#20114;&#28857;&#24314;&#27169;&#21644;&#23376;&#37319;&#26679;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#39044;&#27979;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Phenomenological (P-type) bifurcations are qualitative changes in stochastic dynamical systems whereby the stationary probability density function (PDF) changes its topology. The current state of the art for detecting these bifurcations requires reliable kernel density estimates computed from an ensemble of system realizations. However, in several real world signals such as Big Data, only a single system realization is available -- making it impossible to estimate a reliable kernel density. This study presents an approach for detecting P-type bifurcations using unreliable density estimates. The approach creates an ensemble of objects from Topological Data Analysis (TDA) called persistence diagrams from the system's sole realization and statistically analyzes the resulting set. We compare several methods for replicating the original persistence diagram including Gibbs point process modelling, Pairwise Interaction Point Modelling, and subsampling. We show that for the purpose of predicti
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#22686;&#24378;&#37319;&#26679;&#12289;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#20027;&#21160;&#23398;&#20064;&#26426;&#22120;&#23398;&#20064;&#21183;&#33021;&#30340;&#26041;&#27861;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#37327;&#23376;&#31934;&#24230;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#21450;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2401.16487</link><description>&lt;p&gt;
&#27963;&#24615;&#23398;&#20064;&#29627;&#23572;&#20857;&#26364;&#37319;&#26679;&#22120;&#21644;&#20855;&#26377;&#37327;&#23376;&#21147;&#23398;&#31934;&#24230;&#30340;&#21183;&#33021;
&lt;/p&gt;
&lt;p&gt;
Active learning of Boltzmann samplers and potential energies with quantum mechanical accuracy. (arXiv:2401.16487v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16487
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#22686;&#24378;&#37319;&#26679;&#12289;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#20027;&#21160;&#23398;&#20064;&#26426;&#22120;&#23398;&#20064;&#21183;&#33021;&#30340;&#26041;&#27861;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#37327;&#23376;&#31934;&#24230;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#21450;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29289;&#29702;&#23398;&#12289;&#21270;&#23398;&#21644;&#29983;&#29289;&#23398;&#26469;&#35828;&#65292;&#25552;&#21462;&#20998;&#23376;&#31995;&#32479;&#30456;&#20851;&#33258;&#30001;&#33021;&#26497;&#23567;&#20540;&#20043;&#38388;&#30340;&#19968;&#33268;&#32479;&#35745;&#25968;&#25454;&#33267;&#20851;&#37325;&#35201;&#12290;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#27169;&#25311;&#21487;&#20197;&#24110;&#21161;&#23436;&#25104;&#36825;&#39033;&#20219;&#21153;&#65292;&#20294;&#23545;&#20110;&#38656;&#35201;&#37327;&#23376;&#31934;&#24230;&#30340;&#31995;&#32479;&#32780;&#35328;&#65292;&#35745;&#31639;&#20195;&#20215;&#24456;&#39640;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#32467;&#21512;&#22686;&#24378;&#37319;&#26679;&#12289;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21644;&#20027;&#21160;&#23398;&#20064;&#26426;&#22120;&#23398;&#20064;&#21183;&#33021;&#65288;MLP&#65289;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26694;&#26550;&#65292;&#20351;&#24471;&#27599;&#20010;&#29366;&#24577;&#21487;&#20197;&#35757;&#32451;&#19968;&#20010;&#27491;&#21017;&#21270;&#27969;&#65288;NF&#65289;&#21644;&#19968;&#20010;MLP&#12290;&#25105;&#20204;&#24182;&#34892;&#27169;&#25311;&#22810;&#20010;&#39532;&#23572;&#31185;&#22827;&#38142;&#30452;&#21040;&#25910;&#25947;&#65292;&#20351;&#29992;&#39640;&#25928;&#30340;&#33021;&#37327;&#35780;&#20272;&#20174;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;DFT&#65289;&#35745;&#31639;NF&#29983;&#25104;&#30340;&#37197;&#32622;&#23376;&#38598;&#30340;&#33021;&#37327;&#65292;&#29992;MLP&#39044;&#27979;&#21097;&#20313;&#37197;&#32622;&#30340;&#33021;&#37327;&#65292;&#24182;&#20351;&#29992;DFT&#35745;&#31639;&#24471;&#21040;&#30340;&#33021;&#37327;&#23545;MLP&#36827;&#34892;&#20027;&#21160;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extracting consistent statistics between relevant free-energy minima of a molecular system is essential for physics, chemistry and biology. Molecular dynamics (MD) simulations can aid in this task but are computationally expensive, especially for systems that require quantum accuracy. To overcome this challenge, we develop an approach combining enhanced sampling with deep generative models and active learning of a machine learning potential (MLP). We introduce an adaptive Markov chain Monte Carlo framework that enables the training of one Normalizing Flow (NF) and one MLP per state. We simulate several Markov chains in parallel until they reach convergence, sampling the Boltzmann distribution with an efficient use of energy evaluations. At each iteration, we compute the energy of a subset of the NF-generated configurations using Density Functional Theory (DFT), we predict the remaining configuration's energy with the MLP and actively train the MLP using the DFT-computed energies. Lever
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#22312;&#32447;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#36716;&#21270;&#29575;&#39044;&#27979;&#12290;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#30340;&#25361;&#25112;&#65292;&#28155;&#21152;&#38750;&#28857;&#20987;&#24402;&#22240;&#30340;&#36716;&#21270;&#20250;&#25439;&#22351;&#27169;&#22411;&#30340;&#26657;&#20934;&#65292;&#32780;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#33021;&#22815;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.16432</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#24191;&#21578;&#20013;&#36890;&#36807;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#25913;&#36827;&#36716;&#21270;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Improving conversion rate prediction via self-supervised pre-training in online advertising. (arXiv:2401.16432v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16432
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#22312;&#32447;&#24191;&#21578;&#31995;&#32479;&#20013;&#30340;&#36716;&#21270;&#29575;&#39044;&#27979;&#12290;&#30001;&#20110;&#25968;&#25454;&#31232;&#30095;&#24615;&#30340;&#25361;&#25112;&#65292;&#28155;&#21152;&#38750;&#28857;&#20987;&#24402;&#22240;&#30340;&#36716;&#21270;&#20250;&#25439;&#22351;&#27169;&#22411;&#30340;&#26657;&#20934;&#65292;&#32780;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#33021;&#22815;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#36716;&#21270;&#29575;&#26159;&#22312;&#32447;&#24191;&#21578;&#31995;&#32479;&#20013;&#20248;&#21270;&#25237;&#26631;&#20197;&#28385;&#36275;&#24191;&#21578;&#20027;&#24615;&#33021;&#35201;&#27714;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23835;&#36215;&#65292;&#20294;&#36825;&#20123;&#39044;&#27979;&#36890;&#24120;&#30001;&#20998;&#35299;&#26426;&#65288;FM&#65289;&#36827;&#34892;&#65292;&#29305;&#21035;&#26159;&#22312;&#25512;&#29702;&#24310;&#36831;&#33267;&#20851;&#37325;&#35201;&#30340;&#21830;&#19994;&#29615;&#22659;&#20013;&#12290;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#36923;&#36753;&#22238;&#24402;&#26694;&#26550;&#35757;&#32451;&#65292;&#21033;&#29992;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#36807;&#21435;&#29992;&#25143;&#27963;&#21160;&#24418;&#25104;&#30340;&#26631;&#35760;&#34920;&#26684;&#25968;&#25454;&#12290;&#35768;&#22810;&#24191;&#21578;&#20027;&#21482;&#20851;&#24515;&#34987;&#28857;&#20987;&#23646;&#24615;&#30340;&#36716;&#21270;&#12290;&#39044;&#27979;&#32473;&#23450;&#28857;&#20987;&#30340;&#36716;&#21270;&#27169;&#22411;&#35757;&#32451;&#30340;&#20027;&#35201;&#25361;&#25112;&#26469;&#33258;&#25968;&#25454;&#31232;&#30095;&#24615; - &#28857;&#20987;&#24456;&#23569;&#65292;&#28857;&#20987;&#24402;&#22240;&#30340;&#36716;&#21270;&#26356;&#23569;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#38598;&#20013;&#28155;&#21152;&#38750;&#28857;&#20987;&#24402;&#22240;&#30340;&#36716;&#21270;&#26469;&#20943;&#36731;&#31232;&#30095;&#24615;&#20250;&#25439;&#22351;&#27169;&#22411;&#30340;&#26657;&#20934;&#12290;&#30001;&#20110;&#26657;&#20934;&#23545;&#23454;&#29616;&#24191;&#21578;&#20027;&#30446;&#26631;&#33267;&#20851;&#37325;&#35201;&#65292;&#36825;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#33258;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#24605;&#24819;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The task of predicting conversion rates (CVR) lies at the heart of online advertising systems aiming to optimize bids to meet advertiser performance requirements. Even with the recent rise of deep neural networks, these predictions are often made by factorization machines (FM), especially in commercial settings where inference latency is key. These models are trained using the logistic regression framework on labeled tabular data formed from past user activity that is relevant to the task at hand.  Many advertisers only care about click-attributed conversions. A major challenge in training models that predict conversions-given-clicks comes from data sparsity - clicks are rare, conversions attributed to clicks are even rarer. However, mitigating sparsity by adding conversions that are not click-attributed to the training set impairs model calibration. Since calibration is critical to achieving advertiser goals, this is infeasible.  In this work we use the well-known idea of self-supervi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#22312;&#39640;&#32500;&#24230;&#30456;&#20851;&#21464;&#37327;&#24773;&#20917;&#19979;&#23454;&#29616;&#34394;&#35686;&#29575;&#25511;&#21046;&#65292;&#36890;&#36807;&#32508;&#21512;&#23618;&#27425;&#22270;&#27169;&#22411;&#22312;T-Rex&#26694;&#26550;&#20013;&#21033;&#29992;&#20381;&#36182;&#32467;&#26500;&#65292;&#21033;&#29992;&#38789;&#35770;&#35777;&#26126;&#21464;&#37327;&#24809;&#32602;&#26426;&#21046;&#30830;&#20445;&#20102;FDR&#30340;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.15796</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#30456;&#20851;&#21464;&#37327;&#30340;&#34394;&#35686;&#29575;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional False Discovery Rate Control for Dependent Variables. (arXiv:2401.15796v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15796
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#22312;&#39640;&#32500;&#24230;&#30456;&#20851;&#21464;&#37327;&#24773;&#20917;&#19979;&#23454;&#29616;&#34394;&#35686;&#29575;&#25511;&#21046;&#65292;&#36890;&#36807;&#32508;&#21512;&#23618;&#27425;&#22270;&#27169;&#22411;&#22312;T-Rex&#26694;&#26550;&#20013;&#21033;&#29992;&#20381;&#36182;&#32467;&#26500;&#65292;&#21033;&#29992;&#38789;&#35770;&#35777;&#26126;&#21464;&#37327;&#24809;&#32602;&#26426;&#21046;&#30830;&#20445;&#20102;FDR&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#12289;&#39640;&#32500;&#24230;&#25968;&#25454;&#20013;&#30830;&#20445;&#21487;&#22797;&#29616;&#30340;&#21457;&#29616;&#32467;&#26524;&#30340;&#31639;&#27861;&#22312;&#35768;&#22810;&#20449;&#21495;&#22788;&#29702;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#36817;&#24180;&#26469;&#65292;&#20986;&#29616;&#20102;&#22810;&#21464;&#37327;&#34394;&#35686;&#29575;&#65288;FDR&#65289;&#25511;&#21046;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#21464;&#37327;&#25968;&#37327;&#36229;&#36807;&#26679;&#26412;&#25968;&#37327;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20063;&#33021;&#25552;&#20379;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23384;&#22312;&#39640;&#24230;&#30456;&#20851;&#21464;&#37327;&#32452;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#21487;&#38752;&#22320;&#25511;&#21046;FDR&#65292;&#22312;&#22522;&#22240;&#32452;&#23398;&#21644;&#37329;&#34701;&#31561;&#39046;&#22495;&#20013;&#24456;&#24120;&#35265;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#32771;&#34385;&#19968;&#33324;&#20381;&#36182;&#32467;&#26500;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20381;&#36182;&#24863;&#30693;T-Rex&#36873;&#25321;&#22120;&#23558;&#23618;&#27425;&#22270;&#27169;&#22411;&#25972;&#21512;&#21040;T-Rex&#26694;&#26550;&#20013;&#65292;&#20197;&#26377;&#25928;&#21033;&#29992;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;&#21033;&#29992;&#38789;&#35770;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#21464;&#37327;&#24809;&#32602;&#26426;&#21046;&#30830;&#20445;&#20102;FDR&#30340;&#25511;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#38472;&#36848;&#21644;&#35777;&#26126;&#20102;&#19968;&#20010;&#28165;&#26224;&#30340;FDR&#25511;&#21046;&#26694;&#26550;&#30340;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms that ensure reproducible findings from large-scale, high-dimensional data are pivotal in numerous signal processing applications. In recent years, multivariate false discovery rate (FDR) controlling methods have emerged, providing guarantees even in high-dimensional settings where the number of variables surpasses the number of samples. However, these methods often fail to reliably control the FDR in the presence of highly dependent variable groups, a common characteristic in fields such as genomics and finance. To tackle this critical issue, we introduce a novel framework that accounts for general dependency structures. Our proposed dependency-aware T-Rex selector integrates hierarchical graphical models within the T-Rex framework to effectively harness the dependency structure among variables. Leveraging martingale theory, we prove that our variable penalization mechanism ensures FDR control. We further generalize the FDR-controlling framework by stating and proving a clea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15771</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#25968;&#25454;&#39537;&#21160;&#40065;&#26834;&#20248;&#21270;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#36890;&#24120;&#28041;&#21450;&#20248;&#21270;&#25968;&#25454;&#39537;&#21160;&#30340;&#39118;&#38505;&#20934;&#21017;&#12290;&#39118;&#38505;&#36890;&#24120;&#26159;&#26681;&#25454;&#32463;&#39564;&#25968;&#25454;&#20998;&#24067;&#35745;&#31639;&#30340;&#65292;&#20294;&#30001;&#20110;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#31283;&#23450;&#21644;&#19981;&#22909;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#40065;&#26834;&#20934;&#21017;&#65292;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#65288;&#21363;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65289;&#29702;&#35770;&#21644;&#26368;&#36817;&#30340;&#24179;&#28369;&#27169;&#31946;&#35268;&#36991;&#20559;&#22909;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30340;&#35265;&#35299;&#30456;&#32467;&#21512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#30340;&#26032;&#36830;&#25509;&#65292;&#20854;&#20013;&#21253;&#25324;&#23725;&#22238;&#24402;&#21644;&#22871;&#32034;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#40065;&#26834;&#20248;&#21270;&#36807;&#31243;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#32479;&#35745;&#20445;&#35777;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#23384;&#22312;&#12290;&#23545;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#34920;&#31034;&#30340;&#21487;&#34892;&#36817;&#20284;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;T-Rex&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#20013;&#36873;&#25321;&#23569;&#25968;&#30456;&#20851;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#38598;&#25104;&#26368;&#36817;&#37051;&#24809;&#32602;&#26426;&#21046;&#65292;&#21487;&#38752;&#25511;&#21046;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36807;&#21435;20&#24180;&#20869;&#22522;&#20110;&#23569;&#37327;&#32929;&#31080;&#20934;&#30830;&#36319;&#36394;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.15139</link><description>&lt;p&gt;
FDR&#25511;&#21046;&#30340;&#31232;&#30095;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking. (arXiv:2401.15139v1 [q-fin.PM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;T-Rex&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#20013;&#36873;&#25321;&#23569;&#25968;&#30456;&#20851;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#38598;&#25104;&#26368;&#36817;&#37051;&#24809;&#32602;&#26426;&#21046;&#65292;&#21487;&#38752;&#25511;&#21046;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36807;&#21435;20&#24180;&#20869;&#22522;&#20110;&#23569;&#37327;&#32929;&#31080;&#20934;&#30830;&#36319;&#36394;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#22914;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#25110;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#65292;&#20851;&#38190;&#26159;&#22312;&#20445;&#25345;&#23545;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#30340;&#25511;&#21046;&#30340;&#21516;&#26102;&#36873;&#25321;&#23569;&#25968;&#30456;&#20851;&#21464;&#37327;&#12290;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#21464;&#37327;&#20043;&#38388;&#32463;&#24120;&#23384;&#22312;&#24378;&#20381;&#36182;&#20851;&#31995;&#65288;&#20363;&#22914;&#32929;&#31080;&#25910;&#30410;&#65289;&#65292;&#36825;&#21487;&#33021;&#20250;&#21066;&#24369;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;&#27169;&#22411;X knockoff&#26041;&#27861;&#25110;T-Rex&#36873;&#25321;&#22120;&#65289;&#30340;FDR&#25511;&#21046;&#29305;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;T-Rex&#26694;&#26550;&#65292;&#20197;&#36866;&#24212;&#39640;&#24230;&#30456;&#20851;&#21464;&#37327;&#30340;&#37325;&#21472;&#32452;&#12290;&#36825;&#26159;&#36890;&#36807;&#23558;&#26368;&#36817;&#37051;&#24809;&#32602;&#26426;&#21046;&#38598;&#25104;&#21040;&#26694;&#26550;&#20013;&#23454;&#29616;&#30340;&#65292;&#35813;&#26426;&#21046;&#33021;&#22815;&#22312;&#29992;&#25143;&#23450;&#20041;&#30340;&#30446;&#26631;&#27700;&#24179;&#19978;&#21487;&#38752;&#25511;&#21046;FDR&#12290;&#31232;&#30095;&#25351;&#25968;&#36319;&#36394;&#30340;&#23454;&#20363;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#36807;&#21435;20&#24180;&#20869;&#22522;&#20110;&#23569;&#37327;&#32929;&#31080;&#20934;&#30830;&#36319;&#36394;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#30340;&#33021;&#21147;&#12290;&#22312;CRAN&#19978;&#25552;&#20379;&#20102;R&#21253;TRexSelector&#30340;&#24320;&#28304;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In high-dimensional data analysis, such as financial index tracking or biomedical applications, it is crucial to select the few relevant variables while maintaining control over the false discovery rate (FDR). In these applications, strong dependencies often exist among the variables (e.g., stock returns), which can undermine the FDR control property of existing methods like the model-X knockoff method or the T-Rex selector. To address this issue, we have expanded the T-Rex framework to accommodate overlapping groups of highly correlated variables. This is achieved by integrating a nearest neighbors penalization mechanism into the framework, which provably controls the FDR at the user-defined target level. A real-world example of sparse index tracking demonstrates the proposed method's ability to accurately track the S&amp;P 500 index over the past 20 years based on a small number of stocks. An open-source implementation is provided within the R package TRexSelector on CRAN.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23450;&#20215;&#29615;&#22659;&#19979;&#36827;&#34892;&#38656;&#27714;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#39044;&#27979;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23436;&#20840;&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#26356;&#22909;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#31163;&#32447;&#25919;&#31574;&#35774;&#32622;&#20013;&#20248;&#20110;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2312.15282</link><description>&lt;p&gt;
&#23450;&#20215;&#30340;&#22240;&#26524;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Causal Forecasting for Pricing. (arXiv:2312.15282v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23450;&#20215;&#29615;&#22659;&#19979;&#36827;&#34892;&#38656;&#27714;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#39044;&#27979;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23436;&#20840;&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#26356;&#22909;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#31163;&#32447;&#25919;&#31574;&#35774;&#32622;&#20013;&#20248;&#20110;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23450;&#20215;&#29615;&#22659;&#19979;&#36827;&#34892;&#38656;&#27714;&#39044;&#27979;&#30340;&#26032;&#26041;&#27861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24314;&#27169;&#20215;&#26684;&#20316;&#20026;&#38656;&#27714;&#30340;&#36755;&#20837;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#38646;&#21806;&#21830;&#30340;&#30446;&#26631;&#26159;&#20197;&#65288;&#21033;&#28070;&#65289;&#26368;&#20339;&#26041;&#24335;&#35774;&#23450;&#20215;&#26684;&#65292;&#20197;&#35299;&#20915;&#19979;&#28216;&#20915;&#31574;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#22240;&#26524;&#25512;&#26029;&#30340;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#21464;&#21387;&#22120;&#30340;&#39044;&#27979;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#23454;&#35777;&#23454;&#39564;&#65292;&#25105;&#20204;&#19968;&#26041;&#38754;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23436;&#20840;&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#23545;&#21512;&#25104;&#30340;&#12289;&#20294;&#29616;&#23454;&#30340;&#25968;&#25454;&#26356;&#22909;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#25968;&#25454;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#31163;&#32447;&#25919;&#31574;&#35774;&#32622;&#65288;&#21363;&#23450;&#20215;&#25919;&#31574;&#21457;&#29983;&#21464;&#21270;&#26102;&#65289;&#20013;&#20248;&#20110;&#20854;&#20182;&#39044;&#27979;&#26041;&#27861;&#65292;&#32780;&#22312;&#22312;&#32447;&#25919;&#31574;&#35774;&#32622;&#20013;&#30053;&#26377;&#33853;&#21518;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel method for demand forecasting in a pricing context. Here, modeling the causal relationship between price as an input variable to demand is crucial because retailers aim to set prices in a (profit) optimal manner in a downstream decision making problem. Our methods bring together the Double Machine Learning methodology for causal inference and state-of-the-art transformer-based forecasting models. In extensive empirical experiments, we show on the one hand that our method estimates the causal effect better in a fully controlled setting via synthetic, yet realistic data. On the other hand, we demonstrate on real-world data that our method outperforms forecasting methods in off-policy settings (i.e., when there's a change in the pricing policy) while only slightly trailing in the on-policy setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.15878</link><description>&lt;p&gt;
&#20998;&#37197;&#31119;&#21033;&#30340;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Policy Learning with Distributional Welfare. (arXiv:2311.15878v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.15878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#26469;&#20915;&#23450;&#27835;&#30103;&#20998;&#37197;&#65292;&#24182;&#24341;&#20837;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;&#26469;&#35299;&#20915;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#32852;&#21512;&#20998;&#24067;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#38024;&#23545;&#20998;&#37197;&#31119;&#21033;&#30340;&#26368;&#20248;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#12290;&#22823;&#37096;&#20998;&#20851;&#20110;&#27835;&#30103;&#36873;&#25321;&#30340;&#25991;&#29486;&#37117;&#32771;&#34385;&#20102;&#22522;&#20110;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21151;&#21033;&#31119;&#21033;&#12290;&#34429;&#28982;&#24179;&#22343;&#31119;&#21033;&#26159;&#30452;&#35266;&#30340;&#65292;&#20294;&#22312;&#20010;&#20307;&#24322;&#36136;&#21270;&#65288;&#20363;&#22914;&#65292;&#23384;&#22312;&#31163;&#32676;&#20540;&#65289;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#20998;&#37197; - &#36825;&#27491;&#26159;&#20010;&#24615;&#21270;&#27835;&#30103;&#24341;&#20837;&#30340;&#21407;&#22240;&#20043;&#19968;&#12290;&#36825;&#20010;&#35266;&#23519;&#35753;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26681;&#25454;&#20010;&#20307;&#27835;&#30103;&#25928;&#24212;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65288;QoTE&#65289;&#26469;&#20998;&#37197;&#27835;&#30103;&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#26681;&#25454;&#20998;&#20301;&#25968;&#27010;&#29575;&#30340;&#36873;&#25321;&#65292;&#36825;&#20010;&#20934;&#21017;&#21487;&#20197;&#36866;&#24212;&#35880;&#24910;&#25110;&#31895;&#24515;&#30340;&#20915;&#31574;&#32773;&#12290;&#30830;&#23450;QoTE&#30340;&#25361;&#25112;&#22312;&#20110;&#20854;&#38656;&#35201;&#23545;&#21453;&#20107;&#23454;&#32467;&#26524;&#30340;&#32852;&#21512;&#20998;&#24067;&#26377;&#25152;&#20102;&#35299;&#65292;&#20294;&#21363;&#20351;&#20351;&#29992;&#23454;&#39564;&#25968;&#25454;&#65292;&#36890;&#24120;&#20063;&#24456;&#38590;&#24674;&#22797;&#20986;&#26469;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#40065;&#26834;&#30340;&#26368;&#23567;&#26368;&#22823;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore optimal treatment allocation policies that target distributional welfare. Most literature on treatment choice has considered utilitarian welfare based on the conditional average treatment effect (ATE). While average welfare is intuitive, it may yield undesirable allocations especially when individuals are heterogeneous (e.g., with outliers) - the very reason individualized treatments were introduced in the first place. This observation motivates us to propose an optimal policy that allocates the treatment based on the conditional quantile of individual treatment effects (QoTE). Depending on the choice of the quantile probability, this criterion can accommodate a policymaker who is either prudent or negligent. The challenge of identifying the QoTE lies in its requirement for knowledge of the joint distribution of the counterfactual outcomes, which is generally hard to recover even with experimental data. Therefore, we introduce minimax policies that are robust 
&lt;/p&gt;</description></item><item><title>&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;MFNs&#65289;&#26159;&#19968;&#31181;&#36890;&#36807;&#35299;&#26512;&#30697;&#38453;&#31561;&#21464;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.10434</link><description>&lt;p&gt;
&#31561;&#21464;&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Equivariant Matrix Function Neural Networks. (arXiv:2310.10434v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10434
&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;MFNs&#65289;&#26159;&#19968;&#31181;&#36890;&#36807;&#35299;&#26512;&#30697;&#38453;&#31561;&#21464;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#23588;&#20854;&#26159;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#65292;&#24050;&#32463;&#25104;&#20026;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23398;&#20064;&#22270;&#24418;&#30340;&#24378;&#22823;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#24403;&#24314;&#27169;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#26102;&#65292;MPNNs&#22312;&#22823;&#20849;&#36717;&#20998;&#23376;&#65292;&#37329;&#23646;&#25110;&#38750;&#26230;&#24577;&#26448;&#26009;&#31561;&#31995;&#32479;&#20013;&#38754;&#20020;&#25361;&#25112;&#12290;&#23613;&#31649;&#35889;GNN&#21644;&#20256;&#32479;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;&#20363;&#22914;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#65289;&#21487;&#20197;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65292;&#20294;&#23427;&#20204;&#24120;&#24120;&#32570;&#20047;&#25193;&#23637;&#24615;&#65292;&#36866;&#24212;&#24615;&#65292;&#27867;&#21270;&#33021;&#21147;&#65292;&#35745;&#31639;&#25928;&#29575;&#65292;&#25110;&#32773;&#19981;&#33021;&#25429;&#25417;&#25968;&#25454;&#20013;&#30340;&#35814;&#32454;&#32467;&#26500;&#20851;&#31995;&#25110;&#23545;&#31216;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;MFNs&#65289;&#65292;&#19968;&#31181;&#36890;&#36807;&#35299;&#26512;&#30697;&#38453;&#31561;&#21464;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#30340;&#26032;&#22411;&#26550;&#26500;&#12290;&#37319;&#29992;&#35299;&#26512;&#30697;&#38453;&#23637;&#24320;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#25509;&#30340;&#23454;&#29616;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#38543;&#31995;&#32479;&#22823;&#23567;&#32447;&#24615;&#25193;&#23637;&#30340;&#28508;&#21147;&#12290;&#35813;MFN&#26550;&#26500;&#22312;&#26631;&#20934;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs), especially message-passing neural networks (MPNNs), have emerged as powerful architectures for learning on graphs in diverse applications. However, MPNNs face challenges when modeling non-local interactions in systems such as large conjugated molecules, metals, or amorphous materials. Although Spectral GNNs and traditional neural networks such as recurrent neural networks and transformers mitigate these challenges, they often lack extensivity, adaptability, generalizability, computational efficiency, or fail to capture detailed structural relationships or symmetries in the data. To address these concerns, we introduce Matrix Function Neural Networks (MFNs), a novel architecture that parameterizes non-local interactions through analytic matrix equivariant functions. Employing resolvent expansions offers a straightforward implementation and the potential for linear scaling with system size. The MFN architecture achieves state-of-the-art performance in standa
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#36830;&#32493;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#21160;&#21147;&#23398;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#31163;&#25955;&#26102;&#38388;&#19979;&#36827;&#34892;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#39640;&#38454;&#25968;&#20540;&#31215;&#20998;&#22120;&#36827;&#34892;&#21160;&#21147;&#23398;&#20989;&#25968;&#30340;&#31163;&#25955;&#21270;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#36817;&#20284;&#25512;&#26029;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2309.02351</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#21160;&#21147;&#23398;&#30340;&#31934;&#30830;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Exact Inference for Continuous-Time Gaussian Process Dynamics. (arXiv:2309.02351v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#36830;&#32493;&#26102;&#38388;&#39640;&#26031;&#36807;&#31243;&#21160;&#21147;&#23398;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#31163;&#25955;&#26102;&#38388;&#19979;&#36827;&#34892;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#39640;&#38454;&#25968;&#20540;&#31215;&#20998;&#22120;&#36827;&#34892;&#21160;&#21147;&#23398;&#20989;&#25968;&#30340;&#31163;&#25955;&#21270;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#36817;&#20284;&#25512;&#26029;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#29289;&#29702;&#31995;&#32479;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#21160;&#21147;&#31995;&#32479;&#26469;&#25551;&#36848;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#30495;&#23454;&#31995;&#32479;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#38656;&#35201;&#20174;&#27979;&#37327;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;&#30001;&#20110;&#25968;&#25454;&#36890;&#24120;&#20197;&#31163;&#25955;&#26102;&#38388;&#25910;&#38598;&#65292;&#20363;&#22914;&#36890;&#36807;&#20256;&#24863;&#22120;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#21160;&#21147;&#27169;&#22411;&#23398;&#20064;&#20013;&#30340;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#26159;&#38024;&#23545;&#19968;&#27493;&#39044;&#27979;&#36827;&#34892;&#35757;&#32451;&#30340;&#12290;&#22312;&#19968;&#20123;&#22330;&#26223;&#20013;&#65292;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#38382;&#39064;&#65292;&#20363;&#22914;&#22914;&#26524;&#27979;&#37327;&#32467;&#26524;&#20197;&#19981;&#35268;&#21017;&#30340;&#26102;&#38388;&#27493;&#38271;&#25552;&#20379;&#65292;&#25110;&#32773;&#29289;&#29702;&#31995;&#32479;&#23646;&#24615;&#38656;&#35201;&#20445;&#25345;&#19981;&#21464;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24314;&#31435;&#23545;&#30495;&#23454;&#36830;&#32493;&#26102;&#38388;&#21160;&#21147;&#23398;&#30340;GP&#27169;&#22411;&#12290;&#39640;&#38454;&#25968;&#20540;&#31215;&#20998;&#22120;&#25552;&#20379;&#20102;&#36890;&#36807;&#20219;&#24847;&#31934;&#24230;&#31163;&#25955;&#21270;&#21160;&#21147;&#23398;&#20989;&#25968;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#24037;&#20855;&#12290;&#35768;&#22810;&#39640;&#38454;&#31215;&#20998;&#22120;&#38656;&#35201;&#22312;&#20013;&#38388;&#26102;&#38388;&#27493;&#39588;&#36827;&#34892;&#21160;&#21147;&#23398;&#35780;&#20272;&#65292;&#36825;&#20351;&#24471;&#31934;&#30830;&#30340;GP&#25512;&#26029;&#21464;&#24471;&#38590;&#20197;&#22788;&#29702;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#36890;&#24120;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#26469;&#36817;&#20284;GP&#21518;&#39564;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#31934;&#30830;&#30340;GP&#25512;&#26029;&#26159;&#24456;&#22256;&#38590;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physical systems can often be described via a continuous-time dynamical system. In practice, the true system is often unknown and has to be learned from measurement data. Since data is typically collected in discrete time, e.g. by sensors, most methods in Gaussian process (GP) dynamics model learning are trained on one-step ahead predictions. This can become problematic in several scenarios, e.g. if measurements are provided at irregularly-sampled time steps or physical system properties have to be conserved. Thus, we aim for a GP model of the true continuous-time dynamics. Higher-order numerical integrators provide the necessary tools to address this problem by discretizing the dynamics function with arbitrary accuracy. Many higher-order integrators require dynamics evaluations at intermediate time steps making exact GP inference intractable. In previous work, this problem is often tackled by approximating the GP posterior with variational inference. However, exact GP inference is pre
&lt;/p&gt;</description></item><item><title>UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00238</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00238
&lt;/p&gt;
&lt;p&gt;
UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#24403;&#30446;&#26631;&#25968;&#25454;&#31232;&#32570;&#32780;&#28304;&#25968;&#25454;&#20805;&#36275;&#65292;&#25110;&#32773;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#36716;&#31227;&#23398;&#20064;&#22312;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;UTrans&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#30340;&#30028;&#38480;&#20302;&#20110;&#20165;&#26377;&#30446;&#26631;&#25968;&#25454;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#20551;&#35774;&#26816;&#39564;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#25968;&#25454;&#26816;&#27979;&#31639;&#27861;&#65292;&#29992;&#20110;&#25490;&#38500;&#19981;&#21487;&#36716;&#31227;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#35780;&#20272;&#21644;&#27604;&#36739;&#20102;UTrans&#19982;&#29616;&#26377;&#31639;&#27861;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;UTrans&#22312;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#32654;&#22269;&#20195;&#38469;&#27969;&#21160;&#25968;&#25454;&#65292;&#24182;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#19982;&#32463;&#20856;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#65292;&#25552;&#39640;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07119</link><description>&lt;p&gt;
&#22522;&#20110;&#8220;&#24179;&#22343;&#8221;&#30340;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#30340;&#25913;&#36827;&#65292;&#20197;&#39135;&#21697;&#38656;&#27714;&#39044;&#27979;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast. (arXiv:2306.07119v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#65292;&#25552;&#39640;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24120;&#35265;&#39044;&#27979;&#22330;&#26223;&#26159;&#32771;&#34385;&#19968;&#32452;&#21487;&#33021;&#24322;&#36136;&#24615;&#30340;&#30456;&#21516;&#39046;&#22495;&#26102;&#38388;&#24207;&#21015;&#12290;&#30001;&#20110;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#19981;&#21516;&#29305;&#24615;&#65292;&#22914;&#38271;&#24230;&#31561;&#65292;&#30452;&#25509;&#23545;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#20013;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#25214;&#21040;&#30456;&#20284;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#20197;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#25552;&#20986;&#20102;&#20960;&#31181;&#25191;&#34892;&#24179;&#22343;&#30340;&#26041;&#27861;&#65292;&#24182;&#29702;&#35770;&#35777;&#26126;&#20102;&#24179;&#22343;&#23545;&#20110;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#35786;&#26029;&#24037;&#20855;&#65292;&#20801;&#35768;&#28145;&#20837;&#29702;&#35299;&#35813;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common forecasting setting in real world applications considers a set of possibly heterogeneous time series of the same domain. Due to different properties of each time series such as length, obtaining forecasts for each individual time series in a straight-forward way is challenging. This paper proposes a general framework utilizing a similarity measure in Dynamic Time Warping to find similar time series to build neighborhoods in a k-Nearest Neighbor fashion, and improve forecasts of possibly simple models by averaging. Several ways of performing the averaging are suggested, and theoretical arguments underline the usefulness of averaging for forecasting. Additionally, diagnostics tools are proposed allowing a deep understanding of the procedure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.16284</link><description>&lt;p&gt;
DoWG&#23637;&#31034;&#65306;&#19968;&#31181;&#39640;&#25928;&#30340;&#36890;&#29992;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26131;&#20110;&#23454;&#29616;&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#20248;&#21270;&#22120;&#65306;DoWG&#65288;Weighted Gradients&#30340;&#36317;&#31163;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#8212;&#8212;&#22312;&#19981;&#35843;&#25972;&#20219;&#20309;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#21305;&#37197;&#20248;&#21270;&#20984;&#20248;&#21270;&#20013;&#26368;&#20248;&#35843;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#65292;&#24182;&#19988;&#26159;&#36890;&#29992;&#30340;&#8212;&#8212;&#33258;&#21160;&#36866;&#24212;&#24179;&#28369;&#21644;&#38750;&#24179;&#28369;&#38382;&#39064;&#12290;&#19982;AdaGrad&#65292;Adam&#25110;DoG&#31561;&#27969;&#34892;&#31639;&#27861;&#35745;&#31639;&#24179;&#26041;&#26799;&#24230;&#30340;&#36816;&#34892;&#24179;&#22343;&#20540;&#19981;&#21516;&#65292;DoWG&#20445;&#25345;&#36816;&#34892;&#24179;&#22343;&#20540;&#30340;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#21152;&#26435;&#29256;&#26412;&#65292;&#36825;&#23545;&#20110;&#23454;&#29616;&#25152;&#38656;&#30340;&#24615;&#36136;&#33267;&#20851;&#37325;&#35201;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;DoWG&#26159;&#31532;&#19968;&#20010;&#19981;&#38656;&#35201;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#30340;&#26080;&#21442;&#25968;&#65292;&#39640;&#25928;&#21644;&#36890;&#29992;&#31639;&#27861;&#12290;&#23427;&#36824;&#26159;&#31532;&#19968;&#20010;&#36866;&#24212;&#20110;&#24179;&#31283;&#20248;&#21270;&#30340;&#26080;&#21442;&#25968;AdaGrad&#26679;&#24335;&#31639;&#27861;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;DoWG&#22312;&#31283;&#23450;&#30340;&#36793;&#32536;&#35757;&#32451;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#38543;&#26426;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#20197;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#65292;&#38024;&#23545;&#26410;&#30693;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#36890;&#36807;&#25191;&#34892;&#29305;&#24449;&#21521;&#37327;&#36716;&#25442;&#35299;&#20915;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.17043</link><description>&lt;p&gt;
&#26080;&#35266;&#27979;&#19978;&#19979;&#25991;&#30340;&#32852;&#37030;&#38543;&#26426;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Stochastic Bandit Learning with Unobserved Context. (arXiv:2303.17043v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#38543;&#26426;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#20197;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#65292;&#38024;&#23545;&#26410;&#30693;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#36890;&#36807;&#25191;&#34892;&#29305;&#24449;&#21521;&#37327;&#36716;&#25442;&#35299;&#20915;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26410;&#30693;&#19978;&#19979;&#25991;&#30340;&#32852;&#37030;&#38543;&#26426;&#22810;&#33218;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;M&#20010;&#20195;&#29702;&#38754;&#20020;&#19981;&#21516;&#30340;&#36172;&#21338;&#26426;&#24182;&#21327;&#20316;&#23398;&#20064;&#12290;&#36890;&#20449;&#27169;&#22411;&#30001;&#20013;&#22830;&#26381;&#21153;&#22120;&#32452;&#25104;&#65292;&#24182;&#19988;&#20195;&#29702;&#20250;&#23450;&#26399;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#20849;&#20139;&#20854;&#20272;&#35745;&#32467;&#26524;&#65292;&#20197;&#20415;&#36873;&#25321;&#26368;&#20248;&#21160;&#20316;&#20197;&#26368;&#23567;&#21270;&#24635;&#21518;&#24724;&#12290;&#25105;&#20204;&#20551;&#35774;&#31934;&#30830;&#30340;&#19978;&#19979;&#25991;&#19981;&#21487;&#35266;&#23519;&#65292;&#20195;&#29702;&#20165;&#35266;&#27979;&#19978;&#19979;&#25991;&#30340;&#20998;&#24067;&#12290;&#20363;&#22914;&#65292;&#24403;&#19978;&#19979;&#25991;&#26412;&#36523;&#26159;&#22122;&#22768;&#27979;&#37327;&#25110;&#22522;&#20110;&#39044;&#27979;&#26426;&#21046;&#26102;&#65292;&#23601;&#20250;&#20986;&#29616;&#36825;&#31181;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24320;&#21457;&#19968;&#31181;&#20998;&#24067;&#24335;&#32852;&#37030;&#31639;&#27861;&#65292;&#20419;&#36827;&#20195;&#29702;&#20043;&#38388;&#30340;&#21327;&#20316;&#23398;&#20064;&#65292;&#36873;&#25321;&#19968;&#31995;&#21015;&#26368;&#20248;&#21160;&#20316;&#20197;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#12290;&#36890;&#36807;&#25191;&#34892;&#29305;&#24449;&#21521;&#37327;&#36716;&#25442;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28040;&#38500;&#30340;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#32447;&#24615;&#21442;&#25968;&#21270;&#22870;&#21169;&#20989;&#25968;&#30340;&#21518;&#24724;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of federated stochastic multi-arm contextual bandits with unknown contexts, in which M agents are faced with different bandits and collaborate to learn. The communication model consists of a central server and the agents share their estimates with the central server periodically to learn to choose optimal actions in order to minimize the total regret. We assume that the exact contexts are not observable and the agents observe only a distribution of the contexts. Such a situation arises, for instance, when the context itself is a noisy measurement or based on a prediction mechanism. Our goal is to develop a distributed and federated algorithm that facilitates collaborative learning among the agents to select a sequence of optimal actions so as to maximize the cumulative reward. By performing a feature vector transformation, we propose an elimination-based algorithm and prove the regret bound for linearly parametrized reward functions. Finally, we validated the perfo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#12290;&#35813;&#26041;&#27861;&#23558;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#20854;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#29575;&#30456;&#20851;&#32852;&#65292;&#24182;&#25552;&#20379;&#20102;&#20381;&#36182;&#20110;&#32463;&#39564;&#20998;&#24067;&#32780;&#38750;&#26410;&#30693;&#20998;&#24067;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#25512;&#23548;&#20986;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#20551;&#35774;&#38543;&#26426;&#21464;&#37327;&#30340;&#20219;&#20309;&#20989;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#21253;&#21547;&#24182;&#21487;&#33021;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;PAC-Bayes&#21644;&#25968;&#25454;&#30456;&#20851;&#20869;&#22312;&#32500;&#24230;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.05369</link><description>&lt;p&gt;
&#36890;&#36807;&#21487;&#21464;&#22823;&#23567;&#30340;&#21387;&#32553;&#24615;&#24314;&#31435;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Data-dependent Generalization Bounds via Variable-Size Compressibility. (arXiv:2303.05369v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#12290;&#35813;&#26041;&#27861;&#23558;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#20854;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#29575;&#30456;&#20851;&#32852;&#65292;&#24182;&#25552;&#20379;&#20102;&#20381;&#36182;&#20110;&#32463;&#39564;&#20998;&#24067;&#32780;&#38750;&#26410;&#30693;&#20998;&#24067;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#25512;&#23548;&#20986;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#20551;&#35774;&#38543;&#26426;&#21464;&#37327;&#30340;&#20219;&#20309;&#20989;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#21253;&#21547;&#24182;&#21487;&#33021;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;PAC-Bayes&#21644;&#25968;&#25454;&#30456;&#20851;&#20869;&#22312;&#32500;&#24230;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#8220;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#24615;&#8221;&#26694;&#26550;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#20854;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#22823;&#23567;&#8220;&#21387;&#32553;&#29575;&#8221;&#30456;&#20851;&#32852;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#24471;&#21040;&#30340;&#30028;&#38480;&#20381;&#36182;&#20110;&#25163;&#22836;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#30340;&#32463;&#39564;&#20998;&#24067;&#65292;&#32780;&#19981;&#26159;&#20854;&#26410;&#30693;&#20998;&#24067;&#12290;&#25105;&#20204;&#24314;&#31435;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#21253;&#25324;&#23614;&#37096;&#30028;&#38480;&#12289;&#26399;&#26395;&#20540;&#30340;&#23614;&#37096;&#30028;&#38480;&#21644;&#26399;&#26395;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36824;&#21487;&#20197;&#25512;&#23548;&#20986;&#23545;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#20551;&#35774;&#38543;&#26426;&#21464;&#37327;&#30340;&#20219;&#20309;&#20989;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20123;&#27867;&#21270;&#30028;&#38480;&#21253;&#21547;&#24182;&#21487;&#33021;&#20248;&#20110;&#20960;&#31181;&#29616;&#26377;&#30340;&#22522;&#20110;PAC-Bayes&#21644;&#25968;&#25454;&#30456;&#20851;&#20869;&#22312;&#32500;&#24230;&#30340;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#24471;&#21040;&#22797;&#21407;&#65292;&#20174;&#32780;&#25581;&#31034;&#20986;&#25105;&#20204;&#26041;&#27861;&#30340;&#32479;&#19968;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we establish novel data-dependent upper bounds on the generalization error through the lens of a "variable-size compressibility" framework that we introduce newly here. In this framework, the generalization error of an algorithm is linked to a variable-size 'compression rate' of its input data. This is shown to yield bounds that depend on the empirical measure of the given input data at hand, rather than its unknown distribution. Our new generalization bounds that we establish are tail bounds, tail bounds on the expectation, and in-expectations bounds. Moreover, it is shown that our framework also allows to derive general bounds on any function of the input data and output hypothesis random variables. In particular, these general bounds are shown to subsume and possibly improve over several existing PAC-Bayes and data-dependent intrinsic dimension-based bounds that are recovered as special cases, thus unveiling a unifying character of our approach. For instance, a new da
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MoleculeSTM&#30340;&#22810;&#27169;&#24577;&#20998;&#23376;&#32467;&#26500;-&#25991;&#26412;&#27169;&#22411;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#21270;&#23398;&#32467;&#26500;&#21644;&#25991;&#26412;&#25551;&#36848;&#65292;&#21487;&#20197;&#23454;&#29616;&#22522;&#20110;&#25991;&#26412;&#30340;&#26816;&#32034;&#21644;&#32534;&#36753;&#12290;&#36890;&#36807;&#26500;&#24314;&#22823;&#22411;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#24182;&#35774;&#35745;&#25361;&#25112;&#24615;&#30340;&#38646;&#26679;&#26412;&#20219;&#21153;&#36827;&#34892;&#39564;&#35777;&#65292;&#35813;&#27169;&#22411;&#23637;&#31034;&#20102;&#24320;&#25918;&#35789;&#27719;&#21644;&#32452;&#21512;&#24615;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.10789</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#20998;&#23376;&#32467;&#26500;-&#25991;&#26412;&#27169;&#22411;&#29992;&#20110;&#22522;&#20110;&#25991;&#26412;&#30340;&#26816;&#32034;&#21644;&#32534;&#36753;
&lt;/p&gt;
&lt;p&gt;
Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing. (arXiv:2212.10789v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MoleculeSTM&#30340;&#22810;&#27169;&#24577;&#20998;&#23376;&#32467;&#26500;-&#25991;&#26412;&#27169;&#22411;&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#21270;&#23398;&#32467;&#26500;&#21644;&#25991;&#26412;&#25551;&#36848;&#65292;&#21487;&#20197;&#23454;&#29616;&#22522;&#20110;&#25991;&#26412;&#30340;&#26816;&#32034;&#21644;&#32534;&#36753;&#12290;&#36890;&#36807;&#26500;&#24314;&#22823;&#22411;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#24182;&#35774;&#35745;&#25361;&#25112;&#24615;&#30340;&#38646;&#26679;&#26412;&#20219;&#21153;&#36827;&#34892;&#39564;&#35777;&#65292;&#35813;&#27169;&#22411;&#23637;&#31034;&#20102;&#24320;&#25918;&#35789;&#27719;&#21644;&#32452;&#21512;&#24615;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33647;&#29289;&#21457;&#29616;&#20013;&#27491;&#22312;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#37319;&#29992;&#20154;&#24037;&#26234;&#33021;&#65292;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#21033;&#29992;&#20998;&#23376;&#30340;&#21270;&#23398;&#32467;&#26500;&#65292;&#24573;&#35270;&#20102;&#21270;&#23398;&#39046;&#22495;&#20013;&#21487;&#29992;&#30340;&#20016;&#23500;&#25991;&#26412;&#30693;&#35782;&#12290;&#23558;&#25991;&#26412;&#30693;&#35782;&#32435;&#20837;&#32771;&#34385;&#21487;&#20197;&#23454;&#29616;&#26032;&#30340;&#33647;&#29289;&#35774;&#35745;&#30446;&#26631;&#65292;&#36866;&#24212;&#22522;&#20110;&#25991;&#26412;&#30340;&#25351;&#23548;&#21644;&#39044;&#27979;&#22797;&#26434;&#30340;&#29983;&#29289;&#27963;&#24615;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27169;&#24577;&#30340;&#20998;&#23376;&#32467;&#26500;-&#25991;&#26412;&#27169;&#22411;MoleculeSTM&#65292;&#36890;&#36807;&#32852;&#21512;&#23398;&#20064;&#20998;&#23376;&#30340;&#21270;&#23398;&#32467;&#26500;&#21644;&#25991;&#26412;&#25551;&#36848;&#26469;&#23454;&#29616;&#65292;&#37319;&#29992;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#12290;&#20026;&#20102;&#35757;&#32451;MoleculeSTM&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;PubChemSTM&#65292;&#21253;&#21547;&#36229;&#36807;28&#19975;&#20010;&#21270;&#23398;&#32467;&#26500;-&#25991;&#26412;&#23545;&#12290;&#20026;&#20102;&#23637;&#31034;MoleculeSTM&#30340;&#26377;&#25928;&#24615;&#21644;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#22522;&#20110;&#25991;&#26412;&#25351;&#20196;&#30340;&#25361;&#25112;&#24615;&#38646;&#26679;&#26412;&#20219;&#21153;&#65292;&#21253;&#25324;&#32467;&#26500;-&#25991;&#26412;&#26816;&#32034;&#21644;&#20998;&#23376;&#32534;&#36753;&#12290;MoleculeSTM&#20855;&#26377;&#20004;&#20010;&#20027;&#35201;&#29305;&#24615;&#65306;&#24320;&#25918;&#35789;&#27719;&#21644;&#36890;&#36807;&#33258;&#28982;&#35821;&#35328;&#23454;&#29616;&#32452;&#21512;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi-modal molecule structure-text model, MoleculeSTM, by jointly learning molecules' chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000 chemical structure-text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure-text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#21452;&#37325;&#31283;&#20581;&#26368;&#36817;&#37051;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#19968;&#33268;&#30340;&#20272;&#35745;&#65292;&#24182;&#22312;&#23384;&#22312;&#33391;&#22909;&#30340;&#34892;&#21644;&#21015;&#37051;&#23621;&#26102;&#25552;&#20379;&#65288;&#36817;&#20284;&#65289;&#20108;&#27425;&#25913;&#36827;&#38750;&#28176;&#36817;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.14297</link><description>&lt;p&gt;
&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#21452;&#37325;&#31283;&#20581;&#26368;&#36817;&#37051;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Doubly robust nearest neighbors in factor models. (arXiv:2211.14297v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14297
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#21452;&#37325;&#31283;&#20581;&#26368;&#36817;&#37051;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#19968;&#33268;&#30340;&#20272;&#35745;&#65292;&#24182;&#22312;&#23384;&#22312;&#33391;&#22909;&#30340;&#34892;&#21644;&#21015;&#37051;&#23621;&#26102;&#25552;&#20379;&#65288;&#36817;&#20284;&#65289;&#20108;&#27425;&#25913;&#36827;&#38750;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#24182;&#20998;&#26512;&#20102;&#22312;&#28508;&#22312;&#22240;&#23376;&#27169;&#22411;&#20013;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#25913;&#36827;&#26368;&#36817;&#37051;&#65288;NN&#65289;&#26041;&#27861;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#24102;&#26377;&#32570;&#22833;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#65292;&#20854;&#20013;&#24403;&#34987;&#35266;&#23519;&#21040;&#26102;&#65292;&#31532;$(i, t)$&#20010;&#26465;&#30446;&#30001;&#20854;&#22343;&#20540;$f(u_i, v_t)$&#21152;&#19978;&#22343;&#20540;&#20026;&#38646;&#30340;&#22122;&#22768;&#32473;&#20986;&#65292;&#20854;&#20013;$f$&#20026;&#26410;&#30693;&#20989;&#25968;&#65292;$u_i$&#21644;$v_t$&#20026;&#28508;&#22312;&#22240;&#23376;&#12290;&#20043;&#21069;&#30340;NN&#31574;&#30053;&#65292;&#22914;&#21333;&#20803;-&#21333;&#20803;NN&#65292;&#29992;&#20110;&#20272;&#35745;&#22343;&#20540;$f(u_i, v_t)$&#65292;&#20381;&#36182;&#20110;&#23384;&#22312;&#20854;&#20182;&#34892;$j$&#20351;&#24471;$u_j \approx u_i$&#12290;&#31867;&#20284;&#22320;&#65292;&#26102;&#38388;-&#26102;&#38388;NN&#31574;&#30053;&#20381;&#36182;&#20110;&#23384;&#22312;&#21015;$t'$&#20351;&#24471;$v_{t'} \approx v_t$&#12290;&#24403;&#30456;&#20284;&#34892;&#25110;&#30456;&#20284;&#21015;&#19981;&#21487;&#29992;&#26102;&#65292;&#36825;&#20123;&#31574;&#30053;&#30340;&#24615;&#33021;&#36739;&#24046;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22312;&#20004;&#20010;&#26041;&#38754;&#23545;&#36825;&#31181;&#19981;&#36275;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#65306;(1) &#21482;&#35201;&#23384;&#22312;&#33391;&#22909;&#30340;&#34892;&#25110;&#21015;&#37051;&#23621;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#25552;&#20379;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290; (2) &#27492;&#22806;&#65292;&#22914;&#26524;&#23384;&#22312;&#33391;&#22909;&#30340;&#34892;&#21644;&#21015;&#37051;&#23621;&#65292;&#23427;&#25552;&#20379;&#20102;&#65288;&#36817;&#20284;&#65289;&#20108;&#27425;&#25913;&#36827;&#38750;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce and analyze an improved variant of nearest neighbors (NN) for estimation with missing data in latent factor models. We consider a matrix completion problem with missing data, where the $(i, t)$-th entry, when observed, is given by its mean $f(u_i, v_t)$ plus mean-zero noise for an unknown function $f$ and latent factors $u_i$ and $v_t$. Prior NN strategies, like unit-unit NN, for estimating the mean $f(u_i, v_t)$ relies on existence of other rows $j$ with $u_j \approx u_i$. Similarly, time-time NN strategy relies on existence of columns $t'$ with $v_{t'} \approx v_t$. These strategies provide poor performance respectively when similar rows or similar columns are not available. Our estimate is doubly robust to this deficit in two ways: (1) As long as there exist either good row or good column neighbors, our estimate provides a consistent estimate. (2) Furthermore, if both good row and good column neighbors exist, it provides a (near-)quadratic improvement in the non-asympto
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29109;&#27491;&#21017;&#21270;&#20316;&#20026;&#19968;&#31181;&#24179;&#28369;&#26041;&#27861;&#22312;Wasserstein&#20272;&#35745;&#22120;&#20013;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#36890;&#36807;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#23454;&#29616;&#12290;&#20027;&#35201;&#21457;&#29616;&#26159;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.06934</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#29109;&#27491;&#21017;&#21270;&#24179;&#28369;Wasserstein&#20272;&#35745;&#22120;&#30340;&#28508;&#22312;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
On the potential benefits of entropic regularization for smoothing Wasserstein estimators. (arXiv:2210.06934v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29109;&#27491;&#21017;&#21270;&#20316;&#20026;&#19968;&#31181;&#24179;&#28369;&#26041;&#27861;&#22312;Wasserstein&#20272;&#35745;&#22120;&#20013;&#30340;&#28508;&#22312;&#30410;&#22788;&#65292;&#36890;&#36807;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#23454;&#29616;&#12290;&#20027;&#35201;&#21457;&#29616;&#26159;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#19987;&#27880;&#20110;&#30740;&#31350;&#29109;&#27491;&#21017;&#21270;&#22312;&#26368;&#20248;&#36755;&#36816;&#20013;&#20316;&#20026;Wasserstein&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#35745;&#23398;&#20013;&#36924;&#36817;&#35823;&#24046;&#21644;&#20272;&#35745;&#35823;&#24046;&#30340;&#32463;&#20856;&#26435;&#34913;&#12290;Wasserstein&#20272;&#35745;&#22120;&#34987;&#23450;&#20041;&#20026;&#35299;&#20915;&#21464;&#20998;&#38382;&#39064;&#30340;&#35299;&#65292;&#20854;&#30446;&#26631;&#20989;&#25968;&#28041;&#21450;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#20351;&#29992;&#12290;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;&#29992;&#29109;&#24809;&#32602;&#26367;&#25442;&#26368;&#20248;&#36755;&#36816;&#25104;&#26412;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#26469;&#36827;&#34892;&#27491;&#21017;&#21270;&#65292;&#20174;&#32780;&#23545;&#32467;&#26524;&#20272;&#35745;&#22120;&#20135;&#29983;&#28508;&#22312;&#30340;&#24179;&#28369;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#29109;&#27491;&#21017;&#21270;&#23545;&#27491;&#21017;&#21270;Wasserstein&#20272;&#35745;&#22120;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#24615;&#36136;&#21487;&#33021;&#24102;&#26469;&#30340;&#30410;&#22788;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#35752;&#35770;&#29109;&#27491;&#21017;&#21270;&#22914;&#20309;&#20197;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#36798;&#21040;&#19982;&#26410;&#27491;&#21017;&#21270;&#30340;Wasserstein&#20272;&#35745;&#22120;&#30456;&#24403;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is focused on the study of entropic regularization in optimal transport as a smoothing method for Wasserstein estimators, through the prism of the classical tradeoff between approximation and estimation errors in statistics. Wasserstein estimators are defined as solutions of variational problems whose objective function involves the use of an optimal transport cost between probability measures. Such estimators can be regularized by replacing the optimal transport cost by its regularized version using an entropy penalty on the transport plan. The use of such a regularization has a potentially significant smoothing effect on the resulting estimators. In this work, we investigate its potential benefits on the approximation and estimation properties of regularized Wasserstein estimators. Our main contribution is to discuss how entropic regularization may reach, at a lower computational cost, statistical performances that are comparable to those of un-regularized Wasserstein esti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24490;&#29615;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#20272;&#35745;&#24178;&#39044;&#25928;&#26524;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#26102;&#38388;&#21464;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#20851;&#31995;&#21644;&#21327;&#21464;&#37327;&#21453;&#20107;&#23454;&#39044;&#27979;&#30340;&#22797;&#26434;&#32467;&#26500;&#65292;&#33021;&#22815;&#20934;&#30830;&#35780;&#20272;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#25552;&#20379;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.01900</link><description>&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#20272;&#35745;&#21453;&#20107;&#23454;&#27835;&#30103;&#32467;&#26524;&#30340;&#26102;&#38388;&#21464;&#21270;
&lt;/p&gt;
&lt;p&gt;
Estimating counterfactual treatment outcomes over time in complex multi-agent scenarios. (arXiv:2206.01900v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24490;&#29615;&#32593;&#32476;&#65292;&#29992;&#20110;&#22312;&#22797;&#26434;&#30340;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#20272;&#35745;&#24178;&#39044;&#25928;&#26524;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#26102;&#38388;&#21464;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#20851;&#31995;&#21644;&#21327;&#21464;&#37327;&#21453;&#20107;&#23454;&#39044;&#27979;&#30340;&#22797;&#26434;&#32467;&#26500;&#65292;&#33021;&#22815;&#20934;&#30830;&#35780;&#20272;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#25552;&#20379;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#24037;&#31243;&#21644;&#31185;&#23398;&#39046;&#22495;&#20013;&#65292;&#35780;&#20272;&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#20013;&#30340;&#24178;&#39044;&#34892;&#20026;&#65288;&#20363;&#22914;&#65292;&#20154;&#31867;&#20309;&#26102;&#24212;&#35813;&#24178;&#39044;&#33258;&#21160;&#39550;&#39542;&#31995;&#32479;&#65292;&#20309;&#26102;&#29699;&#21592;&#24212;&#35813;&#20256;&#32473;&#38431;&#21451;&#36827;&#34892;&#22909;&#23556;&#38376;&#65289;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#20351;&#29992;&#21453;&#20107;&#23454;&#30340;&#38271;&#26399;&#39044;&#27979;&#26469;&#20272;&#35745;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE&#65289;&#26159;&#35780;&#20272;&#27492;&#31867;&#24178;&#39044;&#25514;&#26045;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20256;&#32479;&#26694;&#26550;&#27809;&#26377;&#32771;&#34385;&#21040;&#22810;&#26234;&#33021;&#20307;&#20851;&#31995;&#30340;&#26102;&#38388;&#21464;&#21270;&#21644;&#21327;&#21464;&#37327;&#21453;&#20107;&#23454;&#39044;&#27979;&#30340;&#22797;&#26434;&#32467;&#26500;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;ITE&#30340;&#38169;&#35823;&#35780;&#20272;&#21644;&#35299;&#37322;&#22256;&#38590;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#21453;&#20107;&#23454;&#24490;&#29615;&#32593;&#32476;&#65292;&#29992;&#20110;&#20272;&#35745;&#24178;&#39044;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21033;&#29992;&#22270;&#24418;&#21464;&#20998;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#39046;&#22495;&#30693;&#35782;&#30340;&#35745;&#31639;&#26469;&#36827;&#34892;&#22522;&#20110;&#22810;&#26234;&#33021;&#20307;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#30340;&#38271;&#26399;&#39044;&#27979;&#30340;ITE&#20272;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#30830;&#35748;&#24490;&#29615;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evaluation of intervention in a multi-agent system, e.g., when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multi-agent relationships and covariate counterfactual prediction. This may lead to erroneous assessments of ITE and difficulty in interpretation. Here we propose an interpretable, counterfactual recurrent network in multi-agent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multi-agent covariates and outcomes, which can confirm the circu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20013;&#24515;&#32479;&#35745;&#37327;&#8212;&#8212;&#26368;&#36817;&#37051;&#27979;&#24230;&#65292;&#24182;&#36890;&#36807;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#19968;&#31181;&#22343;&#21248;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#30740;&#31350;&#20102;&#23427;&#12290;&#35813;&#27979;&#24230;&#21487;&#33021;&#20026;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.15083</link><description>&lt;p&gt;
&#26368;&#36817;&#37051;&#36807;&#31243;&#65306;&#24369;&#25910;&#25947;&#21644;&#38750;&#28176;&#36817;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Nearest neighbor process: weak convergence and non-asymptotic bound. (arXiv:2110.15083v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.15083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20013;&#24515;&#32479;&#35745;&#37327;&#8212;&#8212;&#26368;&#36817;&#37051;&#27979;&#24230;&#65292;&#24182;&#36890;&#36807;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#19968;&#31181;&#22343;&#21248;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#30740;&#31350;&#20102;&#23427;&#12290;&#35813;&#27979;&#24230;&#21487;&#33021;&#20026;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#30001;&#32473;&#23450;&#28857;&#30340;&#26368;&#36817;&#37051;&#25152;&#24471;&#21040;&#30340;&#32463;&#39564;&#27979;&#24230;&#8212;&#8212;&#26368;&#36817;&#37051;&#27979;&#24230;&#20316;&#20026;&#19968;&#31181;&#20013;&#24515;&#32479;&#35745;&#37327;&#12290;&#39318;&#20808;&#65292;&#22312;&#24213;&#23618;&#20989;&#25968;&#31867;&#19978;&#28385;&#36275;&#65288;&#21453;&#26144;&#26368;&#36817;&#37051;&#31639;&#27861;&#30340;&#26412;&#22320;&#21270;&#29305;&#24615;&#30340;&#65289;&#65288;&#26412;&#22320;&#65289;&#25903;&#25745;&#29109;&#26465;&#20214;&#19979;&#65292;&#23558;&#30456;&#20851;&#32463;&#39564;&#36807;&#31243;&#35777;&#26126;&#20026;&#28385;&#36275;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#20854;&#27425;&#65292;&#22312;&#32479;&#19968;&#29109;&#25968;&#30340;&#33879;&#21517;&#26465;&#20214;&#65288;&#36890;&#24120;&#31216;&#20026;Vapnik-Chervonenkis&#65289;&#19979;&#24314;&#31435;&#20102;&#19968;&#31181;&#22343;&#21248;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#12290;&#22312;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#20013;&#25152;&#33719;&#24471;&#30340;&#39640;&#26031;&#26497;&#38480;&#30340;&#21327;&#26041;&#24046;&#31561;&#20110;&#26465;&#20214;&#21327;&#26041;&#24046;&#31639;&#23376;&#65288;&#32473;&#20986;&#20852;&#36259;&#28857;&#65289;&#12290;&#36825;&#25552;&#31034;&#20102;&#19968;&#31181;&#21487;&#33021;&#24615;&#65292;&#21363;&#22312;&#20351;&#29992;&#30456;&#21516;&#30340;&#25512;&#29702;&#26041;&#24335;&#20294;&#20165;&#20351;&#29992;&#26368;&#36817;&#37051;&#32780;&#19981;&#26159;&#20840;&#37096;&#26367;&#25442;&#26631;&#20934;&#32463;&#39564;&#27979;&#24230;&#30340;&#26631;&#20934;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#26631;&#20934;&#26041;&#27861; - &#38750;&#23616;&#37096;&#12290;
&lt;/p&gt;
&lt;p&gt;
The empirical measure resulting from the nearest neighbors to a given point \textit{the nearest neighbor measure} - is introduced and studied as a central statistical quantity. First, the associated empirical process is shown to satisfy a uniform central limit theorem under a (local) bracketing entropy condition on the underlying class of functions (reflecting the localizing nature of the nearest neighbor algorithm). Second a uniform non-asymptotic bound is established under a well-known condition, often referred to as Vapnik-Chervonenkis, on the uniform entropy numbers. The covariance of the Gaussian limit obtained in the uniform central limit theorem is equal to the conditional covariance operator (given the point of interest). This suggests the possibility of extending standard approaches - non local - replacing simply the standard empirical measure by the nearest neighbor measure while using the same way of making inference but with the nearest neighbors only instead of the full 
&lt;/p&gt;</description></item></channel></rss>