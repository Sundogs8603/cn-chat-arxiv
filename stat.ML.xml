<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#23545;&#20132;&#21449;&#29109;&#12289;&#24191;&#20041;&#20132;&#21449;&#29109;&#12289;&#22343;&#26041;&#35823;&#24046;&#31561;&#19968;&#22823;&#31867;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#20248;&#21183;&#30340;&#21452;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.07288</link><description>&lt;p&gt;
&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#65306;&#29702;&#35770;&#20998;&#26512;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Cross-Entropy Loss Functions: Theoretical Analysis and Applications. (arXiv:2304.07288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20132;&#21449;&#29109;&#12289;&#24191;&#20041;&#20132;&#21449;&#29109;&#12289;&#22343;&#26041;&#35823;&#24046;&#31561;&#19968;&#22823;&#31867;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#20248;&#21183;&#30340;&#21452;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#29109;&#26159;&#24191;&#27867;&#24212;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#24403;&#20351;&#29992;softmax&#20989;&#25968;&#26102;&#65292;&#23427;&#19982;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#24212;&#29992;&#20110;&#36923;&#36753;&#22238;&#24402;&#25439;&#22833;&#20989;&#25968;&#30456;&#31526;&#12290;&#20294;&#26159;&#65292;&#20351;&#29992;&#20132;&#21449;&#29109;&#20316;&#20026;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26102;&#65292;&#25105;&#20204;&#33021;&#20381;&#38752;&#20160;&#20040;&#20445;&#35777;&#21602;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#21253;&#25324;&#20132;&#21449;&#29109;&#65288;&#25110;&#36923;&#36753;&#25439;&#22833;&#65289;&#12289;&#24191;&#20041;&#20132;&#21449;&#29109;&#12289;&#22343;&#26041;&#35823;&#24046;&#21644;&#20854;&#20182;&#20132;&#21449;&#29109;&#31867;&#20989;&#25968;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30340;&#31532;&#19968;&#20010;$H$-&#36830;&#32493;&#24615;&#30028;&#38480;&#12290;&#36825;&#20123;&#37117;&#26159;&#38750;&#28176;&#36827;&#20445;&#35777;&#65292;&#20197;&#20272;&#35745;&#20195;&#29702;&#25439;&#22833;&#30340;&#20272;&#35745;&#35823;&#24046;&#20026;&#19978;&#38480;&#65292;&#29992;&#20110;&#29305;&#23450;&#30340;&#20551;&#35774;&#38598;$H$&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#36825;&#20123;&#36793;&#30028;&#30340;&#32039;&#23494;&#31243;&#24230;&#12290;&#36825;&#20123;&#36793;&#30028;&#21462;&#20915;&#20110;&#31216;&#20026;&#21487;&#26368;&#23567;&#21270;&#38388;&#38553;&#30340;&#37327;&#65292;&#36825;&#20123;&#38388;&#38553;&#21482;&#21462;&#20915;&#20110;&#25439;&#22833;&#20989;&#25968;&#21644;&#20551;&#35774;&#38598;&#12290;&#20026;&#20102;&#20351;&#23427;&#20204;&#26356;&#20855;&#20307;&#21270;&#65292;&#25105;&#20204;&#23545;&#22797;&#26434;&#21644;&#25439;&#22833;&#20989;&#25968;&#30340;&#36825;&#20123;&#38388;&#38553;&#36827;&#34892;&#20102;&#20855;&#20307;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;&#21452;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#23427;&#22522;&#20110;&#20004;&#20010;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#20248;&#20110;&#26631;&#20934;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#29305;&#21035;&#26159;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. But, what guarantees can we rely on when using cross-entropy as a surrogate loss? We present a theoretical analysis of a broad family of losses, comp-sum losses, that includes cross-entropy (or logistic loss), generalized cross-entropy, the mean absolute error and other loss cross-entropy-like functions. We give the first $H$-consistency bounds for these loss functions. These are non-asymptotic guarantees that upper bound the zero-one loss estimation error in terms of the estimation error of a surrogate loss, for the specific hypothesis set $H$ used. We further show that our bounds are tight. These bounds depend on quantities called minimizability gaps, which only depend on the loss function and the hypothesis set. To make them more explicit, we give a specific analysis of these gaps for comp-sum losses. We also introduc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26080;&#20851;&#22870;&#21169;&#25506;&#32034;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#20445;&#35777;&#26679;&#26412;&#25910;&#38598;&#25968;&#37327;&#28385;&#36275;&#22810;&#39033;&#24335;&#32423;&#21035;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#21457;&#29616;&#25152;&#26377;&#32473;&#23450;&#22870;&#21169;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#65292;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#25506;&#32034;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.07278</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#26080;&#20851;&#22870;&#21169;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Minimax-Optimal Reward-Agnostic Exploration in Reinforcement Learning. (arXiv:2304.07278v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26080;&#20851;&#22870;&#21169;&#25506;&#32034;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#20445;&#35777;&#26679;&#26412;&#25910;&#38598;&#25968;&#37327;&#28385;&#36275;&#22810;&#39033;&#24335;&#32423;&#21035;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#21457;&#29616;&#25152;&#26377;&#32473;&#23450;&#22870;&#21169;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#65292;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#25506;&#32034;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26080;&#20851;&#22870;&#21169;&#25506;&#32034;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#26469;&#25913;&#36827;&#29616;&#26377;&#25216;&#26415;&#12290;&#30740;&#31350;&#20102;&#20855;&#26377;S&#20010;&#29366;&#24577;&#65292;A&#20010;&#21160;&#20316;&#21644;&#26377;&#38480;&#26102;&#38388;&#27700;&#24179;H&#30340;&#38750;&#24179;&#31283;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#24182;&#25910;&#38598;&#20102;&#19968;&#23450;&#25968;&#37327;&#30340;&#26080;&#24341;&#23548;&#22870;&#21169;&#20449;&#24687;&#30340;&#26679;&#26412;&#38598;&#65292;&#22312;&#20445;&#35777;&#25910;&#38598;&#30340;&#25968;&#37327;&#28385;&#36275;&#22810;&#39033;&#24335;&#32423;&#21035;&#26102;&#65292;&#31639;&#27861;&#33021;&#22815;&#21457;&#29616;&#25152;&#26377;&#36825;&#20123;&#22870;&#21169;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#65292;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#25506;&#32034;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies reward-agnostic exploration in reinforcement learning (RL) -- a scenario where the learner is unware of the reward functions during the exploration stage -- and designs an algorithm that improves over the state of the art. More precisely, consider a finite-horizon non-stationary Markov decision process with $S$ states, $A$ actions, and horizon length $H$, and suppose that there are no more than a polynomial number of given reward functions of interest. By collecting an order of \begin{align*}  \frac{SAH^3}{\varepsilon^2} \text{ sample episodes (up to log factor)} \end{align*} without guidance of the reward information, our algorithm is able to find $\varepsilon$-optimal policies for all these reward functions, provided that $\varepsilon$ is sufficiently small. This forms the first reward-agnostic exploration scheme in this context that achieves provable minimax optimality. Furthermore, once the sample size exceeds $\frac{S^2AH^3}{\varepsilon^2}$ episodes (up to log f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37319;&#29992;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21644;&#36951;&#20256;&#31639;&#27861;&#65292;&#23545;&#30424;&#24335;&#32852;&#36724;&#22120;&#20013;&#30340;&#26580;&#24615;&#30424;&#20803;&#20214;&#36827;&#34892;&#25913;&#36827;&#35774;&#35745;&#65292;&#38477;&#20302;&#20854;&#36136;&#37327;&#21644;&#24212;&#21147;&#65292;&#32780;&#19981;&#38477;&#20302;&#25197;&#30697;&#20256;&#36882;&#21644;&#19981;&#23545;&#40784;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.07245</link><description>&lt;p&gt;
&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26580;&#24615;&#30424;&#20803;&#20214;&#30340;&#22810;&#30446;&#26631;&#35774;&#35745;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Machine Learning-Based Multi-Objective Design Exploration Of Flexible Disc Elements. (arXiv:2304.07245v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07245
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37319;&#29992;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21644;&#36951;&#20256;&#31639;&#27861;&#65292;&#23545;&#30424;&#24335;&#32852;&#36724;&#22120;&#20013;&#30340;&#26580;&#24615;&#30424;&#20803;&#20214;&#36827;&#34892;&#25913;&#36827;&#35774;&#35745;&#65292;&#38477;&#20302;&#20854;&#36136;&#37327;&#21644;&#24212;&#21147;&#65292;&#32780;&#19981;&#38477;&#20302;&#25197;&#30697;&#20256;&#36882;&#21644;&#19981;&#23545;&#40784;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#25506;&#32034;&#26159;&#24037;&#31243;&#35774;&#35745;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#27493;&#39588;&#12290;&#23427;&#28041;&#21450;&#23547;&#25214;&#28385;&#36275;&#25351;&#23450;&#35774;&#35745;&#26631;&#20934;&#21644;&#23436;&#25104;&#39044;&#23450;&#20041;&#30446;&#26631;&#30340;&#35774;&#35745;&#26041;&#26696;&#12290;&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#24037;&#31243;&#35774;&#35745;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#23558;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANN&#65289;&#26550;&#26500;&#24212;&#29992;&#20110;&#24037;&#31243;&#35774;&#35745;&#38382;&#39064;&#20013;&#65292;&#20197;&#25506;&#32034;&#21644;&#35782;&#21035;&#25913;&#36827;&#30340;&#35774;&#35745;&#26041;&#26696;&#12290;&#26412;&#30740;&#31350;&#30340;&#26696;&#20363;&#38382;&#39064;&#26159;&#26580;&#24615;&#30424;&#20803;&#20214;&#30340;&#35774;&#35745;&#65292;&#35813;&#20803;&#20214;&#29992;&#20110;&#30424;&#24335;&#32852;&#36724;&#22120;&#20013;&#12290;&#25105;&#20204;&#38656;&#35201;&#36890;&#36807;&#38477;&#20302;&#36136;&#37327;&#21644;&#24212;&#21147;&#32780;&#19981;&#38477;&#20302;&#25197;&#30697;&#20256;&#36882;&#21644;&#19981;&#23545;&#40784;&#33021;&#21147;&#26469;&#25913;&#36827;&#30424;&#20803;&#20214;&#30340;&#35774;&#35745;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22312;&#35774;&#35745;&#25506;&#32034;&#27493;&#39588;&#20013;&#37319;&#29992;&#20102;ANN&#21644;&#36951;&#20256;&#31639;&#27861;&#65292;&#20197;&#35782;&#21035;&#31526;&#21512;&#25351;&#23450;&#26631;&#20934;&#65288;&#25197;&#30697;&#21644;&#19981;&#23545;&#40784;&#65289;&#19988;&#20855;&#26377;&#26368;&#23567;&#36136;&#37327;&#21644;&#24212;&#21147;&#30340;&#35774;&#35745;&#26041;&#26696;&#12290;&#32467;&#26524;&#19982;&#20248;&#21270;&#32467;&#26524;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
Design exploration is an important step in the engineering design process. This involves the search for design/s that meet the specified design criteria and accomplishes the predefined objective/s. In recent years, machine learning-based approaches have been widely used in engineering design problems. This paper showcases Artificial Neural Network (ANN) architecture applied to an engineering design problem to explore and identify improved design solutions. The case problem of this study is the design of flexible disc elements used in disc couplings. We are required to improve the design of the disc elements by lowering the mass and stress without lowering the torque transmission and misalignment capability. To accomplish this objective, we employ ANN coupled with genetic algorithm in the design exploration step to identify designs that meet the specified criteria (torque and misalignment) while having minimum mass and stress. The results are comparable to the optimized results obtained
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07235</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#35299;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#21333;&#23618;Transformer&#23545;&#24191;&#20041;Potts&#27169;&#22411;&#36827;&#34892;&#26368;&#20248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Optimal inference of a generalised Potts model by single-layer transformers with factored attention. (arXiv:2304.07235v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07235
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#20998;&#26512;&#21644;&#25968;&#20540;&#25512;&#23548;&#32467;&#21512;&#65292;&#22312;&#22522;&#20110;&#24191;&#20041; Potts &#27169;&#22411;&#30340;&#25968;&#25454;&#19978;&#65292;&#23545;&#32463;&#36807;&#25913;&#36827;&#36866;&#24212;&#36825;&#31181;&#27169;&#22411;&#30340;self-attention&#26426;&#21046;&#36827;&#34892;&#35757;&#32451;&#65292;&#21457;&#29616;&#32463;&#36807;&#20462;&#25913;&#30340;self-attention&#26426;&#21046;&#21487;&#20197;&#22312;&#26497;&#38480;&#37319;&#26679;&#19979;&#20934;&#30830;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#36825;&#20010;&#8220;&#20998;&#35299;&#8221;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30456;&#20851;&#23646;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;Transformer&#30340;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer &#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#34507;&#30333;&#36136;&#31185;&#23398;&#26041;&#38754;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#12290;&#23427;&#20204;&#30340;&#20851;&#38190;&#26500;&#24314;&#22359;&#26159;&#19968;&#20010;&#21483;&#20570;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#26426;&#21046;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;&#39044;&#27979;&#21477;&#23376;&#20013;&#32570;&#22833;&#30340;&#35789;&#12290;&#23613;&#31649;Transformer&#22312;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#23454;&#36341;&#19978;&#30340;&#25104;&#21151;&#65292;&#20294;&#26159;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#31350;&#31455;&#20174;&#25968;&#25454;&#20013;&#23398;&#21040;&#20102;&#20160;&#20040;&#20197;&#21450;&#23427;&#26159;&#24590;&#20040;&#20570;&#21040;&#30340;&#36824;&#19981;&#26159;&#24456;&#28165;&#26970;&#12290;&#26412;&#25991;&#38024;&#23545;&#20174;&#20855;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#20301;&#32622;&#21644; Potts &#39068;&#33394;&#20013;&#25552;&#21462;&#30340;&#25968;&#25454;&#22312;&#35757;&#32451;&#30340;Transformer&#19978;&#32473;&#20986;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#21644;&#25968;&#20540;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#34429;&#28982;&#19968;&#33324;&#30340;transformer&#38656;&#35201;&#22810;&#23618;&#23398;&#20064;&#25165;&#33021;&#20934;&#30830;&#23398;&#20064;&#36825;&#20010;&#20998;&#24067;&#65292;&#20294;&#26159;&#32463;&#36807;&#23567;&#25913;&#36827;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#26080;&#38480;&#37319;&#26679;&#30340;&#26497;&#38480;&#19979;&#21487;&#20197;&#23436;&#32654;&#22320;&#23398;&#20064;Potts&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#36825;&#20010;&#20462;&#25913;&#21518;&#30340;&#33258;&#27880;&#24847;&#21147;&#26426;&#21046;&#25152;&#35859;&#8220;&#20998;&#35299;&#8221;&#30340;&#27867;&#21270;&#35823;&#24046;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#25968;&#20540;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#37322;Transformer&#30340;&#20869;&#22312;&#24037;&#20316;&#21407;&#29702;&#20197;&#21450;&#25552;&#39640;&#20854;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers are the type of neural networks that has revolutionised natural language processing and protein science. Their key building block is a mechanism called self-attention which is trained to predict missing words in sentences. Despite the practical success of transformers in applications it remains unclear what self-attention learns from data, and how. Here, we give a precise analytical and numerical characterisation of transformers trained on data drawn from a generalised Potts model with interactions between sites and Potts colours. While an off-the-shelf transformer requires several layers to learn this distribution, we show analytically that a single layer of self-attention with a small modification can learn the Potts model exactly in the limit of infinite sampling. We show that this modified self-attention, that we call ``factored'', has the same functional form as the conditional probability of a Potts spin given the other spins, compute its generalisation error using t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#25193;&#23637;&#30340; Wasserstein PAC-Bayes &#26694;&#26550;&#65292;&#21033;&#29992;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#20960;&#20309;&#20551;&#35774;&#25552;&#20379;&#20102;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36890;&#36807;&#35813;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102; \cite{lambert2022variational} &#20013;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#24314;&#31435;&#20102; PAC-Bayes &#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;</title><link>http://arxiv.org/abs/2304.07048</link><description>&lt;p&gt;
Wasserstein PAC-Bayes &#23398;&#20064;&#65306;&#27867;&#21270;&#19982;&#20248;&#21270;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wasserstein PAC-Bayes Learning: A Bridge Between Generalisation and Optimisation. (arXiv:2304.07048v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#25193;&#23637;&#30340; Wasserstein PAC-Bayes &#26694;&#26550;&#65292;&#21033;&#29992;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#20960;&#20309;&#20551;&#35774;&#25552;&#20379;&#20102;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36890;&#36807;&#35813;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102; \cite{lambert2022variational} &#20013;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#24314;&#31435;&#20102; PAC-Bayes &#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PAC-Bayes &#23398;&#20064;&#26159;&#19968;&#31181;&#24050;&#24314;&#31435;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#35757;&#32451;&#38454;&#27573;&#35780;&#20272;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#20043;&#21069;&#65292;&#24324;&#28165;&#26970;&#20026;&#20160;&#20040;&#30693;&#21517;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#29305;&#24615;&#32780; PAC-Bayes &#26159;&#21542;&#26377;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25193;&#23637;&#31616;&#35201;&#20171;&#32461;&#22312;&#25991;&#29486; \cite{amit2022ipm} &#20013;&#25552;&#20986;&#30340; \emph{Wasserstein PAC-Bayes} &#26694;&#26550;&#26469;&#31215;&#26497;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#21033;&#29992;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#20960;&#20309;&#20551;&#35774;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#22312;&#20219;&#20309;&#35757;&#32451;&#20043;&#21069;&#23601;&#35777;&#26126;&#20102; \cite{lambert2022variational} &#20013;&#31639;&#27861;&#30340;&#36755;&#20986;&#20855;&#26377;&#24378;&#22823;&#30340;&#28176;&#36817;&#27867;&#21270;&#33021;&#21147;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#27867;&#21270;&#26694;&#26550;&#20013;&#23558;&#20248;&#21270;&#32467;&#26524;&#32467;&#21512;&#36215;&#26469;&#65292;&#26500;&#24314;&#20102; PAC-Bayes &#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#26725;&#26753;&#12290;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes learning is an established framework to assess the generalisation ability of learning algorithm during the training phase. However, it remains challenging to know whether PAC-Bayes is useful to understand, before training, why the output of well-known algorithms generalise well. We positively answer this question by expanding the \emph{Wasserstein PAC-Bayes} framework, briefly introduced in \cite{amit2022ipm}. We provide new generalisation bounds exploiting geometric assumptions on the loss function. Using our framework, we prove, before any training, that the output of an algorithm from \citet{lambert2022variational} has a strong asymptotic generalisation ability. More precisely, we show that it is possible to incorporate optimisation results within a generalisation framework, building a bridge between PAC-Bayes and optimisation algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#22343;&#20540;&#19979;&#30340;&#22823;&#32500;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#35777;&#26126;&#20102;&#20854;&#20108;&#27425;&#25910;&#25947;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26631;&#20934;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.07045</link><description>&lt;p&gt;
Ledoit-Wolf&#32447;&#24615;&#25910;&#32553;&#26041;&#27861;&#22312;&#26410;&#30693;&#22343;&#20540;&#30340;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;(arXiv:2304.07045v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
Ledoit-Wolf linear shrinkage with unknown mean. (arXiv:2304.07045v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#22343;&#20540;&#19979;&#30340;&#22823;&#32500;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#35777;&#26126;&#20102;&#20854;&#20108;&#27425;&#25910;&#25947;&#24615;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26631;&#20934;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#26410;&#30693;&#22343;&#20540;&#19979;&#30340;&#22823;&#32500;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#12290;&#24403;&#32500;&#25968;&#21644;&#26679;&#26412;&#25968;&#25104;&#27604;&#20363;&#24182;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#32463;&#39564;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#22833;&#25928;&#65292;&#27492;&#26102;&#31216;&#20026;Kolmogorov&#28176;&#36827;&#24615;&#12290;&#24403;&#22343;&#20540;&#24050;&#30693;&#26102;&#65292;Ledoit&#21644;Wolf&#65288;2004&#65289;&#25552;&#20986;&#20102;&#19968;&#20010;&#32447;&#24615;&#25910;&#32553;&#20272;&#35745;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#28436;&#36827;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#24403;&#22343;&#20540;&#26410;&#30693;&#26102;&#65292;&#23578;&#26410;&#25552;&#20986;&#27491;&#24335;&#35777;&#26126;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#22312;Ledoit&#21644;Wolf&#30340;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#23427;&#30340;&#20108;&#27425;&#25910;&#25947;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#23427;&#32988;&#36807;&#20102;&#20854;&#20182;&#26631;&#20934;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses large dimensional covariance matrix estimation with unknown mean. The empirical covariance estimator fails when dimension and number of samples are proportional and tend to infinity, settings known as Kolmogorov asymptotics. When the mean is known, Ledoit and Wolf (2004) proposed a linear shrinkage estimator and proved its convergence under those asymptotics. To the best of our knowledge, no formal proof has been proposed when the mean is unknown. To address this issue, we propose a new estimator and prove its quadratic convergence under the Ledoit and Wolf assumptions. Finally, we show empirically that it outperforms other standard estimators.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#36830;&#32493;&#26102;&#38388;&#33258;&#22238;&#24402;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;(CTRNNs)&#30340;&#24212;&#29992;, &#36890;&#36807;&#36830;&#32493;&#28436;&#21270;&#26469;&#35299;&#20915;&#38750;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;, &#20197;&#27010;&#29575;&#39044;&#27979;&#20020;&#24202;&#30417;&#25252;&#35774;&#32622;&#20013;&#30340;&#34880;&#31958;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2304.07025</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65306;&#27010;&#36848;&#21450;&#22312;&#30417;&#25252;&#30149;&#25151;&#34880;&#31958;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Continuous time recurrent neural networks: overview and application to forecasting blood glucose in the intensive care unit. (arXiv:2304.07025v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36830;&#32493;&#26102;&#38388;&#33258;&#22238;&#24402;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;(CTRNNs)&#30340;&#24212;&#29992;, &#36890;&#36807;&#36830;&#32493;&#28436;&#21270;&#26469;&#35299;&#20915;&#38750;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;, &#20197;&#27010;&#29575;&#39044;&#27979;&#20020;&#24202;&#30417;&#25252;&#35774;&#32622;&#20013;&#30340;&#34880;&#31958;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24456;&#22810;&#24212;&#29992;&#20013;&#65292;&#38750;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#26159;&#24120;&#35265;&#30340;&#65292;&#21253;&#25324;&#21307;&#23398;&#39046;&#22495;&#12290;&#36825;&#25552;&#20379;&#20102;&#27169;&#22411;&#36873;&#25321;&#30340;&#25361;&#25112;&#65292;&#36890;&#24120;&#38656;&#35201;&#25554;&#34917;&#25110;&#31867;&#20284;&#31574;&#30053;&#12290;&#36830;&#32493;&#26102;&#38388;&#33258;&#22238;&#24402;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;(CTRNNs) &#26159;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#35266;&#27979;&#20540;&#20043;&#38388;&#34701;&#21512;&#38544;&#34255;&#29366;&#24577;&#30340;&#36830;&#32493;&#28436;&#21270;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#36825;&#26159;&#36890;&#36807;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#25110;&#31070;&#32463;&#27969;&#23618;&#26469;&#23454;&#29616;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#36825;&#20123;&#27169;&#22411;&#65292;&#21253;&#25324;&#20026;&#24212;&#23545; ongoing medical interventions &#31561;&#38382;&#39064;&#32780;&#25552;&#20986;&#30340;&#21508;&#31181;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#27169;&#22411;&#22312;&#20351;&#29992;&#30005;&#23376;&#30149;&#21382;&#21644;&#27169;&#25311;&#25968;&#25454;&#36827;&#34892;&#34880;&#31958;&#27010;&#29575;&#39044;&#27979;&#30340;&#20020;&#24202;&#30417;&#25252;&#35774;&#32622;&#20013;&#30340;&#24212;&#29992;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#28155;&#21152;&#31070;&#32463;ODE&#25110;&#31070;&#32463;&#27969;&#23618;&#30340;&#19968;&#33324;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Irregularly measured time series are common in many of the applied settings in which time series modelling is a key statistical tool, including medicine. This provides challenges in model choice, often necessitating imputation or similar strategies. Continuous time autoregressive recurrent neural networks (CTRNNs) are a deep learning model that account for irregular observations through incorporating continuous evolution of the hidden states between observations. This is achieved using a neural ordinary differential equation (ODE) or neural flow layer. In this manuscript, we give an overview of these models, including the varying architectures that have been proposed to account for issues such as ongoing medical interventions. Further, we demonstrate the application of these models to probabilistic forecasting of blood glucose in a critical care setting using electronic medical record and simulated data. The experiments confirm that addition of a neural ODE or neural flow layer general
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#31361;&#21464;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#21448;&#20445;&#35777;&#21151;&#29575;&#24615;&#33021;&#65292;&#21448;&#25193;&#22823;&#20102;&#20855;&#22791;&#21151;&#29575;&#30340;&#21306;&#22495;&#65307;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#29616;&#30340;&#32858;&#31867;&#31639;&#27861;&#21644;&#20449;&#24687;&#20934;&#21017;&#65292;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#26410;&#30693;&#32452;&#25968;&#21644;&#25104;&#21592;&#36164;&#26684;&#65292;&#20197;&#25913;&#21892;&#21518;&#32858;&#31867;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2304.07003</link><description>&lt;p&gt;
&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#20013;&#32467;&#26500;&#24615;&#31361;&#21464;&#30340;&#26816;&#27979;&#21644;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Detection and Estimation of Structural Breaks in High-Dimensional Functional Time Series. (arXiv:2304.07003v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#31361;&#21464;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#21448;&#20445;&#35777;&#21151;&#29575;&#24615;&#33021;&#65292;&#21448;&#25193;&#22823;&#20102;&#20855;&#22791;&#21151;&#29575;&#30340;&#21306;&#22495;&#65307;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#26131;&#20110;&#23454;&#29616;&#30340;&#32858;&#31867;&#31639;&#27861;&#21644;&#20449;&#24687;&#20934;&#21017;&#65292;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#26410;&#30693;&#32452;&#25968;&#21644;&#25104;&#21592;&#36164;&#26684;&#65292;&#20197;&#25913;&#21892;&#21518;&#32858;&#31867;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#26816;&#27979;&#21644;&#20272;&#35745;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#24322;&#36136;&#22343;&#20540;&#20989;&#25968;&#20013;&#30340;&#31361;&#21464;&#65292;&#20801;&#35768;&#27178;&#21521;&#30456;&#20851;&#21644;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#32467;&#21512;&#20102;&#20989;&#25968;CUSUM&#32479;&#35745;&#37327;&#21644;&#21151;&#29575;&#22686;&#24378;&#32452;&#20214;&#65292;&#20854;&#28176;&#36817;&#38646;&#20998;&#24067;&#29702;&#35770;&#21487;&#19982;&#21333;&#20010;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#20256;&#32479;CUSUM&#29702;&#35770;&#30456;&#23218;&#32654;&#12290;&#29305;&#21035;&#22320;&#65292;&#39069;&#22806;&#30340;&#21151;&#29575;&#22686;&#24378;&#32452;&#20214;&#25193;&#22823;&#20102;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#20855;&#22791;&#21151;&#29575;&#30340;&#21306;&#22495;&#65292;&#24403;&#26367;&#20195;&#20551;&#35774;&#20013;&#30340;&#31361;&#21464;&#31232;&#30095;&#26102;&#65292;&#32467;&#26524;&#20855;&#26377;&#31283;&#23450;&#30340;&#21151;&#29575;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38024;&#23545;&#20855;&#26377;&#24322;&#36136;&#31361;&#21464;&#28857;&#30340;&#23545;&#35937;&#26045;&#21152;&#28508;&#22312;&#30340;&#32452;&#32467;&#26500;&#65292;&#24182;&#24341;&#20837;&#19968;&#31181;&#26131;&#20110;&#23454;&#29616;&#30340;&#32858;&#31867;&#31639;&#27861;&#21644;&#20449;&#24687;&#20934;&#21017;&#65292;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#26410;&#30693;&#32452;&#25968;&#21644;&#25104;&#21592;&#36164;&#26684;&#12290;&#38543;&#21518;&#65292;&#20272;&#35745;&#30340;&#32452;&#32467;&#26500;&#21487;&#20197;&#25913;&#21892;&#21518;&#32858;&#31867;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider detecting and estimating breaks in heterogeneous mean functions of high-dimensional functional time series which are allowed to be cross-sectionally correlated and temporally dependent. A new test statistic combining the functional CUSUM statistic and power enhancement component is proposed with asymptotic null distribution theory comparable to the conventional CUSUM theory derived for a single functional time series. In particular, the extra power enhancement component enlarges the region where the proposed test has power, and results in stable power performance when breaks are sparse in the alternative hypothesis. Furthermore, we impose a latent group structure on the subjects with heterogeneous break points and introduce an easy-to-implement clustering algorithm with an information criterion to consistently estimate the unknown group number and membership. The estimated group structure can subsequently improve the convergence property of the post-clusterin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#24037;&#20855;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;Gibbs&#25277;&#26679;&#22120;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#22312;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#19979;&#33719;&#24471;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#20284;&#28982;&#20989;&#25968;&#30340;&#24191;&#27867;&#30340;&#20108;&#32423;&#27169;&#22411;&#30340;&#26080;&#32500;&#24230;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.06993</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#30340;Gibbs&#25277;&#26679;&#22120;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Complexity of Gibbs samplers through Bayesian asymptotics. (arXiv:2304.06993v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#24037;&#20855;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;Gibbs&#25277;&#26679;&#22120;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#22312;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#19979;&#33719;&#24471;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#20284;&#28982;&#20989;&#25968;&#30340;&#24191;&#27867;&#30340;&#20108;&#32423;&#27169;&#22411;&#30340;&#26080;&#32500;&#24230;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gibbs&#25277;&#26679;&#22120;&#26159;&#29992;&#20110;&#36817;&#20284;&#26469;&#33258;&#36125;&#21494;&#26031;&#20998;&#23618;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#27969;&#34892;&#31639;&#27861;&#12290;&#23613;&#31649;&#23427;&#20204;&#38750;&#24120;&#27969;&#34892;&#19988;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#26159;&#20851;&#20110;&#23427;&#20204;&#30340;&#21487;&#25193;&#23637;&#24615;&#25110;&#19981;&#21487;&#25193;&#23637;&#24615;&#30340;&#23450;&#37327;&#29702;&#35770;&#32467;&#26524;&#30456;&#23545;&#36739;&#23569;&#65292;&#20363;&#22914;&#65292;&#27604;&#22522;&#20110;&#26799;&#24230;&#30340;&#25277;&#26679;&#26041;&#27861;&#35201;&#23569;&#24471;&#22810;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#24037;&#20855;&#30340;&#26032;&#25216;&#26415;&#65292;&#29992;&#20110;&#20998;&#26512;Gibbs&#25277;&#26679;&#22120;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#28176;&#36817;&#34892;&#20026;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#39640;&#32500;&#20998;&#23618;&#27169;&#22411;&#65292;&#24182;&#22312;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#19979;&#33719;&#24471;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#20284;&#28982;&#20989;&#25968;&#30340;&#24191;&#27867;&#30340;&#20108;&#32423;&#27169;&#22411;&#30340;&#26080;&#32500;&#24230;&#25910;&#25947;&#32467;&#26524;&#12290;&#35752;&#35770;&#20102;&#20855;&#26377;&#39640;&#26031;&#12289;&#20108;&#39033;&#24335;&#21644;&#20998;&#31867;&#20284;&#28982;&#30340;&#20855;&#20307;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gibbs samplers are popular algorithms to approximate posterior distributions arising from Bayesian hierarchical models. Despite their popularity and good empirical performances, however, there are still relatively few quantitative theoretical results on their scalability or lack thereof, e.g. much less than for gradient-based sampling methods. We introduce a novel technique to analyse the asymptotic behaviour of mixing times of Gibbs Samplers, based on tools of Bayesian asymptotics. We apply our methodology to high dimensional hierarchical models, obtaining dimension-free convergence results for Gibbs samplers under random data-generating assumptions, for a broad class of two-level models with generic likelihood function. Specific examples with Gaussian, binomial and categorical likelihoods are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#65292;&#24403;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#26102;&#65292;&#38750;&#32447;&#24615;&#38382;&#39064;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#26041;&#27861;&#20248;&#20110;&#38598;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#38388;&#38553;&#30340;&#28176;&#36827;&#20248;&#21183;&#30340;&#22343;&#20540;&#65292;&#25152;&#26377;&#20854;&#20182;&#26102;&#21051;&#21644;&#25972;&#20010;&#28176;&#36827;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2304.06833</link><description>&lt;p&gt;
&#35780;&#20272;-&#20248;&#21270;&#26041;&#27861;&#19982;&#38598;&#25104;&#35780;&#20272;&#20248;&#21270;&#27861;&#65306;&#22522;&#20110;&#38543;&#26426;&#20248;&#21183;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective. (arXiv:2304.06833v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#65292;&#24403;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#26102;&#65292;&#38750;&#32447;&#24615;&#38382;&#39064;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#26041;&#27861;&#20248;&#20110;&#38598;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#38388;&#38553;&#30340;&#28176;&#36827;&#20248;&#21183;&#30340;&#22343;&#20540;&#65292;&#25152;&#26377;&#20854;&#20182;&#26102;&#21051;&#21644;&#25972;&#20010;&#28176;&#36827;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#38500;&#20102;&#38656;&#35201;&#20248;&#21270;&#20219;&#21153;&#65292;&#36824;&#38656;&#35201;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#28508;&#22312;&#20998;&#24067;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;&#36890;&#36807;&#36873;&#25321;&#23548;&#33268;&#26368;&#20339;&#32463;&#39564;&#30446;&#26631;&#24615;&#33021;&#30340;&#27169;&#22411;&#21442;&#25968;&#65292;&#21487;&#20197;&#38598;&#25104;&#20272;&#35745;&#21644;&#20248;&#21270;&#36807;&#31243;&#12290;&#24403;&#27169;&#22411;&#34987;&#38169;&#35823;&#22320;&#25351;&#23450;&#26102;&#65292;&#36825;&#31181;&#38598;&#25104;&#26041;&#27861;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#26174;&#31034;&#20986;&#20248;&#20110;&#31616;&#21333;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#22312;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#25490;&#24207;&#22312;&#24378;&#28872;&#30340;&#24847;&#20041;&#19979;&#34987;&#39072;&#20498;&#12290;&#22312;&#21463;&#38480;&#26465;&#20214;&#21644;&#24403;&#19978;&#19979;&#25991;&#29305;&#24449;&#21487;&#29992;&#26102;&#65292;&#31867;&#20284;&#30340;&#32467;&#26524;&#20063;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven stochastic optimization, model parameters of the underlying distribution need to be estimated from data in addition to the optimization task. Recent literature suggests the integration of the estimation and optimization processes, by selecting model parameters that lead to the best empirical objective performance. Such an integrated approach can be readily shown to outperform simple ``estimate then optimize" when the model is misspecified. In this paper, we argue that when the model class is rich enough to cover the ground truth, the performance ordering between the two approaches is reversed for nonlinear problems in a strong sense. Simple ``estimate then optimize" outperforms the integrated approach in terms of stochastic dominance of the asymptotic optimality gap, i,e, the mean, all other moments, and the entire asymptotic distribution of the optimality gap is always better. Analogous results also hold under constrained settings and when contextual features are availa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#22270;&#21644;&#20855;&#26377;&#23616;&#37096;&#24615;&#36136;&#30340;&#22270;&#20013;&#30340;&#25104;&#23545;&#27604;&#36739;&#25490;&#24207;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#21487;&#20197;&#23454;&#29616;&#31526;&#21512;Cram\'er-Rao&#19979;&#30028;&#30340;&#36880;&#20803;&#20272;&#35745;&#35823;&#24046;&#12290;&#21516;&#26102;&#65292;&#25991;&#31456;&#36824;&#30830;&#23450;&#20102;&#23616;&#37096;&#24615;&#19981;&#20250;&#24433;&#21709;&#30340;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#20998;&#27835;&#31639;&#27861;&#20197;&#23454;&#29616;&#31867;&#20284;&#20445;&#38556;&#12290;</title><link>http://arxiv.org/abs/2304.06821</link><description>&lt;p&gt;
&#36890;&#29992;&#22270;&#21644;&#20855;&#26377;&#23616;&#37096;&#24615;&#36136;&#30340;&#22270;&#20013;&#30340;&#25104;&#23545;&#27604;&#36739;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Ranking from Pairwise Comparisons in General Graphs and Graphs with Locality. (arXiv:2304.06821v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#29992;&#22270;&#21644;&#20855;&#26377;&#23616;&#37096;&#24615;&#36136;&#30340;&#22270;&#20013;&#30340;&#25104;&#23545;&#27604;&#36739;&#25490;&#24207;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#21487;&#20197;&#23454;&#29616;&#31526;&#21512;Cram\'er-Rao&#19979;&#30028;&#30340;&#36880;&#20803;&#20272;&#35745;&#35823;&#24046;&#12290;&#21516;&#26102;&#65292;&#25991;&#31456;&#36824;&#30830;&#23450;&#20102;&#23616;&#37096;&#24615;&#19981;&#20250;&#24433;&#21709;&#30340;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#20998;&#27835;&#31639;&#27861;&#20197;&#23454;&#29616;&#31867;&#20284;&#20445;&#38556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25216;&#26415;&#25253;&#21578;&#30740;&#31350;&#20102;&#32463;&#20856;&#30340;Bradley-Terry-Luce&#65288;BTL&#65289;&#27169;&#22411;&#20013;&#30340;&#25104;&#23545;&#27604;&#36739;&#25490;&#24207;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#24471;&#20998;&#20272;&#35745;&#12290;&#23545;&#20110;&#36890;&#29992;&#22270;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#36890;&#36807;&#36275;&#22815;&#22810;&#30340;&#26679;&#26412;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#21487;&#20197;&#23454;&#29616;&#19968;&#20010;&#31526;&#21512;Cram\'er-Rao&#19979;&#30028;&#30340;&#36880;&#20803;&#20272;&#35745;&#35823;&#24046;&#65292;&#36825;&#21487;&#20197;&#29992;&#26377;&#25928;&#30005;&#38459;&#26469;&#35828;&#26126;&#65307;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#26159;&#32479;&#35745;&#20272;&#35745;&#21644;&#36890;&#36807;&#39044;&#22788;&#29702;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#36845;&#20195;&#20248;&#21270;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#36824;&#29305;&#21035;&#20851;&#27880;&#20855;&#26377;&#23616;&#37096;&#24615;&#36136;&#30340;&#22270;&#65292;&#20854;&#20013;&#20165;&#30456;&#37051;&#39033;&#20043;&#38388;&#21487;&#20197;&#36830;&#25509;&#36793;&#32536;&#65307;&#25105;&#20204;&#30340;&#20998;&#26512;&#30830;&#23450;&#20102;&#23616;&#37096;&#24615;&#19981;&#20250;&#24433;&#21709;&#30340;&#26465;&#20214;&#65292;&#21363;&#22312;&#22270;&#20013;&#36317;&#31163;&#36739;&#36828;&#30340;&#19968;&#23545;&#39033;&#30446;&#20043;&#38388;&#36827;&#34892;&#24471;&#20998;&#27604;&#36739;&#20960;&#20046;&#19982;&#27604;&#36739;&#30456;&#37051;&#39033;&#30446;&#23545;&#19968;&#23545;&#39033;&#30446;&#30456;&#20284;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;&#20998;&#27835;&#31639;&#27861;&#65292;&#21363;&#20351;&#22312;&#26368;&#31232;&#30095;&#30340;&#26679;&#26412;&#21306;&#22495;&#20869;&#65292;&#20063;&#21487;&#20197;&#35777;&#26126;&#33021;&#22815;&#23454;&#29616;&#31867;&#20284;&#30340;&#20445;&#35777;&#65292;&#24182;&#20139;&#21463;&#26412;&#22320;&#26041;&#27861;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This technical report studies the problem of ranking from pairwise comparisons in the classical Bradley-Terry-Luce (BTL) model, with a focus on score estimation. For general graphs, we show that, with sufficiently many samples, maximum likelihood estimation (MLE) achieves an entrywise estimation error matching the Cram\'er-Rao lower bound, which can be stated in terms of effective resistances; the key to our analysis is a connection between statistical estimation and iterative optimization by preconditioned gradient descent. We are also particularly interested in graphs with locality, where only nearby items can be connected by edges; our analysis identifies conditions under which locality does not hurt, i.e. comparing the scores between a pair of items that are far apart in the graph is nearly as easy as comparing a pair of nearby items. We further explore divide-and-conquer algorithms that can provably achieve similar guarantees even in the regime with the sparsest samples, while enj
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24335;&#25968;&#25454;&#20013;&#30340;&#20027;&#21160;&#35745;&#36153;&#26631;&#27880;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#26631;&#35760;&#28857;&#24182;&#32500;&#25252;&#26102;&#38388;&#21644;&#25104;&#26412;&#30456;&#20851;&#38408;&#20540;&#65292;&#22312;$T$&#36718;&#20043;&#21518;&#23454;&#29616;&#20102;$O(B^{\frac { 1 }{ 3 }}K^{\frac { 1 }{ 3 }}T^{\frac { 2 }{ 3 }})$&#30340;&#26368;&#22351;&#24773;&#20917;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2304.06808</link><description>&lt;p&gt;
&#27969;&#24335;&#25968;&#25454;&#20027;&#21160;&#35745;&#36153;&#26631;&#27880;
&lt;/p&gt;
&lt;p&gt;
Active Cost-aware Labeling of Streaming Data. (arXiv:2304.06808v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24335;&#25968;&#25454;&#20013;&#30340;&#20027;&#21160;&#35745;&#36153;&#26631;&#27880;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#26631;&#35760;&#28857;&#24182;&#32500;&#25252;&#26102;&#38388;&#21644;&#25104;&#26412;&#30456;&#20851;&#38408;&#20540;&#65292;&#22312;$T$&#36718;&#20043;&#21518;&#23454;&#29616;&#20102;$O(B^{\frac { 1 }{ 3 }}K^{\frac { 1 }{ 3 }}T^{\frac { 2 }{ 3 }})$&#30340;&#26368;&#22351;&#24773;&#20917;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20027;&#21160;&#26631;&#35760;&#27969;&#25968;&#25454;&#38382;&#39064;&#65292;&#20854;&#20013;&#20027;&#21160;&#23398;&#20064;&#32773;&#38754;&#20020;&#19968;&#31995;&#21015;&#25968;&#25454;&#28857;&#65292;&#24182;&#24517;&#39035;&#36890;&#36807;&#26114;&#36149;&#30340;&#23454;&#39564;&#31934;&#24515;&#36873;&#25321;&#21738;&#20123;&#28857;&#36827;&#34892;&#26631;&#35760;&#65292;&#27492;&#31867;&#38382;&#39064;&#24120;&#24120;&#20986;&#29616;&#22312;&#21307;&#30103;&#21644;&#22825;&#25991;&#23398;&#31561;&#39046;&#22495;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#30340;&#26159;&#25968;&#25454;&#36755;&#20837;&#23646;&#20110;$K$&#20010;&#31163;&#25955;&#20998;&#24067;&#20043;&#19968;&#30340;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#25439;&#22833;&#20989;&#25968;&#24418;&#24335;&#21270;&#25551;&#36848;&#27492;&#38382;&#39064;&#65292;&#35813;&#25439;&#22833;&#20989;&#25968;&#25429;&#25417;&#20102;&#26631;&#35760;&#25104;&#26412;&#21644;&#39044;&#27979;&#35823;&#24046;&#12290;&#24403;&#26631;&#35760;&#25104;&#26412;&#20026;$B$&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#36873;&#25321;&#26631;&#35760;&#28857;&#65292;&#20165;&#22312;&#19981;&#30830;&#23450;&#24615;&#22823;&#20110;&#26102;&#38388;&#21644;&#25104;&#26412;&#30456;&#20851;&#38408;&#20540;&#26102;&#36827;&#34892;&#65292;&#21487;&#20197;&#22312;$T$&#36718;&#20043;&#21518;&#23454;&#29616;$O(B^{\frac { 1 }{ 3 }}K^{\frac { 1 }{ 3 }}T^{\frac { 2 }{ 3 }})$&#30340;&#26368;&#22351;&#24773;&#20917;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26356;&#32454;&#33268;&#30340;&#19978;&#30028;&#65292;&#35777;&#26126;&#20102;&#22312;&#21040;&#36798;&#27169;&#24335;&#26356;&#26377;&#21033;&#26102;&#65292;&#31639;&#27861;&#21487;&#20197;&#36866;&#24212;&#21040;&#36798;&#27169;&#24335;&#65292;&#24182;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#34917;&#20805;&#20102;&#20004;&#20010;&#19978;&#30028;&#30340;&#21305;&#37197;&#19979;&#30028;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27969;&#25968;&#25454;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#26631;&#35760;&#27969;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#19982;&#21069;&#38754;&#24773;&#20917;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study actively labeling streaming data, where an active learner is faced with a stream of data points and must carefully choose which of these points to label via an expensive experiment. Such problems frequently arise in applications such as healthcare and astronomy. We first study a setting when the data's inputs belong to one of $K$ discrete distributions and formalize this problem via a loss that captures the labeling cost and the prediction error. When the labeling cost is $B$, our algorithm, which chooses to label a point if the uncertainty is larger than a time and cost dependent threshold, achieves a worst-case upper bound of $O(B^{\frac{1}{3}} K^{\frac{1}{3}} T^{\frac{2}{3}})$ on the loss after $T$ rounds. We also provide a more nuanced upper bound which demonstrates that the algorithm can adapt to the arrival pattern, and achieves better performance when the arrival pattern is more favorable. We complement both upper bounds with matching lower bounds. We next study this pr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#31561;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#19988;&#24615;&#33021;&#26356;&#20339;&#12290;</title><link>http://arxiv.org/abs/2304.06803</link><description>&lt;p&gt;
&#29992;&#20110;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample Average Approximation for Black-Box VI. (arXiv:2304.06803v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06803
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#31561;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#19988;&#24615;&#33021;&#26356;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#30340;&#22256;&#38590;&#65292;&#21253;&#25324;&#36873;&#25321;&#27493;&#38271;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#20351;&#29992;&#19968;&#31995;&#21015;&#26679;&#26412;&#24179;&#22343;&#20272;&#35745;&#38382;&#39064;&#65288;SAA&#65289;&#12290;&#36890;&#36807;&#23558;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#30830;&#23450;&#24615;&#38382;&#39064;&#65292;SAA&#36924;&#36817;&#20102;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#25311;&#29275;&#39039;&#26041;&#27861;&#21644;&#32447;&#24615;&#25628;&#32034;&#26469;&#35299;&#20915;&#27599;&#20010;&#30830;&#23450;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#31574;&#30053;&#26469;&#33258;&#21160;&#36873;&#25321;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#31616;&#21270;&#20102;&#21464;&#20998;&#25512;&#26029;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#24555;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach for black-box VI that bypasses the difficulties of stochastic gradient ascent, including the task of selecting step-sizes. Our approach involves using a sequence of sample average approximation (SAA) problems. SAA approximates the solution of stochastic optimization problems by transforming them into deterministic ones. We use quasi-Newton methods and line search to solve each deterministic optimization problem and present a heuristic policy to automate hyperparameter selection. Our experiments show that our method simplifies the VI problem and achieves faster performance than existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.06787</link><description>&lt;p&gt;
&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#949;-&#24046;&#20998;&#38544;&#31169;&#12289;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20934;&#30830;&#22320;&#20272;&#35745;$\{0,1\}^d$&#19978;&#30340;&#20056;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#21516;&#26102;&#22312;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#20869;&#33719;&#24471;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#22312;&#26356;&#24369;&#30340;&#38544;&#31169;&#27010;&#24565;&#19979;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#35201;&#20040;&#22312;&#25351;&#25968;&#32423;&#36816;&#34892;&#26102;&#38388;&#20869;&#26368;&#20248;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
&lt;/p&gt;</description></item><item><title>RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.06767</link><description>&lt;p&gt;
RAFT: &#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#29992;&#20110;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06767
&lt;/p&gt;
&lt;p&gt;
RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#24191;&#27867;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#25968;&#25454;&#24102;&#26469;&#30340;&#38544;&#24335;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#26679;&#26412;&#12289;&#25197;&#26354;&#30340;&#32467;&#26524;&#21644;&#19981;&#20844;&#24179;&#65292;&#21487;&#33021;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#19982;&#20154;&#30340;&#20262;&#29702;&#21644;&#20559;&#22909;&#23545;&#40784;&#26159;&#30830;&#20445;&#23427;&#20204;&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#36127;&#36131;&#20219;&#21644;&#26377;&#25928;&#30340;&#37096;&#32626;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#37319;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288; RLHF&#65289;&#20316;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#25163;&#27573;&#12290;&#22312; RL &#31639;&#27861;&#30340;&#25351;&#23548;&#19979;&#65292;&#29992;&#20154;&#31867;&#21453;&#39304;&#25351;&#23548;&#30340;&#22870;&#21169;&#27169;&#22411;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292; RL &#31639;&#27861;&#30340;&#20302;&#25928;&#24615;&#21644;&#19981;&#31283;&#23450;&#24615;&#24120;&#24120;&#20250;&#23545;&#29983;&#25104;&#27169;&#22411;&#30340;&#25104;&#21151;&#23545;&#40784;&#20135;&#29983;&#37325;&#22823;&#38556;&#30861;&#65292;&#22240;&#27492;&#38656;&#35201;&#24320;&#21457;&#19968;&#31181;&#26356;&#20026;&#24378;&#22823;&#21644;&#31616;&#21270;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21363;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#65288; RAFT &#65289;&#65292;&#26088;&#22312;&#23545;&#40784;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#30340; uniform conformal inference &#31639;&#27861;&#65292;&#23454;&#29616;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2304.06158</link><description>&lt;p&gt;
&#20026;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#21518;&#36873;&#25512;&#29702;&#65306;&#26435;&#34913;&#31934;&#24230;&#21644;&#35206;&#30422;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
Post-selection Inference for Conformal Prediction: Trading off Coverage for Precision. (arXiv:2304.06158v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#30340; uniform conformal inference &#31639;&#27861;&#65292;&#23454;&#29616;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#25512;&#29702;&#22312;&#20026;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#30340;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#31639;&#27861;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19978;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#20256;&#32479;&#19978;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#25512;&#29702;&#38656;&#35201;&#29420;&#31435;&#20110;&#25968;&#25454;&#30340;&#38169;&#35823;&#35206;&#30422;&#27700;&#24179;&#35268;&#33539;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#22312;&#35745;&#31639;&#20986;&#39044;&#27979;&#38598;&#20043;&#21518;&#26356;&#26032;&#38169;&#35823;&#35206;&#30422;&#27700;&#24179;&#12290;&#20363;&#22914;&#65292;&#22312;&#20108;&#20803;&#20998;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#20250;&#20174;&#19968;&#20010;95&#65285;&#30340;&#39044;&#27979;&#38598;&#24320;&#22987;&#65292;&#24182;&#21457;&#29616;&#22823;&#22810;&#25968;&#39044;&#27979;&#38598;&#21253;&#21547;&#25152;&#26377;&#36755;&#20986;&#31867;&#21035;&#12290;&#22914;&#26524;&#20004;&#20010;&#31867;&#21035;&#37117;&#19981;&#21487;&#21462;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#20250;&#32771;&#34385;80&#65285;&#30340;&#39044;&#27979;&#38598;&#12290;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#35823;&#35206;&#30422;&#27700;&#24179;&#21644;&#20445;&#35777;&#35206;&#30422;&#33539;&#22260;&#30340;&#39044;&#27979;&#38598;&#30340;&#26500;&#24314;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#21518;&#36873;&#25512;&#29702;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#65292;&#24320;&#21457;&#20102;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal inference has played a pivotal role in providing uncertainty quantification for black-box ML prediction algorithms with finite sample guarantees. Traditionally, conformal prediction inference requires a data-independent specification of miscoverage level. In practical applications, one might want to update the miscoverage level after computing the prediction set. For example, in the context of binary classification, the analyst might start with a $95\%$ prediction sets and see that most prediction sets contain all outcome classes. Prediction sets with both classes being undesirable, the analyst might desire to consider, say $80\%$ prediction set. Construction of prediction sets that guarantee coverage with data-dependent miscoverage level can be considered as a post-selection inference problem. In this work, we develop uniform conformal inference with finite sample prediction guarantee with arbitrary data-dependent miscoverage levels using distribution-free confidence bands f
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#24341;&#23548;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#31639;&#27861;&#36827;&#34892;&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#24341;&#23548;&#30340;&#26102;&#31354;&#25968;&#25454;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#22240;&#26524;&#26410;&#26469;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2301.00736</link><description>&lt;p&gt;
&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#24341;&#23548;&#30340;&#26102;&#31354;&#25968;&#25454;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Mixed moving average field guided learning for spatio-temporal data. (arXiv:2301.00736v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#24341;&#23548;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#31639;&#27861;&#36827;&#34892;&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#24341;&#23548;&#30340;&#26102;&#31354;&#25968;&#25454;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#22240;&#26524;&#26410;&#26469;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#28151;&#21512;&#31227;&#21160;&#24179;&#22343;&#22330;&#30340;&#24433;&#21709;&#65292;&#26102;&#31354;&#25968;&#25454;&#30340;&#24314;&#27169;&#26159;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#25216;&#24039;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#20998;&#24067;&#36890;&#24120;&#19981;&#21487;&#35775;&#38382;&#12290;&#22312;&#36825;&#20010;&#24314;&#27169;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#24341;&#23548;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#24191;&#20041;&#36125;&#21494;&#26031;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#37319;&#29992;Lipschitz&#39044;&#27979;&#22120;&#65288;&#20363;&#22914;&#32447;&#24615;&#27169;&#22411;&#25110;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#27839;&#31354;&#38388;&#21644;&#26102;&#38388;&#32500;&#24230;&#20018;&#34892;&#30456;&#20851;&#30340;&#25968;&#25454;&#30340;&#26032;&#22411;PAC&#36125;&#21494;&#26031;&#30028;&#38480;&#26469;&#30830;&#23450;&#19968;&#20010;&#38543;&#26426;&#20272;&#35745;&#20540;&#12290;&#36827;&#34892;&#22240;&#26524;&#26410;&#26469;&#39044;&#27979;&#26159;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#20142;&#28857;&#65292;&#22240;&#20026;&#23427;&#36866;&#29992;&#20110;&#20855;&#26377;&#30701;&#26399;&#21644;&#38271;&#26399;&#30456;&#20851;&#24615;&#30340;&#25968;&#25454;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#27169;&#25311;STOU&#36807;&#31243;&#30340;&#26102;&#31354;&#25968;&#25454;&#30340;&#31034;&#20363;&#26469;&#23637;&#31034;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Influenced mixed moving average fields are a versatile modeling class for spatio-temporal data. However, their predictive distribution is not generally accessible. Under this modeling assumption, we define a novel theory-guided machine learning approach that employs a generalized Bayesian algorithm to make predictions. We employ a Lipschitz predictor, for example, a linear model or a feed-forward neural network, and determine a randomized estimator by minimizing a novel PAC Bayesian bound for data serially correlated along a spatial and temporal dimension. Performing causal future predictions is a highlight of our methodology as its potential application to data with short and long-range dependence. We conclude by showing the performance of the learning methodology in an example with linear predictors and simulated spatio-temporal data from an STOU process.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2211.15072</link><description>&lt;p&gt;
FaiREE&#65306;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#20445;&#35777;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
FaiREE: Fair Classification with Finite-Sample and Distribution-Free Guarantee. (arXiv:2211.15072v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#21487;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#20844;&#24179;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#32676;&#20307;&#20844;&#24179;&#24615;&#27010;&#24565;&#21644;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#20844;&#24179;&#20998;&#31867;&#26041;&#27861;&#30340;&#20844;&#24179;&#20445;&#35777;&#20027;&#35201;&#20381;&#36182;&#20110;&#29305;&#23450;&#30340;&#25968;&#25454;&#20998;&#24067;&#20551;&#35774;&#65292;&#36890;&#24120;&#38656;&#35201;&#22823;&#26679;&#26412;&#37327;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#36829;&#21453;&#20844;&#24179;&#24615;&#65292;&#32780;&#36825;&#22312;&#23454;&#36341;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;FaiREE&#31639;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#20844;&#24179;&#20998;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#26080;&#20998;&#24067;&#29702;&#35770;&#20445;&#35777;&#19979;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;FaiREE&#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#32676;&#20307;&#20844;&#24179;&#24615;&#27010;&#24565;&#65288;&#20363;&#22914;&#65292;&#26426;&#20250;&#24179;&#31561;&#65292;&#24179;&#34913;&#20960;&#29575;&#65292;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#34913;&#31561;&#65289;&#24182;&#23454;&#29616;&#26368;&#20339;&#20934;&#30830;&#24615;&#12290;&#36825;&#20123;&#29702;&#35770;&#20445;&#35777;&#36827;&#19968;&#27493;&#24471;&#21040;&#20102;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#25903;&#25345;&#12290;FaiREE&#34920;&#29616;&#20986;&#27604;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic fairness plays an increasingly critical role in machine learning research. Several group fairness notions and algorithms have been proposed. However, the fairness guarantee of existing fair classification methods mainly depends on specific data distributional assumptions, often requiring large sample sizes, and fairness could be violated when there is a modest number of samples, which is often the case in practice. In this paper, we propose FaiREE, a fair classification algorithm that can satisfy group fairness constraints with finite-sample and distribution-free theoretical guarantees. FaiREE can be adapted to satisfy various group fairness notions (e.g., Equality of Opportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal accuracy. These theoretical guarantees are further supported by experiments on both synthetic and real data. FaiREE is shown to have favorable performance over state-of-the-art algorithms.
&lt;/p&gt;</description></item><item><title>&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#65292;&#36890;&#36807;&#30417;&#27979;&#26465;&#20214;&#24615;&#34920;&#29616;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#30417;&#27979;&#32771;&#34385;&#28151;&#28102;&#21307;&#30103;&#24178;&#39044;&#26102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#39118;&#38505;&#39044;&#27979;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.09781</link><description>&lt;p&gt;
&#30417;&#27979;&#32771;&#34385;&#28151;&#28102;&#21307;&#30103;&#24178;&#39044;&#26102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#39118;&#38505;&#39044;&#27979;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Monitoring machine learning (ML)-based risk prediction algorithms in the presence of confounding medical interventions. (arXiv:2211.09781v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09781
&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#65292;&#36890;&#36807;&#30417;&#27979;&#26465;&#20214;&#24615;&#34920;&#29616;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#30417;&#27979;&#32771;&#34385;&#28151;&#28102;&#21307;&#30103;&#24178;&#39044;&#26102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#39118;&#38505;&#39044;&#27979;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#20013;&#65292;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#39118;&#38505;&#39044;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#30417;&#27979;&#21463;&#28151;&#28102;&#21307;&#30103;&#24178;&#39044;&#65288;CMI&#65289;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#20020;&#24202;&#21307;&#29983;&#26356;&#21487;&#33021;&#20026;&#39640;&#39118;&#38505;&#24739;&#32773;&#25552;&#20379;&#39044;&#38450;&#24615;&#27835;&#30103;&#24182;&#25913;&#21464;&#31639;&#27861;&#25152;&#39044;&#27979;&#30340;&#30446;&#26631;&#12290;&#24573;&#30053;CMI&#24182;&#21482;&#30417;&#27979;&#26410;&#25509;&#21463;&#27835;&#30103;&#30340;&#24739;&#32773;&#21487;&#33021;&#20250;&#23548;&#33268;&#31867;&#22411;I&#38169;&#35823;&#30340;&#33192;&#32960;&#65292;&#19981;&#36807;&#25105;&#20204;&#35777;&#26126;&#22914;&#26524;&#30417;&#25511;&#26465;&#20214;&#24615;&#34920;&#29616;&#65292;&#24182;&#19988;&#31526;&#21512;&#26465;&#20214;&#20132;&#25442;&#24615;&#25110;&#26102;&#38388;&#19981;&#21464;&#36873;&#25321;&#20559;&#24046;&#65292;&#21017;&#20173;&#28982;&#21487;&#20197;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Performance monitoring of machine learning (ML)-based risk prediction models in healthcare is complicated by the issue of confounding medical interventions (CMI): when an algorithm predicts a patient to be at high risk for an adverse event, clinicians are more likely to administer prophylactic treatment and alter the very target that the algorithm aims to predict. A simple approach is to ignore CMI and monitor only the untreated patients, whose outcomes remain unaltered. In general, ignoring CMI may inflate Type I error because (i) untreated patients disproportionally represent those with low predicted risk and (ii) evolution in both the model and clinician trust in the model can induce complex dependencies that violate standard assumptions. Nevertheless, we show that valid inference is still possible if one monitors conditional performance and if either conditional exchangeability or time-constant selection bias hold. Specifically, we develop a new score-based cumulative sum (CUSUM) m
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24102;&#26377;&#36755;&#36816;&#35745;&#21010;&#26174;&#24335;&#22522;&#25968;&#32422;&#26463;&#30340; OT &#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#27599;&#20010;&#36755;&#20837;&#20196;&#29260;&#37117;&#19982;&#23569;&#37327;&#19987;&#23478;&#21305;&#37197;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.15466</link><description>&lt;p&gt;
&#31232;&#30095;&#21463;&#38480;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Sparsity-Constrained Optimal Transport. (arXiv:2209.15466v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15466
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24102;&#26377;&#36755;&#36816;&#35745;&#21010;&#26174;&#24335;&#22522;&#25968;&#32422;&#26463;&#30340; OT &#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#27599;&#20010;&#36755;&#20837;&#20196;&#29260;&#37117;&#19982;&#23569;&#37327;&#19987;&#23478;&#21305;&#37197;&#65292;&#20174;&#32780;&#25552;&#39640;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816; (OT) &#29616;&#22312;&#36234;&#26469;&#36234;&#22810;&#22320;&#34987;&#29992;&#20316;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25439;&#22833;&#25110;&#21305;&#37197;&#23618;&#12290;&#20351;&#29992;&#29109;&#27491;&#21017;&#21270; OT &#21487;&#20197;&#20351;&#29992; Sinkhorn &#31639;&#27861;&#35745;&#31639;&#65292;&#20294;&#23427;&#20250;&#20135;&#29983;&#23436;&#20840;&#23494;&#38598;&#30340;&#36816;&#36755;&#35745;&#21010;&#65292;&#36825;&#24847;&#21619;&#30528;&#25152;&#26377;&#28304;&#37117;&#19982;&#25152;&#26377;&#30446;&#26631;&#65288;&#20998;&#25968;&#65289;&#21305;&#37197;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20960;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#27425;&#27491;&#21017;&#21270;&#12290;&#36825;&#31181;&#27491;&#21017;&#21270;&#20445;&#30041;&#20102;&#31232;&#30095;&#24615;&#65292;&#24182;&#23548;&#33268;&#20102;&#26080;&#32422;&#26463;&#21644;&#24179;&#28369;&#65288;&#21322;&#65289;&#23545;&#20598;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#26377;&#30340;&#26799;&#24230;&#26041;&#27861;&#36827;&#34892;&#27714;&#35299;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20108;&#27425;&#27491;&#21017;&#21270;&#19981;&#33021;&#30452;&#25509;&#25511;&#21046;&#36816;&#36755;&#35745;&#21010;&#30340;&#22522;&#25968;&#65288;&#38750;&#38646;&#25968;&#30340;&#25968;&#37327;&#65289;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24102;&#26377;&#36755;&#36816;&#35745;&#21010;&#26174;&#24335;&#22522;&#25968;&#32422;&#26463;&#30340; OT &#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#30001;&#23545;&#31232;&#30095;&#19987;&#23478;&#28151;&#21512;&#29289;&#30340;&#24212;&#29992;&#25152;&#39537;&#21160;&#30340;&#65292;&#20854;&#20013; OT &#21487;&#20197;&#29992;&#20110;&#23558;&#36755;&#20837;&#20196;&#29260;&#65288;&#20363;&#22914;&#22270;&#20687;&#34917;&#19969;&#65289;&#19982;&#19987;&#23478;&#27169;&#22411;&#65288;&#20363;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#36827;&#34892;&#21305;&#37197;&#12290;&#22522;&#25968;&#38480;&#21046;&#21487;&#20197;&#30830;&#20445;&#27599;&#20010;&#36755;&#20837;&#20196;&#29260;&#19982;&#23569;&#37327;&#19987;&#23478;&#21305;&#37197;&#65292;&#36825;&#26377;&#21161;&#20110;&#35299;&#37322;&#28151;&#21512;&#26435;&#37325;&#24182;&#26500;&#24314;&#26356;&#20855;&#21487;&#35299;&#37322;&#24615;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#22522;&#20110; Proximal &#26799;&#24230;&#26041;&#27861;&#30340;&#31232;&#30095;&#21463;&#38480; OT &#38382;&#39064;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularized optimal transport (OT) is now increasingly used as a loss or as a matching layer in neural networks. Entropy-regularized OT can be computed using the Sinkhorn algorithm but it leads to fully-dense transportation plans, meaning that all sources are (fractionally) matched with all targets. To address this issue, several works have investigated quadratic regularization instead. This regularization preserves sparsity and leads to unconstrained and smooth (semi) dual objectives, that can be solved with off-the-shelf gradient methods. Unfortunately, quadratic regularization does not give direct control over the cardinality (number of nonzeros) of the transportation plan. We propose in this paper a new approach for OT with explicit cardinality constraints on the transportation plan. Our work is motivated by an application to sparse mixture of experts, where OT can be used to match input tokens such as image patches with expert models such as neural networks. Cardinality constraint
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.13714</link><description>&lt;p&gt;
&#24102;&#29702;&#35770;&#25903;&#25345;&#30340;&#26679;&#26412;&#37325;&#29992;&#30340;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse. (arXiv:2206.13714v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13714
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#23398;&#20064;&#25511;&#21046;&#26041;&#27861;&#20855;&#26377;&#25913;&#21892;&#22797;&#26434;&#31995;&#32479;&#36816;&#34892;&#30340;&#28508;&#21147;&#65292;&#32780;&#22522;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#34920;&#20102;&#19968;&#31181;&#27969;&#34892;&#30340;&#25968;&#25454;&#39537;&#21160;&#25511;&#21046;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31639;&#27861;&#31867;&#21035;&#22312;&#23454;&#38469;&#25511;&#21046;&#37096;&#32626;&#30340;&#20004;&#20010;&#37325;&#35201;&#35201;&#27714;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#65306;&#65288;i&#65289;&#23454;&#38469;&#24615;&#33021;&#20445;&#35777;&#21644;&#65288;ii&#65289;&#25968;&#25454;&#25928;&#29575;&#12290;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36890;&#36807;&#26679;&#26412;&#37325;&#29992;&#26377;&#25928;&#21033;&#29992;&#25968;&#25454;&#65292;&#20294;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#65292;&#32780;&#22312;&#32447;&#31574;&#30053;&#31639;&#27861;&#20445;&#35777;&#20102;&#35757;&#32451;&#26399;&#38388;&#30340;&#36817;&#20284;&#31574;&#30053;&#25913;&#36827;&#65292;&#20294;&#21463;&#21040;&#39640;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#24179;&#34913;&#36825;&#20123;&#31454;&#20105;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31867;&#24191;&#20041;&#31574;&#30053;&#25552;&#21319;&#31639;&#27861;&#65292;&#23427;&#32467;&#21512;&#20102;&#22312;&#32447;&#26041;&#27861;&#30340;&#31574;&#30053;&#25552;&#21319;&#20445;&#35777;&#21644;&#26679;&#26412;&#37325;&#29992;&#30340;&#25928;&#29575;&#12290;&#36890;&#36807;&#23545;&#26469;&#33258;DeepMind C&#30340;&#22810;&#31181;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#36827;&#34892; extensive &#30340;&#23454;&#39564;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31867;&#31639;&#27861;&#30340;&#30410;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven, learning-based control methods offer the potential to improve operations in complex systems, and model-free deep reinforcement learning represents a popular approach to data-driven control. However, existing classes of algorithms present a trade-off between two important deployment requirements for real-world control: (i) practical performance guarantees and (ii) data efficiency. Off-policy algorithms make efficient use of data through sample reuse but lack theoretical guarantees, while on-policy algorithms guarantee approximate policy improvement throughout training but suffer from high sample complexity. In order to balance these competing goals, we develop a class of Generalized Policy Improvement algorithms that combines the policy improvement guarantees of on-policy methods with the efficiency of sample reuse. We demonstrate the benefits of this new class of algorithms through extensive experimental analysis on a variety of continuous control tasks from the DeepMind C
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23545;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26131;&#21463;&#25915;&#20987;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#22312;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#30340;&#21516;&#26102;&#25552;&#39640;&#38544;&#31169;&#21644;&#24615;&#33021;&#65292;&#28040;&#38500;&#20102;&#38544;&#31169;&#19982;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.14055</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#23545;&#25104;&#21592;&#25512;&#29702;&#20013;&#32500;&#24230;&#30340;&#31069;&#31119;
&lt;/p&gt;
&lt;p&gt;
A Blessing of Dimensionality in Membership Inference through Regularization. (arXiv:2205.14055v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14055
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23545;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#26131;&#21463;&#25915;&#20987;&#24615;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#22312;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#30340;&#21516;&#26102;&#25552;&#39640;&#38544;&#31169;&#21644;&#24615;&#33021;&#65292;&#28040;&#38500;&#20102;&#38544;&#31169;&#19982;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#23545;&#20998;&#31867;&#22120;&#22312;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#20013;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#22914;&#20309;&#24341;&#21457;&#38544;&#31169;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#38382;&#39064;&#65306;&#22686;&#21152;&#21442;&#25968;&#25968;&#37327;&#36890;&#24120;&#20250;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#65292;&#20294;&#20250;&#38477;&#20302;&#38544;&#31169;&#20445;&#38556;&#12290;&#28982;&#32780;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#38543;&#21518;&#35777;&#26126;&#65292;&#22914;&#26524;&#19982;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#30456;&#32467;&#21512;&#65292;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#23454;&#38469;&#19978;&#21487;&#20197;&#21516;&#26102;&#22686;&#21152;&#20854;&#38544;&#31169;&#21644;&#24615;&#33021;&#65292;&#20174;&#32780;&#28040;&#38500;&#38544;&#31169;&#19982;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#38382;&#39064;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#21452;&#37325;&#29305;&#24449;&#38598;&#21512;&#35774;&#32622;&#30340;&#23725;&#22238;&#24402;&#36923;&#36753;&#22238;&#24402;&#36827;&#34892;&#30340;&#23454;&#39564;&#26469;&#35777;&#26126;&#20102;&#36825;&#19968;&#31070;&#22855;&#29616;&#35937;&#12290;&#22312;&#25105;&#20204;&#30340;&#29702;&#35770;&#25506;&#32034;&#20043;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;leave-one-out&#20998;&#26512;&#24037;&#20855;&#65292;&#20197;&#31934;&#30830;&#21051;&#30011;&#32447;&#24615;&#20998;&#31867;&#22120;&#23545;&#26368;&#20339;&#25104;&#21592;&#25512;&#29702;&#25915;&#20987;&#30340;&#26131;&#21463;&#25915;&#20987;&#24615;&#12290;&#26368;&#21518;&#25105;&#20204;&#36824;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Is overparameterization a privacy liability? In this work, we study the effect that the number of parameters has on a classifier's vulnerability to membership inference attacks. We first demonstrate how the number of parameters of a model can induce a privacy--utility trade-off: increasing the number of parameters generally improves generalization performance at the expense of lower privacy. However, remarkably, we then show that if coupled with proper regularization, increasing the number of parameters of a model can actually simultaneously increase both its privacy and performance, thereby eliminating the privacy--utility trade-off. Theoretically, we demonstrate this curious phenomenon for logistic regression with ridge regularization in a bi-level feature ensemble setting. Pursuant to our theoretical exploration, we develop a novel leave-one-out analysis tool to precisely characterize the vulnerability of a linear classifier to the optimal membership inference attack. We empirically
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36866;&#24212;&#26410;&#30693;&#26799;&#24230;&#33539;&#25968;&#12289;&#24179;&#28369;&#24615;&#21644;&#24378;&#20984;&#24615;&#65292;&#24182;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2205.02160</link><description>&lt;p&gt;
&#20351;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#26080;&#21442;&#25968;&#21270;
&lt;/p&gt;
&lt;p&gt;
Making SGD Parameter-Free. (arXiv:2205.02160v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02160
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36866;&#24212;&#26410;&#30693;&#26799;&#24230;&#33539;&#25968;&#12289;&#24179;&#28369;&#24615;&#21644;&#24378;&#20984;&#24615;&#65292;&#24182;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#31639;&#27861;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#20165;&#27604;&#23545;&#24212;&#30340;&#24050;&#30693;&#21442;&#25968;&#35774;&#32622;&#30340;&#26368;&#20248;&#36895;&#24230;&#22810;&#19968;&#20010;&#21452;&#23545;&#25968;&#22240;&#23376;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20808;&#21069;&#24050;&#30693;&#30340;&#26080;&#21442;&#25968;SCO&#30340;&#26368;&#20339;&#36895;&#24230;&#26159;&#22522;&#20110;&#22312;&#32447;&#26080;&#21442;&#25968;&#21518;&#24724;&#30028;&#30340;&#65292;&#19982;&#24050;&#30693;&#21442;&#25968;&#30340;&#23545;&#24212;&#26041;&#27861;&#30456;&#27604;&#21253;&#21547;&#19981;&#21487;&#36991;&#20813;&#30340;&#39069;&#22806;&#23545;&#25968;&#39033;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#27010;&#24565;&#19978;&#30340;&#31616;&#21333;&#24615;&#65292;&#20855;&#26377;&#39640;&#27010;&#29575;&#20445;&#35777;&#65292;&#24182;&#19988;&#37096;&#20998;&#36866;&#24212;&#26410;&#30693;&#26799;&#24230;&#33539;&#25968;&#12289;&#24179;&#28369;&#24615;&#21644;&#24378;&#20984;&#24615;&#12290;&#25105;&#20204;&#30340;&#25104;&#26524;&#30340;&#26680;&#24515;&#26159;SGD&#27493;&#38271;&#36873;&#25321;&#30340;&#26032;&#22411;&#26080;&#21442;&#25968;&#35777;&#20070;&#65292;&#20197;&#21450;&#20551;&#35774;&#22312;SGD&#36845;&#20195;&#19978;&#27809;&#26377;&#20808;&#39564;&#30028;&#38480;&#30340;&#26102;&#38388;&#19968;&#33268;&#38598;&#20013;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop an algorithm for parameter-free stochastic convex optimization (SCO) whose rate of convergence is only a double-logarithmic factor larger than the optimal rate for the corresponding known-parameter setting. In contrast, the best previously known rates for parameter-free SCO are based on online parameter-free regret bounds, which contain unavoidable excess logarithmic terms compared to their known-parameter counterparts. Our algorithm is conceptually simple, has high-probability guarantees, and is also partially adaptive to unknown gradient norms, smoothness, and strong convexity. At the heart of our results is a novel parameter-free certificate for SGD step size choice, and a time-uniform concentration result that assumes no a-priori bounds on SGD iterates.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#30001;&#24320;&#21457;&#20154;&#21592;&#21644;&#28304;&#25991;&#20214;&#32452;&#25104;&#30340;&#36129;&#29486;&#22270;&#65292;&#21033;&#29992;&#36825;&#20010;&#22270;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#25913;&#36827;&#20102; JIT &#32570;&#38519;&#39044;&#27979;&#65292;&#27604;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26356;&#22909;&#22320;&#39044;&#27979;&#20102;&#26131;&#20986;&#29616;&#32570;&#38519;&#30340;&#26356;&#25913;&#12290;</title><link>http://arxiv.org/abs/2110.05371</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#25913;&#36827;&#20102; JIT &#32570;&#38519;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Graph-Based Machine Learning Improves Just-in-Time Defect Prediction. (arXiv:2110.05371v3 [cs.SE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.05371
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#30001;&#24320;&#21457;&#20154;&#21592;&#21644;&#28304;&#25991;&#20214;&#32452;&#25104;&#30340;&#36129;&#29486;&#22270;&#65292;&#21033;&#29992;&#36825;&#20010;&#22270;&#25552;&#21462;&#30340;&#29305;&#24449;&#65292;&#25913;&#36827;&#20102; JIT &#32570;&#38519;&#39044;&#27979;&#65292;&#27604;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26356;&#22909;&#22320;&#39044;&#27979;&#20102;&#26131;&#20986;&#29616;&#32570;&#38519;&#30340;&#26356;&#25913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20170;&#36719;&#20214;&#19981;&#26029;&#22686;&#21152;&#30340;&#22797;&#26434;&#24615;&#38656;&#35201;&#25968;&#21315;&#21517;&#24320;&#21457;&#20154;&#21592;&#30340;&#36129;&#29486;&#12290;&#30001;&#20110;&#22797;&#26434;&#30340;&#21512;&#20316;&#32467;&#26500;&#65292;&#24320;&#21457;&#20154;&#21592;&#26356;&#21487;&#33021;&#24341;&#20837;&#26131;&#20986;&#29616;&#32570;&#38519;&#30340;&#26356;&#25913;&#65292;&#23548;&#33268;&#36719;&#20214;&#25925;&#38556;&#12290;&#30830;&#23450;&#36825;&#20123;&#26131;&#20986;&#29616;&#32570;&#38519;&#30340;&#26356;&#25913;&#34987;&#24341;&#20837;&#30340;&#26102;&#38388;&#24050;&#32463;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#32780;&#20351;&#29992;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#36825;&#20123;&#20915;&#31574;&#20284;&#20046;&#24050;&#32463;&#36798;&#21040;&#20102;&#29942;&#39048;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#30001;&#24320;&#21457;&#20154;&#21592;&#21644;&#28304;&#25991;&#20214;&#32452;&#25104;&#30340;&#36129;&#29486;&#22270;&#26469;&#25429;&#25417;&#26500;&#24314;&#36719;&#20214;&#25152;&#38656;&#30340;&#24494;&#22937;&#22797;&#26434;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#36825;&#20123;&#36129;&#29486;&#22270;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#23637;&#31034;&#20102;&#21033;&#29992;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#25913;&#36827; JIT &#32570;&#38519;&#39044;&#27979;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20551;&#35774;&#20174;&#36129;&#29486;&#22270;&#20013;&#25552;&#21462;&#30340;&#29305;&#24449;&#21487;&#33021;&#27604;&#20174;&#36719;&#20214;&#29305;&#24449;&#27966;&#29983;&#30340;&#26412;&#36136;&#29305;&#24449;&#26356;&#22909;&#22320;&#39044;&#27979;&#26131;&#20986;&#29616;&#32570;&#38519;&#30340;&#26356;&#25913;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#26469;&#20998;&#31867;&#34920;&#31034;&#24320;&#21457;&#20154;&#21592;&#20043;&#38388;&#20132;&#20114;&#30340;&#36793;&#65292;&#20197;&#35777;&#23454;&#25105;&#20204;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing complexity of today's software requires the contribution of thousands of developers. This complex collaboration structure makes developers more likely to introduce defect-prone changes that lead to software faults. Determining when these defect-prone changes are introduced has proven challenging, and using traditional machine learning (ML) methods to make these determinations seems to have reached a plateau. In this work, we build contribution graphs consisting of developers and source files to capture the nuanced complexity of changes required to build software. By leveraging these contribution graphs, our research shows the potential of using graph-based ML to improve Just-In-Time (JIT) defect prediction. We hypothesize that features extracted from the contribution graphs may be better predictors of defect-prone changes than intrinsic features derived from software characteristics. We corroborate our hypothesis using graph-based ML for classifying edges that represent 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26063;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#22122;&#22768;&#26102;&#38388;&#34920;&#30340;&#26377;&#25928;&#20248;&#21270;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#20013;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#21644;&#35270;&#35273;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2107.00630</link><description>&lt;p&gt;
&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Variational Diffusion Models. (arXiv:2107.00630v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.00630
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#26063;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#22122;&#22768;&#26102;&#38388;&#34920;&#30340;&#26377;&#25928;&#20248;&#21270;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#20013;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#21644;&#35270;&#35273;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#24050;&#32463;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#21512;&#25104;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#20063;&#33021;&#25104;&#20026;&#24456;&#22909;&#30340;&#22522;&#20110;&#21487;&#33021;&#24615;&#30340;&#27169;&#22411;&#21527;&#65311;&#25105;&#20204;&#22238;&#31572;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#26063;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#26631;&#20934;&#22270;&#20687;&#23494;&#24230;&#20272;&#35745;&#22522;&#20934;&#19978;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;&#19982;&#20854;&#20182;&#22522;&#20110;&#25193;&#25955;&#30340;&#27169;&#22411;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#19982;&#27169;&#22411;&#30340;&#20854;&#20313;&#37096;&#20998;&#20849;&#21516;&#26377;&#25928;&#22320;&#20248;&#21270;&#22122;&#22768;&#26102;&#38388;&#34920;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#25193;&#25955;&#25968;&#25454;&#30340;&#20449;&#22122;&#27604;&#26041;&#38754;&#65292;&#21464;&#20998;&#19979;&#38480;&#65288;VLB&#65289;&#31616;&#21270;&#20026;&#19968;&#20010;&#38750;&#24120;&#31616;&#30701;&#30340;&#34920;&#36798;&#24335;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#25105;&#20204;&#23545;&#35813;&#27169;&#22411;&#31867;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#21033;&#29992;&#36825;&#19968;&#35265;&#35299;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#20960;&#20010;&#27169;&#22411;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#36830;&#32493;&#26102;&#38388;VLB&#23545;&#20110;&#22122;&#22768;&#26102;&#38388;&#34920;&#26159;&#19981;&#21464;&#30340;&#65292;&#38500;&#20102;&#20854;&#31471;&#28857;&#22788;&#30340;&#20449;&#22122;&#27604;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#19968;&#31181;&#22122;&#22768;&#26102;&#38388;&#34920;&#65292;&#35813;&#34920;&#38024;&#23545;&#20449;&#22122;&#27604;&#26368;&#23567;&#21270;&#21464;&#20998;&#19979;&#38480;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21253;&#25324;CIFAR-10&#65292; CelebA-HQ&#21644;FFHQ&#22312;&#20869;&#30340;&#20960;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#21487;&#33021;&#24615;&#36824;&#26159;&#35270;&#35273;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion-based generative models have demonstrated a capacity for perceptually impressive synthesis, but can they also be great likelihood-based models? We answer this in the affirmative, and introduce a family of diffusion-based generative models that obtain state-of-the-art likelihoods on standard image density estimation benchmarks. Unlike other diffusion-based models, our method allows for efficient optimization of the noise schedule jointly with the rest of the model. We show that the variational lower bound (VLB) simplifies to a remarkably short expression in terms of the signal-to-noise ratio of the diffused data, thereby improving our theoretical understanding of this model class. Using this insight, we prove an equivalence between several models proposed in the literature. In addition, we show that the continuous-time VLB is invariant to the noise schedule, except for the signal-to-noise ratio at its endpoints. This enables us to learn a noise schedule that minimizes the vari
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#38469;&#19978;&#26159;&#22522;&#20110;&#23725;&#22238;&#24402;&#30340;&#26102;&#21464;&#21442;&#25968;&#27169;&#22411;&#65292;&#36825;&#27604;&#20256;&#32479;&#30340;&#29366;&#24577;&#31354;&#38388;&#26041;&#27861;&#35745;&#31639;&#26356;&#24555;&#65292;&#35843;&#25972;&#26356;&#23481;&#26131;&#65292;&#26377;&#21161;&#20110;&#30740;&#31350;&#32463;&#27982;&#32467;&#26500;&#24615;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2009.00401</link><description>&lt;p&gt;
&#20351;&#29992;&#23725;&#22238;&#24402;&#27861;&#30340;&#26102;&#21464;&#21442;&#25968;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Time-Varying Parameters as Ridge Regressions. (arXiv:2009.00401v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.00401
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#38469;&#19978;&#26159;&#22522;&#20110;&#23725;&#22238;&#24402;&#30340;&#26102;&#21464;&#21442;&#25968;&#27169;&#22411;&#65292;&#36825;&#27604;&#20256;&#32479;&#30340;&#29366;&#24577;&#31354;&#38388;&#26041;&#27861;&#35745;&#31639;&#26356;&#24555;&#65292;&#35843;&#25972;&#26356;&#23481;&#26131;&#65292;&#26377;&#21161;&#20110;&#30740;&#31350;&#32463;&#27982;&#32467;&#26500;&#24615;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#21464;&#21442;&#25968;&#27169;&#22411;(TVPs)&#32463;&#24120;&#34987;&#29992;&#20110;&#32463;&#27982;&#23398;&#20013;&#26469;&#25429;&#25417;&#32467;&#26500;&#24615;&#21464;&#21270;&#12290;&#25105;&#24378;&#35843;&#20102;&#19968;&#20010;&#34987;&#24573;&#35270;&#30340;&#20107;&#23454;&#8212;&#8212;&#36825;&#20123;&#23454;&#38469;&#19978;&#26159;&#23725;&#22238;&#24402;&#12290;&#36825;&#20351;&#24471;&#35745;&#31639;&#12289;&#35843;&#25972;&#21644;&#23454;&#29616;&#27604;&#29366;&#24577;&#31354;&#38388;&#33539;&#24335;&#26356;&#23481;&#26131;&#12290;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#31561;&#20215;&#30340;&#21452;&#37325;&#23725;&#38382;&#39064;&#30340;&#35745;&#31639;&#38750;&#24120;&#24555;,&#20851;&#38190;&#30340;&#8220;&#26102;&#38388;&#21464;&#21270;&#37327;&#8221;&#36890;&#24120;&#26159;&#30001;&#20132;&#21449;&#39564;&#35777;&#26469;&#35843;&#25972;&#30340;&#12290;&#20351;&#29992;&#20004;&#27493;&#22238;&#24402;&#23725;&#22238;&#24402;&#26469;&#22788;&#29702;&#19981;&#26029;&#21464;&#21270;&#30340;&#27874;&#21160;&#24615;&#12290;&#25105;&#32771;&#34385;&#20102;&#22522;&#20110;&#31232;&#30095;&#24615;(&#31639;&#27861;&#36873;&#25321;&#21738;&#20123;&#21442;&#25968;&#21464;&#21270;, &#21738;&#20123;&#19981;&#21464;)&#21644;&#38477;&#20302;&#31209;&#32422;&#26463;&#30340;&#25193;&#23637;(&#21464;&#21270;&#19982;&#22240;&#23376;&#27169;&#22411;&#30456;&#20851;&#32852;)&#12290;&#20026;&#20102;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;, &#25105;&#20351;&#29992;&#23427;&#26469;&#30740;&#31350;&#21152;&#25343;&#22823;&#36135;&#24065;&#25919;&#31574;&#30340;&#28436;&#21464;, &#24182;&#20351;&#29992;&#22823;&#35268;&#27169;&#26102;&#21464;&#23616;&#37096;&#25237;&#24433;&#20272;&#35745;&#32422;4600&#20010;TVPs, &#36825;&#19968;&#20219;&#21153;&#23436;&#20840;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#26032;&#26041;&#27861;&#23436;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-varying parameters (TVPs) models are frequently used in economics to capture structural change. I highlight a rather underutilized fact -- that these are actually ridge regressions. Instantly, this makes computations, tuning, and implementation much easier than in the state-space paradigm. Among other things, solving the equivalent dual ridge problem is computationally very fast even in high dimensions, and the crucial "amount of time variation" is tuned by cross-validation. Evolving volatility is dealt with using a two-step ridge regression. I consider extensions that incorporate sparsity (the algorithm selects which parameters vary and which do not) and reduced-rank restrictions (variation is tied to a factor model). To demonstrate the usefulness of the approach, I use it to study the evolution of monetary policy in Canada using large time-varying local projections. The application requires the estimation of about 4600 TVPs, a task well within the reach of the new method.
&lt;/p&gt;</description></item></channel></rss>