<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#20351;&#29992;&#27491;&#21017;&#27969;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#20013;&#21382;&#21490;&#38590;&#39064;&#65292;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;</title><link>https://rss.arxiv.org/abs/2311.09200</link><description>&lt;p&gt;
&#27491;&#21017;&#27969;&#26159;&#21542;&#26159;&#35299;&#38145;&#25351;&#25968;&#26426;&#21046;&#30340;&#20851;&#38190;&#65311;&#32463;&#36807;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#21452;&#37325;&#32422;&#26463;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#26465;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
Are Normalizing Flows the Key to Unlocking the Exponential Mechanism? A Path through the Accuracy-Privacy Ceiling Constraining Differentially Private ML
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2311.09200
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#27491;&#21017;&#27969;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#20013;&#21382;&#21490;&#38590;&#39064;&#65292;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#26368;&#20808;&#36827;&#19988;&#20107;&#23454;&#26631;&#20934;&#26159;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DPSGD&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#26412;&#36136;&#19978;&#26159;&#28010;&#36153;&#30340;&#12290;&#36890;&#36807;&#21521;&#27599;&#20010;&#26799;&#24230;&#28155;&#21152;&#22122;&#22768;&#65292;&#23427;&#20250;&#22312;&#27599;&#20010;&#26799;&#24230;&#27493;&#39588;&#20013;&#38477;&#20302;&#25972;&#20307;&#38544;&#31169;&#12290;&#23613;&#31649;&#32463;&#36807;15&#24180;&#30340;&#20016;&#23500;&#30740;&#31350;&#65292;&#25512;&#36827;&#20102;&#32452;&#21512;&#23450;&#29702;&#12289;&#23376;&#37319;&#26679;&#26041;&#27861;&#21644;&#23454;&#29616;&#25216;&#26415;&#65292;&#20294;&#24403;&#21069;&#30340;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#36798;&#21040;&#36275;&#22815;&#30340;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#20026;&#20102;&#31169;&#19979;&#20248;&#21270;&#32780;&#35774;&#35745;&#30340;&#25351;&#25968;&#26426;&#21046;&#65288;ExpM&#65289;&#21382;&#26469;&#34987;&#25490;&#38500;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#31169;&#19979;&#35757;&#32451;&#20043;&#22806;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;ExpM&#38656;&#35201;&#20174;&#19968;&#31181;&#21382;&#26469;&#38590;&#20197;&#22788;&#29702;&#30340;&#23494;&#24230;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23613;&#31649;&#26368;&#36817;&#21457;&#29616;&#20102;&#27491;&#21017;&#27969;&#27169;&#22411;&#65288;NFs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#36924;&#36817;&#38590;&#20197;&#22788;&#29702;&#20998;&#24067;&#30340;&#34920;&#36798;&#28145;&#24230;&#32593;&#32476;&#65292;&#20294;ExpM&#20173;&#28982;&#22788;&#20110;&#32972;&#26223;&#20013;&#12290;&#25105;&#20204;&#30340;&#35266;&#28857;&#26159;&#21033;&#29992;&#27491;&#21017;&#27969;&#26469;&#32469;&#36807;ExpM&#30340;&#21382;&#21490;&#38556;&#30861;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The state of the art and de facto standard for differentially private machine learning (ML) is differentially private stochastic gradient descent (DPSGD). Yet, the method is inherently wasteful. By adding noise to every gradient, it diminishes the overall privacy with every gradient step. Despite 15 years of fruitful research advancing the composition theorems, sub-sampling methods, and implementation techniques, adequate accuracy and privacy is often unattainable with current private ML methods. Meanwhile, the Exponential Mechanism (ExpM), designed for private optimization, has been historically sidelined from privately training modern ML algorithms primarily because ExpM requires sampling from a historically intractable density. Despite the recent discovery of Normalizing Flow models (NFs), expressive deep networks for approximating intractable distributions, ExpM remains in the background. Our position is that leveraging NFs to circumvent historic obstructions of ExpM is a potential
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;R&#233;nyi-DP&#25512;&#23548;&#36890;&#36807;&#23376;&#25277;&#26679;&#30340;&#25918;&#22823;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#38024;&#23545;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#30340;&#26694;&#26550;&#65292;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04867</link><description>&lt;p&gt;
&#32452;&#38544;&#31169;&#25918;&#22823;&#21644;&#23376;&#25277;&#26679;&#30340;R&#233;nyi&#24046;&#20998;&#38544;&#31169;&#32479;&#19968;&#25918;&#22823;
&lt;/p&gt;
&lt;p&gt;
Group Privacy Amplification and Unified Amplification by Subsampling for R\'enyi Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04867
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;R&#233;nyi-DP&#25512;&#23548;&#36890;&#36807;&#23376;&#25277;&#26679;&#30340;&#25918;&#22823;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#38024;&#23545;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#30340;&#26694;&#26550;&#65292;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;(DP)&#20855;&#26377;&#22810;&#31181;&#29702;&#24819;&#23646;&#24615;&#65292;&#22914;&#23545;&#21518;&#22788;&#29702;&#30340;&#40065;&#26834;&#24615;&#12289;&#32452;&#38544;&#31169;&#21644;&#36890;&#36807;&#23376;&#25277;&#26679;&#25918;&#22823;&#65292;&#36825;&#20123;&#23646;&#24615;&#21487;&#20197;&#30456;&#20114;&#29420;&#31435;&#25512;&#23548;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#26159;&#21542;&#36890;&#36807;&#32852;&#21512;&#32771;&#34385;&#36825;&#20123;&#23646;&#24615;&#20013;&#30340;&#22810;&#20010;&#21487;&#20197;&#33719;&#24471;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#32452;&#38544;&#31169;&#21644;&#36890;&#36807;&#23376;&#25277;&#26679;&#25918;&#22823;&#30340;&#32452;&#21512;&#12290;&#20026;&#20102;&#25552;&#20379;&#36866;&#21512;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#20445;&#35777;&#65292;&#25105;&#20204;&#22312;R&#233;nyi-DP&#26694;&#26550;&#20013;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#36825;&#27604;$(\epsilon,\delta)$-DP&#20855;&#26377;&#26356;&#26377;&#21033;&#30340;&#32452;&#21512;&#23646;&#24615;&#12290;&#20316;&#20026;&#36825;&#20010;&#20998;&#26512;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;R&#233;nyi-DP&#25512;&#23548;&#36890;&#36807;&#23376;&#25277;&#26679;&#30340;&#25918;&#22823;&#20445;&#35777;&#65292;&#36825;&#26159;&#39318;&#20010;&#38024;&#23545;&#38544;&#31169;&#26680;&#31639;&#26041;&#27861;&#30340;&#26694;&#26550;&#65292;&#20063;&#20855;&#26377;&#29420;&#31435;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23427;&#19981;&#20165;&#35753;&#25105;&#20204;&#25913;&#36827;&#21644;&#27867;&#21270;&#29616;&#26377;&#30340;&#25918;&#22823;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04867v1 Announce Type: cross  Abstract: Differential privacy (DP) has various desirable properties, such as robustness to post-processing, group privacy, and amplification by subsampling, which can be derived independently of each other. Our goal is to determine whether stronger privacy guarantees can be obtained by considering multiple of these properties jointly. To this end, we focus on the combination of group privacy and amplification by subsampling. To provide guarantees that are amenable to machine learning algorithms, we conduct our analysis in the framework of R\'enyi-DP, which has more favorable composition properties than $(\epsilon,\delta)$-DP. As part of this analysis, we develop a unified framework for deriving amplification by subsampling guarantees for R\'enyi-DP, which represents the first such framework for a privacy accounting method and is of independent interest. We find that it not only lets us improve upon and generalize existing amplification results 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#20110;$k$-PCA&#31639;&#27861;&#20013;&#36817;&#20284;&#21442;&#25968;&#36864;&#21270;&#30340;&#36793;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#26356;&#20026;&#31934;&#30830;&#30340;&#30028;&#38480;</title><link>https://arxiv.org/abs/2403.03905</link><description>&lt;p&gt;
&#40657;&#30418;$k$-to-$1$-PCA&#38477;&#32500;&#65306;&#29702;&#35770;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03905
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#20110;$k$-PCA&#31639;&#27861;&#20013;&#36817;&#20284;&#21442;&#25968;&#36864;&#21270;&#30340;&#36793;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#26356;&#20026;&#31934;&#30830;&#30340;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$k$-&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;$k$-PCA&#65289;&#38382;&#39064;&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#31639;&#27861;&#21407;&#35821;&#65292;&#22312;&#25968;&#25454;&#20998;&#26512;&#21644;&#38477;&#32500;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#22312;&#32479;&#35745;&#29615;&#22659;&#20013;&#65292;$k$-PCA&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#19968;&#20010;&#20998;&#24067;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39030;&#37096;&#29305;&#24449;&#31354;&#38388;&#65292;&#25105;&#20204;&#21482;&#33021;&#36890;&#36807;&#26679;&#26412;&#38544;&#24335;&#35775;&#38382;&#36825;&#20010;&#30697;&#38453;&#12290;&#21463;&#36825;&#20123;&#38544;&#24335;&#35774;&#32622;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20998;&#26512;&#40657;&#30418;&#32553;&#20943;&#26041;&#27861;&#20316;&#20026;&#35774;&#35745;$k$-PCA&#31639;&#27861;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#36890;&#36807;&#40657;&#30418;$1$-PCA&#39044;&#35328;&#27169;&#25311;&#23545;&#26410;&#30693;&#30446;&#26631;&#30697;&#38453;&#30340;&#35775;&#38382;&#65292;&#35813;&#39044;&#35328;&#36820;&#22238;&#19968;&#20010;&#36817;&#20284;&#30340;&#39030;&#37096;&#29305;&#24449;&#21521;&#37327;&#65292;&#26681;&#25454;&#20004;&#20010;&#27969;&#34892;&#30340;&#36817;&#20284;&#27010;&#24565;&#12290;&#23613;&#31649;&#36825;&#31181;&#40657;&#30418;&#26041;&#27861;&#21487;&#33021;&#26159;&#35774;&#35745;$k$-PCA&#31639;&#27861;&#20013;&#26368;&#33258;&#28982;&#30340;&#22522;&#20110;&#38477;&#32500;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#36882;&#24402;&#35843;&#29992;$1$-PCA&#39044;&#35328;&#35843;&#29992;&#20102;$k$&#27425;&#65292;&#20197;&#21069;&#24456;&#38590;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03905v1 Announce Type: cross  Abstract: The $k$-principal component analysis ($k$-PCA) problem is a fundamental algorithmic primitive that is widely-used in data analysis and dimensionality reduction applications. In statistical settings, the goal of $k$-PCA is to identify a top eigenspace of the covariance matrix of a distribution, which we only have implicit access to via samples. Motivated by these implicit settings, we analyze black-box deflation methods as a framework for designing $k$-PCA algorithms, where we model access to the unknown target matrix via a black-box $1$-PCA oracle which returns an approximate top eigenvector, under two popular notions of approximation. Despite being arguably the most natural reduction-based approach to $k$-PCA algorithm design, such black-box methods, which recursively call a $1$-PCA oracle $k$ times, were previously poorly-understood.   Our main contribution is significantly sharper bounds on the approximation parameter degradation of
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;DML&#20272;&#35745;&#22120;&#25193;&#23637;&#65292;&#36890;&#36807;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#65292;&#20197;&#35299;&#20915;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01585</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#24179;&#34913;&#30340;&#22788;&#29702;&#20998;&#37197;&#26657;&#20934;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Calibrating doubly-robust estimators with unbalanced treatment assignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01585
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;DML&#20272;&#35745;&#22120;&#25193;&#23637;&#65292;&#36890;&#36807;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#65292;&#20197;&#35299;&#20915;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#20272;&#35745;&#22120;&#65288;Chernozhukov&#31561;&#65292;2018&#65289;&#65292;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#22320;&#29992;&#20110;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#38598;&#36890;&#24120;&#34920;&#29616;&#20986;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#65292;&#21482;&#26377;&#23569;&#25968;&#35266;&#27979;&#20540;&#34987;&#22788;&#29702;&#65292;&#23548;&#33268;&#31283;&#20581;&#27010;&#29575;&#24471;&#20998;&#20272;&#35745;&#19981;&#31283;&#23450;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DML&#20272;&#35745;&#22120;&#30340;&#31616;&#21333;&#25193;&#23637;&#65292;&#35813;&#25193;&#23637;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#20102;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#20272;&#35745;&#22120;&#20445;&#30041;&#20102;DML&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;&#27169;&#25311;&#30740;&#31350;&#35828;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01585v1 Announce Type: new  Abstract: Machine learning methods, particularly the double machine learning (DML) estimator (Chernozhukov et al., 2018), are increasingly popular for the estimation of the average treatment effect (ATE). However, datasets often exhibit unbalanced treatment assignments where only a few observations are treated, leading to unstable propensity score estimations. We propose a simple extension of the DML estimator which undersamples data for propensity score modeling and calibrates scores to match the original distribution. The paper provides theoretical results showing that the estimator retains the DML estimator's asymptotic properties. A simulation study illustrates the finite sample performance of the estimator.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;</title><link>https://arxiv.org/abs/2402.18477</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#31614;&#21517;&#26680;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#29992;&#20110;&#38543;&#26426;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18477
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38543;&#26426;&#36807;&#31243;&#20013;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#26680;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#65292;&#23454;&#29616;&#20102;&#23545;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#65292;&#20197;&#21450;&#24320;&#21457;&#20102;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#29992;&#20110;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25512;&#26029;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#22312;&#31185;&#23398;&#12289;&#20581;&#24247;&#21644;&#37329;&#34701;&#31561;&#39046;&#22495;&#20855;&#26377;&#24040;&#22823;&#28508;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#31614;&#21517;&#26680;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20869;&#26680;&#30340;&#8220;&#36335;&#24452;&#31354;&#38388;&#8221;&#19978;&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#27979;&#35797;&#65292;&#29992;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#36739;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22312;&#36335;&#24452;&#31354;&#38388;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;CI&#27979;&#35797;&#34920;&#29616;&#20986;&#20005;&#26684;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;&#38750;&#24490;&#29615;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#24320;&#21457;&#20102;&#22522;&#20110;&#32422;&#26463;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#65292;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#26469;&#24674;&#22797;&#25972;&#20010;&#26377;&#21521;&#22270;&#12290;&#22312;&#20551;&#35774;&#24544;&#23454;&#24615;&#21644;CI&#39044;&#35328;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23436;&#22791;&#19988;&#27491;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18477v1 Announce Type: cross  Abstract: Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via "which variables enter the differential of which other variables". In this paper, we develop a kernel-based test of conditional independence (CI) on "path-space" -- solutions to SDEs -- by leveraging recent advances in signature kernels. We demonstrate strictly superior performance of our proposed CI test compared to existing approaches on path-space. Then, we develop constraint-based causal discovery algorithms for acyclic stochastic dynamical systems (allowing for loops) that leverage temporal information to recover the entire directed graph. Assuming faithfulness and a CI oracle, our algorithm is sound and complete. We empirical
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;</title><link>https://arxiv.org/abs/2402.17732</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;
&lt;/p&gt;
&lt;p&gt;
Batched Nonparametric Contextual Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BaSEDB&#30340;&#26041;&#26696;&#65292;&#22312;&#21160;&#24577;&#20998;&#21106;&#21327;&#21464;&#37327;&#31354;&#38388;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#30340;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#33218;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#21160;&#20316;&#30340;&#26399;&#26395;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#21327;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#65292;&#24182;&#19988;&#31574;&#30053;&#26356;&#26032;&#26159;&#22312;&#27599;&#20010;Observations&#25209;&#27425;&#32467;&#26463;&#26102;&#36827;&#34892;&#30340;&#12290;&#25105;&#20204;&#20026;&#36825;&#31181;&#35774;&#32622;&#24314;&#31435;&#20102;&#19968;&#20010;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Batched Successive Elimination with Dynamic Binning&#65288;BaSEDB&#65289;&#30340;&#26041;&#26696;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21518;&#24724;&#65288;&#36798;&#21040;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#23454;&#36136;&#19978;&#65292;BaSEDB&#21160;&#24577;&#22320;&#23558;&#21327;&#21464;&#37327;&#31354;&#38388;&#20998;&#21106;&#25104;&#26356;&#23567;&#30340;&#31665;&#23376;&#65292;&#24182;&#20180;&#32454;&#35843;&#25972;&#23427;&#20204;&#30340;&#23485;&#24230;&#20197;&#31526;&#21512;&#25209;&#27425;&#22823;&#23567;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#25209;&#22788;&#29702;&#32422;&#26463;&#19979;&#38745;&#24577;&#20998;&#31665;&#30340;&#38750;&#26368;&#20248;&#24615;&#65292;&#31361;&#20986;&#20102;&#21160;&#24577;&#20998;&#31665;&#30340;&#24517;&#35201;&#24615;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23436;&#20840;&#22312;&#32447;&#35774;&#32622;&#20013;&#65292;&#20960;&#20046;&#24658;&#23450;&#25968;&#37327;&#30340;&#31574;&#30053;&#26356;&#26032;&#21487;&#20197;&#36798;&#21040;&#26368;&#20339;&#21518;&#24724;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17732v1 Announce Type: cross  Abstract: We study nonparametric contextual bandits under batch constraints, where the expected reward for each action is modeled as a smooth function of covariates, and the policy updates are made at the end of each batch of observations. We establish a minimax regret lower bound for this setting and propose Batched Successive Elimination with Dynamic Binning (BaSEDB) that achieves optimal regret (up to logarithmic factors). In essence, BaSEDB dynamically splits the covariate space into smaller bins, carefully aligning their widths with the batch size. We also show the suboptimality of static binning under batch constraints, highlighting the necessity of dynamic binning. Additionally, our results suggest that a nearly constant number of policy updates can attain optimal regret in the fully online setting.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.14090</link><description>&lt;p&gt;
&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Social Environment Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14090
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#21046;&#23450;&#30340;&#25216;&#26415;&#20855;&#26377;&#28508;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#19982;&#24378;&#21270;&#23398;&#20064;&#12289;&#32463;&#27982;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#31038;&#21306;&#30456;&#36830;&#25509;&#12290;&#35813;&#26694;&#26550;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#21253;&#25324;&#23545;&#25919;&#31574;&#30446;&#26631;&#30340;&#25237;&#31080;&#65292;&#24182;&#20026;&#36890;&#36807;AI&#27169;&#25311;&#23545;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#25552;&#20379;&#25351;&#23548;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#24320;&#25918;&#38382;&#39064;&#12290;&#36890;&#36807;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24076;&#26395;&#23454;&#29616;&#21508;&#31181;&#31038;&#20250;&#31119;&#21033;&#30446;&#26631;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#20855;&#36947;&#24503;&#21644;&#36127;&#36131;&#20219;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14090v1 Announce Type: new  Abstract: Artificial Intelligence (AI) holds promise as a technology that can be used to improve government and economic policy-making. This paper proposes a new research agenda towards this end by introducing Social Environment Design, a general framework for the use of AI for automated policy-making that connects with the Reinforcement Learning, EconCS, and Computational Social Choice communities. The framework seeks to capture general economic environments, includes voting on policy objectives, and gives a direction for the systematic analysis of government and economic policy through AI simulation. We highlight key open problems for future research in AI-based policy-making. By solving these challenges, we hope to achieve various social welfare objectives, thereby promoting more ethical and responsible decision making.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#20013;&#65292;&#36890;&#36807;&#25913;&#36827;AVLPR&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#24754;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.07082</link><description>&lt;p&gt;
&#22522;&#20110;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Refined Sample Complexity for Markov Games with Independent Linear Function Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#29420;&#31435;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#20013;&#65292;&#36890;&#36807;&#25913;&#36827;AVLPR&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#25968;&#25454;&#20381;&#36182;&#30340;&#24754;&#35266;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#31185;&#22827;&#21338;&#24328;&#65288;MG&#65289;&#26159;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#20013;&#30340;&#37325;&#35201;&#27169;&#22411;&#12290;&#38271;&#26399;&#20197;&#26469;&#20154;&#20204;&#19968;&#30452;&#35748;&#20026;&#8220;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#8221;&#65288;&#21363;&#31639;&#27861;&#24615;&#33021;&#38543;&#30528;&#26234;&#33021;&#20307;&#25968;&#37327;&#25351;&#25968;&#32423;&#19979;&#38477;&#65289;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#30452;&#21040;&#26368;&#36817;&#20960;&#31687;&#20316;&#21697;&#65288;Daskalakis&#31561;&#20154;&#65292;2023&#24180;&#65307;Cui&#31561;&#20154;&#65292;2023&#24180;&#65307;Wang&#31561;&#20154;&#65292;2023&#24180;&#65289;&#12290;&#36825;&#20123;&#20316;&#21697;&#30830;&#23454;&#35299;&#20915;&#20102;&#22810;&#26234;&#33021;&#20307;&#30340;&#35781;&#21650;&#65292;&#24403;&#29366;&#24577;&#31354;&#38388;&#26497;&#22823;&#19988;&#65288;&#32447;&#24615;&#65289;&#20989;&#25968;&#36924;&#36817;&#34987;&#24212;&#29992;&#26102;&#65292;&#23427;&#20204;&#35201;&#20040;&#20855;&#26377;&#26356;&#24930;&#30340;&#25910;&#25947;&#36895;&#24230;$O(T^{-1/4})$&#65292;&#35201;&#20040;&#22312;&#34892;&#21160;&#25968;$A_{\max}$&#19978;&#24102;&#26469;&#22810;&#39033;&#24335;&#20381;&#36182;&#8212;&#8212;&#23613;&#31649;&#22312;&#21333;&#26234;&#33021;&#20307;&#24773;&#20917;&#19979;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#38543;&#26102;&#38388;&#20219;&#24847;&#21464;&#21270;&#65288;Dai&#31561;&#20154;&#65292;2023&#24180;&#65289;&#65292;&#20063;&#21487;&#36991;&#20813;&#36825;&#31181;&#20381;&#36182;&#12290;&#26412;&#25991;&#39318;&#20808;&#36890;&#36807;Wang&#31561;&#20154;&#65288;2023&#24180;&#65289;&#30340;&#8220;AVLPR&#8221;&#26694;&#26550;&#31934;&#21270;&#65292;&#27934;&#23519;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#65288;&#21363;&#38543;&#26426;&#30340;&#65289;&#24754;&#35266;&#20272;&#35745;&#23376;&#20248;&#21270;&#24046;&#36317;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#24191;&#27867;&#30340;&#25554;&#20214;&#31639;&#27861;&#36873;&#25321;&#12290;&#24403;&#19987;&#38376;&#24212;&#29992;&#20110;MGs&#26102;&#65292;&#36825;&#19968;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#29420;&#31435;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov Games (MG) is an important model for Multi-Agent Reinforcement Learning (MARL). It was long believed that the "curse of multi-agents" (i.e., the algorithmic performance drops exponentially with the number of agents) is unavoidable until several recent works (Daskalakis et al., 2023; Cui et al., 2023; Wang et al., 2023. While these works did resolve the curse of multi-agents, when the state spaces are prohibitively large and (linear) function approximations are deployed, they either had a slower convergence rate of $O(T^{-1/4})$ or brought a polynomial dependency on the number of actions $A_{\max}$ -- which is avoidable in single-agent cases even when the loss functions can arbitrarily vary with time (Dai et al., 2023). This paper first refines the `AVLPR` framework by Wang et al. (2023), with an insight of *data-dependent* (i.e., stochastic) pessimistic estimation of the sub-optimality gap, allowing a broader choice of plug-in algorithms. When specialized to MGs with independent
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#37096;&#20998;&#35266;&#27979;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#24102;&#26469;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2311.12244</link><description>&lt;p&gt;
&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#24615;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Efficient Reinforcement Learning from Partial Observability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12244
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#37096;&#20998;&#35266;&#27979;&#20013;&#36827;&#34892;&#26377;&#25928;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#24102;&#26469;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22810;&#25968;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#29366;&#24577;&#20449;&#24687;&#21482;&#33021;&#37096;&#20998;&#35266;&#27979;&#21040;&#65292;&#36825;&#30772;&#22351;&#20102;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#20551;&#35774;&#65292;&#23548;&#33268;&#23558;&#35266;&#27979;&#19982;&#29366;&#24577;&#30456;&#28151;&#28102;&#30340;&#31639;&#27861;&#34920;&#29616;&#19981;&#20339;&#12290;&#32780;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#20801;&#35768;&#22312;&#23398;&#20064;&#12289;&#25506;&#32034;&#21644;&#35268;&#21010;&#20013;&#32771;&#34385;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#20294;&#20063;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#25361;&#25112;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#34920;&#31034;&#30340;&#35270;&#35282;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#21644;&#21487;&#34892;&#30340;&#31639;&#27861;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#37096;&#20998;&#35266;&#27979;&#20013;&#36827;&#34892;&#23454;&#38469;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#26469;&#35777;&#26126;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#24182;&#32463;&#39564;&#24615;&#22320;&#35777;&#26126;&#20102;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#37096;&#20998;&#35266;&#27979;&#19979;&#33021;&#22815;&#36229;&#36234;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#25512;&#21160;&#20102;&#21487;&#38752;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In most real-world reinforcement learning applications, state information is only partially observable, which breaks the Markov decision process assumption and leads to inferior performance for algorithms that conflate observations with state. Partially Observable Markov Decision Processes (POMDPs), on the other hand, provide a general framework that allows for partial observability to be accounted for in learning, exploration and planning, but presents significant computational and statistical challenges. To address these difficulties, we develop a representation-based perspective that leads to a coherent framework and tractable algorithmic approach for practical reinforcement learning from partial observations. We provide a theoretical analysis for justifying the statistical efficiency of the proposed algorithm, and also empirically demonstrate the proposed algorithm can surpass state-of-the-art performance with partial observations across various benchmarks, advancing reliable reinf
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.06738</link><description>&lt;p&gt;
&#22122;&#22768;&#33258;&#36866;&#24212;&#65288;&#21152;&#36895;&#65289;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;
&lt;/p&gt;
&lt;p&gt;
Noise-adaptive (Accelerated) Stochastic Heavy-Ball Momentum. (arXiv:2401.06738v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.06738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#12289;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#38024;&#23545;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#35758;&#20102;&#19968;&#31181;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#25910;&#25947;&#36895;&#24230;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#20809;&#28369;&#65292;&#24378;&#20984;&#29615;&#22659;&#20013;&#38543;&#26426;&#37325;&#21147;&#29699;&#21160;&#37327;&#65288;SHB&#65289;&#30340;&#25910;&#25947;&#24615;&#12290;Kidambi&#31561;&#20154;&#65288;2018&#65289;&#34920;&#26126;&#65292;&#23545;&#20110;&#20108;&#27425;&#20989;&#25968;&#65292;SHB&#65288;&#24102;&#26377;&#23567;&#25209;&#37327;&#65289;&#26080;&#27861;&#36798;&#21040;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#29468;&#24819;SHB&#30340;&#23454;&#38469;&#25910;&#30410;&#26159;&#23567;&#25209;&#37327;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#24403;&#25209;&#37327;&#22823;&#23567;&#22823;&#20110;&#19968;&#23450;&#38408;&#20540;&#26102;&#65292;SHB&#21487;&#20197;&#33719;&#24471;&#21152;&#36895;&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35777;&#23454;&#36825;&#19968;&#35266;&#28857;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26465;&#20214;&#25968;&#20026;$\kappa$&#30340;&#24378;&#20984;&#20108;&#27425;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#26631;&#20934;&#27493;&#38271;&#21644;&#21160;&#37327;&#21442;&#25968;&#30340;SHB&#20855;&#26377;$O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$T$&#20026;&#36845;&#20195;&#27425;&#25968;&#65292;$\sigma^2$&#20026;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#12290;&#20026;&#30830;&#20445;&#25910;&#25947;&#21040;&#26497;&#23567;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#38454;&#27573;&#26041;&#27861;&#65292;&#32467;&#26524;&#26159;&#22122;&#22768;&#33258;&#36866;&#24212;&#30340;$O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$&#36895;&#24230;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#24378;&#20984;&#20989;&#25968;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the convergence of stochastic heavy ball (SHB) momentum in the smooth, strongly-convex setting. Kidambi et al. (2018) show that SHB (with small mini-batches) cannot attain an accelerated rate of convergence even for quadratics, and conjecture that the practical gain of SHB is a by-product of mini-batching. We substantiate this claim by showing that SHB can obtain an accelerated rate when the mini-batch size is larger than some threshold. In particular, for strongly-convex quadratics with condition number $\kappa$, we prove that SHB with the standard step-size and momentum parameters results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence rate, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. To ensure convergence to the minimizer, we propose a multi-stage approach that results in a noise-adaptive $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}} \right) + \frac{\sigma}{T}\right)$ rate. For general strongly-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;PCA&#21644;&#20854;&#21464;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#30340;&#32771;&#34385;&#12290;&#36890;&#36807;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#36827;&#34892;&#20248;&#21270;&#38382;&#39064;&#30340;&#27714;&#35299;&#65292;&#32467;&#21512;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.04071</link><description>&lt;p&gt;
&#26071;&#24092;&#28216;&#25103;&#65306;&#36890;&#36807;&#26071;&#24092;&#27969;&#24418;&#26469;&#33719;&#24471;&#40065;&#26834;&#30340;&#20027;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Fun with Flags: Robust Principal Directions via Flag Manifolds. (arXiv:2401.04071v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;PCA&#21644;&#20854;&#21464;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#65292;&#24182;&#24341;&#20837;&#20102;&#23545;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#30340;&#32771;&#34385;&#12290;&#36890;&#36807;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#36827;&#34892;&#20248;&#21270;&#38382;&#39064;&#30340;&#27714;&#35299;&#65292;&#32467;&#21512;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21450;&#20854;&#23545;&#27969;&#24418;&#21644;&#24322;&#24120;&#25968;&#25454;&#30340;&#25193;&#23637;&#65292;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;PCA&#21450;&#20854;&#21464;&#31181;&#30340;&#32479;&#19968;&#24418;&#24335;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#32447;&#24615;&#23376;&#31354;&#38388;&#26071;&#24092;&#30340;&#26694;&#26550;&#65292;&#21363;&#36880;&#28176;&#22686;&#21152;&#32500;&#24230;&#30340;&#23884;&#22871;&#32447;&#24615;&#23376;&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#19981;&#20165;&#20801;&#35768;&#20849;&#21516;&#23454;&#29616;&#65292;&#36824;&#20135;&#29983;&#20102;&#26032;&#30340;&#26410;&#26366;&#25506;&#32034;&#30340;&#21464;&#31181;&#12290;&#25105;&#20204;&#20174;&#24191;&#20041;&#21270;&#20256;&#32479;&#30340;PCA&#26041;&#27861;&#24320;&#22987;&#65292;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#26368;&#22823;&#21270;&#26041;&#24046;&#65292;&#35201;&#20040;&#26368;&#23567;&#21270;&#37325;&#26500;&#35823;&#24046;&#12290;&#25105;&#20204;&#25193;&#23637;&#36825;&#20123;&#35299;&#37322;&#65292;&#36890;&#36807;&#32771;&#34385;&#24322;&#24120;&#20540;&#21644;&#25968;&#25454;&#27969;&#24418;&#65292;&#24320;&#21457;&#20986;&#20102;&#22823;&#37327;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#12290;&#20026;&#20102;&#35774;&#35745;&#19968;&#31181;&#36890;&#29992;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#40065;&#26834;&#21644;&#23545;&#20598;&#24418;&#24335;&#30340;PCA&#37325;&#26032;&#26500;&#24314;&#20026;&#22312;&#26071;&#24092;&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20027;&#27979;&#22320;&#32447;&#36817;&#20284;&#65288;&#20999;&#32447;PCA&#65289;&#25972;&#21512;&#21040;&#36825;&#20010;&#22522;&#20110;&#26071;&#24092;&#30340;&#26694;&#26550;&#20013;&#65292;&#21019;&#36896;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, \ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, crea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#25197;&#26354;&#20989;&#25968;&#23545;Mixup&#25968;&#25454;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23454;&#29616;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#30456;&#20284;&#25968;&#25454;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#36824;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01434</link><description>&lt;p&gt;
&#36890;&#36807;&#26680;&#25197;&#26354;&#20989;&#25968;&#23450;&#21046;Mixup&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#25197;&#26354;&#20989;&#25968;&#23545;Mixup&#25968;&#25454;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23454;&#29616;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#30456;&#20284;&#25968;&#25454;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#36824;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#26159;&#23398;&#20064;&#39640;&#25928;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#37325;&#35201;&#22522;&#30784;&#12290;&#22312;&#25152;&#26377;&#25552;&#20986;&#30340;&#22686;&#24378;&#25216;&#26415;&#20013;&#65292;&#32447;&#24615;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#28857;&#65288;&#20063;&#31216;&#20026;Mixup&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#36873;&#25321;&#21512;&#36866;&#30340;&#28857;&#36827;&#34892;&#28151;&#21512;&#65292;&#25110;&#32773;&#24212;&#29992;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#25554;&#20540;&#65292;&#32780;&#25105;&#20204;&#21017;&#23545;&#26356;&#30456;&#20284;&#30340;&#28857;&#36827;&#34892;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#24863;&#20852;&#36259;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#25197;&#26354;&#20989;&#25968;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#21462;&#20915;&#20110;&#35201;&#32452;&#21512;&#30340;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#39640;&#25928;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#20197;&#36991;&#20813;&#22810;&#26679;&#24615;&#30340;&#25439;&#22833;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26082;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21448;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/ENSTA-U2IS/torch-uncertainty&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data augmentation is an essential building block for learning efficient deep learning models. Among all augmentation techniques proposed so far, linear interpolation of training data points, also called mixup, has found to be effective for a large panel of applications. While the majority of works have focused on selecting the right points to mix, or applying complex non-linear interpolation, we are interested in mixing similar points more frequently and strongly than less similar ones. To this end, we propose to dynamically change the underlying distribution of interpolation coefficients through warping functions, depending on the similarity between data points to combine. We define an efficient and flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves both performance and calibration of models. Code available in https://github.com/ENSTA-U2IS/torch-uncertainty
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30340;&#30446;&#30340;&#26159;&#21033;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#28040;&#38500;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#30340;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#20445;&#25252;&#29305;&#24449;&#23545;&#30149;&#29702;&#39044;&#27979;&#26377;&#26174;&#33879;&#24433;&#21709;&#65292;&#32780;&#24212;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#21487;&#20197;&#28040;&#38500;&#36825;&#20123;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2311.01349</link><description>&lt;p&gt;
&#21462;&#28040;&#20445;&#25252;&#29305;&#24449;&#65306;&#20174;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#28040;&#38500;&#20445;&#25252;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Unreading Race: Purging Protected Features from Chest X-ray Embeddings. (arXiv:2311.01349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01349
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30340;&#30446;&#30340;&#26159;&#21033;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#28040;&#38500;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#30340;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#20445;&#25252;&#29305;&#24449;&#23545;&#30149;&#29702;&#39044;&#27979;&#26377;&#26174;&#33879;&#24433;&#21709;&#65292;&#32780;&#24212;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#21487;&#20197;&#28040;&#38500;&#36825;&#20123;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#20998;&#26512;&#24182;&#28040;&#38500;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#30340;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#12290;&#26041;&#27861;&#65306;&#20351;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#28040;&#38500;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#30340;&#20445;&#25252;&#29305;&#24449;&#65288;&#22914;&#24180;&#40836;&#12289;&#24615;&#21035;&#12289;&#31181;&#26063;&#65289;&#30340;&#24433;&#21709;&#65292;&#30830;&#20445;&#29305;&#24449;&#29420;&#31435;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#39564;&#35777;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#20351;&#29992;&#19977;&#20010;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#26377;&#30417;&#30563;&#23545;&#27604;&#12289;&#33258;&#30417;&#30563;&#23545;&#27604;&#21644;&#22522;&#32447;&#20998;&#31867;&#22120;&#27169;&#22411;&#65289;&#23545;MIMIC&#21644;CheXpert&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22238;&#39038;&#24615;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32479;&#35745;&#20998;&#26512;&#28041;&#21450;&#36890;&#36807;&#20272;&#35745;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#21644;&#35780;&#20272;&#20351;&#29992;&#20004;&#31181;&#31867;&#22411;&#23884;&#20837;&#30340;&#33021;&#21147;&#26469;&#39044;&#27979;&#31181;&#26063;&#12289;&#24180;&#40836;&#25110;&#24615;&#21035;&#30340;&#21407;&#22987;&#19982;&#27491;&#20132;&#23884;&#20837;&#30340;&#27604;&#36739;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#20445;&#25252;&#29305;&#24449;&#23545;&#30149;&#29702;&#39044;&#27979;&#30340;&#26174;&#30528;&#24433;&#21709;&#12290;&#24212;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#21487;&#20197;&#28040;&#38500;&#36825;&#20123;&#29305;&#24449;&#24433;&#21709;&#12290;&#38500;&#20102;&#28040;&#38500;&#23545;&#30149;&#29702;&#20998;&#31867;&#30340;&#24433;&#21709;&#20043;&#22806;&#65292;
&lt;/p&gt;
&lt;p&gt;
Purpose: To analyze and remove protected feature effects in chest radiograph embeddings of deep learning models.  Materials and Methods: An orthogonalization is utilized to remove the influence of protected features (e.g., age, sex, race) in chest radiograph embeddings, ensuring feature-independent results. To validate the efficacy of the approach, we retrospectively study the MIMIC and CheXpert datasets using three pre-trained models, namely a supervised contrastive, a self-supervised contrastive, and a baseline classifier model. Our statistical analysis involves comparing the original versus the orthogonalized embeddings by estimating protected feature influences and evaluating the ability to predict race, age, or sex using the two types of embeddings.  Results: Our experiments reveal a significant influence of protected features on predictions of pathologies. Applying orthogonalization removes these feature effects. Apart from removing any influence on pathology classification, whil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2310.17467</link><description>&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#35745;&#28909;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#24778;&#20154;&#30340;&#34920;&#29616;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#30340;&#22522;&#26412;&#24605;&#24819;&#26469;&#33258;&#38750;&#24179;&#34913;&#29289;&#29702;&#23398;&#65292;&#20294;&#26412;&#25991;&#20013;&#25105;&#20204;&#34920;&#26126;&#65292;&#21487;&#20197;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#26469;&#29702;&#35299;&#36825;&#20123;&#27169;&#22411;&#30340;&#35768;&#22810;&#26041;&#38754;&#12290;&#21033;&#29992;&#36825;&#31181;&#37325;&#26500;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#32463;&#21382;&#20102;&#19982;&#23545;&#31216;&#24615;&#30772;&#32570;&#29616;&#35937;&#30456;&#23545;&#24212;&#30340;&#20108;&#38454;&#30456;&#21464;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#65292;&#23427;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#26680;&#24515;&#65292;&#24182;&#21487;&#20197;&#29992;&#19968;&#32452;&#24179;&#22343;&#22330;&#20020;&#30028;&#25351;&#25968;&#26469;&#25551;&#36848;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#28909;&#21147;&#23398;&#30340;&#20844;&#24335;&#20998;&#26512;&#20102;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#20851;&#32852;&#35760;&#24518;&#32593;&#32476;&#36830;&#25509;&#30340;&#26368;&#36817;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative diffusion models have achieved spectacular performance in many areas of generative modeling. While the fundamental ideas behind these models come from non-equilibrium physics, in this paper we show that many aspects of these models can be understood using the tools of equilibrium statistical mechanics. Using this reformulation, we show that generative diffusion models undergo second-order phase transitions corresponding to symmetry breaking phenomena. We argue that this lead to a form of instability that lies at the heart of their generative capabilities and that can be described by a set of mean field critical exponents. We conclude by analyzing recent work connecting diffusion models and associative memory networks in view of the thermodynamic formulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.13786</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental Limits of Membership Inference Attacks on Machine Learning Models. (arXiv:2310.13786v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21253;&#25324;&#25512;&#23548;&#20102;&#25928;&#26524;&#21644;&#25104;&#21151;&#29575;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#25552;&#20379;&#20102;&#20960;&#31181;&#24773;&#20917;&#19979;&#30340;&#30028;&#38480;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIA&#65289;&#21487;&#20197;&#25581;&#31034;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#26159;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#33021;&#26292;&#38706;&#20010;&#20154;&#30340;&#25935;&#24863;&#20449;&#24687;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19978;MIA&#30340;&#22522;&#26412;&#32479;&#35745;&#38480;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20102;&#32479;&#35745;&#37327;&#65292;&#35813;&#32479;&#35745;&#37327;&#20915;&#23450;&#20102;&#36825;&#31181;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#21644;&#25104;&#21151;&#29575;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20960;&#31181;&#24773;&#20917;&#65292;&#24182;&#23545;&#36825;&#20010;&#24863;&#20852;&#36259;&#30340;&#32479;&#35745;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25968;&#37327;&#21644;&#23398;&#20064;&#27169;&#22411;&#30340;&#20854;&#20182;&#32467;&#26500;&#21442;&#25968;&#25512;&#26029;&#28508;&#22312;&#25915;&#20987;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Membership inference attacks (MIA) can reveal whether a particular data point was part of the training dataset, potentially exposing sensitive information about individuals. This article explores the fundamental statistical limitations associated with MIAs on machine learning models. More precisely, we first derive the statistical quantity that governs the effectiveness and success of such attacks. Then, we investigate several situations for which we provide bounds on this quantity of interest. This allows us to infer the accuracy of potential attacks as a function of the number of samples and other structural parameters of learning models, which in some cases can be directly estimated from the dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35889;&#20272;&#35745;&#22120;&#36827;&#34892;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#27979;&#37327;&#36827;&#34892;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#34920;&#31034;&#65292;&#20998;&#26512;&#20102;&#35889;&#20272;&#35745;&#22120;&#22312;&#32467;&#26500;&#21270;&#35774;&#35745;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#30830;&#23450;&#20102;&#26368;&#20248;&#39044;&#22788;&#29702;&#20197;&#26368;&#23567;&#21270;&#26679;&#26412;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.14507</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#23454;&#29616;&#32467;&#26500;&#21270;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#35889;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Spectral Estimators for Structured Generalized Linear Models via Approximate Message Passing. (arXiv:2308.14507v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14507
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35889;&#20272;&#35745;&#22120;&#36827;&#34892;&#39044;&#22788;&#29702;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#27979;&#37327;&#36827;&#34892;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#34920;&#31034;&#65292;&#20998;&#26512;&#20102;&#35889;&#20272;&#35745;&#22120;&#22312;&#32467;&#26500;&#21270;&#35774;&#35745;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#30830;&#23450;&#20102;&#26368;&#20248;&#39044;&#22788;&#29702;&#20197;&#26368;&#23567;&#21270;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#35266;&#27979;&#20013;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#35889;&#26041;&#27861;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#65306;&#23427;&#36890;&#36807;&#23545;&#35266;&#27979;&#36827;&#34892;&#36866;&#24403;&#39044;&#22788;&#29702;&#24471;&#21040;&#30340;&#30697;&#38453;&#30340;&#20027;&#29305;&#24449;&#21521;&#37327;&#26469;&#20272;&#35745;&#21442;&#25968;&#12290;&#23613;&#31649;&#35889;&#20272;&#35745;&#22120;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#23545;&#20110;&#32467;&#26500;&#21270;&#65288;&#21363;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#21644;&#21704;&#23572;&#65289;&#35774;&#35745;&#65292;&#30446;&#21069;&#20165;&#26377;&#23545;&#35889;&#20272;&#35745;&#22120;&#30340;&#20005;&#26684;&#24615;&#33021;&#34920;&#24449;&#20197;&#21450;&#23545;&#25968;&#25454;&#36827;&#34892;&#39044;&#22788;&#29702;&#30340;&#22522;&#26412;&#26041;&#27861;&#21487;&#29992;&#12290;&#30456;&#21453;&#65292;&#23454;&#38469;&#30340;&#35774;&#35745;&#30697;&#38453;&#20855;&#26377;&#39640;&#24230;&#32467;&#26500;&#21270;&#24182;&#19988;&#34920;&#29616;&#20986;&#38750;&#24179;&#20961;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#25429;&#25417;&#27979;&#37327;&#30340;&#38750;&#21508;&#21521;&#21516;&#24615;&#29305;&#24615;&#30340;&#30456;&#20851;&#39640;&#26031;&#35774;&#35745;&#65292;&#36890;&#36807;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#931;&#36827;&#34892;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#23545;&#20110;&#36825;&#31181;&#24773;&#20917;&#19979;&#35889;&#20272;&#35745;&#22120;&#24615;&#33021;&#30340;&#31934;&#30830;&#28176;&#36817;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#21487;&#20197;&#36890;&#36807;&#36825;&#19968;&#32467;&#26524;&#26469;&#30830;&#23450;&#26368;&#20248;&#39044;&#22788;&#29702;&#65292;&#20174;&#32780;&#26368;&#23567;&#21270;&#25152;&#38656;&#26679;&#26412;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of parameter estimation from observations given by a generalized linear model. Spectral methods are a simple yet effective approach for estimation: they estimate the parameter via the principal eigenvector of a matrix obtained by suitably preprocessing the observations. Despite their wide use, a rigorous performance characterization of spectral estimators, as well as a principled way to preprocess the data, is available only for unstructured (i.e., i.i.d. Gaussian and Haar) designs. In contrast, real-world design matrices are highly structured and exhibit non-trivial correlations. To address this problem, we consider correlated Gaussian designs which capture the anisotropic nature of the measurements via a feature covariance matrix $\Sigma$. Our main result is a precise asymptotic characterization of the performance of spectral estimators in this setting. This then allows to identify the optimal preprocessing that minimizes the number of samples needed to meanin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#12290;&#35813;&#26041;&#27861;&#23558;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#20854;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#29575;&#30456;&#20851;&#32852;&#65292;&#24182;&#25552;&#20379;&#20102;&#20381;&#36182;&#20110;&#32463;&#39564;&#20998;&#24067;&#32780;&#38750;&#26410;&#30693;&#20998;&#24067;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#25512;&#23548;&#20986;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#20551;&#35774;&#38543;&#26426;&#21464;&#37327;&#30340;&#20219;&#20309;&#20989;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#21253;&#21547;&#24182;&#21487;&#33021;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;PAC-Bayes&#21644;&#25968;&#25454;&#30456;&#20851;&#20869;&#22312;&#32500;&#24230;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.05369</link><description>&lt;p&gt;
&#36890;&#36807;&#21487;&#21464;&#22823;&#23567;&#30340;&#21387;&#32553;&#24615;&#24314;&#31435;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Data-dependent Generalization Bounds via Variable-Size Compressibility. (arXiv:2303.05369v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#24615;&#26694;&#26550;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#30028;&#12290;&#35813;&#26041;&#27861;&#23558;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#20854;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#29575;&#30456;&#20851;&#32852;&#65292;&#24182;&#25552;&#20379;&#20102;&#20381;&#36182;&#20110;&#32463;&#39564;&#20998;&#24067;&#32780;&#38750;&#26410;&#30693;&#20998;&#24067;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#36824;&#21487;&#20197;&#25512;&#23548;&#20986;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#20551;&#35774;&#38543;&#26426;&#21464;&#37327;&#30340;&#20219;&#20309;&#20989;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#21253;&#21547;&#24182;&#21487;&#33021;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;PAC-Bayes&#21644;&#25968;&#25454;&#30456;&#20851;&#20869;&#22312;&#32500;&#24230;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#8220;&#21487;&#21464;&#22823;&#23567;&#21387;&#32553;&#24615;&#8221;&#26694;&#26550;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#30456;&#20851;&#27867;&#21270;&#35823;&#24046;&#30340;&#19978;&#30028;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#20854;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#22823;&#23567;&#8220;&#21387;&#32553;&#29575;&#8221;&#30456;&#20851;&#32852;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#24471;&#21040;&#30340;&#30028;&#38480;&#20381;&#36182;&#20110;&#25163;&#22836;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#30340;&#32463;&#39564;&#20998;&#24067;&#65292;&#32780;&#19981;&#26159;&#20854;&#26410;&#30693;&#20998;&#24067;&#12290;&#25105;&#20204;&#24314;&#31435;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#21253;&#25324;&#23614;&#37096;&#30028;&#38480;&#12289;&#26399;&#26395;&#20540;&#30340;&#23614;&#37096;&#30028;&#38480;&#21644;&#26399;&#26395;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36824;&#21487;&#20197;&#25512;&#23548;&#20986;&#23545;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#20551;&#35774;&#38543;&#26426;&#21464;&#37327;&#30340;&#20219;&#20309;&#20989;&#25968;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20123;&#27867;&#21270;&#30028;&#38480;&#21253;&#21547;&#24182;&#21487;&#33021;&#20248;&#20110;&#20960;&#31181;&#29616;&#26377;&#30340;&#22522;&#20110;PAC-Bayes&#21644;&#25968;&#25454;&#30456;&#20851;&#20869;&#22312;&#32500;&#24230;&#30340;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#24471;&#21040;&#22797;&#21407;&#65292;&#20174;&#32780;&#25581;&#31034;&#20986;&#25105;&#20204;&#26041;&#27861;&#30340;&#32479;&#19968;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we establish novel data-dependent upper bounds on the generalization error through the lens of a "variable-size compressibility" framework that we introduce newly here. In this framework, the generalization error of an algorithm is linked to a variable-size 'compression rate' of its input data. This is shown to yield bounds that depend on the empirical measure of the given input data at hand, rather than its unknown distribution. Our new generalization bounds that we establish are tail bounds, tail bounds on the expectation, and in-expectations bounds. Moreover, it is shown that our framework also allows to derive general bounds on any function of the input data and output hypothesis random variables. In particular, these general bounds are shown to subsume and possibly improve over several existing PAC-Bayes and data-dependent intrinsic dimension-based bounds that are recovered as special cases, thus unveiling a unifying character of our approach. For instance, a new da
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.14960</link><description>&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#30340;&#26631;&#31614;&#23545;&#40784;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Label Alignment Regularization for Distribution Shift. (arXiv:2211.14960v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14960
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#23545;&#40784;&#23646;&#24615;&#65288;LAP&#65289;&#65292;&#21363;&#25968;&#25454;&#38598;&#20013;&#25152;&#26377;&#26631;&#31614;&#30340;&#21521;&#37327;&#22823;&#37096;&#20998;&#22312;&#25968;&#25454;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#12290;&#21463;&#21040;&#36825;&#19968;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#12290;&#19982;&#20256;&#32479;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#19987;&#27880;&#20110;&#27491;&#21017;&#21270;&#34920;&#31034;&#19981;&#21516;&#65292;&#25105;&#20204;&#30456;&#21453;&#65292;&#36890;&#36807;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#20351;&#29992;LAP&#65292;&#29992;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#19968;&#23450;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#20301;&#20110;&#30446;&#26631;&#22495;&#25968;&#25454;&#30340;&#21069;&#20960;&#20010;&#21491;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#65292;&#24182;&#19982;&#26368;&#20248;&#35299;&#23545;&#40784;&#12290;&#36890;&#36807;&#28040;&#38500;&#32463;&#20856;&#39046;&#22495;&#36866;&#24212;&#29702;&#35770;&#20013;&#24120;&#35265;&#30340;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has highlighted the label alignment property (LAP) in supervised learning, where the vector of all labels in the dataset is mostly in the span of the top few singular vectors of the data matrix. Drawing inspiration from this observation, we propose a regularization method for unsupervised domain adaptation that encourages alignment between the predictions in the target domain and its top singular vectors. Unlike conventional domain adaptation approaches that focus on regularizing representations, we instead regularize the classifier to align with the unsupervised target data, guided by the LAP in both the source and target domains. Theoretical analysis demonstrates that, under certain assumptions, our solution resides within the span of the top right singular vectors of the target domain data and aligns with the optimal solution. By removing the reliance on the commonly used optimal joint risk assumption found in classic domain adaptation theory, we showcase the effectivene
&lt;/p&gt;</description></item></channel></rss>