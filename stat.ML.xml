<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#27979;&#37327;&#28508;&#22312;&#32467;&#26524;&#22312;&#23384;&#22312;&#25110;&#32570;&#20047;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#30340;&#23614;&#37096;&#34928;&#20943;&#29575;&#21464;&#21270;&#65292;&#26469;&#20272;&#35745;&#26497;&#31471;&#29615;&#22659;&#19979;&#30340;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE$_2$&#65289;&#12290;</title><link>http://arxiv.org/abs/2306.11697</link><description>&lt;p&gt;
&#26497;&#31471;&#29615;&#22659;&#19979;&#30340;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Individual Treatment Effects in Extreme Regimes. (arXiv:2306.11697v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#27979;&#37327;&#28508;&#22312;&#32467;&#26524;&#22312;&#23384;&#22312;&#25110;&#32570;&#20047;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#30340;&#23614;&#37096;&#34928;&#20943;&#29575;&#21464;&#21270;&#65292;&#26469;&#20272;&#35745;&#26497;&#31471;&#29615;&#22659;&#19979;&#30340;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE$_2$&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;&#26497;&#31471;&#29615;&#22659;&#19979;&#30340;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#23545;&#20110;&#25551;&#36848;&#19981;&#21516;&#24178;&#39044;&#31574;&#30053;&#30340;&#39118;&#38505;&#33267;&#20851;&#37325;&#35201;&#12290;&#20294;&#26497;&#31471;&#29615;&#22659;&#25968;&#25454;&#24456;&#38590;&#25910;&#38598;&#65292;&#22240;&#20026;&#23427;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#34987;&#35266;&#23519;&#21040;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#26469;&#20272;&#35745;&#26497;&#31471;&#29615;&#22659;&#19979;&#30340;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE$_2$&#65289;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#28508;&#22312;&#32467;&#26524;&#22312;&#23384;&#22312;&#25110;&#32570;&#20047;&#27835;&#30103;&#30340;&#24773;&#20917;&#19979;&#30340;&#23614;&#37096;&#34928;&#20943;&#29575;&#21464;&#21270;&#26469;&#37327;&#21270;&#36825;&#31181;&#25928;&#26524;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102; ITE$_2$ &#30340;&#35745;&#31639;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#35745;&#31639;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding individual treatment effects in extreme regimes is important for characterizing risks associated with different interventions. This is hindered by the fact that extreme regime data may be hard to collect, as it is scarcely observed in practice. In addressing this issue, we propose a new framework for estimating the individual treatment effect in extreme regimes (ITE$_2$). Specifically, we quantify this effect by the changes in the tail decay rates of potential outcomes in the presence or absence of the treatment. Subsequently, we establish conditions under which ITE$_2$ may be calculated and develop algorithms for its computation. We demonstrate the efficacy of our proposed method on various synthetic and semi-synthetic datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#25913;&#21892;&#20154;&#31867;&#20915;&#31574;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#19982;&#26426;&#22120;&#39044;&#27979;&#65292;&#26367;&#25442;&#37096;&#20998;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#32463;&#36807;&#23454;&#39564;&#26816;&#39564;&#24471;&#20986;&#31639;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#30495;&#38451;&#24615;&#29575;&#21644;&#26356;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20892;&#26449;&#22320;&#21306;&#30340;&#21307;&#29983;&#30340;&#35786;&#26029;&#26356;&#23481;&#26131;&#34987;&#26367;&#20195;&#12290;</title><link>http://arxiv.org/abs/2306.11689</link><description>&lt;p&gt;
&#32479;&#35745;&#27979;&#35797;&#26367;&#20195;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Statistical Tests for Replacing Human Decision Makers with Algorithms. (arXiv:2306.11689v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#25913;&#21892;&#20154;&#31867;&#20915;&#31574;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#36890;&#36807;&#22522;&#20934;&#27979;&#35797;&#19982;&#26426;&#22120;&#39044;&#27979;&#65292;&#26367;&#25442;&#37096;&#20998;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#20915;&#31574;&#21046;&#23450;&#65292;&#24182;&#32463;&#36807;&#23454;&#39564;&#26816;&#39564;&#24471;&#20986;&#31639;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#30495;&#38451;&#24615;&#29575;&#21644;&#26356;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#23588;&#20854;&#26159;&#26469;&#33258;&#20892;&#26449;&#22320;&#21306;&#30340;&#21307;&#29983;&#30340;&#35786;&#26029;&#26356;&#23481;&#26131;&#34987;&#26367;&#20195;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#20154;&#24037;&#26234;&#33021;&#26469;&#25913;&#21892;&#20154;&#31867;&#30340;&#20915;&#31574;&#12290;&#39318;&#20808;&#23558;&#27599;&#20010;&#20154;&#31867;&#20915;&#31574;&#32773;&#30340;&#34920;&#29616;&#19982;&#26426;&#22120;&#39044;&#27979;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#65307;&#28982;&#21518;&#29992;&#25152;&#25552;&#20986;&#30340;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#30340;&#24314;&#35758;&#26367;&#25442;&#20915;&#31574;&#21046;&#23450;&#32773;&#30340;&#19968;&#20010;&#23376;&#38598;&#25152;&#20570;&#20986;&#30340;&#20915;&#31574;&#12290;&#21033;&#29992;&#20840;&#22269;&#22823;&#22411;&#23381;&#20135;&#32467;&#26524;&#21644;&#32321;&#27542;&#24180;&#40836;&#22827;&#22919;&#23381;&#21069;&#26816;&#26597;&#30340;&#21307;&#29983;&#35786;&#26029;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35797;&#39564;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#39640;&#39057;&#29575;&#26041;&#27861;&#20197;&#21450;&#19968;&#31181;&#36125;&#21494;&#26031;&#21518;&#39564;&#25439;&#22833;&#20989;&#25968;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#24322;&#24120;&#20986;&#29983;&#26816;&#27979;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#20010;&#27979;&#35797;&#25968;&#25454;&#38598;&#19978;&#30340;&#32467;&#26524;&#27604;&#20165;&#30001;&#21307;&#29983;&#35786;&#26029;&#30340;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#24635;&#20307;&#30495;&#38451;&#24615;&#29575;&#21644;&#26356;&#20302;&#30340;&#20551;&#38451;&#24615;&#29575;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#26469;&#33258;&#20892;&#26449;&#22320;&#21306;&#30340;&#21307;&#29983;&#30340;&#35786;&#26029;&#26356;&#23481;&#26131;&#34987;&#26367;&#20195;&#65292;&#36825;&#34920;&#26126;&#20154;&#24037;&#26234;&#33021;&#36741;&#21161;&#20915;&#31574;&#21046;&#23450;&#26356;&#23481;&#26131;&#25552;&#39640;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a statistical framework with which artificial intelligence can improve human decision making. The performance of each human decision maker is first benchmarked against machine predictions; we then replace the decisions made by a subset of the decision makers with the recommendation from the proposed artificial intelligence algorithm. Using a large nationwide dataset of pregnancy outcomes and doctor diagnoses from prepregnancy checkups of reproductive age couples, we experimented with both a heuristic frequentist approach and a Bayesian posterior loss function approach with an application to abnormal birth detection. We find that our algorithm on a test dataset results in a higher overall true positive rate and a lower false positive rate than the diagnoses made by doctors only. We also find that the diagnoses of doctors from rural areas are more frequently replaceable, suggesting that artificial intelligence assisted decision making tends to improve precision more i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#25209;&#35268;&#33539;&#21270;&#35757;&#32451;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#32447;&#24615;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26102;&#30340;&#38544;&#24335;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#25209;&#35268;&#33539;&#21270;&#23545;&#20110;&#22343;&#21248;&#38388;&#38548;&#20855;&#26377;&#38544;&#21547;&#20559;&#24046;&#12290;&#36890;&#36807;&#20004;&#20010;&#20363;&#23376;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#29305;&#23450;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#22343;&#21248;&#38388;&#38548;&#20998;&#31867;&#22120;&#30340;&#34920;&#29616;&#29978;&#33267;&#20248;&#20110;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#12290;</title><link>http://arxiv.org/abs/2306.11680</link><description>&lt;p&gt;
&#25209;&#35268;&#33539;&#21270;&#22312;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#32447;&#24615;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
The Implicit Bias of Batch Normalization in Linear Models and Two-layer Linear Convolutional Neural Networks. (arXiv:2306.11680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#25209;&#35268;&#33539;&#21270;&#35757;&#32451;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#32447;&#24615;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26102;&#30340;&#38544;&#24335;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#25209;&#35268;&#33539;&#21270;&#23545;&#20110;&#22343;&#21248;&#38388;&#38548;&#20855;&#26377;&#38544;&#21547;&#20559;&#24046;&#12290;&#36890;&#36807;&#20004;&#20010;&#20363;&#23376;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#29305;&#23450;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#22343;&#21248;&#38388;&#38548;&#20998;&#31867;&#22120;&#30340;&#34920;&#29616;&#29978;&#33267;&#20248;&#20110;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30001;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#25209;&#35268;&#33539;&#21270;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#20351;&#29992;&#25209;&#35268;&#33539;&#21270;&#35757;&#32451;&#20108;&#20998;&#31867;&#32447;&#24615;&#27169;&#22411;&#26102;&#65292;&#26799;&#24230;&#19979;&#38477;&#20250;&#25910;&#25947;&#21040;&#19968;&#20010;&#20855;&#26377;&#22343;&#21248;&#38388;&#38548;&#30340;&#20998;&#31867;&#22120;&#65292;&#25910;&#25947;&#36895;&#24230;&#20026;$\exp&#65288;- \Omega&#65288;\log ^ 2 t&#65289;&#65289;$&#12290;&#36825;&#23558;&#25209;&#35268;&#33539;&#21270;&#30340;&#32447;&#24615;&#27169;&#22411;&#19982;&#19981;&#20351;&#29992;&#25209;&#35268;&#33539;&#21270;&#30340;&#27169;&#22411;&#21306;&#20998;&#24320;&#26469;&#65292;&#20854;&#38544;&#21547;&#20559;&#24046;&#21644;&#25910;&#25947;&#36895;&#24230;&#22343;&#19981;&#21516;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;&#19968;&#31867;&#20004;&#23618;&#21333;&#28388;&#27874;&#22120;&#32447;&#24615;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24182;&#34920;&#26126;&#25209;&#35268;&#33539;&#21270;&#23545;&#20110;&#22343;&#21248;&#38388;&#38548;&#20855;&#26377;&#38544;&#21547;&#20559;&#24046;&#12290;&#36890;&#36807;&#20004;&#20010;&#20363;&#23376;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29305;&#23450;&#23398;&#20064;&#38382;&#39064;&#20013;&#22343;&#21248;&#38388;&#38548;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#21487;&#20197;&#20248;&#20110;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#26356;&#22909;&#22320;&#29702;&#35299;&#25209;&#35268;&#33539;&#21270;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the implicit bias of batch normalization trained by gradient descent. We show that when learning a linear model with batch normalization for binary classification, gradient descent converges to a uniform margin classifier on the training data with an $\exp(-\Omega(\log^2 t))$ convergence rate. This distinguishes linear models with batch normalization from those without batch normalization in terms of both the type of implicit bias and the convergence rate. We further extend our result to a class of two-layer, single-filter linear convolutional neural networks, and show that batch normalization has an implicit bias towards a patch-wise uniform margin. Based on two examples, we demonstrate that patch-wise uniform margin classifiers can outperform the maximum margin classifiers in certain learning problems. Our results contribute to a better theoretical understanding of batch normalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#21407;&#21017;&#26469;&#25351;&#23548;ReLU&#28608;&#27963;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#26550;&#26500;&#36873;&#25321;&#65292;&#20854;&#20013;&#20851;&#38190;&#22312;&#20110;&#20351;&#29992;&#27531;&#24046;&#32858;&#21512;&#31639;&#23376;&#21487;&#20197;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#65292;&#20351;&#29992;&#20462;&#22797;&#22411;&#21021;&#22987;&#21270;&#30340;&#27531;&#24046;&#36830;&#25509;&#21487;&#20197;&#36991;&#20813;&#26368;&#32456;&#23618;&#29305;&#24449;&#30340;&#30456;&#20851;&#23849;&#28291;&#12290;</title><link>http://arxiv.org/abs/2306.11668</link><description>&lt;p&gt;
ReLU&#28608;&#27963;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#26550;&#26500;&#36873;&#25321;&#30340;&#21407;&#21017;
&lt;/p&gt;
&lt;p&gt;
Principles for Initialization and Architecture Selection in Graph Neural Networks with ReLU Activations. (arXiv:2306.11668v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#21407;&#21017;&#26469;&#25351;&#23548;ReLU&#28608;&#27963;&#19979;&#22270;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#21644;&#26550;&#26500;&#36873;&#25321;&#65292;&#20854;&#20013;&#20851;&#38190;&#22312;&#20110;&#20351;&#29992;&#27531;&#24046;&#32858;&#21512;&#31639;&#23376;&#21487;&#20197;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#65292;&#20351;&#29992;&#20462;&#22797;&#22411;&#21021;&#22987;&#21270;&#30340;&#27531;&#24046;&#36830;&#25509;&#21487;&#20197;&#36991;&#20813;&#26368;&#32456;&#23618;&#29305;&#24449;&#30340;&#30456;&#20851;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#26377;&#38480;&#23485;&#24230;&#30340;ReLU&#28608;&#27963;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#20013;&#25512;&#23548;&#24182;&#39564;&#35777;&#20102;&#19977;&#20010;&#21021;&#22987;&#21270;&#21644;&#26550;&#26500;&#36873;&#25321;&#30340;&#21407;&#21017;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#25512;&#23548;&#20102;ReLU GNNs He&#21021;&#22987;&#21270;&#30340;&#26412;&#36136;&#21807;&#19968;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#21270;&#26041;&#26696;&#20445;&#35777;&#20102;&#21021;&#22987;&#21270;&#26102;&#32593;&#32476;&#36755;&#20986;&#21644;&#26799;&#24230;&#30340;&#24179;&#22343;&#35268;&#27169;&#20445;&#25345;&#20026;&#19968;&#38454;&#12290;&#20854;&#27425;&#65292;&#22312;&#26377;&#38480;&#23485;&#24230;&#30340;vanilla ReLU GNNs&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;&#22266;&#23450;&#32858;&#21512;&#31639;&#23376;&#26102;&#65292;&#22312;&#22823;&#28145;&#24230;&#19978;&#36807;&#24230;&#24179;&#28369;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#26080;&#35770;&#21021;&#22987;&#21270;&#22914;&#20309;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;&#27531;&#24046;&#32858;&#21512;&#31639;&#23376;&#65292;&#36890;&#36807;&#25554;&#20540;&#22266;&#23450;&#32858;&#21512;&#31639;&#23376;&#21644;&#24658;&#31561;&#31639;&#23376;&#26469;&#33719;&#24471;&#65292;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#26377;&#25928;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#20462;&#22797;&#22411;&#21021;&#22987;&#21270;&#30340;&#27531;&#24046;&#36830;&#25509;&#24120;&#35268;&#20570;&#27861;&#65292;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#21512;&#29702;&#36991;&#20813;&#26368;&#32456;&#23618;&#29305;&#24449;&#30340;&#30456;&#20851;&#23849;&#28291;&#12290;&#36890;&#36807;&#28040;&#34701;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;GNNs&#20013;&#65292;&#20462;&#22797;&#22411;&#21021;&#22987;&#21270;+&#27531;&#24046;&#36830;&#25509;&#26159;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article derives and validates three principles for initialization and architecture selection in finite width graph neural networks (GNNs) with ReLU activations. First, we theoretically derive what is essentially the unique generalization to ReLU GNNs of the well-known He-initialization. Our initialization scheme guarantees that the average scale of network outputs and gradients remains order one at initialization. Second, we prove in finite width vanilla ReLU GNNs that oversmoothing is unavoidable at large depth when using fixed aggregation operator, regardless of initialization. We then prove that using residual aggregation operators, obtained by interpolating a fixed aggregation operator with the identity, provably alleviates oversmoothing at initialization. Finally, we show that the common practice of using residual connections with a fixup-type initialization provably avoids correlation collapse in final layer features at initialization. Through ablation studies we find that u
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#24494;&#20998;&#28436;&#31639;&#25506;&#35752;&#31639;&#27861;&#31283;&#20581;&#24615;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#24471;&#20986;&#20102;&#24191;&#20041;&#35823;&#24046;&#30340;&#25910;&#25947;&#36895;&#29575;&#20026;$\mathcal{O}(1/n)$&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.11623</link><description>&lt;p&gt;
&#24179;&#22343;&#22330;&#20998;&#26512;&#24191;&#20041;&#21270;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Mean-field Analysis of Generalization Errors. (arXiv:2306.11623v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11623
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#24494;&#20998;&#28436;&#31639;&#25506;&#35752;&#31639;&#27861;&#31283;&#20581;&#24615;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#24471;&#20986;&#20102;&#24191;&#20041;&#35823;&#24046;&#30340;&#25910;&#25947;&#36895;&#29575;&#20026;$\mathcal{O}(1/n)$&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#24494;&#20998;&#28436;&#31639;&#65292;&#25506;&#35752;&#31639;&#27861;&#30340;&#24369;&#31283;&#20581;&#24615;&#19982;$L_2$&#27491;&#21017;&#21270;&#35823;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;KL&#27491;&#21017;&#21270;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#65292;&#20351;&#24471;&#24403;&#26679;&#26412;&#23481;&#37327;&#20026;$n$&#26102;&#65292;&#24191;&#20041;&#35823;&#24046;&#25910;&#25947;&#36895;&#29575;&#20026;$\mathcal{O}(1/n)$&#12290;&#22312;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#22330;&#21306;&#22495;&#30340;&#30417;&#30563;&#23398;&#20064;&#32972;&#26223;&#19979;&#65292;&#36825;&#20123;&#26465;&#20214;&#20307;&#29616;&#22312;&#23545;&#25439;&#22833;&#21644;&#28608;&#27963;&#20989;&#25968;&#30340;&#21512;&#36866;&#21487;&#31215;&#21644;&#27491;&#21017;&#24615;&#20551;&#35774;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for exploring weak and $L_2$ generalization errors of algorithms through the lens of differential calculus on the space of probability measures. Specifically, we consider the KL-regularized empirical risk minimization problem and establish generic conditions under which the generalization error convergence rate, when training on a sample of size $n$, is $\mathcal{O}(1/n)$. In the context of supervised learning with a one-hidden layer neural network in the mean-field regime, these conditions are reflected in suitable integrability and regularity assumptions on the loss and activation functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35745;&#31639;&#39640;&#25928;&#19988;&#33021;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2306.11589</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent. (arXiv:2306.11589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35745;&#31639;&#39640;&#25928;&#19988;&#33021;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#29992;&#20110;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#21644;&#39034;&#24207;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#65292;&#20294;&#20854;&#38656;&#35201;&#27714;&#35299;&#32447;&#24615;&#31995;&#32479;&#65292;&#27599;&#24403;&#25968;&#25454;&#38598;&#22823;&#23567;&#22686;&#21152;&#26102;&#20195;&#20215;&#26159;&#31435;&#26041;&#32423;&#21035;&#30340;&#19988;&#23545;&#26465;&#20214;&#25935;&#24863;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#20316;&#20026;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#36825;&#20123;&#32447;&#24615;&#31995;&#32479;&#65306;&#25105;&#20204;&#24320;&#21457;&#20102;&#20302;&#26041;&#24046;&#30340;&#26368;&#20248;&#21270;&#30446;&#26631;&#20197;&#20174;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#23558;&#20854;&#25193;&#23637;&#21040;&#24341;&#20837;&#28857;&#12290;&#20196;&#20154;&#24847;&#24819;&#19981;&#21040;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#19981;&#24555;&#36895;&#25910;&#25947;&#21040;&#26368;&#20248;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36890;&#24120;&#20063;&#20250;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#38750;&#25910;&#25947;&#30340;&#38544;&#24335;&#20559;&#32622;&#30340;&#35889;&#29305;&#24449;&#26469;&#35299;&#37322;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20250;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#20102;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves sta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24322;&#26041;&#24046;&#25968;&#25454;&#30340;CI&#27979;&#35797;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19987;&#23478;&#30693;&#35782;&#30340;&#24110;&#21161;&#19979;&#39640;&#25928;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#65292;&#19988;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#25928;&#26524;&#20248;&#20110;&#26631;&#20934;&#27979;&#35797;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.11498</link><description>&lt;p&gt;
&#26377;&#20851;&#24322;&#26041;&#24046;&#25968;&#25454;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#21450;&#20854;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Conditional Independence Testing with Heteroskedastic Data and Applications to Causal Discovery. (arXiv:2306.11498v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24322;&#26041;&#24046;&#25968;&#25454;&#30340;CI&#27979;&#35797;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19987;&#23478;&#30693;&#35782;&#30340;&#24110;&#21161;&#19979;&#39640;&#25928;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#65292;&#19988;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#25928;&#26524;&#20248;&#20110;&#26631;&#20934;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29420;&#31435;&#24615;(CI)&#26816;&#39564;&#26159;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#21508;&#23398;&#31185;&#30340;&#39057;&#32321;&#20351;&#29992;&#26041;&#27861;&#65292;&#20063;&#26159;&#22522;&#20110;&#32422;&#26463;&#26465;&#20214;&#30340;&#22240;&#26524;&#21457;&#29616;&#30340;&#22522;&#30784;&#12290;&#20294;&#26159;&#65292;CI&#27979;&#35797;&#32463;&#24120;&#20381;&#36182;&#20110;&#24378;&#28872;&#32780;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#20043;&#19968;&#65306;&#21516;&#26041;&#24046;&#24615;&#65292;&#20063;&#23601;&#26159;&#20551;&#23450;&#23384;&#22312;&#24120;&#25968;&#26465;&#20214;&#26041;&#24046;&#12290;&#25105;&#20204;&#23558;&#24322;&#26041;&#24046;&#24615;&#25918;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#26694;&#26550;&#20013;&#65292;&#24182;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#24322;&#26041;&#24046;&#22122;&#22768;&#19979;&#30340;&#20559;&#30456;&#20851;CI&#27979;&#35797;&#26041;&#27861;&#65292;&#21069;&#25552;&#26159;&#24050;&#32463;&#25484;&#25569;&#20851;&#20110;&#24322;&#26041;&#24046;&#20851;&#31995;&#30340;&#19987;&#23478;&#30693;&#35782;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#25152;&#25552;&#20986;&#30340;CI&#27979;&#35797;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#24182;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#23558;&#20854;&#25512;&#24191;&#21040;&#22240;&#26524;&#21457;&#29616;&#39046;&#22495;&#12290;&#25968;&#23383;&#22240;&#26524;&#21457;&#29616;&#23454;&#39564;&#35777;&#26126;&#65292;&#36866;&#24212;&#20102;&#30340;&#20559;&#30456;&#20851;CI&#27979;&#35797;&#26041;&#27861;&#22312;&#23384;&#22312;&#24322;&#26041;&#24046;&#24615;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#26631;&#20934;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#22312;&#21516;&#26041;&#24046;&#24773;&#20917;&#19979;&#20445;&#25345;&#19968;&#33268;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#30456;&#20851;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional independence (CI) testing is frequently used in data analysis and machine learning for various scientific fields and it forms the basis of constraint-based causal discovery. Oftentimes, CI testing relies on strong, rather unrealistic assumptions. One of these assumptions is homoskedasticity, in other words, a constant conditional variance is assumed. We frame heteroskedasticity in a structural causal model framework and present an adaptation of the partial correlation CI test that works well in the presence of heteroskedastic noise, given that expert knowledge about the heteroskedastic relationships is available. Further, we provide theoretical consistency results for the proposed CI test which carry over to causal discovery under certain assumptions. Numerical causal discovery experiments demonstrate that the adapted partial correlation CI test outperforms the standard test in the presence of heteroskedasticity and is on par for the homoskedastic case. Finally, we discuss 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.11497</link><description>&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24120;&#27493;&#38271;SGD&#30340;&#25910;&#25947;&#21644;&#38598;&#20013;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20248;&#21270;&#24179;&#28369;&#19988;&#24378;&#20984;&#30340;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20854;&#24615;&#36136;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36731;&#24494;&#21463;&#25511;&#26041;&#24046;&#30340;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#65292;&#36845;&#20195;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#22312;&#19982;&#20197;&#21069;&#24037;&#20316;&#30456;&#27604;&#26799;&#24230;&#22122;&#22768;&#20998;&#24067;&#30340;&#25918;&#23485;&#20551;&#35774;&#19979;&#65292;&#22312;Wasserstein-2&#36317;&#31163;&#19979;&#24314;&#31435;&#20102;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#30001;&#20110;&#26497;&#38480;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#36136;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#36825;&#20123;&#23545;&#20110;&#26799;&#24230;&#25104;&#31435;&#26102;&#65292;&#21518;&#32773;&#32487;&#25215;&#20102;&#20122;&#39640;&#26031;&#25110;&#20122;&#25351;&#25968;&#27987;&#24230;&#29305;&#24615;&#12290;&#36825;&#20801;&#35768;&#25512;&#23548;&#20986;&#23545;&#20110;&#26368;&#32456;&#20272;&#35745;&#30340;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;&#26368;&#21518;&#65292;&#22312;&#36825;&#31181;&#26465;&#20214;&#19979;&#65292;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;Polyak-Ruppert&#24207;&#21015;&#30340;&#23614;&#37096;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#26080;&#32500;&#24230;&#20559;&#24046;&#38480;&#21046;&#12290;&#25152;&#26377;&#32467;&#26524;&#22343;&#20026;&#38750;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20174;&#38750;&#24179;&#31283;&#30340;&#31354;&#38388;&#25968;&#25454;&#20013;&#27966;&#29983;&#23376;&#21306;&#22495;&#65292;&#24182;&#37319;&#29992;&#36873;&#25321;&#26426;&#21046;&#35782;&#21035;&#34920;&#29616;&#20986;&#19982;&#31283;&#24577;&#22330;&#30456;&#20284;&#34892;&#20026;&#30340;&#23376;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2306.11487</link><description>&lt;p&gt;
&#21033;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#39640;&#25928;&#22320;&#20272;&#35745;&#22823;&#35268;&#27169;&#38750;&#24179;&#31283;&#31354;&#38388;&#21327;&#26041;&#24046;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Efficient Large-scale Nonstationary Spatial Covariance Function Estimation Using Convolutional Neural Networks. (arXiv:2306.11487v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20174;&#38750;&#24179;&#31283;&#30340;&#31354;&#38388;&#25968;&#25454;&#20013;&#27966;&#29983;&#23376;&#21306;&#22495;&#65292;&#24182;&#37319;&#29992;&#36873;&#25321;&#26426;&#21046;&#35782;&#21035;&#34920;&#29616;&#20986;&#19982;&#31283;&#24577;&#22330;&#30456;&#20284;&#34892;&#20026;&#30340;&#23376;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27668;&#20505;&#21644;&#29615;&#22659;&#31185;&#23398;&#31561;&#39046;&#22495;&#35266;&#23519;&#21040;&#30340;&#31354;&#38388;&#36807;&#31243;&#24448;&#24448;&#21457;&#29983;&#22312;&#22823;&#35268;&#27169;&#19978;&#65292;&#24182;&#21576;&#29616;&#20986;&#31354;&#38388;&#19981;&#24179;&#31283;&#24615;&#12290;&#25311;&#21512;&#20855;&#26377;&#38750;&#24179;&#31283;Matern&#21327;&#26041;&#24046;&#30340;&#39640;&#26031;&#36807;&#31243;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#30740;&#31350;&#36890;&#36807;&#37319;&#29992;&#31354;&#38388;&#21010;&#20998;&#25216;&#26415;&#20272;&#35745;&#22312;&#21327;&#26041;&#24046;&#20989;&#25968;&#20013;&#31354;&#38388;&#21464;&#21270;&#30340;&#21442;&#25968;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#21010;&#20998;&#30340;&#36873;&#25321;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#32771;&#34385;&#22240;&#32032;&#65292;&#20294;&#24448;&#24448;&#26159;&#20027;&#35266;&#30340;&#65292;&#32570;&#20047;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#21033;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;ConvNets&#65289;&#30340;&#33021;&#21147;&#20174;&#38750;&#24179;&#31283;&#30340;&#25968;&#25454;&#20013;&#27966;&#29983;&#23376;&#21306;&#22495;&#12290;&#25105;&#20204;&#37319;&#29992;&#36873;&#25321;&#26426;&#21046;&#26469;&#35782;&#21035;&#34920;&#29616;&#20986;&#19982;&#31283;&#24577;&#22330;&#30456;&#20284;&#34892;&#20026;&#30340;&#23376;&#21306;&#22495;&#12290;&#20026;&#20102;&#21306;&#20998;&#31283;&#24577;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#22330;&#65292;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#27169;&#25311;&#25968;&#25454;&#23545;ConvNet&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20123;&#27169;&#25311;&#25968;&#25454;&#26159;&#20174;&#39640;&#26031;&#36807;&#31243;&#20013;&#29983;&#25104;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatial processes observed in various fields, such as climate and environmental science, often occur on a large scale and demonstrate spatial nonstationarity. Fitting a Gaussian process with a nonstationary Mat\'ern covariance is challenging. Previous studies in the literature have tackled this challenge by employing spatial partitioning techniques to estimate the parameters that vary spatially in the covariance function. The selection of partitions is an important consideration, but it is often subjective and lacks a data-driven approach. To address this issue, in this study, we utilize the power of Convolutional Neural Networks (ConvNets) to derive subregions from the nonstationary data. We employ a selection mechanism to identify subregions that exhibit similar behavior to stationary fields. In order to distinguish between stationary and nonstationary random fields, we conducted training on ConvNet using various simulated data. These simulations are generated from Gaussian processes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21487;&#35299;&#37322;&#35268;&#21017;&#38598;&#21512;&#30340;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;&#27010;&#24565;&#26469;&#36991;&#20813;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#26435;&#34913;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#22120;&#21644;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#30340;&#32467;&#21512;&#36827;&#34892;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.11481</link><description>&lt;p&gt;
&#23398;&#20064;&#26412;&#22320;&#21487;&#35299;&#37322;&#35268;&#21017;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Learning Locally Interpretable Rule Ensemble. (arXiv:2306.11481v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#21487;&#35299;&#37322;&#35268;&#21017;&#38598;&#21512;&#30340;&#26694;&#26550;&#65292;&#24341;&#20837;&#20102;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;&#27010;&#24565;&#26469;&#36991;&#20813;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#26435;&#34913;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#22120;&#21644;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#30340;&#32467;&#21512;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#26469;&#23398;&#20064;&#26082;&#20934;&#30830;&#21448;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#38598;&#21512;&#27169;&#22411;&#12290;&#35268;&#21017;&#38598;&#21512;&#26159;&#19968;&#31181;&#22522;&#20110;&#21152;&#26435;&#35268;&#21017;&#32447;&#24615;&#32452;&#21512;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#32463;&#24120;&#38656;&#35201;&#22312;&#35268;&#21017;&#38598;&#21512;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#20043;&#38388;&#26435;&#34913;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#35268;&#21017;&#38598;&#21512;&#38656;&#35201;&#21253;&#21547;&#36275;&#22815;&#22810;&#30340;&#21152;&#26435;&#35268;&#21017;&#26469;&#20445;&#25345;&#20854;&#20934;&#30830;&#24615;&#65292;&#36825;&#20250;&#25439;&#23475;&#20854;&#23545;&#20154;&#31867;&#29992;&#25143;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#26435;&#34913;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#24615;&#27010;&#24565;&#65292;&#31216;&#20026;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;&#65292;&#23427;&#30340;&#35780;&#20272;&#26159;&#36890;&#36807;&#27169;&#22411;&#25152;&#20570;&#30340;&#20010;&#20307;&#39044;&#27979;&#25152;&#38656;&#30340;&#35268;&#21017;&#24635;&#25968;&#26469;&#36827;&#34892;&#30340;&#65292;&#32780;&#19981;&#26159;&#20026;&#20102;&#34920;&#31034;&#27169;&#22411;&#26412;&#36523;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20419;&#36827;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;&#30340;&#27491;&#21017;&#21270;&#22120;&#65292;&#24182;&#20351;&#29992;&#24102;&#26377;&#26412;&#22320;&#25628;&#32034;&#30340;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#26469;&#23398;&#20064;&#20855;&#26377;&#25152;&#25552;&#20986;&#30340;&#27491;&#21017;&#21270;&#22120;&#30340;&#35268;&#21017;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new framework for learning a rule ensemble model that is both accurate and interpretable. A rule ensemble is an interpretable model based on the linear combination of weighted rules. In practice, we often face the trade-off between the accuracy and interpretability of rule ensembles. That is, a rule ensemble needs to include a sufficiently large number of weighted rules to maintain its accuracy, which harms its interpretability for human users. To avoid this trade-off and learn an interpretable rule ensemble without degrading accuracy, we introduce a new concept of interpretability, named local interpretability, which is evaluated by the total number of rules necessary to express individual predictions made by the model, rather than to express the model itself. Then, we propose a regularizer that promotes local interpretability and develop an efficient algorithm for learning a rule ensemble with the proposed regularizer by coordinate descent with local search. Exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26102;&#31354;&#25554;&#20540;&#21644;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#22312;&#39044;&#27979;&#20013;&#20811;&#26381;&#20102;&#20256;&#32479;&#25216;&#26415;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#25554;&#20540;&#21644;&#27010;&#29575;&#39044;&#27979;&#26041;&#38754;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.11472</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;Kriging&#30340;&#26102;&#31354;&#25554;&#20540;&#21644;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Spatio-temporal DeepKriging for Interpolation and Probabilistic Forecasting. (arXiv:2306.11472v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26102;&#31354;&#25554;&#20540;&#21644;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#22312;&#39044;&#27979;&#20013;&#20811;&#26381;&#20102;&#20256;&#32479;&#25216;&#26415;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#25554;&#20540;&#21644;&#27010;&#29575;&#39044;&#27979;&#26041;&#38754;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#21644;Kriging&#22312;&#20256;&#32479;&#30340;&#26102;&#31354;&#24314;&#27169;&#21644;&#39044;&#27979;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#36890;&#24120;&#39044;&#35774;&#25968;&#25454;&#26159;&#20174;&#20855;&#26377;&#21442;&#25968;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#20013;&#35266;&#27979;&#24471;&#21040;&#30340;&#12290;&#29616;&#23454;&#20013;&#30340;&#36807;&#31243;&#24448;&#24448;&#34920;&#29616;&#20986;&#38750;&#39640;&#26031;&#24615;&#21644;&#38750;&#24179;&#31283;&#24615;&#12290;&#27492;&#22806;&#65292;&#22522;&#20110;&#20284;&#28982;&#30340;&#39640;&#26031;&#36807;&#31243;&#25512;&#26029;&#23545;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#26469;&#35828;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26102;&#31354;&#25554;&#20540;&#21644;&#39044;&#27979;&#30340;&#20004;&#38454;&#27573;&#27169;&#22411;&#12290;&#31532;&#19968;&#27493;&#36827;&#34892;&#25554;&#20540;&#65292;&#21033;&#29992;&#20855;&#26377;&#26102;&#31354;&#22522;&#20989;&#25968;&#26500;&#24314;&#30340;&#30456;&#20851;&#31070;&#32463;&#32593;&#32476;&#30340;&#23884;&#20837;&#23618;&#12290;&#31532;&#20108;&#27493;&#37319;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#21367;&#31215;LSTM&#26469;&#39044;&#27979;&#32473;&#23450;&#20301;&#32622;&#30340;&#26410;&#26469;&#35266;&#27979;&#12290;&#25105;&#20204;&#22312;DNN&#20013;&#37319;&#29992;&#22522;&#20110;&#20998;&#20301;&#25968;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25552;&#20379;&#27010;&#29575;&#39044;&#27979;&#12290;&#19982;Kriging&#30456;&#27604;&#65292;&#25552;&#20986;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#20551;&#35774;&#36807;&#31243;&#26159;&#24179;&#31283;&#21644;&#39640;&#26031;&#24615;&#30340;&#65292;&#21487;&#20197;&#22788;&#29702;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#38750;&#39640;&#26031;&#24615;&#21644;&#38750;&#24179;&#31283;&#24615;&#26102;&#31354;&#25968;&#25454;&#38598;&#12290;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;LSTM&#30340;&#39044;&#27979;&#27169;&#22411;&#23454;&#29616;&#20102;&#39640;&#31934;&#24230;&#30340;&#25554;&#20540;&#21644;&#27010;&#29575;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes (GP) and Kriging are widely used in traditional spatio-temporal mod-elling and prediction. These techniques typically presuppose that the data are observed from a stationary GP with parametric covariance structure. However, processes in real-world applications often exhibit non-Gaussianity and nonstationarity. Moreover, likelihood-based inference for GPs is computationally expensive and thus prohibitive for large datasets. In this paper we propose a deep neural network (DNN) based two-stage model for spatio-temporal interpolation and forecasting. Interpolation is performed in the first step, which utilizes a dependent DNN with the embedding layer constructed with spatio-temporal basis functions. For the second stage, we use Long-Short Term Memory (LSTM) and convolutional LSTM to forecast future observations at a given location. We adopt the quantile-based loss function in the DNN to provide probabilistic forecasting. Compared to Kriging, the proposed method does not 
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#20102;&#19968;&#31181;&#24102;&#26377;&#21160;&#24577;&#26799;&#24230;&#21098;&#35009;&#26426;&#21046;&#30340;&#26102;&#38388;&#24046;&#20998;&#65288;TD&#65289;&#23398;&#20064;&#21487;&#20197;&#22312;&#37325;&#23614;&#22870;&#21169;&#20998;&#24067;&#19979;&#34987;&#35777;&#26126;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11455</link><description>&lt;p&gt;
&#37325;&#23614;&#22870;&#21169;&#30340;&#21487;&#35777;&#26126;&#40065;&#26834;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Provably Robust Temporal Difference Learning for Heavy-Tailed Rewards. (arXiv:2306.11455v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11455
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#19968;&#31181;&#24102;&#26377;&#21160;&#24577;&#26799;&#24230;&#21098;&#35009;&#26426;&#21046;&#30340;&#26102;&#38388;&#24046;&#20998;&#65288;TD&#65289;&#23398;&#20064;&#21487;&#20197;&#22312;&#37325;&#23614;&#22870;&#21169;&#20998;&#24067;&#19979;&#34987;&#35777;&#26126;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#27867;&#30340;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#38543;&#26426;&#22870;&#21169;&#20855;&#26377;&#37325;&#23614;&#20998;&#24067;&#65292;&#36825;&#23548;&#33268;&#31574;&#30053;&#35780;&#20272;&#21644;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#20013;&#30340;&#38543;&#26426;&#65288;&#21322;&#65289;&#26799;&#24230;&#20855;&#26377;&#26080;&#38480;&#30340;&#20108;&#38454;&#30697;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#32463;&#24120;&#20986;&#29616;&#32479;&#35745;&#19978;&#30340;&#31163;&#32676;&#20540;&#65292;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#20250;&#22833;&#36133;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#19968;&#31181;&#24102;&#26377;&#21160;&#24577;&#26799;&#24230;&#21098;&#35009;&#26426;&#21046;&#30340;&#26102;&#38388;&#24046;&#20998;&#65288;TD&#65289;&#23398;&#20064;&#65292;&#20197;&#21450;&#30456;&#24212;&#25805;&#20316;&#30340;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#65288;NAC&#65289;&#65292;&#21487;&#20197;&#22312;&#37325;&#23614;&#22870;&#21169;&#20998;&#24067;&#19979;&#34987;&#35777;&#26126;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#26694;&#26550;&#19979;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#21160;&#24577;&#26799;&#24230;&#21098;&#35009;&#26426;&#21046;&#21487;&#20197;&#22312;&#20559;&#24046;&#21644;&#38543;&#26426;&#26799;&#24230;&#21464;&#24046;&#20043;&#38388;&#21462;&#24471;&#26377;&#21033;&#30340;&#25240;&#34935;&#12290;&#29305;&#21035;&#22320;&#65292;&#35777;&#26126;&#20102;TD&#23398;&#20064;&#30340;&#40065;&#26834;&#29256;&#26412;&#21487;&#20197;&#36798;&#21040;$\mathcal{O}(\varepsilon^{-\frac{1}{p}})$&#21644;$\mathcal{O}(\varepsilon^{-1-\frac{1}{p}})$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a broad class of reinforcement learning applications, stochastic rewards have heavy-tailed distributions, which lead to infinite second-order moments for stochastic (semi)gradients in policy evaluation and direct policy optimization. In such instances, the existing RL methods may fail miserably due to frequent statistical outliers. In this work, we establish that temporal difference (TD) learning with a dynamic gradient clipping mechanism, and correspondingly operated natural actor-critic (NAC), can be provably robustified against heavy-tailed reward distributions. It is shown in the framework of linear function approximation that a favorable tradeoff between bias and variability of the stochastic gradients can be achieved with this dynamic gradient clipping mechanism. In particular, we prove that robust versions of TD learning achieve sample complexities of order $\mathcal{O}(\varepsilon^{-\frac{1}{p}})$ and $\mathcal{O}(\varepsilon^{-1-\frac{1}{p}})$ with and without the full-rank
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#25104;&#26524;&#35745;&#31639;&#22823;&#20559;&#24046;&#21069;&#32622;&#22240;&#23376;&#30340;&#25509;&#36817;&#27425;&#23548;&#25968;&#30340;&#36924;&#36817;&#20540;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#35745;&#31639;&#24179;&#22343;&#36864;&#20986;&#26102;&#38388;&#20197;&#21450;&#25506;&#32034;&#34987;&#24369;&#38543;&#26426;&#27874;&#21160;&#35302;&#21457;&#30340;&#32597;&#35265;&#20107;&#20214;&#30340;&#20869;&#22312;&#26426;&#21046;&#26041;&#38754;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11418</link><description>&lt;p&gt;
&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#35745;&#31639;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#22823;&#20559;&#24046;&#29575;&#30340;&#21069;&#32622;&#22240;&#23376;
&lt;/p&gt;
&lt;p&gt;
Computing large deviation prefactors of stochastic dynamical systems based on machine learning. (arXiv:2306.11418v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#25104;&#26524;&#35745;&#31639;&#22823;&#20559;&#24046;&#21069;&#32622;&#22240;&#23376;&#30340;&#25509;&#36817;&#27425;&#23548;&#25968;&#30340;&#36924;&#36817;&#20540;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#35745;&#31639;&#24179;&#22343;&#36864;&#20986;&#26102;&#38388;&#20197;&#21450;&#25506;&#32034;&#34987;&#24369;&#38543;&#26426;&#27874;&#21160;&#35302;&#21457;&#30340;&#32597;&#35265;&#20107;&#20214;&#30340;&#20869;&#22312;&#26426;&#21046;&#26041;&#38754;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#20197;&#34920;&#24449;&#22312;&#24369;&#22122;&#22768;&#26497;&#38480;&#19979;&#38543;&#26426;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#32597;&#35265;&#20107;&#20214;&#30340;&#25351;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#35745;&#31639;&#22823;&#20559;&#24046;&#21069;&#32622;&#22240;&#23376;&#30340;&#25509;&#36817;&#27425;&#23548;&#25968;&#30340;&#36924;&#36817;&#20540;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#35745;&#31639;&#24179;&#22343;&#36864;&#20986;&#26102;&#38388;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#20197;&#22522;&#20110;&#21521;&#37327;&#22330;&#30340;&#27491;&#20132;&#20998;&#35299;&#35745;&#31639;&#20934;&#21183;&#65292;&#26368;&#21487;&#33021;&#30340;&#36335;&#24452;&#21644;&#21069;&#32622;&#22240;&#23376;&#12290;&#23454;&#35777;&#20363;&#23376;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#23427;&#22312;&#25506;&#32034;&#34987;&#24369;&#38543;&#26426;&#27874;&#21160;&#35302;&#21457;&#30340;&#32597;&#35265;&#20107;&#20214;&#30340;&#20869;&#22312;&#26426;&#21046;&#26041;&#38754;&#20855;&#26377;&#24378;&#22823;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present large deviation theory that characterizes the exponential estimate for rare events of stochastic dynamical systems in the limit of weak noise. We aim to consider next-to-leading-order approximation for more accurate calculation of mean exit time via computing large deviation prefactors with the research efforts of machine learning. More specifically, we design a neural network framework to compute quasipotential, most probable paths and prefactors based on the orthogonal decomposition of vector field. We corroborate the higher effectiveness and accuracy of our algorithm with a practical example. Numerical experiments demonstrate its powerful function in exploring internal mechanism of rare events triggered by weak random fluctuations.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2306.11380</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Take on Gaussian Process Networks. (arXiv:2306.11380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11380
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#65288;GPNs&#65289;&#26159;&#19968;&#31867;&#26377;&#21521;&#22270;&#27169;&#22411;&#65292;&#20854;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#32593;&#32476;&#20013;&#27599;&#20010;&#21464;&#37327;&#32473;&#23450;&#20854;&#29238;&#21464;&#37327;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#35813;&#27169;&#22411;&#20801;&#35768;&#20197;&#32039;&#20945;&#20294;&#28789;&#27963;&#30340;&#26041;&#24335;&#25551;&#36848;&#36830;&#32493;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#20165;&#20570;&#26368;&#23569;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;GPNs&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#38656;&#35201;&#35745;&#31639;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21363;&#20351;&#22312;&#20302;&#32500;&#24773;&#20917;&#19979;&#65292;&#36825;&#20063;&#26159;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#12290;&#26412;&#25991;&#23454;&#29616;&#20102;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#26469;&#20174;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#36981;&#24490;&#36125;&#21494;&#26031;&#33539;&#24335;&#65292;&#36890;&#36807;&#36793;&#32536;&#20284;&#28982;&#27604;&#36739;&#27169;&#22411;&#65292;&#24182;&#35745;&#31639;GPN&#29305;&#24449;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20854;&#21518;&#39564;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows describing continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features. Simulation studies show that our method outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its poste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11313</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#26680;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep graph kernel point processes. (arXiv:2306.11313v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#20998;&#26512;&#22270;&#20013;&#24322;&#27493;&#20107;&#20214;&#65292;&#21453;&#26144;&#19981;&#21516;&#31867;&#22411;&#20107;&#20214;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#12290;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#30340;&#26102;&#38388;&#21644;&#31867;&#22411;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#24182;&#19988;&#22270;&#30340;&#22823;&#23567;&#21644;&#25299;&#25169;&#32467;&#26500;&#22686;&#21152;&#20102;&#38382;&#39064;&#30340;&#38590;&#24230;&#12290;&#26368;&#36817;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#25581;&#31034;&#20102;&#25429;&#25417;&#22797;&#26434;&#30340;&#20107;&#20214;&#31867;&#21035;&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27599;&#20010;&#30446;&#26631;&#20107;&#20214;&#31867;&#22411;&#30340;&#24378;&#24230;&#35745;&#31639;&#20013;&#20351;&#29992;&#20102;&#21253;&#25324;&#25152;&#26377;&#20107;&#20214;&#31867;&#21035;&#22312;&#20869;&#30340;&#26410;&#32463;&#28388;&#27874;&#30340;&#20107;&#20214;&#35760;&#24405;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#12290;&#23545;&#24212;&#30340;&#26080;&#21521;&#22270;&#20855;&#26377;&#20195;&#34920;&#20107;&#20214;&#31867;&#21035;&#30340;&#33410;&#28857;&#21644;&#34920;&#31034;&#28508;&#22312;&#36129;&#29486;&#20851;&#31995;&#30340;&#36793;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#12290;&#26412;&#36136;&#24433;&#21709;&#32467;&#26500;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;-based&#30340;&#23616;&#37096;&#37051;&#22495;&#20449;&#24687;&#32858;&#21512;&#36827;&#34892;&#20102;&#34701;&#21512;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#26356;&#20855;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point process models are widely used to analyze asynchronous events occurring within a graph that reflect how different types of events influence one another. Predicting future events' times and types is a crucial task, and the size and topology of the graph add to the challenge of the problem. Recent neural point process models unveil the possibility of capturing intricate inter-event-category dependencies. However, such methods utilize an unfiltered history of events, including all event categories in the intensity computation for each target event type. In this work, we propose a graph point process method where event interactions occur based on a latent graph topology. The corresponding undirected graph has nodes representing event categories and edges indicating potential contribution relationships. We then develop a novel deep graph kernel to characterize the triggering and inhibiting effects between events. The intrinsic influence structures are incorporated via the graph neural
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#22312;&#36739;&#23567;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#26102;&#38388;&#20869;&#35782;&#21035;&#20986;&#8220;&#25509;&#36817;&#8221;&#30340;&#20998;&#24067;&#30340;&#25968;&#25454;&#32467;&#26500;&#65292;&#21516;&#26102;&#36824;&#25913;&#36827;&#20102;&#19968;&#20010;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#23454;&#29616;&#32473;&#23450;&#20934;&#30830;&#24615;&#25152;&#38656;&#25805;&#20316;&#25968;&#30340;&#20943;&#23569;&#12290;</title><link>http://arxiv.org/abs/2306.11312</link><description>&lt;p&gt;
&#23494;&#24230;&#20272;&#35745;&#30340;&#25968;&#25454;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Data Structures for Density Estimation. (arXiv:2306.11312v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11312
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#22312;&#36739;&#23567;&#30340;&#26679;&#26412;&#25968;&#37327;&#21644;&#26102;&#38388;&#20869;&#35782;&#21035;&#20986;&#8220;&#25509;&#36817;&#8221;&#30340;&#20998;&#24067;&#30340;&#25968;&#25454;&#32467;&#26500;&#65292;&#21516;&#26102;&#36824;&#25913;&#36827;&#20102;&#19968;&#20010;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#23454;&#29616;&#32473;&#23450;&#20934;&#30830;&#24615;&#25152;&#38656;&#25805;&#20316;&#25968;&#30340;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#19979;&#23494;&#24230;&#20272;&#35745;&#38382;&#39064;&#30340;&#32479;&#35745;/&#35745;&#31639;&#26435;&#34913;&#65306;&#32473;&#23450;&#31163;&#25955;&#22495;&#22823;&#23567;&#20026;$n$&#30340;$k$&#20010;&#20998;&#24067;$v_1, \ldots, v_k$&#65292;&#20197;&#21450;&#23545;&#20998;&#24067;$p$&#30340;&#37319;&#26679;&#35775;&#38382;&#65292;&#25214;&#21040;&#19982;$p$&#8220;&#25509;&#36817;&#8221;&#30340;$v_i$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#31532;&#19968;&#20010;&#25968;&#25454;&#32467;&#26500;&#65292;&#32473;&#23450;$p$&#30340;&#23376;&#32447;&#24615;&#65288;&#22312;$n$&#20013;&#65289;&#26679;&#26412;&#25968;&#37327;&#65292;&#33021;&#22815;&#22312;$k$&#30340;&#23376;&#32447;&#24615;&#26102;&#38388;&#20869;&#35782;&#21035;$v_i$&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;Acharya&#31561;&#20154;&#65288;2018&#65289;&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#26102;&#38388;&#20869;&#25253;&#21578;$v_i$&#12290;&#21518;&#32773;&#31639;&#27861;&#30340;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;&#23427;&#30456;&#23545;&#20110;&#20043;&#21069;&#30340;&#24037;&#20316;&#65292;&#22312;&#23454;&#29616;&#32473;&#23450;&#31934;&#24230;&#25152;&#38656;&#25805;&#20316;&#25968;&#19978;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study statistical/computational tradeoffs for the following density estimation problem: given $k$ distributions $v_1, \ldots, v_k$ over a discrete domain of size $n$, and sampling access to a distribution $p$, identify $v_i$ that is "close" to $p$. Our main result is the first data structure that, given a sublinear (in $n$) number of samples from $p$, identifies $v_i$ in time sublinear in $k$. We also give an improved version of the algorithm of Acharya et al. (2018) that reports $v_i$ in time linear in $k$. The experimental evaluation of the latter algorithm shows that it achieves a significant reduction in the number of operations needed to achieve a given accuracy compared to prior work.
&lt;/p&gt;</description></item><item><title>&#25240;&#25187;&#27491;&#21017;&#21270;&#19981;&#20165;&#21487;&#20197;&#36890;&#36807;&#24573;&#30053;&#24310;&#36831;&#25928;&#24212;&#26469;&#32553;&#23567;&#35268;&#21010;&#31354;&#38388;&#65292;&#36824;&#21487;&#20197;&#30475;&#20316;&#26159;&#20855;&#26377;&#20808;&#39564;&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#65292;&#32780;&#20302;&#25240;&#25187;&#22240;&#23376;&#30340;&#20351;&#29992;&#20250;&#23548;&#33268;&#29366;&#24577;-&#21160;&#20316;&#23545;&#20043;&#38388;&#25968;&#25454;&#37327;&#19981;&#22343;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2306.11208</link><description>&lt;p&gt;
&#25240;&#25187;&#27491;&#21017;&#21270;&#30340;&#38750;&#39044;&#26399;&#32467;&#26524;&#65306;&#25913;&#36827;&#30830;&#23450;&#31561;&#20215;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
The Unintended Consequences of Discount Regularization: Improving Regularization in Certainty Equivalence Reinforcement Learning. (arXiv:2306.11208v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11208
&lt;/p&gt;
&lt;p&gt;
&#25240;&#25187;&#27491;&#21017;&#21270;&#19981;&#20165;&#21487;&#20197;&#36890;&#36807;&#24573;&#30053;&#24310;&#36831;&#25928;&#24212;&#26469;&#32553;&#23567;&#35268;&#21010;&#31354;&#38388;&#65292;&#36824;&#21487;&#20197;&#30475;&#20316;&#26159;&#20855;&#26377;&#20808;&#39564;&#20998;&#24067;&#30340;&#27491;&#21017;&#21270;&#65292;&#32780;&#20302;&#25240;&#25187;&#22240;&#23376;&#30340;&#20351;&#29992;&#20250;&#23548;&#33268;&#29366;&#24577;-&#21160;&#20316;&#23545;&#20043;&#38388;&#25968;&#25454;&#37327;&#19981;&#22343;&#30340;&#24615;&#33021;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25240;&#25187;&#27491;&#21017;&#21270;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#31232;&#30095;&#25110;&#22024;&#26434;&#30340;&#25968;&#25454;&#20013;&#20272;&#35745;MDP&#26102;&#23558;&#35268;&#21010;&#38480;&#21046;&#20026;&#19968;&#20010;&#36739;&#31616;&#21333;&#30340;&#31574;&#30053;&#38598;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#25105;&#20204;&#25581;&#31034;&#20102;&#25240;&#25187;&#27491;&#21017;&#21270;&#30340;&#21478;&#19968;&#31181;&#35270;&#35282;&#65292;&#26292;&#38706;&#20986;&#20102;&#38750;&#39044;&#26399;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#20351;&#29992;&#36739;&#20302;&#30340;&#25240;&#25187;&#22240;&#23376;&#36827;&#34892;&#35268;&#21010;&#21487;&#20197;&#20135;&#29983;&#19982;&#20351;&#29992;&#20855;&#26377;&#30456;&#21516;&#20998;&#24067;&#30340;&#36716;&#31227;&#30697;&#38453;&#20808;&#39564;&#30340;&#20219;&#20309;&#35268;&#21010;&#24471;&#21040;&#30340;&#26368;&#20248;&#31574;&#30053;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;&#23454;&#38469;&#19978;&#65292;&#23427;&#30340;&#20316;&#29992;&#31867;&#20284;&#20110;&#23545;&#20855;&#26377;&#26356;&#22810;&#36716;&#31227;&#25968;&#25454;&#30340;&#29366;&#24577;-&#21160;&#20316;&#23545;&#36827;&#34892;&#26356;&#24378;&#30340;&#27491;&#21017;&#21270;&#12290;&#28982;&#32780;&#65292;&#24403;&#36716;&#31227;&#30697;&#38453;&#20174;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#26102;&#65292;&#23545;&#20110;&#29366;&#24577;-&#21160;&#20316;&#23545;&#20043;&#38388;&#25968;&#25454;&#37327;&#19981;&#22343;&#30340;&#24773;&#20917;&#65292;&#36825;&#23558;&#23548;&#33268;&#24615;&#33021;&#19981;&#20339;&#12290;&#25105;&#20204;&#30340;&#31561;&#20215;&#23450;&#29702;&#23548;&#33268;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#20844;&#24335;&#26469;&#35774;&#32622;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discount regularization, using a shorter planning horizon when calculating the optimal policy, is a popular choice to restrict planning to a less complex set of policies when estimating an MDP from sparse or noisy data (Jiang et al., 2015). It is commonly understood that discount regularization functions by de-emphasizing or ignoring delayed effects. In this paper, we reveal an alternate view of discount regularization that exposes unintended consequences. We demonstrate that planning under a lower discount factor produces an identical optimal policy to planning using any prior on the transition matrix that has the same distribution for all states and actions. In fact, it functions like a prior with stronger regularization on state-action pairs with more transition data. This leads to poor performance when the transition matrix is estimated from data sets with uneven amounts of data across state-action pairs. Our equivalence theorem leads to an explicit formula to set regularization pa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26631;&#20934;&#8220;&#19981;&#20805;&#20998;&#30340;&#29702;&#30001;&#33853;&#24046;&#8221;&#65288;IJDI&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#31639;&#27861;&#20915;&#31574;&#25903;&#25345;&#24037;&#20855;&#25152;&#20570;&#20986;&#30340;&#24314;&#35758;&#26159;&#21542;&#20844;&#24179;&#65292;&#24182;&#25551;&#36848;&#20102;IJDI-Scan&#26041;&#27861;&#26469;&#21457;&#29616;&#37325;&#35201;&#30340;IJDI&#12290;&#22312;&#27169;&#25311;&#21644;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#20877;&#29359;&#39118;&#38505;&#35780;&#20272;&#21644;&#20449;&#29992;&#35780;&#20998;&#65292;&#24182;&#23454;&#29616;&#20102;&#20943;&#36731;IJDI&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.11181</link><description>&lt;p&gt;
&#19981;&#20805;&#20998;&#30340;&#29702;&#30001;&#33853;&#24046;&#65306;&#23376;&#32452;&#20844;&#24179;&#24615;&#30340;&#26032;&#26631;&#20934;
&lt;/p&gt;
&lt;p&gt;
Insufficiently Justified Disparate Impact: A New Criterion for Subgroup Fairness. (arXiv:2306.11181v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11181
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26631;&#20934;&#8220;&#19981;&#20805;&#20998;&#30340;&#29702;&#30001;&#33853;&#24046;&#8221;&#65288;IJDI&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#31639;&#27861;&#20915;&#31574;&#25903;&#25345;&#24037;&#20855;&#25152;&#20570;&#20986;&#30340;&#24314;&#35758;&#26159;&#21542;&#20844;&#24179;&#65292;&#24182;&#25551;&#36848;&#20102;IJDI-Scan&#26041;&#27861;&#26469;&#21457;&#29616;&#37325;&#35201;&#30340;IJDI&#12290;&#22312;&#27169;&#25311;&#21644;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#21253;&#25324;&#20877;&#29359;&#39118;&#38505;&#35780;&#20272;&#21644;&#20449;&#29992;&#35780;&#20998;&#65292;&#24182;&#23454;&#29616;&#20102;&#20943;&#36731;IJDI&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26631;&#20934;&#8220;&#19981;&#20805;&#20998;&#30340;&#29702;&#30001;&#33853;&#24046;&#8221;&#65288;IJDI&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#30001;&#31639;&#27861;&#20915;&#31574;&#25903;&#25345;&#24037;&#20855;&#20570;&#20986;&#30340;&#24314;&#35758;&#65288;&#20108;&#20803;&#39044;&#27979;&#65289;&#26159;&#21542;&#20844;&#24179;&#12290;&#25105;&#20204;&#30340;&#23454;&#29992;&#22411;IJDI&#26631;&#20934;&#35780;&#20272;&#20551;&#38451;&#24615;&#21644;&#20551;&#38452;&#24615;&#35823;&#24046;&#29575;&#30340;&#19981;&#24179;&#34913;&#24615;&#65292;&#35782;&#21035;&#20986;&#21363;&#20351;&#22312;&#35843;&#25972;&#32676;&#20307;&#22522;&#30784;&#27604;&#29575;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#20173;&#23384;&#22312;&#30340;&#32676;&#20307;&#38388;&#26174;&#33879;&#24046;&#24322;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#26032;&#30340;IJDI-Scan&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35782;&#21035;&#36328;&#36234;&#25968;&#25454;&#30340;&#22810;&#20010;&#35266;&#23519;&#23646;&#24615;&#30340;&#20132;&#21449;&#23376;&#20154;&#32676;&#65292;&#20854;&#20013;&#20855;&#26377;&#26368;&#37325;&#35201;&#30340;IJDI&#12290;&#20026;&#20102;&#35780;&#20272;IJDI-Scan&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#21253;&#25324;&#20877;&#29359;&#39118;&#38505;&#35780;&#20272;&#21644;&#20449;&#29992;&#35780;&#20998;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23454;&#29616;&#21644;&#35780;&#20272;&#20102;&#22312;&#36825;&#20123;&#39046;&#22495;&#26816;&#27979;&#21040;&#30340;&#23376;&#20154;&#32676;&#19978;&#20943;&#36731;IJDI&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a new criterion, "insufficiently justified disparate impact" (IJDI), for assessing whether recommendations (binarized predictions) made by an algorithmic decision support tool are fair. Our novel, utility-based IJDI criterion evaluates false positive and false negative error rate imbalances, identifying statistically significant disparities between groups which are present even when adjusting for group-level differences in base rates. We describe a novel IJDI-Scan approach which can efficiently identify the intersectional subpopulations, defined across multiple observed attributes of the data, with the most significant IJDI. To evaluate IJDI-Scan's performance, we conduct experiments on both simulated and real-world data, including recidivism risk assessment and credit scoring. Further, we implement and evaluate approaches to mitigating IJDI for the detected subpopulations in these domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#39044;&#27979;&#22303;&#22756;&#19982;&#26893;&#29289;&#34920;&#22411;&#20043;&#38388;&#32852;&#31995;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#35777;&#26126;&#21152;&#20837;&#22303;&#22756;&#29289;&#29702;&#21270;&#23398;&#24615;&#36136;&#21644;&#24494;&#29983;&#29289;&#31181;&#32676;&#23494;&#24230;&#31561;&#29615;&#22659;&#29305;&#24449;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11157</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20154;&#31867;&#38480;&#21046;&#65306;&#21033;&#29992;&#22303;&#22756;&#24494;&#29983;&#29289;&#25968;&#25454;&#39044;&#27979;&#26893;&#29289;&#34920;&#22411;
&lt;/p&gt;
&lt;p&gt;
Human Limits in Machine Learning: Prediction of Plant Phenotypes Using Soil Microbiome Data. (arXiv:2306.11157v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#39044;&#27979;&#22303;&#22756;&#19982;&#26893;&#29289;&#34920;&#22411;&#20043;&#38388;&#32852;&#31995;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#35777;&#26126;&#21152;&#20837;&#22303;&#22756;&#29289;&#29702;&#21270;&#23398;&#24615;&#36136;&#21644;&#24494;&#29983;&#29289;&#31181;&#32676;&#23494;&#24230;&#31561;&#29615;&#22659;&#29305;&#24449;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#25252;&#22303;&#22756;&#20581;&#24247;&#34987;&#35748;&#20026;&#26159;21&#19990;&#32426;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#65292;&#22240;&#20026;&#23427;&#22312;&#20892;&#19994;&#12289;&#20154;&#31867;&#20581;&#24247;&#21644;&#29983;&#29289;&#22810;&#26679;&#24615;&#26041;&#38754;&#20855;&#26377;&#24191;&#27867;&#65288;&#21487;&#33021;&#20855;&#26377;&#23041;&#32961;&#24615;&#30340;&#65289;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#20004;&#31181;&#27169;&#22411;&#65288;&#38543;&#26426;&#26862;&#26519;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65289;&#25506;&#32034;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#29702;&#35299;&#22303;&#22756;&#21644;&#29983;&#29289;&#34920;&#22411;&#20043;&#38388;&#32852;&#31995;&#30340;&#39044;&#27979;&#28508;&#21147;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#20013;&#21152;&#20837;&#22303;&#22756;&#29289;&#29702;&#21270;&#23398;&#24615;&#36136;&#21644;&#24494;&#29983;&#29289;&#31181;&#32676;&#23494;&#24230;&#31561;&#29615;&#22659;&#29305;&#24449;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25506;&#32034;&#22810;&#31181;&#25968;&#25454;&#39044;&#22788;&#29702;&#31574;&#30053;&#65292;&#22914;&#24402;&#19968;&#21270;&#12289;&#38646;&#26367;&#25442;&#21644;&#25968;&#25454;&#22686;&#24378;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The preservation of soil health has been identified as one of the main challenges of the XXI century given its vast (and potentially threatening) ramifications in agriculture, human health and biodiversity. Here, we provide the first deep investigation of the predictive potential of machine-learning models to understand the connections between soil and biological phenotypes. Indeed, we investigate an integrative framework performing accurate machine-learning-based prediction of plant phenotypes from biological, chemical and physical properties of the soil via two models: random forest and Bayesian neural network. We show that prediction is improved, as evidenced by higher weighted F1 scores, when incorporating into the models environmental features like soil physicochemical properties and microbial population density in addition to the microbiome information. Furthermore, by exploring multiple data preprocessing strategies such as normalization, zero replacement, and data augmentation,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#32858;&#21512;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#26032;&#31639;&#27861;&#65306;&#36890;&#36807;&#20449;&#24687;&#29942;&#39048;&#36827;&#34892;&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65288;NFA-IB&#65289;&#21644;&#36890;&#36807;&#26680;&#23884;&#20837;&#36827;&#34892;&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65288;NFA-KE&#65289;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#26102;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#34920;&#31034;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.11143</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65306;&#30001;&#29702;&#35770;&#25512;&#23548;&#32780;&#26469;&#30340;&#20004;&#20010;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Feature Aggregation: Two Algorithms driven by Theory. (arXiv:2306.11143v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#32858;&#21512;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#26032;&#31639;&#27861;&#65306;&#36890;&#36807;&#20449;&#24687;&#29942;&#39048;&#36827;&#34892;&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65288;NFA-IB&#65289;&#21644;&#36890;&#36807;&#26680;&#23884;&#20837;&#36827;&#34892;&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65288;NFA-KE&#65289;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#26102;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#34920;&#31034;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#31243;&#24207;&#37117;&#20855;&#26377;&#22823;&#37327;&#30340;&#29305;&#24449;&#65292;&#36825;&#23548;&#33268;&#20102;&#35745;&#31639;&#21644;&#20869;&#23384;&#38382;&#39064;&#65292;&#20197;&#21450;&#36807;&#25311;&#21512;&#30340;&#39118;&#38505;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#24212;&#35813;&#20165;&#32771;&#34385;&#30456;&#20851;&#30340;&#38750;&#20887;&#20313;&#29305;&#24449;&#65292;&#20197;&#20445;&#30041;&#21407;&#22987;&#25968;&#25454;&#30340;&#23436;&#25972;&#20449;&#24687;&#24182;&#38480;&#21046;&#32500;&#25968;&#12290;&#38477;&#32500;&#21644;&#29305;&#24449;&#36873;&#25321;&#26159;&#24120;&#29992;&#30340;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#25968;&#25454;&#30340;&#26377;&#25928;&#22788;&#29702;&#25361;&#25112;&#12290;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#25511;&#21046;&#25968;&#25454;&#38598;&#20013;&#29305;&#24449;&#30340;&#25968;&#37327;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#32467;&#26500;&#24182;&#26368;&#23567;&#21270;&#20449;&#24687;&#25439;&#22833;&#12290;&#29305;&#24449;&#36873;&#25321;&#26088;&#22312;&#35782;&#21035;&#20219;&#21153;&#30340;&#26368;&#30456;&#20851;&#29305;&#24449;&#65292;&#33293;&#24323;&#20449;&#24687;&#36739;&#23569;&#30340;&#29305;&#24449;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#25552;&#20986;&#20102;&#22522;&#20110;&#30456;&#20851;&#24615;&#32858;&#21512;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#20002;&#24323;&#20219;&#20309;&#29305;&#24449;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#32858;&#21512;&#20445;&#25345;&#20854;&#21487;&#35299;&#37322;&#24615;&#12290;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#22312;&#20110;&#20551;&#35774;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#31995;&#26159;&#32447;&#24615;&#30340;&#65292;&#36825;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#26102;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#34920;&#31034;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#32858;&#21512;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#26032;&#31639;&#27861;&#65306;&#36890;&#36807;&#20449;&#24687;&#29942;&#39048;&#36827;&#34892;&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65288;NFA-IB&#65289;&#21644;&#36890;&#36807;&#26680;&#23884;&#20837;&#36827;&#34892;&#38750;&#32447;&#24615;&#29305;&#24449;&#32858;&#21512;&#65288;NFA-KE&#65289;&#12290;NFA-IB&#22522;&#20110;&#20449;&#24687;&#29942;&#39048;&#21407;&#29702;&#65292;&#32780;NFA-KE&#20351;&#29992;&#26680;&#20989;&#25968;&#23558;&#21407;&#22987;&#29305;&#24449;&#36716;&#25442;&#20026;&#26356;&#39640;&#32500;&#30340;&#31354;&#38388;&#65292;&#21487;&#20197;&#22312;&#20854;&#20013;&#25429;&#25417;&#29305;&#24449;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#22330;&#26223;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#30456;&#27604;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world machine learning applications are characterized by a huge number of features, leading to computational and memory issues, as well as the risk of overfitting. Ideally, only relevant and non-redundant features should be considered to preserve the complete information of the original data and limit the dimensionality. Dimensionality reduction and feature selection are common preprocessing techniques addressing the challenge of efficiently dealing with high-dimensional data. Dimensionality reduction methods control the number of features in the dataset while preserving its structure and minimizing information loss. Feature selection aims to identify the most relevant features for a task, discarding the less informative ones. Previous works have proposed approaches that aggregate features depending on their correlation without discarding any of them and preserving their interpretability through aggregation with the mean. A limitation of methods based on correlation is the as
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2306.11112</link><description>&lt;p&gt;
&#32416;&#27491;&#20844;&#24179;&#20998;&#31867;&#20013;&#30340;&#20302;&#20272;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#34987;&#20302;&#20272;&#20559;&#24046;&#25439;&#22351;&#30340;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#27491;&#20363;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#25935;&#24863;&#32452;&#20013;&#20197;&#19981;&#21516;&#30340;&#26410;&#30693;&#36895;&#29575;&#20174;&#25968;&#25454;&#20013;&#36807;&#28388;&#25481;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26377;&#23569;&#37327;&#26080;&#20559;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#27599;&#20010;&#32452;&#30340;&#20943;&#23569;&#21442;&#25968;&#65292;&#21363;&#20351;&#22312;&#20132;&#21449;&#32452;&#25104;&#21592;&#36164;&#26684;&#20351;&#24471;&#23398;&#20064;&#27599;&#20010;&#20132;&#21449;&#29575;&#21464;&#24471;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#24773;&#20917;&#19979;&#12290;&#21033;&#29992;&#36825;&#20010;&#20998;&#32452;&#20002;&#22833;&#29575;&#30340;&#20272;&#35745;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#20351;&#25105;&#20204;&#36817;&#20284;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#65292;&#21363;&#20351;&#25105;&#20204;&#21482;&#33021;&#22312;&#19968;&#20010;&#26377;&#20559;&#26679;&#26412;&#19978;&#35266;&#23519;&#21040;&#32463;&#39564;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23553;&#35013;&#20102;&#36825;&#20010;&#23398;&#20064;&#21644;&#37325;&#26032;&#21152;&#26435;&#36807;&#31243;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;PAC&#39118;&#26684;&#30340;&#20445;&#35777;&#65292;&#21363;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#25105;&#20204;&#23545;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#39118;&#38505;&#30340;&#20272;&#35745;&#23558;&#19982;&#30495;&#23454;&#39118;&#38505;&#20219;&#24847;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out parameters, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using this estimate for the group-wise drop-out rate, we construct a re-weighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. Finally, we present an algorithm encapsulating this learning and re-weighting process, and we provide strong PAC-style guarantees that, with high probability, our estimate of the risk of the hypothesis over the true distribution will be arbitrarily close to the true risk.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#26080;&#20851;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20934;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;&#32463;&#20856;&#21644;&#31070;&#32463;&#20272;&#35745;&#22120;&#22312;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12289;&#38271;&#23614;&#20998;&#24067;&#21644;&#39640;&#20114;&#20449;&#24687;&#26102;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11078</link><description>&lt;p&gt;
&#36229;&#36234;&#27491;&#24120;&#65306;&#20851;&#20110;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Beyond Normal: On the Evaluation of Mutual Information Estimators. (arXiv:2306.11078v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11078
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#26080;&#20851;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20934;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;&#32463;&#20856;&#21644;&#31070;&#32463;&#20272;&#35745;&#22120;&#22312;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12289;&#38271;&#23614;&#20998;&#24067;&#21644;&#39640;&#20114;&#20449;&#24687;&#26102;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#20449;&#24687;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#32479;&#35745;&#30456;&#20851;&#24230;&#37327;&#65292;&#24050;&#22312;&#34920;&#31034;&#23398;&#20064;&#12289;&#22240;&#26524;&#24615;&#12289;&#22495;&#27867;&#21270;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#31561;&#39046;&#22495;&#24471;&#21040;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#20114;&#20449;&#24687;&#20272;&#35745;&#36890;&#24120;&#21482;&#22312;&#31616;&#21333;&#30340;&#27010;&#29575;&#20998;&#24067;&#26063;&#31867;&#65288;&#21363;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#21644;&#20855;&#26377;&#19968;&#32500;&#38543;&#26426;&#21464;&#37327;&#30340;&#36873;&#25321;&#20998;&#24067;&#65289;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314;&#20855;&#26377;&#24050;&#30693;&#22522;&#20934;&#20114;&#20449;&#24687;&#30340;&#21508;&#31181;&#20998;&#24067;&#26063;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#26080;&#20851;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20934;&#24179;&#21488;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32463;&#20856;&#21644;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#28041;&#21450;&#39640;&#32500;&#24230;&#12289;&#31232;&#30095;&#30456;&#20114;&#20316;&#29992;&#12289;&#38271;&#23614;&#20998;&#24067;&#21644;&#39640;&#20114;&#20449;&#24687;&#30340;&#24773;&#22659;&#20013;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20026;&#20174;&#19994;&#20154;&#21592;&#25552;&#20379;&#20102;&#36873;&#25321;&#36866;&#24403;&#30340;&#20272;&#35745;&#22120;&#20197;&#36866;&#24212;&#25152;&#32771;&#34385;&#38382;&#39064;&#38590;&#24230;&#21644;&#24212;&#29992;&#20272;&#35745;&#20114;&#20449;&#24687;&#26102;&#38656;&#35201;&#32771;&#34385;&#30340;&#38382;&#39064;&#30340;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mutual information is a general statistical dependency measure which has found applications in representation learning, causality, domain generalization and computational biology. However, mutual information estimators are typically evaluated on simple families of probability distributions, namely multivariate normal distribution and selected distributions with one-dimensional random variables. In this paper, we show how to construct a diverse family of distributions with known ground-truth mutual information and propose a language-independent benchmarking platform for mutual information estimators. We discuss the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information. Finally, we provide guidelines for practitioners on how to select appropriate estimator adapted to the difficulty of problem considered and issues one needs to consider when applying an est
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#29305;&#24449;&#37325;&#26032;&#21152;&#26435;&#65288;AFR&#65289;&#30340;&#31616;&#21333;&#24555;&#36895;&#26041;&#27861;&#65292;&#20351;&#29992;&#21152;&#26435;&#25439;&#22833;&#37325;&#26032;&#35757;&#32451;ERC&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#26469;&#20943;&#23569;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22810;&#20010;&#32676;&#20307;&#30340;&#40065;&#26834;&#24615;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.11074</link><description>&lt;p&gt;
&#33258;&#21160;&#29305;&#24449;&#37325;&#26032;&#21152;&#26435;&#23454;&#29616;&#31616;&#21333;&#24555;&#36895;&#30340;&#32452;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Simple and Fast Group Robustness by Automatic Feature Reweighting. (arXiv:2306.11074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#21160;&#29305;&#24449;&#37325;&#26032;&#21152;&#26435;&#65288;AFR&#65289;&#30340;&#31616;&#21333;&#24555;&#36895;&#26041;&#27861;&#65292;&#20351;&#29992;&#21152;&#26435;&#25439;&#22833;&#37325;&#26032;&#35757;&#32451;ERC&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#26469;&#20943;&#23569;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22810;&#20010;&#32676;&#20307;&#30340;&#40065;&#26834;&#24615;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#36234;&#30028;&#27867;&#21270;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#20381;&#36182;&#20110;&#34394;&#20551;&#29305;&#24449;--&#23427;&#20204;&#26159;&#22312;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#20013;&#39044;&#27979;&#31867;&#26631;&#31614;&#30340;&#27169;&#24335;&#65292;&#20294;&#19982;&#30446;&#26631;&#19981;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#12290;&#20943;&#23569;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#30340;&#26631;&#20934;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#25105;&#20204;&#30693;&#36947;&#34394;&#20551;&#29305;&#24449;&#26159;&#20160;&#20040;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#24456;&#23569;&#26159;&#30495;&#23454;&#30340;&#12290;&#35797;&#22270;&#20943;&#36731;&#36825;&#31181;&#38480;&#21046;&#30340;&#26041;&#27861;&#22797;&#26434;&#65292;&#38590;&#20197;&#35843;&#25972;&#65292;&#19982;&#26631;&#20934;&#35757;&#32451;&#30456;&#27604;&#20855;&#26377;&#26174;&#33879;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33258;&#21160;&#29305;&#24449;&#37325;&#26032;&#21152;&#26435;&#65288;AFR&#65289;&#30340;&#26497;&#20854;&#31616;&#21333;&#24555;&#36895;&#30340;&#26041;&#27861;&#26469;&#26356;&#26032;&#27169;&#22411;&#20197;&#20943;&#23569;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#12290;AFR&#20351;&#29992;&#21152;&#26435;&#25439;&#22833;&#37325;&#26032;&#35757;&#32451;&#26631;&#20934;ERM&#35757;&#32451;&#30340;&#22522;&#26412;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#65292;&#24378;&#35843;ERM&#27169;&#22411;&#39044;&#27979;&#19981;&#20339;&#30340;&#31034;&#20363;&#65292;&#33258;&#21160;&#25552;&#39640;&#23569;&#25968;&#32676;&#20307;&#30340;&#26435;&#37325;&#65292;&#32780;&#26080;&#38656;&#32452;&#26631;&#31614;&#12290;&#36890;&#36807;&#36825;&#20010;&#31616;&#21333;&#30340;&#36807;&#31243;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#26368;&#20339;&#25253;&#21578;&#32467;&#26524;&#20013;&#30340;&#35768;&#22810;&#32676;&#20307;&#40065;&#26834;&#24615;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major challenge to out-of-distribution generalization is reliance on spurious features -- patterns that are predictive of the class label in the training data distribution, but not causally related to the target. Standard methods for reducing the reliance on spurious features typically assume that we know what the spurious feature is, which is rarely true in the real world. Methods that attempt to alleviate this limitation are complex, hard to tune, and lead to a significant computational overhead compared to standard training. In this paper, we propose Automatic Feature Reweighting (AFR), an extremely simple and fast method for updating the model to reduce the reliance on spurious features. AFR retrains the last layer of a standard ERM-trained base model with a weighted loss that emphasizes the examples where the ERM model predicts poorly, automatically upweighting the minority group without group labels. With this simple procedure, we improve upon the best reported results among co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#22312;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#25968;&#25454;&#22788;&#29702;&#25216;&#26415;&#65292;&#21487;&#20197;&#35786;&#26029;&#35774;&#22791;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#39044;&#27979;&#25925;&#38556;&#21069;&#30340;&#21097;&#20313;&#23551;&#21629;&#12290;&#36825;&#39033;&#25216;&#26415;&#36824;&#34987;&#24212;&#29992;&#20110;&#27833;&#30000;&#35774;&#22791;&#30340;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#12290;</title><link>http://arxiv.org/abs/2306.11040</link><description>&lt;p&gt;
&#24212;&#29992;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#27833;&#30000;&#35774;&#22791;&#39044;&#27979;&#24615;&#32500;&#25252;
&lt;/p&gt;
&lt;p&gt;
Application of Deep Learning for Predictive Maintenance of Oilfield Equipment. (arXiv:2306.11040v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11040
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#31070;&#32463;&#32593;&#32476;&#25216;&#26415;&#22312;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#25968;&#25454;&#22788;&#29702;&#25216;&#26415;&#65292;&#21487;&#20197;&#35786;&#26029;&#35774;&#22791;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;&#39044;&#27979;&#25925;&#38556;&#21069;&#30340;&#21097;&#20313;&#23551;&#21629;&#12290;&#36825;&#39033;&#25216;&#26415;&#36824;&#34987;&#24212;&#29992;&#20110;&#27833;&#30000;&#35774;&#22791;&#30340;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#28145;&#24230;&#23398;&#20064;&#65288;&#23588;&#20854;&#26159;&#31070;&#32463;&#32593;&#32476;&#65289;&#22312;&#39044;&#27979;&#24615;&#32500;&#25252;&#12289;&#35786;&#26029;&#21644;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#12290;&#35768;&#22810;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65288;&#20363;&#22914;&#20840;&#36830;&#25509;&#12289;&#21367;&#31215;&#21644;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65289;&#22312;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24320;&#21457;&#21644;&#27979;&#35797;&#65292;&#20363;&#22914;NASA C-MAPSS&#12289;Case Western Reserve University Bearings&#21644;FEMTO Bearings&#25968;&#25454;&#38598;&#65292;&#20197;&#35786;&#26029;&#35774;&#22791;&#30340;&#20581;&#24247;&#29366;&#24577;&#21644;/&#25110;&#39044;&#27979;&#25925;&#38556;&#21069;&#21097;&#20313;&#23551;&#21629;&#65288;RUL&#65289;&#12290;&#35768;&#22810;&#25968;&#25454;&#22788;&#29702;&#21644;&#29305;&#24449;&#25552;&#21462;&#31243;&#24207;&#19982;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#19968;&#36215;&#20351;&#29992;&#65292;&#20363;&#22914;&#38477;&#32500;&#65288;&#20027;&#25104;&#20998;&#20998;&#26512;&#65289;&#21644;&#20449;&#21495;&#22788;&#29702;&#65288;&#20613;&#37324;&#21494;&#21644;&#23567;&#27874;&#20998;&#26512;&#65289;&#65292;&#20197;&#21019;&#24314;&#26356;&#26377;&#24847;&#20041;&#21644;&#26356;&#31283;&#20581;&#30340;&#29305;&#24449;&#65292;&#29992;&#20316;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36755;&#20837;&#12290;&#26412;&#35770;&#25991;&#36824;&#25506;&#35752;&#20102;&#36825;&#20123;&#25216;&#26415;&#22312;&#30417;&#27979;&#27833;&#30000;&#21345;&#36710;&#21644;&#35774;&#22791;&#30340;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#30340;&#28508;&#22312;&#29992;&#36884;&#12290;
&lt;/p&gt;
&lt;p&gt;
This thesis explored applications of the new emerging techniques of artificial intelligence and deep learning (neural networks in particular) for predictive maintenance, diagnostics and prognostics. Many neural architectures such as fully-connected, convolutional and recurrent neural networks were developed and tested on public datasets such as NASA C-MAPSS, Case Western Reserve University Bearings and FEMTO Bearings datasets to diagnose equipment health state and/or predict the remaining useful life (RUL) before breakdown. Many data processing and feature extraction procedures were used in combination with deep learning techniques such as dimensionality reduction (Principal Component Analysis) and signal processing (Fourier and Wavelet analyses) in order to create more meaningful and robust features to use as an input for neural networks architectures. This thesis also explored the potential use of these techniques in predictive maintenance within oil rigs for monitoring oilfield crit
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#38750;&#38646;&#21644;&#21452;&#23618;&#20844;&#24335;&#65292;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#25915;&#20987;&#30456;&#21305;&#37197;&#24182;&#19988;&#33021;&#22815;&#36798;&#21040;&#19982;&#26631;&#20934;&#23545;&#25239;&#24615;&#35757;&#32451;&#30456;&#21516;&#30340;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.11035</link><description>&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#24212;&#34987;&#35270;&#20026;&#19968;&#20010;&#38750;&#38646;&#21644;&#21338;&#24328;
&lt;/p&gt;
&lt;p&gt;
Adversarial Training Should Be Cast as a Non-Zero-Sum Game. (arXiv:2306.11035v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11035
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#38750;&#38646;&#21644;&#21452;&#23618;&#20844;&#24335;&#65292;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#25915;&#20987;&#30456;&#21305;&#37197;&#24182;&#19988;&#33021;&#22815;&#36798;&#21040;&#19982;&#26631;&#20934;&#23545;&#25239;&#24615;&#35757;&#32451;&#30456;&#21516;&#30340;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#33030;&#24369;&#24615;&#30340;&#19968;&#20010;&#31361;&#20986;&#26041;&#27861;&#26159;&#37319;&#29992;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#20004;&#20010;&#29609;&#23478;&#38646;&#21644;&#33539;&#24335;&#65292;&#20854;&#20013;&#39044;&#27979;&#22120;&#34987;&#35757;&#32451;&#20197;&#23545;&#25239;&#24615;&#36873;&#25321;&#30340;&#25968;&#25454;&#25200;&#21160;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#24456;&#26377;&#21069;&#36884;&#65292;&#20294;&#26159;&#22522;&#20110;&#36825;&#31181;&#33539;&#24335;&#30340;&#31639;&#27861;&#24182;&#27809;&#26377;&#20135;&#29983;&#36275;&#22815;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#36973;&#21463;&#30149;&#24577;&#34892;&#20026;&#65292;&#22914;&#24378;&#20581;&#30340;&#36807;&#25311;&#21512;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#31181;&#32570;&#38519;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#20013;&#20351;&#29992;&#30340;&#24120;&#35265;&#22522;&#20110;&#20195;&#29702;&#30340;&#26494;&#24347;&#26041;&#27861;&#20351;&#25152;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#31283;&#20581;&#24615;&#27809;&#26377;&#20219;&#20309;&#20445;&#35777;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#20010;&#38382;&#39064;&#21518;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38750;&#38646;&#21644;&#21452;&#23618;&#23545;&#25239;&#35757;&#32451;&#20844;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#29609;&#23478;&#20248;&#21270;&#19981;&#21516;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#25105;&#20204;&#30340;&#20844;&#24335;&#33258;&#28982;&#22320;&#20135;&#29983;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#36798;&#21040;&#19982;&#26631;&#20934;&#23545;&#25239;&#24615;&#35757;&#32451;&#30456;&#24403;&#30340;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
One prominent approach toward resolving the adversarial vulnerability of deep neural networks is the two-player zero-sum paradigm of adversarial training, in which predictors are trained against adversarially-chosen perturbations of data. Despite the promise of this approach, algorithms based on this paradigm have not engendered sufficient levels of robustness, and suffer from pathological behavior like robust overfitting. To understand this shortcoming, we first show that the commonly used surrogate-based relaxation used in adversarial training algorithms voids all guarantees on the robustness of trained classifiers. The identification of this pitfall informs a novel non-zero-sum bilevel formulation of adversarial training, wherein each player optimizes a different objective function. Our formulation naturally yields a simple algorithmic framework that matches and in some cases outperforms state-of-the-art attacks, attains comparable levels of robustness to standard adversarial traini
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#26080;&#38656;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.11017</link><description>&lt;p&gt;
&#26080;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Contextual Bandit Problem without Sparsity. (arXiv:2306.11017v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11017
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#26080;&#38656;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#12290;&#21516;&#26102;&#65292;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457;&#31639;&#27861;&#26469;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#39640;&#32500;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#29305;&#24449;&#25968; $p$ &#22823;&#20110;&#39044;&#31639; $T$ &#25110;&#29978;&#33267;&#26080;&#38480;&#21046;&#12290;&#19982;&#27492;&#39046;&#22495;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#19981;&#23545;&#22238;&#24402;&#31995;&#25968;&#26045;&#21152;&#31232;&#30095;&#24615;&#35201;&#27714;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20381;&#38752;&#26368;&#36817;&#20851;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#20174;&#32780;&#33021;&#22815;&#22312;&#25968;&#25454;&#20998;&#24067;&#20855;&#26377;&#36739;&#23567;&#26377;&#25928;&#31209;&#26102;&#20998;&#26512;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25506;&#32034;-&#24320;&#21457; (EtC) &#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#26816;&#39564;&#20102;&#23427;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#20197; $T$ &#20026;&#21464;&#37327;&#65292;&#23548;&#20986;&#20102;ETC&#31639;&#27861;&#30340;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#34920;&#26126;&#36825;&#20010;&#36895;&#29575;&#21487;&#20197;&#36890;&#36807;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#26469;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#25506;&#32034;-&#24320;&#21457; (AEtC)&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#25214;&#21040;&#26368;&#20248;&#24179;&#34913;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#27169;&#25311;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this research, we investigate the high-dimensional linear contextual bandit problem where the number of features $p$ is greater than the budget $T$, or it may even be infinite. Differing from the majority of previous works in this field, we do not impose sparsity on the regression coefficients. Instead, we rely on recent findings on overparameterized models, which enables us to analyze the performance the minimum-norm interpolating estimator when data distributions have small effective ranks. We propose an explore-then-commit (EtC) algorithm to address this problem and examine its performance. Through our analysis, we derive the optimal rate of the ETC algorithm in terms of $T$ and show that this rate can be achieved by balancing exploration and exploitation. Moreover, we introduce an adaptive explore-then-commit (AEtC) algorithm that adaptively finds the optimal balance. We assess the performance of the proposed algorithms through a series of simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#20197;&#19981;&#38656;&#35201;&#23436;&#20840;&#20102;&#35299;&#22270;&#24418;&#32467;&#26500;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21069;&#38376;&#35843;&#25972;&#27861;&#35745;&#31639;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#27979;&#35797;&#24615;&#26465;&#20214;&#29420;&#31435;&#24615;&#38472;&#36848;&#30340;&#26041;&#24335;&#23454;&#29616;&#65292;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#19981;&#30693;&#36947;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2306.11008</link><description>&lt;p&gt;
&#21069;&#38376;&#35843;&#25972;&#27861;&#65306;&#22312;&#26377;&#38480;&#30340;&#22270;&#32467;&#26500;&#30693;&#35782;&#19979;&#36229;&#36234;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;
&lt;/p&gt;
&lt;p&gt;
Front-door Adjustment Beyond Markov Equivalence with Limited Graph Knowledge. (arXiv:2306.11008v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11008
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#20197;&#19981;&#38656;&#35201;&#23436;&#20840;&#20102;&#35299;&#22270;&#24418;&#32467;&#26500;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21069;&#38376;&#35843;&#25972;&#27861;&#35745;&#31639;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#27979;&#35797;&#24615;&#26465;&#20214;&#29420;&#31435;&#24615;&#38472;&#36848;&#30340;&#26041;&#24335;&#23454;&#29616;&#65292;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#19981;&#30693;&#36947;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#36890;&#24120;&#38656;&#35201;&#23545;&#22240;&#26524;&#20851;&#31995;&#20570;&#20986;&#20551;&#35774;&#65292;&#21487;&#20197;&#26174;&#24335;&#22320;&#22312;Pearlian&#26694;&#26550;&#20013;&#38472;&#36848;&#22240;&#26524;&#22270;&#32467;&#26500;&#65292;&#20063;&#21487;&#20197;&#38544;&#21547;&#22320;&#20351;&#29992;&#28508;&#22312;&#32467;&#26524;&#26694;&#26550;&#20013;&#30340;&#65288;&#26465;&#20214;&#65289;&#29420;&#31435;&#24615;&#38472;&#36848;&#12290;&#24403;&#22788;&#29702;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#28151;&#28102;&#26102;&#65292;&#21069;&#38376;&#35843;&#25972;&#27861;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#20854;&#20013;&#65292;&#22312;&#32473;&#23450;&#22270;&#24418;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#20351;&#29992;&#21518;&#22788;&#29702;&#21464;&#37327;&#20272;&#35745;&#22788;&#29702;&#23545;&#30446;&#26631;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#21069;&#38376;&#35843;&#25972;&#27861;&#30340;&#31934;&#30830;&#20844;&#24335;&#21462;&#20915;&#20110;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#23398;&#20064;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21487;&#27979;&#35797;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#38472;&#36848;&#65292;&#20197;&#20351;&#29992;&#31867;&#20284;&#21069;&#38376;&#30340;&#35843;&#25972;&#27861;&#35745;&#31639;&#22240;&#26524;&#25928;&#24212;&#65292;&#32780;&#26080;&#38656;&#20102;&#35299;&#26377;&#38480;&#30340;&#32467;&#26500;&#20391;&#38754;&#20449;&#24687;&#30340;&#22270;&#24418;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#19981;&#30693;&#36947;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal effect estimation from data typically requires assumptions about the cause-effect relations either explicitly in the form of a causal graph structure within the Pearlian framework, or implicitly in terms of (conditional) independence statements between counterfactual variables within the potential outcomes framework. When the treatment variable and the outcome variable are confounded, front-door adjustment is an important special case where, given the graph, causal effect of the treatment on the target can be estimated using post-treatment variables. However, the exact formula for front-door adjustment depends on the structure of the graph, which is difficult to learn in practice. In this work, we provide testable conditional independence statements to compute the causal effect using front-door-like adjustment without knowing the graph under limited structural side information. We show that our method is applicable in scenarios where knowing the Markov equivalence class is not s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25277;&#26679;&#22810;&#20803;&#37325;&#23614;&#20998;&#24067;&#30340;VAE&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#27169;&#25311;&#30495;&#23454;&#19990;&#30028;&#30340;&#22810;&#20803;&#26497;&#20540;&#24773;&#20917;&#65292;&#22914;&#27827;&#27969;&#27700;&#20301;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#35780;&#20272;&#26410;&#26469;&#21487;&#33021;&#20986;&#29616;&#30340;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2306.10987</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#22810;&#20803;&#26497;&#20540;&#30340;VAE&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A VAE Approach to Sample Multivariate Extremes. (arXiv:2306.10987v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25277;&#26679;&#22810;&#20803;&#37325;&#23614;&#20998;&#24067;&#30340;VAE&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#27169;&#25311;&#30495;&#23454;&#19990;&#30028;&#30340;&#22810;&#20803;&#26497;&#20540;&#24773;&#20917;&#65292;&#22914;&#27827;&#27969;&#27700;&#20301;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#35780;&#20272;&#26410;&#26469;&#21487;&#33021;&#20986;&#29616;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25105;&#20204;&#38656;&#35201;&#35780;&#20272;&#26410;&#26469;&#21487;&#33021;&#20250;&#20986;&#29616;&#30340;&#27604;&#24050;&#35266;&#23519;&#21040;&#30340;&#26497;&#20540;&#26356;&#22823;&#30340;&#26497;&#31471;&#24773;&#20917;&#30340;&#39118;&#38505;&#26102;&#65292;&#20174;&#35266;&#27979;&#25968;&#25454;&#38598;&#20013;&#20934;&#30830;&#22320;&#29983;&#25104;&#26497;&#20540;&#33267;&#20851;&#37325;&#35201;&#12290; &#24212;&#29992;&#33539;&#22260;&#21253;&#25324;&#33258;&#28982;&#28798;&#23475;&#21644;&#37329;&#34701;&#23849;&#28291;&#12290; &#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#30340;&#29983;&#25104;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#26497;&#31471;&#26679;&#26412;&#65292;&#38656;&#35201;&#20180;&#32454;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#26497;&#20540;&#29702;&#35770;&#30340;&#28176;&#36827;&#32467;&#26524;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#23588;&#20854;&#26159;&#36890;&#36807;&#22810;&#20803;&#27491;&#21017;&#21464;&#21270;&#30340;&#27010;&#24565;&#26469;&#27169;&#25311;&#22810;&#20803;&#26497;&#31471;&#20107;&#20214;&#12290; &#36830;&#25509;&#36825;&#20004;&#20010;&#39046;&#22495;&#65292;&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#25277;&#26679;&#22810;&#20803;&#37325;&#23614;&#20998;&#24067;&#30340;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26041;&#27861;&#65292;&#21363;&#21487;&#33021;&#20855;&#26377;&#29305;&#21035;&#22823;&#24378;&#24230;&#30340;&#26497;&#31471;&#20998;&#24067;&#12290; &#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#27839;&#22810;&#29785;&#27827;&#32593;&#32476;&#30340;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#35828;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#30456;&#20851;&#24615;&#12290; &#21518;&#32773;&#26174;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20174;&#24050;&#35266;&#23519;&#21040;&#30340;&#26497;&#20540;&#20998;&#24067;&#20013;&#25277;&#26679;&#26469;&#27169;&#25311;&#27827;&#27969;&#27700;&#20301;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generating accurate extremes from an observational data set is crucial when seeking to estimate risks associated with the occurrence of future extremes which could be larger than those already observed. Applications range from the occurrence of natural disasters to financial crashes. Generative approaches from the machine learning community do not apply to extreme samples without careful adaptation. Besides, asymptotic results from extreme value theory (EVT) give a theoretical framework to model multivariate extreme events, especially through the notion of multivariate regular variation. Bridging these two fields, this paper details a variational autoencoder (VAE) approach for sampling multivariate heavy-tailed distributions, i.e., distributions likely to have extremes of particularly large intensities. We illustrate the relevance of our approach on a synthetic data set and on a real data set of discharge measurements along the Danube river network. The latter shows the potential of ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26494;&#24347;&#20102;&#23436;&#20840;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#25928;&#26524;&#19981;&#21464;&#24615;&#65292;&#35777;&#26126;&#23427;&#36275;&#20197;&#36827;&#34892;&#38646;&#26679;&#26412;&#31574;&#30053;&#27010;&#25324;&#65292;&#24182;&#35752;&#35770;&#20102;&#22522;&#20110;&#23569;&#37327;&#26679;&#26412;&#30340;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2306.10983</link><description>&lt;p&gt;
&#31574;&#30053;&#27010;&#25324;&#20013;&#30340;&#25928;&#26524;&#19981;&#21464;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Effect-Invariant Mechanisms for Policy Generalization. (arXiv:2306.10983v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26494;&#24347;&#20102;&#23436;&#20840;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#25928;&#26524;&#19981;&#21464;&#24615;&#65292;&#35777;&#26126;&#23427;&#36275;&#20197;&#36827;&#34892;&#38646;&#26679;&#26412;&#31574;&#30053;&#27010;&#25324;&#65292;&#24182;&#35752;&#35770;&#20102;&#22522;&#20110;&#23569;&#37327;&#26679;&#26412;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#23398;&#20064;&#26159;&#35768;&#22810;&#23454;&#38469;&#23398;&#20064;&#31995;&#32479;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#31574;&#30053;&#23398;&#20064;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#22914;&#20309;&#26377;&#25928;&#22320;&#36866;&#24212;&#26410;&#35265;&#36807;&#30340;&#29615;&#22659;&#25110;&#20219;&#21153;&#12290;&#26368;&#36817;&#65292;&#26377;&#20154;&#24314;&#35758;&#21033;&#29992;&#19981;&#21464;&#30340;&#26465;&#20214;&#20998;&#24067;&#26469;&#23398;&#20064;&#26356;&#22909;&#22320;&#27010;&#25324;&#26410;&#35265;&#36807;&#29615;&#22659;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#20551;&#35774;&#25972;&#20010;&#26465;&#20214;&#20998;&#24067;&#26159;&#19981;&#21464;&#30340;&#65288;&#25105;&#20204;&#31216;&#20043;&#20026;&#23436;&#20840;&#19981;&#21464;&#24615;&#65289;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26159;&#19968;&#20010;&#22826;&#24378;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26494;&#24347;&#23436;&#20840;&#19981;&#21464;&#24615;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#25928;&#26524;&#19981;&#21464;&#24615;&#65288;&#31616;&#31216;e-&#19981;&#21464;&#24615;&#65289;&#65292;&#24182;&#35777;&#26126;&#23427;&#26159;&#36275;&#22815;&#30340;&#65288;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65289;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#31574;&#30053;&#27010;&#25324;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19968;&#31181;&#25193;&#23637;&#65292;&#23427;&#22312;&#27979;&#35797;&#29615;&#22659;&#20013;&#21482;&#26377;&#23569;&#37327;&#26679;&#26412;&#26102;&#21033;&#29992;e-&#19981;&#21464;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23569;&#26679;&#26412;&#31574;&#30053;&#25512;&#24191;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#19981;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#22522;&#30784;&#22240;&#26524;&#22270;&#65292;&#20063;&#19981;&#20551;&#35774;&#25968;&#25454;&#26159;&#30001;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#29983;&#25104;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#27979;&#35797;&#36807;&#31243;&#26469;&#27979;&#35797;e-&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy learning is an important component of many real-world learning systems. A major challenge in policy learning is how to adapt efficiently to unseen environments or tasks. Recently, it has been suggested to exploit invariant conditional distributions to learn models that generalize better to unseen environments. However, assuming invariance of entire conditional distributions (which we call full invariance) may be too strong of an assumption in practice. In this paper, we introduce a relaxation of full invariance called effect-invariance (e-invariance for short) and prove that it is sufficient, under suitable assumptions, for zero-shot policy generalization. We also discuss an extension that exploits e-invariance when we have a small sample from the test environment, enabling few-shot policy generalization. Our work does not assume an underlying causal graph or that the data are generated by a structural causal model; instead, we develop testing procedures to test e-invariance dir
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#20960;&#31181;&#37325;&#25277;&#26679;&#26041;&#27861;&#20197;&#25913;&#36827;&#26631;&#20934;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#20102;&#25277;&#26679;&#29575;&#23545;&#39044;&#27979;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.10977</link><description>&lt;p&gt;
&#32437;&#21521;&#36319;&#36394;&#30740;&#31350;&#20013;&#32597;&#35265;&#20107;&#20214;&#30340;&#39044;&#27979;&#27169;&#22411;&#21450;&#37325;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction model for rare events in longitudinal follow-up and resampling methods. (arXiv:2306.10977v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10977
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#20960;&#31181;&#37325;&#25277;&#26679;&#26041;&#27861;&#20197;&#25913;&#36827;&#26631;&#20934;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#35780;&#20272;&#20102;&#25277;&#26679;&#29575;&#23545;&#39044;&#27979;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#32437;&#21521;&#36319;&#36394;&#30740;&#31350;&#20013;&#38024;&#23545;&#32597;&#35265;&#20107;&#20214;&#39044;&#27979;&#30340;&#27169;&#22411;&#26500;&#24314;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#23454;&#38469;&#26696;&#20363;&#20013;&#27604;&#36739;&#20102;&#20960;&#31181;&#37325;&#25277;&#26679;&#26041;&#27861;&#65292;&#20197;&#25913;&#36827;&#26631;&#20934;&#22238;&#24402;&#27169;&#22411;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25277;&#26679;&#29575;&#23545;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35780;&#20272;&#32437;&#21521;&#27169;&#22411;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#32771;&#34385;&#26102;&#38388;&#22240;&#32032;&#12289;&#19982;&#23454;&#38469;&#24212;&#29992;&#30456;&#23545;&#24212;&#30340;&#39564;&#35777;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of model building for rare events prediction in longitudinal follow-up studies. In this paper, we compare several resampling methods to improve standard regression models on a real life example. We evaluate the effect of the sampling rate on the predictive performances of the models. To evaluate the predictive performance of a longitudinal model, we consider a validation technique that takes into account time and corresponds to the actual use in real life.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;Unibo-INAIL&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#22522;&#20110;sEMG&#20449;&#21495;&#30340;&#25163;&#21183;&#35782;&#21035;&#65292;&#25506;&#32034;&#20102;&#34987;&#35797;&#32773;&#20043;&#38388;&#12289;&#20250;&#35805;&#20043;&#38388;&#21644;&#25163;&#33218;&#23039;&#21183;&#20043;&#38388;&#30340;&#21487;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.10954</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;sEMG&#25163;&#21183;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
sEMG-based Hand Gesture Recognition with Deep Learning. (arXiv:2306.10954v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;Unibo-INAIL&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#22522;&#20110;sEMG&#20449;&#21495;&#30340;&#25163;&#21183;&#35782;&#21035;&#65292;&#25506;&#32034;&#20102;&#34987;&#35797;&#32773;&#20043;&#38388;&#12289;&#20250;&#35805;&#20043;&#38388;&#21644;&#25163;&#33218;&#23039;&#21183;&#20043;&#38388;&#30340;&#21487;&#21464;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#34920;&#38754;&#32908;&#30005;&#22270;(sEMG)&#20449;&#21495;&#30340;&#25163;&#21183;&#35782;&#21035;&#26159;&#21457;&#23637;&#33258;&#28982;&#25511;&#21046;&#30340;&#20154;&#26426;&#30028;&#38754;(HMIs)&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#27604;&#22914;&#30452;&#35266;&#30340;&#26426;&#22120;&#20154;&#30028;&#38754;&#25110;&#22810;&#20851;&#33410;&#20551;&#32930;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36816;&#21160;&#20266;&#24433;&#12289;&#23039;&#24577;&#21644;&#26102;&#38388;&#21464;&#21270;&#20197;&#21450;&#20256;&#24863;&#22120;&#37325;&#26032;&#23450;&#20301;&#31561;&#21487;&#38752;&#24615;&#38382;&#39064;&#65292;&#30495;&#23454;&#24212;&#29992;&#21463;&#21040;&#38480;&#21046;&#12290;&#26412;&#25991;&#26159;&#22312;Unibo-INAIL&#25968;&#25454;&#38598;&#19978;&#39318;&#27425;&#24212;&#29992;&#28145;&#24230;&#23398;&#20064;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#31532;&#19968;&#20010;&#20844;&#24320;&#30340;sEMG&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#37319;&#38598;&#27599;&#20010;7&#20010;&#20581;&#24247;&#34987;&#35797;&#32773;&#22312;4&#31181;&#23039;&#21183;&#19979;&#25191;&#34892;6&#31181;&#25163;&#21183;&#30340;8&#20010;&#20250;&#35805;&#65292;&#26469;&#25506;&#32034;&#34987;&#35797;&#32773;&#20043;&#38388;&#12289;&#20250;&#35805;&#20043;&#38388;&#21644;&#25163;&#33218;&#23039;&#21183;&#20043;&#38388;&#30340;&#21487;&#21464;&#24615;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#36890;&#36807;&#22522;&#20110;&#35757;&#32451;&#38598;&#26500;&#25104;&#30340;&#31574;&#30053;&#26469;&#35299;&#20915;&#21487;&#21464;&#24615;&#38382;&#39064;&#65292;&#25913;&#21892;&#38750;&#28145;&#24230;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#36328;&#23039;&#21183;&#21644;&#36328;&#22825;&#27867;&#21270;&#33021;&#21147;&#65292;&#20854;&#20013;&#24452;&#21521;&#22522;&#26680;SVM&#30340;&#20934;&#30830;&#29575;&#26368;&#39640;&#12290;&#26412;&#30740;&#31350;&#23454;&#29616;&#30340;&#28145;&#24230;&#32467;&#26500;&#26159;&#19968;&#20010;1d-CNN&#12290;
&lt;/p&gt;
&lt;p&gt;
Hand gesture recognition based on surface electromyographic (sEMG) signals is a promising approach for developing Human-Machine Interfaces (HMIs) with a natural control, such as intuitive robot interfaces or poly-articulated prostheses. However, real-world applications are limited by reliability problems due to motion artefacts, postural and temporal variability, and sensor re-positioning. This master thesis is the first application of deep learning on the Unibo-INAIL dataset, the first public sEMG dataset exploring the variability between subjects, sessions and arm postures by collecting data over 8 sessions of each of 7 able-bodied subjects executing 6 hand gestures in 4 arm postures. Recent studies address variability with strategies based on training set composition, which improve inter-posture and inter-day generalization of non-deep machine learning classifiers, among which the RBF-kernel SVM yields the highest accuracy. The deep architecture realized in this work is a 1d-CNN ins
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;</title><link>http://arxiv.org/abs/2306.10947</link><description>&lt;p&gt;
&#20351;&#29992;&#36895;&#29575;&#20989;&#25968;&#29702;&#35299;&#25554;&#20540;&#21306;&#38388;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Understanding Generalization in the Interpolation Regime using the Rate Function. (arXiv:2306.10947v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#22823;&#20559;&#24046;&#29702;&#35770;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#30340;&#24179;&#28369;&#27169;&#22411;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#26377;&#24456;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#20197;&#21450;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#20026;&#20160;&#20040;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#22823;&#20559;&#24046;&#29702;&#35770;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#26032;&#29305;&#24449;&#25551;&#36848;&#26041;&#27861;&#12290;&#19982;&#20197;&#24448;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#20197;&#24448;&#30340;&#24037;&#20316;&#36890;&#24120;&#29992;&#23454;&#25968;&#20540;&#65288;&#22914;&#26435;&#37325;&#33539;&#25968;&#65289;&#26469;&#34920;&#24449;&#27169;&#22411;&#30340;&#24179;&#28369;&#24230;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#20197;&#29992;&#31616;&#21333;&#30340;&#23454;&#20540;&#20989;&#25968;&#26469;&#25551;&#36848;&#24179;&#28369;&#24230;&#12290;&#22522;&#20110;&#27169;&#22411;&#24179;&#28369;&#24230;&#30340;&#36825;&#19968;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#35299;&#37322;&#65292;&#20026;&#20160;&#20040;&#19968;&#20123;&#25554;&#20540;&#22120;&#34920;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;&#24191;&#27867;&#20351;&#29992;&#30340;&#29616;&#20195;&#23398;&#20064;&#25216;&#26415;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;$\ell_2$-&#35268;&#33539;&#21270;&#65292;&#25968;&#25454;&#22686;&#24378;&#65292;&#19981;&#21464;&#30340;&#26550;&#26500;&#21644;&#36229;&#21442;&#25968;&#21270;&#65289;&#33021;&#22815;&#25214;&#21040;&#23427;&#20204;&#12290;&#25105;&#20204;&#24471;&#20986;&#30340;&#32467;&#35770;&#26159;&#65292;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#37117;&#25552;&#20379;&#20102;&#20114;&#34917;&#30340;&#36807;&#31243;&#65292;&#36825;&#20123;&#36807;&#31243;&#20351;&#20248;&#21270;&#22120;&#20559;&#21521;&#20110;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#65292;&#32780;&#26681;&#25454;&#36825;&#31181;&#29702;&#35770;&#20998;&#26512;&#65292;&#26356;&#24179;&#28369;&#30340;&#25554;&#20540;&#22120;&#26159;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#25554;&#20540;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a novel characterization of the smoothness of a model based on basic principles of Large Deviation Theory. In contrast to prior work, where the smoothness of a model is normally characterized by a real value (e.g., the weights' norm), we show that smoothness can be described by a simple real-valued function. Based on this concept of smoothness, we propose an unifying theoretical explanation of why some interpolators generalize remarkably well and why a wide range of modern learning techniques (i.e., stochastic gradient descent, $\ell_2$-norm regularization, data augmentation, invariant architectures, and overparameterization) are able to find them. The emergent conclusion is that all these methods provide complimentary procedures that bias the optimizer to smoother interpolators, which, according to this theoretical analysis, are the ones with better generalization error.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#21521;&#29983;&#25104;&#22120;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;KL&#25955;&#24230;&#39033;&#30340;&#26041;&#27861;&#65292;&#26469;&#20445;&#35777;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#20998;&#24067;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#24212;&#20998;&#24067;&#37325;&#21512;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10943</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#30495;&#23454;&#25968;&#25454;&#21644;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#30340;&#27010;&#29575;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Probabilistic matching of real and generated data statistics in generative adversarial networks. (arXiv:2306.10943v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36890;&#36807;&#21521;&#29983;&#25104;&#22120;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;KL&#25955;&#24230;&#39033;&#30340;&#26041;&#27861;&#65292;&#26469;&#20445;&#35777;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#20998;&#24067;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#24212;&#20998;&#24067;&#37325;&#21512;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#12290;&#34429;&#28982;&#29983;&#25104;&#26679;&#26412;&#24448;&#24448;&#38590;&#20197;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#65292;&#20294;&#19981;&#33021;&#20445;&#35777;&#23427;&#20204;&#36981;&#24490;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#30830;&#20445;&#26576;&#20123;&#29983;&#25104;&#25968;&#25454;&#32479;&#35745;&#20998;&#24067;&#19982;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#24212;&#20998;&#24067;&#37325;&#21512;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#29983;&#25104;&#22120;&#25439;&#22833;&#20989;&#25968;&#20013;&#28155;&#21152;&#20102;Kullback-Leibler&#39033;&#65306;KL&#25955;&#24230;&#26159;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20174;&#23567;&#25209;&#37327;&#20540;&#33719;&#24471;&#30340;&#30456;&#24212;&#29983;&#25104;&#20998;&#24067;&#21644;&#30001;&#26465;&#20214;&#33021;&#37327;&#27169;&#22411;&#34920;&#31034;&#30340;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20004;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks constitute a powerful approach to generative modeling. While generated samples often are indistinguishable from real data, there is no guarantee that they will follow the true data distribution. In this work, we propose a method to ensure that the distributions of certain generated data statistics coincide with the respective distributions of the real data. In order to achieve this, we add a Kullback-Leibler term to the generator loss function: the KL divergence is taken between the true distributions as represented by a conditional energy-based model, and the corresponding generated distributions obtained from minibatch values at each iteration. We evaluate the method on a synthetic dataset and two real-world datasets and demonstrate improved performance of our method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#20851;&#31995;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#65288;RCNPs&#65289;&#26159;&#19968;&#31181;&#26377;&#25928;&#23558;&#31561;&#21464;&#24615;&#32435;&#20837;&#20219;&#20309;&#31070;&#32463;&#36807;&#31243;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#31561;&#21464;&#31070;&#32463;&#36807;&#31243;&#30340;&#36866;&#29992;&#24615;&#21644;&#24433;&#21709;&#21147;&#21040;&#26356;&#39640;&#30340;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.10915</link><description>&lt;p&gt;
&#36890;&#36807;&#20851;&#31995;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#23454;&#29616;&#23454;&#29992;&#30340;&#31561;&#21464;&#24615;
&lt;/p&gt;
&lt;p&gt;
Practical Equivariances via Relational Conditional Neural Processes. (arXiv:2306.10915v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#20851;&#31995;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#65288;RCNPs&#65289;&#26159;&#19968;&#31181;&#26377;&#25928;&#23558;&#31561;&#21464;&#24615;&#32435;&#20837;&#20219;&#20309;&#31070;&#32463;&#36807;&#31243;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#31561;&#21464;&#31070;&#32463;&#36807;&#31243;&#30340;&#36866;&#29992;&#24615;&#21644;&#24433;&#21709;&#21147;&#21040;&#26356;&#39640;&#30340;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#65288;CNPs&#65289;&#26159;&#19968;&#31867;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#20197;&#20854;&#32508;&#21512;&#36816;&#34892;&#26102;&#25928;&#29575;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32780;&#21463;&#27426;&#36814;&#12290;&#35768;&#22810;&#30456;&#20851;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#20363;&#22914;&#26102;&#31354;&#24314;&#27169;&#12289;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#36830;&#32493;&#25511;&#21046;&#65292;&#21253;&#21547;&#31561;&#21464;&#24615;&#65292;&#20363;&#22914;&#23545;&#20110;&#24179;&#31227;&#65292;&#27169;&#22411;&#21487;&#20197;&#21033;&#29992;&#26368;&#22823;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#35797;&#22270;&#22312;CNPs&#20013;&#21253;&#21547;&#31561;&#21464;&#24615;&#22312;&#36229;&#36807;&#20004;&#20010;&#36755;&#20837;&#32500;&#24230;&#20043;&#22806;&#30340;&#23610;&#24230;&#19978;&#26080;&#27861;&#26377;&#25928;&#25193;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#31995;&#26465;&#20214;&#31070;&#32463;&#36807;&#31243;&#65288;RCNPs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26377;&#25928;&#23558;&#31561;&#21464;&#24615;&#32435;&#20837;&#20219;&#20309;&#31070;&#32463;&#36807;&#31243;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25193;&#23637;&#20102;&#31561;&#21464;&#31070;&#32463;&#36807;&#31243;&#30340;&#36866;&#29992;&#24615;&#21644;&#24433;&#21709;&#21147;&#21040;&#26356;&#39640;&#30340;&#32500;&#24230;&#12290;&#25105;&#20204;&#22312;&#33258;&#28982;&#21253;&#21547;&#31561;&#21464;&#24615;&#20219;&#21153;&#30340;&#22823;&#37327;&#20219;&#21153;&#19978;&#32463;&#39564;&#35777;&#23454;&#20102;RCNPs&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Neural Processes (CNPs) are a class of metalearning models popular for combining the runtime efficiency of amortized inference with reliable uncertainty quantification. Many relevant machine learning tasks, such as spatio-temporal modeling, Bayesian Optimization and continuous control, contain equivariances -- for example to translation -- which the model can exploit for maximal performance. However, prior attempts to include equivariances in CNPs do not scale effectively beyond two input dimensions. In this work, we propose Relational Conditional Neural Processes (RCNPs), an effective approach to incorporate equivariances into any neural process model. Our proposed method extends the applicability and impact of equivariant neural processes to higher dimensions. We empirically demonstrate the competitive performance of RCNPs on a large array of tasks naturally containing equivariances.
&lt;/p&gt;</description></item><item><title>AdaStop&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#39564;&#32467;&#26524;&#21487;&#22797;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.10882</link><description>&lt;p&gt;
AdaStop&#65306;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#27604;&#36739;&#30340;&#39640;&#25928;&#21487;&#38752;&#24207;&#21015;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents. (arXiv:2306.10882v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10882
&lt;/p&gt;
&lt;p&gt;
AdaStop&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#39564;&#32467;&#26524;&#21487;&#22797;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#23454;&#39564;&#32467;&#26524;&#30340;&#21487;&#22797;&#29616;&#24615;&#21463;&#21040;&#36136;&#30097;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#21487;&#22797;&#29616;&#24615;&#21361;&#26426;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#19978;&#21487;&#38752;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#30001;&#20110;&#19968;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#19968;&#27425;&#25191;&#34892;&#24615;&#33021;&#26159;&#38543;&#26426;&#30340;&#65292;&#25152;&#20197;&#38656;&#35201;&#36827;&#34892;&#29420;&#31435;&#30340;&#22810;&#27425;&#25191;&#34892;&#26469;&#31934;&#30830;&#35780;&#20272;&#23427;&#12290;&#24403;&#27604;&#36739;&#22810;&#20010;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26102;&#65292;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#26159;&#38656;&#35201;&#36827;&#34892;&#22810;&#23569;&#27425;&#25191;&#34892;&#65292;&#24182;&#19988;&#22914;&#20309;&#30830;&#20445;&#36825;&#26679;&#27604;&#36739;&#30340;&#32467;&#26524;&#22312;&#29702;&#35770;&#19978;&#26159;&#21487;&#38752;&#30340;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#20351;&#29992;&#23569;&#20110;5&#20010;&#29420;&#31435;&#25191;&#34892;&#26469;&#27604;&#36739;&#31639;&#27861;&#65306;&#25105;&#20204;&#35748;&#20026;&#36825;&#36890;&#24120;&#26159;&#19981;&#22815;&#30340;&#12290;&#32780;&#19988;&#65292;&#24403;&#21516;&#26102;&#27604;&#36739;&#20960;&#20010;&#31639;&#27861;&#26102;&#65292;&#27599;&#20010;&#27604;&#36739;&#30340;&#35823;&#24046;&#37117;&#20250;&#32047;&#31215;&#65292;&#24517;&#39035;&#37319;&#29992;&#22810;&#37325;&#27979;&#35797;&#31243;&#24207;&#26469;&#32771;&#34385;&#36825;&#20123;&#35823;&#24046;&#65292;&#20197;&#32500;&#25345;&#20302;&#35823;&#24046;&#20445;&#35777;&#12290;&#20026;&#20102;&#20197;&#32479;&#35745;&#23398;&#19978;&#30340;&#21487;&#38752;&#26041;&#24335;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;AdaStop&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reproducibility of many experimental results in Deep Reinforcement Learning (RL) is under question. To solve this reproducibility crisis, we propose a theoretically sound methodology to compare multiple Deep RL algorithms. The performance of one execution of a Deep RL algorithm is random so that independent executions are needed to assess it precisely. When comparing several RL algorithms, a major question is how many executions must be made and how can we assure that the results of such a comparison is theoretically sound. Researchers in Deep RL often use less than 5 independent executions to compare algorithms: we claim that this is not enough in general. Moreover, when comparing several algorithms at once, the error of each comparison accumulates and must be taken into account with a multiple tests procedure to preserve low error guarantees. To address this problem in a statistically sound way, we introduce AdaStop, a new statistical test based on multiple group sequential tests
&lt;/p&gt;</description></item><item><title>innsight&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;R&#21253;&#65292;&#33021;&#22815;&#29420;&#31435;&#20110;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#35299;&#37322;&#26469;&#33258;&#20219;&#20309;R&#21253;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#20197;&#25581;&#31034;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21464;&#37327;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2306.10822</link><description>&lt;p&gt;
&#21033;&#29992;innsight&#21253;&#35299;&#37322;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Interpreting Deep Neural Networks with the Package innsight. (arXiv:2306.10822v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10822
&lt;/p&gt;
&lt;p&gt;
innsight&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;R&#21253;&#65292;&#33021;&#22815;&#29420;&#31435;&#20110;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#35299;&#37322;&#26469;&#33258;&#20219;&#20309;R&#21253;&#30340;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#20197;&#25581;&#31034;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21464;&#37327;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
R&#21253;innsight&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24037;&#20855;&#31665;&#65292;&#36890;&#36807;&#25152;&#35859;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#30340;&#21464;&#37327;&#35299;&#37322;&#12290;&#38500;&#20102;&#32479;&#19968;&#30340;&#29992;&#25143;&#21451;&#22909;&#30340;&#26694;&#26550;&#22806;&#65292;&#35813;&#21253;&#22312;&#19977;&#20010;&#26041;&#38754;&#33073;&#39062;&#32780;&#20986;&#65306;&#39318;&#20808;&#65292;&#23427;&#36890;&#24120;&#26159;&#31532;&#19968;&#20010;&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#30340;R&#21253;&#12290;&#20854;&#27425;&#65292;&#23427;&#29420;&#31435;&#20110;&#28145;&#24230;&#23398;&#20064;&#24211;&#65292;&#20801;&#35768;&#35299;&#37322;&#26469;&#33258;&#20219;&#20309;R&#21253;&#65292;&#21253;&#25324;keras&#12289;torch&#12289;neuralnet&#29978;&#33267;&#29992;&#25143;&#23450;&#20041;&#27169;&#22411;&#30340;&#27169;&#22411;&#12290;&#23613;&#31649;&#23427;&#24456;&#28789;&#27963;&#65292;&#20294;innsight&#22312;&#20869;&#37096;&#20174;torch&#21253;&#30340;&#24555;&#36895;&#21644;&#39640;&#25928;&#30340;&#25968;&#32452;&#35745;&#31639;&#20013;&#21463;&#30410;&#65292;&#36825;&#24314;&#31435;&#22312;LibTorch&#65288;PyTorch&#30340;C++&#21518;&#31471;&#65289;&#19978;&#65292;&#32780;&#19981;&#38656;&#35201;Python&#20381;&#36182;&#12290;&#26368;&#21518;&#65292;&#23427;&#25552;&#20379;&#20102;&#21508;&#31181;&#21487;&#35270;&#21270;&#24037;&#20855;&#65292;&#29992;&#20110;&#34920;&#26684;&#12289;&#20449;&#21495;&#12289;&#22270;&#20687;&#25968;&#25454;&#25110;&#36825;&#20123;&#25968;&#25454;&#30340;&#32452;&#21512;&#12290;&#27492;&#22806;&#65292;&#21487;&#20197;&#20351;&#29992;plotly&#21253;&#20197;&#20132;&#20114;&#26041;&#24335;&#21576;&#29616;&#36825;&#20123;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The R package innsight offers a general toolbox for revealing variable-wise interpretations of deep neural networks' predictions with so-called feature attribution methods. Aside from the unified and user-friendly framework, the package stands out in three ways: It is generally the first R package implementing feature attribution methods for neural networks. Secondly, it operates independently of the deep learning library allowing the interpretation of models from any R package, including keras, torch, neuralnet, and even custom models. Despite its flexibility, innsight benefits internally from the torch package's fast and efficient array calculations, which builds on LibTorch $-$ PyTorch's C++ backend $-$ without a Python dependency. Finally, it offers a variety of visualization tools for tabular, signal, image data or a combination of these. Additionally, the plots can be rendered interactively using the plotly package.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#22522;&#20110;&#35013;&#37197;&#32447;&#25968;&#25454;&#30340;&#21322;&#21512;&#25104;&#21046;&#36896;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#25903;&#25345;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2306.10816</link><description>&lt;p&gt;
$\texttt{causalAssembly}$: &#29992;&#20110;&#22522;&#20934;&#22240;&#26524;&#21457;&#29616;&#30340;&#29983;&#25104;&#30495;&#23454;&#29983;&#20135;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
$\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery. (arXiv:2306.10816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10816
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#22522;&#20110;&#35013;&#37197;&#32447;&#25968;&#25454;&#30340;&#21322;&#21512;&#25104;&#21046;&#36896;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#25903;&#25345;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#24555;&#36895;&#36827;&#23637;&#24182;&#36234;&#26469;&#36234;&#22810;&#22320;&#20381;&#38752;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22823;&#22810;&#25968;&#30495;&#23454;&#25968;&#25454;&#28304;&#20013;&#30495;&#27491;&#30340;&#22240;&#26524;&#20851;&#31995;&#20173;&#19981;&#20026;&#20154;&#25152;&#30693;&#65292;&#22240;&#27492;&#36825;&#20123;&#31639;&#27861;&#38656;&#35201;&#20805;&#20998;&#30340;&#32463;&#39564;&#39564;&#35777;&#12290;&#36825;&#20010;&#38382;&#39064;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#29615;&#32469;&#21512;&#36866;&#39640;&#36136;&#37327;&#25968;&#25454;&#21457;&#24067;&#30340;&#38544;&#31169;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#32452;&#22797;&#26434;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21046;&#36896;&#36807;&#31243;&#20013;&#35013;&#37197;&#32447;&#30340;&#27979;&#37327;&#25968;&#25454;&#12290;&#20511;&#21161;&#20110;&#23545;&#29289;&#29702;&#23398;&#30340;&#28145;&#20837;&#30740;&#31350;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#33021;&#22815;&#25552;&#20379;&#22320;&#38754;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#29031;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#35013;&#37197;&#32447;&#25968;&#25454;&#21644;&#30456;&#20851;&#30340;&#22320;&#38754;&#30495;&#23454;&#20449;&#24687;&#26469;&#26500;&#24314;&#19968;&#20010;&#31995;&#32479;&#65292;&#29983;&#25104;&#21322;&#21512;&#25104;&#36896;&#25968;&#25454;&#26469;&#25903;&#25345;&#22522;&#20934;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;&#20223;&#30495;&#25216;&#26415;&#26469;&#29983;&#25104;&#25968;&#25454;&#38598;&#65292;&#27169;&#20223;&#21407;&#22987;&#35013;&#37197;&#32447;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#65292;&#20445;&#30041;&#20102;&#36807;&#31243;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#21644;&#23427;&#20204;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for causal discovery have recently undergone rapid advances and increasingly draw on flexible nonparametric methods to process complex data. With these advances comes a need for adequate empirical validation of the causal relationships learned by different algorithms. However, for most real data sources true causal relations remain unknown. This issue is further compounded by privacy concerns surrounding the release of suitable high-quality data. To help address these challenges, we gather a complex dataset comprising measurements from an assembly line in a manufacturing context. This line consists of numerous physical processes for which we are able to provide ground truth causal relationships on the basis of a detailed study of the underlying physics. We use the assembly line data and associated ground truth information to build a system for generation of semisynthetic manufacturing data that supports benchmarking of causal discovery methods. To accomplish this, we employ 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;FOBO&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26799;&#24230;GP&#30340;&#20449;&#24687;&#65292;&#26377;&#25928;&#22320;&#35782;&#21035;&#20855;&#26377;&#38646;&#26799;&#24230;&#30340;&#28508;&#22312;&#26597;&#35810;&#28857;&#65292;&#37319;&#29992;&#22810;&#32423;&#37319;&#38598;&#20989;&#25968;&#26469;&#28508;&#22312;&#30830;&#23450;&#20840;&#23616;&#26368;&#22823;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.10815</link><description>&lt;p&gt;
&#23454;&#29992;&#30340;&#19968;&#38454;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Practical First-Order Bayesian Optimization Algorithms. (arXiv:2306.10815v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;FOBO&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#26799;&#24230;GP&#30340;&#20449;&#24687;&#65292;&#26377;&#25928;&#22320;&#35782;&#21035;&#20855;&#26377;&#38646;&#26799;&#24230;&#30340;&#28508;&#22312;&#26597;&#35810;&#28857;&#65292;&#37319;&#29992;&#22810;&#32423;&#37319;&#38598;&#20989;&#25968;&#26469;&#28508;&#22312;&#30830;&#23450;&#20840;&#23616;&#26368;&#22823;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31532;&#19968;&#38454;&#36125;&#21494;&#26031;&#20248;&#21270;(FOBO)&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#39034;&#24207;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24403;&#22320;&#26597;&#35810;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#35780;&#20272;&#65292;&#26469;&#23547;&#25214;&#26114;&#36149;&#30340;&#40657;&#30418;&#23376;&#30446;&#26631;&#20989;&#25968;&#30340;&#20840;&#23616;&#26497;&#20540;&#12290;&#36825;&#31181;&#26041;&#27861;&#20551;&#35774;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;(GP)&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#23427;&#20204;&#26500;&#24314;&#19968;&#20010;&#33719;&#21462;&#20989;&#25968;&#65292;&#20197;&#35782;&#21035;&#19979;&#19968;&#20010;&#26597;&#35810;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#23454;&#29992;&#30340;FOBO&#31639;&#27861;&#65292;&#23427;&#26377;&#25928;&#21033;&#29992;&#20102;&#26799;&#24230;GP&#30340;&#20449;&#24687;&#65292;&#20197;&#35782;&#21035;&#20855;&#26377;&#38646;&#26799;&#24230;&#30340;&#28508;&#22312;&#26597;&#35810;&#28857;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#32423;&#37319;&#38598;&#20989;&#25968;&#65292;&#22312;&#31532;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22810;&#37325;&#37325;&#21551;&#26469;&#20248;&#21270;&#36739;&#20302;&#32423;&#21035;&#30340;&#37319;&#38598;&#20989;&#25968;&#65292;&#20197;&#35782;&#21035;&#20855;&#26377;&#38646;&#26799;&#24230;&#20540;&#30340;&#28508;&#22312;&#26597;&#35810;&#28857;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#19978;&#23618;&#33719;&#21462;&#20989;&#25968;&#26681;&#25454;&#23427;&#20204;&#30340;&#20989;&#25968;&#20540;&#23545;&#36825;&#20123;&#26597;&#35810;&#28857;&#36827;&#34892;&#25490;&#24207;&#65292;&#20197;&#28508;&#22312;&#22320;&#30830;&#23450;&#20840;&#23616;&#26368;&#22823;&#20540;&#12290;&#20316;&#20026;&#26368;&#21518;&#19968;&#27493;&#65292;&#26368;&#22823;&#20540;&#30340;&#28508;&#22312;&#28857;&#34987;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
First Order Bayesian Optimization (FOBO) is a sample efficient sequential approach to find the global maxima of an expensive-to-evaluate black-box objective function by suitably querying for the function and its gradient evaluations. Such methods assume Gaussian process (GP) models for both, the function and its gradient, and use them to construct an acquisition function that identifies the next query point. In this paper, we propose a class of practical FOBO algorithms that efficiently utilizes the information from the gradient GP to identify potential query points with zero gradients. We construct a multi-level acquisition function where in the first step, we optimize a lower level acquisition function with multiple restarts to identify potential query points with zero gradient value. We then use the upper level acquisition function to rank these query points based on their function values to potentially identify the global maxima. As a final step, the potential point of maxima is ch
&lt;/p&gt;</description></item><item><title>P-tensors &#25552;&#20379;&#20102;&#26500;&#24314;&#39640;&#38454;&#28040;&#24687;&#20256;&#36882;&#32593;&#32476;&#30340;&#36890;&#29992;&#24418;&#24335;&#65292;&#20854;&#22312;&#20998;&#23376;&#31561;&#39640;&#24230;&#32467;&#26500;&#21270;&#30340;&#22270;&#24418;&#20013;&#20855;&#26377;&#20248;&#24322;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.10767</link><description>&lt;p&gt;
P&#24352;&#37327;&#65306;&#26500;&#24314;&#39640;&#38454;&#28040;&#24687;&#20256;&#36882;&#32593;&#32476;&#30340;&#36890;&#29992;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
P-tensors: a General Formalism for Constructing Higher Order Message Passing Networks. (arXiv:2306.10767v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10767
&lt;/p&gt;
&lt;p&gt;
P-tensors &#25552;&#20379;&#20102;&#26500;&#24314;&#39640;&#38454;&#28040;&#24687;&#20256;&#36882;&#32593;&#32476;&#30340;&#36890;&#29992;&#24418;&#24335;&#65292;&#20854;&#22312;&#20998;&#23376;&#31561;&#39640;&#24230;&#32467;&#26500;&#21270;&#30340;&#22270;&#24418;&#20013;&#20855;&#26377;&#20248;&#24322;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#20960;&#31687;&#35770;&#25991;&#34920;&#26126;&#65292;&#39640;&#38454;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#39640;&#24230;&#32467;&#26500;&#21270;&#30340;&#22270;&#24418;&#22914;&#20998;&#23376;&#20013;&#33021;&#22815;&#27604;&#20854;&#26631;&#20934;&#30340;&#28040;&#24687;&#20256;&#36882;&#23545;&#24212;&#29289;&#33719;&#24471;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#36890;&#36807;&#32771;&#34385;&#21253;&#21547;&#22312;&#32473;&#23450;&#22270;&#24418;&#20013;&#30340;&#23376;&#22270;&#30340;&#39640;&#38454;&#34920;&#31034;&#65292;&#28982;&#21518;&#22312;&#23427;&#20204;&#20043;&#38388;&#25191;&#34892;&#26576;&#20123;&#32447;&#24615;&#26144;&#23556;&#26469;&#24037;&#20316;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26500;&#27491;&#24335;&#21270;&#20026;&#25490;&#21015;&#31561;&#21464;&#24352;&#37327;&#25110;P&#24352;&#37327;&#65292;&#24182;&#25512;&#23548;&#20986;&#25152;&#26377;&#32447;&#24615;&#26144;&#23556;&#20043;&#38388;&#30340;&#20219;&#24847;&#39034;&#24207;&#31561;&#21464;P&#24352;&#37327;&#30340;&#22522;&#30784;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#33539;&#24335;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#20102;&#29616;&#26377;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent papers have recently shown that higher order graph neural networks can achieve better accuracy than their standard message passing counterparts, especially on highly structured graphs such as molecules. These models typically work by considering higher order representations of subgraphs contained within a given graph and then perform some linear maps between them. We formalize these structures as permutation equivariant tensors, or P-tensors, and derive a basis for all linear maps between arbitrary order equivariant P-tensors. Experimentally, we demonstrate this paradigm achieves state of the art performance on several benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#31639;&#27861;&#26694;&#26550;BNN-DP&#65292;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#26469;&#20445;&#35777;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#65292;&#35813;&#31639;&#27861;&#26694;&#26550;&#30340;&#31934;&#24230;&#21644;&#26102;&#38388;&#25928;&#29575;&#22343;&#39640;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.10742</link><description>&lt;p&gt;
BNN-DP: &#36890;&#36807;&#21160;&#24577;&#35268;&#21010;&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
BNN-DP: Robustness Certification of Bayesian Neural Networks via Dynamic Programming. (arXiv:2306.10742v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#31639;&#27861;&#26694;&#26550;BNN-DP&#65292;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#26469;&#20445;&#35777;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#65292;&#35813;&#31639;&#27861;&#26694;&#26550;&#30340;&#31934;&#24230;&#21644;&#26102;&#38388;&#25928;&#29575;&#22343;&#39640;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#26694;&#26550;BNN-DP&#65292;&#29992;&#20110;&#20998;&#26512;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#30340;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#23558;BNN&#35270;&#20026;&#38543;&#26426;&#21160;&#24577;&#31995;&#32479;&#30340;&#35299;&#37322;&#65292;&#21033;&#29992;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#27839;&#30528;&#32593;&#32476;&#23618;&#27425;&#36793;&#30028;&#20272;&#35745;BNN&#30340;&#39044;&#27979;&#33539;&#22260;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#36793;&#30028;&#20256;&#25773;&#25216;&#26415;&#21644;&#20984;&#26494;&#24347;&#26469;&#23548;&#20986;&#21453;&#21521;&#36882;&#24402;&#36807;&#31243;&#65292;&#21033;&#29992;&#20998;&#27573;&#20223;&#23556;&#20989;&#25968;&#26469;&#20248;&#21270;BNN&#30340;&#39044;&#27979;&#33539;&#22260;&#12290;&#35813;&#31639;&#27861;&#26159;&#36890;&#29992;&#30340;&#65292;&#21487;&#20197;&#22788;&#29702;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#12290;&#22312;&#23545;&#21508;&#31181;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20197;&#21450;BNN&#20307;&#31995;&#32467;&#26500;&#36827;&#34892;&#30340;&#19968;&#31995;&#21015;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;BNN-DP&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#22235;&#20010;&#25968;&#37327;&#32423;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#39640;&#30340;&#31934;&#24230;&#21644;&#26102;&#38388;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce BNN-DP, an efficient algorithmic framework for analysis of adversarial robustness of Bayesian Neural Networks (BNNs). Given a compact set of input points $T\subset \mathbb{R}^n$, BNN-DP computes lower and upper bounds on the BNN's predictions for all the points in $T$. The framework is based on an interpretation of BNNs as stochastic dynamical systems, which enables the use of Dynamic Programming (DP) algorithms to bound the prediction range along the layers of the network. Specifically, the method uses bound propagation techniques and convex relaxations to derive a backward recursion procedure to over-approximate the prediction range of the BNN with piecewise affine functions. The algorithm is general and can handle both regression and classification tasks. On a set of experiments on various regression and classification tasks and BNN architectures, we show that BNN-DP outperforms state-of-the-art methods by up to four orders of magnitude in both tightness 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10656</link><description>&lt;p&gt;
&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65306;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20154;&#31867;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VHGM&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#22522;&#20110;&#25513;&#30721;&#24314;&#27169;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#20581;&#24247;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36890;&#36807;&#20351;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#26377;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#21069;&#26223;&#65292;&#20363;&#22914;&#29992;&#20110;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#21307;&#30103;&#23646;&#24615;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20154;&#26684;&#20043;&#38388;&#30340;&#20851;&#31995;&#23545;&#20110;&#29702;&#35299;&#21644;&#25913;&#21892;&#36523;&#20307;&#21644;&#31934;&#31070;&#29366;&#20917;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#34394;&#25311;&#20154;&#31867;&#29983;&#25104;&#27169;&#22411;&#65288;VHGM&#65289;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#26377;&#20851;&#21307;&#30103;&#20445;&#20581;&#12289;&#29983;&#27963;&#26041;&#24335;&#21644;&#20010;&#24615;&#30340;&#23646;&#24615;&#12290;VHGM&#26159;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20351;&#29992;&#25513;&#30721;&#24314;&#27169;&#35757;&#32451;&#65292;&#22312;&#24050;&#30693;&#23646;&#24615;&#30340;&#26465;&#20214;&#19979;&#23398;&#20064;&#23646;&#24615;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#21033;&#29992;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;VHGM&#39640;&#25928;&#22320;&#23398;&#20064;&#20102;&#36229;&#36807;1,800&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#25968;&#20540;&#35780;&#20272;&#20102;VHGM&#21450;&#20854;&#35757;&#32451;&#25216;&#26415;&#30340;&#24615;&#33021;&#12290;&#20316;&#20026;VHGM&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#28436;&#31034;&#20102;&#29992;&#25143;&#24773;&#22659;&#65292;&#20363;&#22914;&#21307;&#30103;&#23646;&#24615;&#30340;&#34394;&#25311;&#27979;&#37327;&#21644;&#29983;&#27963;&#26041;&#24335;&#30340;&#20551;&#35774;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#20840;&#33021;&#39044;&#27979;&#22120;&#23545;&#21333;&#25351;&#25968;&#27169;&#22411;&#36827;&#34892;&#33258;&#20027;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#19988;&#20165;&#38656;&#35201;&#36793;&#32536;&#20855;&#26377;&#26377;&#30028;&#30340;&#20108;&#38454;&#30697;&#12290;&#35813;&#26041;&#27861;&#21487;&#36866;&#29992;&#20110;&#20219;&#24847;&#21333;&#35843;&#21644;&#21033;&#26222;&#24076;&#33576;&#28608;&#27963;&#65292;&#24182;&#19988;&#36807;&#24448;&#26041;&#27861;&#20013;&#25152;&#38656;&#30340;&#26356;&#24378;&#20998;&#24067;&#20551;&#35774;&#19981;&#20877;&#38656;&#35201;&#12290;&#30740;&#31350;&#32773;&#20204;&#36890;&#36807;&#21305;&#37197;&#25439;&#22833;&#19982;$\ell_p$&#36317;&#31163;&#30340;&#20851;&#31995;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20998;&#26512;&#26041;&#24335;&#65292;&#24182;&#22312;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#20026;&#26631;&#20934;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.10615</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#33021;&#39044;&#27979;&#22120;&#23545;&#21333;&#25351;&#25968;&#27169;&#22411;&#36827;&#34892;&#33258;&#20027;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Agnostically Learning Single-Index Models using Omnipredictors. (arXiv:2306.10615v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#20840;&#33021;&#39044;&#27979;&#22120;&#23545;&#21333;&#25351;&#25968;&#27169;&#22411;&#36827;&#34892;&#33258;&#20027;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#19988;&#20165;&#38656;&#35201;&#36793;&#32536;&#20855;&#26377;&#26377;&#30028;&#30340;&#20108;&#38454;&#30697;&#12290;&#35813;&#26041;&#27861;&#21487;&#36866;&#29992;&#20110;&#20219;&#24847;&#21333;&#35843;&#21644;&#21033;&#26222;&#24076;&#33576;&#28608;&#27963;&#65292;&#24182;&#19988;&#36807;&#24448;&#26041;&#27861;&#20013;&#25152;&#38656;&#30340;&#26356;&#24378;&#20998;&#24067;&#20551;&#35774;&#19981;&#20877;&#38656;&#35201;&#12290;&#30740;&#31350;&#32773;&#20204;&#36890;&#36807;&#21305;&#37197;&#25439;&#22833;&#19982;$\ell_p$&#36317;&#31163;&#30340;&#20851;&#31995;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20998;&#26512;&#26041;&#24335;&#65292;&#24182;&#22312;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#20026;&#26631;&#20934;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32473;&#20986;&#20102;&#31532;&#19968;&#20010;&#32467;&#26524;&#65292;&#21363;&#22312;&#20855;&#26377;&#20219;&#24847;&#21333;&#35843;&#21644;&#21033;&#26222;&#24076;&#33576;&#28608;&#27963;&#30340;&#21333;&#25351;&#25968;&#27169;&#22411;&#65288;SIM&#65289;&#20013;&#36827;&#34892;&#33258;&#20027;&#23398;&#20064;&#12290;&#25152;&#26377;&#20043;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#20165;&#36866;&#29992;&#20110;&#21487;&#20197;&#23454;&#29616;&#30340;&#35774;&#32622;&#65292;&#35201;&#20040;&#38656;&#35201;&#30693;&#36947;&#28608;&#27963;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20165;&#38656;&#35201;&#36793;&#32536;&#20855;&#26377;&#26377;&#30028;&#30340;&#20108;&#38454;&#30697;&#65292;&#32780;&#25152;&#26377;&#20043;&#21069;&#30340;&#24037;&#20316;&#37117;&#38656;&#35201;&#26356;&#24378;&#30340;&#20998;&#24067;&#20551;&#35774;&#65288;&#22914;&#21453;&#27987;&#24230;&#25110;&#26377;&#30028;&#24615;&#65289;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;[GHK&#65291;23]&#26368;&#36817;&#30340;&#20840;&#33021;&#39044;&#27979;&#20351;&#29992;&#31526;&#21512;&#26657;&#20934;&#30340;&#35266;&#23519;&#31934;&#24230;&#30340;&#39044;&#27979;&#22120;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31616;&#21333;&#19988;&#20381;&#36182;&#20110;Bregman&#36317;&#31163;&#65288;&#25110;&#21305;&#37197;&#25439;&#22833;&#65289;&#19982;$\ell_p$&#36317;&#31163;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#20026;GLMtron&#21644;&#36923;&#36753;&#22238;&#24402;&#31561;&#26631;&#20934;&#31639;&#27861;&#22312;&#19981;&#21487;&#30693;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#26032;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give the first result for agnostically learning Single-Index Models (SIMs) with arbitrary monotone and Lipschitz activations. All prior work either held only in the realizable setting or required the activation to be known. Moreover, we only require the marginal to have bounded second moments, whereas all prior work required stronger distributional assumptions (such as anticoncentration or boundedness). Our algorithm is based on recent work by [GHK$^+$23] on omniprediction using predictors satisfying calibrated multiaccuracy. Our analysis is simple and relies on the relationship between Bregman divergences (or matching losses) and $\ell_p$ distances. We also provide new guarantees for standard algorithms like GLMtron and logistic regression in the agnostic setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#21644;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#32416;&#27491;&#22240;&#27835;&#30103;&#21464;&#37327;&#19981;&#20934;&#30830;&#27979;&#37327;&#24341;&#36215;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20559;&#24046;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#21644;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.10614</link><description>&lt;p&gt;
&#24102;&#26377;&#22024;&#26434;&#27835;&#30103;&#21644;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#30340;&#21487;&#35782;&#21035;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Identifiable causal inference with noisy treatment and no side information. (arXiv:2306.10614v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#20391;&#38754;&#20449;&#24687;&#21644;&#20855;&#26377;&#22797;&#26434;&#38750;&#32447;&#24615;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#32416;&#27491;&#22240;&#27835;&#30103;&#21464;&#37327;&#19981;&#20934;&#30830;&#27979;&#37327;&#24341;&#36215;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20559;&#24046;&#30340;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#21644;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26576;&#20123;&#22240;&#26524;&#25512;&#26029;&#22330;&#26223;&#20013;&#65292;&#27835;&#30103;&#65288;&#21363;&#21407;&#22240;&#65289;&#21464;&#37327;&#30340;&#27979;&#37327;&#23384;&#22312;&#19981;&#20934;&#30830;&#24615;&#65292;&#20363;&#22914;&#22312;&#27969;&#34892;&#30149;&#23398;&#25110;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#12290;&#26410;&#33021;&#32416;&#27491;&#27979;&#37327;&#35823;&#24046;&#30340;&#24433;&#21709;&#21487;&#33021;&#23548;&#33268;&#20559;&#24046;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#27809;&#26377;&#20174;&#22240;&#26524;&#35270;&#35282;&#30740;&#31350;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20801;&#35768;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#24182;&#19988;&#19981;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#20391;&#38754;&#20449;&#24687;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#22330;&#26223;&#65292;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#23427;&#20551;&#35774;&#23384;&#22312;&#19968;&#20010;&#36830;&#32493;&#30340;&#27835;&#30103;&#21464;&#37327;&#65292;&#35813;&#21464;&#37327;&#27979;&#37327;&#19981;&#20934;&#30830;&#12290;&#24314;&#31435;&#22312;&#29616;&#26377;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#21363;&#20351;&#27809;&#26377;&#27979;&#37327;&#35823;&#24046;&#26041;&#24046;&#25110;&#20854;&#20182;&#20391;&#38754;&#20449;&#24687;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#28145;&#24230;&#28508;&#22312;&#21464;&#37327;&#27169;&#22411;&#65292;&#20854;&#20013;&#39640;&#26031;&#26465;&#20214;&#30001;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20998;&#25674;&#26435;&#37325;&#21464;&#20998;&#23458;&#35266;&#20989;&#25968;&#26469;&#35757;&#32451;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In some causal inference scenarios, the treatment (i.e. cause) variable is measured inaccurately, for instance in epidemiology or econometrics. Failure to correct for the effect of this measurement error can lead to biased causal effect estimates. Previous research has not studied methods that address this issue from a causal viewpoint while allowing for complex nonlinear dependencies and without assuming access to side information. For such as scenario, this paper proposes a model that assumes a continuous treatment variable which is inaccurately measured. Building on existing results for measurement error models, we prove that our model's causal effect estimates are identifiable, even without knowledge of the measurement error variance or other side information. Our method relies on a deep latent variable model where Gaussian conditionals are parameterized by neural networks, and we develop an amortized importance-weighted variational objective for training the model. Empirical resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;</title><link>http://arxiv.org/abs/2306.10592</link><description>&lt;p&gt;
&#22522;&#20110;&#32039;&#26680;&#30340;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional expectation via compact kernels. (arXiv:2306.10592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32039;&#26680;&#30340;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#35299;&#20915;&#26465;&#20214;&#26399;&#26395;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#23454;&#29616;&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19988;&#25104;&#21151;&#24212;&#29992;&#20110;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#12289;&#26465;&#20214;&#26399;&#26395;&#21644;&#27969;&#24418;&#23398;&#20064;&#20219;&#21153;&#36890;&#24120;&#21487;&#20197;&#22312;&#23547;&#25214;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#31215;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20844;&#20849;&#29615;&#22659;&#19979;&#34920;&#36848;&#12290;&#26412;&#25991;&#38024;&#23545;&#36825;&#20010;&#26356;&#19968;&#33324;&#30340;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#19968;&#31181;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#12290;&#26680;&#31215;&#20998;&#31639;&#23376;&#34987;&#29992;&#20316;&#32039;&#33268;&#21270;&#24037;&#20855;&#65292;&#23558;&#20272;&#35745;&#38382;&#39064;&#35774;&#32622;&#20026;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#35813;&#26041;&#31243;&#30340;&#35299;&#34987;&#35777;&#26126;&#23545;&#25968;&#20540;&#36924;&#36817;&#26159;&#31283;&#23450;&#30340;&#65292;&#20174;&#32780;&#30830;&#20445;&#20102;&#25968;&#25454;&#39537;&#21160;&#23454;&#29616;&#30340;&#25910;&#25947;&#24615;&#12290;&#24635;&#20307;&#25216;&#26415;&#26131;&#20110;&#23454;&#29616;&#65292;&#36824;&#23637;&#31034;&#20102;&#20854;&#22312;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#25104;&#21151;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The separate tasks of denoising, conditional expectation and manifold learning can often be posed in a common setting of finding the conditional expectations arising from a product of two random variables. This paper focuses on this more general problem and describes an operator theoretic approach to estimating the conditional expectation. Kernel integral operators are used as a compactification tool, to set up the estimation problem as a linear inverse problem in a reproducing kernel Hilbert space. This equation is shown to have solutions that are stable to numerical approximation, thus guaranteeing the convergence of data-driven implementations. The overall technique is easy to implement, and their successful application to some real-world problems are also shown.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2306.10590</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#21542;&#22312;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#20266;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#19979;&#30340;&#26377;&#25928;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#29256;&#26412;&#30340;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#25253;&#36947;&#30340;&#20197;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;(DML)&#20272;&#35745;&#37327;&#20026;&#20013;&#24515;&#30340;&#21517;&#20041;$(1-\alpha)$Wald&#32622;&#20449;&#21306;&#38388;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#65292;&#23545;Rotnitzky&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#21452;&#37325;&#31283;&#20581;(DR)&#20989;&#25968;&#31867;&#30340;&#20219;&#20309;&#25104;&#21592;&#36827;&#34892;&#26816;&#39564;&#12290;DR&#20989;&#25968;&#31867;&#22312;&#32463;&#27982;&#23398;&#21644;&#29983;&#29289;&#32479;&#35745;&#23398;&#20013;&#20855;&#26377;&#24191;&#27867;&#21644;&#26680;&#24515;&#30340;&#37325;&#35201;&#24615;&#12290;&#23427;&#20005;&#26684;&#21253;&#25324;&#20004;&#20010;&#31867;&#21035;&#65292;&#21363;(i)&#21487;&#20197;&#34987;&#20889;&#25104;&#26465;&#20214;&#26399;&#26395;&#30340;&#20223;&#23556;&#20989;&#25968;&#26399;&#26395;&#30340;&#22343;&#26041;&#36830;&#32493;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#26159;&#30001;Chernozhukov&#31561;&#20154;&#30740;&#31350;&#30340;&#65292;&#20197;&#21450;Robins&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#31867;&#21035;&#12290;&#30446;&#21069;DR&#20989;&#25968;&#30340;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#20540;&#26159;DML&#20272;&#35745;&#20540;&#12290;$\hat{\psi}_{1}$&#30340;&#20559;&#24046;&#21462;&#20915;&#20110;&#20004;&#20010;&#36741;&#21161;&#20989;&#25968;$b$&#21644;$p$&#30340;&#20272;&#35745;&#29575;&#30340;&#20056;&#31215;&#12290;&#26368;&#24120;&#35265;&#30340;&#26159;&#65292;&#20998;&#26512;&#24072;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#30475;&#20284;&#26080;&#20851;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#37325;&#26032;&#26500;&#36896;&#20026;&#20849;&#21516;&#30340;&#20004;&#20010;&#20132;&#38169;&#27493;&#39588;&#65292;&#21363;&#20048;&#35266;&#31574;&#30053;&#25913;&#36827;&#21644;&#21518;&#35265;&#36866;&#24212;&#65292;&#32479;&#19968;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#21152;&#36895;&#26041;&#27861;&#20013;&#30340;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;&#30340;&#20849;&#21516;&#29702;&#35770;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10587</link><description>&lt;p&gt;
&#31574;&#30053;&#20248;&#21270;&#20013;&#30340;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimism and Adaptivity in Policy Optimization. (arXiv:2306.10587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#30475;&#20284;&#26080;&#20851;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#37325;&#26032;&#26500;&#36896;&#20026;&#20849;&#21516;&#30340;&#20004;&#20010;&#20132;&#38169;&#27493;&#39588;&#65292;&#21363;&#20048;&#35266;&#31574;&#30053;&#25913;&#36827;&#21644;&#21518;&#35265;&#36866;&#24212;&#65292;&#32479;&#19968;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#21152;&#36895;&#26041;&#27861;&#20013;&#30340;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;&#30340;&#20849;&#21516;&#29702;&#35770;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#36890;&#36807;&#8220;&#20048;&#35266;&#24615;&#8221;&#21644;&#8220;&#36866;&#24212;&#24615;&#8221;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21152;&#36895;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#30340;&#32479;&#19968;&#33539;&#24335;&#12290;&#36890;&#36807;&#21033;&#29992;&#31574;&#30053;&#36845;&#20195;&#21644;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#65292;&#25105;&#20204;&#23558;&#19968;&#20123;&#30475;&#20284;&#26080;&#20851;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#37325;&#26032;&#26500;&#36896;&#20026;&#20004;&#20010;&#20132;&#38169;&#27493;&#39588;&#65288;i&#65289;&#20048;&#35266;&#31574;&#30053;&#25913;&#36827;&#25805;&#20316;&#22120;&#20351;&#29992;&#8220;&#26799;&#24230;&#19978;&#21319;&#39044;&#27979;&#8221;&#23558;&#20808;&#21069;&#30340;&#31574;&#30053;$\pi_t$&#26144;&#23556;&#21040;&#19968;&#20010;&#20551;&#35774;$\pi_{t+1}$&#65292;&#28982;&#21518;&#65288;ii&#65289;&#23545;$\pi_{t+1}$&#30340;&#24615;&#33021;&#36827;&#34892;&#37096;&#20998;&#35780;&#20272;&#65292;&#24182;&#22522;&#20110;&#27492;&#36827;&#34892;&#8220;&#21518;&#35265;&#36866;&#24212;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#20849;&#20139;&#30340;&#35270;&#35282;&#26469;&#20849;&#21516;&#34920;&#36798;&#20854;&#20182;&#20247;&#25152;&#21608;&#30693;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#36719;&#20214;&#21644;&#20048;&#35266;&#31574;&#30053;&#36845;&#20195;&#12289;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#12289;&#22522;&#20110;&#21069;&#21521;&#25628;&#32034;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#25913;&#36827;&#21644;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20851;&#20110;&#36890;&#36807;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;&#21152;&#36895;&#30340;&#20849;&#21516;&#29702;&#35770;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We work towards a unifying paradigm for accelerating policy optimization methods in reinforcement learning (RL) through \emph{optimism} \&amp; \emph{adaptivity}. Leveraging the deep connection between policy iteration and policy gradient methods, we recast seemingly unrelated policy optimization algorithms as the repeated application of two interleaving steps (i) an \emph{optimistic policy improvement operator} maps a prior policy $\pi_t$ to a hypothesis $\pi_{t+1}$ using a \emph{gradient ascent prediction}, followed by (ii) a \emph{hindsight adaptation} of the optimistic prediction based on a partial evaluation of the performance of $\pi_{t+1}$. We use this shared lens to jointly express other well-known algorithms, including soft and optimistic policy iteration, natural actor-critic methods, model-based policy improvement based on forward search, and meta-learning algorithms. By doing so, we shed light on collective theoretical properties related to acceleration via optimism \&amp; adaptivit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;OpenDataVal&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#25972;&#21512;&#20102;&#22810;&#31181;&#25968;&#25454;&#38598;&#21644;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26469;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.10577</link><description>&lt;p&gt;
OpenDataVal&#65306;&#19968;&#31181;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#30340;&#32479;&#19968;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
OpenDataVal: a Unified Benchmark for Data Valuation. (arXiv:2306.10577v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;OpenDataVal&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#25972;&#21512;&#20102;&#22810;&#31181;&#25968;&#25454;&#38598;&#21644;&#20061;&#31181;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26469;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#21333;&#20010;&#25968;&#25454;&#28857;&#30340;&#36136;&#37327;&#21644;&#24433;&#21709;&#23545;&#20110;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#21644;&#20943;&#36731;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#19981;&#33391;&#20559;&#24046;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#20010;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#26469;&#37327;&#21270;&#25968;&#25454;&#36136;&#37327;&#65292;&#20294;&#36824;&#32570;&#20047;&#19968;&#20010;&#31995;&#32479;&#21270;&#21644;&#26631;&#20934;&#21270;&#30340;&#25968;&#25454;&#20272;&#20540;&#22522;&#20934;&#27979;&#35797;&#31995;&#32479;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;OpenDataVal&#65292;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#21644;&#32479;&#19968;&#30340;&#22522;&#20934;&#27979;&#35797;&#26694;&#26550;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#33021;&#22815;&#24212;&#29992;&#21644;&#27604;&#36739;&#21508;&#31181;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#12290;OpenDataVal&#25552;&#20379;&#20102;&#19968;&#20010;&#32508;&#21512;&#29615;&#22659;&#65292;&#21253;&#25324;&#65288;i&#65289;&#21508;&#31181;&#22270;&#20687;&#65292;&#33258;&#28982;&#35821;&#35328;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#65292;&#65288;ii&#65289;&#20061;&#31181;&#19981;&#21516;&#30340;&#26368;&#20808;&#36827;&#30340;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#30340;&#23454;&#29616;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#21487;&#20197;&#23548;&#20837;&#20219;&#20309;scikit-learn&#27169;&#22411;&#30340;&#39044;&#27979;&#27169;&#22411;API&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#19979;&#28216;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#29992;&#20110;&#35780;&#20272;&#25968;&#25454;&#20540;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;OpenDataVal&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#20998;&#26512;&#65292;&#37327;&#21270;&#24182;&#27604;&#36739;&#19981;&#21516;&#25968;&#25454;&#20272;&#20540;&#31639;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the quality and impact of individual data points is critical for improving model performance and mitigating undesirable biases within the training dataset. Several data valuation algorithms have been proposed to quantify data quality, however, there lacks a systemic and standardized benchmarking system for data valuation. In this paper, we introduce OpenDataVal, an easy-to-use and unified benchmark framework that empowers researchers and practitioners to apply and compare various data valuation algorithms. OpenDataVal provides an integrated environment that includes (i) a diverse collection of image, natural language, and tabular datasets, (ii) implementations of nine different state-of-the-art data valuation algorithms, and (iii) a prediction model API that can import any models in scikit-learn. Furthermore, we propose four downstream machine learning tasks for evaluating the quality of data values. We perform benchmarking analysis using OpenDataVal, quantifying and comparin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#29366;&#24577;&#36712;&#36857;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#26080;&#38656;&#20381;&#36182;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#21644;&#28385;&#36275;&#39640;&#32500;&#31995;&#32479;&#19982;&#38271;&#26102;&#38388;&#36328;&#24230;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2306.10574</link><description>&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;
&lt;/p&gt;
&lt;p&gt;
Score-based Data Assimilation. (arXiv:2306.10574v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#29366;&#24577;&#36712;&#36857;&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#26080;&#38656;&#20381;&#36182;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#21644;&#28385;&#36275;&#39640;&#32500;&#31995;&#32479;&#19982;&#38271;&#26102;&#38388;&#36328;&#24230;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#20840;&#38754;&#30340;&#24418;&#24335;&#19979;&#65292;&#25968;&#25454;&#21516;&#21270;&#35299;&#20915;&#20102;&#37492;&#23450;&#38543;&#26426;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#21487;&#33021;&#29366;&#24577;&#36712;&#36857;&#30340;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#65292;&#20174;&#32780;&#35299;&#37322;&#23613;&#31649;&#23384;&#22312;&#22122;&#22768;&#25110;&#19981;&#23436;&#25972;&#35266;&#27979;&#30340;&#20869;&#23481;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21253;&#25324;&#22522;&#20110;&#31890;&#23376;&#30340;&#21644;&#21487;&#21464;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#31639;&#27861;&#20381;&#36182;&#20110;&#36716;&#31227;&#21160;&#24577;&#36827;&#34892;&#25512;&#26029;&#65292;&#36825;&#22312;&#38271;&#26102;&#38388;&#36328;&#24230;&#25110;&#20855;&#26377;&#22797;&#26434;&#21160;&#24577;&#30340;&#39640;&#32500;&#31995;&#32479;&#20013;&#21464;&#24471;&#26840;&#25163;&#65292;&#22914;&#28023;&#27915;&#25110;&#22823;&#27668;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26469;&#23454;&#29616;&#36712;&#36857;&#25512;&#26029;&#12290;&#25105;&#20204;&#23398;&#20064;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#29366;&#24577;&#36712;&#36857;&#27169;&#22411;&#65292;&#36825;&#26159;&#22522;&#20110;&#19968;&#20010;&#20851;&#38190;&#27934;&#23519;&#65292;&#21363;&#20219;&#24847;&#38271;&#36712;&#36857;&#30340;&#24471;&#20998;&#21487;&#20197;&#20998;&#35299;&#20026;&#30701;&#37096;&#20998;&#30340;&#24471;&#20998;&#31995;&#21015;&#12290;&#22312;&#35757;&#32451;&#23436;&#25104;&#21518;&#65292;&#36816;&#29992;&#24471;&#20998;&#27169;&#22411;&#36827;&#34892;&#26080;&#33258;&#22238;&#24402;&#30340;&#25512;&#26029;&#65292;&#36890;&#36807;&#21516;&#26102;&#29983;&#25104;&#25152;&#26377;&#29366;&#24577;&#12290;&#19982;&#20247;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#35299;&#32806;&#20102;&#35266;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data assimilation, in its most comprehensive form, addresses the Bayesian inverse problem of identifying plausible state trajectories that explain noisy or incomplete observations of stochastic dynamical systems. Various approaches have been proposed to solve this problem, including particle-based and variational methods. However, most algorithms depend on the transition dynamics for inference, which becomes intractable for long time horizons or for high-dimensional systems with complex dynamics, such as oceans or atmospheres. In this work, we introduce score-based data assimilation for trajectory inference. We learn a score-based generative model of state trajectories based on the key insight that the score of an arbitrarily long trajectory can be decomposed into a series of scores over short segments. After training, inference is carried out using the score model, in a non-autoregressive manner by generating all states simultaneously. Quite distinctively, we decouple the observation 
&lt;/p&gt;</description></item><item><title>&#23613;&#31649;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#24120;&#24120;&#21033;&#29992;&#38750;&#22240;&#26524;&#30456;&#20851;&#24615;&#65292;&#20294;&#26159;&#36890;&#36807;&#36866;&#24403;&#30340;&#29305;&#24449;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#39044;&#27979;&#27169;&#22411;&#20173;&#28982;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2306.10551</link><description>&lt;p&gt;
&#39044;&#27979;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can predictive models be used for causal inference?. (arXiv:2306.10551v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10551
&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#24120;&#24120;&#21033;&#29992;&#38750;&#22240;&#26524;&#30456;&#20851;&#24615;&#65292;&#20294;&#26159;&#36890;&#36807;&#36866;&#24403;&#30340;&#29305;&#24449;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#39044;&#27979;&#27169;&#22411;&#20173;&#28982;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#36890;&#24120;&#20551;&#35774;&#23427;&#20204;&#24120;&#24120;&#21033;&#29992;&#38750;&#22240;&#26524;&#30456;&#20851;&#24615;&#65292;&#36825;&#21487;&#33021;&#20250;&#38480;&#21046;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#35299;&#37322;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#36825;&#31181;&#26435;&#34913;&#24182;&#19981;&#20687;&#39044;&#26399;&#30340;&#37027;&#20040;&#28145;&#21051;&#21644;&#22522;&#26412;&#12290;&#34429;&#28982;&#24403;&#25552;&#20379;&#25152;&#26377;&#25968;&#25454;&#36827;&#34892;&#39044;&#27979;&#26102;&#65292;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30830;&#23454;&#20542;&#21521;&#20110;&#20351;&#29992;&#38750;&#22240;&#26524;&#29305;&#24449;&#36827;&#34892;&#39044;&#27979;&#65292;&#20294;&#26159;&#21487;&#20197;&#36890;&#36807;&#25353;&#29031;Pearl&#30340;&#21453;&#21521;&#38376;&#25511;&#20934;&#21017;&#36873;&#25321;&#29305;&#24449;&#26469;&#32422;&#26463;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26576;&#20123;&#31639;&#27861;&#65288;&#23588;&#20854;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#21487;&#20197;&#22312;&#29305;&#24449;&#20849;&#32447;&#24615;&#19979;&#25552;&#20379;&#36817;&#20284;&#26080;&#20559;&#30340;&#25928;&#24212;&#20272;&#35745;&#12290;&#21097;&#20313;&#30340;&#20559;&#24046;&#21487;&#30001;&#29305;&#23450;&#30340;&#31639;&#27861;&#32467;&#26500;&#21644;&#36229;&#21442;&#25968;&#36873;&#25321;&#36827;&#34892;&#35299;&#37322;&#12290;&#22240;&#27492;&#65292;&#24403;&#29992;&#20110;&#39044;&#27979;&#25110;&#25512;&#26029;&#26102;&#65292;&#26368;&#20339;&#36229;&#21442;&#25968;&#35774;&#32622;&#26159;&#19981;&#21516;&#30340;&#65292;&#36825;&#35777;&#23454;&#20102;&#20004;&#32773;&#20043;&#38388;&#23384;&#22312;&#26435;&#34913;&#30340;&#19968;&#33324;&#30452;&#35273;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20351;&#29992;&#36866;&#24403;&#30340;&#29305;&#24449;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#39044;&#27979;&#27169;&#22411;&#20173;&#28982;&#21487;&#20197;&#26377;&#25928;&#22320;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised machine learning (ML) and deep learning (DL) algorithms excel at predictive tasks, but it is commonly assumed that they often do so by exploiting non-causal correlations, which may limit both interpretability and generalizability. Here, we show that this trade-off between explanation and prediction is not as deep and fundamental as expected. Whereas ML and DL algorithms will indeed tend to use non-causal features for prediction when fed indiscriminately with all data, it is possible to constrain the learning process of any ML and DL algorithm by selecting features according to Pearl's backdoor adjustment criterion. In such a situation, some algorithms, in particular deep neural networks, can provide near unbiased effect estimates under feature collinearity. Remaining biases are explained by the specific algorithmic structures as well as hyperparameter choice. Consequently, optimal hyperparameter settings are different when tuned for prediction or inference, confirming the ge
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#37319;&#29992;dropout&#25216;&#26415;&#30340;&#32479;&#35745;&#34892;&#20026;&#20855;&#26377;&#26356;&#21152;&#24494;&#22937;&#30340;&#19982;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#32852;&#31995;&#65292;dropout&#24182;&#19981;&#20687;&#39044;&#26399;&#20013;&#37027;&#26679;&#20855;&#26377;&#31283;&#23450;&#30340;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10529</link><description>&lt;p&gt;
&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;Dropout&#27491;&#21017;&#21270;&#19982;$\ell_2$-Penalization&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Dropout Regularization Versus $\ell_2$-Penalization in the Linear Model. (arXiv:2306.10529v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10529
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#37319;&#29992;dropout&#25216;&#26415;&#30340;&#32479;&#35745;&#34892;&#20026;&#20855;&#26377;&#26356;&#21152;&#24494;&#22937;&#30340;&#19982;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#32852;&#31995;&#65292;dropout&#24182;&#19981;&#20687;&#39044;&#26399;&#20013;&#37027;&#26679;&#20855;&#26377;&#31283;&#23450;&#30340;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#37319;&#29992;dropout&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25512;&#23548;&#20102;&#36845;&#20195;&#30340;&#26399;&#26395;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#38750;&#28176;&#36817;&#24615;&#30028;&#38480;&#12290;&#19982;&#25991;&#29486;&#20013;&#24191;&#27867;&#24341;&#29992;&#30340;dropout&#19982;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#26399;&#26395;&#32852;&#31995;&#19981;&#21516;&#30340;&#26159;&#65292;&#32467;&#26524;&#34920;&#26126;&#20102;&#30001;&#20110;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#19982;dropout&#24341;&#20837;&#30340;&#38468;&#21152;&#38543;&#26426;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20004;&#32773;&#20043;&#38388;&#23384;&#22312;&#30528;&#26356;&#21152;&#24494;&#22937;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#31181;&#31616;&#21270;&#29256;&#30340;dropout&#65292;&#23427;&#19981;&#20855;&#26377;&#27491;&#21017;&#21270;&#20316;&#29992;&#65292;&#24182;&#25910;&#25947;&#20110;&#26368;&#23567;&#24179;&#26041;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the statistical behavior of gradient descent iterates with dropout in the linear regression model. In particular, non-asymptotic bounds for expectations and covariance matrices of the iterates are derived. In contrast with the widely cited connection between dropout and $\ell_2$-regularization in expectation, the results indicate a much more subtle relationship, owing to interactions between the gradient descent dynamics and the additional randomness induced by dropout. We also study a simplified variant of dropout which does not have a regularizing effect and converges to the least squares estimator.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#27714;&#35299;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;OED&#38382;&#39064;&#65292;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#26356;&#23569;&#30340;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.10430</link><description>&lt;p&gt;
&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Variational Sequential Optimal Experimental Design using Reinforcement Learning. (arXiv:2306.10430v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10430
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#30340;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#27714;&#35299;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;OED&#38382;&#39064;&#65292;&#32467;&#26524;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#26356;&#23569;&#30340;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21464;&#20998;&#24207;&#21015;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745; (vsOED) &#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#21644;&#20449;&#24687;&#22686;&#30410;&#25928;&#29992;&#26469;&#26368;&#20248;&#22320;&#35774;&#35745;&#26377;&#38480;&#24207;&#21015;&#30340;&#23454;&#39564;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#21464;&#20998;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#19979;&#30028;&#20272;&#35745;&#26399;&#26395;&#25928;&#29992;&#12290;&#36890;&#36807;&#21516;&#26102;&#26368;&#22823;&#21270;&#21464;&#20998;&#19979;&#30028;&#21644;&#25191;&#34892;&#31574;&#30053;&#26799;&#24230;&#26356;&#26032;&#26469;&#25968;&#20540;&#35299;&#20915;&#26368;&#20248;&#35774;&#35745;&#31574;&#30053;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#31995;&#21015;&#38754;&#21521;&#21442;&#25968;&#25512;&#26029;&#12289;&#27169;&#22411;&#21306;&#20998;&#21644;&#30446;&#26631;&#23548;&#21521;&#39044;&#27979;&#30340;OED&#38382;&#39064;&#12290;&#36825;&#20123;&#26696;&#20363;&#28085;&#30422;&#20102;&#26174;&#24335;&#21644;&#38544;&#24335;&#20284;&#28982;&#20989;&#25968;&#12289;&#40635;&#28902;&#21442;&#25968;&#21644;&#22522;&#20110;&#29289;&#29702;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;vsOED&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20197;&#21069;&#30340;&#39034;&#24207;&#35774;&#35745;&#31639;&#27861;&#30456;&#27604;&#65292;&#26679;&#26412;&#25928;&#29575;&#22823;&#22823;&#25552;&#39640;&#65292;&#25152;&#38656;&#21069;&#21521;&#27169;&#22411;&#27169;&#25311;&#27425;&#25968;&#20943;&#23569;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce variational sequential Optimal Experimental Design (vsOED), a new method for optimally designing a finite sequence of experiments under a Bayesian framework and with information-gain utilities. Specifically, we adopt a lower bound estimator for the expected utility through variational approximation to the Bayesian posteriors. The optimal design policy is solved numerically by simultaneously maximizing the variational lower bound and performing policy gradient updates. We demonstrate this general methodology for a range of OED problems targeting parameter inference, model discrimination, and goal-oriented prediction. These cases encompass explicit and implicit likelihoods, nuisance parameters, and physics-based partial differential equation models. Our vsOED results indicate substantially improved sample efficiency and reduced number of forward model simulations compared to previous sequential design algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#34701;&#21512;&#20102;&#26377;/&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#20026;M&#20272;&#35745;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23450;&#21046;&#21435;&#20559;&#26041;&#27861;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#32467;&#21512;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10395</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Distributed Semi-Supervised Sparse Statistical Inference. (arXiv:2306.10395v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#34701;&#21512;&#20102;&#26377;/&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#20026;M&#20272;&#35745;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23450;&#21046;&#21435;&#20559;&#26041;&#27861;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#32467;&#21512;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#29615;&#22659;&#19979;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22810;&#36718;&#20998;&#24067;&#24335;&#21435;&#20559;&#20272;&#35745;&#22120;&#65292;&#23427;&#34701;&#21512;&#20102;&#26377;&#26631;&#35760;&#21644;&#26080;&#26631;&#35760;&#25968;&#25454;&#65292;&#24182;&#19988;&#28436;&#31034;&#20102;&#39069;&#22806;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#22914;&#20309;&#24110;&#21161;&#25552;&#39640;&#27599;&#36718;&#36845;&#20195;&#30340;&#32479;&#35745;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;$M$- &#20272;&#35745;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#37327;&#36523;&#23450;&#21046;&#30340;&#21435;&#20559;&#26041;&#27861;&#65292;&#20855;&#20307;&#26681;&#25454;&#25439;&#22833;&#20989;&#25968;&#30340;&#29305;&#23450;&#24418;&#24335;&#32780;&#23450;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20809;&#28369;&#25439;&#22833;&#65292;&#20363;&#22914;&#32477;&#23545;&#20559;&#24046;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#39640;&#32500;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#32467;&#21512;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is devoted to studying the semi-supervised sparse statistical inference in a distributed setup. An efficient multi-round distributed debiased estimator, which integrates both labeled and unlabelled data, is developed. We will show that the additional unlabeled data helps to improve the statistical rate of each round of iteration. Our approach offers tailored debiasing methods for $M$-estimation and generalized linear model according to the specific form of the loss function. Our method also applies to a non-smooth loss like absolute deviation loss. Furthermore, our algorithm is computationally efficient since it requires only one estimation of a high-dimensional inverse covariance matrix. We demonstrate the effectiveness of our method by presenting simulation studies and real data applications that highlight the benefits of incorporating unlabeled data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#38543;&#26426;&#28608;&#21169;&#22122;&#22768;&#19979;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#21644;/&#25110;&#26102;&#21464;&#31574;&#30053;&#19979;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;&#36825;&#36866;&#29992;&#20110;&#23433;&#20840;&#23398;&#20064;&#25511;&#21046;&#20013;&#30340;&#21463;&#38480;&#21046;&#32447;&#24615;&#31995;&#32479;&#65292;&#19982;&#32447;&#24615;&#31574;&#30053;&#30456;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2306.10369</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#31574;&#30053;&#19979;&#32447;&#24615;&#31995;&#32479;&#30340;&#26080;&#28176;&#36827;&#31995;&#32479;&#36776;&#35782;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic System Identification for Linear Systems with Nonlinear Policies. (arXiv:2306.10369v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#65292;&#36866;&#29992;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#38543;&#26426;&#28608;&#21169;&#22122;&#22768;&#19979;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#21644;/&#25110;&#26102;&#21464;&#31574;&#30053;&#19979;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;&#36825;&#36866;&#29992;&#20110;&#23433;&#20840;&#23398;&#20064;&#25511;&#21046;&#20013;&#30340;&#21463;&#38480;&#21046;&#32447;&#24615;&#31995;&#32479;&#65292;&#19982;&#32447;&#24615;&#31574;&#30053;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#38543;&#26426;&#28608;&#21169;&#22122;&#22768;&#19979;&#65292;&#38024;&#23545;&#38750;&#32447;&#24615;&#21644;/&#25110;&#26102;&#21464;&#31574;&#30053;&#19979;&#30340;&#32447;&#24615;&#31995;&#32479;&#30340;&#21333;&#36712;&#36857;&#31995;&#32479;&#36776;&#35782;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#30340;&#21160;&#26426;&#26159;&#20445;&#35777;&#22522;&#20110;&#23398;&#20064;&#30340;&#21463;&#38480;&#21046;&#32447;&#24615;&#31995;&#32479;&#30340;&#23433;&#20840;&#25511;&#21046;&#65292;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#23433;&#20840;&#31574;&#30053;&#36890;&#24120;&#26159;&#38750;&#32447;&#24615;&#21644;&#26102;&#21464;&#30340;&#65292;&#20197;&#28385;&#36275;&#29366;&#24577;&#21644;&#36755;&#20837;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#35823;&#24046;&#30028;&#65292;&#21482;&#35201;&#29983;&#25104;&#30340;&#29366;&#24577;&#21644;&#25805;&#20316;&#36712;&#36857;&#26377;&#30028;&#65292;&#35813;&#30028;&#36866;&#29992;&#20110;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20013;&#20351;&#29992;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#21644;/&#25110;&#26102;&#21464;&#31574;&#30053;&#19979;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;&#36825;&#26174;&#30528;&#25512;&#24191;&#20102;&#29616;&#26377;&#30340;&#32447;&#24615;&#31995;&#32479;&#36776;&#35782;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#36825;&#20123;&#20445;&#35777;&#36890;&#24120;&#32771;&#34385;&#29420;&#31435;&#21516;&#20998;&#24067;&#38543;&#26426;&#36755;&#20837;&#25110;&#32447;&#24615;&#31574;&#30053;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#23545;&#20110;&#36712;&#36857;&#38271;&#24230;&#12289;&#31995;&#32479;&#32500;&#25968;&#21644;&#28608;&#21169;&#27700;&#24179;&#30340;&#20381;&#36182;&#19982;&#32447;&#24615;&#31574;&#30053;&#30456;&#19968;&#33268;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20570;&#20102;&#23454;&#39564;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers a single-trajectory system identification problem for linear systems under general nonlinear and/or time-varying policies with i.i.d. random excitation noises. The problem is motivated by safe learning-based control for constrained linear systems, where the safe policies during the learning process are usually nonlinear and time-varying for satisfying the state and input constraints. In this paper, we provide a non-asymptotic error bound for least square estimation when the data trajectory is generated by any nonlinear and/or time-varying policies as long as the generated state and action trajectories are bounded. This significantly generalizes the existing non-asymptotic guarantees for linear system identification, which usually consider i.i.d. random inputs or linear policies. Interestingly, our error bound is consistent with that for linear policies with respect to the dependence on the trajectory length, system dimensions, and excitation levels. Lastly, we demo
&lt;/p&gt;</description></item><item><title>DHQRN&#21487;&#20197;&#39044;&#27979;&#26356;&#19968;&#33324;&#30340;Huber&#20998;&#20301;&#25968;&#65292;&#24182;&#19988;&#22312;&#39044;&#27979;&#20998;&#24067;&#30340;&#23614;&#37096;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.10306</link><description>&lt;p&gt;
&#28145;&#24230;Huber&#20998;&#20301;&#25968;&#22238;&#24402;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep Huber quantile regression networks. (arXiv:2306.10306v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10306
&lt;/p&gt;
&lt;p&gt;
DHQRN&#21487;&#20197;&#39044;&#27979;&#26356;&#19968;&#33324;&#30340;Huber&#20998;&#20301;&#25968;&#65292;&#24182;&#19988;&#22312;&#39044;&#27979;&#20998;&#24067;&#30340;&#23614;&#37096;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20856;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#24212;&#29992;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#24179;&#26041;&#35823;&#24046;&#25110;&#32477;&#23545;&#35823;&#24046;&#35780;&#20998;&#20989;&#25968;&#26469;&#25253;&#21578;&#39044;&#27979;&#27010;&#29575;&#20998;&#24067;&#30340;&#22343;&#20540;&#25110;&#20013;&#20301;&#25968;&#12290;&#21457;&#20986;&#26356;&#22810;&#39044;&#27979;&#27010;&#29575;&#20998;&#24067;&#30340;&#20989;&#25968;&#65288;&#20998;&#20301;&#25968;&#21644;&#26399;&#26395;&#20540;&#65289;&#30340;&#37325;&#35201;&#24615;&#24050;&#34987;&#35748;&#20026;&#26159;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#25163;&#27573;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#36890;&#36807;&#20998;&#20301;&#25968;&#21644;&#26399;&#26395;&#20540;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;QRNN&#21644;ERNN&#65289;&#21487;&#20197;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#28145;&#24230;Huber&#20998;&#20301;&#25968;&#22238;&#24402;&#32593;&#32476;&#65288;DHQRN&#65289;&#65292;&#23427;&#23558;QRNN&#21644;ERNN&#23884;&#22871;&#20026;&#36793;&#32536;&#24773;&#20917;&#12290; DHQRN&#21487;&#20197;&#39044;&#27979;Huber&#20998;&#20301;&#25968;&#65292;&#36825;&#26159;&#26356;&#19968;&#33324;&#30340;&#20989;&#25968;&#65292;&#22240;&#20026;&#23427;&#20204;&#23558;&#20998;&#20301;&#25968;&#21644;&#26399;&#26395;&#20540;&#20316;&#20026;&#26497;&#38480;&#24773;&#20917;&#23884;&#22871;&#36215;&#26469;&#12290;&#20027;&#35201;&#24605;&#24819;&#26159;&#20351;&#29992;Huber&#20998;&#20301;&#25968;&#22238;&#24402;&#20989;&#25968;&#35757;&#32451;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#36825;&#19982;Huber&#20998;&#20301;&#25968;&#21151;&#33021;&#19968;&#33268;&#12290;&#20316;&#20026;&#27010;&#24565;&#39564;&#35777;&#65292;DHQRN&#34987;&#24212;&#29992;&#20110;&#39044;&#27979;&#25151;&#20215;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#65292;&#24182;&#19982;&#20854;&#20182;&#22238;&#24402;&#25216;&#26415;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#20960;&#20010;&#35823;&#24046;&#25351;&#26631;&#20013;&#65292;DHQRN&#32988;&#36807;&#20854;&#20182;&#25216;&#26415;&#65292;&#22312;&#39044;&#27979;&#20998;&#24067;&#30340;&#23614;&#37096;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Typical machine learning regression applications aim to report the mean or the median of the predictive probability distribution, via training with a squared or an absolute error scoring function. The importance of issuing predictions of more functionals of the predictive probability distribution (quantiles and expectiles) has been recognized as a means to quantify the uncertainty of the prediction. In deep learning (DL) applications, that is possible through quantile and expectile regression neural networks (QRNN and ERNN respectively). Here we introduce deep Huber quantile regression networks (DHQRN) that nest QRNNs and ERNNs as edge cases. DHQRN can predict Huber quantiles, which are more general functionals in the sense that they nest quantiles and expectiles as limiting cases. The main idea is to train a deep learning algorithm with the Huber quantile regression function, which is consistent for the Huber quantile functional. As a proof of concept, DHQRN are applied to predict hou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36866;&#24212;&#19981;&#21516;&#30340;&#22122;&#22768;&#27700;&#24179;&#21644;&#26799;&#24230;&#27604;&#20363;&#33539;&#22260;&#65292;&#20174;&#32780;&#36798;&#21040;&#65288;&#36817;&#20284;&#65289;&#26368;&#20248;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.10278</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Adaptive Strategies in Non-convex Optimization. (arXiv:2306.10278v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36866;&#24212;&#19981;&#21516;&#30340;&#22122;&#22768;&#27700;&#24179;&#21644;&#26799;&#24230;&#27604;&#20363;&#33539;&#22260;&#65292;&#20174;&#32780;&#36798;&#21040;&#65288;&#36817;&#20284;&#65289;&#26368;&#20248;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#31639;&#27861;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#23601;&#21487;&#20197;&#34920;&#29616;&#24471;&#19982;&#30693;&#36947;&#36825;&#20010;&#38382;&#39064;&#29305;&#23450;&#21442;&#25968;&#30340;&#31639;&#27861;&#30456;&#31454;&#20105;&#65292;&#37027;&#20040;&#23601;&#35828;&#31639;&#27861;&#23545;&#26576;&#20010;&#21442;&#25968;&#26159;&#33258;&#36866;&#24212;&#30340;&#12290;&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#25105;&#20204;&#22312;&#20197;&#19979;&#22330;&#26223;&#20013;&#24320;&#21457;&#33258;&#36866;&#24212;&#31639;&#27861;&#30340;&#24037;&#20316;&#65306;1. &#22312;&#38543;&#26426;&#20248;&#21270;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#21482;&#25910;&#21040;&#38543;&#26426;&#26799;&#24230;&#65292;&#24182;&#19988;&#35780;&#20272;&#36825;&#20123;&#26799;&#24230;&#30340;&#22122;&#22768;&#27700;&#24179;&#26497;&#22823;&#22320;&#24433;&#21709;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#36890;&#24120;&#38656;&#35201;&#35843;&#25972;&#22122;&#22768;&#27700;&#24179;&#25165;&#33021;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#65292;&#32780;&#25105;&#20204;&#24320;&#21457;&#20102;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#30693;&#36947;&#22122;&#22768;&#33539;&#22260;&#30340;&#24773;&#20917;&#19979;&#33258;&#21160;&#20445;&#35777;&#65288;&#36817;&#20284;&#65289;&#26368;&#20248;&#36895;&#29575;&#12290;2. &#22312;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#27599;&#20010;&#22352;&#26631;&#36724;&#19978;&#30340;&#26799;&#24230;&#22823;&#23567;&#27604;&#20363;&#21487;&#20197;&#25955;&#24067;&#22312;&#38750;&#24120;&#24191;&#30340;&#33539;&#22260;&#20869;&#65292;&#38500;&#38750;&#37319;&#29992;&#20687;BatchNorm&#36825;&#26679;&#30340;&#24402;&#19968;&#21270;&#25216;&#26415;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19981;&#32771;&#34385;&#26799;&#24230;&#27604;&#20363;&#38382;&#39064;&#30340;&#31639;&#27861;&#21487;&#33021;&#34920;&#29616;&#38750;&#24120;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
An algorithm is said to be adaptive to a certain parameter (of the problem) if it does not need a priori knowledge of such a parameter but performs competitively to those that know it. This dissertation presents our work on adaptive algorithms in following scenarios: 1. In the stochastic optimization setting, we only receive stochastic gradients and the level of noise in evaluating them greatly affects the convergence rate. Tuning is typically required when without prior knowledge of the noise scale in order to achieve the optimal rate. Considering this, we designed and analyzed noise-adaptive algorithms that can automatically ensure (near)-optimal rates under different noise scales without knowing it. 2. In training deep neural networks, the scales of gradient magnitudes in each coordinate can scatter across a very wide range unless normalization techniques, like BatchNorm, are employed. In such situations, algorithms not addressing this problem of gradient scales can behave very poor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;MAPS&#21644;MAPS-SE&#20004;&#20010;&#31639;&#27861;&#65292;&#21487;&#22312;&#22810;&#40657;&#30418;&#39044;&#35328;&#24773;&#20917;&#19979;&#65292;&#37319;&#29992;&#27169;&#20223;&#23398;&#20064;&#24182;&#20027;&#21160;&#36873;&#25321;&#21644;&#25913;&#36827;&#26368;&#20248;&#39044;&#35328;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10259</link><description>&lt;p&gt;
&#22810;&#40657;&#30418;&#39044;&#35328;&#19979;&#30340;&#20027;&#21160;&#31574;&#30053;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Active Policy Improvement from Multiple Black-box Oracles. (arXiv:2306.10259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;MAPS&#21644;MAPS-SE&#20004;&#20010;&#31639;&#27861;&#65292;&#21487;&#22312;&#22810;&#40657;&#30418;&#39044;&#35328;&#24773;&#20917;&#19979;&#65292;&#37319;&#29992;&#27169;&#20223;&#23398;&#20064;&#24182;&#20027;&#21160;&#36873;&#25321;&#21644;&#25913;&#36827;&#26368;&#20248;&#39044;&#35328;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#21508;&#31181;&#22797;&#26434;&#39046;&#22495;&#20013;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#26159;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#30830;&#23450;&#26377;&#25928;&#31574;&#30053;&#24448;&#24448;&#38656;&#35201;&#36827;&#34892;&#24191;&#27867;&#30340;&#25506;&#32034;&#65292;&#32780;&#27169;&#20223;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#19987;&#23478;&#28436;&#31034;&#26469;&#25351;&#23548;&#25506;&#32034;&#65292;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#24773;&#22659;&#19979;&#65292;&#20154;&#20204;&#36890;&#24120;&#21482;&#33021;&#25509;&#35302;&#21040;&#22810;&#20010;&#27425;&#20248;&#30340;&#40657;&#30418;&#39044;&#35328;&#65292;&#32780;&#19981;&#26159;&#21333;&#20010;&#26368;&#20248;&#30340;&#39044;&#35328;&#65292;&#36825;&#20123;&#39044;&#35328;&#19981;&#33021;&#22312;&#25152;&#26377;&#29366;&#24577;&#19979;&#26222;&#36941;&#20248;&#20110;&#24444;&#27492;&#65292;&#36825;&#32473;&#20027;&#21160;&#20915;&#23450;&#22312;&#21738;&#31181;&#29366;&#24577;&#19979;&#20351;&#29992;&#21738;&#31181;&#39044;&#35328;&#20197;&#21450;&#22914;&#20309;&#25913;&#36827;&#21508;&#33258;&#20272;&#35745;&#20540;&#20989;&#25968;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;MAPS&#21644;MAPS-SE&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has made significant strides in various complex domains. However, identifying an effective policy via RL often necessitates extensive exploration. Imitation learning aims to mitigate this issue by using expert demonstrations to guide exploration. In real-world scenarios, one often has access to multiple suboptimal black-box experts, rather than a single optimal oracle. These experts do not universally outperform each other across all states, presenting a challenge in actively deciding which oracle to use and in which state. We introduce MAPS and MAPS-SE, a class of policy improvement algorithms that perform imitation learning from multiple suboptimal oracles. In particular, MAPS actively selects which of the oracles to imitate and improve their value function estimates, and MAPS-SE additionally leverages an active state exploration criterion to determine which states one should explore. We provide a comprehensive theoretical analysis and demonstrate that MAP
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#22312;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;ODE&#31995;&#32479;&#65292;&#21487;&#20197;&#35299;&#20915;&#26174;&#24335;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#25968;&#25454;&#21644;&#22270;&#20687;&#25968;&#25454;&#20013;&#37117;&#20855;&#26377;&#36890;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10189</link><description>&lt;p&gt;
&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#23398;&#20064;&#39640;&#32500;&#38750;&#21442;&#25968;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning High-Dimensional Nonparametric Differential Equations via Multivariate Occupation Kernel Functions. (arXiv:2306.10189v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10189
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32447;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#22312;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;ODE&#31995;&#32479;&#65292;&#21487;&#20197;&#35299;&#20915;&#26174;&#24335;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#30340;&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#25968;&#25454;&#21644;&#22270;&#20687;&#25968;&#25454;&#20013;&#37117;&#20855;&#26377;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;$d$&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;$n$&#20010;&#36712;&#36857;&#24555;&#29031;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#31995;&#32479;&#38656;&#35201;&#23398;&#20064;$d$&#20010;&#20989;&#25968;&#12290;&#38500;&#38750;&#20855;&#26377;&#39069;&#22806;&#30340;&#31995;&#32479;&#23646;&#24615;&#30693;&#35782;&#65292;&#20363;&#22914;&#31232;&#30095;&#24615;&#21644;&#23545;&#31216;&#24615;&#65292;&#21542;&#21017;&#26174;&#24335;&#30340;&#20844;&#24335;&#25353;&#20108;&#27425;&#26041;&#32553;&#25918;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21521;&#37327;&#20540;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#25552;&#20379;&#30340;&#38544;&#24335;&#20844;&#24335;&#23398;&#20064;&#30340;&#32447;&#24615;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;ODE&#37325;&#20889;&#20026;&#26356;&#24369;&#30340;&#31215;&#20998;&#24418;&#24335;&#65292;&#25105;&#20204;&#38543;&#21518;&#36827;&#34892;&#26368;&#23567;&#21270;&#24182;&#25512;&#23548;&#20986;&#25105;&#20204;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#35299;&#21521;&#37327;&#22330;&#20381;&#36182;&#20110;&#19982;&#35299;&#36712;&#36857;&#30456;&#20851;&#30340;&#22810;&#20803;&#21344;&#20301;&#26680;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;$d$&#21487;&#33021;&#36229;&#36807;100&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#20174;&#22270;&#20687;&#25968;&#25454;&#23398;&#20064;&#38750;&#21442;&#25968;&#19968;&#38454;&#25311;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning a nonparametric system of ordinary differential equations (ODEs) from $n$ trajectory snapshots in a $d$-dimensional state space requires learning $d$ functions of $d$ variables. Explicit formulations scale quadratically in $d$ unless additional knowledge about system properties, such as sparsity and symmetries, is available. In this work, we propose a linear approach to learning using the implicit formulation provided by vector-valued Reproducing Kernel Hilbert Spaces. By rewriting the ODEs in a weaker integral form, which we subsequently minimize, we derive our learning algorithm. The minimization problem's solution for the vector field relies on multivariate occupation kernel functions associated with the solution trajectories. We validate our approach through experiments on highly nonlinear simulated and real data, where $d$ may exceed 100. We further demonstrate the versatility of the proposed method by learning a nonparametric first order quasilinear partial differential 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Samplet&#22352;&#26631;&#19979;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#24341;&#20837;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#22686;&#21152;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#30456;&#27604;&#20110;&#21333;&#23610;&#24230;&#22522;&#65292;Samplet&#22522;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#26356;&#22810;&#31867;&#22411;&#30340;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20351;&#29992;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10180</link><description>&lt;p&gt;
&#22522;&#20110;Samplet&#22522; Pursuit &#30340;&#26680;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Samplet basis pursuit. (arXiv:2306.10180v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Samplet&#22352;&#26631;&#19979;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#24341;&#20837;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#22686;&#21152;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#30456;&#27604;&#20110;&#21333;&#23610;&#24230;&#22522;&#65292;Samplet&#22522;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#26356;&#22810;&#31867;&#22411;&#30340;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20351;&#29992;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22522;&#20110;l1&#27491;&#21017;&#21270;&#30340;Samplet&#22352;&#26631;&#19979;&#30340;&#26680;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;Samplet&#22522;&#30340;&#31995;&#25968;&#19978;&#65292;&#24212;&#29992;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#24378;&#21046;&#22686;&#21152;&#31232;&#30095;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#31216;&#36825;&#31181;&#26041;&#27861;&#20026;Samplet&#22522; Pursuit&#12290;Samplet&#22522;&#26159;&#27874;&#24418;&#31867;&#22411;&#30340;&#26377;&#31526;&#21495;&#27979;&#24230;&#65292;&#19987;&#38376;&#29992;&#20110;&#25955;&#20081;&#25968;&#25454;&#12290;&#23427;&#20204;&#20855;&#26377;&#19982;&#23567;&#27874;&#30456;&#20284;&#30340;&#26412;&#22320;&#21270;&#12289;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#21644;&#25968;&#25454;&#21387;&#32553;&#24615;&#36136;&#12290;&#21487;&#20197;&#22312;Samplet&#22522;&#19978;&#31232;&#30095;&#22320;&#34920;&#31034;&#30340;&#20449;&#21495;&#31867;&#27604;&#21333;&#23610;&#24230;&#22522;&#19978;&#33021;&#22815;&#34920;&#31034;&#31232;&#30095;&#30340;&#20449;&#21495;&#31867;&#21035;&#35201;&#22823;&#24471;&#22810;&#12290;&#29305;&#21035;&#22320;&#65292;&#20165;&#29992;&#22522;&#20989;&#25968;&#26144;&#23556;&#30340;&#20960;&#20010;&#29305;&#24449;&#21472;&#21152;&#21363;&#21487;&#34920;&#31034;&#30340;&#25152;&#26377;&#20449;&#21495;&#20063;&#21487;&#20197;&#22312;Samplet&#22352;&#26631;&#19979;&#23454;&#29616;&#31232;&#30095;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23558;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#19982;&#24555;&#36895;&#36845;&#20195;&#25910;&#32553;&#38408;&#20540;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#31232;&#30095;&#24615;&#21644;&#39044;&#27979;&#31934;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernel-based learning in samplet coordinates with l1-regularization. The application of an l1-regularization term enforces sparsity of the coefficients with respect to the samplet basis. Therefore, we call this approach samplet basis pursuit. Samplets are wavelet-type signed measures, which are tailored to scattered data. They provide similar properties as wavelets in terms of localization, multiresolution analysis, and data compression. The class of signals that can sparsely be represented in a samplet basis is considerably larger than the class of signals which exhibit a sparse representation in the single-scale basis. In particular, every signal that can be represented by the superposition of only a few features of the canonical feature map is also sparse in samplet coordinates. We propose the efficient solution of the problem under consideration by combining soft-shrinkage with the semi-smooth Newton method and compare the approach to the fast iterative shrinkage thresh
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#24341;&#23548;&#24335;&#34920;&#31034;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#21457;&#29616;&#19982;&#33945;&#29305;&#21345;&#32599;&#21644;&#27531;&#24046;&#26799;&#24230;&#31639;&#27861;&#23398;&#20064;&#30340;&#29305;&#24449;&#22823;&#22810;&#19981;&#21516;</title><link>http://arxiv.org/abs/2306.10171</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24341;&#23548;&#24335;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Bootstrapped Representations in Reinforcement Learning. (arXiv:2306.10171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#24341;&#23548;&#24335;&#34920;&#31034;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#21457;&#29616;&#19982;&#33945;&#29305;&#21345;&#32599;&#21644;&#27531;&#24046;&#26799;&#24230;&#31639;&#27861;&#23398;&#20064;&#30340;&#29305;&#24449;&#22823;&#22810;&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#29366;&#24577;&#34920;&#31034;&#26159;&#22788;&#29702;&#22823;&#22411;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;&#20851;&#38190;&#12290;&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#25215;&#35834;&#26159;&#33258;&#21160;&#26500;&#24314;&#36866;&#21512;&#35299;&#20915;&#20219;&#21153;&#30340;&#29305;&#24449;&#65292;&#20294;&#36825;&#26679;&#30340;&#34920;&#31034;&#21487;&#33021;&#19981;&#20250;&#20174;&#28145;&#24230;RL&#20195;&#29702;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;&#20013;&#20986;&#29616;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#24120;&#24120;&#23558;&#36741;&#21161;&#30446;&#26631;&#32435;&#20837;&#23398;&#20064;&#36807;&#31243;&#20013;&#65292;&#24182;&#24110;&#21161;&#24418;&#22609;&#23398;&#20064;&#30340;&#29366;&#24577;&#34920;&#31034;&#12290;&#24341;&#23548;&#26041;&#27861;&#26159;&#22914;&#20170;&#27492;&#31867;&#38468;&#21152;&#39044;&#27979;&#30340;&#36873;&#25321;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#25429;&#33719;&#30340;&#29305;&#24449;&#19981;&#28165;&#26970;&#65292;&#20063;&#19981;&#30693;&#36947;&#23427;&#20204;&#19982;&#20854;&#20182;&#22522;&#20110;&#36741;&#21161;&#20219;&#21153;&#30340;&#26041;&#27861;&#20013;&#30340;&#29305;&#24449;&#30456;&#20851;&#24615;&#22914;&#20309;&#12290;&#26412;&#25991;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#25552;&#20379;&#20102;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;(Sutton, 1988)&#23398;&#20064;&#30340;&#29366;&#24577;&#34920;&#31034;&#30340;&#29702;&#35770;&#21051;&#30011;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#34920;&#31034;&#19982;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#27531;&#24046;&#26799;&#24230;&#31639;&#27861;&#23398;&#20064;&#30340;&#29305;&#24449;&#22312;&#22823;&#22810;&#25968;&#36716;&#31227;&#20013;&#26159;&#19981;&#21516;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reinforcement learning (RL), state representations are key to dealing with large or continuous state spaces. While one of the promises of deep learning algorithms is to automatically construct features well-tuned for the task they try to solve, such a representation might not emerge from end-to-end training of deep RL agents. To mitigate this issue, auxiliary objectives are often incorporated into the learning process and help shape the learnt state representation. Bootstrapping methods are today's method of choice to make these additional predictions. Yet, it is unclear which features these algorithms capture and how they relate to those from other auxiliary-task-based approaches. In this paper, we address this gap and provide a theoretical characterization of the state representation learnt by temporal difference learning (Sutton, 1988). Surprisingly, we find that this representation differs from the features learned by Monte Carlo and residual gradient algorithms for most transit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;Wasserstein barycenters&#25193;&#23637;`Strong Demographic Parity`&#30340;&#23450;&#20041;&#65292;&#23454;&#29616;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10155</link><description>&lt;p&gt;
&#36890;&#36807;Wasserstein Barycenters&#23454;&#29616;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fairness in Multi-Task Learning via Wasserstein Barycenters. (arXiv:2306.10155v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;Wasserstein barycenters&#25193;&#23637;`Strong Demographic Parity`&#30340;&#23450;&#20041;&#65292;&#23454;&#29616;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#20844;&#24179;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#24050;&#32463;&#25104;&#29087;&#30340;&#39046;&#22495;&#65292;&#26088;&#22312;&#20943;&#23569;&#25968;&#25454;&#20013;&#30340;&#20559;&#24046;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#30830;&#20445;&#21333;&#21464;&#37327;&#29615;&#22659;&#19979;&#30340;&#20844;&#24179;&#24615;&#65292;&#21363;&#30446;&#26631;&#26159;&#21435;&#38500;&#21333;&#20010;&#20219;&#21153;&#30340;&#20559;&#24046;&#12290;&#28982;&#32780;&#65292;&#23558;&#20844;&#24179;&#24615;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#29615;&#22659;&#65292;&#20854;&#20013;&#20351;&#29992;&#20849;&#20139;&#34920;&#31034;&#26469;&#20248;&#21270;&#22810;&#20010;&#30446;&#26631;&#65292;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#24320;&#21457;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#20803;Wasserstein barycenters&#23558;\textit{Strong Demographic Parity}&#30340;&#23450;&#20041;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#26368;&#20248;&#30340;&#20844;&#24179;&#22810;&#20219;&#21153;&#39044;&#27979;&#22120;&#25552;&#20379;&#20102;&#23553;&#38381;&#24335;&#35299;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#20272;&#35745;&#36807;&#31243;&#65292;&#20197;&#23547;&#25214;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#25968;&#23383;&#23454;&#39564;&#12290;&#32463;&#39564;&#32467;&#26524;&#31361;&#26174;&#20102;&#25105;&#20204;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#22312;&#20419;&#36827;&#20844;&#24179;&#20915;&#31574;&#26041;&#38754;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Fairness is an established field in machine learning that aims to reduce biases in data. Recent advances have proposed various methods to ensure fairness in a univariate environment, where the goal is to de-bias a single task. However, extending fairness to a multi-task setting, where more than one objective is optimised using a shared representation, remains underexplored. To bridge this gap, we develop a method that extends the definition of \textit{Strong Demographic Parity} to multi-task learning using multi-marginal Wasserstein barycenters. Our approach provides a closed form solution for the optimal fair multi-task predictor including both regression and binary classification tasks. We develop a data-driven estimation procedure for the solution and run numerical experiments on both synthetic and real datasets. The empirical results highlight the practical value of our post-processing methodology in promoting fair decision-making.
&lt;/p&gt;</description></item><item><title>&#36882;&#24402;&#21106;&#24179;&#38754;&#31639;&#27861;&#26063;&#21487;&#22312;&#20855;&#26377;&#21463;&#38480;&#20869;&#23384;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#24182;&#20351;&#29992;&#23376;&#22810;&#39033;&#24335;&#33539;&#22260;&#20869;&#39044;&#35328;&#26426;&#22797;&#26434;&#24230;/&#20869;&#23384;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.10096</link><description>&lt;p&gt;
&#36882;&#24402;&#21106;&#24179;&#38754;&#31639;&#27861;&#26063;&#29992;&#20110;&#20855;&#26377;&#21463;&#38480;&#20869;&#23384;&#30340;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Memory-Constrained Algorithms for Convex Optimization via Recursive Cutting-Planes. (arXiv:2306.10096v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10096
&lt;/p&gt;
&lt;p&gt;
&#36882;&#24402;&#21106;&#24179;&#38754;&#31639;&#27861;&#26063;&#21487;&#22312;&#20855;&#26377;&#21463;&#38480;&#20869;&#23384;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#24182;&#20351;&#29992;&#23376;&#22810;&#39033;&#24335;&#33539;&#22260;&#20869;&#39044;&#35328;&#26426;&#22797;&#26434;&#24230;/&#20869;&#23384;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36882;&#24402;&#21106;&#24179;&#38754;&#31639;&#27861;&#26063;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#21463;&#38480;&#20869;&#23384;&#30340;&#21487;&#34892;&#24615;&#38382;&#39064;, &#21516;&#26102;&#20063;&#21487;&#20197;&#29992;&#20110;&#19968;&#38454;&#20984;&#20248;&#21270;&#12290;&#35813;&#31639;&#27861;&#20351;&#29992;&#23376;&#22810;&#39033;&#24335;&#33539;&#22260;&#21487;&#25552;&#20379;&#39044;&#35328;&#26426;&#22797;&#26434;&#24230;/&#20869;&#23384;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a family of recursive cutting-plane algorithms to solve feasibility problems with constrained memory, which can also be used for first-order convex optimization. Precisely, in order to find a point within a ball of radius $\epsilon$ with a separation oracle in dimension $d$ -- or to minimize $1$-Lipschitz convex functions to accuracy $\epsilon$ over the unit ball -- our algorithms use $\mathcal O(\frac{d^2}{p}\ln \frac{1}{\epsilon})$ bits of memory, and make $\mathcal O((C\frac{d}{p}\ln \frac{1}{\epsilon})^p)$ oracle calls, for some universal constant $C \geq 1$. The family is parametrized by $p\in[d]$ and provides an oracle-complexity/memory trade-off in the sub-polynomial regime $\ln\frac{1}{\epsilon}\gg\ln d$. While several works gave lower-bound trade-offs (impossibility results) -- we explicit here their dependence with $\ln\frac{1}{\epsilon}$, showing that these also hold in any sub-polynomial regime -- to the best of our knowledge this is the first class of algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23398;&#24466;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#22522;&#20110;Q&#23398;&#20064;&#21644;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064; (IRL)&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#31232;&#30095;&#37066;&#21306;&#29615;&#22659;&#20013;&#65292;&#26080;&#20154;&#26426;&#30340;&#32852;&#32593;&#36335;&#24452;&#35268;&#21010;&#19982;&#21151;&#29575;&#20998;&#37197;&#30340;&#24178;&#25200;&#24863;&#30693;&#38382;&#39064;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#34892;&#20026;&#20811;&#38534;&#65288;BC&#65289;&#35843;&#33410;&#23398;&#20064;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2306.10071</link><description>&lt;p&gt;
&#22522;&#20110;&#23398;&#24466;&#23398;&#20064;&#30340;&#26080;&#20154;&#26426;&#32852;&#32593;&#36335;&#24452;&#35268;&#21010;&#19982;&#21151;&#29575;&#20998;&#37197;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Joint Path planning and Power Allocation of a Cellular-Connected UAV using Apprenticeship Learning via Deep Inverse Reinforcement Learning. (arXiv:2306.10071v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23398;&#24466;&#23398;&#20064;&#26041;&#27861;&#65292;&#37319;&#29992;&#22522;&#20110;Q&#23398;&#20064;&#21644;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064; (IRL)&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#31232;&#30095;&#37066;&#21306;&#29615;&#22659;&#20013;&#65292;&#26080;&#20154;&#26426;&#30340;&#32852;&#32593;&#36335;&#24452;&#35268;&#21010;&#19982;&#21151;&#29575;&#20998;&#37197;&#30340;&#24178;&#25200;&#24863;&#30693;&#38382;&#39064;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#34892;&#20026;&#20811;&#38534;&#65288;BC&#65289;&#35843;&#33410;&#23398;&#20064;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31232;&#30095;&#37066;&#21306;&#29615;&#22659;&#20013;&#65292;&#19968;&#20010;&#32852;&#32593;&#30340;&#26080;&#20154;&#26426;&#36890;&#36807;&#27839;&#30528;&#20449;&#21495;&#35206;&#30422;&#21333;&#20803;&#31227;&#21160;&#65292;&#20174;&#20986;&#21457;&#28857;&#39134;&#21521;&#30446;&#30340;&#22320;&#20197;&#20445;&#35777;&#26381;&#21153;&#36136;&#37327;&#65288;QoS&#65289;&#30340;&#24178;&#25200;&#24863;&#30693;&#32852;&#32593;&#36335;&#24452;&#35268;&#21010;&#19982;&#21151;&#29575;&#20998;&#37197;&#26426;&#21046;&#12290;&#19987;&#23478;&#30693;&#35782;&#34987;&#29992;&#26469;&#20307;&#39564;&#24773;&#26223;&#24182;&#20026;&#26234;&#33021;&#20307;&#65288;&#21363;&#65292;&#26080;&#20154;&#26426;&#65289;&#22521;&#35757;&#23450;&#20041;&#25152;&#38656;&#30340;&#34892;&#20026;&#65292;&#20026;&#27492;&#65292;&#19968;&#31181;&#22522;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#30340;&#23398;&#24466;&#23398;&#20064;&#26041;&#27861;&#34987;&#37319;&#29992;&#65292;&#24182;&#36890;&#36807;Q&#23398;&#20064;&#21644;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#36827;&#34892;&#27604;&#36739;&#24615;&#33021;&#65292;&#24182;&#23558;&#20854;&#19982;&#34892;&#20026;&#20811;&#38534;&#65288;BC&#65289;&#35843;&#33410;&#23398;&#20064;&#25216;&#26415;&#30340;&#23398;&#20064;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates an interference-aware joint path planning and power allocation mechanism for a cellular-connected unmanned aerial vehicle (UAV) in a sparse suburban environment. The UAV's goal is to fly from an initial point and reach a destination point by moving along the cells to guarantee the required quality of service (QoS). In particular, the UAV aims to maximize its uplink throughput and minimize the level of interference to the ground user equipment (UEs) connected to the neighbor cellular BSs, considering the shortest path and flight resource limitation. Expert knowledge is used to experience the scenario and define the desired behavior for the sake of the agent (i.e., UAV) training. To solve the problem, an apprenticeship learning method is utilized via inverse reinforcement learning (IRL) based on both Q-learning and deep reinforcement learning (DRL). The performance of this method is compared to learning from a demonstration technique called behavioral cloning (BC)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21457;&#29616;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#36923;&#36753;&#19981;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#23545;&#20110;&#36229;&#20154;&#27169;&#22411;&#30340;&#20915;&#31574;&#27491;&#30830;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#35780;&#20272;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2306.09983</link><description>&lt;p&gt;
&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21457;&#29616;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#36923;&#36753;&#19981;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#23545;&#20110;&#36229;&#20154;&#27169;&#22411;&#30340;&#20915;&#31574;&#27491;&#30830;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#35780;&#20272;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#21508;&#31181;&#25512;&#29702;&#25110;&#20915;&#31574;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#36229;&#20154;&#33021;&#21147;&#65292;&#37027;&#20040;&#25105;&#20204;&#35813;&#22914;&#20309;&#35780;&#20272;&#36825;&#20123;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#20154;&#31867;&#20195;&#29702;&#20250;&#20135;&#29983;&#20559;&#24046;? &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#19968;&#33268;&#24615;&#26816;&#26597;&#35780;&#20272;&#36229;&#20154;&#27169;&#22411;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#21069;&#25552;&#26159;&#65292;&#34429;&#28982;&#35780;&#20272;&#36229;&#20154;&#20915;&#31574;&#30340;&#27491;&#30830;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20294;&#26159;&#22914;&#26524;&#27169;&#22411;&#30340;&#20915;&#31574;&#26410;&#33021;&#28385;&#36275;&#26576;&#20123;&#36923;&#36753;&#19978;&#12289;&#21487;&#35299;&#37322;&#30340;&#35268;&#21017;&#65292;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#21457;&#29616;&#38169;&#35823;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#22312;&#19977;&#20010;&#20219;&#21153;&#19978;&#65292;&#36825;&#20123;&#20219;&#21153;&#30340;&#20915;&#31574;&#27491;&#30830;&#24615;&#30001;&#20110;&#36229;&#20154;&#27169;&#22411;&#33021;&#21147;&#25110;&#20854;&#20182;&#32570;&#20047;&#22522;&#26412;&#20107;&#23454;&#32780;&#38590;&#20197;&#35780;&#20272;&#65306;&#35780;&#20272;&#22269;&#38469;&#35937;&#26827;&#23616;&#38754;&#12289;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#21644;&#20316;&#20986;&#27861;&#24459;&#21028;&#26029;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#26080;&#35770;&#27169;&#22411;&#22312;&#36825;&#20123;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#22914;&#20309;(&#21487;&#33021;&#26159;&#36229;&#20154;&#30340;)&#65292;&#25105;&#20204;&#37117;&#33021;&#21457;&#29616;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#36923;&#36753;&#19981;&#19968;&#33268;&#24615;&#12290;&#20363;&#22914;&#65306;&#22269;&#38469;&#35937;&#26827;&#24341;&#25806;&#32473;&#20986;&#23545;&#23616;&#20013;&#26827;&#23376;&#30456;&#23545;&#20272;&#20540;&#30340;&#19981;&#21516;&#25490;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#24471;&#20998;&#21305;&#37197;&#31639;&#27861;&#22312;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#30340;&#20998;&#24067;&#19978;&#30340;&#32479;&#35745;&#20195;&#20215;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.09332</link><description>&lt;p&gt;
Fit Like You Sample: &#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains. (arXiv:2306.09332v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#24471;&#20998;&#21305;&#37197;&#31639;&#27861;&#22312;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#30340;&#20998;&#24067;&#19978;&#30340;&#32479;&#35745;&#20195;&#20215;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24471;&#20998;&#21305;&#37197;&#26159;&#19968;&#31181;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20854;&#21442;&#25968;&#21270;&#20026;&#27604;&#20363;&#24120;&#25968;&#65288;&#20363;&#22914;&#65292;&#33021;&#37327;&#22522;&#27169;&#22411;&#65289;&#12290;&#20854;&#24605;&#24819;&#26159;&#25311;&#21512;&#20998;&#24067;&#30340;&#24471;&#20998;&#65292;&#32780;&#19981;&#26159;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#35780;&#20272;&#27604;&#20363;&#24120;&#25968;&#30340;&#38656;&#27714;&#12290;&#34429;&#28982;&#36825;&#20855;&#26377;&#26126;&#26174;&#30340;&#31639;&#27861;&#20248;&#21183;&#65292;&#20294;&#32479;&#35745;&#20195;&#20215;&#21487;&#33021;&#24456;&#39640;&#65306;Koehler&#31561;&#20154;&#30340;&#26368;&#26032;&#24037;&#20316;&#34920;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#65288;&#36739;&#22823;&#30340;Poincare&#25110;&#23545;&#25968;Sobolev&#24120;&#25968;&#65289;&#30340;&#20998;&#24067;&#65292;&#24471;&#20998;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29575;&#26126;&#26174;&#20302;&#20110;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#33258;&#28982;&#23454;&#38469;&#30340;&#20998;&#24067;&#65292;&#20363;&#22914;&#19968;&#32500;&#20013;&#30340;&#20004;&#20010;&#39640;&#26031;&#20998;&#24067;&#28151;&#21512;&#29289;&#31561;&#22810;&#23792;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#24046;&#30340;Poincar&#233;&#24120;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#24847;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#19982;&#35797;&#22270;&#25311;&#21512;$\frac{\mathcal{O} p}{p}$&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#12290;&#22914;&#26524;$\mathcal{L}$&#30340;&#29305;&#24449;&#21521;&#37327;&#19981;&#20381;&#36182;&#20110;$p$&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#30340;&#26679;&#26412;&#39640;&#25928;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score matching is an approach to learning probability distributions parametrized up to a constant of proportionality (e.g. Energy-Based Models). The idea is to fit the score of the distribution, rather than the likelihood, thus avoiding the need to evaluate the constant of proportionality. While there's a clear algorithmic benefit, the statistical "cost'' can be steep: recent work by Koehler et al. 2022 showed that for distributions that have poor isoperimetric properties (a large Poincar\'e or log-Sobolev constant), score matching is substantially statistically less efficient than maximum likelihood. However, many natural realistic distributions, e.g. multimodal distributions as simple as a mixture of two Gaussians in one dimension -- have a poor Poincar\'e constant.  In this paper, we show a close connection between the mixing time of an arbitrary Markov process with generator $\mathcal{L}$ and a generalized score matching loss that tries to fit $\frac{\mathcal{O} p}{p}$. If $\mathca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23616;&#37096;&#21040;&#20840;&#23616;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21253;&#25324;&#19981;&#21464;&#22270;&#32593;&#32476;&#12289;&#23616;&#37096;&#20449;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#65292;&#24182;&#30740;&#31350;&#20854;&#25910;&#25947;&#24615;&#36136;&#21644;&#22312;&#22270;&#31895;&#21270;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.06547</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Local-to-global Perspectives on Graph Neural Networks. (arXiv:2306.06547v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23616;&#37096;&#21040;&#20840;&#23616;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21253;&#25324;&#19981;&#21464;&#22270;&#32593;&#32476;&#12289;&#23616;&#37096;&#20449;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#65292;&#24182;&#30740;&#31350;&#20854;&#25910;&#25947;&#24615;&#36136;&#21644;&#22312;&#22270;&#31895;&#21270;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#30340;&#35270;&#35282;&#65292;&#20854;&#20013;&#20998;&#20026;&#23616;&#37096;&#20449;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#20010;&#24037;&#20316;&#65306;1&#65289;&#30740;&#31350;&#19968;&#31181;&#20840;&#23616; GNN&#65292;&#19981;&#21464;&#22270;&#32593;&#32476;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;2&#65289;&#36830;&#25509;&#23616;&#37096; MPNN &#21644;&#20840;&#23616;&#22270;&#21464;&#25442;&#22120;&#65292;3&#65289;&#22312;&#20840;&#23616;&#24314;&#27169;&#20013;&#65292;&#20351;&#29992;&#23616;&#37096; MPNN &#36827;&#34892;&#22270;&#31895;&#21270;&#65292;&#36825;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#23376;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a local-to-global perspective on graph neural networks (GNN), which are categorized as local Message Passing Neural Networks (MPNN) and global Graph Transformer. We present three pieces of work: 1) study the convergence property of a type of global GNN, Invariant Graph Networks, 2) connect the local MPNN and global Graph Transformer, and 3) use local MPNN for graph coarsening, a common subroutine used in global modeling.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02709</link><description>&lt;p&gt;
&#29992;&#20110;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study on Semi-supervised Learning Applied for Anomaly Detection in Hydraulic Condition Monitoring System. (arXiv:2306.02709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#19981;&#21516;&#31867;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#34920;&#29616;&#26368;&#22909;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29366;&#24577;&#30340;&#32500;&#25252;&#22312;&#28082;&#21387;&#31995;&#32479;&#20013;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31995;&#32479;&#30340;&#24322;&#24120;&#26816;&#27979;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#24322;&#24120;&#25968;&#25454;&#24456;&#23569;&#65292;&#26631;&#35760;&#36825;&#20123;&#25968;&#25454;&#26159;&#36153;&#26102;&#36153;&#21147;&#29978;&#33267;&#21361;&#38505;&#30340;&#12290;&#22240;&#27492;&#65292;&#24314;&#35758;&#20351;&#29992;&#26080;&#30417;&#30563;&#25110;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#21482;&#26377;&#23569;&#37327;&#26631;&#31614;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#26080;&#30417;&#30563;&#23398;&#20064;&#20316;&#20026;&#29305;&#24449;&#25552;&#21462;&#26426;&#21046;&#26469;&#36741;&#21161;&#30417;&#30563;&#23398;&#20064;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#27604;&#36739;&#20102;&#22312;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#31995;&#32479;&#20013;&#24212;&#29992;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#12290;&#39318;&#20808;&#65292;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#29305;&#24449;&#23398;&#20064;&#65292;&#20197;&#20102;&#35299;&#24320;&#28304;&#30340;&#28082;&#21387;&#29366;&#24577;&#30417;&#27979;&#25968;&#25454;&#38598;&#12290;&#28982;&#21518;&#65292;&#23454;&#26045;&#21644;&#35780;&#20272;&#20102;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#20256;&#32479;&#30340;&#29420;&#31435;&#21322;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#19968;&#31867;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#40065;&#26834;&#21327;&#26041;&#24046;&#65289;&#12289;&#38598;&#25104;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#23396;&#31435;&#26862;&#26519;&#65289;&#21644;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#27169;&#22411;&#65288;&#20363;&#22914;&#65292;&#33258;&#21160;&#32534;&#30721;&#22120;&#12289;&#22270;&#21367;&#31215;&#32593;&#32476;&#65289;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;&#27169;&#22411;&#65292;&#32780;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Condition-based maintenance is becoming increasingly important in hydraulic systems. However, anomaly detection for these systems remains challenging, especially since that anomalous data is scarce and labeling such data is tedious and even dangerous. Therefore, it is advisable to make use of unsupervised or semi-supervised methods, especially for semi-supervised learning which utilizes unsupervised learning as a feature extraction mechanism to aid the supervised part when only a small number of labels are available. This study systematically compares semi-supervised learning methods applied for anomaly detection in hydraulic condition monitoring systems. Firstly, thorough data analysis and feature learning were carried out to understand the open-sourced hydraulic condition monitoring dataset. Then, various methods were implemented and evaluated including traditional stand-alone semi-supervised learning models (e.g., one-class SVM, Robust Covariance), ensemble models (e.g., Isolation F
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#21644;&#23436;&#20840;&#20934;&#30830;&#26102;&#20998;&#21035;&#37319;&#21462;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#23454;&#29616;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;ImageNet&#21644;nuScenes&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#24635;&#32467;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.00265</link><description>&lt;p&gt;
&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Self-Training. (arXiv:2306.00265v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#21644;&#23436;&#20840;&#20934;&#30830;&#26102;&#20998;&#21035;&#37319;&#21462;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#23454;&#29616;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;ImageNet&#21644;nuScenes&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#24635;&#32467;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#35757;&#32451;&#26159;&#35299;&#20915;&#21322;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#31181;&#37325;&#35201;&#25216;&#26415;&#12290;&#23427;&#36890;&#36807;&#29983;&#25104;&#20266;&#26631;&#31614;&#24182;&#23558;&#20854;&#19982;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#32467;&#21512;&#20351;&#29992;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#12290;&#33258;&#25105;&#35757;&#32451;&#30340;&#26377;&#25928;&#24615;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#36825;&#20123;&#20266;&#26631;&#31614;&#30340;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#30417;&#30563;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#22312;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#24179;&#34913;&#12290;&#24403;&#20266;&#26631;&#31614;&#23436;&#20840;&#19981;&#27491;&#30830;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#34987;&#20943;&#23569;&#21040;&#20165;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#30456;&#21453;&#65292;&#24403;&#20266;&#26631;&#31614;&#23436;&#20840;&#20934;&#30830;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#21464;&#25104;&#21033;&#29992;&#25152;&#26377;&#20266;&#26631;&#31614;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#65292;&#20174;&#32780;&#22686;&#21152;&#26377;&#25928;&#30340;&#26679;&#26412;&#37327;&#12290;&#36890;&#36807;&#22312;ImageNet&#22270;&#20687;&#20998;&#31867;&#21644;nuScenes&#33258;&#20027;&#39550;&#39542;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21452;&#37325;&#31283;&#20581;&#25439;&#22833;&#20248;&#20110;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#22522;&#32447;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-training is an important technique for solving semi-supervised learning problems. It leverages unlabeled data by generating pseudo-labels and combining them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly robust self-training, a novel semi-supervised algorithm that provably balances between two extremes. When the pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when the pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly robust loss over the standard self-training baseline.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#65306;&#22914;&#20309;&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#22312;&#23384;&#22312;&#26377;&#38480;&#23545;&#25239;&#38169;&#35823;&#26102;&#31215;&#26497;&#23398;&#20064;&#23436;&#20840;&#24674;&#22797;&#21010;&#20998;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35299;&#26512;&#26694;&#26550;&#24182;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#26597;&#35810;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.13402</link><description>&lt;p&gt;
&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#30340;&#23481;&#38169;&#31934;&#30830;&#26597;&#35810;&#23398;&#20064;&#26377;&#38480;&#38598;&#21512;&#21010;&#20998;
&lt;/p&gt;
&lt;p&gt;
Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle. (arXiv:2305.13402v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#65306;&#22914;&#20309;&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#22312;&#23384;&#22312;&#26377;&#38480;&#23545;&#25239;&#38169;&#35823;&#26102;&#31215;&#26497;&#23398;&#20064;&#23436;&#20840;&#24674;&#22797;&#21010;&#20998;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35299;&#26512;&#26694;&#26550;&#24182;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#26597;&#35810;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#23384;&#22312;&#26377;&#38480;&#30340;&#23545;&#25239;&#38169;&#35823;&#26102;&#65292;&#20165;&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#26469;&#31215;&#26497;&#23398;&#20064;&#23436;&#20840;&#24674;&#22797;&#21010;&#20998;&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#31361;&#20986;&#20102;&#23398;&#20064;&#21010;&#20998;&#21644;&#30456;&#20851;&#32858;&#31867;&#20043;&#38388;&#30340;&#26032;&#39062;&#32852;&#31995;&#12290;&#28982;&#21518;&#21033;&#29992;&#36825;&#31181;&#32852;&#31995;&#20026;&#36825;&#20010;&#38382;&#39064;&#24314;&#31435;&#20102;&#19968;&#20010;R&#233;nyi-Ulam&#26679;&#24335;&#30340;&#35299;&#26512;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#26597;&#35810;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#38480;&#21046;&#20102;&#30456;&#20851;&#38543;&#26426;&#31639;&#27861;&#30340;&#26399;&#26395;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#22312;&#35813;&#38382;&#39064;&#21644;&#30456;&#20851;&#21464;&#20307;&#20013;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper initiates the study of active learning for exact recovery of partitions exclusively through access to a same-cluster oracle in the presence of bounded adversarial error. We first highlight a novel connection between learning partitions and correlation clustering. Then we use this connection to build a R\'enyi-Ulam style analytical framework for this problem, and prove upper and lower bounds on its worst-case query complexity. Further, we bound the expected performance of a relevant randomized algorithm. Finally, we study the relationship between adaptivity and query complexity for this problem and related variants.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2305.11283</link><description>&lt;p&gt;
&#20851;&#20110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;&#65288;MFC&#65289;&#21644;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#20013;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Mean-Field Model-Based Eluder Dimension (MBED)&#30340;&#26032;&#27010;&#24565;&#65292;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#36820;&#22238;&#19968;&#20010;$\epsilon$&#20248;&#30340;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;MFC&#25110;$\epsilon$&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#36866;&#29992;&#20110;MFG&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#22810;&#39033;&#24335;&#19982;&#30456;&#20851;&#21442;&#25968;&#26080;&#20851;&#65292;&#19982;&#29366;&#24577;&#12289;&#21160;&#20316;&#21644;&#20195;&#29702;&#25968;&#37327;&#26080;&#20851;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#36991;&#20813;&#20102;&#20197;&#21069;&#30340;&#24378;&#32467;&#26500;&#20551;&#35774;&#12290;&#26368;&#21518;&#65292;&#22312;tabular&#35774;&#32622;&#19979;&#65292;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26679;&#26412;&#39640;&#25928;&#30340;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#20197;&#36924;&#36817;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#36890;&#36807;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#21487;&#20197;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.08529</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#32852;&#21512;&#29420;&#31435;&#24615;&#26816;&#39564;&#29992;&#20110;&#22810;&#20803;&#12289;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series. (arXiv:2305.08529v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#36890;&#36807;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#21487;&#20197;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25429;&#25417;&#30456;&#20114;&#36830;&#25509;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#20102;&#35299;&#20849;&#21516;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#21644;&#28508;&#22312;&#20381;&#36182;&#20851;&#31995;&#26159;&#20934;&#30830;&#32479;&#35745;&#24314;&#27169;&#21644;&#20998;&#26512;&#27492;&#31867;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558; d &#21464;&#37327; Hilbert-Schmidt &#29420;&#31435;&#24615;&#20934;&#21017;&#65288;dHSIC&#65289;&#25193;&#23637;&#21040;&#21253;&#21547;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#24191;&#27867;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#12290;&#36890;&#36807;&#21033;&#29992;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#37327;&#36523;&#23450;&#21046;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22914;&#20309;&#22312;&#21512;&#25104;&#31034;&#20363;&#65288;&#21253;&#25324;&#39057;&#29575;&#28151;&#21512;&#25968;&#25454;&#65289;&#20197;&#21450;&#23454;&#38469;&#27668;&#20505;&#21644;&#31038;&#20250;&#32463;&#27982;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#20998;&#26512;&#22797;&#26434;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#22686;&#21152;&#20102;&#25968;&#23398;&#24037;&#20855;&#31665;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate time-series data that capture the temporal evolution of interconnected systems are ubiquitous in diverse areas. Understanding the complex relationships and potential dependencies among co-observed variables is crucial for the accurate statistical modelling and analysis of such systems. Here, we introduce kernel-based statistical tests of joint independence in multivariate time-series by extending the d-variable Hilbert-Schmidt independence criterion (dHSIC) to encompass both stationary and nonstationary random processes, thus allowing broader real-world applications. By leveraging resampling techniques tailored for both single- and multiple-realization time series, we show how the method robustly uncovers significant higher-order dependencies in synthetic examples, including frequency mixing data, as well as real-world climate and socioeconomic data. Our method adds to the mathematical toolbox for the analysis of complex high-dimensional time-series datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.08074</link><description>&lt;p&gt;
&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#21644;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#22312;&#28151;&#27788;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#26159;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21160;&#24577;&#30340;&#39044;&#27979;&#21644;&#27169;&#22411;&#31616;&#21270;&#65292;&#22312;&#29289;&#29702;&#31185;&#23398;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65292;&#20294;&#22312;&#30830;&#23450;&#24615;&#28151;&#27788;&#20013;&#65292;&#23427;&#30340;&#24615;&#36136;&#25110;&#32773;&#23427;&#30340;&#25910;&#25947;&#24615;&#36824;&#19981;&#28165;&#26970;&#12290;&#29305;&#21035;&#26159;&#65292;EDMD&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#22914;&#20309;&#22788;&#29702;&#38656;&#35201;&#25551;&#32472;&#28151;&#27788;&#21160;&#21147;&#23398;&#21547;&#20041;&#30340;&#27491;&#21017;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#20063;&#26159;&#19981;&#28165;&#26970;&#30340;&#12290;&#26412;&#25991;&#22312;&#20998;&#26512;&#19978;&#31616;&#21333;&#30340;&#19968;&#20010;&#22278;&#29615;&#23637;&#24320;&#26144;&#23556;&#30340;&#26368;&#31616;&#21333;&#20363;&#23376;&#19978;&#65292;&#21457;&#23637;&#20102;&#20851;&#20110;EDMD&#30340;&#19968;&#33324;&#30340;&#12289;&#20005;&#26684;&#30340;&#29702;&#35770;&#12290;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#20851;&#20110;&#22312;&#21333;&#20301;&#22278;&#19978;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#65288;OPUC&#65289;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#26102;&#65292;&#38024;&#23545;&#22810;&#39033;&#24335;&#30340;&#21487;&#35266;&#27979;&#23383;&#20856;&#30340;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#20855;&#26377;&#25351;&#25968;&#25928;&#29575;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#21040;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#30340;&#25351;&#25968;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#37319;&#26679;&#30340;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#35813;&#31639;&#27861;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31532;&#19968;&#20010;&#23574;&#38160;&#29575;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;&#26041;&#26696;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.02456</link><description>&lt;p&gt;
&#38754;&#21521;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#27969;&#24335;PCA&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Streaming PCA for Markovian Data. (arXiv:2305.02456v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#37319;&#26679;&#30340;&#27969;&#24335;PCA&#31639;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#35813;&#31639;&#27861;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31532;&#19968;&#20010;&#23574;&#38160;&#29575;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#33258;&#36866;&#24212;&#26041;&#26696;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;Oja&#22312;1982&#24180;&#30340;&#32463;&#20856;&#35770;&#25991;&#20013;&#39318;&#27425;&#25552;&#20986;&#20197;&#26469;&#65292;Oja&#31639;&#27861;&#24050;&#25104;&#20026;&#27969;&#24335;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#30340;&#19968;&#31181;&#24120;&#29992;&#26041;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24335;PCA&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#28857;&#20174;&#19968;&#20010;&#19981;&#21487;&#32422;&#12289;&#26080;&#21608;&#26399;&#12289;&#21487;&#36870;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745;&#24179;&#31283;&#20998;&#24067;&#30340;&#26410;&#30693;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21069;&#19968;&#20010;&#29305;&#24449;&#21521;&#37327;&#12290;&#36825;&#31181;&#24773;&#20917;&#36866;&#29992;&#20110;&#21482;&#33021;&#20174;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;(MCMC)&#31867;&#22411;&#30340;&#31639;&#27861;&#20013;&#37319;&#26679;&#25968;&#25454;&#65292;&#24182;&#19988;&#30446;&#26631;&#26159;&#23545;&#35813;&#38142;&#30340;&#24179;&#31283;&#20998;&#24067;&#30340;&#21442;&#25968;&#36827;&#34892;&#25512;&#26029;&#30340;&#24773;&#20917;&#12290;&#29616;&#26377;&#25991;&#29486;&#20013;&#22823;&#22810;&#25968;Oja&#31639;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#37117;&#20551;&#23450;&#25968;&#25454;&#28857;&#26159;IID&#37319;&#26679;&#30340;&#12290;&#23545;&#20110;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#20381;&#36182;&#20851;&#31995;&#30340;&#25968;&#25454;&#27969;&#65292;&#20154;&#20204;&#36890;&#24120;&#23545;&#25968;&#25454;&#36827;&#34892;&#19979;&#37319;&#26679;&#20197;&#33719;&#24471;"&#20960;&#20046;"&#29420;&#31435;&#30340;&#25968;&#25454;&#27969;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;Oja&#31639;&#27861;&#22312;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#31532;&#19968;&#20010;&#23574;&#38160;&#29575;&#65292;&#20854;&#20013;&#21435;&#25481;&#20102;$n$&#30340;&#23545;&#25968;&#20381;&#36182;&#24615;&#65292;&#32467;&#26524;&#26159;$\mathcal{O}(n^{-1})$&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#26696;&#26469;&#35843;&#25972;&#31639;&#27861;&#30340;&#27493;&#38271;&#65292;&#23427;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#37117;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since its inception in Erikki Oja's seminal paper in 1982, Oja's algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in situations where data can only be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the goal is to do inference for parameters of the stationary distribution of this chain. Most convergence guarantees for Oja's algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a "nearly" independent data stream. In this paper, we obtain the first sharp rate for Oja's algorithm on the entire data, where we remove the logarithmic dependence on $n$ resulti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20132;&#21449;&#29109;&#12289;&#24191;&#20041;&#20132;&#21449;&#29109;&#12289;&#22343;&#26041;&#35823;&#24046;&#31561;&#19968;&#22823;&#31867;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#20248;&#21183;&#30340;&#21452;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.07288</link><description>&lt;p&gt;
&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#65306;&#29702;&#35770;&#20998;&#26512;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Cross-Entropy Loss Functions: Theoretical Analysis and Applications. (arXiv:2304.07288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20132;&#21449;&#29109;&#12289;&#24191;&#20041;&#20132;&#21449;&#29109;&#12289;&#22343;&#26041;&#35823;&#24046;&#31561;&#19968;&#22823;&#31867;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#20248;&#21183;&#30340;&#21452;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#29109;&#26159;&#24191;&#27867;&#24212;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#24403;&#20351;&#29992;softmax&#20989;&#25968;&#26102;&#65292;&#23427;&#19982;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#24212;&#29992;&#20110;&#36923;&#36753;&#22238;&#24402;&#25439;&#22833;&#20989;&#25968;&#30456;&#31526;&#12290;&#20294;&#26159;&#65292;&#20351;&#29992;&#20132;&#21449;&#29109;&#20316;&#20026;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#26102;&#65292;&#25105;&#20204;&#33021;&#20381;&#38752;&#20160;&#20040;&#20445;&#35777;&#21602;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#23478;&#26063;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#21253;&#25324;&#20132;&#21449;&#29109;&#65288;&#25110;&#36923;&#36753;&#25439;&#22833;&#65289;&#12289;&#24191;&#20041;&#20132;&#21449;&#29109;&#12289;&#22343;&#26041;&#35823;&#24046;&#21644;&#20854;&#20182;&#20132;&#21449;&#29109;&#31867;&#20989;&#25968;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#36825;&#20123;&#25439;&#22833;&#20989;&#25968;&#30340;&#31532;&#19968;&#20010;$H$-&#36830;&#32493;&#24615;&#30028;&#38480;&#12290;&#36825;&#20123;&#37117;&#26159;&#38750;&#28176;&#36827;&#20445;&#35777;&#65292;&#20197;&#20272;&#35745;&#20195;&#29702;&#25439;&#22833;&#30340;&#20272;&#35745;&#35823;&#24046;&#20026;&#19978;&#38480;&#65292;&#29992;&#20110;&#29305;&#23450;&#30340;&#20551;&#35774;&#38598;$H$&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#36825;&#20123;&#36793;&#30028;&#30340;&#32039;&#23494;&#31243;&#24230;&#12290;&#36825;&#20123;&#36793;&#30028;&#21462;&#20915;&#20110;&#31216;&#20026;&#21487;&#26368;&#23567;&#21270;&#38388;&#38553;&#30340;&#37327;&#65292;&#36825;&#20123;&#38388;&#38553;&#21482;&#21462;&#20915;&#20110;&#25439;&#22833;&#20989;&#25968;&#21644;&#20551;&#35774;&#38598;&#12290;&#20026;&#20102;&#20351;&#23427;&#20204;&#26356;&#20855;&#20307;&#21270;&#65292;&#25105;&#20204;&#23545;&#22797;&#26434;&#21644;&#25439;&#22833;&#20989;&#25968;&#30340;&#36825;&#20123;&#38388;&#38553;&#36827;&#34892;&#20102;&#20855;&#20307;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#31216;&#20026;&#21452;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#23427;&#22522;&#20110;&#20004;&#20010;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23427;&#21487;&#20197;&#20248;&#20110;&#26631;&#20934;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#29305;&#21035;&#26159;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#25110;&#31867;&#21035;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. But, what guarantees can we rely on when using cross-entropy as a surrogate loss? We present a theoretical analysis of a broad family of losses, comp-sum losses, that includes cross-entropy (or logistic loss), generalized cross-entropy, the mean absolute error and other loss cross-entropy-like functions. We give the first $H$-consistency bounds for these loss functions. These are non-asymptotic guarantees that upper bound the zero-one loss estimation error in terms of the estimation error of a surrogate loss, for the specific hypothesis set $H$ used. We further show that our bounds are tight. These bounds depend on quantities called minimizability gaps, which only depend on the loss function and the hypothesis set. To make them more explicit, we give a specific analysis of these gaps for comp-sum losses. We also introduc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#21487;&#21516;&#26102;&#36827;&#34892;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#65292;&#24182;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.05223</link><description>&lt;p&gt;
&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#19981;&#22343;&#21248;&#22270;&#36235;&#21183;&#36807;&#28388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inhomogeneous graph trend filtering via a l2,0 cardinality penalty. (arXiv:2304.05223v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#21487;&#21516;&#26102;&#36827;&#34892;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#65292;&#24182;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#20272;&#35745;&#20998;&#27573;&#24179;&#28369;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;$\ell_{2,0}$-&#33539;&#25968;&#24809;&#32602;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#21516;&#26102;&#26159;&#22522;&#20110;&#33410;&#28857;&#19978;&#30340;&#20449;&#21495;&#30340;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20854;&#20013;&#32858;&#31867;&#21644;&#21106;&#20849;&#20139;&#30456;&#21516;&#30340;&#20998;&#37197;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#65306;&#19968;&#31181;&#26159;&#22522;&#20110;&#35889;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#26159;&#22522;&#20110;&#27169;&#25311;&#36864;&#28779;&#30340;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#19988;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#35299;&#20915;&#20102;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study estimation of piecewise smooth signals over a graph. We propose a $\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate piecewise smooth graph signals that exhibits inhomogeneous levels of smoothness across the nodes. We prove that the proposed GTF model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. We propose two methods to solve the proposed GTF model: a spectral decomposition method and a method based on simulated annealing. In the experiment on synthetic and real-world datasets, we show that the proposed GTF model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. We also show that the proposed GTF model can be solved more efficiently than existing models for the dataset with a large edge set.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#23558;&#21345;&#23572;&#26364;&#21644;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#25512;&#24191;&#21040;&#22270;&#24418;&#19978;&#65292;&#20351;&#24471;&#23427;&#21487;&#20197;&#36866;&#29992;&#20110;&#36755;&#20986;&#26159;&#21521;&#37327;&#25110;&#26631;&#37327;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#23398;&#20064;&#26410;&#30693;&#30340;&#29366;&#24577;&#36716;&#31227;&#21644;&#35835;&#21462;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.12021</link><description>&lt;p&gt;
&#22270;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Graph Kalman Filters. (arXiv:2303.12021v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12021
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#23558;&#21345;&#23572;&#26364;&#21644;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#25512;&#24191;&#21040;&#22270;&#24418;&#19978;&#65292;&#20351;&#24471;&#23427;&#21487;&#20197;&#36866;&#29992;&#20110;&#36755;&#20986;&#26159;&#21521;&#37327;&#25110;&#26631;&#37327;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#23398;&#20064;&#26410;&#30693;&#30340;&#29366;&#24577;&#36716;&#31227;&#21644;&#35835;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#36890;&#36807;&#20351;&#29992;&#29366;&#24577;&#31354;&#38388;&#34920;&#31034;&#26469;&#27169;&#25311;&#21160;&#24577;&#31995;&#32479;&#65292;&#19979;&#19968;&#20010;&#29366;&#24577;&#30340;&#26356;&#26032;&#20197;&#21450;&#19982;&#26032;&#35266;&#23519;&#21040;&#30340;&#31995;&#32479;&#36755;&#20986;&#30456;&#20851;&#30340;&#20449;&#24687;&#26469;&#25511;&#21046;&#20854;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#23558;&#21345;&#23572;&#26364;&#21644;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#25512;&#24191;&#21040;&#31163;&#25955;&#26102;&#38388;&#30340;&#35774;&#32622;&#19979;&#65292;&#20854;&#20013;&#36755;&#20837;&#12289;&#29366;&#24577;&#21644;&#36755;&#20986;&#22343;&#34920;&#31034;&#20026;&#24102;&#23646;&#24615;&#30340;&#22270;&#24418;&#65292;&#20854;&#25299;&#25169;&#21644;&#23646;&#24615;&#21487;&#20197;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#27492;&#35774;&#32622;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#23558;&#26694;&#26550;&#36866;&#24212;&#20110;&#36755;&#20986;&#26159;&#21521;&#37327;&#25110;&#26631;&#37327;&#30340;&#24773;&#20917;&#65288;&#33410;&#28857;/&#22270;&#32423;&#20219;&#21153;&#65289;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#29702;&#35770;&#26694;&#26550;&#20869;&#65292;&#26410;&#30693;&#30340;&#29366;&#24577;&#36716;&#31227;&#21644;&#35835;&#21462;&#20989;&#25968;&#19982;&#19979;&#28216;&#39044;&#27979;&#20219;&#21153;&#19968;&#36215;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The well-known Kalman filters model dynamical systems by relying on state-space representations with the next state updated, and its uncertainty controlled, by fresh information associated with newly observed system outputs. This paper generalizes, for the first time in the literature, Kalman and extended Kalman filters to discrete-time settings where inputs, states, and outputs are represented as attributed graphs whose topology and attributes can change with time. The setup allows us to adapt the framework to cases where the output is a vector or a scalar too (node/graph level tasks). Within the proposed theoretical framework, the unknown state-transition and the readout functions are learned end-to-end along with the downstream prediction task.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#36827;&#34892;&#21464;&#20998;&#39640;&#26031;&#28388;&#27874;&#65292;&#31454;&#20105;&#21147;&#31361;&#20986;&#12290;</title><link>http://arxiv.org/abs/2303.06398</link><description>&lt;p&gt;
&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#36827;&#34892;&#21464;&#20998;&#39640;&#26031;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Variational Gaussian filtering via Wasserstein gradient flows. (arXiv:2303.06398v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06398
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#36827;&#34892;&#21464;&#20998;&#39640;&#26031;&#28388;&#27874;&#65292;&#31454;&#20105;&#21147;&#31361;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#36817;&#20284;&#39640;&#26031;&#21644;&#39640;&#26031;&#28151;&#21512;&#28388;&#27874;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#36890;&#36807;&#26799;&#24230;&#27969;&#34920;&#31034;&#30340;&#21464;&#20998;&#36817;&#20284;&#12290;&#26799;&#24230;&#27969;&#26159;&#22522;&#20110;&#22312;&#27010;&#29575;&#20998;&#24067;&#31354;&#38388;&#19978;&#37197;&#22791;&#20102;Wasserstein&#24230;&#37327;&#30340;Kullback-Leibler&#24046;&#24322;&#26368;&#23567;&#21270;&#23548;&#20986;&#30340;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#19968;&#33324;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#21518;&#39564;&#34920;&#31034;&#21644;&#21442;&#25968;&#20272;&#35745;&#19978;&#30340;&#31454;&#20105;&#21147;&#65292;&#38024;&#23545;&#39640;&#26031;&#36817;&#20284;&#36890;&#24120;&#22833;&#36133;&#30340;&#20004;&#31181;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65306;&#20855;&#26377;&#20056;&#27861;&#22122;&#22768;&#21644;&#22810;&#23792;&#24577;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach to approximate Gaussian and mixture-of-Gaussians filtering. Our method relies on a variational approximation via a gradient-flow representation. The gradient flow is derived from a Kullback--Leibler discrepancy minimization on the space of probability distributions equipped with the Wasserstein metric. We outline the general method and show its competitiveness in posterior representation and parameter estimation on two state-space models for which Gaussian approximations typically fail: systems with multiplicative noise and multi-modal state distributions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31526;&#21512;&#24050;&#30693;&#30005;&#27969;&#29289;&#29702;&#29305;&#24615;&#30340;&#27169;&#22411;&#65292;&#22312;&#36890;&#36807;Helmholtz&#20998;&#35299;&#33719;&#24471;&#30340;&#21521;&#37327;&#22330;&#30340;&#21457;&#25955;&#21644;&#26080;&#26059;&#20998;&#37327;&#19978;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#39044;&#27979;&#28023;&#27969;&#12290;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#28014;&#26631;&#25968;&#25454;&#26041;&#38754;&#37117;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#26356;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.10364</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#36203;&#36203;&#23572;&#22982;&#38669;&#20857;&#20998;&#35299;&#20013;&#30340;&#24212;&#29992;&#65306;&#19968;&#31181;&#26356;&#27969;&#20307;&#30340;&#28023;&#27915;&#27668;&#27969;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes at the Helm(holtz): A more fluid model for ocean currents. (arXiv:2302.10364v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10364
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31526;&#21512;&#24050;&#30693;&#30005;&#27969;&#29289;&#29702;&#29305;&#24615;&#30340;&#27169;&#22411;&#65292;&#22312;&#36890;&#36807;Helmholtz&#20998;&#35299;&#33719;&#24471;&#30340;&#21521;&#37327;&#22330;&#30340;&#21457;&#25955;&#21644;&#26080;&#26059;&#20998;&#37327;&#19978;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#39044;&#27979;&#28023;&#27969;&#12290;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#28014;&#26631;&#25968;&#25454;&#26041;&#38754;&#37117;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28023;&#27915;&#23398;&#23478;&#26377;&#20852;&#36259;&#39044;&#27979;&#28023;&#27969;&#21644;&#22522;&#20110;&#28014;&#26631;&#36895;&#24230;&#30340;&#31232;&#30095;&#35266;&#27979;&#25968;&#25454;&#26469;&#35782;&#21035;&#24403;&#21069;&#30690;&#37327;&#22330;&#20013;&#30340;&#21457;&#25955;&#24615;&#12290;&#39640;&#26031;&#36807;&#31243;(GPs)&#22312;&#31354;&#38388;&#20301;&#32622;&#19978;&#20805;&#24403;&#36830;&#32493;&#20294;&#39640;&#24230;&#38750;&#32447;&#24615;&#21151;&#33021;&#30340;&#36895;&#24230;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#27169;&#22411;&#12290;&#20294;&#25105;&#20204;&#34920;&#26126;&#65292;&#23558;&#20855;&#26377;&#26631;&#20934;&#24179;&#31283;&#26680;&#30340;GP&#30452;&#25509;&#24212;&#29992;&#20110;&#28014;&#26631;&#25968;&#25454;&#21487;&#33021;&#22312;&#24403;&#21069;&#39044;&#27979;&#21644;&#21457;&#25955;&#24615;&#35782;&#21035;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#8212;&#30001;&#20110;&#19968;&#20123;&#29289;&#29702;&#19978;&#19981;&#20999;&#23454;&#38469;&#30340;&#20808;&#39564;&#20551;&#35774;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#21453;&#26144;&#24050;&#30693;&#30340;&#30005;&#27969;&#29289;&#29702;&#29305;&#24615;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#26631;&#20934;&#24179;&#31283;&#26680;&#25918;&#22312;&#36890;&#36807;Helmholtz&#20998;&#35299;&#33719;&#24471;&#30340;&#21521;&#37327;&#22330;&#30340;&#21457;&#25955;&#21644;&#26080;&#26059;&#20998;&#37327;&#19978;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30001;&#20110;&#35813;&#20998;&#35299;&#20165;&#36890;&#36807;&#28151;&#21512;&#20559;&#23548;&#25968;&#19982;&#21407;&#22987;&#21521;&#37327;&#22330;&#30456;&#20851;&#65292;&#22240;&#27492;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#22312;&#21407;&#22987;&#25968;&#25454;&#32473;&#23450;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#25512;&#29702;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#39069;&#22806;&#36827;&#34892;&#23569;&#25968;&#35745;&#31639;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#28014;&#26631;&#25968;&#25454;&#35777;&#26126;&#20102;&#36825;&#31181;&#34746;&#26059;GP&#30340;&#26377;&#25928;&#24615;&#65292;&#20174;&#32780;&#22312;&#22343;&#26041;&#39044;&#27979;&#35823;&#24046;&#26041;&#38754;&#20248;&#20110;&#20808;&#21069;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oceanographers are interested in predicting ocean currents and identifying divergences in a current vector field based on sparse observations of buoy velocities. Since we expect current velocity to be a continuous but highly non-linear function of spatial location, Gaussian processes (GPs) offer an attractive model. But we show that applying a GP with a standard stationary kernel directly to buoy data can struggle at both current prediction and divergence identification -- due to some physically unrealistic prior assumptions. To better reflect known physical properties of currents, we propose to instead put a standard stationary kernel on the divergence and curl-free components of a vector field obtained through a Helmholtz decomposition. We show that, because this decomposition relates to the original vector field just via mixed partial derivatives, we can still perform inference given the original data with only a small constant multiple of additional computational expense. We illust
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102; JANA &#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#26434;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#36817;&#20284;&#35745;&#31639;&#12290;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#19977;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#20998;&#25674;&#30340;&#36817;&#20284;&#21518;&#39564;&#21644;&#20284;&#28982;&#65292;&#20026;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#36884;&#24452;&#12290;&#27492;&#26041;&#27861;&#22312;&#22810;&#31181;&#27169;&#25311;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#26657;&#20934;&#35786;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.09125</link><description>&lt;p&gt;
JANA&#65306;&#22797;&#26434;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#32852;&#21512;&#20998;&#25674;&#36817;&#20284;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
JANA: Jointly Amortized Neural Approximation of Complex Bayesian Models. (arXiv:2302.09125v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102; JANA &#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22797;&#26434;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#36817;&#20284;&#35745;&#31639;&#12290;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#19977;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#20998;&#25674;&#30340;&#36817;&#20284;&#21518;&#39564;&#21644;&#20284;&#28982;&#65292;&#20026;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#36884;&#24452;&#12290;&#27492;&#26041;&#27861;&#22312;&#22810;&#31181;&#27169;&#25311;&#27169;&#22411;&#20013;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#26657;&#20934;&#35786;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#32852;&#21512;&#20998;&#25674;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#8221;&#65288;JANA&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#36125;&#21494;&#26031;&#20195;&#29702;&#24314;&#27169;&#21644;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#20013;&#20986;&#29616;&#30340;&#38590;&#20197;&#35745;&#31639;&#30340;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#23494;&#24230;&#12290;&#25105;&#20204;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#35757;&#32451;&#19977;&#20010;&#30456;&#20114;&#34917;&#20805;&#30340;&#31070;&#32463;&#32593;&#32476;&#65306;1&#65289;&#19968;&#20010;&#24635;&#32467;&#32593;&#32476;&#65292;&#23558;&#20010;&#21035;&#25968;&#25454;&#28857;&#12289;&#38598;&#21512;&#25110;&#26102;&#38388;&#24207;&#21015;&#21387;&#32553;&#25104;&#20449;&#24687;&#23884;&#20837;&#21521;&#37327;&#65307;2&#65289;&#19968;&#20010;&#21518;&#39564;&#32593;&#32476;&#65292;&#23398;&#20064;&#20998;&#25674;&#30340;&#36817;&#20284;&#21518;&#39564;&#65307;3&#65289;&#19968;&#20010;&#20284;&#28982;&#32593;&#32476;&#65292;&#23398;&#20064;&#20998;&#25674;&#30340;&#36817;&#20284;&#20284;&#28982;&#12290;&#23427;&#20204;&#30340;&#20132;&#20114;&#20026;&#20998;&#25674;&#36793;&#32536;&#20284;&#28982;&#21644;&#21518;&#39564;&#39044;&#27979;&#20272;&#35745;&#25552;&#20379;&#20102;&#26032;&#30340;&#36884;&#24452;&#65292;&#36825;&#26159;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#30340;&#20004;&#20010;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#24120;&#24120;&#23545;&#20110;&#26631;&#20934;&#26041;&#27861;&#26469;&#35828;&#22826;&#26114;&#36149;&#20102;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#27169;&#25311;&#27169;&#22411;&#20013;&#23545;JANA&#30340;&#20445;&#30495;&#24230;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#22823;&#32780;&#21487;&#35299;&#37322;&#30340;&#32852;&#21512;&#26657;&#20934;&#35786;&#26029;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24490;&#29615;&#20284;&#28982;&#32593;&#32476;&#27169;&#25311;&#22797;&#26434;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes ''jointly amortized neural approximation'' (JANA) of intractable likelihood functions and posterior densities arising in Bayesian surrogate modeling and simulation-based inference. We train three complementary networks in an end-to-end fashion: 1) a summary network to compress individual data points, sets, or time series into informative embedding vectors; 2) a posterior network to learn an amortized approximate posterior; and 3) a likelihood network to learn an amortized approximate likelihood. Their interaction opens a new route to amortized marginal likelihood and posterior predictive estimation -- two important ingredients of Bayesian workflows that are often too expensive for standard methods. We benchmark the fidelity of JANA on a variety of simulation models against state-of-the-art Bayesian methods and propose a powerful and interpretable diagnostic for joint calibration. In addition, we investigate the ability of recurrent likelihood networks to emulate comp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#29305;&#24449;&#25193;&#25955;&#30697;&#38453;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26469;&#32553;&#25918;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#29992;Hessians&#26469;&#34913;&#37327;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#22122;&#22768;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20943;&#23567;&#27867;&#21270;&#30028;&#38480;&#65292;&#26356;&#22909;&#22320;&#35299;&#20915;&#20102;&#23454;&#38469;&#22270;&#24418;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.04451</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27867;&#21270;&#65306;&#22522;&#20110;&#22270;&#25193;&#25955;&#30340;&#25913;&#36827;PAC-Bayesian&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion. (arXiv:2302.04451v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#29305;&#24449;&#25193;&#25955;&#30697;&#38453;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26469;&#32553;&#25918;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#29992;Hessians&#26469;&#34913;&#37327;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#22122;&#22768;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#20943;&#23567;&#27867;&#21270;&#30028;&#38480;&#65292;&#26356;&#22909;&#22320;&#35299;&#20915;&#20102;&#23454;&#38469;&#22270;&#24418;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#26159;&#22270;&#39044;&#27979;&#20219;&#21153;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#24037;&#20855;&#12290;&#30001;&#20854;&#23454;&#35777;&#34920;&#29616;&#25152;&#39537;&#21160;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#24320;&#21457;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#23427;&#20204;&#26681;&#25454;&#26368;&#22823;&#24230;&#25968;&#22312;&#22270;&#32467;&#26500;&#26041;&#38754;&#36827;&#34892;&#32553;&#25918;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#26681;&#25454;&#22270;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#25193;&#25955;&#30697;&#38453;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#36827;&#34892;&#32553;&#25918;&#12290;&#23545;&#20110;&#23454;&#38469;&#22270;&#24418;&#65292;&#36825;&#20123;&#30028;&#38480;&#30340;&#25968;&#20540;&#35201;&#27604;&#20808;&#21069;&#30340;&#30028;&#38480;&#23567;&#24471;&#22810;&#12290;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#19968;&#20010;&#30456;&#31526;&#30340;&#27867;&#21270;&#24046;&#36317;&#19979;&#38480;&#65292;&#20854;&#28176;&#36817;&#22320;&#21305;&#37197;&#20102;&#25105;&#20204;&#30340;&#19978;&#38480;&#30028;&#38480;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#20808;&#21069;&#30340;&#35774;&#32622;&#65288;&#21363;&#21367;&#31215;&#21644;&#28040;&#24687;&#20256;&#36882;&#32593;&#32476;&#65289;&#21644;&#26032;&#30340;&#35774;&#32622;&#65288;&#21363;&#22270;&#21516;&#26500;&#32593;&#32476;&#65289;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#21033;&#29992;Hessians&#26469;&#34913;&#37327;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#20110;&#22122;&#22768;&#25200;&#21160;&#30340;&#31283;&#23450;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22522;&#20110;Hessian&#30340;&#27979;&#37327;&#19982;&#35266;&#23519;&#21040;&#30340;&#27867;&#21270;&#24046;&#36317;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network's feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works' settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with the observed generalization gaps
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#22823;&#35268;&#27169;&#36890;&#29992;&#26680;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#35299;&#20915;&#20102;&#20256;&#32479;&#26680;&#26426;&#22120;&#20013;&#27169;&#22411;&#22823;&#23567;&#19982;&#25968;&#25454;&#22823;&#23567;&#30456;&#20114;&#32806;&#21512;&#30340;&#38382;&#39064;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2302.02605</link><description>&lt;p&gt;
&#21521;&#22823;&#26680;&#27169;&#22411;&#36808;&#36827;
&lt;/p&gt;
&lt;p&gt;
Toward Large Kernel Models. (arXiv:2302.02605v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#22823;&#35268;&#27169;&#36890;&#29992;&#26680;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#35299;&#20915;&#20102;&#20256;&#32479;&#26680;&#26426;&#22120;&#20013;&#27169;&#22411;&#22823;&#23567;&#19982;&#25968;&#25454;&#22823;&#23567;&#30456;&#20114;&#32806;&#21512;&#30340;&#38382;&#39064;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30456;&#27604;&#65292;&#26680;&#26426;&#22120;&#22312;&#23567;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#36890;&#24120;&#21487;&#20197;&#36798;&#21040;&#25110;&#36229;&#36807;DNN&#12290;&#26680;&#26426;&#22120;&#30340;&#20852;&#36259;&#21463;&#21040;&#20854;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#31561;&#25928;&#20110;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#21457;&#29616;&#30340;&#25512;&#21160;&#12290;&#28982;&#32780;&#65292;DNN&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#26159;&#23427;&#20204;&#33021;&#22815;&#29420;&#31435;&#22320;&#25193;&#23637;&#27169;&#22411;&#22823;&#23567;&#21644;&#35757;&#32451;&#25968;&#25454;&#37327;&#65292;&#32780;&#22312;&#20256;&#32479;&#30340;&#26680;&#26426;&#22120;&#20013;&#65292;&#27169;&#22411;&#22823;&#23567;&#19982;&#25968;&#25454;&#22823;&#23567;&#26159;&#30456;&#20114;&#32806;&#21512;&#30340;&#12290;&#30001;&#20110;&#36825;&#31181;&#32806;&#21512;&#65292;&#23558;&#26680;&#26426;&#22120;&#25193;&#23637;&#21040;&#22823;&#25968;&#25454;&#26159;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26500;&#24314;&#22823;&#35268;&#27169;&#36890;&#29992;&#26680;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#26680;&#26426;&#22120;&#30340;&#19968;&#33324;&#21270;&#65292;&#36890;&#36807;&#35299;&#32806;&#27169;&#22411;&#21644;&#25968;&#25454;&#65292;&#20801;&#35768;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#25237;&#24433;&#21452;&#37325;&#39044;&#22788;&#29702;SGD&#30340;EigenPro 3.0&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20351;&#29992;&#29616;&#26377;&#26680;&#26041;&#27861;&#19981;&#21487;&#33021;&#23454;&#29616;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies indicate that kernel machines can often perform similarly or better than deep neural networks (DNNs) on small datasets. The interest in kernel machines has been additionally bolstered by the discovery of their equivalence to wide neural networks in certain regimes. However, a key feature of DNNs is their ability to scale the model size and training data size independently, whereas in traditional kernel machines model size is tied to data size. Because of this coupling, scaling kernel machines to large data has been computationally challenging. In this paper, we provide a way forward for constructing large-scale general kernel models, which are a generalization of kernel machines that decouples the model and data, allowing training on large datasets. Specifically, we introduce EigenPro 3.0, an algorithm based on projected dual preconditioned SGD and show scaling to model and data sizes which have not been possible with existing kernel methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22810;&#32500;&#27010;&#24565;&#21457;&#29616;(MCD)&#26041;&#27861;&#65292;&#23427;&#28385;&#36275;&#27010;&#24565;&#23618;&#38754;&#19978;&#30340;&#23436;&#25972;&#24615;&#20851;&#31995;&#65292;&#19981;&#38656;&#35201;&#21152;&#24378;&#27010;&#24565;&#21487;&#35299;&#37322;&#24615;&#25110;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#37096;&#20998;&#65292;&#24182;&#25552;&#20379;&#27010;&#24565;&#28608;&#27963;&#22270;&#20998;&#26512;&#24037;&#20855;</title><link>http://arxiv.org/abs/2301.11911</link><description>&lt;p&gt;
&#22810;&#32500;&#27010;&#24565;&#21457;&#29616;(MCD): &#19968;&#20010;&#20855;&#26377;&#23436;&#25972;&#24615;&#20445;&#35777;&#30340;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees. (arXiv:2301.11911v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11911
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22810;&#32500;&#27010;&#24565;&#21457;&#29616;(MCD)&#26041;&#27861;&#65292;&#23427;&#28385;&#36275;&#27010;&#24565;&#23618;&#38754;&#19978;&#30340;&#23436;&#25972;&#24615;&#20851;&#31995;&#65292;&#19981;&#38656;&#35201;&#21152;&#24378;&#27010;&#24565;&#21487;&#35299;&#37322;&#24615;&#25110;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#37096;&#20998;&#65292;&#24182;&#25552;&#20379;&#27010;&#24565;&#28608;&#27963;&#22270;&#20998;&#26512;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23436;&#25972;&#24615;&#20844;&#29702;&#20351;&#24471;&#21518;&#32493;XAI&#26041;&#27861;&#30340;&#35299;&#37322;&#20165;&#23545;&#27169;&#22411;&#22312;&#21333;&#20010;&#20915;&#31574;&#19978;&#26377;&#25928;&#12290;&#20026;&#20102;&#21487;&#20449;&#22320;&#24212;&#29992;XAI&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#39640;&#39118;&#38505;&#30340;&#20915;&#31574;&#65292;&#38656;&#35201;&#26356;&#20840;&#29699;&#30340;&#27169;&#22411;&#29702;&#35299;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#22522;&#20110;&#27010;&#24565;&#30340;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#19981;&#33021;&#20445;&#35777;&#19982;&#23454;&#38469;&#30340;&#27169;&#22411;&#25512;&#29702;&#30456;&#32467;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#32500;&#27010;&#24565;&#21457;&#29616;(MCD)&#65292;&#20316;&#20026;&#20043;&#21069;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#28385;&#36275;&#27010;&#24565;&#23618;&#38754;&#19978;&#30340;&#23436;&#25972;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;&#36890;&#29992;&#30340;&#32447;&#24615;&#23376;&#31354;&#38388;&#20316;&#20026;&#27010;&#24565;&#24320;&#22987;&#65292;&#24182;&#19981;&#38656;&#35201;&#21152;&#24378;&#27010;&#24565;&#21487;&#35299;&#37322;&#24615;&#25110;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#37096;&#20998;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31232;&#30095;&#23376;&#31354;&#38388;&#32858;&#31867;&#26469;&#21457;&#29616;&#25913;&#36827;&#30340;&#27010;&#24565;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#22810;&#32500;&#23376;&#31354;&#38388;&#30340;&#28508;&#33021;&#12290;MCD&#25552;&#20379;&#20102;&#20004;&#31181;&#27010;&#24565;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#20114;&#34917;&#20998;&#26512;&#24037;&#20855;&#65306;(1)&#27010;&#24565;&#28608;&#27963;&#22270;&#65292;&#26174;&#31034;&#27010;&#24565;&#34920;&#36798;&#30340;&#20301;&#32622;
&lt;/p&gt;
&lt;p&gt;
The completeness axiom renders the explanation of a post-hoc XAI method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. Recently, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is express
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#31070;&#32463;&#36830;&#32493;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#20854;&#37319;&#29992;&#36741;&#21161;&#21464;&#37327;&#26469;&#21306;&#20998;&#35782;&#21035;&#21644;&#21160;&#24577;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#21644;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.11308</link><description>&lt;p&gt;
&#38024;&#23545;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#31070;&#32463;&#36830;&#32493;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series. (arXiv:2301.11308v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#30340;&#31070;&#32463;&#36830;&#32493;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#20854;&#37319;&#29992;&#36741;&#21161;&#21464;&#37327;&#26469;&#21306;&#20998;&#35782;&#21035;&#21644;&#21160;&#24577;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#21644;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#30495;&#23454;&#19990;&#30028;&#21160;&#24577;&#29616;&#35937;&#65288;&#22914;&#27668;&#20505;&#12289;&#29983;&#29289;&#23398;&#31561;&#65289;&#30340;&#20934;&#30830;&#39044;&#27979;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#19968;&#39033;&#20851;&#38190;&#38382;&#39064;&#26159;&#65292;&#33258;&#28982;&#21644;&#20154;&#24037;&#36807;&#31243;&#29983;&#25104;&#30340;&#25968;&#25454;&#24448;&#24448;&#21253;&#21547;&#19981;&#35268;&#21017;&#37319;&#26679;&#21644;/&#25110;&#32570;&#22833;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#31070;&#32463;&#36830;&#32493;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;NCDSSM&#65289;&#65292;&#29992;&#20110;&#36890;&#36807;&#31163;&#25955;&#26102;&#38388;&#35266;&#27979;&#23545;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#36830;&#32493;&#26102;&#38388;&#24314;&#27169;&#12290;NCDSSM&#37319;&#29992;&#36741;&#21161;&#21464;&#37327;&#26469;&#21306;&#20998;&#35782;&#21035;&#21644;&#21160;&#24577;&#65292;&#22240;&#27492;&#20165;&#38656;&#35201;&#23545;&#36741;&#21161;&#21464;&#37327;&#36827;&#34892;&#25674;&#38144;&#25512;&#29702;&#12290;&#21033;&#29992;&#36830;&#32493;-&#31163;&#25955;&#28388;&#27874;&#29702;&#35770;&#30340;&#25216;&#26415;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23545;&#21160;&#24577;&#29366;&#24577;&#36827;&#34892;&#20934;&#30830;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#28789;&#27963;&#30340;&#28508;&#22312;&#21160;&#24577;&#21442;&#25968;&#21270;&#26041;&#27861;&#21644;&#19968;&#31181;&#22312;&#25512;&#26029;&#26399;&#38388;&#23545;&#21160;&#24577;&#29366;&#24577;&#36827;&#34892;&#36793;&#32536;&#21270;&#30340;&#39640;&#25928;&#22521;&#35757;&#30446;&#26631;&#12290;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#20102;&#25913;&#36827;&#20102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning accurate predictive models of real-world dynamic phenomena (e.g., climate, biological) remains a challenging task. One key issue is that the data generated by both natural and artificial processes often comprise time series that are irregularly sampled and/or contain missing observations. In this work, we propose the Neural Continuous-Discrete State Space Model (NCDSSM) for continuous-time modeling of time series through discrete-time observations. NCDSSM employs auxiliary variables to disentangle recognition from dynamics, thus requiring amortized inference only for the auxiliary variables. Leveraging techniques from continuous-discrete filtering theory, we demonstrate how to perform accurate Bayesian inference for the dynamic states. We propose three flexible parameterizations of the latent dynamics and an efficient training objective that marginalizes the dynamic states during inference. Empirical results on multiple benchmark datasets across various domains show improved i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#20132;&#26367;&#32676;($A_n$)&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#34920;&#24449;&#65292;&#20854;&#20013;&#25551;&#36848;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#12289;$A_n$&#31561;&#21464;&#23618;&#20989;&#25968;&#30340;&#30697;&#38453;&#22522;&#65292;&#22312;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.10152</link><description>&lt;p&gt;
&#27700;&#27597;&#22914;&#20309;&#34920;&#24449;&#20132;&#26367;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
How Jellyfish Characterise Alternating Group Equivariant Neural Networks. (arXiv:2301.10152v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10152
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#20132;&#26367;&#32676;($A_n$)&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#34920;&#24449;&#65292;&#20854;&#20013;&#25551;&#36848;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#12289;$A_n$&#31561;&#21464;&#23618;&#20989;&#25968;&#30340;&#30697;&#38453;&#22522;&#65292;&#22312;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;&#21487;&#33021;&#30340;&#23618;&#25968;&#20026;$\mathbb{R}^{n}$&#24352;&#37327;&#24130;&#27425;&#30340;&#20132;&#26367;&#32676;($A_n$)&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#34920;&#24449;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;$\mathbb{R}^{n}$&#30340;&#26631;&#20934;&#22522;&#30784;&#19978;&#25214;&#21040;&#19968;&#32452;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#12289;$A_n$&#31561;&#21464;&#23618;&#20989;&#25968;&#30340;&#30697;&#38453;&#22522;&#12290;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#25512;&#24191;&#21040;&#26500;&#24314;&#31561;&#21464;&#20110;&#23616;&#37096;&#23545;&#31216;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a full characterisation of all of the possible alternating group ($A_n$) equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a basis of matrices for the learnable, linear, $A_n$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$. We also describe how our approach generalises to the construction of neural networks that are equivariant to local symmetries.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#35777;&#26126;&#23545;&#20110;&#22343;&#26041;&#35823;&#24046;&#21644;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20986;&#29616;&#30340;&#20840;&#23616;&#35299;&#22312;&#19981;&#21516;&#25968;&#25454;&#19978;&#37117;&#20855;&#26377;&#31070;&#32463;&#22604;&#38519;&#30340;&#29305;&#24615;&#65292;&#21363;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#23849;&#28291;&#20026;&#31867;&#22343;&#20540;&#65292;&#32780;&#36825;&#20123;&#31867;&#22343;&#20540;&#26159;&#31561;&#35282;&#32039;&#26694;&#26550;&#30340;&#39030;&#28857;&#12290;</title><link>http://arxiv.org/abs/2301.00437</link><description>&lt;p&gt;
&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22604;&#38519;:&#20174;&#24179;&#34913;&#21040;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Neural Collapse in Deep Linear Networks: From Balanced to Imbalanced Data. (arXiv:2301.00437v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00437
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#35777;&#26126;&#23545;&#20110;&#22343;&#26041;&#35823;&#24046;&#21644;&#20132;&#21449;&#29109;&#25439;&#22833;&#65292;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20986;&#29616;&#30340;&#20840;&#23616;&#35299;&#22312;&#19981;&#21516;&#25968;&#25454;&#19978;&#37117;&#20855;&#26377;&#31070;&#32463;&#22604;&#38519;&#30340;&#29305;&#24615;&#65292;&#21363;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#23849;&#28291;&#20026;&#31867;&#22343;&#20540;&#65292;&#32780;&#36825;&#20123;&#31867;&#22343;&#20540;&#26159;&#31561;&#35282;&#32039;&#26694;&#26550;&#30340;&#39030;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#20687;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#36825;&#20123;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#22797;&#26434;&#31995;&#32479;&#22312;&#35757;&#32451;&#21040;&#25910;&#25947;&#26102;&#65292;&#23427;&#20204;&#30340;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#21644;&#20998;&#31867;&#22120;&#22312;&#32463;&#20856;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#30456;&#21516;&#30340;&#32467;&#26500;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#35266;&#23519;&#21040;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#23849;&#28291;&#20026;&#31867;&#22343;&#20540;&#65292;&#24182;&#19988;&#36825;&#20123;&#31867;&#22343;&#20540;&#26159;&#31561;&#35282;&#32039;&#26694;&#26550;(simplex Equiangular Tight Frame)&#30340;&#39030;&#28857;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#22604;&#38519;(NC)&#12290;&#26368;&#36817;&#30340;&#35770;&#25991;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#22312;&#31616;&#21270;&#30340;&#8220;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#8221;&#35757;&#32451;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#20013;&#20986;&#29616;&#20102;$\mathcal{NC}$&#12290;&#22312;&#36825;&#20010;&#35821;&#22659;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#22312;&#24120;&#29992;&#30340;&#22343;&#26041;&#35823;&#24046;(MSE)&#21644;&#20132;&#21449;&#29109;(CE)&#25439;&#22833;&#19979;&#65292;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#20063;&#20250;&#21457;&#29983;$\mathcal{NC}$&#29616;&#35937;&#65292;&#34920;&#26126;&#20840;&#23616;&#35299;&#22312;&#19981;&#21516;&#25968;&#25454;&#19978;&#37117;&#20855;&#26377;$\mathcal{NC}$&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks have achieved impressive performance on tasks from image classification to natural language processing. Surprisingly, these complex systems with massive amounts of parameters exhibit the same structural properties in their last-layer features and classifiers across canonical datasets when training until convergence. In particular, it has been observed that the last-layer features collapse to their class-means, and those class-means are the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is known as Neural Collapse ($\mathcal{NC}$). Recent papers have theoretically shown that $\mathcal{NC}$ emerges in the global minimizers of training problems with the simplified ``unconstrained feature model''. In this context, we take a step further and prove the $\mathcal{NC}$ occurrences in deep linear networks for the popular mean squared error (MSE) and cross entropy (CE) losses, showing that global solutions exhibit $\mathcal{NC}$ properties across
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;&#23545;&#20110;&#19977;&#20010;&#22312;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#32570;&#22833;&#30340;&#23545;&#31216;&#32676;&#65288;$O(n)$&#12289;$SO(n)$&#21644;$Sp(n)$&#65289;&#65292;&#25152;&#26377;&#21487;&#33021;&#30340;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#65292;&#24182;&#25214;&#21040;&#20102;&#36825;&#20123;&#32593;&#32476;&#22312;&#19981;&#21516;&#22522;&#30784;&#19979;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;</title><link>http://arxiv.org/abs/2212.08630</link><description>&lt;p&gt;
Brauer&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Brauer's Group Equivariant Neural Networks. (arXiv:2212.08630v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08630
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#23545;&#20110;&#19977;&#20010;&#22312;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#32570;&#22833;&#30340;&#23545;&#31216;&#32676;&#65288;$O(n)$&#12289;$SO(n)$&#21644;$Sp(n)$&#65289;&#65292;&#25152;&#26377;&#21487;&#33021;&#30340;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#65292;&#24182;&#25214;&#21040;&#20102;&#36825;&#20123;&#32593;&#32476;&#22312;&#19981;&#21516;&#22522;&#30784;&#19979;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#26377;&#21487;&#33021;&#30340;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23436;&#25972;&#29305;&#24449;&#25551;&#36848;&#65292;&#20854;&#20013;&#30340;&#23618;&#26159;$\mathbb{R}^{n}$&#30340;&#26576;&#20123;&#24352;&#37327;&#24130;&#65292;&#36866;&#29992;&#20110;&#19977;&#20010;&#22312;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#32570;&#22833;&#30340;&#23545;&#31216;&#32676;&#65306;$O(n)$&#65288;&#27491;&#20132;&#32676;&#65289;&#65292;$SO(n)$&#65288;&#29305;&#27530;&#27491;&#20132;&#32676;&#65289;&#21644;$Sp(n)$&#65288;&#36763;&#32676;&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#32676;&#20026;$O(n)$&#25110;$SO(n)$&#26102;&#65292;&#22312;$\mathbb{R}^{n}$&#30340;&#26631;&#20934;&#22522;&#30784;&#19979;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#21487;&#23398;&#20064;&#30340;&#12289;&#32447;&#24615;&#30340;&#12289;&#31561;&#21464;&#30340;&#23618;&#20989;&#25968;&#20043;&#38388;&#30340;&#30697;&#38453;&#30340;&#29983;&#25104;&#38598;&#65307;&#24403;&#32676;&#20026;$Sp(n)$&#26102;&#65292;&#25105;&#20204;&#21017;&#22312;$\mathbb{R}^{n}$&#30340;&#36763;&#22522;&#30784;&#19979;&#25214;&#21040;&#20102;&#36825;&#26679;&#30340;&#29983;&#25104;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a full characterisation of all of the possible group equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$ for three symmetry groups that are missing from the machine learning literature: $O(n)$, the orthogonal group; $SO(n)$, the special orthogonal group; and $Sp(n)$, the symplectic group. In particular, we find a spanning set of matrices for the learnable, linear, equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$ when the group is $O(n)$ or $SO(n)$, and in the symplectic basis of $\mathbb{R}^{n}$ when the group is $Sp(n)$.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20256;&#36755;&#22810;&#38754;&#20307;&#19978;&#36827;&#34892;&#22312;&#32447;&#20984;&#30446;&#26631;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#27492;&#31639;&#27861;&#22522;&#20110;Sinkhorn&#30697;&#38453;&#32553;&#25918;&#21644;&#38236;&#20687;&#19979;&#38477;&#30340;&#21407;&#29702;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#22122;&#38899;&#29615;&#22659;&#19979;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2211.10420</link><description>&lt;p&gt;
&#38236;&#20687;Sinkhorn&#65306;&#22312;&#20256;&#36755;&#22810;&#38754;&#20307;&#19978;&#36827;&#34892;&#24555;&#36895;&#22312;&#32447;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes. (arXiv:2211.10420v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10420
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20256;&#36755;&#22810;&#38754;&#20307;&#19978;&#36827;&#34892;&#22312;&#32447;&#20984;&#30446;&#26631;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#27492;&#31639;&#27861;&#22522;&#20110;Sinkhorn&#30697;&#38453;&#32553;&#25918;&#21644;&#38236;&#20687;&#19979;&#38477;&#30340;&#21407;&#29702;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#22122;&#38899;&#29615;&#22659;&#19979;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#20256;&#36755;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#36890;&#36807;&#22312;&#20256;&#36755;&#22810;&#38754;&#20307;&#19978;&#30340;&#32447;&#24615;&#35268;&#21010;&#26469;&#25429;&#25417;&#25968;&#25454;&#30340;&#20960;&#20309;&#23646;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#20248;&#21270;&#31639;&#27861;&#65292;&#21033;&#29992;Sinkhorn&#30697;&#38453;&#32553;&#25918;&#21644;&#38236;&#20687;&#19979;&#38477;&#30340;&#21407;&#29702;&#65292;&#22312;&#36825;&#20123;&#39046;&#22495;&#19978;&#26368;&#23567;&#21270;&#19968;&#33324;&#20984;&#30446;&#26631;&#12290;&#35813;&#31639;&#27861;&#23545;&#22122;&#38899;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#21487;&#22312;&#22312;&#32447;&#35774;&#32622;&#20013;&#20351;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20984;&#30446;&#26631;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal transport is an important tool in machine learning, allowing to capture geometric properties of the data through a linear program on transport polytopes. We present a single-loop optimization algorithm for minimizing general convex objectives on these domains, utilizing the principles of Sinkhorn matrix scaling and mirror descent. The proposed algorithm is robust to noise, and can be used in an online setting. We provide theoretical guarantees for convex objectives and experimental results showcasing it effectiveness on both synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21333;&#35843;&#23433;&#20840;UCB(M-SafeUCB)&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21333;&#35843;&#24615;&#20551;&#35774;&#65292;&#21462;&#24471;&#20102;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2211.01561</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20013;&#21333;&#35843;&#24615;&#30340;&#23433;&#20840;&#25506;&#32034;&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Benefits of Monotonicity in Safe Exploration with Gaussian Processes. (arXiv:2211.01561v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21333;&#35843;&#23433;&#20840;UCB(M-SafeUCB)&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21333;&#35843;&#24615;&#20551;&#35774;&#65292;&#21462;&#24471;&#20102;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#30456;&#24212;&#30340;&#23433;&#20840;&#38408;&#20540;&#19979;&#39034;&#24207;&#22320;&#23547;&#25214;&#26410;&#30693;&#20989;&#25968;&#30340;&#26368;&#22823;&#20540;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#26680;&#30340;&#21644;&#39640;&#26031;&#36807;&#31243;&#26041;&#27861;&#24314;&#27169;&#20989;&#25968;&#65292;&#20294;&#20551;&#35774;&#35813;&#20989;&#25968;&#30456;&#23545;&#20110;&#8220;&#23433;&#20840;&#21464;&#37327;&#8221;&#26159;&#21333;&#35843;&#36882;&#22686;&#30340;&#65292;&#36825;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#12290;&#27492;&#20551;&#35774;&#21463;&#21040;&#20102;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#20363;&#22914;&#33258;&#36866;&#24212;&#20020;&#24202;&#35797;&#39564;&#35774;&#35745;&#21644;&#26426;&#22120;&#20154;&#23398;&#12290;&#25105;&#20204;&#20174;GP-UCB&#21644;SafeOpt&#31639;&#27861;&#20013;&#27762;&#21462;&#28789;&#24863;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21333;&#35843;&#23433;&#20840;UCB(M-SafeUCB)&#30340;&#31639;&#27861;&#26469;&#23436;&#25104;&#36825;&#20010;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;M-SafeUCB&#22312;&#23433;&#20840;&#24615;&#12289;&#36866;&#24403;&#23450;&#20041;&#30340;&#21518;&#24724;&#27010;&#24565;&#21644;&#36817;&#20284;&#25214;&#21040;&#25972;&#20010;&#23433;&#20840;&#36793;&#30028;&#26041;&#38754;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35828;&#26126;&#65292;&#21333;&#35843;&#24615;&#20551;&#35774;&#22312;&#20445;&#35777;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#20063;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequentially maximising an unknown function over a set of actions while ensuring that every sampled point has a function value below a given safety threshold. We model the function using kernel-based and Gaussian process methods, while differing from previous works in our assumption that the function is monotonically increasing with respect to a \emph{safety variable}. This assumption is motivated by various practical applications such as adaptive clinical trial design and robotics. Taking inspiration from the \textsc{\sffamily GP-UCB} and \textsc{\sffamily SafeOpt} algorithms, we propose an algorithm, monotone safe {\sffamily UCB} (\textsc{\sffamily M-SafeUCB}) for this task. We show that \textsc{\sffamily M-SafeUCB} enjoys theoretical guarantees in terms of safety, a suitably-defined regret notion, and approximately finding the entire safe boundary. In addition, we illustrate that the monotonicity assumption yields significant benefits in terms of the guara
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;LIBO&#65292;&#21487;&#20197;&#26080;&#38656;&#30452;&#25509;&#35775;&#38382;&#25968;&#25454;&#65292;&#23545;&#19968;&#31995;&#21015;&#36172;&#21338;&#20248;&#21270;&#20219;&#21153;&#36827;&#34892;&#23398;&#20064;&#21644;&#36866;&#24212;&#65292;&#24182;&#20445;&#35777;&#26368;&#20248;&#24615;&#33021;&#21644;&#20122;&#32447;&#24615;&#32456;&#36523;&#21518;&#24724;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.15513</link><description>&lt;p&gt;
&#32456;&#36523;&#36172;&#21338;&#20248;&#21270;&#65306;&#26080;&#20808;&#39564;&#30693;&#35782;&#21644;&#26080;&#21518;&#24724;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Lifelong Bandit Optimization: No Prior and No Regret. (arXiv:2210.15513v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;LIBO&#65292;&#21487;&#20197;&#26080;&#38656;&#30452;&#25509;&#35775;&#38382;&#25968;&#25454;&#65292;&#23545;&#19968;&#31995;&#21015;&#36172;&#21338;&#20248;&#21270;&#20219;&#21153;&#36827;&#34892;&#23398;&#20064;&#21644;&#36866;&#24212;&#65292;&#24182;&#20445;&#35777;&#26368;&#20248;&#24615;&#33021;&#21644;&#20122;&#32447;&#24615;&#32456;&#36523;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#32463;&#24120;&#37325;&#22797;&#24212;&#29992;&#20110;&#30456;&#20284;&#32467;&#26500;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#20851;&#27880;&#35299;&#20915;&#19968;&#31995;&#21015;&#36172;&#21338;&#20248;&#21270;&#20219;&#21153;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#36866;&#24212;&#29615;&#22659;&#30340;&#31639;&#27861;LIBO&#12290;&#25105;&#20204;&#20551;&#35774;&#20869;&#26680;&#21270;&#32467;&#26500;&#65292;&#20854;&#20013;&#30340;&#20869;&#26680;&#22312;&#25152;&#26377;&#20219;&#21153;&#20013;&#37117;&#26159;&#26410;&#30693;&#30340;&#20294;&#20849;&#20139;&#30340;&#12290;LIBO&#20381;&#27425;&#20803;&#23398;&#20064;&#19968;&#20010;&#36924;&#36817;&#30495;&#23454;&#20869;&#26680;&#30340;&#20869;&#26680;&#65292;&#28982;&#21518;&#29992;&#26368;&#26032;&#30340;&#20869;&#26680;&#20272;&#35745;&#26469;&#35299;&#20915;&#21363;&#23558;&#21040;&#26469;&#30340;&#20219;&#21153;&#12290;&#26412;&#31639;&#27861;&#21487;&#20197;&#19982;&#20219;&#20309;&#20869;&#26680;&#21270;&#25110;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#37197;&#23545;&#65292;&#24182;&#20445;&#35777;&#26368;&#20248;&#30340;&#39044;&#26399;&#24615;&#33021;&#12290;&#22914;&#26524;&#19982;&#20122;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#37197;&#23545;&#65292;LIBO&#23558;&#20135;&#29983;&#19968;&#20010;&#20122;&#32447;&#24615;&#32456;&#36523;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning algorithms are often repeatedly applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#35299;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#22797;&#26434;&#38750;&#24179;&#31283;&#21644;&#38750;&#32447;&#24615;&#21160;&#24577;&#34920;&#31034;&#20026;&#31616;&#21333;&#12289;&#21487;&#35299;&#37322;&#30340;&#31232;&#30095;&#32452;&#21512;&#65292;&#24182;&#36890;&#36807;&#23383;&#20856;&#23398;&#20064;&#36807;&#31243;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2206.02972</link><description>&lt;p&gt;
&#20998;&#35299;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;dLDS&#65289;&#29992;&#20110;&#23398;&#20064;&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#28508;&#22312;&#25104;&#20998;
&lt;/p&gt;
&lt;p&gt;
Decomposed Linear Dynamical Systems (dLDS) for learning the latent components of neural dynamics. (arXiv:2206.02972v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02972
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#35299;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#22797;&#26434;&#38750;&#24179;&#31283;&#21644;&#38750;&#32447;&#24615;&#21160;&#24577;&#34920;&#31034;&#20026;&#31616;&#21333;&#12289;&#21487;&#35299;&#37322;&#30340;&#31232;&#30095;&#32452;&#21512;&#65292;&#24182;&#36890;&#36807;&#23383;&#20856;&#23398;&#20064;&#36807;&#31243;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32676;&#20307;&#27700;&#24179;&#19978;&#23398;&#20064;&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#21487;&#35299;&#37322;&#34920;&#31034;&#26159;&#29702;&#35299;&#35266;&#23519;&#21040;&#30340;&#31070;&#32463;&#27963;&#21160;&#22914;&#20309;&#19982;&#30693;&#35273;&#21644;&#34892;&#20026;&#30456;&#20851;&#30340;&#20851;&#38190;&#31532;&#19968;&#27493;&#12290;&#31070;&#32463;&#21160;&#21147;&#23398;&#27169;&#22411;&#36890;&#24120;&#38598;&#20013;&#20110;&#31070;&#32463;&#27963;&#21160;&#30340;&#20302;&#32500;&#25237;&#24433;&#65292;&#25110;&#32773;&#23398;&#20064;&#19982;&#31070;&#32463;&#29366;&#24577;&#38543;&#26102;&#38388;&#26126;&#30830;&#30456;&#20851;&#30340;&#21160;&#21147;&#31995;&#32479;&#12290;&#36890;&#36807;&#23558;&#21160;&#21147;&#31995;&#32479;&#35270;&#20026;&#20302;&#32500;&#27969;&#30340;&#20195;&#34920;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;&#22312;&#27492;&#27010;&#24565;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#35299;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#65292;&#23558;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22797;&#26434;&#38750;&#24179;&#31283;&#21644;&#38750;&#32447;&#24615;&#21160;&#24577;&#34920;&#31034;&#20026;&#26356;&#31616;&#21333;&#12289;&#26356;&#21487;&#35299;&#37322;&#30340;&#25104;&#20998;&#30340;&#31232;&#30095;&#32452;&#21512;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#36890;&#36807;&#19968;&#20010;&#23383;&#20856;&#23398;&#20064;&#36807;&#31243;&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20013;&#25105;&#20204;&#21033;&#29992;&#20102;&#26368;&#36817;&#22312;&#36319;&#36394;&#31232;&#30095;&#21521;&#37327;&#38543;&#26102;&#38388;&#21464;&#21270;&#26041;&#38754;&#30340;&#32467;&#26524;&#12290;&#30456;&#36739;&#20110;&#20197;&#24448;&#30340;&#24320;&#20851;&#26041;&#27861;&#65292;&#22312;&#32473;&#23450;&#21442;&#25968;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20998;&#35299;&#21160;&#24577;&#24615;&#36136;&#26356;&#20026;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning interpretable representations of neural dynamics at a population level is a crucial first step to understanding how observed neural activity relates to perception and behavior. Models of neural dynamics often focus on either low-dimensional projections of neural activity, or on learning dynamical systems that explicitly relate to the neural state over time. We discuss how these two approaches are interrelated by considering dynamical systems as representative of flows on a low-dimensional manifold. Building on this concept, we propose a new decomposed dynamical system model that represents complex non-stationary and nonlinear dynamics of time series data as a sparse combination of simpler, more interpretable components. Our model is trained through a dictionary learning procedure, where we leverage recent results in tracking sparse vectors over time. The decomposed nature of the dynamics is more expressive than previous switched approaches for a given number of parameters and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#22312;&#38750;&#21442;&#25968;&#20108;&#20803;&#20998;&#31867;&#20013;&#65292;&#32570;&#20047;&#23569;&#25968;&#27966;&#26679;&#26412;&#26159;&#23398;&#20064;&#30340;&#26681;&#26412;&#38480;&#21046;&#65292;&#24182;&#25506;&#35752;&#20102;&#27424;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#23567;&#21270;&#26497;&#24046;&#39118;&#38505;&#30340;&#40065;&#26834;&#24615;&#34920;&#29616;&#65292;&#29305;&#21035;&#26159;&#22312;&#26631;&#31614;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#26368;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2205.13094</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20998;&#31867;&#20013;&#30340;&#27424;&#37319;&#26679;&#26159;&#19968;&#31181;&#26497;&#23567;&#21270;&#26497;&#24046;&#39118;&#38505;&#30340;&#40065;&#26834;&#24615;&#24178;&#39044;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification. (arXiv:2205.13094v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13094
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#22312;&#38750;&#21442;&#25968;&#20108;&#20803;&#20998;&#31867;&#20013;&#65292;&#32570;&#20047;&#23569;&#25968;&#27966;&#26679;&#26412;&#26159;&#23398;&#20064;&#30340;&#26681;&#26412;&#38480;&#21046;&#65292;&#24182;&#25506;&#35752;&#20102;&#27424;&#37319;&#26679;&#31639;&#27861;&#30340;&#26368;&#23567;&#21270;&#26497;&#24046;&#39118;&#38505;&#30340;&#40065;&#26834;&#24615;&#34920;&#29616;&#65292;&#29305;&#21035;&#26159;&#22312;&#26631;&#31614;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#26368;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#24191;&#27867;&#30340;&#25216;&#26415;&#26469;&#35299;&#20915;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#20294;&#22312;&#20960;&#20010;&#27969;&#34892;&#30340;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#22522;&#20110;&#27424;&#37319;&#26679;&#30340;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#35757;&#32451;&#36890;&#24120;&#33021;&#22815;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#21442;&#25968;&#20108;&#20803;&#20998;&#31867;&#35774;&#32622;&#19979;&#65292;&#23398;&#20064;&#30340;&#22522;&#26412;&#38480;&#21046;&#26159;&#30001;&#20110;&#32570;&#20047;&#23569;&#25968;&#32676;&#20307;&#26679;&#26412;&#32780;&#20135;&#29983;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#38500;&#38750;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#23384;&#22312;&#39640;&#24230;&#37325;&#21472;&#65288;&#36825;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#19981;&#22826;&#21487;&#33021;&#65289;&#65292;&#21542;&#21017;&#31639;&#27861;&#26080;&#27861;&#36229;&#36234;&#27424;&#37319;&#26679;&#65292;&#38500;&#38750;&#31639;&#27861;&#21033;&#29992;&#26377;&#20851;&#20998;&#24067;&#20559;&#31227;&#30340;&#20854;&#20182;&#32467;&#26500;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#26631;&#31614;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24635;&#26159;&#23384;&#22312;&#19968;&#31181;&#26368;&#23567;&#21270;&#26497;&#24046;&#39118;&#38505;&#30340;&#27424;&#37319;&#26679;&#31639;&#27861;&#12290;&#22312;&#32452;&#36716;&#25442;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#26368;&#23567;&#26497;&#24046;&#39118;&#38505;&#30340;&#27424;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#23454;&#39564;&#20197;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an $\textit{undersampled}$ balanced dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of nonparametric binary classification. Our results show that in the worst case, an algorithm cannot outperform undersampling unless there is a high degree of overlap between the train and test distributions (which is unlikely to be the case in real-world datasets), or if the algorithm leverages additional structure about the distribution shift. In particular, in the case of label shift we show that there is always an undersampling algorithm that is minimax optimal. In the case of grou
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#23567;&#27874;&#25955;&#23556;&#35889;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;&#24179;&#31283;&#22686;&#37327;&#30340;&#26102;&#38388;&#24207;&#21015;&#30340;&#38750;&#39640;&#26031;&#29305;&#24615;&#65292;&#20854;&#31995;&#25968;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#26368;&#22823;&#29109;&#27169;&#22411;&#21644;&#29983;&#25104;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#33258;&#30456;&#20284;&#36807;&#31243;&#20855;&#26377;&#25955;&#23556;&#35889;&#30340;&#23610;&#24230;&#19981;&#21464;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.10177</link><description>&lt;p&gt;
&#22522;&#20110;&#23567;&#27874;&#25955;&#23556;&#35889;&#30340;&#23610;&#24230;&#20381;&#36182;&#24615;&#21644;&#33258;&#30456;&#20284;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Scale Dependencies and Self-Similar Models with Wavelet Scattering Spectra. (arXiv:2204.10177v2 [physics.data-an] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#23567;&#27874;&#25955;&#23556;&#35889;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24314;&#27169;&#20855;&#26377;&#24179;&#31283;&#22686;&#37327;&#30340;&#26102;&#38388;&#24207;&#21015;&#30340;&#38750;&#39640;&#26031;&#29305;&#24615;&#65292;&#20854;&#31995;&#25968;&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;&#26368;&#22823;&#29109;&#27169;&#22411;&#21644;&#29983;&#25104;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#33258;&#30456;&#20284;&#36807;&#31243;&#20855;&#26377;&#25955;&#23556;&#35889;&#30340;&#23610;&#24230;&#19981;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#23567;&#27874;&#25955;&#23556;&#35889;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#20855;&#26377;&#24179;&#31283;&#22686;&#37327;&#30340;&#26102;&#38388;&#24207;&#21015;&#30340;&#38750;&#39640;&#26031;&#27169;&#22411;&#12290;&#22797;&#23567;&#27874;&#21464;&#25442;&#35745;&#31639;&#27599;&#20010;&#23610;&#24230;&#19978;&#30340;&#20449;&#21495;&#21464;&#21270;&#12290;&#36328;&#23610;&#24230;&#30340;&#20381;&#36182;&#20851;&#31995;&#30001;&#23567;&#27874;&#31995;&#25968;&#21450;&#20854;&#27169;&#25968;&#22312;&#26102;&#38388;&#21644;&#23610;&#24230;&#19978;&#30340;&#32852;&#21512;&#30456;&#20851;&#24615;&#25152;&#25429;&#33719;&#12290;&#35813;&#30456;&#20851;&#30697;&#38453;&#30001;&#31532;&#20108;&#20010;&#23567;&#27874;&#21464;&#25442;&#36817;&#20284;&#23545;&#35282;&#21270;&#65292;&#23450;&#20041;&#20102;&#25955;&#23556;&#35889;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#30456;&#20284;&#36807;&#31243;&#20855;&#26377;&#25955;&#23556;&#35889;&#30340;&#23610;&#24230;&#19981;&#21464;&#24615;&#12290;&#35813;&#29305;&#24615;&#21487;&#20197;&#22312;&#21333;&#20010;&#23454;&#29616;&#19978;&#36827;&#34892;&#32479;&#35745;&#27979;&#35797;&#65292;&#24182;&#23450;&#20041;&#20102;&#19968;&#31867;&#23485;&#20041;&#33258;&#30456;&#20284;&#36807;&#31243;&#12290;&#25105;&#20204;&#36890;&#36807;&#25955;&#23556;&#35889;&#31995;&#25968;&#26500;&#24314;&#26368;&#22823;&#29109;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#24494;&#27491;&#21017;&#37319;&#26679;&#31639;&#27861;&#29983;&#25104;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#23637;&#31034;&#20102;&#39640;&#24230;&#38750;&#39640;&#26031;&#30340;&#37329;&#34701;&#21644;&#28237;&#27969;&#26102;&#38388;&#24207;&#21015;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the wavelet scattering spectra which provide non-Gaussian models of time-series having stationary increments. A complex wavelet transform computes signal variations at each scale. Dependencies across scales are captured by the joint correlation across time and scales of wavelet coefficients and their modulus. This correlation matrix is nearly diagonalized by a second wavelet transform, which defines the scattering spectra. We show that this vector of moments characterizes a wide range of non-Gaussian properties of multi-scale processes. We prove that self-similar processes have scattering spectra which are scale invariant. This property can be tested statistically on a single realization and defines a class of wide-sense self-similar processes. We build maximum entropy models conditioned by scattering spectra coefficients, and generate new time-series with a microcanonical sampling algorithm. Applications are shown for highly non-Gaussian financial and turbulence time-seri
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#22788;&#29702;&#22797;&#26434;&#30340;&#24739;&#32773;&#25968;&#25454;&#65292;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#65292;&#20351;&#29992;&#22240;&#26524;&#26641;&#26041;&#27861;&#65288;&#20855;&#20307;&#26469;&#35828;&#26159;&#22240;&#26524;&#26641;&#21644;&#22240;&#26524;&#26862;&#26519;&#65289;&#65292;&#23398;&#20064;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#25511;&#21046;&#26102;&#38388;&#21464;&#21270;&#28151;&#28102;&#65292;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#21644;&#21487;&#35299;&#37322;&#30340;&#12290;&#22312;&#27835;&#30103;&#25233;&#37057;&#30151;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#23454;&#38469;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2204.07124</link><description>&lt;p&gt;
&#22312;&#21307;&#23398;&#20013;&#20351;&#29992;&#22240;&#26524;&#26641;&#26041;&#27861;&#23398;&#20064;&#26368;&#20339;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.07124
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#22788;&#29702;&#22797;&#26434;&#30340;&#24739;&#32773;&#25968;&#25454;&#65292;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#65292;&#20351;&#29992;&#22240;&#26524;&#26641;&#26041;&#27861;&#65288;&#20855;&#20307;&#26469;&#35828;&#26159;&#22240;&#26524;&#26641;&#21644;&#22240;&#26524;&#26862;&#26519;&#65289;&#65292;&#23398;&#20064;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#25511;&#21046;&#26102;&#38388;&#21464;&#21270;&#28151;&#28102;&#65292;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#21644;&#21487;&#35299;&#37322;&#30340;&#12290;&#22312;&#27835;&#30103;&#25233;&#37057;&#30151;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#23454;&#38469;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#65288;DTR&#65289;&#22312;&#21307;&#23398;&#20013;&#29992;&#20110;&#26681;&#25454;&#24739;&#32773;&#24322;&#36136;&#24615;&#23450;&#21046;&#36830;&#32493;&#30340;&#27835;&#30103;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#23398;&#20064;&#26368;&#20339;DTR&#30340;&#26041;&#27861;&#23384;&#22312;&#32570;&#38519;&#65306;&#23427;&#20204;&#36890;&#24120;&#22522;&#20110;&#32467;&#26524;&#39044;&#27979;&#32780;&#38750;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#65292;&#25110;&#32773;&#20351;&#29992;&#32447;&#24615;&#27169;&#22411;&#65292;&#23545;&#20110;&#29616;&#20195;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#30340;&#24739;&#32773;&#25968;&#25454;&#20855;&#26377;&#38480;&#21046;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#38519;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#22788;&#29702;&#22797;&#26434;&#30340;&#24739;&#32773;&#25968;&#25454;&#65292;&#31216;&#20026;DTR-CT&#21644;DTR-CF&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#65292;&#20351;&#29992;&#22240;&#26524;&#26641;&#26041;&#27861;&#65288;&#20855;&#20307;&#26469;&#35828;&#26159;&#22240;&#26524;&#26641;&#21644;&#22240;&#26524;&#26862;&#26519;&#65289;&#65292;&#23398;&#20064;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#25511;&#21046;&#26102;&#38388;&#21464;&#21270;&#28151;&#28102;&#65292;&#26159;&#21452;&#37325;&#31283;&#20581;&#30340;&#21644;&#21487;&#35299;&#37322;&#30340;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#35770;&#25991;&#26159;&#31532;&#19968;&#31687;&#20026;&#20102;&#23398;&#20064;&#26368;&#20339;DTR&#32780;&#25913;&#32534;&#22240;&#26524;&#26641;&#26041;&#27861;&#30340;&#35770;&#25991;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#22312;&#25233;&#37057;&#30151;&#27835;&#30103;&#32972;&#26223;&#19979;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#24212;&#29992;&#31243;&#24207;&#26469;&#35780;&#20272;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#21644;&#23454;&#38469;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic treatment regimes (DTRs) are used in medicine to tailor sequential treatment decisions to patients by considering patient heterogeneity. Common methods for learning optimal DTRs, however, have shortcomings: they are typically based on outcome prediction and not treatment effect estimation, or they use linear models that are restrictive for patient data from modern electronic health records. To address these shortcomings, we develop two novel methods for learning optimal DTRs that effectively handle complex patient data. We call our methods DTR-CT and DTR-CF. Our methods are based on a data-driven estimation of heterogeneous treatment effects using causal tree methods, specifically causal trees and causal forests, that learn non-linear relationships, control for time-varying confounding, are doubly robust, and explainable. To the best of our knowledge, our paper is the first that adapts causal tree methods for learning optimal DTRs. We evaluate our proposed methods using synthet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986; PredSet-1Step &#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#26410;&#30693;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#39640;&#25928;&#26500;&#24314;&#20855;&#22791;&#28176;&#36817;&#35206;&#30422;&#20445;&#38556;&#30340;&#39044;&#27979;&#38598;&#65292;&#20855;&#22791;&#24456;&#22909;&#30340;&#26657;&#20934;&#35206;&#30422;&#35823;&#24046;&#21644;&#39640;&#32622;&#20449;&#24230;&#12290;</title><link>http://arxiv.org/abs/2203.06126</link><description>&lt;p&gt;
&#38024;&#23545;&#26410;&#30693;&#21327;&#21464;&#37327;&#28418;&#31227;&#30340;&#33258;&#36866;&#24212;&#39044;&#27979;&#38598;&#26500;&#24314;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction Sets Adaptive to Unknown Covariate Shift. (arXiv:2203.06126v6 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.06126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986; PredSet-1Step &#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#26410;&#30693;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#39640;&#25928;&#26500;&#24314;&#20855;&#22791;&#28176;&#36817;&#35206;&#30422;&#20445;&#38556;&#30340;&#39044;&#27979;&#38598;&#65292;&#20855;&#22791;&#24456;&#22909;&#30340;&#26657;&#20934;&#35206;&#30422;&#35823;&#24046;&#21644;&#39640;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#65292;&#39044;&#27979;&#32467;&#26524;&#30340;&#38598;&#21512;&#32780;&#38750;&#21333;&#20010;&#32467;&#26524;&#26159;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;&#26500;&#24314;&#20855;&#26377;&#32479;&#35745;&#20445;&#38556;&#30340;&#39044;&#27979;&#38598;&#30340;&#25991;&#29486;&#24456;&#20016;&#23500;&#65292;&#20294;&#36866;&#24212;&#26410;&#30693;&#21327;&#21464;&#37327;&#28418;&#31227;&#36825;&#19968;&#22312;&#23454;&#36341;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#20173;&#28982;&#26159;&#19968;&#22823;&#38590;&#28857;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#20855;&#22791;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#20445;&#38556;&#30340;&#39044;&#27979;&#38598;&#26159;&#26080;&#20449;&#24687;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28789;&#27963;&#26080;&#20998;&#24067;&#26041;&#27861; PredSet-1Step &#29992;&#20110;&#24555;&#36895;&#26500;&#24314;&#22312;&#26410;&#30693;&#21327;&#21464;&#37327;&#28418;&#31227;&#19979;&#20855;&#22791;&#28176;&#36817;&#35206;&#30422;&#20445;&#38556;&#30340;&#39044;&#27979;&#38598;&#12290;&#25105;&#20204;&#27491;&#24335;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#26159;&#28176;&#36817;&#20960;&#20046;&#27491;&#30830;&#30340;&#65292;&#23545;&#20110;&#22823;&#26679;&#26412;&#20855;&#26377;&#39640;&#32622;&#20449;&#24230;&#30340;&#26657;&#20934;&#35206;&#30422;&#35823;&#24046;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807; HIV &#39118;&#38505;&#39044;&#27979;&#30340;&#23454;&#39564;&#21644;&#21335;&#38750;&#38431;&#21015;&#30740;&#31350;&#25968;&#25454;&#38598;&#28436;&#31034;&#20102;&#23427;&#36798;&#21040;&#21517;&#20041;&#35206;&#30422;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting sets of outcomes -- instead of unique outcomes -- is a promising solution to uncertainty quantification in statistical learning. Despite a rich literature on constructing prediction sets with statistical guarantees, adapting to unknown covariate shift -- a prevalent issue in practice -- poses a serious unsolved challenge. In this paper, we show that prediction sets with finite-sample coverage guarantee are uninformative and propose a novel flexible distribution-free method, PredSet-1Step, to efficiently construct prediction sets with an asymptotic coverage guarantee under unknown covariate shift. We formally show that our method is \textit{asymptotically probably approximately correct}, having well-calibrated coverage error with high confidence for large samples. We illustrate that it achieves nominal coverage in a number of experiments and a data set concerning HIV risk prediction in a South African cohort study. Our theory hinges on a new bound for the convergence rate of 
&lt;/p&gt;</description></item><item><title>&#21452;&#37325;PC&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#20043;&#38388;&#30340;&#21453;&#21521;&#20851;&#31995;&#65292;&#23454;&#29616;&#20102;CI&#27979;&#35797;&#65292;&#33021;&#22815;&#24674;&#22797;&#27491;&#30830;&#30340;&#31561;&#20215;&#31867;&#65292;&#24182;&#21487;&#23545;&#20114;&#34917;&#35843;&#33410;&#38598;&#30340;&#20559;&#30456;&#20851;&#36827;&#34892;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2112.09036</link><description>&lt;p&gt;
&#21452;&#37325;PC&#31639;&#27861;&#21450;&#20854;&#23545;&#39640;&#26031;&#24615;&#36136;&#22312;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Dual PC Algorithm and the Role of Gaussianity for Structure Learning of Bayesian Networks. (arXiv:2112.09036v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09036
&lt;/p&gt;
&lt;p&gt;
&#21452;&#37325;PC&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#20043;&#38388;&#30340;&#21453;&#21521;&#20851;&#31995;&#65292;&#23454;&#29616;&#20102;CI&#27979;&#35797;&#65292;&#33021;&#22815;&#24674;&#22797;&#27491;&#30830;&#30340;&#31561;&#20215;&#31867;&#65292;&#24182;&#21487;&#23545;&#20114;&#34917;&#35843;&#33410;&#38598;&#30340;&#20559;&#30456;&#20851;&#36827;&#34892;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26159;&#25551;&#36848;&#35768;&#22810;&#22797;&#26434;&#24212;&#29992;&#31243;&#24207;&#20013;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#20851;&#38190;&#65292;&#20294;&#38754;&#20020;&#30528;&#24040;&#22823;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#65292;&#27969;&#34892;&#30340;PC&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36870;&#21521;&#24037;&#31243;&#21464;&#37327;&#20998;&#24067;&#20013;&#25152;&#20855;&#26377;&#30340;&#26465;&#20214;&#29420;&#31435;&#20851;&#31995;&#26469;&#19968;&#33268;&#22320;&#24674;&#22797;&#27491;&#30830;&#30340;&#31561;&#20215;&#31867;&#12290;&#21452;&#37325;PC&#31639;&#27861;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#21033;&#29992;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#20043;&#38388;&#30340;&#21453;&#21521;&#20851;&#31995;&#26469;&#36827;&#34892;PC&#31639;&#27861;&#20013;&#30340;CI&#27979;&#35797;&#12290;&#36890;&#36807;&#21033;&#29992;&#22359;&#30697;&#38453;&#27714;&#36870;&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#23545;&#20114;&#34917;&#65288;&#25110;&#21452;&#37325;&#65289;&#35843;&#33410;&#38598;&#30340;&#20559;&#30456;&#20851;&#36827;&#34892;&#27979;&#35797;&#12290;&#21452;&#37325;PC&#31639;&#27861;&#30340;&#22810;&#20010;CI&#27979;&#35797;&#39318;&#20808;&#32771;&#34385;&#36793;&#32536;&#21644;&#23436;&#20840;&#25490;&#24207;CI&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning the graphical structure of Bayesian networks is key to describing data-generating mechanisms in many complex applications but poses considerable computational challenges. Observational data can only identify the equivalence class of the directed acyclic graph underlying a Bayesian network model, and a variety of methods exist to tackle the problem. Under certain assumptions, the popular PC algorithm can consistently recover the correct equivalence class by reverse-engineering the conditional independence (CI) relationships holding in the variable distribution. The dual PC algorithm is a novel scheme to carry out the CI tests within the PC algorithm by leveraging the inverse relationship between covariance and precision matrices. By exploiting block matrix inversions we can also perform tests on partial correlations of complementary (or dual) conditioning sets. The multiple CI tests of the dual PC algorithm proceed by first considering marginal and full-order CI relationships a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#20123;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#20811;&#26381;&#22312;&#20351;&#29992;&#20256;&#32479;&#32479;&#35745;&#26041;&#27861;&#26102;&#36935;&#21040;&#30340;&#22256;&#38590;&#65292;&#20174;&#32780;&#20026;&#24314;&#27169;&#21644;&#25968;&#25454;&#25910;&#38598;&#25552;&#20379;&#30452;&#25509;&#30340;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2110.12122</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Quantifying Epistemic Uncertainty in Deep Learning. (arXiv:2110.12122v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.12122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#20123;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#20811;&#26381;&#22312;&#20351;&#29992;&#20256;&#32479;&#32479;&#35745;&#26041;&#27861;&#26102;&#36935;&#21040;&#30340;&#22256;&#38590;&#65292;&#20174;&#32780;&#20026;&#24314;&#27169;&#21644;&#25968;&#25454;&#25910;&#38598;&#25552;&#20379;&#30452;&#25509;&#30340;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#26426;&#22120;&#23398;&#20064;&#21487;&#38752;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#26680;&#24515;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#29305;&#21035;&#26159;\textit {&#35748;&#35782;&#25104;&#20998;}&#65307;&#20998;&#20026;\textit {&#31243;&#24207;&#21464;&#24322;&#24615;}(&#26469;&#33258;&#35757;&#32451;&#36807;&#31243;)&#21644;\textit {&#25968;&#25454;&#21464;&#24322;&#24615;} (&#26469;&#33258;&#35757;&#32451;&#25968;&#25454;)&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#39318;&#27425;&#23581;&#35797;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#20004;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#65292;&#19968;&#31181;&#26159;&#22522;&#20110;&#24433;&#21709;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#26159;&#25209;&#27425;&#21270;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#22312;&#24212;&#29992;&#32463;&#20856;&#32479;&#35745;&#26041;&#27861;&#26102;&#36935;&#21040;&#30340;&#35745;&#31639;&#22256;&#38590;&#12290;&#22810;&#20010;&#38382;&#39064;&#35774;&#32622;&#30340;&#23454;&#39564;&#35780;&#20272;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24182;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#21644;&#20272;&#35745;&#22914;&#20309;&#25552;&#20379;&#23545;&#24314;&#27169;&#21644;&#25968;&#25454;&#25910;&#38598;&#24037;&#20316;&#30340;&#30452;&#25509;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is at the core of the reliability and robustness of machine learning. In this paper, we provide a theoretical framework to dissect the uncertainty, especially the \textit{epistemic} component, in deep learning into \textit{procedural variability} (from the training procedure) and \textit{data variability} (from the training data), which is the first such attempt in the literature to our best knowledge. We then propose two approaches to estimate these uncertainties, one based on influence function and one on batching. We demonstrate how our approaches overcome the computational difficulties in applying classical statistical methods. Experimental evaluations on multiple problem settings corroborate our theory and illustrate how our framework and estimation can provide direct guidance on modeling and data collection efforts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;NTK&#23545;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#36827;&#34892;&#36830;&#32493;&#26102;&#38388;&#20998;&#26512;&#65292;&#21457;&#29616;&#22122;&#22768;&#21482;&#20250;&#24433;&#21709;&#38544;&#31169;&#39118;&#38505;&#32780;&#19981;&#24433;&#21709;&#25910;&#25947;&#24615;&#21644;&#26657;&#20934;&#24615;&#65292;&#32780;&#22522;&#20110;&#27599;&#20010;&#26679;&#26412;&#30340;&#26799;&#24230;&#21098;&#35009;&#20250;&#24433;&#21709;&#25910;&#25947;&#24615;&#21644;&#26657;&#20934;&#24615;&#12290;&#27492;&#22806;&#65292;&#22823;&#21098;&#35009;&#33539;&#25968;&#19979;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#19981;&#20165;&#20139;&#26377;&#30456;&#21516;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#32780;&#19988;&#26657;&#20934;&#25928;&#26524;&#22909;&#12290;</title><link>http://arxiv.org/abs/2106.07830</link><description>&lt;p&gt;
&#35770;&#28145;&#24230;&#23398;&#20064;&#22312;&#24046;&#20998;&#38544;&#31169;&#19979;&#30340;&#25910;&#25947;&#24615;&#19982;&#26657;&#20934;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Convergence and Calibration of Deep Learning with Differential Privacy. (arXiv:2106.07830v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.07830
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;NTK&#23545;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#36827;&#34892;&#36830;&#32493;&#26102;&#38388;&#20998;&#26512;&#65292;&#21457;&#29616;&#22122;&#22768;&#21482;&#20250;&#24433;&#21709;&#38544;&#31169;&#39118;&#38505;&#32780;&#19981;&#24433;&#21709;&#25910;&#25947;&#24615;&#21644;&#26657;&#20934;&#24615;&#65292;&#32780;&#22522;&#20110;&#27599;&#20010;&#26679;&#26412;&#30340;&#26799;&#24230;&#21098;&#35009;&#20250;&#24433;&#21709;&#25910;&#25947;&#24615;&#21644;&#26657;&#20934;&#24615;&#12290;&#27492;&#22806;&#65292;&#22823;&#21098;&#35009;&#33539;&#25968;&#19979;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#19981;&#20165;&#20139;&#26377;&#30456;&#21516;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#32780;&#19988;&#26657;&#20934;&#25928;&#26524;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#36890;&#24120;&#20250;&#20197;&#25968;&#25454;&#38544;&#31169;&#20445;&#25252;&#20026;&#20195;&#20215;&#65292;&#23548;&#33268;&#25910;&#25947;&#36895;&#24230;&#21464;&#24930;&#65288;&#20174;&#32780;&#31934;&#24230;&#38477;&#20302;&#65289;&#65292;&#19988;&#27604;&#38750;&#38544;&#31169;&#26041;&#27861;&#26356;&#23481;&#26131;&#20986;&#29616;&#20005;&#37325;&#30340;&#26657;&#20934;&#35823;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#20174;&#36830;&#32493;&#26102;&#38388;&#30340;&#35282;&#24230;&#20998;&#26512;&#20102;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#25910;&#25947;&#24615;&#65292;&#23545;&#20219;&#24847;&#32593;&#32476;&#32467;&#26500;&#21644;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#20102;&#24314;&#27169;&#65292;&#21457;&#29616;&#22122;&#22768;&#21482;&#20250;&#24433;&#21709;&#38544;&#31169;&#39118;&#38505;&#32780;&#19981;&#24433;&#21709;&#25910;&#25947;&#24615;&#21644;&#26657;&#20934;&#24615;&#65292;&#32780;&#22522;&#20110;&#27599;&#20010;&#26679;&#26412;&#30340;&#26799;&#24230;&#21098;&#35009;&#65288;&#22312;&#24179;&#22374;&#21644;&#23618;&#32423;&#21098;&#35009;&#39118;&#26684;&#19979;&#65289;&#20250;&#24433;&#21709;&#25910;&#25947;&#24615;&#21644;&#26657;&#20934;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#23567;&#21098;&#35009;&#33539;&#25968;&#19979;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#36890;&#24120;&#20250;&#22312;&#31934;&#24230;&#19978;&#34920;&#29616;&#26368;&#20339;&#65292;&#20294;&#20854;&#26657;&#20934;&#24615;&#36739;&#24046;&#19988;&#19981;&#21487;&#38752;&#12290;&#32780;&#22312;&#22823;&#21098;&#35009;&#33539;&#25968;&#19979;&#35757;&#32451;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#19981;&#20165;&#20139;&#26377;&#30456;&#21516;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#32780;&#19988;&#26657;&#20934;&#25928;&#26524;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private (DP) training preserves the data privacy usually at the cost of slower convergence (and thus lower accuracy), as well as more severe mis-calibration than its non-private counterpart. To analyze the convergence of DP training, we formulate a continuous time analysis through the lens of neural tangent kernel (NTK), which characterizes the per-sample gradient clipping and the noise addition in DP training, for arbitrary network architectures and loss functions. Interestingly, we show that the noise addition only affects the privacy risk but not the convergence or calibration, whereas the per-sample gradient clipping (under both flat and layerwise clipping styles) only affects the convergence and calibration.  Furthermore, we observe that while DP models trained with small clipping norm usually achieve the best accurate, but are poorly calibrated and thus unreliable. In sharp contrast, DP models trained with large clipping norm enjoy the same privacy guarantee and si
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;&#20840;&#21464;&#24046;&#26368;&#23567;&#21270;&#30340;&#23436;&#20840;&#20998;&#25955;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#35757;&#32451;&#36866;&#29992;&#20110;&#20855;&#26377;&#26412;&#22320;&#25968;&#25454;&#38598;&#30340;&#20998;&#25955;&#24335;&#21435;&#20013;&#24515;&#21270;&#29615;&#22659;&#30340;&#26412;&#22320;&#21270;&#65288;&#25110;&#20010;&#24615;&#21270;&#65289;&#27169;&#22411;&#65292;&#24182;&#33719;&#24471;&#20102;&#33391;&#22909;&#30340;&#27169;&#25311;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2105.12769</link><description>&lt;p&gt;
&#22522;&#20110;&#24191;&#20041;&#20840;&#21464;&#24046;&#26368;&#23567;&#21270;&#30340;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Clustered Federated Learning via Generalized Total Variation Minimization. (arXiv:2105.12769v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.12769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;&#20840;&#21464;&#24046;&#26368;&#23567;&#21270;&#30340;&#23436;&#20840;&#20998;&#25955;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#35757;&#32451;&#36866;&#29992;&#20110;&#20855;&#26377;&#26412;&#22320;&#25968;&#25454;&#38598;&#30340;&#20998;&#25955;&#24335;&#21435;&#20013;&#24515;&#21270;&#29615;&#22659;&#30340;&#26412;&#22320;&#21270;&#65288;&#25110;&#20010;&#24615;&#21270;&#65289;&#27169;&#22411;&#65292;&#24182;&#33719;&#24471;&#20102;&#33391;&#22909;&#30340;&#27169;&#25311;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20869;&#22312;&#32593;&#32476;&#32467;&#26500;&#30340;&#20998;&#25955;&#24335;&#26412;&#22320;&#25968;&#25454;&#38598;&#30340;&#21435;&#20013;&#24515;&#21270;&#29615;&#22659;&#19979;&#35757;&#32451;&#26412;&#22320;&#65288;&#25110;&#20010;&#24615;&#21270;&#65289;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;&#36825;&#31181;&#32593;&#32476;&#32467;&#26500;&#26159;&#30001;&#26412;&#22320;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#39046;&#22495;&#29305;&#23450;&#30456;&#20284;&#24615;&#27010;&#24565;&#24341;&#36215;&#30340;&#12290;&#36825;&#20123;&#27010;&#24565;&#30340;&#20363;&#23376;&#21253;&#25324;&#26102;&#31354;&#37051;&#36817;&#24615;&#65292;&#32479;&#35745;&#20381;&#36182;&#24615;&#25110;&#21151;&#33021;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#27010;&#24565;&#24615;&#36129;&#29486;&#22312;&#20110;&#23558;&#32852;&#37030;&#23398;&#20064;&#25551;&#36848;&#20026;&#24191;&#20041;&#24635;&#21464;&#24046;&#65288;GTV&#65289;&#26368;&#23567;&#21270;&#12290;&#36825;&#31181;&#34920;&#36848;&#32479;&#19968;&#24182;&#26174;&#33879;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#12290;&#23427;&#20855;&#26377;&#39640;&#24230;&#30340;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#24191;&#27867;&#30340;&#21442;&#25968;&#27169;&#22411;&#32467;&#21512;&#20351;&#29992;&#65292;&#21253;&#25324;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#31639;&#27861;&#36129;&#29486;&#26159;&#19968;&#31181;&#23436;&#20840;&#20998;&#25955;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#26159;&#36890;&#36807;&#24212;&#29992;&#24050;&#24314;&#31435;&#30340;&#21407;&#22987;-&#23545;&#20598;&#26041;&#27861;&#26469;&#35299;&#20915;GTV&#26368;&#23567;&#21270;&#38382;&#39064;&#32780;&#33719;&#24471;&#30340;&#12290;&#23427;&#21487;&#20197;&#23454;&#29616;&#20026;&#28040;&#24687;&#20256;&#36882;&#65292;&#24182;&#19988;&#23545;&#20110;&#30001;&#36890;&#20449;&#24310;&#36831;&#25110;&#24178;&#25200;&#20135;&#29983;&#30340;&#19981;&#31934;&#30830;&#35745;&#31639;&#24456;&#31283;&#20581;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#25311;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study optimization methods to train local (or personalized) models for decentralized collections of local datasets with an intrinsic network structure. This network structure arises from domain-specific notions of similarity between local datasets. Examples for such notions include spatio-temporal proximity, statistical dependencies or functional relations. Our main conceptual contribution is to formulate federated learning as generalized total variation (GTV) minimization. This formulation unifies and considerably extends existing federated learning methods. It is highly flexible and can be combined with a broad range of parametric models, including generalized linear models or deep neural networks. Our main algorithmic contribution is a fully decentralized federated learning algorithm. This algorithm is obtained by applying an established primal-dual method to solve GTV minimization. It can be implemented as message passing and is robust against inexact computations that arise fro
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;Langevin&#25193;&#25955;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#29699;&#38754;&#30340;&#20056;&#31215;&#27969;&#24418;&#19978;&#36827;&#34892;&#38750;&#20984;&#20248;&#21270;&#21644;&#37319;&#26679;&#65292;&#23637;&#31034;&#20102;&#22312;&#36866;&#24403;&#30340;&#28201;&#24230;&#36873;&#25321;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#20445;&#35777;&#27425;&#20248;&#35299;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38388;&#38553;&#27010;&#29575;&#38750;&#24120;&#23567;&#65292;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#27714;&#35299;&#21322;&#23450;&#21521;&#35268;&#21010;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20840;&#23616;&#26368;&#20248;&#24615;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2010.11176</link><description>&lt;p&gt;
&#29992;&#40654;&#26364;Langevin&#31639;&#27861;&#27714;&#35299;&#21322;&#23450;&#21521;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Riemannian Langevin Algorithm for Solving Semidefinite Programs. (arXiv:2010.11176v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.11176
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;Langevin&#25193;&#25955;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#29699;&#38754;&#30340;&#20056;&#31215;&#27969;&#24418;&#19978;&#36827;&#34892;&#38750;&#20984;&#20248;&#21270;&#21644;&#37319;&#26679;&#65292;&#23637;&#31034;&#20102;&#22312;&#36866;&#24403;&#30340;&#28201;&#24230;&#36873;&#25321;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#20445;&#35777;&#27425;&#20248;&#35299;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38388;&#38553;&#27010;&#29575;&#38750;&#24120;&#23567;&#65292;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#25552;&#20986;&#20102;&#27714;&#35299;&#21322;&#23450;&#21521;&#35268;&#21010;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20840;&#23616;&#26368;&#20248;&#24615;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110; Langevin &#25193;&#25955;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#29699;&#38754;&#30340;&#20056;&#31215;&#27969;&#24418;&#19978;&#36827;&#34892;&#38750;&#20984;&#20248;&#21270;&#21644;&#37319;&#26679;&#12290;&#22312;&#23545;&#25968; Sobolev &#19981;&#31561;&#24335;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#38480;&#36845;&#20195;&#25910;&#25947;&#21040; Gibbs &#20998;&#24067;&#30340;&#20445;&#35777;&#65292;&#36825;&#20010;&#20445;&#35777;&#26159;&#22522;&#20110; Kullback-Leibler &#25955;&#24230;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#21512;&#36866;&#30340;&#28201;&#24230;&#36873;&#25321;&#65292;&#21487;&#20197;&#20445;&#35777;&#27425;&#20248;&#35299;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38388;&#38553;&#27010;&#29575;&#26497;&#39640;&#22320;&#38750;&#24120;&#23567;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#32771;&#34385; Burer-Monteiro &#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#24102;&#23545;&#35282;&#32422;&#26463;&#30340;&#21322;&#23450;&#21521;&#35268;&#21010;(SDP)&#65292;&#24182;&#20998;&#26512;&#20102;&#29992;&#20110;&#20248;&#21270;&#38750;&#20984;&#30446;&#26631;&#30340; Langevin &#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#27809;&#26377;&#34394;&#20551;&#23616;&#37096;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;Burer-Monteiro &#38382;&#39064;&#30340;&#23545;&#25968; Sobolev &#19981;&#31561;&#24335;&#26159;&#25104;&#31435;&#30340;&#65292;&#20294;&#36825;&#37324;&#23384;&#22312;&#38797;&#28857;&#12290;&#32467;&#21512;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102; SDP &#21644; Max-Cut &#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102; Langevin &#31639;&#27861;&#23454;&#29616;&#20102;&#36825;&#20010;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a Langevin diffusion-based algorithm for non-convex optimization and sampling on a product manifold of spheres. Under a logarithmic Sobolev inequality, we establish a guarantee for finite iteration convergence to the Gibbs distribution in terms of Kullback--Leibler divergence. We show that with an appropriate temperature choice, the suboptimality gap to the global minimum is guaranteed to be arbitrarily small with high probability.  As an application, we consider the Burer--Monteiro approach for solving a semidefinite program (SDP) with diagonal constraints, and analyze the proposed Langevin algorithm for optimizing the non-convex objective. In particular, we establish a logarithmic Sobolev inequality for the Burer--Monteiro problem when there are no spurious local minima, but under the presence saddle points. Combining the results, we then provide a global optimality guarantee for the SDP and the Max-Cut problem. More precisely, we show that the Langevin algorithm achieves 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#29366;&#24577;&#21644;&#21160;&#20316;&#20449;&#24687;&#30340;&#20998;&#24067;&#24335;&#38646;&#38454;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#37096;&#20998;&#35266;&#27979;&#30340;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65292;&#20943;&#23567;&#36890;&#20449;&#24320;&#38144;&#24182;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2006.10822</link><description>&lt;p&gt;
&#37096;&#20998;&#35266;&#27979;&#19979;&#30340;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Cooperative Multi-Agent Reinforcement Learning with Partial Observations. (arXiv:2006.10822v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.10822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23616;&#37096;&#29366;&#24577;&#21644;&#21160;&#20316;&#20449;&#24687;&#30340;&#20998;&#24067;&#24335;&#38646;&#38454;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#37096;&#20998;&#35266;&#27979;&#30340;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65292;&#20943;&#23567;&#36890;&#20449;&#24320;&#38144;&#24182;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#30340;&#38646;&#38454;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#65288;MARL&#65289;&#12290;&#29616;&#26377;&#30340;MARL&#31639;&#27861;&#36890;&#24120;&#20551;&#35774;&#27599;&#20010;&#26234;&#33021;&#20307;&#37117;&#21487;&#20197;&#35266;&#23519;&#32593;&#32476;&#20013;&#25152;&#26377;&#20854;&#20182;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#12290;&#20294;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#65292;&#19982;&#22810;&#36339;&#37051;&#23621;&#20849;&#20139;&#29366;&#24577;&#21644;&#21160;&#20316;&#20449;&#24687;&#21487;&#33021;&#20250;&#23548;&#33268;&#26174;&#30528;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;&#25552;&#20986;&#30340;&#38646;&#38454;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#30340;&#20248;&#21183;&#22312;&#20110;&#65292;&#23427;&#20801;&#35768;&#26234;&#33021;&#20307;&#20165;&#22522;&#20110;&#23616;&#37096;&#30340;&#12289;&#37096;&#20998;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#20449;&#24687;&#26469;&#35745;&#31639;&#26412;&#22320;&#31574;&#30053;&#26799;&#24230;&#65292;&#20174;&#32780;&#26356;&#26032;&#23427;&#20204;&#30340;&#26412;&#22320;&#31574;&#30053;&#20989;&#25968;&#65292;&#24182;&#20351;&#29992;&#20849;&#35782;&#26469;&#33719;&#24471;&#20381;&#36182;&#20110;&#20840;&#23616;&#32047;&#31215;&#22870;&#21169;&#30340;&#23616;&#37096;&#20272;&#35745;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20026;&#20102;&#35745;&#31639;&#26412;&#22320;&#31574;&#30053;&#26799;&#24230;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#24335;&#38646;&#38454;&#31574;&#30053;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#23427;&#20381;&#36182;&#20110;&#19968;&#28857;&#27531;&#24046;&#21453;&#39304;&#65292; im&#21516;&#26102;&#19982;&#29616;&#26377;&#30340;&#20381;&#36182;&#20110;&#19968;&#28857;&#21453;&#39304;&#30340;&#38646;&#38454;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#36890;&#20449;&#24320;&#38144;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21327;&#20316;&#22810;&#26234;&#33021;&#20307;&#22522;&#20934;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#32988;&#36807;&#20102;&#29616;&#26377;&#30340;&#20551;&#35774;&#20855;&#26377;&#20840;&#35266;&#23519;&#20449;&#24687;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a distributed zeroth-order policy optimization method for Multi-Agent Reinforcement Learning (MARL). Existing MARL algorithms often assume that every agent can observe the states and actions of all the other agents in the network. This can be impractical in large-scale problems, where sharing the state and action information with multi-hop neighbors may incur significant communication overhead. The advantage of the proposed zeroth-order policy optimization method is that it allows the agents to compute the local policy gradients needed to update their local policy functions using local estimates of the global accumulated rewards that depend on partial state and action information only and can be obtained using consensus. Specifically, to calculate the local policy gradients, we develop a new distributed zeroth-order policy gradient estimator that relies on one-point residual-feedback which, compared to existing zeroth-order estimators that also rely on one-poi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#38543;&#26426;&#28216;&#36208;&#21160;&#24577;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#20135;&#29983;&#31934;&#30830;&#30340;&#26497;&#23567;&#21270;&#39044;&#27979;&#23494;&#24230;&#12290;&#36825;&#20010;&#32467;&#26524;&#20026;&#20854;&#20182;&#27169;&#22411;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#32447;&#65292;&#24182;&#19988;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#27668;&#20505;&#23398;&#21644;&#32463;&#27982;&#23398;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/1911.08662</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#31561;&#21464;&#22312;&#32447;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Equivariant online predictions of non-stationary time series. (arXiv:1911.08662v5 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.08662
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#38543;&#26426;&#28216;&#36208;&#21160;&#24577;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#20135;&#29983;&#31934;&#30830;&#30340;&#26497;&#23567;&#21270;&#39044;&#27979;&#23494;&#24230;&#12290;&#36825;&#20010;&#32467;&#26524;&#20026;&#20854;&#20182;&#27169;&#22411;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#32447;&#65292;&#24182;&#19988;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#27668;&#20505;&#23398;&#21644;&#32463;&#27982;&#23398;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35752;&#35770;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#22312;&#32447;&#39044;&#27979;&#30340;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#24615;&#36136;&#12290;&#20026;&#20102;&#20998;&#26512;&#20915;&#31574;&#35770;&#26694;&#26550;&#19979;&#32479;&#35745;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#29702;&#35770;&#39044;&#27979;&#24615;&#33021;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#20102;Kullback-Leibler&#39118;&#38505;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31867;&#29305;&#23450;&#30340;&#21160;&#24577;&#27169;&#22411;--&#38543;&#26426;&#28216;&#36208;&#21160;&#24577;&#32447;&#24615;&#27169;&#22411;--&#20135;&#29983;&#20102;&#31934;&#30830;&#30340;&#26497;&#23567;&#21270;&#39044;&#27979;&#23494;&#24230;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#39640;&#26031;&#20551;&#35774;&#19979;&#23637;&#31034;&#20102;&#36825;&#20010;&#32467;&#26524;&#65292;&#28982;&#21518;&#20351;&#29992;&#21322;&#38789;&#36807;&#31243;&#25918;&#26494;&#20102;&#36825;&#20010;&#20551;&#35774;&#12290;&#35813;&#32467;&#26524;&#20026;&#38750;&#24179;&#31283;&#21644;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#22522;&#32447;&#65292;&#21487;&#20197;&#29992;&#26469;&#19982;&#20854;&#20182;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#22810;&#20010;&#39044;&#27979;&#23494;&#24230;&#30340;&#32508;&#21512;&#12290;&#22312;&#27969;&#34892;&#30149;&#23398;&#12289;&#27668;&#20505;&#23398;&#21644;&#32463;&#27982;&#23398;&#20013;&#30340;&#19977;&#20010;&#20027;&#39064;&#24212;&#29992;&#65292;&#35777;&#23454;&#24182;&#20984;&#26174;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We discuss the finite sample theoretical properties of online predictions in non-stationary time series under model misspecification. To analyze the theoretical predictive properties of statistical methods under this setting, we first define the Kullback-Leibler risk, in order to place the problem within a decision theoretic framework. Under this framework, we show that a specific class of dynamic models -- random walk dynamic linear models -- produce exact minimax predictive densities. We first show this result under Gaussian assumptions, then relax this assumption using semi-martingale processes. This result provides a theoretical baseline, under both non-stationary and stationary time series data, for which other models can be compared against. We extend the result to the synthesis of multiple predictive densities. Three topical applications in epidemiology, climatology, and economics, confirm and highlight our theoretical results.
&lt;/p&gt;</description></item></channel></rss>