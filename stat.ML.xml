<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;(NCL)&#26159;&#23545;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;(NMF)&#30340;&#37325;&#26032;&#28436;&#32462;&#65292;&#36890;&#36807;&#23545;&#29305;&#24449;&#26045;&#21152;&#38750;&#36127;&#32422;&#26463;&#26469;&#33719;&#24471;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#65292;&#20445;&#30041;&#20102;NMF&#30340;&#21487;&#35299;&#37322;&#23646;&#24615;&#65292;&#20174;&#32780;&#24471;&#21040;&#27604;&#26631;&#20934;&#23545;&#27604;&#23398;&#20064;(CL)&#26356;&#31232;&#30095;&#21644;&#35299;&#32806;&#30340;&#34920;&#31034;</title><link>https://arxiv.org/abs/2403.12459</link><description>&lt;p&gt;
&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Non-negative Contrastive Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12459
&lt;/p&gt;
&lt;p&gt;
&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;(NCL)&#26159;&#23545;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;(NMF)&#30340;&#37325;&#26032;&#28436;&#32462;&#65292;&#36890;&#36807;&#23545;&#29305;&#24449;&#26045;&#21152;&#38750;&#36127;&#32422;&#26463;&#26469;&#33719;&#24471;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#65292;&#20445;&#30041;&#20102;NMF&#30340;&#21487;&#35299;&#37322;&#23646;&#24615;&#65292;&#20174;&#32780;&#24471;&#21040;&#27604;&#26631;&#20934;&#23545;&#27604;&#23398;&#20064;(CL)&#26356;&#31232;&#30095;&#21644;&#35299;&#32806;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#34920;&#31034;&#22312;&#20197;&#40657;&#30418;&#26041;&#24335;&#36716;&#31227;&#21040;&#19979;&#28216;&#20219;&#21153;&#26102;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22266;&#26377;&#30340;&#19981;&#21487;&#35299;&#37322;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#36825;&#20123;&#29305;&#24449;&#36890;&#24120;&#23545;&#20154;&#31867;&#29702;&#35299;&#32780;&#35328;&#26159;&#19981;&#36879;&#26126;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;&#65288;NCL&#65289;&#65292;&#36825;&#26159;&#23545;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#30340;&#22797;&#20852;&#65292;&#26088;&#22312;&#24471;&#20986;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#12290;NCL&#30340;&#21147;&#37327;&#22312;&#20110;&#24378;&#21046;&#23558;&#38750;&#36127;&#32422;&#26463;&#24212;&#29992;&#20110;&#29305;&#24449;&#65292;&#36825;&#35753;&#20154;&#24819;&#36215;NMF&#33021;&#22815;&#25552;&#21462;&#19982;&#26679;&#26412;&#38598;&#32676;&#32039;&#23494;&#23545;&#40784;&#30340;&#29305;&#24449;&#30340;&#33021;&#21147;&#12290;NCL&#19981;&#20165;&#22312;&#25968;&#23398;&#19978;&#19982;NMF&#30446;&#26631;&#24456;&#22909;&#22320;&#23545;&#40784;&#65292;&#32780;&#19988;&#20445;&#30041;&#20102;NMF&#30340;&#21487;&#35299;&#37322;&#23646;&#24615;&#65292;&#20351;&#24471;&#19982;&#26631;&#20934;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#30456;&#27604;&#65292;&#24471;&#21040;&#20102;&#26356;&#21152;&#31232;&#30095;&#21644;&#35299;&#32806;&#30340;&#34920;&#31034;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#20026;NCL&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#19979;&#28216;&#27867;&#21270;&#24615;&#33021;&#25552;&#20379;&#20102;&#20445;&#35777;&#12290;&#20174;&#32463;&#39564;&#19978;&#30475;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12459v1 Announce Type: cross  Abstract: Deep representations have shown promising performance when transferred to downstream tasks in a black-box manner. Yet, their inherent lack of interpretability remains a significant challenge, as these features are often opaque to human understanding. In this paper, we propose Non-negative Contrastive Learning (NCL), a renaissance of Non-negative Matrix Factorization (NMF) aimed at deriving interpretable features. The power of NCL lies in its enforcement of non-negativity constraints on features, reminiscent of NMF's capability to extract features that align closely with sample clusters. NCL not only aligns mathematically well with an NMF objective but also preserves NMF's interpretability attributes, resulting in a more sparse and disentangled representation compared to standard contrastive learning (CL). Theoretically, we establish guarantees on the identifiability and downstream generalization of NCL. Empirically, we show that these 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#20613;&#37324;&#21494;&#34920;&#36798;&#24335;&#23548;&#20986;&#23574;&#23792;&#21464;&#25442;&#65292;&#23454;&#29616;&#20102;&#23545;&#21508;&#31181;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#25551;&#36848;&#21644;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.15984</link><description>&lt;p&gt;
&#29992;&#32479;&#19968;&#30340;&#20613;&#37324;&#21494;&#20999;&#29255;&#26041;&#27861;&#23548;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#31181;&#28145;&#24230;-2&#31070;&#32463;&#32593;&#32476;&#30340;&#23574;&#23792;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
A unified Fourier slice method to derive ridgelet transform for a variety of depth-2 neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15984
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#20613;&#37324;&#21494;&#34920;&#36798;&#24335;&#23548;&#20986;&#23574;&#23792;&#21464;&#25442;&#65292;&#23454;&#29616;&#20102;&#23545;&#21508;&#31181;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#25551;&#36848;&#21644;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#26102;&#65292;&#30740;&#31350;&#21442;&#25968;&#20998;&#24067;&#27604;&#30740;&#31350;&#27599;&#20010;&#31070;&#32463;&#20803;&#30340;&#21442;&#25968;&#26356;&#23481;&#26131;&#12290;&#23574;&#23792;&#21464;&#25442;&#26159;&#19968;&#20010;&#20266;&#36870;&#31639;&#23376;&#65292;&#23558;&#32473;&#23450;&#20989;&#25968; $f$ &#26144;&#23556;&#21040;&#21442;&#25968;&#20998;&#24067; $\gamma$&#65292;&#20351;&#24471;&#32593;&#32476; $\mathtt{NN}[\gamma]$ &#33021;&#22815;&#37325;&#29616; $f$&#65292;&#21363; $\mathtt{NN}[\gamma]=f$&#12290;&#22312;&#27431;&#27663;&#31354;&#38388;&#19978;&#30340;&#28145;&#24230;-2&#20840;&#36830;&#25509;&#32593;&#32476;&#20013;&#65292;&#24050;&#21457;&#29616;&#20102;&#23574;&#23792;&#21464;&#25442;&#30340;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#65292;&#22240;&#27492;&#25105;&#20204;&#21487;&#20197;&#25551;&#36848;&#21442;&#25968;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#31181;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#23578;&#19981;&#30693;&#36947;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20613;&#37324;&#21494;&#34920;&#36798;&#24335;&#30340;&#31995;&#32479;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#23548;&#21508;&#31181;&#29616;&#20195;&#32593;&#32476;&#30340;&#23574;&#23792;&#21464;&#25442;&#65292;&#20363;&#22914;&#26377;&#38480;&#22495; $\mathbb{F}_p$ &#19978;&#30340;&#32593;&#32476;&#12289;&#25277;&#35937;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388; $\mathcal{H}$ &#19978;&#30340;&#32676;&#21367;&#31215;&#32593;&#32476;&#65292;&#20197;&#21450;&#38750;&#32039;&#33268;&#23545;&#31216;&#30340;&#20840;&#36830;&#25509;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15984v1 Announce Type: new  Abstract: To investigate neural network parameters, it is easier to study the distribution of parameters than to study the parameters in each neuron. The ridgelet transform is a pseudo-inverse operator that maps a given function $f$ to the parameter distribution $\gamma$ so that a network $\mathtt{NN}[\gamma]$ reproduces $f$, i.e. $\mathtt{NN}[\gamma]=f$. For depth-2 fully-connected networks on a Euclidean space, the ridgelet transform has been discovered up to the closed-form expression, thus we could describe how the parameters are distributed. However, for a variety of modern neural network architectures, the closed-form expression has not been known. In this paper, we explain a systematic method using Fourier expressions to derive ridgelet transforms for a variety of modern networks such as networks on finite fields $\mathbb{F}_p$, group convolutional networks on abstract Hilbert space $\mathcal{H}$, fully-connected networks on noncompact symm
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10043</link><description>&lt;p&gt;
&#22914;&#20309;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to validate average calibration for machine learning regression tasks ?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#21487;&#20197;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#27979;&#35797;&#12290;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#26657;&#20934;&#35823;&#24046;&#65288;CE&#65289;&#20272;&#35745;&#20026;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MSE&#65289;&#19982;&#24179;&#22343;&#26041;&#24046;&#65288;MV&#65289;&#25110;&#24179;&#22343;&#24179;&#26041;&#19981;&#30830;&#23450;&#24615;&#20043;&#38388;&#30340;&#24046;&#20540;&#12290;&#21478;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#25110;&#32553;&#25918;&#35823;&#24046;&#65288;ZMS&#65289;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#24471;&#20986;&#19981;&#21516;&#30340;&#32467;&#35770;&#65292;&#27491;&#22914;&#26469;&#33258;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25991;&#29486;&#20013;&#30340;&#25968;&#25454;&#38598;&#38598;&#21512;&#25152;&#31034;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;CE&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#38750;&#24120;&#25935;&#24863;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#31163;&#32676;&#19981;&#30830;&#23450;&#24615;&#30340;&#23384;&#22312;&#65292;&#22240;&#27492;&#26080;&#27861;&#21487;&#38752;&#22320;&#29992;&#20110;&#26657;&#20934;&#27979;&#35797;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;ZMS&#32479;&#35745;&#37327;&#19981;&#20855;&#26377;&#36825;&#31181;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;&#25991;&#31456;&#36824;&#35752;&#35770;&#20102;&#23545;&#26465;&#20214;&#26657;&#20934;&#39564;&#35777;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10043v1 Announce Type: cross  Abstract: Average calibration of the uncertainties of machine learning regression tasks can be tested in two ways. One way is to estimate the calibration error (CE) as the difference between the mean absolute error (MSE) and the mean variance (MV) or mean squared uncertainty. The alternative is to compare the mean squared z-scores or scaled errors (ZMS) to 1. Both approaches might lead to different conclusion, as illustrated on an ensemble of datasets from the recent machine learning uncertainty quantification literature. It is shown here that the CE is very sensitive to the distribution of uncertainties, and notably to the presence of outlying uncertainties, and that it cannot be used reliably for calibration testing. By contrast, the ZMS statistic does not present this sensitivity issue and offers the most reliable approach in this context. Implications for the validation of conditional calibration are discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;FESS-GDA&#65292;&#21033;&#29992;&#24179;&#28369;&#25216;&#26415;&#36827;&#34892;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#12290;&#36890;&#36807;&#35299;&#20915;&#19981;&#21516;&#31867;&#22411;&#30340;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FESS-GDA&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.00944</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#24179;&#28369;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#27861;&#30340;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization. (arXiv:2311.00944v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;FESS-GDA&#65292;&#21033;&#29992;&#24179;&#28369;&#25216;&#26415;&#36827;&#34892;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#12290;&#36890;&#36807;&#35299;&#20915;&#19981;&#21516;&#31867;&#22411;&#30340;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FESS-GDA&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#20854;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;&#22312;&#38598;&#20013;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#20013;&#65292;&#24179;&#28369;&#20132;&#26367;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#65288;Smoothed-AGDA&#65289;&#24050;&#32463;&#35777;&#26126;&#20102;&#20854;&#25104;&#21151;&#20043;&#22788;&#65292;&#20294;&#24179;&#28369;&#25216;&#26415;&#22312;&#32852;&#37030;&#35774;&#32622;&#20013;&#30340;&#20316;&#29992;&#21644;&#26159;&#21542;&#26377;&#25152;&#24110;&#21161;&#23578;&#26410;&#34987;&#25506;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#31216;&#20026;&#32852;&#37030;&#38543;&#26426;&#24179;&#28369;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#65288;FESS-GDA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#24179;&#28369;&#25216;&#26415;&#36827;&#34892;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;FESS-GDA&#21487;&#20197;&#32479;&#19968;&#35299;&#20915;&#20960;&#31867;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#24182;&#20026;&#36825;&#20123;&#35774;&#32622;&#25552;&#20379;&#20102;&#26032;&#30340;&#25110;&#26356;&#22909;&#30340;&#25910;&#25947;&#32467;&#26524;&#20998;&#26512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;FESS-GDA&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#35757;&#32451;&#21644;&#20844;&#24179;&#20998;&#31867;&#20013;&#30340;&#23454;&#38469;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, federated minimax optimization has attracted growing interest due to its extensive applications in various machine learning tasks. While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved its success in centralized nonconvex minimax optimization, how and whether smoothing technique could be helpful in federated setting remains unexplored. In this paper, we propose a new algorithm termed Federated Stochastic Smoothed Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for federated minimax optimization. We prove that FESS-GDA can be uniformly used to solve several classes of federated minimax problems and prove new or better analytical convergence results for these settings. We showcase the practical efficiency of FESS-GDA in practical federated learning tasks of training generative adversarial networks (GANs) and fair classification.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.18784</link><description>&lt;p&gt;
&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#19979;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise. (arXiv:2310.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#20010;&#30740;&#31350;&#24037;&#20316;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21450;&#20854;&#21098;&#20999;&#21464;&#20307;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#12290;&#19982;&#26222;&#36890;&#30340;SGD&#30456;&#27604;&#65292;&#21098;&#20999;SGD&#22312;&#23454;&#38469;&#20013;&#26356;&#21152;&#31283;&#23450;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#19978;&#26377;&#23545;&#25968;&#20381;&#36182;&#20110;&#22833;&#36133;&#27010;&#29575;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#20854;&#20182;&#23454;&#38469;&#38750;&#32447;&#24615;SGD&#21464;&#20307;&#65288;&#22914;&#31526;&#21495;SGD&#12289;&#37327;&#21270;SGD&#21644;&#24402;&#19968;&#21270;SGD&#65289;&#30340;&#25910;&#25947;&#24615;&#29702;&#35299;&#35201;&#23569;&#24471;&#22810;&#65292;&#36825;&#20123;&#26041;&#27861;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#36890;&#20449;&#25928;&#29575;&#25110;&#21152;&#36895;&#25910;&#25947;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#20041;&#38750;&#32447;&#24615;SGD&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#19982;&#21098;&#20999;SGD&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26356;&#20026;&#19968;&#33324;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20989;&#25968;&#65292;&#22914;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantizati
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23545;&#20110;&#20855;&#26377;&#24418;&#29366;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#32553;&#25918;&#26497;&#38480;&#21487;&#20197;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#20449;&#24687;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#32593;&#32476;&#65292;&#21457;&#29616;&#23427;&#20204;&#20063;&#21487;&#20197;&#30001;&#31867;&#20284;&#30340;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#65292;&#24182;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#19968;&#20123;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2310.12079</link><description>&lt;p&gt;
&#24418;&#29366;&#21644;&#38750;&#24418;&#29366;&#31070;&#32463;&#32593;&#32476;&#30340;&#24494;&#20998;&#26041;&#31243;&#32553;&#25918;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Differential Equation Scaling Limits of Shaped and Unshaped Neural Networks. (arXiv:2310.12079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12079
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#23545;&#20110;&#20855;&#26377;&#24418;&#29366;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#32553;&#25918;&#26497;&#38480;&#21487;&#20197;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#20449;&#24687;&#23578;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#26410;&#32463;&#24418;&#29366;&#22788;&#29702;&#30340;&#32593;&#32476;&#65292;&#21457;&#29616;&#23427;&#20204;&#20063;&#21487;&#20197;&#30001;&#31867;&#20284;&#30340;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#65292;&#24182;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#19968;&#20123;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#20855;&#26377;&#24418;&#29366;&#28608;&#27963;&#20989;&#25968;&#65288;&#21363;&#38543;&#30528;&#32593;&#32476;&#35268;&#27169;&#22686;&#22823;&#32780;&#32553;&#25918;&#30340;&#28608;&#27963;&#20989;&#25968;&#65289;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#23427;&#20204;&#20855;&#26377;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#30340;&#32553;&#25918;&#26497;&#38480;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#19981;&#39044;&#20808;&#21578;&#35785;&#25105;&#20204;&#20851;&#20110;&#8220;&#26222;&#36890;&#8221;&#38750;&#24418;&#29366;&#32593;&#32476;&#30340;&#20219;&#20309;&#20449;&#24687;&#65292;&#20854;&#20013;&#28608;&#27963;&#20989;&#25968;&#22312;&#32593;&#32476;&#35268;&#27169;&#22686;&#22823;&#26102;&#20445;&#25345;&#19981;&#21464;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#20004;&#31181;&#31867;&#22411;&#30340;&#38750;&#24418;&#29366;&#32593;&#32476;&#25214;&#21040;&#20102;&#31867;&#20284;&#30340;&#22522;&#20110;&#24494;&#20998;&#26041;&#31243;&#30340;&#28176;&#36817;&#29305;&#24449;&#25551;&#36848;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20197;&#19979;&#20004;&#31181;&#26550;&#26500;&#22312;&#21021;&#22987;&#21270;&#26102;&#20250;&#25910;&#25947;&#21040;&#30456;&#21516;&#30340;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#26497;&#38480;&#65306;&#65288;i&#65289;&#24102;&#26377;&#27531;&#24046;&#20998;&#25903;&#19978;&#30340; $d^{-1/2}$ &#22240;&#23376;&#30340;&#20840;&#36830;&#25509; ResNet&#65292;&#20854;&#20013; $d$ &#26159;&#32593;&#32476;&#30340;&#28145;&#24230;&#65307;&#65288;ii&#65289;&#24102;&#26377;&#28145;&#24230; $d \ll$ &#23485;&#24230; $n$ &#21644;&#24418;&#29366; ReLU &#28608;&#27963;&#20989;&#25968; (activation) &#30340;&#22810;&#23618;&#24863;&#30693;&#26426; (MLP)&#65292;&#20197; $d^{-1/2}$ &#30340;&#36895;&#29575;&#12290;&#20854;&#27425;&#65292;&#23545;&#20110;&#21021;&#22987;&#21270;&#30340;&#38750;&#24418;&#29366; MLP&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#23618;&#38388;&#30456;&#20851;&#24615;&#30340;&#19968;&#38454;&#28176;&#36817;&#20462;&#27491;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524; $\rho_\ell$ &#26159;&#31532; $\ell$ &#23618;&#30340;&#30456;&#20851;&#24615;&#65292;&#21017;...
&lt;/p&gt;
&lt;p&gt;
Recent analyses of neural networks with shaped activations (i.e. the activation function is scaled as the network size grows) have led to scaling limits described by differential equations. However, these results do not a priori tell us anything about "ordinary" unshaped networks, where the activation is unchanged as the network size grows. In this article, we find similar differential equation based asymptotic characterization for two types of unshaped networks.  Firstly, we show that the following two architectures converge to the same infinite-depth-and-width limit at initialization: (i) a fully connected ResNet with a $d^{-1/2}$ factor on the residual branch, where $d$ is the network depth. (ii) a multilayer perceptron (MLP) with depth $d \ll$ width $n$ and shaped ReLU activation at rate $d^{-1/2}$.  Secondly, for an unshaped MLP at initialization, we derive the first order asymptotic correction to the layerwise correlation. In particular, if $\rho_\ell$ is the correlation at layer
&lt;/p&gt;</description></item><item><title>RandCom&#26159;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36890;&#36807;&#27010;&#29575;&#24615;&#26412;&#22320;&#26356;&#26032;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2310.07983</link><description>&lt;p&gt;
RandCom&#65306;&#21435;&#20013;&#24515;&#21270;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#29992;&#20110;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
RandCom: Random Communication Skipping Method for Decentralized Stochastic Optimization. (arXiv:2310.07983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07983
&lt;/p&gt;
&lt;p&gt;
RandCom&#26159;&#19968;&#31181;&#21435;&#20013;&#24515;&#21270;&#30340;&#38543;&#26426;&#36890;&#20449;&#36339;&#36291;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#20013;&#36890;&#36807;&#27010;&#29575;&#24615;&#26412;&#22320;&#26356;&#26032;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#65292;&#24182;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#38543;&#26426;&#36890;&#20449;&#36339;&#36807;&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#26041;&#27861;&#22240;&#20854;&#22312;&#21152;&#36895;&#36890;&#20449;&#22797;&#26434;&#24615;&#26041;&#38754;&#20855;&#26377;&#30340;&#20248;&#21183;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#24378;&#20984;&#30830;&#23450;&#24615;&#35774;&#32622;&#30340;&#38598;&#20013;&#24335;&#36890;&#20449;&#21327;&#35758;&#19978;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RandCom&#30340;&#20998;&#24067;&#24335;&#20248;&#21270;&#26041;&#27861;&#65292;&#23427;&#37319;&#29992;&#20102;&#27010;&#29575;&#24615;&#30340;&#26412;&#22320;&#26356;&#26032;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;RandCom&#22312;&#38543;&#26426;&#38750;&#20984;&#12289;&#20984;&#21644;&#24378;&#20984;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#33021;&#22815;&#36890;&#36807;&#36890;&#20449;&#27010;&#29575;&#26469;&#28176;&#36817;&#22320;&#20943;&#23569;&#36890;&#20449;&#24320;&#38144;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#33410;&#28857;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;RandCom&#33021;&#22815;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;&#22312;&#38543;&#26426;&#24378;&#20984;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;RandCom&#21487;&#20197;&#36890;&#36807;&#29420;&#31435;&#20110;&#32593;&#32476;&#30340;&#27493;&#38271;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;RandCom&#24212;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#23454;&#29616;&#32447;&#24615;&#21152;&#36895;&#30340;&#28508;&#21147;&#30340;&#31215;&#26497;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed optimization methods with random communication skips are gaining increasing attention due to their proven benefits in accelerating communication complexity. Nevertheless, existing research mainly focuses on centralized communication protocols for strongly convex deterministic settings. In this work, we provide a decentralized optimization method called RandCom, which incorporates probabilistic local updates. We analyze the performance of RandCom in stochastic non-convex, convex, and strongly convex settings and demonstrate its ability to asymptotically reduce communication overhead by the probability of communication. Additionally, we prove that RandCom achieves linear speedup as the number of nodes increases. In stochastic strongly convex settings, we further prove that RandCom can achieve linear speedup with network-independent stepsizes. Moreover, we apply RandCom to federated learning and provide positive results concerning the potential for achieving linear speedup and
&lt;/p&gt;</description></item><item><title>Lion&#26159;&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#23613;&#31649;&#20854;&#29702;&#35770;&#22522;&#30784;&#19981;&#26126;&#30830;&#65292;&#20294;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2310.05898</link><description>&lt;p&gt;
&#29422;&#23376;&#31192;&#23494;&#22320;&#35299;&#20915;&#21463;&#38480;&#21046;&#20248;&#21270;&#38382;&#39064;&#65306;&#27491;&#22914;&#26446;&#38597;&#26222;&#35834;&#22827;&#25152;&#39044;&#27979;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05898
&lt;/p&gt;
&lt;p&gt;
Lion&#26159;&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#23613;&#31649;&#20854;&#29702;&#35770;&#22522;&#30784;&#19981;&#26126;&#30830;&#65292;&#20294;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;Lion&#65288;&#36827;&#21270;&#30340;&#31526;&#21495;&#21160;&#37327;&#65289;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#23427;&#22312;&#35757;&#32451;&#25928;&#26524;&#19978;&#19982;AdamW&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#27491;&#22914;&#25105;&#20204;&#21487;&#20197;&#20174;&#38543;&#26426;&#25628;&#32034;&#31243;&#24207;&#30340;&#32467;&#26524;&#20013;&#26399;&#24453;&#30340;&#65292;Lion&#38598;&#25104;&#20102;&#20960;&#20010;&#29616;&#26377;&#31639;&#27861;&#30340;&#20803;&#32032;&#65292;&#21253;&#25324;&#31526;&#21495;&#21160;&#37327;&#12289;&#29420;&#31435;&#30340;&#26435;&#37325;&#34928;&#20943;&#12289;Polak&#21644;Nesterov&#21160;&#37327;&#65292;&#20294;&#21448;&#19981;&#23646;&#20110;&#20219;&#20309;&#29616;&#26377;&#30340;&#29702;&#35770;&#22522;&#30784;&#20248;&#21270;&#22120;&#31867;&#21035;&#12290;&#22240;&#27492;&#65292;&#23613;&#31649;Lion&#20316;&#20026;&#24191;&#27867;&#20219;&#21153;&#30340;&#36890;&#29992;&#20248;&#21270;&#22120;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#36825;&#31181;&#32570;&#20047;&#29702;&#35770;&#30340;&#26126;&#30830;&#24615;&#38480;&#21046;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#21644;&#25193;&#23637;Lion&#30340;&#21487;&#33021;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#25581;&#24320;Lion&#30340;&#31070;&#31192;&#38754;&#32433;&#12290;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;$f(x)$&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.  This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32534;&#30721;&#29305;&#24449;&#32858;&#21512;&#26041;&#26696;&#65292;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#12290;</title><link>http://arxiv.org/abs/2309.00380</link><description>&lt;p&gt;
&#29992;&#25490;&#24207;&#19981;&#21464;&#30340;&#32534;&#30721;&#22120;&#21644;&#26356;&#32039;&#30340;&#21464;&#20998;&#36793;&#30028;&#23398;&#20064;&#22810;&#27169;&#24577;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning multi-modal generative models with permutation-invariant encoders and tighter variational bounds. (arXiv:2309.00380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32534;&#30721;&#29305;&#24449;&#32858;&#21512;&#26041;&#26696;&#65292;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#29992;&#20110;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#19968;&#30452;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20027;&#39064;&#12290;&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; (VAE) &#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#29983;&#25104;&#27169;&#22411;&#31867;&#21035;&#65292;&#23427;&#23398;&#20064;&#33021;&#22815;&#20849;&#21516;&#35299;&#37322;&#22810;&#31181;&#27169;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#21508;&#31181;&#23458;&#35266;&#20989;&#25968;&#24050;&#34987;&#25552;&#20986;&#29992;&#20110;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#24448;&#24448;&#20197;&#22810;&#27169;&#24577;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#19979;&#30028;&#20197;&#21450;&#20449;&#24687;&#35770;&#26041;&#38754;&#30340;&#32771;&#34385;&#20026;&#21160;&#26426;&#12290;&#20026;&#20102;&#23545;&#19981;&#21516;&#27169;&#24577;&#23376;&#38598;&#36827;&#34892;&#32534;&#30721;&#65292;&#25105;&#20204;&#32463;&#24120;&#20351;&#29992;&#24182;&#23637;&#31034;&#20102;&#20135;&#21697;&#22411;&#19987;&#23478; (PoE) &#25110;&#32773;&#28151;&#21512;&#22411;&#19987;&#23478; (MoE) &#32858;&#21512;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#22312;&#29983;&#25104;&#36136;&#37327;&#25110;&#32773;&#22810;&#27169;&#24577;&#19968;&#33268;&#24615;&#31561;&#26041;&#38754;&#20855;&#26377;&#19981;&#21516;&#30340;&#26435;&#34913;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#33021;&#22815;&#32039;&#23494;&#22320;&#19979;&#30028;&#25968;&#25454;&#23545;&#25968;&#20284;&#28982;&#30340;&#21464;&#20998;&#36793;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#19981;&#21516;&#27169;&#24577;&#30340;&#32534;&#30721;&#29305;&#24449;&#32452;&#21512;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#26356;&#28789;&#27963;&#30340;&#32858;&#21512;&#26041;&#26696;&#65292;&#36825;&#20123;&#26041;&#26696;&#25512;&#24191;&#20102; PoE &#25110;&#32773; MoE &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Devising deep latent variable models for multi-modal data has been a long-standing theme in machine learning research. Multi-modal Variational Autoencoders (VAEs) have been a popular generative model class that learns latent representations which jointly explain multiple modalities. Various objective functions for such models have been suggested, often motivated as lower bounds on the multi-modal data log-likelihood or from information-theoretic considerations. In order to encode latent variables from different modality subsets, Product-of-Experts (PoE) or Mixture-of-Experts (MoE) aggregation schemes have been routinely used and shown to yield different trade-offs, for instance, regarding their generative quality or consistency across multiple modalities. In this work, we consider a variational bound that can tightly lower bound the data log-likelihood. We develop more flexible aggregation schemes that generalise PoE or MoE approaches by combining encoded features from different modali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.08553</link><description>&lt;p&gt;
&#22122;&#22768;&#31283;&#23450;&#20248;&#21270;&#23545;&#20110;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#29575;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Noise Stability Optimization for Flat Minima with Optimal Convergence Rates. (arXiv:2306.08553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#21152;&#20837;&#21152;&#26435;&#25200;&#21160;&#26469;&#25214;&#21040;&#24179;&#22374;&#30340;&#26497;&#23567;&#20540;&#12290;&#32473;&#23450;&#19968;&#20010;&#38750;&#20984;&#20989;&#25968;$f:\mathbb{R}^d\rightarrow \mathbb{R}$&#21644;&#19968;&#20010;$d$&#32500;&#20998;&#24067;$\mathcal{P}$&#65292;&#25105;&#20204;&#25200;&#21160;$f$&#30340;&#26435;&#37325;&#65292;&#24182;&#23450;&#20041;$F(W)=\mathbb{E}[f({W+U})]$&#65292;&#20854;&#20013;$U$&#26159;&#19968;&#20010;&#20174;$\mathcal{P}$&#20013;&#38543;&#26426;&#25277;&#21462;&#30340;&#26679;&#26412;&#12290;&#36825;&#20010;&#36807;&#31243;&#36890;&#36807;$f$&#30340;&#28023;&#26862;&#30697;&#38453;&#30340;&#36857;&#26469;&#35825;&#23548;&#27491;&#21017;&#21270;&#65292;&#20197;&#36866;&#24212;&#20110;&#23567;&#30340;&#12289;&#21508;&#21521;&#21516;&#24615;&#30340;&#39640;&#26031;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#21152;&#26435;&#25200;&#21160;&#30340;&#20989;&#25968;&#20559;&#21521;&#20110;&#24102;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#26497;&#23567;&#20540;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;SGD&#30340;&#31639;&#27861;&#65292;&#22312;&#35745;&#31639;&#26799;&#24230;&#20043;&#21069;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#65292;&#21516;&#26102;&#21033;&#29992;$\mathcal{P}$&#30340;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We consider finding flat, local minimizers by adding average weight perturbations. Given a nonconvex function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ and a $d$-dimensional distribution $\mathcal{P}$ which is symmetric at zero, we perturb the weight of $f$ and define $F(W) = \mathbb{E}[f({W + U})]$, where $U$ is a random sample from $\mathcal{P}$. This injection induces regularization through the Hessian trace of $f$ for small, isotropic Gaussian perturbations. Thus, the weight-perturbed function biases to minimizers with low Hessian trace. Several prior works have studied settings related to this weight-perturbed function by designing algorithms to improve generalization. Still, convergence rates are not known for finding minima under the average perturbations of the function $F$. This paper considers an SGD-like algorithm that injects random noise before computing gradients while leveraging the symmetry of $\mathcal{P}$ to reduce variance. We then provide a rigorous analysis, showing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-CKF&#65289;&#21644;&#36870;&#22810;&#39033;&#24335;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-QKF&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#31995;&#32479;&#27169;&#22411;&#30340;&#36870;&#35748;&#30693;&#38382;&#39064;&#65292;&#24182;&#22312;&#25351;&#25968;-&#24179;&#22343;-&#20108;&#27425;&#26377;&#30028;&#24615;&#24847;&#20041;&#19979;&#25512;&#23548;&#20102;&#20854;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#39640;&#30340;&#20272;&#35745;&#31934;&#24230;&#21644;&#36882;&#24402;Cram\'{e}r-Rao&#19979;&#30028;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2303.10322</link><description>&lt;p&gt;
&#36870;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21644;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Inverse Cubature and Quadrature Kalman filters. (arXiv:2303.10322v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-CKF&#65289;&#21644;&#36870;&#22810;&#39033;&#24335;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-QKF&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#31995;&#32479;&#27169;&#22411;&#30340;&#36870;&#35748;&#30693;&#38382;&#39064;&#65292;&#24182;&#22312;&#25351;&#25968;-&#24179;&#22343;-&#20108;&#27425;&#26377;&#30028;&#24615;&#24847;&#20041;&#19979;&#25512;&#23548;&#20102;&#20854;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#39640;&#30340;&#20272;&#35745;&#31934;&#24230;&#21644;&#36882;&#24402;Cram\'{e}r-Rao&#19979;&#30028;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#23545;&#25239;&#31995;&#32479;&#30740;&#31350;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#23548;&#33268;&#24320;&#21457;&#20102;&#36870;&#38543;&#26426;&#28388;&#27874;&#22120;&#65292;&#36825;&#20123;&#28388;&#27874;&#22120;&#34987;&#38450;&#24481;&#32773;&#29992;&#26469;&#25512;&#26029;&#20854;&#23545;&#25163;&#21487;&#33021;&#23398;&#21040;&#30340;&#20449;&#24687;&#12290;&#26089;&#26399;&#30340;&#20316;&#21697;&#36890;&#36807;&#38024;&#23545;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#39640;&#26031;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20998;&#21035;&#25552;&#20986;&#20102;&#36870;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-KF&#65289;&#21644;&#36870;&#25193;&#23637;KF&#65288;I-EKF&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#36870;&#35748;&#30693;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#24456;&#22810;&#21453;&#23545;&#25239;&#24615;&#35774;&#32622;&#20250;&#28041;&#21450;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#31995;&#32479;&#27169;&#22411;&#65292;&#20854;&#20013;EKF&#30340;&#32447;&#24615;&#21270;&#24120;&#24120;&#20250;&#22833;&#36133;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#26377;&#25928;&#30340;&#25968;&#20540;&#31215;&#20998;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#31181;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#24182;&#22240;&#27492;&#24320;&#21457;&#20102;&#36870;&#22810;&#38754;&#31215;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-CKF&#65289;&#21644;&#36870;&#22810;&#39033;&#24335;&#31215;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-QKF&#65289;&#12290;&#25105;&#20204;&#22312;&#25351;&#25968;-&#24179;&#22343;-&#20108;&#27425;&#26377;&#30028;&#24615;&#24847;&#20041;&#19979;&#25512;&#23548;&#20102;&#25152;&#25552;&#20986;&#30340;&#28388;&#27874;&#22120;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;I-CKF&#21644;I-QKF&#30340;&#20272;&#35745;&#31934;&#24230;&#65292;&#36319;&#36882;&#24402;Cram\'{e}r-Rao&#19979;&#30028;&#20316;&#20026;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent developments in counter-adversarial system research have led to the development of inverse stochastic filters that are employed by a defender to infer the information its adversary may have learned. Prior works addressed this inverse cognition problem by proposing inverse Kalman filter (I-KF) and inverse extended KF (I-EKF), respectively, for linear and non-linear Gaussian state-space models. However, in practice, many counter-adversarial settings involve highly non-linear system models, wherein EKF's linearization often fails. In this paper, we consider the efficient numerical integration techniques to address such nonlinearities and, to this end, develop inverse cubature KF (I-CKF) and inverse quadrature KF (I-QKF). We derive the stochastic stability conditions for the proposed filters in the exponential-mean-squared-boundedness sense. Numerical experiments demonstrate the estimation accuracy of our I-CKF and I-QKF with the recursive Cram\'{e}r-Rao lower bound as a benchmark.
&lt;/p&gt;</description></item></channel></rss>