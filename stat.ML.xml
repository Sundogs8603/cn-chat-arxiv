<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#38590;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#24050;&#30693;&#30340;&#38382;&#39064;&#23545;&#31216;&#24615;&#26080;&#27861;&#32531;&#35299;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#38590;&#65292;&#24182;&#32473;&#20986;&#20102;&#22810;&#31181;&#32593;&#32476;&#24418;&#24335;&#30340;&#19979;&#30028;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2401.01869</link><description>&lt;p&gt;
&#20851;&#20110;&#23398;&#20064;&#23545;&#31216;&#24615;&#22256;&#38590;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the hardness of learning under symmetries. (arXiv:2401.01869v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#38590;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#24050;&#30693;&#30340;&#38382;&#39064;&#23545;&#31216;&#24615;&#26080;&#27861;&#32531;&#35299;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#38590;&#65292;&#24182;&#32473;&#20986;&#20102;&#22810;&#31181;&#32593;&#32476;&#24418;&#24335;&#30340;&#19979;&#30028;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#38382;&#39064;&#12290;&#23558;&#24050;&#30693;&#30340;&#23545;&#31216;&#24615;&#65288;"&#31561;&#21464;&#24615;"&#65289;&#32435;&#20837;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24050;&#32463;&#22312;&#20174;&#29983;&#29289;&#23398;&#21040;&#35745;&#31639;&#26426;&#35270;&#35273;&#31561;&#39046;&#22495;&#30340;&#23398;&#20064;&#27969;&#31243;&#20013;&#32463;&#39564;&#19978;&#25913;&#21892;&#20102;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20016;&#23500;&#32780;&#29420;&#31435;&#30340;&#23398;&#20064;&#29702;&#35770;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#65292;&#22312;&#30456;&#20851;&#32479;&#35745;&#26597;&#35810;&#65288;CSQ&#65289;&#27169;&#22411;&#20013;&#65292;&#23454;&#38469;&#23398;&#20064;&#27973;&#23618;&#20840;&#36830;&#25509;&#65288;&#21363;&#38750;&#23545;&#31216;&#65289;&#32593;&#32476;&#22312;&#22797;&#26434;&#24615;&#19978;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#22797;&#26434;&#24230;&#65292;&#35813;&#27169;&#22411;&#21253;&#25324;&#26799;&#24230;&#19979;&#38477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#24050;&#30693;&#30340;&#38382;&#39064;&#23545;&#31216;&#24615;&#26159;&#21542;&#36275;&#20197;&#32531;&#35299;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#26412;&#22256;&#38590;&#65311;&#25105;&#20204;&#30340;&#31572;&#26696;&#26159;&#21542;&#23450;&#30340;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#27973;&#23618;&#22270;&#31070;&#32463;&#32593;&#32476;&#12289;&#21367;&#31215;&#32593;&#32476;&#12289;&#19981;&#21464;&#22810;&#39033;&#24335;&#21644;&#32622;&#25442;&#23376;&#32676;&#30340;&#24103;&#24179;&#22343;&#32593;&#32476;&#30340;&#19979;&#30028;&#65292;&#23427;&#20204;&#22312;&#30456;&#20851;&#36755;&#20837;&#32500;&#24230;&#19978;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#35201;&#20040;&#36229;&#22810;&#39033;&#24335;&#65292;&#35201;&#20040;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning equivariant neural networks via gradient descent. The incorporation of known symmetries ("equivariance") into neural nets has empirically improved the performance of learning pipelines, in domains ranging from biology to computer vision. However, a rich yet separate line of learning theoretic research has demonstrated that actually learning shallow, fully-connected (i.e. non-symmetric) networks has exponential complexity in the correlational statistical query (CSQ) model, a framework encompassing gradient descent. In this work, we ask: are known problem symmetries sufficient to alleviate the fundamental hardness of learning neural nets with gradient descent? We answer this question in the negative. In particular, we give lower bounds for shallow graph neural networks, convolutional networks, invariant polynomials, and frame-averaged networks for permutation subgroups, which all scale either superpolynomially or exponentially in the relevant input dimens
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#8220;&#20132;&#21449;&#23398;&#20064;&#8221;&#35774;&#32622;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#65292;&#22312;&#26410;&#30693;&#19978;&#19979;&#25991;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#21327;&#35843;&#22810;&#20010;&#26102;&#26399;&#20869;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#25191;&#34892;&#65292;&#23454;&#29616;&#20102;&#20960;&#20046;&#32039;&#33268;&#30340;&#36951;&#25022;&#30028;&#12290;&#27492;&#31639;&#27861;&#35299;&#20915;&#20102;&#23398;&#20064;&#22312;&#19968;&#20215;&#25293;&#21334;&#21644;&#30561;&#35273;&#36172;&#24466;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#38590;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.01857</link><description>&lt;p&gt;
&#26410;&#30693;&#19978;&#19979;&#25991;&#20998;&#24067;&#19979;&#19978;&#19979;&#25991;&#36172;&#21338;&#26368;&#20248;&#20132;&#21449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal cross-learning for contextual bandits with unknown context distributions. (arXiv:2401.01857v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#8220;&#20132;&#21449;&#23398;&#20064;&#8221;&#35774;&#32622;&#30340;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#65292;&#22312;&#26410;&#30693;&#19978;&#19979;&#25991;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#21327;&#35843;&#22810;&#20010;&#26102;&#26399;&#20869;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#25191;&#34892;&#65292;&#23454;&#29616;&#20102;&#20960;&#20046;&#32039;&#33268;&#30340;&#36951;&#25022;&#30028;&#12290;&#27492;&#31639;&#27861;&#35299;&#20915;&#20102;&#23398;&#20064;&#22312;&#19968;&#20215;&#25293;&#21334;&#21644;&#30561;&#35273;&#36172;&#24466;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;Balseiro&#31561;&#20154;&#30340;&#8220;&#20132;&#21449;&#23398;&#20064;&#8221;&#35774;&#32622;&#20013;&#35774;&#35745;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#22120;&#35266;&#23519;&#21040;&#22312;&#25152;&#26377;&#21487;&#33021;&#30340;&#19978;&#19979;&#25991;&#20013;&#20182;&#20204;&#25152;&#36873;&#25321;&#30340;&#21160;&#20316;&#30340;&#25439;&#22833;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#24403;&#21069;&#22238;&#21512;&#30340;&#19978;&#19979;&#25991;&#12290;&#25105;&#20204;&#29305;&#21035;&#32771;&#34385;&#22312;&#25439;&#22833;&#34987;&#23545;&#25239;&#24615;&#22320;&#36873;&#25321;&#21644;&#19978;&#19979;&#25991;&#20174;&#26410;&#30693;&#20998;&#24067;&#29420;&#31435;&#21516;&#20998;&#24067;&#37319;&#26679;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#25928;&#29575;&#31639;&#27861;&#35299;&#20915;&#20102;Balseiro&#31561;&#20154;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#20854;&#36951;&#25022;&#30028;&#20960;&#20046;&#36798;&#21040;&#32039;&#33268;&#27700;&#24179;&#65288;&#23545;&#25968;&#22240;&#23376;&#65289;&#65292;&#20026;$\widetilde{O}(\sqrt{TK})$&#65292;&#19981;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#30340;&#25968;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#39318;&#27425;&#33719;&#24471;&#20102;&#22312;&#26410;&#30693;&#20540;&#20998;&#24067;&#30340;&#19968;&#20215;&#25293;&#21334;&#20013;&#23398;&#20064;&#20986;&#20960;&#20046;&#32039;&#33268;&#30340;&#36951;&#25022;&#30028;&#21644;&#20855;&#26377;&#38543;&#26426;&#21160;&#20316;&#38598;&#30340;&#30561;&#35273;&#36172;&#24466;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of designing contextual bandit algorithms in the ``cross-learning'' setting of Balseiro et al., where the learner observes the loss for the action they play in all possible contexts, not just the context of the current round. We specifically consider the setting where losses are chosen adversarially and contexts are sampled i.i.d. from an unknown distribution. In this setting, we resolve an open problem of Balseiro et al. by providing an efficient algorithm with a nearly tight (up to logarithmic factors) regret bound of $\widetilde{O}(\sqrt{TK})$, independent of the number of contexts. As a consequence, we obtain the first nearly tight regret bounds for the problems of learning to bid in first-price auctions (under unknown value distributions) and sleeping bandits with a stochastic action set.  At the core of our algorithm is a novel technique for coordinating the execution of a learning algorithm over multiple epochs in such a way to remove correlations between
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22343;&#21248;&#20998;&#24067;&#32593;&#26684;&#19978;&#20351;&#29992;&#20998;&#31867;&#27861;&#39640;&#25928;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#26426;&#20998;&#31867;&#22120;&#65292;&#23558;&#21442;&#25968;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#21306;&#22495;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#20998;&#31867;&#22120;&#24555;&#36895;&#30830;&#23450;&#28857;&#26159;&#21542;&#22312;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2401.01804</link><description>&lt;p&gt;
&#22312;&#22343;&#21248;&#20998;&#24067;&#32593;&#26684;&#19978;&#20351;&#29992;&#20998;&#31867;&#27861;&#39640;&#25928;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Efficient Computation of Confidence Sets Using Classification on Equidistributed Grids. (arXiv:2401.01804v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01804
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22343;&#21248;&#20998;&#24067;&#32593;&#26684;&#19978;&#20351;&#29992;&#20998;&#31867;&#27861;&#39640;&#25928;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#26426;&#20998;&#31867;&#22120;&#65292;&#23558;&#21442;&#25968;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#21306;&#22495;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#20998;&#31867;&#22120;&#24555;&#36895;&#30830;&#23450;&#28857;&#26159;&#21542;&#22312;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#39640;&#25928;&#21644;&#20934;&#30830;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#27982;&#27169;&#22411;&#20135;&#29983;&#30340;&#30697;&#19981;&#31561;&#24335;&#21487;&#20197;&#29992;&#26469;&#24418;&#25104;&#23545;&#30495;&#23454;&#21442;&#25968;&#30340;&#26816;&#39564;&#65292;&#36890;&#36807;&#23545;&#36825;&#20123;&#26816;&#39564;&#36827;&#34892;&#21453;&#28436;&#21487;&#20197;&#24471;&#20986;&#30495;&#23454;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32622;&#20449;&#21306;&#38388;&#36890;&#24120;&#27809;&#26377;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#38656;&#35201;&#36890;&#36807;&#20445;&#30041;&#36890;&#36807;&#26816;&#39564;&#30340;&#32593;&#26684;&#28857;&#26469;&#25968;&#20540;&#35745;&#31639;&#24471;&#20986;&#32622;&#20449;&#21306;&#38388;&#12290;&#24403;&#32479;&#35745;&#37327;&#19981;&#20855;&#26377;&#28176;&#36817;&#20851;&#38190;&#24615;&#26102;&#65292;&#22312;&#21442;&#25968;&#31354;&#38388;&#30340;&#27599;&#20010;&#32593;&#26684;&#28857;&#19978;&#26500;&#24314;&#20020;&#30028;&#20540;&#22686;&#21152;&#20102;&#35745;&#31639;&#36127;&#25285;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#20998;&#31867;&#22120;&#65292;&#23558;&#35745;&#31639;&#38382;&#39064;&#36716;&#21270;&#20026;&#20998;&#31867;&#38382;&#39064;&#12290;&#20854;&#20915;&#31574;&#20989;&#25968;&#20026;&#23558;&#21442;&#25968;&#31354;&#38388;&#21010;&#20998;&#20026;&#20004;&#20010;&#21306;&#22495;&#65288;&#32622;&#20449;&#21306;&#38388;&#20869;&#37096;&#19982;&#22806;&#37096;&#65289;&#25552;&#20379;&#20102;&#26356;&#24555;&#36895;&#21644;&#26356;&#31995;&#32479;&#30340;&#26041;&#24335;&#12290;&#25105;&#20204;&#23558;&#32622;&#20449;&#21306;&#38388;&#20869;&#37096;&#30340;&#28857;&#26631;&#35760;&#20026;1&#65292;&#23558;&#22806;&#37096;&#30340;&#28857;&#26631;&#35760;&#20026;-1&#12290;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#22312;&#21487;&#31649;&#29702;&#30340;&#32593;&#26684;&#19978;&#35757;&#32451;SVM&#20998;&#31867;&#22120;&#65292;&#24182;&#20351;&#29992;&#35813;&#20998;&#31867;&#22120;&#30830;&#23450;&#23494;&#24230;&#26356;&#39640;&#30340;&#32593;&#26684;&#19978;&#30340;&#28857;&#26159;&#21542;&#22312;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#25105;&#20204;&#20570;&#20986;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Economic models produce moment inequalities, which can be used to form tests of the true parameters. Confidence sets (CS) of the true parameters are derived by inverting these tests. However, they often lack analytical expressions, necessitating a grid search to obtain the CS numerically by retaining the grid points that pass the test. When the statistic is not asymptotically pivotal, constructing the critical value for each grid point in the parameter space adds to the computational burden. In this paper, we convert the computational issue into a classification problem by using a support vector machine (SVM) classifier. Its decision function provides a faster and more systematic way of dividing the parameter space into two regions: inside vs. outside of the confidence set. We label those points in the CS as 1 and those outside as -1. Researchers can train the SVM classifier on a grid of manageable size and use it to determine whether points on denser grids are in the CS or not. We est
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#65288;&#29305;&#21035;&#26159;LSTM&#32593;&#32476;&#65289;&#35780;&#20272;&#20102;&#20998;&#25968;&#38543;&#26426;&#36807;&#31243;&#20013;&#30340;Hurst&#21442;&#25968;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#21487;&#38752;&#24615;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#21644;&#20998;&#25968;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#20013;&#65292;LSTM&#32593;&#32476;&#20248;&#20110;&#20256;&#32479;&#32479;&#35745;&#26041;&#27861;&#65292;&#20294;&#22312;&#32447;&#24615;&#20998;&#25968;&#31283;&#23450;&#36816;&#21160;&#36807;&#31243;&#20013;&#20934;&#30830;&#24615;&#21463;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.01789</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#32447;&#24615;&#20998;&#25968;&#36807;&#31243;&#30340;Hurst&#21442;&#25968;&#21450;&#20854;&#21487;&#38752;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Deep learning the Hurst parameter of linear fractional processes and assessing its reliability. (arXiv:2401.01789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#65288;&#29305;&#21035;&#26159;LSTM&#32593;&#32476;&#65289;&#35780;&#20272;&#20102;&#20998;&#25968;&#38543;&#26426;&#36807;&#31243;&#20013;&#30340;Hurst&#21442;&#25968;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#21487;&#38752;&#24615;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#21644;&#20998;&#25968;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#20013;&#65292;LSTM&#32593;&#32476;&#20248;&#20110;&#20256;&#32479;&#32479;&#35745;&#26041;&#27861;&#65292;&#20294;&#22312;&#32447;&#24615;&#20998;&#25968;&#31283;&#23450;&#36816;&#21160;&#36807;&#31243;&#20013;&#20934;&#30830;&#24615;&#21463;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#28145;&#24230;&#23398;&#20064;&#65288;&#29305;&#21035;&#26159;&#38271;&#30701;&#26102;&#35760;&#24518;&#32593;&#32476;&#65289;&#22312;&#20272;&#35745;&#20998;&#25968;&#38543;&#26426;&#36807;&#31243;&#20013;&#30340;Hurst&#21442;&#25968;&#30340;&#21487;&#38752;&#24615;&#12290;&#30740;&#31350;&#38598;&#20013;&#22312;&#19977;&#31181;&#31867;&#22411;&#30340;&#36807;&#31243;&#19978;&#65306;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#65288;fBm&#65289;&#65292;&#20998;&#25968;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#65288;fOU&#65289;&#36807;&#31243;&#21644;&#32447;&#24615;&#20998;&#25968;&#31283;&#23450;&#36816;&#21160;&#65288;lfsm&#65289;&#12290;&#30740;&#31350;&#21253;&#25324;&#23545;fBm&#21644;fOU&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#24555;&#36895;&#29983;&#25104;&#65292;&#20197;&#20415;&#22312;&#21512;&#29702;&#30340;&#26102;&#38388;&#20869;&#35757;&#32451;LSTM&#32593;&#32476;&#12290;&#30740;&#31350;&#20998;&#26512;&#20102;LSTM&#32593;&#32476;&#22312;Hurst&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#65292;&#21253;&#25324;&#22343;&#26041;&#26681;&#35823;&#24046;&#65288;RMSE&#65289;&#65292;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MAE&#65289;&#65292;&#30456;&#23545;&#35823;&#24046;&#30340;&#20998;&#20301;&#25968;&#31561;&#21508;&#31181;&#24615;&#33021;&#25351;&#26631;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;fBm&#21644;fOU&#36807;&#31243;&#30340;&#24773;&#20917;&#19979;&#65292;LSTM&#20248;&#20110;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#65307;&#28982;&#32780;&#65292;&#22312;lfsm&#36807;&#31243;&#19978;&#30340;&#20934;&#30830;&#24615;&#26377;&#38480;&#12290;&#30740;&#31350;&#36824;&#28145;&#20837;&#25506;&#35752;&#20102;&#35757;&#32451;&#38271;&#24230;&#21644;&#35780;&#20272;&#24207;&#21015;&#38271;&#24230;&#23545;LSTM&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#35813;&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
This research explores the reliability of deep learning, specifically Long Short-Term Memory (LSTM) networks, for estimating the Hurst parameter in fractional stochastic processes. The study focuses on three types of processes: fractional Brownian motion (fBm), fractional Ornstein-Uhlenbeck (fOU) process, and linear fractional stable motions (lfsm). The work involves a fast generation of extensive datasets for fBm and fOU to train the LSTM network on a large volume of data in a feasible time. The study analyses the accuracy of the LSTM network's Hurst parameter estimation regarding various performance measures like RMSE, MAE, MRE, and quantiles of the absolute and relative errors. It finds that LSTM outperforms the traditional statistical methods in the case of fBm and fOU processes; however, it has limited accuracy on lfsm processes. The research also delves into the implications of training length and valuation sequence length on the LSTM's performance. The methodology is applied by 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#21452;&#26426;&#22120;&#23398;&#20064;&#21644;&#27169;&#22411;&#24179;&#22343;&#21270;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32467;&#26500;&#21442;&#25968;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#27604;&#36215;&#24120;&#35265;&#30340;&#22522;&#20110;&#21333;&#19968;&#23398;&#20064;&#22120;&#30340;&#26367;&#20195;&#26041;&#27861;&#26356;&#21152;&#40065;&#26834;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#37096;&#20998;&#26410;&#30693;&#30340;&#20989;&#25968;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.01645</link><description>&lt;p&gt;
&#27169;&#22411;&#24179;&#22343;&#21270;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Model Averaging and Double Machine Learning. (arXiv:2401.01645v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#21452;&#26426;&#22120;&#23398;&#20064;&#21644;&#27169;&#22411;&#24179;&#22343;&#21270;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32467;&#26500;&#21442;&#25968;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#27604;&#36215;&#24120;&#35265;&#30340;&#22522;&#20110;&#21333;&#19968;&#23398;&#20064;&#22120;&#30340;&#26367;&#20195;&#26041;&#27861;&#26356;&#21152;&#40065;&#26834;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#37096;&#20998;&#26410;&#30693;&#30340;&#20989;&#25968;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#23558;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DDML&#65289;&#19982;stacking&#65288;&#19968;&#31181;&#27169;&#22411;&#24179;&#22343;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#32467;&#21512;&#22810;&#20010;&#20505;&#36873;&#23398;&#20064;&#22120;&#65289;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20272;&#35745;&#32467;&#26500;&#21442;&#25968;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#26032;&#30340;DDML stacking&#26041;&#27861;&#65306;&#30701;stacking&#21033;&#29992;DDML&#30340;&#20132;&#21449;&#25311;&#21512;&#27493;&#39588;&#22823;&#22823;&#20943;&#23569;&#20102;&#35745;&#31639;&#36127;&#25285;&#65292;&#32780;&#27719;&#24635;stacking&#21487;&#20197;&#22312;&#20132;&#21449;&#25311;&#21512;&#30340;&#25240;&#21472;&#19978;&#24378;&#21046;&#25191;&#34892;&#36890;&#29992; stacking&#26435;&#37325;&#12290;&#36890;&#36807;&#32463;&#36807;&#26657;&#20934;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#20004;&#20010;&#24212;&#29992;&#31243;&#24207;&#65292;&#21363;&#20272;&#35745;&#24341;&#29992;&#21644;&#24037;&#36164;&#20013;&#30340;&#24615;&#21035;&#24046;&#36317;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;DDML&#19982;stacking&#30456;&#27604;&#22522;&#20110;&#21333;&#20010;&#39044;&#36873;&#23398;&#20064;&#22120;&#30340;&#24120;&#35265;&#26367;&#20195;&#26041;&#27861;&#23545;&#20110;&#37096;&#20998;&#26410;&#30693;&#30340;&#20989;&#25968;&#24418;&#24335;&#26356;&#21152;&#40065;&#26834;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#29616;&#25105;&#20204;&#26041;&#26696;&#30340;Stata&#21644;R&#36719;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper discusses pairing double/debiased machine learning (DDML) with stacking, a model averaging method for combining multiple candidate learners, to estimate structural parameters. We introduce two new stacking approaches for DDML: short-stacking exploits the cross-fitting step of DDML to substantially reduce the computational burden and pooled stacking enforces common stacking weights over cross-fitting folds. Using calibrated simulation studies and two applications estimating gender gaps in citations and wages, we show that DDML with stacking is more robust to partially unknown functional forms than common alternative approaches based on single pre-selected learners. We provide Stata and R software implementing our proposals.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#38598;&#21512;&#32447;&#24615;&#21270;&#26368;&#20248;&#20256;&#36755;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23558;&#28857;&#20113;&#23884;&#20837;&#21040;L2&#31354;&#38388;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#21487;&#20197;&#21306;&#20998;&#19981;&#21516;&#31867;&#21035;&#28857;&#20113;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#28857;&#20113;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#36817;&#20284;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#32593;&#32476;&#26469;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.01460</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#38598;&#21512;&#32447;&#24615;&#21270;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#28857;&#20113;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Point Cloud Classification via Deep Set Linearized Optimal Transport. (arXiv:2401.01460v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01460
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#38598;&#21512;&#32447;&#24615;&#21270;&#26368;&#20248;&#20256;&#36755;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23558;&#28857;&#20113;&#23884;&#20837;&#21040;L2&#31354;&#38388;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#21487;&#20197;&#21306;&#20998;&#19981;&#21516;&#31867;&#21035;&#28857;&#20113;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#28857;&#20113;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#36817;&#20284;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#32593;&#32476;&#26469;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;&#28145;&#24230;&#38598;&#21512;&#32447;&#24615;&#21270;&#26368;&#20248;&#20256;&#36755;&#30340;&#31639;&#27861;&#65292;&#26088;&#22312;&#23558;&#28857;&#20113;&#39640;&#25928;&#22320;&#23884;&#20837;&#21040;L2&#31354;&#38388;&#20013;&#12290;&#36825;&#31181;&#23884;&#20837;&#22312;&#20445;&#30041;Wasserstein&#31354;&#38388;&#20013;&#29305;&#23450;&#20302;&#32500;&#32467;&#26500;&#30340;&#21516;&#26102;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#31867;&#21035;&#28857;&#20113;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20197;&#19979;&#35266;&#23519;&#65292;&#21363;&#19981;&#21516;&#28857;&#20113;&#30340;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#20043;&#38388;&#30340;L2&#36317;&#31163;&#65288;&#28304;&#33258;&#20849;&#20139;&#30340;&#22266;&#23450;&#21442;&#32771;&#20998;&#24067;&#65289;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#36817;&#20284;&#34920;&#31034;&#36825;&#20123;&#28857;&#20113;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#12290;&#20026;&#20102;&#23398;&#20064;&#36825;&#20123;&#20256;&#36755;&#26144;&#23556;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#37319;&#29992;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#65288;ICNNs&#65289;&#65292;&#24182;&#19988;&#35777;&#26126;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#36825;&#20123;ICNNs&#30340;&#26679;&#26412;&#20043;&#38388;&#30340;&#27431;&#27663;&#36317;&#31163;&#19982;&#30495;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#38750;&#24120;&#30456;&#20284;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#37492;&#21035;&#22120;&#32593;&#32476;&#65292;&#23545;&#36825;&#20123;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65292;&#24182;&#21019;&#24314;&#20102;&#19968;&#20010;&#32622;&#25442;&#19981;&#21464;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Deep Set Linearized Optimal Transport, an algorithm designed for the efficient simultaneous embedding of point clouds into an $L^2-$space. This embedding preserves specific low-dimensional structures within the Wasserstein space while constructing a classifier to distinguish between various classes of point clouds. Our approach is motivated by the observation that $L^2-$distances between optimal transport maps for distinct point clouds, originating from a shared fixed reference distribution, provide an approximation of the Wasserstein-2 distance between these point clouds, under certain assumptions. To learn approximations of these transport maps, we employ input convex neural networks (ICNNs) and establish that, under specific conditions, Euclidean distances between samples from these ICNNs closely mirror Wasserstein-2 distances between the true distributions. Additionally, we train a discriminator network that attaches weights these samples and creates a permutation inva
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26469;&#22238;&#31572;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2401.01426</link><description>&lt;p&gt;
&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Modular Learning of Deep Causal Generative Models for High-dimensional Causal Inference. (arXiv:2401.01426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#22240;&#26524;&#25512;&#26029;&#30340;&#27169;&#22359;&#21270;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#26469;&#22238;&#31572;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Pearl&#30340;&#22240;&#26524;&#23618;&#27425;&#32467;&#26500;&#22312;&#35266;&#27979;&#12289;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#38382;&#39064;&#20043;&#38388;&#24314;&#31435;&#20102;&#26126;&#30830;&#30340;&#20998;&#31163;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20102;&#35745;&#31639;&#21487;&#36776;&#35782;&#22240;&#26524;&#26597;&#35810;&#30340;&#22768;&#38899;&#21644;&#23436;&#25972;&#31639;&#27861;&#65292;&#22312;&#32473;&#23450;&#23618;&#27425;&#30340;&#22240;&#26524;&#32467;&#26500;&#21644;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#36739;&#20302;&#23618;&#27425;&#30340;&#23618;&#27425;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#31639;&#27861;&#20551;&#35774;&#25105;&#20204;&#21487;&#20197;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#36825;&#23545;&#20110;&#22914;&#22270;&#20687;&#36825;&#26679;&#30340;&#39640;&#32500;&#21464;&#37327;&#26159;&#19968;&#20010;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29616;&#20195;&#29983;&#25104;&#24335;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#21487;&#20197;&#34987;&#35757;&#32451;&#26469;&#23398;&#20064;&#22914;&#20309;&#20934;&#30830;&#22320;&#20174;&#36825;&#26679;&#30340;&#39640;&#32500;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#29305;&#21035;&#26159;&#38543;&#30528;&#22270;&#20687;&#22522;&#27169;&#22411;&#30340;&#26368;&#36817;&#20852;&#36215;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26469;&#22238;&#31572;&#24102;&#26377;&#36825;&#26679;&#39640;&#32500;&#25968;&#25454;&#30340;&#22240;&#26524;&#26597;&#35810;&#26159;&#38750;&#24120;&#26377;&#21560;&#24341;&#21147;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#35757;&#32451;&#31639;&#27861;&#65292;&#32473;&#23450;&#22240;&#26524;&#32467;&#26500;&#21644;&#39044;&#35757;&#32451;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#35757;&#32451;&#19968;&#20010;&#27169;&#22411;&#26469;&#20272;&#35745;&#30001;&#39640;&#32500;&#25968;&#25454;&#24341;&#36215;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pearl's causal hierarchy establishes a clear separation between observational, interventional, and counterfactual questions. Researchers proposed sound and complete algorithms to compute identifiable causal queries at a given level of the hierarchy using the causal structure and data from the lower levels of the hierarchy. However, most of these algorithms assume that we can accurately estimate the probability distribution of the data, which is an impractical assumption for high-dimensional variables such as images. On the other hand, modern generative deep learning architectures can be trained to learn how to accurately sample from such high-dimensional distributions. Especially with the recent rise of foundation models for images, it is desirable to leverage pre-trained models to answer causal queries with such high-dimensional data. To address this, we propose a sequential training algorithm that, given the causal structure and a pre-trained conditional generative model, can train a
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;</title><link>http://arxiv.org/abs/2401.01404</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#23376;&#20108;&#27425;&#26102;&#38388;&#32593;&#32476;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable network reconstruction in subquadratic time. (arXiv:2401.01404v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01404
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32593;&#32476;&#37325;&#24314;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#27425;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#36890;&#36807;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#20135;&#29983;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#37325;&#24314;&#26159;&#25351;&#22312;&#21482;&#26377;&#20851;&#20110;&#26465;&#20214;&#20598;&#32852;&#30340;&#35266;&#27979;&#25968;&#25454;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#22270;&#27169;&#22411;&#30340;&#29420;&#31435;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;N&#20010;&#33410;&#28857;&#20043;&#38388;&#26410;&#35266;&#27979;&#21040;&#30340;&#25104;&#23545;&#32806;&#21512;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#20284;&#20046;&#26080;&#27861;&#36991;&#20813;&#30340;&#20108;&#27425;&#22797;&#26434;&#24230;O(N^2)&#65292;&#21363;&#35201;&#32771;&#34385;&#27599;&#31181;&#21487;&#33021;&#30340;&#25104;&#23545;&#32806;&#21512;&#33267;&#23569;&#19968;&#27425;&#65292;&#23613;&#31649;&#22823;&#22810;&#25968;&#24863;&#20852;&#36259;&#30340;&#32593;&#32476;&#37117;&#26159;&#31232;&#30095;&#30340;&#65292;&#38750;&#38646;&#32806;&#21512;&#30340;&#25968;&#37327;&#21482;&#26377;O(N)&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#24191;&#27867;&#37325;&#24314;&#38382;&#39064;&#30340;&#36890;&#29992;&#31639;&#27861;&#65292;&#20854;&#22312;&#23376;&#20108;&#27425;&#26102;&#38388;&#20869;&#23454;&#29616;&#32467;&#26524;&#65292;&#20854;&#25968;&#25454;&#30456;&#20851;&#22797;&#26434;&#24230;&#23485;&#26494;&#19978;&#30028;&#20026;O(N^(3/2)logN)&#65292;&#20294;&#20855;&#26377;&#26356;&#20856;&#22411;&#30340;&#23545;&#25968;&#32447;&#24615;&#22797;&#26434;&#24230;O(Nlog^2 N)&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#20108;&#38454;&#37051;&#23621;&#25628;&#32034;&#65292;&#20135;&#29983;&#20102;&#26368;&#20339;&#30340;&#36793;&#20505;&#36873;&#12290;
&lt;/p&gt;
&lt;p&gt;
Network reconstruction consists in determining the unobserved pairwise couplings between $N$ nodes given only observational data on the resulting behavior that is conditioned on those couplings -- typically a time-series or independent samples from a graphical model. A major obstacle to the scalability of algorithms proposed for this problem is a seemingly unavoidable quadratic complexity of $O(N^2)$, corresponding to the requirement of each possible pairwise coupling being contemplated at least once, despite the fact that most networks of interest are sparse, with a number of non-zero couplings that is only $O(N)$. Here we present a general algorithm applicable to a broad range of reconstruction problems that achieves its result in subquadratic time, with a data-dependent complexity loosely upper bounded by $O(N^{3/2}\log N)$, but with a more typical log-linear complexity of $O(N\log^2N)$. Our algorithm relies on a stochastic second neighbor search that produces the best edge candidat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#31867;&#21035;&#37327;&#21270;&#30340;&#26680;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#30446;&#21069;&#30340;&#26041;&#27861;&#65292;&#23427;&#33021;&#26356;&#22909;&#22320;&#27169;&#25311;&#25968;&#25454;&#20013;&#30340;&#31867;&#38388;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2401.00490</link><description>&lt;p&gt;
&#22810;&#31867;&#21035;&#37327;&#21270;&#30340;&#26680;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Kernel Density Estimation for Multiclass Quantification. (arXiv:2401.00490v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.00490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#31867;&#21035;&#37327;&#21270;&#30340;&#26680;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#30446;&#21069;&#30340;&#26041;&#27861;&#65292;&#23427;&#33021;&#26356;&#22909;&#22320;&#27169;&#25311;&#25968;&#25454;&#20013;&#30340;&#31867;&#38388;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20123;&#23398;&#31185;&#65292;&#22914;&#31038;&#20250;&#31185;&#23398;&#12289;&#27969;&#34892;&#30149;&#23398;&#12289;&#24773;&#24863;&#20998;&#26512;&#25110;&#24066;&#22330;&#30740;&#31350;&#65292;&#20851;&#27880;&#30340;&#26159;&#20102;&#35299;&#20154;&#32676;&#20013;&#21508;&#31867;&#21035;&#30340;&#20998;&#24067;&#24773;&#20917;&#65292;&#32780;&#19981;&#26159;&#20010;&#20307;&#30340;&#26631;&#31614;&#12290;&#37327;&#21270;&#26159;&#19968;&#31181;&#30417;&#30563;&#24335;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#26088;&#22312;&#33719;&#24471;&#20934;&#30830;&#30340;&#31867;&#21035;&#39057;&#29575;&#39044;&#27979;&#22120;&#65292;&#24182;&#22312;&#26631;&#31614;&#20559;&#31227;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#12290;&#20998;&#24067;&#21305;&#37197;&#65288;DM&#65289;&#26041;&#27861;&#26159;&#36804;&#20170;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#37327;&#21270;&#26041;&#27861;&#20013;&#26368;&#37325;&#35201;&#30340;&#23478;&#26063;&#20043;&#19968;&#12290;&#30446;&#21069;&#30340;DM&#26041;&#27861;&#36890;&#36807;&#21518;&#39564;&#27010;&#29575;&#30340;&#30452;&#26041;&#22270;&#23545;&#28041;&#21450;&#30340;&#20154;&#32676;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#22810;&#31867;&#21035;&#35774;&#32622;&#26159;&#27425;&#20248;&#30340;&#65292;&#22240;&#20026;&#30452;&#26041;&#22270;&#21464;&#25104;&#20102;&#31867;&#21035;&#29305;&#23450;&#30340;&#65292;&#26080;&#27861;&#27169;&#25311;&#25968;&#25454;&#20013;&#21487;&#33021;&#23384;&#22312;&#30340;&#31867;&#38388;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20803;&#23494;&#24230;&#30340;&#26032;&#30340;&#34920;&#31034;&#26426;&#21046;&#65292;&#36890;&#36807;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several disciplines, like the social sciences, epidemiology, sentiment analysis, or market research, are interested in knowing the distribution of the classes in a population rather than the individual labels of the members thereof. Quantification is the supervised machine learning task concerned with obtaining accurate predictors of class prevalence, and to do so particularly in the presence of label shift. The distribution-matching (DM) approaches represent one of the most important families among the quantification methods that have been proposed in the literature so far. Current DM approaches model the involved populations by means of histograms of posterior probabilities. In this paper, we argue that their application to the multiclass setting is suboptimal since the histograms become class-specific, thus missing the opportunity to model inter-class information that may exist in the data. We propose a new representation mechanism based on multivariate densities that we model via k
&lt;/p&gt;</description></item><item><title>CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2307.00859</link><description>&lt;p&gt;
CardiGraphormer: &#25581;&#31034;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery. (arXiv:2307.00859v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00859
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#38420;&#30340;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#20013;&#65292;&#24050;&#30693;&#33647;&#29289;&#32422;&#26377;15,000&#31181;&#65292;&#20294;&#21482;&#26377;&#22823;&#32422;4,200&#31181;&#24471;&#21040;&#20102;&#25209;&#20934;&#65292;&#21270;&#23398;&#31354;&#38388;&#30340;&#32452;&#21512;&#24615;&#36136;&#25552;&#20379;&#20102;&#19968;&#39033;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#20154;&#24037;&#26234;&#33021;&#25104;&#20026;&#20102;&#26377;&#21147;&#30340;&#20249;&#20276;&#65292;&#20256;&#32479;&#30340;&#20154;&#24037;&#26234;&#33021;&#26694;&#26550;&#20173;&#38754;&#20020;&#37325;&#22823;&#38556;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CardiGraphormer&#65292;&#36825;&#26159;&#19968;&#31181;&#21010;&#26102;&#20195;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#20174;&#32780;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#12290;CardiGraphormer&#26159;Graphormer&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#30340;&#26032;&#39062;&#32452;&#21512;&#65292;&#21033;&#29992;SSL&#23398;&#20064;&#26377;&#25928;&#30340;&#20998;&#23376;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;GNN&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#12290;&#23427;&#22312;&#22788;&#29702;&#20998;&#23376;&#32467;&#26500;&#31561;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#33021;&#25191;&#34892;&#19982;&#33410;&#28857;&#12289;&#33410;&#28857;&#23545;&#12289;&#23376;&#22270;&#25110;&#25972;&#20010;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#65292;&#36890;&#36807;&#23558;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#65292;&#20351;&#29992;&#25968;&#20540;&#31283;&#23450;&#30340;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2306.07774</link><description>&lt;p&gt;
&#38477;&#31209;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65306;&#22312;&#39640;&#32500;&#20013;&#36827;&#34892;&#36817;&#20284;&#20302;&#31209;&#21160;&#24577;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
The Rank-Reduced Kalman Filter: Approximate Dynamical-Low-Rank Filtering In High Dimensions. (arXiv:2306.07774v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07774
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#65292;&#36890;&#36807;&#23558;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#65292;&#20351;&#29992;&#25968;&#20540;&#31283;&#23450;&#30340;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#21160;&#24577;&#31995;&#32479;&#30340;&#25512;&#26029;&#21644;&#27169;&#25311;&#20013;&#65292;&#38656;&#35201;&#36827;&#34892;&#26576;&#31181;&#24418;&#24335;&#30340;&#38477;&#32500;&#25165;&#33021;&#20351;&#38382;&#39064;&#20855;&#26377;&#21487;&#22788;&#29702;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#39640;&#26031;&#28388;&#27874;&#21644;&#24179;&#28369;&#26041;&#27861;&#65292;&#23427;&#23558;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#20256;&#25773;&#12290;&#36825;&#26159;&#36890;&#36807;&#23558;&#39044;&#27979;&#27493;&#39588;&#30456;&#20851;&#30340;Lyapunov&#26041;&#31243;&#25237;&#24433;&#21040;&#20302;&#31209;&#30697;&#38453;&#30340;&#27969;&#24418;&#19978;&#26469;&#23454;&#29616;&#30340;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#36817;&#24320;&#21457;&#30340;&#25968;&#20540;&#31283;&#23450;&#12289;&#21160;&#24577;&#20302;&#31209;&#31215;&#20998;&#22120;&#27714;&#35299;&#36825;&#20123;&#26041;&#31243;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36890;&#36807;&#27880;&#24847;&#21327;&#26041;&#24046;&#26356;&#26032;&#20165;&#36716;&#25442;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21015;&#31354;&#38388;&#65292;&#32780;&#35813;&#31354;&#38388;&#30001;&#26500;&#36896;&#24471;&#21040;&#65292;&#20174;&#32780;&#20351;&#26356;&#26032;&#27493;&#39588;&#20855;&#26377;&#21487;&#22788;&#29702;&#24615;&#12290;&#31639;&#27861;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#38598;&#21512;&#30340;&#26041;&#27861;&#19981;&#21516;&#20043;&#22788;&#22312;&#20110;&#65292;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20302;&#31209;&#36817;&#20284;&#26159;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#30340;&#12290;&#20851;&#38190;&#22312;&#20110;&#65292;&#36825;&#20351;&#24471;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference and simulation in the context of high-dimensional dynamical systems remain computationally challenging problems. Some form of dimensionality reduction is required to make the problem tractable in general. In this paper, we propose a novel approximate Gaussian filtering and smoothing method which propagates low-rank approximations of the covariance matrices. This is accomplished by projecting the Lyapunov equations associated with the prediction step to a manifold of low-rank matrices, which are then solved by a recently developed, numerically stable, dynamical low-rank integrator. Meanwhile, the update steps are made tractable by noting that the covariance update only transforms the column space of the covariance matrix, which is low-rank by construction. The algorithm differentiates itself from existing ensemble-based approaches in that the low-rank approximations of the covariance matrices are deterministic, rather than stochastic. Crucially, this enables the method to repr
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;$\ell_p$&#23376;&#31354;&#38388;&#23884;&#20837;&#30340;&#28789;&#25935;&#24230;&#37319;&#26679;&#30028;&#38480;&#65292;&#21462;&#24471;&#20102;&#27604;&#36890;&#29992;&#30028;&#38480;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#23545;&#20110;$1\leq p&lt;2$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2/p}$&#65292;&#23545;&#20110;$2&lt;p&lt;\infty$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2-2/p}$&#12290;</title><link>http://arxiv.org/abs/2306.00732</link><description>&lt;p&gt;
$\ell_p$&#28789;&#25935;&#24230;&#37319;&#26679;&#30340;&#26356;&#20005;&#26684;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharper Bounds for $\ell_p$ Sensitivity Sampling. (arXiv:2306.00732v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;$\ell_p$&#23376;&#31354;&#38388;&#23884;&#20837;&#30340;&#28789;&#25935;&#24230;&#37319;&#26679;&#30028;&#38480;&#65292;&#21462;&#24471;&#20102;&#27604;&#36890;&#29992;&#30028;&#38480;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#23545;&#20110;$1\leq p&lt;2$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2/p}$&#65292;&#23545;&#20110;$2&lt;p&lt;\infty$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2-2/p}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#38543;&#26426;&#37319;&#26679;&#26159;&#19968;&#31181;&#36817;&#20284;&#25968;&#25454;&#38598;&#30340;&#27969;&#34892;&#26041;&#24335;&#65292;&#36825;&#31181;&#26041;&#24335;&#21487;&#20197;&#36890;&#36807;&#19968;&#23567;&#37096;&#20998;&#20855;&#26377;&#20195;&#34920;&#24615;&#30340;&#31034;&#20363;&#26469;&#36827;&#34892;&#12290;&#29305;&#21035;&#22320;&#65292;&#28789;&#25935;&#24230;&#37319;&#26679;&#26159;&#19968;&#31181;&#24378;&#28872;&#30740;&#31350;&#30340;&#25216;&#26415;&#65292;&#23427;&#22312;&#26497;&#20854;&#26222;&#36941;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#36817;&#20284;&#36136;&#37327;&#20445;&#35777;&#65292;&#21516;&#26102;&#23558;&#31034;&#20363;&#30340;&#25968;&#37327;&#20943;&#23569;&#21040;VC&#32500;$d$&#21644;&#24635;&#28789;&#25935;&#24230;$\mathfrak{S}$&#30340;&#20056;&#31215;&#12290;&#28982;&#32780;&#65292;&#38500;&#20102;$\ell_2$&#23376;&#31354;&#38388;&#23884;&#20837;&#20197;&#22806;&#65292;&#24456;&#23569;&#26377;&#20445;&#35777;&#36229;&#36807;&#36825;&#20010;$\mathfrak{S}d$&#36890;&#29992;&#30028;&#38480;&#30340;&#30693;&#35782;&#65292;&#23613;&#31649;&#20197;&#21069;&#30340;&#24037;&#20316;&#38750;&#24120;&#24378;&#35843;&#28789;&#25935;&#24230;&#37319;&#26679;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23637;&#31034;&#20102;&#23545;&#20110;$ p\neq2$&#30340;$\ell_p$&#23376;&#31354;&#38388;&#23884;&#20837;&#30340;&#28789;&#25935;&#24230;&#37319;&#26679;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#36229;&#36807;&#20102;&#19968;&#33324;&#30340;$\mathfrak{S}d$&#30028;&#38480;&#65292;&#23545;&#20110;$1\leq p&lt;2$&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#22823;&#32422;$\mathfrak{S}^{2/p}$&#30340;&#30028;&#38480;&#65292;&#24182;&#19988;&#23545;&#20110;$2&lt;p&lt;\infty$&#65292;&#21462;&#24471;&#20102;$\mathfrak{S}^{2-2/p}$&#30340;&#30028;&#38480;&#12290;&#22312;$1\leq p&lt;2$&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#34920;&#26126;&#36825;&#20010;&#36793;&#30028;&#26159;&#23494;&#20999;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In large scale machine learning, random sampling is a popular way to approximate datasets by a small representative subset of examples. In particular, sensitivity sampling is an intensely studied technique which provides provable guarantees on the quality of approximation, while reducing the number of examples to the product of the VC dimension $d$ and the total sensitivity $\mathfrak S$ in remarkably general settings. However, guarantees going beyond this general bound of $\mathfrak S d$ are known in perhaps only one setting, for $\ell_2$ subspace embeddings, despite intense study of sensitivity sampling in prior work. In this work, we show the first bounds for sensitivity sampling for $\ell_p$ subspace embeddings for $p\neq 2$ that improve over the general $\mathfrak S d$ bound, achieving a bound of roughly $\mathfrak S^{2/p}$ for $1\leq p&lt;2$ and $\mathfrak S^{2-2/p}$ for $2&lt;p&lt;\infty$. For $1\leq p&lt;2$, we show that this bound is tight, in the sense that there exist matrices for which
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#23548;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#22266;&#23450;&#26679;&#26412;&#22823;&#23567;&#26041;&#24335;&#65292;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#25152;&#26377;&#20572;&#27490;&#26102;&#38388;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#26032;&#30340;&#36793;&#30028;&#26041;&#27861;&#65292;&#20063;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#24179;&#31283;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2302.03421</link><description>&lt;p&gt;
&#19968;&#31181;&#32479;&#19968;&#30340;&#26041;&#27861;&#25512;&#23548;&#65288;&#26102;&#38388;&#22343;&#21248;&#30340;&#65289;PAC-Bayes&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
A unified recipe for deriving (time-uniform) PAC-Bayes bounds. (arXiv:2302.03421v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03421
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25512;&#23548;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;&#22266;&#23450;&#26679;&#26412;&#22823;&#23567;&#26041;&#24335;&#65292;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#25152;&#26377;&#20572;&#27490;&#26102;&#38388;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#26032;&#30340;&#36793;&#30028;&#26041;&#27861;&#65292;&#20063;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#24179;&#31283;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#23548;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#12290;&#19982;&#22823;&#22810;&#25968;&#20851;&#20110;&#27492;&#20027;&#39064;&#30340;&#25991;&#29486;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#20219;&#20309;&#26102;&#38388;&#37117;&#26377;&#25928;&#30340;&#65288;&#21363;&#26102;&#38388;&#22343;&#21248;&#30340;&#65289;&#65292;&#36825;&#24847;&#21619;&#30528;&#23427;&#20204;&#36866;&#29992;&#20110;&#25152;&#26377;&#20572;&#27490;&#26102;&#38388;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#22266;&#23450;&#30340;&#26679;&#26412;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25353;&#29031;&#20197;&#19979;&#39034;&#24207;&#32467;&#21512;&#20102;&#22235;&#31181;&#24037;&#20855;&#65306;&#65288;a&#65289;&#38750;&#36127;&#36229;&#39532;&#19969;&#26684;&#23572;&#25110;&#21453;&#21521;&#20122;&#39532;&#36874;&#65292;&#65288;b&#65289;&#28151;&#21512;&#27861;&#65292;&#65288;c&#65289;Donsker-Varadhan&#20844;&#24335;&#65288;&#25110;&#20854;&#23427;&#20984;&#24615;&#23545;&#20598;&#21407;&#29702;&#65289;&#21644;&#65288;d&#65289;Ville&#19981;&#31561;&#24335;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25104;&#26524;&#26159;&#19968;&#20010;PAC-Bayes&#23450;&#29702;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#31163;&#25955;&#38543;&#26426;&#36807;&#31243;&#31867;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#32467;&#26524;&#22914;&#20309;&#25512;&#20986;&#30693;&#21517;&#30340;&#32463;&#20856;PAC-Bayes&#30028;&#38480;&#65292;&#20363;&#22914;Seeger&#12289;McAllester&#12289;Maurer&#21644;Catoni&#30340;&#30028;&#38480;&#65292;&#20197;&#21450;&#35768;&#22810;&#26368;&#26032;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20960;&#20010;&#26032;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36824;&#20351;&#25105;&#20204;&#33021;&#22815;&#25918;&#26494;&#20256;&#32479;&#30340;&#20551;&#35774;&#65307;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#38750;&#24179;&#31283;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a unified framework for deriving PAC-Bayesian generalization bounds. Unlike most previous literature on this topic, our bounds are anytime-valid (i.e., time-uniform), meaning that they hold at all stopping times, not only for a fixed sample size. Our approach combines four tools in the following order: (a) nonnegative supermartingales or reverse submartingales, (b) the method of mixtures, (c) the Donsker-Varadhan formula (or other convex duality principles), and (d) Ville's inequality. Our main result is a PAC-Bayes theorem which holds for a wide class of discrete stochastic processes. We show how this result implies time-uniform versions of well-known classical PAC-Bayes bounds, such as those of Seeger, McAllester, Maurer, and Catoni, in addition to many recent bounds. We also present several novel bounds. Our framework also enables us to relax traditional assumptions; in particular, we consider nonstationary loss functions and non-i.i.d. data. In sum, we unify the derivati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#29992;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#26469;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#27604;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22522;&#32447;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2212.08123</link><description>&lt;p&gt;
&#24102;&#26377;&#38543;&#26426;&#38598;&#21512;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Bayesian posterior approximation with stochastic ensembles. (arXiv:2212.08123v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#20351;&#29992;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#26469;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#27604;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22522;&#32447;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#38598;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#12290;&#23427;&#23558;&#38543;&#26426;&#26041;&#27861;&#65288;&#22914;dropout&#65289;&#19982;&#28145;&#24230;&#38598;&#25104;&#30456;&#32467;&#21512;&#65292;&#24182;&#23558;&#38543;&#26426;&#38598;&#21512;&#20844;&#24335;&#21270;&#20026;&#20998;&#24067;&#26063;&#65292;&#24182;&#20351;&#29992;&#21464;&#20998;&#25512;&#26029;&#35757;&#32451;&#20197;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#29609;&#20855;&#38382;&#39064;&#21644;CIFAR&#22270;&#20687;&#20998;&#31867;&#19978;&#23454;&#29616;&#20102;&#22522;&#20110;Monte Carlo Dropout&#65292;DropConnect&#21644;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#29256;&#26412;&#30340;&#38543;&#26426;&#38598;&#21512;&#65292;&#24182;&#30452;&#25509;&#19982;&#21704;&#23494;&#39039;&#39532;&#23572;&#21487;&#22827;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#27604;&#36739;&#36136;&#37327;&#26469;&#27979;&#35797;&#21518;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#26426;&#38598;&#21512;&#25552;&#20379;&#20102;&#27604;&#20854;&#20182;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22522;&#32447;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce ensembles of stochastic neural networks to approximate the Bayesian posterior, combining stochastic methods such as dropout with deep ensembles. The stochastic ensembles are formulated as families of distributions and trained to approximate the Bayesian posterior with variational inference. We implement stochastic ensembles based on Monte Carlo dropout, DropConnect and a novel non-parametric version of dropout and evaluate them on a toy problem and CIFAR image classification. For both tasks, we test the quality of the posteriors directly against Hamiltonian Monte Carlo simulations. Our results show that stochastic ensembles provide more accurate posterior estimates than other popular baselines for Bayesian inference.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#33324;&#20989;&#25968;&#31354;&#38388;&#20013;&#20272;&#35745;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#32473;&#23450;&#26679;&#26412;&#20174;&#20998;&#24067;P&#21644;&#25512;&#21069;&#20998;&#24067;T_#P&#20013;&#20272;&#35745;&#20989;&#25968;T&#30340;&#38382;&#39064;&#65292;&#24182;&#20551;&#35774;T&#20026;&#20984;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;&#35813;&#26041;&#27861;&#30340;&#20551;&#35774;&#35201;&#27714;&#27604;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#20551;&#35774;&#35201;&#24369;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#30340;&#20272;&#35745;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2212.03722</link><description>&lt;p&gt;
&#22312;&#19968;&#33324;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal transport map estimation in general function spaces. (arXiv:2212.03722v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19968;&#33324;&#20989;&#25968;&#31354;&#38388;&#20013;&#20272;&#35745;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#32473;&#23450;&#26679;&#26412;&#20174;&#20998;&#24067;P&#21644;&#25512;&#21069;&#20998;&#24067;T_#P&#20013;&#20272;&#35745;&#20989;&#25968;T&#30340;&#38382;&#39064;&#65292;&#24182;&#20551;&#35774;T&#20026;&#20984;&#20989;&#25968;&#30340;&#26799;&#24230;&#12290;&#35813;&#26041;&#27861;&#30340;&#20551;&#35774;&#35201;&#27714;&#27604;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#20551;&#35774;&#35201;&#24369;&#65292;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#30340;&#20272;&#35745;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32473;&#23450;&#26469;&#33258;&#20998;&#24067;P&#21644;&#25512;&#21069;&#20998;&#24067;T_#P&#30340;&#29420;&#31435;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#20989;&#25968;T&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#35774;&#32622;&#30340;&#21160;&#26426;&#26469;&#33258;&#31185;&#23398;&#24212;&#29992;&#65292;&#20854;&#20013;T&#34920;&#31034;&#29289;&#29702;&#31995;&#32479;&#38543;&#26102;&#38388;&#28436;&#21270;&#30340;&#36807;&#31243;&#65292;&#20197;&#21450;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;T&#21487;&#33021;&#20195;&#34920;&#20026;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#32780;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#21040;&#30340;&#21464;&#25442;&#12290;&#20026;&#20102;&#30830;&#20445;&#21487;&#35782;&#21035;&#24615;&#65292;&#25105;&#20204;&#20551;&#35774;T = &#119899;&#119886;&#119887;&#119897;&#119886;&#966;0&#26159;&#19968;&#20010;&#20984;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#27492;&#26102;T&#34987;&#31216;&#20026;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#30740;&#31350;&#20102;&#22312;T&#23646;&#20110;H&#246;lder&#31867;&#30340;&#20551;&#35774;&#19979;&#20272;&#35745;T&#30340;&#38382;&#39064;&#65292;&#20294;&#32570;&#20047;&#19968;&#33324;&#29702;&#35770;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#19968;&#33324;&#20989;&#25968;&#31354;&#38388;&#20013;&#33719;&#21462;&#26368;&#20248;&#20256;&#36755;&#26144;&#23556;&#30340;&#20272;&#35745;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#20551;&#35774;&#27604;&#25991;&#29486;&#20013;&#30340;&#20551;&#35774;&#35201;&#24369;&#24471;&#22810;&#65306;&#25105;&#20204;&#21482;&#35201;&#27714;&#28304;&#27979;&#24230;P&#28385;&#36275;Poincar&#233;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating a function $T$ given independent samples from a distribution $P$ and from the pushforward distribution $T_\sharp P$. This setting is motivated by applications in the sciences, where $T$ represents the evolution of a physical system over time, and in machine learning, where, for example, $T$ may represent a transformation learned by a deep neural network trained for a generative modeling task. To ensure identifiability, we assume that $T = \nabla \varphi_0$ is the gradient of a convex function, in which case $T$ is known as an \emph{optimal transport map}. Prior work has studied the estimation of $T$ under the assumption that it lies in a H\"older class, but general theory is lacking. We present a unified methodology for obtaining rates of estimation of optimal transport maps in general function spaces. Our assumptions are significantly weaker than those appearing in the literature: we require only that the source measure $P$ satisfy a Poincar\'e inequ
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24046;&#24322;&#20256;&#25773;&#39564;&#35777;&#22797;&#21512;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#28508;&#22312;&#19981;&#20934;&#30830;&#30340;&#27169;&#25311;&#20013;&#25512;&#23548;&#20986;&#30495;&#23454;&#31995;&#32479;&#30340;&#25925;&#38556;&#27010;&#29575;&#19978;&#30028;&#12290;&#23545;&#20110;&#24230;&#37327;&#22914;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322; (MMD) &#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#32039;&#20945;&#30340;&#20984;&#26494;&#24347;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#33391;&#22909;&#30340;&#39564;&#35777;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.12061</link><description>&lt;p&gt;
&#36890;&#36807;&#24046;&#24322;&#20256;&#25773;&#39564;&#35777;&#22797;&#21512;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Validation of Composite Systems by Discrepancy Propagation. (arXiv:2210.12061v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24046;&#24322;&#20256;&#25773;&#39564;&#35777;&#22797;&#21512;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#28508;&#22312;&#19981;&#20934;&#30830;&#30340;&#27169;&#25311;&#20013;&#25512;&#23548;&#20986;&#30495;&#23454;&#31995;&#32479;&#30340;&#25925;&#38556;&#27010;&#29575;&#19978;&#30028;&#12290;&#23545;&#20110;&#24230;&#37327;&#22914;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322; (MMD) &#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#32039;&#20945;&#30340;&#20984;&#26494;&#24347;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#33391;&#22909;&#30340;&#39564;&#35777;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#22522;&#20110;&#32473;&#23450;&#36136;&#37327;&#26631;&#20934;&#35780;&#20272;&#30495;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#26377;&#25928;&#24615;&#26159;&#19968;&#39033;&#24120;&#35265;&#20294;&#26114;&#36149;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#38656;&#35201;&#22823;&#37327;&#30340;&#30495;&#23454;&#19990;&#30028;&#27979;&#35797;&#12290;&#36890;&#36807;&#27169;&#25311;&#26469;&#39564;&#35777;&#36825;&#31867;&#31995;&#32479;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#19988;&#26356;&#20415;&#23452;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#38656;&#35201;&#35780;&#20272;&#27169;&#25311;&#30340;&#20934;&#30830;&#24615;&#21644;&#31471;&#21040;&#31471;&#27979;&#37327;&#12290;&#27492;&#22806;&#65292;&#27169;&#25311;&#21644;&#23454;&#38469;&#20351;&#29992;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#21487;&#33021;&#23548;&#33268;&#20272;&#35745;&#36825;&#31867;&#31995;&#32479;&#21487;&#38752;&#24615;&#30340;&#22256;&#38590;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39564;&#35777;&#26041;&#27861;&#65292;&#36890;&#36807;&#22797;&#21512;&#31995;&#32479;&#20256;&#25773;&#20998;&#24067;&#24046;&#24322;&#24230;&#37327;&#30340;&#30028;&#38480;&#65292;&#20174;&#32780;&#20801;&#35768;&#25105;&#20204;&#20174;&#28508;&#22312;&#19981;&#20934;&#30830;&#30340;&#27169;&#25311;&#20013;&#25512;&#23548;&#20986;&#30495;&#23454;&#31995;&#32479;&#30340;&#25925;&#38556;&#27010;&#29575;&#19978;&#30028;&#12290;&#27599;&#20010;&#20256;&#25773;&#27493;&#39588;&#37117;&#28041;&#21450;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#23545;&#20110;&#20687;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322; (MMD) &#36825;&#26679;&#30340;&#24230;&#37327;&#65292;&#25105;&#20204;&#22522;&#20110;&#21322;&#23450;&#31243;&#24207;&#24320;&#21457;&#20102;&#32039;&#20945;&#30340;&#20984;&#26494;&#24347;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#20063;&#20855;&#26377;&#21487;&#27604;&#36739;&#30340;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#19988;&#22312;&#22810;&#20010;&#22797;&#21512;&#31995;&#32479;&#39564;&#35777;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the validity of a real-world system with respect to given quality criteria is a common yet costly task in industrial applications due to the vast number of required real-world tests. Validating such systems by means of simulation offers a promising and less expensive alternative, but requires an assessment of the simulation accuracy and therefore end-to-end measurements. Additionally, covariate shifts between simulations and actual usage can cause difficulties for estimating the reliability of such systems. In this work, we present a validation method that propagates bounds on distributional discrepancy measures through a composite system, thereby allowing us to derive an upper bound on the failure probability of the real system from potentially inaccurate simulations. Each propagation step entails an optimization problem, where -- for measures such as maximum mean discrepancy (MMD) -- we develop tight convex relaxations based on semidefinite programs. We demonstrate that our
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#39044;&#27979;&#33391;&#22909;&#30340;&#21453;&#24212;&#22352;&#26631;&#20197;&#21450;MD&#36712;&#36857;&#30340;&#28436;&#21270;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#27491;&#21017;&#21270;&#32422;&#26463;&#23545;&#20110;&#36873;&#25321;&#37325;&#35201;&#21453;&#24212;&#22352;&#26631;&#30340;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2208.10962</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#39044;&#27979;&#33391;&#22909;&#21453;&#24212;&#22352;&#26631;&#21644;MD&#36712;&#36857;&#30340;&#26410;&#26469;&#28436;&#21270;&#65306;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction of good reaction coordinates and future evolution of MD trajectories using Regularized Sparse Autoencoders: A novel deep learning approach. (arXiv:2208.10962v2 [physics.chem-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10962
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#39044;&#27979;&#33391;&#22909;&#30340;&#21453;&#24212;&#22352;&#26631;&#20197;&#21450;MD&#36712;&#36857;&#30340;&#28436;&#21270;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#27491;&#21017;&#21270;&#32422;&#26463;&#23545;&#20110;&#36873;&#25321;&#37325;&#35201;&#21453;&#24212;&#22352;&#26631;&#30340;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#23450;&#21453;&#24212;&#22352;&#26631;(RCs)&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#22240;&#20026;RCs&#22312;&#30830;&#23450;&#21270;&#23398;&#21453;&#24212;&#30340;&#36827;&#23637;&#20013;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36873;&#25321;&#21453;&#24212;&#22352;&#26631;&#36890;&#24120;&#22522;&#20110;&#21551;&#21457;&#24335;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#36873;&#25321;&#30340;&#26631;&#20934;&#20043;&#19968;&#26159;&#35813;&#22352;&#26631;&#24212;&#28165;&#26224;&#22320;&#25429;&#33719;&#21453;&#24212;&#29289;&#21644;&#29983;&#25104;&#29289;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;&#22352;&#26631;&#24212;&#35813;&#26159;&#26368;&#24930;&#30340;&#65292;&#20351;&#24471;&#25152;&#26377;&#20854;&#20182;&#33258;&#30001;&#24230;&#21487;&#20197;&#27839;&#30528;&#21453;&#24212;&#22352;&#26631;&#36731;&#26494;&#36798;&#21040;&#24179;&#34913;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#31232;&#30095;&#33258;&#32534;&#30721;&#22120;&#65292;&#21363;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65292;&#26469;&#21457;&#29616;&#19968;&#32452;&#20851;&#38190;&#30340;&#21453;&#24212;&#22352;&#26631;&#12290;&#38500;&#20102;&#21457;&#29616;&#21453;&#24212;&#22352;&#26631;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#36824;&#21487;&#20197;&#39044;&#27979;&#20998;&#23376;&#21160;&#21147;&#23398;(MD)&#36712;&#36857;&#30340;&#28436;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21253;&#25324;&#31232;&#30095;&#32422;&#26463;&#27491;&#21017;&#21270;&#26377;&#21161;&#20110;&#36873;&#25321;&#19968;&#20010;&#23567;&#20294;&#37325;&#35201;&#30340;&#19968;&#32452;&#21453;&#24212;&#22352;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying reaction coordinates(RCs) is an active area of research, given the crucial role RCs play in determining the progress of a chemical reaction. The choice of the reaction coordinate is often based on heuristic knowledge. However, an essential criterion for the choice is that the coordinate should capture both the reactant and product states unequivocally. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. Also, the coordinate should be the slowest one so that all the other degrees of freedom can easily equilibrate along the reaction coordinate. We used a regularised sparse autoencoder, an energy-based model, to discover a crucial set of reaction coordinates. Along with discovering reaction coordinates, our model also predicts the evolution of a molecular dynamics(MD) trajectory. We showcased that including sparsity enforcing regularisation helps in choosing a small but important set of r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#22312;&#21487;&#35266;&#27979;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#30340;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2204.06990</link><description>&lt;p&gt;
&#21487;&#35266;&#27979;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#30340;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#30340;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Observable adjustments in single-index models for regularized M-estimators. (arXiv:2204.06990v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.06990
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#22312;&#21487;&#35266;&#27979;&#21333;&#25351;&#25968;&#27169;&#22411;&#20013;&#30340;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#26410;&#30693;&#36830;&#25509;&#20989;&#25968;&#12289;&#39640;&#26031;&#21327;&#21464;&#37327;&#21644;&#30001;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#22120;&#26500;&#36896;&#30340;&#27491;&#21017;&#21270;M&#20272;&#35745;&#22120;&#967;&#770;&#30340;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#35266;&#27979;&#20540;(X, y)&#12290;&#22312;&#26679;&#26412;&#22823;&#23567;n&#21644;&#23610;&#24230;p&#37117;&#22312;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#24471;p/n&#26377;&#19968;&#20010;&#26377;&#38480;&#26497;&#38480;&#65292;&#24050;&#32463;&#22312;&#35768;&#22810;&#27169;&#22411;&#20013;&#34920;&#24449;&#20102;&#967;&#770;&#30340;&#32463;&#39564;&#20998;&#24067;&#21644;&#39044;&#27979;&#20540;X&#967;&#770;&#30340;&#34892;&#20026;&#65306;&#24050;&#30693;&#32463;&#39564;&#20998;&#24067;&#25910;&#25947;&#20110;&#30456;&#20851;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#25439;&#22833;&#21644;&#24809;&#32602;&#30340;&#37051;&#36817;&#31639;&#23376;&#65292;&#35813;&#27169;&#22411;&#25429;&#25417;&#20102;&#27604;&#29575;p/n&#12289;&#25439;&#22833;&#12289;&#27491;&#21017;&#21270;&#21644;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36825;&#31181;$(\hat\beta,X\hat\beta)$&#21644;&#30456;&#24212;&#30340;&#37051;&#36817;&#31639;&#23376;&#20043;&#38388;&#30340;&#36830;&#25509;&#38656;&#35201;&#35299;&#20915;&#36890;&#24120;&#28041;&#21450;&#26080;&#27861;&#35266;&#23519;&#21040;&#30340;&#25968;&#37327;&#65292;&#22914;&#25351;&#25968;&#19978;&#30340;&#20808;&#39564;&#20998;&#24067;&#25110;&#36830;&#25509;&#20989;&#25968;&#30340;&#22266;&#23450;&#28857;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider observations $(X,y)$ from single index models with unknown link function, Gaussian covariates and a regularized M-estimator $\hat\beta$ constructed from convex loss function and regularizer. In the regime where sample size $n$ and dimension $p$ are both increasing such that $p/n$ has a finite limit, the behavior of the empirical distribution of $\hat\beta$ and the predicted values $X\hat\beta$ has been previously characterized in a number of models: The empirical distributions are known to converge to proximal operators of the loss and penalty in a related Gaussian sequence model, which captures the interplay between ratio $p/n$, loss, regularization and the data generating process. This connection between$(\hat\beta,X\hat\beta)$ and the corresponding proximal operators require solving fixed-point equations that typically involve unobservable quantities such as the prior distribution on the index or the link function.  This paper develops a different theory to describe the 
&lt;/p&gt;</description></item></channel></rss>