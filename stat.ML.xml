<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#26367;&#20195;&#25903;&#25345;&#21521;&#37327;&#26426;(SVM)&#26041;&#27861;&#36827;&#34892;&#25968;&#25454;&#20998;&#31867;&#65292;&#22312;&#20445;&#25345;&#31867;&#20284;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#23545;SVM&#26041;&#27861;&#30340;&#19968;&#20123;&#32570;&#28857;&#36827;&#34892;&#20102;&#25913;&#36827;&#21644;&#25935;&#24863;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2308.11579</link><description>&lt;p&gt;
SVM&#26041;&#27861;&#30340;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#29992;&#20110;&#25968;&#25454;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
An alternative to SVM Method for Data Classification. (arXiv:2308.11579v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#26367;&#20195;&#25903;&#25345;&#21521;&#37327;&#26426;(SVM)&#26041;&#27861;&#36827;&#34892;&#25968;&#25454;&#20998;&#31867;&#65292;&#22312;&#20445;&#25345;&#31867;&#20284;&#24615;&#33021;&#30340;&#21516;&#26102;&#65292;&#23545;SVM&#26041;&#27861;&#30340;&#19968;&#20123;&#32570;&#28857;&#36827;&#34892;&#20102;&#25913;&#36827;&#21644;&#25935;&#24863;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;(SVM)&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#26680;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#25454;&#20998;&#31867;&#65292;&#24182;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#35777;&#26126;&#20102;&#20854;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65292;&#21253;&#25324;&#26102;&#38388;&#22788;&#29702;&#12289;&#39640;&#32500;&#24773;&#20917;&#19979;&#20248;&#21270;&#36807;&#31243;&#22833;&#36133;&#30340;&#39118;&#38505;&#12289;&#22810;&#31867;&#21035;&#12289;&#19981;&#24179;&#34913;&#31867;&#21035;&#21644;&#21160;&#24577;&#20998;&#31867;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#31867;&#20284;&#30340;&#24615;&#33021;&#65292;&#23545;&#19978;&#36848;&#32570;&#28857;&#36827;&#34892;&#20102;&#25935;&#24863;&#25913;&#36827;&#12290;&#36825;&#31181;&#26032;&#26041;&#27861;&#22522;&#20110;&#21040;&#21253;&#21547;&#26144;&#23556;&#21407;&#22987;&#31867;&#21035;&#30340;&#26368;&#20248;&#23376;&#31354;&#38388;&#30340;&#26368;&#23567;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support vector machine (SVM), is a popular kernel method for data classification that demonstrated its efficiency for a large range of practical applications. The method suffers, however, from some weaknesses including; time processing, risk of failure of the optimization process for high dimension cases, generalization to multi-classes, unbalanced classes, and dynamic classification. In this paper an alternative method is proposed having a similar performance, with a sensitive improvement of the aforementioned shortcomings. The new method is based on a minimum distance to optimal subspaces containing the mapped original classes.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#36890;&#36807;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#24352;&#37327;&#31209;&#28436;&#21270;&#26469;&#29702;&#35299;&#31070;&#32463;&#20803;&#36830;&#25509;&#22312;&#23398;&#20064;&#20013;&#30340;&#21327;&#35843;&#21464;&#21270;&#12290;&#30740;&#31350;&#34920;&#26126;&#35757;&#32451;&#36807;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#30697;&#38453;&#36890;&#24120;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#65292;&#32780;&#36825;&#31181;&#32467;&#26500;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#20445;&#25345;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#12290;&#23545;&#30495;&#23454;&#26435;&#37325;&#36827;&#34892;&#20302;&#31209;&#20998;&#35299;&#39564;&#35777;&#20102;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.11567</link><description>&lt;p&gt;
&#31070;&#32463;&#21160;&#21147;&#23398;&#30340;&#20302;&#38454;&#24352;&#37327;&#31209;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Low Tensor Rank Learning of Neural Dynamics. (arXiv:2308.11567v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11567
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#36890;&#36807;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#24352;&#37327;&#31209;&#28436;&#21270;&#26469;&#29702;&#35299;&#31070;&#32463;&#20803;&#36830;&#25509;&#22312;&#23398;&#20064;&#20013;&#30340;&#21327;&#35843;&#21464;&#21270;&#12290;&#30740;&#31350;&#34920;&#26126;&#35757;&#32451;&#36807;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#30697;&#38453;&#36890;&#24120;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#65292;&#32780;&#36825;&#31181;&#32467;&#26500;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#20445;&#25345;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#12290;&#23545;&#30495;&#23454;&#26435;&#37325;&#36827;&#34892;&#20302;&#31209;&#20998;&#35299;&#39564;&#35777;&#20102;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20381;&#36182;&#20110;&#31070;&#32463;&#20803;&#32676;&#20307;&#20013;&#30340;&#21327;&#35843;&#31361;&#35302;&#21464;&#21270;&#12290;&#22240;&#27492;&#65292;&#20102;&#35299;&#23398;&#20064;&#36807;&#31243;&#20013;&#31361;&#35302;&#36830;&#25509;&#30340;&#38598;&#20307;&#28436;&#21270;&#26159;&#31070;&#32463;&#31185;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#32463;&#36807;&#35757;&#32451;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#30340;&#26435;&#37325;&#30697;&#38453;&#36890;&#24120;&#26159;&#20302;&#31209;&#30340;&#65292;&#20294;&#26159;&#36825;&#31181;&#20302;&#31209;&#32467;&#26500;&#22914;&#20309;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#23637;&#24320;&#36824;&#19981;&#28165;&#26970;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#30001;&#26435;&#37325;&#30697;&#38453;&#24418;&#25104;&#30340;3&#38454;&#24352;&#37327;&#30340;&#31209;&#12290;&#36890;&#36807;&#29992;&#19981;&#21516;&#31209;&#30340;RNN&#25311;&#21512;&#22823;&#35268;&#27169;&#31070;&#32463;&#35760;&#24405;&#30340;&#36816;&#21160;&#23398;&#20064;&#20219;&#21153;&#65292;&#25105;&#20204;&#21457;&#29616;&#25512;&#26029;&#30340;&#26435;&#37325;&#26159;&#20302;&#38454;&#24352;&#37327;&#31209;&#30340;&#65292;&#22240;&#27492;&#22312;&#25972;&#20010;&#23398;&#20064;&#36807;&#31243;&#20013;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20013;&#28436;&#21270;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#30495;&#23454;&#26435;&#37325;&#19978;&#30452;&#25509;&#36827;&#34892;&#20302;&#38454;&#24352;&#37327;&#31209;&#20998;&#35299;&#65292;&#24182;&#23637;&#31034;&#25105;&#20204;&#25152;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#39564;&#35777;&#20102;&#20302;&#38454;&#24352;&#37327;&#31209;&#23398;&#20064;&#30340;&#35266;&#23519;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning relies on coordinated synaptic changes in recurrently connected populations of neurons. Therefore, understanding the collective evolution of synaptic connectivity over learning is a key challenge in neuroscience and machine learning. In particular, recent work has shown that the weight matrices of task-trained RNNs are typically low rank, but how this low rank structure unfolds over learning is unknown. To address this, we investigate the rank of the 3-tensor formed by the weight matrices throughout learning. By fitting RNNs of varying rank to large-scale neural recordings during a motor learning task, we find that the inferred weights are low-tensor-rank and therefore evolve over a fixed low-dimensional subspace throughout the entire course of learning. We next validate the observation of low-tensor-rank learning on an RNN trained to solve the same task by performing a low-tensor-rank decomposition directly on the ground truth weights, and by showing that the method we applie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#25968;&#25454;&#20013;&#21033;&#29992;&#38598;&#32676;&#32467;&#26500;&#25913;&#36827;&#23398;&#20064;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#38024;&#23545;&#24102;&#26377;&#38598;&#32676;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#65292;&#24212;&#29992;&#20102;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.11518</link><description>&lt;p&gt;
EM&#31639;&#27861;&#22312;&#24102;&#26377;&#38598;&#32676;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
EM for Mixture of Linear Regression with Clustered Data. (arXiv:2308.11518v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11518
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20998;&#24067;&#24335;&#25968;&#25454;&#20013;&#21033;&#29992;&#38598;&#32676;&#32467;&#26500;&#25913;&#36827;&#23398;&#20064;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#38024;&#23545;&#24102;&#26377;&#38598;&#32676;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#65292;&#24212;&#29992;&#20102;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25968;&#25454;&#39537;&#21160;&#21644;&#20998;&#24067;&#24335;&#23398;&#20064;&#26694;&#26550;&#22788;&#29702;&#30001;&#20998;&#24067;&#22312;&#24322;&#36136;&#29615;&#22659;&#20013;&#30340;&#23458;&#25143;&#31471;&#29983;&#25104;&#30340;&#21508;&#31181;&#22823;&#35268;&#27169;&#25968;&#25454;&#12290;&#25968;&#25454;&#30340;&#24322;&#36136;&#24615;&#26159;&#25193;&#22823;&#35768;&#22810;&#20998;&#24067;&#24335;&#23398;&#20064;&#33539;&#20363;&#30340;&#19968;&#20010;&#20027;&#35201;&#29942;&#39048;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#24322;&#26500;&#25968;&#25454;&#21487;&#33021;&#20197;&#20855;&#26377;&#20849;&#20139;&#32467;&#26500;&#30340;&#38598;&#32676;&#24418;&#24335;&#29983;&#25104;&#65292;&#20363;&#22914;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#19968;&#20010;&#20849;&#21516;&#30340;&#28508;&#21464;&#37327;&#25511;&#21046;&#30528;&#23458;&#25143;&#31471;&#29983;&#25104;&#30340;&#25152;&#26377;&#26679;&#26412;&#30340;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#33258;&#28982;&#20250;&#38382;&#22312;&#20998;&#24067;&#24335;&#25968;&#25454;&#20013;&#22914;&#20309;&#21033;&#29992;&#28508;&#22312;&#30340;&#38598;&#32676;&#32467;&#26500;&#26469;&#25913;&#36827;&#23398;&#20064;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20197;&#20272;&#35745;&#19968;&#20010;&#20855;&#26377;&#20004;&#20010;&#20998;&#37327;&#30340;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#38382;&#39064;&#30340;d&#32500;&#21442;&#25968;&#30340;&#29305;&#20363;&#20026;&#20363;&#65292;&#20854;&#20013;&#27599;&#20010;&#33410;&#28857;&#29983;&#25104;&#20855;&#26377;&#20849;&#20139;&#28508;&#21464;&#37327;&#30340;n&#20010;&#26679;&#26412;&#12290;&#25105;&#20204;&#20351;&#29992;&#20247;&#25152;&#21608;&#30693;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26041;&#27861;&#26469;&#20174;m&#20010;&#33410;&#28857;&#20013;&#20272;&#35745;&#26368;&#22823;&#20284;&#28982;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from $m$ b
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#35770;&#25991;&#20840;&#38754;&#22238;&#39038;&#20102;&#26080;&#30417;&#30563;&#23398;&#20064;&#22270;&#20687;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#24182;&#24635;&#32467;&#20102;&#26368;&#26032;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#20026;&#28145;&#20837;&#30740;&#31350;&#34920;&#31034;&#23398;&#20064;&#39046;&#22495;&#30340;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#36215;&#28857;&#12290;</title><link>http://arxiv.org/abs/2308.11455</link><description>&lt;p&gt;
&#12298;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#32508;&#36848;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Survey on Self-Supervised Representation Learning. (arXiv:2308.11455v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11455
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#35770;&#25991;&#20840;&#38754;&#22238;&#39038;&#20102;&#26080;&#30417;&#30563;&#23398;&#20064;&#22270;&#20687;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#24182;&#24635;&#32467;&#20102;&#26368;&#26032;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#20026;&#28145;&#20837;&#30740;&#31350;&#34920;&#31034;&#23398;&#20064;&#39046;&#22495;&#30340;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20010;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#65292;&#23398;&#20064;&#26377;&#24847;&#20041;&#30340;&#34920;&#31034;&#26159;&#35768;&#22810;&#20219;&#21153;&#30340;&#26680;&#24515;&#12290;&#26368;&#36817;&#24341;&#20837;&#20102;&#35768;&#22810;&#20801;&#35768;&#26080;&#30417;&#30563;&#23398;&#20064;&#22270;&#20687;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#34920;&#31034;&#21487;&#20197;&#24212;&#29992;&#20110;&#20998;&#31867;&#25110;&#29289;&#20307;&#26816;&#27979;&#31561;&#19979;&#28216;&#20219;&#21153;&#20013;&#12290;&#36825;&#20123;&#34920;&#31034;&#30340;&#36136;&#37327;&#25509;&#36817;&#20110;&#26377;&#30417;&#30563;&#23398;&#20064;&#65292;&#32780;&#19981;&#38656;&#35201;&#26631;&#35760;&#30340;&#22270;&#20687;&#12290;&#26412;&#32508;&#36848;&#35770;&#25991;&#20197;&#32479;&#19968;&#30340;&#31526;&#21495;&#34920;&#31034;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#22238;&#39038;&#65292;&#25351;&#20986;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#30456;&#20284;&#24615;&#21644;&#24046;&#24322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#27861;&#65292;&#23558;&#36825;&#20123;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32508;&#36848;&#36890;&#36807;&#20803;&#20998;&#26512;&#24635;&#32467;&#20102;&#25991;&#29486;&#20013;&#26368;&#26032;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32508;&#36848;&#26088;&#22312;&#20026;&#24076;&#26395;&#28145;&#20837;&#30740;&#31350;&#34920;&#31034;&#23398;&#20064;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#25552;&#20379;&#19968;&#20010;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning meaningful representations is at the heart of many tasks in the field of modern machine learning. Recently, a lot of methods were introduced that allow learning of image representations without supervision. These representations can then be used in downstream tasks like classification or object detection. The quality of these representations is close to supervised learning, while no labeled images are needed. This survey paper provides a comprehensive review of these methods in a unified notation, points out similarities and differences of these methods, and proposes a taxonomy which sets these methods in relation to each other. Furthermore, our survey summarizes the most-recent experimental results reported in the literature in form of a meta-study. Our survey is intended as a starting point for researchers and practitioners who want to dive into the field of representation learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#31243;&#26469;&#25506;&#32034;&#21644;&#20998;&#26512;&#21307;&#30103;&#25968;&#25454;&#20013;&#30340;&#25289;&#33298;&#33945;&#38598;&#21512;&#27169;&#22411;&#65292;&#20174;&#32780;&#36229;&#36234;&#20256;&#32479;&#21333;&#19968;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;"&#25289;&#33298;&#33945;&#26816;&#27979;"&#31639;&#27861;&#35782;&#21035;&#20986;&#38598;&#21512;&#20013;&#26368;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.11446</link><description>&lt;p&gt;
&#25506;&#32034;&#25289;&#33298;&#33945;&#38598;&#21512;&#26377;&#21161;&#20110;&#21307;&#30103;&#25968;&#25454;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Exploration of Rashomon Set Assists Explanations for Medical Data. (arXiv:2308.11446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#31243;&#26469;&#25506;&#32034;&#21644;&#20998;&#26512;&#21307;&#30103;&#25968;&#25454;&#20013;&#30340;&#25289;&#33298;&#33945;&#38598;&#21512;&#27169;&#22411;&#65292;&#20174;&#32780;&#36229;&#36234;&#20256;&#32479;&#21333;&#19968;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;"&#25289;&#33298;&#33945;&#26816;&#27979;"&#31639;&#27861;&#35782;&#21035;&#20986;&#38598;&#21512;&#20013;&#26368;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#24314;&#27169;&#36807;&#31243;&#36890;&#24120;&#20197;&#36873;&#25321;&#26368;&#22823;&#21270;&#26576;&#20010;&#24615;&#33021;&#25351;&#26631;&#30340;&#21333;&#19968;&#27169;&#22411;&#20316;&#20026;&#26368;&#32456;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#23545;&#31245;&#24494;&#24046;&#19968;&#20123;&#30340;&#27169;&#22411;&#36827;&#34892;&#26356;&#28145;&#20837;&#30340;&#20998;&#26512;&#34987;&#24573;&#35270;&#12290;&#23588;&#20854;&#22312;&#21307;&#30103;&#21644;&#20581;&#24247;&#30740;&#31350;&#20013;&#65292;&#30446;&#26631;&#19981;&#20165;&#20165;&#26159;&#39044;&#27979;&#65292;&#36824;&#21253;&#25324;&#20135;&#29983;&#26377;&#20215;&#20540;&#30340;&#27934;&#23519;&#65292;&#20165;&#20165;&#20381;&#36182;&#24615;&#33021;&#25351;&#26631;&#21487;&#33021;&#20250;&#23548;&#33268;&#35823;&#23548;&#25110;&#19981;&#23436;&#25972;&#30340;&#32467;&#35770;&#12290;&#24403;&#22788;&#29702;&#19968;&#32452;&#24615;&#33021;&#25509;&#36817;&#26368;&#20248;&#30340;&#27169;&#22411;&#38598;&#21512;&#26102;&#65292;&#21363;&#25152;&#35859;&#30340;"&#25289;&#33298;&#33945;&#38598;&#21512;"&#65292;&#36825;&#20010;&#38382;&#39064;&#23588;&#20026;&#31361;&#20986;&#12290;&#36825;&#26679;&#30340;&#38598;&#21512;&#21487;&#33021;&#21253;&#21547;&#25551;&#36848;&#25968;&#25454;&#30340;&#19981;&#21516;&#26041;&#24335;&#30340;&#27169;&#22411;&#65292;&#38656;&#35201;&#36827;&#34892;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#31243;&#26469;&#25506;&#32034;&#25289;&#33298;&#33945;&#38598;&#21512;&#27169;&#22411;&#65292;&#25193;&#23637;&#20102;&#20256;&#32479;&#24314;&#27169;&#26041;&#27861;&#12290;&#26680;&#24515;&#26159;&#36890;&#36807;&#24341;&#20837;&#30340;"&#25289;&#33298;&#33945;&#26816;&#27979;"&#31639;&#27861;&#26469;&#35782;&#21035;&#25289;&#33298;&#33945;&#38598;&#21512;&#20013;&#26368;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorit
&lt;/p&gt;</description></item><item><title>&#26412;&#20070;&#31995;&#32479;&#30740;&#31350;&#20102;&#22522;&#20110;&#24352;&#37327;&#30340;&#22238;&#24402;&#27169;&#22411;&#21450;&#20854;&#24212;&#29992;&#65292;&#24182;&#35206;&#30422;&#20102;&#22522;&#26412;&#30693;&#35782;&#12289;&#26680;&#24515;&#24605;&#24819;&#21644;&#29702;&#35770;&#29305;&#24615;&#12290;&#35835;&#32773;&#21487;&#20197;&#23398;&#20064;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#35299;&#20915;&#22810;&#36335;&#24452;&#25968;&#25454;&#22238;&#24402;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2308.11419</link><description>&lt;p&gt;
&#24352;&#37327;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Tensor Regression. (arXiv:2308.11419v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#20070;&#31995;&#32479;&#30740;&#31350;&#20102;&#22522;&#20110;&#24352;&#37327;&#30340;&#22238;&#24402;&#27169;&#22411;&#21450;&#20854;&#24212;&#29992;&#65292;&#24182;&#35206;&#30422;&#20102;&#22522;&#26412;&#30693;&#35782;&#12289;&#26680;&#24515;&#24605;&#24819;&#21644;&#29702;&#35770;&#29305;&#24615;&#12290;&#35835;&#32773;&#21487;&#20197;&#23398;&#20064;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#35299;&#20915;&#22810;&#36335;&#24452;&#25968;&#25454;&#22238;&#24402;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#24402;&#20998;&#26512;&#26159;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#37325;&#35201;&#30740;&#31350;&#26041;&#21521;&#65292;&#26088;&#22312;&#25506;&#32034;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#36890;&#24120;&#20351;&#29992;&#21521;&#37327;&#34920;&#31034;&#12290;&#39640;&#32500;&#25968;&#25454;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#27668;&#20505;&#23398;&#21644;&#31038;&#20132;&#32593;&#32476;&#31561;&#25216;&#26415;&#20013;&#30340;&#20986;&#29616;&#32473;&#20256;&#32479;&#25968;&#25454;&#34920;&#31034;&#26041;&#27861;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20316;&#20026;&#21521;&#37327;&#30340;&#39640;&#32500;&#25193;&#23637;&#65292;&#24352;&#37327;&#34987;&#35270;&#20026;&#39640;&#32500;&#25968;&#25454;&#30340;&#33258;&#28982;&#34920;&#31034;&#12290;&#26412;&#20070;&#31995;&#32479;&#22320;&#30740;&#31350;&#21644;&#20998;&#26512;&#20102;&#22522;&#20110;&#24352;&#37327;&#30340;&#22238;&#24402;&#27169;&#22411;&#21450;&#20854;&#22312;&#36817;&#24180;&#26469;&#30340;&#24212;&#29992;&#12290;&#23427;&#23545;&#29616;&#26377;&#30340;&#22522;&#20110;&#24352;&#37327;&#30340;&#22238;&#24402;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#32452;&#21644;&#35828;&#26126;&#65292;&#24182;&#28085;&#30422;&#20102;&#22823;&#22810;&#25968;&#22522;&#20110;&#24352;&#37327;&#30340;&#22238;&#24402;&#26041;&#27861;&#30340;&#22522;&#26412;&#30693;&#35782;&#12289;&#26680;&#24515;&#24605;&#24819;&#21644;&#29702;&#35770;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#35835;&#32773;&#36824;&#21487;&#20197;&#23398;&#20064;&#22914;&#20309;&#20351;&#29992;&#29616;&#26377;&#30340;&#22522;&#20110;&#24352;&#37327;&#30340;&#22238;&#24402;&#26041;&#27861;&#35299;&#20915;&#20855;&#20307;&#30340;&#22810;&#36335;&#24452;&#25968;&#25454;&#22238;&#24402;&#20219;&#21153;&#65292;&#24212;&#36873;&#25321;&#21738;&#20123;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;&#20351;&#29992;&#21738;&#20123;&#36719;&#20214;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regression analysis is a key area of interest in the field of data analysis and machine learning which is devoted to exploring the dependencies between variables, often using vectors. The emergence of high dimensional data in technologies such as neuroimaging, computer vision, climatology and social networks, has brought challenges to traditional data representation methods. Tensors, as high dimensional extensions of vectors, are considered as natural representations of high dimensional data. In this book, the authors provide a systematic study and analysis of tensor-based regression models and their applications in recent years. It groups and illustrates the existing tensor-based regression methods and covers the basics, core ideas, and theoretical characteristics of most tensor-based regression methods. In addition, readers can learn how to use existing tensor-based regression methods to solve specific regression tasks with multiway data, what datasets can be selected, and what softw
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#36830;&#32493;&#35780;&#20998;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#20998;&#24067;&#19981;&#21464;&#20844;&#24179;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#37322;&#24230;&#37327;&#32467;&#26524;&#24182;&#36866;&#29992;&#20110;&#27604;&#36739;&#19981;&#21516;&#27169;&#22411;&#12289;&#25968;&#25454;&#38598;&#25110;&#26102;&#38388;&#28857;&#20043;&#38388;&#30340;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2308.11375</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#20998;&#24067;&#19981;&#21464;&#20844;&#24179;&#24615;&#24230;&#37327;&#26041;&#27861;&#23545;&#20110;&#36830;&#32493;&#35780;&#20998;
&lt;/p&gt;
&lt;p&gt;
Interpretable Distribution-Invariant Fairness Measures for Continuous Scores. (arXiv:2308.11375v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11375
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#36830;&#32493;&#35780;&#20998;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#20998;&#24067;&#19981;&#21464;&#20844;&#24179;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#37322;&#24230;&#37327;&#32467;&#26524;&#24182;&#36866;&#29992;&#20110;&#27604;&#36739;&#19981;&#21516;&#27169;&#22411;&#12289;&#25968;&#25454;&#38598;&#25110;&#26102;&#38388;&#28857;&#20043;&#38388;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#20844;&#24179;&#24615;&#24230;&#37327;&#36890;&#24120;&#22312;&#20108;&#20803;&#20915;&#31574;&#30340;&#32972;&#26223;&#19979;&#36827;&#34892;&#35752;&#35770;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#21040;&#36830;&#32493;&#35780;&#20998;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#22522;&#20110;ROC&#30340;&#24230;&#37327;&#26041;&#27861;&#20027;&#35201;&#29992;&#20110;&#27492;&#30446;&#30340;&#12290;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#20381;&#36182;&#20110;&#35780;&#20998;&#30340;&#20998;&#24067;&#65292;&#19981;&#36866;&#29992;&#20110;&#25490;&#21517;&#20219;&#21153;&#65292;&#25110;&#32773;&#23427;&#20204;&#30340;&#25928;&#26524;&#22823;&#23567;&#19981;&#21487;&#35299;&#37322;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#36830;&#32493;&#35780;&#20998;&#30340;&#20998;&#24067;&#19981;&#21464;&#20844;&#24179;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#20855;&#26377;&#21512;&#29702;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#26041;&#27861;&#26131;&#20110;&#35745;&#31639;&#65292;&#24182;&#36866;&#29992;&#20110;&#37327;&#21270;&#21644;&#35299;&#37322;&#32676;&#20307;&#24046;&#24322;&#30340;&#24378;&#24230;&#65292;&#20197;&#21450;&#27604;&#36739;&#19981;&#21516;&#27169;&#22411;&#12289;&#25968;&#25454;&#38598;&#25110;&#26102;&#38388;&#28857;&#20043;&#38388;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29616;&#26377;&#35780;&#20998;&#20844;&#24179;&#24615;&#24230;&#37327;&#26041;&#27861;&#30340;&#19981;&#21516;&#26063;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#20998;&#24067;&#19981;&#21464;&#20844;&#24179;&#24615;&#24230;&#37327;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#22240;&#20026;&#23427;&#20204;&#26356;&#26126;&#30830;&#65292;&#24182;&#19988;&#21487;&#20197;&#37327;&#21270;&#26174;&#33879;&#30340;&#20559;&#24046;&#65292;&#32780;ROC-based&#19981;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measures of algorithmic fairness are usually discussed in the context of binary decisions. We extend the approach to continuous scores. So far, ROC-based measures have mainly been suggested for this purpose. Other existing methods depend heavily on the distribution of scores, are unsuitable for ranking tasks, or their effect sizes are not interpretable. Here, we propose a distributionally invariant version of fairness measures for continuous scores with a reasonable interpretation based on the Wasserstein distance. Our measures are easily computable and well suited for quantifying and interpreting the strength of group disparities as well as for comparing biases across different models, datasets, or time points. We derive a link between the different families of existing fairness measures for scores and show that the proposed distributionally invariant fairness measures outperform ROC-based fairness measures because they are more explicit and can quantify significant biases that ROC-ba
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#32454;&#20998;&#39044;&#27979;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#39044;&#27979;&#36890;&#32960;&#30340;&#26377;&#25928;&#24615;&#65292;&#21457;&#29616;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#29305;&#21035;&#22312;&#39044;&#27979;&#32454;&#20998;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2308.11173</link><description>&lt;p&gt;
&#20351;&#29992;&#32454;&#20998;&#21644;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#36890;&#32960;
&lt;/p&gt;
&lt;p&gt;
Forecasting inflation using disaggregates and machine learning. (arXiv:2308.11173v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#32454;&#20998;&#39044;&#27979;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#39044;&#27979;&#36890;&#32960;&#30340;&#26377;&#25928;&#24615;&#65292;&#21457;&#29616;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#29305;&#21035;&#22312;&#39044;&#27979;&#32454;&#20998;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20123;&#39044;&#27979;&#36890;&#32960;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#32454;&#20998;&#39044;&#27979;-&#22312;&#25991;&#29486;&#20013;&#20063;&#34987;&#31216;&#20026;&#33258;&#19979;&#32780;&#19978;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#20197;&#24052;&#35199;&#20026;&#26696;&#20363;&#65292;&#32771;&#34385;&#20102;&#19981;&#21516;&#31243;&#24230;&#30340;&#36890;&#32960;&#32454;&#20998;&#65292;&#24182;&#37319;&#29992;&#20102;&#19968;&#31995;&#21015;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#25216;&#26415;&#20197;&#21450;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#22788;&#29702;&#26356;&#22810;&#30340;&#39044;&#27979;&#22240;&#23376;&#12290;&#23545;&#20110;&#35768;&#22810;&#39044;&#27979;&#26102;&#38388;&#27573;&#65292;&#32454;&#20998;&#39044;&#27979;&#30340;&#32858;&#21512;&#25928;&#26524;&#19982;&#22522;&#20110;&#35843;&#26597;&#30340;&#39044;&#26399;&#21644;&#30452;&#25509;&#20351;&#29992;&#24635;&#20307;&#36827;&#34892;&#39044;&#27979;&#30340;&#27169;&#22411;&#19968;&#26679;&#22909;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#22312;&#39044;&#27979;&#32454;&#20998;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#22312;&#36890;&#32960;&#39044;&#27979;&#20013;&#21033;&#29992;&#25968;&#25454;&#20016;&#23500;&#30340;&#29615;&#22659;&#20013;&#30340;&#27169;&#22411;&#30340;&#22909;&#22788;&#65292;&#21253;&#25324;&#20174;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20013;&#32858;&#21512;&#32454;&#20998;&#39044;&#27979;&#65292;&#23588;&#20854;&#26159;&#22312;&#27874;&#21160;&#26102;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper examines the effectiveness of several forecasting methods for predicting inflation, focusing on aggregating disaggregated forecasts - also known in the literature as the bottom-up approach. Taking the Brazilian case as an application, we consider different disaggregation levels for inflation and employ a range of traditional time series techniques as well as linear and nonlinear machine learning (ML) models to deal with a larger number of predictors. For many forecast horizons, the aggregation of disaggregated forecasts performs just as well survey-based expectations and models that generate forecasts using the aggregate directly. Overall, ML methods outperform traditional time series models in predictive accuracy, with outstanding performance in forecasting disaggregates. Our results reinforce the benefits of using models in a data-rich environment for inflation forecasting, including aggregating disaggregated forecasts from ML techniques, mainly during volatile periods. St
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#20998;&#31867;&#31639;&#27861;&#23545;&#20110;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.11138</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#31995;&#32479;&#24322;&#24120;&#30340;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NLP-based detection of systematic anomalies among the narratives of consumer complaints. (arXiv:2308.11138v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#20998;&#31867;&#31639;&#27861;&#23545;&#20110;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#65292;&#31616;&#31216;&#20026;&#31995;&#32479;&#24322;&#24120;&#12290;&#23613;&#31649;&#20998;&#31867;&#31639;&#27861;&#34987;&#29992;&#20110;&#26816;&#27979;&#26126;&#26174;&#30340;&#24322;&#24120;&#65292;&#20294;&#22312;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#24773;&#20917;&#19979;&#65292;&#31639;&#27861;&#21487;&#33021;&#20250;&#22240;&#20026;&#21508;&#31181;&#21407;&#22240;&#32780;&#22833;&#25928;&#65292;&#21253;&#25324;&#25216;&#26415;&#21407;&#22240;&#21644;&#20154;&#24037;&#20998;&#26512;&#24072;&#30340;&#33258;&#28982;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#22312;&#20998;&#31867;&#20043;&#21518;&#30340;&#19979;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#19968;&#31181;&#31639;&#27861;&#26469;&#26816;&#27979;&#31995;&#32479;&#24322;&#24120;&#12290;&#25105;&#20204;&#20351;&#29992;&#28040;&#36153;&#32773;&#37329;&#34701;&#20445;&#25252;&#23616;&#30340;&#28040;&#36153;&#32773;&#25237;&#35785;&#25968;&#25454;&#24211;&#20013;&#30340;&#25237;&#35785;&#21465;&#36848;&#26469;&#35828;&#26126;&#25972;&#20010;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop an NLP-based procedure for detecting systematic nonmeritorious consumer complaints, simply called systematic anomalies, among complaint narratives. While classification algorithms are used to detect pronounced anomalies, in the case of smaller and frequent systematic anomalies, the algorithms may falter due to a variety of reasons, including technical ones as well as natural limitations of human analysts. Therefore, as the next step after classification, we convert the complaint narratives into quantitative data, which are then analyzed using an algorithm for detecting systematic anomalies. We illustrate the entire procedure using complaint narratives from the Consumer Complaint Database of the Consumer Financial Protection Bureau.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38169;&#35823;&#30456;&#20851;&#24615;&#30340;&#21457;&#29983;&#21407;&#22240;&#20197;&#21450;&#20854;&#23545;&#26631;&#20934;ERM&#22522;&#32447;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#36825;&#20123;&#21407;&#22240;&#19982;&#27169;&#22411;&#35774;&#35745;&#36873;&#25321;&#20043;&#38388;&#30340;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2308.11043</link><description>&lt;p&gt;
&#38169;&#35823;&#30340;&#30456;&#20851;&#24615;&#21450;&#20854;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Spurious Correlations and Where to Find Them. (arXiv:2308.11043v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38169;&#35823;&#30456;&#20851;&#24615;&#30340;&#21457;&#29983;&#21407;&#22240;&#20197;&#21450;&#20854;&#23545;&#26631;&#20934;ERM&#22522;&#32447;&#30340;&#24433;&#21709;&#65292;&#24182;&#35266;&#23519;&#21040;&#20102;&#36825;&#20123;&#21407;&#22240;&#19982;&#27169;&#22411;&#35774;&#35745;&#36873;&#25321;&#20043;&#38388;&#30340;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38169;&#35823;&#30340;&#30456;&#20851;&#24615;&#25351;&#30340;&#26159;&#27169;&#22411;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#19981;&#21487;&#38752;&#30340;&#29305;&#24449;&#65292;&#26159;&#25968;&#25454;&#39537;&#21160;&#23398;&#20064;&#30340;&#19968;&#20010;&#24050;&#30693;&#32570;&#38519;&#12290;&#23613;&#31649;&#24050;&#32463;&#26377;&#20960;&#31181;&#31639;&#27861;&#25552;&#20986;&#26469;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#25105;&#20204;&#36824;&#27809;&#26377;&#33021;&#22815;&#20849;&#21516;&#25512;&#23548;&#20986;&#38169;&#35823;&#30456;&#20851;&#24615;&#30340;&#25351;&#26631;&#12290;&#22240;&#27492;&#65292;&#22522;&#20110;&#29420;&#31435;&#20551;&#35774;&#26500;&#24314;&#30340;&#35299;&#20915;&#26041;&#26696;&#26080;&#27861;&#20987;&#36133;&#31616;&#21333;&#30340;ERM&#22522;&#32447;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20123;&#24120;&#35265;&#30340;&#38169;&#35823;&#30456;&#20851;&#24615;&#20986;&#29616;&#32972;&#21518;&#30340;&#20551;&#35774;&#65292;&#24182;&#20351;&#29992;&#20174;&#22240;&#26524;&#22270;&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#30740;&#31350;&#23427;&#20204;&#23545;&#26631;&#20934;ERM&#22522;&#32447;&#30340;&#24433;&#21709;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#20123;&#20551;&#35774;&#21644;&#27169;&#22411;&#35774;&#35745;&#36873;&#25321;&#20043;&#38388;&#30340;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spurious correlations occur when a model learns unreliable features from the data and are a well-known drawback of data-driven learning. Although there are several algorithms proposed to mitigate it, we are yet to jointly derive the indicators of spurious correlations. As a result, the solutions built upon standalone hypotheses fail to beat simple ERM baselines. We collect some of the commonly studied hypotheses behind the occurrence of spurious correlations and investigate their influence on standard ERM baselines using synthetic datasets generated from causal graphs. Subsequently, we observe patterns connecting these hypotheses and model design choices.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#21487;&#20449;&#21306;&#38388;&#65292;&#33021;&#22815;&#23454;&#29616;&#20219;&#24847;&#39044;&#20808;&#25351;&#23450;&#30340;&#21487;&#20449;&#27700;&#24179;&#12290;&#36890;&#36807;&#24314;&#31435;&#36125;&#21494;&#26031;&#26368;&#39640;&#21518;&#39564;&#23494;&#24230;&#21487;&#20449;&#21306;&#38388;&#19982;Neyman-Pearson&#24341;&#29702;&#20043;&#38388;&#30340;&#31616;&#21333;&#32852;&#31995;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38543;&#26426;&#20915;&#31574;&#35268;&#21017;&#26469;&#35299;&#20915;&#31163;&#25955;&#21487;&#20449;&#27700;&#24179;&#20043;&#38388;&#30340;&#31354;&#38553;&#65292;&#24182;&#19988;&#24320;&#21457;&#20102;&#8220;&#26041;&#21521;&#30424;&#22270;&#8221;&#26469;&#21487;&#35270;&#21270;&#20998;&#31867;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.11037</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#31867;&#21644;&#27169;&#24335;&#35782;&#21035;&#30340;&#31934;&#30830;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
On Exact Bayesian Credible Sets for Classification and Pattern Recognition. (arXiv:2308.11037v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#21487;&#20449;&#21306;&#38388;&#65292;&#33021;&#22815;&#23454;&#29616;&#20219;&#24847;&#39044;&#20808;&#25351;&#23450;&#30340;&#21487;&#20449;&#27700;&#24179;&#12290;&#36890;&#36807;&#24314;&#31435;&#36125;&#21494;&#26031;&#26368;&#39640;&#21518;&#39564;&#23494;&#24230;&#21487;&#20449;&#21306;&#38388;&#19982;Neyman-Pearson&#24341;&#29702;&#20043;&#38388;&#30340;&#31616;&#21333;&#32852;&#31995;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38543;&#26426;&#20915;&#31574;&#35268;&#21017;&#26469;&#35299;&#20915;&#31163;&#25955;&#21487;&#20449;&#27700;&#24179;&#20043;&#38388;&#30340;&#31354;&#38553;&#65292;&#24182;&#19988;&#24320;&#21457;&#20102;&#8220;&#26041;&#21521;&#30424;&#22270;&#8221;&#26469;&#21487;&#35270;&#21270;&#20998;&#31867;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#30340;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#23450;&#20041;&#36890;&#24120;&#26080;&#27861;&#36798;&#21040;&#20219;&#24847;&#39044;&#20808;&#25351;&#23450;&#30340;&#21487;&#20449;&#27700;&#24179;&#12290;&#23545;&#20110;&#20998;&#31867;&#38382;&#39064;&#65292;&#36825;&#20010;&#32570;&#28857;&#23588;&#20026;&#20005;&#37325;&#65292;&#22240;&#20026;&#21482;&#26377;&#26377;&#38480;&#20010;&#21487;&#23454;&#29616;&#30340;&#21487;&#20449;&#27700;&#24179;&#12290;&#22240;&#27492;&#65292;&#36804;&#20170;&#20026;&#27490;&#27809;&#26377;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#21487;&#20197;&#26500;&#24314;&#19968;&#20010;&#31934;&#30830;&#30340;&#20998;&#31867;&#21487;&#20449;&#21306;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#21487;&#20449;&#21306;&#38388;&#65292;&#21487;&#20197;&#23454;&#29616;&#20219;&#20309;&#39044;&#20808;&#25351;&#23450;&#30340;&#21487;&#20449;&#27700;&#24179;&#12290;&#20851;&#38190;&#27934;&#23519;&#26159;&#36125;&#21494;&#26031;&#26368;&#39640;&#21518;&#39564;&#23494;&#24230;&#21487;&#20449;&#21306;&#38388;&#21644;Neyman-Pearson&#24341;&#29702;&#20043;&#38388;&#30340;&#31616;&#21333;&#32852;&#31995;&#65292;&#22312;&#25105;&#20204;&#25152;&#30693;&#36947;&#30340;&#33539;&#22260;&#20869;&#65292;&#36825;&#19968;&#28857;&#20043;&#21069;&#36824;&#26410;&#34987;&#27880;&#24847;&#21040;&#12290;&#21033;&#29992;&#36825;&#20010;&#32852;&#31995;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38543;&#26426;&#20915;&#31574;&#35268;&#21017;&#26469;&#22635;&#34917;&#31163;&#25955;&#30340;&#21487;&#20449;&#27700;&#24179;&#20043;&#38388;&#30340;&#31354;&#38553;&#12290;&#38500;&#20102;&#36825;&#20010;&#26041;&#27861;&#35770;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#8220;&#26041;&#21521;&#30424;&#22270;&#8221;&#26469;&#34920;&#31034;&#21487;&#20449;&#21306;&#38388;&#65292;&#36825;&#22312;&#21487;&#35270;&#21270;&#20998;&#31867;&#30340;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#38750;&#24120;&#26377;&#29992;&#12290;&#36890;&#36807;&#20026;&#31163;&#25955;&#21442;&#25968;&#24320;&#21457; &#20934;&#30830;&#30340;&#21487;&#20449;&#21306;&#38388;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#21019;&#26032;
&lt;/p&gt;
&lt;p&gt;
The current definition of a Bayesian credible set cannot, in general, achieve an arbitrarily preassigned credible level. This drawback is particularly acute for classification problems, where there are only a finite number of achievable credible levels. As a result, there is as of today no general way to construct an exact credible set for classification. In this paper, we introduce a generalized credible set that can achieve any preassigned credible level. The key insight is a simple connection between the Bayesian highest posterior density credible set and the Neyman--Pearson lemma, which, as far as we know, hasn't been noticed before. Using this connection, we introduce a randomized decision rule to fill the gaps among the discrete credible levels. Accompanying this methodology, we also develop the Steering Wheel Plot to represent the credible set, which is useful in visualizing the uncertainty in classification. By developing the exact credible set for discrete parameters, we make 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#32463;&#27982;&#39044;&#27979;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#21363;&#26102;&#39044;&#27979;&#12289;&#25991;&#26412;&#25968;&#25454;&#12289;&#38754;&#26495;&#21644;&#24352;&#37327;&#25968;&#25454;&#12289;Granger&#22240;&#26524;&#20851;&#31995;&#27979;&#35797;&#12289;&#26102;&#38388;&#24207;&#21015;&#20132;&#21449;&#39564;&#35777;&#21644;&#32463;&#27982;&#25439;&#22833;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2308.10993</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#32463;&#27982;&#39044;&#27979;&#20013;&#30340;&#35745;&#37327;&#32463;&#27982;&#23398;
&lt;/p&gt;
&lt;p&gt;
Econometrics of Machine Learning Methods in Economic Forecasting. (arXiv:2308.10993v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10993
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35843;&#26597;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#32463;&#27982;&#39044;&#27979;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#21253;&#25324;&#21363;&#26102;&#39044;&#27979;&#12289;&#25991;&#26412;&#25968;&#25454;&#12289;&#38754;&#26495;&#21644;&#24352;&#37327;&#25968;&#25454;&#12289;Granger&#22240;&#26524;&#20851;&#31995;&#27979;&#35797;&#12289;&#26102;&#38388;&#24207;&#21015;&#20132;&#21449;&#39564;&#35777;&#21644;&#32463;&#27982;&#25439;&#22833;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#32463;&#27982;&#39044;&#27979;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#35813;&#35843;&#26597;&#28085;&#30422;&#20102;&#20197;&#19979;&#20027;&#39064;&#65306;&#21363;&#26102;&#39044;&#27979;&#12289;&#25991;&#26412;&#25968;&#25454;&#12289;&#38754;&#26495;&#21644;&#24352;&#37327;&#25968;&#25454;&#12289;&#39640;&#32500;Granger&#22240;&#26524;&#20851;&#31995;&#27979;&#35797;&#12289;&#26102;&#38388;&#24207;&#21015;&#20132;&#21449;&#39564;&#35777;&#12289;&#32463;&#27982;&#25439;&#22833;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper surveys the recent advances in machine learning method for economic forecasting. The survey covers the following topics: nowcasting, textual data, panel and tensor data, high-dimensional Granger causality tests, time series cross-validation, classification with economic losses.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27867;&#21270;&#27714;&#21644;&#27744;&#21270;&#26041;&#27861;&#65288;GSP&#65289;&#29992;&#20110;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#12290;GSP&#36890;&#36807;&#36873;&#25321;&#35821;&#20041;&#23454;&#20307;&#30340;&#23376;&#38598;&#65292;&#23398;&#20064;&#24573;&#30053;&#26080;&#29992;&#20449;&#24687;&#65292;&#24182;&#23398;&#20064;&#27599;&#20010;&#23454;&#20307;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#20840;&#23616;&#24179;&#22343;&#27744;&#21270;&#65288;GAP&#65289;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.09228</link><description>&lt;p&gt;
&#27867;&#21270;&#30340;&#27714;&#21644;&#27744;&#21270;&#29992;&#20110;&#24230;&#37327;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generalized Sum Pooling for Metric Learning. (arXiv:2308.09228v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09228
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27867;&#21270;&#27714;&#21644;&#27744;&#21270;&#26041;&#27861;&#65288;GSP&#65289;&#29992;&#20110;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#12290;GSP&#36890;&#36807;&#36873;&#25321;&#35821;&#20041;&#23454;&#20307;&#30340;&#23376;&#38598;&#65292;&#23398;&#20064;&#24573;&#30053;&#26080;&#29992;&#20449;&#24687;&#65292;&#24182;&#23398;&#20064;&#27599;&#20010;&#23454;&#20307;&#30340;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#20840;&#23616;&#24179;&#22343;&#27744;&#21270;&#65288;GAP&#65289;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#30340;&#24120;&#35265;&#26550;&#26500;&#36873;&#25321;&#26159;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#21518;&#36319;&#20840;&#23616;&#24179;&#22343;&#27744;&#21270;&#65288;GAP&#65289;&#12290;&#23613;&#31649;&#31616;&#21333;&#65292;GAP&#26159;&#19968;&#31181;&#39640;&#24230;&#26377;&#25928;&#30340;&#20449;&#24687;&#32858;&#21512;&#26041;&#24335;&#12290;&#23545;&#20110;GAP&#30340;&#26377;&#25928;&#24615;&#65292;&#19968;&#31181;&#21487;&#33021;&#30340;&#35299;&#37322;&#26159;&#23558;&#27599;&#20010;&#29305;&#24449;&#21521;&#37327;&#35270;&#20026;&#34920;&#31034;&#19981;&#21516;&#35821;&#20041;&#23454;&#20307;&#30340;&#38598;&#21512;&#65292;&#32780;GAP&#21017;&#26159;&#23427;&#20204;&#30340;&#20984;&#32452;&#21512;&#12290;&#22312;&#36825;&#20010;&#35270;&#35282;&#19979;&#65292;&#25105;&#20204;&#27867;&#21270;&#20102;GAP&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#23398;&#20064;&#30340;&#27867;&#21270;&#27714;&#21644;&#27744;&#21270;&#26041;&#27861;&#65288;GSP&#65289;&#12290;GSP&#36890;&#36807;&#20004;&#31181;&#19981;&#21516;&#30340;&#33021;&#21147;&#25913;&#36827;&#20102;GAP&#65306;i&#65289;&#33021;&#22815;&#36873;&#25321;&#35821;&#20041;&#23454;&#20307;&#30340;&#23376;&#38598;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#23398;&#20064;&#24573;&#30053;&#26080;&#29992;&#20449;&#24687;&#65307;ii&#65289;&#23398;&#20064;&#19982;&#27599;&#20010;&#23454;&#20307;&#30340;&#37325;&#35201;&#24615;&#23545;&#24212;&#30340;&#26435;&#37325;&#12290;&#24418;&#24335;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29109;&#24179;&#28369;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#26159;GAP&#30340;&#20005;&#26684;&#27867;&#21270;&#65292;&#21363;&#38382;&#39064;&#30340;&#19968;&#20010;&#29305;&#23450;&#23454;&#29616;&#20250;&#24471;&#21040;GAP&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#20855;&#26377;&#35299;&#26512;&#26799;&#24230;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#20316;&#20026;&#30452;&#25509;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common architectural choice for deep metric learning is a convolutional neural network followed by global average pooling (GAP). Albeit simple, GAP is a highly effective way to aggregate information. One possible explanation for the effectiveness of GAP is considering each feature vector as representing a different semantic entity and GAP as a convex combination of them. Following this perspective, we generalize GAP and propose a learnable generalized sum pooling method (GSP). GSP improves GAP with two distinct abilities: i) the ability to choose a subset of semantic entities, effectively learning to ignore nuisance information, and ii) learning the weights corresponding to the importance of each entity. Formally, we propose an entropy-smoothed optimal transport problem and show that it is a strict generalization of GAP, i.e., a specific realization of the problem gives back GAP. We show that this optimization problem enjoys analytical gradients enabling us to use it as a direct lear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;MSDA&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#22495;&#34920;&#31034;&#20026;&#23383;&#20856;&#21407;&#23376;&#30340;Wasserstein&#37325;&#24515;&#26469;&#32531;&#35299;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#12290;&#26681;&#25454;&#35813;&#23383;&#20856;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;MSDA&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#30446;&#26631;&#22495;&#26631;&#35760;&#26679;&#26412;&#30340;&#37325;&#26500;&#21644;&#22312;&#21407;&#23376;&#20998;&#24067;&#19978;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.14953</link><description>&lt;p&gt;
&#22312;Wasserstein&#31354;&#38388;&#20013;&#36890;&#36807;&#25968;&#25454;&#38598;&#23383;&#20856;&#23398;&#20064;&#36827;&#34892;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;MSDA&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#22495;&#34920;&#31034;&#20026;&#23383;&#20856;&#21407;&#23376;&#30340;Wasserstein&#37325;&#24515;&#26469;&#32531;&#35299;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#12290;&#26681;&#25454;&#35813;&#23383;&#20856;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;MSDA&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#30446;&#26631;&#22495;&#26631;&#35760;&#26679;&#26412;&#30340;&#37325;&#26500;&#21644;&#22312;&#21407;&#23376;&#20998;&#24067;&#19978;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#22810;&#28304;&#22495;&#33258;&#36866;&#24212;&#65288;MSDA&#65289;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#26088;&#22312;&#22312;&#20174;&#22810;&#20010;&#26631;&#35760;&#30340;&#28304;&#22495;&#36716;&#31227;&#30693;&#35782;&#21040;&#26410;&#26631;&#35760;&#30340;&#30446;&#26631;&#22495;&#26102;&#32531;&#35299;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23383;&#20856;&#23398;&#20064;&#21644;&#26368;&#20248;&#20256;&#36755;&#30340;&#26032;&#22411;MSDA&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;MSDA&#20013;&#30340;&#27599;&#20010;&#22495;&#35299;&#37322;&#20026;&#32463;&#39564;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#22495;&#34920;&#36798;&#20026;&#23383;&#20856;&#21407;&#23376;&#30340;Wasserstein&#37325;&#24515;&#65292;&#36825;&#20123;&#21407;&#23376;&#26159;&#32463;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#36807;&#23567;&#25209;&#37327;&#23398;&#20064;&#30340;&#31639;&#27861;DaDiL&#65306;&#65288;i&#65289;&#21407;&#23376;&#20998;&#24067;&#65307;&#65288;ii&#65289;&#37325;&#24515;&#22352;&#26631;&#30697;&#38453;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#23383;&#20856;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;MSDA&#26041;&#27861;&#65306;DaDiL-R&#65292;&#22522;&#20110;&#30446;&#26631;&#22495;&#26631;&#35760;&#26679;&#26412;&#30340;&#37325;&#26500;&#65307;DaDiL-E&#65292;&#22522;&#20110;&#22312;&#21407;&#23376;&#20998;&#24067;&#19978;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#12290;&#25105;&#20204;&#22312;3&#20010;&#22522;&#20934;&#27979;&#35797;&#38598;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65306;Caltech-Office&#12289;Office 31&#21644;CRWU&#65292;&#22312;&#20998;&#31867;&#19978;&#25913;&#36827;&#20102;&#20197;&#21069;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;3.15&#65285;&#12289;2.29&#65285;&#21644;7.71&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23376;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#20998;&#23618;&#32467;&#26500;&#34701;&#20837;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20013;&#65292;&#24182;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#26469;&#35774;&#35745;&#26377;&#25928;&#30340;&#20998;&#23376;&#28508;&#22312;&#21521;&#37327;&#65292;&#29992;&#20110;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2307.00623</link><description>&lt;p&gt;
&#20351;&#29992;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#23545;&#20998;&#23376;&#22270;&#36827;&#34892;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Variational Autoencoding Molecular Graphs with Denoising Diffusion Probabilistic Model. (arXiv:2307.00623v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00623
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23376;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#20998;&#23618;&#32467;&#26500;&#34701;&#20837;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20013;&#65292;&#24182;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#26469;&#35774;&#35745;&#26377;&#25928;&#30340;&#20998;&#23376;&#28508;&#22312;&#21521;&#37327;&#65292;&#29992;&#20110;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#33647;&#29289;&#21457;&#29616;&#20013;&#65292;&#35774;&#35745;&#20998;&#23376;&#25551;&#36848;&#31526;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;(VAEs)&#31561;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36890;&#36807;&#35774;&#35745;&#30001;&#20998;&#23376;&#32467;&#26500;&#23548;&#20986;&#30340;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20316;&#20026;&#25551;&#36848;&#31526;&#65292;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#22312;&#21482;&#26377;&#20998;&#23376;&#32467;&#26500;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#24212;&#29992;&#20110;&#36801;&#31227;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;VAE&#30340;&#28508;&#22312;&#21521;&#37327;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#20551;&#35774;&#20026;&#31616;&#21333;&#30340;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#65292;&#32780;&#19988;&#21327;&#26041;&#24046;&#20026;&#38646;&#65292;&#36825;&#21487;&#33021;&#38480;&#21046;&#20102;&#34920;&#31034;&#28508;&#22312;&#29305;&#24449;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23376;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#20998;&#23618;&#32467;&#26500;&#34701;&#20837;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;(DDPM)&#23454;&#29616;&#20102;&#36825;&#19968;&#30446;&#26631;&#12290;&#36890;&#36807;&#19968;&#20123;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#21487;&#20197;&#20026;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#35774;&#35745;&#20986;&#26377;&#25928;&#30340;&#20998;&#23376;&#28508;&#22312;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven drug discovery, designing molecular descriptors is a very important task. Deep generative models such as variational autoencoders (VAEs) offer a potential solution by designing descriptors as probabilistic latent vectors derived from molecular structures. These models can be trained on large datasets, which have only molecular structures, and applied to transfer learning. Nevertheless, the approximate posterior distribution of the latent vectors of the usual VAE assumes a simple multivariate Gaussian distribution with zero covariance, which may limit the performance of representing the latent features. To overcome this limitation, we propose a novel molecular deep generative model that incorporates a hierarchical structure into the probabilistic latent vectors. We achieve this by a denoising diffusion probabilistic model (DDPM). We demonstrate that our model can design effective molecular latent vectors for molecular property prediction from some experiments by small dat
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21033;&#29992;&#31561;&#21387;&#31561;&#28201;&#27969;&#24471;&#21040;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#65292;&#24182;&#22312;&#21333;&#21407;&#23376;&#27700;&#30340;&#32467;&#26230;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.13233</link><description>&lt;p&gt;
&#36890;&#36807;&#31561;&#21387;&#31561;&#28201;&#27969;&#33719;&#24471;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;
&lt;/p&gt;
&lt;p&gt;
Gibbs free energies via isobaric-isothermal flows. (arXiv:2305.13233v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13233
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21033;&#29992;&#31561;&#21387;&#31561;&#28201;&#27969;&#24471;&#21040;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#65292;&#24182;&#22312;&#21333;&#21407;&#23376;&#27700;&#30340;&#32467;&#26230;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32463;&#36807;&#35757;&#32451;&#21487;&#20174;&#31561;&#21387;&#31561;&#28201;&#65288;NPT&#65289;&#38598;&#21512;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#36817;&#20284;&#26041;&#27861;&#26469;&#24471;&#21040;&#23436;&#20840;&#28789;&#27963;&#30340;&#19977;&#26012;&#26230;&#31995;&#32479;&#30340;&#32852;&#21512;&#20998;&#24067;&#21644;&#31890;&#23376;&#22352;&#26631;&#20197;&#36798;&#21040;&#25152;&#38656;&#30340;&#20869;&#37096;&#21387;&#21147;&#12290;&#25105;&#20204;&#23545;&#21333;&#21407;&#23376;&#27700;&#22312;&#31435;&#26041;&#21644;&#20845;&#35282;&#20912;&#30456;&#20013;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#21457;&#29616;&#19982;&#24050;&#24314;&#31435;&#30340;&#22522;&#32447;&#30456;&#27604;&#65292;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#21644;&#20854;&#20182;&#21487;&#35266;&#27979;&#37327;&#30340;&#32467;&#26524;&#23436;&#20840;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a machine-learning model based on normalizing flows that is trained to sample from the isobaric-isothermal (NPT) ensemble. In our approach, we approximate the joint distribution of a fully-flexible triclinic simulation box and particle coordinates to achieve a desired internal pressure. We test our model on monatomic water in the cubic and hexagonal ice phases and find excellent agreement of Gibbs free energies and other observables compared with established baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;P2MPO&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#21644;&#21452;&#37325;&#24754;&#35266;&#30340;&#31574;&#30053;&#20248;&#21270;&#27493;&#39588;&#65292;&#37319;&#29992;&#21452;&#37325;&#24754;&#35266;&#24615;&#21407;&#21017;&#20197;&#20811;&#26381;&#27169;&#22411;&#20559;&#31227;&#31561;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#20551;&#35774;&#19979;&#65292;&#35813;&#26694;&#26550;&#22312;&#25317;&#26377;&#33391;&#22909;&#30340;&#40065;&#26834;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26159;&#20855;&#22791;&#39640;&#25928;&#24615;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.09659</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#40065;&#26834;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65306;&#22522;&#20110;&#21452;&#37325;&#24754;&#35266;&#24615;&#30340;&#36890;&#29992;&#31639;&#27861;&#21644;&#24378;&#20581;&#37096;&#20998;&#35206;&#30422;
&lt;/p&gt;
&lt;p&gt;
Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage. (arXiv:2305.09659v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;P2MPO&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#21644;&#21452;&#37325;&#24754;&#35266;&#30340;&#31574;&#30053;&#20248;&#21270;&#27493;&#39588;&#65292;&#37319;&#29992;&#21452;&#37325;&#24754;&#35266;&#24615;&#21407;&#21017;&#20197;&#20811;&#26381;&#27169;&#22411;&#20559;&#31227;&#31561;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#20551;&#35774;&#19979;&#65292;&#35813;&#26694;&#26550;&#22312;&#25317;&#26377;&#33391;&#22909;&#30340;&#40065;&#26834;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26159;&#20855;&#22791;&#39640;&#25928;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#40065;&#26834;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;&#40065;&#26834;&#31163;&#32447;RL&#65289;&#65292;&#20854;&#26088;&#22312;&#20174;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#32431;&#31929;&#22320;&#25214;&#21040;&#19968;&#20010;&#33021;&#22815;&#22312;&#25200;&#21160;&#29615;&#22659;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#26368;&#20248;&#24378;&#40065;&#26834;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;P2MPO&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#28789;&#27963;&#30340;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#21644;&#21452;&#37325;&#24754;&#35266;&#30340;&#31574;&#30053;&#20248;&#21270;&#27493;&#39588;&#12290;&#21452;&#37325;&#24754;&#35266;&#24615;&#21407;&#21017;&#23545;&#20110;&#20811;&#26381;&#30001;&#34892;&#20026;&#31574;&#30053;&#21644;&#30446;&#26631;&#31574;&#30053;&#23478;&#26063;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#20197;&#21450;&#21517;&#20041;&#27169;&#22411;&#30340;&#25200;&#21160;&#25152;&#24341;&#36215;&#30340;&#20998;&#24067;&#20559;&#31227;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#23545;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#36827;&#34892;&#19968;&#23450;&#20934;&#30830;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;P2MPO&#31639;&#27861;&#22312;&#25317;&#26377;&#33391;&#22909;&#30340;&#40065;&#26834;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26159;&#21487;&#35777;&#26126;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributionally robust offline reinforcement learning (robust offline RL), which seeks to find an optimal robust policy purely from an offline dataset that can perform well in perturbed environments. We propose a generic algorithm framework \underline{D}oubly \underline{P}essimistic \underline{M}odel-based \underline{P}olicy \underline{O}ptimization ($\texttt{P}^2\texttt{MPO}$) for robust offline RL, which features a novel combination of a flexible model estimation subroutine and a doubly pessimistic policy optimization step. The \emph{double pessimism} principle is crucial to overcome the distributional shift incurred by i) the mismatch between behavior policy and the family of target policies; and ii) the perturbation of the nominal model. Under certain accuracy assumptions on the model estimation subroutine, we show that $\texttt{P}^2\texttt{MPO}$ is provably efficient with \emph{robust partial coverage data}, which means that the offline dataset has good coverage of the d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.00700</link><description>&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#21452;&#37325;&#21644;&#21333;&#19968;&#19979;&#38477;&#29616;&#35937;&#65292;&#21450;&#20854;&#22312;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Double and Single Descent in Causal Inference with an Application to High-Dimensional Synthetic Control. (arXiv:2305.00700v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00700
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#37325;&#19979;&#38477;&#29616;&#35937;&#65292;&#32771;&#34385;&#20102;&#39640;&#24230;&#36807;&#21442;&#25968;&#21270;&#30340;&#22240;&#26524;&#25512;&#26029;&#27169;&#22411;&#65292;&#21253;&#25324;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#21512;&#25104;&#25511;&#21046;&#12290;&#22312;&#36825;&#31181;&#27169;&#22411;&#20013;&#65292;&#21487;&#33021;&#23384;&#22312;&#22826;&#22810;&#30340;&#33258;&#30001;&#21442;&#25968;&#65292;&#20197;&#33267;&#20110;&#27169;&#22411;&#21487;&#20197;&#23436;&#32654;&#22320;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#12290;&#26412;&#25991;&#39318;&#20808;&#20197;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20026;&#20363;&#65292;&#30740;&#31350;&#34218;&#36164;&#25968;&#25454;&#30340;&#22635;&#20805;&#65292;&#21457;&#29616;&#27604;&#31616;&#21333;&#27169;&#22411;&#26356;&#22810;&#30340;&#21327;&#21464;&#37327;&#23545;&#20110;&#27169;&#22411;&#24615;&#33021;&#30340;&#25552;&#21319;&#24456;&#26377;&#25928;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25506;&#35752;&#20102;&#22810;&#20010;&#25511;&#21046;&#21333;&#20803;&#30340;&#39640;&#32500;&#21512;&#25104;&#25511;&#21046;&#20272;&#35745;&#24615;&#33021;&#65292;&#21457;&#29616;&#22686;&#21152;&#25511;&#21046;&#21333;&#20803;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#22635;&#20805;&#24615;&#33021;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#39044;&#22788;&#29702;&#25311;&#21512;&#23436;&#32654;&#30340;&#28857;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#29702;&#35770;&#35270;&#35282;&#26469;&#35299;&#37322;&#36825;&#20123;&#39640;&#32500;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21363;&#23558;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#35270;&#20026;&#23545;&#31616;&#21333;&#27169;&#22411;&#30340;&#27169;&#22411;&#24179;&#22343;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider highly over-parametrized models in causal inference, including synthetic control with many control units. In such models, there may be so many free parameters that the model fits the training data perfectly. As a motivating example, we first investigate high-dimensional linear regression for imputing wage data, where we find that models with many more covariates than sample size can outperform simple ones. As our main contribution, we document the performance of high-dimensional synthetic control estimators with many control units. We find that adding control units can help improve imputation performance even beyond the point where the pre-treatment fit is perfect. We then provide a unified theoretical perspective on the performance of these high-dimensional models. Specifically, we show that more complex models can be interpreted as model-averaging estimators over simpler ones, which we 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;Stochastically Extended Adversarial (SEA)&#27169;&#22411;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#23545;&#20110;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#36951;&#25022;&#30028;&#38480;&#20026;O(sqrt(&#963;_{1:T}^2) + sqrt(&#931;_{1:T}^2))&#65292;&#23545;&#20110;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#30028;&#38480;&#20026;O(sqrt(&#963;_{\max}^2) + sqrt(&#931;_{\max}^2))&#12290;</title><link>http://arxiv.org/abs/2302.04552</link><description>&lt;p&gt;
&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;&#36830;&#25509;&#38543;&#26426;&#24615;&#21644;&#23545;&#25239;&#24615;&#22312;&#32447;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization. (arXiv:2302.04552v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;Stochastically Extended Adversarial (SEA)&#27169;&#22411;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#23545;&#20110;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#36951;&#25022;&#30028;&#38480;&#20026;O(sqrt(&#963;_{1:T}^2) + sqrt(&#931;_{1:T}^2))&#65292;&#23545;&#20110;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#30028;&#38480;&#20026;O(sqrt(&#963;_{\max}^2) + sqrt(&#931;_{\max}^2))&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sachs&#31561;&#20154;&#20171;&#32461;&#20102;Stochastically Extended Adversarial (SEA)&#27169;&#22411;&#65292;&#20316;&#20026;&#38543;&#26426;&#24615;&#21644;&#23545;&#25239;&#24615;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#25554;&#20540;&#26041;&#27861;&#12290;&#22312;&#20809;&#28369;&#26465;&#20214;&#19979;&#65292;&#20182;&#20204;&#35777;&#26126;&#20102;&#20048;&#35266;&#30340;Follow-the-Regularized-Leader (FTRL)&#31639;&#27861;&#30340;&#26399;&#26395;&#36951;&#25022;&#20381;&#36182;&#20110;&#20984;&#20989;&#25968;&#30340;&#32047;&#31215;&#38543;&#26426;&#26041;&#24046;&#21644;&#32047;&#31215;&#23545;&#25239;&#21464;&#21270;&#12290;&#23545;&#20110;&#24378;&#20984;&#20989;&#25968;&#65292;&#20182;&#20204;&#20063;&#32473;&#20986;&#20102;&#22522;&#20110;&#26368;&#22823;&#38543;&#26426;&#26041;&#24046;&#21644;&#26368;&#22823;&#23545;&#25239;&#21464;&#21270;&#30340;&#31245;&#24369;&#30028;&#38480;&#12290;&#21463;&#21040;&#20182;&#20204;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;SEA&#27169;&#22411;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#23545;&#20110;&#20984;&#19988;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#21363;O(sqrt(&#963;_{1:T}^2) + sqrt(&#931;_{1:T}^2))&#65292;&#32780;&#19981;&#38656;&#35201;&#20010;&#21035;&#20989;&#25968;&#30340;&#20984;&#24615;&#35201;&#27714;&#12290;&#23545;&#20110;&#24378;&#20984;&#19988;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;O(sqrt(&#963;_{\max}^2) + sqrt(&#931;_{\max}^2))&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastically Extended Adversarial (SEA) model is introduced by Sachs et al. [2022] as an interpolation between stochastic and adversarial online convex optimization. Under the smoothness condition, they demonstrate that the expected regret of optimistic follow-the-regularized-leader (FTRL) depends on the cumulative stochastic variance $\sigma_{1:T}^2$ and the cumulative adversarial variation $\Sigma_{1:T}^2$ for convex functions. They also provide a slightly weaker bound based on the maximal stochastic variance $\sigma_{\max}^2$ and the maximal adversarial variation $\Sigma_{\max}^2$ for strongly convex functions. Inspired by their work, we investigate the theoretical guarantees of optimistic online mirror descent (OMD) for the SEA model. For convex and smooth functions, we obtain the same $\mathcal{O}(\sqrt{\sigma_{1:T}^2}+\sqrt{\Sigma_{1:T}^2})$ regret bound, without the convexity requirement of individual functions. For strongly convex and smooth functions, we establish an $\mathc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Quantile Risk Minimization&#65288;QRM&#65289;&#26041;&#27861;&#23454;&#29616;&#21487;&#33021;&#30340;&#39046;&#22495;&#27867;&#21270;&#30340;&#27010;&#29575;&#24615;&#26694;&#26550;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#39044;&#27979;&#22120;&#39118;&#38505;&#20998;&#24067;&#22312;&#19981;&#21516;&#39046;&#22495;&#19978;&#30340;&#20998;&#20301;&#25968;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#22312;&#27979;&#35797;&#26102;&#20197;&#39640;&#27010;&#29575;&#34920;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#22120;&#12290;</title><link>http://arxiv.org/abs/2207.09944</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#20301;&#25968;&#39118;&#38505;&#26368;&#23567;&#21270;&#23454;&#29616;&#21487;&#33021;&#30340;&#39046;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Probable Domain Generalization via Quantile Risk Minimization. (arXiv:2207.09944v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09944
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;Quantile Risk Minimization&#65288;QRM&#65289;&#26041;&#27861;&#23454;&#29616;&#21487;&#33021;&#30340;&#39046;&#22495;&#27867;&#21270;&#30340;&#27010;&#29575;&#24615;&#26694;&#26550;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#39044;&#27979;&#22120;&#39118;&#38505;&#20998;&#24067;&#22312;&#19981;&#21516;&#39046;&#22495;&#19978;&#30340;&#20998;&#20301;&#25968;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#22312;&#27979;&#35797;&#26102;&#20197;&#39640;&#27010;&#29575;&#34920;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#27867;&#21270;&#65288;DG&#65289;&#36890;&#36807;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#30456;&#20851;&#35757;&#32451;&#39046;&#22495;&#30340;&#25968;&#25454;&#65292;&#23547;&#25214;&#22312;&#26410;&#35265;&#27979;&#35797;&#20998;&#24067;&#19978;&#34920;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#22120;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;DG&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#23545;&#21487;&#33021;&#30340;&#39046;&#22495;&#38598;&#21512;&#36827;&#34892;&#24179;&#22343;&#25110;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#22120;&#32570;&#20047;&#40065;&#26834;&#24615;&#65292;&#32780;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#22120;&#24448;&#24448;&#36807;&#20110;&#20445;&#23432;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#27010;&#29575;&#24615;&#26694;&#26550;&#26469;&#36827;&#34892;DG&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#20197;&#39640;&#27010;&#29575;&#34920;&#29616;&#33391;&#22909;&#30340;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#21464;&#21270;&#24212;&#35813;&#33021;&#22815;&#21578;&#35785;&#25105;&#20204;&#27979;&#35797;&#26102;&#21487;&#33021;&#30340;&#20998;&#24067;&#21464;&#21270;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#35757;&#32451;&#21644;&#27979;&#35797;&#39046;&#22495;&#26126;&#30830;&#22320;&#35270;&#20026;&#20174;&#21516;&#19968;&#22522;&#30784;&#20803;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20026;&#20102;&#23454;&#29616;&#21487;&#33021;&#30340;DG&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;Quantile Risk Minimization&#65288;QRM&#65289;&#30340;&#26032;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#39044;&#27979;&#22120;&#39118;&#38505;&#20998;&#24067;&#22312;&#39046;&#22495;&#19978;&#30340;&#945;-&#20998;&#20301;&#25968;&#65292;QRM&#21487;&#20197;&#23454;&#29616;&#27010;&#29575;&#19978;&#30340;DG&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain generalization (DG) seeks predictors which perform well on unseen test distributions by leveraging data drawn from multiple related training distributions or domains. To achieve this, DG is commonly formulated as an average- or worst-case problem over the set of possible domains. However, predictors that perform well on average lack robustness while predictors that perform well in the worst case tend to be overly-conservative. To address this, we propose a new probabilistic framework for DG where the goal is to learn predictors that perform well with high probability. Our key idea is that distribution shifts seen during training should inform us of probable shifts at test time, which we realize by explicitly relating training and test domains as draws from the same underlying meta-distribution. To achieve probable DG, we propose a new optimization problem called Quantile Risk Minimization (QRM). By minimizing the $\alpha$-quantile of predictor's risk distribution over domains, Q
&lt;/p&gt;</description></item><item><title>AceIRL&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20027;&#21160;&#25506;&#32034;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#22312;&#19981;&#38656;&#35201;&#29615;&#22659;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#30830;&#23450;&#21487;&#34892;&#22870;&#21169;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25214;&#21040;&#20391;&#37325;&#20110;&#29615;&#22659;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#30340;&#25506;&#32034;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2207.08645</link><description>&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#21160;&#25506;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08645
&lt;/p&gt;
&lt;p&gt;
AceIRL&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20027;&#21160;&#25506;&#32034;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#21644;&#31574;&#30053;&#65292;&#22312;&#19981;&#38656;&#35201;&#29615;&#22659;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#30830;&#23450;&#21487;&#34892;&#22870;&#21169;&#20989;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#25214;&#21040;&#20391;&#37325;&#20110;&#29615;&#22659;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#30340;&#25506;&#32034;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#26159;&#20174;&#19987;&#23478;&#28436;&#31034;&#20013;&#25512;&#26029;&#22870;&#21169;&#20989;&#25968;&#30340;&#24378;&#22823;&#33539;&#24335;&#12290;&#35768;&#22810;IRL&#31639;&#27861;&#38656;&#35201;&#24050;&#30693;&#30340;&#36716;&#31227;&#27169;&#22411;&#65292;&#26377;&#26102;&#29978;&#33267;&#38656;&#35201;&#24050;&#30693;&#30340;&#19987;&#23478;&#31574;&#30053;&#65292;&#25110;&#32773;&#33267;&#23569;&#38656;&#35201;&#35775;&#38382;&#29983;&#25104;&#27169;&#22411;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#20551;&#35774;&#23545;&#20110;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#26469;&#35828;&#22826;&#24378;&#20102;&#65292;&#22240;&#20026;&#21482;&#33021;&#36890;&#36807;&#39034;&#24207;&#20132;&#20114;&#26469;&#35775;&#38382;&#29615;&#22659;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;IRL&#31639;&#27861;&#65306;&#20027;&#21160;&#25506;&#32034;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;AceIRL&#65289;&#65292;&#23427;&#20027;&#21160;&#25506;&#32034;&#26410;&#30693;&#29615;&#22659;&#21644;&#19987;&#23478;&#31574;&#30053;&#65292;&#24555;&#36895;&#23398;&#20064;&#19987;&#23478;&#30340;&#22870;&#21169;&#20989;&#25968;&#24182;&#35782;&#21035;&#20986;&#19968;&#20010;&#22909;&#30340;&#31574;&#30053;&#12290;AceIRL&#20351;&#29992;&#20808;&#21069;&#30340;&#35266;&#23519;&#32467;&#26524;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#26469;&#25429;&#25417;&#21487;&#34892;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#25214;&#21040;&#20391;&#37325;&#20110;&#29615;&#22659;&#20013;&#26368;&#26377;&#20449;&#24687;&#30340;&#21306;&#22495;&#30340;&#25506;&#32034;&#31574;&#30053;&#12290;AceIRL&#26159;&#31532;&#19968;&#31181;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#19988;&#19981;&#38656;&#35201;&#29615;&#22659;&#29983;&#25104;&#27169;&#22411;&#30340;&#20027;&#21160;IRL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring a reward function from expert demonstrations. Many IRL algorithms require a known transition model and sometimes even a known expert policy, or they at least require access to a generative model. However, these assumptions are too strong for many real-world applications, where the environment can be accessed only through sequential interaction. We propose a novel IRL algorithm: Active exploration for Inverse Reinforcement Learning (AceIRL), which actively explores an unknown environment and expert policy to quickly learn the expert's reward function and identify a good policy. AceIRL uses previous observations to construct confidence intervals that capture plausible reward functions and find exploration policies that focus on the most informative regions of the environment. AceIRL is the first approach to active IRL with sample-complexity bounds that does not require a generative model of the environment. AceIRL 
&lt;/p&gt;</description></item></channel></rss>