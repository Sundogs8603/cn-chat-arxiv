<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.03626</link><description>&lt;p&gt;
&#40065;&#26834;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340;&#21487;&#39564;&#35777;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Verifiable Learning for Robust Tree Ensembles. (arXiv:2305.03626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27979;&#35797;&#26102;&#38388;&#20869;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#30830;&#23450;&#65292;&#23545;&#20110;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159; NP-hard &#65292;&#22240;&#27492;&#23545;&#20110;&#29305;&#23450;&#30340;&#36755;&#20837;&#26469;&#35828;&#26159;&#19981;&#21487;&#35299;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#31867;&#21463;&#38480;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#31216;&#20026; large-spread &#38598;&#25104;&#65292;&#20854;&#20801;&#35768;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#23433;&#20840;&#39564;&#35777;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39564;&#35777;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#20513;&#23548;&#35757;&#32451;&#36825;&#31181;&#26131;&#20110;&#39564;&#35777;&#30340;&#21463;&#38480;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20174;&#26631;&#35760;&#25968;&#25454;&#20013;&#33258;&#21160;&#23398;&#20064; large-spread &#20915;&#31574;&#26641;&#38598;&#25104;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#30410;&#22788;&#65292;&#20174;&#32780;&#20351;&#20854;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#12290;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#31639;&#27861;&#35757;&#32451;&#30340; large-spread &#38598;&#25104;&#21487;&#20197;&#22312;&#20960;&#31186;&#38047;&#20869;&#20351;&#29992;&#26631;&#20934;&#21322;&#23450;&#32534;&#31243;&#27714;&#35299;&#22120;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on publicly available datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using stand
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#21512;&#26381;&#37327;&#21270;&#22238;&#24402;&#20248;&#21270;&#36229;&#21442;&#25968;&#65292;&#30456;&#27604;&#39640;&#26031;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#23545;&#35266;&#27979;&#22122;&#22768;&#20570;&#20986;&#26368;&#23569;&#30340;&#20551;&#35774;&#65292;&#26356;&#30495;&#23454;&#40065;&#26834;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#22312;&#22810;&#20445;&#30495;&#24230;&#35774;&#32622;&#20013;&#32858;&#21512;&#32467;&#26524;&#30340;&#26041;&#27861;&#65292;&#22312;&#23454;&#38469;&#20219;&#21153;&#20013;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.03623</link><description>&lt;p&gt;
&#21033;&#29992;&#21512;&#26381;&#37327;&#21270;&#22238;&#24402;&#20248;&#21270;&#36229;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Optimizing Hyperparameters with Conformal Quantile Regression. (arXiv:2305.03623v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03623
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#21512;&#26381;&#37327;&#21270;&#22238;&#24402;&#20248;&#21270;&#36229;&#21442;&#25968;&#65292;&#30456;&#27604;&#39640;&#26031;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#23545;&#35266;&#27979;&#22122;&#22768;&#20570;&#20986;&#26368;&#23569;&#30340;&#20551;&#35774;&#65292;&#26356;&#30495;&#23454;&#40065;&#26834;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#22312;&#22810;&#20445;&#30495;&#24230;&#35774;&#32622;&#20013;&#32858;&#21512;&#32467;&#26524;&#30340;&#26041;&#27861;&#65292;&#22312;&#23454;&#38469;&#20219;&#21153;&#20013;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24456;&#22810;&#29616;&#26377;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#31639;&#27861;&#20381;&#36182;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#20248;&#21270;&#24037;&#20855;&#65292;&#23427;&#20204;&#21487;&#20197;&#23398;&#20064;&#20195;&#29702;&#27169;&#22411;&#26469;&#25351;&#23548;&#25628;&#32034;&#12290;&#39640;&#26031;&#36807;&#31243;&#26159;&#40664;&#35748;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#25429;&#25417;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#26159;&#23427;&#20204;&#23545;&#35266;&#27979;&#22122;&#22768;&#20570;&#20986;&#24378;&#28872;&#30340;&#20551;&#35774;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26159;&#19981;&#21512;&#29702;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#21512;&#26381;&#37327;&#21270;&#22238;&#24402;&#65292;&#35813;&#26041;&#27861;&#23545;&#35266;&#27979;&#22122;&#22768;&#20570;&#20986;&#26368;&#23569;&#30340;&#20551;&#35774;&#65292;&#22240;&#27492;&#26356;&#30495;&#23454;&#21644;&#40065;&#26834;&#22320;&#24314;&#27169;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#22312;&#23454;&#35777;&#22522;&#20934;&#19978;&#24555;&#36895;&#23454;&#29616;&#36229;&#21442;&#25968;&#20248;&#21270;&#25910;&#25947;&#12290;&#20026;&#20102;&#22312;&#22810;&#20445;&#30495;&#24230;&#35774;&#32622;&#20013;&#24212;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#32858;&#21512;&#19981;&#21516;&#36164;&#28304;&#27700;&#24179;&#19978;&#35266;&#23519;&#21040;&#30340;&#32467;&#26524;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#20219;&#21153;&#20013;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many state-of-the-art hyperparameter optimization (HPO) algorithms rely on model-based optimizers that learn surrogate models of the target function to guide the search. Gaussian processes are the de facto surrogate model due to their ability to capture uncertainty but they make strong assumptions about the observation noise, which might not be warranted in practice. In this work, we propose to leverage conformalized quantile regression which makes minimal assumptions about the observation noise and, as a result, models the target function in a more realistic and robust fashion which translates to quicker HPO convergence on empirical benchmarks. To apply our method in a multi-fidelity setting, we propose a simple, yet effective, technique that aggregates observed results across different resource levels and outperforms conventional methods across many empirical tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23581;&#35797;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#24182;&#29983;&#25104;&#25509;&#36817;&#26368;&#20248;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#65292;&#25552;&#20986;&#20351;&#29992; $L^1$-&#36317;&#31163;&#35745;&#31639;&#25345;&#20037;&#22270;&#24182;&#37319;&#29992;&#25351;&#25968;&#26426;&#21046;&#20445;&#25252;&#38544;&#31169;&#65292;&#25104;&#21151;&#23454;&#29616;&#22312;&#38544;&#31169;&#20445;&#25252;&#21644;&#25968;&#25454;&#20998;&#26512;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.03609</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Topological Data Analysis. (arXiv:2305.03609v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23581;&#35797;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#24182;&#29983;&#25104;&#25509;&#36817;&#26368;&#20248;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#65292;&#25552;&#20986;&#20351;&#29992; $L^1$-&#36317;&#31163;&#35745;&#31639;&#25345;&#20037;&#22270;&#24182;&#37319;&#29992;&#25351;&#25968;&#26426;&#21046;&#20445;&#25252;&#38544;&#31169;&#65292;&#25104;&#21151;&#23454;&#29616;&#22312;&#38544;&#31169;&#20445;&#25252;&#21644;&#25968;&#25454;&#20998;&#26512;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#39318;&#31687;&#23581;&#35797;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#24182;&#29983;&#25104;&#25509;&#36817;&#26368;&#20248;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#12290;&#25105;&#20204;&#36890;&#36807;&#29942;&#39048;&#36317;&#31163;&#20998;&#26512;&#25345;&#20037;&#22270;&#30340;&#28789;&#25935;&#24230;&#65292;&#21457;&#29616;&#24120;&#29992;&#30340; \v{C}ech &#22797;&#24418;&#30340;&#28789;&#25935;&#24230;&#24182;&#19981;&#20250;&#38543;&#30528;&#26679;&#26412;&#37327; $n$ &#30340;&#22686;&#21152;&#32780;&#38477;&#20302;&#65292;&#36825;&#20351;&#24471; \v{C}ech &#22797;&#24418;&#25345;&#20037;&#22270;&#38590;&#20197;&#38544;&#31169;&#21270;&#12290;&#20316;&#20026;&#26367;&#20195;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992; $L^1$-&#36317;&#31163;&#26469;&#35745;&#31639;&#25345;&#20037;&#22270;&#65292;&#21457;&#29616;&#20854;&#28789;&#25935;&#24230;&#20026; $O(1/n)$&#12290;&#22522;&#20110;&#28789;&#25935;&#24230;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#37319;&#29992;&#25351;&#25968;&#26426;&#21046;&#65292;&#20854;&#25928;&#29992;&#20989;&#25968;&#23450;&#20041;&#20026; $L^1$-DTM &#25345;&#20037;&#22270;&#30340;&#29942;&#39048;&#36317;&#31163;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#25105;&#20204;&#38544;&#31169;&#26426;&#21046;&#30340;&#31934;&#24230;&#19978;&#19979;&#30028;&#65307;&#24471;&#21040;&#30340;&#30028;&#38480;&#34920;&#26126;&#25105;&#20204;&#30340;&#26426;&#21046;&#38544;&#31169;&#35823;&#24046;&#25509;&#36817;&#26368;&#20248;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is the first to attempt differentially private (DP) topological data analysis (TDA), producing near-optimal private persistence diagrams. We analyze the sensitivity of persistence diagrams in terms of the bottleneck distance, and we show that the commonly used \v{C}ech complex has sensitivity that does not decrease as the sample size $n$ increases. This makes it challenging for the persistence diagrams of \v{C}ech complexes to be privatized. As an alternative, we show that the persistence diagram obtained by the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the sensitivity analysis, we propose using the exponential mechanism whose utility function is defined in terms of the bottleneck distance of the $L^1$-DTM persistence diagrams. We also derive upper and lower bounds of the accuracy of our privacy mechanism; the obtained bounds indicate that the privacy error of our mechanism is near-optimal. We demonstrate the performance of our privatized persistence
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#65288;SPG&#65289;&#24378;&#21270;&#23398;&#20064;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#36890;&#36947;&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;&#65292;&#33021;&#22815;&#20256;&#36755;&#24847;&#20041;&#32780;&#38750;&#31934;&#30830;&#29256;&#26412;&#65292;&#36798;&#21040;&#20102;&#20449;&#24687;&#36895;&#29575;&#33410;&#30465;&#30340;&#30446;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.03571</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#30340;&#27169;&#22411;&#26080;&#20851;&#35821;&#20041;&#36890;&#20449;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Model-free Reinforcement Learning of Semantic Communication by Stochastic Policy Gradient. (arXiv:2305.03571v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#21033;&#29992;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#65288;SPG&#65289;&#24378;&#21270;&#23398;&#20064;&#65292;&#25104;&#21151;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#36890;&#36947;&#27169;&#22411;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;&#65292;&#33021;&#22815;&#20256;&#36755;&#24847;&#20041;&#32780;&#38750;&#31934;&#30830;&#29256;&#26412;&#65292;&#36798;&#21040;&#20102;&#20449;&#24687;&#36895;&#29575;&#33410;&#30465;&#30340;&#30446;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#22312;&#26080;&#32447;&#36890;&#20449;&#26041;&#38754;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#38886;&#24343;&#65288;Weaver&#65289;&#20110;1949&#24180;&#25552;&#20986;&#30340;&#35821;&#20041;&#36890;&#20449;&#27010;&#24565;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#23427;&#25171;&#30772;&#20102;&#39321;&#20892;&#32463;&#20856;&#30340;&#35774;&#35745;&#33539;&#20363;&#65292;&#26088;&#22312;&#20256;&#36755;&#28040;&#24687;&#30340;&#24847;&#20041;&#65292;&#21363;&#35821;&#20041;&#65292;&#32780;&#19981;&#26159;&#31934;&#30830;&#29256;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#20449;&#24687;&#36895;&#29575;&#33410;&#30465;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#38543;&#26426;&#31574;&#30053;&#26799;&#24230;&#65288;SPG&#65289;&#26469;&#35774;&#35745;&#19968;&#31181;&#22522;&#20110;&#24378;&#21270;&#23398;&#20064;&#30340;&#35821;&#20041;&#36890;&#20449;&#31995;&#32479;&#65292;&#19981;&#38656;&#35201;&#24050;&#30693;&#25110;&#21487;&#24494;&#20998;&#36890;&#36947;&#27169;&#22411;&#65292;&#36825;&#26159;&#23454;&#38469;&#37096;&#32626;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#26368;&#22823;&#21270;&#25509;&#25910;&#21644;&#30446;&#26631;&#21464;&#37327;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#20986;&#21457;&#65292;&#28608;&#21457;&#20102;&#23558;SPG&#29992;&#20110;&#32463;&#20856;&#21644;&#35821;&#20041;&#36890;&#20449;&#30340;&#21160;&#26426;&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36798;&#21040;&#20102;&#19982;&#22522;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#25216;&#24039;&#30340;&#27169;&#22411;&#24863;&#30693;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#23613;&#31649;&#25910;&#25947;&#36895;&#24230;&#26377;&#25152;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the recent success of Machine Learning tools in wireless communications, the idea of semantic communication by Weaver from 1949 has gained attention. It breaks with Shannon's classic design paradigm by aiming to transmit the meaning, i.e., semantics, of a message instead of its exact version, allowing for information rate savings. In this work, we apply the Stochastic Policy Gradient (SPG) to design a semantic communication system by reinforcement learning, not requiring a known or differentiable channel model a crucial step towards deployment in practice. Further, we motivate the use of SPG for both classic and semantic communication from the maximization of the mutual information between received and target variables. Numerical results show that our approach achieves comparable performance to a model-aware approach based on the reparametrization trick, albeit with a decreased convergence rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;Wasserstein&#32858;&#31867;&#65292;&#29992;&#20110;&#22788;&#29702;&#37329;&#34701;&#26426;&#26500;&#30340;&#22797;&#26434;&#25968;&#25454;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#32570;&#22833;&#20540;&#21644;&#22522;&#20110;&#29305;&#23450;&#29305;&#24449;&#35782;&#21035;&#32858;&#31867;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#30417;&#31649;&#32773;&#30340;&#30417;&#31649;&#24037;&#20316;&#65292;&#24182;&#22312;&#20854;&#39046;&#22495;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.03565</link><description>&lt;p&gt;
&#37329;&#34701;&#26426;&#26500;&#30340;&#20960;&#20309;&#24418;&#24577;--&#37329;&#34701;&#25968;&#25454;&#30340;Wasserstein&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
The geometry of financial institutions -- Wasserstein clustering of financial data. (arXiv:2305.03565v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;Wasserstein&#32858;&#31867;&#65292;&#29992;&#20110;&#22788;&#29702;&#37329;&#34701;&#26426;&#26500;&#30340;&#22797;&#26434;&#25968;&#25454;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#32570;&#22833;&#20540;&#21644;&#22522;&#20110;&#29305;&#23450;&#29305;&#24449;&#35782;&#21035;&#32858;&#31867;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#30417;&#31649;&#32773;&#30340;&#30417;&#31649;&#24037;&#20316;&#65292;&#24182;&#22312;&#20854;&#39046;&#22495;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#26029;&#22686;&#21152;&#30340;&#21508;&#31181;&#26377;&#36259;&#23545;&#35937;&#30340;&#32454;&#33410;&#21644;&#22823;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#20351;&#24471;&#26377;&#24517;&#35201;&#24320;&#21457;&#23558;&#36825;&#20123;&#20449;&#24687;&#21387;&#32553;&#25104;&#20195;&#34920;&#24615;&#21644;&#21487;&#29702;&#35299;&#30340;&#22320;&#22270;&#30340;&#26041;&#27861;&#12290;&#37329;&#34701;&#30417;&#31649;&#26159;&#19968;&#20010;&#23637;&#31034;&#36825;&#31181;&#38656;&#27714;&#30340;&#39046;&#22495;&#65292;&#22240;&#20026;&#30417;&#31649;&#26426;&#26500;&#38656;&#35201;&#20174;&#37329;&#34701;&#26426;&#26500;&#33719;&#21462;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#65292;&#26377;&#26102;&#26159;&#39640;&#24230;&#32454;&#31890;&#24230;&#30340;&#65292;&#20197;&#30417;&#30563;&#21644;&#35780;&#20272;&#20182;&#20204;&#30340;&#27963;&#21160;&#12290;&#28982;&#32780;&#65292;&#22788;&#29702;&#21644;&#20998;&#26512;&#36825;&#26679;&#30340;&#25968;&#25454;&#21487;&#33021;&#26159;&#19968;&#39033;&#33392;&#24040;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#32771;&#34385;&#21040;&#22788;&#29702;&#32570;&#22833;&#20540;&#21644;&#22522;&#20110;&#29305;&#23450;&#29305;&#24449;&#35782;&#21035;&#32858;&#31867;&#25152;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#27010;&#29575;&#20998;&#24067;&#30340;Lloyd&#31639;&#27861;&#21464;&#20307;&#65292;&#24182;&#20351;&#29992;&#24191;&#20041;Wasserstein&#37325;&#24515;&#26500;&#24314;&#34920;&#31034;&#19981;&#21516;&#23545;&#35937;&#19978;&#30340;&#32473;&#23450;&#25968;&#25454;&#30340;&#24230;&#37327;&#31354;&#38388;&#65292;&#20174;&#32780;&#24212;&#23545;&#37329;&#34701;&#30417;&#31649;&#32972;&#26223;&#19979;&#30417;&#31649;&#32773;&#38754;&#20020;&#30340;&#20855;&#20307;&#25361;&#25112;&#12290;&#25105;&#20204;&#30456;&#20449;&#36825;&#31181;&#26041;&#27861;&#22312;&#37329;&#34701;&#30417;&#31649;&#39046;&#22495;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing availability of granular and big data on various objects of interest has made it necessary to develop methods for condensing this information into a representative and intelligible map. Financial regulation is a field that exemplifies this need, as regulators require diverse and often highly granular data from financial institutions to monitor and assess their activities. However, processing and analyzing such data can be a daunting task, especially given the challenges of dealing with missing values and identifying clusters based on specific features.  To address these challenges, we propose a variant of Lloyd's algorithm that applies to probability distributions and uses generalized Wasserstein barycenters to construct a metric space which represents given data on various objects in condensed form. By applying our method to the financial regulation context, we demonstrate its usefulness in dealing with the specific challenges faced by regulators in this domain. We beli
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#26354;&#29575;&#31354;&#38388;&#30340;&#23545;&#27604;&#22270;&#32858;&#31867;&#26041;&#27861;CONGREGATE&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.03555</link><description>&lt;p&gt;
&#26354;&#29575;&#31354;&#38388;&#20013;&#23545;&#27604;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Contrastive Graph Clustering in Curvature Spaces. (arXiv:2305.03555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03555
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#26354;&#29575;&#31354;&#38388;&#30340;&#23545;&#27604;&#22270;&#32858;&#31867;&#26041;&#27861;CONGREGATE&#65292;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#32858;&#31867;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#30740;&#31350;&#30340;&#35805;&#39064;&#65292;&#22312;&#36817;&#24180;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20013;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#37325;&#35201;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#35299;&#20915;&#12290;&#19968;&#26041;&#38754;&#65292;&#20174;&#20960;&#20309;&#35282;&#24230;&#36827;&#34892;&#22270;&#32858;&#31867;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#24456;&#23569;&#28041;&#21450;&#21040;&#23427;&#30340;&#20960;&#20309;&#32858;&#31867;&#31354;&#38388;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#23545;&#27604;&#23398;&#20064;&#21487;&#20197;&#25552;&#39640;&#28145;&#24230;&#22270;&#32858;&#31867;&#30340;&#25928;&#26524;&#65292;&#20294;&#36890;&#24120;&#20250;&#22312;&#22270;&#22686;&#24378;&#25110;&#38590;&#20363;&#25366;&#25496;&#26041;&#38754;&#38754;&#20020;&#22256;&#38590;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#37325;&#26032;&#24605;&#32771;&#22270;&#32858;&#31867;&#38382;&#39064;&#65292;&#24182;&#23581;&#35797;&#39318;&#27425;&#24341;&#20837;&#24322;&#26500;&#26354;&#29575;&#31354;&#38388;&#21040;&#22270;&#32858;&#31867;&#38382;&#39064;&#20013;&#12290;&#30456;&#24212;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;CONGREGATE&#30340;&#26032;&#39062;&#30340;&#31471;&#21040;&#31471;&#23545;&#27604;&#22270;&#32858;&#31867;&#27169;&#22411;&#65292;&#29992;Ricci&#26354;&#29575;&#35299;&#20915;&#20960;&#20309;&#22270;&#32858;&#31867;&#12290;&#20026;&#20102;&#25903;&#25345;&#20960;&#20309;&#32858;&#31867;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#25903;&#25745;&#30340;&#24322;&#26500;&#26354;&#29575;&#31354;&#38388;&#26694;&#26550;&#65292;&#21487;&#20197;&#25429;&#25417;&#22270;&#30340;&#21508;&#31181;&#26354;&#29575;&#29305;&#24449;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#22522;&#20110;&#26354;&#29575;&#30340;&#20960;&#20309;&#22270;&#32858;&#31867;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph clustering is a longstanding research topic, and has achieved remarkable success with the deep learning methods in recent years. Nevertheless, we observe that several important issues largely remain open. On the one hand, graph clustering from the geometric perspective is appealing but has rarely been touched before, as it lacks a promising space for geometric clustering. On the other hand, contrastive learning boosts the deep graph clustering but usually struggles in either graph augmentation or hard sample mining. To bridge this gap, we rethink the problem of graph clustering from geometric perspective and, to the best of our knowledge, make the first attempt to introduce a heterogeneous curvature space to graph clustering problem. Correspondingly, we present a novel end-to-end contrastive graph clustering model named CONGREGATE, addressing geometric graph clustering with Ricci curvatures. To support geometric clustering, we construct a theoretically grounded Heterogeneous Curv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#23646;&#20110;&#32463;&#20856;Sobolev&#31354;&#38388;&#33539;&#22260;&#20869;&#30340;&#21508;&#31181;&#30495;&#23454;&#20989;&#25968;&#65292;&#36890;&#36807;&#24341;&#20837;&#22122;&#22768;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#24555;&#30340;&#36895;&#24230;&#19979;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.03531</link><description>&lt;p&gt;
&#26680;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20013;&#30340;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Random Smoothing Regularization in Kernel Gradient Descent Learning. (arXiv:2305.03531v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#23646;&#20110;&#32463;&#20856;Sobolev&#31354;&#38388;&#33539;&#22260;&#20869;&#30340;&#21508;&#31181;&#30495;&#23454;&#20989;&#25968;&#65292;&#36890;&#36807;&#24341;&#20837;&#22122;&#22768;&#36991;&#20813;&#36807;&#25311;&#21512;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#36739;&#24555;&#30340;&#36895;&#24230;&#19979;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#24179;&#28369;&#25968;&#25454;&#22686;&#24378;&#26159;&#19968;&#31181;&#29420;&#29305;&#30340;&#27491;&#21017;&#21270;&#24418;&#24335;&#65292;&#21487;&#20197;&#36890;&#36807;&#21521;&#36755;&#20837;&#25968;&#25454;&#24341;&#20837;&#22122;&#22768;&#26469;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#40723;&#21169;&#27169;&#22411;&#23398;&#20064;&#26356;&#24191;&#27867;&#30340;&#29305;&#24449;&#12290;&#23613;&#31649;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#37117;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#38543;&#26426;&#24179;&#28369;&#30340;&#27491;&#21017;&#21270;&#33021;&#21147;&#32570;&#20047;&#31995;&#32479;&#30340;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#12289;&#26377;&#25928;&#22320;&#23398;&#20064;&#23646;&#20110;&#32463;&#20856; Sobolev &#31354;&#38388;&#33539;&#22260;&#20869;&#30340;&#21508;&#31181;&#30495;&#23454;&#20989;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#22522;&#30784;&#30340;&#20989;&#25968;&#31354;&#38388;&#65306;&#20302;&#22266;&#26377;&#32500;&#24230;&#30340; Sobolev &#31354;&#38388;&#65292;&#20854;&#20013;&#21253;&#25324; $D$ &#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#25110;&#20302;&#32500;&#23376;&#27969;&#24418;&#20316;&#20026;&#29305;&#20363;&#65292;&#20197;&#21450;&#20855;&#26377;&#24352;&#37327;&#32467;&#26500;&#30340;&#28151;&#21512;&#24179;&#28369; Sobolev &#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#24179;&#28369;&#27491;&#21017;&#21270;&#20316;&#20026;&#26032;&#22411;&#21367;&#31215;&#24179;&#28369;&#26680;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random smoothing data augmentation is a unique form of regularization that can prevent overfitting by introducing noise to the input data, encouraging the model to learn more generalized features. Despite its success in various applications, there has been a lack of systematic study on the regularization ability of random smoothing. In this paper, we aim to bridge this gap by presenting a framework for random smoothing regularization that can adaptively and effectively learn a wide range of ground truth functions belonging to the classical Sobolev spaces. Specifically, we investigate two underlying function spaces: the Sobolev space of low intrinsic dimension, which includes the Sobolev space in $D$-dimensional Euclidean space or low-dimensional sub-manifolds as special cases, and the mixed smooth Sobolev space with a tensor structure. By using random smoothing regularization as novel convolution-based smoothing kernels, we can attain optimal convergence rates in these cases using a ke
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#31232;&#30095;&#21270;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#29992;&#28508;&#22312;&#20108;&#36827;&#21046;&#21464;&#37327;&#21644;&#24402;&#19968;&#21270;&#27969;&#65292;&#23454;&#29616;&#20102;&#32593;&#32476;&#22312;&#27979;&#35797;&#26102;&#30340;&#33258;&#21160;&#31232;&#30095;&#21270;&#65292;&#32780;&#19988;&#32467;&#26524;&#34920;&#26126;&#36825;&#20010;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#19978;&#33021;&#22815;&#19982;&#29616;&#26377;&#30340;&#31232;&#30095;&#21270;&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;</title><link>http://arxiv.org/abs/2305.03395</link><description>&lt;p&gt;
&#29992;&#28508;&#22312;&#20108;&#36827;&#21046;&#21464;&#37327;&#21644;&#24402;&#19968;&#21270;&#27969;&#26469;&#31232;&#30095;&#21270;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Sparsifying Bayesian neural networks with latent binary variables and normalizing flows. (arXiv:2305.03395v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#31232;&#30095;&#21270;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#29992;&#28508;&#22312;&#20108;&#36827;&#21046;&#21464;&#37327;&#21644;&#24402;&#19968;&#21270;&#27969;&#65292;&#23454;&#29616;&#20102;&#32593;&#32476;&#22312;&#27979;&#35797;&#26102;&#30340;&#33258;&#21160;&#31232;&#30095;&#21270;&#65292;&#32780;&#19988;&#32467;&#26524;&#34920;&#26126;&#36825;&#20010;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#19978;&#33021;&#22815;&#19982;&#29616;&#26377;&#30340;&#31232;&#30095;&#21270;&#26041;&#27861;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANN&#65289;&#26159;&#29616;&#20195;&#35768;&#22810;&#24212;&#29992;&#20013;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#38754;&#37096;&#35782;&#21035;&#12289;&#26426;&#22120;&#32763;&#35793;&#21644;&#30284;&#30151;&#35786;&#26029;&#12290;ANN&#30340;&#19968;&#20010;&#24120;&#35265;&#38382;&#39064;&#26159;&#23427;&#20204;&#36890;&#24120;&#20855;&#26377;&#25968;&#30334;&#19975;&#25110;&#25968;&#21313;&#20159;&#20010;&#21487;&#35757;&#32451;&#21442;&#25968;&#65292;&#24182;&#19988;&#22240;&#27492;&#20542;&#21521;&#20110;&#36807;&#24230;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#12290;&#36825;&#22312;&#38656;&#35201;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#24212;&#29992;&#20013;&#29305;&#21035;&#26377;&#38382;&#39064;&#12290;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#21487;&#20197;&#25913;&#21892;&#36825;&#19968;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#21253;&#21547;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;&#28508;&#22312;&#20108;&#36827;&#21046;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;LBBNN&#65289;&#36890;&#36807;&#20801;&#35768;&#23558;&#26435;&#37325;&#25171;&#24320;&#25110;&#20851;&#38381;&#65292;&#20174;&#32780;&#22312;&#26435;&#37325;&#21644;&#32467;&#26500;&#30340;&#32852;&#21512;&#31354;&#38388;&#20013;&#21551;&#29992;&#25512;&#26029;&#65292;&#20063;&#32771;&#34385;&#20102;&#32467;&#26500;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#23558;&#32771;&#34385;LBBNN&#26041;&#27861;&#30340;&#20004;&#20010;&#25193;&#23637;&#65306;&#39318;&#20808;&#65292;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;&#37325;&#21442;&#25968;&#21270;&#25216;&#24039;&#65288;LRT&#65289;&#30452;&#25509;&#37319;&#26679;&#38544;&#34255;&#21333;&#20803;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#26356;&#21152;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#36890;&#36807;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#65292;&#25105;&#20204;&#21487;&#20197;&#36817;&#20284;&#28508;&#22312;&#20108;&#36827;&#21046;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#22312;&#27979;&#35797;&#26102;&#23454;&#29616;&#32593;&#32476;&#30340;&#31232;&#30095;&#21270;&#12290;&#25105;&#20204;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#31232;&#30095;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#33021;&#22815;&#33719;&#24471;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#25345;&#31867;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial neural networks (ANNs) are powerful machine learning methods used in many modern applications such as facial recognition, machine translation, and cancer diagnostics. A common issue with ANNs is that they usually have millions or billions of trainable parameters, and therefore tend to overfit to the training data. This is especially problematic in applications where it is important to have reliable uncertainty estimates. Bayesian neural networks (BNN) can improve on this, since they incorporate parameter uncertainty. In addition, latent binary Bayesian neural networks (LBBNN) also take into account structural uncertainty by allowing the weights to be turned on or off, enabling inference in the joint space of weights and structures. In this paper, we will consider two extensions to the LBBNN method: Firstly, by using the local reparametrization trick (LRT) to sample the hidden units directly, we get a more computationally efficient algorithm. More importantly, by using normal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#22312;&#38750;&#21442;&#25968;&#24773;&#20917;&#19979;&#65292;&#20165;&#36890;&#36807;&#30456;&#37051;&#33410;&#28857;&#20043;&#38388;&#30340;&#20449;&#24687;&#20256;&#25773;&#65292;&#36991;&#20813;&#25968;&#25454;&#20132;&#25442;&#30340;&#20998;&#25955;&#25193;&#25955;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.03295</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#30340;&#20998;&#25955;&#25193;&#25955;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Decentralized diffusion-based learning under non-parametric limited prior knowledge. (arXiv:2305.03295v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#22312;&#38750;&#21442;&#25968;&#24773;&#20917;&#19979;&#65292;&#20165;&#36890;&#36807;&#30456;&#37051;&#33410;&#28857;&#20043;&#38388;&#30340;&#20449;&#24687;&#20256;&#25773;&#65292;&#36991;&#20813;&#25968;&#25454;&#20132;&#25442;&#30340;&#20998;&#25955;&#25193;&#25955;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22312;&#22122;&#22768;&#29615;&#22659;&#20013;&#65292;&#20174;&#23616;&#37096;&#20195;&#29702;&#30340;&#27979;&#37327;&#32467;&#26524;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29616;&#35937; m &#30340;&#25193;&#25955;&#32593;&#32476;&#23398;&#20064;&#38382;&#39064;&#12290;&#23545;&#20110;&#20998;&#25955;&#30340;&#32593;&#32476;&#65292;&#20165;&#22312;&#30452;&#25509;&#30456;&#37051;&#33410;&#28857;&#20043;&#38388;&#20256;&#25773;&#20449;&#24687;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#23398;&#20064;&#31639;&#27861;&#65292;&#36991;&#20813;&#20102;&#21407;&#22987;&#25968;&#25454;&#20132;&#25442;&#65292;&#20165;&#38656;&#35201;&#23545; m &#26377;&#36731;&#24494;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#23545;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#38750;&#28176;&#36817;&#20272;&#35745;&#35823;&#24046;&#30028;&#30340;&#23548;&#20986;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35828;&#26126;&#20102;&#23427;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of diffusion-based network learning of a nonlinear phenomenon, $m$, from local agents' measurements collected in a noisy environment. For a decentralized network and information spreading merely between directly neighboring nodes, we propose a non-parametric learning algorithm, that avoids raw data exchange and requires only mild \textit{a priori} knowledge about $m$. Non-asymptotic estimation error bounds are derived for the proposed method. Its potential applications are illustrated through simulation experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#21442;&#25968;Vononoi&#25439;&#22833;&#20989;&#25968;&#24182;&#24314;&#31435;&#20102;MLE&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;Softmax&#38376;&#25511;&#38382;&#39064;&#65292;&#30740;&#31350;&#34920;&#26126;&#35813;&#38376;&#25511;&#19982;&#39640;&#26031;&#20998;&#24067;&#20013;&#30340;&#19987;&#23478;&#20989;&#25968;&#36890;&#36807;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20114;&#20316;&#29992;&#65292;&#26159;&#19968;&#20010;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.03288</link><description>&lt;p&gt;
&#35299;&#23494;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;Softmax&#38376;&#25511;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Demystifying Softmax Gating in Gaussian Mixture of Experts. (arXiv:2305.03288v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#21442;&#25968;Vononoi&#25439;&#22833;&#20989;&#25968;&#24182;&#24314;&#31435;&#20102;MLE&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;Softmax&#38376;&#25511;&#38382;&#39064;&#65292;&#30740;&#31350;&#34920;&#26126;&#35813;&#38376;&#25511;&#19982;&#39640;&#26031;&#20998;&#24067;&#20013;&#30340;&#19987;&#23478;&#20989;&#25968;&#36890;&#36807;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20114;&#20316;&#29992;&#65292;&#26159;&#19968;&#20010;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;Softmax&#38376;&#25511;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#19968;&#30452;&#26159;&#25991;&#29486;&#20013;&#38271;&#26399;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#36825;&#20027;&#35201;&#26159;&#30001;&#20110;&#19977;&#20010;&#22522;&#26412;&#29702;&#35770;&#25361;&#25112;&#19982;Softmax&#38376;&#25511;&#30456;&#20851;&#65306;&#65288;i&#65289;&#21482;&#33021;&#35782;&#21035;&#21442;&#25968;&#30340;&#24179;&#31227;&#65307;&#65288;ii&#65289;Softmax&#38376;&#25511;&#21644;&#39640;&#26031;&#20998;&#24067;&#20013;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#36890;&#36807;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#20869;&#22312;&#30456;&#20114;&#20316;&#29992;&#65307;&#65288;iii&#65289;Softmax&#38376;&#25511;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#26465;&#20214;&#23494;&#24230;&#30340;&#20998;&#23376;&#21644;&#20998;&#27597;&#20043;&#38388;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#21442;&#25968;Vononoi&#25439;&#22833;&#20989;&#25968;&#24182;&#24314;&#31435;MLE&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#24403;&#19987;&#23478;&#25968;&#37327;&#26410;&#30693;&#19988;&#36229;&#39069;&#25351;&#23450;&#26102;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;MLE&#30340;&#36895;&#29575;&#19982;&#19968;&#32452;&#22810;&#39033;&#24335;&#26041;&#31243;&#30340;&#21487;&#35299;&#24615;&#38382;&#39064;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding parameter estimation of softmax gating Gaussian mixture of experts has remained a long-standing open problem in the literature. It is mainly due to three fundamental theoretical challenges associated with the softmax gating: (i) the identifiability only up to the translation of the parameters; (ii) the intrinsic interaction via partial differential equation between the softmax gating and the expert functions in Gaussian distribution; (iii) the complex dependence between the numerator and denominator of the conditional density of softmax gating Gaussian mixture of experts. We resolve these challenges by proposing novel Vononoi loss functions among parameters and establishing the convergence rates of the maximum likelihood estimator (MLE) for solving parameter estimation in these models. When the number of experts is unknown and over-specified, our findings show a connection between the rate of MLE and a solvability problem of a system of polynomial equations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;Bootstrap&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#33258;&#21161;&#27861;&#12289;&#37325;&#25277;&#26679;&#21644;&#32447;&#24615;&#22238;&#24402;&#26469;&#26356;&#26032;&#38544;&#34255;&#23618;&#30340;&#21152;&#26435;&#36830;&#25509;&#65292;&#20174;&#32780;&#36798;&#21040;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.03099</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#24555;&#36895;&#26377;&#30417;&#30563;&#23398;&#20064;&#30340;Bootstrap&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bootstrap Algorithm for Fast Supervised Learning. (arXiv:2305.03099v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;Bootstrap&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#33258;&#21161;&#27861;&#12289;&#37325;&#25277;&#26679;&#21644;&#32447;&#24615;&#22238;&#24402;&#26469;&#26356;&#26032;&#38544;&#34255;&#23618;&#30340;&#21152;&#26435;&#36830;&#25509;&#65292;&#20174;&#32780;&#36798;&#21040;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#36890;&#24120;&#20381;&#36182;&#26576;&#31181;&#31867;&#22411;&#30340;&#26354;&#32447;&#36319;&#38543;&#26041;&#27861;&#65292;&#20363;&#22914;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65288;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#65289;&#65292;ADADELTA&#65292;ADAM&#25110;&#26377;&#38480;&#20869;&#23384;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#30340;&#25910;&#25947;&#36890;&#24120;&#20381;&#36182;&#20110;&#35775;&#38382;&#22823;&#37327;&#30340;&#35266;&#27979;&#20540;&#20197;&#23454;&#29616;&#39640;&#31934;&#24230;&#65292;&#24182;&#19988;&#23545;&#20110;&#26576;&#20123;&#20989;&#25968;&#31867;&#65292;&#36825;&#20123;&#31639;&#27861;&#21487;&#33021;&#38656;&#35201;&#22810;&#20010;epoch&#30340;&#25968;&#25454;&#28857;&#25165;&#33021;&#36827;&#34892;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#25216;&#26415;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#27973;&#23618;&#30340;&#32593;&#32476;&#32780;&#35328;&#12290;&#23427;&#19981;&#26159;&#26354;&#32447;&#36319;&#38543;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#8220;&#20998;&#31163;&#8221;&#38544;&#34255;&#23618;&#24182;&#36890;&#36807;&#33258;&#21161;&#27861;&#12289;&#37325;&#25277;&#26679;&#21644;&#32447;&#24615;&#22238;&#24402;&#26469;&#26356;&#26032;&#23427;&#20204;&#30340;&#21152;&#26435;&#36830;&#25509;&#12290;&#36890;&#36807;&#21033;&#29992;&#37325;&#25277;&#26679;&#30340;&#35266;&#27979;&#20540;&#65292;&#26412;&#26041;&#27861;&#30340;&#25910;&#25947;&#34987;&#23454;&#35777;&#22320;&#26174;&#31034;&#20986;&#24555;&#36895;&#21644;&#38656;&#35201;&#26356;&#23569;&#30340;&#25968;&#25454;&#28857;&#65306;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#21482;&#38656;&#35201;&#23569;&#37327;&#30340;&#25968;&#25454;&#28857;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training a neural network (NN) typically relies on some type of curve-following method, such as gradient descent (GD) (and stochastic gradient descent (SGD)), ADADELTA, ADAM or limited memory algorithms. Convergence for these algorithms usually relies on having access to a large quantity of observations in order to achieve a high level of accuracy and, with certain classes of functions, these algorithms could take multiple epochs of data points to catch on. Herein, a different technique with the potential of achieving dramatically better speeds of convergence, especially for shallow networks, is explored: it does not curve-follow but rather relies on 'decoupling' hidden layers and on updating their weighted connections through bootstrapping, resampling and linear regression. By utilizing resampled observations, the convergence of this process is empirically shown to be remarkably fast and to require a lower amount of data points: in particular, our experiments show that one needs a fra
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22522;&#20110;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#36716;&#31227;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#25968;&#25454;&#38598;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#23545;&#35937;&#26102;&#65292;VNN&#33021;&#22815;&#23637;&#29616;&#20986;&#24615;&#33021;&#21487;&#36716;&#31227;&#24615;&#12290;&#22810;&#23610;&#24230;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#38598;&#21487;&#20197;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#30740;&#31350;&#33041;&#37096;&#65292;&#24182;&#19988;&#21487;&#20197;&#39564;&#35777;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.01807</link><description>&lt;p&gt;
&#22522;&#20110;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#36716;&#31227;&#23398;&#20064;&#21644;&#24212;&#29992;&#20110;&#35299;&#37322;&#24615;&#33041;&#40836;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Transferablility of coVariance Neural Networks and Application to Interpretable Brain Age Prediction using Anatomical Features. (arXiv:2305.01807v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22522;&#20110;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#36716;&#31227;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#25968;&#25454;&#38598;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#23545;&#35937;&#26102;&#65292;VNN&#33021;&#22815;&#23637;&#29616;&#20986;&#24615;&#33021;&#21487;&#36716;&#31227;&#24615;&#12290;&#22810;&#23610;&#24230;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#38598;&#21487;&#20197;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#30740;&#31350;&#33041;&#37096;&#65292;&#24182;&#19988;&#21487;&#20197;&#39564;&#35777;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21033;&#29992;&#22522;&#20110;&#25299;&#25169;&#22270;&#30340;&#21367;&#31215;&#25805;&#20316;&#26469;&#32452;&#21512;&#22270;&#19978;&#30340;&#20449;&#24687;&#36827;&#34892;&#25512;&#29702;&#20219;&#21153;&#12290;&#25105;&#20204;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#21327;&#26041;&#24046;&#30697;&#38453;&#20316;&#20026;&#22270;&#26469;&#35774;&#35745;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#20256;&#32479;PCA&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#30340;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#65288;VNN&#65289;&#65292;&#24182;&#20855;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;&#26412;&#25991;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;&#21487;&#36716;&#31227;&#24615;&#30340;&#27010;&#24565;&#26159;&#20174;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#22312;&#8220;&#20860;&#23481;&#8221;&#30340;&#25968;&#25454;&#38598;&#19978;&#27867;&#21270;&#30340;&#30452;&#35266;&#26399;&#26395;&#20013;&#20135;&#29983;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;VNN&#20174;GCN&#32487;&#25215;&#30340;&#26080;&#26631;&#24230;&#25968;&#25454;&#22788;&#29702;&#26550;&#26500;&#65292;&#24182;&#35777;&#26126;&#24403;&#25968;&#25454;&#38598;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#23545;&#35937;&#26102;&#65292;VNN&#33021;&#22815;&#23637;&#29616;&#20986;&#24615;&#33021;&#21487;&#36716;&#31227;&#24615;&#12290;&#22810;&#23610;&#24230;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#38598;&#21487;&#20197;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#30740;&#31350;&#33041;&#37096;&#65292;&#24182;&#19988;&#21487;&#20197;&#39564;&#35777;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph convolutional networks (GCN) leverage topology-driven graph convolutional operations to combine information across the graph for inference tasks. In our recent work, we have studied GCNs with covariance matrices as graphs in the form of coVariance neural networks (VNNs) that draw similarities with traditional PCA-driven data analysis approaches while offering significant advantages over them. In this paper, we first focus on theoretically characterizing the transferability of VNNs. The notion of transferability is motivated from the intuitive expectation that learning models could generalize to "compatible" datasets (possibly of different dimensionalities) with minimal effort. VNNs inherit the scale-free data processing architecture from GCNs and here, we show that VNNs exhibit transferability of performance over datasets whose covariance matrices converge to a limit object. Multi-scale neuroimaging datasets enable the study of the brain at multiple scales and hence, can validate
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#34920;&#26126;&#23545;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#36827;&#34892;&#25311;&#21512;&#21487;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13761</link><description>&lt;p&gt;
&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization. (arXiv:2304.13761v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13761
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#34920;&#26126;&#23545;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#36827;&#34892;&#25311;&#21512;&#21487;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;(GBDT)&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#39640;&#25928;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22797;&#26434;&#30340;&#32467;&#26500;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#23545;&#26410;&#35265;&#25968;&#25454;&#20013;&#30340;&#23567;&#21327;&#21464;&#37327;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#36739;&#20302;&#12290;&#26412;&#30740;&#31350;&#24212;&#29992;&#29420;&#28909;&#32534;&#30721;&#23558;GBDT&#27169;&#22411;&#36716;&#25442;&#20026;&#32447;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#26641;&#21494;&#32534;&#30721;&#20026;&#19968;&#20010;&#34394;&#25311;&#21464;&#37327;&#12290;&#36825;&#20801;&#35768;&#20351;&#29992;&#32447;&#24615;&#22238;&#24402;&#25216;&#26415;&#65292;&#20197;&#21450;&#19968;&#31181;&#26032;&#39062;&#30340;&#39118;&#38505;&#20998;&#35299;&#26041;&#27861;&#26469;&#35780;&#20272;GBDT&#27169;&#22411;&#23545;&#21327;&#21464;&#37327;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#37325;&#26032;&#25311;&#21512;&#20854;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#65292;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#20102;&#27491;&#21017;&#21270;&#23545;&#27169;&#22411;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#29420;&#28909;&#32534;&#30721;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-boosted decision trees (GBDT) are widely used and highly effective machine learning approach for tabular data modeling. However, their complex structure may lead to low robustness against small covariate perturbation in unseen data. In this study, we apply one-hot encoding to convert a GBDT model into a linear framework, through encoding of each tree leaf to one dummy variable. This allows for the use of linear regression techniques, plus a novel risk decomposition for assessing the robustness of a GBDT model against covariate perturbations. We propose to enhance the robustness of GBDT models by refitting their linear regression forms with $L_1$ or $L_2$ regularization. Theoretical results are obtained about the effect of regularization on the model performance and robustness. It is demonstrated through numerical experiments that the proposed regularization approach can enhance the robustness of the one-hot-encoded GBDT models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#21644;&#30072;&#24418;&#22495;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.01294</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31232;&#30095;Cholesky&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes. (arXiv:2304.01294v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#26031;&#36807;&#31243;&#27714;&#35299;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#39640;&#32500;&#21644;&#30072;&#24418;&#22495;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#26694;&#26550;&#27714;&#35299;&#19968;&#33324;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35745;&#31639;&#21487;&#20280;&#32553;&#24615;&#12290;&#36825;&#20010;&#26694;&#26550;&#25226;&#27714;&#35299;PDE&#36716;&#21270;&#20026;&#35299;&#38750;&#32447;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#27425;&#20248;&#21270;&#38382;&#39064;&#12290;&#20854;&#22797;&#26434;&#24230;&#30340;&#29942;&#39048;&#22312;&#20110;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#30340;&#21327;&#26041;&#24046;&#26680;&#21450;&#20854;&#22312;&#25311;&#21512;&#28857;&#30340;&#20559;&#23548;&#25968;&#36827;&#34892;&#28857;&#23545;&#28857;&#35745;&#31639;&#25152;&#24471;&#21040;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Diracs&#21644;&#23548;&#25968;&#27979;&#37327;&#30340;&#26032;&#25490;&#21015;&#39034;&#24207;&#30340;&#31232;&#30095;Cholesky&#20998;&#35299;&#31639;&#27861;&#29992;&#20110;&#35745;&#31639;&#27492;&#31867;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#20005;&#26684;&#22320;&#30830;&#23450;&#20102;&#35813;Cholesky&#20998;&#35299;&#30340;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#37327;&#21270;&#20102;&#30456;&#24212;Vecchia&#36817;&#20284;&#30340;&#25351;&#25968;&#25910;&#25947;&#31934;&#24230;&#65292;&#22312;Kullback-Leibler&#36317;&#31163;&#24230;&#37327;&#19979;&#36798;&#21040;&#26368;&#20248;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;$O(N\log^d(N/\epsilon))$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;$O(N\log^{d+2}(N/\epsilon))$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#35745;&#31639;$\epsilon$-&#36817;&#20284;&#30340;&#36870;Cholesky&#22240;&#23376;&#12290;&#20854;&#20013;&#65292;$N$&#34920;&#31034;&#25311;&#21512;&#28857;&#30340;&#25968;&#37327;&#65292;$d$&#20026;&#29289;&#29702;&#22495;&#30340;&#32500;&#25968;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#39640;&#32500;&#65288;&#26368;&#39640;&#21487;&#36798;&#21040;$d=50$&#65289;&#21644;&#30072;&#24418;&#22495;&#30340;&#22522;&#20934;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the computational scalability of a Gaussian process (GP) framework for solving general nonlinear partial differential equations (PDEs). This framework transforms solving PDEs to solving quadratic optimization problem with nonlinear constraints. Its complexity bottleneck lies in computing with dense kernel matrices obtained from pointwise evaluations of the covariance kernel of the GP and its partial derivatives at collocation points.  We present a sparse Cholesky factorization algorithm for such kernel matrices based on the near-sparsity of the Cholesky factor under a new ordering of Diracs and derivative measurements. We rigorously identify the sparsity pattern and quantify the exponentially convergent accuracy of the corresponding Vecchia approximation of the GP, which is optimal in the Kullback-Leibler divergence. This enables us to compute $\epsilon$-approximate inverse Cholesky factors of the kernel matrices with complexity $O(N\log^d(N/\epsilon))$ in space and $O(N\log^{
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#22823;&#35268;&#27169;&#36890;&#29992;&#26680;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#35299;&#20915;&#20102;&#20256;&#32479;&#26680;&#26426;&#22120;&#20013;&#27169;&#22411;&#22823;&#23567;&#19982;&#25968;&#25454;&#22823;&#23567;&#30456;&#20114;&#32806;&#21512;&#30340;&#38382;&#39064;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2302.02605</link><description>&lt;p&gt;
&#21521;&#22823;&#26680;&#27169;&#22411;&#36808;&#36827;
&lt;/p&gt;
&lt;p&gt;
Toward Large Kernel Models. (arXiv:2302.02605v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#22823;&#35268;&#27169;&#36890;&#29992;&#26680;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#35299;&#20915;&#20102;&#20256;&#32479;&#26680;&#26426;&#22120;&#20013;&#27169;&#22411;&#22823;&#23567;&#19982;&#25968;&#25454;&#22823;&#23567;&#30456;&#20114;&#32806;&#21512;&#30340;&#38382;&#39064;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30456;&#27604;&#65292;&#26680;&#26426;&#22120;&#22312;&#23567;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#36890;&#24120;&#21487;&#20197;&#36798;&#21040;&#25110;&#36229;&#36807;DNN&#12290;&#26680;&#26426;&#22120;&#30340;&#20852;&#36259;&#21463;&#21040;&#20854;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#31561;&#25928;&#20110;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#21457;&#29616;&#30340;&#25512;&#21160;&#12290;&#28982;&#32780;&#65292;DNN&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#26159;&#23427;&#20204;&#33021;&#22815;&#29420;&#31435;&#22320;&#25193;&#23637;&#27169;&#22411;&#22823;&#23567;&#21644;&#35757;&#32451;&#25968;&#25454;&#37327;&#65292;&#32780;&#22312;&#20256;&#32479;&#30340;&#26680;&#26426;&#22120;&#20013;&#65292;&#27169;&#22411;&#22823;&#23567;&#19982;&#25968;&#25454;&#22823;&#23567;&#26159;&#30456;&#20114;&#32806;&#21512;&#30340;&#12290;&#30001;&#20110;&#36825;&#31181;&#32806;&#21512;&#65292;&#23558;&#26680;&#26426;&#22120;&#25193;&#23637;&#21040;&#22823;&#25968;&#25454;&#26159;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26500;&#24314;&#22823;&#35268;&#27169;&#36890;&#29992;&#26680;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36825;&#26159;&#26680;&#26426;&#22120;&#30340;&#19968;&#33324;&#21270;&#65292;&#36890;&#36807;&#35299;&#32806;&#27169;&#22411;&#21644;&#25968;&#25454;&#65292;&#20801;&#35768;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#25237;&#24433;&#21452;&#37325;&#39044;&#22788;&#29702;SGD&#30340;EigenPro 3.0&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20351;&#29992;&#29616;&#26377;&#26680;&#26041;&#27861;&#19981;&#21487;&#33021;&#23454;&#29616;&#30340;&#27169;&#22411;&#21644;&#25968;&#25454;&#35268;&#27169;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies indicate that kernel machines can often perform similarly or better than deep neural networks (DNNs) on small datasets. The interest in kernel machines has been additionally bolstered by the discovery of their equivalence to wide neural networks in certain regimes. However, a key feature of DNNs is their ability to scale the model size and training data size independently, whereas in traditional kernel machines model size is tied to data size. Because of this coupling, scaling kernel machines to large data has been computationally challenging. In this paper, we provide a way forward for constructing large-scale general kernel models, which are a generalization of kernel machines that decouples the model and data, allowing training on large datasets. Specifically, we introduce EigenPro 3.0, an algorithm based on projected dual preconditioned SGD and show scaling to model and data sizes which have not been possible with existing kernel methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#39564;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#25913;&#36827;&#36125;&#21494;&#26031;&#20998;&#23618;&#28151;&#21512;&#32858;&#31867;&#27169;&#22411;&#65292;&#22312;&#27599;&#20010;&#23618;&#32423;&#23545;&#33410;&#28857;&#23454;&#26045;&#26368;&#22823;&#38388;&#38548;&#32422;&#26463;&#20197;&#22686;&#24378;&#38598;&#32676;&#30340;&#20998;&#31163;&#12290;</title><link>http://arxiv.org/abs/2105.06903</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#23618;&#28151;&#21512;&#32858;&#31867;&#20013;&#30340;&#21518;&#39564;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Posterior Regularization on Bayesian Hierarchical Mixture Clustering. (arXiv:2105.06903v7 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.06903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#39564;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#25913;&#36827;&#36125;&#21494;&#26031;&#20998;&#23618;&#28151;&#21512;&#32858;&#31867;&#27169;&#22411;&#65292;&#22312;&#27599;&#20010;&#23618;&#32423;&#23545;&#33410;&#28857;&#23454;&#26045;&#26368;&#22823;&#38388;&#38548;&#32422;&#26463;&#20197;&#22686;&#24378;&#38598;&#32676;&#30340;&#20998;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20998;&#23618;&#28151;&#21512;&#32858;&#31867;&#36890;&#36807;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#29992;&#23618;&#32423;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#28151;&#21512;&#27169;&#22411;(HDPMM)&#26367;&#25442;&#20256;&#32479;&#30340;&#39640;&#26031;-&#39640;&#26031;&#26680;&#26469;&#23454;&#29616;&#20174;&#29238;&#33410;&#28857;&#21040;&#23376;&#33410;&#28857;&#30340;&#25193;&#25955;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#20998;&#23618;&#32858;&#31867;&#12290;&#28982;&#32780;&#65292;BHMC&#21487;&#33021;&#20250;&#20135;&#29983;&#20855;&#26377;&#39640;&#33410;&#28857;&#26041;&#24046;&#30340;&#26641;&#65292;&#34920;&#26126;&#22312;&#36739;&#39640;&#23618;&#32423;&#20043;&#38388;&#30340;&#33410;&#28857;&#20043;&#38388;&#23384;&#22312;&#36739;&#24369;&#30340;&#20998;&#31163;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21518;&#39564;&#27491;&#21017;&#21270;(Posterior Regularization)&#65292;&#23427;&#23545;&#27599;&#20010;&#23618;&#32423;&#30340;&#33410;&#28857;&#23454;&#26045;&#26368;&#22823;&#38388;&#38548;&#32422;&#26463;&#20197;&#22686;&#24378;&#38598;&#32676;&#30340;&#20998;&#31163;&#12290;&#25105;&#20204;&#38416;&#36848;&#20102;&#22914;&#20309;&#23558;PR&#24212;&#29992;&#20110;BHMC&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#22312;&#25913;&#36827;BHMC&#27169;&#22411;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian hierarchical mixture clustering (BHMC) improves traditionalBayesian hierarchical clustering by replacing conventional Gaussian-to-Gaussian kernels with a Hierarchical Dirichlet Process Mixture Model(HDPMM) for parent-to-child diffusion in the generative process. However,BHMC may produce trees with high nodal variance, indicating weak separation between nodes at higher levels. To address this issue, we employ Posterior Regularization, which imposes max-margin constraints on nodes at every level to enhance cluster separation. We illustrate how to apply PR toBHMC and demonstrate its effectiveness in improving the BHMC model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#22914;&#20309;&#22312;GNN&#20013;&#38024;&#23545;&#25200;&#21160;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#65292;&#24182;&#25552;&#20986;&#20102;&#31283;&#23450;-&#21487;&#35782;&#21035;GNN&#21453;&#23545;&#25200;&#21160; (SIGNNAP) &#27169;&#22411;&#20197;&#26080;&#30417;&#30563;&#24418;&#24335;&#23398;&#20064;&#21487;&#38752;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2008.11416</link><description>&lt;p&gt;
&#38024;&#23545;&#25200;&#21160;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Node Representations against Perturbations. (arXiv:2008.11416v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.11416
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#22914;&#20309;&#22312;GNN&#20013;&#38024;&#23545;&#25200;&#21160;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#65292;&#24182;&#25552;&#20986;&#20102;&#31283;&#23450;-&#21487;&#35782;&#21035;GNN&#21453;&#23545;&#25200;&#21160; (SIGNNAP) &#27169;&#22411;&#20197;&#26080;&#30417;&#30563;&#24418;&#24335;&#23398;&#20064;&#21487;&#38752;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476; (GNN) &#22312;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#34920;&#29616;&#12290;GNN&#30340;&#25104;&#21151;&#20851;&#38190;&#22240;&#32032;&#20043;&#19968;&#26159;&#33410;&#28857;&#34920;&#31034;&#19978;&#30340;&#8220;&#24179;&#28369;&#8221;&#23646;&#24615;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#22823;&#22810;&#25968;GNN&#27169;&#22411;&#23545;&#22270;&#36755;&#20837;&#30340;&#25200;&#21160;&#24456;&#33030;&#24369;&#65292;&#21487;&#33021;&#20250;&#23398;&#20064;&#21040;&#19981;&#21487;&#38752;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;GNN&#20013;&#38024;&#23545;&#25200;&#21160;&#23398;&#20064;&#33410;&#28857;&#34920;&#31034;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35748;&#20026;&#33410;&#28857;&#34920;&#31034;&#24212;&#22312;&#36755;&#20837;&#30053;&#24494;&#25200;&#21160;&#26102;&#20445;&#25345;&#31283;&#23450;&#65292;&#24182;&#19988;&#24212;&#33021;&#22815;&#35782;&#21035;&#19981;&#21516;&#32467;&#26500;&#30340;&#33410;&#28857;&#34920;&#31034;&#65292;&#36825;&#20004;&#32773;&#20998;&#21035;&#34987;&#31216;&#20026;&#33410;&#28857;&#34920;&#31034;&#30340;&#8220;&#31283;&#23450;&#24615;&#8221;&#21644;&#8220;&#21487;&#35782;&#21035;&#24615;&#8221;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31283;&#23450;-&#21487;&#35782;&#21035;GNN&#21453;&#23545;&#25200;&#21160; (SIGNNAP) &#30340;&#26032;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#23398;&#20064;&#21487;&#38752;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;SIGNNAP&#36890;&#36807;&#23545;&#27604;&#30446;&#26631;&#26469;&#24418;&#24335;&#21270;&#8220;&#31283;&#23450;&#24615;&#8221;&#21644;&#8220;&#21487;&#35782;&#21035;&#24615;&#8221;&#65292;&#24182;&#20445;&#30041;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Recent graph neural networks (GNN) has achieved remarkable performance in node representation learning. One key factor of GNN's success is the \emph{smoothness} property on node representations. Despite this, most GNN models are fragile to the perturbations on graph inputs and could learn unreliable node representations. In this paper, we study how to learn node representations against perturbations in GNN. Specifically, we consider that a node representation should remain stable under slight perturbations on the input, and node representations from different structures should be identifiable, which two are termed as the \emph{stability} and \emph{identifiability} on node representations, respectively. To this end, we propose a novel model called Stability-Identifiability GNN Against Perturbations (SIGNNAP) that learns reliable node representations in an unsupervised manner. SIGNNAP formalizes the \emph{stability} and \emph{identifiability} by a contrastive objective and preserves the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#36755;&#20986;&#19981;&#30830;&#23450;&#24615;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#23454;&#29616;&#12290;&#36825;&#19968;&#29702;&#35770;&#25552;&#20379;&#20102;&#25152;&#26377;&#29616;&#26377;&#30340;&#39034;&#24207;&#21462;&#26679;&#31574;&#30053;&#21644;&#20572;&#27490;&#20934;&#21017;&#30340;&#32479;&#19968;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2002.01569</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification for Bayesian Optimization. (arXiv:2002.01569v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.01569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#36755;&#20986;&#19981;&#30830;&#23450;&#24615;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#23454;&#29616;&#12290;&#36825;&#19968;&#29702;&#35770;&#25552;&#20379;&#20102;&#25152;&#26377;&#29616;&#26377;&#30340;&#39034;&#24207;&#21462;&#26679;&#31574;&#30053;&#21644;&#20572;&#27490;&#20934;&#21017;&#30340;&#32479;&#19968;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#25216;&#26415;&#12290;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#30446;&#26631;&#20989;&#25968;&#34987;&#24314;&#27169;&#20026;&#39640;&#26031;&#36807;&#31243;&#30340;&#23454;&#29616;&#12290;&#23613;&#31649;&#39640;&#26031;&#36807;&#31243;&#30340;&#20551;&#35774;&#24847;&#21619;&#30528;&#36125;&#21494;&#26031;&#20248;&#21270;&#36755;&#20986;&#30340;&#38543;&#26426;&#20998;&#24067;&#65292;&#20294;&#23545;&#20110;&#27492;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#22312;&#25991;&#29486;&#20013;&#24456;&#23569;&#26377;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#30340;&#36755;&#20986;&#19981;&#30830;&#23450;&#24615;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26500;&#24314;&#30446;&#26631;&#20989;&#25968;&#26368;&#22823;&#28857;&#65288;&#25110;&#20540;&#65289;&#30340;&#32622;&#20449;&#21306;&#38388;&#26469;&#23454;&#29616;&#12290;&#36825;&#20123;&#21306;&#38388;&#21487;&#20197;&#39640;&#25928;&#22320;&#35745;&#31639;&#65292;&#20854;&#32622;&#20449;&#27700;&#24179;&#30001;&#26412;&#30740;&#31350;&#20013;&#26032;&#24320;&#21457;&#30340;&#39034;&#24207;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#32479;&#19968;&#35823;&#24046;&#30028;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20026;&#25152;&#26377;&#29616;&#26377;&#30340;&#39034;&#24207;&#21462;&#26679;&#31574;&#30053;&#21644;&#20572;&#27490;&#20934;&#21017;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a class of global optimization techniques. In Bayesian optimization, the underlying objective function is modeled as a realization of a Gaussian process. Although the Gaussian process assumption implies a random distribution of the Bayesian optimization outputs, quantification of this uncertainty is rarely studied in the literature. In this work, we propose a novel approach to assess the output uncertainty of Bayesian optimization algorithms, which proceeds by constructing confidence regions of the maximum point (or value) of the objective function. These regions can be computed efficiently, and their confidence levels are guaranteed by the uniform error bounds for sequential Gaussian process regression newly developed in the present work. Our theory provides a unified uncertainty quantification framework for all existing sequential sampling policies and stopping criteria.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#21098;&#24322;&#24120;&#20540;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21024;&#38500;&#26368;&#19981;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#28857;&#65292;&#28982;&#21518;&#29992;&#31526;&#21512;&#21442;&#32771;&#20998;&#24067;&#30340;&#23545;&#25968;&#20284;&#28982;&#24230;&#36827;&#34892;&#20462;&#21098;&#65292;&#20174;&#32780;&#22266;&#26377;&#20272;&#35745;&#24322;&#24120;&#20540;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/1907.01136</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#27169;&#22411;&#30340;&#32858;&#31867;&#20013;&#24322;&#24120;&#20540;&#30340;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Finding Outliers in Gaussian Model-Based Clustering. (arXiv:1907.01136v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1907.01136
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#21098;&#24322;&#24120;&#20540;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21024;&#38500;&#26368;&#19981;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#28857;&#65292;&#28982;&#21518;&#29992;&#31526;&#21512;&#21442;&#32771;&#20998;&#24067;&#30340;&#23545;&#25968;&#20284;&#28982;&#24230;&#36827;&#34892;&#20462;&#21098;&#65292;&#20174;&#32780;&#22266;&#26377;&#20272;&#35745;&#24322;&#24120;&#20540;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#20998;&#31867;&#25110;&#32858;&#31867;&#24120;&#24120;&#21463;&#21040;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#26080;&#30417;&#30563;&#20998;&#31867;&#20013;&#22788;&#29702;&#24322;&#24120;&#20540;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#30446;&#21069;&#65292;&#24322;&#24120;&#20540;&#31639;&#27861;&#21487;&#20998;&#20026;&#20004;&#22823;&#31867;&#65306;&#24322;&#24120;&#28857;&#21253;&#21547;&#26041;&#27861;&#21644;&#20462;&#21098;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35201;&#21024;&#38500;&#30340;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;&#12290;&#26412;&#25991;&#21033;&#29992;&#26679;&#26412;&#39532;&#27663;&#36317;&#31163;&#30340;&#36125;&#22612;&#20998;&#24067;&#23548;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#20998;&#24067;&#65292;&#29992;&#20110;&#26377;&#38480;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#23376;&#38598;&#30340;&#23545;&#25968;&#20284;&#28982;&#24230;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21024;&#38500;&#26368;&#19981;&#21487;&#33021;&#20986;&#29616;&#30340;&#25968;&#25454;&#28857;&#65292;&#21363;&#21028;&#23450;&#20026;&#24322;&#24120;&#20540;&#65292;&#30452;&#21040;&#23545;&#25968;&#20284;&#28982;&#24230;&#31526;&#21512;&#21442;&#32771;&#20998;&#24067;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#22266;&#26377;&#20272;&#35745;&#24322;&#24120;&#20540;&#25968;&#37327;&#30340;&#20462;&#21098;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised classification, or clustering, is a problem often plagued by outliers, yet there is a paucity of work on handling outliers in unsupervised classification. Outlier algorithms tend to fall into two broad categories: outlier inclusion methods and trimming methods, which often require pre-specification of the number of points to remove. The fact that sample Mahalanobis distance is beta-distributed is used to derive an approximate distribution for the log-likelihoods of subset finite Gaussian mixture models. An algorithm is proposed that removes the least likely points, which are deemed outliers, until the log-likelihoods adhere to the reference distribution. This results in a trimming method which inherently estimates the number of outliers present.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;CoarsenRank&#65292;&#20854;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#27169;&#22411;&#38169;&#35823;&#29305;&#21270;&#12290;&#23427;&#37319;&#29992;&#30001;&#31895;&#21040;&#31934;&#30340;&#26041;&#26696;&#26469;&#22788;&#29702;&#29992;&#25143;&#25910;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#21033;&#29992;&#25490;&#21517;&#31354;&#38388;&#20013;&#30340;&#20960;&#20309;&#32467;&#26500;&#26469;&#26356;&#22909;&#22320;&#27169;&#25311;&#32858;&#21512;&#36807;&#31243;&#12290;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;CoarsenRank&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/1905.12341</link><description>&lt;p&gt;
&#24555;&#36895;&#12289;&#40065;&#26834;&#30340;&#25490;&#21517;&#32858;&#21512;&#31639;&#27861;&#22312;&#27169;&#22411;&#38169;&#35823;&#29305;&#21270;&#26041;&#38754;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fast and Robust Rank Aggregation against Model Misspecification. (arXiv:1905.12341v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.12341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;CoarsenRank&#65292;&#20854;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#27169;&#22411;&#38169;&#35823;&#29305;&#21270;&#12290;&#23427;&#37319;&#29992;&#30001;&#31895;&#21040;&#31934;&#30340;&#26041;&#26696;&#26469;&#22788;&#29702;&#29992;&#25143;&#25910;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#21033;&#29992;&#25490;&#21517;&#31354;&#38388;&#20013;&#30340;&#20960;&#20309;&#32467;&#26500;&#26469;&#26356;&#22909;&#22320;&#27169;&#25311;&#32858;&#21512;&#36807;&#31243;&#12290;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;CoarsenRank&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#32858;&#21512;&#31639;&#27861;&#65288;RA&#65289;&#29992;&#20110;&#23558;&#26469;&#33258;&#19981;&#21516;&#29992;&#25143;&#30340;&#20559;&#22909;&#24635;&#32467;&#25104;&#19968;&#20010;&#24635;&#25490;&#24207;&#12290;&#22312;&#20551;&#35774;&#29992;&#25143;&#21516;&#36136;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#39033;&#24037;&#20316;&#22522;&#26412;&#26080;&#35823;&#12290;&#20294;&#22312;&#22797;&#26434;&#30340;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#21516;&#36136;&#20551;&#35774;&#26080;&#27861;&#39564;&#35777;&#65292;RA&#30340;&#27169;&#22411;&#38169;&#35823;&#29305;&#21270;&#20986;&#29616;&#20102;&#12290;&#29616;&#26377;&#30340;&#20581;&#22766;RA&#36890;&#24120;&#37319;&#29992;&#25490;&#21517;&#27169;&#22411;&#25193;&#20805;&#26469;&#35299;&#37322;&#39069;&#22806;&#30340;&#22122;&#22768;&#65292;&#20854;&#20013;&#25910;&#38598;&#21040;&#30340;&#20559;&#22909;&#21487;&#20197;&#34987;&#35270;&#20026;&#21333;&#20010;&#38468;&#21152;&#21040;&#29702;&#24819;&#20559;&#22909;&#19978;&#30340;&#25200;&#21160;&#12290;&#30001;&#20110;&#20581;&#22766;&#38383;&#38383;&#20142;RAs&#22823;&#22810;&#20381;&#36182;&#20110;&#26576;&#20123;&#25200;&#21160;&#20551;&#35774;&#65292;&#22240;&#27492;&#23427;&#20204;&#19981;&#33021;&#24456;&#22909;&#22320;&#25512;&#24191;&#21040;&#30495;&#23454;&#19990;&#30028;&#20013;&#23545;&#19981;&#30830;&#23450;&#22122;&#22768;&#30340;&#20559;&#22909;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CoarsenRank&#65292;&#23427;&#23545;&#27169;&#22411;&#30340;&#38169;&#35823;&#29305;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;CoarsenRank&#20855;&#26377;&#20197;&#19979;&#29305;&#24615;&#65306;&#65288;1&#65289;CoarsenRank&#26159;&#38024;&#23545;&#36731;&#24494;&#30340;&#27169;&#22411;&#38169;&#35823;&#29305;&#21270;&#32780;&#35774;&#35745;&#30340;&#65292;&#20551;&#35774;&#19982;&#27169;&#22411;&#20551;&#35774;&#19968;&#33268;&#30340;&#29702;&#24819;&#20559;&#22909;&#20301;&#20110;&#25910;&#38598;&#21040;&#30340;&#20559;&#22909;&#30340;&#38468;&#36817;&#12290;&#65288;2&#65289;CoarsenRank&#37319;&#29992;&#30001;&#31895;&#21040;&#31934;&#30340;&#26041;&#26696;&#26469;&#25429;&#25417;&#25910;&#38598;&#21040;&#30340;&#26469;&#33258;&#19981;&#21516;&#29992;&#25143;&#30340;&#32454;&#24494;&#24046;&#24322;&#65292; &#24182;&#21033;&#29992;&#32858;&#31867;&#25216;&#26415;&#12290;&#65288;3&#65289;CoarsenRank&#21033;&#29992;&#25490;&#21517;&#31354;&#38388;&#30340;&#20960;&#20309;&#32467;&#26500;&#26469;&#26356;&#22909;&#22320;&#27169;&#25311;&#32858;&#21512;&#36807;&#31243;&#65292;&#24182;&#36827;&#19968;&#27493;&#22686;&#24378;&#20854;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#28085;&#30422;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#65292;&#39564;&#35777;&#20102;CoarsenRank&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In rank aggregation (RA), a collection of preferences from different users are summarized into a total order under the assumption of homogeneity of users. Model misspecification in RA arises since the homogeneity assumption fails to be satisfied in the complex real-world situation. Existing robust RAs usually resort to an augmentation of the ranking model to account for additional noises, where the collected preferences can be treated as a noisy perturbation of idealized preferences. Since the majority of robust RAs rely on certain perturbation assumptions, they cannot generalize well to agnostic noise-corrupted preferences in the real world. In this paper, we propose CoarsenRank, which possesses robustness against model misspecification. Specifically, the properties of our CoarsenRank are summarized as follows: (1) CoarsenRank is designed for mild model misspecification, which assumes there exist the ideal preferences (consistent with model assumption) that locates in a neighborhood o
&lt;/p&gt;</description></item></channel></rss>