<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#29615;&#26694;&#26550;&#65292;&#21363;LLMs&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;&#65288;LATM&#65289;&#65292;&#20351;LLMs&#33021;&#22815;&#33258;&#20027;&#22320;&#21019;&#24314;&#29992;&#20110;&#35299;&#20915;&#38382;&#39064;&#30340;&#24037;&#20855;&#65292;&#32780;&#19981;&#38656;&#35201;&#20381;&#36182;&#20110;&#29616;&#26377;&#30340;&#22806;&#37096;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.17126</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;
&lt;/p&gt;
&lt;p&gt;
Large Language Models as Tool Makers. (arXiv:2305.17126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#29615;&#26694;&#26550;&#65292;&#21363;LLMs&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;&#65288;LATM&#65289;&#65292;&#20351;LLMs&#33021;&#22815;&#33258;&#20027;&#22320;&#21019;&#24314;&#29992;&#20110;&#35299;&#20915;&#38382;&#39064;&#30340;&#24037;&#20855;&#65292;&#32780;&#19981;&#38656;&#35201;&#20381;&#36182;&#20110;&#29616;&#26377;&#30340;&#22806;&#37096;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#20351;&#29992;&#22806;&#37096;&#24037;&#20855;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#21487;&#20197;&#22686;&#24378;&#20854;&#38382;&#39064;&#35299;&#20915;&#33021;&#21147;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#26041;&#38754;&#30340;&#20808;&#21069;&#24037;&#20316;&#20381;&#36182;&#20110;&#29616;&#26377;&#24037;&#20855;&#30340;&#21487;&#29992;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38381;&#29615;&#26694;&#26550;&#65292;&#31216;&#20026;LLMs As Tool Makers&#65288;LATM&#65289;&#65292;&#20197;&#28040;&#38500;&#36825;&#31181;&#20381;&#36182;&#24615;&#65292;&#20854;&#20013;LLMs&#21019;&#24314;&#33258;&#24049;&#30340;&#21487;&#37325;&#29992;&#24037;&#20855;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#20851;&#38190;&#38454;&#27573;&#65306;1&#65289;&#21046;&#36896;&#24037;&#20855;&#65306;LLM&#20316;&#20026;&#24037;&#20855;&#21046;&#36896;&#32773;&#65292;&#20026;&#32473;&#23450;&#20219;&#21153;&#21046;&#20316;&#24037;&#20855;&#65292;&#20854;&#20013;&#24037;&#20855;&#20316;&#20026;Python&#23454;&#29992;&#20989;&#25968;&#23454;&#29616;&#12290;2&#65289;&#20351;&#29992;&#24037;&#20855;&#65306;LLM&#20316;&#20026;&#24037;&#20855;&#29992;&#25143;&#65292;&#24212;&#29992;&#24037;&#20855;&#21046;&#36896;&#32773;&#26500;&#24314;&#30340;&#24037;&#20855;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#24037;&#20855;&#29992;&#25143;&#21487;&#20197;&#26159;&#19982;&#24037;&#20855;&#21046;&#36896;&#32773;&#30456;&#21516;&#25110;&#19981;&#21516;&#30340;LLM&#12290;&#24037;&#20855;&#21046;&#36896;&#20351;LLM&#33021;&#22815;&#19981;&#26029;&#29983;&#25104;&#21487;&#24212;&#29992;&#20110;&#19981;&#21516;&#35831;&#27714;&#30340;&#24037;&#20855;&#65292;&#20197;&#20415;&#23558;&#26469;&#35831;&#27714;&#22312;&#35299;&#20915;&#38382;&#39064;&#26102;&#33021;&#35843;&#29992;&#30456;&#24212;&#30340;API&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research shows the potential of enhancing the problem-solving ability of large language models (LLMs) through the use of external tools. However, prior work along this line depends on the availability of existing tools. In this work, we take an initial step towards removing this dependency by proposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM), where LLMs create their own reusable tools for problem-solving. Our approach consists of two key phases: 1) tool making: an LLM acts as the tool maker that crafts tools for given tasks, where a tool is implemented as a Python utility function. 2) tool using: an LLM acts as the tool user, which applies the tool built by the tool maker for problem-solving. The tool user can be either the same or a different LLM from the tool maker. Tool-making enables an LLM to continually generate tools that can be applied to different requests so that future requests can call the corresponding APIs when beneficial for solving the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27969;&#24418;&#27491;&#21017;&#21270;&#30446;&#26631;&#21644;&#35825;&#23548;&#20559;&#24046;&#32593;&#32476;&#35774;&#35745;&#21407;&#21017;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#23384;&#39640;&#25928;&#35757;&#32451;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#23398;&#20064;&#25216;&#26415;&#21487;&#33719;&#24471;&#26356;&#22909;&#30340;&#32477;&#23545;&#24615;&#33021;&#21644;&#23454;&#35777;&#19968;&#33324;&#21270;&#35823;&#24046;&#65292;&#32463;&#23454;&#39564;&#39564;&#35777;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2305.17119</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#23384;&#39640;&#25928;&#35757;&#32451;&#30340;&#27969;&#24418;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Manifold Regularization for Memory-Efficient Training of Deep Neural Networks. (arXiv:2305.17119v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27969;&#24418;&#27491;&#21017;&#21270;&#30446;&#26631;&#21644;&#35825;&#23548;&#20559;&#24046;&#32593;&#32476;&#35774;&#35745;&#21407;&#21017;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#23384;&#39640;&#25928;&#35757;&#32451;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#23398;&#20064;&#25216;&#26415;&#21487;&#33719;&#24471;&#26356;&#22909;&#30340;&#32477;&#23545;&#24615;&#33021;&#21644;&#23454;&#35777;&#19968;&#33324;&#21270;&#35823;&#24046;&#65292;&#32463;&#23454;&#39564;&#39564;&#35777;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#21644;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#20013;&#19968;&#31181;&#20027;&#27969;&#36235;&#21183;&#26159;&#65292;&#37319;&#29992;&#36234;&#26469;&#36234;&#22823;&#30340;&#27169;&#22411;&#20197;&#25512;&#21160;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#36235;&#21183;&#20351;&#26222;&#36890;&#20174;&#19994;&#32773;&#38590;&#20197;&#25509;&#35302;&#30456;&#20851;&#25216;&#26415;&#65292;&#19981;&#21033;&#20110;&#27665;&#20027;&#21270;&#30693;&#35782;&#30340;&#29983;&#20135;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#35825;&#23548;&#20559;&#24046;&#32593;&#32476;&#35774;&#35745;&#21407;&#21017;&#21644;&#22522;&#20110;&#23618;&#30340;&#27969;&#24418;&#27491;&#21017;&#21270;&#30446;&#26631;&#65292;&#23454;&#29616;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#36807;&#31243;&#20013;&#30340;&#20869;&#23384;&#25928;&#29575;&#25552;&#39640;&#12290;&#20351;&#29992;&#35813;&#26694;&#26550;&#21487;&#20197;&#30456;&#23545;&#20110;&#20256;&#32479;&#23398;&#20064;&#25216;&#26415;&#33719;&#24471;&#26356;&#22909;&#30340;&#32477;&#23545;&#24615;&#33021;&#21644;&#23454;&#35777;&#19968;&#33324;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#26694;&#26550;&#30340;&#23454;&#35777;&#39564;&#35777;&#65292;&#21253;&#25324;&#20854;&#22312;&#20004;&#20010;&#26631;&#20934;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#21363;CIFAR-10&#21644;CIFAR-100&#19978;&#30340;&#26377;&#25928;&#24615;&#30340;&#23450;&#24615;&#21644;&#23450;&#37327;&#35777;&#25454;&#12290;&#35813;&#25552;&#35758;&#30340;&#26694;&#26550;&#21487;&#20197;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the prevailing trends in the machine- and deep-learning community is to gravitate towards the use of increasingly larger models in order to keep pushing the state-of-the-art performance envelope. This tendency makes access to the associated technologies more difficult for the average practitioner and runs contrary to the desire to democratize knowledge production in the field. In this paper, we propose a framework for achieving improved memory efficiency in the process of learning traditional neural networks by leveraging inductive-bias-driven network design principles and layer-wise manifold-oriented regularization objectives. Use of the framework results in improved absolute performance and empirical generalization error relative to traditional learning techniques. We provide empirical validation of the framework, including qualitative and quantitative evidence of its effectiveness on two standard image datasets, namely CIFAR-10 and CIFAR-100. The proposed framework can be sea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#22411;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#21487;&#21516;&#26102;&#22788;&#29702;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17083</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Policy Gradient Method for Confounded POMDPs. (arXiv:2305.17083v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#22411;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#21487;&#21516;&#26102;&#22788;&#29702;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#30340;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#20351;&#29992;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35782;&#21035;&#32467;&#26524;&#65292;&#20197;&#22312;&#31163;&#32447;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;POMDP&#20013;&#30340;&#20219;&#20309;&#21382;&#21490;&#20381;&#36182;&#31574;&#30053;&#26799;&#24230;&#12290;&#35782;&#21035;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#35299;&#20915;&#19968;&#31995;&#21015;&#26465;&#20214;&#30697;&#38480;&#21046;&#65292;&#24182;&#37319;&#29992;&#20855;&#26377;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#26368;&#23567;&#26368;&#22823;&#23398;&#20064;&#36807;&#31243;&#26469;&#20272;&#35745;&#31574;&#30053;&#26799;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#38024;&#23545;&#39044;&#20808;&#25351;&#23450;&#30340;&#31574;&#30053;&#31867;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#30340;&#38750;&#28176;&#36817;&#20272;&#35745;&#30028;&#38480;&#65292;&#20197;&#20102;&#35299;&#26679;&#26412;&#22823;&#23567;&#12289;&#26102;&#38388;&#38271;&#24230;&#12289;&#38598;&#20013;&#24230;&#31995;&#25968;&#21644;&#27714;&#35299;&#26465;&#20214;&#30697;&#38480;&#21046;&#30340;&#20266;&#27491;&#21017;&#24230;&#37327;&#23545;&#20110;&#22343;&#21248;&#20272;&#35745;&#26799;&#24230;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#22312;&#26799;&#24230;&#19978;&#21319;&#31639;&#27861;&#20013;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#26799;&#24230;&#20272;&#35745;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#25214;&#21040;&#21382;&#21490;&#20381;&#36182;&#24615;&#31574;&#30053;&#26799;&#24230;&#26041;&#38754;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a policy gradient method for confounded partially observable Markov decision processes (POMDPs) with continuous state and observation spaces in the offline setting. We first establish a novel identification result to non-parametrically estimate any history-dependent policy gradient under POMDPs using the offline data. The identification enables us to solve a sequence of conditional moment restrictions and adopt the min-max learning procedure with general function approximation for estimating the policy gradient. We then provide a finite-sample non-asymptotic bound for estimating the gradient uniformly over a pre-specified policy class in terms of the sample size, length of horizon, concentratability coefficient and the measure of ill-posedness in solving the conditional moment restrictions. Lastly, by deploying the proposed gradient estimation in the gradient ascent algorithm, we show the global convergence of the proposed algorithm in finding the history-depe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;Wasserstein&#20998;&#24067;&#24335;&#24378;&#40065;&#26834;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#20445;&#35777;&#36866;&#29992;&#20110;&#19968;&#33324;&#27169;&#22411;&#31867;&#21035;&#65292;&#19981;&#21463;&#32500;&#25968;&#28798;&#38590;&#25152;&#22256;&#25200;&#65292;&#29978;&#33267;&#21487;&#20197;&#28085;&#30422;&#27979;&#35797;&#26102;&#30340;&#20998;&#24067;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.17076</link><description>&lt;p&gt;
&#65288;&#27491;&#21017;&#21270;&#65289;Wasserstein&#20998;&#24067;&#24335;&#24378;&#26368;&#20248;&#27169;&#22411;&#30340;&#30830;&#20999;&#27867;&#21270;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Exact Generalization Guarantees for (Regularized) Wasserstein Distributionally Robust Models. (arXiv:2305.17076v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;Wasserstein&#20998;&#24067;&#24335;&#24378;&#40065;&#26834;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#20445;&#35777;&#36866;&#29992;&#20110;&#19968;&#33324;&#27169;&#22411;&#31867;&#21035;&#65292;&#19981;&#21463;&#32500;&#25968;&#28798;&#38590;&#25152;&#22256;&#25200;&#65292;&#29978;&#33267;&#21487;&#20197;&#28085;&#30422;&#27979;&#35797;&#26102;&#30340;&#20998;&#24067;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Wasserstein&#20998;&#24067;&#24335;&#24378;&#40065;&#26834;&#20272;&#35745;&#22120;&#24050;&#32463;&#25104;&#20026;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#39044;&#27979;&#21644;&#20915;&#31574;&#30340;&#24378;&#22823;&#27169;&#22411;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#26377;&#21560;&#24341;&#21147;&#30340;&#27867;&#21270;&#20445;&#35777;&#65306;&#35757;&#32451;&#20998;&#24067;&#24471;&#21040;&#30340;&#24378;&#40065;&#26834;&#30446;&#26631;&#26159;&#30495;&#23454;&#39118;&#38505;&#30340;&#19968;&#20010;&#31934;&#30830;&#19978;&#30028;&#65292;&#24182;&#19988;&#39640;&#27010;&#29575;&#25104;&#31435;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20445;&#35777;&#35201;&#20040;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#22256;&#25200;&#65292;&#35201;&#20040;&#20165;&#38480;&#20110;&#29305;&#23450;&#30340;&#35774;&#32622;&#65292;&#25110;&#32773;&#20250;&#23548;&#33268;&#34394;&#20551;&#30340;&#38169;&#35823;&#26415;&#35821;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#36825;&#20123;&#27867;&#21270;&#20445;&#35777;&#23454;&#38469;&#19978;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#27169;&#22411;&#31867;&#21035;&#65292;&#19981;&#21463;&#32500;&#25968;&#28798;&#38590;&#25152;&#22256;&#25200;&#65292;&#29978;&#33267;&#21487;&#20197;&#28085;&#30422;&#27979;&#35797;&#26102;&#30340;&#20998;&#24067;&#21464;&#21270;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#25512;&#24191;&#21040;&#26032;&#24341;&#20837;&#30340;Wasserstein&#20998;&#24067;&#24335;&#24378;&#26368;&#20248;&#38382;&#39064;&#30340;&#27491;&#21017;&#21270;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wasserstein distributionally robust estimators have emerged as powerful models for prediction and decision-making under uncertainty. These estimators provide attractive generalization guarantees: the robust objective obtained from the training distribution is an exact upper bound on the true risk with high probability. However, existing guarantees either suffer from the curse of dimensionality, are restricted to specific settings, or lead to spurious error terms. In this paper, we show that these generalization guarantees actually hold on general classes of models, do not suffer from the curse of dimensionality, and can even cover distribution shifts at testing. We also prove that these results carry over to the newly-introduced regularized versions of Wasserstein distributionally robust problems.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#30340;Vecchia&#39640;&#26031;&#36807;&#31243;&#38598;&#25104;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#19982;DNN&#30456;&#32467;&#21512;&#65292;&#29983;&#25104;&#19968;&#31181;&#19981;&#20165;&#33021;&#22815;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#33021;&#22815;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26356;&#31283;&#20581;&#30340;&#39044;&#27979;&#30340;&#28145;&#24230;Vecchia&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.17063</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#19978;&#30340;Vecchia&#39640;&#26031;&#36807;&#31243;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Vecchia Gaussian Process Ensembles on Internal Representations of Deep Neural Networks. (arXiv:2305.17063v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17063
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#34920;&#24449;&#30340;Vecchia&#39640;&#26031;&#36807;&#31243;&#38598;&#25104;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#19982;DNN&#30456;&#32467;&#21512;&#65292;&#29983;&#25104;&#19968;&#31181;&#19981;&#20165;&#33021;&#22815;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19988;&#33021;&#22815;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26356;&#31283;&#20581;&#30340;&#39044;&#27979;&#30340;&#28145;&#24230;Vecchia&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22238;&#24402;&#20219;&#21153;&#65292;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;(GPs)&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#32780;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#25797;&#38271;&#34920;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#65292;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#21327;&#21516;&#32452;&#21512;&#36215;&#26469;&#65292;&#24418;&#25104;&#19968;&#20010;&#22522;&#20110;DNN&#30340;&#38544;&#34255;&#23618;&#36755;&#20986;&#26500;&#24314;&#30340;GP&#38598;&#21512;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#37051;&#26465;&#20214;&#29420;&#31435;&#30340;Vecchia&#36817;&#20284;&#23454;&#29616;&#20102;GP&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#29983;&#25104;&#30340;&#28145;&#24230;Vecchia&#38598;&#21512;&#19981;&#20165;&#36171;&#20104;DNN&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#36824;&#21487;&#20197;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#26356;&#31283;&#20581;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#25928;&#29992;&#65292;&#24182;&#36827;&#34892;&#20102;&#23454;&#39564;&#20197;&#20102;&#35299;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#20869;&#37096;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
For regression tasks, standard Gaussian processes (GPs) provide natural uncertainty quantification, while deep neural networks (DNNs) excel at representation learning. We propose to synergistically combine these two approaches in a hybrid method consisting of an ensemble of GPs built on the output of hidden layers of a DNN. GP scalability is achieved via Vecchia approximations that exploit nearest-neighbor conditional independence. The resulting deep Vecchia ensemble not only imbues the DNN with uncertainty quantification but can also provide more accurate and robust predictions. We demonstrate the utility of our model on several datasets and carry out experiments to understand the inner workings of the proposed method.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31934;&#30830;&#25512;&#29702;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#31163;&#25955;&#37319;&#26679;&#12289;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#12290;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#23454;&#29616;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#24615;&#33021;&#20248;&#20110;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#24182;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.17058</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#31163;&#25955;&#27169;&#22411;&#31934;&#30830;&#25512;&#29702;&#65306;&#27010;&#29575;&#32534;&#31243;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach. (arXiv:2305.17058v1 [cs.PL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17058
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31934;&#30830;&#25512;&#29702;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#25903;&#25345;&#31163;&#25955;&#37319;&#26679;&#12289;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#12290;&#36890;&#36807;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#23454;&#29616;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#24615;&#33021;&#20248;&#20110;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#24182;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#25955;&#32479;&#35745;&#27169;&#22411;&#30340;&#31934;&#30830;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#21363;&#20351;&#26159;&#23545;&#20110;&#26080;&#38480;&#25903;&#25345;&#21644;&#36830;&#32493;&#20808;&#39564;&#20063;&#21487;&#20197;&#25214;&#21040;&#20934;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#34920;&#36798;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#25903;&#25345;&#31163;&#25955;&#21644;&#36830;&#32493;&#37319;&#26679;&#12289;&#31163;&#25955;&#35266;&#27979;&#12289;&#20223;&#23556;&#20989;&#25968;&#12289;&#65288;&#38543;&#26426;&#65289;&#20998;&#25903;&#21644;&#20107;&#20214;&#26465;&#20214;&#30340;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;&#27010;&#29575;&#29983;&#25104;&#20989;&#25968;&#65306;&#23427;&#20204;&#25552;&#20379;&#20102;&#23450;&#20041;&#31243;&#24207;&#30340;&#20998;&#24067;&#30340;&#32039;&#20945;&#38381;&#21512;&#24418;&#24335;&#34920;&#31034;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#21518;&#39564;&#27010;&#29575;&#12289;&#26399;&#26395;&#12289;&#26041;&#24046;&#21644;&#39640;&#38454;&#30697;&#30340;&#31934;&#30830;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#25512;&#29702;&#26041;&#27861;&#26159;&#21487;&#35777;&#26126;&#27491;&#30830;&#30340;&#12289;&#23436;&#20840;&#33258;&#21160;&#21270;&#30340;&#65292;&#20351;&#29992;&#33258;&#21160;&#24494;&#20998;&#65288;&#29305;&#21035;&#26159;&#27888;&#21202;&#22810;&#39033;&#24335;&#65289;&#65292;&#20294;&#19981;&#38656;&#35201;&#35745;&#31639;&#26426;&#20195;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#20013;&#30340;&#24615;&#33021;&#19982;&#36817;&#20284;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#31454;&#20105;&#65292;&#21516;&#26102;&#36991;&#20813;&#20102;&#36817;&#20284;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to many discrete inference problems, even with infinite support and continuous priors. To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on events. Our key tool is probability generating functions: they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments. Our inference method is provably correct, fully automated and uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra. Our experiments show that its performance on a range of real-world examples is competitive with approximate Monte Carlo methods, while avoiding approximation errors
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)&#26041;&#27861;&#22312;&#24515;&#30005;&#22270;(ECG)&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#22871;&#26816;&#26597;&#25514;&#26045;&#20197;&#30830;&#23450;&#21512;&#29702;&#30340;&#24402;&#22240;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#24739;&#32773;&#20122;&#32452;&#30340;&#25968;&#25454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#36825;&#20123;XAI&#25216;&#26415;&#22914;&#20309;&#34987;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#65292;&#22914;&#35782;&#21035;&#24515;&#32908;&#26775;&#27515;&#20122;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.17043</link><description>&lt;p&gt;
&#35299;&#26512;&#24515;&#30005;&#22270;&#20998;&#26512;&#30340;&#28145;&#24230;&#23398;&#20064;&#65306;&#23457;&#35745;&#21644;&#30693;&#35782;&#21457;&#29616;&#30340;&#22522;&#30707;
&lt;/p&gt;
&lt;p&gt;
Explaining Deep Learning for ECG Analysis: Building Blocks for Auditing and Knowledge Discovery. (arXiv:2305.17043v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;(XAI)&#26041;&#27861;&#22312;&#24515;&#30005;&#22270;(ECG)&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#22871;&#26816;&#26597;&#25514;&#26045;&#20197;&#30830;&#23450;&#21512;&#29702;&#30340;&#24402;&#22240;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#24739;&#32773;&#20122;&#32452;&#30340;&#25968;&#25454;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#36825;&#20123;XAI&#25216;&#26415;&#22914;&#20309;&#34987;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#65292;&#22914;&#35782;&#21035;&#24515;&#32908;&#26775;&#27515;&#20122;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#20934;&#30830;&#35782;&#21035;&#24515;&#33039;&#30142;&#30149;&#21644;&#38544;&#34255;&#30340;&#20020;&#24202;&#22240;&#32032;&#65292;&#22240;&#27492;&#23427;&#20204;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#22320;&#29992;&#20110;&#20998;&#26512;&#24515;&#30005;&#22270;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#40657;&#21283;&#23376;&#29305;&#24615;&#32570;&#20047;&#36879;&#26126;&#24230;&#65292;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#21518;&#20107;&#35299;&#37322;(XAI)&#26041;&#27861;&#30340;&#20840;&#38754;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#23616;&#37096;(&#27599;&#20010;&#26679;&#26412;&#30340;&#36129;&#29486;&#20540;)&#21644;&#20840;&#23616;(&#22522;&#20110;&#39046;&#22495;&#19987;&#23478;&#27010;&#24565;)&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#22871;&#26816;&#26597;&#25514;&#26045;&#65292;&#20197;&#30830;&#23450;&#21512;&#29702;&#30340;&#24402;&#22240;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#31526;&#21512;&#19987;&#23478;&#35268;&#21017;&#30340;&#23450;&#37327;&#35777;&#25454;&#12290;&#36825;&#31181;&#25968;&#25454;&#38598;&#33539;&#22260;&#30340;&#20998;&#26512;&#36229;&#20986;&#20102;&#20010;&#26696;&#32463;&#39564;&#35777;&#25454;&#65292;&#36890;&#36807;&#27719;&#24635;&#24739;&#32773;&#20122;&#32452;&#30340;&#25968;&#25454;&#26469;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;XAI&#25216;&#26415;&#22914;&#20309;&#34987;&#29992;&#20110;&#30693;&#35782;&#21457;&#29616;&#65292;&#22914;&#35782;&#21035;&#24515;&#32908;&#26775;&#27515;&#30340;&#20122;&#22411;&#12290;&#25105;&#20204;&#30456;&#20449;&#65292;&#36825;&#20123;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20316;&#20026;&#23457;&#35745;&#21644;&#30693;&#35782;&#21457;&#29616;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks have become increasingly popular for analyzing ECG data because of their ability to accurately identify cardiac conditions and hidden clinical factors. However, the lack of transparency due to the black box nature of these models is a common concern. To address this issue, explainable AI (XAI) methods can be employed. In this study, we present a comprehensive analysis of post-hoc XAI methods, investigating the local (attributions per sample) and global (based on domain expert concepts) perspectives. We have established a set of sanity checks to identify sensible attribution methods, and we provide quantitative evidence in accordance with expert rules. This dataset-wide analysis goes beyond anecdotal evidence by aggregating data across patient subgroups. Furthermore, we demonstrate how these XAI techniques can be utilized for knowledge discovery, such as identifying subtypes of myocardial infarction. We believe that these proposed methods can serve as building block
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.17028</link><description>&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#26356;&#22909;Batch&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Better Batch for Deep Probabilistic Time Series Forecasting. (arXiv:2305.17028v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17028
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22240;&#20854;&#33021;&#22815;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#36807;&#20110;&#31616;&#21333;&#21270;&#38382;&#39064;&#65292;&#20551;&#35774;&#35823;&#24046;&#36807;&#31243;&#26159;&#19982;&#26102;&#38388;&#26080;&#20851;&#30340;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#35823;&#24046;&#36807;&#31243;&#20013;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#12290;&#36825;&#21487;&#33021;&#20250;&#38477;&#20302;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#36825;&#20123;&#27169;&#22411;&#23545;&#20915;&#31574;&#24615;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#20943;&#24369;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#35823;&#24046;&#33258;&#30456;&#20851;&#24615;&#32435;&#20837;&#32771;&#34385;&#65292;&#20197;&#22686;&#24378;&#27010;&#29575;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#26500;&#36896;&#19968;&#20010;mini-batch&#65292;&#20316;&#20026;$D$&#20010;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#27573;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#24182;&#26174;&#24335;&#22320;&#23398;&#20064;&#19968;&#20010;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#35206;&#30422;&#20102;&#30456;&#37051;&#26102;&#38388;&#27493;&#20043;&#38388;&#30340;&#35823;&#24046;&#30456;&#20851;&#24615;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#21487;&#29992;&#20110;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep probabilistic time series forecasting has gained significant attention due to its ability to provide valuable uncertainty quantification for decision-making tasks. However, many existing models oversimplify the problem by assuming the error process is time-independent, thereby overlooking the serial correlation in the error process. This oversight can potentially diminish the accuracy of the forecasts, rendering these models less effective for decision-making purposes. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance the accuracy of probabilistic forecasting. Our method involves constructing a mini-batch as a collection of $D$ consecutive time series segments for model training and explicitly learning a covariance matrix over each mini-batch that encodes the error correlation among adjacent time steps. The resulting covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantifica
&lt;/p&gt;</description></item><item><title>GLOBE-CE&#26159;&#19968;&#31181;&#29992;&#20110;&#20840;&#29699;&#22240;&#26524;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#36229;&#36234;&#23616;&#37096;&#35299;&#37322;&#65292;&#25552;&#20379;&#26356;&#26377;&#25928;&#21644;&#20132;&#20114;&#24335;&#30340;&#35299;&#37322;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.17021</link><description>&lt;p&gt;
GLOBE-CE&#65306;&#19968;&#31181;&#29992;&#20110;&#20840;&#29699;&#22240;&#26524;&#35299;&#37322;&#30340;&#22522;&#20110;&#32763;&#35793;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
GLOBE-CE: A Translation-Based Approach for Global Counterfactual Explanations. (arXiv:2305.17021v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17021
&lt;/p&gt;
&lt;p&gt;
GLOBE-CE&#26159;&#19968;&#31181;&#29992;&#20110;&#20840;&#29699;&#22240;&#26524;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#36229;&#36234;&#23616;&#37096;&#35299;&#37322;&#65292;&#25552;&#20379;&#26356;&#26377;&#25928;&#21644;&#20132;&#20114;&#24335;&#30340;&#35299;&#37322;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#35299;&#37322;&#22312;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20844;&#24179;&#24615;&#12289;&#36861;&#32034;&#26435;&#21644;&#27169;&#22411;&#29702;&#35299;&#31561;&#39046;&#22495;&#30340;&#24212;&#29992;&#20381;&#36182;&#20110;&#19968;&#31995;&#21015;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#26368;&#22823;&#30340;&#32570;&#28857;&#26159;&#26080;&#27861;&#25552;&#20379;&#36229;&#36234;&#23616;&#37096;&#25110;&#23454;&#20363;&#32423;&#21035;&#30340;&#35299;&#37322;&#12290;&#23613;&#31649;&#35768;&#22810;&#20316;&#21697;&#28041;&#21450;&#20840;&#23616;&#35299;&#37322;&#30340;&#27010;&#24565;&#65292;&#36890;&#24120;&#24314;&#35758;&#32858;&#21512;&#22823;&#37327;&#23616;&#37096;&#35299;&#37322;&#20197;&#30830;&#23450;&#20840;&#23616;&#23646;&#24615;&#65292;&#20294;&#24456;&#23569;&#25552;&#20379;&#21487;&#38752;&#19988;&#35745;&#31639;&#21487;&#34892;&#30340;&#26694;&#26550;&#12290;&#21516;&#26102;&#65292;&#23454;&#36341;&#32773;&#38656;&#35201;&#26356;&#26377;&#25928;&#21644;&#20132;&#20114;&#24335;&#30340;&#21487;&#35299;&#37322;&#24615;&#24037;&#20855;&#12290;&#25105;&#20204;&#20511;&#27492;&#26426;&#20250;&#25552;&#20986;&#20102;&#20840;&#23616;&#19988;&#26377;&#25928;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26694;&#26550;(GLOBE-CE)&#65292;&#36825;&#26159;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#26694;&#26550;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#21644;&#36830;&#32493;&#29305;&#24449;&#23384;&#22312;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25968;&#23398;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual explanations have been widely studied in explainability, with a range of application dependent methods prominent in fairness, recourse and model understanding. The major shortcoming associated with these methods, however, is their inability to provide explanations beyond the local or instance-level. While many works touch upon the notion of a global explanation, typically suggesting to aggregate masses of local explanations in the hope of ascertaining global properties, few provide frameworks that are both reliable and computationally tractable. Meanwhile, practitioners are requesting more efficient and interactive explainability tools. We take this opportunity to propose Global &amp; Efficient Counterfactual Explanations (GLOBE-CE), a flexible framework that tackles the reliability and scalability issues associated with current state-of-the-art, particularly on higher dimensional datasets and in the presence of continuous features. Furthermore, we provide a unique mathemati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GFlowNets&#30340;&#26426;&#22120;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#35757;&#32451;&#26041;&#38754;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.17010</link><description>&lt;p&gt;
&#21033;&#29992;GFlowNets&#35299;&#20915;&#22270;&#24418;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Let the Flows Tell: Solving Graph Combinatorial Optimization Problems with GFlowNets. (arXiv:2305.17010v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;GFlowNets&#30340;&#26426;&#22120;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#35757;&#32451;&#26041;&#38754;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#32467;&#26524;&#34920;&#26126;&#20854;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#26159;NP&#38590;&#39064;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;&#31934;&#30830;&#31639;&#27861;&#65292;&#36825;&#20351;&#23427;&#20204;&#25104;&#20026;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#29702;&#24819;&#39046;&#22495;&#12290;&#36825;&#20123;&#38382;&#39064;&#20013;&#39640;&#24230;&#32467;&#26500;&#21270;&#30340;&#38480;&#21046;&#21487;&#33021;&#20250;&#30452;&#25509;&#38459;&#30861;&#20248;&#21270;&#25110;&#37319;&#26679;&#35299;&#20915;&#26041;&#26696;&#30340;&#31354;&#38388;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;GFlowNets&#26368;&#36817;&#34987;&#21457;&#29616;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26426;&#22120;&#65292;&#21487;&#20197;&#39034;&#24207;&#22320;&#20174;&#22797;&#21512;&#38750;&#35268;&#33539;&#21270;&#23494;&#24230;&#20013;&#26377;&#25928;&#22320;&#37319;&#26679;&#65292;&#24182;&#20855;&#26377;&#22312;CO&#20013;&#20998;&#25674;&#27492;&#31867;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#36807;&#31243;&#20197;&#21450;&#29983;&#25104;&#19981;&#21516;&#30340;&#35299;&#20915;&#26041;&#26696;&#20505;&#36873;&#39033;&#30340;&#28508;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#32452;&#21512;&#38382;&#39064;&#30340;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#65292;&#24182;&#25552;&#20986;&#35757;&#32451;&#26377;&#26465;&#20214;&#30340;GFlowNets&#20174;&#35299;&#31354;&#38388;&#20013;&#37319;&#26679;&#30340;&#31574;&#30053;&#12290;&#36824;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#35757;&#32451;&#25216;&#26415;&#26469;&#21463;&#30410;&#20110;&#36828;&#31243;&#20449;&#29992;&#20998;&#37197;&#12290;&#36890;&#36807;&#23545;&#21508;&#31181;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#19981;&#21516;CO&#20219;&#21153;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;GFlowNet&#31574;&#30053;&#21487;&#20197;&#26377;&#25928;&#22320;&#25214;&#21040;&#39640;&#36136;&#37327;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space. On the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates. In this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. Efficient training techniques are also developed to benefit long-range credit assignment. Through extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#65292;&#21457;&#29616;&#24403;&#19988;&#20165;&#24403;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#26102;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.16910</link><description>&lt;p&gt;
&#24102;&#26377;&#22797;&#20540;&#30340;&#28145;&#31364;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Universal approximation with complex-valued deep narrow neural networks. (arXiv:2305.16910v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#65292;&#21457;&#29616;&#24403;&#19988;&#20165;&#24403;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#26102;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#23485;&#24230;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#37027;&#20123;&#28608;&#27963;&#20989;&#25968; $\varrho:\mathbb{CC}\to \mathbb{C}$ &#30340;&#23436;&#25972;&#25551;&#36848;&#65292;&#36825;&#20123;&#20989;&#25968;&#20855;&#26377;&#36825;&#26679;&#19968;&#20010;&#23646;&#24615;&#65306;&#23427;&#20204;&#20851;&#32852;&#30340;&#32593;&#32476;&#26159;&#26222;&#36866;&#30340;&#65292;&#21363;&#33021;&#22815;&#22312;&#32039;&#33268;&#22495;&#19978;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#33267;&#20219;&#24847;&#31934;&#24230;&#12290;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#20102;&#24403;&#19988;&#20165;&#24403;&#23427;&#20204;&#30340;&#28608;&#27963;&#20989;&#25968;&#26082;&#19981;&#26159;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159;&#21453;&#20840;&#32431;&#30340;&#65292;&#20063;&#19981;&#26159; $\mathbb{R}$-&#20223;&#23556;&#30340;&#65292;&#28145;&#31364;&#30340;&#22797;&#20540;&#32593;&#32476;&#26159;&#26222;&#36866;&#30340;&#12290;&#36825;&#26159;&#19968;&#20010;&#27604;&#23485;&#24230;&#20219;&#24847;&#12289;&#28145;&#24230;&#22266;&#23450;&#30340;&#23545;&#20598;&#35774;&#32622;&#20013;&#26356;&#22823;&#30340;&#20989;&#25968;&#31867;&#12290;&#19982;&#23454;&#20540;&#24773;&#20917;&#19981;&#21516;&#30340;&#26159;&#65292;&#36275;&#22815;&#30340;&#23485;&#24230;&#20381;&#36182;&#20110;&#32771;&#34385;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23485;&#24230;&#20026; $2n+2m+5$ &#24635;&#26159;&#36275;&#22815;&#30340;&#65292;&#24182;&#19988;&#36890;&#24120; $\max\{2n,2m\}$ &#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#21487;&#20801;&#35768;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#23485;&#24230;&#20026; $n+m+4$ &#26159;&#36275;&#22815;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the universality of complex-valued neural networks with bounded widths and arbitrary depths. Under mild assumptions, we give a full description of those activation functions $\varrho:\mathbb{CC}\to \mathbb{C}$ that have the property that their associated networks are universal, i.e., are capable of approximating continuous functions to arbitrary accuracy on compact domains. Precisely, we show that deep narrow complex-valued networks are universal if and only if their activation function is neither holomorphic, nor antiholomorphic, nor $\mathbb{R}$-affine. This is a much larger class of functions than in the dual setting of arbitrary width and fixed depth. Unlike in the real case, the sufficient width differs significantly depending on the considered activation function. We show that a width of $2n+2m+5$ is always sufficient and that in general a width of $\max\{2n,2m\}$ is necessary. We prove, however, that a width of $n+m+4$ suffices for a rich subclass of the admissible acti
&lt;/p&gt;</description></item><item><title>CyPhERS&#26159;&#19968;&#27454;&#32593;&#32476;&#29289;&#29702;&#20107;&#20214;&#25512;&#29702;&#31995;&#32479;&#65292;&#20855;&#26377;&#23454;&#26102;&#24863;&#30693;&#32593;&#32476;&#25915;&#20987;&#21644;&#29289;&#29702;&#25925;&#38556;&#12289;&#26032;&#22411;&#20107;&#20214;&#25512;&#29702;&#31639;&#27861;&#21644;&#24555;&#36895;&#21709;&#24212;&#33021;&#21147;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.16907</link><description>&lt;p&gt;
CyPhERS: &#19968;&#31181;&#25552;&#20379;&#23454;&#26102;&#24577;&#21183;&#24863;&#30693;&#30340;&#32593;&#32476;&#29289;&#29702;&#20107;&#20214;&#25512;&#29702;&#31995;&#32479;&#65292;&#29992;&#20110;&#25915;&#20987;&#21644;&#25925;&#38556;&#21709;&#24212;
&lt;/p&gt;
&lt;p&gt;
CyPhERS: A Cyber-Physical Event Reasoning System providing real-time situational awareness for attack and fault response. (arXiv:2305.16907v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16907
&lt;/p&gt;
&lt;p&gt;
CyPhERS&#26159;&#19968;&#27454;&#32593;&#32476;&#29289;&#29702;&#20107;&#20214;&#25512;&#29702;&#31995;&#32479;&#65292;&#20855;&#26377;&#23454;&#26102;&#24863;&#30693;&#32593;&#32476;&#25915;&#20987;&#21644;&#29289;&#29702;&#25925;&#38556;&#12289;&#26032;&#22411;&#20107;&#20214;&#25512;&#29702;&#31639;&#27861;&#21644;&#24555;&#36895;&#21709;&#24212;&#33021;&#21147;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#29289;&#29702;&#31995;&#32479;&#65288;CPS&#65289;&#26159;&#35832;&#22914;&#30005;&#21147;&#32593;&#32476;&#25110;&#27700;&#21147;&#20998;&#37197;&#32593;&#32476;&#20043;&#31867;&#20851;&#38190;&#22522;&#30784;&#35774;&#26045;&#30340;&#25903;&#26609;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#25805;&#20316;&#25925;&#38556;&#21487;&#33021;&#20250;&#23545;&#31038;&#20250;&#36896;&#25104;&#20005;&#37325;&#39118;&#38505;&#12290;&#20026;&#20102;&#36991;&#20813;&#25110;&#26368;&#23567;&#21270;&#20572;&#26426;&#26102;&#38388;&#65292;&#36816;&#33829;&#21830;&#38656;&#35201;&#23454;&#26102;&#20102;&#35299;&#20851;&#38190;&#20107;&#20214;&#12290;&#28982;&#32780;&#65292;CPS&#20013;&#30340;&#22312;&#32447;&#20107;&#20214;&#35782;&#21035;&#21463;&#21040;&#35768;&#22810;&#29289;&#29702;&#21644;&#25968;&#23383;&#32452;&#20214;&#30456;&#20114;&#20381;&#36182;&#30340;&#22797;&#26434;&#24615;&#30340;&#25361;&#25112;&#65292;&#38656;&#35201;&#22312;&#21516;&#31561;&#32771;&#34385;&#32593;&#32476;&#25915;&#20987;&#21644;&#29289;&#29702;&#25925;&#38556;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#12290;&#22312;&#32447;&#20107;&#20214;&#35782;&#21035;&#38382;&#39064;&#30001;&#20110;&#32570;&#20047;&#23545;&#20851;&#38190;&#20294;&#32597;&#35265;&#20107;&#20214;&#30340;&#21382;&#21490;&#35266;&#23519;&#20197;&#21450;&#32593;&#32476;&#25915;&#20987;&#31574;&#30053;&#30340;&#19981;&#26029;&#28436;&#21464;&#32780;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#12290;&#26412;&#25991;&#20171;&#32461;&#24182;&#28436;&#31034;&#20102;CyPhERS&#65292;&#19968;&#31181;&#32593;&#32476;&#29289;&#29702;&#20107;&#20214;&#25512;&#29702;&#31995;&#32479;&#12290;CyPhERS&#25552;&#20379;&#20851;&#20110;CPS&#20013;&#30340;&#28508;&#22312;&#20851;&#38190;&#20107;&#20214;&#21457;&#29983;&#12289;&#20301;&#32622;&#12289;&#29289;&#29702;&#24433;&#21709;&#21644;&#26681;&#26412;&#21407;&#22240;&#30340;&#23454;&#26102;&#20449;&#24687;&#65292;&#26080;&#38656;&#21382;&#21490;&#20107;&#20214;&#35266;&#23519;&#12290; CyPhERS&#30340;&#20851;&#38190;&#29305;&#28857;&#21253;&#25324;&#20854;&#33021;&#22815;&#26816;&#27979;&#21644;&#35786;&#26029;&#32593;&#32476;&#25915;&#20987;&#21644;&#29289;&#29702;&#25925;&#38556;&#65292;&#20854;&#20351;&#29992;&#30340;&#26032;&#22411;&#20107;&#20214;&#25512;&#29702;&#31639;&#27861;&#20197;&#21450;&#20854;&#23454;&#26102;&#33021;&#21147;&#65292;&#21487;&#24555;&#36895;&#21709;&#24212;&#20851;&#38190;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cyber-physical systems (CPSs) constitute the backbone of critical infrastructures such as power grids or water distribution networks. Operating failures in these systems can cause serious risks for society. To avoid or minimize downtime, operators require real-time awareness about critical incidents. However, online event identification in CPSs is challenged by the complex interdependency of numerous physical and digital components, requiring to take cyber attacks and physical failures equally into account. The online event identification problem is further complicated through the lack of historical observations of critical but rare events, and the continuous evolution of cyber attack strategies. This work introduces and demonstrates CyPhERS, a Cyber-Physical Event Reasoning System. CyPhERS provides real-time information pertaining the occurrence, location, physical impact, and root cause of potentially critical events in CPSs, without the need for historical event observations. Key no
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.16905</link><description>&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65306;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#39640;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference. (arXiv:2305.16905v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#40657;&#30418;&#24615;&#36136;&#38459;&#30861;&#20102;&#35299;&#37322;&#24615;&#12290;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;NAM&#65289;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#20998;&#20026;&#21152;&#24615;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#20351;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#20114;&#21464;&#24471;&#26126;&#26174;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#65306;a&#65289;&#23427;&#36890;&#36807;&#20272;&#35745;&#23376;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#19981;&#30830;&#23450;&#24615;&#20026;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65307;b&#65289;&#23427;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#36807;&#31243;&#25191;&#34892;&#29305;&#24449;&#30340;&#38544;&#24335;&#36873;&#25321;&#65307;c&#65289;&#23427;&#21487;&#29992;&#20110;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#65292;&#20316;&#20026;&#31934;&#32454;&#35843;&#25972;&#30340;&#20132;&#20114;&#27169;&#22411;&#20505;&#36873;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;LA-NAM&#65289;&#25552;&#39640;&#20102;NAM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#23376;&#32593;&#32476;&#30340;&#20132;&#20114;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improv
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#33258;&#36866;&#24212;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#23481;&#24525;&#21327;&#21464;&#37327;&#20013;&#30340;&#36817;&#20284;&#20381;&#36182;&#20851;&#31995;&#25968;&#37327;&#65292;&#20174;&#32780;&#36798;&#21040;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#20855;&#26377;&#36817;&#20046;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#12290;</title><link>http://arxiv.org/abs/2305.16892</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#29305;&#24449;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Feature Adaptation for Sparse Linear Regression. (arXiv:2305.16892v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16892
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#33258;&#36866;&#24212;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#23481;&#24525;&#21327;&#21464;&#37327;&#20013;&#30340;&#36817;&#20284;&#20381;&#36182;&#20851;&#31995;&#25968;&#37327;&#65292;&#20174;&#32780;&#36798;&#21040;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#20855;&#26377;&#36817;&#20046;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#26159;&#39640;&#32500;&#32479;&#35745;&#23398;&#20013;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#30456;&#20851;&#38543;&#26426;&#35774;&#35745;&#29615;&#22659;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#26159;&#20174;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;$N(0,\Sigma)$&#20013;&#32472;&#21046;&#30340;&#65292;&#25105;&#20204;&#23547;&#27714;&#20855;&#26377;&#23567;&#36807;&#37327;&#39118;&#38505;&#30340;&#20272;&#35745;&#22120;&#12290;&#22914;&#26524;&#30495;&#23454;&#20449;&#21495;&#26159;$t$-&#31232;&#30095;&#30340;&#65292;&#21017;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#65292;&#20165;&#38656;$O(t\log n)$&#20010;&#26679;&#26412;&#23601;&#21487;&#20197;&#33719;&#24471;&#24378;&#22823;&#30340;&#24674;&#22797;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#30340;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#26159;$\Sigma$&#30340;&#26576;&#31181;&#21464;&#20307;&#30340;&#26465;&#20214;&#25968;&#30340;&#32447;&#24615;&#12290;&#21363;&#20351;&#22312;&#21327;&#21464;&#37327;&#20013;&#20165;&#26377;&#21333;&#19968;&#30340;&#31232;&#30095;&#36817;&#20284;&#20381;&#36182;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#65292;&#20687;Lasso&#36825;&#26679;&#30340;&#32463;&#20856;&#31639;&#27861;&#20063;&#21487;&#33021;&#38656;&#35201;&#27604;&#24517;&#35201;&#26356;&#22810;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;$\Sigma$&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#21160;&#36866;&#24212;Lasso&#20197;&#23481;&#24525;&#23567;&#30340;&#36817;&#20284;&#20381;&#36182;&#20851;&#31995;&#25968;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#20855;&#26377;&#24120;&#25968;&#31232;&#30095;&#24615;&#24182;&#19988;$\Sigma$&#20855;&#26377;&#23569;&#37327;&#8220;&#24322;&#24120;&#8221;&#29305;&#24449;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20339;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear regression is a central problem in high-dimensional statistics. We study the correlated random design setting, where the covariates are drawn from a multivariate Gaussian $N(0,\Sigma)$, and we seek an estimator with small excess risk.  If the true signal is $t$-sparse, information-theoretically, it is possible to achieve strong recovery guarantees with only $O(t\log n)$ samples. However, computationally efficient algorithms have sample complexity linear in (some variant of) the condition number of $\Sigma$. Classical algorithms such as the Lasso can require significantly more samples than necessary even if there is only a single sparse approximate dependency among the covariates.  We provide a polynomial-time algorithm that, given $\Sigma$, automatically adapts the Lasso to tolerate a small number of approximate dependencies. In particular, we achieve near-optimal sample complexity for constant sparsity and if $\Sigma$ has few ``outlier'' eigenvalues. Our algorithm fits i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20840;&#38754;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#20998;&#26512;&#65292;&#22312;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#35777;&#26126;&#20102;GD&#31639;&#27861;&#30340;&#19968;&#33324;&#24615;&#20445;&#35777;&#65292;&#20026;&#21452;&#23618;&#21644;&#19977;&#23618;NN&#25512;&#23548;&#20986;&#20102;&#36807;&#37327;&#39118;&#38505;&#29575;&#65292;&#25193;&#23637;&#20102;&#20197;&#24448;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2305.16891</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#22312;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27867;&#21270;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Generalization Guarantees of Gradient Descent for Multi-Layer Neural Networks. (arXiv:2305.16891v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16891
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20840;&#38754;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#20998;&#26512;&#65292;&#22312;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#35777;&#26126;&#20102;GD&#31639;&#27861;&#30340;&#19968;&#33324;&#24615;&#20445;&#35777;&#65292;&#20026;&#21452;&#23618;&#21644;&#19977;&#23618;NN&#25512;&#23548;&#20986;&#20102;&#36807;&#37327;&#39118;&#38505;&#29575;&#65292;&#25193;&#23637;&#20102;&#20197;&#24448;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#26041;&#27861;&#65292;&#23545;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#30340;&#27867;&#21270;&#36827;&#34892;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#38598;&#20013;&#22312;&#21333;&#38544;&#34255;&#23618;NN&#19978;&#65292;&#24182;&#27809;&#26377;&#35299;&#20915;&#19981;&#21516;&#32593;&#32476;&#32553;&#25918;&#21442;&#25968;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;GD&#22312;&#22810;&#23618;NN&#19978;&#36827;&#34892;&#20840;&#38754;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#20998;&#26512;&#65292;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#20197;&#24448;&#30340;&#24037;&#20316;&#12290;&#23545;&#20110;&#21452;&#23618;NN&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#22312;&#19968;&#33324;&#30340;&#32593;&#32476;&#32553;&#25918;&#21442;&#25968;&#19979;&#24314;&#31435;&#30340;&#65292;&#25918;&#23485;&#20102;&#20197;&#21069;&#30340;&#26465;&#20214;&#12290;&#23545;&#20110;&#19977;&#23618;NN&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#36129;&#29486;&#22312;&#20110;&#21033;&#29992;&#19968;&#31181;&#26032;&#30340;&#24402;&#32435;&#31574;&#30053;&#65292;&#28145;&#20837;&#25506;&#35752;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#23427;&#30340;&#20960;&#20046;&#21327;&#21516;&#32422;&#26463;&#24615;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#19968;&#33324;&#24615;&#21457;&#29616;&#30340;&#30452;&#25509;&#24212;&#29992;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;GD&#31639;&#27861;&#22312;&#21452;&#23618;&#21644;&#19977;&#23618;NN&#20013;&#30340;&#36807;&#37327;&#39118;&#38505;&#36895;&#29575;&#20026;$O(1/\sqrt{n})$&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, significant progress has been made in understanding the generalization of neural networks (NNs) trained by gradient descent (GD) using the algorithmic stability approach. However, most of the existing research has focused on one-hidden-layer NNs and has not addressed the impact of different network scaling parameters. In this paper, we greatly extend the previous work \cite{lei2022stability,richards2021stability} by conducting a comprehensive stability and generalization analysis of GD for multi-layer NNs. For two-layer NNs, our results are established under general network scaling parameters, relaxing previous conditions. In the case of three-layer NNs, our technical contribution lies in demonstrating its nearly co-coercive property by utilizing a novel induction strategy that thoroughly explores the effects of over-parameterization. As a direct application of our general findings, we derive the excess risk rate of $O(1/\sqrt{n})$ for GD algorithms in both two-layer and thre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;ODE&#30340;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#23436;&#20840;&#30830;&#23450;&#24615;&#25277;&#26679;&#65292;&#38656;&#35201;&#28385;&#36275;$L^2$&#36817;&#20284;&#35823;&#24046;&#33539;&#22260;&#30340;&#35268;&#24459;&#24615;&#26465;&#20214;&#21644;&#25968;&#25454;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.16860</link><description>&lt;p&gt;
&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Error Bounds for Flow Matching Methods. (arXiv:2305.16860v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;ODE&#30340;&#27969;&#21305;&#37197;&#26041;&#27861;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#23436;&#20840;&#30830;&#23450;&#24615;&#25277;&#26679;&#65292;&#38656;&#35201;&#28385;&#36275;$L^2$&#36817;&#20284;&#35823;&#24046;&#33539;&#22260;&#30340;&#35268;&#24459;&#24615;&#26465;&#20214;&#21644;&#25968;&#25454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#26159;&#19968;&#31867;&#20381;&#36182;&#20110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#27969;&#34892;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#12290;&#33258;&#20174;&#23427;&#20204;&#35806;&#29983;&#20197;&#26469;&#65292;&#23601;&#24050;&#32463;&#24847;&#35782;&#21040;&#21487;&#20197;&#20351;&#29992;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#32780;&#19981;&#26159;SDE&#36827;&#34892;&#29983;&#25104;&#12290;&#36825;&#23548;&#33268;&#20171;&#32461;&#20102;&#27010;&#29575;&#27969;ODE&#26041;&#27861;&#21644;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#12290;&#27969;&#21305;&#37197;&#26041;&#27861;&#26368;&#36817;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#36825;&#20123;&#22522;&#20110;ODE&#30340;&#26041;&#27861;&#65292;&#24182;&#36817;&#20284;&#20110;&#20004;&#20010;&#20219;&#24847;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#27969;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#38024;&#23545;&#38543;&#26426;&#25277;&#26679;&#27169;&#24335;&#19979;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#23548;&#20102;&#36817;&#20284;&#35823;&#24046;&#30340;&#36793;&#30028;&#65292;&#20551;&#35774;$L^2$&#25439;&#22833;&#20855;&#26377;&#26576;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#22312;&#23436;&#20840;&#30830;&#23450;&#24615;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#27969;&#21305;&#37197;&#36807;&#31243;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#20551;&#35774;$L^2$&#36817;&#20284;&#35823;&#24046;&#33539;&#22260;&#26377;&#19968;&#23450;&#30340;&#35268;&#24459;&#24615;&#26465;&#20214;&#21644;&#25968;&#25454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models are a popular class of generative modelling techniques relying on stochastic differential equations (SDE). From their inception, it was realized that it was also possible to perform generation using ordinary differential equations (ODE) rather than SDE. This led to the introduction of the probability flow ODE approach and denoising diffusion implicit models. Flow matching methods have recently further extended these ODE-based approaches and approximate a flow between two arbitrary probability distributions. Previous work derived bounds on the approximation error of diffusion models under the stochastic sampling regime, given assumptions on the $L^2$ loss. We present error bounds for the flow matching procedure using fully deterministic sampling, assuming an $L^2$ bound on the approximation error and a certain regularity condition on the data distributions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;LFlows&#27169;&#22411;&#65292;&#23427;&#20351;&#29992;&#21487;&#24494;&#21644;&#21487;&#36870;&#30340;&#21464;&#25442;&#65292;&#22312;&#26102;&#38388;&#19978;&#35268;&#23450;&#21442;&#25968;&#21270;&#30340;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#26469;&#23545;&#22522;&#30784;&#23494;&#24230;&#36827;&#34892;&#36716;&#25442;&#65292;&#20197;&#36830;&#32493;&#22320;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#21644;&#36895;&#24230;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20854;&#20248;&#21183;&#22312;&#20110;&#36895;&#24230;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24635;&#26159;&#19982;&#23494;&#24230;&#20445;&#25345;&#19968;&#33268;&#65292;&#26080;&#38656;&#26114;&#36149;&#30340;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#20063;&#26080;&#38656;&#20351;&#29992;&#24809;&#32602;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.16846</link><description>&lt;p&gt;
&#25289;&#26684;&#26391;&#26085;&#27969;&#32593;&#32476;&#29992;&#20110;&#23432;&#24658;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Lagrangian Flow Networks for Conservation Laws. (arXiv:2305.16846v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16846
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;LFlows&#27169;&#22411;&#65292;&#23427;&#20351;&#29992;&#21487;&#24494;&#21644;&#21487;&#36870;&#30340;&#21464;&#25442;&#65292;&#22312;&#26102;&#38388;&#19978;&#35268;&#23450;&#21442;&#25968;&#21270;&#30340;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#26469;&#23545;&#22522;&#30784;&#23494;&#24230;&#36827;&#34892;&#36716;&#25442;&#65292;&#20197;&#36830;&#32493;&#22320;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#21644;&#36895;&#24230;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20854;&#20248;&#21183;&#22312;&#20110;&#36895;&#24230;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24635;&#26159;&#19982;&#23494;&#24230;&#20445;&#25345;&#19968;&#33268;&#65292;&#26080;&#38656;&#26114;&#36149;&#30340;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#20063;&#26080;&#38656;&#20351;&#29992;&#24809;&#32602;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#25289;&#26684;&#26391;&#26085;&#27969;&#32593;&#32476;&#65288;LFlows&#65289;&#65292;&#29992;&#20110;&#36830;&#32493;&#22320;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#21644;&#36895;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;LFlows&#22522;&#20110;&#36830;&#32493;&#26041;&#31243;&#30340;&#35299;&#65292;&#20854;&#20013;&#36830;&#32493;&#26041;&#31243;&#26159;&#25551;&#36848;&#19981;&#21516;&#24418;&#24335;&#30340;&#36136;&#37327;&#23432;&#24658;&#24615;&#36136;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22522;&#20110;&#36825;&#26679;&#30340;&#24605;&#36335;&#65306;&#36830;&#32493;&#26041;&#31243;&#30340;&#35299;&#21487;&#20197;&#36890;&#36807;&#21487;&#24494;&#21644;&#21487;&#36870;&#30340;&#21464;&#25442;&#34920;&#31034;&#20026;&#26102;&#38388;&#20381;&#36182;&#30340;&#23494;&#24230;&#21464;&#25442;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#26102;&#38388;&#19978;&#35268;&#23450;&#21442;&#25968;&#21270;&#30340;&#24494;&#20998;&#21516;&#32986;&#21464;&#25442;&#26469;&#23545;&#22522;&#30784;&#23494;&#24230;&#36827;&#34892;&#36716;&#25442;&#20197;&#24314;&#27169;&#27969;&#20307;&#23494;&#24230;&#12290;&#19982;&#20381;&#36182;&#20110;Neural-ODE&#25110;PINNs&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#20851;&#38190;&#30340;&#20248;&#21183;&#22312;&#20110;&#36895;&#24230;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#22987;&#32456;&#19982;&#23494;&#24230;&#20445;&#25345;&#19968;&#33268;&#12290;&#27492;&#22806;&#65292;&#26080;&#38656;&#26114;&#36149;&#30340;&#25968;&#20540;&#27714;&#35299;&#22120;&#65292;&#20063;&#26080;&#38656;&#20351;&#29992;&#24809;&#32602;&#26041;&#27861;&#26469;&#23454;&#26045;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#25289;&#26684;&#26391;&#26085;&#27969;&#32593;&#32476;&#22312;&#21512;&#25104;&#23494;&#24230;&#25968;&#25454;&#19978;&#26174;&#31034;&#20986;&#20102;&#26356;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities and velocities continuously in space and time. The proposed LFlows satisfy by construction the continuity equation, a PDE describing mass conservation in its differentiable form. Our model is based on the insight that solutions to the continuity equation can be expressed as time-dependent density transformations via differentiable and invertible maps. This follows from classical theory of existence and uniqueness of Lagrangian flows for smooth vector fields. Hence, we model fluid densities by transforming a base density with parameterized diffeomorphisms conditioned on time. The key benefit compared to methods relying on Neural-ODE or PINNs is that the analytic expression of the velocity is always consistent with the density. Furthermore, there is no need for expensive numerical solvers, nor for enforcing the PDE with penalty methods. Lagrangian Flow Networks show improved predictive accuracy on synthetic densi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#38543;&#26426;&#20301;&#32622;&#32534;&#30721;&#26426;&#21046;&#65292;&#33021;&#22815;&#25552;&#39640;Transformer&#30340;&#38271;&#24230;&#26222;&#36866;&#24615;&#65292;&#20351;&#20854;&#22312;&#31639;&#27861;&#25512;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2305.16843</link><description>&lt;p&gt;
&#38543;&#26426;&#20301;&#32622;&#32534;&#30721;&#25552;&#21319;&#20102;Transformer&#30340;&#38271;&#24230;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
Randomized Positional Encodings Boost Length Generalization of Transformers. (arXiv:2305.16843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#38543;&#26426;&#20301;&#32622;&#32534;&#30721;&#26426;&#21046;&#65292;&#33021;&#22815;&#25552;&#39640;Transformer&#30340;&#38271;&#24230;&#26222;&#36866;&#24615;&#65292;&#20351;&#20854;&#22312;&#31639;&#27861;&#25512;&#29702;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#22312;&#22266;&#23450;&#38271;&#24230;&#30340;&#20219;&#21153;&#19978;&#25317;&#26377;&#24778;&#20154;&#30340;&#26222;&#36866;&#24615;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#25512;&#24191;&#21040;&#20219;&#24847;&#38271;&#24230;&#30340;&#24207;&#21015;&#65292;&#29978;&#33267;&#26159;&#20687;&#22797;&#21046;&#23383;&#31526;&#20018;&#36825;&#26679;&#30475;&#20284;&#31616;&#21333;&#30340;&#20219;&#21153;&#20063;&#20250;&#22833;&#36133;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#20840;&#23616;&#27880;&#24847;&#26426;&#21046;&#30340;&#20108;&#27425;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#20165;&#20165;&#35757;&#32451;&#26356;&#38271;&#30340;&#24207;&#21015;&#26159;&#20302;&#25928;&#30340;&#12290;&#26412;&#25991;&#34920;&#26126;&#36825;&#31181;&#22833;&#36133;&#27169;&#24335;&#19982;&#38271;&#24230;&#26356;&#38271;&#30340;&#24207;&#21015;&#65288;&#21363;&#20351;&#26159;&#30456;&#23545;&#32534;&#30721;&#65289;&#30340;&#20301;&#32622;&#32534;&#30721;&#22312;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#26102;&#26377;&#20851;&#65292;&#24182;&#24341;&#20837;&#19968;&#31181;&#33021;&#22815;&#20811;&#26381;&#27492;&#38382;&#39064;&#30340;&#26032;&#39062;&#20301;&#32622;&#32534;&#30721;&#31995;&#21015;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#38543;&#26426;&#20301;&#32622;&#32534;&#30721;&#26426;&#21046;&#27169;&#25311;&#20102;&#26356;&#38271;&#24207;&#21015;&#30340;&#20301;&#32622;&#65292;&#24182;&#38543;&#26426;&#36873;&#25321;&#19968;&#20010;&#26377;&#24207;&#23376;&#38598;&#26469;&#36866;&#24212;&#24207;&#21015;&#30340;&#38271;&#24230;&#12290;&#25105;&#20204;&#22312;15&#20010;&#31639;&#27861;&#25512;&#29702;&#20219;&#21153;&#30340;6000&#31181;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#23454;&#35777;&#35780;&#20272;&#26174;&#31034;&#20986;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;Transformer&#33021;&#22815;&#25512;&#24191;&#21040;&#26410;&#35265;&#38271;&#24230;&#30340;&#24207;&#21015;&#65288;&#24179;&#22343;&#27979;&#35797;&#20934;&#30830;&#24230;&#25552;&#39640;&#20102;12.0%&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers have impressive generalization capabilities on tasks with a fixed context length. However, they fail to generalize to sequences of arbitrary length, even for seemingly simple tasks such as duplicating a string. Moreover, simply training on longer sequences is inefficient due to the quadratic computation complexity of the global attention mechanism. In this work, we demonstrate that this failure mode is linked to positional encodings being out-of-distribution for longer sequences (even for relative encodings) and introduce a novel family of positional encodings that can overcome this problem. Concretely, our randomized positional encoding scheme simulates the positions of longer sequences and randomly selects an ordered subset to fit the sequence's length. Our large-scale empirical evaluation of 6000 models across 15 algorithmic reasoning tasks shows that our method allows Transformers to generalize to sequences of unseen length (increasing test accuracy by 12.0% on average
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#33021;&#21147;&#38382;&#39064;&#65292;&#36890;&#36807;&#37327;&#21270;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#65292;&#24471;&#21040;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#30340;&#27867;&#21270;&#24046;&#36317;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.16791</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#30340;&#27867;&#21270;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Capacities of Neural Controlled Differential Equations. (arXiv:2305.16791v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#36827;&#34892;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#33021;&#21147;&#38382;&#39064;&#65292;&#36890;&#36807;&#37327;&#21270;&#31163;&#25955;&#21270;&#20559;&#24046;&#21644;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#65292;&#24471;&#21040;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#30340;&#27867;&#21270;&#24046;&#36317;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;Kidger&#65292;Morrill&#31561;&#65292;2020&#65289;&#20174;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#26679;&#26412;&#20013;&#39044;&#27979;&#32467;&#26524;&#30340;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#26102;&#38388;&#24207;&#21015;&#26159;&#19968;&#20010;&#26410;&#35266;&#23519;&#21040;&#30340;&#36830;&#32493;&#36335;&#24452;&#30340;&#31163;&#25955;&#21270;&#65292;&#32467;&#26524;&#36890;&#36807;&#19968;&#20010;&#20855;&#26377;&#26410;&#30693;&#21521;&#37327;&#22330;&#30340;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#20381;&#36182;&#20110;&#36825;&#20010;&#36335;&#24452;&#12290;&#20351;&#29992;&#31163;&#25955;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#20250;&#24341;&#20837;&#31163;&#25955;&#20559;&#24046;&#65292;&#25105;&#20204;&#31934;&#30830;&#22320;&#37327;&#21270;&#20102;&#36825;&#31181;&#20559;&#24046;&#12290;&#36890;&#36807;&#20351;&#29992;&#20851;&#20110;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27969;&#30340;&#36830;&#32493;&#24615;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36924;&#36817;&#20559;&#24046;&#30452;&#25509;&#19982;&#30001;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#23450;&#20041;&#29983;&#25104;&#27169;&#22411;&#30340;&#21033;&#26222;&#24076;&#33576;&#20989;&#25968;&#30340;&#36924;&#36817;&#35823;&#24046;&#30456;&#20851;&#12290;&#36890;&#36807;&#32467;&#21512;&#26368;&#36817;&#30340;&#24037;&#20316;&#23558;&#31070;&#32463;&#32593;&#32476;&#30340;&#21033;&#26222;&#24076;&#33576;&#24120;&#25968;&#19982;&#20854;&#27867;&#21270;&#33021;&#21147;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#19978;&#30028;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#36798;&#21040;&#30340;&#26399;&#26395;&#25439;&#22833;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#39118;&#38505;&#20043;&#38388;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a supervised learning setup in which the goal is to predicts an outcome from a sample of irregularly sampled time series using Neural Controlled Differential Equations (Kidger, Morrill, et al. 2020). In our framework, the time series is a discretization of an unobserved continuous path, and the outcome depends on this path through a controlled differential equation with unknown vector field. Learning with discrete data thus induces a discretization bias, which we precisely quantify. Using theoretical results on the continuity of the flow of controlled differential equations, we show that the approximation bias is directly related to the approximation error of a Lipschitz function defining the generative model by a shallow neural network. By combining these result with recent work linking the Lipschitz constant of neural networks to their generalization capacities, we upper bound the generalization gap between the expected loss attained by the empirical risk minimizer and th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#27604;&#36739;&#20102;&#21464;&#21387;&#22120;&#21644;&#22522;&#20110;&#38598;&#21512;&#30340;MLP&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#20108;&#32773;&#22312;&#20998;&#24067;&#20869;&#35780;&#20272;&#20013;&#37117;&#34920;&#29616;&#20986;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#38450;&#33539;&#36739;&#23567;&#30340;&#20998;&#24067;&#28418;&#31227;&#26041;&#38754;&#65292;&#21464;&#21387;&#22120;&#26356;&#32988;&#19968;&#31609;&#12290;</title><link>http://arxiv.org/abs/2305.16704</link><description>&lt;p&gt;
&#25506;&#31350;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65306;&#20197;&#32447;&#24615;&#22238;&#24402;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
A Closer Look at In-Context Learning under Distribution Shifts. (arXiv:2305.16704v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16704
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#65292;&#27604;&#36739;&#20102;&#21464;&#21387;&#22120;&#21644;&#22522;&#20110;&#38598;&#21512;&#30340;MLP&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;&#20108;&#32773;&#22312;&#20998;&#24067;&#20869;&#35780;&#20272;&#20013;&#37117;&#34920;&#29616;&#20986;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#65292;&#20294;&#22312;&#38450;&#33539;&#36739;&#23567;&#30340;&#20998;&#24067;&#28418;&#31227;&#26041;&#38754;&#65292;&#21464;&#21387;&#22120;&#26356;&#32988;&#19968;&#31609;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19978;&#19979;&#25991;&#23398;&#20064;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19968;&#20010;&#23450;&#20041;&#29305;&#24449;&#65292;&#23427;&#20351;&#27169;&#22411;&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#36827;&#34892;&#26435;&#37325;&#26356;&#26032;&#30340;&#24773;&#20917;&#19979;&#21363;&#26102;&#22320;&#20174;&#36755;&#20837;&#26679;&#20363;&#20013;&#23398;&#20064;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#32447;&#24615;&#22238;&#24402;&#36825;&#19968;&#31616;&#21333;&#32780;&#22522;&#30784;&#30340;&#20219;&#21153;&#65292;&#36981;&#24490;&#65288;Garg et al., 2022&#65289;&#25552;&#20986;&#30340;&#35774;&#32622;&#65292;&#20174;&#31616;&#21333;&#30340;&#22522;&#20110;&#38598;&#21512;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#26550;&#26500;&#30340;&#35282;&#24230;&#65292;&#26356;&#22909;&#22320;&#29702;&#35299;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#26680;&#24515;&#38382;&#39064;&#26159;&#65306;&#22312;&#21464;&#21270;&#30340;&#20998;&#24067;&#28418;&#31227;&#19979;&#65292;&#21464;&#21387;&#22120;&#26159;&#21542;&#27604;&#19968;&#20123;&#33258;&#28982;&#19988;&#26356;&#31616;&#21333;&#30340;&#26550;&#26500;&#26356;&#25797;&#38271;&#25191;&#34892;&#19978;&#19979;&#25991;&#23398;&#20064;&#65311;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#20998;&#24067;&#20869;&#35780;&#20272;&#19979;&#65292;&#21464;&#21387;&#22120;&#21644;&#22522;&#20110;&#38598;&#21512;&#30340;MLP&#27169;&#22411;&#37117;&#34920;&#29616;&#20986;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#65292;&#20294;&#26159;&#21464;&#21387;&#22120;&#26356;&#25509;&#36817;&#20110;&#26368;&#23567;&#20108;&#20056;&#27861;&#65288;OLS&#65289;&#30340;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#28418;&#31227;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;&#21464;&#21387;&#22120;&#30340;&#38887;&#24615;&#20063;&#27604;&#22522;&#20110;&#38598;&#21512;&#30340;MLP&#27169;&#22411;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
In-context learning, a capability that enables a model to learn from input examples on the fly without necessitating weight updates, is a defining characteristic of large language models. In this work, we follow the setting proposed in (Garg et al., 2022) to better understand the generality and limitations of in-context learning from the lens of the simple yet fundamental task of linear regression. The key question we aim to address is: Are transformers more adept than some natural and simpler architectures at performing in-context learning under varying distribution shifts? To compare transformers, we propose to use a simple architecture based on set-based Multi-Layer Perceptrons (MLPs). We find that both transformers and set-based MLPs exhibit in-context learning under in-distribution evaluations, but transformers more closely emulate the performance of ordinary least squares (OLS). Transformers also display better resilience to mild distribution shifts, where set-based MLPs falter. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#21644;&#31867;&#22411;&#65292;&#20174;&#32479;&#35745;&#23398;&#23478;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#20998;&#31867;&#21035;&#20171;&#32461;&#20102;&#38543;&#26426;&#24615;&#21644;&#35748;&#30693;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#27010;&#24565;&#65292;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#21508;&#24322;&#65292;&#19981;&#21487;&#31616;&#21333;&#24402;&#20026;&#20004;&#31867;&#12290;&#21516;&#26102;&#65292;&#19982;&#32479;&#35745;&#23398;&#27010;&#24565;&#36827;&#34892;&#31867;&#27604;&#65292;&#25506;&#35752;&#19981;&#30830;&#23450;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.16703</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304; -- &#19968;&#20010;&#32479;&#35745;&#23398;&#23478;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Sources of Uncertainty in Machine Learning -- A Statisticians' View. (arXiv:2305.16703v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#21644;&#31867;&#22411;&#65292;&#20174;&#32479;&#35745;&#23398;&#23478;&#30340;&#35270;&#35282;&#20986;&#21457;&#65292;&#20998;&#31867;&#21035;&#20171;&#32461;&#20102;&#38543;&#26426;&#24615;&#21644;&#35748;&#30693;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#27010;&#24565;&#65292;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#21508;&#24322;&#65292;&#19981;&#21487;&#31616;&#21333;&#24402;&#20026;&#20004;&#31867;&#12290;&#21516;&#26102;&#65292;&#19982;&#32479;&#35745;&#23398;&#27010;&#24565;&#36827;&#34892;&#31867;&#27604;&#65292;&#25506;&#35752;&#19981;&#30830;&#23450;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#23601;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22238;&#31572;&#20960;&#24180;&#21069;&#38590;&#20197;&#24819;&#35937;&#30340;&#38382;&#39064;&#12290;&#38500;&#20102;&#36825;&#20123;&#25104;&#21151;&#20043;&#22806;&#65292;&#36234;&#26469;&#36234;&#28165;&#26224;&#30340;&#26159;&#65292;&#22312;&#32431;&#39044;&#27979;&#20043;&#22806;&#65292;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#20063;&#26159;&#30456;&#20851;&#21644;&#24517;&#35201;&#30340;&#12290;&#34429;&#28982;&#36817;&#24180;&#26469;&#24050;&#32463;&#20986;&#29616;&#20102;&#36825;&#26041;&#38754;&#30340;&#31532;&#19968;&#25209;&#27010;&#24565;&#21644;&#24605;&#24819;&#65292;&#20294;&#26412;&#25991;&#37319;&#29992;&#20102;&#19968;&#20010;&#27010;&#24565;&#24615;&#30340;&#35270;&#35282;&#65292;&#24182;&#25506;&#35752;&#20102;&#21487;&#33021;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36890;&#36807;&#37319;&#29992;&#32479;&#35745;&#23398;&#23478;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#26426;&#22120;&#23398;&#20064;&#26356;&#24120;&#35265;&#30456;&#20851;&#30340;&#38543;&#26426;&#24615;&#21644;&#35748;&#30693;&#24615;&#19981;&#30830;&#23450;&#24615;&#30340;&#27010;&#24565;&#12290;&#26412;&#25991;&#26088;&#22312;&#35268;&#33539;&#36825;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#30340;&#26469;&#28304;&#21508;&#24322;&#65292;&#24182;&#19988;&#19981;&#24635;&#26159;&#21487;&#20197;&#20998;&#35299;&#20026;&#38543;&#26426;&#24615;&#21644;&#35748;&#30693;&#24615;&#12290;&#36890;&#36807;&#23558;&#32479;&#35745;&#27010;&#24565;&#19982;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#31867;&#27604;&#65292;&#25105;&#20204;&#20063;&#23637;&#31034;&#20102;&#32479;&#35745;&#23398;&#27010;&#24565;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning and Deep Learning have achieved an impressive standard today, enabling us to answer questions that were inconceivable a few years ago. Besides these successes, it becomes clear, that beyond pure prediction, which is the primary strength of most supervised machine learning algorithms, the quantification of uncertainty is relevant and necessary as well. While first concepts and ideas in this direction have emerged in recent years, this paper adopts a conceptual perspective and examines possible sources of uncertainty. By adopting the viewpoint of a statistician, we discuss the concepts of aleatoric and epistemic uncertainty, which are more commonly associated with machine learning. The paper aims to formalize the two types of uncertainty and demonstrates that sources of uncertainty are miscellaneous and can not always be decomposed into aleatoric and epistemic. Drawing parallels between statistical concepts and uncertainty in machine learning, we also demonstrate the rol
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#21508;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;&#22238;&#24402;&#22120;&#26816;&#27979;&#25968;&#20540;&#25968;&#25454;&#20013;&#30340;&#24322;&#24120;&#20540;&#19982;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#65292;&#33021;&#22815;&#26377;&#25928;&#21306;&#20998;&#30495;&#27491;&#30340;&#24322;&#24120;&#21644;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#12290;</title><link>http://arxiv.org/abs/2305.16583</link><description>&lt;p&gt;
&#36890;&#36807;&#20219;&#24847;&#22238;&#24402;&#27169;&#22411;&#26816;&#27979;&#25968;&#20540;&#25968;&#25454;&#20013;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting Errors in Numerical Data via any Regression Model. (arXiv:2305.16583v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16583
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#21508;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;&#22238;&#24402;&#22120;&#26816;&#27979;&#25968;&#20540;&#25968;&#25454;&#20013;&#30340;&#24322;&#24120;&#20540;&#19982;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#65292;&#33021;&#22815;&#26377;&#25928;&#21306;&#20998;&#30495;&#27491;&#30340;&#24322;&#24120;&#21644;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22122;&#22768;&#22256;&#25200;&#30528;&#35768;&#22810;&#25968;&#20540;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#25968;&#25454;&#35760;&#24405;&#30340;&#20540;&#21487;&#33021;&#30001;&#20110;&#38169;&#35823;&#30340;&#20256;&#24863;&#22120;&#12289;&#25968;&#25454;&#36755;&#20837;/&#22788;&#29702;&#38169;&#35823;&#25110;&#19981;&#23436;&#32654;&#30340;&#20154;&#31867;&#20272;&#35745;&#31561;&#21407;&#22240;&#32780;&#26080;&#27861;&#21305;&#37197;&#30495;&#23454;&#30340;&#24213;&#23618;&#20540;&#12290;&#25105;&#20204;&#32771;&#34385;&#20272;&#35745;&#27839;&#25968;&#20540;&#21015;&#21738;&#20123;&#25968;&#25454;&#20540;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;&#22238;&#24402;&#22120;&#65288;&#21363;&#22522;&#20110;&#25968;&#25454;&#38598;&#20013;&#30340;&#20854;&#20182;&#21464;&#37327;&#26469;&#39044;&#27979;&#35813;&#21015;&#20540;&#30340;&#32479;&#35745;&#23398;&#25110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65289;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#36890;&#36807;&#32771;&#34385;&#21508;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21306;&#20998;&#20102;&#30495;&#27491;&#30340;&#24322;&#24120;&#21644;&#33258;&#28982;&#25968;&#25454;&#27874;&#21160;&#65292;&#26465;&#20214;&#26159;&#26377;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#20449;&#24687;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#26041;&#27861;&#24314;&#31435;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#34920;&#26126;&#20854;&#20182;&#26041;&#27861;&#65288;&#22914;&#31526;&#21512;&#24615;&#25512;&#26029;&#65289;&#38590;&#20197;&#26816;&#27979;&#38169;&#35823;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#35823;&#24046;&#26816;&#27979;&#22522;&#20934;&#65292;&#28041;&#21450; 5 &#20010;&#20855;&#26377;&#30495;&#23454;&#19990;&#30028;&#25968;&#23383;&#38169;&#35823;&#30340;&#22238;&#24402;&#25968;&#25454;&#38598;&#65288;&#23545;&#20110;&#20854;&#20013;&#30340;&#30495;&#23454;&#20540;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Noise plagues many numerical datasets, where the recorded values in the data may fail to match the true underlying values due to reasons including: erroneous sensors, data entry/processing mistakes, or imperfect human estimates. Here we consider estimating \emph{which} data values are incorrect along a numerical column. We present a model-agnostic approach that can utilize \emph{any} regressor (i.e.\ statistical or machine learning model) which was fit to predict values in this column based on the other variables in the dataset. By accounting for various uncertainties, our approach distinguishes between genuine anomalies and natural data fluctuations, conditioned on the available information in the dataset. We establish theoretical guarantees for our method and show that other approaches like conformal inference struggle to detect errors. We also contribute a new error detection benchmark involving 5 regression datasets with real-world numerical errors (for which the true values are al
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#35780;&#20272;&#23884;&#20837;&#36136;&#37327;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#20851;&#27880;&#22914;&#20309;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36827;&#34892;&#32447;&#24615;&#20998;&#31163;&#12290;&#20174;&#35843;&#26597;&#30340;&#25991;&#29486;&#21644;&#24341;&#20837;&#30340;&#26032;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#35780;&#20272;&#23884;&#20837;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#29616;&#12290;(This work proposes new methods to evaluate the quality of embeddings, focusing on stable linear separation. From the surveyed literature and introduced novel methods, we can evaluate the quality of embeddings and improve the performance of unsupervised learning.)</title><link>http://arxiv.org/abs/2305.16562</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#23884;&#20837;&#36136;&#37327;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Embedding Quality Evaluation. (arXiv:2305.16562v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16562
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#35780;&#20272;&#23884;&#20837;&#36136;&#37327;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#20851;&#27880;&#22914;&#20309;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36827;&#34892;&#32447;&#24615;&#20998;&#31163;&#12290;&#20174;&#35843;&#26597;&#30340;&#25991;&#29486;&#21644;&#24341;&#20837;&#30340;&#26032;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#35780;&#20272;&#23884;&#20837;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#29616;&#12290;(This work proposes new methods to evaluate the quality of embeddings, focusing on stable linear separation. From the surveyed literature and introduced novel methods, we can evaluate the quality of embeddings and improve the performance of unsupervised learning.)
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#26368;&#36817;&#22312;&#23398;&#26415;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#30340;&#21457;&#23637;&#12290;&#34429;&#28982;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#25509;&#36817;&#30417;&#30563;&#23398;&#20064;&#27700;&#24179;&#30340;&#25104;&#26524;&#65292;&#20294;&#30001;&#20110;&#26080;&#30417;&#30563;&#38382;&#39064;&#30340;&#26412;&#36136;&#65292;&#23454;&#36341;&#20013;&#35757;&#32451;&#21644;&#35780;&#20272; SSL &#27169;&#22411;&#20173;&#28982;&#24456;&#22256;&#38590;&#12290;&#21363;&#20351;&#26159;&#20197;&#26377;&#30417;&#30563;&#30340;&#26041;&#24335;&#35757;&#32451;&#30340;&#32593;&#32476;&#65292;&#22312;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#39046;&#22495;&#26102;&#26159;&#21542;&#33021;&#22815;&#33391;&#22909;&#22320;&#34920;&#29616;&#65292;&#20063;&#24448;&#24448;&#19981;&#28165;&#26970;&#12290;&#36807;&#21435;&#30340;&#24037;&#20316;&#36890;&#24120;&#20165;&#38480;&#20110;&#35780;&#20272;&#23884;&#20837;&#20013;&#21253;&#21547;&#30340;&#20449;&#24687;&#37327;&#65292;&#36825;&#23545;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26368;&#20026;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#36825;&#39033;&#24037;&#20316;&#36873;&#25321;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#65306;&#25105;&#20204;&#33021;&#21542;&#37327;&#21270;&#25968;&#25454;&#20013;&#22914;&#20309;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36827;&#34892;&#32447;&#24615;&#20998;&#31163;&#65311;&#25105;&#20204;&#35843;&#26597;&#20102;&#30456;&#20851;&#30340;&#25991;&#29486;&#65292;&#24182;&#21457;&#29616;&#19977;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#35780;&#20272;&#23884;&#20837;&#30340;&#36136;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#26399;&#23545;&#39640;&#32500;&#31354;&#38388;&#29702;&#35299;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised learning has recently significantly gained in popularity, especially with deep learning-based approaches. Despite numerous successes and approaching supervised-level performance on a variety of academic benchmarks, it is still hard to train and evaluate SSL models in practice due to the unsupervised nature of the problem. Even with networks trained in a supervised fashion, it is often unclear whether they will perform well when transferred to another domain.  Past works are generally limited to assessing the amount of information contained in embeddings, which is most relevant for self-supervised learning of deep neural networks. This works chooses to follow a different approach: can we quantify how easy it is to linearly separate the data in a stable way? We survey the literature and uncover three methods that could be potentially used for evaluating quality of representations. We also introduce one novel method based on recent advances in understanding the high-dimension
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#31639;&#27861;(TreeDSB)&#26469;&#35299;&#20915;&#22810;&#20803;&#26368;&#20248;&#36755;&#36816;(mOT)&#30340;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#32500;&#35774;&#32622;&#22914;&#22270;&#20687;&#25554;&#20540;&#21644;&#36125;&#21494;&#26031;&#34701;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.16557</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#31639;&#27861;&#22312;Wasserstein&#37325;&#24515;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Tree-Based Diffusion Schr\"odinger Bridge with Applications to Wasserstein Barycenters. (arXiv:2305.16557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#31639;&#27861;(TreeDSB)&#26469;&#35299;&#20915;&#22810;&#20803;&#26368;&#20248;&#36755;&#36816;(mOT)&#30340;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#32500;&#35774;&#32622;&#22914;&#22270;&#20687;&#25554;&#20540;&#21644;&#36125;&#21494;&#26031;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26368;&#20248;&#36755;&#36816;(mOT)&#26159;&#26368;&#20248;&#36755;&#36816;(OT)&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#20854;&#26088;&#22312;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#30456;&#23545;&#20110;&#26576;&#20123;&#39044;&#20808;&#25351;&#23450;&#30340;&#36793;&#38469;&#20998;&#24067;&#30340;&#31215;&#20998;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26641;&#24418;&#20108;&#27425;&#25104;&#26412;&#30340;&#29109;&#29256;&#26412;&#65292;&#21363;&#19968;&#31181;&#21487;&#20197;&#20889;&#20316;&#26641;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#25104;&#26412;&#20989;&#25968;&#20043;&#21644;&#30340;&#20989;&#25968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Tree-based Diffusion Schr\"odinger Bridge(TreeDSB)&#65292;&#36825;&#26159;&#25193;&#23637;&#20102;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;(DSB)&#31639;&#27861;&#30340;&#31639;&#27861;&#12290;TreeDSB&#23545;&#24212;&#20110;&#22810;&#20803;Sinkhorn&#31639;&#27861;&#30340;&#21160;&#24577;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#26174;&#33879;&#24212;&#29992;&#26159;&#35745;&#31639;Wasserstein&#37325;&#24515;&#65292;&#23427;&#21487;&#20197;&#34987;&#37325;&#26032;&#36716;&#21270;&#20026;&#22522;&#20110;&#26143;&#24418;&#26641;&#30340;mOT&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#32500;&#35774;&#32622;&#65292;&#22914;&#22270;&#20687;&#25554;&#20540;&#21644;&#36125;&#21494;&#26031;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-marginal Optimal Transport (mOT), a generalization of OT, aims at minimizing the integral of a cost function with respect to a distribution with some prescribed marginals. In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i.e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree. To address this problem, we develop Tree-based Diffusion Schr\"odinger Bridge (TreeDSB), an extension of the Diffusion Schr\"odinger Bridge (DSB) algorithm. TreeDSB corresponds to a dynamic and continuous state-space counterpart of the multimarginal Sinkhorn algorithm. A notable use case of our methodology is to compute Wasserstein barycenters which can be recast as the solution of a mOT problem on a star-shaped tree. We demonstrate that our methodology can be applied in high-dimensional settings such as image interpolation and Bayesian fusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#28201;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#24320;&#21457;&#20102;&#29616;&#20195;&#23454;&#29616;&#26041;&#27861;&#24182;&#35777;&#26126;&#20854;&#22312;&#31934;&#24230;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#26356;&#19968;&#33324;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.16543</link><description>&lt;p&gt;
&#37325;&#28201;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Revisiting Structured Variational Autoencoders. (arXiv:2305.16543v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#28201;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#24320;&#21457;&#20102;&#29616;&#20195;&#23454;&#29616;&#26041;&#27861;&#24182;&#35777;&#26126;&#20854;&#22312;&#31934;&#24230;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#26356;&#19968;&#33324;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;SVAEs&#65289;&#23558;&#27010;&#29575;&#22270;&#27169;&#22411;&#30340;&#20808;&#39564;&#24212;&#29992;&#20110;&#28508;&#21464;&#37327;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23558;&#28508;&#21464;&#37327;&#19982;&#35266;&#27979;&#25968;&#25454;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#20351;&#29992;&#32467;&#26500;&#21270;&#31639;&#27861;&#36827;&#34892;&#36817;&#20284;&#21518;&#39564;&#25512;&#26029;&#12290;&#36825;&#20123;&#27169;&#22411;&#23545;&#20110;&#24207;&#21015;&#25968;&#25454;&#29305;&#21035;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#20808;&#39564;&#21487;&#20197;&#25429;&#25417;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20854;&#29702;&#24565;&#20248;&#32654;&#65292;&#20294;&#23454;&#29616;&#38590;&#24230;&#36739;&#22823;&#65292;&#23454;&#38469;&#24212;&#29992;&#20013;&#26356;&#36890;&#29992;&#30340;&#26041;&#27861;&#26356;&#21463;&#38738;&#30544;&#12290;&#26412;&#25991;&#37319;&#29992;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#37325;&#26032;&#23457;&#35270;SVAEs&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#22312;&#31934;&#24230;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#26356;&#19968;&#33324;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#29616;&#20195;&#23454;&#29616;&#26041;&#27861;&#65292;&#23545;SVAE&#26680;&#24515;&#30340;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#36827;&#34892;&#20102;&#30828;&#20214;&#21152;&#36895;&#12289;&#24182;&#34892;&#21270;&#21644;&#33258;&#21160;&#27714;&#23548;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#21033;&#29992;&#20808;&#39564;&#20013;&#30340;&#32467;&#26500;&#65292;SVAE&#21487;&#20197;&#23398;&#20064;&#26356;&#31934;&#30830;&#30340;&#27169;&#22411;&#21644;&#21518;&#39564;&#20998;&#24067;&#65292;&#36825;&#36716;&#21270;&#20026;&#20102;&#24615;&#33021;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured variational autoencoders (SVAEs) combine probabilistic graphical model priors on latent variables, deep neural networks to link latent variables to observed data, and structure-exploiting algorithms for approximate posterior inference. These models are particularly appealing for sequential data, where the prior can capture temporal dependencies. However, despite their conceptual elegance, SVAEs have proven difficult to implement, and more general approaches have been favored in practice. Here, we revisit SVAEs using modern machine learning tools and demonstrate their advantages over more general alternatives in terms of both accuracy and efficiency. First, we develop a modern implementation for hardware acceleration, parallelization, and automatic differentiation of the message passing algorithms at the core of the SVAE. Second, we show that by exploiting structure in the prior, the SVAE learns more accurate models and posterior distributions, which translate into improved p
&lt;/p&gt;</description></item><item><title>&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#23545;&#20110;&#26377;&#30417;&#30563;&#30340;&#24773;&#20917;&#26131;&#20110;&#20135;&#29983;&#31867;&#22349;&#22604;&#65292;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#26131;&#20110;&#25233;&#21046;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#65307;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20559;&#21521;&#20110;&#23547;&#25214;&#26356;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23548;&#33268;&#36825;&#31181;&#29616;&#35937;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;</title><link>http://arxiv.org/abs/2305.16536</link><description>&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#20102;&#21738;&#20123;&#29305;&#24449;&#65311;&#20851;&#20110;&#31616;&#26131;&#20559;&#24046;&#22312;&#31867;&#22349;&#22604;&#21644;&#29305;&#24449;&#25233;&#21046;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression. (arXiv:2305.16536v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16536
&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#23545;&#20110;&#26377;&#30417;&#30563;&#30340;&#24773;&#20917;&#26131;&#20110;&#20135;&#29983;&#31867;&#22349;&#22604;&#65292;&#26080;&#30417;&#30563;&#24773;&#20917;&#19979;&#26131;&#20110;&#25233;&#21046;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#65307;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20559;&#21521;&#20110;&#23547;&#25214;&#26356;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23548;&#33268;&#36825;&#31181;&#29616;&#35937;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#20855;&#22791;&#26080;&#30417;&#30563;&#21644;&#26377;&#30417;&#30563;&#23398;&#20064;&#30340;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#65292;&#22312;&#26377;&#30417;&#30563;&#22330;&#26223;&#19979;&#26131;&#20110;&#22349;&#22604;&#21516;&#19968;&#31867;&#21035;&#20869;&#30340;&#23376;&#31867;&#34920;&#31034;&#65292;&#20002;&#22833;&#19968;&#37096;&#20998;&#29305;&#24449;&#20449;&#24687;&#65307;&#32780;&#26080;&#30417;&#30563;&#23398;&#20064;&#21017;&#21487;&#33021;&#36890;&#36807;&#23398;&#20064;&#26131;&#20110;&#22788;&#29702;&#30340;&#31867;&#21035;&#26080;&#20851;&#29305;&#24449;&#32780;&#26080;&#35270;&#19968;&#20123;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#20449;&#24687;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#20250;&#26174;&#33879;&#22320;&#38477;&#20302;&#34920;&#24449;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#32479;&#19968;&#20005;&#35880;&#30340;&#26694;&#26550;&#26469;&#29702;&#35299;&#27979;&#35797;&#26102;&#30340;&#31867;&#22349;&#22604;&#21644;&#29305;&#24449;&#25233;&#21046;&#20135;&#29983;&#30340;&#21407;&#22240;&#65292;&#30456;&#20851;&#20998;&#26512;&#34920;&#26126;&#65292;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20559;&#21521;&#20110;&#23547;&#25214;&#26356;&#31616;&#21333;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23548;&#33268;&#23376;&#31867;&#34920;&#31034;&#22349;&#22604;&#21644;&#31867;&#21035;&#30456;&#20851;&#30340;&#22797;&#26434;&#29305;&#24449;&#34987;&#25233;&#21046;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25552;&#39640;&#23884;&#20837;&#32500;&#24230;&#21644;&#25913;&#36827;&#25968;&#25454;&#22686;&#24378;&#30340;&#26041;&#27861;&#26469;&#25552;&#20379;&#26377;&#25928;&#30340;&#39044;&#38450;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning (CL) has emerged as a powerful technique for representation learning, with or without label supervision. However, supervised CL is prone to collapsing representations of subclasses within a class by not capturing all their features, and unsupervised CL may suppress harder class-relevant features by focusing on learning easy class-irrelevant features; both significantly compromise representation quality. Yet, there is no theoretical understanding of \textit{class collapse} or \textit{feature suppression} at \textit{test} time. We provide the first unified theoretically rigorous framework to determine \textit{which} features are learnt by CL. Our analysis indicate that, perhaps surprisingly, bias of (stochastic) gradient descent towards finding simpler solutions is a key factor in collapsing subclass representations and suppressing harder class-relevant features. Moreover, we present increasing embedding dimensionality and improving the quality of data augmentations 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#36890;&#36807;&#21152;&#26435;&#34928;&#20943;&#35757;&#32451;&#30340;&#22810;&#36755;&#20986;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31867;&#22411;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#26032;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.16534</link><description>&lt;p&gt;
&#21521;&#37327;&#20540;&#21464;&#20998;&#31354;&#38388;&#21644;DNN&#30340;&#23485;&#24230;&#30028;&#65306;&#20851;&#20110;&#26435;&#37325;&#34928;&#20943;&#27491;&#21017;&#21270;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vector-Valued Variation Spaces and Width Bounds for DNNs: Insights on Weight Decay Regularization. (arXiv:2305.16534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16534
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#36890;&#36807;&#21152;&#26435;&#34928;&#20943;&#35757;&#32451;&#30340;&#22810;&#36755;&#20986;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31867;&#22411;&#21644;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#26368;&#23567;&#21270;&#25439;&#22833;&#39033;&#21644;&#24179;&#26041;&#26435;&#37325;&#21644;&#30456;&#24212;&#65292;&#23545;&#24212;&#20110;&#35757;&#32451;&#21152;&#26435;&#34928;&#20943;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#20851;&#36825;&#31181;&#24120;&#35265;&#23398;&#20064;&#26694;&#26550;&#30340;&#26032;&#35265;&#35299;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#35757;&#32451;&#21152;&#26435;&#34928;&#20943;&#20197;&#33719;&#24471;&#22810;&#36755;&#20986;(&#21521;&#37327;&#20540;)ReLU&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30340;&#20989;&#25968;&#31867;&#22411;&#12290;&#36825;&#25193;&#23637;&#20102;&#20808;&#21069;&#38480;&#20110;&#21333;&#36755;&#20986;(&#26631;&#37327;&#20540;)&#32593;&#32476;&#30340;&#34920;&#24449;&#12290;&#36825;&#31181;&#34920;&#24449;&#38656;&#35201;&#23450;&#20041;&#25105;&#20204;&#31216;&#20043;&#20026;&#21521;&#37327;&#20540;&#21464;&#20998;(VV)&#31354;&#38388;&#30340;&#26032;&#31867;&#31070;&#32463;&#20989;&#25968;&#31354;&#38388;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#34920;&#24449;&#23450;&#29702;&#35777;&#26126;&#65292;&#31070;&#32463;&#32593;&#32476;(NNs)&#26159;&#36890;&#36807;VV&#31354;&#38388;&#20013;&#25552;&#20986;&#23398;&#20064;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#12290;&#36825;&#20010;&#26032;&#30340;&#34920;&#24449;&#23450;&#29702;&#34920;&#26126;&#65292;&#36825;&#20123;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#23384;&#22312;&#20110;&#23485;&#24230;&#21463;&#35757;&#32451;&#25968;&#25454;&#25968;&#38480;&#21046;&#30340;&#21521;&#37327;&#20540;&#31070;&#32463;&#32593;&#32476;&#20013;&#12290;&#25509;&#19979;&#26469;&#65292;&#36890;&#36807;&#19982;&#22810;&#20219;&#21153;lasso&#38382;&#39064;&#30340;&#26032;&#32852;&#31995;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) trained to minimize a loss term plus the sum of squared weights via gradient descent corresponds to the common approach of training with weight decay. This paper provides new insights into this common learning framework. We characterize the kinds of functions learned by training with weight decay for multi-output (vector-valued) ReLU neural networks. This extends previous characterizations that were limited to single-output (scalar-valued) networks. This characterization requires the definition of a new class of neural function spaces that we call vector-valued variation (VV) spaces. We prove that neural networks (NNs) are optimal solutions to learning problems posed over VV spaces via a novel representer theorem. This new representer theorem shows that solutions to these learning problems exist as vector-valued neural networks with widths bounded in terms of the number of training data. Next, via a novel connection to the multi-task lasso problem, we derive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#12289;&#39640;&#20445;&#30495;&#24230;&#26679;&#26412;&#20013;&#20272;&#35745;&#29289;&#29702;&#31995;&#32479;&#20013;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24179;&#34913;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#20540;&#31934;&#24230;&#20043;&#38388;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2305.16530</link><description>&lt;p&gt;
&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bi-fidelity Variational Auto-encoder for Uncertainty Quantification. (arXiv:2305.16530v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20302;&#12289;&#39640;&#20445;&#30495;&#24230;&#26679;&#26412;&#20013;&#20272;&#35745;&#29289;&#29702;&#31995;&#32479;&#20013;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24179;&#34913;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#20540;&#31934;&#24230;&#20043;&#38388;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27169;&#22411;&#39564;&#35777;&#20013;&#65292;&#37327;&#21270;&#29289;&#29702;&#31995;&#32479;&#24863;&#20852;&#36259;&#30340;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#19968;&#20010;&#20027;&#35201;&#30446;&#26631;&#12290;&#28982;&#32780;&#65292;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#38656;&#35201;&#24179;&#34913;&#35745;&#31639;&#25928;&#29575;&#21644;&#25968;&#20540;&#31934;&#24230;&#20043;&#38388;&#30340;&#38656;&#27714;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#20445;&#30495;&#24230;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;BF-VAE&#65289;&#20844;&#24335;&#65292;&#26088;&#22312;&#20174;&#29289;&#29702;&#31995;&#32479;&#20013;&#20302;&#12289;&#39640;&#20445;&#30495;&#24230;&#26679;&#26412;&#20013;&#20272;&#35745;&#19982;&#37327;&#24863;&#20852;&#36259;&#30340;&#37327;&#26377;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#21033;&#29992;&#20174;&#20302;&#20445;&#30495;&#24230;&#26679;&#26412;&#24471;&#20986;&#30340;&#20449;&#24687;&#26469;&#36924;&#36817;&#39640;&#20445;&#30495;&#24230;&#37327;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#21452;&#20445;&#30495;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#23558;&#20854;&#25972;&#21512;&#21040;VAE&#30340;&#27010;&#29575;&#32534;&#30721;-&#35299;&#30721;&#32467;&#26500;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20197;&#22312;&#23384;&#22312;&#26377;&#38480;&#39640;&#20445;&#30495;&#24230;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#21270;&#39640;&#20445;&#30495;&#24230;&#23545;&#25968;&#20284;&#28982;&#30340;&#21464;&#20998;&#19979;&#30028;&#65292;&#20174;&#32780;&#20197;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#21512;&#25104;&#39640;&#20445;&#30495;&#24230;&#30340;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#25968;&#20540;&#31034;&#20363;&#20013;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#38543;&#26426;&#31995;&#32479;&#21644;&#35745;&#31639;&#27969;&#20307;&#21160;&#21147;&#23398;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying the uncertainty of quantities of interest (QoIs) from physical systems is a primary objective in model validation. However, achieving this goal entails balancing the need for computational efficiency with the requirement for numerical accuracy. To address this trade-off, we propose a novel bi-fidelity formulation of variational auto-encoders (BF-VAE) designed to estimate the uncertainty associated with a QoI from low-fidelity (LF) and high-fidelity (HF) samples of the QoI. This model allows for the approximation of the statistics of the HF QoI by leveraging information derived from its LF counterpart. Specifically, we design a bi-fidelity auto-regressive model in the latent space that is integrated within the VAE's probabilistic encoder-decoder structure. An effective algorithm is proposed to maximize the variational lower bound of the HF log-likelihood in the presence of limited HF data, resulting in the synthesis of HF realizations with a reduced computational cost. Addit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22238;&#24402;&#35843;&#25972;&#25511;&#21046;&#21464;&#37327;&#26469;&#20943;&#23569;&#26041;&#24046;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#22312;&#20805;&#20998;&#20809;&#28369;&#30340;&#20551;&#35774;&#19979;&#21487;&#20197;&#23454;&#29616;Minimax&#26368;&#20248;&#36895;&#24230;&#65292;&#24182;&#21487;&#20197;&#35299;&#20915;&#23384;&#22312;&#32597;&#35265;&#21644;&#26497;&#31471;&#20107;&#20214;&#30340;&#26041;&#24046;&#32553;&#20943;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.16527</link><description>&lt;p&gt;
&#38543;&#26426;&#20107;&#20214;&#23569;&#30340;&#24773;&#20917;&#19979;&#65292;&#22238;&#24402;&#35843;&#25972;&#25511;&#21046;&#21464;&#37327;&#20309;&#26102;&#26377;&#24110;&#21161;&#65311;Sobolev&#23884;&#20837;&#21644;Minimax&#26368;&#20248;&#24615;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
When can Regression-Adjusted Control Variates Help? Rare Events, Sobolev Embedding and Minimax Optimality. (arXiv:2305.16527v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22238;&#24402;&#35843;&#25972;&#25511;&#21046;&#21464;&#37327;&#26469;&#20943;&#23569;&#26041;&#24046;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#22312;&#20805;&#20998;&#20809;&#28369;&#30340;&#20551;&#35774;&#19979;&#21487;&#20197;&#23454;&#29616;Minimax&#26368;&#20248;&#36895;&#24230;&#65292;&#24182;&#21487;&#20197;&#35299;&#20915;&#23384;&#22312;&#32597;&#35265;&#21644;&#26497;&#31471;&#20107;&#20214;&#30340;&#26041;&#24046;&#32553;&#20943;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20272;&#35745;&#22120;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#26469;&#20943;&#23569;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#26041;&#24046;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26088;&#22312;&#25581;&#31034;&#24433;&#21709;&#25511;&#21046;&#21464;&#37327;&#25928;&#29575;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#25105;&#20204;&#30740;&#31350;&#19968;&#20010;&#21407;&#22411;&#20272;&#35745;&#38382;&#39064;&#65292;&#28041;&#21450;&#26681;&#25454;&#20174;&#65288;&#38543;&#26426;&#30340;&#65289;&#25968;&#20540;&#31215;&#20998;&#33410;&#28857;&#33719;&#21462;&#30340;&#35266;&#27979;&#20540;&#27169;&#25311;Sobolev&#20989;&#25968;&#30340;&#30697;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20026;&#35813;&#38382;&#39064;&#24314;&#31435;&#20102;&#20449;&#24687;&#35770;&#19979;&#38480;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#29305;&#23450;&#30340;&#25968;&#20540;&#31215;&#20998;&#35268;&#21017;&#65292;&#23427;&#37319;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#35843;&#25972;&#25511;&#21046;&#21464;&#37327;&#26469;&#38477;&#20302;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#25968;&#20540;&#31215;&#20998;&#35268;&#21017;&#21487;&#20197;&#25913;&#21892;&#33945;&#29305;&#21345;&#32599;&#36895;&#24230;&#65292;&#24182;&#22312;&#20805;&#20998;&#20809;&#28369;&#30340;&#20551;&#35774;&#19979;&#23454;&#29616;Minimax&#26368;&#20248;&#36895;&#24230;&#12290;&#30001;&#20110; Sobolev &#23884;&#20837;&#23450;&#29702;&#65292;&#20805;&#20998;&#20809;&#28369;&#30340;&#20551;&#35774;&#28040;&#38500;&#20102;&#32597;&#35265;&#21644;&#26497;&#31471;&#20107;&#20214;&#30340;&#23384;&#22312;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#32597;&#35265;&#21644;&#26497;&#31471;&#20107;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#22238;&#24402;&#35843;&#25972;&#25511;&#21046;&#21464;&#37327;&#21487;&#20197;&#24110;&#21161;&#35299;&#20915;&#26041;&#24046;&#32553;&#20943;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the use of a machine learning-based estimator as a control variate for mitigating the variance of Monte Carlo sampling. Specifically, we seek to uncover the key factors that influence the efficiency of control variates in reducing variance. We examine a prototype estimation problem that involves simulating the moments of a Sobolev function based on observations obtained from (random) quadrature nodes. Firstly, we establish an information-theoretic lower bound for the problem. We then study a specific quadrature rule that employs a nonparametric regression-adjusted control variate to reduce the variance of the Monte Carlo simulation. We demonstrate that this kind of quadrature rule can improve the Monte Carlo rate and achieve the minimax optimal rate under a sufficient smoothness assumption. Due to the Sobolev Embedding Theorem, the sufficient smoothness assumption eliminates the existence of rare and extreme events. Finally, we show that, in the presence of rare and 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#30340;PTAS&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#35823;&#24046;&#21644;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.16508</link><description>&lt;p&gt;
&#22823;&#37096;&#20998;&#31070;&#32463;&#32593;&#32476;&#20960;&#20046;&#26159;&#21487;&#23398;&#20064;&#30340;
&lt;/p&gt;
&lt;p&gt;
Most Neural Networks Are Almost Learnable. (arXiv:2305.16508v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#30340;PTAS&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#35823;&#24046;&#21644;&#28145;&#24230;&#65292;&#20960;&#20046;&#25152;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#37117;&#26159;&#21487;&#23398;&#20064;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;PTAS&#26469;&#23398;&#20064;&#38543;&#26426;&#24120;&#25968;&#28145;&#24230;&#32593;&#32476;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#22266;&#23450;&#30340;$\epsilon&gt;0$&#21644;&#28145;&#24230;$i$&#65292;&#23384;&#22312;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#23545;&#20110;$\sqrt{d} \cdot \mathbb{S}^{d-1}$&#19978;&#30340;&#20219;&#20309;&#20998;&#24067;&#65292;&#23398;&#20064;&#38543;&#26426;Xavier&#32593;&#32476;&#30340;&#28145;&#24230;$i$&#65292;&#35823;&#24046;&#20026;$\epsilon$&#12290;&#35813;&#31639;&#27861;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$(\bar{d})^{\mathrm{poly}(\epsilon^{-1})}$&#65292;&#20854;&#20013;$\bar d$&#26159;&#32593;&#32476;&#30340;&#22823;&#23567;&#12290;&#23545;&#20110;&#26576;&#20123;&#31867;&#20284;&#20110;Sigmoid&#21644;ReLU&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20197;&#23558;&#35823;&#24046;&#30028;&#38480;&#25913;&#36827;&#20026;$(\bar{d})^{\mathrm{polylog}(\epsilon^{-1})}$&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#31181;&#20960;&#20046;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#23398;&#20064;&#24120;&#25968;&#28145;&#24230;&#38543;&#26426;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a PTAS for learning random constant-depth networks. We show that for any fixed $\epsilon&gt;0$ and depth $i$, there is a poly-time algorithm that for any distribution on $\sqrt{d} \cdot \mathbb{S}^{d-1}$ learns random Xavier networks of depth $i$, up to an additive error of $\epsilon$. The algorithm runs in time and sample complexity of $(\bar{d})^{\mathrm{poly}(\epsilon^{-1})}$, where $\bar d$ is the size of the network. For some cases of sigmoid and ReLU-like activations the bound can be improved to $(\bar{d})^{\mathrm{polylog}(\epsilon^{-1})}$, resulting in a quasi-poly-time algorithm for learning constant depth random networks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#26041;&#27861;&#65292;&#21363;SAMoSSA&#12290;&#35813;&#26041;&#27861;&#32508;&#21512;&#20102;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;&#21644;&#33258;&#22238;&#24402;&#20998;&#26512;&#65292;&#22312;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#25104;&#20998;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.16491</link><description>&lt;p&gt;
SAMoSSA&#65306;&#24102;&#38543;&#26426;&#33258;&#22238;&#24402;&#22122;&#22768;&#30340;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
SAMoSSA: Multivariate Singular Spectrum Analysis with Stochastic Autoregressive Noise. (arXiv:2305.16491v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16491
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#26041;&#27861;&#65292;&#21363;SAMoSSA&#12290;&#35813;&#26041;&#27861;&#32508;&#21512;&#20102;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;&#21644;&#33258;&#22238;&#24402;&#20998;&#26512;&#65292;&#22312;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#25104;&#20998;&#26041;&#38754;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#24815;&#20363;&#26159;&#20808;&#20272;&#35745;&#30830;&#23450;&#24615;&#12289;&#38750;&#24179;&#31283;&#36235;&#21183;&#21644;&#23395;&#33410;&#25104;&#20998;&#65292;&#28982;&#21518;&#23398;&#20064;&#27531;&#24046;&#38543;&#26426;&#12289;&#24179;&#31283;&#25104;&#20998;&#12290;&#26368;&#36817;&#24050;&#32463;&#34920;&#26126;&#65292;&#22312;&#27809;&#26377;&#30456;&#20851;&#24179;&#31283;&#25104;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#20351;&#29992;&#22810;&#20803;&#22855;&#24322;&#35889;&#20998;&#26512;&#65288;mSSA&#65289;&#20934;&#30830;&#22320;&#23398;&#20064;&#30830;&#23450;&#24615;&#38750;&#24179;&#31283;&#25104;&#20998;&#65307;&#21516;&#26102;&#65292;&#22312;&#27809;&#26377;&#30830;&#23450;&#24615;&#38750;&#24179;&#31283;&#25104;&#20998;&#30340;&#24773;&#20917;&#19979;&#65292;&#33258;&#22238;&#24402;&#65288;AR&#65289;&#24179;&#31283;&#25104;&#20998;&#20063;&#21487;&#20197;&#36731;&#26494;&#23398;&#20064;&#65292;&#20363;&#22914;&#36890;&#36807;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#65288;OLS&#65289;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#36825;&#31181;&#20004;&#20010;&#27493;&#39588;&#30340;&#23398;&#20064;&#31639;&#27861;&#24050;&#32463;&#26222;&#36941;&#23384;&#22312;&#65292;&#20294;&#20851;&#20110;&#21516;&#26102;&#28041;&#21450;&#30830;&#23450;&#24615;&#21644;&#24179;&#31283;&#25104;&#20998;&#30340;&#22810;&#38454;&#27573;&#23398;&#20064;&#31639;&#27861;&#30340;&#29702;&#35770;&#25903;&#25745;&#22312;&#25991;&#29486;&#20013;&#36824;&#27809;&#26377;&#35299;&#20915;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#19968;&#31181;&#33258;&#28982;&#30340;&#20004;&#38454;&#27573;&#31639;&#27861;&#24314;&#31435;&#29702;&#35770;&#20445;&#35777;&#26469;&#35299;&#20915;&#36825;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#20854;&#20013;&#39318;&#20808;&#24212;&#29992;mSSA&#26469;&#20272;&#35745;&#38750;&#24179;&#31283;&#25104;&#20998;&#65292;&#23613;&#31649;&#23384;&#22312;&#30456;&#20851;&#24615;&#24179;&#31283;&#25104;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
The well-established practice of time series analysis involves estimating deterministic, non-stationary trend and seasonality components followed by learning the residual stochastic, stationary components. Recently, it has been shown that one can learn the deterministic non-stationary components accurately using multivariate Singular Spectrum Analysis (mSSA) in the absence of a correlated stationary component; meanwhile, in the absence of deterministic non-stationary components, the Autoregressive (AR) stationary component can also be learnt readily, e.g. via Ordinary Least Squares (OLS). However, a theoretical underpinning of multi-stage learning algorithms involving both deterministic and stationary components has been absent in the literature despite its pervasiveness. We resolve this open question by establishing desirable theoretical guarantees for a natural two-stage algorithm, where mSSA is first applied to estimate the non-stationary components despite the presence of a correla
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26032;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#19968;&#20123;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#26032;&#30340;&#20984;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#21487;&#20197;&#34987;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2305.16475</link><description>&lt;p&gt;
&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Initialization-Dependent Sample Complexity of Linear Predictors and Neural Networks. (arXiv:2305.16475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#32447;&#24615;&#39044;&#27979;&#22120;&#21644;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#26032;&#32467;&#26524;&#65292;&#35299;&#20915;&#20102;&#19968;&#20123;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#26032;&#30340;&#20984;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#21487;&#20197;&#34987;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#21521;&#37327;&#20540;&#32447;&#24615;&#39044;&#27979;&#22120;(&#30001;&#30697;&#38453;&#21442;&#25968;&#21270;)&#12289;&#26356;&#19968;&#33324;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#26032;&#32467;&#26524;&#12290;&#19987;&#27880;&#20110;&#22823;&#23567;&#26080;&#20851;&#30340;&#30028;&#38480;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20165;&#25511;&#21046;&#20174;&#26576;&#20010;&#22266;&#23450;&#21442;&#32771;&#30697;&#38453;$W_0$&#30340;&#21442;&#25968;&#30340;Frobenius&#33539;&#25968;&#36317;&#31163;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#34892;&#20026;&#21487;&#20197;&#20986;&#20154;&#24847;&#26009;&#22320;&#19981;&#21516;&#20110;&#25105;&#20204;&#22312;&#30740;&#31350;&#26631;&#37327;&#20540;&#32447;&#24615;&#39044;&#27979;&#22120;&#26041;&#38754;&#25152;&#26399;&#26395;&#30340;&#12290;&#36825;&#36824;&#23548;&#33268;&#20102;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#35299;&#20915;&#20102;&#19968;&#20123;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#24182;&#30830;&#31435;&#20102;&#19968;&#20010;&#26032;&#30340;&#20984;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23427;&#21487;&#20197;&#22312;&#27809;&#26377;&#32479;&#19968;&#25910;&#25947;&#30340;&#24773;&#20917;&#19979;&#34987;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide several new results on the sample complexity of vector-valued linear predictors (parameterized by a matrix), and more generally neural networks. Focusing on size-independent bounds, where only the Frobenius norm distance of the parameters from some fixed reference matrix $W_0$ is controlled, we show that the sample complexity behavior can be surprisingly different than what we may expect considering the well-studied setting of scalar-valued linear predictors. This also leads to new sample complexity bounds for feed-forward neural networks, tackling some open questions in the literature, and establishing a new convex linear prediction problem that is provably learnable without uniform convergence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.16446</link><description>&lt;p&gt;
&#22522;&#20110;&#34920;&#31034;&#30340;Jensen-Shannon&#25955;&#24230;
&lt;/p&gt;
&lt;p&gt;
The Representation Jensen-Shannon Divergence. (arXiv:2305.16446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#65292;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#25193;&#23637;&#24615;&#65292;&#21487;&#24494;&#20998;&#24615;&#30340;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20989;&#25968;&#21644;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#25955;&#24230;&#37327;&#21270;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#37325;&#35201;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#30001;&#20110;&#25968;&#25454;&#30340;&#24213;&#23618;&#20998;&#24067;&#36890;&#24120;&#26410;&#30693;&#65292;&#20174;&#32463;&#39564;&#26679;&#26412;&#20013;&#20272;&#35745;&#25955;&#24230;&#26159;&#19968;&#20010;&#22522;&#26412;&#38590;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#20013;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#26032;&#22411;&#25955;&#24230;&#8212;&#8212;&#34920;&#31034;Jensen-Shannon&#25955;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#25968;&#25454;&#20998;&#24067;&#23884;&#20837;&#21040;RKHS&#20013;&#65292;&#24182;&#21033;&#29992;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#39057;&#35889;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;Fourier&#29305;&#24449;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;RKHS&#20013;&#12290;&#27492;&#20272;&#35745;&#20989;&#25968;&#26159;&#28789;&#27963;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#24494;&#20998;&#30340;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#23567;&#25209;&#37327;&#20248;&#21270;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30697;&#38453;&#30340;&#20272;&#35745;&#20989;&#25968;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;RKHS&#36827;&#34892;&#26174;&#24335;&#26144;&#23556;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#37327;&#26159;Jensen-Shannon&#25955;&#24230;&#30340;&#19968;&#20010;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#36801;&#31227;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#32473;&#23450;&#24456;&#23569;&#25968;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#22312;&#21487;&#33021;&#19981;&#21516;&#30340;&#25968;&#25454;&#39046;&#22495;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#65292;&#26469;&#26500;&#24314;&#30446;&#26631;&#27169;&#22411;&#65292;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.16440</link><description>&lt;p&gt;
&#22810;&#20010;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#34920;&#31034;&#36801;&#31227;&#23398;&#20064;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Representation Transfer Learning via Multiple Pre-trained models for Linear Regression. (arXiv:2305.16440v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#36801;&#31227;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#32473;&#23450;&#24456;&#23569;&#25968;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#22312;&#21487;&#33021;&#19981;&#21516;&#30340;&#25968;&#25454;&#39046;&#22495;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#65292;&#26469;&#26500;&#24314;&#30446;&#26631;&#27169;&#22411;&#65292;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32473;&#23450;&#24456;&#23569;&#25968;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#22312;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#39046;&#22495;&#65288;&#30446;&#26631;&#65289;&#19978;&#23398;&#20064;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#36801;&#31227;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#22312;&#21487;&#33021;&#19981;&#21516;&#30340;&#25968;&#25454;&#39046;&#22495;&#65288;&#26469;&#28304;&#65289;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#65292;&#26469;&#26500;&#24314;&#30446;&#26631;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#30001;&#20004;&#20010;&#38454;&#27573;&#32452;&#25104;&#65306;&#65288;i&#65289;&#21033;&#29992;&#19981;&#21516;&#30340;&#28304;&#34920;&#31034;&#26469;&#26500;&#36896;&#36866;&#24212;&#30446;&#26631;&#25968;&#25454;&#30340;&#34920;&#31034;&#65292;&#65288;ii&#65289;&#23558;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#20316;&#20026;&#21021;&#22987;&#20540;&#65292;&#36890;&#36807;&#24494;&#35843;&#31243;&#24207;&#65292;&#22312;&#30446;&#26631;&#25968;&#25454;&#19978;&#37325;&#26032;&#35757;&#32451;&#25972;&#20010;&#65288;&#36229;&#21442;&#25968;&#65289;&#22238;&#24402;&#27169;&#22411;&#12290;&#23545;&#20110;&#35757;&#32451;&#26041;&#27861;&#30340;&#27599;&#20010;&#38454;&#27573;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#27169;&#22411;&#19982;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#30446;&#26631;&#27169;&#22411;&#20043;&#38388;&#30340;&#36229;&#39069;&#39118;&#38505;&#38480;&#21046;&#12290;&#23548;&#20986;&#30340;&#38480;&#21046;&#26174;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of learning a linear regression model on a data domain of interest (target) given few samples. To aid learning, we are provided with a set of pre-trained regression models that are trained on potentially different data domains (sources). Assuming a representation structure for the data generating linear models at the sources and the target domains, we propose a representation transfer based learning method for constructing the target model. The proposed scheme is comprised of two phases: (i) utilizing the different source representations to construct a representation that is adapted to the target data, and (ii) using the obtained model as an initialization to a fine-tuning procedure that re-trains the entire (over-parameterized) regression model on the target data. For each phase of the training method, we provide excess risk bounds for the learned model compared to the true data generating target model. The derived bounds show a gain in sample co
&lt;/p&gt;</description></item><item><title>SketchOGD&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#22312;&#32447;&#33609;&#22270;&#31639;&#27861;&#65292;&#23558;&#27169;&#22411;&#26799;&#24230;&#21387;&#32553;&#20026;&#22266;&#23450;&#22823;&#23567;&#30340;&#30697;&#38453;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#12290;</title><link>http://arxiv.org/abs/2305.16424</link><description>&lt;p&gt;
SketchOGD&#65306;&#20869;&#23384;&#39640;&#25928;&#30340;&#25345;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SketchOGD: Memory-Efficient Continual Learning. (arXiv:2305.16424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16424
&lt;/p&gt;
&lt;p&gt;
SketchOGD&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#37319;&#29992;&#22312;&#32447;&#33609;&#22270;&#31639;&#27861;&#65292;&#23558;&#27169;&#22411;&#26799;&#24230;&#21387;&#32553;&#20026;&#22266;&#23450;&#22823;&#23567;&#30340;&#30697;&#38453;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#19968;&#31995;&#21015;&#20219;&#21153;&#19978;&#25345;&#32493;&#35757;&#32451;&#26102;&#65292;&#23427;&#20204;&#23481;&#26131;&#24536;&#35760;&#20808;&#21069;&#20219;&#21153;&#19978;&#23398;&#20064;&#21040;&#30340;&#30693;&#35782;&#65292;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#28798;&#38590;&#24615;&#36951;&#24536;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#24448;&#24448;&#28041;&#21450;&#23384;&#20648;&#36807;&#21435;&#20219;&#21153;&#30340;&#20449;&#24687;&#65292;&#36825;&#24847;&#21619;&#30528;&#20869;&#23384;&#20351;&#29992;&#26159;&#30830;&#23450;&#23454;&#29992;&#24615;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#23384;&#39640;&#25928;&#30340;&#35299;&#20915;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#19968;&#31181;&#24050;&#26377;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#12290;OGD&#21033;&#29992;&#20808;&#21069;&#27169;&#22411;&#26799;&#24230;&#26469;&#25214;&#21040;&#32500;&#25345;&#20808;&#21069;&#25968;&#25454;&#28857;&#24615;&#33021;&#30340;&#26435;&#37325;&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#20648;&#20808;&#21069;&#27169;&#22411;&#26799;&#24230;&#30340;&#20869;&#23384;&#25104;&#26412;&#38543;&#31639;&#27861;&#36816;&#34892;&#26102;&#38388;&#22686;&#38271;&#32780;&#22686;&#21152;&#65292;&#22240;&#27492;OGD&#19981;&#36866;&#29992;&#20110;&#20219;&#24847;&#38271;&#26102;&#38388;&#36328;&#24230;&#30340;&#36830;&#32493;&#23398;&#20064;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;SketchOGD&#12290;SketchOGD&#37319;&#29992;&#22312;&#32447;&#33609;&#22270;&#31639;&#27861;&#65292;&#23558;&#27169;&#22411;&#26799;&#24230;&#21387;&#32553;&#20026;&#22266;&#23450;&#22823;&#23567;&#30340;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
When machine learning models are trained continually on a sequence of tasks, they are liable to forget what they learned on previous tasks -- a phenomenon known as catastrophic forgetting. Proposed solutions to catastrophic forgetting tend to involve storing information about past tasks, meaning that memory usage is a chief consideration in determining their practicality. This paper proposes a memory-efficient solution to catastrophic forgetting, improving upon an established algorithm known as orthogonal gradient descent (OGD). OGD utilizes prior model gradients to find weight updates that preserve performance on prior datapoints. However, since the memory cost of storing prior model gradients grows with the runtime of the algorithm, OGD is ill-suited to continual learning over arbitrarily long time horizons. To address this problem, this paper proposes SketchOGD. SketchOGD employs an online sketching algorithm to compress model gradients as they are encountered into a matrix of a fix
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#25968;&#25454;&#25299;&#25169;&#30456;&#20851;&#30340;&#31070;&#32463;&#32593;&#32476;&#23485;&#24230;&#19978;&#30028;&#65292;&#24182;&#36890;&#36807;&#25299;&#25169;&#26041;&#27861;&#35777;&#26126;&#20102;&#19977;&#23618;ReLU&#32593;&#32476;&#30340;&#26222;&#36866;&#36924;&#36817;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2305.16375</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#23485;&#24230;&#19982;&#25968;&#25454;&#25299;&#25169;&#29305;&#24449;&#30456;&#20851;&#30340;&#19978;&#30028;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Data Topology-Dependent Upper Bounds of Neural Network Widths. (arXiv:2305.16375v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#25968;&#25454;&#25299;&#25169;&#30456;&#20851;&#30340;&#31070;&#32463;&#32593;&#32476;&#23485;&#24230;&#19978;&#30028;&#65292;&#24182;&#36890;&#36807;&#25299;&#25169;&#26041;&#27861;&#35777;&#26126;&#20102;&#19977;&#23618;ReLU&#32593;&#32476;&#30340;&#26222;&#36866;&#36924;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26222;&#36866;&#36924;&#36817;&#24615;&#36136;&#19982;&#25968;&#25454;&#25299;&#25169;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24341;&#20837;&#20102;&#25968;&#25454;&#25299;&#25169;&#30456;&#20851;&#30340;&#32593;&#32476;&#23485;&#24230;&#19978;&#30028;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#19968;&#20010;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#24212;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#21644;&#26368;&#22823;&#27744;&#21270;&#65292;&#21487;&#20197;&#35774;&#35745;&#26469;&#36924;&#36817;&#19968;&#20010;&#22312;&#32039;&#20945;&#20984;&#22810;&#38754;&#20307;&#20869;&#23553;&#35013;&#30340;&#25351;&#31034;&#20989;&#25968;&#12290;&#28982;&#21518;&#25105;&#20204;&#23558;&#20854;&#25193;&#23637;&#21040;&#19968;&#20010;&#21333;&#32431;&#22797;&#21512;&#20307;&#65292;&#22522;&#20110;&#20854;&#25299;&#25169;&#32467;&#26500;&#25512;&#23548;&#23485;&#24230;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#36873;&#25321;&#25299;&#25169;&#31354;&#38388;&#30340;Betti&#25968;&#35745;&#31639;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25299;&#25169;&#26041;&#27861;&#35777;&#26126;&#20102;&#19977;&#23618;ReLU&#32593;&#32476;&#30340;&#26222;&#36866;&#36924;&#36817;&#24615;&#36136;&#12290;&#25105;&#20204;&#36824;&#39564;&#35777;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#25910;&#25947;&#20110;&#26412;&#30740;&#31350;&#25552;&#20986;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the relationship between the universal approximation property of deep neural networks and topological characteristics of datasets. Our primary contribution is to introduce data topology-dependent upper bounds on the network width. Specifically, we first show that a three-layer neural network, applying a ReLU activation function and max pooling, can be designed to approximate an indicator function over a compact set, one that is encompassed by a tight convex polytope. This is then extended to a simplicial complex, deriving width upper bounds based on its topological structure. Further, we calculate upper bounds in relation to the Betti numbers of select topological spaces. Finally, we prove the universal approximation property of three-layer ReLU networks using our topological approach. We also verify that gradient descent converges to the network structure proposed in our study.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#20854;&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#26174;&#30528;&#25552;&#39640;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#22343;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.16368</link><description>&lt;p&gt;
&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#65306;&#23398;&#20064;&#20849;&#36717;&#26799;&#24230;&#27861;&#30340;&#39044;&#22788;&#29702;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neural incomplete factorization: learning preconditioners for the conjugate gradient method. (arXiv:2305.16368v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#20854;&#36890;&#36807;&#26367;&#25442;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#26174;&#30528;&#25552;&#39640;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#22343;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#29992;&#20110;&#21152;&#36895;&#31185;&#23398;&#35745;&#31639;&#21644;&#20248;&#21270;&#20013;&#36935;&#21040;&#30340;&#22823;&#35268;&#27169;&#32447;&#24615;&#26041;&#31243;&#32452;&#27714;&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#33258;&#30417;&#30563;&#35757;&#32451;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#29983;&#25104;&#36866;&#29992;&#20110;&#29305;&#23450;&#38382;&#39064;&#22495;&#30340;&#26377;&#25928;&#39044;&#22788;&#29702;&#22120;&#12290;&#36890;&#36807;&#26367;&#25442;&#19982;&#20849;&#36717;&#26799;&#24230;&#27861;&#19968;&#36215;&#20351;&#29992;&#30340;&#20256;&#32479;&#25163;&#24037;&#39044;&#22788;&#29702;&#22120;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#65288;&#31216;&#20026;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#65289;&#26174;&#30528;&#21152;&#36895;&#20102;&#25910;&#25947;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#19968;&#31181;&#21463;&#31232;&#30095;&#30697;&#38453;&#29702;&#35770;&#21551;&#21457;&#30340;&#26032;&#22411;&#28040;&#24687;&#20256;&#36882;&#22359;&#65292;&#23427;&#19982;&#23547;&#25214;&#30697;&#38453;&#30340;&#31232;&#30095;&#20998;&#35299;&#30340;&#30446;&#26631;&#30456;&#19968;&#33268;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#38382;&#39064;&#21644;&#26469;&#33258;&#31185;&#23398;&#35745;&#31639;&#30340;&#30495;&#23454;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31070;&#32463;&#19981;&#23436;&#20840;&#20998;&#35299;&#22987;&#32456;&#20248;&#20110;&#26368;&#24120;&#35265;&#30340;&#36890;&#29992;&#39044;&#22788;&#29702;&#22120;&#65292;&#21253;&#25324;&#19981;&#23436;&#20840;&#30340;Cholesky&#26041;&#27861;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a novel data-driven approach to accelerate solving large-scale linear equation systems encountered in scientific computing and optimization. Our method utilizes self-supervised training of a graph neural network to generate an effective preconditioner tailored to the specific problem domain. By replacing conventional hand-crafted preconditioners used with the conjugate gradient method, our approach, named neural incomplete factorization (NeuralIF), significantly speeds-up convergence and computational efficiency. At the core of our method is a novel message-passing block, inspired by sparse matrix theory, that aligns with the objective to find a sparse factorization of the matrix. We evaluate our proposed method on both a synthetic and a real-world problem arising from scientific computing. Our results demonstrate that NeuralIF consistently outperforms the most common general-purpose preconditioners, including the incomplete Cholesky method, achieving competit
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#25200;&#21160;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;&#65292;&#20381;&#36182;&#20110;&#32447;&#24615;&#35268;&#21010;&#35299;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.16358</link><description>&lt;p&gt;
&#24102;&#25200;&#21160;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentiable Clustering with Perturbed Spanning Forests. (arXiv:2305.16358v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16358
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#25200;&#21160;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;&#65292;&#20381;&#36182;&#20110;&#32447;&#24615;&#35268;&#21010;&#35299;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#23567;&#26435;&#37325;&#29983;&#25104;&#26641;&#30340;&#21487;&#24494;&#32858;&#31867;&#26041;&#27861;&#65292;&#23427;&#26159;&#29983;&#25104;&#26641;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#20855;&#26377;&#22810;&#20010;&#36830;&#36890;&#20998;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#32447;&#24615;&#35268;&#21010;&#35299;&#30340;&#38543;&#26426;&#25200;&#21160;&#65292;&#20197;&#23454;&#29616;&#24179;&#28369;&#21644;&#39640;&#25928;&#30340;&#26799;&#24230;&#35745;&#31639;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#31471;&#21040;&#31471;&#21487;&#35757;&#32451;&#30340;&#27969;&#27700;&#32447;&#20013;&#21253;&#21547;&#32858;&#31867;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20960;&#20309;&#29615;&#22659;&#19979;&#20063;&#33021;&#33391;&#22909;&#22320;&#24037;&#20316;&#12290;&#25105;&#20204;&#36824;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#21046;&#23450;&#20102;&#19968;&#20010;&#29305;&#21035;&#30340;&#25439;&#22833;&#65292;&#20197;&#26377;&#25928;&#22320;&#20174;&#37096;&#20998;&#32858;&#31867;&#25968;&#25454;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#23427;&#22312;&#30417;&#30563;&#21644;&#21322;&#30417;&#30563;&#20219;&#21153;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a differentiable clustering method based on minimum-weight spanning forests, a variant of spanning trees with several connected components. Our method relies on stochastic perturbations of solutions of linear programs, for smoothing and efficient gradient computations. This allows us to include clustering in end-to-end trainable pipelines. We show that our method performs well even in difficult settings, such as datasets with high noise and challenging geometries. We also formulate an ad hoc loss to efficiently learn from partial clustering data using this operation. We demonstrate its performance on several real world datasets for supervised and semi-supervised tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;</title><link>http://arxiv.org/abs/2305.15925</link><description>&lt;p&gt;
&#20851;&#20110;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability of Markov Switching Models. (arXiv:2305.15925v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#22240;&#20854;&#22312;&#21487;&#35299;&#37322;&#24615;&#25110;&#20998;&#24067;&#27867;&#21270;&#26041;&#38754;&#30340;&#24212;&#29992;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20316;&#20026;&#23558;&#26368;&#36817;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#24207;&#21015;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#31532;&#19968;&#27493;&#30340;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#22312;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#25552;&#20986;&#20102;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifiability of latent variable models has recently gained interest in terms of its applications to interpretability or out of distribution generalisation. In this work, we study identifiability of Markov Switching Models as a first step towards extending recent results to sequential latent variable models. We present identifiability conditions within first-order Markov dependency structures, and parametrise the transition distribution via non-linear Gaussians. Our experiments showcase the applicability of our approach for regime-dependent causal discovery and high-dimensional time series segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.15786</link><description>&lt;p&gt;
&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#30340;&#29702;&#35770;&#20445;&#35777;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting. (arXiv:2305.15786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#21512;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#20943;&#23569;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#38024;&#23545;&#40657;&#30418;&#22522;&#23398;&#20064;&#22120;&#30340;&#22823;&#22810;&#25968;&#38598;&#21512;&#26041;&#27861;&#37117;&#23646;&#20110;&#8220;&#21472;&#21152;&#27867;&#21270;&#8221;&#33539;&#30068;&#65292;&#21363;&#35757;&#32451;&#19968;&#20010;&#25509;&#21463;&#22522;&#23398;&#20064;&#22120;&#25512;&#29702;&#20316;&#20026;&#36755;&#20837;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#34429;&#28982;&#21472;&#21152;&#27867;&#21270;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#8220;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#8221;&#21472;&#21152;&#27867;&#21270;&#20013;&#30340;&#26368;&#20339;&#21472;&#21152;&#27867;&#21270;&#24182;&#19981;&#27604;&#26368;&#20248;&#35299;&#34920;&#29616;&#8220;&#24046;&#24471;&#22810;&#8221;&#12290;&#36825;&#19968;&#32467;&#26524;&#21152;&#24378;&#21644;&#22823;&#22823;&#25193;&#23637;&#20102;Van der Laan&#31561;&#20154;&#65288;2007&#24180;&#65289;&#30340;&#32467;&#26524;&#12290;&#21463;&#21040;&#29702;&#35770;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#27010;&#29575;&#39044;&#27979;&#30340;&#32972;&#26223;&#19979;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#19981;&#21516;&#25935;&#24863;&#24615;&#30340;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the 
&lt;/p&gt;</description></item><item><title>PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.10255</link><description>&lt;p&gt;
PED-ANOVA: &#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#37327;&#21270;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA: Efficiently Quantifying Hyperparameter Importance in Arbitrary Subspaces. (arXiv:2304.10255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10255
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#27969;&#34892;&#20351;&#24471;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#23545;&#20110;&#35757;&#32451;&#24378;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#21448;&#20005;&#37325;&#20381;&#36182;&#20110;&#20102;&#35299;&#19981;&#21516;&#36229;&#21442;&#25968;&#30340;&#20316;&#29992;&#12290;&#36825;&#28608;&#21457;&#20102;&#20851;&#20110;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#30740;&#31350;&#65292;&#20363;&#22914;&#20351;&#29992;&#21151;&#33021;&#26041;&#24046;&#20998;&#26512; (f-ANOVA) &#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#21407;&#22987;&#30340; f-ANOVA &#20844;&#24335;&#19981;&#36866;&#29992;&#20110;&#31639;&#27861;&#35774;&#35745;&#24072;&#26368;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#65292;&#20363;&#22914;&#30001;&#26368;&#20339;&#24615;&#33021;&#23450;&#20041;&#30340;&#23376;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#26032;&#30340;&#38024;&#23545;&#20219;&#24847;&#23376;&#31354;&#38388;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#20351;&#29992; Pearson &#25955;&#24230; (PED) &#23454;&#29616;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#38381;&#24335;&#35745;&#31639;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20010;&#26032;&#31639;&#27861;&#65292;&#31216;&#20026; PED-ANOVA&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#35782;&#21035;&#19981;&#21516;&#23376;&#31354;&#38388;&#20013;&#37325;&#35201;&#30340;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#35745;&#31639;&#25928;&#29575;&#26497;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent rise in popularity of Hyperparameter Optimization (HPO) for deep learning has highlighted the role that good hyperparameter (HP) space design can play in training strong models. In turn, designing a good HP space is critically dependent on understanding the role of different HPs. This motivates research on HP Importance (HPI), e.g., with the popular method of functional ANOVA (f-ANOVA). However, the original f-ANOVA formulation is inapplicable to the subspaces most relevant to algorithm designers, such as those defined by top performance. To overcome this problem, we derive a novel formulation of f-ANOVA for arbitrary subspaces and propose an algorithm that uses Pearson divergence (PED) to enable a closed-form computation of HPI. We demonstrate that this new algorithm, dubbed PED-ANOVA, is able to successfully identify important HPs in different subspaces while also being extremely computationally efficient.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;&#27874;&#21160;&#30340;&#34920;&#24449;&#20197;&#21450;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2304.03408</link><description>&lt;p&gt;
&#26377;&#38480;&#23485;&#24230;&#26680;&#21644;&#24179;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#27874;&#21160;&#21160;&#21147;&#23398;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks. (arXiv:2304.03408v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;&#27874;&#21160;&#30340;&#34920;&#24449;&#20197;&#21450;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#12290;&#19982;&#35768;&#22810;&#20808;&#21069;&#30340;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#38024;&#23545;&#29305;&#24449;&#23398;&#20064;&#24378;&#24230;&#30340;&#38750;&#24494;&#25200;&#26377;&#38480;&#23485;&#24230;&#30340;&#32467;&#26524;&#12290;&#20174;&#26080;&#38480;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26680;&#21644;&#39044;&#27979;&#21160;&#21147;&#23398;&#30340;&#21160;&#21147;&#23398;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#25551;&#36848;&#24320;&#22987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;$\mathcal{O}(1/\sqrt{\text{width}})$&#27874;&#21160;&#30340;&#34920;&#24449;&#12290;&#22312;&#32593;&#32476;&#35757;&#32451;&#30340;&#25042;&#24816;&#26497;&#38480;&#20013;&#65292;&#25152;&#26377;&#26680;&#37117;&#26159;&#38543;&#26426;&#30340;&#20294;&#22312;&#26102;&#38388;&#19978;&#38745;&#27490;&#30340;&#65292;&#39044;&#27979;&#26041;&#24046;&#20855;&#26377;&#36890;&#29992;&#24418;&#24335;&#12290;&#28982;&#32780;&#65292;&#22312;&#23500;&#26377;&#29305;&#24449;&#23398;&#20064;&#30340;&#21306;&#22495;&#65292;&#26680;&#21644;&#39044;&#27979;&#30340;&#27874;&#21160;&#26159;&#21160;&#24577;&#32806;&#21512;&#19988;&#26041;&#24046;&#21487;&#20197;&#34987;&#33258;&#27965;&#35745;&#31639;&#12290;&#22312;&#20004;&#23618;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the dynamics of finite width effects in wide but finite feature learning neural networks. Unlike many prior analyses, our results, while perturbative in width, are non-perturbative in the strength of feature learning. Starting from a dynamical mean field theory (DMFT) description of infinite width deep neural network kernel and prediction dynamics, we provide a characterization of the $\mathcal{O}(1/\sqrt{\text{width}})$ fluctuations of the DMFT order parameters over random initialization of the network weights. In the lazy limit of network training, all kernels are random but static in time and the prediction variance has a universal form. However, in the rich, feature learning regime, the fluctuations of the kernels and predictions are dynamically coupled with variance that can be computed self-consistently. In two layer networks, we show how feature learning can dynamically reduce the variance of the final NTK and final network predictions. We also show how initialization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#23383;&#20856;&#23398;&#20064;&#20013;&#20004;&#31181;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#22312;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#33021;&#22815;&#20197;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#20110;&#29983;&#25104;&#30340;&#23383;&#20856;&#65292;&#19988;&#21487;&#36866;&#29992;&#20110;&#38750;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2304.01768</link><description>&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#20013;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of alternating minimisation algorithms for dictionary learning. (arXiv:2304.01768v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#23383;&#20856;&#23398;&#20064;&#20013;&#20004;&#31181;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#22312;&#33391;&#22909;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#33021;&#22815;&#20197;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#20110;&#29983;&#25104;&#30340;&#23383;&#20856;&#65292;&#19988;&#21487;&#36866;&#29992;&#20110;&#38750;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23548;&#20986;&#20102;&#38024;&#23545;&#23383;&#20856;&#23398;&#20064;&#20004;&#31181;&#27969;&#34892;&#30340;&#20132;&#26367;&#26497;&#23567;&#21270;&#31639;&#27861; - &#26368;&#20248;&#26041;&#21521;&#27861;&#65288;MOD&#65289;&#21644;&#22312;&#32447;&#23383;&#20856;&#23398;&#20064;&#65288;ODL&#65289;&#30340;&#25910;&#25947;&#24615;&#36275;&#22815;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#33391;&#22909;&#65292;&#21363;&#36317;&#31163;&#29983;&#25104;&#30340;&#23383;&#20856;&#19981;&#36229;&#36807;$1/\log(K)$&#25110;&#20855;&#26377;&#19968;&#23450;&#30340;&#32467;&#26500;&#65292;&#30830;&#20445;&#21021;&#22987;&#20540;&#20013;&#30340;&#27599;&#20010;&#20803;&#32032;&#21482;&#25351;&#21521;&#19968;&#20010;&#29983;&#25104;&#20803;&#65292;&#20004;&#31181;&#31639;&#27861;&#23558;&#20197;&#20960;&#20309;&#25910;&#25947;&#36895;&#29575;&#25910;&#25947;&#20110;&#29983;&#25104;&#30340;&#23383;&#20856;&#12290;&#36825;&#22312;&#20855;&#26377;&#38750;&#22343;&#21248;&#20998;&#24067;&#30340;&#25968;&#25454;&#27169;&#22411;&#19978;&#20063;&#33021;&#23454;&#29616;&#65292;&#35813;&#27169;&#22411;&#20013;&#31232;&#30095;&#31995;&#25968;&#30340;&#25903;&#25745;&#38598;&#30340;&#20986;&#29616;&#39057;&#29575;&#21487;&#20197;&#21464;&#21270;&#24456;&#22823;&#65292;&#20174;&#32780;&#26356;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we derive sufficient conditions for the convergence of two popular alternating minimisation algorithms for dictionary learning - the Method of Optimal Directions (MOD) and Online Dictionary Learning (ODL), which can also be thought of as approximative K-SVD. We show that given a well-behaved initialisation that is either within distance at most $1/\log(K)$ to the generating dictionary or has a special structure ensuring that each element of the initialisation only points to one generating element, both algorithms will converge with geometric convergence rate to the generating dictionary. This is done even for data models with non-uniform distributions on the supports of the sparse coefficients. These allow the appearance frequency of the dictionary elements to vary heavily and thus model real data more closely.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;</title><link>http://arxiv.org/abs/2304.00195</link><description>&lt;p&gt;
&#25277;&#35937;&#22120;&#65306;&#22522;&#20110;Transformer&#30340;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
Abstractors: Transformer Modules for Symbolic Message Passing and Relational Reasoning. (arXiv:2304.00195v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00195
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#20851;&#31995;&#23398;&#20064;&#36716;&#21270;&#20026;Transformer&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
A framework is proposed that casts relational learning in terms of transformers, implementing binding between sensory states and abstract states with relational cross attention mechanisms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.10472</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#23454;&#29992;&#21305;&#37197;&#26799;&#24230;&#26041;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. (arXiv:2303.10472v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#30340;&#26799;&#24230;&#26041;&#24046;&#26159;&#24314;&#31435;&#20854;&#25910;&#25947;&#24615;&#21644;&#31639;&#27861;&#25913;&#36827;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#23578;&#26410;&#34920;&#26126;BBVI&#30340;&#26799;&#24230;&#26041;&#24046;&#28385;&#36275;&#29992;&#20110;&#30740;&#31350;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25910;&#25947;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#24212;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#26102;&#65292;BBVI&#28385;&#36275;&#19982;SGD&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;ABC&#26465;&#20214;&#30456;&#21305;&#37197;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#24179;&#22343;&#22330;&#21442;&#25968;&#21270;&#30340;&#26041;&#24046;&#20855;&#26377;&#32463;&#36807;&#39564;&#35777;&#30340;&#20248;&#36234;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the $ABC$ condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22810;&#20803;Edgeworth&#23637;&#24320;&#65292;&#25552;&#20986;&#29992;&#24494;&#20998;&#24418;&#24335;&#34920;&#31034;&#38750;&#39640;&#26031;&#20998;&#24067;&#65292;&#26469;&#27169;&#25311;&#26377;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#39640;&#26031;&#21518;&#39564;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2303.02859</link><description>&lt;p&gt;
&#26377;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference with finitely wide neural networks. (arXiv:2303.02859v2 [cond-mat.dis-nn] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22810;&#20803;Edgeworth&#23637;&#24320;&#65292;&#25552;&#20986;&#29992;&#24494;&#20998;&#24418;&#24335;&#34920;&#31034;&#38750;&#39640;&#26031;&#20998;&#24067;&#65292;&#26469;&#27169;&#25311;&#26377;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#39640;&#26031;&#21518;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#23558;&#23485;&#24230;&#24456;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#35270;&#20026;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#30340;&#39640;&#26031;&#36807;&#31243;&#26102;&#65292;&#35299;&#26512;&#25512;&#26029;&#65292;&#20363;&#22914;&#39044;&#27979;&#20998;&#24067;&#20197;&#38381;&#21512;&#24418;&#24335;&#32473;&#20986;&#65292;&#21487;&#33021;&#26159;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#20248;&#21183;&#12290;&#20294;&#26159;&#65292;&#23454;&#38469;&#30340;&#23485;&#24230;&#26159;&#26377;&#38480;&#30340;&#65292;&#24182;&#19988;&#22312;&#35813;&#23485;&#24230;&#19979;&#65292;&#19968;&#20123;&#38543;&#26426;&#21464;&#37327;&#30340;&#36793;&#38469;&#21270;&#30340;&#39640;&#26031;&#20551;&#35774;&#21487;&#33021;&#20986;&#29616;&#20559;&#24046;&#12290;&#22522;&#20110;&#22810;&#20803;Edgeworth&#23637;&#24320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#24494;&#20998;&#24418;&#24335;&#34920;&#31034;&#30340;&#38750;&#39640;&#26031;&#20998;&#24067;&#65292;&#26469;&#23545;&#26469;&#33258;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#38480;&#36755;&#20986;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#25512;&#23548;&#20986;&#30456;&#24212;&#30340;&#36793;&#38469;&#21644;&#26465;&#20214;&#23646;&#24615;&#65292;&#20174;&#32780;&#33021;&#22815;&#22312;&#36125;&#21494;&#26031;&#22238;&#24402;&#20219;&#21153;&#20013;&#25512;&#23548;&#20986;&#38750;&#39640;&#26031;&#21518;&#39564;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#22312;&#29942;&#39048;&#24335;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#36890;&#36807;&#36793;&#32536;&#26680;&#25506;&#31350;&#20102;&#28145;&#39640;&#26031;&#36807;&#31243;&#30340;&#38750;&#39640;&#26031;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The analytic inference, e.g. predictive distribution being in closed form, may be an appealing benefit for machine learning practitioners when they treat wide neural networks as Gaussian process in Bayesian setting. The realistic widths, however, are finite and cause weak deviation from the Gaussianity under which partial marginalization of random variables in a model is straightforward. On the basis of multivariate Edgeworth expansion, we propose a non-Gaussian distribution in differential form to model a finite set of outputs from a random neural network, and derive the corresponding marginal and conditional properties. Thus, we are able to derive the non-Gaussian posterior distribution in Bayesian regression task. In addition, in the bottlenecked deep neural networks, a weight space representation of deep Gaussian process, the non-Gaussianity is investigated through the marginal kernel.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24187;&#24819;&#23545;&#25239;&#25511;&#21046;&#30340;HAMBO&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#20986;&#26377;&#25928;&#30340;&#31574;&#30053;&#34920;&#29616;&#19979;&#38480;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.01076</link><description>&lt;p&gt;
&#22522;&#20110;&#24187;&#24819;&#23545;&#25239;&#25511;&#21046;&#30340;&#20445;&#23432;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Hallucinated Adversarial Control for Conservative Offline Policy Evaluation. (arXiv:2303.01076v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24187;&#24819;&#23545;&#25239;&#25511;&#21046;&#30340;HAMBO&#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#20986;&#26377;&#25928;&#30340;&#31574;&#30053;&#34920;&#29616;&#19979;&#38480;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20445;&#23432;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#38382;&#39064;&#65292;&#23545;&#20110;&#32473;&#23450;&#20854;&#20182;&#20195;&#29702;&#25910;&#38598;&#30340;&#31163;&#32447;&#29615;&#22659;&#20132;&#20114;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#26088;&#22312;&#33719;&#24471;&#19968;&#20010;&#20851;&#20110;&#31574;&#30053;&#24615;&#33021;&#30340;(&#32039;)&#19979;&#38480;&#20272;&#35745;&#12290;&#36825;&#22312;&#20915;&#23450;&#26159;&#21542;&#37096;&#32626;&#26576;&#20010;&#31574;&#30053;&#28385;&#36275;&#26368;&#23567;&#24615;&#33021;/&#23433;&#20840;&#26631;&#20934;&#20043;&#21069;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;HAMBO&#65292;&#23427;&#24314;&#31435;&#22312;&#19968;&#20010;&#23398;&#20064;&#21040;&#30340;&#20256;&#36882;&#21160;&#24577;&#30340;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#27169;&#22411;&#20043;&#19978;&#12290;&#20026;&#20102;&#24418;&#25104;&#31574;&#30053;&#32489;&#25928;&#30340;&#20445;&#23432;&#20272;&#35745;&#65292;HAMBO&#20250;&#24187;&#24819;&#31574;&#30053;&#21487;&#33021;&#37319;&#21462;&#30340;&#26368;&#22351;&#36712;&#36857;&#65292;&#19988;&#35813;&#36712;&#36857;&#22312;&#27169;&#22411;&#30340;&#35748;&#30693;&#32622;&#20449;&#21306;&#38388;&#20869;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;COPE&#20272;&#35745;&#26159;&#26377;&#25928;&#30340;&#19979;&#38480;&#65292;&#24182;&#22312;&#27491;&#21017;&#24615;&#26465;&#20214;&#19979;&#23637;&#31034;&#20854;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;&#39044;&#26399;&#22238;&#25253;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#22522;&#20110;Bayesian&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#25193;&#23637;&#21464;&#20307;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#23427;&#20204;&#20135;&#29983;&#21487;&#38752;&#19988;&#32039;&#23494;&#30340;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy's performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy's performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models' epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in var
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#20351;&#29992;&#36125;&#21494;&#26031;&#20869;&#26680;&#24352;&#37327;&#20998;&#35299;&#20316;&#20026;&#20195;&#29702;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#23398;&#20064;&#20855;&#26377;&#22797;&#26434;&#29305;&#24449;&#30340;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2302.14510</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20869;&#26680;&#24352;&#37327;&#20998;&#35299;&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26367;&#20195;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Bayesian Kernelized Tensor Factorization as Surrogate for Bayesian Optimization. (arXiv:2302.14510v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#20351;&#29992;&#36125;&#21494;&#26031;&#20869;&#26680;&#24352;&#37327;&#20998;&#35299;&#20316;&#20026;&#20195;&#29702;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20197;&#23398;&#20064;&#20855;&#26377;&#22797;&#26434;&#29305;&#24449;&#30340;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20316;&#20026;&#20027;&#35201;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#22823;&#22810;&#20351;&#29992;&#31616;&#21333;&#30340;&#22266;&#23450;&#21644;&#21487;&#20998;&#31163;&#30340;&#20869;&#26680;&#20989;&#25968;&#65292;&#20363;&#22914;&#20855;&#26377;&#33258;&#21160;&#30456;&#20851;&#20915;&#23450;&#65288;SE-ARD&#65289;&#30340;&#24179;&#26041;&#25351;&#25968;&#20869;&#26680;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#31616;&#21333;&#20869;&#26680;&#35268;&#26684;&#35828;&#26126;&#19981;&#36275;&#20197;&#23398;&#20064;&#20855;&#26377;&#22797;&#26434;&#29305;&#24449;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#38750;&#23450;&#24120;&#65292;&#38750;&#21487;&#20998;&#31163;&#21644;&#22810;&#23792;&#12290;&#21363;&#20351;&#22312;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;&#20351;&#29992;&#23616;&#37096;GP&#36924;&#36817;&#36825;&#26679;&#30340;&#20989;&#25968;&#20063;&#38656;&#35201;&#22823;&#37327;&#26679;&#26412;&#65292;&#26356;&#19981;&#29992;&#35828;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#20102;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#36125;&#21494;&#26031;&#20869;&#26680;&#24352;&#37327;&#20998;&#35299;&#65288;BKTF&#65289;&#20316;&#20026;$ D $&#32500;&#31515;&#21345;&#23572;&#20056;&#31215;&#31354;&#38388;&#20013; BO &#30340;&#26032;&#20195;&#29702;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#20840;&#36125;&#21494;&#26031;&#20302;&#31209;&#24352;&#37327; CP &#20998;&#35299;&#36817;&#20284;&#22522;&#30784;&#30340; $ D $ &#32500;&#23454;&#20307;&#65292;&#22312;&#20854;&#20013;&#25105;&#20204;&#20026;&#27599;&#20010;&#32500;&#24230;&#30340;&#28508;&#22312;&#22522;&#30784;&#20989;&#25968;&#25918;&#32622; GP &#20808;&#39564;&#65292;&#20197;&#32534;&#30721;&#23616;&#37096;&#19968;&#33268;&#24615;&#21644;&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) primarily uses Gaussian processes (GP) as the key surrogate model, mostly with a simple stationary and separable kernel function such as the squared-exponential kernel with automatic relevance determination (SE-ARD). However, such simple kernel specifications are deficient in learning functions with complex features, such as being nonstationary, nonseparable, and multimodal. Approximating such functions using a local GP, even in a low-dimensional space, requires a large number of samples, not to mention in a high-dimensional setting. In this paper, we propose to use Bayesian Kernelized Tensor Factorization (BKTF) -- as a new surrogate model -- for BO in a $D$-dimensional Cartesian product space. Our key idea is to approximate the underlying $D$-dimensional solid with a fully Bayesian low-rank tensor CP decomposition, in which we place GP priors on the latent basis functions for each dimension to encode local consistency and smoothness. With this formulation, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#20102;&#25968;&#25454;&#20998;&#25968;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#26159;&#19968;&#20010;&#38789;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#30340;DPM&#65292;&#26377;&#25928;&#20943;&#23567;&#27169;&#22411;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#22686;&#21152;&#27169;&#22411;&#20284;&#28982;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33324;&#26657;&#20934;&#25351;&#21335;&#12290;</title><link>http://arxiv.org/abs/2302.10688</link><description>&lt;p&gt;
&#20851;&#20110;&#26657;&#20934;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
On Calibrating Diffusion Probabilistic Models. (arXiv:2302.10688v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10688
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#20102;&#25968;&#25454;&#20998;&#25968;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#26159;&#19968;&#20010;&#38789;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#30340;DPM&#65292;&#26377;&#25928;&#20943;&#23567;&#27169;&#22411;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#22686;&#21152;&#27169;&#22411;&#20284;&#28982;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33324;&#26657;&#20934;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPM&#65289;&#22312;&#21508;&#31181;&#29983;&#25104;&#24615;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;DPM&#26694;&#26550;&#21253;&#25324;&#19968;&#20010;&#36880;&#28176;&#25193;&#25955;&#25968;&#25454;&#20998;&#24067;&#30340;&#27491;&#21521;&#36807;&#31243;&#21644;&#19968;&#20010;&#20174;&#26102;&#38388;&#30456;&#20851;&#25968;&#25454;&#20998;&#25968;&#20013;&#24674;&#22797;&#25968;&#25454;&#20998;&#24067;&#30340;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#12290;&#26412;&#25991;&#35266;&#23519;&#21040;&#25968;&#25454;&#20998;&#25968;&#30340;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#26159;&#19968;&#20010;&#38789;&#65292;&#20174;&#20013;&#21487;&#20197;&#23548;&#20986;&#25968;&#25454;&#20998;&#25968;&#30340;&#38598;&#20013;&#30028;&#21644;&#38543;&#26426;&#20572;&#27490;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#30340;DPM&#65292;&#20197;&#20943;&#23567;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24182;&#22240;&#27492;&#22686;&#21152;&#27169;&#22411;&#20284;&#28982;&#30340;&#19979;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21508;&#31181;&#27169;&#22411;&#21442;&#25968;&#21270;&#19979;&#30340;&#19968;&#33324;&#26657;&#20934;&#25351;&#21335;&#12290;&#25105;&#20204;&#30340;&#26657;&#20934;&#26041;&#27861;&#20165;&#25191;&#34892;&#19968;&#27425;&#65292;&#24182;&#19988;&#21487;&#20197;&#37325;&#22797;&#20351;&#29992;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#25105;&#20204;&#30340;&#25552;&#35758;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#20301;&#20110;https://github.com/thudzj/Cal&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, diffusion probabilistic models (DPMs) have achieved promising results in diverse generative tasks. A typical DPM framework includes a forward process that gradually diffuses the data distribution and a reverse process that recovers the data distribution from time-dependent data scores. In this work, we observe that the stochastic reverse process of data scores is a martingale, from which concentration bounds and the optional stopping theorem for data scores can be derived. Then, we discover a simple way for calibrating an arbitrary pretrained DPM, with which the score matching loss can be reduced and the lower bounds of model likelihood can consequently be increased. We provide general calibration guidelines under various model parametrizations. Our calibration method is performed only once and the resulting models can be used repeatedly for sampling. We conduct experiments on multiple datasets to empirically validate our proposal. Our code is at https://github.com/thudzj/Cal
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20998;&#26512;&#22240;&#23376;&#21270;&#39640;&#26031;&#36924;&#36817;&#22312;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#35813;&#26041;&#27861;&#20302;&#20272;&#25152;&#36924;&#36817;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#29992;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36924;&#36817;&#20855;&#26377;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#26102;&#65292;&#25152;&#25512;&#26029;&#30340;&#39640;&#26031;&#24635;&#26159;&#20302;&#20272;&#20102;&#21407;&#22987;&#39640;&#26031;&#30340;&#20998;&#37327;&#26041;&#24046;&#21644;&#29109;&#12290;</title><link>http://arxiv.org/abs/2302.09163</link><description>&lt;p&gt;
&#25910;&#32553;-&#35299;&#32806;&#24179;&#34913;&#65306;&#20998;&#26512;&#22240;&#23376;&#21270;&#39640;&#26031;&#36924;&#36817;&#22312;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Shrinkage-Delinkage Trade-off: An Analysis of Factorized Gaussian Approximations for Variational Inference. (arXiv:2302.09163v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09163
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20998;&#26512;&#22240;&#23376;&#21270;&#39640;&#26031;&#36924;&#36817;&#22312;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#35813;&#26041;&#27861;&#20302;&#20272;&#25152;&#36924;&#36817;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#29992;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#36924;&#36817;&#20855;&#26377;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#26102;&#65292;&#25152;&#25512;&#26029;&#30340;&#39640;&#26031;&#24635;&#26159;&#20302;&#20272;&#20102;&#21407;&#22987;&#39640;&#26031;&#30340;&#20998;&#37327;&#26041;&#24046;&#21644;&#29109;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#20351;&#29992;&#22240;&#23376;&#21270;&#36924;&#36817;&#26102;&#65292;&#23427;&#20204;&#24448;&#24448;&#20250;&#20302;&#20272;&#23427;&#20204;&#29992;&#26469;&#36924;&#36817;&#30340;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#22914;&#20197;&#21508;&#31181;&#26041;&#24335;&#27979;&#37327;&#12290;&#25105;&#20204;&#32771;&#34385;&#20004;&#31181;&#34913;&#37327;VI&#19981;&#30830;&#23450;&#24615;&#20111;&#25439;&#30340;&#27969;&#34892;&#26041;&#27861;&#65306;&#65288;i&#65289;&#23427;&#20302;&#20272;&#20998;&#37327;&#26041;&#24046;&#30340;&#31243;&#24230;&#65292;&#65288;ii&#65289;&#23427;&#20302;&#20272;&#29109;&#30340;&#31243;&#24230;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#20123;&#24433;&#21709;&#20197;&#21450;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20449;&#24687;&#20016;&#23500;&#30340;&#35774;&#32622;&#65292;&#21487;&#20197;&#22312;&#20854;&#20013;&#26126;&#30830;&#65288;&#21644;&#20248;&#38597;&#22320;&#65289;&#20998;&#26512;&#36825;&#20123;&#24433;&#21709;&#65306;&#20351;&#29992;&#23545;&#35282;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#65288;$q$&#65289;&#36924;&#36817;&#20855;&#26377;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#65288;$p$&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$q$&#24635;&#26159;&#20302;&#20272;&#20102;$p$&#30340;&#20998;&#37327;&#26041;&#24046;&#21644;&#29109;&#65292;&#23613;&#31649;&#19981;&#19968;&#23450;&#20302;&#20272;&#30340;&#31243;&#24230;&#30456;&#21516;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;$q$&#30340;&#29109;&#30001;&#20004;&#20010;&#30456;&#20114;&#31454;&#20105;&#30340;&#22240;&#32032;&#30340;&#24179;&#34913;&#20915;&#23450;&#65306;&#23427;&#30340;&#20998;&#37327;&#26041;&#24046;&#25910;&#32553;&#20250;&#38477;&#20302;&#23427;&#30340;&#29109;&#12290;
&lt;/p&gt;
&lt;p&gt;
When factorized approximations are used for variational inference (VI), they tend to underestimate the uncertainty -- as measured in various ways -- of the distributions they are meant to approximate. We consider two popular ways to measure the uncertainty deficit of VI: (i) the degree to which it underestimates the componentwise variance, and (ii) the degree to which it underestimates the entropy. To better understand these effects, and the relationship between them, we examine an informative setting where they can be explicitly (and elegantly) analyzed: the approximation of a Gaussian,~$p$, with a dense covariance matrix, by a Gaussian,~$q$, with a diagonal covariance matrix. We prove that $q$ always underestimates both the componentwise variance and the entropy of $p$, \textit{though not necessarily to the same degree}. Moreover we demonstrate that the entropy of $q$ is determined by the trade-off of two competing forces: it is decreased by the shrinkage of its componentwise varianc
&lt;/p&gt;</description></item><item><title>&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#20026;Wasserstein GAN&#21644;Energy-Based GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20986;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;</title><link>http://arxiv.org/abs/2302.08942</link><description>&lt;p&gt;
&#38754;&#21521;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian Generalization Bounds for Adversarial Generative Models. (arXiv:2302.08942v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08942
&lt;/p&gt;
&lt;p&gt;
&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#27867;&#21270;&#30028;&#65292;&#20026;Wasserstein GAN&#21644;Energy-Based GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20986;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;PAC-Bayesian&#29702;&#35770;&#25193;&#23637;&#21040;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#20026;&#22522;&#20110;Wasserstein&#36317;&#31163;&#21644;&#24635;&#21464;&#24046;&#36317;&#31163;&#30340;&#27169;&#22411;&#24320;&#21457;&#20102;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#31532;&#19968;&#20010;&#20851;&#20110;Wasserstein&#36317;&#31163;&#30340;&#32467;&#26524;&#20551;&#35774;&#23454;&#20363;&#31354;&#38388;&#26159;&#26377;&#30028;&#30340;&#65292;&#32780;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#32467;&#26524;&#21033;&#29992;&#20102;&#38477;&#32500;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#33258;&#28982;&#36866;&#29992;&#20110;Wasserstein GAN&#21644;Energy-Based GAN&#65292;&#32780;&#25105;&#20204;&#30340;&#30028;&#38480;&#20026;&#36825;&#20004;&#31181;GAN&#25552;&#20379;&#20102;&#26032;&#30340;&#35757;&#32451;&#30446;&#26631;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#24037;&#20316;&#20027;&#35201;&#26159;&#29702;&#35770;&#24615;&#30340;&#65292;&#20294;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;Wasserstein GAN&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#38750;&#34394;&#31354;&#27867;&#21270;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;I$^2$SB&#65292;&#30452;&#25509;&#23398;&#20064;&#20004;&#20010;&#32473;&#23450;&#20998;&#24067;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#12290;&#36890;&#36807;&#36793;&#30028;&#23545;&#27714;&#35299;&#30340;&#26041;&#27861;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#27169;&#25311;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#26694;&#26550;&#65292;&#22312;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#20248;&#20110;&#26631;&#20934;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#26356;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2302.05872</link><description>&lt;p&gt;
I$^2$SB&#65306;&#22270;&#20687;&#21040;&#22270;&#20687;&#30340;Schr\"odinger&#26725;
&lt;/p&gt;
&lt;p&gt;
I$^2$SB: Image-to-Image Schr\"odinger Bridge. (arXiv:2302.05872v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05872
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;I$^2$SB&#65292;&#30452;&#25509;&#23398;&#20064;&#20004;&#20010;&#32473;&#23450;&#20998;&#24067;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#12290;&#36890;&#36807;&#36793;&#30028;&#23545;&#27714;&#35299;&#30340;&#26041;&#27861;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#27169;&#25311;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#26694;&#26550;&#65292;&#22312;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#20248;&#20110;&#26631;&#20934;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#26356;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#21363;&#22270;&#20687;&#21040;&#22270;&#20687;&#30340;Schr\"odinger&#26725;&#65288;I$^2$SB&#65289;&#65292;&#30452;&#25509;&#23398;&#20064;&#20004;&#20010;&#32473;&#23450;&#20998;&#24067;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#12290;&#36825;&#20123;&#25193;&#25955;&#26725;&#23545;&#20110;&#22270;&#20687;&#24674;&#22797;&#29305;&#21035;&#26377;&#29992;&#65292;&#22240;&#20026;&#36864;&#21270;&#22270;&#20687;&#26159;&#37325;&#26500;&#28165;&#26224;&#22270;&#20687;&#30340;&#32467;&#26500;&#20449;&#24687;&#20808;&#39564;&#12290; I$^2$SB&#23646;&#20110;&#19968;&#31867;&#21487;&#22788;&#29702;&#30340;Schr\"odinger&#26725;&#27169;&#22411;&#65292;&#23427;&#26159;&#24471;&#20998;&#27169;&#22411;&#30340;&#38750;&#32447;&#24615;&#25193;&#23637;&#65292;&#20854;&#36793;&#30028;&#23545;&#30340;&#36793;&#32536;&#20998;&#24067;&#21487;&#20197;&#22312;&#35299;&#26512;&#19978;&#35745;&#31639;&#12290;&#36825;&#31181;&#36890;&#36807;&#36793;&#30028;&#23545;&#27714;&#35299;&#30340;&#26041;&#27861;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#27169;&#25311;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#26694;&#26550;&#65292;&#36827;&#32780;&#37319;&#29992;&#22312;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#20013;&#20351;&#29992;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;ImageNet 256x256&#19978;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;I$^2$SB&#22312;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20462;&#22797;&#65292;&#36229;&#20998;&#36776;&#29575;&#65292;&#21435;&#27169;&#31946;&#21644;JPEG&#24674;&#22797;&#65292;&#24182;&#34920;&#26126;I$^2$SB&#36229;&#36807;&#20102;&#26631;&#20934;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#20855;&#26377;&#26356;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Image-to-Image Schr\"odinger Bridge (I$^2$SB), a new class of conditional diffusion models that directly learn the nonlinear diffusion processes between two given distributions. These diffusion bridges are particularly useful for image restoration, as the degraded images are structurally informative priors for reconstructing the clean images. I$^2$SB belongs to a tractable class of Schr\"odinger bridge, the nonlinear extension to score-based models, whose marginal distributions can be computed analytically given boundary pairs. This results in a simulation-free framework for nonlinear diffusions, where the I$^2$SB training becomes scalable by adopting practical techniques used in standard diffusion models. We validate I$^2$SB in solving various image restoration tasks, including inpainting, super-resolution, deblurring, and JPEG restoration on ImageNet 256x256 and show that I$^2$SB surpasses standard conditional diffusion models with more interpretable generative processes. 
&lt;/p&gt;</description></item><item><title>AGNES&#26159;&#19968;&#31181;&#33021;&#22312;&#24179;&#28369;&#20984;&#20248;&#21270;&#20219;&#21153;&#20013;&#23454;&#29616;&#21152;&#36895;&#30340;&#31639;&#27861;&#65292;&#21363;&#20351;&#26799;&#24230;&#20272;&#35745;&#30340;&#20449;&#22122;&#27604;&#24456;&#23567;&#65292;&#23427;&#20063;&#33021;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#25928;&#26524;&#26174;&#33879;&#20248;&#20110;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.05515</link><description>&lt;p&gt;
&#23454;&#29616;&#21152;&#36895;&#23613;&#31649;&#26799;&#24230;&#38750;&#24120;&#22024;&#26434;&#12290;
&lt;/p&gt;
&lt;p&gt;
Achieving acceleration despite very noisy gradients. (arXiv:2302.05515v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05515
&lt;/p&gt;
&lt;p&gt;
AGNES&#26159;&#19968;&#31181;&#33021;&#22312;&#24179;&#28369;&#20984;&#20248;&#21270;&#20219;&#21153;&#20013;&#23454;&#29616;&#21152;&#36895;&#30340;&#31639;&#27861;&#65292;&#21363;&#20351;&#26799;&#24230;&#20272;&#35745;&#30340;&#20449;&#22122;&#27604;&#24456;&#23567;&#65292;&#23427;&#20063;&#33021;&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#25928;&#26524;&#26174;&#33879;&#20248;&#20110;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Nesterov&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#19968;&#33324;&#21270;&#12290;&#22914;&#26524;&#22122;&#22768;&#30340;&#24378;&#24230;&#19982;&#26799;&#24230;&#30340;&#22823;&#23567;&#25104;&#27604;&#20363;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;AGNES&#65289;&#21487;&#20197;&#35777;&#26126;&#22312;&#20855;&#26377;&#22024;&#26434;&#26799;&#24230;&#20272;&#35745;&#30340;&#24179;&#28369;&#20984;&#20248;&#21270;&#20219;&#21153;&#20013;&#23454;&#29616;&#21152;&#36895;&#12290;&#22914;&#26524;&#24120;&#25968;&#27604;&#20363;&#36229;&#36807;&#19968;&#65292;Nesterov&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#22312;&#36825;&#31181;&#22122;&#22768;&#27169;&#22411;&#19979;&#19981;&#20250;&#25910;&#25947;&#12290;AGNES&#33021;&#20462;&#22797;&#36825;&#31181;&#19981;&#36275;&#65292;&#24182;&#19988;&#21487;&#20197;&#35777;&#26126;&#23427;&#30340;&#25910;&#25947;&#36895;&#24230;&#21152;&#24555;&#65292;&#26080;&#35770;&#26799;&#24230;&#20272;&#35745;&#30340;&#20449;&#22122;&#27604;&#26377;&#22810;&#23567;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#26159;&#29992;&#20110;&#36229;&#21442;&#25968;&#36807;&#22810;&#30340;&#28145;&#24230;&#23398;&#20064;&#23567;&#25209;&#37327;&#26799;&#24230;&#30340;&#36866;&#24403;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;AGNES&#22312;CNN&#35757;&#32451;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a generalization of Nesterov's accelerated gradient descent algorithm. Our algorithm (AGNES) provably achieves acceleration for smooth convex minimization tasks with noisy gradient estimates if the noise intensity is proportional to the magnitude of the gradient. Nesterov's accelerated gradient descent does not converge under this noise model if the constant of proportionality exceeds one. AGNES fixes this deficiency and provably achieves an accelerated convergence rate no matter how small the signal to noise ratio in the gradient estimate. Empirically, we demonstrate that this is an appropriate model for mini-batch gradients in overparameterized deep learning. Finally, we show that AGNES outperforms stochastic gradient descent with momentum and Nesterov's method in the training of CNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40654;&#26364;&#27969;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#20960;&#20309;&#19978;&#35757;&#32451;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#65292;&#24182;&#22312;&#39640;&#32500;&#24230;&#25968;&#25454;&#19978;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.03660</link><description>&lt;p&gt;
&#19968;&#33324;&#20960;&#20309;&#19978;&#30340;&#40654;&#26364;&#27969;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Riemannian Flow Matching on General Geometries. (arXiv:2302.03660v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03660
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40654;&#26364;&#27969;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#20960;&#20309;&#19978;&#35757;&#32451;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#65292;&#24182;&#22312;&#39640;&#32500;&#24230;&#25968;&#25454;&#19978;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#40654;&#26364;&#27969;&#21305;&#37197;&#65288;RFM&#65289;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#27969;&#24418;&#19978;&#35757;&#32451;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#12290;&#29616;&#26377;&#30340;&#27969;&#24418;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#26114;&#36149;&#30340;&#27169;&#25311;&#65292;&#35201;&#20040;&#26080;&#27861;&#26412;&#36136;&#19978;&#25193;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#35201;&#20040;&#20351;&#29992;&#38480;&#21046;&#37327;&#30340;&#36817;&#20284;&#26469;&#20135;&#29983;&#26377;&#20559;&#30340;&#35757;&#32451;&#30446;&#26631;&#12290;&#40654;&#26364;&#27969;&#21305;&#37197;&#32469;&#36807;&#20102;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#27604;&#20197;&#21069;&#26041;&#27861;&#26356;&#22810;&#30340;&#20248;&#21183;&#65306;&#23427;&#22312;&#31616;&#21333;&#20960;&#20309;&#19978;&#26080;&#38656;&#27169;&#25311;&#65292;&#19981;&#38656;&#35201;&#25955;&#24230;&#35745;&#31639;&#65292;&#24182;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#20854;&#30446;&#26631;&#21521;&#37327;&#22330;&#12290; RFM&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#26500;&#24314;&#19968;&#20010;&#30456;&#23545;&#31616;&#21333;&#30340;&#21069;&#24230;&#37327;&#65292;&#20197;&#23450;&#20041;&#30446;&#26631;&#21521;&#37327;&#22330;&#65292;&#20854;&#20013;&#21253;&#25324;&#29616;&#26377;&#30340;&#27431;&#20960;&#37324;&#24471;&#24773;&#20917;&#12290;&#20026;&#20102;&#25193;&#23637;&#21040;&#19968;&#33324;&#20960;&#20309;&#65292;&#25105;&#20204;&#20381;&#38752;&#20351;&#29992;&#35889;&#20998;&#35299;&#26469;&#26377;&#25928;&#22320;&#21363;&#20852;&#35745;&#31639;&#21069;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#22312;3D&#32593;&#26684;&#21644;&#21452;&#26354;&#31354;&#38388;&#19978;&#35757;&#32451;&#26631;&#20934;&#21270;&#27969;&#26469;&#35777;&#26126;&#20854;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on real-world non-Euclidean datasets, and we demonstr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26131;&#21463;&#25915;&#20987;&#24615;&#65292;&#25581;&#31034;&#20102;&#26679;&#26412;&#25968;&#12289;&#38544;&#31169;&#32423;&#21035;&#12289;&#27169;&#22411;&#26550;&#26500;&#12289;&#19979;&#28216;&#25968;&#25454;&#38598;&#20197;&#21450;&#21487;&#23398;&#20064;&#21442;&#25968;&#23376;&#38598;&#31561;&#22240;&#32032;&#23545;&#20998;&#31867;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.01190</link><description>&lt;p&gt;
&#20851;&#20110;&#24046;&#20998;&#38544;&#31169;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#26041;&#27861;&#26377;&#25928;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Efficacy of Differentially Private Few-shot Image Classification. (arXiv:2302.01190v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01190
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#23569;&#26679;&#26412;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26131;&#21463;&#25915;&#20987;&#24615;&#65292;&#25581;&#31034;&#20102;&#26679;&#26412;&#25968;&#12289;&#38544;&#31169;&#32423;&#21035;&#12289;&#27169;&#22411;&#26550;&#26500;&#12289;&#19979;&#28216;&#25968;&#25454;&#38598;&#20197;&#21450;&#21487;&#23398;&#20064;&#21442;&#25968;&#23376;&#38598;&#31561;&#22240;&#32032;&#23545;&#20998;&#31867;&#25928;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#27169;&#22411;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#36825;&#20123;DP&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#25509;&#36817;&#26368;&#20339;&#30340;&#38750;&#31169;&#26377;&#27169;&#22411;&#12290;&#36825;&#20123;DP&#27169;&#22411;&#36890;&#24120;&#22312;&#22823;&#35268;&#27169;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#39044;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#30456;&#23545;&#22823;&#19988;&#19982;&#39044;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#30456;&#20284;&#30340;&#31169;&#26377;&#19979;&#28216;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#21253;&#25324;&#20010;&#24615;&#21270;&#21644;&#32852;&#21512;&#23398;&#20064;&#65292;&#37325;&#35201;&#30340;&#26159;&#22312;&#23569;&#26679;&#26412;&#24773;&#20917;&#19979;&#33391;&#22909;&#22320;&#34920;&#29616;&#65288;i.e. &#33719;&#21462;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#21487;&#33021;&#26377;&#38382;&#39064;&#65289;&#65292;&#19988;&#33021;&#22815;&#22312;&#21508;&#31181;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#65288;&#21363;&#29992;&#20110;&#21508;&#31181;&#19987;&#19994;&#35774;&#32622;&#65289;&#36827;&#34892;&#33391;&#22909;&#30340;&#20998;&#31867;&#12290;&#20026;&#20102;&#20102;&#35299;&#23569;&#26679;&#26412;DP&#20309;&#26102;&#26377;&#25928;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#35814;&#23613;&#30340;&#23454;&#39564;&#65292;&#25581;&#31034;&#20102;&#27599;&#31867;&#26679;&#26412;&#25968;&#12289;&#38544;&#31169;&#32423;&#21035;&#12289;&#27169;&#22411;&#26550;&#26500;&#12289;&#19979;&#28216;&#25968;&#25454;&#38598;&#20197;&#21450;&#21487;&#23398;&#20064;&#21442;&#25968;&#23376;&#38598;&#31561;&#23545;&#23569;&#26679;&#26412;DP&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#20934;&#30830;&#24615;&#21644;&#26131;&#21463;&#25915;&#20987;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been significant recent progress in training differentially private (DP) models which achieve accuracy that approaches the best non-private models. These DP models are typically pretrained on large public datasets and then fine-tuned on private downstream datasets that are relatively large and similar in distribution to the pretraining data. However, in many applications including personalization and federated learning, it is crucial to perform well (i) in the few-shot setting, as obtaining large amounts of labeled data may be problematic; and (ii) on datasets from a wide variety of domains for use in various specialist settings. To understand under which conditions few-shot DP can be effective, we perform an exhaustive set of experiments that reveals how the accuracy and vulnerability to attack of few-shot DP image classification models are affected as the number of shots per class, privacy level, model architecture, downstream dataset, and subset of learnable parameters in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#39640;&#33021;&#29289;&#29702;&#20107;&#20214;&#65292;&#21487;&#29992;&#20110;&#21442;&#25968;&#21270;&#30340;&#20107;&#20214;&#29983;&#25104;&#65292;&#24322;&#24120;&#20449;&#21495;&#25506;&#27979;&#20197;&#21450;&#31890;&#23376;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2302.00695</link><description>&lt;p&gt;
&#22810;&#21151;&#33021;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#22312;&#39640;&#33021;&#29289;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Versatile Energy-Based Probabilistic Models for High Energy Physics. (arXiv:2302.00695v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#39640;&#33021;&#29289;&#29702;&#20107;&#20214;&#65292;&#21487;&#29992;&#20110;&#21442;&#25968;&#21270;&#30340;&#20107;&#20214;&#29983;&#25104;&#65292;&#24322;&#24120;&#20449;&#21495;&#25506;&#27979;&#20197;&#21450;&#31890;&#23376;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#19968;&#31181;&#32463;&#20856;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#20855;&#26377;&#33021;&#37327;&#20989;&#25968;&#24418;&#24335;&#28789;&#27963;&#24615;&#30340;&#22825;&#28982;&#20248;&#21183;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#24314;&#27169;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#19982;&#36825;&#20123;&#36827;&#23637;&#19968;&#33268;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#26469;&#33258;&#22823;&#22411;&#24378;&#23376;&#23545;&#25758;&#26426;&#30340;&#39640;&#33021;&#29289;&#29702;&#20107;&#20214;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#19968;&#20010;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#25551;&#36848;&#20102;&#26356;&#39640;&#38454;&#30340;&#31890;&#23376;&#38388;&#30456;&#20114;&#20316;&#29992;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#32534;&#30721;&#20307;&#31995;&#32467;&#26500;&#21644;&#38544;&#24335;&#29983;&#25104;&#12290;&#22312;&#24212;&#29992;&#26041;&#38754;&#65292;&#23427;&#21487;&#20197;&#20316;&#20026;&#24378;&#22823;&#30340;&#21442;&#25968;&#21270;&#20107;&#20214;&#29983;&#25104;&#22120;&#29992;&#20110;&#29289;&#29702;&#20223;&#30495;&#65292;&#19968;&#31181;&#27867;&#29992;&#30340;&#26080;&#20551;&#35774;&#20851;&#32852;&#30340;&#24322;&#24120;&#20449;&#21495;&#25506;&#27979;&#22120;&#65292;&#20197;&#21450;&#29992;&#20110;&#31890;&#23376;&#35782;&#21035;&#30340;&#22686;&#24378;&#20107;&#20214;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a classical generative modeling approach, energy-based models have the natural advantage of flexibility in the form of the energy function. Recently, energy-based models have achieved great success in modeling high-dimensional data in computer vision and natural language processing. In line with these advancements, we build a multi-purpose energy-based probabilistic model for High Energy Physics events at the Large Hadron Collider. This framework builds on a powerful generative model and describes higher-order inter-particle interactions.It suits different encoding architectures and builds on implicit generation. As for applicational aspects, it can serve as a powerful parameterized event generator for physics simulation, a generic anomalous signal detector free from spurious correlations, and an augmented event classifier for particle identification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#38544;&#24335;&#27491;&#21017;&#21270;&#21487;&#23545;&#20110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#20855;&#26377;&#20419;&#36827;&#20316;&#29992;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#21442;&#25968;&#21270;&#24418;&#24335;&#65292;&#32467;&#21512;&#20102;$\ell_1$&#21644;$\ell_2$&#20869;&#25554;&#22120;&#30340;&#20248;&#28857;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#21487;&#24471;&#21040;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#27979;&#35797;&#25439;&#22833;&#30340;&#20869;&#25554;&#22120;&#12290;</title><link>http://arxiv.org/abs/2302.00257</link><description>&lt;p&gt;
&#38544;&#24335;&#27491;&#21017;&#21270;&#23545;&#20110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#20855;&#26377;&#20419;&#36827;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Implicit Regularization Leads to Benign Overfitting for Sparse Linear Regression. (arXiv:2302.00257v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00257
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#38544;&#24335;&#27491;&#21017;&#21270;&#21487;&#23545;&#20110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#20855;&#26377;&#20419;&#36827;&#20316;&#29992;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#21442;&#25968;&#21270;&#24418;&#24335;&#65292;&#32467;&#21512;&#20102;$\ell_1$&#21644;$\ell_2$&#20869;&#25554;&#22120;&#30340;&#20248;&#28857;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#21487;&#24471;&#21040;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#27979;&#35797;&#25439;&#22833;&#30340;&#20869;&#25554;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#35757;&#32451;&#36807;&#31243;&#32463;&#24120;&#20250;&#25214;&#21040;&#19968;&#20010;&#20869;&#25554;&#22120;&#65288;&#19968;&#20010;0&#35757;&#32451;&#25439;&#22833;&#30340;&#35299;&#65289;&#65292;&#20294;&#27979;&#35797;&#25439;&#22833;&#20173;&#28982;&#24456;&#20302;&#12290;&#36825;&#31181;&#34987;&#31216;&#20026;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#29616;&#35937;&#65292;&#26159;&#19968;&#20010;&#22791;&#21463;&#20851;&#27880;&#30340;&#37325;&#35201;&#35868;&#22242;&#12290;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#19968;&#20010;&#24120;&#35265;&#26426;&#21046;&#26159;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#35757;&#32451;&#36807;&#31243;&#20250;&#23548;&#33268;&#20869;&#25554;&#22120;&#20855;&#26377;&#39069;&#22806;&#30340;&#24615;&#36136;&#65292;&#24120;&#34987;&#25551;&#36848;&#20026;&#26368;&#23567;&#21270;&#26576;&#20123;&#33539;&#25968;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#23545;&#20110;&#19968;&#20010;&#31616;&#21333;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;$y=\beta^{*\top}x+\xi$&#65292;&#26368;&#23567;&#30340;$\ell_1$&#25110;$\ell_2$&#33539;&#25968;&#20869;&#25554;&#22120;&#20063;&#19981;&#33021;&#32473;&#20986;&#26368;&#20248;&#30340;&#27979;&#35797;&#25439;&#22833;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#30340;&#19981;&#21516;&#21442;&#25968;&#21270;&#24418;&#24335;&#65292;&#23427;&#23548;&#33268;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32467;&#21512;&#20102;$\ell_1$&#21644;$\ell_2$&#20869;&#25554;&#22120;&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#25105;&#20204;&#30340;&#26032;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#27979;&#35797;&#25439;&#22833;&#30340;&#20869;&#25554;&#22120;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#22522;&#20110;&#23545;&#35757;&#32451;&#21160;&#21147;&#23398;&#30340;&#32454;&#33268;&#20998;&#26512;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35299;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning, often the training process finds an interpolator (a solution with 0 training loss), but the test loss is still low. This phenomenon, known as benign overfitting, is a major mystery that received a lot of recent attention. One common mechanism for benign overfitting is implicit regularization, where the training process leads to additional properties for the interpolator, often characterized by minimizing certain norms. However, even for a simple sparse linear regression problem $y = \beta^{*\top} x +\xi$ with sparse $\beta^*$, neither minimum $\ell_1$ or $\ell_2$ norm interpolator gives the optimal test loss. In this work, we give a different parametrization of the model which leads to a new implicit regularization effect that combines the benefit of $\ell_1$ and $\ell_2$ interpolators. We show that training our new model via gradient descent leads to an interpolator with near-optimal test loss. Our result is based on careful analysis of the training dynamics and prov
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;STEEL&#65292;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#19981;&#20381;&#36182;&#20110;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#36890;&#36807;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.13152</link><description>&lt;p&gt;
STEEL: &#22855;&#24322;&#24615;&#24863;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
STEEL: Singularity-aware Reinforcement Learning. (arXiv:2301.13152v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;STEEL&#65292;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#19981;&#20381;&#36182;&#20110;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#36890;&#36807;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#21033;&#29992;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#20197;&#26368;&#22823;&#21270;&#26399;&#26395;&#24635;&#22238;&#25253;&#12290;&#28982;&#32780;&#65292;&#20960;&#20046;&#25152;&#26377;&#29616;&#26377;&#31639;&#27861;&#37117;&#20381;&#36182;&#20110;&#30446;&#26631;&#31574;&#30053;&#35825;&#23548;&#30340;&#20998;&#24067;&#32477;&#23545;&#36830;&#32493;&#20551;&#35774;&#65292;&#20197;&#20415;&#36890;&#36807;&#21464;&#25442;&#27979;&#24230;&#20351;&#29992;&#25209;&#37327;&#25968;&#25454;&#26469;&#26657;&#20934;&#30446;&#26631;&#31574;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#38656;&#35201;&#22312;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#34892;&#21160;&#30340;&#26080;&#38480;&#26102;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#32477;&#23545;&#36830;&#32493;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#31216;&#36825;&#20010;&#31639;&#27861;&#20026;STEEL&#65306;SingulariTy-awarE rEinforcement Learning&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21463;&#21040;&#20851;&#20110;&#31163;&#32447;&#35780;&#20272;&#30340;&#26032;&#35823;&#24046;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#20102;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#65292;&#20197;&#21450;&#24102;&#26377;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31574;&#30053;&#23450;&#21521;&#35823;&#24046;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#24322;&#24120;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#22855;&#24322;&#24773;&#20917;&#30340;&#23450;&#21521;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch reinforcement learning (RL) aims at leveraging pre-collected data to find an optimal policy that maximizes the expected total rewards in a dynamic environment. Nearly all existing algorithms rely on the absolutely continuous assumption on the distribution induced by target policies with respect to the data distribution, so that the batch data can be used to calibrate target policies via the change of measure. However, the absolute continuity assumption could be violated in practice (e.g., no-overlap support), especially when the state-action space is large or continuous. In this paper, we propose a new batch RL algorithm without requiring absolute continuity in the setting of an infinite-horizon Markov decision process with continuous states and actions. We call our algorithm STEEL: SingulariTy-awarE rEinforcement Learning. Our algorithm is motivated by a new error analysis on off-policy evaluation, where we use maximum mean discrepancy, together with distributionally robust opti
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32852;&#37030;&#24179;&#22343;&#31639;&#27861;&#65292;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#20998;&#24067;&#24335;&#38750;&#20984;&#30446;&#26631;&#36827;&#34892;&#20102;&#38543;&#26426;&#20248;&#21270;&#65292;&#24314;&#31435;&#20102;&#20165;&#28385;&#36275;&#38543;&#26426;&#26799;&#24230;&#28201;&#21644;&#26465;&#20214;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.12677</link><description>&lt;p&gt;
&#36890;&#29992;&#26041;&#24046;&#26465;&#20214;&#19979;&#30340;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributed Stochastic Optimization under a General Variance Condition. (arXiv:2301.12677v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12677
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#37325;&#26032;&#23457;&#35270;&#32852;&#37030;&#24179;&#22343;&#31639;&#27861;&#65292;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#20998;&#24067;&#24335;&#38750;&#20984;&#30446;&#26631;&#36827;&#34892;&#20102;&#38543;&#26426;&#20248;&#21270;&#65292;&#24314;&#31435;&#20102;&#20165;&#28385;&#36275;&#38543;&#26426;&#26799;&#24230;&#28201;&#21644;&#26465;&#20214;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;&#22312;&#35299;&#20915;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#20102;&#24456;&#39640;&#30340;&#25928;&#29575;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#19968;&#33324;&#23454;&#38469;&#38382;&#39064;&#30340;&#31639;&#27861;&#24456;&#22810;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#20027;&#35201;&#20381;&#36182;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#26576;&#20123;&#26377;&#30028;&#26465;&#20214;&#65292;&#20174;&#22343;&#21248;&#26377;&#30028;&#24615;&#21040;&#25918;&#26494;&#22686;&#38271;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#22312;&#20195;&#29702;&#20043;&#38388;&#34920;&#24449;&#25968;&#25454;&#24322;&#36136;&#24615;&#21450;&#20854;&#23545;&#31639;&#27861;&#24615;&#33021;&#30340;&#24433;&#21709;&#20381;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20986;&#20110;&#36825;&#26679;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#37325;&#26032;&#32771;&#34385;&#20102;&#32463;&#20856;&#30340;&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#20998;&#24067;&#24335;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#22312;&#24179;&#28369;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#20165;&#28385;&#36275;&#28201;&#21644;&#26041;&#24046;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435;&#20102;&#25910;&#25947;&#32467;&#26524;&#12290;&#22312;&#27492;&#26465;&#20214;&#19979;&#65292;&#36824;&#24314;&#31435;&#20102;&#25509;&#36817;&#30830;&#23450;&#30340;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#24577;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20010;&#26356;&#20855;&#20449;&#24687;&#24615;&#30340;&#24230;&#37327;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributed stochastic optimization has drawn great attention recently due to its effectiveness in solving large-scale machine learning problems. Though numerous algorithms have been proposed and successfully applied to general practical problems, their theoretical guarantees mainly rely on certain boundedness conditions on the stochastic gradients, varying from uniform boundedness to the relaxed growth condition. In addition, how to characterize the data heterogeneity among the agents and its impacts on the algorithmic performance remains challenging. In light of such motivations, we revisit the classical Federated Averaging (FedAvg) algorithm for solving the distributed stochastic optimization problem and establish the convergence results under only a mild variance condition on the stochastic gradients for smooth nonconvex objective functions. Almost sure convergence to a stationary point is also established under the condition. Moreover, we discuss a more informative measurement for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#38024;&#23545;&#21253;&#21547;&#24322;&#26041;&#24046;&#22870;&#21169;&#22122;&#22768;&#30340;&#31574;&#30053;&#35780;&#20272;&#65292;&#20351;&#29992;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#26032;&#31639;&#27861; SPEED&#65292;&#35813;&#31639;&#27861;&#21487;&#23454;&#29616;&#24102;&#26377;&#22343;&#26041;&#35823;&#24046;&#27604;&#36739;&#23567;&#30340;&#31574;&#30053;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2301.12357</link><description>&lt;p&gt;
SPEED: &#32447;&#24615;&#24322;&#26041;&#24046; Bandit &#31574;&#30053;&#35780;&#20272;&#30340;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits. (arXiv:2301.12357v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#38024;&#23545;&#21253;&#21547;&#24322;&#26041;&#24046;&#22870;&#21169;&#22122;&#22768;&#30340;&#31574;&#30053;&#35780;&#20272;&#65292;&#20351;&#29992;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#26032;&#31639;&#27861; SPEED&#65292;&#35813;&#31639;&#27861;&#21487;&#23454;&#29616;&#24102;&#26377;&#22343;&#26041;&#35823;&#24046;&#27604;&#36739;&#23567;&#30340;&#31574;&#30053;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615; Bandit &#19979;&#31574;&#30053;&#35780;&#20272;&#30340;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#12290;&#22312;&#31574;&#30053;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#20272;&#35745;&#22810;&#33218;&#36172;&#21338;&#26426;&#29615;&#22659;&#20013;&#25191;&#34892;&#30446;&#26631;&#31574;&#30053;&#23558;&#33719;&#24471;&#30340;&#26399;&#26395;&#25910;&#30410;&#12290;&#26412;&#25991;&#26159;&#39318;&#20010;&#19987;&#27880;&#20110;&#35299;&#20915;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#21253;&#21547;&#24322;&#26041;&#24046;&#22870;&#21169;&#22122;&#22768;&#30340;&#31574;&#30053;&#35780;&#20272;&#30340;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#21046;&#23450;&#20102;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#26368;&#20248;&#35774;&#35745;&#65292;&#20197;&#20943;&#23569;&#30446;&#26631;&#31574;&#30053;&#20215;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#20351;&#29992;&#35813;&#35774;&#35745;&#26469;&#25512;&#23548;&#20986;&#25968;&#25454;&#25910;&#38598;&#26399;&#38388;&#27599;&#20010;&#21160;&#20316;&#30340;&#26368;&#20248;&#26679;&#26412;&#20998;&#37197;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026; SPEED&#65288;Structured Policy Evaluation Experimental Design&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36319;&#36394;&#26368;&#20248;&#35774;&#35745;&#65292;&#24182;&#35745;&#31639;&#20854;&#19982;&#26368;&#20248;&#35774;&#35745;&#30340;&#36951;&#25022;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126; SPEED &#21487;&#20197;&#23454;&#29616;&#24102;&#26377;&#22343;&#26041;&#35823;&#24046;&#27604;&#36739;&#23567;&#30340;&#31574;&#30053;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of optimal data collection for policy evaluation in linear bandits. In policy evaluation, we are given a target policy and asked to estimate the expected reward it will obtain when executed in a multi-armed bandit environment. Our work is the first work that focuses on such optimal data collection strategy for policy evaluation involving heteroscedastic reward noise in the linear bandit setting. We first formulate an optimal design for weighted least squares estimates in the heteroscedastic linear bandit setting that reduces the MSE of the value of the target policy. We then use this formulation to derive the optimal allocation of samples per action during data collection. We then introduce a novel algorithm SPEED (Structured Policy Evaluation Experimental Design) that tracks the optimal design and derive its regret with respect to the optimal design. Finally, we empirically validate that SPEED leads to policy evaluation with mean squared error compa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#23398;&#20064;&#29575;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26368;&#22823;&#21021;&#22987;&#23398;&#20064;&#29575;&#30340;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#20854;&#34892;&#20026;&#19982;&#35757;&#32451;&#21518;&#26399;&#30340;&#26368;&#22823;&#23398;&#20064;&#29575;&#19981;&#21516;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65306;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#26368;&#22823;&#21021;&#22987;&#23398;&#20064;&#29575;&#21487;&#20197;&#24456;&#22909;&#22320;&#39044;&#27979;&#20026;&#28145;&#24230;&#215;&#23485;&#24230;&#30340;&#24130;&#27425;&#12290;</title><link>http://arxiv.org/abs/2212.07295</link><description>&lt;p&gt;
&#28145;&#23618;ReLU&#32593;&#32476;&#20013;&#30340;&#26368;&#22823;&#21021;&#22987;&#23398;&#20064;&#29575;
&lt;/p&gt;
&lt;p&gt;
Maximal Initial Learning Rates in Deep ReLU Networks. (arXiv:2212.07295v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#23398;&#20064;&#29575;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#26368;&#22823;&#21021;&#22987;&#23398;&#20064;&#29575;&#30340;&#27010;&#24565;&#65292;&#24182;&#21457;&#29616;&#20854;&#34892;&#20026;&#19982;&#35757;&#32451;&#21518;&#26399;&#30340;&#26368;&#22823;&#23398;&#20064;&#29575;&#19981;&#21516;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65306;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#26368;&#22823;&#21021;&#22987;&#23398;&#20064;&#29575;&#21487;&#20197;&#24456;&#22909;&#22320;&#39044;&#27979;&#20026;&#28145;&#24230;&#215;&#23485;&#24230;&#30340;&#24130;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#36873;&#25321;&#36866;&#24403;&#30340;&#23398;&#20064;&#29575;&#65292;&#36825;&#28041;&#21450;&#21040;&#36895;&#24230;&#21644;&#26377;&#25928;&#25910;&#25947;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#23613;&#31649;&#23545;&#20110;&#23398;&#20064;&#29575;&#21487;&#20197;&#26377;&#22810;&#22823;&#36827;&#34892;&#20102;&#30456;&#24403;&#22823;&#37327;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#20294;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#24037;&#20316;&#21482;&#20851;&#27880;&#20110;&#21518;&#26399;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26368;&#22823;&#21021;&#22987;&#23398;&#20064;&#29575;$\eta^{*}$&#8212;&#8212;&#22312;&#36825;&#20010;&#23398;&#20064;&#29575;&#19979;&#65292;&#19968;&#20010;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25104;&#21151;&#22320;&#24320;&#22987;&#35757;&#32451;&#24182;&#36798;&#21040;&#65288;&#33267;&#23569;&#65289;&#19968;&#20010;&#32473;&#23450;&#30340;&#38408;&#20540;&#31934;&#24230;&#12290;&#20351;&#29992;&#31616;&#21333;&#30340;&#26041;&#27861;&#20272;&#35745;$\eta^{*}$&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#24658;&#23450;&#23485;&#24230;&#30340;&#23436;&#20840;&#36830;&#25509;&#30340;ReLU&#32593;&#32476;&#20013;&#65292;$\eta^{*}$&#30340;&#34892;&#20026;&#19982;&#35757;&#32451;&#21518;&#26399;&#30340;&#26368;&#22823;&#23398;&#20064;&#29575;&#19981;&#21516;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;$\eta^{*}$&#21487;&#20197;&#24456;&#22909;&#22320;&#39044;&#27979;&#20026;&#28145;&#24230;$\times$&#23485;&#24230;&#30340;&#24130;&#27425;&#65292;&#21069;&#25552;&#26159;&#65288;i&#65289;&#32593;&#32476;&#30340;&#23485;&#24230;&#30456;&#23545;&#28145;&#24230;&#36275;&#22815;&#22823;&#65292;&#65288;ii&#65289;&#36755;&#20837;&#23618;&#20197;&#30456;&#23545;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training a neural network requires choosing a suitable learning rate, which involves a trade-off between speed and effectiveness of convergence. While there has been considerable theoretical and empirical analysis of how large the learning rate can be, most prior work focuses only on late-stage training. In this work, we introduce the maximal initial learning rate $\eta^{\ast}$ - the largest learning rate at which a randomly initialized neural network can successfully begin training and achieve (at least) a given threshold accuracy. Using a simple approach to estimate $\eta^{\ast}$, we observe that in constant-width fully-connected ReLU networks, $\eta^{\ast}$ behaves differently from the maximum learning rate later in training. Specifically, we find that $\eta^{\ast}$ is well predicted as a power of depth $\times$ width, provided that (i) the width of the network is sufficiently large compared to the depth, and (ii) the input layer is trained at a relatively small learning rate. We fu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#26399;&#38388;&#20250;&#20986;&#29616;&#20998;&#24067;&#24335;&#31616;&#21333;&#24615;&#20559;&#24046;&#65288;DSB&#65289;&#65292;&#21363;&#26368;&#21021;&#20351;&#29992;&#20302;&#38454;&#36755;&#20837;&#32479;&#35745;&#26469;&#20998;&#31867;&#36755;&#20837;&#65292;&#21482;&#26377;&#22312;&#35757;&#32451;&#21518;&#26399;&#25165;&#21033;&#29992;&#26356;&#39640;&#38454;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2211.11567</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#26085;&#30410;&#22797;&#26434;&#30340;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Neural networks trained with SGD learn distributions of increasing complexity. (arXiv:2211.11567v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#26399;&#38388;&#20250;&#20986;&#29616;&#20998;&#24067;&#24335;&#31616;&#21333;&#24615;&#20559;&#24046;&#65288;DSB&#65289;&#65292;&#21363;&#26368;&#21021;&#20351;&#29992;&#20302;&#38454;&#36755;&#20837;&#32479;&#35745;&#26469;&#20998;&#31867;&#36755;&#20837;&#65292;&#21482;&#26377;&#22312;&#35757;&#32451;&#21518;&#26399;&#25165;&#21033;&#29992;&#26356;&#39640;&#38454;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21363;&#20351;&#22312;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#26102;&#20063;&#33021;&#24456;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#30340;&#33021;&#21147;&#24050;&#32463;&#36890;&#36807;&#21508;&#31181;&#8220;&#31616;&#21333;&#24615;&#20559;&#24046;&#8221;&#24471;&#21040;&#20102;&#35299;&#37322;&#12290;&#36825;&#20123;&#29702;&#35770;&#20551;&#35774;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#26356;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#20043;&#21069;&#20808;&#23398;&#20064;&#31616;&#21333;&#20989;&#25968;&#65292;&#20363;&#22914;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#21516;&#26102;&#65292;&#25968;&#25454;&#32467;&#26500;&#20063;&#34987;&#35748;&#20026;&#26159;&#33391;&#22909;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#28982;&#32780;&#65292;&#25968;&#25454;&#32467;&#26500;&#22312;&#31616;&#21333;&#24615;&#20559;&#24046;&#20013;&#30340;&#20316;&#29992;&#23578;&#26410;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#26368;&#21021;&#20351;&#29992;&#20302;&#38454;&#36755;&#20837;&#32479;&#35745;&#65288;&#22914;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65289;&#26469;&#23545;&#20854;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#65292;&#21482;&#26377;&#22312;&#35757;&#32451;&#21518;&#26399;&#25165;&#21033;&#29992;&#26356;&#39640;&#38454;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#31070;&#32463;&#32593;&#32476;&#23545;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#21487;&#35299;&#27169;&#22411;&#20013;&#23637;&#31034;&#20102;&#36825;&#31181;&#20998;&#24067;&#24335;&#31616;&#21333;&#24615;&#20559;&#24046;&#65288;DSB&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#35757;&#32451;&#20110;CIFAR10&#19978;&#30340;&#19968;&#31995;&#21015;&#28145;&#24230;&#21367;&#31215;&#32593;&#32476;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#20013;&#32463;&#39564;&#24615;&#22320;&#35777;&#26126;&#20102;DSB&#65292;&#29978;&#33267;&#21457;&#29616;&#35813;&#20559;&#24046;&#22312;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#21644;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#20307;&#31995;&#32467;&#26500;&#20013;&#20063;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability of deep neural networks to generalise well even when they interpolate their training data has been explained using various "simplicity biases". These theories postulate that neural networks avoid overfitting by first learning simple functions, say a linear classifier, before learning more complex, non-linear functions. Meanwhile, data structure is also recognised as a key ingredient for good generalisation, yet its role in simplicity biases is not yet understood. Here, we show that neural networks trained using stochastic gradient descent initially classify their inputs using lower-order input statistics, like mean and covariance, and exploit higher-order statistics only later during training. We first demonstrate this distributional simplicity bias (DSB) in a solvable model of a neural network trained on synthetic data. We empirically demonstrate DSB in a range of deep convolutional networks and visual transformers trained on CIFAR10, and show that it even holds in network
&lt;/p&gt;</description></item><item><title>&#22810;&#27169;&#20809;&#32420;&#21033;&#29992;&#27700;&#24211;&#35745;&#31639;&#33539;&#20363;&#36827;&#34892;&#20998;&#31867;&#65292;&#31934;&#24230;&#39640;&#20110;&#30452;&#25509;&#35757;&#32451;&#21407;&#22987;&#22270;&#20687;&#21644;&#20256;&#32479;&#30340;&#20256;&#36755;&#30697;&#38453;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2210.04745</link><description>&lt;p&gt;
&#22810;&#27169;&#20809;&#32420;&#27700;&#24211;&#35745;&#31639;&#20811;&#26381;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Multi-mode fiber reservoir computing overcomes shallow neural networks classifiers. (arXiv:2210.04745v2 [physics.optics] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04745
&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#20809;&#32420;&#21033;&#29992;&#27700;&#24211;&#35745;&#31639;&#33539;&#20363;&#36827;&#34892;&#20998;&#31867;&#65292;&#31934;&#24230;&#39640;&#20110;&#30452;&#25509;&#35757;&#32451;&#21407;&#22987;&#22270;&#20687;&#21644;&#20256;&#32479;&#30340;&#20256;&#36755;&#30697;&#38453;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#24207;&#20809;&#23376;&#23398;&#39046;&#22495;&#20013;&#65292;&#24120;&#35265;&#30340;&#30446;&#26631;&#26159;&#23545;&#19981;&#36879;&#26126;&#26448;&#26009;&#36827;&#34892;&#34920;&#24449;&#65292;&#20197;&#25511;&#21046;&#20809;&#30340;&#20256;&#36882;&#25110;&#25191;&#34892;&#25104;&#20687;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#30340;&#22120;&#20214;&#20013;&#65292;&#22810;&#27169;&#20809;&#32420;&#20197;&#20854;&#25104;&#26412;&#25928;&#30410;&#39640;&#12289;&#26131;&#20110;&#25805;&#20316;&#30340;&#29305;&#28857;&#33073;&#39062;&#32780;&#20986;&#65292;&#20351;&#20854;&#22312;&#20960;&#20010;&#20219;&#21153;&#20013;&#20855;&#26377;&#21560;&#24341;&#21147;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#21033;&#29992;&#27700;&#24211;&#35745;&#31639;&#33539;&#20363;&#65292;&#23558;&#36825;&#20123;&#20809;&#32420;&#36716;&#21270;&#20026;&#38543;&#26426;&#30828;&#20214;&#25237;&#24433;&#20202;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#38598;&#36716;&#21270;&#20026;&#39640;&#32500;&#26001;&#28857;&#22270;&#20687;&#38598;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#30446;&#26631;&#26159;&#35777;&#26126;&#65292;&#36890;&#36807;&#35757;&#32451;&#21333;&#20010;&#36923;&#36753;&#22238;&#24402;&#23618;&#23545;&#36825;&#20123;&#38543;&#26426;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#21487;&#20197;&#25552;&#39640;&#31934;&#24230;&#65292;&#30456;&#27604;&#20043;&#19979;&#30452;&#25509;&#35757;&#32451;&#21407;&#22987;&#22270;&#20687;&#35201;&#26356;&#20026;&#20934;&#30830;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#20351;&#29992;&#27700;&#24211;&#25152;&#36798;&#21040;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#20063;&#39640;&#20110;&#37319;&#29992;&#20256;&#32479;&#30340;&#20256;&#36755;&#30697;&#38453;&#27169;&#22411;&#65292;&#21518;&#32773;&#26159;&#25551;&#36848;&#36890;&#36807;&#26080;&#24207;&#22120;&#20214;&#20256;&#36882;&#20809;&#30340;&#24191;&#27867;&#25509;&#21463;&#24037;&#20855;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#31181;&#25913;&#36827;&#24615;&#33021;&#30340;&#21407;&#22240;&#22312;&#20110;&#27700;&#24211;&#30340;&#21160;&#21147;&#23398;&#20855;&#26377;&#26356;&#39640;&#30340;&#23481;&#37327;&#26469;&#25429;&#25417;&#22797;&#26434;&#30340;&#36755;&#20837;&#36755;&#20986;&#26144;&#23556;&#65292;&#30456;&#23545;&#20110;&#20256;&#36755;&#30697;&#38453;&#30340;&#32447;&#24615;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of disordered photonics, a common objective is to characterize optically opaque materials for controlling light delivery or performing imaging. Among various complex devices, multi-mode optical fibers stand out as cost-effective and easy-to-handle tools, making them attractive for several tasks. In this context, we leverage the reservoir computing paradigm to recast these fibers into random hardware projectors, transforming an input dataset into a higher dimensional speckled image set. The goal of our study is to demonstrate that using such randomized data for classification by training a single logistic regression layer improves accuracy compared to training on direct raw images. Interestingly, we found that the classification accuracy achieved using the reservoir is also higher than that obtained with the standard transmission matrix model, a widely accepted tool for describing light transmission through disordered devices. We find that the reason for such improved perfo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#26080;&#38480;&#23485;&#24230;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#23398;&#20064;&#35268;&#21017;&#22914;GD&#12289;FA&#12289;DFA&#12289;Hebb&#21644;GLN&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#21457;&#29616;&#27599;&#31181;&#35268;&#21017;&#19979;&#30340;&#36755;&#20986;&#20989;&#25968;&#28436;&#21270;&#37117;&#21463;&#21040;&#26102;&#38388;&#21464;&#21270;&#30340;&#26377;&#25928;&#31070;&#32463;&#20999;&#21521;&#26680;(eNTK)&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21160;&#24577;&#22343;&#22330;&#29702;&#35770;(DMFT)&#27604;&#36739;&#20102;&#27599;&#31181;&#23398;&#20064;&#35268;&#21017;&#25152;&#24341;&#36215;&#30340;&#29305;&#24449;&#21644;&#39044;&#27979;&#21160;&#21147;&#23398;&#12290;</title><link>http://arxiv.org/abs/2210.02157</link><description>&lt;p&gt;
&#23398;&#20064;&#35268;&#21017;&#23545;&#24191;&#27867;&#31070;&#32463;&#32593;&#32476;&#34920;&#24449;&#21160;&#21147;&#23398;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks. (arXiv:2210.02157v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.02157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#26080;&#38480;&#23485;&#24230;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#23398;&#20064;&#35268;&#21017;&#22914;GD&#12289;FA&#12289;DFA&#12289;Hebb&#21644;GLN&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#21457;&#29616;&#27599;&#31181;&#35268;&#21017;&#19979;&#30340;&#36755;&#20986;&#20989;&#25968;&#28436;&#21270;&#37117;&#21463;&#21040;&#26102;&#38388;&#21464;&#21270;&#30340;&#26377;&#25928;&#31070;&#32463;&#20999;&#21521;&#26680;(eNTK)&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#21160;&#24577;&#22343;&#22330;&#29702;&#35770;(DMFT)&#27604;&#36739;&#20102;&#27599;&#31181;&#23398;&#20064;&#35268;&#21017;&#25152;&#24341;&#36215;&#30340;&#29305;&#24449;&#21644;&#39044;&#27979;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#23578;&#19981;&#28165;&#26970;&#25913;&#21464;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#35268;&#21017;&#22914;&#20309;&#25913;&#21464;&#20854;&#23398;&#20064;&#21160;&#21147;&#23398;&#21644;&#34920;&#24449;&#12290;&#20026;&#20102;&#28145;&#20837;&#20102;&#35299;&#23398;&#20064;&#29305;&#24449;&#12289;&#20989;&#25968;&#36924;&#36817;&#21644;&#23398;&#20064;&#35268;&#21017;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#26080;&#38480;&#23485;&#30340;&#28145;&#24230;&#32593;&#32476;&#65292;&#37319;&#29992;&#20102;&#26799;&#24230;&#19979;&#38477;(GD)&#20197;&#21450;&#29983;&#29289;&#21487;&#34892;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#21253;&#25324;&#21453;&#39304;&#23545;&#40784;(FA)&#12289;&#30452;&#25509;&#21453;&#39304;&#23545;&#40784;(DFA)&#12289;&#35823;&#24046;&#35843;&#21046;&#40657;&#27604;&#23398;&#20064;(Hebb)&#65292;&#20197;&#21450;&#38376;&#25511;&#32447;&#24615;&#32593;&#32476;(GLN)&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is unclear how changing the learning rule of a deep neural network alters its learning dynamics and representations. To gain insight into the relationship between learned features, function approximation, and the learning rule, we analyze infinite-width deep networks trained with gradient descent (GD) and biologically-plausible alternatives including feedback alignment (FA), direct feedback alignment (DFA), and error modulated Hebbian learning (Hebb), as well as gated linear networks (GLN). We show that, for each of these learning rules, the evolution of the output function at infinite width is governed by a time varying effective neural tangent kernel (eNTK). In the lazy training limit, this eNTK is static and does not evolve, while in the rich mean-field regime this kernel's evolution can be determined self-consistently with dynamical mean field theory (DMFT). This DMFT enables comparisons of the feature and prediction dynamics induced by each of these learning rules. In the lazy 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#22522;&#22240;&#32452;&#24207;&#21015;&#21306;&#20998;&#21644;&#21487;&#35270;&#21270;COVID-19&#20027;&#35201;&#21464;&#24322;&#20307;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36825;&#19968;&#26694;&#26550;&#21487;&#20197;&#24110;&#21161;&#21307;&#30103;&#20445;&#20581;&#19987;&#19994;&#20154;&#21592;&#20102;&#35299;&#30149;&#27602;&#30340;&#27969;&#34892;&#30149;&#23398;&#21644;&#36827;&#21270;&#21160;&#24577;&#12290;</title><link>http://arxiv.org/abs/2208.01439</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#21306;&#20998;COVID-19&#20027;&#35201;&#21464;&#24322;&#20307;
&lt;/p&gt;
&lt;p&gt;
Unsupervised machine learning framework for discriminating major variants of concern during COVID-19. (arXiv:2208.01439v3 [q-bio.OT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.01439
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#22522;&#22240;&#32452;&#24207;&#21015;&#21306;&#20998;&#21644;&#21487;&#35270;&#21270;COVID-19&#20027;&#35201;&#21464;&#24322;&#20307;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36825;&#19968;&#26694;&#26550;&#21487;&#20197;&#24110;&#21161;&#21307;&#30103;&#20445;&#20581;&#19987;&#19994;&#20154;&#21592;&#20102;&#35299;&#30149;&#27602;&#30340;&#27969;&#34892;&#30149;&#23398;&#21644;&#36827;&#21270;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#30149;&#27602;&#30340;&#39640;&#31361;&#21464;&#29575;&#65292;COVID-19&#30123;&#24773;&#36805;&#36895;&#28436;&#21464;&#12290;&#26576;&#20123;&#30149;&#27602;&#21464;&#24322;&#20307;&#65292;&#22914;Delta&#21644;Omicron&#65292;&#20986;&#29616;&#24182;&#25913;&#21464;&#20102;&#30149;&#27602;&#30340;&#29305;&#24615;&#65292;&#23548;&#33268;&#30149;&#20363;&#20256;&#25773;&#21644;&#27515;&#20129;&#29575;&#20005;&#37325;&#12290;&#36825;&#20123;&#21464;&#24322;&#20307;&#23545;&#20840;&#29699;&#21307;&#30103;&#31995;&#32479;&#36896;&#25104;&#20102;&#27785;&#37325;&#36127;&#25285;&#65292;&#23545;&#26053;&#34892;&#12289;&#29983;&#20135;&#21147;&#21644;&#19990;&#30028;&#32463;&#27982;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#12290;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#21387;&#32553;&#12289;&#25551;&#36848;&#21644;&#21487;&#35270;&#21270;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22522;&#20110;&#22522;&#22240;&#32452;&#24207;&#21015;&#21306;&#20998;&#21644;&#21487;&#35270;&#21270;COVID-19&#20027;&#35201;&#21464;&#24322;&#20307;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36825;&#20123;&#26041;&#27861;&#37319;&#29992;&#19968;&#20123;&#36873;&#23450;&#30340;&#38477;&#32500;&#21644;&#32858;&#31867;&#25216;&#26415;&#30340;&#32452;&#21512;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#23545;&#25968;&#25454;&#25191;&#34892;k-mer&#20998;&#26512;&#26469;&#22788;&#29702;RNA&#24207;&#21015;&#65292;&#24182;&#20351;&#29992;&#21253;&#25324;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#12289;t-&#20998;&#24067;&#38543;&#26426;&#37051;&#22495;&#23884;&#20837;&#65288;t-SNE&#65289;&#21644;&#22343;&#21248;&#27969;&#24418;&#36924;&#36817;&#21644;&#25237;&#24433;&#65288;UMAP&#65289;&#30340;&#36873;&#23450;&#38477;&#32500;&#26041;&#27861;&#36827;&#19968;&#27493;&#21487;&#35270;&#21270;&#21644;&#27604;&#36739;&#32467;&#26524;&#12290;&#36825;&#20010;&#26694;&#26550;&#23637;&#31034;&#30340;&#32858;&#31867;&#21644;&#20851;&#32852;&#21487;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#21307;&#30103;&#20445;&#20581;&#19987;&#19994;&#20154;&#21592;&#20102;&#35299;COVID-19&#30149;&#27602;&#30340;&#27969;&#34892;&#30149;&#23398;&#21644;&#36827;&#21270;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the high mutation rate of the virus, the COVID-19 pandemic evolved rapidly. Certain variants of the virus, such as Delta and Omicron, emerged with altered viral properties leading to severe transmission and death rates. These variants burdened the medical systems worldwide with a major impact to travel, productivity, and the world economy. Unsupervised machine learning methods have the ability to compress, characterize, and visualize unlabelled data. This paper presents a framework that utilizes unsupervised machine learning methods to discriminate and visualize the associations between major COVID-19 variants based on their genome sequences. These methods comprise a combination of selected dimensionality reduction and clustering techniques. The framework processes the RNA sequences by performing a k-mer analysis on the data and further visualises and compares the results using selected dimensionality reduction methods that include principal component analysis (PCA), t-distribut
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#23545;&#25239;&#24615;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#31561;&#20215;&#30340;&#24191;&#20041;&#20960;&#20309;&#37325;&#24515;&#38382;&#39064;&#21644;&#22810;&#37325;&#36793;&#38469;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#37325;&#36848;&#65292;&#25581;&#31034;&#20102;&#20854;&#20016;&#23500;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#20165;&#38480;&#20110;&#20108;&#20998;&#31867;&#35774;&#32622;&#30340;&#30456;&#20851;&#32467;&#26524;&#12290;&#36890;&#36807;&#26412;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#23545;&#25239;&#24615;&#38382;&#39064;&#30340;&#26368;&#20248;&#31283;&#20581;&#20998;&#31867;&#35268;&#21017;&#21644;&#26368;&#20248;&#23545;&#25239;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2204.12676</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#30340;&#22810;&#37325;&#36793;&#38469;&#26368;&#20248;&#36755;&#36816;&#20844;&#24335;
&lt;/p&gt;
&lt;p&gt;
The Multimarginal Optimal Transport Formulation of Adversarial Multiclass Classification. (arXiv:2204.12676v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.12676
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#23545;&#25239;&#24615;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#31561;&#20215;&#30340;&#24191;&#20041;&#20960;&#20309;&#37325;&#24515;&#38382;&#39064;&#21644;&#22810;&#37325;&#36793;&#38469;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#37325;&#36848;&#65292;&#25581;&#31034;&#20102;&#20854;&#20016;&#23500;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#20165;&#38480;&#20110;&#20108;&#20998;&#31867;&#35774;&#32622;&#30340;&#30456;&#20851;&#32467;&#26524;&#12290;&#36890;&#36807;&#26412;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#23545;&#25239;&#24615;&#38382;&#39064;&#30340;&#26368;&#20248;&#31283;&#20581;&#20998;&#31867;&#35268;&#21017;&#21644;&#26368;&#20248;&#23545;&#25239;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#23545;&#25239;&#24615;&#22810;&#31867;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#31561;&#20215;&#37325;&#36848;&#12290;&#20854;&#20013;&#19968;&#31181;&#26159;&#22522;&#20110;&#26412;&#25991;&#24341;&#20837;&#30340;&#19968;&#32452;&#24191;&#20041;&#20960;&#20309;&#37325;&#24515;&#38382;&#39064;&#65307;&#21478;&#19968;&#31181;&#26159;&#20351;&#29992;&#22810;&#37325;&#36793;&#38469;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#20854;&#20013;&#36793;&#38469;&#30340;&#25968;&#37327;&#31561;&#20110;&#21407;&#22987;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#31867;&#25968;&#12290;&#36825;&#20123;&#26032;&#30340;&#29702;&#35770;&#32467;&#26524;&#25581;&#31034;&#20102;&#22810;&#31867;&#20998;&#31867;&#20013;&#23545;&#25239;&#24615;&#23398;&#20064;&#38382;&#39064;&#30340;&#20016;&#23500;&#20960;&#20309;&#32467;&#26500;&#65292;&#24182;&#25193;&#23637;&#20102;&#20043;&#21069;&#20165;&#38480;&#20110;&#20108;&#20998;&#31867;&#35774;&#32622;&#30340;&#30456;&#20851;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#19968;&#20010;&#30452;&#25509;&#35745;&#31639;&#21547;&#20041;&#26159;&#65292;&#36890;&#36807;&#35299;&#20915;&#37325;&#24515;&#38382;&#39064;&#21450;&#20854;&#23545;&#20598;&#65292;&#25110;&#32773;&#26159; MOT &#38382;&#39064;&#21450;&#20854;&#23545;&#20598;&#65292;&#25105;&#20204;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#23545;&#25239;&#24615;&#38382;&#39064;&#30340;&#26368;&#20248;&#31283;&#20581;&#20998;&#31867;&#35268;&#21017;&#21644;&#26368;&#20248;&#23545;&#25239;&#31574;&#30053;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#31034;&#20363;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a family of adversarial multiclass classification problems and provide equivalent reformulations in terms of: 1) a family of generalized barycenter problems introduced in the paper and 2) a family of multimarginal optimal transport problems where the number of marginals is equal to the number of classes in the original classification problem. These new theoretical results reveal a rich geometric structure of adversarial learning problems in multiclass classification and extend recent results restricted to the binary classification setting. A direct computational implication of our results is that by solving either the barycenter problem and its dual, or the MOT problem and its dual, we can recover the optimal robust classification rule and the optimal adversarial strategy for the original adversarial problem. Examples with synthetic and real data illustrate our results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#19968;&#33324;&#26465;&#20214;&#65292;&#21253;&#25324;&#35299;&#30340;&#23384;&#22312;&#21807;&#19968;&#24615;&#21644;&#22238;&#25253;&#20998;&#24067;&#30340;&#23614;&#37096;&#24615;&#36136;&#12290;&#23558;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#19982;&#22810;&#20803;&#20223;&#23556;&#20998;&#24067;&#26041;&#31243;&#32852;&#31995;&#36215;&#26469;&#65292;&#21457;&#29616;&#20219;&#20309;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#35299;&#37117;&#21487;&#20197;&#20316;&#20026;&#35299;&#30340;&#36793;&#32536;&#24459;&#30340;&#21521;&#37327;&#26469;&#33719;&#24471;&#12290;&#36825;&#19968;&#29702;&#35770;&#36866;&#29992;&#20110;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2202.00081</link><description>&lt;p&gt;
&#35770;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#35299;
&lt;/p&gt;
&lt;p&gt;
On solutions of the distributional Bellman equation. (arXiv:2202.00081v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.00081
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#19968;&#33324;&#26465;&#20214;&#65292;&#21253;&#25324;&#35299;&#30340;&#23384;&#22312;&#21807;&#19968;&#24615;&#21644;&#22238;&#25253;&#20998;&#24067;&#30340;&#23614;&#37096;&#24615;&#36136;&#12290;&#23558;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#19982;&#22810;&#20803;&#20223;&#23556;&#20998;&#24067;&#26041;&#31243;&#32852;&#31995;&#36215;&#26469;&#65292;&#21457;&#29616;&#20219;&#20309;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#35299;&#37117;&#21487;&#20197;&#20316;&#20026;&#35299;&#30340;&#36793;&#32536;&#24459;&#30340;&#21521;&#37327;&#26469;&#33719;&#24471;&#12290;&#36825;&#19968;&#29702;&#35770;&#36866;&#29992;&#20110;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#19981;&#20165;&#35201;&#32771;&#34385;&#39044;&#26399;&#22238;&#25253;&#65292;&#36824;&#35201;&#32771;&#34385;&#31574;&#30053;&#30340;&#23436;&#25972;&#22238;&#25253;&#20998;&#24067;&#12290;&#23545;&#20110;&#22266;&#23450;&#30340;&#31574;&#30053;&#65292;&#20854;&#22238;&#25253;&#20998;&#24067;&#26159;&#30456;&#24212;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#35299;&#12290;&#26412;&#25991;&#32771;&#34385;&#19968;&#33324;&#30340;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#65292;&#30740;&#31350;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#20197;&#21450;&#22238;&#25253;&#20998;&#24067;&#30340;&#23614;&#37096;&#24615;&#36136;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#22238;&#25253;&#20998;&#24067;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#30830;&#23450;&#20102;&#27491;&#21017;&#21464;&#21270;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#23558;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#19982;&#22810;&#20803;&#20223;&#23556;&#20998;&#24067;&#26041;&#31243;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#22810;&#20803;&#20223;&#23556;&#20998;&#24067;&#26041;&#31243;&#30340;&#35299;&#30340;&#26465;&#20214;&#19979;&#65292;&#20219;&#20309;&#20998;&#24067;&#36125;&#23572;&#26364;&#26041;&#31243;&#30340;&#35299;&#37117;&#21487;&#20197;&#20316;&#20026;&#35299;&#30340;&#36793;&#32536;&#24459;&#30340;&#21521;&#37327;&#26469;&#33719;&#24471;&#12290;&#36825;&#20351;&#24471;&#36825;&#31181;&#26041;&#31243;&#30340;&#19968;&#33324;&#29702;&#35770;&#36866;&#29992;&#20110;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
In distributional reinforcement learning not only expected returns but the complete return distributions of a policy are taken into account. The return distribution for a fixed policy is given as the solution of an associated distributional Bellman equation. In this note we consider general distributional Bellman equations and study existence and uniqueness of their solutions as well as tail properties of return distributions. We give necessary and sufficient conditions for existence and uniqueness of return distributions and identify cases of regular variation. We link distributional Bellman equations to multivariate affine distributional equations. We show that any solution of a distributional Bellman equation can be obtained as the vector of marginal laws of a solution to a multivariate affine distributional equation. This makes the general theory of such equations applicable to the distributional reinforcement learning setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#21152;&#24615;&#27169;&#22411;&#65292;&#20351;&#29992;&#23569;&#37327;&#20027;&#35201;&#21644;&#25104;&#23545;&#20132;&#20114;&#25928;&#24212;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#26131;&#20110;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#30340;&#39044;&#27979;&#38754;&#65292;&#24182;&#21462;&#24471;&#20102; ROAM &#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21487;&#20197;&#25552;&#20379;&#25913;&#36827;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#21644;&#20854;&#20182;&#35843;&#26597;&#30340;&#21453;&#24212;&#29575;&#35758;&#35770;&#12290;</title><link>http://arxiv.org/abs/2108.11328</link><description>&lt;p&gt;
&#29992;&#31616;&#27905;&#21487;&#35299;&#37322;&#30340;&#21152;&#24615;&#27169;&#22411;&#21644;&#32467;&#26500;&#20132;&#20114;&#39044;&#27979;&#20154;&#21475;&#26222;&#26597;&#35843;&#26597;&#21453;&#24212;&#29575;
&lt;/p&gt;
&lt;p&gt;
Predicting Census Survey Response Rates With Parsimonious Additive Models and Structured Interactions. (arXiv:2108.11328v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.11328
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#21152;&#24615;&#27169;&#22411;&#65292;&#20351;&#29992;&#23569;&#37327;&#20027;&#35201;&#21644;&#25104;&#23545;&#20132;&#20114;&#25928;&#24212;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#26131;&#20110;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#30340;&#39044;&#27979;&#38754;&#65292;&#24182;&#21462;&#24471;&#20102; ROAM &#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21487;&#20197;&#25552;&#20379;&#25913;&#36827;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#21644;&#20854;&#20182;&#35843;&#26597;&#30340;&#21453;&#24212;&#29575;&#35758;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#19968;&#31995;&#21015;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#27169;&#22411;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#12290;&#26412;&#30740;&#31350;&#21463;&#21040;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#33879;&#21517;&#30340; ROAM &#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#35813;&#24212;&#29992;&#20351;&#29992;&#22312;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#35268;&#21010;&#25968;&#25454;&#24211;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#35782;&#21035;&#38590;&#20197;&#35843;&#26597;&#30340;&#21306;&#22495;&#12290;&#21313;&#24180;&#21069;&#32452;&#32455;&#30340;&#19968;&#22330;&#20247;&#21253;&#31454;&#36187;&#34920;&#26126;&#65292;&#22522;&#20110;&#22238;&#24402;&#26641;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#65307;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#65292;&#30456;&#24212;&#30340;&#27169;&#22411;&#19981;&#33021;&#29992;&#20110;&#25311;&#23450;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992; $\ell_0$-based &#24809;&#32602;&#30340;&#38750;&#21442;&#25968;&#21152;&#24615;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#23569;&#25968;&#20027;&#35201;&#21644;&#25104;&#23545;&#20132;&#20114;&#25928;&#24212;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#65292;&#24182;&#35752;&#35770;&#20102;&#23558;&#24378;&#23618;&#27425;&#20132;&#20114;&#21512;&#24182;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;&#22312;Github &#19978;&#24320;&#28304;&#65289;&#20801;&#35768;&#25105;&#20204;&#29983;&#25104;&#26131;&#20110;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#30340;&#39044;&#27979;&#38754;&#65292;&#20174;&#32780;&#33719;&#24471;&#26377;&#20851;&#35843;&#26597;&#21453;&#24212;&#29575;&#30340;&#21487;&#34892;&#35265;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312; ROAM &#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#21644;&#20854;&#20182;&#35843;&#26597;&#30340;&#25913;&#36827;&#35843;&#26597;&#21453;&#24212;&#29575;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider the problem of predicting survey response rates using a family of flexible and interpretable nonparametric models. The study is motivated by the US Census Bureau's well-known ROAM application which uses a linear regression model trained on the US Census Planning Database data to identify hard-to-survey areas. A crowdsourcing competition organized around ten years ago revealed that machine learning methods based on ensembles of regression trees led to the best performance in predicting survey response rates; however, the corresponding models could not be adopted for the intended application due to their black-box nature. We consider nonparametric additive models with small number of main and pairwise interaction effects using $\ell_0$-based penalization. From a methodological viewpoint, we study both computational and statistical aspects of our estimator; and discuss variants that incorporate strong hierarchical interactions. Our algorithms (opensourced on gith
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#21644;&#39640;&#26031;&#36807;&#31243;&#25216;&#26415;&#35299;&#37322;&#20102;&#31070;&#32463;&#32593;&#32476;&#21452;&#23792;&#19979;&#38477;&#29616;&#35937;&#65292;&#24314;&#31435;&#20102;NNGP&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#20043;&#38388;&#30340;&#26032;&#32852;&#31995;&#65292;&#25581;&#31034;&#35813;&#29616;&#35937;&#21463;&#21040;&#32463;&#39564;&#26680;&#21644;NNGP&#26680;&#20043;&#38388;&#24046;&#24322;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2102.07238</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#35270;&#35282;&#19979;&#31070;&#32463;&#32593;&#32476;&#30340;&#21452;&#23792;&#19979;&#38477;&#26354;&#32447;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Double-descent curves in neural networks: a new perspective using Gaussian processes. (arXiv:2102.07238v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.07238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#21644;&#39640;&#26031;&#36807;&#31243;&#25216;&#26415;&#35299;&#37322;&#20102;&#31070;&#32463;&#32593;&#32476;&#21452;&#23792;&#19979;&#38477;&#29616;&#35937;&#65292;&#24314;&#31435;&#20102;NNGP&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#20043;&#38388;&#30340;&#26032;&#32852;&#31995;&#65292;&#25581;&#31034;&#35813;&#29616;&#35937;&#21463;&#21040;&#32463;&#39564;&#26680;&#21644;NNGP&#26680;&#20043;&#38388;&#24046;&#24322;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21452;&#23792;&#19979;&#38477;&#26354;&#32447;&#29616;&#35937;&#25551;&#36848;&#20102;&#24403;&#22686;&#21152;&#21442;&#25968;&#26102;&#65292;&#27867;&#21270;&#35823;&#24046;&#36215;&#21021;&#19979;&#38477;&#65292;&#20294;&#22312;&#36798;&#21040;&#19968;&#20010;&#23567;&#20110;&#25968;&#25454;&#28857;&#25968;&#37327;&#30340;&#26368;&#20248;&#21442;&#25968;&#21518;&#22686;&#21152;&#65292;&#28982;&#21518;&#22312;&#36807;&#21442;&#25968;&#21270;&#21306;&#38388;&#20877;&#27425;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#25216;&#26415;&#26469;&#34920;&#24449;&#32463;&#39564;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#35889;&#20998;&#24067;&#65292;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#65288;NNGP&#65289;&#26680;&#35889;&#30340;&#23485;&#24230;&#30456;&#20851;&#25200;&#21160;&#65292;&#20174;&#32780;&#22312;&#31070;&#32463;&#32593;&#32476;&#39046;&#22495;&#24314;&#31435;&#20102;NNGP&#25991;&#29486;&#19982;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#25991;&#29486;&#20043;&#38388;&#30340;&#26032;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#20801;&#35768;&#25105;&#20204;&#30740;&#31350;&#30456;&#24212;&#26680;&#21644;GP&#22238;&#24402;&#30340;&#27867;&#21270;&#34892;&#20026;&#65292;&#24182;&#20026;&#21452;&#23792;&#19979;&#38477;&#30340;&#29616;&#35937;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#35299;&#37322;&#65292;&#21363;&#30001;&#23485;&#24230;&#30456;&#20851;&#30340;&#32463;&#39564;&#26680;&#19982;&#23485;&#24230;&#26080;&#20851;&#30340;NNGP&#26680;&#20043;&#38388;&#30340;&#24046;&#24322;&#25152;&#20915;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Double-descent curves in neural networks describe the phenomenon that the generalisation error initially descends with increasing parameters, then grows after reaching an optimal number of parameters which is less than the number of data points, but then descends again in the overparameterized regime. In this paper, we use techniques from random matrix theory to characterize the spectral distribution of the empirical feature covariance matrix as a width-dependent perturbation of the spectrum of the neural network Gaussian process (NNGP) kernel, thus establishing a novel connection between the NNGP literature and the random matrix theory literature in the context of neural networks. Our analytical expression allows us to study the generalisation behavior of the corresponding kernel and GP regression, and provides a new interpretation of the double-descent phenomenon, namely as governed by the discrepancy between the width-dependent empirical kernel and the width-independent NNGP kernel.
&lt;/p&gt;</description></item></channel></rss>