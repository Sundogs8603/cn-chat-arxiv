<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.16172</link><description>&lt;p&gt;
&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#36827;&#34892;&#26102;&#31354;&#27169;&#22411;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Temporal-spatial model via Trend Filtering. (arXiv:2308.16172v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16172
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#36235;&#21183;&#28388;&#27874;&#26041;&#27861;&#23545;&#20855;&#26377;&#26102;&#31354;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#30740;&#31350;&#20102;&#35813;&#26041;&#27861;&#22312;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#26497;&#23567;&#21270;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#20102;&#20197;&#24448;&#26410;&#26366;&#25506;&#32034;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20391;&#37325;&#20110;&#23545;&#20855;&#26377;&#21516;&#26102;&#26102;&#38388;&#21644;&#31354;&#38388;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36235;&#21183;&#28388;&#27874;&#65292;&#36825;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#30001;Mammen&#21644;Rudin&#25552;&#20986;&#12290;&#22312;&#21333;&#21464;&#37327;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#30340;&#20449;&#21495;&#20551;&#35774;&#20855;&#26377;&#26377;&#30028;&#24635;&#21464;&#24322;&#24230;&#30340;k&#27425;&#24369;&#23548;&#25968;&#65292;&#20801;&#35768;&#19968;&#23450;&#31243;&#24230;&#30340;&#24179;&#28369;&#24615;&#12290;&#22312;&#22810;&#21464;&#37327;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Padilla&#31561;&#20154;&#30340;K&#26368;&#36817;&#37051;&#34701;&#21512;&#22871;&#32034;&#20272;&#35745;&#22120;&#65292;&#37319;&#29992;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#21464;&#24322;&#24230;&#19988;&#31526;&#21512;&#20998;&#27573;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#20934;&#21017;&#30340;&#20449;&#21495;&#30340;ADMM&#31639;&#27861;&#12290;&#36890;&#36807;&#19982;&#19979;&#30028;&#23545;&#40784;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#26497;&#23567;&#21270;&#24615;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#20197;&#24448;&#36235;&#21183;&#28388;&#27874;&#30740;&#31350;&#20013;&#26410;&#26366;&#25506;&#32034;&#36807;&#30340;&#29420;&#29305;&#30456;&#21464;&#29616;&#35937;&#12290;&#20223;&#30495;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#37117;&#31361;&#20986;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20986;&#33394;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research focuses on the estimation of a non-parametric regression function designed for data with simultaneous time and space dependencies. In such a context, we study the Trend Filtering, a nonparametric estimator introduced by \cite{mammen1997locally} and \cite{rudin1992nonlinear}. For univariate settings, the signals we consider are assumed to have a kth weak derivative with bounded total variation, allowing for a general degree of smoothness. In the multivariate scenario, we study a $K$-Nearest Neighbor fused lasso estimator as in \cite{padilla2018adaptive}, employing an ADMM algorithm, suitable for signals with bounded variation that adhere to a piecewise Lipschitz continuity criterion. By aligning with lower bounds, the minimax optimality of our estimators is validated. A unique phase transition phenomenon, previously uncharted in Trend Filtering studies, emerges through our analysis. Both Simulation studies and real data applications underscore the superior performance of o
&lt;/p&gt;</description></item><item><title>survex&#26159;&#19968;&#20010;R&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24212;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#36830;&#36143;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#20219;&#20309;&#29983;&#23384;&#27169;&#22411;&#65292;&#21487;&#20197;&#25913;&#36827;&#27169;&#22411;&#65292;&#25552;&#39640;&#36879;&#26126;&#24230;&#21644;&#36131;&#20219;&#24863;&#12290;</title><link>http://arxiv.org/abs/2308.16113</link><description>&lt;p&gt;
survex&#65306;&#29992;&#20110;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#27169;&#22411;&#30340;R&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
survex: an R package for explaining machine learning survival models. (arXiv:2308.16113v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16113
&lt;/p&gt;
&lt;p&gt;
survex&#26159;&#19968;&#20010;R&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24212;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#36830;&#36143;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#20219;&#20309;&#29983;&#23384;&#27169;&#22411;&#65292;&#21487;&#20197;&#25913;&#36827;&#27169;&#22411;&#65292;&#25552;&#39640;&#36879;&#26126;&#24230;&#21644;&#36131;&#20219;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#20986;&#33394;&#24615;&#33021;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32463;&#24120;&#29992;&#20110;&#34917;&#20805;&#21644;&#36229;&#36234;&#20256;&#32479;&#30340;&#32479;&#35745;&#29983;&#23384;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#32570;&#20047;&#29992;&#25143;&#21451;&#22909;&#30340;&#24037;&#20855;&#26469;&#35299;&#37322;&#20854;&#20869;&#37096;&#25805;&#20316;&#21644;&#39044;&#27979;&#21407;&#29702;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;survex R&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#24212;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#36830;&#36143;&#30340;&#26694;&#26550;&#26469;&#35299;&#37322;&#20219;&#20309;&#29983;&#23384;&#27169;&#22411;&#12290;&#25152;&#25552;&#36719;&#20214;&#30340;&#21151;&#33021;&#21253;&#25324;&#29702;&#35299;&#21644;&#35786;&#26029;&#29983;&#23384;&#27169;&#22411;&#65292;&#20174;&#32780;&#21487;&#20197;&#25913;&#36827;&#23427;&#20204;&#12290;&#36890;&#36807;&#25581;&#31034;&#21464;&#37327;&#25928;&#24212;&#21644;&#37325;&#35201;&#24615;&#31561;&#20915;&#31574;&#36807;&#31243;&#30340;&#35265;&#35299;&#65292;survex&#33021;&#22815;&#35780;&#20272;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#24182;&#26816;&#27979;&#20559;&#24046;&#12290;&#22240;&#27492;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#30740;&#31350;&#21644;&#21307;&#30103;&#24212;&#29992;&#31561;&#25935;&#24863;&#39046;&#22495;&#21487;&#20197;&#20419;&#36827;&#36879;&#26126;&#24230;&#21644;&#36131;&#20219;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#28180;&#32593;&#36807;&#31243;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#39044;&#27979;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#22797;&#21512;&#20284;&#28982;&#20989;&#25968;&#21644;&#36845;&#20195;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#20272;&#35745;&#20102;&#28180;&#32593;&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#24182;&#20943;&#23567;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#28180;&#32593;&#36807;&#31243;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#26041;&#27861;&#23398;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2308.16092</link><description>&lt;p&gt;
&#22522;&#20110;&#20284;&#28982;&#30340;&#28180;&#32593;&#36807;&#31243;&#25512;&#26029;&#21644;&#39044;&#27979;&#65306;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Likelihood-based inference and forecasting for trawl processes: a stochastic optimization approach. (arXiv:2308.16092v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#28180;&#32593;&#36807;&#31243;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#39044;&#27979;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#22797;&#21512;&#20284;&#28982;&#20989;&#25968;&#21644;&#36845;&#20195;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#20272;&#35745;&#20102;&#28180;&#32593;&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#24182;&#20943;&#23567;&#20102;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#36827;&#19968;&#27493;&#30740;&#31350;&#28180;&#32593;&#36807;&#31243;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#26041;&#27861;&#23398;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#28180;&#32593;&#36807;&#31243;&#65292;&#28180;&#32593;&#36807;&#31243;&#26159;&#24179;&#31283;&#19988;&#26080;&#38480;&#21487;&#20998;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#21487;&#20197;&#25551;&#36848;&#21508;&#31181;&#32479;&#35745;&#29305;&#24615;&#65292;&#22914;&#37325;&#23614;&#21644;&#38271;&#35760;&#24518;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#31532;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#26469;&#25512;&#26029;&#23454;&#20540;&#28180;&#32593;&#36807;&#31243;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#30830;&#23450;&#24615;&#21644;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#12290;&#30001;&#20110;&#28180;&#32593;&#36807;&#31243;&#26159;&#38750;&#39532;&#23572;&#31185;&#22827;&#36807;&#31243;&#65292;&#20284;&#28982;&#20989;&#25968;&#39640;&#24230;&#22797;&#26434;&#65292;&#38656;&#35201;&#20351;&#29992;&#22797;&#21512;&#20284;&#28982;&#20989;&#25968;&#26469;&#31616;&#21270;&#25429;&#25417;&#20854;&#32479;&#35745;&#29305;&#24615;&#12290;&#25105;&#20204;&#23558;&#22797;&#21512;&#20284;&#28982;&#20272;&#35745;&#38382;&#39064;&#34920;&#31034;&#20026;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#36845;&#20195;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#36827;&#34892;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#20960;&#20010;&#25968;&#37327;&#32423;&#20943;&#23567;&#26041;&#24046;&#30340;&#26032;&#39062;&#26799;&#24230;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20123;&#20272;&#35745;&#22120;&#30340;&#29702;&#35770;&#24615;&#36136;&#21644;&#23454;&#38469;&#23454;&#26045;&#32454;&#33410;&#65292;&#24182;&#21457;&#24067;&#20102;&#19968;&#20010;Python&#24211;&#65292;&#21487;&#20197;&#29992;&#20110;&#25311;&#21512;&#22823;&#31867;&#28180;&#32593;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider trawl processes, which are stationary and infinitely divisible stochastic processes and can describe a wide range of statistical properties, such as heavy tails and long memory. In this paper, we develop the first likelihood-based methodology for the inference of real-valued trawl processes and introduce novel deterministic and probabilistic forecasting methods. Being non-Markovian, with a highly intractable likelihood function, trawl processes require the use of composite likelihood functions to parsimoniously capture their statistical properties. We formulate the composite likelihood estimation as a stochastic optimization problem for which it is feasible to implement iterative gradient descent methods. We derive novel gradient estimators with variances that are reduced by several orders of magnitude. We analyze both the theoretical properties and practical implementation details of these estimators and release a Python library which can be used to fit a large class of tr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#35299;&#20915;&#20102;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#35282;&#32447;&#20027;&#23548;&#24773;&#20917;&#19979;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#20197;&#21450;&#20381;&#36182;&#26410;&#30693;&#21442;&#25968;&#30340;&#25238;&#21160;&#23610;&#24230;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.16059</link><description>&lt;p&gt;
&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#25913;&#36827;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Parameter-Free Two-Bit Covariance Estimator with Improved Operator Norm Error Rate. (arXiv:2308.16059v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16059
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#21442;&#25968;&#30340;&#20108;&#20301;&#21327;&#26041;&#24046;&#20272;&#35745;&#22120;&#65292;&#36890;&#36807;&#20351;&#29992;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#35299;&#20915;&#20102;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#23545;&#35282;&#32447;&#20027;&#23548;&#24773;&#20917;&#19979;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#20197;&#21450;&#20381;&#36182;&#26410;&#30693;&#21442;&#25968;&#30340;&#25238;&#21160;&#23610;&#24230;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;Dirksen, Maly and Rauhut&#22312;&#12298;Annals of Statistics&#12299;&#19978;&#24320;&#21457;&#20102;&#19968;&#31181;&#20351;&#29992;&#27599;&#20010;&#26465;&#30446;&#20004;&#20301;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#35813;&#20272;&#35745;&#22120;&#22312;&#19968;&#33324;&#20122;&#39640;&#26031;&#20998;&#24067;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26497;&#23567;&#21270;&#36895;&#29575;&#65292;&#20294;&#20063;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#29702;&#35770;&#19978;&#65292;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23545;&#35282;&#32447;&#30001;&#23569;&#25968;&#26465;&#30446;&#20027;&#23548;&#26102;&#65292;&#20854;&#20272;&#35745;&#22120;&#19982;&#26679;&#26412;&#21327;&#26041;&#24046;&#20043;&#38388;&#23384;&#22312;&#26412;&#36136;&#19978;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#24046;&#36317;&#65307;&#23454;&#38469;&#19978;&#65292;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#38656;&#35201;&#26681;&#25454;&#19968;&#20123;&#26410;&#30693;&#21442;&#25968;&#36827;&#34892;&#35843;&#25972;&#30340;&#25238;&#21160;&#23610;&#24230;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#30340;&#26032;&#22411;&#20108;&#20301;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#19982;Dirksen&#31561;&#20154;&#37319;&#29992;&#30340;&#22343;&#21248;&#25238;&#21160;&#30456;&#20851;&#30340;&#31526;&#21495;&#37327;&#21270;&#22120;&#19981;&#21516;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21463;&#22810;&#20301;&#22343;&#21248;&#37327;&#21270;&#22120;&#21551;&#21457;&#30340;&#19977;&#35282;&#25238;&#21160;&#22120;&#20043;&#21518;&#20877;&#36827;&#34892;&#20108;&#20301;&#37327;&#21270;&#12290;&#36890;&#36807;&#20351;&#29992;&#21508;&#20010;&#26465;&#30446;&#20043;&#38388;&#21464;&#21270;&#30340;&#25238;&#21160;&#23610;&#24230;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#31639;&#23376;&#33539;&#25968;&#35823;&#24046;&#29575;&#65292;&#35813;&#35823;&#24046;&#29575;&#21462;&#20915;&#20110;...
&lt;/p&gt;
&lt;p&gt;
A covariance matrix estimator using two bits per entry was recently developed by Dirksen, Maly and Rauhut [Annals of Statistics, 50(6), pp. 3538-3562]. The estimator achieves near minimax rate for general sub-Gaussian distributions, but also suffers from two downsides: theoretically, there is an essential gap on operator norm error between their estimator and sample covariance when the diagonal of the covariance matrix is dominated by only a few entries; practically, its performance heavily relies on the dithering scale, which needs to be tuned according to some unknown parameters. In this work, we propose a new 2-bit covariance matrix estimator that simultaneously addresses both issues. Unlike the sign quantizer associated with uniform dither in Dirksen et al., we adopt a triangular dither prior to a 2-bit quantizer inspired by the multi-bit uniform quantizer. By employing dithering scales varying across entries, our estimator enjoys an improved operator norm error rate that depends o
&lt;/p&gt;</description></item><item><title>PAVI&#26159;&#19968;&#31181;&#26495;&#22359;&#21270;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#35268;&#27169;&#20154;&#21475;&#30740;&#31350;&#65292;&#36890;&#36807;&#20849;&#20139;&#21442;&#25968;&#21270;&#21644;&#23398;&#20064;&#21152;&#36895;&#35757;&#32451;&#21464;&#20998;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#20998;&#23618;&#38382;&#39064;&#19978;&#30340;&#34920;&#36798;&#21147;&#24378;&#21644;&#31616;&#26126;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.16022</link><description>&lt;p&gt;
PAVI&#65306;&#26495;&#22359;&#21270;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PAVI: Plate-Amortized Variational Inference. (arXiv:2308.16022v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.16022
&lt;/p&gt;
&lt;p&gt;
PAVI&#26159;&#19968;&#31181;&#26495;&#22359;&#21270;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#35268;&#27169;&#20154;&#21475;&#30740;&#31350;&#65292;&#36890;&#36807;&#20849;&#20139;&#21442;&#25968;&#21270;&#21644;&#23398;&#20064;&#21152;&#36895;&#35757;&#32451;&#21464;&#20998;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#20998;&#23618;&#38382;&#39064;&#19978;&#30340;&#34920;&#36798;&#21147;&#24378;&#21644;&#31616;&#26126;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32473;&#23450;&#35266;&#27979;&#25968;&#25454;&#21644;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#23547;&#25214;&#21487;&#33021;&#20135;&#29983;&#25968;&#25454;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#20998;&#24067;&#12290;&#22312;&#22823;&#35268;&#27169;&#20154;&#21475;&#30740;&#31350;&#20013;&#65292;&#25512;&#26029;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#22312;&#25104;&#30334;&#19978;&#21315;&#30340;&#21463;&#35797;&#32773;&#32676;&#20307;&#19978;&#36827;&#34892;&#20102;&#25968;&#30334;&#19975;&#27425;&#27979;&#37327;&#65292;&#23548;&#33268;&#21442;&#25968;&#31354;&#38388;&#24040;&#22823;&#12290;&#36825;&#31181;&#22823;&#22522;&#25968;&#20351;&#24471;&#29616;&#25104;&#30340;&#21464;&#20998;&#25512;&#26029;&#22312;&#35745;&#31639;&#19978;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#26377;&#25928;&#22788;&#29702;&#22823;&#35268;&#27169;&#20154;&#21475;&#30740;&#31350;&#30340;&#32467;&#26500;&#21270;&#21464;&#20998;&#25512;&#26029;&#23478;&#26063;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#20849;&#20139;&#21442;&#25968;&#21270;&#21644;&#23398;&#20064;&#65292;&#36328;&#36234;&#29983;&#25104;&#27169;&#22411;&#20013;&#30340;&#19981;&#21516;i.i.d.&#21464;&#37327;&#65292;&#30001;&#27169;&#22411;&#30340;&#8220;&#26495;&#22359;&#8221;&#26469;&#35937;&#24449;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#27010;&#24565;&#21629;&#21517;&#20026;&#8220;&#26495;&#22359;&#21270;&#8221;&#12290;&#19982;&#20943;&#32531;&#25512;&#26029;&#30340;&#29616;&#25104;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#30456;&#21453;&#65292;&#26495;&#22359;&#21270;&#23548;&#33268;&#35757;&#32451;&#21464;&#20998;&#20998;&#24067;&#30340;&#36895;&#24230;&#25552;&#39640;&#25968;&#20010;&#25968;&#37327;&#32423;&#12290;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#20998;&#23618;&#38382;&#39064;&#65292;PAVI&#20135;&#29983;&#20102;&#34920;&#36798;&#21147;&#24378;&#12289;&#31616;&#26126;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given observed data and a probabilistic generative model, Bayesian inference searches for the distribution of the model's parameters that could have yielded the data. Inference is challenging for large population studies where millions of measurements are performed over a cohort of hundreds of subjects, resulting in a massive parameter space. This large cardinality renders off-the-shelf Variational Inference (VI) computationally impractical.  In this work, we design structured VI families that efficiently tackle large population studies. Our main idea is to share the parameterization and learning across the different i.i.d. variables in a generative model, symbolized by the model's \textit{plates}. We name this concept \textit{plate amortization}. Contrary to off-the-shelf stochastic VI, which slows down inference, plate amortization results in orders of magnitude faster to train variational distributions.  Applied to large-scale hierarchical problems, PAVI yields expressive, parsimoni
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22495;&#27867;&#21270;&#20013;&#36807;&#37327;&#39118;&#38505;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20445;&#35777;&#32463;&#39564;&#39118;&#38505;&#26368;&#20248;&#30340;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#24809;&#32602;&#65292;&#36991;&#20813;&#20102;&#24809;&#32602;&#23545;&#32463;&#39564;&#39118;&#38505;&#20248;&#21270;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2308.15856</link><description>&lt;p&gt;
&#19981;&#38656;&#35201;&#36807;&#37327;&#32463;&#39564;&#39118;&#38505;&#30340;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Domain Generalization without Excess Empirical Risk. (arXiv:2308.15856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22495;&#27867;&#21270;&#20013;&#36807;&#37327;&#39118;&#38505;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#20445;&#35777;&#32463;&#39564;&#39118;&#38505;&#26368;&#20248;&#30340;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#24809;&#32602;&#65292;&#36991;&#20813;&#20102;&#24809;&#32602;&#23545;&#32463;&#39564;&#39118;&#38505;&#20248;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32473;&#23450;&#19981;&#21516;&#20998;&#24067;&#30340;&#22810;&#26679;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#22495;&#27867;&#21270;&#26088;&#22312;&#23398;&#20064;&#21487;&#20197;&#25512;&#24191;&#21040;&#26410;&#35265;&#20998;&#24067;&#30340;&#27169;&#22411;&#12290;&#19968;&#31181;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#35774;&#35745;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26367;&#20195;&#24809;&#32602;&#26469;&#25429;&#25417;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#19982;&#24809;&#32602;&#19968;&#36215;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#31181;&#26041;&#27861;&#30340;&#19968;&#20010;&#37325;&#35201;&#22833;&#36133;&#27169;&#24335;&#26159;&#30001;&#20110;&#38169;&#35823;&#30340;&#24809;&#32602;&#25110;&#32852;&#21512;&#20248;&#21270;&#30340;&#22256;&#38590;&#32780;&#23548;&#33268;&#30340;&#36807;&#37327;&#39118;&#38505;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#19981;&#26159;&#23558;&#32463;&#39564;&#39118;&#38505;&#21644;&#24809;&#32602;&#32852;&#21512;&#26368;&#23567;&#21270;&#65292;&#32780;&#26159;&#22312;&#20445;&#35777;&#32463;&#39564;&#39118;&#38505;&#26368;&#20248;&#30340;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#24809;&#32602;&#12290;&#36825;&#31181;&#25913;&#21464;&#20445;&#35777;&#20102;&#22495;&#27867;&#21270;&#24809;&#32602;&#19981;&#20250;&#24433;&#21709;&#23545;&#32463;&#39564;&#39118;&#38505;&#30340;&#20248;&#21270;&#65292;&#21363;&#22312;&#20998;&#24067;&#20869;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19982;&#29575;&#22833;&#30495;&#29702;&#35770;&#30340;&#20196;&#20154;&#20852;&#22859;&#30340;&#32852;&#31995;&#65292;&#24182;&#21033;&#29992;&#20854;&#24037;&#20855;&#35774;&#35745;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#22522;&#20110;&#24809;&#32602;&#30340;&#22495;&#27867;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given data from diverse sets of distinct distributions, domain generalization aims to learn models that generalize to unseen distributions. A common approach is designing a data-driven surrogate penalty to capture generalization and minimize the empirical risk jointly with the penalty. We argue that a significant failure mode of this recipe is an excess risk due to an erroneous penalty or hardness in joint optimization. We present an approach that eliminates this problem. Instead of jointly minimizing empirical risk with the penalty, we minimize the penalty under the constraint of optimality of the empirical risk. This change guarantees that the domain generalization penalty cannot impair optimization of the empirical risk, i.e., in-distribution performance. To solve the proposed optimization problem, we demonstrate an exciting connection to rate-distortion theory and utilize its tools to design an efficient method. Our approach can be applied to any penalty-based domain generalization
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#36890;&#36807;&#23545;&#36716;&#31227;Lasso&#30340;&#28176;&#36827;&#24615;&#36136;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#23427;&#19982;&#33258;&#36866;&#24212;Lasso&#30340;&#21306;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#20004;&#32773;&#30340;&#20248;&#21183;&#36827;&#34892;&#20102;&#34701;&#21512;&#24182;&#34917;&#20607;&#20102;&#20182;&#20204;&#30340;&#24369;&#28857;&#12290;</title><link>http://arxiv.org/abs/2308.15838</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;Lasso&#12289;&#36716;&#31227;Lasso&#21450;&#20854;&#25299;&#23637;&#65306;&#28176;&#36827;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adaptive Lasso, Transfer Lasso, and Beyond: An Asymptotic Perspective. (arXiv:2308.15838v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#36890;&#36807;&#23545;&#36716;&#31227;Lasso&#30340;&#28176;&#36827;&#24615;&#36136;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#65292;&#20998;&#26512;&#20102;&#23427;&#19982;&#33258;&#36866;&#24212;Lasso&#30340;&#21306;&#21035;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#20004;&#32773;&#30340;&#20248;&#21183;&#36827;&#34892;&#20102;&#34701;&#21512;&#24182;&#34917;&#20607;&#20102;&#20182;&#20204;&#30340;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#25506;&#35752;&#20102;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#33258;&#36866;&#24212;Lasso&#26159;&#19968;&#31181;&#25104;&#29087;&#30340;&#26041;&#27861;&#65292;&#37319;&#29992;&#26681;&#25454;&#21021;&#22987;&#20272;&#35745;&#20540;&#36827;&#34892;&#30340;&#27491;&#21017;&#21270;&#65292;&#20855;&#26377;&#28176;&#36827;&#27491;&#24577;&#24615;&#21644;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#30340;&#29305;&#28857;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#36817;&#25552;&#20986;&#30340;&#36716;&#31227;Lasso&#37319;&#29992;&#26681;&#25454;&#21021;&#22987;&#20272;&#35745;&#20540;&#36827;&#34892;&#30340;&#27491;&#21017;&#21270;&#20943;&#27861;&#65292;&#20855;&#26377;&#20943;&#23569;&#38750;&#28176;&#36827;&#20272;&#35745;&#35823;&#24046;&#30340;&#33021;&#21147;&#12290;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#22240;&#27492;&#20986;&#29616;&#65306;&#37492;&#20110;&#33258;&#36866;&#24212;Lasso&#21644;&#36716;&#31227;Lasso&#22312;&#20351;&#29992;&#21021;&#22987;&#20272;&#35745;&#20540;&#26041;&#38754;&#23384;&#22312;&#30340;&#19981;&#21516;&#26041;&#24335;&#65292;&#36825;&#31181;&#24046;&#24322;&#32473;&#27599;&#31181;&#26041;&#27861;&#24102;&#26469;&#20102;&#20160;&#20040;&#22909;&#22788;&#25110;&#24330;&#31471;&#65311;&#26412;&#25991;&#23545;&#36716;&#31227;Lasso&#30340;&#28176;&#36827;&#24615;&#36136;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#23427;&#19982;&#33258;&#36866;&#24212;Lasso&#30340;&#21306;&#21035;&#12290;&#26681;&#25454;&#36825;&#20010;&#20998;&#26512;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#21508;&#33258;&#30340;&#20248;&#21183;&#36827;&#34892;&#20102;&#34701;&#21512;&#24182;&#34917;&#20607;&#20102;&#20182;&#20204;&#30340;&#24369;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a comprehensive exploration of the theoretical properties inherent in the Adaptive Lasso and the Transfer Lasso. The Adaptive Lasso, a well-established method, employs regularization divided by initial estimators and is characterized by asymptotic normality and variable selection consistency. In contrast, the recently proposed Transfer Lasso employs regularization subtracted by initial estimators with the demonstrated capacity to curtail non-asymptotic estimation errors. A pivotal question thus emerges: Given the distinct ways the Adaptive Lasso and the Transfer Lasso employ initial estimators, what benefits or drawbacks does this disparity confer upon each method? This paper conducts a theoretical examination of the asymptotic properties of the Transfer Lasso, thereby elucidating its differentiation from the Adaptive Lasso. Informed by the findings of this analysis, we introduce a novel method, one that amalgamates the strengths and compensates for the weaknesses o
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.15728</link><description>&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#30340;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15728
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#35770;&#20272;&#35745;&#26159;&#32593;&#32476;&#20998;&#26512;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#21463;&#21040;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#20174;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#39640;&#31561;&#25552;&#20986;&#20102;&#23545;&#20110;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#21644;&#38750;&#21442;&#25968;&#22270;&#35770;&#20272;&#35745;&#30340;&#22270;&#35770;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#24046;&#35823;&#24046;&#29575;&#12290;&#32479;&#35745;&#20248;&#21270;&#20272;&#35745;&#26159;&#22522;&#20110;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#27861;&#65292;&#24182;&#19988;&#22312;&#32500;&#24230;&#19978;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#24050;&#30693;&#30340;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#26159;&#22522;&#20110;&#36890;&#29992;&#22855;&#24322;&#20540;&#38408;&#20540;&#65288;USVT&#65289;&#65292;&#20294;&#26159;&#23427;&#21482;&#33021;&#36798;&#21040;&#27604;&#26497;&#23567;&#26497;&#24046;&#38169;&#35823;&#29575;&#24930;&#24471;&#22810;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;&#20154;&#20204;&#33258;&#28982;&#20250;&#24819;&#30693;&#36947;&#36825;&#26679;&#30340;&#24046;&#36317;&#26159;&#21542;&#26159;&#24517;&#35201;&#30340;&#12290;USVT&#30340;&#35745;&#31639;&#20248;&#21270;&#24615;&#25110;&#22270;&#35770;&#20272;&#35745;&#20013;&#30340;&#35745;&#31639;&#38556;&#30861;&#30340;&#23384;&#22312;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#27492;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#65292;&#24182;&#20026;&#22270;&#35770;&#20272;&#35745;&#30340;&#35745;&#31639;&#38556;&#30861;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphon estimation has been one of the most fundamental problems in network analysis and has received considerable attention in the past decade. From the statistical perspective, the minimax error rate of graphon estimation has been established by Gao et al (2015) for both stochastic block model (SBM) and nonparametric graphon estimation. The statistical optimal estimators are based on constrained least squares and have computational complexity exponential in the dimension. From the computational perspective, the best-known polynomial-time estimator is based on universal singular value thresholding (USVT), but it can only achieve a much slower estimation error rate than the minimax one. It is natural to wonder if such a gap is essential. The computational optimality of the USVT or the existence of a computational barrier in graphon estimation has been a long-standing open problem. In this work, we take the first step towards it and provide rigorous evidence for the computational barrie
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38754;&#20020;&#30340;&#38544;&#31169;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#31169;&#21451;&#22909;&#30340;&#25913;&#36827;&#26041;&#27861;TKNN-Shapley&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21069;&#25552;&#19979;&#33021;&#22815;&#35780;&#20272;&#25968;&#25454;&#36136;&#37327;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#38544;&#31169;-&#23454;&#29992;&#24615;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2308.15709</link><description>&lt;p&gt;
&#38408;&#20540;KNN-Shapley&#65306;&#19968;&#31181;&#32447;&#24615;&#26102;&#38388;&#21644;&#38544;&#31169;&#21451;&#22909;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation. (arXiv:2308.15709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38754;&#20020;&#30340;&#38544;&#31169;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#31169;&#21451;&#22909;&#30340;&#25913;&#36827;&#26041;&#27861;TKNN-Shapley&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25252;&#38544;&#31169;&#30340;&#21069;&#25552;&#19979;&#33021;&#22815;&#35780;&#20272;&#25968;&#25454;&#36136;&#37327;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#38544;&#31169;-&#23454;&#29992;&#24615;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26159;&#25968;&#25454;&#20013;&#24515;&#21270;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#26088;&#22312;&#37327;&#21270;&#21333;&#20010;&#25968;&#25454;&#28304;&#22312;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#38754;&#20020;&#30528;&#24456;&#22810;&#37325;&#35201;&#20294;&#32463;&#24120;&#34987;&#24573;&#35270;&#30340;&#38544;&#31169;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#30446;&#21069;&#26368;&#23454;&#29992;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#20043;&#19968;KNN-Shapley&#65292;&#30740;&#31350;&#20102;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#24378;&#35843;&#20102;KNN-Shapley&#22266;&#26377;&#30340;&#38544;&#31169;&#39118;&#38505;&#65292;&#24182;&#23637;&#31034;&#20102;&#23558;KNN-Shapley&#25913;&#36827;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;(DP)&#30340;&#26174;&#33879;&#25216;&#26415;&#22256;&#38590;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TKNN-Shapley&#65292;KNN-Shapley&#30340;&#19968;&#31181;&#25913;&#36827;&#21464;&#20307;&#65292;&#20855;&#26377;&#38544;&#31169;&#21451;&#22909;&#24615;&#65292;&#21487;&#20197;&#36827;&#34892;&#31616;&#21333;&#30340;&#20462;&#27491;&#20197;&#21253;&#21547;DP&#20445;&#35777;&#65288;DP-TKNN-Shapley&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;DP-TKNN-Shapley&#22312;&#36776;&#21035;&#25968;&#25454;&#36136;&#37327;&#26041;&#38754;&#20855;&#26377;&#19968;&#20123;&#20248;&#21183;&#65292;&#24182;&#22312;&#38544;&#31169;-&#23454;&#29992;&#24615;&#26435;&#34913;&#26041;&#38754;&#20248;&#20110;&#26420;&#32032;&#21270;&#30340;KNN-Shapley&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#26159;&#38750;&#38544;&#31169;&#30340;TKNN-Shapley&#20063;&#33021;&#20197;&#32447;&#24615;&#26102;&#38388;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation, a critical aspect of data-centric ML research, aims to quantify the usefulness of individual data sources in training machine learning (ML) models. However, data valuation faces significant yet frequently overlooked privacy challenges despite its importance. This paper studies these challenges with a focus on KNN-Shapley, one of the most practical data valuation methods nowadays. We first emphasize the inherent privacy risks of KNN-Shapley, and demonstrate the significant technical difficulties in adapting KNN-Shapley to accommodate differential privacy (DP). To overcome these challenges, we introduce TKNN-Shapley, a refined variant of KNN-Shapley that is privacy-friendly, allowing for straightforward modifications to incorporate DP guarantee (DP-TKNN-Shapley). We show that DP-TKNN-Shapley has several advantages and offers a superior privacy-utility tradeoff compared to naively privatized KNN-Shapley in discerning data quality. Moreover, even non-private TKNN-Shapley ac
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#36827;&#34892;&#22270;&#32858;&#31867;&#30340;&#26032;&#31639;&#27861;&#65292;&#33021;&#22815;&#24674;&#22797;&#22823;&#32858;&#31867;&#65292;&#26080;&#35770;&#20854;&#20182;&#32858;&#31867;&#30340;&#22823;&#23567;&#65292;&#24182;&#19988;&#23545;&#20013;&#31561;&#22823;&#23567;&#30340;&#32858;&#31867;&#25552;&#20986;&#20102;&#26032;&#30340;&#25216;&#26415;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2308.15642</link><description>&lt;p&gt;
&#26080;&#38656;&#29305;&#24449;&#38388;&#38548;&#30340;&#32858;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Clustering Without an Eigengap. (arXiv:2308.15642v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15642
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#36827;&#34892;&#22270;&#32858;&#31867;&#30340;&#26032;&#31639;&#27861;&#65292;&#33021;&#22815;&#24674;&#22797;&#22823;&#32858;&#31867;&#65292;&#26080;&#35770;&#20854;&#20182;&#32858;&#31867;&#30340;&#22823;&#23567;&#65292;&#24182;&#19988;&#23545;&#20013;&#31561;&#22823;&#23567;&#30340;&#32858;&#31867;&#25552;&#20986;&#20102;&#26032;&#30340;&#25216;&#26415;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#20013;&#30740;&#31350;&#20102;&#20855;&#26377;&#22823;&#32858;&#31867;&#21644;&#23567;&#19981;&#21487;&#24674;&#22797;&#32858;&#31867;&#30340;&#22270;&#32858;&#31867;&#38382;&#39064;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#35201;&#20040;&#19981;&#20801;&#35768;&#23567;&#20110;$ o&#65288;\sqrt {n}&#65289;$&#22823;&#23567;&#30340;&#23567;&#32858;&#31867;&#65292;&#35201;&#20040;&#35201;&#27714;&#26368;&#23567;&#21487;&#24674;&#22797;&#32858;&#31867;&#21644;&#26368;&#22823;&#19981;&#21487;&#24674;&#22797;&#32858;&#31867;&#20043;&#38388;&#23384;&#22312;&#22823;&#23567;&#38388;&#38548;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#30340;&#31639;&#27861;&#65292;&#23427;&#28040;&#38500;&#20102;&#36825;&#20123;&#35201;&#27714;&#65292;&#24182;&#21487;&#20197;&#30830;&#23450;&#22320;&#24674;&#22797;&#22823;&#32858;&#31867;&#65292;&#32780;&#19981;&#32771;&#34385;&#20854;&#20182;&#32858;&#31867;&#30340;&#22823;&#23567;&#12290;&#20013;&#31561;&#22823;&#23567;&#30340;&#32858;&#31867;&#23545;&#20998;&#26512;&#25552;&#20986;&#20102;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#25509;&#36817;&#24674;&#22797;&#38408;&#20540;&#65292;&#38750;&#24120;&#25935;&#24863;&#20110;&#23567;&#30340;&#22122;&#22768;&#25200;&#21160;&#65292;&#19981;&#20801;&#35768;&#38381;&#21512;&#24418;&#24335;&#30340;&#20505;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#39062;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;leave-one-out&#39118;&#26684;&#30340;&#35770;&#35777;&#65292;&#21363;&#20351;&#21435;&#25481;&#19968;&#34892;&#22122;&#22768;&#20063;&#21487;&#33021;&#22823;&#24133;&#25913;&#21464;SDP&#35299;&#20915;&#26041;&#26696;&#65292;&#20173;&#28982;&#21487;&#20197;&#25511;&#21046;SDP&#35299;&#20915;&#26041;&#26696;&#19982;&#22122;&#22768;&#21521;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study graph clustering in the Stochastic Block Model (SBM) in the presence of both large clusters and small, unrecoverable clusters. Previous approaches achieving exact recovery do not allow any small clusters of size $o(\sqrt{n})$, or require a size gap between the smallest recovered cluster and the largest non-recovered cluster. We provide an algorithm based on semidefinite programming (SDP) which removes these requirements and provably recovers large clusters regardless of the remaining cluster sizes. Mid-sized clusters pose unique challenges to the analysis, since their proximity to the recovery threshold makes them highly sensitive to small noise perturbations and precludes a closed-form candidate solution. We develop novel techniques, including a leave-one-out-style argument which controls the correlation between SDP solutions and noise vectors even when the removal of one row of noise can drastically change the SDP solution. We also develop improved eigenvalue perturbation bo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#24046;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#31163;&#25955;&#20998;&#24067;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#31163;&#25955;&#19988;&#20445;&#25345;&#24230;&#37327;&#30340;&#26144;&#23556;&#65292;&#32780;&#19981;&#38656;&#35201;&#36830;&#32493;&#23884;&#20837;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#36830;&#32493;&#23884;&#20837;&#27969;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#26356;&#21487;&#38752;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2308.15613</link><description>&lt;p&gt;
&#28151;&#21512;&#26041;&#24046;&#27969;&#29992;&#20110;&#31163;&#25955;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Mixed Variational Flows for Discrete Variables. (arXiv:2308.15613v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#24046;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#31163;&#25955;&#20998;&#24067;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#31163;&#25955;&#19988;&#20445;&#25345;&#24230;&#37327;&#30340;&#26144;&#23556;&#65292;&#32780;&#19981;&#38656;&#35201;&#36830;&#32493;&#23884;&#20837;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#36830;&#32493;&#23884;&#20837;&#27969;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#26356;&#21487;&#38752;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#27969;&#20801;&#35768;&#20174;&#20107;&#32773;&#23398;&#20064;&#22797;&#26434;&#30340;&#36830;&#32493;&#20998;&#24067;&#65292;&#20294;&#26159;&#36817;&#20284;&#31163;&#25955;&#20998;&#24067;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#30446;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#23558;&#31163;&#25955;&#30446;&#26631;&#23884;&#20837;&#36830;&#32493;&#31354;&#38388;&#20013;-&#36890;&#24120;&#26159;&#36890;&#36807;&#36830;&#32493;&#26494;&#24347;&#25110;&#21435;&#37327;&#21270;-&#28982;&#21518;&#24212;&#29992;&#36830;&#32493;&#27969;&#21160;&#12290;&#36825;&#20123;&#26041;&#27861;&#28041;&#21450;&#19968;&#20010;&#21487;&#33021;&#26080;&#27861;&#25429;&#25417;&#21040;&#21407;&#22987;&#31163;&#25955;&#30446;&#26631;&#30340;&#26367;&#20195;&#30446;&#26631;&#65292;&#21487;&#33021;&#20855;&#26377;&#20559;&#20506;&#25110;&#19981;&#31283;&#23450;&#30340;&#26799;&#24230;&#65292;&#24182;&#19988;&#21487;&#33021;&#20250;&#21019;&#24314;&#19968;&#20010;&#22256;&#38590;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#38024;&#23545;&#31163;&#25955;&#20998;&#24067;&#30340;&#21464;&#20998;&#27969;&#26063;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36830;&#32493;&#23884;&#20837;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20445;&#25345;&#24230;&#37327;&#30340;&#31163;&#25955;&#21487;&#36870;&#26144;&#23556;&#65292;&#20351;&#31163;&#25955;&#30446;&#26631;&#20445;&#25345;&#19981;&#21464;&#65292;&#28982;&#21518;&#22522;&#20110;&#35813;&#26144;&#23556;&#21019;&#24314;&#20102;&#19968;&#20010;&#28151;&#21512;&#21464;&#20998;&#27969;(MAD Mix)&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25193;&#23637;&#65292;&#29992;&#20110;&#22788;&#29702;&#32852;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;MAD Mix&#20135;&#29983;&#20102;&#27604;&#36830;&#32493;&#23884;&#20837;&#27969;&#26356;&#21487;&#38752;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational flows allow practitioners to learn complex continuous distributions, but approximating discrete distributions remains a challenge. Current methodologies typically embed the discrete target in a continuous space - usually via continuous relaxation or dequantization - and then apply a continuous flow. These approaches involve a surrogate target that may not capture the original discrete target, might have biased or unstable gradients, and can create a difficult optimization problem. In this work, we develop a variational flow family for discrete distributions without any continuous embedding. First, we develop a measure-preserving and discrete (MAD) invertible map that leaves the discrete target invariant, and then create a mixed variational flow (MAD Mix) based on that map. We also develop an extension to MAD Mix that handles joint discrete and continuous models. Our experiments suggest that MAD Mix produces more reliable approximations than continuous-embedding flows while 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#23637;ACD&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#20197;&#20998;&#20301;&#25968;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#23545;&#25968;&#23545;&#31216;&#20998;&#24067;&#65292;&#21487;&#20197;&#23545;&#19981;&#21516;&#30340;&#30334;&#20998;&#20301;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#19978;&#20351;&#29992;&#30340;&#22343;&#20540;&#65288;&#25110;&#20013;&#20301;&#25968;&#65289;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2308.15571</link><description>&lt;p&gt;
&#21442;&#25968;&#21270;&#20998;&#20301;&#25968;&#33258;&#22238;&#24402;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#27169;&#22411;&#21450;&#20854;&#22312;&#26085;&#20869;&#39118;&#38505;&#20215;&#20540;&#19978;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parametric quantile autoregressive conditional duration models with application to intraday value-at-risk. (arXiv:2308.15571v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25193;&#23637;ACD&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#20197;&#20998;&#20301;&#25968;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#23545;&#25968;&#23545;&#31216;&#20998;&#24067;&#65292;&#21487;&#20197;&#23545;&#19981;&#21516;&#30340;&#30334;&#20998;&#20301;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#19978;&#20351;&#29992;&#30340;&#22343;&#20540;&#65288;&#25110;&#20013;&#20301;&#25968;&#65289;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#39057;&#37329;&#34701;&#36164;&#20135;&#20132;&#26131;&#25968;&#25454;&#30340;&#24314;&#27169;&#19968;&#30452;&#26159;&#32479;&#35745;&#23398;&#23478;&#21644;&#35745;&#37327;&#32463;&#27982;&#23398;&#23478;&#24863;&#20852;&#36259;&#30340;&#39046;&#22495;&#65292;&#23588;&#20854;&#26159;&#23545;&#37329;&#34701;&#25345;&#32493;&#26102;&#38388;&#26102;&#38388;&#24207;&#21015;&#30340;&#20998;&#26512;&#12290;&#33258;&#22238;&#24402;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#65288;ACD&#65289;&#27169;&#22411;&#19968;&#30452;&#26159;&#24314;&#27169;&#37329;&#34701;&#20132;&#26131;&#25968;&#25454;&#30340;&#20027;&#35201;&#24037;&#20855;&#65292;&#20854;&#20013;&#25345;&#32493;&#26102;&#38388;&#36890;&#24120;&#23450;&#20041;&#20026;&#20004;&#20010;&#36830;&#32493;&#20107;&#20214;&#20043;&#38388;&#30340;&#26102;&#38388;&#38388;&#38548;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20197;&#26102;&#21464;&#22343;&#20540;&#65288;&#25110;&#20013;&#20301;&#25968;&#65289;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#30340;&#24418;&#24335;&#36827;&#34892;&#35268;&#23450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;ACD&#27169;&#22411;&#30340;&#26032;&#25193;&#23637;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#20197;&#20998;&#20301;&#25968;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#23545;&#25968;&#23545;&#31216;&#20998;&#24067;&#12290;&#25152;&#25552;&#20986;&#30340;&#20998;&#20301;&#25968;&#23545;&#25968;&#23545;&#31216;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#33258;&#22238;&#24402;&#27169;&#22411;&#20801;&#35768;&#25105;&#20204;&#23545;&#19981;&#21516;&#30340;&#30334;&#20998;&#20301;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#19978;&#20351;&#29992;&#30340;&#22343;&#20540;&#65288;&#25110;&#20013;&#20301;&#25968;&#65289;&#26465;&#20214;&#25345;&#32493;&#26102;&#38388;&#12290;&#25105;&#20204;&#24320;&#23637;&#20102;&#23545;&#20110;&#29702;&#35770;&#24615;&#36136;&#21644;&#23454;&#38469;&#38382;&#39064;&#65288;&#22914;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#65289;&#30340;&#28145;&#20837;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
The modeling of high-frequency data that qualify financial asset transactions has been an area of relevant interest among statisticians and econometricians -- above all, the analysis of time series of financial durations. Autoregressive conditional duration (ACD) models have been the main tool for modeling financial transaction data, where duration is usually defined as the time interval between two successive events. These models are usually specified in terms of a time-varying mean (or median) conditional duration. In this paper, a new extension of ACD models is proposed which is built on the basis of log-symmetric distributions reparametrized by their quantile. The proposed quantile log-symmetric conditional duration autoregressive model allows us to model different percentiles instead of the traditionally used conditional mean (or median) duration. We carry out an in-depth study of theoretical properties and practical issues, such as parameter estimation using maximum likelihood me
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#39044;&#26399;&#36827;&#29699;&#27169;&#22411;&#30340;&#20840;&#23616;&#35299;&#37322;&#65288;&#20171;&#20110;&#26412;&#22320;&#21644;&#20840;&#23616;&#20043;&#38388;&#30340;&#35299;&#37322;&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#32858;&#21512;&#29256;&#26412;&#30340;SHAP&#20540;&#21644;&#37096;&#20998;&#20381;&#36182;&#20989;&#25968;&#65292;&#21487;&#20197;&#23545;&#22242;&#38431;&#21644;&#29699;&#21592;&#27700;&#24179;&#36827;&#34892;&#32489;&#25928;&#20998;&#26512;&#21644;&#30693;&#35782;&#25552;&#21462;&#12290;</title><link>http://arxiv.org/abs/2308.15559</link><description>&lt;p&gt;
&#36275;&#29699;&#20013;&#39044;&#26399;&#36827;&#29699;&#27169;&#22411;&#30340;&#20840;&#23616;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Glocal Explanations of Expected Goal Models in Soccer. (arXiv:2308.15559v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#39044;&#26399;&#36827;&#29699;&#27169;&#22411;&#30340;&#20840;&#23616;&#35299;&#37322;&#65288;&#20171;&#20110;&#26412;&#22320;&#21644;&#20840;&#23616;&#20043;&#38388;&#30340;&#35299;&#37322;&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#32858;&#21512;&#29256;&#26412;&#30340;SHAP&#20540;&#21644;&#37096;&#20998;&#20381;&#36182;&#20989;&#25968;&#65292;&#21487;&#20197;&#23545;&#22242;&#38431;&#21644;&#29699;&#21592;&#27700;&#24179;&#36827;&#34892;&#32489;&#25928;&#20998;&#26512;&#21644;&#30693;&#35782;&#25552;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#26399;&#36827;&#29699;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#36890;&#24120;&#26377;&#38480;&#65292;&#23588;&#20854;&#26159;&#22312;&#20351;&#29992;&#40657;&#30418;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#26102;&#12290;&#38543;&#30528;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#30340;&#20986;&#29616;&#65292;&#21487;&#20197;&#22686;&#24378;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#65292;&#24182;&#20174;&#21333;&#20010;&#35266;&#23519;&#25110;&#25152;&#26377;&#35266;&#23519;&#20013;&#25552;&#21462;&#25551;&#36848;&#24615;&#30693;&#35782;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#39046;&#22495;&#20013;&#65292;&#35299;&#37322;&#29305;&#23450;&#32676;&#20307;&#35266;&#23519;&#30340;&#40657;&#30418;&#27169;&#22411;&#21487;&#33021;&#26356;&#26377;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#20351;&#29992;SHAP&#20540;&#21644;&#37096;&#20998;&#20381;&#36182;&#20989;&#25968;&#30340;&#32858;&#21512;&#29256;&#26412;&#65292;&#24341;&#20837;&#39044;&#26399;&#36827;&#29699;&#27169;&#22411;&#30340;&#20840;&#23616;&#35299;&#37322;&#65288;&#20171;&#20110;&#26412;&#22320;&#21644;&#20840;&#23616;&#20043;&#38388;&#30340;&#35299;&#37322;&#65289;&#26469;&#23454;&#29616;&#23545;&#22242;&#38431;&#21644;&#29699;&#21592;&#27700;&#24179;&#30340;&#32489;&#25928;&#20998;&#26512;&#12290;&#36825;&#26679;&#21487;&#20197;&#20174;&#39044;&#26399;&#36827;&#29699;&#27169;&#22411;&#20013;&#25552;&#21462;&#19982;&#29699;&#21592;&#25110;&#29699;&#38431;&#30456;&#20851;&#30340;&#30693;&#35782;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21333;&#20010;&#23556;&#38376;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#26469;&#35828;&#26126;&#32858;&#21512;SHAP&#20540;&#21644;&#32858;&#21512;&#20989;&#25968;&#30340;&#26377;&#29992;&#24615;&#12290;&#26412;&#25991;&#26368;&#21518;&#23545;&#36825;&#20123;&#35299;&#37322;&#30340;&#28508;&#21147;&#36827;&#34892;&#20102;&#35780;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The expected goal models have gained popularity, but their interpretability is often limited, especially when trained using black-box methods. Explainable artificial intelligence tools have emerged to enhance model transparency and extract descriptive knowledge for a single observation or for all observations. However, explaining black-box models for a specific group of observations may be more useful in some domains. This paper introduces the glocal explanations (between local and global levels) of the expected goal models to enable performance analysis at the team and player levels by proposing the use of aggregated versions of the SHAP values and partial dependence profiles. This allows knowledge to be extracted from the expected goal model for a player or team rather than just a single shot. In addition, we conducted real-data applications to illustrate the usefulness of aggregated SHAP and aggregated profiles. The paper concludes with remarks on the potential of these explanations
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20005;&#26684;&#25512;&#24191;&#30340;&#20256;&#32479;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#21363;&#20013;&#20171;&#21453;&#39304;&#19979;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI-MF&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#20013;&#20171;&#32773;&#26469;&#27169;&#25311;&#19968;&#20123;&#23454;&#38469;&#20915;&#31574;&#38382;&#39064;&#65292;&#22914;&#31163;&#32447;&#23398;&#20064;&#12289;&#37096;&#20998;&#21487;&#25511;&#29615;&#22659;&#21644;&#20154;&#31867;&#21453;&#39304;&#12290;</title><link>http://arxiv.org/abs/2308.15552</link><description>&lt;p&gt;
&#32431;&#25506;&#32034;&#19979;&#30340;&#20013;&#20171;&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Pure Exploration under Mediators' Feedback. (arXiv:2308.15552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20005;&#26684;&#25512;&#24191;&#30340;&#20256;&#32479;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#21363;&#20013;&#20171;&#21453;&#39304;&#19979;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI-MF&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#20013;&#20171;&#32773;&#26469;&#27169;&#25311;&#19968;&#20123;&#23454;&#38469;&#20915;&#31574;&#38382;&#39064;&#65292;&#22914;&#31163;&#32447;&#23398;&#20064;&#12289;&#37096;&#20998;&#21487;&#25511;&#29615;&#22659;&#21644;&#20154;&#31867;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#26159;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#26694;&#26550;&#65292;&#27599;&#19968;&#27493;&#20132;&#20114;&#20013;&#23398;&#20064;&#32773;&#36873;&#25321;&#19968;&#20010;&#33218;&#24182;&#35266;&#23519;&#19968;&#20010;&#38543;&#26426;&#22238;&#25253;&#12290;&#22312;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#20934;&#30830;&#21644;&#39640;&#25928;&#22320;&#25214;&#21040;&#26368;&#20248;&#33218;&#65292;&#21363;&#20855;&#26377;&#26368;&#39640;&#26399;&#26395;&#22238;&#25253;&#30340;&#33218;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;BAI&#38382;&#39064;&#30340;&#39034;&#24207;&#20132;&#20114;&#21327;&#35758;&#65292;&#21363;&#23398;&#20064;&#32773;&#22312;&#27599;&#19968;&#36718;&#20013;&#23545;&#36873;&#25321;&#30340;&#33218;&#20855;&#26377;&#23436;&#20840;&#25511;&#21046;&#26435;&#65292;&#26080;&#27861;&#26377;&#25928;&#22320;&#27169;&#25311;&#19968;&#20123;&#20540;&#24471;&#20851;&#27880;&#30340;&#20915;&#31574;&#38382;&#39064;&#65288;&#20363;&#22914;&#65292;&#31163;&#32447;&#23398;&#20064;&#65292;&#37096;&#20998;&#21487;&#25511;&#29615;&#22659;&#21644;&#20154;&#31867;&#21453;&#39304;&#65289;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20005;&#26684;&#25512;&#24191;&#30340;&#20256;&#32479;BAI&#38382;&#39064;&#65292;&#31216;&#20043;&#20026;&#20013;&#20171;&#21453;&#39304;&#19979;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#65288;BAI-MF&#65289;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23398;&#20064;&#32773;&#21487;&#20197;&#35775;&#38382;&#19968;&#32452;&#20013;&#20171;&#32773;&#30340;&#24773;&#20917;&#65292;&#27599;&#20010;&#20013;&#20171;&#32773;&#37117;&#36873;&#25321;&#35201;&#25289;&#21160;&#30340;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic multi-armed bandits are a sequential-decision-making framework, where, at each interaction step, the learner selects an arm and observes a stochastic reward. Within the context of best-arm identification (BAI) problems, the goal of the agent lies in finding the optimal arm, i.e., the one with highest expected reward, as accurately and efficiently as possible. Nevertheless, the sequential interaction protocol of classical BAI problems, where the agent has complete control over the arm being pulled at each round, does not effectively model several decision-making problems of interest (e.g., off-policy learning, partially controllable environments, and human feedback). For this reason, in this work, we propose a novel strict generalization of the classical BAI problem that we refer to as best-arm identification under mediators' feedback (BAI-MF). More specifically, we consider the scenario in which the learner has access to a set of mediators, each of which selects the arms on 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#37319;&#26679;&#30340;&#26041;&#27861;&#25913;&#36827;&#20102;&#22823;&#25968;&#25454;&#38598;&#19979;t-SNE&#23884;&#20837;&#30340;&#36136;&#37327;&#21644;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.15513</link><description>&lt;p&gt;
&#35843;&#25972;&#22256;&#24785;&#24230;&#24182;&#35745;&#31639;&#22522;&#20110;&#37319;&#26679;&#30340;t-SNE&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Tuning the perplexity for and computing sampling-based t-SNE embeddings. (arXiv:2308.15513v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#37319;&#26679;&#30340;&#26041;&#27861;&#25913;&#36827;&#20102;&#22823;&#25968;&#25454;&#38598;&#19979;t-SNE&#23884;&#20837;&#30340;&#36136;&#37327;&#21644;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#24120;&#29992;&#30340;&#31649;&#36947;&#21033;&#29992;&#20108;&#32500;&#21487;&#35270;&#21270;&#65292;&#20363;&#22914;&#36890;&#36807;t&#20998;&#24067;&#37051;&#36817;&#38543;&#26426;&#23884;&#20837;&#65288;t-SNE&#65289;&#12290;&#20294;&#22312;&#22788;&#29702;&#22823;&#25968;&#25454;&#38598;&#26102;&#65292;&#24212;&#29992;&#36825;&#20123;&#21487;&#35270;&#21270;&#25216;&#26415;&#20250;&#29983;&#25104;&#27425;&#20248;&#30340;&#23884;&#20837;&#65292;&#22240;&#20026;&#36229;&#21442;&#25968;&#19981;&#36866;&#29992;&#20110;&#22823;&#25968;&#25454;&#12290;&#23558;&#36825;&#20123;&#21442;&#25968;&#22686;&#21152;&#36890;&#24120;&#19981;&#36215;&#20316;&#29992;&#65292;&#22240;&#20026;&#35745;&#31639;&#23545;&#20110;&#23454;&#38469;&#24037;&#20316;&#27969;&#31243;&#26469;&#35828;&#22826;&#26114;&#36149;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#22522;&#20110;&#37319;&#26679;&#30340;&#23884;&#20837;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24517;&#39035;&#35880;&#24910;&#36873;&#25321;&#36229;&#21442;&#25968;&#65292;&#21462;&#20915;&#20110;&#37319;&#26679;&#29575;&#21644;&#39044;&#26399;&#30340;&#26368;&#32456;&#23884;&#20837;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22914;&#20309;&#21152;&#36895;&#35745;&#31639;&#24182;&#25552;&#39640;&#23884;&#20837;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Widely used pipelines for the analysis of high-dimensional data utilize two-dimensional visualizations. These are created, e.g., via t-distributed stochastic neighbor embedding (t-SNE). When it comes to large data sets, applying these visualization techniques creates suboptimal embeddings, as the hyperparameters are not suitable for large data. Cranking up these parameters usually does not work as the computations become too expensive for practical workflows. In this paper, we argue that a sampling-based embedding approach can circumvent these problems. We show that hyperparameters must be chosen carefully, depending on the sampling rate and the intended final embedding. Further, we show how this approach speeds up the computation and increases the quality of the embeddings.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#21453;&#38382;&#39064;&#20013;&#24212;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#21644;&#36817;&#20284;&#35745;&#31639;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#22797;&#26434;&#30340;&#21453;&#38382;&#39064;&#65292;&#24182;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.15492</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21453;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Learning and Bayesian inference for Inverse Problems. (arXiv:2308.15492v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15492
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#21453;&#38382;&#39064;&#20013;&#24212;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#21644;&#36817;&#20284;&#35745;&#31639;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#22797;&#26434;&#30340;&#21453;&#38382;&#39064;&#65292;&#24182;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#38382;&#39064;&#22312;&#20219;&#20309;&#38388;&#25509;&#27979;&#37327;&#30340;&#24773;&#20917;&#19979;&#37117;&#20250;&#20986;&#29616;&#12290;&#30001;&#20110;&#36890;&#24120;&#24773;&#20917;&#19979;&#23427;&#20204;&#26159;&#30149;&#24577;&#30340;&#65292;&#20026;&#20102;&#24471;&#21040;&#20196;&#20154;&#28385;&#24847;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#38656;&#35201;&#20808;&#26377;&#20808;&#39564;&#30693;&#35782;&#12290;&#32463;&#20856;&#26041;&#27861;&#21253;&#25324;&#19981;&#21516;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#21644;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#30001;&#20110;&#36825;&#20123;&#26041;&#27861;&#38656;&#35201;&#22823;&#37327;&#30340;&#27491;&#21521;&#21644;&#21453;&#21521;&#35745;&#31639;&#65292;&#23588;&#20854;&#26159;&#24403;&#27491;&#21521;&#25110;&#29983;&#25104;&#27169;&#22411;&#22797;&#26434;&#19988;&#20284;&#28982;&#20989;&#25968;&#30340;&#35780;&#20272;&#38750;&#24120;&#26114;&#36149;&#26102;&#65292;&#35745;&#31639;&#25104;&#26412;&#23601;&#20250;&#21464;&#39640;&#12290;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#21644;&#36817;&#20284;&#35745;&#31639;&#21487;&#20197;&#38750;&#24120;&#26377;&#24110;&#21161;&#12290;&#20294;&#26159;&#65292;&#20026;&#20102;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#38656;&#35201;&#20808;&#20102;&#35299;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#65292;&#28982;&#21518;&#20877;&#30475;&#22914;&#20309;&#23558;&#20854;&#29992;&#20110;&#21453;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#37325;&#28857;&#20851;&#27880;&#31070;&#32463;&#32593;&#32476;&#12289;&#28145;&#24230;&#23398;&#20064;&#65292;&#29305;&#21035;&#26159;&#36866;&#29992;&#20110;&#21453;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12290;&#25105;&#20204;&#39318;&#20808;&#35814;&#32454;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#36817;&#20284;&#35745;&#31639;&#19982;&#25351;&#25968;&#26063;&#30340;&#26041;&#27861;&#65292;&#28982;&#21518;&#20877;&#30475;&#22914;&#20309;&#23558;&#20854;&#24212;&#29992;&#20110;&#21453;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse problems arise anywhere we have indirect measurement. As, in general they are ill-posed, to obtain satisfactory solutions for them needs prior knowledge. Classically, different regularization methods and Bayesian inference based methods have been proposed. As these methods need a great number of forward and backward computations, they become costly in computation, in particular, when the forward or generative models are complex and the evaluation of the likelihood becomes very costly. Using Deep Neural Network surrogate models and approximate computation can become very helpful. However, accounting for the uncertainties, we need first understand the Bayesian Deep Learning and then, we can see how we can use them for inverse problems. In this work, we focus on NN, DL and more specifically the Bayesian DL particularly adapted for inverse problems. We first give details of Bayesian DL approximate computations with exponential families, then we will see how we can use them for inve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximal&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32473;&#23450;&#30340;&#28508;&#21183;&#20989;&#25968;&#30830;&#23450;&#24615;&#22320;&#36827;&#34892;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#21644;&#36895;&#24230;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.14945</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximals&#23454;&#29616;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Noise-Free Sampling Algorithms via Regularized Wasserstein Proximals. (arXiv:2308.14945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27491;&#21017;&#21270;Wasserstein Proximal&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#22122;&#22768;&#30340;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32473;&#23450;&#30340;&#28508;&#21183;&#20989;&#25968;&#30830;&#23450;&#24615;&#22320;&#36827;&#34892;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#25552;&#20379;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#21644;&#36895;&#24230;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#30001;&#28508;&#21183;&#20989;&#25968;&#25511;&#21046;&#30340;&#20998;&#24067;&#25277;&#26679;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26174;&#24335;&#30340;&#22522;&#20110;&#35780;&#20998;&#30340;&#30830;&#23450;&#24615;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#20351;&#24471;&#31890;&#23376;&#30340;&#28436;&#21270;&#21464;&#20026;&#30830;&#23450;&#24615;&#30340;&#65292;&#32780;&#19981;&#26159;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#28436;&#21270;&#12290;&#35780;&#20998;&#39033;&#30001;&#27491;&#21017;&#21270;&#30340;Wasserstein proximal&#20197;&#38381;&#21512;&#24418;&#24335;&#32473;&#20986;&#65292;&#20351;&#29992;&#37319;&#26679;&#26469;&#36817;&#20284;&#26680;&#21367;&#31215;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#24182;&#19988;&#19982;&#26410;&#35843;&#25972;Langevin&#31639;&#27861;&#21644;Metropolis&#35843;&#25972;Langevin&#31639;&#27861;&#30456;&#27604;&#65292;&#26174;&#31034;&#20102;&#39640;&#26031;&#20998;&#24067;&#30340;&#28151;&#21512;&#26102;&#38388;&#36793;&#30028;&#30340;&#25913;&#21892;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#20108;&#27425;&#28508;&#21183;&#20989;&#25968;&#27599;&#27425;&#36845;&#20195;&#30340;&#20998;&#24067;&#30340;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#65292;&#34920;&#24449;&#20102;&#26041;&#24046;&#38477;&#20302;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#31890;&#23376;&#30340;&#34892;&#20026;&#26159;&#26377;&#32452;&#32455;&#30340;&#65292;&#20301;&#20110;&#28508;&#21183;&#30340;&#31561;&#20540;&#32447;&#19978;&#12290;&#27492;&#22806;&#65292;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling from a distribution governed by a potential function. This work proposes an explicit score-based MCMC method that is deterministic, resulting in a deterministic evolution for particles rather than a stochastic differential equation evolution. The score term is given in closed form by a regularized Wasserstein proximal, using a kernel convolution that is approximated by sampling. We demonstrate fast convergence on various problems and show improved dimensional dependence of mixing time bounds for the case of Gaussian distributions compared to the unadjusted Langevin algorithm (ULA) and the Metropolis-adjusted Langevin algorithm (MALA). We additionally derive closed form expressions for the distributions at each iterate for quadratic potential functions, characterizing the variance reduction. Empirical results demonstrate that the particles behave in an organized manner, lying on level set contours of the potential. Moreover, the posterior mean estimat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2308.12767</link><description>&lt;p&gt;
&#20851;&#20110;&#24179;&#22343;&#23884;&#20837;&#29992;&#20110;&#29289;&#21697;&#25512;&#33616;&#30340;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Consistency of Average Embeddings for Item Recommendation. (arXiv:2308.12767v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12767
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#33616;&#31995;&#32479;&#20013;&#24179;&#22343;&#23884;&#20837;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#34913;&#37327;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#23884;&#20837;&#22312;&#25512;&#33616;&#20013;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#36827;&#19968;&#27493;&#25913;&#36827;&#29616;&#23454;&#19990;&#30028;&#23884;&#20837;&#25552;&#20379;&#20102;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#20570;&#27861;&#26159;&#23558;&#29289;&#21697;&#23884;&#20837;&#36827;&#34892;&#24179;&#22343;&#20197;&#22312;&#21516;&#19968;&#23884;&#20837;&#31354;&#38388;&#20013;&#20195;&#34920;&#29992;&#25143;&#25110;&#26356;&#39640;&#32423;&#30340;&#27010;&#24565;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#20570;&#27861;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26399;&#26395;&#31934;&#24230;&#20998;&#25968;&#65292;&#29992;&#20110;&#34913;&#37327;&#24179;&#22343;&#23884;&#20837;&#19982;&#20854;&#26500;&#24314;&#25152;&#20351;&#29992;&#30340;&#29289;&#21697;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#38543;&#21518;&#22312;&#20855;&#26377;&#29305;&#23450;&#20551;&#35774;&#30340;&#29702;&#35770;&#29615;&#22659;&#21644;&#26469;&#33258;&#38899;&#20048;&#27969;&#23186;&#20307;&#26381;&#21153;&#30340;&#30495;&#23454;&#25968;&#25454;&#19978;&#20998;&#26512;&#20102;&#35813;&#20998;&#25968;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#21450;&#20854;&#32463;&#39564;&#34920;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24378;&#35843;&#20102;&#29616;&#23454;&#19990;&#30028;&#30340;&#24179;&#22343;&#20540;&#22312;&#25512;&#33616;&#20013;&#30340;&#19968;&#33268;&#24615;&#36739;&#20302;&#65292;&#20026;&#26410;&#26469;&#30740;&#31350;&#26356;&#22909;&#22320;&#23558;&#29616;&#23454;&#19990;&#30028;&#30340;&#23884;&#20837;&#19982;&#25105;&#20204;&#29702;&#35770;&#29615;&#22659;&#30340;&#20551;&#35774;&#30456;&#19968;&#33268;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
A prevalent practice in recommender systems consists of averaging item embeddings to represent users or higher-level concepts in the same embedding space. This paper investigates the relevance of such a practice. For this purpose, we propose an expected precision score, designed to measure the consistency of an average embedding relative to the items used for its construction. We subsequently analyze the mathematical expression of this score in a theoretical setting with specific assumptions, as well as its empirical behavior on real-world data from music streaming services. Our results emphasize that real-world averages are less consistent for recommendation, which paves the way for future research to better align real-world embeddings with assumptions from our theoretical setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27169;&#22411;&#39537;&#21160;&#30340;&#21452;&#37325;&#31639;&#27861;OptAug-CMDP&#65292;&#29992;&#20110;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#65292;&#35299;&#20915;&#20102;&#21407;&#20808;&#31639;&#27861;&#20013;&#23433;&#20840;&#24615;&#38382;&#39064;&#30340;&#32570;&#38519;&#65292;&#35777;&#26126;&#20102;&#20854;&#36951;&#25022;&#20540;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2306.07001</link><description>&lt;p&gt;
&#22522;&#20110;Lagrangian&#26041;&#27861;&#30340;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#26080;&#38656;&#21462;&#28040;&#24809;&#32602;&#30340;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Cancellation-Free Regret Bounds for Lagrangian Approaches in Constrained Markov Decision Processes. (arXiv:2306.07001v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27169;&#22411;&#39537;&#21160;&#30340;&#21452;&#37325;&#31639;&#27861;OptAug-CMDP&#65292;&#29992;&#20110;&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#65292;&#35299;&#20915;&#20102;&#21407;&#20808;&#31639;&#27861;&#20013;&#23433;&#20840;&#24615;&#38382;&#39064;&#30340;&#32570;&#38519;&#65292;&#35777;&#26126;&#20102;&#20854;&#36951;&#25022;&#20540;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32422;&#26463;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#26159;&#24314;&#27169;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#24120;&#35265;&#26041;&#27861;&#65292;&#20854;&#20013;&#23433;&#20840;&#30446;&#26631;&#30001;&#32422;&#26463;&#20989;&#25968;&#24314;&#27169;&#12290;&#22522;&#20110;Lagrangian&#30340;&#21452;&#37325;&#25110;&#21407;&#22987;&#21452;&#37325;&#31639;&#27861;&#20026;CMDPs&#20013;&#30340;&#23398;&#20064;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#24403;&#21069;&#24050;&#30693;&#30340;&#26377;&#38480;&#26102;&#38388;&#27573;&#36951;&#25022;&#30028;&#38480;&#20801;&#35768;&#8220;&#21462;&#28040;&#38169;&#35823;&#8221;&#65292;&#36825;&#24847;&#21619;&#30528;&#21487;&#20197;&#36890;&#36807;&#21478;&#19968;&#31181;&#22330;&#26223;&#20013;&#30340;&#20005;&#26684;&#32422;&#26463;&#28385;&#36275;&#26469;&#34917;&#20607;&#19968;&#20010;&#22330;&#26223;&#20013;&#30340;&#32422;&#26463;&#36829;&#35268;&#34892;&#20026;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27169;&#22411;&#39537;&#21160;&#30340;&#21452;&#37325;&#31639;&#27861;OptAug-CMDP&#65292;&#35813;&#31639;&#27861;&#21463;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#26041;&#27861;&#21551;&#21457;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#22320;&#25191;&#34892;&#26469;&#24357;&#34917;&#36825;&#31181;&#32570;&#38519;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;$K$&#20010;&#25506;&#32034;CMDP&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;$\tilde{O}(\sqrt{K})$&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#30446;&#26631;&#21644;&#32422;&#26463;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constrained Markov Decision Processes (CMDPs) are one of the common ways to model safe reinforcement learning problems, where the safety objectives are modeled by constraint functions. Lagrangian-based dual or primal-dual algorithms provide efficient methods for learning in CMDPs. For these algorithms, the currently known regret bounds in the finite-horizon setting allow for a \textit{cancellation of errors}; that is, one can compensate for a constraint violation in one episode with a strict constraint satisfaction in another episode. However, in practical applications, we do not consider such a behavior safe.  In this paper, we overcome this weakness by proposing a novel model-based dual algorithm \textsc{OptAug-CMDP} for tabular finite-horizon CMDPs. Our algorithm is motivated by the augmented Lagrangian method and can be performed efficiently. We show that during $K$ episodes of exploring the CMDP, our algorithm obtains a regret of $\tilde{O}(\sqrt{K})$ for both the objective and th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#36890;&#36947;&#30417;&#30563;&#23398;&#20064;&#30340;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#30828;&#20214;&#36866;&#24212;&#24615;&#30340;&#37327;&#23376;&#30005;&#36335;ansatzes&#29992;&#20316;&#21367;&#31215;&#26680;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#36890;&#36947;&#38388;&#20449;&#24687;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;QCNNs&#12290;</title><link>http://arxiv.org/abs/2305.18961</link><description>&lt;p&gt;
&#22810;&#36890;&#36947;&#30417;&#30563;&#23398;&#20064;&#30340;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Quantum Convolutional Neural Networks for Multi-Channel Supervised Learning. (arXiv:2305.18961v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22810;&#36890;&#36947;&#30417;&#30563;&#23398;&#20064;&#30340;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#30828;&#20214;&#36866;&#24212;&#24615;&#30340;&#37327;&#23376;&#30005;&#36335;ansatzes&#29992;&#20316;&#21367;&#31215;&#26680;&#65292;&#33021;&#22815;&#26377;&#25928;&#23398;&#20064;&#36890;&#36947;&#38388;&#20449;&#24687;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;QCNNs&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#21046;&#36896;&#20986;&#38750;&#24120;&#26377;&#29992;&#30340;&#24037;&#20855;&#21644;&#27169;&#22411;&#65292;&#37327;&#23376;&#35745;&#31639;&#20026;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25552;&#20379;&#21152;&#36895;&#30340;&#28508;&#21147;&#27491;&#22312;&#26085;&#30410;&#21463;&#21040;&#37325;&#35270;&#12290;&#29305;&#21035;&#26159;&#65292;&#30740;&#31350;&#29992;&#20110;&#22522;&#20110;&#22270;&#20687;&#26816;&#27979;&#20219;&#21153;&#30340;&#37327;&#23376;&#30005;&#36335;&#21462;&#20195;&#32463;&#20856;&#21367;&#31215;&#28388;&#27874;&#22120;&#20197;&#21033;&#29992;&#37327;&#23376;&#20248;&#21183;&#30340;&#23581;&#35797;&#65292;&#31216;&#20026;&#37327;&#23376;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;QCNNs&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#23581;&#35797;&#32570;&#20047;&#22788;&#29702;&#20855;&#26377;&#22810;&#20010;&#36890;&#36947;&#30340;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#22240;&#27492;&#21482;&#36866;&#29992;&#20110;&#30456;&#23545;&#31616;&#21333;&#30340;&#36755;&#20837;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#31181;&#30828;&#20214;&#36866;&#24212;&#24615;&#30340;&#37327;&#23376;&#30005;&#36335;ansatzes&#29992;&#20316;&#21367;&#31215;&#26680;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#25253;&#21578;&#30340;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#22312;&#28041;&#21450;&#22810;&#36890;&#36947;&#25968;&#25454;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;QCNNs&#12290;&#25105;&#20204;&#39044;&#35745;&#65292;&#36825;&#20123;&#23454;&#29616;&#26377;&#25928;&#23398;&#20064;&#36890;&#36947;&#38388;&#20449;&#24687;&#30340;&#33021;&#21147;&#23558;&#20801;&#35768;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#22312;&#22788;&#29702;&#29616;&#23454;&#20219;&#21153;&#26102;&#33719;&#24471;&#37325;&#22823;&#31361;&#30772;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the rapidly evolving field of machine learning continues to produce incredibly useful tools and models, the potential for quantum computing to provide speed up for machine learning algorithms is becoming increasingly desirable. In particular, quantum circuits in place of classical convolutional filters for image detection-based tasks are being investigated for the ability to exploit quantum advantage. However, these attempts, referred to as quantum convolutional neural networks (QCNNs), lack the ability to efficiently process data with multiple channels and therefore are limited to relatively simple inputs. In this work, we present a variety of hardware-adaptable quantum circuit ansatzes for use as convolutional kernels, and demonstrate that the quantum neural networks we report outperform existing QCNNs on classification tasks involving multi-channel data. We envision that the ability of these implementations to effectively learn inter-channel information will allow quantum machine
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26550;&#26500;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#34920;&#31034;&#36755;&#20837;&#36755;&#20986;&#21644;&#29366;&#24577;&#65292;&#20855;&#26377;&#21487;&#32553;&#25918;&#24615;&#12289;&#34920;&#36798;&#24615;&#12289;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2305.18415</link><description>&lt;p&gt;
&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Geometric Algebra Transformers. (arXiv:2305.18415v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26550;&#26500;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#34920;&#31034;&#36755;&#20837;&#36755;&#20986;&#21644;&#29366;&#24577;&#65292;&#20855;&#26377;&#21487;&#32553;&#25918;&#24615;&#12289;&#34920;&#36798;&#24615;&#12289;&#22810;&#21151;&#33021;&#24615;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#20309;&#25968;&#25454;&#38382;&#39064;&#28041;&#21450;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#26426;&#22120;&#20154;&#12289;&#21270;&#23398;&#21644;&#29289;&#29702;&#39046;&#22495;&#12290;&#36825;&#20123;&#25968;&#25454;&#21487;&#20197;&#37319;&#29992;&#35768;&#22810;&#24418;&#24335;&#65292;&#20363;&#22914;&#28857;&#12289;&#26041;&#21521;&#21521;&#37327;&#12289;&#24179;&#38754;&#25110;&#21464;&#25442;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#36824;&#27809;&#26377;&#19968;&#31181;&#21333;&#19968;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#22914;&#27492;&#22810;&#31181;&#20960;&#20309;&#31867;&#22411;, &#21516;&#26102;&#23562;&#37325;&#23427;&#20204;&#30340;&#23545;&#31216;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20960;&#20309;&#20195;&#25968;&#21464;&#25442;&#22120;&#65288;GATr&#65289;&#65292;&#19968;&#31181;&#29992;&#20110;&#20960;&#20309;&#25968;&#25454;&#30340;&#36890;&#29992;&#26550;&#26500;&#12290;GATr&#20351;&#29992;&#25237;&#24433;&#20960;&#20309;&#20195;&#25968;&#26469;&#34920;&#31034;&#36755;&#20837;&#12289;&#36755;&#20986;&#21644;&#38544;&#34255;&#29366;&#24577;&#65292;&#20854;&#25552;&#20379;&#24120;&#35265;&#20960;&#20309;&#23545;&#35937;&#30340;&#39640;&#25928;16&#32500;&#21521;&#37327;&#31354;&#38388;&#34920;&#31034;&#20197;&#21450;&#20316;&#29992;&#20110;&#23427;&#20204;&#30340;&#36816;&#31639;&#31526;&#12290;GATr&#26159;&#30456;&#23545;&#20110;E(3)&#65288;3D&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#23545;&#31216;&#32676;&#65289;&#31561;&#21464;&#30340;&#12290;&#20316;&#20026;&#21464;&#25442;&#22120;&#65292;GATr&#21487;&#25193;&#23637;&#12289;&#34920;&#36798;&#20016;&#23500;&#19988;&#22810;&#21151;&#33021;&#12290;&#22312;n&#20307;&#24314;&#27169;&#21644;&#26426;&#22120;&#20154;&#35268;&#21010;&#30340;&#23454;&#39564;&#20013;&#65292;GATr&#30456;&#23545;&#20110;&#38750;&#20960;&#20309;&#22522;&#32447;&#22343;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Problems involving geometric data arise in a variety of fields, including computer vision, robotics, chemistry, and physics. Such data can take numerous forms, such as points, direction vectors, planes, or transformations, but to date there is no single architecture that can be applied to such a wide variety of geometric types while respecting their symmetries. In this paper we introduce the Geometric Algebra Transformer (GATr), a general-purpose architecture for geometric data. GATr represents inputs, outputs, and hidden states in the projective geometric algebra, which offers an efficient 16-dimensional vector space representation of common geometric objects as well as operators acting on them. GATr is equivariant with respect to E(3), the symmetry group of 3D Euclidean space. As a transformer, GATr is scalable, expressive, and versatile. In experiments with n-body modeling and robotic planning, GATr shows strong improvements over non-geometric baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.18061</link><description>&lt;p&gt;
&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#25552;&#39640;&#36719;&#20214;&#36807;&#31243;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging Evolutionary Changes for Software Process Quality. (arXiv:2305.18061v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#36719;&#20214;&#24212;&#29992;&#24517;&#39035;&#19981;&#26029;&#28436;&#36827;&#25165;&#33021;&#20445;&#25345;&#30456;&#20851;&#24615;&#12290;&#20256;&#32479;&#30340;&#36719;&#20214;&#36136;&#37327;&#25511;&#21046;&#26041;&#27861;&#28041;&#21450;&#36719;&#20214;&#36136;&#37327;&#27169;&#22411;&#21644;&#25345;&#32493;&#30340;&#20195;&#30721;&#26816;&#26597;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#19982;&#26368;&#32456;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#20043;&#38388;&#23384;&#22312;&#24378;&#20851;&#32852;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#38388;&#25509;&#25552;&#39640;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#38656;&#35201;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24320;&#21457;&#36807;&#31243;&#30340;&#28436;&#36827;&#21464;&#21270;&#26469;&#25552;&#39640;&#36719;&#20214;&#36136;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.14683</link><description>&lt;p&gt;
&#35770;&#36827;&#21270;&#30952;&#38155;&#12289;&#24179;&#22374;&#26497;&#23567;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On progressive sharpening, flat minima and generalisation. (arXiv:2305.14683v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#25439;&#22833;&#26354;&#29575;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#29616;&#26377;&#30340;&#28145;&#24230;&#32593;&#32476;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#39057;&#35889;&#32463;&#39564;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#23558;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31995;&#21015;&#29702;&#35770;&#32467;&#26524;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#20551;&#35774;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#36827;&#21270;&#30952;&#38155;&#29616;&#35937;&#20197;&#21450;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#25551;&#36848;&#12290;&#23454;&#39564;&#35777;&#25454;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20027;&#24352;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new approach to understanding the relationship between loss curvature and generalisation in deep learning. Specifically, we use existing empirical analyses of the spectrum of deep network loss Hessians to ground an ansatz tying together the loss Hessian and the input-output Jacobian of a deep neural network. We then prove a series of theoretical results which quantify the degree to which the input-output Jacobian of a model approximates its Lipschitz norm over a data distribution, and deduce a novel generalisation bound in terms of the empirical Jacobian. We use our ansatz, together with our theoretical results, to give a new account of the recently observed progressive sharpening phenomenon, as well as the generalisation properties of flat minima. Experimental evidence is provided to validate our claims.
&lt;/p&gt;</description></item><item><title>RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.06767</link><description>&lt;p&gt;
RAFT: &#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#29992;&#20110;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06767
&lt;/p&gt;
&lt;p&gt;
RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#24191;&#27867;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#25968;&#25454;&#24102;&#26469;&#30340;&#38544;&#24335;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#26679;&#26412;&#12289;&#25197;&#26354;&#30340;&#32467;&#26524;&#21644;&#19981;&#20844;&#24179;&#65292;&#21487;&#33021;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#19982;&#20154;&#30340;&#20262;&#29702;&#21644;&#20559;&#22909;&#23545;&#40784;&#26159;&#30830;&#20445;&#23427;&#20204;&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#36127;&#36131;&#20219;&#21644;&#26377;&#25928;&#30340;&#37096;&#32626;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#37319;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288; RLHF&#65289;&#20316;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#25163;&#27573;&#12290;&#22312; RL &#31639;&#27861;&#30340;&#25351;&#23548;&#19979;&#65292;&#29992;&#20154;&#31867;&#21453;&#39304;&#25351;&#23548;&#30340;&#22870;&#21169;&#27169;&#22411;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292; RL &#31639;&#27861;&#30340;&#20302;&#25928;&#24615;&#21644;&#19981;&#31283;&#23450;&#24615;&#24120;&#24120;&#20250;&#23545;&#29983;&#25104;&#27169;&#22411;&#30340;&#25104;&#21151;&#23545;&#40784;&#20135;&#29983;&#37325;&#22823;&#38556;&#30861;&#65292;&#22240;&#27492;&#38656;&#35201;&#24320;&#21457;&#19968;&#31181;&#26356;&#20026;&#24378;&#22823;&#21644;&#31616;&#21270;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21363;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#65288; RAFT &#65289;&#65292;&#26088;&#22312;&#23545;&#40784;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#21270;&#30340;&#20302;&#31209;&#22810;&#20803;&#22238;&#24402;&#65292;&#36890;&#36807;&#37319;&#29992;&#22343;&#21248;&#37327;&#21270;&#19982;&#38543;&#26426;&#25238;&#21160;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#32422;&#26463;Lasso&#21644;&#27491;&#21017;&#21270;Lasso&#20272;&#35745;&#22120;&#65292;&#23454;&#29616;&#20102;&#26368;&#23567;&#26368;&#20248;&#29575;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#37327;&#21270;&#20165;&#23545;&#20056;&#27861;&#22240;&#23376;&#30053;&#26377;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.11197</link><description>&lt;p&gt;
&#37327;&#23376;&#21270;&#30340;&#20302;&#31209;&#22810;&#20803;&#22238;&#24402;&#19982;&#38543;&#26426;&#25238;&#21160;
&lt;/p&gt;
&lt;p&gt;
Quantized Low-Rank Multivariate Regression with Random Dithering. (arXiv:2302.11197v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11197
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#21270;&#30340;&#20302;&#31209;&#22810;&#20803;&#22238;&#24402;&#65292;&#36890;&#36807;&#37319;&#29992;&#22343;&#21248;&#37327;&#21270;&#19982;&#38543;&#26426;&#25238;&#21160;&#30340;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#32422;&#26463;Lasso&#21644;&#27491;&#21017;&#21270;Lasso&#20272;&#35745;&#22120;&#65292;&#23454;&#29616;&#20102;&#26368;&#23567;&#26368;&#20248;&#29575;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#37327;&#21270;&#20165;&#23545;&#20056;&#27861;&#22240;&#23376;&#30053;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#22810;&#20803;&#22238;&#24402;&#65288;LRMR&#65289;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#65292;&#23558;&#39640;&#24230;&#30456;&#20851;&#30340;&#20219;&#21153;&#20316;&#20026;&#20855;&#26377;&#20302;&#31209;&#20808;&#39564;&#30340;&#22810;&#21709;&#24212;&#22238;&#24402;&#38382;&#39064;&#36827;&#34892;&#32452;&#21512;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#21270;&#30340;LRMR&#65292;&#36825;&#26159;&#19968;&#31181;&#23454;&#38469;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#21709;&#24212;&#21644;/&#25110;&#21327;&#21464;&#37327;&#34987;&#31163;&#25955;&#21270;&#20026;&#26377;&#38480;&#30340;&#31934;&#24230;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20272;&#35745;&#22522;&#30784;&#31995;&#25968;&#30697;&#38453;&#12290;&#20026;&#20102;&#20351;&#33021;&#22815;&#23454;&#29616;&#20219;&#24847;&#23567;&#35823;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#25104;&#20026;&#21487;&#33021;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#22343;&#21248;&#37327;&#21270;&#19982;&#38543;&#26426;&#25238;&#21160;&#65292;&#21363;&#22312;&#37327;&#21270;&#20043;&#21069;&#21521;&#25968;&#25454;&#28155;&#21152;&#36866;&#24403;&#30340;&#38543;&#26426;&#22122;&#22768;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21709;&#24212;&#20351;&#29992;&#22343;&#21248;&#25238;&#21160;&#65292;&#21327;&#21464;&#37327;&#20351;&#29992;&#19977;&#35282;&#25238;&#21160;&#12290;&#22522;&#20110;&#37327;&#21270;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32422;&#26463;Lasso&#21644;&#27491;&#21017;&#21270;Lasso&#20272;&#35745;&#22120;&#65292;&#24182;&#25512;&#23548;&#20102;&#38750;&#28176;&#36817;&#24615;&#35823;&#24046;&#30028;&#12290;&#36890;&#36807;&#25238;&#21160;&#30340;&#24110;&#21161;&#65292;&#20272;&#35745;&#22120;&#23454;&#29616;&#20102;&#26368;&#23567;&#26368;&#20248;&#29575;&#65292;&#32780;&#37327;&#21270;&#20165;&#30053;&#24494;&#24694;&#21270;&#20102;&#20056;&#27861;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-rank multivariate regression (LRMR) is an important statistical learning model that combines highly correlated tasks as a multiresponse regression problem with low-rank priori on the coefficient matrix. In this paper, we study quantized LRMR, a practical setting where the responses and/or the covariates are discretized to finite precision. We focus on the estimation of the underlying coefficient matrix. To make consistent estimator that could achieve arbitrarily small error possible, we employ uniform quantization with random dithering, i.e., we add appropriate random noise to the data before quantization. Specifically, uniform dither and triangular dither are used for responses and covariates, respectively. Based on the quantized data, we propose the constrained Lasso and regularized Lasso estimators, and derive the non-asymptotic error bounds. With the aid of dithering, the estimators achieve minimax optimal rate, while quantization only slightly worsens the multiplicative factor
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2104.10751</link><description>&lt;p&gt;
&#20998;&#31867;&#35268;&#21017;&#29983;&#25104;&#65306;&#21487;&#25193;&#23637;&#24615;&#65292;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rule Generation for Classification: Scalability, Interpretability, and Fairness. (arXiv:2104.10751v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.10751
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#20855;&#26377;&#32422;&#26463;&#26465;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#65292;&#22240;&#27492;&#21487;&#25193;&#23637;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#25152;&#24471;&#23450;&#20215;&#23376;&#38382;&#39064;&#34987;&#35777;&#26126;&#26159;NP&#38590;&#38382;&#39064;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20915;&#31574;&#26641;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#19968;&#20010;&#20195;&#29702;&#23450;&#20215;&#23376;&#38382;&#39064;&#20197;&#21152;&#36895;&#12290;&#35813;&#26041;&#27861;&#36820;&#22238;&#19968;&#32452;&#35268;&#21017;&#20197;&#21450;&#23427;&#20204;&#30340;&#26368;&#20248;&#26435;&#37325;&#65292;&#25351;&#31034;&#27599;&#20010;&#35268;&#21017;&#23545;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#35268;&#21017;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#26469;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#23616;&#37096;&#35299;&#37322;&#24615;&#65292;&#24182;&#23558;&#20844;&#24179;&#24615;&#30340;&#19968;&#33324;&#20998;&#31163;&#20934;&#21017;&#25512;&#24191;&#21040;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#21644;&#31867;&#21035;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#26469;&#35814;&#32454;&#38416;&#36848;&#20854;&#19981;&#21516;&#26041;&#38754;&#12290;&#25152;&#25552;&#20986;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#23398;&#20064;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#36798;&#21040;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new rule-based optimization method for classification with constraints. The proposed method leverages column generation for linear programming, and hence, is scalable to large datasets. The resulting pricing subproblem is shown to be NP-Hard. We recourse to a decision tree-based heuristic and solve a proxy pricing subproblem for acceleration. The method returns a set of rules along with their optimal weights indicating the importance of each rule for learning. We address interpretability and fairness by assigning cost coefficients to the rules and introducing additional constraints. In particular, we focus on local interpretability and generalize separation criterion in fairness to multiple sensitive attributes and classes. We test the performance of the proposed methodology on a collection of datasets and present a case study to elaborate on its different aspects. The proposed rule-based learning method exhibits a good compromise between local interpretability and fairn
&lt;/p&gt;</description></item><item><title>Coagent Networks&#65288;&#20849;&#26234;&#32593;&#32476;&#65289;&#26159;&#25351;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#21327;&#20316;&#30340;&#38543;&#26426;&#20195;&#29702;&#32593;&#32476;&#12290;&#36825;&#31687;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#20849;&#26234;&#32593;&#32476;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#25191;&#34892;&#36335;&#24452;&#30340;&#24605;&#24819;&#65292;&#24182;&#36890;&#36807;&#36825;&#19968;&#24605;&#24819;&#23454;&#29616;&#20102;&#23545;&#31574;&#26799;&#24230;&#23450;&#29702;&#30340;&#31616;&#27905;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2001.10474</link><description>&lt;p&gt;
Coagent Networks&#20877;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Coagent Networks Revisited. (arXiv:2001.10474v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.10474
&lt;/p&gt;
&lt;p&gt;
Coagent Networks&#65288;&#20849;&#26234;&#32593;&#32476;&#65289;&#26159;&#25351;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#21327;&#20316;&#30340;&#38543;&#26426;&#20195;&#29702;&#32593;&#32476;&#12290;&#36825;&#31687;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#20849;&#26234;&#32593;&#32476;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#25191;&#34892;&#36335;&#24452;&#30340;&#24605;&#24819;&#65292;&#24182;&#36890;&#36807;&#36825;&#19968;&#24605;&#24819;&#23454;&#29616;&#20102;&#23545;&#31574;&#26799;&#24230;&#23450;&#29702;&#30340;&#31616;&#27905;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Coagent networks&#65288;&#20849;&#26234;&#32593;&#32476;&#65289;&#24418;&#24335;&#21270;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#21327;&#20316;&#20197;&#37319;&#21462;&#34892;&#21160;&#30340;&#38543;&#26426;&#20195;&#29702;&#32593;&#32476;&#30340;&#27010;&#24565;&#12290;&#20849;&#26234;&#32593;&#32476;&#30340;&#26174;&#33879;&#24212;&#29992;&#21253;&#25324;&#23618;&#27425;&#24378;&#21270;&#23398;&#20064;&#65288;HRL&#65289;&#30340;&#26041;&#27861;&#65292;&#20363;&#22914;&#20351;&#29992;&#36873;&#39033;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;HRL&#20195;&#29702;&#20013;&#20018;&#32852;&#22810;&#20010;&#38543;&#26426;&#32593;&#32476;&#24341;&#20837;&#19981;&#21516;&#23618;&#27425;&#30340;&#25277;&#35937;&#21160;&#20316;&#65292;&#26469;&#35299;&#20915;&#25506;&#32034;&#21033;&#29992;&#26435;&#34913;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#22312;&#20849;&#26234;&#32593;&#32476;&#20013;&#24418;&#24335;&#21270;&#25191;&#34892;&#35268;&#21017;&#12289;&#36890;&#36807;&#20849;&#26234;&#32593;&#32476;&#20013;&#25191;&#34892;&#36335;&#24452;&#30340;&#26032;&#39062;&#32780;&#30452;&#35266;&#30340;&#24605;&#24819;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#35270;&#35282;&#26469;&#25551;&#36848;&#35768;&#22810;&#19981;&#21516;&#30340;&#20363;&#23376;&#12290;&#22312;&#23618;&#27425;&#36873;&#39033;&#35780;&#35770;&#32773;&#26550;&#26500;&#20013;&#21463;&#21040;&#21442;&#25968;&#20849;&#20139;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20849;&#26234;&#32593;&#32476;&#29702;&#35770;&#65292;&#24182;&#20351;&#29992;&#25105;&#20204;&#30340;&#25191;&#34892;&#36335;&#24452;&#24605;&#24819;&#24471;&#21040;&#20102;&#23545;&#31574;&#26799;&#24230;&#23450;&#29702;&#30340;&#26356;&#31616;&#27905;&#35777;&#26126;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;&#21442;&#25968;&#20849;&#20139;&#20570;&#20986;&#20219;&#20309;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
Coagent networks formalize the concept of arbitrary networks of stochastic agents that collaborate to take actions in a reinforcement learning environment. Prominent examples of coagent networks in action include approaches to hierarchical reinforcement learning (HRL), such as those using options, which attempt to address the exploration exploitation trade-off by introducing abstract actions at different levels by sequencing multiple stochastic networks within the HRL agents. We first provide a unifying perspective on the many diverse examples that fall under coagent networks. We do so by formalizing the rules of execution in a coagent network, enabled by the novel and intuitive idea of execution paths in a coagent network. Motivated by parameter sharing in the hierarchical option-critic architecture, we revisit the coagent network theory and achieve a much shorter proof of the policy gradient theorem using our idea of execution paths, without any assumption on how parameters are share
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#33324;&#37319;&#26679;&#20998;&#24067;&#19979;&#30340;&#20302;&#31209;&#36857;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36890;&#29992;&#23792;&#20540;&#27010;&#24565;&#65292;&#25552;&#20379;&#20102;&#35777;&#26126;&#36857;&#22238;&#24402;&#37319;&#26679;&#31639;&#23376;&#24378;&#20984;&#24615;&#21644;&#33719;&#24471;&#38750;&#28176;&#36827;&#12289;&#36817;&#20046;&#26368;&#20248;&#30028;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#23558;&#35823;&#24046;&#30028;&#25193;&#23637;&#21040;&#20197;&#20132;&#21449;&#39564;&#35777;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/1904.08576</link><description>&lt;p&gt;
&#20851;&#20110;&#22312;&#19968;&#33324;&#37319;&#26679;&#20998;&#24067;&#19979;&#30340;&#20302;&#31209;&#36857;&#22238;&#24402;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Low-rank Trace Regression under General Sampling Distribution. (arXiv:1904.08576v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1904.08576
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#33324;&#37319;&#26679;&#20998;&#24067;&#19979;&#30340;&#20302;&#31209;&#36857;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#36890;&#29992;&#23792;&#20540;&#27010;&#24565;&#65292;&#25552;&#20379;&#20102;&#35777;&#26126;&#36857;&#22238;&#24402;&#37319;&#26679;&#31639;&#23376;&#24378;&#20984;&#24615;&#21644;&#33719;&#24471;&#38750;&#28176;&#36827;&#12289;&#36817;&#20046;&#26368;&#20248;&#30028;&#30340;&#26041;&#27861;&#12290;&#21516;&#26102;&#65292;&#23558;&#35823;&#24046;&#30028;&#25193;&#23637;&#21040;&#20197;&#20132;&#21449;&#39564;&#35777;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#31209;&#27491;&#21017;&#21270;&#22238;&#24402;&#30340;&#20984;&#26494;&#24347;&#25110;&#27491;&#21017;&#21270;&#38750;&#20984;&#20248;&#21270;&#26469;&#20272;&#35745;&#21442;&#25968;&#30697;&#38453;B*&#30340;&#36857;&#22238;&#24402;&#38382;&#39064;&#12290;&#24050;&#30693;&#36825;&#20123;&#20272;&#35745;&#22120;&#22312;&#23545;B*&#30340;&#31209;&#12289;&#19968;&#33268;&#24615;&#21644;&#23792;&#20540;&#24615;&#20551;&#35774;&#19979;&#28385;&#36275;&#36817;&#20046;&#26368;&#20248;&#30340;&#35823;&#24046;&#30028;&#12290;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#23545;B*&#30340;&#19968;&#31181;&#36890;&#29992;&#23792;&#20540;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#25552;&#20379;&#20102;&#35777;&#26126;&#36857;&#22238;&#24402;&#37319;&#26679;&#31639;&#23376;&#30340;&#21463;&#38480;&#24378;&#20984;&#24615;&#20197;&#21450;&#33719;&#24471;&#20272;&#35745;&#35823;&#24046;&#30340;&#38750;&#28176;&#36827;&#12289;&#36817;&#20046;&#26368;&#20248;&#30028;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#19982;&#29616;&#26377;&#25991;&#29486;&#31867;&#20284;&#65292;&#36825;&#20123;&#32467;&#26524;&#35201;&#27714;&#27491;&#21017;&#21270;&#21442;&#25968;&#39640;&#20110;&#26576;&#20010;&#29702;&#35770;&#19978;&#30340;&#38408;&#20540;&#65292;&#35813;&#38408;&#20540;&#21462;&#20915;&#20110;&#23454;&#36341;&#20013;&#21487;&#33021;&#26410;&#30693;&#30340;&#35266;&#27979;&#22122;&#22768;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23558;&#35823;&#24046;&#30028;&#25193;&#23637;&#21040;&#20197;&#20132;&#21449;&#39564;&#35777;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#24773;&#20917;&#12290;&#36825;&#20010;&#32467;&#26524;&#30340;&#37325;&#35201;&#24615;&#22312;&#20110;&#29616;&#26377;&#20851;&#20110;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#22120;&#30340;&#29702;&#35770;&#32467;&#26524;(Kale&#31561;)&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the trace regression when a matrix of parameters B* is estimated via the convex relaxation of a rank-regularized regression or via regularized non-convex optimization. It is known that these estimators satisfy near-optimal error bounds under assumptions on the rank, coherence, and spikiness of B*. We start by introducing a general notion of spikiness for B* that provides a generic recipe to prove the restricted strong convexity of the sampling operator of the trace regression and obtain near-optimal and non-asymptotic error bounds for the estimation error. Similar to the existing literature, these results require the regularization parameter to be above a certain theory-inspired threshold that depends on observation noise that may be unknown in practice. Next, we extend the error bounds to cases where the regularization parameter is chosen via cross-validation. This result is significant in that existing theoretical results on cross-validated estimators (Kale et
&lt;/p&gt;</description></item></channel></rss>