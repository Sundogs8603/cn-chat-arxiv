<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.09401</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#21160;&#26597;&#35810;&#30340;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback with Active Queries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#19982;&#20154;&#31867;&#21453;&#39304;&#30340;&#23545;&#40784;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#20013;&#20943;&#23569;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#20195;&#20215;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#23545;&#40784;&#65292;&#22312;&#26500;&#24314;&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#20013;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24403;&#21069;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#65292;&#20294;&#24448;&#24448;&#38656;&#35201;&#22823;&#37327;&#30340;&#20154;&#24037;&#26631;&#27880;&#20559;&#22909;&#25968;&#25454;&#65292;&#32780;&#36825;&#31181;&#25968;&#25454;&#25910;&#38598;&#36153;&#26102;&#36153;&#21147;&#12290;&#26412;&#25991;&#21463;&#21040;&#20027;&#21160;&#23398;&#20064;&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#36890;&#36807;&#25552;&#20986;&#26597;&#35810;&#25928;&#29575;&#39640;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#23545;&#40784;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19978;&#19979;&#25991;&#31454;&#20105;&#20108;&#33218;&#24378;&#30423;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#20027;&#21160;&#26597;&#35810;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;APPO&#65289;&#31639;&#27861;&#65292;&#20855;&#26377;$\tilde{O}(d^2/\Delta)$&#30340;&#36951;&#25022;&#30028;&#21644;$\tilde{O}(d^2/\Delta^2)$&#30340;&#26597;&#35810;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;$\Delta$&#26159;&#25152;&#26377;&#19978;&#19979;&#25991;&#20013;&#30340;&#27425;&#20248;&#24046;&#36317;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;ADPO&#65292;&#36825;&#26159;&#25105;&#20204;&#31639;&#27861;&#30340;&#23454;&#38469;&#29256;&#26412;&#65292;&#22522;&#20110;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09401v1 Announce Type: cross Abstract: Aligning large language models (LLM) with human preference plays a key role in building modern generative models and can be achieved by reinforcement learning from human feedback (RLHF). Despite their superior performance, current RLHF approaches often require a large amount of human-labelled preference data, which is expensive to collect. In this paper, inspired by the success of active learning, we address this problem by proposing query-efficient RLHF methods. We first formalize the alignment problem as a contextual dueling bandit problem and design an active-query-based proximal policy optimization (APPO) algorithm with an $\tilde{O}(d^2/\Delta)$ regret bound and an $\tilde{O}(d^2/\Delta^2)$ query complexity, where $d$ is the dimension of feature space and $\Delta$ is the sub-optimality gap over all the contexts. We then propose ADPO, a practical version of our algorithm based on direct preference optimization (DPO) and apply it to 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#21463;&#38480;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#35774;&#32622;&#25439;&#22833;&#19978;&#38480;&#26469;&#23547;&#25214;&#26368;&#20339;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24179;&#22343;&#24615;&#33021;&#20248;&#21270;&#23548;&#33268;&#29305;&#23450;&#26102;&#38388;&#27493;&#39588;&#19978;&#35823;&#24046;&#36807;&#22823;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.09373</link><description>&lt;p&gt;
&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25439;&#22833;&#22609;&#36896;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Loss Shaping Constraints for Long-Term Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09373
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#21463;&#38480;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#35774;&#32622;&#25439;&#22833;&#19978;&#38480;&#26469;&#23547;&#25214;&#26368;&#20339;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24179;&#22343;&#24615;&#33021;&#20248;&#21270;&#23548;&#33268;&#29305;&#23450;&#26102;&#38388;&#27493;&#39588;&#19978;&#35823;&#24046;&#36807;&#22823;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#24212;&#29992;&#31243;&#24207;&#38656;&#35201;&#39044;&#27979;&#22810;&#20010;&#27493;&#39588;&#12290;&#23613;&#31649;&#22312;&#36825;&#20010;&#20027;&#39064;&#19978;&#26377;&#22823;&#37327;&#30340;&#25991;&#29486;&#65292;&#20294;&#32463;&#20856;&#21644;&#26368;&#36817;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#26368;&#23567;&#21270;&#39044;&#27979;&#31383;&#21475;&#19978;&#30340;&#24615;&#33021;&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#22312;&#39044;&#27979;&#27493;&#39588;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#30340;&#38169;&#35823;&#20998;&#24067;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#22312;&#24120;&#35265;&#39044;&#27979;&#22522;&#20934;&#19978;&#35757;&#32451;&#30340;&#26368;&#36817;&#30340;&#21464;&#25442;&#22120;&#26550;&#26500;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#24179;&#22343;&#24615;&#33021;&#20248;&#21270;&#21487;&#33021;&#23548;&#33268;&#29305;&#23450;&#26102;&#38388;&#27493;&#39588;&#19978;&#30340;&#38169;&#35823;&#36807;&#22823;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#21463;&#38480;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#25214;&#21040;&#22312;&#24179;&#22343;&#24615;&#33021;&#19978;&#26368;&#22909;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#20445;&#25345;&#29992;&#25143;&#23450;&#20041;&#30340;&#25439;&#22833;&#19978;&#38480;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#26041;&#27861;&#20026;&#25439;&#22833;&#22609;&#36896;&#32422;&#26463;&#65292;&#22240;&#20026;&#23427;&#23545;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#25439;&#22833;&#26045;&#21152;&#32422;&#26463;&#65292;&#24182;&#21033;&#29992;&#26368;&#36817;&#30340;&#23545;&#20598;&#24615;&#32467;&#26524;&#23637;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09373v1 Announce Type: new Abstract: Several applications in time series forecasting require predicting multiple steps ahead. Despite the vast amount of literature in the topic, both classical and recent deep learning based approaches have mostly focused on minimising performance averaged over the predicted window. We observe that this can lead to disparate distributions of errors across forecasting steps, especially for recent transformer architectures trained on popular forecasting benchmarks. That is, optimising performance on average can lead to undesirably large errors at specific time-steps. In this work, we present a Constrained Learning approach for long-term time series forecasting that aims to find the best model in terms of average performance that respects a user-defined upper bound on the loss at each time-step. We call our approach loss shaping constraints because it imposes constraints on the loss at each time step, and leverage recent duality results to show 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#31639;&#27861;&#20844;&#24179;&#24615;&#19982;&#26426;&#22120;&#23398;&#20064;&#22312;&#23448;&#26041;&#32479;&#35745;&#21644;&#35843;&#26597;&#29983;&#20135;&#20013;&#30340;&#36136;&#37327;&#32500;&#24230;&#32852;&#31995;&#36215;&#26469;&#65292;&#25193;&#23637;&#20102;&#36136;&#37327;&#26694;&#26550;&#65292;&#24182;&#35843;&#26597;&#20102;&#20844;&#24179;&#24615;&#19982;&#20854;&#20182;&#36136;&#37327;&#32500;&#24230;&#30340;&#20114;&#21160;&#12290;</title><link>https://arxiv.org/abs/2402.09328</link><description>&lt;p&gt;
&#23558;&#31639;&#27861;&#20844;&#24179;&#24615;&#19982;&#26426;&#22120;&#23398;&#20064;&#22312;&#23448;&#26041;&#32479;&#35745;&#21644;&#35843;&#26597;&#29983;&#20135;&#20013;&#30340;&#36136;&#37327;&#32500;&#24230;&#32852;&#31995;&#36215;&#26469;
&lt;/p&gt;
&lt;p&gt;
Connecting Algorithmic Fairness to Quality Dimensions in Machine Learning in Official Statistics and Survey Production
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09328
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#31639;&#27861;&#20844;&#24179;&#24615;&#19982;&#26426;&#22120;&#23398;&#20064;&#22312;&#23448;&#26041;&#32479;&#35745;&#21644;&#35843;&#26597;&#29983;&#20135;&#20013;&#30340;&#36136;&#37327;&#32500;&#24230;&#32852;&#31995;&#36215;&#26469;&#65292;&#25193;&#23637;&#20102;&#36136;&#37327;&#26694;&#26550;&#65292;&#24182;&#35843;&#26597;&#20102;&#20844;&#24179;&#24615;&#19982;&#20854;&#20182;&#36136;&#37327;&#32500;&#24230;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22269;&#23478;&#32479;&#35745;&#26426;&#26500;&#65288;NSOs&#65289;&#36234;&#26469;&#36234;&#22810;&#22320;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26469;&#25552;&#39640;&#20135;&#21697;&#30340;&#26102;&#25928;&#24615;&#21644;&#25104;&#26412;&#25928;&#30410;&#24615;&#12290;&#24341;&#20837;ML&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;NSOs&#24517;&#39035;&#30830;&#20445;&#22312;&#32479;&#35745;&#31639;&#27861;&#30340;&#36136;&#37327;&#26694;&#26550;&#65288;QF4SA; Yung&#31561;,2022&#65289;&#20013;&#26126;&#30830;&#35268;&#23450;&#30340;&#20581;&#22766;&#24615;&#12289;&#21487;&#37325;&#22797;&#24615;&#21644;&#20934;&#30830;&#24615;&#31561;&#39640;&#26631;&#20934;&#24471;&#21040;&#20445;&#25345;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#20844;&#24179;&#24615;&#20316;&#20026;&#23433;&#20840;&#37096;&#32626;ML&#30340;&#21069;&#25552;&#65292;&#20197;&#38450;&#27490;&#23454;&#36341;&#20013;&#19981;&#21516;&#31038;&#20250;&#24433;&#21709;&#30340;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#22312;NSOs&#24212;&#29992;ML&#30340;&#32972;&#26223;&#19979;&#65292;&#20844;&#24179;&#24615;&#23578;&#26410;&#26126;&#30830;&#35752;&#35770;&#20026;&#36136;&#37327;&#26041;&#38754;&#12290;&#25105;&#20204;&#20351;&#29992;Yung&#31561;&#20154; (2022)&#30340;QF4SA&#36136;&#37327;&#26694;&#26550;&#65292;&#24182;&#23558;&#20854;&#36136;&#37327;&#32500;&#24230;&#26144;&#23556;&#21040;&#31639;&#27861;&#20844;&#24179;&#24615;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#26041;&#38754;&#25193;&#23637;&#20102;QF4SA&#26694;&#26550;&#65306;&#25105;&#20204;&#20027;&#24352;&#20844;&#24179;&#24615;&#20316;&#20026;&#20854;&#29420;&#31435;&#30340;&#36136;&#37327;&#32500;&#24230;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#20844;&#24179;&#24615;&#19982;&#20854;&#20182;&#36136;&#37327;&#32500;&#24230;&#30340;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09328v1 Announce Type: cross Abstract: National Statistical Organizations (NSOs) increasingly draw on Machine Learning (ML) to improve the timeliness and cost-effectiveness of their products. When introducing ML solutions, NSOs must ensure that high standards with respect to robustness, reproducibility, and accuracy are upheld as codified, e.g., in the Quality Framework for Statistical Algorithms (QF4SA; Yung et al. 2022). At the same time, a growing body of research focuses on fairness as a pre-condition of a safe deployment of ML to prevent disparate social impacts in practice. However, fairness has not yet been explicitly discussed as a quality aspect in the context of the application of ML at NSOs. We employ Yung et al. (2022)'s QF4SA quality framework and present a mapping of its quality dimensions to algorithmic fairness. We thereby extend the QF4SA framework in several ways: we argue for fairness as its own quality dimension, we investigate the interaction of fairness
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#22522;&#30784;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#27010;&#24565;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#32479;&#19968;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.09236</link><description>&lt;p&gt;
&#23398;&#20064;&#21487;&#35299;&#37322;&#27010;&#24565;&#65306;&#32479;&#19968;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#19982;&#22522;&#30784;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#21644;&#22522;&#30784;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#30740;&#31350;&#20102;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#27010;&#24565;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#32479;&#19968;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#26234;&#33021;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#26377;&#20004;&#31181;&#24191;&#27867;&#30340;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#26159;&#26500;&#24314;&#22825;&#29983;&#21487;&#35299;&#37322;&#30340;&#27169;&#22411;&#65292;&#36825;&#26159;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#39046;&#22495;&#30340;&#21162;&#21147;&#26041;&#21521;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#26500;&#24314;&#39640;&#24615;&#33021;&#30340;&#22522;&#30784;&#27169;&#22411;&#65292;&#28982;&#21518;&#25237;&#20837;&#21162;&#21147;&#21435;&#29702;&#35299;&#23427;&#20204;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;&#26412;&#30740;&#31350;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#65292;&#30740;&#31350;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#20154;&#31867;&#21487;&#35299;&#37322;&#30340;&#27010;&#24565;&#12290;&#36890;&#36807;&#32467;&#21512;&#36825;&#20004;&#20010;&#39046;&#22495;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#20102;&#27010;&#24565;&#30340;&#27010;&#24565;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#21487;&#20197;&#20174;&#22810;&#26679;&#30340;&#25968;&#25454;&#20013;&#34987;&#21487;&#38752;&#22320;&#24674;&#22797;&#20986;&#26469;&#12290;&#23545;&#20110;&#21512;&#25104;&#25968;&#25454;&#21644;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#32479;&#19968;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09236v1 Announce Type: cross Abstract: To build intelligent machine learning systems, there are two broad approaches. One approach is to build inherently interpretable models, as endeavored by the growing field of causal representation learning. The other approach is to build highly-performant foundation models and then invest efforts into understanding how they work. In this work, we relate these two approaches and study how to learn human-interpretable concepts from data. Weaving together ideas from both fields, we formally define a notion of concepts and show that they can be provably recovered from diverse data. Experiments on synthetic data and large language models show the utility of our unified approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#22312;&#23567;&#21021;&#20540;&#38468;&#36817;&#30340;&#26799;&#24230;&#27969;&#21160;&#65292;&#21457;&#29616;&#26435;&#37325;&#20250;&#22312;&#26041;&#21521;&#19978;&#25910;&#25947;&#21040;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#21644;&#26576;&#20123;&#38797;&#28857;&#38468;&#36817;&#12290;</title><link>https://arxiv.org/abs/2402.09226</link><description>&lt;p&gt;
&#22312;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#30340;&#23567;&#21021;&#20540;&#21644;&#38797;&#28857;&#38468;&#36817;&#30340;&#26041;&#21521;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Directional Convergence Near Small Initializations and Saddles in Two-Homogeneous Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#22312;&#23567;&#21021;&#20540;&#38468;&#36817;&#30340;&#26799;&#24230;&#27969;&#21160;&#65292;&#21457;&#29616;&#26435;&#37325;&#20250;&#22312;&#26041;&#21521;&#19978;&#25910;&#25947;&#21040;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;KKT&#28857;&#21644;&#26576;&#20123;&#38797;&#28857;&#38468;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#27425;&#40784;&#27425;&#31070;&#32463;&#32593;&#32476;&#22312;&#23567;&#21021;&#20540;&#38468;&#36817;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#65292;&#20854;&#20013;&#25152;&#26377;&#26435;&#37325;&#37117;&#21021;&#22987;&#21270;&#22312;&#21407;&#28857;&#38468;&#36817;&#12290;&#38024;&#23545;&#24179;&#26041;&#35823;&#24046;&#21644;&#36923;&#36753;&#25439;&#22833;&#65292;&#35770;&#25991;&#35777;&#26126;&#65292;&#23545;&#20110;&#36275;&#22815;&#23567;&#30340;&#21021;&#22987;&#20540;&#65292;&#26799;&#24230;&#27969;&#21160;&#21160;&#24577;&#22312;&#21407;&#28857;&#38468;&#36817;&#33457;&#36153;&#36275;&#22815;&#30340;&#26102;&#38388;&#65292;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#21487;&#20197;&#36817;&#20284;&#22320;&#22312;&#26041;&#21521;&#19978;&#25910;&#25947;&#21040;&#31070;&#32463;&#30456;&#20851;&#20989;&#25968;&#30340;Karush-Kuhn-Tucker&#65288;KKT&#65289;&#28857;&#65292;&#35813;&#20989;&#25968;&#37327;&#21270;&#20102;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#19982;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#30456;&#24212;&#26631;&#31614;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09226v1 Announce Type: new Abstract: This paper examines gradient flow dynamics of two-homogeneous neural networks for small initializations, where all weights are initialized near the origin. For both square and logistic losses, it is shown that for sufficiently small initializations, the gradient flow dynamics spend sufficient time in the neighborhood of the origin to allow the weights of the neural network to approximately converge in direction to the Karush-Kuhn-Tucker (KKT) points of a neural correlation function that quantifies the correlation between the output of the neural network and corresponding labels in the training data set. For square loss, it has been observed that neural networks undergo saddle-to-saddle dynamics when initialized close to the origin. Motivated by this, this paper also shows a similar directional convergence among weights of small magnitude in the neighborhood of certain saddle points.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#27604;KL PAC-Bayes&#30028;&#38480;&#26041;&#27861;&#26469;&#20272;&#35745;&#24207;&#21015;&#22343;&#20540;&#65292;&#24212;&#29992;&#20110;&#39044;&#27979;&#22120;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.09201</link><description>&lt;p&gt;
&#26356;&#22909;&#30340;&#27604;KL PAC-Bayes&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Better-than-KL PAC-Bayes Bounds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#27604;KL PAC-Bayes&#30028;&#38480;&#26041;&#27861;&#26469;&#20272;&#35745;&#24207;&#21015;&#22343;&#20540;&#65292;&#24212;&#29992;&#20110;&#39044;&#27979;&#22120;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35753;$f(\theta, X_1),$ $ \dots,$ $ f(\theta, X_n)$&#25104;&#20026;&#19968;&#20010;&#38543;&#26426;&#20803;&#32032;&#24207;&#21015;&#65292;&#20854;&#20013;$f$&#26159;&#19968;&#20010;&#22266;&#23450;&#30340;&#26631;&#37327;&#20989;&#25968;&#65292;$X_1, \dots, X_n$&#26159;&#29420;&#31435;&#30340;&#38543;&#26426;&#21464;&#37327;&#65288;&#25968;&#25454;&#65289;&#65292;&#32780;$\theta$&#26159;&#26681;&#25454;&#19968;&#20123;&#25968;&#25454;&#30456;&#20851;&#30340;&#21518;&#39564;&#20998;&#24067;$P_n$&#20998;&#24067;&#30340;&#38543;&#26426;&#21442;&#25968;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#35777;&#26126;&#27987;&#24230;&#19981;&#31561;&#24335;&#26469;&#20272;&#35745;&#24207;&#21015;&#22343;&#20540;&#30340;&#38382;&#39064;&#12290;&#36825;&#26679;&#19968;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#20363;&#23376;&#26159;&#23545;&#26576;&#20123;&#36890;&#36807;&#38543;&#26426;&#31639;&#27861;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#65292;&#27604;&#22914;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#20013;$f$&#26159;&#19968;&#20010;&#25439;&#22833;&#20989;&#25968;&#12290;&#20256;&#32479;&#19978;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159;&#36890;&#36807;PAC-Bayes&#20998;&#26512;&#26469;&#35299;&#20915;&#30340;&#65292;&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#65292;&#38500;&#20102;&#21518;&#39564;&#20998;&#24067;&#65292;&#25105;&#20204;&#36824;&#36873;&#25321;&#19968;&#20010;&#33021;&#22815;&#25429;&#25417;&#21040;&#23398;&#20064;&#38382;&#39064;&#24402;&#32435;&#20559;&#24046;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;PAC-Bayes&#27987;&#24230;&#30028;&#38480;&#20013;&#30340;&#20851;&#38190;&#25968;&#37327;&#26159;&#19968;&#20010;&#33021;&#22815;&#25429;&#25417;&#21040;&#23398;&#20064;&#38382;&#39064;&#22797;&#26434;&#24615;&#30340;&#20998;&#27495;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09201v1 Announce Type: new Abstract: Let $f(\theta, X_1),$ $ \dots,$ $ f(\theta, X_n)$ be a sequence of random elements, where $f$ is a fixed scalar function, $X_1, \dots, X_n$ are independent random variables (data), and $\theta$ is a random parameter distributed according to some data-dependent posterior distribution $P_n$. In this paper, we consider the problem of proving concentration inequalities to estimate the mean of the sequence. An example of such a problem is the estimation of the generalization error of some predictor trained by a stochastic algorithm, such as a neural network where $f$ is a loss function. Classically, this problem is approached through a PAC-Bayes analysis where, in addition to the posterior, we choose a prior distribution which captures our belief about the inductive bias of the learning problem. Then, the key quantity in PAC-Bayes concentration bounds is a divergence that captures the complexity of the learning problem where the de facto stand
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20449;&#21495;&#20998;&#31163;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#21253;&#21547;&#32431;&#32452;&#20998;&#20449;&#21495;&#21152;&#26435;&#21644;&#30340;&#24773;&#20917;&#65292;&#36866;&#29992;&#20110;&#20809;&#35889;&#23398;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#22810;&#31181;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09122</link><description>&lt;p&gt;
&#28151;&#21512;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixed-Output Gaussian Process Latent Variable Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20449;&#21495;&#20998;&#31163;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#21253;&#21547;&#32431;&#32452;&#20998;&#20449;&#21495;&#21152;&#26435;&#21644;&#30340;&#24773;&#20917;&#65292;&#36866;&#29992;&#20110;&#20809;&#35889;&#23398;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#22810;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20449;&#21495;&#20998;&#31163;&#26041;&#27861;&#65292;&#20854;&#20013;&#20449;&#21495;&#21487;&#20197;&#26681;&#25454;&#28508;&#21464;&#37327;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22686;&#21152;&#20102;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;GPLVMs&#65289;&#65292;&#20197;&#21253;&#25324;&#27599;&#20010;&#25968;&#25454;&#28857;&#30001;&#24050;&#30693;&#25968;&#37327;&#30340;&#32431;&#32452;&#20998;&#20449;&#21495;&#30340;&#21152;&#26435;&#21644;&#32452;&#25104;&#30340;&#24773;&#20917;&#65292;&#24182;&#35266;&#23519;&#22810;&#20010;&#36755;&#20837;&#20301;&#32622;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#20351;&#29992;&#21508;&#31181;&#20851;&#20110;&#27599;&#20010;&#35266;&#27979;&#26435;&#37325;&#30340;&#20808;&#39564;&#12290;&#36825;&#31181;&#28789;&#27963;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#34920;&#31034;&#21253;&#25324;&#29992;&#20110;&#20272;&#35745;&#20998;&#25968;&#32452;&#25104;&#30340;&#24635;&#21644;&#20026;&#19968;&#32422;&#26463;&#21644;&#29992;&#20110;&#20998;&#31867;&#30340;&#20108;&#36827;&#21046;&#26435;&#37325;&#30340;&#29992;&#20363;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#23545;&#20110;&#20809;&#35889;&#23398;&#23588;&#20854;&#30456;&#20851;&#65292;&#22240;&#20026;&#25913;&#21464;&#26465;&#20214;&#21487;&#33021;&#23548;&#33268;&#22522;&#30784;&#32431;&#32452;&#20998;&#20449;&#21495;&#22312;&#26679;&#26412;&#20043;&#38388;&#21464;&#21270;&#12290;&#20026;&#20102;&#23637;&#31034;&#23545;&#20809;&#35889;&#23398;&#21644;&#20854;&#20182;&#39046;&#22495;&#30340;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20960;&#20010;&#24212;&#29992;&#65306;&#19968;&#20010;&#20855;&#26377;&#19981;&#21516;&#28201;&#24230;&#30340;&#36817;&#32418;&#22806;&#20809;&#35889;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09122v1 Announce Type: cross Abstract: This work develops a Bayesian non-parametric approach to signal separation where the signals may vary according to latent variables. Our key contribution is to augment Gaussian Process Latent Variable Models (GPLVMs) to incorporate the case where each data point comprises the weighted sum of a known number of pure component signals, observed across several input locations. Our framework allows the use of a range of priors for the weights of each observation. This flexibility enables us to represent use cases including sum-to-one constraints for estimating fractional makeup, and binary weights for classification. Our contributions are particularly relevant to spectroscopy, where changing conditions may cause the underlying pure component signals to vary from sample to sample. To demonstrate the applicability to both spectroscopy and other domains, we consider several applications: a near-infrared spectroscopy data set with varying temper
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#38750;&#32447;&#24615;&#20998;&#23618;&#39044;&#27979;&#21327;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30452;&#25509;&#19988;&#33258;&#21160;&#21270;&#22320;&#29983;&#25104;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#39044;&#27979;&#65292;&#36890;&#36807;&#23545;&#26469;&#33258;&#25353;&#38656;&#20132;&#20184;&#24179;&#21488;&#30340;&#22823;&#35268;&#27169;&#27969;&#24335;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27979;&#35797;&#12290;</title><link>https://arxiv.org/abs/2402.09033</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;
&lt;/p&gt;
&lt;p&gt;
Cross-Temporal Forecast Reconciliation at Digital Platforms with Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#38750;&#32447;&#24615;&#20998;&#23618;&#39044;&#27979;&#21327;&#35843;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#30452;&#25509;&#19988;&#33258;&#21160;&#21270;&#22320;&#29983;&#25104;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#39044;&#27979;&#65292;&#36890;&#36807;&#23545;&#26469;&#33258;&#25353;&#38656;&#20132;&#20184;&#24179;&#21488;&#30340;&#22823;&#35268;&#27169;&#27969;&#24335;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#21488;&#19994;&#21153;&#22312;&#25968;&#23383;&#26680;&#24515;&#19978;&#36816;&#20316;&#65292;&#20854;&#20915;&#31574;&#38656;&#35201;&#19981;&#21516;&#23618;&#27425;&#65288;&#20363;&#22914;&#22320;&#29702;&#21306;&#22495;&#65289;&#21644;&#26102;&#38388;&#32858;&#21512;&#65288;&#20363;&#22914;&#20998;&#38047;&#21040;&#22825;&#65289;&#30340;&#39640;&#32500;&#20934;&#30830;&#39044;&#27979;&#27969;&#12290;&#20026;&#20102;&#30830;&#20445;&#19981;&#21516;&#35268;&#21010;&#21333;&#20803;&#65288;&#22914;&#23450;&#20215;&#12289;&#20135;&#21697;&#12289;&#25511;&#21046;&#21644;&#25112;&#30053;&#65289;&#20043;&#38388;&#30340;&#20915;&#31574;&#19968;&#33268;&#65292;&#20063;&#38656;&#35201;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#25152;&#26377;&#32423;&#21035;&#19978;&#36827;&#34892;&#21327;&#35843;&#39044;&#27979;&#12290;&#37492;&#20110;&#24179;&#21488;&#25968;&#25454;&#27969;&#20855;&#26377;&#22797;&#26434;&#30340;&#29305;&#24449;&#21644;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38750;&#32447;&#24615;&#20998;&#23618;&#39044;&#27979;&#21327;&#35843;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#30452;&#25509;&#21644;&#33258;&#21160;&#21270;&#30340;&#26041;&#24335;&#29983;&#25104;&#36328;&#26102;&#39044;&#27979;&#21327;&#35843;&#30340;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#36275;&#22815;&#24555;&#65292;&#21487;&#20197;&#28385;&#36275;&#24179;&#21488;&#25152;&#38656;&#30340;&#22522;&#20110;&#39044;&#27979;&#30340;&#39640;&#39057;&#20915;&#31574;&#12290;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#39046;&#20808;&#30340;&#25353;&#38656;&#20132;&#20184;&#24179;&#21488;&#30340;&#29420;&#29305;&#22823;&#35268;&#27169;&#27969;&#24335;&#25968;&#25454;&#38598;&#23545;&#25105;&#20204;&#30340;&#26694;&#26550;&#36827;&#34892;&#20102;&#23454;&#35777;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09033v1 Announce Type: new Abstract: Platform businesses operate on a digital core and their decision making requires high-dimensional accurate forecast streams at different levels of cross-sectional (e.g., geographical regions) and temporal aggregation (e.g., minutes to days). It also necessitates coherent forecasts across all levels of the hierarchy to ensure aligned decision making across different planning units such as pricing, product, controlling and strategy. Given that platform data streams feature complex characteristics and interdependencies, we introduce a non-linear hierarchical forecast reconciliation method that produces cross-temporal reconciled forecasts in a direct and automated way through the use of popular machine learning methods. The method is sufficiently fast to allow forecast-based high-frequency decision making that platforms require. We empirically test our framework on a unique, large-scale streaming dataset from a leading on-demand delivery plat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Energy-consistent Neural Operators (ENOs)&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#36981;&#24490;&#33021;&#37327;&#23432;&#24658;&#25110;&#32791;&#25955;&#23450;&#24459;&#30340;PDE&#35299;&#31639;&#23376;&#12290;&#36890;&#36807;&#24341;&#20837;&#21463;&#29289;&#29702;&#23398;&#33021;&#37327;&#29702;&#35770;&#21551;&#21457;&#30340;&#24809;&#32602;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#21478;&#19968;&#20010;DNN&#27169;&#22411;&#24314;&#27169;&#33021;&#37327;&#20989;&#25968;&#65292;&#21487;&#20197;&#30830;&#20445;DNN&#35299;&#31639;&#23376;&#30340;&#36755;&#20986;&#28385;&#36275;&#33021;&#37327;&#19968;&#33268;&#24615;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30340;PDEs&#12290;&#23454;&#39564;&#35777;&#26126;ENO&#22312;&#22810;&#20010;&#29289;&#29702;&#31995;&#32479;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#20197;&#24448;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.09018</link><description>&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#36935;&#19978;&#33021;&#37327;&#29702;&#35770;: &#21704;&#23494;&#39039;&#21644;&#32791;&#25955;&#22411;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31639;&#23376;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Neural Operators Meet Energy-based Theory: Operator Learning for Hamiltonian and Dissipative PDEs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Energy-consistent Neural Operators (ENOs)&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#36981;&#24490;&#33021;&#37327;&#23432;&#24658;&#25110;&#32791;&#25955;&#23450;&#24459;&#30340;PDE&#35299;&#31639;&#23376;&#12290;&#36890;&#36807;&#24341;&#20837;&#21463;&#29289;&#29702;&#23398;&#33021;&#37327;&#29702;&#35770;&#21551;&#21457;&#30340;&#24809;&#32602;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#21478;&#19968;&#20010;DNN&#27169;&#22411;&#24314;&#27169;&#33021;&#37327;&#20989;&#25968;&#65292;&#21487;&#20197;&#30830;&#20445;DNN&#35299;&#31639;&#23376;&#30340;&#36755;&#20986;&#28385;&#36275;&#33021;&#37327;&#19968;&#33268;&#24615;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30340;PDEs&#12290;&#23454;&#39564;&#35777;&#26126;ENO&#22312;&#22810;&#20010;&#29289;&#29702;&#31995;&#32479;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#20197;&#24448;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31639;&#23376;&#23398;&#20064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#26088;&#22312;&#23398;&#20064;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#26144;&#23556;&#20851;&#31995;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#23398;&#20064;&#36825;&#31181;&#26144;&#23556;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#23545;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#30340;&#35299;&#31639;&#23376;&#30340;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38590;&#20197;&#23398;&#20064;&#36981;&#23432;&#29289;&#29702;&#35268;&#24459;&#30340;&#21160;&#21147;&#23398;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#19968;&#33268;&#31070;&#32463;&#31639;&#23376;(ENOs)&#65292;&#36825;&#26159;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#36981;&#24490;&#33021;&#37327;&#23432;&#24658;&#25110;&#32791;&#25955;&#23450;&#24459;&#30340;PDE&#35299;&#31639;&#23376;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21463;&#29289;&#29702;&#23398;&#33021;&#37327;&#29702;&#35770;&#21551;&#21457;&#30340;&#24809;&#32602;&#20989;&#25968;&#29992;&#20110;&#35757;&#32451;&#65292;&#20854;&#20013;&#33021;&#37327;&#20989;&#25968;&#30001;&#21478;&#19968;&#20010;DNN&#26469;&#24314;&#27169;&#65292;&#20351;&#24471;&#22522;&#20110;DNN&#30340;&#35299;&#31639;&#23376;&#30340;&#36755;&#20986;&#33021;&#22815;&#20445;&#35777;&#33021;&#37327;&#19968;&#33268;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#26174;&#24335;&#30340;PDEs&#12290;&#22312;&#22810;&#20010;&#29289;&#29702;&#31995;&#32479;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;ENO&#30340;&#24615;&#33021;&#26126;&#26174;&#20248;&#20110;&#20197;&#24448;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09018v1 Announce Type: cross Abstract: The operator learning has received significant attention in recent years, with the aim of learning a mapping between function spaces. Prior works have proposed deep neural networks (DNNs) for learning such a mapping, enabling the learning of solution operators of partial differential equations (PDEs). However, these works still struggle to learn dynamics that obeys the laws of physics. This paper proposes Energy-consistent Neural Operators (ENOs), a general framework for learning solution operators of PDEs that follows the energy conservation or dissipation law from observed solution trajectories. We introduce a novel penalty function inspired by the energy-based theory of physics for training, in which the energy functional is modeled by another DNN, allowing one to bias the outputs of the DNN-based solution operators to ensure energetic consistency without explicit PDEs. Experiments on multiple physical systems show that ENO outperfor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#28151;&#21512;&#36716;&#31227;&#26680;&#20989;&#25968;&#30340;&#38543;&#26426;&#26368;&#30701;&#36335;&#24452;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#26032;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#24102;&#26377;&#26041;&#24046;&#24863;&#30693;&#32622;&#20449;&#21306;&#38388;&#30340;&#25193;&#23637;&#20540;&#36845;&#20195;&#65292;&#24182;&#36890;&#36807;&#39640;&#38454;&#30697;&#30340;&#36882;&#24402;&#20272;&#35745;&#23454;&#29616;&#20102;&#36817;&#20284;&#26368;&#23567;&#26368;&#22823;&#36951;&#25022;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.08998</link><description>&lt;p&gt;
&#23398;&#20064;&#32447;&#24615;&#28151;&#21512;&#38543;&#26426;&#26368;&#30701;&#36335;&#24452;&#30340;&#36817;&#20284;&#26368;&#23567;&#26368;&#22823;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Nearly Minimax Optimal Regret for Learning Linear Mixture Stochastic Shortest Path
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08998
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#28151;&#21512;&#36716;&#31227;&#26680;&#20989;&#25968;&#30340;&#38543;&#26426;&#26368;&#30701;&#36335;&#24452;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#38480;&#21046;&#24615;&#20551;&#35774;&#30340;&#26032;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#24102;&#26377;&#26041;&#24046;&#24863;&#30693;&#32622;&#20449;&#21306;&#38388;&#30340;&#25193;&#23637;&#20540;&#36845;&#20195;&#65292;&#24182;&#36890;&#36807;&#39640;&#38454;&#30697;&#30340;&#36882;&#24402;&#20272;&#35745;&#23454;&#29616;&#20102;&#36817;&#20284;&#26368;&#23567;&#26368;&#22823;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#28151;&#21512;&#36716;&#31227;&#26680;&#20989;&#25968;&#30340;&#38543;&#26426;&#26368;&#30701;&#36335;&#24452;&#65288;SSP&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#37325;&#22797;&#19982;&#38543;&#26426;&#29615;&#22659;&#20114;&#21160;&#65292;&#24182;&#23547;&#27714;&#36798;&#21040;&#29305;&#23450;&#30446;&#26631;&#29366;&#24577;&#21516;&#26102;&#26368;&#23567;&#21270;&#32047;&#31215;&#25104;&#26412;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#36890;&#24120;&#20551;&#35774;&#25104;&#26412;&#20989;&#25968;&#20855;&#26377;&#20005;&#26684;&#30340;&#27491;&#19979;&#30028;&#65292;&#25110;&#32773;&#26399;&#26395;&#38271;&#24230;&#30340;&#26368;&#20248;&#31574;&#30053;&#20855;&#26377;&#19978;&#30028;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#28040;&#38500;&#36825;&#20123;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#24102;&#26377;&#31934;&#32454;&#21270;&#26041;&#24046;&#24863;&#30693;&#32622;&#20449;&#21306;&#38388;&#30340;&#25193;&#23637;&#20540;&#36845;&#20195;&#65292;&#20854;&#20013;&#26041;&#24046;&#20174;&#39640;&#38454;&#30697;&#36882;&#24402;&#20272;&#35745;&#24471;&#21040;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;$\tilde{\mathcal O}(dB_*\sqrt{K})$ &#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;$d$ &#26159;&#32447;&#24615;&#36716;&#31227;&#26680;&#20989;&#25968;&#20013;&#29305;&#24449;&#26144;&#23556;&#30340;&#32500;&#24230;&#65292;$B_*$ &#26159;&#26368;&#20248;&#31574;&#30053;&#30340;&#24635;&#32047;&#31215;&#25104;&#26412;&#30340;&#19978;&#30028;&#65292;$K$ &#26159;&#21095;&#38598;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#36951;&#25022;&#19978;&#30028;&#19982;$\Omega(.
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08998v1 Announce Type: new Abstract: We study the Stochastic Shortest Path (SSP) problem with a linear mixture transition kernel, where an agent repeatedly interacts with a stochastic environment and seeks to reach certain goal state while minimizing the cumulative cost. Existing works often assume a strictly positive lower bound of the cost function or an upper bound of the expected length for the optimal policy. In this paper, we propose a new algorithm to eliminate these restrictive assumptions. Our algorithm is based on extended value iteration with a fine-grained variance-aware confidence set, where the variance is estimated recursively from high-order moments. Our algorithm achieves an $\tilde{\mathcal O}(dB_*\sqrt{K})$ regret bound, where $d$ is the dimension of the feature mapping in the linear transition kernel, $B_*$ is the upper bound of the total cumulative cost for the optimal policy, and $K$ is the number of episodes. Our regret upper bound matches the $\Omega(
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2402.08992</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#26041;&#24046;&#20943;&#23569;&#21644;&#20302;&#26679;&#26412;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Variance Reduction and Low Sample Complexity in Stochastic Optimization via Proximal Point Method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36817;&#31471;&#28857;&#26041;&#27861;&#36827;&#34892;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24369;&#26465;&#20214;&#19979;&#33719;&#24471;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23454;&#29616;&#26041;&#24046;&#20943;&#23569;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#36817;&#31471;&#28857;&#27861;&#26469;&#35299;&#20915;&#38543;&#26426;&#20984;&#22797;&#21512;&#20248;&#21270;&#38382;&#39064;&#12290;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#39640;&#27010;&#29575;&#32467;&#26524;&#36890;&#24120;&#20381;&#36182;&#20110;&#23545;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#20363;&#22914;&#23376;&#39640;&#26031;&#20998;&#24067;&#12290;&#26412;&#25991;&#21482;&#20551;&#35774;&#20102;&#38543;&#26426;&#26799;&#24230;&#30340;&#26377;&#30028;&#26041;&#24046;&#31561;&#24369;&#26465;&#20214;&#65292;&#24314;&#31435;&#20102;&#19968;&#31181;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#20197;&#33719;&#24471;&#20851;&#20110;&#25152;&#25552;&#26041;&#27861;&#25910;&#25947;&#30340;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#26412;&#24037;&#20316;&#30340;&#19968;&#20010;&#26174;&#33879;&#26041;&#38754;&#26159;&#21457;&#23637;&#20102;&#19968;&#20010;&#29992;&#20110;&#35299;&#20915;&#36817;&#31471;&#23376;&#38382;&#39064;&#30340;&#23376;&#31243;&#24207;&#65292;&#23427;&#21516;&#26102;&#20063;&#26159;&#19968;&#31181;&#29992;&#20110;&#20943;&#23569;&#26041;&#24046;&#30340;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08992v1 Announce Type: cross Abstract: This paper proposes a stochastic proximal point method to solve a stochastic convex composite optimization problem. High probability results in stochastic optimization typically hinge on restrictive assumptions on the stochastic gradient noise, for example, sub-Gaussian distributions. Assuming only weak conditions such as bounded variance of the stochastic gradient, this paper establishes a low sample complexity to obtain a high probability guarantee on the convergence of the proposed method. Additionally, a notable aspect of this work is the development of a subroutine to solve the proximal subproblem, which also serves as a novel technique for variance reduction.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#23545;&#36716;&#31227;&#27169;&#22411;&#30340;&#20581;&#22766;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.08991</link><description>&lt;p&gt;
&#38754;&#21521;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#20581;&#22766;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Robust Model-Based Reinforcement Learning Against Adversarial Corruption
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08991
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#23454;&#29616;&#20102;&#23545;&#36716;&#31227;&#27169;&#22411;&#30340;&#20581;&#22766;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#27169;&#22411;&#39537;&#21160;&#24378;&#21270;&#23398;&#20064;&#20013;&#23545;&#25239;&#24615;&#30772;&#22351;&#30340;&#25361;&#25112;&#65292;&#20854;&#20013;&#36716;&#31227;&#21160;&#21147;&#23398;&#21487;&#20197;&#34987;&#23545;&#25163;&#30772;&#22351;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#27169;&#22411;&#26080;&#20851;&#24378;&#21270;&#23398;&#20064;&#30340;&#24773;&#26223;&#19979;&#65292;&#36890;&#24120;&#37319;&#29992;&#20581;&#22766;&#30340;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#26469;&#36827;&#34892;&#20540;&#20989;&#25968;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#27169;&#22411;&#39537;&#21160;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#27169;&#22411;&#39537;&#21160;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#24182;&#37319;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#26041;&#27861;&#26469;&#23398;&#20064;&#36716;&#31227;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#28085;&#30422;&#20102;&#22312;&#32447;&#21644;&#31163;&#32447;&#20004;&#31181;&#24773;&#20917;&#12290;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#23545;&#25239;&#24615;&#20581;&#22766;&#30340;&#20048;&#35266;MLE&#65288;CR-OMLE&#65289;&#30340;&#31639;&#27861;&#65292;&#23427;&#21033;&#29992;&#22522;&#20110;&#24635;&#21464;&#24046;&#65288;TV&#65289;&#30340;&#20449;&#24687;&#27604;&#29575;&#20316;&#20026;MLE&#30340;&#19981;&#30830;&#23450;&#26435;&#37325;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;CR-OMLE&#30340;&#36951;&#25022;&#24230;&#20026;$ \tilde {\mathcal {O}}&#65288;\sqrt {T} + C&#65289;$&#65292;&#20854;&#20013;$ C $&#34920;&#31034;&#32463;&#36807;$ T $&#20010;&#22238;&#21512;&#21518;&#30340;&#32047;&#35745;&#30772;&#22351;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08991v1 Announce Type: cross Abstract: This study tackles the challenges of adversarial corruption in model-based reinforcement learning (RL), where the transition dynamics can be corrupted by an adversary. Existing studies on corruption-robust RL mostly focus on the setting of model-free RL, where robust least-square regression is often employed for value function estimation. However, these techniques cannot be directly applied to model-based RL. In this paper, we focus on model-based RL and take the maximum likelihood estimation (MLE) approach to learn transition model. Our work encompasses both online and offline settings. In the online setting, we introduce an algorithm called corruption-robust optimistic MLE (CR-OMLE), which leverages total-variation (TV)-based information ratios as uncertainty weights for MLE. We prove that CR-OMLE achieves a regret of $\tilde{\mathcal{O}}(\sqrt{T} + C)$, where $C$ denotes the cumulative corruption level after $T$ episodes. We also pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#23454;&#29992;&#30340;&#20108;&#38454;&#36172;&#24466;&#20984;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#19968;&#31867;&#31216;&#20043;&#20026;$\kappa$-&#20984;&#30340;&#20984;&#20989;&#25968;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#26399;&#25439;&#22833;&#30028;&#38480;&#12290;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#39640;&#25928;&#24615;&#33021;&#65292;&#21253;&#25324;&#36172;&#24466;&#36923;&#36753;&#22238;&#24402;&#12290;</title><link>https://arxiv.org/abs/2402.08929</link><description>&lt;p&gt;
&#20108;&#38454;&#26041;&#27861;&#29992;&#20110;&#36172;&#24466;&#20248;&#21270;&#19982;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Second Order Methods for Bandit Optimization and Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#23454;&#29992;&#30340;&#20108;&#38454;&#36172;&#24466;&#20984;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#19968;&#31867;&#31216;&#20043;&#20026;$\kappa$-&#20984;&#30340;&#20984;&#20989;&#25968;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21518;&#26399;&#25439;&#22833;&#30028;&#38480;&#12290;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#39640;&#25928;&#24615;&#33021;&#65292;&#21253;&#25324;&#36172;&#24466;&#36923;&#36753;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bandit&#20984;&#20248;&#21270;(BCO)&#26159;&#19968;&#31181;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#22312;&#32447;&#20915;&#31574;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#23613;&#31649;&#24050;&#32463;&#24314;&#31435;&#20102;&#19968;&#33324;&#20984;&#25439;&#22833;&#30340;&#32039;&#26463;&#21518;&#26399;&#30028;&#38480;&#65292;&#20294;&#29616;&#26377;&#31639;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#20855;&#26377;&#38590;&#20197;&#24525;&#21463;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;&#31639;&#27861;&#21551;&#21457;&#30340;&#31616;&#21333;&#23454;&#29992;&#30340;BCO&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#20110;&#19968;&#31867;&#25105;&#20204;&#31216;&#20043;&#20026;$\kappa$-&#20984;&#30340;&#20984;&#20989;&#25968;&#23454;&#29616;&#20102;&#26368;&#20248;(&#20174;&#23618;&#38754;&#19978;&#35762;)&#30340;&#21518;&#26399;&#30028;&#38480;&#12290;&#36825;&#20010;&#31867;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#23454;&#38469;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#32447;&#24615;&#12289;&#20108;&#27425;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;&#38500;&#20102;&#26368;&#20248;&#30340;&#21518;&#26399;&#25439;&#22833;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#26159;&#19968;&#20123;&#32463;&#36807;&#28145;&#20837;&#30740;&#31350;&#30340;&#24212;&#29992;&#20013;&#24050;&#30693;&#30340;&#26368;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#36172;&#24466;&#36923;&#36753;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08929v1 Announce Type: new Abstract: Bandit convex optimization (BCO) is a general framework for online decision making under uncertainty. While tight regret bounds for general convex losses have been established, existing algorithms achieving these bounds have prohibitive computational costs for high dimensional data.   In this paper, we propose a simple and practical BCO algorithm inspired by the online Newton step algorithm. We show that our algorithm achieves optimal (in terms of horizon) regret bounds for a large class of convex functions that we call $\kappa$-convex. This class contains a wide range of practically relevant loss functions including linear, quadratic, and generalized linear models. In addition to optimal regret, this method is the most efficient known algorithm for several well-studied applications including bandit logistic regression.   Furthermore, we investigate the adaptation of our second-order bandit algorithm to online convex optimization with mem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#21644;&#25506;&#35752;&#20102;&#38236;&#20687;&#24433;&#21709;&#20551;&#35774;&#65292;&#31361;&#20986;&#20102;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#24433;&#21709;&#30340;&#30456;&#20114;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#25351;&#20986;&#65292;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27979;&#35797;&#39044;&#27979;&#30340;&#24433;&#21709;&#21487;&#20197;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#31561;&#25928;&#20294;&#30456;&#21453;&#30340;&#38382;&#39064;&#65306;&#35780;&#20272;&#22914;&#26524;&#27169;&#22411;&#22312;&#29305;&#23450;&#30340;&#27979;&#35797;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#23545;&#35757;&#32451;&#26679;&#26412;&#30340;&#39044;&#27979;&#23558;&#22914;&#20309;&#25913;&#21464;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#39564;&#35777;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#19968;&#20551;&#35774;&#30340;&#27491;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.08922</link><description>&lt;p&gt;
&#38236;&#20687;&#24433;&#21709;&#20551;&#35774;&#65306;&#36890;&#36807;&#21033;&#29992;&#21069;&#21521;&#20256;&#36882;&#23454;&#29616;&#39640;&#25928;&#30340;&#25968;&#25454;&#24433;&#21709;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
The Mirrored Influence Hypothesis: Efficient Data Influence Estimation by Harnessing Forward Passes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#21644;&#25506;&#35752;&#20102;&#38236;&#20687;&#24433;&#21709;&#20551;&#35774;&#65292;&#31361;&#20986;&#20102;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#24433;&#21709;&#30340;&#30456;&#20114;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#23427;&#25351;&#20986;&#65292;&#35780;&#20272;&#35757;&#32451;&#25968;&#25454;&#23545;&#27979;&#35797;&#39044;&#27979;&#30340;&#24433;&#21709;&#21487;&#20197;&#37325;&#26032;&#34920;&#36848;&#20026;&#19968;&#20010;&#31561;&#25928;&#20294;&#30456;&#21453;&#30340;&#38382;&#39064;&#65306;&#35780;&#20272;&#22914;&#26524;&#27169;&#22411;&#22312;&#29305;&#23450;&#30340;&#27979;&#35797;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#23545;&#35757;&#32451;&#26679;&#26412;&#30340;&#39044;&#27979;&#23558;&#22914;&#20309;&#25913;&#21464;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#39564;&#35777;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#36825;&#19968;&#20551;&#35774;&#30340;&#27491;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#40657;&#30418;&#27169;&#22411;&#24050;&#32463;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21464;&#24471;&#26080;&#22788;&#19981;&#22312;&#12290;&#20102;&#35299;&#20010;&#21035;&#35757;&#32451;&#25968;&#25454;&#28304;&#23545;&#36825;&#20123;&#27169;&#22411;&#25152;&#20570;&#39044;&#27979;&#30340;&#24433;&#21709;&#23545;&#20110;&#25913;&#21892;&#20854;&#21487;&#20449;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#30340;&#24433;&#21709;&#35780;&#20272;&#25216;&#26415;&#28041;&#21450;&#35745;&#31639;&#27599;&#20010;&#35757;&#32451;&#28857;&#30340;&#26799;&#24230;&#25110;&#22312;&#19981;&#21516;&#23376;&#38598;&#19978;&#37325;&#22797;&#35757;&#32451;&#12290;&#24403;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#38754;&#20020;&#26126;&#26174;&#30340;&#35745;&#31639;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08922v1 Announce Type: new Abstract: Large-scale black-box models have become ubiquitous across numerous applications. Understanding the influence of individual training data sources on predictions made by these models is crucial for improving their trustworthiness. Current influence estimation techniques involve computing gradients for every training point or repeated training on different subsets. These approaches face obvious computational challenges when scaled up to large datasets and models.   In this paper, we introduce and explore the Mirrored Influence Hypothesis, highlighting a reciprocal nature of influence between training and test data. Specifically, it suggests that evaluating the influence of training data on test predictions can be reformulated as an equivalent, yet inverse problem: assessing how the predictions for training samples would be altered if the model were trained on specific test samples. Through both empirical and theoretical validations, we demo
&lt;/p&gt;</description></item><item><title>&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#23558;&#25299;&#25169;&#29305;&#24449;&#24341;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20316;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#34917;&#20805;&#65292;&#32473;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#25552;&#20379;&#20102;&#33258;&#28982;&#36873;&#25321;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;</title><link>https://arxiv.org/abs/2402.08871</link><description>&lt;p&gt;
&#20301;&#32622;&#35770;&#25991;&#65306;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Challenges and Opportunities in Topological Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08871
&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#23558;&#25299;&#25169;&#29305;&#24449;&#24341;&#20837;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20316;&#20026;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#34917;&#20805;&#65292;&#32473;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#25552;&#20379;&#20102;&#33258;&#28982;&#36873;&#25321;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#23427;&#21033;&#29992;&#25299;&#25169;&#29305;&#24449;&#26469;&#29702;&#35299;&#21644;&#35774;&#35745;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#36890;&#36807;&#34701;&#20837;&#25299;&#25169;&#27010;&#24565;&#65292;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#21487;&#20197;&#34917;&#20805;&#22270;&#34920;&#31034;&#23398;&#20064;&#21644;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#65292;&#24182;&#25104;&#20026;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#33258;&#28982;&#36873;&#25321;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#35752;&#35770;&#20102;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#28085;&#30422;&#20102;&#20174;&#23454;&#29992;&#30410;&#22788;&#21040;&#29702;&#35770;&#22522;&#30784;&#30340;&#21508;&#20010;&#26041;&#38754;&#12290;&#38024;&#23545;&#27599;&#20010;&#38382;&#39064;&#65292;&#23427;&#27010;&#36848;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26426;&#20250;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#20063;&#26159;&#23545;&#31185;&#23398;&#30028;&#30340;&#36992;&#35831;&#65292;&#24076;&#26395;&#31215;&#26497;&#21442;&#19982;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#65292;&#24320;&#21457;&#36825;&#20010;&#26032;&#20852;&#39046;&#22495;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08871v1 Announce Type: new Abstract: Topological deep learning (TDL) is a rapidly evolving field that uses topological features to understand and design deep learning models. This paper posits that TDL may complement graph representation learning and geometric deep learning by incorporating topological concepts, and can thus provide a natural choice for various machine learning settings. To this end, this paper discusses open problems in TDL, ranging from practical benefits to theoretical foundations. For each problem, it outlines potential solutions and future research opportunities. At the same time, this paper serves as an invitation to the scientific community to actively participate in TDL research to unlock the potential of this emerging field.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22810;&#23618;&#24863;&#30693;&#26426;&#20869;&#31215;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#20316;&#20026;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#33021;&#21147;&#12290;&#24471;&#21040;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#20851;&#31995;&#20989;&#25968;&#36924;&#36817;&#25152;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2402.08856</link><description>&lt;p&gt;
&#20851;&#20110;&#20851;&#31995;&#20989;&#25968;&#21644;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#36817;&#20284;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximation of relation functions and attention mechanisms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08856
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22810;&#23618;&#24863;&#30693;&#26426;&#20869;&#31215;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#20316;&#20026;&#36890;&#29992;&#36924;&#36817;&#22120;&#30340;&#33021;&#21147;&#12290;&#24471;&#21040;&#20102;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#20851;&#31995;&#20989;&#25968;&#36924;&#36817;&#25152;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#26144;&#23556;&#30340;&#20869;&#31215;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#20013;&#34987;&#29992;&#20110;&#24314;&#27169;&#36755;&#20837;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#31215;&#30340;&#36817;&#20284;&#24615;&#36136;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22810;&#23618;&#24863;&#30693;&#26426;&#33258;&#36523;&#30340;&#20869;&#31215;&#26159;&#23545;&#31216;&#27491;&#23450;&#20851;&#31995;&#20989;&#25968;&#30340;&#36890;&#29992;&#36924;&#36817;&#22120;&#12290;&#23545;&#20110;&#38750;&#23545;&#31216;&#20851;&#31995;&#20989;&#25968;&#65292;&#19981;&#21516;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#30340;&#20869;&#31215;&#26159;&#19968;&#20010;&#36890;&#29992;&#36924;&#36817;&#22120;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#37117;&#24471;&#21040;&#20102;&#36798;&#21040;&#32473;&#23450;&#36924;&#36817;&#31934;&#24230;&#25152;&#38656;&#30340;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#30028;&#38480;&#12290;&#23545;&#31216;&#24773;&#20917;&#19979;&#65292;&#20989;&#25968;&#31867;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#26680;&#20989;&#25968;&#65292;&#32780;&#23545;&#31216;&#24773;&#20917;&#19979;&#20989;&#25968;&#31867;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20877;&#29983;&#26680;&#24052;&#25343;&#36203;&#31354;&#38388;&#20013;&#30340;&#26680;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#36825;&#20123;&#36924;&#36817;&#32467;&#26524;&#34987;&#24212;&#29992;&#20110;&#20998;&#26512;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08856v1 Announce Type: new Abstract: Inner products of neural network feature maps arises in a wide variety of machine learning frameworks as a method of modeling relations between inputs. This work studies the approximation properties of inner products of neural networks. It is shown that the inner product of a multi-layer perceptron with itself is a universal approximator for symmetric positive-definite relation functions. In the case of asymmetric relation functions, it is shown that the inner product of two different multi-layer perceptrons is a universal approximator. In both cases, a bound is obtained on the number of neurons required to achieve a given accuracy of approximation. In the symmetric case, the function class can be identified with kernels of reproducing kernel Hilbert spaces, whereas in the asymmetric case the function class can be identified with kernels of reproducing kernel Banach spaces. Finally, these approximation results are applied to analyzing the
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26102;&#31354;&#28151;&#21512;&#31574;&#30053;&#29983;&#25104;&#29420;&#31435;&#21516;&#20998;&#24067;&#21512;&#25104;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#23454;&#29616;&#26368;&#20339;&#36716;&#36816;&#65292;&#36827;&#19968;&#27493;&#32454;&#21270;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#25216;&#26415;&#35757;&#32451;&#26041;&#27861;</title><link>https://arxiv.org/abs/2402.08847</link><description>&lt;p&gt;
&#26102;&#31354;&#26725;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Space-Time Bridge-Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08847
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26102;&#31354;&#28151;&#21512;&#31574;&#30053;&#29983;&#25104;&#29420;&#31435;&#21516;&#20998;&#24067;&#21512;&#25104;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#23454;&#29616;&#26368;&#20339;&#36716;&#36816;&#65292;&#36827;&#19968;&#27493;&#32454;&#21270;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#25216;&#26415;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#30001;&#19968;&#32452;&#22320;&#38754;&#30495;&#23454;&#26679;&#26412;&#65288;GT&#26679;&#26412;&#65289;&#38544;&#24335;&#23450;&#20041;&#30340;&#39640;&#32500;&#23454;&#20540;&#27010;&#29575;&#20998;&#24067;&#20013;&#29983;&#25104;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#30340;&#26032;&#21512;&#25104;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#36890;&#36807;&#26102;&#31354;&#28151;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#21644;&#31354;&#38388;&#32500;&#24230;&#19978;&#36827;&#34892;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#19977;&#20010;&#30456;&#20114;&#20851;&#32852;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#26088;&#22312;&#23454;&#29616;&#20174;&#23481;&#26131;&#22788;&#29702;&#30340;&#21021;&#22987;&#27010;&#29575;&#20998;&#24067;&#21040;&#30001;GT&#26679;&#26412;&#34920;&#31034;&#30340;&#30446;&#26631;&#20998;&#24067;&#30340;&#26368;&#20339;&#36716;&#36816;&#65306;&#65288;a&#65289;&#21253;&#21547;&#26102;&#31354;&#28151;&#21512;&#30340;&#32447;&#24615;&#36807;&#31243;&#20135;&#29983;&#39640;&#26031;&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#65292;&#65288;b&#65289;&#20854;&#26725;&#25193;&#25955;&#27169;&#25311;&#65292;&#26465;&#20214;&#20026;&#21021;&#22987;&#21644;&#26368;&#32456;&#29366;&#24577;&#21521;&#37327;&#65292;&#20197;&#21450;&#65288;c&#65289;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#25216;&#26415;&#36827;&#34892;&#32454;&#21270;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#36807;&#31243;&#12290;&#25105;&#20204;&#35757;&#32451;&#26041;&#27861;&#30340;&#20851;&#38190;&#22312;&#20110;&#31934;&#35843;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08847v1 Announce Type: cross Abstract: In this study, we introduce a novel method for generating new synthetic samples that are independent and identically distributed (i.i.d.) from high-dimensional real-valued probability distributions, as defined implicitly by a set of Ground Truth (GT) samples. Central to our method is the integration of space-time mixing strategies that extend across temporal and spatial dimensions. Our methodology is underpinned by three interrelated stochastic processes designed to enable optimal transport from an easily tractable initial probability distribution to the target distribution represented by the GT samples: (a) linear processes incorporating space-time mixing that yield Gaussian conditional probability densities, (b) their bridge-diffusion analogs that are conditioned to the initial and final state vectors, and (c) nonlinear stochastic processes refined through score-matching techniques. The crux of our training regime involves fine-tuning
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34701;&#21512;&#27425;&#35201;&#32467;&#26524;&#26469;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#65292;&#26082;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#21448;&#23613;&#21487;&#33021;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;</title><link>https://arxiv.org/abs/2402.08828</link><description>&lt;p&gt;
&#20351;&#29992;&#27425;&#35201;&#32467;&#26524;&#34701;&#21512;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Fusing Individualized Treatment Rules Using Secondary Outcomes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08828
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#34701;&#21512;&#27425;&#35201;&#32467;&#26524;&#26469;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#65292;&#26082;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#21448;&#23613;&#21487;&#33021;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;(ITR)&#26159;&#26681;&#25454;&#24739;&#32773;&#20010;&#20307;&#29305;&#24449;&#21464;&#37327;&#25512;&#33616;&#27835;&#30103;&#26041;&#26696;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290;&#22312;&#35768;&#22810;&#23454;&#36341;&#20013;&#65292;&#29702;&#24819;&#30340;&#20027;&#35201;&#32467;&#26524;&#30340;ITR&#36824;&#39044;&#35745;&#23545;&#20854;&#20182;&#27425;&#35201;&#32467;&#26524;&#36896;&#25104;&#26368;&#23567;&#30340;&#21361;&#23475;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#31181;ITR&#65292;&#23427;&#19981;&#20165;&#26368;&#22823;&#21270;&#20027;&#35201;&#32467;&#26524;&#30340;&#20215;&#20540;&#20989;&#25968;&#65292;&#36824;&#23613;&#21487;&#33021;&#22320;&#25509;&#36817;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;&#35268;&#21017;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#34701;&#21512;&#24809;&#32602;&#65292;&#40723;&#21169;&#22522;&#20110;&#19981;&#21516;&#32467;&#26524;&#30340;ITR&#20135;&#29983;&#31867;&#20284;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20351;&#29992;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#20272;&#35745;ITR&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20027;&#35201;&#32467;&#26524;&#30340;&#20272;&#35745;ITR&#19982;&#27425;&#35201;&#32467;&#26524;&#30340;&#26368;&#20248;ITR&#20043;&#38388;&#30340;&#19968;&#33268;&#29575;&#25910;&#25947;&#27604;&#27809;&#26377;&#32771;&#34385;&#27425;&#35201;&#32467;&#26524;&#26102;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08828v1 Announce Type: cross Abstract: An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26799;&#24230;&#20248;&#21270;&#20013;&#30340;&#36208;&#24266;&#20960;&#20309;&#65292;&#21457;&#29616;&#36208;&#24266;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#30340;&#27934;&#35265;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#23398;&#20064;&#29575;&#33258;&#36866;&#24212;&#31574;&#30053;CLR&#65292;&#35813;&#31574;&#30053;&#19982;&#20984;&#20248;&#21270;&#20013;&#30340;Polyak&#27493;&#38271;&#29305;&#20363;&#19968;&#33268;&#12290;</title><link>https://arxiv.org/abs/2402.08818</link><description>&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#20248;&#21270;&#20013;&#30340;&#36208;&#24266;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Corridor Geometry in Gradient-Based Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26799;&#24230;&#20248;&#21270;&#20013;&#30340;&#36208;&#24266;&#20960;&#20309;&#65292;&#21457;&#29616;&#36208;&#24266;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#30340;&#27934;&#35265;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#23398;&#20064;&#29575;&#33258;&#36866;&#24212;&#31574;&#30053;CLR&#65292;&#35813;&#31574;&#30053;&#19982;&#20984;&#20248;&#21270;&#20013;&#30340;Polyak&#27493;&#38271;&#29305;&#20363;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#26368;&#38497;&#19979;&#38477;&#30340;&#36830;&#32493;&#26354;&#32447;&#65292;&#21363;&#26799;&#24230;&#27969;&#30340;&#35299;&#65292;&#21464;&#25104;&#30452;&#32447;&#65292;&#23558;&#25439;&#22833;&#26354;&#38754;&#30340;&#21306;&#22495;&#21010;&#20998;&#20026;&#36208;&#24266;&#12290;&#25105;&#20204;&#34920;&#26126;&#36208;&#24266;&#33021;&#22815;&#25552;&#20379;&#20851;&#20110;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#30340;&#27934;&#35265;&#65292;&#22240;&#20026;&#36208;&#24266;&#27491;&#26159;&#26799;&#24230;&#19979;&#38477;&#21644;&#26799;&#24230;&#27969;&#36981;&#24490;&#30456;&#21516;&#36712;&#36857;&#19988;&#25439;&#22833;&#32447;&#24615;&#19979;&#38477;&#30340;&#21306;&#22495;&#12290;&#22240;&#27492;&#65292;&#22312;&#36208;&#24266;&#20869;&#37096;&#65292;&#19981;&#23384;&#22312;&#22240;&#26799;&#24230;&#19979;&#38477;&#21644;&#26799;&#24230;&#27969;&#20043;&#38388;&#30340;&#28418;&#31227;&#32780;&#23548;&#33268;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#24212;&#25110;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#12290;&#22522;&#20110;&#36208;&#24266;&#19978;&#25439;&#22833;&#30340;&#32447;&#24615;&#19979;&#38477;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#23398;&#20064;&#29575;&#33258;&#36866;&#24212;&#31574;&#30053;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#36208;&#24266;&#23398;&#20064;&#29575;(CLR)&#12290;CLR&#30340;&#24418;&#24335;&#19982;&#20984;&#20248;&#21270;&#19978;&#26368;&#36817;&#21457;&#29616;&#30340;Polyak&#27493;&#38271;&#29305;&#20363;&#19968;&#33268;&#12290;Polyak&#27493;&#38271;&#36817;&#26399;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#33391;&#22909;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08818v1 Announce Type: cross Abstract: We characterize regions of a loss surface as corridors when the continuous curves of steepest descent -- the solutions of the gradient flow -- become straight lines. We show that corridors provide insights into gradient-based optimization, since corridors are exactly the regions where gradient descent and the gradient flow follow the same trajectory, while the loss decreases linearly. As a result, inside corridors there are no implicit regularization effects or training instabilities that have been shown to occur due to the drift between gradient descent and the gradient flow. Using the loss linear decrease on corridors, we devise a learning rate adaptation scheme for gradient descent; we call this scheme Corridor Learning Rate (CLR). The CLR formulation coincides with a special case of Polyak step-size, discovered in the context of convex optimization. The Polyak step-size has been shown recently to have also good convergence propertie
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#20998;&#38548;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#29992;&#28145;&#24230;&#20026;3&#30340;ReLU&#32593;&#32476;&#23398;&#20064;&#27604;&#29992;&#28145;&#24230;&#20026;2&#30340;ReLU&#32593;&#32476;&#23398;&#20064;&#35201;&#26356;&#39640;&#25928;&#12290;</title><link>https://arxiv.org/abs/2402.08808</link><description>&lt;p&gt;
&#22312;&#35268;&#33539;&#26377;&#30028;&#30340;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#20998;&#38548;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Depth Separation in Norm-Bounded Infinite-Width Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#20998;&#38548;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#29992;&#28145;&#24230;&#20026;3&#30340;ReLU&#32593;&#32476;&#23398;&#20064;&#27604;&#29992;&#28145;&#24230;&#20026;2&#30340;ReLU&#32593;&#32476;&#23398;&#20064;&#35201;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#20998;&#38548;&#38382;&#39064;&#65292;&#20854;&#20013;&#22797;&#26434;&#24615;&#30001;&#26435;&#37325;&#30340;&#25972;&#20307;&#20108;&#27425;$\ell_2$&#33539;&#25968;&#25511;&#21046;&#65288;&#32593;&#32476;&#20013;&#25152;&#26377;&#26435;&#37325;&#30340;&#24179;&#26041;&#21644;&#65289;&#12290;&#20043;&#21069;&#30340;&#28145;&#24230;&#20998;&#38548;&#32467;&#26524;&#20027;&#35201;&#20851;&#27880;&#23485;&#24230;&#26041;&#38754;&#30340;&#20998;&#38548;&#65292;&#36825;&#20123;&#32467;&#26524;&#26080;&#27861;&#35828;&#26126;&#28145;&#24230;&#26159;&#21542;&#20915;&#23450;&#20102;&#22312;&#23485;&#24230;&#26080;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#33021;&#21542;&#23398;&#20064;&#20986;&#36866;&#29992;&#20110;&#24191;&#20041;&#19978;&#30340;&#22909;&#27867;&#21270;&#24615;&#33021;&#30340;&#32593;&#32476;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#23398;&#20064;&#21487;&#34892;&#24615;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#38754;&#30340;&#20998;&#38548;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#26377;&#20123;&#20989;&#25968;&#21487;&#20197;&#36890;&#36807;&#25511;&#21046;&#33539;&#25968;&#30340;&#28145;&#24230;3 ReLU&#32593;&#32476;&#20197;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#30340;&#26679;&#26412;&#37327;&#36827;&#34892;&#23398;&#20064;&#65292;&#20294;&#19981;&#33021;&#36890;&#36807;&#25511;&#21046;&#33539;&#25968;&#30340;&#28145;&#24230;2 ReLU&#32593;&#32476;&#65288;&#20219;&#20309;&#33539;&#25968;&#20540;&#65289;&#20197;&#20122;&#25351;&#25968;&#22797;&#26434;&#24230;&#36827;&#34892;&#23398;&#20064;&#12290;&#21516;&#26102;&#25105;&#20204;&#36824;&#34920;&#26126;&#31867;&#20284;&#30340;&#36870;&#21521;&#35828;&#27861;&#26159;&#19981;&#21487;&#33021;&#25104;&#31435;&#30340;&#65306;&#20219;&#20309;&#21487;&#20197;&#36890;&#36807;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24230;&#36827;&#34892;&#23398;&#20064;&#30340;&#20989;&#25968;&#65292;&#24182;&#19981;&#33021;&#36890;&#36807;&#20122;&#25351;&#25968;&#26679;&#26412;&#22797;&#26434;&#24230;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08808v1 Announce Type: new Abstract: We study depth separation in infinite-width neural networks, where complexity is controlled by the overall squared $\ell_2$-norm of the weights (sum of squares of all weights in the network). Whereas previous depth separation results focused on separation in terms of width, such results do not give insight into whether depth determines if it is possible to learn a network that generalizes well even when the network width is unbounded. Here, we study separation in terms of the sample complexity required for learnability. Specifically, we show that there are functions that are learnable with sample complexity polynomial in the input dimension by norm-controlled depth-3 ReLU networks, yet are not learnable with sub-exponential sample complexity by norm-controlled depth-2 ReLU networks (with any value for the norm). We also show that a similar statement in the reverse direction is not possible: any function learnable with polynomial sample co
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#30340;&#25237;&#24433;-free&#31639;&#27861;&#65292;&#20351;&#29992;&#32447;&#24615;&#20248;&#21270;&#39044;&#27979;&#35775;&#38382;&#22266;&#23450;&#21487;&#34892;&#38598;&#65292;&#24182;&#28385;&#36275;&#26102;&#21464;&#32422;&#26463;&#12290;&#31639;&#27861;&#22312;&#24207;&#21015;&#19978;&#23454;&#29616;&#20102;$\tilde{O}(T^{3/4})$&#30340;&#36951;&#25022;&#21644;$O(T^{7/8})$&#30340;&#32422;&#26463;&#36829;&#21453;&#12290;</title><link>https://arxiv.org/abs/2402.08799</link><description>&lt;p&gt;
&#20855;&#26377;&#26102;&#21464;&#32422;&#26463;&#30340;&#26080;&#25237;&#24433;&#22312;&#32447;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Projection-Free Online Convex Optimization with Time-Varying Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08799
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#30340;&#25237;&#24433;-free&#31639;&#27861;&#65292;&#20351;&#29992;&#32447;&#24615;&#20248;&#21270;&#39044;&#27979;&#35775;&#38382;&#22266;&#23450;&#21487;&#34892;&#38598;&#65292;&#24182;&#28385;&#36275;&#26102;&#21464;&#32422;&#26463;&#12290;&#31639;&#27861;&#22312;&#24207;&#21015;&#19978;&#23454;&#29616;&#20102;$\tilde{O}(T^{3/4})$&#30340;&#36951;&#25022;&#21644;$O(T^{7/8})$&#30340;&#32422;&#26463;&#36829;&#21453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#30340;&#23545;&#25239;&#24615;&#26102;&#21464;&#32422;&#26463;&#35774;&#32622;&#65292;&#20854;&#20013;&#30340;&#25805;&#20316;&#24517;&#39035;&#26159;&#30456;&#23545;&#20110;&#22266;&#23450;&#32422;&#26463;&#38598;&#21487;&#34892;&#30340;&#65292;&#24182;&#19988;&#36824;&#35201;&#24179;&#22343;&#22320;&#28385;&#36275;&#39069;&#22806;&#30340;&#26102;&#21464;&#32422;&#26463;&#12290;&#21463;&#21040;&#22266;&#23450;&#21487;&#34892;&#38598;&#65288;&#30828;&#32422;&#26463;&#65289;&#22312;&#25237;&#24433;&#26041;&#38754;&#22256;&#38590;&#30340;&#24773;&#26223;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#32771;&#34385;&#21482;&#36890;&#36807;&#32447;&#24615;&#20248;&#21270;&#39044;&#27979;&#65288;LOO&#65289;&#35775;&#38382;&#35813;&#38598;&#21512;&#30340;&#26080;&#25237;&#24433;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#38271;&#24230;&#20026;$T$&#30340;&#24207;&#21015;&#19978;&#65292;&#24182;&#20351;&#29992;&#24635;&#20849;$T$&#27425;LOO&#35843;&#29992;&#65292;&#20445;&#35777;&#19982;&#25439;&#22833;&#30456;&#20851;&#30340;$\tilde{O}(T^{3/4})$&#30340;&#36951;&#25022;&#21644;$O(T^{7/8})$&#30340;&#32422;&#26463;&#36829;&#21453;&#65288;&#24573;&#30053;&#25152;&#26377;&#38500;$T$&#20043;&#22806;&#30340;&#37327;&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#36825;&#20123;&#30028;&#38480;&#23545;&#20110;&#24207;&#21015;&#30340;&#20219;&#24847;&#21306;&#38388;&#37117;&#25104;&#31435;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23427;&#21482;&#38656;&#35201;&#23545;&#36719;&#32422;&#26463;&#36827;&#34892;&#19968;&#38454;&#39044;&#27979;&#35775;&#38382;&#65292;&#24182;&#23454;&#29616;&#20102;&#19982;&#25972;&#20010;&#24207;&#21015;&#30456;&#20851;&#30340;&#31867;&#20284;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08799v1 Announce Type: new Abstract: We consider the setting of online convex optimization with adversarial time-varying constraints in which actions must be feasible w.r.t. a fixed constraint set, and are also required on average to approximately satisfy additional time-varying constraints. Motivated by scenarios in which the fixed feasible set (hard constraint) is difficult to project on, we consider projection-free algorithms that access this set only through a linear optimization oracle (LOO). We present an algorithm that, on a sequence of length $T$ and using overall $T$ calls to the LOO, guarantees $\tilde{O}(T^{3/4})$ regret w.r.t. the losses and $O(T^{7/8})$ constraints violation (ignoring all quantities except for $T$) . In particular, these bounds hold w.r.t. any interval of the sequence. We also present a more efficient algorithm that requires only first-order oracle access to the soft constraints and achieves similar bounds w.r.t. the entire sequence. We extend t
&lt;/p&gt;</description></item><item><title>&#20462;&#27491;&#20102;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38169;&#35823;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20998;&#26512;&#25968;&#20540;&#31163;&#25955;&#36941;&#21382;SDE&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#35299;&#20915;&#20102;&#23454;&#36341;&#20013;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08711</link><description>&lt;p&gt;
&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Correction to "Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations"
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08711
&lt;/p&gt;
&lt;p&gt;
&#20462;&#27491;&#20102;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38169;&#35823;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20998;&#26512;&#25968;&#20540;&#31163;&#25955;&#36941;&#21382;SDE&#30340;Wasserstein-2&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#24182;&#35299;&#20915;&#20102;&#23454;&#36341;&#20013;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;San-Serna&#21644;Zygalakis&#30340;&#12298;&#23545;&#20110;&#25968;&#20540;&#36924;&#36817;&#36941;&#21382;SDE&#30340;&#20998;&#24067;&#30340;Wasserstein&#36317;&#31163;&#20272;&#35745;&#12299;&#20013;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#25968;&#20540;&#31163;&#25955;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#20102;&#20462;&#27491;&#12290;&#20182;&#20204;&#20998;&#26512;&#20102;UBU&#31215;&#20998;&#22120;&#65292;&#35813;&#31215;&#20998;&#22120;&#26159;&#20108;&#38454;&#24378;&#22411;&#30340;&#65292;&#24182;&#19988;&#27599;&#20010;&#27493;&#39588;&#21482;&#38656;&#35201;&#19968;&#27425;&#26799;&#24230;&#35780;&#20272;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#29702;&#24819;&#30340;&#38750;&#28176;&#36817;&#20445;&#35777;&#65292;&#29305;&#21035;&#26159;&#22312;Wasserstein-2&#36317;&#31163;&#20013;&#21040;&#36798;&#31163;&#30446;&#26631;&#20998;&#24067; $\epsilon &gt; 0$ &#30340;&#36317;&#31163;&#20165;&#38656; $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ &#27493;&#12290;&#28982;&#32780;&#65292;Sanz-Serna&#21644;Zygalakis (2021)&#20013;&#30340;&#23616;&#37096;&#35823;&#24046;&#20272;&#35745;&#23384;&#22312;&#38169;&#35823;&#65292;&#22312;&#23454;&#36341;&#20013;&#38656;&#35201;&#26356;&#24378;&#30340;&#20551;&#35774;&#25165;&#33021;&#23454;&#29616;&#36825;&#20123;&#22797;&#26434;&#24230;&#20272;&#35745;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#30340;&#35768;&#22810;&#24212;&#29992;&#22330;&#26223;&#20013;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.08711v1 Announce Type: cross Abstract: A method for analyzing non-asymptotic guarantees of numerical discretizations of ergodic SDEs in Wasserstein-2 distance is presented by Sanz-Serna and Zygalakis in ``Wasserstein distance estimates for the distributions of numerical approximations to ergodic stochastic differential equations". They analyze the UBU integrator which is strong order two and only requires one gradient evaluation per step, resulting in desirable non-asymptotic guarantees, in particular $\mathcal{O}(d^{1/4}\epsilon^{-1/2})$ steps to reach a distance of $\epsilon &gt; 0$ in Wasserstein-2 distance away from the target distribution. However, there is a mistake in the local error estimates in Sanz-Serna and Zygalakis (2021), in particular, a stronger assumption is needed to achieve these complexity estimates. This note reconciles the theory with the dimension dependence observed in practice in many applications of interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#39640;&#32500;&#29615;&#22659;&#19979;&#65292;&#38024;&#23545;&#38750;&#21487;&#24494;&#24809;&#32602;&#39033;&#65288;&#22914;&#25512;&#24191;&#30340;LASSO&#21644;&#26680;&#33539;&#25968;&#65289;&#65292;&#36890;&#36807;&#30740;&#31350;LOOCV&#22312;&#20272;&#35745;&#22806;&#26679;&#26412;&#39118;&#38505;&#26102;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#29702;&#35770;&#32570;&#22833;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.08543</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#29615;&#22659;&#19979;&#65292;&#20851;&#20110;&#38750;&#21487;&#24494;&#24809;&#32602;&#39033;&#30340;LOOCV&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis of Leave-one-out Cross Validation for Non-differentiable Penalties under High-dimensional Settings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#39640;&#32500;&#29615;&#22659;&#19979;&#65292;&#38024;&#23545;&#38750;&#21487;&#24494;&#24809;&#32602;&#39033;&#65288;&#22914;&#25512;&#24191;&#30340;LASSO&#21644;&#26680;&#33539;&#25968;&#65289;&#65292;&#36890;&#36807;&#30740;&#31350;LOOCV&#22312;&#20272;&#35745;&#22806;&#26679;&#26412;&#39118;&#38505;&#26102;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#29702;&#35770;&#32570;&#22833;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;&#27491;&#21017;&#21270;&#27169;&#22411;&#30340;&#38750;&#26679;&#26465;&#24809;&#32602;&#39033;&#65288;&#22914;&#25512;&#24191;&#30340;LASSO&#21644;&#26680;&#33539;&#25968;&#65289;&#30340;&#22806;&#26679;&#26412;&#39118;&#38505;&#20272;&#35745;&#26377;&#22823;&#37327;&#30340;&#37325;&#35201;&#24037;&#20316;&#65292;&#20294;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#32570;&#22833;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#25361;&#25112;&#12290;&#25105;&#20204;&#22312;&#27604;&#20363;&#39640;&#32500;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#26679;&#26412;&#37327;n&#21644;&#29305;&#24449;&#25968;p&#37117;&#24456;&#22823;&#65292;&#19988;n/p&#21644;&#20449;&#22122;&#27604;&#65288;&#27599;&#20010;&#35266;&#27979;&#65289;&#20445;&#25345;&#26377;&#38480;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;LOOCV&#22312;&#20272;&#35745;&#22806;&#26679;&#26412;&#39118;&#38505;&#26102;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#12290;&#26412;&#25991;&#25552;&#20986;&#30340;&#29702;&#35770;&#26694;&#26550;&#20026;&#38416;&#26126;LOOCV&#30340;&#20934;&#30830;&#24615;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite a large and significant body of recent work focused on estimating the out-of-sample risk of regularized models in the high dimensional regime, a theoretical understanding of this problem for non-differentiable penalties such as generalized LASSO and nuclear norm is missing. In this paper we resolve this challenge. We study this problem in the proportional high dimensional regime where both the sample size n and number of features p are large, and n/p and the signal-to-noise ratio (per observation) remain finite. We provide finite sample upper bounds on the expected squared error of leave-one-out cross-validation (LO) in estimating the out-of-sample risk. The theoretical framework presented here provides a solid foundation for elucidating empirical findings that show the accuracy of LO.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22343;&#21248;&#21270;&#30340;&#26041;&#24335;&#30830;&#20999;&#23454;&#29616;&#20102;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#20854;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#37319;&#26679;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;KL&#25955;&#24230;&#20445;&#35777;&#12290;&#36825;&#19968;&#26041;&#27861;&#22312;&#24314;&#27169;&#31163;&#25955;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.08095</link><description>&lt;p&gt;
&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#20998;&#26512;&#65306;&#36890;&#36807;&#22343;&#21248;&#21270;&#30340;&#30830;&#20999;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Discrete Diffusion Model: Exact Implementation through Uniformization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22343;&#21248;&#21270;&#30340;&#26041;&#24335;&#30830;&#20999;&#23454;&#29616;&#20102;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;&#20854;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#37319;&#26679;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;KL&#25955;&#24230;&#20445;&#35777;&#12290;&#36825;&#19968;&#26041;&#27861;&#22312;&#24314;&#27169;&#31163;&#25955;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25968;&#25454;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#32463;&#39564;&#25104;&#21151;&#12290;&#26368;&#36817;&#65292;&#19968;&#20123;&#21162;&#21147;&#24050;&#32463;&#34987;&#20570;&#20986;&#26469;&#65292;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#26694;&#26550;&#36866;&#24212;&#21040;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#65292;&#20026;&#24314;&#27169;&#26412;&#36136;&#19978;&#26159;&#31163;&#25955;&#25968;&#25454;&#65288;&#22914;&#35821;&#35328;&#21644;&#22270;&#24418;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#33258;&#28982;&#30340;&#26041;&#27861;&#12290;&#36825;&#36890;&#36807;&#23558;&#21069;&#21521;&#22122;&#22768;&#36807;&#31243;&#21644;&#30456;&#24212;&#30340;&#36870;&#36807;&#31243;&#37117;&#26500;&#24314;&#20026;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#38142;&#65288;CTMC&#65289;&#26469;&#23454;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#36830;&#32493;&#39532;&#23572;&#21487;&#22827;&#38142;&#22343;&#21248;&#21270;&#30340;&#31639;&#27861;&#65292;&#22312;&#38543;&#26426;&#26102;&#38388;&#28857;&#19978;&#23454;&#29616;&#36716;&#31227;&#12290;&#22312;&#20851;&#20110;&#31163;&#25955;&#24471;&#20998;&#20989;&#25968;&#23398;&#20064;&#30340;&#21512;&#29702;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20174;&#36229;&#31435;&#26041;&#20307;&#19978;&#30340;&#20219;&#20309;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#25152;&#38656;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#21644;KL&#25955;&#24230;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19982;&#22312;$\mathbb{R}^d$&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#25104;&#23601;&#30456;&#19968;&#33268;&#65292;&#24182;&#36827;&#19968;&#27493;&#24378;&#35843;&#20102;d&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have achieved huge empirical success in data generation tasks. Recently, some efforts have been made to adapt the framework of diffusion models to discrete state space, providing a more natural approach for modeling intrinsically discrete data, such as language and graphs. This is achieved by formulating both the forward noising process and the corresponding reversed process as Continuous Time Markov Chains (CTMCs). In this paper, we investigate the theoretical properties of the discrete diffusion model. Specifically, we introduce an algorithm leveraging the uniformization of continuous Markov chains, implementing transitions on random time points. Under reasonable assumptions on the learning of the discrete score function, we derive Total Variation distance and KL divergence guarantees for sampling from any distribution on a hypercube. Our results align with state-of-the-art achievements for diffusion models in $\mathbb{R}^d$ and further underscore the advantages of d
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;&#65292;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.08082</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models break the curse of dimensionality in learning a family of sub-Gaussian probability distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.08082
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#31361;&#30772;&#20102;&#32500;&#25968;&#28798;&#38590;&#65292;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#22312;&#24040;&#22823;&#30340;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#30340;&#25968;&#23398;&#22522;&#30784;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;SGMs&#22312;&#23398;&#20064;&#19968;&#20010;&#23376;&#39640;&#26031;&#27010;&#29575;&#20998;&#24067;&#26063;&#20013;&#30340;&#36817;&#20284;&#21644;&#27867;&#21270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20851;&#20110;&#27010;&#29575;&#20998;&#24067;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#21363;&#30456;&#23545;&#23494;&#24230;&#19982;&#26631;&#20934;&#39640;&#26031;&#27979;&#24230;&#30340;&#30456;&#23545;&#23494;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#23545;&#25968;&#30456;&#23545;&#23494;&#24230;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23616;&#37096;&#36924;&#36817;&#65292;&#24182;&#19988;&#32593;&#32476;&#21442;&#25968;&#21487;&#20197;&#36866;&#24403;&#22320;&#21463;&#38480;&#65292;&#37027;&#20040;&#36890;&#36807;&#32463;&#39564;&#20998;&#25968;&#21305;&#37197;&#29983;&#25104;&#30340;&#20998;&#24067;&#20197;&#32500;&#24230;&#26080;&#20851;&#30340;&#36895;&#29575;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#31034;&#20363;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#20854;&#20013;&#21253;&#25324;&#26576;&#20123;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#30340;&#19968;&#20010;&#20851;&#38190;&#28857;&#26159;&#25512;&#23548;&#20986;&#19982;&#27491;&#21521;&#36807;&#31243;&#30456;&#20851;&#30340;&#30495;&#23454;&#24471;&#20998;&#20989;&#25968;&#30340;&#32500;&#24230;&#26080;&#20851;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
While score-based generative models (SGMs) have achieved remarkable success in enormous image generation tasks, their mathematical foundations are still limited. In this paper, we analyze the approximation and generalization of SGMs in learning a family of sub-Gaussian probability distributions. We introduce a notion of complexity for probability distributions in terms of their relative density with respect to the standard Gaussian measure. We prove that if the log-relative density can be locally approximated by a neural network whose parameters can be suitably bounded, then the distribution generated by empirical score matching approximates the target distribution in total variation with a dimension-independent rate. We illustrate our theory through examples, which include certain mixtures of Gaussians. An essential ingredient of our proof is to derive a dimension-free deep neural network approximation rate for the true score function associated with the forward process, which is inte
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65292;&#35813;&#25351;&#25968;&#26681;&#25454;&#29616;&#26377;&#30340;&#22522;&#30784;&#25351;&#25968;&#23450;&#20041;&#65292;&#24182;&#29992;&#20110;&#26816;&#27979;&#27425;&#20248;&#32858;&#31867;&#25968;&#65292;&#36890;&#36807;&#19982;&#20854;&#20182;&#25351;&#25968;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02162</link><description>&lt;p&gt;
&#19968;&#20010;&#36125;&#21494;&#26031;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Bayesian cluster validity index
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02162
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65292;&#35813;&#25351;&#25968;&#26681;&#25454;&#29616;&#26377;&#30340;&#22522;&#30784;&#25351;&#25968;&#23450;&#20041;&#65292;&#24182;&#29992;&#20110;&#26816;&#27979;&#27425;&#20248;&#32858;&#31867;&#25968;&#65292;&#36890;&#36807;&#19982;&#20854;&#20182;&#25351;&#25968;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#32858;&#31867;&#31639;&#27861;&#26102;&#65292;&#36873;&#25321;&#32858;&#31867;&#25968;&#26159;&#20851;&#38190;&#27493;&#39588;&#20043;&#19968;&#12290;&#20026;&#20102;&#23436;&#25104;&#36825;&#20010;&#20219;&#21153;&#65292;&#24341;&#20837;&#20102;&#21508;&#31181;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65288;CVIs&#65289;&#12290;&#22823;&#22810;&#25968;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#37117;&#34987;&#23450;&#20041;&#20026;&#26816;&#27979;&#25968;&#25454;&#38598;&#20013;&#38544;&#34255;&#30340;&#26368;&#20248;&#32858;&#31867;&#25968;&#12290;&#28982;&#32780;&#65292;&#29992;&#25143;&#26377;&#26102;&#24182;&#19981;&#26399;&#26395;&#33719;&#24471;&#26368;&#20248;&#32858;&#31867;&#25968;&#65292;&#32780;&#26159;&#26356;&#36866;&#21512;&#20182;&#20204;&#24212;&#29992;&#30340;&#27425;&#20248;&#32858;&#31867;&#25968;&#12290;&#36825;&#20419;&#20351;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#29616;&#26377;&#22522;&#30784;&#25351;&#25968;&#30340;&#36125;&#21494;&#26031;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#25968;&#65288;BCVI&#65289;&#12290;&#35813;&#25351;&#25968;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#25110;&#24191;&#20041;&#29380;&#21033;&#20811;&#38647;&#20808;&#39564;&#23450;&#20041;&#65292;&#24471;&#21040;&#30456;&#21516;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#28982;&#21518;&#25105;&#20204;&#22522;&#20110;Wiroonsri&#25351;&#25968;&#65288;WI&#65289;&#21644;Wiroonsri-Preedasawakul&#25351;&#25968;&#65288;WP&#65289;&#20316;&#20026;&#30828;&#32858;&#31867;&#21644;&#36719;&#32858;&#31867;&#30340;&#22522;&#30784;&#25351;&#25968;&#26469;&#27979;&#35797;&#25105;&#20204;&#30340;BCVI&#12290;&#25105;&#20204;&#23558;&#23427;&#20204;&#30340;&#32467;&#26524;&#19982;&#21407;&#22987;&#30340;&#22522;&#30784;&#25351;&#25968;&#20197;&#21450;&#19968;&#20123;&#20854;&#20182;&#23384;&#22312;&#30340;CVIs&#65288;&#21253;&#25324;Davies and Bouldin (DB)&#65292;Starczewski (STR)&#65289;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selecting the number of clusters is one of the key processes when applying clustering algorithms. To fulfill this task, various cluster validity indices (CVIs) have been introduced. Most of the cluster validity indices are defined to detect the optimal number of clusters hidden in a dataset. However, users sometimes do not expect to get the optimal number of groups but a secondary one which is more reasonable for their applications. This has motivated us to introduce a Bayesian cluster validity index (BCVI) based on existing underlying indices. This index is defined based on either Dirichlet or Generalized Dirichlet priors which result in the same posterior distribution. Our BCVI is then tested based on the Wiroonsri index (WI), and the Wiroonsri-Preedasawakul index (WP) as underlying indices for hard and soft clustering, respectively. We compare their outcomes with the original underlying indices, as well as a few more existing CVIs including Davies and Bouldin (DB), Starczewski (STR)
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#25506;&#35752;&#20102;Transformer&#22312;&#38271;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#32452;&#20214;&#23545;&#34920;&#36798;&#33021;&#21147;&#30340;&#24433;&#21709;&#26426;&#21046;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#20851;&#38190;&#21442;&#25968;&#23545;Transformer&#30340;&#20316;&#29992;&#65292;&#24182;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;</title><link>https://arxiv.org/abs/2402.00522</link><description>&lt;p&gt;
&#29702;&#35299;Transformer&#22312;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Understanding the Expressive Power and Mechanisms of Transformer for Sequence Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#31995;&#32479;&#22320;&#25506;&#35752;&#20102;Transformer&#22312;&#38271;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#32452;&#20214;&#23545;&#34920;&#36798;&#33021;&#21147;&#30340;&#24433;&#21709;&#26426;&#21046;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#20851;&#38190;&#21442;&#25968;&#23545;Transformer&#30340;&#20316;&#29992;&#65292;&#24182;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;Transformer&#22312;&#38271;&#12289;&#31232;&#30095;&#21644;&#22797;&#26434;&#35760;&#24518;&#30340;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#36817;&#20284;&#24615;&#36136;&#36827;&#34892;&#20102;&#31995;&#32479;&#30740;&#31350;&#12290;&#25105;&#20204;&#35843;&#26597;&#20102;Transformer&#30340;&#19981;&#21516;&#32452;&#20214;&#65288;&#22914;&#28857;&#31215;&#33258;&#27880;&#24847;&#21147;&#12289;&#20301;&#32622;&#32534;&#30721;&#21644;&#21069;&#39304;&#23618;&#65289;&#26159;&#22914;&#20309;&#24433;&#21709;&#20854;&#34920;&#36798;&#33021;&#21147;&#30340;&#26426;&#21046;&#65292;&#24182;&#36890;&#36807;&#24314;&#31435;&#26126;&#30830;&#30340;&#36817;&#20284;&#29575;&#26469;&#30740;&#31350;&#23427;&#20204;&#30340;&#32508;&#21512;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;Transformer&#20013;&#20851;&#38190;&#21442;&#25968;&#65288;&#22914;&#23618;&#25968;&#21644;&#27880;&#24847;&#21147;&#22836;&#25968;&#65289;&#30340;&#20316;&#29992;&#65292;&#24182;&#19988;&#36825;&#20123;&#27934;&#23519;&#36824;&#20026;&#26367;&#20195;&#26550;&#26500;&#25552;&#20379;&#20102;&#33258;&#28982;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We conduct a systematic study of the approximation properties of Transformer for sequence modeling with long, sparse and complicated memory. We investigate the mechanisms through which different components of Transformer, such as the dot-product self-attention, positional encoding and feed-forward layer, affect its expressive power, and we study their combined effects through establishing explicit approximation rates. Our study reveals the roles of critical parameters in the Transformer, such as the number of layers and the number of attention heads, and these insights also provide natural suggestions for alternative architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#19982;&#27880;&#24847;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32593;&#32476;&#23450;&#20301;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#20986;&#33394;&#30340;&#31934;&#30830;&#24230;&#65292;&#29978;&#33267;&#22312;&#20005;&#37325;&#38750;&#30452;&#35270;&#35270;&#32447;&#26465;&#20214;&#19979;&#20063;&#33021;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#20851;&#27880;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25913;&#21892;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#21644;&#23545;&#36229;&#21442;&#25968;&#30340;&#25935;&#24863;&#24615;&#12290;</title><link>https://arxiv.org/abs/2311.16856</link><description>&lt;p&gt;
&#20851;&#27880;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#31283;&#20581;&#30340;&#22823;&#35268;&#27169;&#32593;&#32476;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Attentional Graph Neural Networks for Robust Massive Network Localization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#22270;&#31070;&#32463;&#32593;&#32476;&#19982;&#27880;&#24847;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32593;&#32476;&#23450;&#20301;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#20986;&#33394;&#30340;&#31934;&#30830;&#24230;&#65292;&#29978;&#33267;&#22312;&#20005;&#37325;&#38750;&#30452;&#35270;&#35270;&#32447;&#26465;&#20214;&#19979;&#20063;&#33021;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;&#20851;&#27880;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25913;&#21892;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#21644;&#23545;&#36229;&#21442;&#25968;&#30340;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#24050;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22312;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#20026;&#20102;&#21457;&#25496;GNNs&#22312;&#22238;&#24402;&#20013;&#30340;&#28508;&#21147;&#65292;&#26412;&#25991;&#23558;GNNs&#19982;&#27880;&#24847;&#26426;&#21046;&#30456;&#32467;&#21512;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20854;&#36866;&#24212;&#24615;&#21644;&#40065;&#26834;&#24615;&#24443;&#24213;&#25913;&#21464;&#20102;&#24207;&#21015;&#23398;&#20064;&#20219;&#21153;&#30340;&#25216;&#26415;&#65292;&#20197;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38750;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65306;&#32593;&#32476;&#23450;&#20301;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#21367;&#31215;&#32593;&#32476;(GCN)&#30340;&#26032;&#22411;&#32593;&#32476;&#23450;&#20301;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#20005;&#37325;&#38750;&#30452;&#35270;&#35270;&#32447;(NLOS)&#26465;&#20214;&#19979;&#20063;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#31934;&#24230;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#32321;&#29712;&#30340;&#31163;&#32447;&#26657;&#20934;&#25110;NLOS&#35782;&#21035;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#27880;&#22270;&#31070;&#32463;&#32593;&#32476;(AGNN)&#27169;&#22411;&#65292;&#26088;&#22312;&#25913;&#21892;&#22522;&#20110;GCN&#26041;&#27861;&#30340;&#26377;&#38480;&#28789;&#27963;&#24615;&#21644;&#23545;&#36229;&#21442;&#25968;&#30340;&#39640;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.16856v2 Announce Type: replace Abstract: In recent years, Graph neural networks (GNNs) have emerged as a prominent tool for classification tasks in machine learning. However, their application in regression tasks remains underexplored. To tap the potential of GNNs in regression, this paper integrates GNNs with attention mechanism, a technique that revolutionized sequential learning tasks with its adaptability and robustness, to tackle a challenging nonlinear regression problem: network localization. We first introduce a novel network localization method based on graph convolutional network (GCN), which exhibits exceptional precision even under severe non-line-of-sight (NLOS) conditions, thereby diminishing the need for laborious offline calibration or NLOS identification. We further propose an attentional graph neural network (AGNN) model, aimed at improving the limited flexibility and mitigating the high sensitivity to the hyperparameter of the GCN-based method. The AGNN co
&lt;/p&gt;</description></item><item><title>&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#20013;&#30340;&#20272;&#35745;&#26102;&#24207;&#19981;&#19968;&#33268;&#24230;&#26469;&#25311;&#21512;&#20540;&#20989;&#25968;&#65292;&#20855;&#26377;&#32479;&#35745;&#20248;&#21183;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#20540;&#20272;&#35745;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#20004;&#20010;&#29366;&#24577;&#30340;&#20540;&#24046;&#20272;&#35745;&#20013;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2301.13289</link><description>&lt;p&gt;
&#20851;&#20110;&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#30340;&#32479;&#35745;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Benefits of Temporal Difference Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.13289
&lt;/p&gt;
&lt;p&gt;
&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#20013;&#30340;&#20272;&#35745;&#26102;&#24207;&#19981;&#19968;&#33268;&#24230;&#26469;&#25311;&#21512;&#20540;&#20989;&#25968;&#65292;&#20855;&#26377;&#32479;&#35745;&#20248;&#21183;&#65292;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#20540;&#20272;&#35745;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#20004;&#20010;&#29366;&#24577;&#30340;&#20540;&#24046;&#20272;&#35745;&#20013;&#33719;&#24471;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#20851;&#20110;&#21160;&#20316;&#21644;&#38271;&#26399;&#22870;&#21169;&#30340;&#25968;&#25454;&#38598;&#65292;&#30452;&#25509;&#20272;&#35745;&#26041;&#27861;&#36890;&#36807;&#23558;&#20540;&#20989;&#25968;&#19982;&#35757;&#32451;&#25968;&#25454;&#30340;&#39044;&#27979;&#35823;&#24046;&#26368;&#23567;&#21270;&#26469;&#25311;&#21512;&#12290;&#32780;&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;(TD)&#26041;&#27861;&#21017;&#36890;&#36807;&#26368;&#23567;&#21270;&#22312;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#20013;&#36827;&#34892;&#30340;&#20272;&#35745;&#20043;&#38388;&#30340;&#26102;&#24207;&#19981;&#19968;&#33268;&#31243;&#24230;&#26469;&#25311;&#21512;&#20540;&#20989;&#25968;&#12290;&#38024;&#23545;&#26377;&#38480;&#29366;&#24577;Markov&#38142;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#31181;&#26041;&#27861;&#30340;&#32479;&#35745;&#20248;&#21183;&#30340;&#28165;&#26224;&#28176;&#36827;&#29702;&#35770;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#30452;&#35266;&#30340;&#36870;&#36712;&#36857;&#27719;&#38598;&#31995;&#25968;&#23436;&#20840;&#21051;&#30011;&#20102;&#20540;&#20272;&#35745;&#22343;&#26041;&#35823;&#24046;&#30340;&#30334;&#20998;&#27604;&#20943;&#23569;&#12290;&#26681;&#25454;&#38382;&#39064;&#32467;&#26500;&#30340;&#19981;&#21516;&#65292;&#36825;&#31181;&#20943;&#23569;&#21487;&#20197;&#26159;&#24040;&#22823;&#30340;&#25110;&#19981;&#23384;&#22312;&#30340;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#20010;&#29366;&#24577;&#30340;&#20540;&#24046;&#20272;&#35745;&#21487;&#20197;&#26377;&#24040;&#22823;&#30340;&#25913;&#36827;&#65306;TD&#30340;&#35823;&#24046;&#21463;&#21040;&#38382;&#39064;&#36712;&#36857;&#20132;&#21449;&#26102;&#38388;&#30340;&#30028;&#38480;&#65292;&#32780;&#36825;&#20010;&#30028;&#38480;&#21487;&#33021;&#36828;&#23567;&#20110;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.13289v3 Announce Type: replace Abstract: Given a dataset on actions and resulting long-term rewards, a direct estimation approach fits value functions that minimize prediction error on the training data. Temporal difference learning (TD) methods instead fit value functions by minimizing the degree of temporal inconsistency between estimates made at successive time-steps. Focusing on finite state Markov chains, we provide a crisp asymptotic theory of the statistical advantages of this approach. First, we show that an intuitive inverse trajectory pooling coefficient completely characterizes the percent reduction in mean-squared error of value estimates. Depending on problem structure, the reduction could be enormous or nonexistent. Next, we prove that there can be dramatic improvements in estimates of the difference in value-to-go for two states: TD's errors are bounded in terms of a novel measure - the problem's trajectory crossing time - which can be much smaller than the pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#35843;&#33410;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#21644;&#36866;&#24212;&#31639;&#27861;&#65292;&#25361;&#25112;&#20102;&#23545;&#19987;&#23478;&#30340;&#20449;&#24515;&#20551;&#35774;&#65292;&#24182;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2301.07530</link><description>&lt;p&gt;
&#20048;&#35266;&#35843;&#33410;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimistically Tempered Online Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.07530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#35843;&#33410;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#21644;&#36866;&#24212;&#31639;&#27861;&#65292;&#25361;&#25112;&#20102;&#23545;&#19987;&#23478;&#30340;&#20449;&#24515;&#20551;&#35774;&#65292;&#24182;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20048;&#35266;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#24050;&#32463;&#34987;&#24320;&#21457;&#20986;&#26469;&#65292;&#20197;&#21033;&#29992;&#19987;&#23478;&#24847;&#35265;&#65292;&#20551;&#35774;&#19987;&#23478;&#24847;&#35265;&#24635;&#26159;&#26377;&#29992;&#30340;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21487;&#20197;&#21512;&#29702;&#22320;&#23545;&#36825;&#20123;&#24847;&#35265;&#19982;&#22522;&#20110;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#25552;&#20379;&#30340;&#23398;&#20064;&#20449;&#24687;&#30340;&#30456;&#20851;&#24615;&#25552;&#20986;&#36136;&#30097;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#23545;&#19987;&#23478;&#30340;&#20449;&#24515;&#20551;&#35774;&#65292;&#24182;&#24320;&#21457;&#20102;&#20048;&#35266;&#35843;&#33410;&#65288;OT&#65289;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#20197;&#21450;&#22312;&#32447;&#31639;&#27861;&#30340;OT&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#21160;&#24577;&#36951;&#25022;&#30028;&#38480;&#30340;&#31283;&#22266;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#26368;&#32456;&#39564;&#35777;&#20102;OT&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.07530v2 Announce Type: replace Abstract: Optimistic Online Learning algorithms have been developed to exploit expert advices, assumed optimistically to be always useful. However, it is legitimate to question the relevance of such advices \emph{w.r.t.} the learning information provided by gradient-based online algorithms. In this work, we challenge the confidence assumption on the expert and develop the \emph{optimistically tempered} (OT) online learning framework as well as OT adaptations of online algorithms. Our algorithms come with sound theoretical guarantees in the form of dynamic regret bounds, and we eventually provide experimental validation of the usefulness of the OT approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#39640;&#32500;&#38750;&#23450;&#21521;&#22270;&#27169;&#22411;&#20013;&#22788;&#29702;&#20219;&#24847;&#28151;&#21512;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#28508;&#21464;&#37327;&#39640;&#26031;copula&#26694;&#26550;&#20013;&#24212;&#29992;&#32463;&#20856;&#30340;&#22810;&#39033;&#21644;&#22810;&#24207;&#30456;&#20851;&#30340;&#24605;&#24819;&#12290;</title><link>https://arxiv.org/abs/2211.11700</link><description>&lt;p&gt;
&#39640;&#32500;&#38750;&#23450;&#21521;&#22270;&#27169;&#22411;&#20013;&#30340;&#20219;&#24847;&#28151;&#21512;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Undirected Graphical Models for Arbitrary Mixed Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.11700
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#39640;&#32500;&#38750;&#23450;&#21521;&#22270;&#27169;&#22411;&#20013;&#22788;&#29702;&#20219;&#24847;&#28151;&#21512;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#28508;&#21464;&#37327;&#39640;&#26031;copula&#26694;&#26550;&#20013;&#24212;&#29992;&#32463;&#20856;&#30340;&#22810;&#39033;&#21644;&#22810;&#24207;&#30456;&#20851;&#30340;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#27169;&#22411;&#26159;&#25506;&#32034;&#22797;&#26434;&#22810;&#21464;&#37327;&#25968;&#25454;&#20013;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#23398;&#20064;&#36825;&#20123;&#22270;&#27169;&#22411;&#30340;&#26041;&#27861;&#22312;&#25152;&#26377;&#21464;&#37327;&#37117;&#26159;&#36830;&#32493;&#25110;&#31163;&#25955;&#30340;&#24773;&#20917;&#19979;&#24050;&#32463;&#24456;&#25104;&#29087;&#65292;&#21253;&#25324;&#39640;&#32500;&#24773;&#20917;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#28041;&#21450;&#19981;&#21516;&#31867;&#22411;&#30340;&#21464;&#37327;&#65288;&#20363;&#22914;&#36830;&#32493;&#12289;&#35745;&#25968;&#12289;&#20108;&#20540;&#12289;&#26377;&#24207;&#31561;&#65289;&#65292;&#20854;&#32852;&#21512;&#20998;&#26512;&#26159;&#38750;&#24179;&#20961;&#30340;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#24050;&#32463;&#23637;&#31034;&#20102;&#22914;&#20309;&#22788;&#29702;&#20108;&#20540;-&#36830;&#32493;&#24773;&#20917;&#65292;&#20294;&#26159;&#19968;&#33324;&#30340;&#28151;&#21512;&#21464;&#37327;&#31867;&#22411;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#31616;&#21333;&#32780;&#26377;&#29992;&#22320;&#35266;&#23519;&#21040;&#65292;&#20851;&#20110;&#22810;&#39033;&#19982;&#22810;&#24207;&#30456;&#20851;&#30340;&#32463;&#20856;&#24605;&#24819;&#21487;&#20197;&#22312;&#28508;&#21464;&#37327;&#39640;&#26031;copula&#26694;&#26550;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.11700v2 Announce Type: replace-cross Abstract: Graphical models are an important tool in exploring relationships between variables in complex, multivariate data. Methods for learning such graphical models are well developed in the case where all variables are either continuous or discrete, including in high-dimensions. However, in many applications data span variables of different types (e.g. continuous, count, binary, ordinal, etc.), whose principled joint analysis is nontrivial. Latent Gaussian copula models, in which all variables are modeled as transformations of underlying jointly Gaussian variables, represent a useful approach. Recent advances have shown how the binary-continuous case can be tackled, but the general mixed variable type regime remains challenging. In this work, we make the simple yet useful observation that classical ideas concerning polychoric and polyserial correlations can be leveraged in a latent Gaussian copula framework. Building on this observati
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#32622;&#25442;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#31181;&#26550;&#26500;&#33021;&#22815;&#35299;&#20915;&#20256;&#32479; QNNs &#36935;&#21040;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#21644;&#36139;&#30240;&#30340;&#39640;&#21407;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#22312;&#23569;&#37327;&#25968;&#25454;&#19978;&#36827;&#34892;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;</title><link>https://arxiv.org/abs/2210.09974</link><description>&lt;p&gt;
&#12298;&#32622;&#25442;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#20445;&#35777;&#12299;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees for Permutation-Equivariant Quantum Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.09974
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#32622;&#25442;&#31561;&#21464;&#37327;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#31181;&#26550;&#26500;&#33021;&#22815;&#35299;&#20915;&#20256;&#32479; QNNs &#36935;&#21040;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#21644;&#36139;&#30240;&#30340;&#39640;&#21407;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#22312;&#23569;&#37327;&#25968;&#25454;&#19978;&#36827;&#34892;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26377;&#30528;&#24040;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#22312;&#37322;&#25918;&#20854;&#20840;&#37096;&#28508;&#21147;&#20043;&#21069;&#65292;&#25105;&#20204;&#24517;&#39035;&#20811;&#26381;&#19968;&#20123;&#25361;&#25112;&#12290;&#20363;&#22914;&#65292;&#22522;&#20110;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNN&#65289;&#30340;&#27169;&#22411;&#21487;&#33021;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36935;&#21040;&#36807;&#22810;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#21644;&#36139;&#30240;&#30340;&#39640;&#21407;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;&#20960;&#20309;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;GQML&#65289;&#36825;&#19968;&#26032;&#20852;&#39046;&#22495;&#24050;&#34987;&#25552;&#20986;&#20316;&#20026;&#20854;&#20013;&#19968;&#20123;&#38382;&#39064;&#30340;&#28508;&#22312;&#35299;&#20915;&#26041;&#26696;&#12290;GQML &#30340;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#25105;&#20204;&#24212;&#35813;&#35774;&#35745;&#32534;&#30721;&#38382;&#39064;&#30340;&#23545;&#31216;&#24615;&#30340;&#26550;&#26500;&#65292;&#20363;&#22914;&#31561;&#21464; QNNs&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#20855;&#26377;&#32622;&#25442;&#23545;&#31216;&#24615;&#65288;&#21363;&#23545;&#31216;&#32676; $S_n$&#65289;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314; $S_n$-equivariant QNNs&#12290;&#25105;&#20204;&#23545;&#23427;&#20204;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#20998;&#26512;&#30740;&#31350;&#65292;&#35777;&#26126;&#23427;&#20204;&#19981;&#20250;&#36973;&#36935;&#36139;&#30240;&#30340;&#39640;&#21407;&#38382;&#39064;&#65292;&#33021;&#22815;&#24555;&#36895;&#23454;&#29616;&#36807;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20174;&#23569;&#37327;&#30340;&#25968;&#25454;&#20013;&#36827;&#34892;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#20223;&#30495;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.09974v3 Announce Type: replace-cross Abstract: Despite the great promise of quantum machine learning models, there are several challenges one must overcome before unlocking their full potential. For instance, models based on quantum neural networks (QNNs) can suffer from excessive local minima and barren plateaus in their training landscapes. Recently, the nascent field of geometric quantum machine learning (GQML) has emerged as a potential solution to some of those issues. The key insight of GQML is that one should design architectures, such as equivariant QNNs, encoding the symmetries of the problem at hand. Here, we focus on problems with permutation symmetry (i.e., the group of symmetry $S_n$), and show how to build $S_n$-equivariant QNNs. We provide an analytical study of their performance, proving that they do not suffer from barren plateaus, quickly reach overparametrization, and generalize well from small amounts of data. To verify our results, we perform numerical s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#23545;&#25239;&#24615;&#26597;&#35810;&#40065;&#26834;&#24615;&#30340;&#21160;&#24577;&#32500;&#25252;&#26680;&#23494;&#24230;&#20272;&#35745;&#25968;&#25454;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20122;&#20108;&#27425;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;&#20122;&#32447;&#24615;&#26356;&#26032;&#26102;&#38388;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;</title><link>https://arxiv.org/abs/2208.03915</link><description>&lt;p&gt;
&#21160;&#24577;&#32500;&#25252;&#26680;&#23494;&#24230;&#20272;&#35745;&#25968;&#25454;&#32467;&#26500;&#65306;&#20174;&#23454;&#36341;&#21040;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Dynamic Maintenance of Kernel Density Estimation Data Structure: From Practice to Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.03915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#23545;&#25239;&#24615;&#26597;&#35810;&#40065;&#26834;&#24615;&#30340;&#21160;&#24577;&#32500;&#25252;&#26680;&#23494;&#24230;&#20272;&#35745;&#25968;&#25454;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20122;&#20108;&#27425;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;&#20122;&#32447;&#24615;&#26356;&#26032;&#26102;&#38388;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kernel density estimation (KDE)&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#35813;&#38382;&#39064;&#23450;&#20041;&#22914;&#19979;&#65306;&#32473;&#23450;&#19968;&#20010;&#26680;&#20989;&#25968;$f(x,y)$&#21644;&#19968;&#32452;&#28857;$\{x_1, x_2, \cdots, x_n \} \subset \mathbb{R}^d$&#65292;&#25105;&#20204;&#24076;&#26395;&#35745;&#31639;&#20219;&#24847;&#26597;&#35810;&#28857;$y \in \mathbb{R}^d$&#30340;$\frac{1}{n}\sum_{i=1}^{n} f(x_i,y)$&#12290;&#36817;&#24180;&#26469;&#65292;&#20351;&#29992;&#25968;&#25454;&#32467;&#26500;&#26469;&#39640;&#25928;&#35745;&#31639;KDE&#30340;&#36235;&#21183;&#26085;&#30410;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;KDE&#25968;&#25454;&#32467;&#26500;&#25552;&#20379;&#30340;&#26159;&#38745;&#24577;&#35774;&#32622;&#19979;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#23545;&#20110;&#21160;&#24577;&#21464;&#21270;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#40065;&#26834;&#24615;&#38382;&#39064;&#24182;&#26410;&#24471;&#21040;&#35299;&#20915;&#12290;&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#20855;&#26377;&#23545;&#25239;&#24615;&#26597;&#35810;&#40065;&#26834;&#24615;&#30340;&#21160;&#24577;&#32500;&#25252;KDE&#25968;&#25454;&#32467;&#26500;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;KDE&#25968;&#25454;&#32467;&#26500;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;KDE&#25968;&#25454;&#32467;&#26500;&#21482;&#38656;&#35201;&#20122;&#20108;&#27425;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25968;&#25454;&#32467;&#26500;&#25903;&#25345;&#25968;&#25454;&#38598;&#30340;&#21160;&#24577;&#26356;&#26032;&#65292;&#19988;&#26356;&#26032;&#26102;&#38388;&#20026;&#20122;&#32447;&#24615;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2208.03915v2 Announce Type: replace Abstract: Kernel density estimation (KDE) stands out as a challenging task in machine learning. The problem is defined in the following way: given a kernel function $f(x,y)$ and a set of points $\{x_1, x_2, \cdots, x_n \} \subset \mathbb{R}^d$, we would like to compute $\frac{1}{n}\sum_{i=1}^{n} f(x_i,y)$ for any query point $y \in \mathbb{R}^d$. Recently, there has been a growing trend of using data structures for efficient KDE. However, the proposed KDE data structures focus on static settings. The robustness of KDE data structures over dynamic changing data distributions is not addressed. In this work, we focus on the dynamic maintenance of KDE data structures with robustness to adversarial queries. Especially, we provide a theoretical framework of KDE data structures. In our framework, the KDE data structures only require subquadratic spaces. Moreover, our data structure supports the dynamic update of the dataset in sublinear time. Furtherm
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#34920;&#31034;&#36873;&#25321;&#23545;&#20110;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;&#25552;&#20986;&#20102;ReLEX&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#39640;&#25928;&#34920;&#31034;&#23398;&#20064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#32447;&#29256;&#26412;ReLEX-UCB&#24635;&#26159;&#19981;&#27604;&#27809;&#26377;&#34920;&#31034;&#36873;&#25321;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#24046;&#65292;&#24182;&#22312;&#34920;&#31034;&#20989;&#25968;&#31867;&#20855;&#26377;&#8220;&#35206;&#30422;&#24230;&#8221;&#24615;&#36136;&#26102;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24120;&#25968;&#36951;&#25022;&#12290;&#23545;&#20110;&#31163;&#32447;&#29256;&#26412;ReLEX-LCB&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2106.11935</link><description>&lt;p&gt;
&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;&#34920;&#31034;&#36873;&#25321;&#65306;&#20174;&#22312;&#32447;&#21040;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Representation Selection in Low-rank Markov Decision Processes: From Online to Offline RL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2106.11935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#34920;&#31034;&#36873;&#25321;&#23545;&#20110;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#25928;&#29575;&#30340;&#24433;&#21709;&#12290;&#25552;&#20986;&#20102;ReLEX&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22312;&#32447;&#21644;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#23454;&#29616;&#39640;&#25928;&#34920;&#31034;&#23398;&#20064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#32447;&#29256;&#26412;ReLEX-UCB&#24635;&#26159;&#19981;&#27604;&#27809;&#26377;&#34920;&#31034;&#36873;&#25321;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#24046;&#65292;&#24182;&#22312;&#34920;&#31034;&#20989;&#25968;&#31867;&#20855;&#26377;&#8220;&#35206;&#30422;&#24230;&#8221;&#24615;&#36136;&#26102;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24120;&#25968;&#36951;&#25022;&#12290;&#23545;&#20110;&#31163;&#32447;&#29256;&#26412;ReLEX-LCB&#65292;&#21487;&#20197;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;(DRL)&#30340;&#25104;&#21151;&#22312;&#20110;&#20854;&#23398;&#20064;&#36866;&#21512;&#25506;&#32034;&#21644;&#21033;&#29992;&#20219;&#21153;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#29702;&#35299;&#34920;&#31034;&#36873;&#25321;&#22914;&#20309;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#30340;&#25928;&#29575;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#65292;&#20854;&#20013;&#36716;&#31227;&#26680;&#33021;&#22815;&#20197;&#21452;&#32447;&#24615;&#24418;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;ReLEX&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#21644;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ReLEX&#30340;&#22312;&#32447;&#29256;&#26412;ReLEX-UCB&#24635;&#26159;&#19981;&#27604;&#27809;&#26377;&#34920;&#31034;&#36873;&#25321;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#24046;&#65292;&#24182;&#22312;&#34920;&#31034;&#20989;&#25968;&#31867;&#22312;&#25972;&#20010;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#19978;&#20855;&#26377;&#8220;&#35206;&#30422;&#24230;&#8221;&#24615;&#36136;&#26102;&#65292;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24120;&#25968;&#36951;&#25022;&#12290;&#23545;&#20110;&#20854;&#31163;&#32447;&#23545;&#24212;&#29289;ReLEX-LCB&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#22914;&#26524;&#34920;&#31034;&#20989;&#25968;&#31867;&#20855;&#26377;&#8220;&#35206;&#30422;&#24230;&#8221;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2106.11935v2 Announce Type: replace Abstract: The success of deep reinforcement learning (DRL) lies in its ability to learn a representation that is well-suited for the exploration and exploitation task. To understand how the choice of representation can improve the efficiency of reinforcement learning (RL), we study representation selection for a class of low-rank Markov Decision Processes (MDPs) where the transition kernel can be represented in a bilinear form. We propose an efficient algorithm, called ReLEX, for representation learning in both online and offline RL. Specifically, we show that the online version of ReLEX, called ReLEX-UCB, always performs no worse than the state-of-the-art algorithm without representation selection, and achieves a strictly better constant regret if the representation function class has a "coverage" property over the entire state-action space. For the offline counterpart, ReLEX-LCB, we show that the algorithm can find the optimal policy if the r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#65288;TTSA&#65289;&#30340;&#24191;&#20041;&#20998;&#26512;&#65292;&#21033;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#25581;&#31034;&#20102;TTSA&#21463;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#24433;&#21709;&#30340;&#32806;&#21512;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#25299;&#23637;&#20102;&#20256;&#32479;SGD&#30340;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#21516;&#26102;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;GTD&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.09339</link><description>&lt;p&gt;
&#20004;&#26102;&#38388;&#23610;&#24230;&#24102;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#36924;&#36817;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65306;&#29702;&#35770;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications. (arXiv:2401.09339v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#65288;TTSA&#65289;&#30340;&#24191;&#20041;&#20998;&#26512;&#65292;&#21033;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#25581;&#31034;&#20102;TTSA&#21463;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#24433;&#21709;&#30340;&#32806;&#21512;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#25299;&#23637;&#20102;&#20256;&#32479;SGD&#30340;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#21516;&#26102;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;GTD&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20004;&#26102;&#38388;&#23610;&#24230;&#38543;&#26426;&#36924;&#36817;&#65288;TTSA&#65289;&#26159;&#26368;&#36890;&#29992;&#30340;&#36845;&#20195;&#38543;&#26426;&#31639;&#27861;&#26694;&#26550;&#20043;&#19968;&#12290;&#36825;&#21253;&#25324;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#22914;SGD&#21464;&#31181;&#21644;&#29992;&#20110;&#21452;&#23618;&#25110;&#26497;&#23567;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20197;&#21450;&#31867;&#20284;&#26799;&#24230;-based&#26102;&#24207;&#24046;&#24322;&#65288;GTD&#65289;&#31639;&#27861;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;&#26412;&#25991;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65288;CLT&#65289;&#23545;&#24102;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;TTSA&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#28176;&#36817;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;TTSA&#21463;&#24213;&#23618;&#39532;&#23572;&#21487;&#22827;&#38142;&#24433;&#21709;&#30340;&#32806;&#21512;&#21160;&#21147;&#23398;&#65292;&#36825;&#22312;&#20197;&#21069;&#20165;&#32771;&#34385;&#38789;&#24046;&#24322;&#22122;&#22768;&#30340;TTSA&#30340;CLT&#32467;&#26524;&#20013;&#27809;&#26377;&#24471;&#21040;&#35299;&#20915;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;CLT&#65292;&#25105;&#20204;&#23558;&#39640;&#25928;&#37319;&#26679;&#31574;&#30053;&#30340;&#24212;&#29992;&#33539;&#22260;&#20174;&#20256;&#32479;SGD&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;TTSA&#32972;&#26223;&#19979;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#65292;&#20174;&#32780;&#25193;&#22823;&#20102;&#32993;&#31561;&#20154;&#65288;2022&#65289;&#30340;&#30740;&#31350;&#33539;&#22260;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;CLT&#32467;&#26524;&#25512;&#23548;&#20102;&#20855;&#26377;&#38750;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;GTD&#31639;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. (2022). In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approxi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#36890;&#29992;&#38750;&#21442;&#25968;&#22240;&#26524;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#36890;&#29992;&#36716;&#25442;&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#38750;&#32806;&#21512;&#24178;&#39044;&#24314;&#31435;&#20102;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#22312;&#19981;&#30693;&#36947;&#20855;&#20307;&#24178;&#39044;&#23545;&#24212;&#30340;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#32467;&#26524;&#20445;&#35777;&#20102;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#30340;&#23436;&#32654;&#24674;&#22797;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.15450</link><description>&lt;p&gt;
&#36890;&#29992;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;
&lt;/p&gt;
&lt;p&gt;
General Identifiability and Achievability for Causal Representation Learning. (arXiv:2310.15450v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#36890;&#29992;&#38750;&#21442;&#25968;&#22240;&#26524;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#36890;&#29992;&#36716;&#25442;&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#38750;&#32806;&#21512;&#24178;&#39044;&#24314;&#31435;&#20102;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#22312;&#19981;&#30693;&#36947;&#20855;&#20307;&#24178;&#39044;&#23545;&#24212;&#30340;&#33410;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#32467;&#26524;&#20445;&#35777;&#20102;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#30340;&#23436;&#32654;&#24674;&#22797;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#36890;&#29992;&#38750;&#21442;&#25968;&#22240;&#26524;&#28508;&#21464;&#37327;&#27169;&#22411;&#21644;&#23558;&#28508;&#21464;&#37327;&#25968;&#25454;&#26144;&#23556;&#21040;&#35266;&#27979;&#25968;&#25454;&#30340;&#36890;&#29992;&#36716;&#25442;&#27169;&#22411;&#19979;&#30340;&#22240;&#26524;&#34920;&#36798;&#23398;&#20064;&#12290;&#36890;&#36807;&#22312;&#28508;&#22312;&#22240;&#26524;&#22270;&#20013;&#27599;&#20010;&#33410;&#28857;&#36827;&#34892;&#20004;&#20010;&#30828;&#24615;&#38750;&#32806;&#21512;&#24178;&#39044;&#26469;&#24314;&#31435;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#23454;&#29616;&#24615;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#20154;&#20204;&#19981;&#30693;&#36947;&#21738;&#20010;&#24178;&#39044;&#29615;&#22659;&#23545;&#24212;&#30340;&#33410;&#28857;&#26159;&#30456;&#21516;&#30340;&#65288;&#22240;&#27492;&#26159;&#38750;&#32806;&#21512;&#29615;&#22659;&#65289;&#12290;&#22312;&#21487;&#35782;&#21035;&#24615;&#26041;&#38754;&#65292;&#26412;&#25991;&#30830;&#20445;&#22312;&#38750;&#32806;&#21512;&#24178;&#39044;&#19979;&#33021;&#22815;&#23436;&#32654;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#12290;&#22312;&#21487;&#23454;&#29616;&#24615;&#26041;&#38754;&#65292;&#35774;&#35745;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#21033;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#35813;&#31639;&#27861;&#30340;&#21487;&#39564;&#35777;&#30340;&#20445;&#35777;&#65292;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#21644;&#21464;&#37327;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#19981;&#21516;&#29615;&#22659;&#20013;&#30340;&#24471;&#20998;&#21464;&#21270;&#26469;&#20272;&#35745;&#36716;&#25442;&#22120;&#30340;&#36870;&#21644;&#38543;&#21518;&#30340;&#28508;&#21464;&#37327;&#12290;&#35813;&#20998;&#26512;&#36824;...
&lt;/p&gt;
&lt;p&gt;
This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes \textbf{identifiability} and \textbf{achievability} results using two hard \textbf{uncoupled} interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, addit
&lt;/p&gt;</description></item><item><title>&#22312;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#20013;&#65292;&#36138;&#23146;&#36861;&#27714;&#21487;&#36716;&#31227;&#30693;&#35782;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#23398;&#20064;&#32773;&#38754;&#20020;&#20219;&#21153;&#35782;&#21035;&#21644;&#21487;&#36716;&#31227;&#30693;&#35782;&#33719;&#21462;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;</title><link>http://arxiv.org/abs/2310.14968</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#30340;&#22522;&#26412;&#22256;&#22659;
&lt;/p&gt;
&lt;p&gt;
The Fundamental Dilemma of Bayesian Active Meta-learning. (arXiv:2310.14968v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14968
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#20013;&#65292;&#36138;&#23146;&#36861;&#27714;&#21487;&#36716;&#31227;&#30693;&#35782;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65292;&#23398;&#20064;&#32773;&#38754;&#20020;&#20219;&#21153;&#35782;&#21035;&#21644;&#21487;&#36716;&#31227;&#30693;&#35782;&#33719;&#21462;&#20043;&#38388;&#30340;&#22256;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#38656;&#35201;&#20272;&#35745;&#22312;&#22810;&#20010;&#19981;&#21516;&#20294;&#30456;&#20851;&#30340;&#25968;&#25454;&#31232;&#32570;&#20219;&#21153;&#29615;&#22659;&#20013;&#25512;&#24191;&#30340;&#21442;&#25968;&#12290;&#36125;&#21494;&#26031;&#20027;&#21160;&#20803;&#23398;&#20064;&#26159;&#19968;&#31181;&#39034;&#24207;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#30340;&#24418;&#24335;&#65292;&#20026;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#12290;&#20027;&#21160;&#20803;&#23398;&#20064;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#24403;&#21069;&#20219;&#21153;&#30340;&#29305;&#27530;&#29305;&#24449;&#65288;&#20219;&#21153;&#29305;&#23450;&#21442;&#25968;&#65289;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#21487;&#36716;&#31227;&#30340;&#30693;&#35782;&#65288;&#20272;&#35745;&#21487;&#36716;&#31227;&#30340;&#21442;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36138;&#23146;&#36861;&#27714;&#36825;&#20010;&#30446;&#26631;&#23454;&#38469;&#19978;&#21487;&#33021;&#20250;&#25439;&#23475;&#23545;&#21487;&#36716;&#31227;&#21442;&#25968;&#30340;&#20272;&#35745;&#65288;&#24341;&#36215;&#25152;&#35859;&#30340;&#36127;&#36801;&#31227;&#65289;&#12290;&#23398;&#20064;&#32773;&#38754;&#20020;&#30528;&#19968;&#20010;&#31867;&#20284;&#20294;&#19981;&#21516;&#20110;&#21208;&#25506;-&#21033;&#29992;&#22256;&#22659;&#30340;&#22256;&#22659;&#65306;&#20182;&#20204;&#24212;&#35813;&#33457;&#36153;&#20182;&#20204;&#30340;&#33719;&#21462;&#39044;&#31639;&#26469;&#36861;&#27714;&#21487;&#36716;&#31227;&#30340;&#30693;&#35782;&#65292;&#36824;&#26159;&#29992;&#26469;&#30830;&#23450;&#24403;&#21069;&#20219;&#21153;&#29305;&#23450;&#30340;&#21442;&#25968;&#65311;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#19968;&#20123;&#20219;&#21153;&#23384;&#22312;&#19981;&#21487;&#36991;&#20813;&#19988;&#20219;&#24847;&#22823;&#30340;&#36127;&#36801;&#31227;&#23041;&#32961;&#65292;&#20219;&#21153;&#30340;&#35782;&#21035;&#23545;&#20110;&#37325;&#26032;&#23547;&#25214;&#21487;&#36801;&#31227;&#21442;&#25968;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications involve estimation of parameters that generalize across multiple diverse, but related, data-scarce task environments. Bayesian active meta-learning, a form of sequential optimal experimental design, provides a framework for solving such problems. The active meta-learner's goal is to gain transferable knowledge (estimate the transferable parameters) in the presence of idiosyncratic characteristics of the current task (task-specific parameters). We show that in such a setting, greedy pursuit of this goal can actually hurt estimation of the transferable parameters (induce so-called negative transfer). The learner faces a dilemma akin to but distinct from the exploration--exploitation dilemma: should they spend their acquisition budget pursuing transferable knowledge, or identifying the current task-specific parameters? We show theoretically that some tasks pose an inevitable and arbitrarily large threat of negative transfer, and that task identification is critical to re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;MMD&#36317;&#31163;&#21644;&#32463;&#20856;&#30340;drop and relearn&#21407;&#29702;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#20013;&#26816;&#27979;&#24433;&#21709;&#36755;&#20986;&#20998;&#24067;&#30340;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#36229;&#36234;&#20102;&#31454;&#20105;&#23545;&#25163;&#12290;</title><link>http://arxiv.org/abs/2310.12115</link><description>&lt;p&gt;
&#22522;&#20110;MMD&#30340;&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
MMD-based Variable Importance for Distributional Random Forest. (arXiv:2310.12115v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;MMD&#36317;&#31163;&#21644;&#32463;&#20856;&#30340;drop and relearn&#21407;&#29702;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#20013;&#26816;&#27979;&#24433;&#21709;&#36755;&#20986;&#20998;&#24067;&#30340;&#21464;&#37327;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#36229;&#36234;&#20102;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#38543;&#26426;&#26862;&#26519;&#65288;DRF&#65289;&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#26862;&#26519;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32473;&#23450;&#36755;&#20837;&#21464;&#37327;&#30340;&#22810;&#20803;&#36755;&#20986;&#30340;&#20840;&#26465;&#20214;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32463;&#20856;&#30340;drop and relearn&#21407;&#29702;&#21644;MMD&#36317;&#31163;&#30340;DRF&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#12290;&#20256;&#32479;&#30340;&#37325;&#35201;&#24615;&#24230;&#37327;&#21482;&#33021;&#21457;&#29616;&#23545;&#36755;&#20986;&#22343;&#20540;&#26377;&#24433;&#21709;&#30340;&#21464;&#37327;&#65292;&#32780;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#26356;&#26222;&#36941;&#22320;&#21457;&#29616;&#24433;&#21709;&#36755;&#20986;&#20998;&#24067;&#30340;&#21464;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24341;&#20837;&#30340;&#37325;&#35201;&#24615;&#24230;&#37327;&#26159;&#19968;&#33268;&#30340;&#65292;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#27169;&#25311;&#25968;&#25454;&#19978;&#20855;&#26377;&#36739;&#39640;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#24182;&#19988;&#36229;&#36234;&#20102;&#31454;&#20105;&#23545;&#25163;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#36882;&#24402;&#29305;&#24449;&#28040;&#38500;&#39640;&#25928;&#22320;&#36873;&#25321;&#21464;&#37327;&#65292;&#22240;&#27492;&#21487;&#20197;&#25552;&#20379;&#23567;&#22411;&#21464;&#37327;&#38598;&#21512;&#26469;&#26500;&#24314;&#20934;&#30830;&#30340;&#26465;&#20214;&#36755;&#20986;&#20998;&#24067;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributional Random Forest (DRF) is a flexible forest-based method to estimate the full conditional distribution of a multivariate output of interest given input variables. In this article, we introduce a variable importance algorithm for DRFs, based on the well-established drop and relearn principle and MMD distance. While traditional importance measures only detect variables with an influence on the output mean, our algorithm detects variables impacting the output distribution more generally. We show that the introduced importance measure is consistent, exhibits high empirical performance on both real and simulated data, and outperforms competitors. In particular, our algorithm is highly efficient to select variables through recursive feature elimination, and can therefore provide small sets of variables to build accurate estimates of conditional output distributions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;DPZero&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#32454;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#20869;&#23384;&#21644;&#38544;&#31169;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.09639</link><description>&lt;p&gt;
DPZero&#65306;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization. (arXiv:2310.09639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09639
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;DPZero&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#32454;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#20869;&#23384;&#21644;&#38544;&#31169;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32454;&#35843;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#36341;&#20013;&#65292;&#38754;&#20020;&#30528;&#20869;&#23384;&#21644;&#38544;&#31169;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#38543;&#30528;LLM&#30340;&#35268;&#27169;&#19981;&#26029;&#22686;&#38271;&#65292;&#36798;&#21040;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;&#26041;&#27861;&#25152;&#38656;&#30340;&#20869;&#23384;&#28040;&#32791;&#21464;&#24471;&#38590;&#20197;&#25215;&#21463;&#12290;&#20854;&#27425;&#65292;&#32771;&#34385;&#21040;LLM&#20542;&#21521;&#20110;&#35760;&#24518;&#21644;&#27844;&#38706;&#25935;&#24863;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#24517;&#39035;&#20445;&#25252;&#32454;&#35843;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#23558;&#38646;&#38454;&#26041;&#27861;&#19982;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#30456;&#32467;&#21512;&#29992;&#20110;LLM&#30340;&#32454;&#35843;&#30340;&#28508;&#21147;&#12290;&#38646;&#38454;&#26041;&#27861;&#20165;&#20381;&#36182;&#21069;&#21521;&#20256;&#36882;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20869;&#23384;&#28040;&#32791;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#23558;&#23427;&#20204;&#19982;&#26631;&#20934;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#32467;&#21512;&#22312;&#19968;&#36215;&#20250;&#23548;&#33268;&#32500;&#24230;&#30456;&#20851;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DPZero&#65292;&#19968;&#31181;&#20855;&#26377;&#36817;&#20046;&#32500;&#24230;&#26080;&#20851;&#29575;&#30340;&#26032;&#22411;&#24046;&#20998;&#38544;&#31169;&#38646;&#38454;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
The widespread practice of fine-tuning pretrained large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continue to grow, encompassing billions of parameters, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize and disclose sensitive training data, the privacy of fine-tuning data must be respected. To this end, we explore the potential of zeroth-order methods in differentially private optimization for fine-tuning LLMs. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differential privacy mechanism poses dimension-dependent complexity. To bridge the gap, we introduce DPZero, a novel differentially private zeroth-order algorithm with nearly dimension-independent rates. Our theoretical analysis reveals that 
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#20998;&#31867;&#22120;&#23637;&#31034;&#20102;&#35760;&#24405;&#30772;&#32426;&#24405;&#30340;&#20154;&#31867;&#24418;&#29366;&#20559;&#22909;&#12289;&#25509;&#36817;&#20154;&#31867;&#32423;&#21035;&#30340;&#36229;&#20986;&#20998;&#24067;&#20934;&#30830;&#24615;&#12289;&#19982;&#20154;&#31867;&#20998;&#31867;&#38169;&#35823;&#30340;&#26368;&#20808;&#36827;&#23545;&#40784;&#20197;&#21450;&#29702;&#35299;&#26576;&#20123;&#30693;&#35273;&#24187;&#35937;&#30340;&#26032;&#20852;&#29305;&#24615;&#65292;&#25581;&#31034;&#20102;&#38646;&#26679;&#26412;&#29983;&#25104;&#27169;&#22411;&#20986;&#22855;&#22320;&#25509;&#36817;&#20154;&#31867;&#29289;&#20307;&#35782;&#21035;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2309.16779</link><description>&lt;p&gt;
&#29983;&#25104;&#20998;&#31867;&#22120;&#30340;&#26377;&#36259;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
Intriguing properties of generative classifiers. (arXiv:2309.16779v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16779
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20998;&#31867;&#22120;&#23637;&#31034;&#20102;&#35760;&#24405;&#30772;&#32426;&#24405;&#30340;&#20154;&#31867;&#24418;&#29366;&#20559;&#22909;&#12289;&#25509;&#36817;&#20154;&#31867;&#32423;&#21035;&#30340;&#36229;&#20986;&#20998;&#24067;&#20934;&#30830;&#24615;&#12289;&#19982;&#20154;&#31867;&#20998;&#31867;&#38169;&#35823;&#30340;&#26368;&#20808;&#36827;&#23545;&#40784;&#20197;&#21450;&#29702;&#35299;&#26576;&#20123;&#30693;&#35273;&#24187;&#35937;&#30340;&#26032;&#20852;&#29305;&#24615;&#65292;&#25581;&#31034;&#20102;&#38646;&#26679;&#26412;&#29983;&#25104;&#27169;&#22411;&#20986;&#22855;&#22320;&#25509;&#36817;&#20154;&#31867;&#29289;&#20307;&#35782;&#21035;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35782;&#21035;&#23545;&#35937;&#30340;&#26368;&#20339;&#33539;&#24335;&#26159;&#21028;&#21035;&#24335;&#25512;&#29702;&#65288;&#24555;&#36895;&#20294;&#28508;&#22312;&#23481;&#26131;&#20986;&#29616;&#24555;&#25463;&#23398;&#20064;&#65289;&#36824;&#26159;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#65288;&#36739;&#24930;&#20294;&#28508;&#22312;&#26356;&#31283;&#20581;&#65289;&#65311;&#25105;&#20204;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#36827;&#23637;&#65292;&#23558;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#36716;&#21270;&#20026;&#20998;&#31867;&#22120;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#30740;&#31350;&#20854;&#34892;&#20026;&#65292;&#24182;&#23558;&#20854;&#19982;&#21028;&#21035;&#27169;&#22411;&#21644;&#20154;&#31867;&#24515;&#29702;&#29289;&#29702;&#25968;&#25454;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#25253;&#36947;&#20102;&#29983;&#25104;&#20998;&#31867;&#22120;&#30340;&#22235;&#20010;&#26377;&#36259;&#30340;&#26032;&#20852;&#29305;&#24615;&#65306;&#23427;&#20204;&#26174;&#31034;&#20986;&#30772;&#32426;&#24405;&#30340;&#20154;&#31867;&#24418;&#29366;&#20559;&#22909;&#65288;&#23545;&#20110;Imagen&#36798;&#21040;99%&#65289;&#65292;&#25509;&#36817;&#20154;&#31867;&#32423;&#21035;&#30340;&#36229;&#20986;&#20998;&#24067;&#20934;&#30830;&#24615;&#65292;&#19982;&#20154;&#31867;&#20998;&#31867;&#38169;&#35823;&#30340;&#26368;&#20808;&#36827;&#23545;&#40784;&#20197;&#21450;&#23427;&#20204;&#29702;&#35299;&#26576;&#20123;&#30693;&#35273;&#24187;&#35937;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23613;&#31649;&#30446;&#21069;&#27169;&#25311;&#20154;&#31867;&#29289;&#20307;&#35782;&#21035;&#30340;&#20027;&#23548;&#33539;&#24335;&#26159;&#21028;&#21035;&#24335;&#25512;&#29702;&#65292;&#38646;&#26679;&#26412;&#29983;&#25104;&#27169;&#22411;&#20986;&#22855;&#22320;&#25509;&#36817;&#20154;&#31867;&#29289;&#20307;&#35782;&#21035;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
What is the best paradigm to recognize objects -- discriminative inference (fast but potentially prone to shortcut learning) or using a generative model (slow but potentially more robust)? We build on recent advances in generative modeling that turn text-to-image models into classifiers. This allows us to study their behavior and to compare them against discriminative models and human psychophysical data. We report four intriguing emergent properties of generative classifiers: they show a record-breaking human-like shape bias (99% for Imagen), near human-level out-of-distribution accuracy, state-of-the-art alignment with human classification errors, and they understand certain perceptual illusions. Our results indicate that while the current dominant paradigm for modeling human object recognition is discriminative inference, zero-shot generative models approximate human object recognition data surprisingly well.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MPHD&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#39044;&#35757;&#32451;&#21644;&#31070;&#32463;&#32593;&#32476;&#22312;&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#19978;&#23454;&#29616;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#36801;&#31227;&#23398;&#20064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;MPHD&#30340;&#26377;&#25928;&#24615;&#21644;&#22312;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.16597</link><description>&lt;p&gt;
&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#19978;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MPHD&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#39044;&#35757;&#32451;&#21644;&#31070;&#32463;&#32593;&#32476;&#22312;&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#19978;&#23454;&#29616;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#36801;&#31227;&#23398;&#20064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;MPHD&#30340;&#26377;&#25928;&#24615;&#21644;&#22312;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#65288;&#36890;&#24120;&#26159;&#39640;&#26031;&#36807;&#31243;&#65289;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#20026;&#20102;&#30830;&#20445;&#27169;&#22411;&#30340;&#36136;&#37327;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#8220;&#35757;&#32451;&#8221;&#20989;&#25968;&#30340;&#35266;&#23519;&#32467;&#26524;&#26469;&#33258;&#21160;&#35774;&#35745;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#12290;&#36825;&#20123;&#35757;&#32451;&#20989;&#25968;&#36890;&#24120;&#38656;&#35201;&#19982;&#8220;&#27979;&#35797;&#8221;&#20989;&#25968;&#65288;&#24453;&#20248;&#21270;&#30340;&#40657;&#30418;&#20989;&#25968;&#65289;&#20855;&#26377;&#30456;&#21516;&#30340;&#23450;&#20041;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MPHD&#30340;&#27169;&#22411;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23558;&#29305;&#23450;&#20110;&#39046;&#22495;&#30340;&#19978;&#19979;&#25991;&#26144;&#23556;&#21040;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#30340;&#35268;&#33539;&#12290;MPHD&#21487;&#20197;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#26080;&#32541;&#38598;&#25104;&#65292;&#23454;&#29616;&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#30340;&#30693;&#35782;&#36801;&#31227;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;MPHD&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on "training" functions. These training functions are typically required to have the same domain as the "test" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#27491;&#21017;&#21270;&#23494;&#24230;&#30340; Sobolev &#33539;&#25968;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#21644;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#65292;&#21487;&#20197;&#24471;&#21040;&#24615;&#33021;&#33391;&#22909;&#30340;&#35299;&#65292;&#35813;&#26041;&#27861;&#22312; Anomaly Detection benchmark &#20013;&#25490;&#21517;&#31532;&#20108;&#12290;</title><link>http://arxiv.org/abs/2307.13763</link><description>&lt;p&gt;
&#38544;&#24335;&#24402;&#19968;&#21270;&#26174;&#24335;&#27491;&#21017;&#21270;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Implicitly Normalized Explicitly Regularized Density Estimation. (arXiv:2307.13763v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13763
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#27491;&#21017;&#21270;&#23494;&#24230;&#30340; Sobolev &#33539;&#25968;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#21644;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#65292;&#21487;&#20197;&#24471;&#21040;&#24615;&#33021;&#33391;&#22909;&#30340;&#35299;&#65292;&#35813;&#26041;&#27861;&#22312; Anomaly Detection benchmark &#20013;&#25490;&#21517;&#31532;&#20108;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#22522;&#20110;&#27491;&#21017;&#21270;&#23494;&#24230;&#30340; Sobolev &#33539;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#19982;&#26680;&#23494;&#24230;&#20272;&#35745;&#26377;&#26126;&#26174;&#24046;&#24322;&#65292;&#21487;&#20197;&#28165;&#26224;&#35299;&#37322;&#27169;&#22411;&#30340;&#20559;&#24046;&#12290;&#34429;&#28982;&#25105;&#20204;&#26080;&#27861;&#24471;&#21040;&#30456;&#20851;&#26680;&#20989;&#25968;&#30340;&#38381;&#21512;&#35299;&#26512;&#24418;&#24335;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#37319;&#26679;&#36827;&#34892;&#36817;&#20284;&#12290;&#20915;&#23450;&#23494;&#24230;&#30340;&#20248;&#21270;&#38382;&#39064;&#26159;&#38750;&#20984;&#30340;&#65292;&#26631;&#20934;&#30340;&#26799;&#24230;&#26041;&#27861;&#25928;&#26524;&#19981;&#22909;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#21644;&#20351;&#29992;&#33258;&#28982;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#24471;&#21040;&#24615;&#33021;&#33391;&#22909;&#30340;&#35299;&#12290;&#26368;&#21518;&#65292;&#34429;&#28982;&#35813;&#26041;&#27861;&#25552;&#20379;&#30340;&#26159;&#38750;&#24402;&#19968;&#21270;&#30340;&#23494;&#24230;&#65292;&#26080;&#27861;&#20351;&#29992;&#23545;&#25968;&#20284;&#28982;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#65292;&#20294;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#37319;&#29992;&#22522;&#20110; Fisher &#25955;&#24230;&#30340;&#20998;&#25968;&#21305;&#37197;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#26368;&#36817;&#30340;&#24322;&#24120;&#26816;&#27979;&#22522;&#20934;&#22871;&#20214; ADBench &#19978;&#35780;&#20272;&#20102;&#24471;&#21040;&#30340;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#23427;&#22312;&#36229;&#36807;15&#20010;&#31639;&#27861;&#20013;&#25490;&#21517;&#31532;&#20108;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 al
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#24322;&#26041;&#24046;&#31070;&#32463;&#22238;&#24402;&#27169;&#22411;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#26102;&#30340;&#22256;&#38590;&#65292;&#24182;&#20174;&#32479;&#35745;&#29289;&#29702;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#36825;&#20123;&#19981;&#31283;&#23450;&#24615;&#19981;&#20165;&#36866;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#19988;&#24050;&#32463;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#39640;&#26031;&#20284;&#28982;&#27169;&#22411;&#30340;&#22330;&#35770;&#20013;&#23384;&#22312;&#12290;&#25968;&#20540;&#27714;&#35299;&#32467;&#26524;&#19982;&#23454;&#35777;&#27169;&#22411;&#25311;&#21512;&#30340;&#23450;&#24615;&#19968;&#33268;&#24615;&#35777;&#26126;&#20102;&#30456;&#21464;&#30340;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2306.16717</link><description>&lt;p&gt;
&#29702;&#35299;&#28145;&#24230;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#30149;&#24577;
&lt;/p&gt;
&lt;p&gt;
Understanding Pathologies of Deep Heteroskedastic Regression. (arXiv:2306.16717v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16717
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#24322;&#26041;&#24046;&#31070;&#32463;&#22238;&#24402;&#27169;&#22411;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#26102;&#30340;&#22256;&#38590;&#65292;&#24182;&#20174;&#32479;&#35745;&#29289;&#29702;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;&#20316;&#32773;&#35777;&#26126;&#20102;&#36825;&#20123;&#19981;&#31283;&#23450;&#24615;&#19981;&#20165;&#36866;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#19988;&#24050;&#32463;&#22312;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#39640;&#26031;&#20284;&#28982;&#27169;&#22411;&#30340;&#22330;&#35770;&#20013;&#23384;&#22312;&#12290;&#25968;&#20540;&#27714;&#35299;&#32467;&#26524;&#19982;&#23454;&#35777;&#27169;&#22411;&#25311;&#21512;&#30340;&#23450;&#24615;&#19968;&#33268;&#24615;&#35777;&#26126;&#20102;&#30456;&#21464;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#25253;&#21578;&#20102;&#22312;&#20351;&#29992;&#24322;&#26041;&#24046;&#31070;&#32463;&#22238;&#24402;&#27169;&#22411;&#23545;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#24314;&#27169;&#26102;&#20986;&#29616;&#30340;&#36127;&#38754;&#32467;&#26524;&#12290;&#29305;&#21035;&#26159;&#65292;&#23545;&#20110;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#65292;&#22343;&#20540;&#32593;&#32476;&#21644;&#26041;&#24046;&#32593;&#32476;&#36275;&#22815;&#24378;&#22823;&#65292;&#21487;&#20197;&#25311;&#21512;&#27599;&#20010;&#25968;&#25454;&#28857;&#65288;&#21516;&#26102;&#23558;&#39044;&#27979;&#30340;&#26041;&#24046;&#25910;&#32553;&#21040;&#38646;&#65289;&#65292;&#25110;&#32773;&#23398;&#20064;&#19968;&#20010;&#24658;&#23450;&#30340;&#39044;&#27979;&#65292;&#36755;&#20986;&#26041;&#24046;&#24688;&#22909;&#21305;&#37197;&#27599;&#20010;&#39044;&#27979;&#27531;&#24046;&#65288;&#21363;&#23558;&#30446;&#26631;&#35299;&#37322;&#20026;&#32431;&#22122;&#22768;&#65289;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#29289;&#29702;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20123;&#22256;&#38590;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35266;&#23519;&#21040;&#30340;&#19981;&#31283;&#23450;&#24615;&#19981;&#29305;&#23450;&#20110;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#32780;&#26159;&#24050;&#32463;&#23384;&#22312;&#20110;&#36807;&#21442;&#25968;&#21270;&#26465;&#20214;&#39640;&#26031;&#20284;&#28982;&#27169;&#22411;&#30340;&#22330;&#35770;&#20013;&#12290;&#22312;&#36731;&#24494;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#21487;&#20197;&#36890;&#36807;&#25968;&#20540;&#27714;&#35299;&#30340;&#38750;&#21442;&#25968;&#33258;&#30001;&#33021;&#12290;&#24471;&#21040;&#30340;&#35299;&#19982;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#19978;&#30340;&#23454;&#35777;&#27169;&#22411;&#25311;&#21512;&#20855;&#26377;&#33391;&#22909;&#30340;&#23450;&#24615;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#29305;&#21035;&#35777;&#26126;&#20102;&#30456;&#21464;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent studies have reported negative results when using heteroskedastic neural regression models to model real-world data. In particular, for overparameterized models, the mean and variance networks are powerful enough to either fit every single data point (while shrinking the predicted variances to zero), or to learn a constant prediction with an output variance exactly matching every predicted residual (i.e., explaining the targets as pure noise). This paper studies these difficulties from the perspective of statistical physics. We show that the observed instabilities are not specific to any neural network architecture but are already present in a field theory of an overparameterized conditional Gaussian likelihood model. Under light assumptions, we derive a nonparametric free energy that can be solved numerically. The resulting solutions show excellent qualitative agreement with empirical model fits on real-world data and, in particular, prove the existence of phase transit
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#26102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.15056</link><description>&lt;p&gt;
&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Differentially Private Learning with Public Data. (arXiv:2306.15056v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#26368;&#20248;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#35757;&#32451;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#26102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#25552;&#39640;&#20934;&#30830;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#33021;&#22815;&#30830;&#20445;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19981;&#27844;&#28431;&#31169;&#23494;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#24046;&#20998;&#38544;&#31169;&#30340;&#20195;&#20215;&#26159;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#38477;&#20302;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#22686;&#21152;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#21487;&#33021;&#21487;&#20197;&#35775;&#38382;&#19981;&#28041;&#21450;&#38544;&#31169;&#38382;&#39064;&#30340;&#36741;&#21161;&#20844;&#20849;&#25968;&#25454;&#12290;&#36825;&#20419;&#20351;&#20102;&#26368;&#36817;&#30740;&#31350;&#20844;&#20849;&#25968;&#25454;&#22312;&#25552;&#39640;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#20934;&#30830;&#24615;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#26377;&#19968;&#23450;&#25968;&#37327;&#30340;&#20844;&#20849;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#20197;&#19979;&#22522;&#26412;&#24320;&#25918;&#38382;&#39064;&#65306;1.&#22312;&#26377;&#20844;&#20849;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#35757;&#32451;&#22522;&#20110;&#31169;&#26377;&#25968;&#25454;&#38598;&#30340;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#30340;&#26368;&#20248;&#65288;&#26368;&#22351;&#24773;&#20917;&#65289;&#35823;&#24046;&#26159;&#22810;&#23569;&#65311;&#21738;&#20123;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#65311;2.&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#22312;&#23454;&#36341;&#20013;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#35757;&#32451;&#65311;&#25105;&#20204;&#22312;&#26412;&#22320;&#27169;&#22411;&#21644;&#20013;&#24515;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#38382;&#39064;&#19979;&#32771;&#34385;&#36825;&#20123;&#38382;&#39064;&#12290;&#20026;&#20102;&#22238;&#31572;&#31532;&#19968;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#19977;&#20010;&#22522;&#26412;&#38382;&#39064;&#30340;&#26368;&#20248;&#35823;&#24046;&#29575;&#30340;&#32039;&#23494;&#65288;&#26368;&#39640;&#24120;&#25968;&#22240;&#23376;&#65289;&#19979;&#30028;&#21644;&#19978;&#30028;&#12290;&#36825;&#19977;&#20010;&#38382;&#39064;&#26159;&#65306;&#22343;&#20540;&#20272;&#35745;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20984;&#22855;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy (DP) ensures that training a machine learning model does not leak private data. However, the cost of DP is lower model accuracy or higher sample complexity. In practice, we may have access to auxiliary public data that is free of privacy concerns. This has motivated the recent study of what role public data might play in improving the accuracy of DP models. In this work, we assume access to a given amount of public data and settle the following fundamental open questions: 1. What is the optimal (worst-case) error of a DP model trained over a private data set while having access to side public data? What algorithms are optimal? 2. How can we harness public data to improve DP model training in practice? We consider these questions in both the local and central models of DP. To answer the first question, we prove tight (up to constant factors) lower and upper bounds that characterize the optimal error rates of three fundamental problems: mean estimation, empirical ris
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#65292;&#22312;&#26377;&#30028;&#21644;&#19968;&#33324;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#20013;&#22343;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30028;&#38480;&#36824;&#33021;&#22815;&#20445;&#25345;&#38543;&#26102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12214</link><description>&lt;p&gt;
&#26356;&#22810;&#30340;PAC-Bayes Bounds&#65306;&#20174;&#26377;&#30028;&#25439;&#22833;&#21040;&#20855;&#26377;&#19968;&#33324;&#24615;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#65292;&#21040;&#20219;&#20309;&#26102;&#38388;&#22343;&#26377;&#25928;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity. (arXiv:2306.12214v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#65292;&#22312;&#26377;&#30028;&#21644;&#19968;&#33324;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#20013;&#22343;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30028;&#38480;&#36824;&#33021;&#22815;&#20445;&#25345;&#38543;&#26102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#25552;&#20986;&#20102;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#26377;&#30028;&#33539;&#22260;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Catoni&#30028;&#30340;&#21152;&#24378;&#29256;&#26412;&#65292;&#36866;&#29992;&#20110;&#25152;&#26377;&#21442;&#25968;&#20540;&#30340;&#32479;&#19968;&#30028;&#12290;&#36825;&#23548;&#33268;&#20102;&#26032;&#30340;&#24555;&#36895;&#36895;&#29575;&#21644;&#28151;&#21512;&#36895;&#29575;&#19978;&#38480;&#65292;&#36825;&#20123;&#19978;&#38480;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#27604;&#25991;&#29486;&#20013;&#20808;&#21069;&#30028;&#38480;&#26356;&#32039;&#12290;&#20854;&#27425;&#65292;&#38024;&#23545;&#26356;&#19968;&#33324;&#30340;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#26080;&#21442;&#25968;&#19978;&#38480;&#65306;&#24403;&#25439;&#22833;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;PAC-Bayes Chernoff&#31867;&#27604;&#65292;&#21478;&#19968;&#20010;&#19978;&#38480;&#26159;&#25439;&#22833;&#30340;&#20108;&#38454;&#30697;&#26377;&#30028;&#12290;&#36825;&#20004;&#20010;&#19978;&#38480;&#26159;&#21033;&#29992;&#19968;&#31181;&#22522;&#20110;&#21487;&#33021;&#20107;&#20214;&#31354;&#38388;&#30340;&#31163;&#25955;&#21270;&#30340;&#26032;&#25216;&#26415;&#33719;&#24471;&#30340;&#65292;&#8220;&#22312;&#27010;&#29575;&#8221;&#21442;&#25968;&#20248;&#21270;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#29616;&#26377;&#30028;&#38480;&#30340;&#31616;&#21333;&#25216;&#26415;&#23558;&#25152;&#26377;&#20808;&#21069;&#32467;&#26524;&#25193;&#23637;&#21040;&#20219;&#20309;&#26102;&#38388;&#26377;&#25928;&#30340;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present new high-probability PAC-Bayes bounds for different types of losses. Firstly, for losses with a bounded range, we present a strengthened version of Catoni's bound that holds uniformly for all parameter values. This leads to new fast rate and mixed rate bounds that are interpretable and tighter than previous bounds in the literature. Secondly, for losses with more general tail behaviors, we introduce two new parameter-free bounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generating function is bounded, and a bound when the loss' second moment is bounded. These two bounds are obtained using a new technique based on a discretization of the space of possible events for the "in probability" parameter optimization problem. Finally, we extend all previous results to anytime-valid bounds using a simple technique applicable to any existing bound.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#22522;&#20110;&#35013;&#37197;&#32447;&#25968;&#25454;&#30340;&#21322;&#21512;&#25104;&#21046;&#36896;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#25903;&#25345;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2306.10816</link><description>&lt;p&gt;
$\texttt{causalAssembly}$: &#29992;&#20110;&#22522;&#20934;&#22240;&#26524;&#21457;&#29616;&#30340;&#29983;&#25104;&#30495;&#23454;&#29983;&#20135;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
$\texttt{causalAssembly}$: Generating Realistic Production Data for Benchmarking Causal Discovery. (arXiv:2306.10816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10816
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#22522;&#20110;&#35013;&#37197;&#32447;&#25968;&#25454;&#30340;&#21322;&#21512;&#25104;&#21046;&#36896;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#25903;&#25345;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#24555;&#36895;&#36827;&#23637;&#24182;&#36234;&#26469;&#36234;&#22810;&#22320;&#20381;&#38752;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22823;&#22810;&#25968;&#30495;&#23454;&#25968;&#25454;&#28304;&#20013;&#30495;&#27491;&#30340;&#22240;&#26524;&#20851;&#31995;&#20173;&#19981;&#20026;&#20154;&#25152;&#30693;&#65292;&#22240;&#27492;&#36825;&#20123;&#31639;&#27861;&#38656;&#35201;&#20805;&#20998;&#30340;&#32463;&#39564;&#39564;&#35777;&#12290;&#36825;&#20010;&#38382;&#39064;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#29615;&#32469;&#21512;&#36866;&#39640;&#36136;&#37327;&#25968;&#25454;&#21457;&#24067;&#30340;&#38544;&#31169;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#32452;&#22797;&#26434;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#21046;&#36896;&#36807;&#31243;&#20013;&#35013;&#37197;&#32447;&#30340;&#27979;&#37327;&#25968;&#25454;&#12290;&#20511;&#21161;&#20110;&#23545;&#29289;&#29702;&#23398;&#30340;&#28145;&#20837;&#30740;&#31350;&#65292;&#36825;&#20010;&#25968;&#25454;&#38598;&#33021;&#22815;&#25552;&#20379;&#22320;&#38754;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#29031;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#35013;&#37197;&#32447;&#25968;&#25454;&#21644;&#30456;&#20851;&#30340;&#22320;&#38754;&#30495;&#23454;&#20449;&#24687;&#26469;&#26500;&#24314;&#19968;&#20010;&#31995;&#32479;&#65292;&#29983;&#25104;&#21322;&#21512;&#25104;&#36896;&#25968;&#25454;&#26469;&#25903;&#25345;&#22522;&#20934;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#26368;&#20808;&#36827;&#30340;&#20223;&#30495;&#25216;&#26415;&#26469;&#29983;&#25104;&#25968;&#25454;&#38598;&#65292;&#27169;&#20223;&#21407;&#22987;&#35013;&#37197;&#32447;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#65292;&#20445;&#30041;&#20102;&#36807;&#31243;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#21644;&#23427;&#20204;&#30340;&#38750;&#32447;&#24615;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for causal discovery have recently undergone rapid advances and increasingly draw on flexible nonparametric methods to process complex data. With these advances comes a need for adequate empirical validation of the causal relationships learned by different algorithms. However, for most real data sources true causal relations remain unknown. This issue is further compounded by privacy concerns surrounding the release of suitable high-quality data. To help address these challenges, we gather a complex dataset comprising measurements from an assembly line in a manufacturing context. This line consists of numerous physical processes for which we are able to provide ground truth causal relationships on the basis of a detailed study of the underlying physics. We use the assembly line data and associated ground truth information to build a system for generation of semisynthetic manufacturing data that supports benchmarking of causal discovery methods. To accomplish this, we employ 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2306.02939</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#19982;&#27867;&#21270;&#20998;&#26512;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(D-SGD)&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#35823;&#24046;&#20998;&#26512;&#26041;&#27861;&#12290;&#24471;&#21040;&#30340;&#32467;&#26524;&#22823;&#22823;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#25512;&#32763;&#20102;&#23427;&#20204;&#20851;&#20110;&#36890;&#20449;&#22270;&#23545;&#27867;&#21270;&#30340;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#12290;&#20363;&#22914;&#65292;&#22312;&#20984;&#35774;&#32622;&#20013;&#65292;&#26080;&#35770;&#22270;&#30340;&#36873;&#25321;&#22914;&#20309;&#65292;D-SGD&#20855;&#26377;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#30456;&#21516;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#21453;&#30452;&#35273;&#30340;&#32467;&#26524;&#26469;&#33258;&#20110;&#32771;&#34385;&#26412;&#22320;&#21442;&#25968;&#30340;&#24179;&#22343;&#20540;&#65292;&#36825;&#20250;&#38544;&#34255;&#19968;&#20010;&#19982;&#20998;&#24067;&#24335;&#22330;&#26223;&#19981;&#20860;&#23481;&#30340;&#26368;&#32456;&#20840;&#23616;&#24179;&#22343;&#21270;&#27493;&#39588;&#12290;&#32771;&#34385;&#21040;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#20513;&#23548;&#20998;&#26512;&#26412;&#22320;&#21442;&#25968;&#30340;&#19978;&#30830;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22270;&#30830;&#23454;&#23545;&#27867;&#21270;&#20135;&#29983;&#24433;&#21709;&#12290;&#19982;&#20043;&#21069;&#30340;&#32467;&#26524;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#21363;&#20351;&#23545;&#20110;&#38750;&#36830;&#25509;&#22270;&#20063;&#33021;&#20135;&#29983;&#38750;&#24179;&#20961;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#20195;&#20215;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#65292;&#25104;&#21151;&#20943;&#23569;&#20102;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#30340;&#25968;&#37327;&#65292;&#25552;&#39640;&#20102;&#40657;&#30418;&#25915;&#20987;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.02895</link><description>&lt;p&gt;
&#19981;&#30772;&#22351;&#40657;&#30418;&#20998;&#31867;&#22120;&#30340;&#24773;&#20917;&#19979;&#35268;&#36991;&#23427;&#30340;&#20998;&#31867;&#8212;&#8212;&#22522;&#20110;&#23454;&#38469;&#20195;&#20215;&#30340;&#40657;&#30418;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Evading Black-box Classifiers Without Breaking Eggs. (arXiv:2306.02895v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02895
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#20195;&#20215;&#30340;&#40657;&#30418;&#25915;&#20987;&#65292;&#36890;&#36807;&#35774;&#35745;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#65292;&#25104;&#21151;&#20943;&#23569;&#20102;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#30340;&#25968;&#37327;&#65292;&#25552;&#39640;&#20102;&#40657;&#30418;&#25915;&#20987;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20915;&#31574;&#30340;&#35268;&#36991;&#25915;&#20987;&#26159;&#36890;&#36807;&#19981;&#26029;&#26597;&#35810;&#40657;&#30418;&#20998;&#31867;&#22120;&#26469;&#29983;&#25104;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#26412;&#25991;&#35748;&#20026;&#29616;&#26377;&#30340;&#25915;&#20987;&#26041;&#24335;&#22312;&#22788;&#29702;&#23545;&#23433;&#20840;&#24615;&#25935;&#24863;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#26102;&#26377;&#32570;&#38519;&#12290;&#22240;&#20026;&#36825;&#20123;&#31995;&#32479;&#20027;&#35201;&#30446;&#30340;&#26159;&#36807;&#28388;&#20986;&#26377;&#23475;&#25968;&#25454;&#65288;&#20363;&#22914;&#24694;&#24847;&#36719;&#20214;&#12289;&#26377;&#23475;&#20869;&#23481;&#31561;&#65289;&#65292;&#25152;&#20197;&#26597;&#35810;&#30340;&#20195;&#20215;&#26159;&#19981;&#23545;&#31561;&#30340;&#65292;&#19968;&#26086;&#26597;&#35810;&#34987;&#26816;&#27979;&#20986;&#26159;&#26377;&#23475;&#30340;&#65292;&#23601;&#20250;&#35302;&#21457;&#39069;&#22806;&#30340;&#23433;&#20840;&#36807;&#28388;&#65292;&#20363;&#22914;&#20351;&#29992;&#38480;&#21046;&#25110;&#36134;&#25143;&#26242;&#20572;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20915;&#31574;&#30340;&#25915;&#20987;&#20135;&#29983;&#20102;&#22823;&#37327;&#30340;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#65292;&#23548;&#33268;&#23427;&#20204;&#24456;&#21487;&#33021;&#23545;&#23433;&#20840;&#20851;&#38190;&#31995;&#32479;&#26080;&#25928;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;&#25915;&#20987;&#26041;&#24335;&#65292;&#36890;&#36807;&#20943;&#23569;&#8220;&#26377;&#23475;&#8221;&#26597;&#35810;&#30340;&#25968;&#37327;&#65288;&#26368;&#22810;&#21487;&#20197;&#20943;&#23569; $1.5$ &#20493;&#21040; $7.3$ &#20493;&#65289;&#65292;&#20197;&#23454;&#29616;&#26356;&#21152;&#26377;&#25928;&#30340;&#40657;&#30418;&#25915;&#20987;&#12290;&#20294;&#36825;&#20123;&#25915;&#20987;&#30340;&#27491;&#24120;&#26597;&#35810;&#25968;&#37327;&#22823;&#22823;&#22686;&#21152;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#22312;&#23454;&#38469;&#20195;&#20215;&#24230;&#37327;&#19979;&#26500;&#24314;&#26356;&#26377;&#25928;&#30340;&#40657;&#30418;&#25915;&#20987;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision-based evasion attacks repeatedly query a black-box classifier to generate adversarial examples. Prior work measures the cost of such attacks by the total number of queries made to the classifier. We argue this metric is flawed. Most security-critical machine learning systems aim to weed out "bad" data (e.g., malware, harmful content, etc). Queries to such systems carry a fundamentally asymmetric cost: queries detected as "bad" come at a higher cost because they trigger additional security filters, e.g., usage throttling or account suspension. Yet, we find that existing decision-based attacks issue a large number of "bad" queries, which likely renders them ineffective against security-critical systems. We then design new attacks that reduce the number of bad queries by $1.5$-$7.3\times$, but often at a significant increase in total (non-bad) queries. We thus pose it as an open problem to build black-box attacks that are more effective under realistic cost metrics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE) &#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36755;&#20837;&#26799;&#24230;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.02775</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#38598;&#21512;&#30340;&#36755;&#20837;&#26799;&#24230;&#22810;&#26679;&#24615;
&lt;/p&gt;
&lt;p&gt;
Input gradient diversity for neural network ensembles. (arXiv:2306.02775v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02775
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE) &#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36755;&#20837;&#26799;&#24230;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38598;&#25104; (DE) &#36890;&#36807;&#23427;&#20204;&#30340;&#21151;&#33021;&#22810;&#26679;&#24615;&#22312;&#20934;&#30830;&#24615;&#12289;&#26657;&#20934;&#24615;&#21644;&#25269;&#25239;&#24178;&#25200;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029; (ParVI) &#26041;&#27861;&#36890;&#36807;&#22522;&#20110;&#32593;&#32476;&#30456;&#20284;&#24615;&#20869;&#26680;&#30340;&#25490;&#26021;&#39033;&#26469;&#22686;&#24378;&#22810;&#26679;&#24615;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#26435;&#37325;&#31354;&#38388;&#25490;&#26021;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#30452;&#25509;&#21151;&#33021;&#31354;&#38388;&#25490;&#26021;&#34987;&#21457;&#29616;&#23545; DE &#30340;&#25913;&#36827;&#24456;&#23567;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#20123;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110; ParVI &#30340;&#19968;&#38454;&#26021;&#21147;&#28145;&#24230;&#38598;&#25104; (FoRDE)&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#36755;&#20837;&#26799;&#24230;&#30340;&#38598;&#25104;&#23398;&#20064;&#26041;&#27861;&#12290;&#30001;&#20110;&#36755;&#20837;&#26799;&#24230;&#21807;&#19968;&#22320;&#30830;&#23450;&#20102;&#19968;&#20010;&#20989;&#25968;&#24182;&#19988;&#27604;&#26435;&#37325;&#23567;&#24471;&#22810;&#65292;&#25152;&#20197;&#36825;&#31181;&#26041;&#27861;&#20445;&#35777;&#20102;&#38598;&#21512;&#25104;&#21592;&#22312;&#21151;&#33021;&#19978;&#26159;&#19981;&#21516;&#30340;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#22810;&#26679;&#21270;&#36755;&#20837;&#26799;&#24230;&#40723;&#21169;&#27599;&#20010;&#32593;&#32476;&#23398;&#20064;&#19981;&#21516;&#30340;&#29305;&#24449;&#65292;&#36825;&#26377;&#26395;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improv
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#28857;&#21608;&#22260;&#26377;&#22823;&#30340;&#20960;&#20046;&#30830;&#23450;&#30340;&#32622;&#20449;&#37051;&#22495;&#65292;&#36825;&#23548;&#33268;&#29616;&#20195;&#27169;&#22411;&#26657;&#20934;&#38754;&#20020;&#37325;&#35201;&#38556;&#30861;&#12290;</title><link>http://arxiv.org/abs/2306.00740</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#32622;&#20449;&#29616;&#35937;&#21450;&#20854;&#23545;&#26657;&#20934;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
A Uniform Confidence Phenomenon in Deep Learning and its Implications for Calibration. (arXiv:2306.00740v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00740
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#28857;&#21608;&#22260;&#26377;&#22823;&#30340;&#20960;&#20046;&#30830;&#23450;&#30340;&#32622;&#20449;&#37051;&#22495;&#65292;&#36825;&#23548;&#33268;&#29616;&#20195;&#27169;&#22411;&#26657;&#20934;&#38754;&#20020;&#37325;&#35201;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#24778;&#20154;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#23649;&#27425;&#34920;&#29616;&#20986;&#22312;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#20272;&#35745;&#19981;&#20339;&#30340;&#24773;&#20917;&#8212;&#8212;&#25442;&#21477;&#35805;&#35828;&#65292;&#23427;&#20204;&#22312;&#38169;&#35823;&#26102;&#32463;&#24120;&#36807;&#24230;&#33258;&#20449;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#27169;&#22411;&#26657;&#20934;&#65292;&#24182;&#20197;&#20462;&#25913;&#35757;&#32451;&#26041;&#26696;&#21644;&#35757;&#32451;&#21518;&#26657;&#20934;&#31243;&#24207;&#30340;&#24418;&#24335;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29616;&#20195;&#27169;&#22411;&#26657;&#20934;&#30340;&#37325;&#35201;&#38556;&#30861;&#65306;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#23427;&#20204;&#30340;&#35757;&#32451;&#28857;&#21608;&#22260;&#26377;&#22823;&#30340;&#20960;&#20046;&#30830;&#23450;&#30340;&#32622;&#20449;&#37051;&#22495;&#12290;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#22312;&#24456;&#22810;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#23545;&#20013;&#37117;&#20250;&#20986;&#29616;&#65288;&#22312;&#22270;&#20687;&#20998;&#31867;&#30340;&#32972;&#26223;&#19979;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#36825;&#31181;&#29616;&#35937;&#20986;&#29616;&#26102;&#65292;&#22312;&#31867;&#21035;&#20043;&#38388;&#23384;&#22312;&#37325;&#21472;&#30340;&#22823;&#31867;&#25968;&#25454;&#20998;&#24067;&#20013;&#65292;&#21363;&#20351;&#22312;&#24212;&#29992;&#26657;&#20934;&#21518;&#20063;&#19981;&#33021;&#33719;&#24471;&#27604;&#38543;&#26426;&#26356;&#22909;&#30340;&#28176;&#36817;&#26657;&#20934;&#27169;&#22411;&#65288;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the impressive generalization capabilities of deep neural networks, they have been repeatedly shown to poorly estimate their predictive uncertainty - in other words, they are frequently overconfident when they are wrong. Fixing this issue is known as model calibration, and has consequently received much attention in the form of modified training schemes and post-training calibration procedures. In this work, we present a significant hurdle to the calibration of modern models: deep neural networks have large neighborhoods of almost certain confidence around their training points. We demonstrate in our experiments that this phenomenon consistently arises (in the context of image classification) across many model and dataset pairs. Furthermore, we prove that when this phenomenon holds, for a large class of data distributions with overlaps between classes, it is not possible to obtain a model that is asymptotically better than random (with respect to calibration) even after applyin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.19685</link><description>&lt;p&gt;
&#28145;&#24230;&#38543;&#26426;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21463;&#38543;&#26426;&#21147;&#23398;&#21644;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#21551;&#21457;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#20174;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#20013;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#28508;&#22312;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#22312;&#26356;&#39640;&#30340;&#32500;&#24230;&#19978;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#32467;&#26524;&#20855;&#26377;&#19982;&#32500;&#25968;&#25968;&#37327;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#24182;&#26174;&#31034;&#20986;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#29992;&#20110;&#37327;&#23376;&#21147;&#23398;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26174;&#30528;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel deep-learning-based approach for numerical simulation of a time-evolving Schr\"odinger equation inspired by stochastic mechanics and generative diffusion models. Unlike existing approaches, which exhibit computational complexity that scales exponentially in the problem dimension, our method allows us to adapt to the latent low-dimensional structure of the wave function by sampling from the Markovian diffusion. Depending on the latent dimension, our method may have far lower computational complexity in higher dimensions. Moreover, we propose novel equations for stochastic quantum mechanics, resulting in linear computational complexity with respect to the number of dimensions. Numerical simulations verify our theoretical findings and show a significant advantage of our method compared to other deep-learning-based approaches used for quantum mechanics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25200;&#21160;&#36741;&#21161;&#26679;&#26412;&#21512;&#25104;&#65288;PASS&#65289;&#26041;&#27861;&#65292;&#21487;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#32472;&#21046;&#21487;&#38752;&#32467;&#35770;&#65292;&#24182;&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#21644;&#33945;&#29305;&#21345;&#32599;&#23454;&#39564;&#35777;&#26126;&#20219;&#20309;&#32479;&#35745;&#25968;&#25454;&#30340;&#20272;&#35745;&#20998;&#24067;&#12290;&#36827;&#19968;&#27493;&#25512;&#20986;&#25200;&#21160;&#36741;&#21161;&#25512;&#29702;&#65288;PAI&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#25552;&#20379;&#26377;&#25928;&#24615;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.18671</link><description>&lt;p&gt;
&#25200;&#21160;&#36741;&#21161;&#26679;&#26412;&#21512;&#25104;&#65306;&#19968;&#31181;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Perturbation-Assisted Sample Synthesis: A Novel Approach for Uncertainty Quantification. (arXiv:2305.18671v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25200;&#21160;&#36741;&#21161;&#26679;&#26412;&#21512;&#25104;&#65288;PASS&#65289;&#26041;&#27861;&#65292;&#21487;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#32472;&#21046;&#21487;&#38752;&#32467;&#35770;&#65292;&#24182;&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#21644;&#33945;&#29305;&#21345;&#32599;&#23454;&#39564;&#35777;&#26126;&#20219;&#20309;&#32479;&#35745;&#25968;&#25454;&#30340;&#20272;&#35745;&#20998;&#24067;&#12290;&#36827;&#19968;&#27493;&#25512;&#20986;&#25200;&#21160;&#36741;&#21161;&#25512;&#29702;&#65288;PAI&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#25552;&#20379;&#26377;&#25928;&#24615;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#25200;&#21160;&#36741;&#21161;&#26679;&#26412;&#21512;&#25104;&#65288;PASS&#65289;&#8221;&#30340;&#26032;&#22411;&#29983;&#25104;&#22120;&#65292;&#26088;&#22312;&#20174;&#22797;&#26434;&#25968;&#25454;&#20013;&#32472;&#21046;&#21487;&#38752;&#30340;&#32467;&#35770;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31561;&#39640;&#32423;&#24314;&#27169;&#25216;&#26415;&#26102;&#12290; PASS&#21033;&#29992;&#25200;&#21160;&#29983;&#25104;&#38752;&#36817;&#21407;&#22987;&#25968;&#25454;&#20998;&#24067;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#21253;&#25324;&#25968;&#23383;&#21644;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#31867;&#22411;&#65292;&#22914;&#22522;&#22240;&#34920;&#36798;&#12289;&#22270;&#20687;&#21644;&#25991;&#26412;&#12290;&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#24182;&#21033;&#29992;&#22823;&#22411;&#39044;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;PASS&#25552;&#39640;&#20102;&#20272;&#35745;&#31934;&#24230;&#65292;&#24182;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#23454;&#39564;&#35777;&#26126;&#20102;&#20219;&#20309;&#32479;&#35745;&#25968;&#25454;&#30340;&#20272;&#35745;&#20998;&#24067;&#12290;&#22522;&#20110;PASS&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#25512;&#29702;&#26694;&#26550;&#31216;&#20026;&#8220;&#25200;&#21160;&#36741;&#21161;&#25512;&#29702;&#65288;PAI&#65289;&#8221;&#65292;&#23427;&#25552;&#20379;&#20102;&#26377;&#25928;&#24615;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#22312;&#20851;&#38190;&#25512;&#29702;&#20013;&#65292;PAI&#20351;&#24471;&#22312;&#19981;&#30693;&#36947;&#24341;&#23548;&#20998;&#24067;&#65288;&#22914;&#27169;&#25311;&#20013;&#65289;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#24471;&#20986;&#20934;&#30830;&#30340;&#32467;&#35770;&#65292;&#21363;&#20351;&#21482;&#26377;&#26377;&#38480;&#30340;&#25968;&#25454;&#12290;&#22312;&#38750;&#20851;&#38190;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35757;&#32451;PASS&#20351;&#29992;&#20013;&#38388;&#21464;&#37327;&#25554;&#34917;&#31574;&#30053;&#26469;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#65292;&#21253;&#25324;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12289;&#22270;&#20687;&#20998;&#31867;&#21644;&#25991;&#26412;&#29983;&#25104;&#65292;PASS&#21644;PAI&#37117;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26367;&#20195;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel generator called Perturbation-Assisted Sample Synthesis (PASS), designed for drawing reliable conclusions from complex data, especially when using advanced modeling techniques like deep neural networks. PASS utilizes perturbation to generate synthetic data that closely mirrors the distribution of raw data, encompassing numerical and unstructured data types such as gene expression, images, and text. By estimating the data-generating distribution and leveraging large pre-trained generative models, PASS enhances estimation accuracy, providing an estimated distribution of any statistic through Monte Carlo experiments. Building on PASS, we propose a generative inference framework called Perturbation-Assisted Inference (PAI), which offers a statistical guarantee of validity. In pivotal inference, PAI enables accurate conclusions without knowing a pivotal's distribution as in simulations, even with limited data. In non-pivotal situations, we train PASS using an i
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#31561;&#21464;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#26174;&#24335;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#32452;&#30340;&#28508;&#22312;&#32447;&#24615;&#20316;&#29992;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#38544;&#34255;&#32467;&#26500;&#30340;&#25552;&#21462;&#12290;</title><link>http://arxiv.org/abs/2305.18484</link><description>&lt;p&gt;
&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#65306;&#31561;&#21464;&#34920;&#31034;&#23398;&#20064;&#30340;&#36890;&#29992;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Neural Fourier Transform: A General Approach to Equivariant Representation Learning. (arXiv:2305.18484v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18484
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#31561;&#21464;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#26174;&#24335;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#32452;&#30340;&#28508;&#22312;&#32447;&#24615;&#20316;&#29992;&#65292;&#23454;&#29616;&#23545;&#25968;&#25454;&#38544;&#34255;&#32467;&#26500;&#30340;&#25552;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#23398;&#20064;&#24050;&#34987;&#35777;&#26126;&#26159;&#25552;&#21462;&#25968;&#25454;&#38544;&#34255;&#32467;&#26500;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#20854;&#20013;&#31561;&#21464;&#20851;&#31995;&#27010;&#24565;&#36215;&#30528;&#20013;&#24515;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30740;&#31350;&#37117;&#24314;&#31435;&#22312;&#24314;&#31569;&#29702;&#35770;&#21644;&#23545;&#25968;&#25454;&#24418;&#24335;&#30340;&#30456;&#24212;&#20551;&#35774;&#20043;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31070;&#32463;&#20613;&#37324;&#21494;&#21464;&#25442;&#65288;NFT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23398;&#20064;&#32452;&#30340;&#28508;&#22312;&#32447;&#24615;&#20316;&#29992;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;&#20851;&#20110;&#32452;&#22914;&#20309;&#20316;&#29992;&#20110;&#25968;&#25454;&#30340;&#26174;&#24335;&#30693;&#35782;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;NFT&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#24182;&#34920;&#26126;&#31561;&#21464;&#29305;&#24449;&#30340;&#23384;&#22312;&#65292;&#21363;&#22312;&#31561;&#21464;&#24615;&#23398;&#20064;&#20013;&#26222;&#36941;&#20551;&#23450;&#30340;&#65292;&#31561;&#20215;&#20110;&#25968;&#25454;&#31354;&#38388;&#20013;&#23384;&#22312;&#19968;&#32452;&#19981;&#21464;&#26680;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#23454;&#39564;&#32467;&#26524;&#65292;&#28436;&#31034;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#31243;&#24230;&#30340;&#20851;&#20110;&#25805;&#20316;&#32452;&#30340;&#30693;&#35782;&#30340;&#20856;&#22411;&#22330;&#26223;&#20013;&#24212;&#29992;NFT&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry learning has proven to be an effective approach for extracting the hidden structure of data, with the concept of equivariance relation playing the central role. However, most of the current studies are built on architectural theory and corresponding assumptions on the form of data. We propose Neural Fourier Transform (NFT), a general framework of learning the latent linear action of the group without assuming explicit knowledge of how the group acts on data. We present the theoretical foundations of NFT and show that the existence of a linear equivariant feature, which has been assumed ubiquitously in equivariance learning, is equivalent to the existence of a group invariant kernel on the dataspace. We also provide experimental results to demonstrate the application of NFT in typical scenarios with varying levels of knowledge about the acting group.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.15742</link><description>&lt;p&gt;
&#26102;&#38388;&#21464;&#21270;&#22788;&#29702;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#24179;&#22343;&#22240;&#26524;&#25928;&#24212;&#26159;&#27979;&#35797;&#26032;&#30103;&#27861;&#30340;&#24120;&#29992;&#20570;&#27861;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#25928;&#24212;&#20250;&#25513;&#30422;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#37325;&#35201;&#30340;&#20010;&#20307;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#24341;&#36215;&#23433;&#20840;&#12289;&#20844;&#24179;&#21644;&#36947;&#24503;&#26041;&#38754;&#30340;&#25285;&#24551;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26102;&#38388;&#35774;&#32622;&#20013;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#22788;&#29702;&#26159;&#26102;&#24207;&#30340;&#21644;&#26102;&#21464;&#30340;&#65292;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#20135;&#29983;&#20102;&#38169;&#32508;&#22797;&#26434;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#20197;&#25429;&#33719;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#20801;&#35768;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#36825;&#20351;&#24471;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#36890;&#36807;&#36793;&#38469;&#32467;&#26500;&#27169;&#22411;&#35880;&#24910;&#22320;&#35299;&#20915;&#20102;&#35266;&#23519;&#25968;&#25454;&#21644;&#30446;&#26631;&#21453;&#20107;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.14496</link><description>&lt;p&gt;
&#36890;&#36807;&#20013;&#24230;&#20559;&#24046;&#29702;&#35770;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#20351;&#29992;&#32622;&#20449;&#21306;&#38388;&#23398;&#20064;&#20989;&#25968;&#20540;&#30340;&#32479;&#35745;&#26368;&#20248;&#26041;&#27861;&#65292;&#21253;&#25324;&#25551;&#36848;&#20026;&#38543;&#26426;&#35268;&#21010;&#38382;&#39064;&#25110;&#21508;&#31181;SDE&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#30340;&#19968;&#33324;&#38750;&#21442;&#25968;&#20272;&#35745;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#22522;&#20110;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#32479;&#35745;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#28385;&#36275;&#20197;&#25351;&#25968;&#31934;&#24230;&#12289;&#26368;&#23567;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#35823;&#21028;&#27010;&#29575;&#20197;&#21450;&#26368;&#32456;&#30340;&#19968;&#33268;&#26368;&#22823;&#31934;&#24230;&#20026;&#26631;&#20934;&#30340;&#35201;&#27714;&#12290;&#35813;&#26041;&#27861;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#36890;&#36807;&#24378;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#26469;&#34920;&#36798;&#30340;&#65292;&#20854;&#20013;&#19981;&#30830;&#23450;&#24615;&#36890;&#36807;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#24341;&#21457;&#30340;&#20013;&#24230;&#20559;&#24046;&#29575;&#20989;&#25968;&#26469;&#34920;&#31034;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#23545;&#20110;&#35768;&#22810;&#27169;&#22411;&#65292;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#20855;&#26377;&#26131;&#20110;&#35299;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.12569</link><description>&lt;p&gt;
&#26377;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#26159;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#24517;&#22791;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Modeling is All You Need for Marked Temporal Point Processes. (arXiv:2305.12569v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#24314;&#27169;&#30340;&#36827;&#27493;&#20351;&#24471;&#20174;&#19978;&#19979;&#25991;&#20449;&#24687;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#20869;&#23481;&#25104;&#20026;&#21487;&#33021;&#65292;&#20294;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#22914;&#20309;&#25945;&#27169;&#22411;&#30693;&#36947;&#20309;&#26102;&#29983;&#25104;&#20869;&#23481;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#24178;&#20928;&#12289;&#28789;&#27963;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#28041;&#21450;&#22810;&#32500;&#26631;&#35760;&#30340;&#21508;&#31181;&#24212;&#29992;&#12290;&#25105;&#20204;&#26088;&#22312;&#25429;&#25417;&#28857;&#36807;&#31243;&#30340;&#20998;&#24067;&#32780;&#19981;&#38656;&#26126;&#30830;&#25351;&#23450;&#26465;&#20214;&#24378;&#24230;&#25110;&#27010;&#29575;&#23494;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#20197;&#20107;&#20214;&#21382;&#21490;&#20026;&#36755;&#20837;&#24182;&#29983;&#25104;&#22312;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#20107;&#20214;&#19979;&#65292;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#21033;&#30410;&#65292;&#21253;&#25324;&#22312;&#23398;&#20064;&#27169;&#22411;&#21644;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#30340;&#24322;&#24120;&#25928;&#29575;&#20197;&#21450;&#30456;&#24403;&#22823;&#30340;&#34920;&#31034;&#33021;&#21147;&#26469;&#25429;&#25417;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in generative modeling have made it possible to generate high-quality content from context information, but a key question remains: how to teach models to know when to generate content? To answer this question, this study proposes a novel event generative model that draws its statistical intuition from marked temporal point processes, and offers a clean, flexible, and computationally efficient solution for a wide range of applications involving multi-dimensional marks. We aim to capture the distribution of the point process without explicitly specifying the conditional intensity or probability density. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including exceptional efficiency in learning the model and generating samples, as well as considerable representational power to capture
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#22270;&#19978;&#23450;&#20041;&#30340;&#36716;&#31227;&#31639;&#23376;&#21450;&#20854;&#35889;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#36716;&#31227;&#31639;&#23376;&#30340;&#26377;&#21521;&#22270;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11766</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#36716;&#31227;&#31639;&#23376;&#65306;&#35889;&#32858;&#31867;&#21450;&#20854;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Transfer operators on graphs: Spectral clustering and beyond. (arXiv:2305.11766v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#22270;&#19978;&#23450;&#20041;&#30340;&#36716;&#31227;&#31639;&#23376;&#21450;&#20854;&#35889;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#36716;&#31227;&#31639;&#23376;&#30340;&#26377;&#21521;&#22270;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21644;&#32593;&#32476;&#22312;&#24314;&#27169;&#21644;&#20998;&#26512;&#22797;&#26434;&#30340;&#30456;&#20851;&#31995;&#32479;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#20363;&#22914;&#20132;&#36890;&#32593;&#32476;&#65292;&#38598;&#25104;&#30005;&#36335;&#65292;&#30005;&#21147;&#32593;&#26684;&#65292;&#24341;&#25991;&#22270;&#20197;&#21450;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#12290;&#26412;&#25991;&#22312;&#22270;&#19978;&#23450;&#20041;&#20102;&#36716;&#31227;&#31639;&#23376;&#65292;&#22914;Koopman&#31639;&#23376;&#21644;Perron-Frobenius&#31639;&#23376;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#35889;&#29305;&#24615;&#65292;&#24341;&#20837;&#20102;&#36825;&#20123;&#31639;&#23376;&#30340;Galerkin&#25237;&#24433;&#65292;&#24182;&#35828;&#26126;&#20102;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#38477;&#20302;&#34920;&#31034;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#21521;&#22270;&#35889;&#32858;&#31867;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;Koopman&#31639;&#23376;&#30340;&#29305;&#24449;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#36716;&#31227;&#31639;&#23376;&#30340;&#26377;&#21521;&#22270;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#25152;&#24471;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19981;&#21516;&#32858;&#31867;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphs and networks play an important role in modeling and analyzing complex interconnected systems such as transportation networks, integrated circuits, power grids, citation graphs, and biological and artificial neural networks. Graph clustering algorithms can be used to detect groups of strongly connected vertices and to derive coarse-grained models. We define transfer operators such as the Koopman operator and the Perron-Frobenius operator on graphs, study their spectral properties, introduce Galerkin projections of these operators, and illustrate how reduced representations can be estimated from data. In particular, we show that spectral clustering of undirected graphs can be interpreted in terms of eigenfunctions of the Koopman operator and propose novel clustering algorithms for directed graphs based on generalized transfer operators. We demonstrate the efficacy of the resulting algorithms on several benchmark problems and provide different interpretations of clusters.
&lt;/p&gt;</description></item></channel></rss>