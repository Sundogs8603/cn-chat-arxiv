<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#19981;&#21487;&#21306;&#20998;&#24615;&#12290;&#20182;&#20204;&#36890;&#36807;&#23398;&#20064;&#35268;&#21017;&#30340;&#32467;&#26524;&#30456;&#20284;&#24615;&#26469;&#26816;&#39564;&#20004;&#20010;&#36755;&#20986;&#20998;&#24067;&#26159;&#21542;&#30456;&#20284;&#12290;&#26412;&#25991;&#21457;&#29616; TV &#19981;&#21487;&#21306;&#20998;&#24615;&#19982;&#29616;&#26377;&#31639;&#27861;&#31283;&#23450;&#24615;&#27010;&#24565;&#31561;&#20215;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14311</link><description>&lt;p&gt;
&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#19981;&#21487;&#21306;&#20998;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Indistinguishability of Learning Algorithms. (arXiv:2305.14311v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#31639;&#27861;&#30340;&#32479;&#35745;&#19981;&#21487;&#21306;&#20998;&#24615;&#12290;&#20182;&#20204;&#36890;&#36807;&#23398;&#20064;&#35268;&#21017;&#30340;&#32467;&#26524;&#30456;&#20284;&#24615;&#26469;&#26816;&#39564;&#20004;&#20010;&#36755;&#20986;&#20998;&#24067;&#26159;&#21542;&#30456;&#20284;&#12290;&#26412;&#25991;&#21457;&#29616; TV &#19981;&#21487;&#21306;&#20998;&#24615;&#19982;&#29616;&#26377;&#31639;&#27861;&#31283;&#23450;&#24615;&#27010;&#24565;&#31561;&#20215;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20004;&#20010;&#19981;&#21516;&#30340;&#29992;&#25143;&#22312;&#20182;&#20204;&#33258;&#24049;&#30340;&#25968;&#25454;&#19978;&#20351;&#29992;&#30456;&#21516;&#30340;&#23398;&#20064;&#35268;&#21017;&#26102;&#65292;&#25105;&#20204;&#22914;&#20309;&#27979;&#35797;&#20004;&#20010;&#32467;&#26524;&#30340;&#20998;&#24067;&#26159;&#21542;&#30456;&#20284;&#65311;&#26412;&#25991;&#36890;&#36807;&#20998;&#24067;&#30340;&#24635;&#21464;&#24046;&#36317;&#31163;&#26469;&#30740;&#31350;&#23398;&#20064;&#35268;&#21017;&#32467;&#26524;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#31216;&#23398;&#20064;&#35268;&#21017;&#22312;&#26399;&#26395;&#24635;&#21464;&#24046;&#36317;&#31163;&#19978;&#26159;&#23567;&#30340;&#65292;&#33509;&#20854;&#36755;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#22312;&#20004;&#20010;&#29420;&#31435;&#20110;&#30456;&#21516;&#20998;&#24067;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#19978;&#25191;&#34892;&#26102;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20351;&#29992; TV &#19981;&#21487;&#21306;&#20998;&#23398;&#20064;&#22120;&#30340;&#20551;&#35774;&#31867;&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159; TV &#19981;&#21487;&#21306;&#20998;&#24615;&#21644;&#29616;&#26377;&#31639;&#27861;&#31283;&#23450;&#24615;&#27010;&#24565;&#20043;&#38388;&#30340;&#20449;&#24687;&#35770;&#31561;&#20215;&#24615;&#65292;&#22914;&#21487;&#22797;&#21046;&#24615;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102; TV &#19981;&#21487;&#21306;&#20998;&#23398;&#20064;&#22120;&#30340;&#32479;&#35745;&#25193;&#22823;&#21644;&#25552;&#21319;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
When two different parties use the same learning rule on their own data, how can we test whether the distributions of the two outcomes are similar? In this paper, we study the similarity of outcomes of learning rules through the lens of the Total Variation (TV) distance of distributions. We say that a learning rule is TV indistinguishable if the expected TV distance between the posterior distributions of its outputs, executed on two training data sets drawn independently from the same distribution, is small. We first investigate the learnability of hypothesis classes using TV indistinguishable learners. Our main results are information-theoretic equivalences between TV indistinguishability and existing algorithmic stability notions such as replicability and approximate differential privacy. Then, we provide statistical amplification and boosting algorithms for TV indistinguishable learners.
&lt;/p&gt;</description></item><item><title>MACE&#30340;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#26550;&#26500;&#22312;&#20869;&#22495;&#12289;&#22806;&#25512;&#21644;&#20302;&#25968;&#25454;&#33539;&#22260;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#22312;&#22788;&#29702;&#38750;&#26230;&#30899;&#12289;&#23567;&#20998;&#23376;&#26377;&#26426;&#21270;&#23398;&#12289;&#22823;&#20998;&#23376;&#21644;&#28082;&#24577;&#27700;&#31561;&#39046;&#22495;&#26102;&#24120;&#24120;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#12290;&#21363;&#20351;&#21482;&#26377;50&#20010;&#38543;&#26426;&#36873;&#23450;&#30340;&#21442;&#32771;&#37197;&#32622;&#65292;&#35813;&#27169;&#22411;&#20063;&#33021;&#38750;&#24120;&#39640;&#25928;&#22320;&#22797;&#29616;&#23454;&#39564;&#20998;&#23376;&#25391;&#21160;&#20809;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.14247</link><description>&lt;p&gt;
MACE&#21147;&#22330;&#26550;&#26500;&#30340;&#35780;&#20272;&#65306;&#20174;&#33647;&#29289;&#21270;&#23398;&#21040;&#26448;&#26009;&#31185;&#23398;
&lt;/p&gt;
&lt;p&gt;
Evaluation of the MACE Force Field Architecture: from Medicinal Chemistry to Materials Science. (arXiv:2305.14247v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14247
&lt;/p&gt;
&lt;p&gt;
MACE&#30340;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#26550;&#26500;&#22312;&#20869;&#22495;&#12289;&#22806;&#25512;&#21644;&#20302;&#25968;&#25454;&#33539;&#22260;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#22312;&#22788;&#29702;&#38750;&#26230;&#30899;&#12289;&#23567;&#20998;&#23376;&#26377;&#26426;&#21270;&#23398;&#12289;&#22823;&#20998;&#23376;&#21644;&#28082;&#24577;&#27700;&#31561;&#39046;&#22495;&#26102;&#24120;&#24120;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#12290;&#21363;&#20351;&#21482;&#26377;50&#20010;&#38543;&#26426;&#36873;&#23450;&#30340;&#21442;&#32771;&#37197;&#32622;&#65292;&#35813;&#27169;&#22411;&#20063;&#33021;&#38750;&#24120;&#39640;&#25928;&#22320;&#22797;&#29616;&#23454;&#39564;&#20998;&#23376;&#25391;&#21160;&#20809;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
MACE&#26550;&#26500;&#20195;&#34920;&#20102;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#30340;&#26368;&#26032;&#25216;&#26415;&#65292;&#33021;&#22815;&#22788;&#29702;&#20869;&#22495;&#12289;&#22806;&#25512;&#21644;&#20302;&#25968;&#25454;&#33539;&#22260;&#20219;&#21153;&#12290;&#26412;&#25991;&#23545;MACE&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#35780;&#20272;&#65292;&#36890;&#36807;&#25311;&#21512;&#24050;&#21457;&#34920;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#27169;&#22411;&#26469;&#34920;&#26126;MACE&#22312;&#21508;&#31181;&#20307;&#31995;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#65292;&#21253;&#25324;&#38750;&#26230;&#30899;&#12289;&#19968;&#33324;&#30340;&#23567;&#20998;&#23376;&#26377;&#26426;&#21270;&#23398;&#12289;&#22823;&#20998;&#23376;&#21644;&#28082;&#24577;&#27700;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#20174;&#32422;&#26463;&#20960;&#20309;&#20248;&#21270;&#21040;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#65292;&#21457;&#29616;&#20854;&#22312;&#25152;&#26377;&#27979;&#35797;&#39046;&#22495;&#37117;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#22312;&#20165;50&#20010;&#38543;&#26426;&#36873;&#23450;&#30340;&#21442;&#32771;&#37197;&#32622;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;MACE&#21363;&#21487;&#38750;&#24120;&#39640;&#25928;&#22320;&#22797;&#29616;&#23454;&#39564;&#20998;&#23376;&#25391;&#21160;&#20809;&#35889;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#21363;&#20351;&#22312;&#22823;&#20998;&#23376;&#21644;&#24369;&#30456;&#20114;&#20316;&#29992;&#30340;&#20998;&#23376;&#32452;&#35013;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#22522;&#20110;&#20005;&#26684;&#23616;&#37096;&#30340;&#21407;&#23376;&#20013;&#24515;&#27169;&#22411;&#20063;&#26159;&#36275;&#22815;&#36866;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The MACE architecture represents the state of the art in the field of machine learning force fields for a variety of in-domain, extrapolation and low-data regime tasks. In this paper, we further evaluate MACE by fitting models for published benchmark datasets. We show that MACE generally outperforms alternatives for a wide range of systems from amorphous carbon and general small molecule organic chemistry to large molecules and liquid water. We demonstrate the capabilities of the model on tasks ranging from constrained geometry optimisation to molecular dynamics simulations and find excellent performance across all tested domains. We show that MACE is very data efficient, and can reproduce experimental molecular vibrational spectra when trained on as few as 50 randomly selected reference configurations. We further demonstrate that the strictly local atom-centered model is sufficient for such tasks even in the case of large molecules and weakly interacting molecular assemblies.
&lt;/p&gt;</description></item><item><title>ZeroSCROLLS&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#20845;&#20010;&#20219;&#21153;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24403;&#21069;&#65292;GPT-4&#30340;&#24179;&#22343;&#24471;&#20998;&#26368;&#39640;&#65292;&#20294;&#22312;&#32858;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#25361;&#25112;&#19978;&#65292;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2305.14196</link><description>&lt;p&gt;
ZeroSCROLLS&#65306;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14196
&lt;/p&gt;
&lt;p&gt;
ZeroSCROLLS&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#20845;&#20010;&#20219;&#21153;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24403;&#21069;&#65292;GPT-4&#30340;&#24179;&#22343;&#24471;&#20998;&#26368;&#39640;&#65292;&#20294;&#22312;&#32858;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#25361;&#25112;&#19978;&#65292;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102; ZeroSCROLLS&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#20165;&#21253;&#21547;&#27979;&#35797;&#38598;&#32780;&#27809;&#26377;&#35757;&#32451;&#25110;&#24320;&#21457;&#25968;&#25454;&#12290;&#25105;&#20204;&#20174;SCROLLS&#22522;&#20934;&#27979;&#35797;&#20013;&#36866;&#24212;&#20102;&#20845;&#20010;&#20219;&#21153;&#65292;&#24182;&#28155;&#21152;&#20102;&#22235;&#20010;&#26032;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20004;&#20010;&#26032;&#30340;&#20449;&#24687;&#34701;&#21512;&#20219;&#21153;&#65292;&#20363;&#22914;&#32858;&#21512;&#27491;&#38754;&#35780;&#20215;&#30340;&#30334;&#20998;&#27604;&#12290;&#20351;&#29992;ZeroSCROLLS&#65292;&#25105;&#20204;&#23545;&#24320;&#28304;&#21644;&#38381;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;Claude&#20248;&#20110;ChatGPT&#65292;&#24182;&#19988;GPT-4&#33719;&#24471;&#20102;&#26368;&#39640;&#30340;&#24179;&#22343;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;ZeroSCROLLS&#30340;&#22810;&#20010;&#24320;&#25918;&#25361;&#25112;&#26041;&#38754;&#65288;&#20363;&#22914;&#65292;&#32858;&#21512;&#20219;&#21153;&#65289;&#65292;&#36824;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#65292;&#22240;&#20026;&#27169;&#22411;&#24456;&#38590;&#36890;&#36807;&#26420;&#32032;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#30001;&#20110;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#36824;&#22312;&#19981;&#26029;&#26356;&#26032;&#65292;&#25105;&#20204;&#36992;&#35831;&#30740;&#31350;&#20154;&#21592;&#22312;&#23454;&#26102;&#30340;ZeroSCROLLS&#25490;&#34892;&#27036;&#19978;&#35780;&#20272;&#20182;&#20204;&#30340;&#24819;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test sets, without training or development data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#26657;&#27491;&#26041;&#26696;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14164</link><description>&lt;p&gt;
&#36890;&#36807;&#39044;&#27979;&#20462;&#27491;&#25552;&#39640;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improved Convergence of Score-Based Diffusion Models via Prediction-Correction. (arXiv:2305.14164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#26657;&#27491;&#26041;&#26696;&#65292;&#25552;&#39640;&#20102;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGM&#65289;&#26159;&#20174;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#20854;&#22522;&#26412;&#24605;&#24819;&#26159;&#65288;i&#65289;&#36890;&#36807;&#21521;&#25968;&#25454;&#28155;&#21152;&#22122;&#22768;&#36816;&#34892;&#26102;&#38388;&#20026;$T_1$&#30340;&#27491;&#21521;&#36807;&#31243;&#65292;&#65288;ii&#65289;&#20272;&#35745;&#20854;&#24471;&#20998;&#20989;&#25968;&#65292;&#24182;&#65288;iii&#65289;&#20351;&#29992;&#27492;&#20272;&#35745;&#20540;&#36816;&#34892;&#21453;&#21521;&#36807;&#31243;&#12290;&#30001;&#20110;&#21453;&#21521;&#36807;&#31243;&#20197;&#27491;&#21521;&#36807;&#31243;&#30340;&#24179;&#31283;&#20998;&#24067;&#20316;&#20026;&#21021;&#22987;&#20540;&#65292;&#22240;&#27492;&#29616;&#26377;&#30340;&#20998;&#26512;&#33539;&#24335;&#35201;&#27714;$T_1\to\infty$&#12290;&#28982;&#32780;&#65292;&#20174;&#29702;&#35770;&#35282;&#24230;&#26469;&#30475;&#65292;&#23545;&#20110;&#32473;&#23450;&#30340;&#20998;&#25968;&#36924;&#36817;&#31934;&#24230;&#65292;&#24403;$T_1$&#21457;&#25955;&#26102;&#65292;&#25910;&#25947;&#20445;&#35777;&#23558;&#22833;&#36133;&#65307;&#20174;&#23454;&#38469;&#35282;&#24230;&#26469;&#30475;&#65292;$T_1$&#36234;&#22823;&#65292;&#35745;&#31639;&#25104;&#26412;&#23601;&#36234;&#39640;&#65292;&#24182;&#19988;&#20250;&#23548;&#33268;&#35823;&#24046;&#20256;&#25773;&#12290;&#26412;&#25991;&#36890;&#36807;&#32771;&#34385;&#27969;&#34892;&#30340;&#39044;&#27979;&#22120;&#26657;&#27491;&#26041;&#26696;&#30340;&#19968;&#20010;&#29256;&#26412;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65306;&#22312;&#36816;&#34892;&#27491;&#21521;&#36807;&#31243;&#20043;&#21518;&#65292;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#19981;&#31934;&#30830;&#30340; Langevin &#21160;&#21147;&#23398;&#20272;&#35745;&#26368;&#32456;&#20998;&#24067;&#65292;&#28982;&#21518;&#24674;&#22797;&#35813;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#26159;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative models (SGMs) are powerful tools to sample from complex data distributions. Their underlying idea is to (i) run a forward process for time $T_1$ by adding noise to the data, (ii) estimate its score function, and (iii) use such estimate to run a reverse process. As the reverse process is initialized with the stationary distribution of the forward one, the existing analysis paradigm requires $T_1\to\infty$. This is however problematic: from a theoretical viewpoint, for a given precision of the score approximation, the convergence guarantee fails as $T_1$ diverges; from a practical viewpoint, a large $T_1$ increases computational costs and leads to error propagation. This paper addresses the issue by considering a version of the popular predictor-corrector scheme: after running the forward process, we first estimate the final distribution via an inexact Langevin dynamics and then revert the process. Our key technical contribution is to provide convergence guarantees
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;Neyman-Pearson&#26816;&#39564;&#22312;&#25311;&#21512;&#20248;&#24230;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#21517;&#20026;NPLM&#30340;&#23454;&#29992;&#23454;&#29616;&#12290;&#21644;&#22522;&#20110;&#20998;&#31867;&#22120;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#25506;&#27979;&#21040;&#25968;&#25454;&#19982;&#26399;&#26395;&#20998;&#24067;&#30340;&#23567;&#20559;&#24046;&#26102;&#65292;NPLM&#26356;&#28789;&#25935;&#19988;&#19981;&#20250;&#20559;&#21521;&#20219;&#20309;&#31867;&#22411;&#30340;&#24322;&#24120;&#65292;&#27604;&#36739;&#36866;&#29992;&#20110;&#23545;&#25758;&#26426;&#23454;&#39564;&#20013;&#23545;&#20110;&#26032;&#29289;&#29702;&#30340;&#19981;&#21487;&#30693;&#25628;&#32034;&#12290; future work &#38656;&#35201;&#30740;&#31350;&#23427;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.14137</link><description>&lt;p&gt;
Neyman-Pearson&#26816;&#39564;&#30340;&#25311;&#21512;&#20248;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Goodness of fit by Neyman-Pearson testing. (arXiv:2305.14137v1 [hep-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;Neyman-Pearson&#26816;&#39564;&#22312;&#25311;&#21512;&#20248;&#24230;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#21517;&#20026;NPLM&#30340;&#23454;&#29992;&#23454;&#29616;&#12290;&#21644;&#22522;&#20110;&#20998;&#31867;&#22120;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#25506;&#27979;&#21040;&#25968;&#25454;&#19982;&#26399;&#26395;&#20998;&#24067;&#30340;&#23567;&#20559;&#24046;&#26102;&#65292;NPLM&#26356;&#28789;&#25935;&#19988;&#19981;&#20250;&#20559;&#21521;&#20219;&#20309;&#31867;&#22411;&#30340;&#24322;&#24120;&#65292;&#27604;&#36739;&#36866;&#29992;&#20110;&#23545;&#25758;&#26426;&#23454;&#39564;&#20013;&#23545;&#20110;&#26032;&#29289;&#29702;&#30340;&#19981;&#21487;&#30693;&#25628;&#32034;&#12290; future work &#38656;&#35201;&#30740;&#31350;&#23427;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#22791;&#36873;&#20551;&#35774;$H_1$&#36275;&#22815;&#36890;&#29992;&#65292;&#26082;&#19981;&#24341;&#20837;&#37325;&#22823;&#20559;&#24046;&#21448;&#36991;&#20813;&#36807;&#24230;&#25311;&#21512;&#26102;&#65292;Neyman-Pearson&#31574;&#30053;&#21487;&#20197;&#29992;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#12290;&#22312;&#39640;&#33021;&#29289;&#29702;&#30340;&#32972;&#26223;&#19979;&#65292;&#19968;&#31181;&#21517;&#20026;NPLM&#30340;&#23454;&#29992;&#23454;&#29616;&#24050;&#34987;&#24320;&#21457;&#65292;&#26088;&#22312;&#25506;&#27979;&#26631;&#20934;&#27169;&#22411;&#26410;&#39044;&#26009;&#21040;&#30340;&#26032;&#29289;&#29702;&#25928;&#24212;&#65292;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#23558;&#35813;&#26041;&#27861;&#19982;&#20854;&#20182;&#25311;&#21512;&#20248;&#24230;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Neyman-Pearson strategy for hypothesis testing can be employed for goodness of fit if the alternative hypothesis $\rm H_1$ is generic enough not to introduce a significant bias while at the same time avoiding overfitting. A practical implementation of this idea (dubbed NPLM) has been developed in the context of high energy physics, targeting the detection in collider data of new physical effects not foreseen by the Standard Model. In this paper we initiate a comparison of this methodology with other approaches to goodness of fit, and in particular with classifier-based strategies that share strong similarities with NPLM. NPLM emerges from our comparison as more sensitive to small departures of the data from the expected distribution and not biased towards detecting specific types of anomalies while being blind to others. These features make it more suited for agnostic searches for new physics at collider experiments. Its deployment in other contexts should be investigated.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36716;&#31227;&#23398;&#20064;&#36712;&#36857;&#30340;&#31639;&#27861;&#65292;&#21487;&#23558;&#20043;&#21069;&#35757;&#32451;&#36807;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36712;&#36857;&#24212;&#29992;&#22312;&#26032;&#30340;&#35757;&#32451;&#20013;&#65292;&#24182;&#33021;&#22312;&#20219;&#20309;&#30452;&#25509;&#35757;&#32451;&#20043;&#21069;&#23454;&#29616;&#38750;&#24179;&#20961;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14122</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#36712;&#36857;&#30340;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Transferring Learning Trajectories of Neural Networks. (arXiv:2305.14122v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#36716;&#31227;&#23398;&#20064;&#36712;&#36857;&#30340;&#31639;&#27861;&#65292;&#21487;&#23558;&#20043;&#21069;&#35757;&#32451;&#36807;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36712;&#36857;&#24212;&#29992;&#22312;&#26032;&#30340;&#35757;&#32451;&#20013;&#65292;&#24182;&#33021;&#22312;&#20219;&#20309;&#30452;&#25509;&#35757;&#32451;&#20043;&#21069;&#23454;&#29616;&#38750;&#24179;&#20961;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#26159;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#65292;&#36825;&#22312;&#25191;&#34892;&#37325;&#22797;&#35757;&#32451;&#36816;&#34892;&#65288;&#20363;&#22914;&#27169;&#22411;&#38598;&#25104;&#25110;&#30693;&#35782;&#33976;&#39311;&#65289;&#26102;&#23588;&#20854;&#25104;&#38382;&#39064;&#12290;&#19968;&#26086;&#25105;&#20204;&#22312;&#26576;&#20010;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#20102;&#19968;&#20010;DNN&#65292;&#25105;&#20204;&#23601;&#25317;&#26377;&#20102;&#20854;&#23398;&#20064;&#36712;&#36857;&#65288;&#21363;&#35757;&#32451;&#26399;&#38388;&#30340;&#20013;&#38388;&#21442;&#25968;&#24207;&#21015;&#65289;&#65292;&#20854;&#20013;&#21487;&#33021;&#21253;&#21547;&#23398;&#20064;&#25968;&#25454;&#38598;&#30340;&#26377;&#29992;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#23578;&#26410;&#23581;&#35797;&#21033;&#29992;&#32473;&#23450;&#23398;&#20064;&#36712;&#36857;&#30340;&#36825;&#31181;&#20449;&#24687;&#36827;&#34892;&#21478;&#19968;&#31181;&#35757;&#32451;&#12290;&#26412;&#25991;&#23558;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#8220;&#36716;&#31227;&#8221;&#32473;&#23450;&#23398;&#20064;&#36712;&#36857;&#20174;&#19968;&#20010;&#21021;&#22987;&#21442;&#25968;&#21040;&#21478;&#19968;&#20010;&#21021;&#22987;&#21442;&#25968;&#65292;&#31216;&#20026;&#23398;&#20064;&#36716;&#31227;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#21305;&#37197;&#27839;&#36712;&#36857;&#36880;&#28176;&#24179;&#31227;&#23545;&#31216;&#24615;&#30340;&#26799;&#24230;&#23548;&#20986;&#20102;&#31532;&#19968;&#20010;&#31639;&#27861;&#65292;&#20197;&#36817;&#20284;&#35299;&#20915;&#23427;&#12290;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;&#36716;&#31227;&#21442;&#25968;&#22312;&#20219;&#20309;&#30452;&#25509;&#35757;&#32451;&#20043;&#21069;&#23601;&#33021;&#36798;&#21040;&#38750;&#24179;&#20961;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36716;&#31227;&#21442;&#25968;&#30340;&#25439;&#22833;&#26223;&#35266;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training deep neural networks (DNNs) is computationally expensive, which is problematic especially when performing duplicated training runs, such as model ensemble or knowledge distillation. Once we have trained one DNN on some dataset, we have its learning trajectory (i.e., a sequence of intermediate parameters during training) which may potentially contain useful information for learning the dataset. However, there has been no attempt to utilize such information of a given learning trajectory for another training. In this paper, we formulate the problem of "transferring" a given learning trajectory from one initial parameter to another one, called learning transfer problem, and derive the first algorithm to approximately solve it by matching gradients successively along the trajectory via permutation symmetry. We empirically show that the transferred parameters achieve non-trivial accuracy before any direct training. Also, we analyze the loss landscape property of the transferred par
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14120</link><description>&lt;p&gt;
&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#24773;&#22659;&#21464;&#37327;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Cost-aware learning of relevant contextual variables within Bayesian optimization. (arXiv:2305.14120v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#22659;&#36125;&#21494;&#26031;&#20248;&#21270;(CBO)&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#38024;&#23545;&#35774;&#35745;&#21464;&#37327;&#20248;&#21270;&#40657;&#30418;&#26114;&#36149;&#30340;&#35780;&#20272;&#20989;&#25968;&#65292;&#24182;&#21516;&#26102;&#26377;&#25928;&#22320;&#25972;&#21512;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#22914;&#23454;&#39564;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#19981;&#19968;&#23450;&#26159;&#39044;&#20808;&#24050;&#30693;&#30340;&#12290;&#27492;&#22806;&#65292;&#26377;&#26102;&#36824;&#21487;&#20197;&#26368;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#26412;&#36523;&#65292;&#36825;&#26159;&#24403;&#21069;CBO&#31639;&#27861;&#26410;&#32771;&#34385;&#30340;&#35774;&#32622;&#12290;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#21487;&#33021;&#26159;&#26114;&#36149;&#30340;&#65292;&#36825;&#24341;&#20986;&#20102;&#30830;&#23450;&#19968;&#20010;&#26368;&#23567;&#30456;&#20851;&#23376;&#38598;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#20316;&#20026;&#19968;&#20010;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#20219;&#21153;&#26469;&#26500;&#26550;&#65292;&#37319;&#29992;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#24773;&#22659;BO (SADCBO) &#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#29305;&#23450;&#36755;&#20837;&#28857;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#30340;&#20195;&#20215;&#12290;SADCBO&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#22522;&#20934;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#26174;&#31034;&#20986;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions with respect to design variables, while simultaneously efficiently integrating relevant contextual information regarding the environment, such as experimental conditions. However, in many practical scenarios, the relevance of contextual variables is not necessarily known beforehand. Moreover, the contextual variables can sometimes be optimized themselves, a setting that current CBO algorithms do not take into account. Optimizing contextual variables may be costly, which raises the question of determining a minimal relevant subset. In this paper, we frame this problem as a cost-aware model selection BO task and address it using a novel method, Sensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points, whilst minimizing the cost of optimization by lev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#33258;&#36866;&#24212;&#21160;&#24577;&#26089;&#26399;&#36864;&#20986;&#26426;&#21046;&#65292;&#36890;&#36807;&#33021;&#37327;&#24863;&#30693;&#30340;&#31574;&#30053;&#65292;&#22312;EH&#36793;&#32536;&#35774;&#22791;&#20013;&#23454;&#29616;&#20102;&#39640;&#25928;&#20934;&#30830;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2305.14094</link><description>&lt;p&gt;
&#36890;&#36807;&#33021;&#37327;&#24863;&#30693;&#30340;&#26089;&#26399;&#36864;&#20986;&#23454;&#29616;&#21487;&#25345;&#32493;&#30340;&#36793;&#32536;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
Sustainable Edge Intelligence Through Energy-Aware Early Exiting. (arXiv:2305.14094v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#33258;&#36866;&#24212;&#21160;&#24577;&#26089;&#26399;&#36864;&#20986;&#26426;&#21046;&#65292;&#36890;&#36807;&#33021;&#37327;&#24863;&#30693;&#30340;&#31574;&#30053;&#65292;&#22312;EH&#36793;&#32536;&#35774;&#22791;&#20013;&#23454;&#29616;&#20102;&#39640;&#25928;&#20934;&#30830;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#24050;&#25104;&#20026;&#29289;&#32852;&#32593;&#24212;&#29992;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#28040;&#32791;&#22823;&#37327;&#33021;&#37327;&#65292;&#36825;&#21487;&#33021;&#20250;&#24555;&#36895;&#32791;&#23613;&#30005;&#27744;&#24182;&#24433;&#21709;&#29289;&#32852;&#32593;&#35774;&#22791;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#23454;&#29616;&#21487;&#25345;&#32493;&#36816;&#34892;&#65292;&#26412;&#25991;&#32771;&#34385;&#19968;&#20010;&#24102;&#26377;&#21487;&#20805;&#30005;&#30005;&#27744;&#21644;&#33021;&#37327;&#25910;&#33719;&#33021;&#21147;&#30340;&#36793;&#32536;&#35774;&#22791;&#12290;&#38500;&#20102;&#29615;&#22659;&#33021;&#28304;&#30340;&#38543;&#26426;&#24615;&#22806;&#65292;&#25910;&#33719;&#36895;&#29575;&#36890;&#24120;&#19981;&#36275;&#20197;&#28385;&#36275;&#25512;&#29702;&#33021;&#28304;&#38656;&#27714;&#65292;&#22312;&#33021;&#28304;&#19981;&#21487;&#30693;&#30340;&#35774;&#22791;&#20013;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#24615;&#33021;&#38477;&#20302;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#37327;&#33258;&#36866;&#24212;&#21160;&#24577;&#26089;&#26399;&#36864;&#20986;&#26426;&#21046;&#65292;&#20197;&#23454;&#29616;&#22312;&#20805;&#28385;&#29615;&#22659;&#33021;&#28304;&#24773;&#20917;&#19979;&#30340;&#39640;&#25928;&#20934;&#30830;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning (DL) models have emerged as a promising solution for Internet of Things (IoT) applications. However, due to their computational complexity, DL models consume significant amounts of energy, which can rapidly drain the battery and compromise the performance of IoT devices. For sustainable operation, we consider an edge device with a rechargeable battery and energy harvesting (EH) capabilities. In addition to the stochastic nature of the ambient energy source, the harvesting rate is often insufficient to meet the inference energy requirements, leading to drastic performance degradation in energy-agnostic devices. To mitigate this problem, we propose energy-adaptive dynamic early exiting (EE) to enable efficient and accurate inference in an EH edge intelligence system. Our approach derives an energy-aware EE policy that determines the optimal amount of computational processing on a per-sample basis. The proposed policy balances the energy consumption to match the limited inco
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22266;&#23450;&#32500;&#24230;&#19979;&#20869;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#21457;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#20851;&#38190;&#22312;&#20110;&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#24230;&#32780;&#19981;&#26159;&#32500;&#25968;&#65292;&#24182;&#35777;&#26126;&#22312;&#22266;&#23450;&#32500;&#24230;&#19979;&#20013;&#24230;&#23548;&#25968;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#24207;&#21015;&#26680;&#36827;&#34892;&#22238;&#24402;&#26159;&#21487;&#33021;&#20986;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.14077</link><description>&lt;p&gt;
&#35686;&#24789;&#23574;&#23792;&#65306;&#22266;&#23450;&#32500;&#24230;&#19979;&#20869;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension. (arXiv:2305.14077v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14077
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22266;&#23450;&#32500;&#24230;&#19979;&#20869;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#21457;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#20851;&#38190;&#22312;&#20110;&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#24230;&#32780;&#19981;&#26159;&#32500;&#25968;&#65292;&#24182;&#35777;&#26126;&#22312;&#22266;&#23450;&#32500;&#24230;&#19979;&#20013;&#24230;&#23548;&#25968;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#24207;&#21015;&#26680;&#36827;&#34892;&#22238;&#24402;&#26159;&#21487;&#33021;&#20986;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36798;&#21040;&#25509;&#36817;&#38646;&#30340;&#35757;&#32451;&#35823;&#24046;&#30340;&#25104;&#21151;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#30340;&#26497;&#22823;&#20852;&#36259;&#65292;&#21363;&#20351;&#20272;&#35745;&#22120;&#25554;&#20540;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#23427;&#20204;&#36824;&#26159;&#20855;&#26377;&#32479;&#35745;&#19968;&#33268;&#24615;&#12290;&#23613;&#31649;&#26576;&#20123;&#23398;&#20064;&#26041;&#27861;&#30340;&#22266;&#23450;&#32500;&#24230;&#19979;&#24050;&#32463;&#30830;&#23450;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#20294;&#30446;&#21069;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;&#23545;&#20110;&#20856;&#22411;&#20869;&#26680;&#26041;&#27861;&#21644;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#22238;&#24402;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#38656;&#35201;&#39640;&#32500;&#24230;&#35774;&#32622;&#65292;&#20854;&#20013;&#32500;&#25968;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#24230;&#26159;&#20851;&#38190;&#65292;&#32780;&#19981;&#26159;&#32500;&#25968;&#65306;&#21482;&#26377;&#24403;&#20272;&#35745;&#22120;&#30340;&#23548;&#25968;&#36275;&#22815;&#22823;&#26102;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#25165;&#21487;&#33021;&#21457;&#29983;&#12290;&#25105;&#20204;&#23558;&#29616;&#26377;&#30340;&#19981;&#19968;&#33268;&#24615;&#32467;&#26524;&#25512;&#24191;&#21040;&#38750;&#25554;&#20540;&#27169;&#22411;&#21644;&#26356;&#22810;&#20869;&#26680;&#65292;&#20197;&#34920;&#26126;&#22312;&#22266;&#23450;&#32500;&#24230;&#19979;&#20013;&#24230;&#23548;&#25968;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#24207;&#21015;&#26680;&#36827;&#34892;&#22238;&#24402;&#26159;&#21487;&#33021;&#20986;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of over-parameterized neural networks trained to near-zero training error has caused great interest in the phenomenon of benign overfitting, where estimators are statistically consistent even though they interpolate noisy training data. While benign overfitting in fixed dimension has been established for some learning methods, current literature suggests that for regression with typical kernel methods and wide neural networks, benign overfitting requires a high-dimensional setting where the dimension grows with the sample size. In this paper, we show that the smoothness of the estimators, and not the dimension, is the key: benign overfitting is possible if and only if the estimator's derivatives are large enough. We generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension. Conversely, we show that benign overfitting is possible for regression with a seque
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.14076</link><description>&lt;p&gt;
&#20851;&#20110;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Dynamics of Gaussian--Stein Variational Gradient Descent. (arXiv:2305.14076v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD)&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#22522;&#20110;&#31890;&#23376;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#29702;&#35299;SVGD&#30340;&#29702;&#35770;&#23646;&#24615;&#19968;&#30452;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#21463;&#27492;&#20107;&#23454;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#21452;&#32447;&#24615;&#26680;&#23558;SVGD&#25237;&#24433;&#21040;&#39640;&#26031;&#20998;&#24067;&#26063;&#20013;&#65292;&#21363;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029; (GVI) &#19982; SVGD&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#22343;&#22330; PDE &#21644;&#31163;&#25955;&#31890;&#23376;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#22270;&#20687;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#24658;&#31561;&#24335;&#65292;&#35813;&#31561;&#24335;&#23558;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#19982;&#31890;&#23376;&#22343;&#21248;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#30456;&#20851;&#32852;&#12290;&#36825;&#20010;&#31561;&#24335;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#36879;&#35270; GVI with SVGD &#22312;&#22343;&#22330;&#21644;&#31890;&#23376;&#35774;&#32622;&#20013;&#30340;&#21160;&#24577;&#24615;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based deterministic sampling algorithm. Despite its wide usage, understanding the theoretical properties of SVGD has remained a challenging problem. For sampling from a Gaussian target, the SVGD dynamics with a bilinear kernel will remain Gaussian as long as the initializer is Gaussian. Inspired by this fact, we undertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD projected to the family of Gaussian distributions via the bilinear kernel, or equivalently Gaussian variational inference (GVI) with SVGD. We present a complete picture by considering both the mean-field PDE and discrete particle systems. When the target is strongly log-concave, the mean-field Gaussian-SVGD dynamics is proven to converge linearly to the Gaussian distribution closest to the target in KL divergence. In the finite-particle setting, there is both uniform in time convergence to the mean-field limit and linear convergence in ti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;DIVA&#31639;&#27861;&#65292;&#19968;&#20010;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#65292;&#24182;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#23454;&#29616;&#31751;&#30340;&#21160;&#24577;&#36866;&#24212;&#31227;&#21160;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2305.14067</link><description>&lt;p&gt;
DIVA&#65306;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm via Variational Auto-Encoder. (arXiv:2305.14067v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;DIVA&#31639;&#27861;&#65292;&#19968;&#20010;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#21033;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#65292;&#24182;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#23454;&#29616;&#31751;&#30340;&#21160;&#24577;&#36866;&#24212;&#31227;&#21160;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#35813;&#31639;&#27861;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#22312;&#20998;&#31867;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#22788;&#29702;&#21160;&#24577;&#21644;&#22797;&#26434;&#29305;&#24449;&#26041;&#38754;&#21463;&#21040;&#38480;&#21046;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20808;&#30693;&#36947;&#31751;&#30340;&#25968;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#65292;&#37319;&#29992;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#20316;&#20026;&#20808;&#39564;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21033;&#29992;&#19968;&#31181;&#35760;&#24518;&#21270;&#30340;&#22312;&#32447;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#31751;&#30340;&#8220;&#20986;&#29983;&#8221;&#21644;&#8220;&#21512;&#24182;&#8221;&#31227;&#21160;&#65292;&#20351;&#25105;&#20204;&#30340;&#26694;&#26550;&#33021;&#22815;&#20197;&#8220;&#21160;&#24577;&#36866;&#24212;&#8221;&#30340;&#26041;&#24335;&#32858;&#31867;&#25968;&#25454;&#65292;&#32780;&#19981;&#38656;&#35201;&#20808;&#30693;&#36947;&#29305;&#24449;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#25226;&#35813;&#26694;&#26550;&#21629;&#21517;&#20026;DIVA&#65292;&#21363;&#22522;&#20110;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#30340;&#22686;&#37327;&#28145;&#24230;&#32858;&#31867;&#26694;&#26550;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#20998;&#31867;&#20855;&#26377;&#21160;&#24577;&#21464;&#21270;&#29305;&#24449;&#30340;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20248;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#22686;&#37327;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#65292;&#36229;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative model-based deep clustering frameworks excel in classifying complex data, but are limited in handling dynamic and complex features because they require prior knowledge of the number of clusters. In this paper, we propose a nonparametric deep clustering framework that employs an infinite mixture of Gaussians as a prior. Our framework utilizes a memoized online variational inference method that enables the "birth" and "merge" moves of clusters, allowing our framework to cluster data in a "dynamic-adaptive" manner, without requiring prior knowledge of the number of features. We name the framework as DIVA, a Dirichlet Process-based Incremental deep clustering framework via Variational Auto-Encoder. Our framework, which outperforms state-of-the-art baselines, exhibits superior performance in classifying complex data with dynamically changing features, particularly in the case of incremental features.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#65292;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#26368;&#26032;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65307;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#36827;&#34892;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.13991</link><description>&lt;p&gt;
&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Expressive Losses for Verified Robustness via Convex Combinations. (arXiv:2305.13991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13991
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#65292;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#26368;&#26032;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65307;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#36827;&#34892;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#36890;&#36807;&#65288;&#25200;&#21160;&#21306;&#22495;&#30340;&#23376;&#38598;&#65289;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#38480;&#65292;&#25110;&#22312;&#23545;&#25239;&#35757;&#32451;&#20043;&#19978;&#24341;&#20837;&#21487;&#39564;&#35777;&#24615;&#26469;&#35757;&#32451;&#20855;&#26377;&#24050;&#39564;&#35777;&#40065;&#26834;&#24615;&#30340;&#32593;&#32476;&#12290;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20851;&#38190;&#22312;&#20110;&#25152;&#20351;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23427;&#24212;&#35813;&#33021;&#22815;&#21305;&#37197;&#35757;&#32451;&#21518;&#35201;&#20351;&#29992;&#30340;&#39564;&#35777;&#22120;&#30340;&#32039;&#23494;&#24230;&#12290;&#25105;&#20204;&#24418;&#24335;&#21270;&#23450;&#20041;&#20102;&#34920;&#36798;&#21147;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#26469;&#28385;&#36275;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;CC-IBP&#21644;MTL-IBP&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#22343;&#21487;&#20197;&#20135;&#29983;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#23613;&#31649;&#20854;&#27010;&#24565;&#19978;&#26159;&#31616;&#21333;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;TinyImageNet&#21644;&#32553;&#23567;&#30340;ImageNet&#19978;&#65292;&#23545;&#20110;&#21322;&#24452;&#20026;$ \frac{1} {255} $&#30340;$ \ell_ \infty $&#25200;&#21160;&#65292;MTL-IBP&#21487;&#20197;&#23558;&#25991;&#29486;&#20013;&#26368;&#20339;&#26631;&#20934;&#21644;&#39564;&#35777;&#20934;&#30830;&#24615;&#20174;$1.98\%$&#25552;&#39640;&#21040;$3.92\%$&#65292;&#21516;&#26102;&#20165;&#20381;&#36182;&#20110;&#21333;&#27493;&#33258;&#36866;&#24212;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\ell_\infty$ perturbations of radius $\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\%$ to $3.92\%$ points while only relying on single-step ad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#30340;&#31532;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#19978;&#30028;&#65292;&#31639;&#27861;&#26174;&#31034;&#20122;&#32447;&#24615;&#36951;&#25022;&#29575;&#65292;&#24182;&#22312;&#25968;&#25454;&#8220;&#23481;&#26131;&#8221;&#26102;&#23454;&#29616;&#23545;&#25968;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2305.13946</link><description>&lt;p&gt;
&#26080;&#38656;Lipschitzness&#21644;Smoothness&#30340;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#30340;&#25968;&#25454;&#30456;&#20851;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
Data-Dependent Bounds for Online Portfolio Selection Without Lipschitzness and Smoothness. (arXiv:2305.13946v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#30340;&#31532;&#19968;&#20010;&#25968;&#25454;&#30456;&#20851;&#19978;&#30028;&#65292;&#31639;&#27861;&#26174;&#31034;&#20122;&#32447;&#24615;&#36951;&#25022;&#29575;&#65292;&#24182;&#22312;&#25968;&#25454;&#8220;&#23481;&#26131;&#8221;&#26102;&#23454;&#29616;&#23545;&#25968;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#20013;&#30340;&#31532;&#19968;&#31181;&#23567;&#25439;&#22833;&#21644;&#24179;&#31283;&#21464;&#21270;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#26631;&#24535;&#30528;&#22312;&#32447;&#20984;&#20248;&#21270;&#20855;&#26377;&#38750;Lipschitz&#12289;&#38750;&#20809;&#28369;&#25439;&#22833;&#30340;&#25968;&#25454;&#30456;&#20851;&#19978;&#30028;&#30340;&#39318;&#27425;&#23454;&#20363;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#26174;&#31034;&#20986;&#20122;&#32447;&#24615;&#36951;&#25022;&#29575;&#65292;&#24182;&#22312;&#25968;&#25454;&#8220;&#23481;&#26131;&#8221;&#26102;&#23454;&#29616;&#23545;&#25968;&#36951;&#25022;&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#26102;&#38388;&#20960;&#20046;&#26159;&#25237;&#36164;&#36873;&#25321;&#25968;&#37327;&#30340;&#32447;&#24615;&#12290;&#36951;&#25022;&#19978;&#30028;&#26159;&#20351;&#29992;&#23545;&#25968;&#25439;&#22833;&#30340;&#26032;&#22411;&#20809;&#28369;&#24615;&#34920;&#24449;&#12289;&#36981;&#24490;&#20855;&#26377;&#33258;&#20849;&#36717;&#27491;&#21017;&#21270;&#22120;&#30340;&#27491;&#21017;&#21270;&#39046;&#34966;&#65288;FTRL&#65289;&#30340;&#23616;&#37096;&#33539;&#25968;&#20998;&#26512;&#12289;&#23427;&#20204;&#19981;&#19968;&#23450;&#26159;&#38556;&#30861;&#30340;&#21644;&#20855;&#26377;log&#38556;&#30861;&#30340;&#20048;&#35266;FTRL&#30340;&#38544;&#24335;&#21464;&#20307;&#26469;&#25512;&#23548;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces the first small-loss and gradual-variation regret bounds for online portfolio selection, marking the first instances of data-dependent bounds for online convex optimization with non-Lipschitz, non-smooth losses. The algorithms we propose exhibit sublinear regret rates in the worst cases and achieve logarithmic regrets when the data is "easy," with per-iteration time almost linear in the number of investment alternatives. The regret bounds are derived using novel smoothness characterizations of the logarithmic loss, a local norm-based analysis of following the regularized leader (FTRL) with self-concordant regularizers, which are not necessarily barriers, and an implicit variant of optimistic FTRL with the log-barrier.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20998;&#26512;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#22312;&#22823;&#22411;&#25968;&#25454;&#29615;&#22659;&#19979;&#20351;&#29992;&#23376;&#37319;&#26679;&#20135;&#29983;&#30340;&#35823;&#24046;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#35813;&#36807;&#31243;&#20999;&#25442;&#25968;&#25454;&#23376;&#38598;&#24182;&#21487;&#29992;&#20110;&#25193;&#25955;&#23376;&#37319;&#26679; MCMC &#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.13882</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#25193;&#25955;&#20013;&#30340;&#23376;&#37319;&#26679;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Subsampling Error in Stochastic Gradient Langevin Diffusions. (arXiv:2305.13882v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13882
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20998;&#26512;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#22312;&#22823;&#22411;&#25968;&#25454;&#29615;&#22659;&#19979;&#20351;&#29992;&#23376;&#37319;&#26679;&#20135;&#29983;&#30340;&#35823;&#24046;&#12290;&#30740;&#31350;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#35813;&#36807;&#31243;&#20999;&#25442;&#25968;&#25454;&#23376;&#38598;&#24182;&#21487;&#29992;&#20110;&#25193;&#25955;&#23376;&#37319;&#26679; MCMC &#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398; (SGLD) &#36890;&#24120;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#32479;&#35745;&#23398;&#20064;&#20013;&#36817;&#20284;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#12290;&#19982;&#35768;&#22810;&#24120;&#35268;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599; (MCMC) &#31639;&#27861;&#19981;&#21516;&#65292;SGLD &#23545;&#20110;&#21518;&#39564;&#20998;&#24067;&#19981;&#26159;&#31283;&#23450;&#30340;&#12290;&#23427;&#26377;&#20004;&#20010;&#38169;&#35823;&#26469;&#28304;&#65306;&#31532;&#19968;&#20010;&#38169;&#35823;&#26159;&#30001; Euler-Maruyama &#31163;&#25955;&#21270; Langevin &#25193;&#25955;&#36807;&#31243;&#24341;&#20837;&#30340;&#65292;&#31532;&#20108;&#20010;&#38169;&#35823;&#26469;&#33258;&#20110;&#25968;&#25454;&#23376;&#37319;&#26679;&#65292;&#36825;&#20351;&#24471;&#23427;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102; SGLD &#30340;&#29702;&#24819;&#21270;&#29256;&#26412;&#65292;&#20197;&#20998;&#26512;&#35813;&#26041;&#27861;&#30340;&#32431;&#23376;&#37319;&#26679;&#35823;&#24046;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#20854;&#35270;&#20026;&#22522;&#20110;&#25193;&#25955;&#30340;&#23376;&#37319;&#26679; MCMC &#26041;&#27861;&#30340;&#26368;&#20339;&#24773;&#20917;&#35823;&#24046;&#12290;&#20107;&#23454;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#24182;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#25193;&#25955; (SGLDiff)&#65292;&#36825;&#26159;&#19968;&#20010;&#36830;&#32493;&#26102;&#38388;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#23427;&#36981;&#24490;&#19982;&#25968;&#25454;&#23376;&#38598;&#30456;&#24212;&#30340; Langevin &#25193;&#25955;&#65292;&#24182;&#22312;&#25351;&#25968;&#31561;&#24453;&#26102;&#38388;&#21518;&#20999;&#25442;&#35813;&#25968;&#25454;&#23376;&#38598;&#12290;&#22312;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163; (Was)
&lt;/p&gt;
&lt;p&gt;
The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to approximate Bayesian posterior distributions in statistical learning procedures with large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC) algorithms, SGLD is not stationary with respect to the posterior distribution; two sources of error appear: The first error is introduced by an Euler--Maruyama discretisation of a Langevin diffusion process, the second error comes from the data subsampling that enables its use in large-scale data settings. In this work, we consider an idealised version of SGLD to analyse the method's pure subsampling error that we then see as a best-case error for diffusion-based subsampling MCMC methods. Indeed, we introduce and study the Stochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov process that follows the Langevin diffusion corresponding to a data subset and switches this data subset after exponential waiting times. There, we show that the Was
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24037;&#31243;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#65292;&#20351;&#29992;&#38543;&#26426;PDE&#34920;&#31034;&#26469;&#24320;&#21457;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#20174;&#32780;&#21487;&#20197;&#22312;&#20960;&#20309;&#22797;&#26434;&#30340;&#22495;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#12290;</title><link>http://arxiv.org/abs/2305.13879</link><description>&lt;p&gt;
&#38024;&#23545;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#21644;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#30340;&#38543;&#26426;PDE&#34920;&#31034;&#38543;&#26426;&#22330;
&lt;/p&gt;
&lt;p&gt;
Stochastic PDE representation of random fields for large-scale Gaussian process regression and statistical finite element analysis. (arXiv:2305.13879v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24037;&#31243;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#65292;&#20351;&#29992;&#38543;&#26426;PDE&#34920;&#31034;&#26469;&#24320;&#21457;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#20174;&#32780;&#21487;&#20197;&#22312;&#20960;&#20309;&#22797;&#26434;&#30340;&#22495;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24037;&#31243;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#24314;&#27169;&#20013;&#65292;&#26377;&#25928;&#34920;&#31034;&#20960;&#20309;&#22797;&#26434;&#22495;&#19978;&#30340;&#38543;&#26426;&#22330;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#26222;&#36941;&#20351;&#29992;&#30340;&#38543;&#26426;&#22330;&#34920;&#31034;&#20165;&#38480;&#20110;&#26080;&#30028;&#22495;&#25110;&#22312;&#21487;&#33021;&#30340;&#22330;&#23646;&#24615;&#26041;&#38754;&#36807;&#20110;&#21463;&#38480;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#38543;&#26426;PDE&#19982;&#38543;&#26426;&#22330;&#20043;&#38388;&#30340;&#21382;&#21490;&#32852;&#31995;&#30340;&#26032;&#25216;&#26415;&#23545;&#20110;&#20855;&#26377;&#22797;&#26434;&#20960;&#20309;&#24418;&#29366;&#21644;&#23384;&#22312;&#26377;&#38480;&#20803;&#31163;&#25955;&#21270;&#29992;&#20110;&#27714;&#35299;&#29289;&#29702;&#23432;&#24658;&#26041;&#31243;&#30340;&#24037;&#31243;&#24212;&#29992;&#23588;&#20026;&#21560;&#24341;&#20154;&#12290;&#19982;&#38543;&#26426;&#22330;&#30340;&#23494;&#38598;&#21327;&#26041;&#24046;&#30697;&#38453;&#19981;&#21516;&#65292;&#20854;&#36870;&#30697;&#38453;--&#31934;&#24230;&#30697;&#38453;&#36890;&#24120;&#26159;&#31232;&#30095;&#30340;&#65292;&#24182;&#31561;&#20110;&#31867;&#20284;Helmholtz&#30340;&#38543;&#26426;PDE&#30340;&#21018;&#24230;&#30697;&#38453;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;SPDE&#34920;&#31034;&#26469;&#24320;&#21457;&#21487;&#25193;&#23637;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20960;&#20309;&#22797;&#26434;&#22495;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30340;&#32479;&#35745;&#26377;&#38480;&#20803;&#20998;&#26512;&#65288;StatFEM&#65289;&#21644;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#12290;&#25105;&#20204;&#20351;&#29992;SPDE&#20844;&#24335;
&lt;/p&gt;
&lt;p&gt;
The efficient representation of random fields on geometrically complex domains is crucial for Bayesian modelling in engineering and machine learning. Today's prevalent random field representations are restricted to unbounded domains or are too restrictive in terms of possible field properties. As a result, new techniques leveraging the historically established link between stochastic PDEs (SPDEs) and random fields are especially appealing for engineering applications with complex geometries which already have a finite element discretisation for solving the physical conservation equations. Unlike the dense covariance matrix of a random field, its inverse, the precision matrix, is usually sparse and equal to the stiffness matrix of a Helmholtz-like SPDE. In this paper, we use the SPDE representation to develop a scalable framework for large-scale statistical finite element analysis (statFEM) and Gaussian process (GP) regression on geometrically complex domains. We use the SPDE formulatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#30340;&#38382;&#39064;&#26159;&#22312;&#25308;&#21344;&#24237;&#23481;&#38169;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#24403;&#26799;&#24230;&#35745;&#31639;&#24635;&#25968;&#22266;&#23450;&#26102;&#65292;&#26368;&#20339;&#30340;&#25209;&#22788;&#29702;&#22823;&#23567;&#38543;&#25308;&#21344;&#24237;&#24037;&#20154;&#30340;&#27604;&#20363;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2305.13856</link><description>&lt;p&gt;
&#35770;&#25308;&#21344;&#24237;&#23481;&#38169;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#26368;&#20339;&#25209;&#22788;&#29702;&#22823;&#23567;
&lt;/p&gt;
&lt;p&gt;
On the Optimal Batch Size for Byzantine-Robust Distributed Learning. (arXiv:2305.13856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#30340;&#38382;&#39064;&#26159;&#22312;&#25308;&#21344;&#24237;&#23481;&#38169;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#65292;&#24403;&#26799;&#24230;&#35745;&#31639;&#24635;&#25968;&#22266;&#23450;&#26102;&#65292;&#26368;&#20339;&#30340;&#25209;&#22788;&#29702;&#22823;&#23567;&#38543;&#25308;&#21344;&#24237;&#24037;&#20154;&#30340;&#27604;&#20363;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#30001;&#20110;&#24847;&#22806;&#22833;&#35823;&#25110;&#24694;&#24847;&#25915;&#20987;&#23548;&#33268;&#35745;&#31639;&#35774;&#22791;&#24322;&#24120;&#34892;&#20026;&#30340;&#25308;&#21344;&#24237;&#23481;&#38169;&#20998;&#24067;&#24335;&#23398;&#20064;&#65288;BRDL&#65289;&#24050;&#25104;&#20026;&#28909;&#38376;&#30740;&#31350;&#35838;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#30001;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#22823;&#26041;&#24046;&#65292;&#29616;&#26377;&#30340;BRDL&#26041;&#27861;&#20173;&#20250;&#23548;&#33268;&#27169;&#22411;&#20934;&#30830;&#29575;&#26174;&#33879;&#19979;&#38477;&#12290;&#22686;&#21152;&#25209;&#22788;&#29702;&#22823;&#23567;&#26159;&#20943;&#23569;&#26041;&#24046;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#26799;&#24230;&#35745;&#31639;&#24635;&#25968;&#22266;&#23450;&#26102;&#65292;&#36807;&#22823;&#30340;&#25209;&#22788;&#29702;&#22823;&#23567;&#20250;&#23548;&#33268;&#36845;&#20195;&#27425;&#25968;&#36807;&#23569;&#65288;&#26356;&#26032;&#27425;&#25968;&#65289;&#65292;&#21487;&#33021;&#20063;&#20250;&#38477;&#20302;&#27169;&#22411;&#20934;&#30830;&#29575;&#12290;&#38024;&#23545;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22312;&#22266;&#23450;&#26799;&#24230;&#35745;&#31639;&#24635;&#25968;&#30340;&#24773;&#20917;&#19979;&#26368;&#20339;&#30340;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#21644;&#32463;&#39564;&#19978;&#34920;&#26126;&#65292;&#24403;&#26799;&#24230;&#35745;&#31639;&#24635;&#25968;&#22266;&#23450;&#26102;&#65292;BRDL&#20013;&#26368;&#20339;&#30340;&#25209;&#22788;&#29702;&#22823;&#23567;&#38543;&#25308;&#21344;&#24237;&#24037;&#20154;&#30340;&#27604;&#20363;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Byzantine-robust distributed learning (BRDL), in which computing devices are likely to behave abnormally due to accidental failures or malicious attacks, has recently become a hot research topic. However, even in the independent and identically distributed (i.i.d.) case, existing BRDL methods will suffer from a significant drop on model accuracy due to the large variance of stochastic gradients. Increasing batch sizes is a simple yet effective way to reduce the variance. However, when the total number of gradient computation is fixed, a too-large batch size will lead to a too-small iteration number (update number), which may also degrade the model accuracy. In view of this challenge, we mainly study the optimal batch size when the total number of gradient computation is fixed in this work. In particular, we theoretically and empirically show that when the total number of gradient computation is fixed, the optimal batch size in BRDL increases with the fraction of Byzantine workers. Ther
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31215;&#20998;&#27010;&#29575;&#27979;&#37327;&#36827;&#34892;&#21327;&#21464;&#37327;&#24179;&#34913;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#26080;&#38656;&#27491;&#30830;&#35268;&#23450;&#20542;&#21521;&#24471;&#20998;&#25110;&#32467;&#26524;&#22238;&#24402;&#27169;&#22411;&#21363;&#21487;&#20445;&#35777;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.13715</link><description>&lt;p&gt;
&#21033;&#29992;&#31215;&#20998;&#27010;&#29575;&#27979;&#37327;&#36827;&#34892;&#21327;&#21464;&#37327;&#24179;&#34913;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Covariate balancing using the integral probability metric for causal inference. (arXiv:2305.13715v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#31215;&#20998;&#27010;&#29575;&#27979;&#37327;&#36827;&#34892;&#21327;&#21464;&#37327;&#24179;&#34913;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#26080;&#38656;&#27491;&#30830;&#35268;&#23450;&#20542;&#21521;&#24471;&#20998;&#25110;&#32467;&#26524;&#22238;&#24402;&#27169;&#22411;&#21363;&#21487;&#20445;&#35777;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#20248;&#24322;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#21152;&#26435;&#26041;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#23454;&#29616;&#20196;&#20154;&#28385;&#24847;&#30340;&#21327;&#21464;&#37327;&#24179;&#34913;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#21152;&#26435;&#26041;&#27861;&#21482;&#26377;&#22312;&#26576;&#31181;&#27169;&#22411;&#65288;&#22914;&#20542;&#21521;&#24471;&#20998;&#25110;&#32467;&#26524;&#22238;&#24402;&#27169;&#22411;&#65289;&#34987;&#27491;&#30830;&#35268;&#23450;&#26102;&#25165;&#20855;&#26377;&#29702;&#24819;&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#24182;&#19988;&#21363;&#20351;&#27169;&#22411;&#34987;&#27491;&#30830;&#35268;&#23450;&#65292;&#30456;&#24212;&#30340;&#20272;&#35745;&#22120;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#20063;&#19981;&#34920;&#29616;&#33391;&#22909;&#12290;&#26412;&#25991;&#32771;&#34385;&#21033;&#29992;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;&#65288;IPM&#65289;&#36827;&#34892;&#21327;&#21464;&#37327;&#24179;&#34913;&#12290;&#30830;&#23450;&#26368;&#20339;&#26435;&#37325;&#65292;&#20351;&#24471;&#38024;&#23545;&#32473;&#23450;&#30340;&#21028;&#21035;&#22120;&#65292;&#27835;&#30103;&#32452;&#21644;&#23545;&#29031;&#32452;&#30340;&#21152;&#26435;&#32463;&#39564;&#20998;&#24067;&#20855;&#26377;&#26368;&#23567;&#30340;IPM&#20540;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#24212;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#26159;&#19968;&#33268;&#30340;&#65292;&#32780;&#19981;&#38656;&#35201;&#27491;&#30830;&#22320;&#35268;&#23450;&#20219;&#20309;&#27169;&#22411;&#65288;&#26082;&#19981;&#26159;&#20542;&#21521;&#24471;&#20998;&#27169;&#22411;&#20063;&#19981;&#26159;&#32467;&#26524;&#22238;&#24402;&#27169;&#22411;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#24050;&#26377;&#30340;&#21152;&#26435;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Weighting methods in causal inference have been widely used to achieve a desirable level of covariate balancing. However, the existing weighting methods have desirable theoretical properties only when a certain model, either the propensity score or outcome regression model, is correctly specified. In addition, the corresponding estimators do not behave well for finite samples due to large variance even when the model is correctly specified. In this paper, we consider to use the integral probability metric (IPM), which is a metric between two probability measures, for covariate balancing. Optimal weights are determined so that weighted empirical distributions for the treated and control groups have the smallest IPM value for a given set of discriminators. We prove that the corresponding estimator can be consistent without correctly specifying any model (neither the propensity score nor the outcome regression model). In addition, we empirically show that our proposed method outperforms e
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65306;&#28145;&#24230;RKHM&#65292;&#36890;&#36807;&#20351;&#29992;$C^*$&#20195;&#25968;&#33719;&#24471;&#26356;&#28201;&#21644;&#30340;&#30028;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.13588</link><description>&lt;p&gt;
&#36890;&#36807;RKHM&#21644;Perron-Frobenius&#31639;&#23376;&#30340;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Learning with Kernels through RKHM and the Perron-Frobenius Operator. (arXiv:2305.13588v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13588
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65306;&#28145;&#24230;RKHM&#65292;&#36890;&#36807;&#20351;&#29992;$C^*$&#20195;&#25968;&#33719;&#24471;&#26356;&#28201;&#21644;&#30340;&#30028;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;$C^*$-&#27169;(RKHM)&#36890;&#36807;$C^*$&#20195;&#25968;&#23545;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#36827;&#34892;&#20102;&#27867;&#21270;&#65292;&#32780;Perron-Frobenius&#31639;&#23376;&#26159;&#19982;&#20989;&#25968;&#32452;&#21512;&#30456;&#20851;&#30340;&#32447;&#24615;&#31639;&#23376;&#12290;&#23558;&#36825;&#20004;&#20010;&#27010;&#24565;&#32467;&#21512;&#36215;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#28145;&#24230;RKHM&#65292;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#25512;&#23548;&#20102;&#19968;&#20010;&#26032;&#30340;Rademacher&#24191;&#20041;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;Perron-Frobenius&#31639;&#23376;&#25552;&#20379;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#30001;&#20110;$C^*$&#20195;&#25968;&#30340;&#20248;&#21183;&#65292;&#35813;&#30028;&#38480;&#23545;&#36755;&#20986;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#36739;&#29616;&#26377;&#30028;&#38480;&#26356;&#21152;&#28201;&#21644;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;$C^*$&#20195;&#25968;&#26159;&#28145;&#24230;&#23398;&#20064;&#30340;&#26680;&#24515;&#24037;&#20855;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#31639;&#23376;&#30340;&#20056;&#31215;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#19982;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26126;&#30830;&#32852;&#31995;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#28145;&#24230;&#26680;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reproducing kernel Hilbert $C^*$-module (RKHM) is a generalization of reproducing kernel Hilbert space (RKHS) by means of $C^*$-algebra, and the Perron-Frobenius operator is a linear operator related to the composition of functions. Combining these two concepts, we present deep RKHM, a deep learning framework for kernel methods. We derive a new Rademacher generalization bound in this setting and provide a theoretical interpretation of benign overfitting by means of Perron-Frobenius operators. By virtue of $C^*$-algebra, the dependency of the bound on output dimension is milder than existing bounds. We show that $C^*$-algebra is a suitable tool for deep learning with kernels, enabling us to take advantage of the product structure of operators and to provide a clear connection with convolutional neural networks. Our theoretical analysis provides a new lens through which one can design and analyze deep kernel methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#31867;&#8212;&#8212;&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65292;&#20854;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;2&#33539;&#25968;&#36827;&#34892;&#24179;&#26041;&#21644;&#22522;&#20110;&#26576;&#20010;&#22522;&#30784;&#24230;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#20005;&#26684;&#25512;&#24191;&#20102;&#32463;&#20856;&#25351;&#25968;&#26063;&#65292;&#20855;&#26377;&#38381;&#24615;&#26465;&#20214;&#25512;&#26029;&#21644;&#21487;&#35745;&#31639;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.13552</link><description>&lt;p&gt;
&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65306;&#19968;&#31181;&#26032;&#30340;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#31867;
&lt;/p&gt;
&lt;p&gt;
Squared Neural Families: A New Class of Tractable Density Models. (arXiv:2305.13552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13552
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#31867;&#8212;&#8212;&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65292;&#20854;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;2&#33539;&#25968;&#36827;&#34892;&#24179;&#26041;&#21644;&#22522;&#20110;&#26576;&#20010;&#22522;&#30784;&#24230;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#20005;&#26684;&#25512;&#24191;&#20102;&#32463;&#20856;&#25351;&#25968;&#26063;&#65292;&#20855;&#26377;&#38381;&#24615;&#26465;&#20214;&#25512;&#26029;&#21644;&#21487;&#35745;&#31639;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#20998;&#24067;&#30340;&#28789;&#27963;&#27169;&#22411;&#26159;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#24320;&#21457;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#20998;&#24067;&#31867;&#21035;&#65292;&#31216;&#20026;&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65288;SNEFY&#65289;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;2&#33539;&#25968;&#36827;&#34892;&#24179;&#26041;&#24182;&#22522;&#20110;&#26576;&#20010;&#22522;&#30784;&#24230;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#12290;&#31867;&#20284;&#20110;&#26080;&#31351;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#24191;&#27867;&#32852;&#31995;&#30340;&#25512;&#29702;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#24773;&#20917;&#19979;&#65292;SNEFY&#20855;&#26377;&#23553;&#38381;&#24418;&#24335;&#30340;&#26631;&#20934;&#21270;&#24120;&#25968;&#65292;&#22240;&#27492;&#26159;&#28789;&#27963;&#19988;&#23436;&#20840;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#12290;SNEFY&#20005;&#26684;&#25512;&#24191;&#20102;&#32463;&#20856;&#30340;&#25351;&#25968;&#26063;&#65292;&#23545;&#20110;&#26465;&#20214;&#25512;&#26029;&#20855;&#26377;&#38381;&#24615;&#65292;&#24182;&#19988;&#20855;&#26377;&#21487;&#35745;&#31639;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#23494;&#24230;&#20272;&#35745;&#21644;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#20219;&#21153;&#20013;&#23637;&#31034;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Flexible models for probability distributions are an essential ingredient in many machine learning tasks. We develop and investigate a new class of probability distributions, which we call a Squared Neural Family (SNEFY), formed by squaring the 2-norm of a neural network and normalising it with respect to a base measure. Following the reasoning similar to the well established connections between infinitely wide neural networks and Gaussian processes, we show that SNEFYs admit a closed form normalising constants in many cases of interest, thereby resulting in flexible yet fully tractable density models. SNEFYs strictly generalise classical exponential families, are closed under conditioning, and have tractable marginal distributions. Their utility is illustrated on a variety of density estimation and conditional density estimation tasks. Software available at https://github.com/RussellTsuchida/snefy.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#32676;&#19981;&#21464;GAN&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32676;&#19981;&#21464;&#20998;&#24067;&#26102;&#65292;&#32676;&#19981;&#21464;GAN&#25152;&#38656;&#26679;&#26412;&#25968;&#20250;&#25353;&#32676;&#20307;&#22823;&#23567;&#30340;&#24130;&#27604;&#20363;&#20943;&#23569;&#12290;</title><link>http://arxiv.org/abs/2305.13517</link><description>&lt;p&gt;
Group-Invariant GAN&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Guarantees of Group-Invariant GANs. (arXiv:2305.13517v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13517
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#32676;&#19981;&#21464;GAN&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32676;&#19981;&#21464;&#20998;&#24067;&#26102;&#65292;&#32676;&#19981;&#21464;GAN&#25152;&#38656;&#26679;&#26412;&#25968;&#20250;&#25353;&#32676;&#20307;&#22823;&#23567;&#30340;&#24130;&#27604;&#20363;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Group-Invariant&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(GAN)&#26159;&#19968;&#31181;GAN&#65292;&#20854;&#20013;&#29983;&#25104;&#22120;&#21644;&#21028;&#21035;&#22120;&#20855;&#26377;&#30828;&#24615;&#38598;&#22242;&#23545;&#31216;&#24615;&#12290;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#26174;&#30528;&#25913;&#36827;&#25968;&#25454;&#25928;&#29575;&#30340;&#38598;&#22242;&#19981;&#21464;&#20998;&#24067;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#32676;&#19981;&#21464;GAN&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20943;&#23569;&#26469;&#20005;&#26684;&#37327;&#21270;&#36825;&#31181;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#23398;&#20064;&#32676;&#19981;&#21464;&#20998;&#24067;&#26102;&#65292;&#32676;&#19981;&#21464;GAN&#25152;&#38656;&#26679;&#26412;&#25968;&#25353;&#29031;&#32676;&#20307;&#22823;&#23567;&#30340;&#24130;&#27604;&#20363;&#20943;&#23569;&#65292;&#36825;&#20010;&#24130;&#21462;&#20915;&#20110;&#20998;&#24067;&#25903;&#25345;&#30340;&#26412;&#36136;&#32500;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#26159;&#39318;&#20010;&#20026;&#32676;&#19981;&#21464;&#29983;&#25104;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;GAN&#25552;&#20379;&#32479;&#35745;&#20272;&#35745;&#30340;&#24037;&#20316;&#65292;&#24182;&#21487;&#20197;&#20026;&#20854;&#20182;&#32676;&#19981;&#21464;&#29983;&#25104;&#27169;&#22411;&#30340;&#30740;&#31350;&#25552;&#20379;&#20511;&#37492;&#12290;
&lt;/p&gt;
&lt;p&gt;
Group-invariant generative adversarial networks (GANs) are a type of GANs in which the generators and discriminators are hardwired with group symmetries. Empirical studies have shown that these networks are capable of learning group-invariant distributions with significantly improved data efficiency. In this study, we aim to rigorously quantify this improvement by analyzing the reduction in sample complexity for group-invariant GANs. Our findings indicate that when learning group-invariant distributions, the number of samples required for group-invariant GANs decreases proportionally with a power of the group size, and this power depends on the intrinsic dimension of the distribution's support. To our knowledge, this work presents the first statistical estimation for group-invariant generative models, specifically for GANs, and it may shed light on the study of other group-invariant generative models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#27979;&#37327;&#22122;&#22768;&#30340;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#21644;&#26041;&#27861;&#33021;&#22815;&#20998;&#31163;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#25913;&#21892;&#25968;&#25454;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.13498</link><description>&lt;p&gt;
&#29992;&#20110;&#24102;&#27979;&#37327;&#22122;&#22768;&#30340;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Parameter estimation from an Ornstein-Uhlenbeck process with measurement noise. (arXiv:2305.13498v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#27979;&#37327;&#22122;&#22768;&#30340;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#20272;&#35745;&#65292;&#25552;&#20986;&#20102;&#31639;&#27861;&#21644;&#26041;&#27861;&#33021;&#22815;&#20998;&#31163;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#25913;&#21892;&#25968;&#25454;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#22122;&#22768;&#23545;Ornstein-Uhlenbeck&#36807;&#31243;&#21442;&#25968;&#25311;&#21512;&#30340;&#24433;&#21709;&#65292;&#37325;&#28857;&#32771;&#23519;&#20102;&#20056;&#24615;&#22122;&#22768;&#21644;&#28909;&#22122;&#22768;&#23545;&#20449;&#21495;&#20998;&#31163;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26377;&#25928;&#21306;&#20998;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#12289;&#25913;&#21892;&#21442;&#25968;&#20272;&#35745;&#31934;&#24230;&#30340;&#31639;&#27861;&#21644;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#20056;&#24615;&#21644;&#28909;&#22122;&#22768;&#23545;&#23454;&#38469;&#20449;&#21495;&#28151;&#28102;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#20998;&#31163;&#28909;&#22122;&#22768;&#30340;&#31639;&#27861;&#65292;&#20854;&#24615;&#33021;&#21487;&#19982;Hamilton Monte Carlo (HMC)&#30456;&#23218;&#32654;&#65292;&#20294;&#36895;&#24230;&#26174;&#33879;&#25552;&#39640;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20056;&#24615;&#22122;&#22768;&#65292;&#24182;&#35777;&#26126;&#20102;HMC&#26080;&#27861;&#38548;&#31163;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22312;&#39069;&#22806;&#20102;&#35299;&#28909;&#22122;&#22768;&#21644;&#20056;&#24615;&#22122;&#22768;&#20043;&#38388;&#27604;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#31934;&#30830;&#22320;&#20272;&#35745;&#21442;&#25968;&#21644;&#20998;&#31163;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article aims to investigate the impact of noise on parameter fitting for an Ornstein-Uhlenbeck process, focusing on the effects of multiplicative and thermal noise on the accuracy of signal separation. To address these issues, we propose algorithms and methods that can effectively distinguish between thermal and multiplicative noise and improve the precision of parameter estimation for optimal data analysis. Specifically, we explore the impact of both multiplicative and thermal noise on the obfuscation of the actual signal and propose methods to resolve them. Firstly, we present an algorithm that can effectively separate thermal noise with comparable performance to Hamilton Monte Carlo (HMC) but with significantly improved speed. Subsequently, we analyze multiplicative noise and demonstrate that HMC is insufficient for isolating thermal and multiplicative noise. However, we show that, with additional knowledge of the ratio between thermal and multiplicative noise, we can accuratel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38041;&#25104;&#20687;&#20013;&#30340;&#22270;&#25340;&#25509;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#38750;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.13491</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#39640;&#26031;&#22270;&#25340;&#25509;&#21450;&#20854;&#22312;&#38041;&#25104;&#20687;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Nonparanormal Graph Quilting with Applications to Calcium Imaging. (arXiv:2305.13491v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13491
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38041;&#25104;&#20687;&#20013;&#30340;&#22270;&#25340;&#25509;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#38750;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#22270;&#27169;&#22411;&#24050;&#25104;&#20026;&#19968;&#31181;&#37325;&#35201;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#24037;&#20855;&#65292;&#29992;&#20110;&#26816;&#27979;&#21508;&#31181;&#38382;&#39064;&#30340;&#32593;&#32476;&#32467;&#26500;&#65292;&#21253;&#25324;&#20174;&#21452;&#20809;&#23376;&#38041;&#25104;&#20687;&#25968;&#25454;&#20013;&#20272;&#35745;&#21151;&#33021;&#31070;&#32463;&#20803;&#36830;&#25509;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#38041;&#25104;&#20687;&#30340;&#24773;&#20917;&#19979;&#65292;&#25216;&#26415;&#38480;&#21046;&#21482;&#20801;&#35768;&#35760;&#24405;&#24863;&#20852;&#36259;&#21306;&#22495;&#20013;&#37096;&#20998;&#37325;&#21472;&#30340;&#31070;&#32463;&#20803;&#23618;&#20849;&#21516;&#35760;&#24405;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#23436;&#25972;&#25968;&#25454;&#30340;&#22270;&#24418;&#20272;&#35745;&#38656;&#35201;&#38024;&#23545;&#36793;&#32536;&#36873;&#25321;&#36827;&#34892;&#25512;&#26029;&#65292;&#24403;&#35768;&#22810;&#31070;&#32463;&#20803;&#23545;&#27809;&#26377;&#21516;&#26102;&#35266;&#23519;&#21040;&#26102;&#65292;&#36825;&#23601;&#23548;&#33268;&#20102;&#22270;&#25340;&#25509;&#38382;&#39064;&#65292;&#22312;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#23384;&#22312;&#22359;&#29366;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#22270;&#24418;&#12290;&#20197;&#21069;&#24050;&#32463;&#30740;&#31350;&#20102;&#39640;&#26031;&#22270;&#24418;&#27169;&#22411;&#30340;&#22270;&#25340;&#25509;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65307;&#28982;&#32780;&#65292;&#26469;&#33258;&#38041;&#25104;&#20687;&#30340;&#31070;&#32463;&#27963;&#21160;&#25968;&#25454;&#36890;&#24120;&#26159;&#38750;&#39640;&#26031;&#30340;&#65292;&#22240;&#27492;&#38656;&#35201;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#24314;&#27169;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#21442;&#25968;&#38750;&#39640;&#26031;&#22270;&#38025;&#21512;&#26041;&#27861;&#65292;&#20801;&#35768;&#22312;&#32570;&#23569;&#22359;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#24213;&#23618;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#30340;&#38041;&#25104;&#20687;&#25968;&#25454;&#19978;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic graphical models have become an important unsupervised learning tool for detecting network structures for a variety of problems, including the estimation of functional neuronal connectivity from two-photon calcium imaging data. However, in the context of calcium imaging, technological limitations only allow for partially overlapping layers of neurons in a brain region of interest to be jointly recorded. In this case, graph estimation for the full data requires inference for edge selection when many pairs of neurons have no simultaneous observations. This leads to the Graph Quilting problem, which seeks to estimate a graph in the presence of block-missingness in the empirical covariance matrix. Solutions for the Graph Quilting problem have previously been studied for Gaussian graphical models; however, neural activity data from calcium imaging are often non-Gaussian, thereby requiring a more flexible modeling approach. Thus, in our work, we study two approaches for nonpara
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21487;&#20197;&#39537;&#20351;&#27169;&#22411;&#20248;&#21270;&#21152;&#26435;&#20998;&#31867;&#24230;&#37327;&#26631;&#20934;&#65292;&#21253;&#25324;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#12289;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#21644;&#20540;&#21152;&#26435;&#25216;&#33021;&#24471;&#20998;&#31561;&#24050;&#30830;&#31435;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.13472</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#24615;&#33021;&#20248;&#21270;&#22522;&#20110;&#21152;&#26435;&#24230;&#37327;&#30340;&#32508;&#21512;&#29702;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A comprehensive theoretical framework for the optimization of neural networks classification performance with respect to weighted metrics. (arXiv:2305.13472v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21487;&#20197;&#39537;&#20351;&#27169;&#22411;&#20248;&#21270;&#21152;&#26435;&#20998;&#31867;&#24230;&#37327;&#26631;&#20934;&#65292;&#21253;&#25324;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#12289;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#21644;&#20540;&#21152;&#26435;&#25216;&#33021;&#24471;&#20998;&#31561;&#24050;&#30830;&#31435;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#20026;&#20102;&#35780;&#20272;&#31070;&#32463;&#32593;&#32476;&#25152;&#20570;&#20986;&#30340;&#39044;&#27979;&#30340;&#20934;&#30830;&#31243;&#24230;&#65292;&#38656;&#35201;&#35774;&#35745;&#23450;&#21046;&#21270;&#21644;&#21152;&#26435;&#20998;&#31867;&#35780;&#20998;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#38454;&#27573;&#20013;&#26368;&#22823;&#21270;&#36825;&#20123;&#35780;&#20998;&#19982;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24418;&#24335;&#21270;&#20102;&#21152;&#26435;&#20998;&#31867;&#24230;&#37327;&#65292;&#24182;&#20801;&#35768;&#26500;&#24314;&#25439;&#22833;&#20989;&#25968;&#20197;&#39537;&#20351;&#27169;&#22411;&#20248;&#21270;&#36825;&#20123;&#26377;&#36259;&#30340;&#25351;&#26631;&#12290;&#32463;&#36807;&#35814;&#32454;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#32463;&#20856;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#12289;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#21644;&#20540;&#21152;&#26435;&#25216;&#33021;&#24471;&#20998;&#31561;&#24050;&#30830;&#31435;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many contexts, customized and weighted classification scores are designed in order to evaluate the goodness of the predictions carried out by neural networks. However, there exists a discrepancy between the maximization of such scores and the minimization of the loss function in the training phase. In this paper, we provide a complete theoretical setting that formalizes weighted classification metrics and then allows the construction of losses that drive the model to optimize these metrics of interest. After a detailed theoretical analysis, we show that our framework includes as particular instances well-established approaches such as classical cost-sensitive learning, weighted cross entropy loss functions and value-weighted skill scores.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#65306;&#22914;&#20309;&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#22312;&#23384;&#22312;&#26377;&#38480;&#23545;&#25239;&#38169;&#35823;&#26102;&#31215;&#26497;&#23398;&#20064;&#23436;&#20840;&#24674;&#22797;&#21010;&#20998;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35299;&#26512;&#26694;&#26550;&#24182;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#26597;&#35810;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.13402</link><description>&lt;p&gt;
&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#30340;&#23481;&#38169;&#31934;&#30830;&#26597;&#35810;&#23398;&#20064;&#26377;&#38480;&#38598;&#21512;&#21010;&#20998;
&lt;/p&gt;
&lt;p&gt;
Error-Tolerant Exact Query Learning of Finite Set Partitions with Same-Cluster Oracle. (arXiv:2305.13402v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#38382;&#39064;&#65306;&#22914;&#20309;&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#22312;&#23384;&#22312;&#26377;&#38480;&#23545;&#25239;&#38169;&#35823;&#26102;&#31215;&#26497;&#23398;&#20064;&#23436;&#20840;&#24674;&#22797;&#21010;&#20998;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35299;&#26512;&#26694;&#26550;&#24182;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#26597;&#35810;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#65292;&#24182;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#23384;&#22312;&#26377;&#38480;&#30340;&#23545;&#25239;&#38169;&#35823;&#26102;&#65292;&#20165;&#36890;&#36807;&#21516;&#31751;&#39044;&#35328;&#26426;&#26469;&#31215;&#26497;&#23398;&#20064;&#23436;&#20840;&#24674;&#22797;&#21010;&#20998;&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#31361;&#20986;&#20102;&#23398;&#20064;&#21010;&#20998;&#21644;&#30456;&#20851;&#32858;&#31867;&#20043;&#38388;&#30340;&#26032;&#39062;&#32852;&#31995;&#12290;&#28982;&#21518;&#21033;&#29992;&#36825;&#31181;&#32852;&#31995;&#20026;&#36825;&#20010;&#38382;&#39064;&#24314;&#31435;&#20102;&#19968;&#20010;R&#233;nyi-Ulam&#26679;&#24335;&#30340;&#35299;&#26512;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#26597;&#35810;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#38480;&#21046;&#20102;&#30456;&#20851;&#38543;&#26426;&#31639;&#27861;&#30340;&#26399;&#26395;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36866;&#24212;&#24615;&#21644;&#26597;&#35810;&#22797;&#26434;&#24230;&#22312;&#35813;&#38382;&#39064;&#21644;&#30456;&#20851;&#21464;&#20307;&#20013;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper initiates the study of active learning for exact recovery of partitions exclusively through access to a same-cluster oracle in the presence of bounded adversarial error. We first highlight a novel connection between learning partitions and correlation clustering. Then we use this connection to build a R\'enyi-Ulam style analytical framework for this problem, and prove upper and lower bounds on its worst-case query complexity. Further, we bound the expected performance of a relevant randomized algorithm. Finally, we study the relationship between adaptivity and query complexity for this problem and related variants.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.11509</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#25628;&#32034;&#21040;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25628;&#32034;&#26159;&#36229;&#21442;&#25968;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#24615;&#33021;&#20196;&#20154;&#24778;&#21497;&#65292;&#20294;&#24456;&#23569;&#26377;&#38750;&#21551;&#21457;&#24335;&#30340;&#29702;&#35770;&#29992;&#20110;&#25551;&#36848;&#20854;&#24037;&#20316;&#26426;&#21046;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#38543;&#26426;&#25628;&#32034;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#24182;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29615;&#22659;&#27809;&#26377;&#22122;&#22768;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#20854;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $&#65292;&#20854;&#20013;$ d_s \ge 0 $&#26159;&#24213;&#23618;&#20989;&#25968;&#30340;&#25955;&#23556;&#32500;&#24230;&#12290;&#24403;&#35266;&#23519;&#21040;&#30340;&#20989;&#25968;&#20540;&#21463;&#21040;&#26377;&#30028;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#22122;&#22768;&#24433;&#21709;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\ell_1$-TCL&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30693;&#35782;&#36801;&#31227;&#21644;Lasso&#22238;&#24402;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.09126</link><description>&lt;p&gt;
&#30693;&#35782;&#36801;&#31227;&#19979;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;: &#36716;&#31227;&#22240;&#26524;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Causal Learning: Causal Effect Estimation with Knowledge Transfer. (arXiv:2305.09126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\ell_1$-TCL&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30693;&#35782;&#36801;&#31227;&#21644;Lasso&#22238;&#24402;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#21363;&#22312;&#30456;&#21516;&#30340;&#21327;&#21464;&#37327;&#65288;&#25110;&#29305;&#24449;&#65289;&#31354;&#38388;&#35774;&#32622;&#19979;&#36890;&#36807;&#30693;&#35782;&#36801;&#31227;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#65292;&#21363;&#21516;&#31867;&#21035;&#36801;&#31227;&#23398;&#20064;&#65288;TL&#65289;&#65292;&#23558;&#20854;&#31216;&#20026;&#36716;&#31227;&#22240;&#26524;&#23398;&#20064;&#65288;TCL&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;$\ell_1$-TCL&#65292;&#20854;&#20013;&#21253;&#21547;$\ell_1$&#27491;&#21017;&#21270;TL&#26469;&#36827;&#34892;&#33510;&#20107;&#21442;&#25968;&#20272;&#35745;&#21644;&#19979;&#28216;&#25554;&#20214;ACE&#20272;&#35745;&#22120;&#65292;&#21253;&#25324;&#32467;&#26524;&#22238;&#24402;&#12289;&#36870;&#27010;&#29575;&#21152;&#26435;&#21644;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#20511;&#21161;&#20110;Lasso&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#24674;&#22797;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
A novel problem of improving causal effect estimation accuracy with the help of knowledge transfer under the same covariate (or feature) space setting, i.e., homogeneous transfer learning (TL), is studied, referred to as the Transfer Causal Learning (TCL) problem. While most recent efforts in adapting TL techniques to estimate average causal effect (ACE) have been focused on the heterogeneous covariate space setting, those methods are inadequate for tackling the TCL problem since their algorithm designs are based on the decomposition into shared and domain-specific covariate spaces. To address this issue, we propose a generic framework called \texttt{$\ell_1$-TCL}, which incorporates $\ell_1$ regularized TL for nuisance parameter estimation and downstream plug-in ACE estimators, including outcome regression, inverse probability weighted, and doubly robust estimators. Most importantly, with the help of Lasso for high-dimensional regression, we establish non-asymptotic recovery guarantee
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20801;&#35768;$k$&#20010;&#33218;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#24773;&#22659;&#12290;&#22312;&#20551;&#35774;&#29615;&#22659;&#36739;&#20026;&#28201;&#21644;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20851;&#20110;Learner's Losses $V_T$&#30340;&#20108;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#21644;&#20851;&#20110;&#26368;&#20339;&#31574;&#30053;$L_T^*$&#30340;&#19968;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#30340;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.00832</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
First- and Second-Order Bounds for Adversarial Linear Contextual Bandits. (arXiv:2305.00832v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00832
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20801;&#35768;$k$&#20010;&#33218;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#24773;&#22659;&#12290;&#22312;&#20551;&#35774;&#29615;&#22659;&#36739;&#20026;&#28201;&#21644;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20851;&#20110;Learner's Losses $V_T$&#30340;&#20108;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#21644;&#20851;&#20110;&#26368;&#20339;&#31574;&#30053;$L_T^*$&#30340;&#19968;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#24773;&#22659;&#65292;&#35813;&#24773;&#22659;&#20801;&#35768;&#19982;K&#20010;&#33218;&#30456;&#20851;&#32852;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#12290; &#20551;&#35774;d&#32500;&#19978;&#19979;&#25991;&#20174;&#24050;&#30693;&#20998;&#24067;&#20013;&#32472;&#21046;&#65292;&#37027;&#20040;&#22312;T&#36718;&#28216;&#25103;&#26399;&#38388;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#39044;&#26399;&#36951;&#25022;&#23558;&#20197;$\tilde O(\sqrt{Kd T})$&#30340;&#36895;&#24230;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#19978;&#19979;&#25991;&#30340;&#23494;&#24230;&#26159;&#23545;&#25968;&#20985;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20108;&#38454;&#30028;&#65292;&#20854;&#22312;&#32047;&#31215;&#25439;&#22833;&#30340;&#20108;&#27425;&#30697;$V_T$&#26041;&#38754;&#30340;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#65292;&#20197;&#21450;&#19968;&#20010;&#19982;&#20043;&#23494;&#20999;&#30456;&#20851;&#30340;&#19968;&#38454;&#30028;&#65292;&#20854;&#22312;&#26368;&#20339;&#31574;&#30053;&#30340;&#32047;&#31215;&#25439;&#22833;$L_T^*$&#26041;&#38754;&#30340;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#12290;&#30001;&#20110;$V_T$&#25110;$L_T^*$&#21487;&#33021;&#26126;&#26174;&#23567;&#20110;$T$&#65292;&#22240;&#27492;&#27599;&#24403;&#29615;&#22659;&#30456;&#23545;&#28201;&#21644;&#26102;&#65292;&#20415;&#20250;&#25913;&#21892;&#26368;&#22351;&#24773;&#20917;&#30340;&#36951;&#25022;&#12290;&#26412;&#25991;&#20351;&#29992;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#36830;&#32493;&#25351;&#25968;&#26435;&#37325;&#31639;&#27861;&#30340;&#25130;&#26029;&#29256;&#26412;&#26469;&#33719;&#24471;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
We consider the adversarial linear contextual bandit setting, which allows for the loss functions associated with each of $K$ arms to change over time without restriction. Assuming the $d$-dimensional contexts are drawn from a fixed known distribution, the worst-case expected regret over the course of $T$ rounds is known to scale as $\tilde O(\sqrt{Kd T})$. Under the additional assumption that the density of the contexts is log-concave, we obtain a second-order bound of order $\tilde O(K\sqrt{d V_T})$ in terms of the cumulative second moment of the learner's losses $V_T$, and a closely related first-order bound of order $\tilde O(K\sqrt{d L_T^*})$ in terms of the cumulative loss of the best policy $L_T^*$. Since $V_T$ or $L_T^*$ may be significantly smaller than $T$, these improve over the worst-case regret whenever the environment is relatively benign. Our results are obtained using a truncated version of the continuous exponential weights algorithm over the probability simplex, which
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13534</link><description>&lt;p&gt;
&#29992;&#22343;&#22330;&#21338;&#24328;&#20026;&#29983;&#25104;&#27169;&#22411;&#25645;&#24314;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22343;&#22330;&#21338;&#24328; (MFGs) &#20316;&#20026;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#12289;&#22686;&#24378;&#21644;&#35774;&#35745;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102; MFGs &#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#20851;&#32852;&#65292;&#24182;&#36890;&#36807;&#19981;&#21516;&#30340;&#31890;&#23376;&#21160;&#21147;&#23398;&#21644;&#20195;&#20215;&#20989;&#25968;&#25512;&#23548;&#20102;&#36825;&#19977;&#20010;&#31867;&#21035;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#8212;&#8212;&#19968;&#32452;&#32806;&#21512;&#30340;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#21644;&#29305;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#21512;&#25104;&#26679;&#26412;&#65292;&#21478;&#19968;&#20010;&#20195;&#29702;&#23545;&#26679;&#26412;&#36827;&#34892;&#35782;&#21035;&#65292;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#22810;&#26679;&#19988;&#36924;&#30495;&#65292;&#21516;&#26102;&#19982;&#22522;&#20934;&#27169;&#22411;&#30456;&#27604;&#65292;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;&#24635;&#20043;&#65292;&#26412;&#25991;&#31361;&#26174;&#20102; MFGs &#20316;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#29983;&#25104;&#27169;&#22411;&#30340;&#23454;&#39564;&#23460;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2304.05365</link><description>&lt;p&gt;
&#25105;&#20204;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#21527;&#65311;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20010;&#24615;&#21270;&#27835;&#30103;&#24207;&#21015;&#20197;&#25903;&#25345;&#29992;&#25143;&#37319;&#21462;&#26356;&#20581;&#24247;&#30340;&#34892;&#20026;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#31181;&#36830;&#32493;&#20915;&#31574;&#38382;&#39064;&#28041;&#21450;&#21040;&#22522;&#20110;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#20808;&#21069;&#30340;&#27963;&#21160;&#27700;&#24179;&#12289;&#20301;&#32622;&#31561;&#65289;&#22312;&#20309;&#26102;&#27835;&#30103;&#20197;&#21450;&#22914;&#20309;&#27835;&#30103;&#30340;&#20915;&#23450;&#12290;&#22312;&#32447;RL&#31639;&#27861;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22522;&#20110;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#30693;&#35782;&#20010;&#24615;&#21270;&#36825;&#20123;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#35201;&#20915;&#23450;&#26159;&#21542;&#24212;&#22312;&#23454;&#38469;&#37096;&#32626;&#30340;&#8220;&#20248;&#21270;&#8221;&#24178;&#39044;&#20013;&#21253;&#21547;RL&#31639;&#27861;&#65292;&#25105;&#20204;&#24517;&#39035;&#35780;&#20272;&#25968;&#25454;&#35777;&#25454;&#65292;&#34920;&#26126;RL&#31639;&#27861;&#23454;&#38469;&#19978;&#27491;&#22312;&#23558;&#27835;&#30103;&#20010;&#24615;&#21270;&#36866;&#24212;&#20854;&#29992;&#25143;&#12290;&#30001;&#20110;RL&#31639;&#27861;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#23545;&#20854;&#22312;&#26576;&#20123;&#29366;&#24577;&#19979;&#30340;&#23398;&#20064;&#24182;&#20351;&#29992;&#27492;&#23398;&#20064;&#26469;&#25552;&#20379;&#29305;&#23450;&#27835;&#30103;&#30340;&#33021;&#21147;&#20135;&#29983;&#35823;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#24037;&#20316;&#23450;&#20041;&#30340;&#20010;&#24615;&#21270;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#37325;&#22797;&#37319;&#26679;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#32447;RL&#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#20010;&#24615;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22914;&#20309;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#20272;&#35745;&#19968;&#20010;&#20998;&#24067;&#30340;&#22810;&#20010;&#20998;&#20301;&#25968;&#12290;&#23427;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#65306;&#19968;&#31181;&#26159;&#36890;&#36807;&#31169;&#26377;&#22320;&#20272;&#35745;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#65292;&#21478;&#19968;&#31181;&#26159;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#25216;&#26415;&#36827;&#34892;&#20998;&#20301;&#25968;&#20989;&#25968;&#20272;&#35745;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2302.06943</link><description>&lt;p&gt;
&#22810;&#20010;&#20998;&#20301;&#25968;&#30340;&#31169;&#26377;&#32479;&#35745;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Private Statistical Estimation of Many Quantiles. (arXiv:2302.06943v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#22914;&#20309;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#20272;&#35745;&#19968;&#20010;&#20998;&#24067;&#30340;&#22810;&#20010;&#20998;&#20301;&#25968;&#12290;&#23427;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#65306;&#19968;&#31181;&#26159;&#36890;&#36807;&#31169;&#26377;&#22320;&#20272;&#35745;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#65292;&#21478;&#19968;&#31181;&#26159;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#25216;&#26415;&#36827;&#34892;&#20998;&#20301;&#25968;&#20989;&#25968;&#20272;&#35745;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#24046;&#20998;&#38544;&#31169;&#26465;&#20214;&#19979;&#20272;&#35745;&#35768;&#22810;&#32479;&#35745;&#20998;&#20301;&#25968;&#30340;&#38382;&#39064;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#32473;&#23450;&#19968;&#20010;&#20998;&#24067;&#24182;&#19988;&#33021;&#22815;&#35775;&#38382;&#26469;&#33258;&#20854;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#29305;&#23450;&#28857;&#19978;&#20272;&#35745;&#20854;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#30340;&#36870;&#20989;&#25968;&#65288;&#20998;&#20301;&#25968;&#20989;&#25968;&#65289;&#12290;&#20363;&#22914;&#65292;&#36825;&#39033;&#20219;&#21153;&#22312;&#31169;&#26377;&#25968;&#25454;&#29983;&#25104;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26159;&#31169;&#19979;&#20272;&#35745;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#20301;&#25968;&#65292;&#24182;&#23558;&#27492;&#32467;&#26524;&#29992;&#20316;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#20272;&#35745;&#22120;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102; Kaplan&#31561;&#20154;&#26368;&#36817;&#21457;&#34920;&#30340;&#36882;&#24402;&#20272;&#35745;&#20998;&#20301;&#25968;&#30340;&#38544;&#31169;&#31639;&#27861;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#20351;&#29992;&#23494;&#24230;&#20272;&#35745;&#25216;&#26415;&#36827;&#34892;&#22343;&#21248;&#38388;&#38548;&#20869;&#30340;&#20998;&#20301;&#25968;&#20989;&#25968;&#20272;&#35745;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#24403;&#25105;&#20204;&#24819;&#35201;&#20272;&#35745;&#35768;&#22810;&#20998;&#20301;&#25968;&#26102;&#65292;&#26368;&#22909;&#20351;&#29992;&#31532;&#19968;&#31181;&#26041;&#27861;&#21333;&#29420;&#20272;&#35745;&#23427;&#20204;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#24403;&#25105;&#20204;&#24819;&#35201;&#22312;&#22823;&#21306;&#38388;&#19978;&#20272;&#35745;&#20998;&#20301;&#25968;&#20989;&#25968;&#26102;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the estimation of many statistical quantiles under differential privacy. More precisely, given a distribution and access to i.i.d. samples from it, we study the estimation of the inverse of its cumulative distribution function (the quantile function) at specific points. For instance, this task is of key importance in private data generation. We present two different approaches. The first one consists in privately estimating the empirical quantiles of the samples and using this result as an estimator of the quantiles of the distribution. In particular, we study the statistical properties of the recently published algorithm introduced by Kaplan et al. 2022 that privately estimates the quantiles recursively. The second approach is to use techniques of density estimation in order to uniformly estimate the quantile function on an interval. In particular, we show that there is a tradeoff between the two methods. When we want to estimate many quantiles, it is better to estim
&lt;/p&gt;</description></item><item><title>OPORP&#20351;&#29992;&#19968;&#31181;"&#35745;&#25968;&#33609;&#22270;"&#31867;&#22411;&#30340;&#25968;&#25454;&#38477;&#32500;/&#21387;&#32553;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#65292;&#22312;&#20445;&#35777;&#36739;&#23569;&#30340;&#20449;&#24687;&#25439;&#22833;&#30340;&#21069;&#25552;&#19979;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#35745;&#31639;&#21644;&#23384;&#20648;&#30340;&#25104;&#26412;</title><link>http://arxiv.org/abs/2302.03505</link><description>&lt;p&gt;
OPORP&#65306;&#19968;&#27425;&#32622;&#25442;+&#19968;&#27425;&#38543;&#26426;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
OPORP: One Permutation + One Random Projection. (arXiv:2302.03505v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03505
&lt;/p&gt;
&lt;p&gt;
OPORP&#20351;&#29992;&#19968;&#31181;"&#35745;&#25968;&#33609;&#22270;"&#31867;&#22411;&#30340;&#25968;&#25454;&#38477;&#32500;/&#21387;&#32553;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#23884;&#20837;&#24335;&#26816;&#32034;&#65292;&#22312;&#20445;&#35777;&#36739;&#23569;&#30340;&#20449;&#24687;&#25439;&#22833;&#30340;&#21069;&#25552;&#19979;&#65292;&#26174;&#33879;&#38477;&#20302;&#20102;&#35745;&#31639;&#21644;&#23384;&#20648;&#30340;&#25104;&#26412;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#20004;&#20010;$D$&#32500;&#25968;&#25454;&#21521;&#37327;&#65288;&#20363;&#22914;&#23884;&#20837;&#65289;&#65306;$u, v$&#12290;&#22312;&#35768;&#22810;&#22522;&#20110;&#23884;&#20837;&#30340;&#26816;&#32034;&#65288;EBR&#65289;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;$D=256\sim 1024$&#24456;&#24120;&#35265;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;OPORP&#65288;&#19968;&#27425;&#32622;&#25442;+&#19968;&#27425;&#38543;&#26426;&#25237;&#24433;&#65289;&#20351;&#29992;&#19968;&#31181;&#8220;&#35745;&#25968;&#33609;&#22270;&#8221;&#31867;&#22411;&#30340;&#25968;&#25454;&#32467;&#26500;&#21464;&#20307;&#36827;&#34892;&#25968;&#25454;&#38477;&#32500;/&#21387;&#32553;&#12290;&#20351;&#29992;OPORP&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#25968;&#25454;&#21521;&#37327;&#36827;&#34892;&#32622;&#25442;&#12290;&#29983;&#25104;&#38543;&#26426;&#21521;&#37327;$r$&#65292;i.i.d. &#65292;&#28385;&#36275;&#65306;$E&#65288;r_i&#65289;=0&#65292;E&#65288;r_i^2&#65289;=1&#65292;E&#65288;r_i^3&#65289;=0&#65292;E&#65288;r_i^4&#65289;=s$&#12290;&#25105;&#20204;&#23558;$r$&#19982;&#25152;&#26377;&#32622;&#25442;&#25968;&#25454;&#21521;&#37327;&#30456;&#20056;&#65288;&#20316;&#20026;&#28857;&#31215;&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;$D$&#21015;&#20998;&#25104;$k$&#20010;&#30456;&#31561;&#38271;&#24230;&#30340;&#31665;&#65288;bin&#65289;&#65292;&#24182;&#27719;&#24635;&#65288;&#21363;&#27714;&#21644;&#65289;&#27599;&#20010;&#31665;&#20013;&#30340;&#20540;&#20197;&#20174;&#27599;&#20010;&#25968;&#25454;&#21521;&#37327;&#20013;&#33719;&#21462;$k$&#20010;&#26679;&#26412;&#12290;&#19968;&#20010;&#20851;&#38190;&#30340;&#27493;&#39588;&#26159;&#23558;$k$&#20010;&#26679;&#26412;&#26631;&#20934;&#21270;&#20026;&#21333;&#20301;$l_2$&#33539;&#25968;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20272;&#35745;&#26041;&#24046;&#26412;&#36136;&#19978;&#26159;&#65306;$(s-1)A + \frac{D-k}{D-1}\frac{1}{k}\left[ (1-\rho^2)^2 -2A\right]$&#65292;&#20854;&#20013;$A\geq 0$&#26159;&#25968;&#25454;&#65288;$u,v$&#65289;&#30340;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Consider two $D$-dimensional data vectors (e.g., embeddings): $u, v$. In many embedding-based retrieval (EBR) applications where the vectors are generated from trained models, $D=256\sim 1024$ are common. In this paper, OPORP (one permutation + one random projection) uses a variant of the ``count-sketch'' type of data structures for achieving data reduction/compression. With OPORP, we first apply a permutation on the data vectors. A random vector $r$ is generated i.i.d. with moments: $E(r_i) = 0, E(r_i^2)=1, E(r_i^3) =0, E(r_i^4)=s$. We multiply (as dot product) $r$ with all permuted data vectors. Then we break the $D$ columns into $k$ equal-length bins and aggregate (i.e., sum) the values in each bin to obtain $k$ samples from each data vector. One crucial step is to normalize the $k$ samples to the unit $l_2$ norm. We show that the estimation variance is essentially: $(s-1)A + \frac{D-k}{D-1}\frac{1}{k}\left[ (1-\rho^2)^2 -2A\right]$, where $A\geq 0$ is a function of the data ($u,v$)
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;SE&#65288;3&#65289;&#25193;&#25955;&#27169;&#22411;&#21450;&#20854;&#29702;&#35770;&#22522;&#30784;&#65292;&#24182;&#20351;&#29992;FrameDiff&#26694;&#26550;&#22312;&#22810;&#20010;&#26694;&#26550;&#19978;&#23398;&#20064;SE&#65288;3&#65289;&#31561;&#21464;&#20998;&#25968;&#65292;&#25104;&#21151;&#29983;&#25104;&#21487;&#35774;&#35745;&#30340;&#38271;&#36798;500&#20010;&#27688;&#22522;&#37240;&#30340;&#21333;&#20307;&#32972;&#26223;&#12290;</title><link>http://arxiv.org/abs/2302.02277</link><description>&lt;p&gt;
&#24212;&#29992;&#20110;&#34507;&#30333;&#36136;&#20027;&#38142;&#29983;&#25104;&#30340;SE&#65288;3&#65289;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SE(3) diffusion model with application to protein backbone generation. (arXiv:2302.02277v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SE&#65288;3&#65289;&#25193;&#25955;&#27169;&#22411;&#21450;&#20854;&#29702;&#35770;&#22522;&#30784;&#65292;&#24182;&#20351;&#29992;FrameDiff&#26694;&#26550;&#22312;&#22810;&#20010;&#26694;&#26550;&#19978;&#23398;&#20064;SE&#65288;3&#65289;&#31561;&#21464;&#20998;&#25968;&#65292;&#25104;&#21151;&#29983;&#25104;&#21487;&#35774;&#35745;&#30340;&#38271;&#36798;500&#20010;&#27688;&#22522;&#37240;&#30340;&#21333;&#20307;&#32972;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#26032;&#22411;&#34507;&#30333;&#36136;&#32467;&#26500;&#20173;&#28982;&#26159;&#29983;&#29289;&#21307;&#23398;&#21644;&#21270;&#23398;&#39046;&#22495;&#20013;&#30340;&#19968;&#39033;&#25361;&#25112;&#12290;&#22312;&#36825;&#26041;&#38754;&#30340;&#24037;&#20316;&#20013;&#65292;&#19968;&#20010;&#19977;&#32500;&#21018;&#24615;&#20307;&#65288;&#31216;&#20026;&#26694;&#26550;&#65289;&#19978;&#30340;&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#21151;&#22320;&#29983;&#25104;&#20102;&#22312;&#33258;&#28982;&#30028;&#20013;&#27809;&#26377;&#35266;&#23519;&#21040;&#30340;&#26032;&#22411;&#21151;&#33021;&#34507;&#30333;&#20027;&#38142;&#12290;&#28982;&#32780;&#65292;&#22312;3D&#31354;&#38388;&#20013;&#30340;&#26041;&#21521;&#20445;&#25345;&#21018;&#24615;&#36816;&#21160;&#30340;SE&#65288;3&#65289;&#25193;&#25955;&#19978;&#32570;&#20047;&#26126;&#30830;&#30340;&#26041;&#27861;&#35770;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#26694;&#26550;&#25805;&#20316;&#20013;&#20445;&#25345;&#32676;&#19981;&#21464;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#22810;&#20010;&#26694;&#26550;&#19978;SE&#65288;3&#65289;&#19981;&#21464;&#25193;&#25955;&#27169;&#22411;&#30340;&#29702;&#35770;&#22522;&#30784;&#26469;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;FrameDiff&#65292;&#26469;&#23398;&#20064;&#22810;&#20010;&#26694;&#26550;&#19978;SE&#65288;3&#65289;&#31561;&#21464;&#20998;&#25968;&#12290;&#25105;&#20204;&#22312;&#21333;&#20307;&#32972;&#26223;&#29983;&#25104;&#19978;&#24212;&#29992;FrameDiff&#65292;&#24182;&#21457;&#29616;&#23427;&#21487;&#20197;&#29983;&#25104;&#21487;&#35774;&#35745;&#30340;&#21333;&#20307;&#32972;&#26223;&#65292;&#38271;&#36798;500&#20010;&#27688;&#22522;&#37240;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20043;&#21069;&#26041;&#27861;&#20013;&#24517;&#35201;&#30340;&#39044;&#35757;&#32451;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#32593;&#32476;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;sa
&lt;/p&gt;
&lt;p&gt;
The design of novel protein structures remains a challenge in protein engineering for applications across biomedicine and chemistry. In this line of work, a diffusion model over rigid bodies in 3D (referred to as frames) has shown success in generating novel, functional protein backbones that have not been observed in nature. However, there exists no principled methodological framework for diffusion on SE(3), the space of orientation preserving rigid motions in R3, that operates on frames and confers the group invariance. We address these shortcomings by developing theoretical foundations of SE(3) invariant diffusion models on multiple frames followed by a novel framework, FrameDiff, for learning the SE(3) equivariant score over multiple frames. We apply FrameDiff on monomer backbone generation and find it can generate designable monomers up to 500 amino acids without relying on a pretrained protein structure prediction network that has been integral to previous methods. We find our sa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32676;&#19981;&#21464;&#24615;&#30340;&#20998;&#24067;&#21464;&#37327;&#22312;&#21464;&#20998;&#24046;&#24322;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#22312;&#32676;&#22823;&#23567;&#32500;&#24230;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20250;&#26377;&#25152;&#38477;&#20302;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.01915</link><description>&lt;p&gt;
&#22522;&#20110;&#32676;&#23545;&#31216;&#24615;&#30340;&#27010;&#29575;&#24046;&#24322;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Probability Divergences under Group Symmetry. (arXiv:2302.01915v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32676;&#19981;&#21464;&#24615;&#30340;&#20998;&#24067;&#21464;&#37327;&#22312;&#21464;&#20998;&#24046;&#24322;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#22312;&#32676;&#22823;&#23567;&#32500;&#24230;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20250;&#26377;&#25152;&#38477;&#20302;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#20110;&#20855;&#26377;&#32676;&#19981;&#21464;&#24615;&#30340;&#20998;&#24067;&#21464;&#37327;&#22312;&#21464;&#20998;&#24046;&#24322;&#20272;&#35745;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#36827;&#34892;&#20102;&#20005;&#35880;&#30340;&#37327;&#21270;&#20998;&#26512;&#12290;&#22312;Wasserstein-1&#36317;&#31163;&#21644;Lipschitz&#27491;&#21017;&#21270;&#945;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#38477;&#20302;&#19982;&#32676;&#22823;&#23567;&#30340;&#32500;&#24230;&#30456;&#20851;&#12290;&#23545;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25913;&#36827;&#26356;&#21152;&#22797;&#26434;&#65292;&#22240;&#20026;&#23427;&#19981;&#20165;&#21462;&#20915;&#20110;&#32676;&#22823;&#23567;&#65292;&#36824;&#21462;&#20915;&#20110;&#20869;&#26680;&#30340;&#36873;&#25321;&#12290; &#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We rigorously quantify the improvement in the sample complexity of variational divergence estimations for group-invariant distributions. In the cases of the Wasserstein-1 metric and the Lipschitz-regularized $\alpha$-divergences, the reduction of sample complexity is proportional to an ambient-dimension-dependent power of the group size. For the maximum mean discrepancy (MMD), the improvement of sample complexity is more nuanced, as it depends on not only the group size but also the choice of kernel. Numerical simulations verify our theories.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#21518;&#22788;&#29702;MCMC&#36755;&#20986;&#36807;&#31243;&#20013;&#30340;&#30149;&#24577;&#38382;&#39064;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;Stein&#31232;&#37322;&#31639;&#27861;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#36825;&#20123;&#30149;&#24577;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#20026;&#25552;&#39640;&#36924;&#36817;&#36136;&#37327;&#25552;&#20379;&#20102;&#26032;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2301.13528</link><description>&lt;p&gt;
&#26680;&#26031;&#22374;&#36317;&#31163;&#31232;&#37322;&#65306;&#20851;&#20110;&#30149;&#24577;&#30340;&#29702;&#35770;&#35270;&#35282;&#21644;&#27491;&#21017;&#21270;&#30340;&#23454;&#38469;&#20462;&#22797;&#65288;arXiv:2301.13528v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization. (arXiv:2301.13528v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#21518;&#22788;&#29702;MCMC&#36755;&#20986;&#36807;&#31243;&#20013;&#30340;&#30149;&#24577;&#38382;&#39064;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;Stein&#31232;&#37322;&#31639;&#27861;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#36825;&#20123;&#30149;&#24577;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#20026;&#25552;&#39640;&#36924;&#36817;&#36136;&#37327;&#25552;&#20379;&#20102;&#26032;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#31232;&#37322;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#31639;&#27861;&#65292;&#30001;&#65288;Riabiz et al.&#65292;2022&#65289;&#25552;&#20986;&#29992;&#20110;&#21518;&#22788;&#29702;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#30340;&#36755;&#20986;&#12290;&#20854;&#20027;&#35201;&#21407;&#21017;&#26159;&#36138;&#23146;&#22320;&#26368;&#23567;&#21270;&#26680;&#21270;Stein&#24046;&#24322;&#65288;KSD&#65289;&#65292;&#23427;&#20165;&#38656;&#35201;&#23545;&#25968;&#30446;&#26631;&#20998;&#24067;&#30340;&#26799;&#24230;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#21512;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290; Stein&#31232;&#37322;&#30340;&#20027;&#35201;&#20248;&#21183;&#26159;&#33258;&#21160;&#28040;&#38500;&#21551;&#21160;&#26399;&#65292;&#32416;&#27491;&#26368;&#36817;&#30340;MCMC&#31639;&#27861;&#24341;&#20837;&#30340;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#25910;&#25947;&#33267;&#30446;&#26631;&#20998;&#24067;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;&#28982;&#32780;&#65292; Stein&#31232;&#37322;&#23384;&#22312;&#20960;&#20010;&#32463;&#39564;&#30149;&#24577;&#65292;&#21487;&#33021;&#23548;&#33268;&#21155;&#36136;&#36924;&#36817;&#65292;&#36825;&#22312;&#25991;&#29486;&#20013;&#24050;&#34987;&#35266;&#23519;&#21040;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#30149;&#24577;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20197;&#26126;&#30830;&#35782;&#21035;&#28041;&#21450;&#30340;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31574;&#30053;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27491;&#21017;&#21270;&#30340; Stein&#31232;&#37322;&#31639;&#27861;&#26469;&#32531;&#35299;&#24050;&#35782;&#21035;&#30340;&#30149;&#24577;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein thinning is a promising algorithm proposed by (Riabiz et al., 2022) for post-processing outputs of Markov chain Monte Carlo (MCMC). The main principle is to greedily minimize the kernelized Stein discrepancy (KSD), which only requires the gradient of the log-target distribution, and is thus well-suited for Bayesian inference. The main advantages of Stein thinning are the automatic remove of the burn-in period, the correction of the bias introduced by recent MCMC algorithms, and the asymptotic properties of convergence towards the target distribution. Nevertheless, Stein thinning suffers from several empirical pathologies, which may result in poor approximations, as observed in the literature. In this article, we conduct a theoretical analysis of these pathologies, to clearly identify the mechanisms at stake, and suggest improved strategies. Then, we introduce the regularized Stein thinning algorithm to alleviate the identified pathologies. Finally, theoretical guarantees and exte
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#22312;&#39640;&#32500;&#29305;&#24449;&#21464;&#37327;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#26412;&#36523;&#36827;&#34892;&#25512;&#26029;&#30340;&#24037;&#20316;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#20272;&#35745;&#22120;&#20197;&#25552;&#39640;&#20215;&#20540;&#20989;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.12553</link><description>&lt;p&gt;
&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#30340;&#39640;&#32500;&#29305;&#24449;&#28176;&#36817;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Inference for Multi-Stage Stationary Treatment Policy with High Dimensional Features. (arXiv:2301.12553v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22635;&#34917;&#20102;&#22312;&#39640;&#32500;&#29305;&#24449;&#21464;&#37327;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#26412;&#36523;&#36827;&#34892;&#25512;&#26029;&#30340;&#24037;&#20316;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#20272;&#35745;&#22120;&#20197;&#25552;&#39640;&#20215;&#20540;&#20989;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#35268;&#21017;&#26159;&#19968;&#31995;&#21015;&#38024;&#23545;&#20010;&#20307;&#29305;&#24449;&#37327;&#36523;&#23450;&#21046;&#30340;&#22810;&#38454;&#27573;&#20915;&#31574;&#20989;&#25968;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#19968;&#31867;&#37325;&#35201;&#30340;&#27835;&#30103;&#31574;&#30053;&#26159;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#65292;&#20854;&#20351;&#29992;&#30456;&#21516;&#30340;&#20915;&#31574;&#20989;&#25968;&#26469;&#25351;&#23450;&#27835;&#30103;&#20998;&#37197;&#27010;&#29575;&#65292;&#22312;&#20915;&#31574;&#26102;&#22522;&#20110;&#21516;&#26102;&#21253;&#25324;&#22522;&#32447;&#21464;&#37327;&#65288;&#20363;&#22914;&#20154;&#21475;&#32479;&#35745;&#23398;&#65289;&#21644;&#26102;&#21464;&#21464;&#37327;&#65288;&#20363;&#22914;&#24120;&#35268;&#26816;&#27979;&#21040;&#30340;&#30142;&#30149;&#29983;&#29289;&#26631;&#24535;&#29289;&#65289;&#30340;&#19968;&#32452;&#29305;&#24449;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#22823;&#37327;&#25991;&#29486;&#23545;&#19982;&#21160;&#24577;&#27835;&#30103;&#31574;&#30053;&#30456;&#20851;&#30340;&#20215;&#20540;&#20989;&#25968;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#65292;&#20294;&#22312;&#39640;&#32500;&#29305;&#24449;&#21464;&#37327;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#27835;&#30103;&#31574;&#30053;&#26412;&#36523;&#30340;&#24037;&#20316;&#36824;&#24456;&#23569;&#12290;&#25105;&#20204;&#26088;&#22312;&#22635;&#34917;&#36825;&#39033;&#24037;&#20316;&#30340;&#31354;&#30333;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#22522;&#20110;&#22686;&#24378;&#30340;&#20498;&#25968;&#26435;&#37325;&#20272;&#35745;&#22120;&#20272;&#35745;&#22810;&#38454;&#27573;&#38745;&#24577;&#27835;&#30103;&#31574;&#30053;&#65292;&#20197;&#25552;&#39640;&#20215;&#20540;&#20989;&#25968;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic treatment rules or policies are a sequence of decision functions over multiple stages that are tailored to individual features. One important class of treatment policies for practice, namely multi-stage stationary treatment policies, prescribe treatment assignment probabilities using the same decision function over stages, where the decision is based on the same set of features consisting of both baseline variables (e.g., demographics) and time-evolving variables (e.g., routinely collected disease biomarkers). Although there has been extensive literature to construct valid inference for the value function associated with the dynamic treatment policies, little work has been done for the policies themselves, especially in the presence of high dimensional feature variables. We aim to fill in the gap in this work. Specifically, we first estimate the multistage stationary treatment policy based on an augmented inverse probability weighted estimator for the value function to increase
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25277;&#26679;&#30340;Nystr&#246;m&#36924;&#36817;&#26041;&#27861;&#29992;&#20110;&#26680;&#31215;&#20998;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#38750;i.i.d.&#22320;&#26631;&#28857;&#30340;&#29702;&#35770;&#20445;&#35777;&#26041;&#27861;&#65292;&#20351;&#24471;&#25552;&#39640;&#20102;&#36924;&#36817;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2301.09517</link><description>&lt;p&gt;
&#22522;&#20110;&#25277;&#26679;&#30340;Nystr&#246;m&#36924;&#36817;&#21644;&#26680;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling-based Nystr\"om Approximation and Kernel Quadrature. (arXiv:2301.09517v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09517
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25277;&#26679;&#30340;Nystr&#246;m&#36924;&#36817;&#26041;&#27861;&#29992;&#20110;&#26680;&#31215;&#20998;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#38750;i.i.d.&#22320;&#26631;&#28857;&#30340;&#29702;&#35770;&#20445;&#35777;&#26041;&#27861;&#65292;&#20351;&#24471;&#25552;&#39640;&#20102;&#36924;&#36817;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#19982;&#27010;&#29575;&#27979;&#37327;&#30456;&#20851;&#30340;&#27491;&#23450;&#26680;&#30340;Nystr&#246;m&#36924;&#36817;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#20256;&#32479;Nystr&#246;m&#36924;&#36817;&#22312;&#36830;&#32493;&#21306;&#38388;&#20013;&#20351;&#29992;i.i.d.&#25277;&#26679;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#65292;&#35777;&#26126;&#25216;&#24039;&#20511;&#37492;&#20102;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24341;&#20837;&#20102;Nystr&#246;m&#36924;&#36817;&#20013;&#30340;&#23376;&#31354;&#38388;&#31934;&#32454;&#36873;&#25321;&#65292;&#36825;&#26159;&#36866;&#29992;&#20110;&#38750;i.i.d.&#22320;&#26631;&#28857;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#22312;&#20984;&#26680;&#31215;&#20998;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#32473;&#20986;&#20102;&#26032;&#30340;&#29702;&#35770;&#20445;&#35777;&#20197;&#21450;&#25968;&#20540;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the Nystr\"om approximation of a positive definite kernel associated with a probability measure. We first prove an improved error bound for the conventional Nystr\"om approximation with i.i.d. sampling and singular-value decomposition in the continuous regime; the proof techniques are borrowed from statistical learning theory. We further introduce a refined selection of subspaces in Nystr\"om approximation with theoretical guarantees that is applicable to non-i.i.d. landmark points. Finally, we discuss their application to convex kernel quadrature and give novel theoretical guarantees as well as numerical observations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#30340;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#65292;&#24182;&#25552;&#20986;&#20102;&#24369;&#20551;&#35774;&#12290;&#36890;&#36807;&#36825;&#31181;&#21160;&#24577;&#25511;&#21046;&#30340;&#27010;&#29575;&#23494;&#24230;&#25351;&#25968;&#32423;&#22320;&#24555;&#36895;&#25910;&#25947;&#21040;&#21513;&#24067;&#26031;&#24179;&#34913;&#27979;&#24230;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#30340;&#25968;&#20540;&#37319;&#26679;&#22120;&#65292;&#24182;&#23545;&#20854;&#36924;&#36817;&#21697;&#36136;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2211.00450</link><description>&lt;p&gt;
&#37319;&#26679;&#30340;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#65306;&#20840;&#23616;&#25910;&#25947;&#65292;&#36924;&#36817;&#21450;&#20854;&#28176;&#36817;&#24615;&#36136;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Birth-death dynamics for sampling: Global convergence, approximations and their asymptotics. (arXiv:2211.00450v2 [math.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#30340;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#65292;&#24182;&#25552;&#20986;&#20102;&#24369;&#20551;&#35774;&#12290;&#36890;&#36807;&#36825;&#31181;&#21160;&#24577;&#25511;&#21046;&#30340;&#27010;&#29575;&#23494;&#24230;&#25351;&#25968;&#32423;&#22320;&#24555;&#36895;&#25910;&#25947;&#21040;&#21513;&#24067;&#26031;&#24179;&#34913;&#27979;&#24230;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#30340;&#25968;&#20540;&#37319;&#26679;&#22120;&#65292;&#24182;&#23545;&#20854;&#36924;&#36817;&#21697;&#36136;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#37319;&#26679;&#38750;&#20984;&#20301;&#21183;&#21513;&#24067;&#26031;&#27979;&#24230;&#20026;&#25361;&#25112;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24369;&#20551;&#35774;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;[51,57]&#30340;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#30001;Kullback-Leibler&#25955;&#24230;&#25110;$\chi^2$&#25955;&#24230;&#25511;&#21046;&#30340;&#20986;&#29983;&#27515;&#20129;&#27010;&#29575;&#23494;&#24230;&#20250;&#25351;&#25968;&#32423;&#24555;&#36895;&#22320;&#25910;&#25947;&#21040;&#21513;&#24067;&#26031;&#24179;&#34913;&#27979;&#24230;&#65292;&#20854;&#26222;&#36866;&#36895;&#29575;&#29420;&#31435;&#20110;&#21183;&#22418;&#12290;&#20026;&#20102;&#26500;&#24314;&#22522;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#30340;&#23454;&#29992;&#25968;&#20540;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#65292;&#23427;&#28789;&#24863;&#26469;&#33258;&#20110;&#26799;&#24230;&#27969;&#32467;&#26500;&#21644;&#32463;&#20856;&#30340;Fokker-Planck&#26041;&#31243;&#65292;&#24182;&#20381;&#36182;&#20110;&#27979;&#37327;&#30340;&#22522;&#20110;&#26680;&#30340;&#36924;&#36817;&#12290;&#36890;&#36807;&#26799;&#24230;&#27969;&#30340;$\Gamma$-&#25910;&#25947;&#25216;&#26415;&#65292;&#35777;&#26126;&#22312;&#29615;&#19978;&#65292;&#26680;&#21270;&#21160;&#24577;&#30340;&#20809;&#28369;&#26377;&#30028;&#27491;&#35299;&#22312;&#26377;&#38480;&#26102;&#38388;&#38388;&#38548;&#20869;&#65292;&#24403;&#26680;&#24102;&#23485;&#25910;&#32553;&#21040;&#38646;&#26102;&#65292;&#25910;&#25947;&#20110;&#32431;&#20986;&#29983;&#27515;&#20129;&#21160;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#20285;&#39532;&#25910;&#25947;&#30340;&#25216;&#26415;&#23545;&#32431;&#20986;&#29983;&#27515;&#20129;&#36807;&#31243;&#30340;&#36924;&#36817;&#21697;&#36136;&#36827;&#34892;&#20102;&#23450;&#37327;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the challenge of sampling Gibbs measures with nonconvex potentials, we study a continuum birth-death dynamics. We improve results in previous works [51,57] and provide weaker hypotheses under which the probability density of the birth-death governed by Kullback-Leibler divergence or by $\chi^2$ divergence converge exponentially fast to the Gibbs equilibrium measure, with a universal rate that is independent of the potential barrier. To build a practical numerical sampler based on the pure birth-death dynamics, we consider an interacting particle system, which is inspired by the gradient flow structure and the classical Fokker-Planck equation and relies on kernel-based approximations of the measure. Using the technique of $\Gamma$-convergence of gradient flows, we show that on the torus, smooth and bounded positive solutions of the kernelized dynamics converge on finite time intervals, to the pure birth-death dynamics as the kernel bandwidth shrinks to zero. Moreover we pro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#20915;&#31574;&#21382;&#21490;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#29992;&#20110;&#37327;&#21270;&#20381;&#36182;&#31243;&#24230;&#30340;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2210.09903</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#38480;&#21046;&#20869;&#23384;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Online Convex Optimization with Unbounded Memory. (arXiv:2210.09903v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#20915;&#31574;&#21382;&#21490;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#29992;&#20110;&#37327;&#21270;&#20381;&#36182;&#31243;&#24230;&#30340;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20984;&#20248;&#21270;&#65288;OCO&#65289;&#26159;&#22312;&#32447;&#23398;&#20064;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#22312;&#24456;&#22810;&#24212;&#29992;&#20013;&#65292;&#23398;&#20064;&#32773;&#30340;&#25439;&#22833;&#19981;&#20165;&#21462;&#20915;&#20110;&#24403;&#21069;&#30340;&#20915;&#31574;&#65292;&#36824;&#21462;&#20915;&#20110;&#30452;&#21040;&#37027;&#20010;&#26102;&#38388;&#28857;&#30340;&#25152;&#26377;&#20915;&#31574;&#21382;&#21490;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;OCO&#30340;&#25193;&#23637;&#26694;&#26550;&#65292;&#8220;&#20855;&#26377;&#26080;&#38480;&#21046;&#20869;&#23384;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#8221;&#65292;&#26469;&#25429;&#25417;&#23545;&#36807;&#21435;&#20915;&#31574;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#65292;$H_p$&#65292;&#23427;&#37327;&#21270;&#20102;$p$&#38454;&#24433;&#21709;&#30340;&#26368;&#22823;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online convex optimization (OCO) is a widely used framework in online learning. In each round, the learner chooses a decision in a convex set and an adversary chooses a convex loss function, and then the learner suffers the loss associated with their current decision. However, in many applications the learner's loss depends not only on the current decision but on the entire history of decisions until that point. The OCO framework and its existing generalizations do not capture this, and they can only be applied to many settings of interest after a long series of approximation arguments. They also leave open the question of whether the dependence on memory is tight because there are no non-trivial lower bounds. In this work we introduce a generalization of the OCO framework, ``Online Convex Optimization with Unbounded Memory'', that captures long-term dependence on past decisions. We introduce the notion of $p$-effective memory capacity, $H_p$, that quantifies the maximum influence of p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#38669;&#20811;&#36807;&#31243;&#30340;Granger&#22240;&#26524;&#38142;&#21457;&#29616;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;EMR&#25968;&#25454;&#20013;&#22810;&#20010;&#24739;&#32773;&#29305;&#24449;&#20043;&#38388;&#30340;&#26102;&#38388;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#30830;&#23450;&#36133;&#34880;&#30151;&#30456;&#20851;&#24322;&#24120;&#30340;&#23454;&#39564;&#23460;&#20540;&#38142;&#12290;</title><link>http://arxiv.org/abs/2209.04480</link><description>&lt;p&gt;
&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#38669;&#20811;&#36807;&#31243;&#30340;&#36133;&#34880;&#30151;&#30456;&#20851;&#24322;&#24120;&#30340;Granger&#22240;&#26524;&#38142;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Granger Causal Chain Discovery for Sepsis-Associated Derangements via Continuous-Time Hawkes Processes. (arXiv:2209.04480v5 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04480
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#38669;&#20811;&#36807;&#31243;&#30340;Granger&#22240;&#26524;&#38142;&#21457;&#29616;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#25512;&#26029;EMR&#25968;&#25454;&#20013;&#22810;&#20010;&#24739;&#32773;&#29305;&#24449;&#20043;&#38388;&#30340;&#26102;&#38388;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#30830;&#23450;&#36133;&#34880;&#30151;&#30456;&#20851;&#24322;&#24120;&#30340;&#23454;&#39564;&#23460;&#20540;&#38142;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#21307;&#30103;&#20445;&#20581;&#31995;&#32479;&#27491;&#22312;&#22686;&#21152;&#23545;&#30005;&#23376;&#30149;&#21382;&#65288;EMR&#65289;&#36827;&#34892;&#36830;&#32493;&#33258;&#21160;&#30417;&#27979;&#65292;&#20197;&#26356;&#39057;&#32321;&#22320;&#35782;&#21035;&#19981;&#33391;&#20107;&#20214;; &#20294;&#26159;&#65292;&#35768;&#22810;&#20107;&#20214;&#65288;&#22914;&#36133;&#34880;&#30151;&#65289;&#27809;&#26377;&#24050;&#38416;&#26126;&#30340;&#21069;&#39537;&#30151;&#29366;&#65288;&#21363;&#20107;&#20214;&#38142;&#65289;&#65292;&#21487;&#20197;&#29992;&#20110;&#22312;&#20854;&#30149;&#31243;&#26089;&#26399;&#35782;&#21035;&#21644;&#25130;&#33719;&#19981;&#33391;&#20107;&#20214;&#12290;&#20020;&#24202;&#30456;&#20851;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#38656;&#35201;&#19968;&#20010;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#65288;i&#65289;&#25512;&#26029;EMR&#25968;&#25454;&#20013;&#22810;&#20010;&#24739;&#32773;&#29305;&#24449;&#20043;&#38388;&#30340;&#26102;&#38388;&#20132;&#20114;&#20316;&#29992;&#65288;&#20363;&#22914;&#23454;&#39564;&#23460;&#26816;&#26597;&#12289;&#29983;&#21629;&#20307;&#24449;&#31561;&#65289;&#65292;&#24182;&#19988;&#21487;&#20197;&#65288;ii&#65289;&#30830;&#23450;&#22312;&#21363;&#23558;&#21457;&#29983;&#30340;&#19981;&#33391;&#20107;&#20214;&#65288;&#20363;&#22914;&#36133;&#34880;&#30151;&#65289;&#20043;&#21069;&#20808;&#23548;&#19988;&#29305;&#23450;&#30340;&#27169;&#24335;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32447;&#24615;&#22810;&#20803;&#38669;&#20811;&#36807;&#31243;&#27169;&#22411;&#65292;&#32467;&#21512;ReLU&#38142;&#25509;&#20989;&#25968;&#65292;&#20197;&#24674;&#22797;&#20855;&#26377;&#20852;&#22859;&#21644;&#25233;&#21046;&#25928;&#24212;&#30340;Granger&#22240;&#26524;&#65288;GC&#65289;&#22270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#20004;&#38454;&#27573;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20197;&#33719;&#24471;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20540;&#65292;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#22411;EMR&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#26174;&#31034;&#36133;&#34880;&#30151;&#30456;&#20851;&#23454;&#39564;&#23460;&#24322;&#24120;&#30340;&#21487;&#35299;&#37322;&#30340;&#26102;&#38388;&#27169;&#24335;&#12290;&#36825;&#20123;&#27169;&#24335;&#24314;&#35758;&#20102;&#19968;&#26465;&#23454;&#39564;&#23460;&#20215;&#20540;&#35266;&#30340;&#38142;&#65292;&#21487;&#20197;&#24110;&#21161;&#26089;&#26399;&#26816;&#27979;&#21644;&#31649;&#29702;&#36133;&#34880;&#30151;&#30456;&#20851;&#24322;&#24120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern health care systems are conducting continuous, automated surveillance of the electronic medical record (EMR) to identify adverse events with increasing frequency; however, many events such as sepsis do not have elucidated prodromes (i.e., event chains) that can be used to identify and intercept the adverse event early in its course. Clinically relevant and interpretable results require a framework that can (i) infer temporal interactions across multiple patient features found in EMR data (e.g., Labs, vital signs, etc.) and (ii) identify patterns that precede and are specific to an impending adverse event (e.g., sepsis). In this work, we propose a linear multivariate Hawkes process model, coupled with ReLU link function, to recover a Granger Causal (GC) graph with both exciting and inhibiting effects. We develop a scalable two-phase gradient-based method to obtain a maximum surrogate-likelihood estimator, which is shown to be effective via extensive numerical simulation. Our meth
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20004;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;SVRP &#21644; Catalyzed SVRP&#65292;&#23427;&#20204;&#37117;&#26377;&#36739;&#39640;&#30340;&#36890;&#20449;&#25928;&#29575;&#21644;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#24191;&#27867;&#36866;&#29992;&#20110;&#20998;&#24067;&#24335;&#32479;&#35745;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2209.02257</link><description>&lt;p&gt;
&#22522;&#20110;&#20108;&#38454;&#30456;&#20284;&#24615;&#30340;&#26356;&#24555;&#32852;&#37030;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Faster federated optimization under second-order similarity. (arXiv:2209.02257v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.02257
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20004;&#31181;&#26032;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;SVRP &#21644; Catalyzed SVRP&#65292;&#23427;&#20204;&#37117;&#26377;&#36739;&#39640;&#30340;&#36890;&#20449;&#25928;&#29575;&#21644;&#24615;&#33021;&#34920;&#29616;&#65292;&#24182;&#24191;&#27867;&#36866;&#29992;&#20110;&#20998;&#24067;&#24335;&#32479;&#35745;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#20010;&#20998;&#25903;&#65292;&#22312;&#36890;&#20449;&#32422;&#26463;&#19979;&#65292;&#22810;&#20010;&#23458;&#25143;&#31471;&#23581;&#35797;&#22312;&#32593;&#32476;&#19978;&#21327;&#20316;&#23398;&#20064;&#27169;&#22411;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#20108;&#38454;&#20989;&#25968;&#30456;&#20284;&#24615;&#26465;&#20214;&#21644;&#24378;&#20984;&#24615;&#19979;&#30340;&#26377;&#38480;&#21644;&#32852;&#37030;&#20248;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;&#65306;SVRP &#21644;&#20652;&#21270; SVRP&#12290;&#36817;&#24180;&#26469;&#65292;&#20108;&#38454;&#30456;&#20284;&#24615;&#26465;&#20214;&#24050;&#32463;&#21464;&#24471;&#27969;&#34892;&#36215;&#26469;&#65292;&#24182;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#24471;&#21040;&#28385;&#36275;&#65292;&#21253;&#25324;&#20998;&#24067;&#24335;&#32479;&#35745;&#23398;&#20064;&#21644;&#24046;&#20998;&#38544;&#31169;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#12290;&#31532;&#19968;&#20010;&#31639;&#27861; SVRP &#32452;&#21512;&#20102;&#36817;&#20284;&#38543;&#26426;&#36817;&#31471;&#28857;&#35780;&#20272;&#12289;&#23458;&#25143;&#31471;&#25277;&#26679;&#21644;&#26041;&#24046;&#32553;&#20943;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102; SVRP &#20855;&#26377;&#36890;&#20449;&#25928;&#29575;&#65292;&#24182;&#19988;&#22312;&#20989;&#25968;&#30456;&#20284;&#24615;&#36275;&#22815;&#39640;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#33719;&#24471;&#20248;&#36234;&#30340;&#24615;&#33021;&#65292;&#20248;&#20110;&#35768;&#22810;&#29616;&#26377;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#31639;&#27861;&#65292;Catalyzed SVRP &#26159; SVRP &#30340;&#20652;&#21270;&#21058;&#21152;&#36895;&#21464;&#20307;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#32479;&#19968;&#25913;&#36827;&#29616;&#26377;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) is a subfield of machine learning where multiple clients try to collaboratively learn a model over a network under communication constraints. We consider finite-sum federated optimization under a second-order function similarity condition and strong convexity, and propose two new algorithms: SVRP and Catalyzed SVRP. This second-order similarity condition has grown popular recently, and is satisfied in many applications including distributed statistical learning and differentially private empirical risk minimization. The first algorithm, SVRP, combines approximate stochastic proximal point evaluations, client sampling, and variance reduction. We show that SVRP is communication efficient and achieves superior performance to many existing algorithms when function similarity is high enough. Our second algorithm, Catalyzed SVRP, is a Catalyst-accelerated variant of SVRP that achieves even better performance and uniformly improves upon existing algorithms for federate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#65292;&#23427;&#21487;&#20197;&#20351;&#29992;&#25513;&#30721;&#21464;&#37327;&#22312;&#33410;&#28857;&#32423;&#21035;&#19978;&#20851;&#38381;&#19968;&#20123;&#33410;&#28857;&#65292;&#20197;&#20135;&#29983;&#31232;&#30095;&#30340;DNN&#32467;&#26500;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#20808;&#39564;&#20998;&#24067;&#65292;&#20351;&#24471;&#21518;&#39564;&#20998;&#24067;&#20855;&#26377;&#29702;&#35770;&#19978;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MCMC&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#33021;&#22815;&#21457;&#29616;&#31934;&#31616;&#30340;DNN&#32467;&#26500;&#65292;&#20855;&#26377;&#19982;&#22823;&#22411;DNN&#30456;&#20284;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2206.00853</link><description>&lt;p&gt;
&#25513;&#30721;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;: &#35745;&#31639;&#19982;&#20248;&#36234;&#24615;
&lt;/p&gt;
&lt;p&gt;
Masked Bayesian Neural Networks : Computation and Optimality. (arXiv:2206.00853v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#65292;&#23427;&#21487;&#20197;&#20351;&#29992;&#25513;&#30721;&#21464;&#37327;&#22312;&#33410;&#28857;&#32423;&#21035;&#19978;&#20851;&#38381;&#19968;&#20123;&#33410;&#28857;&#65292;&#20197;&#20135;&#29983;&#31232;&#30095;&#30340;DNN&#32467;&#26500;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#20808;&#39564;&#20998;&#24067;&#65292;&#20351;&#24471;&#21518;&#39564;&#20998;&#24067;&#20855;&#26377;&#29702;&#35770;&#19978;&#30340;&#26368;&#20248;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MCMC&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#33021;&#22815;&#21457;&#29616;&#31934;&#31616;&#30340;DNN&#32467;&#26500;&#65292;&#20855;&#26377;&#19982;&#22823;&#22411;DNN&#30456;&#20284;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#37327;&#21644;&#35745;&#31639;&#33021;&#21147;&#30340;&#22686;&#38271;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#26550;&#26500;&#21464;&#24471;&#36234;&#26469;&#36234;&#22797;&#26434;&#21644;&#24222;&#22823;&#65292;&#22240;&#27492;&#38656;&#35201;&#31616;&#21270;&#36825;&#31181;&#22797;&#26434;&#21644;&#24222;&#22823;&#30340;DNN&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31232;&#30095;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#65292;&#35813;&#32593;&#32476;&#21487;&#20197;&#25214;&#21040;&#19968;&#20010;&#36866;&#24403;&#22797;&#26434;&#24230;&#30340; DNN&#12290;&#25105;&#20204;&#22312;&#27599;&#20010;&#33410;&#28857;&#19978;&#20351;&#29992;&#25513;&#30721;&#21464;&#37327;&#65292;&#26681;&#25454;&#21518;&#39564;&#20998;&#24067;&#20851;&#38381;&#19968;&#20123;&#33410;&#28857;&#65292;&#20197;&#20135;&#29983;&#31232;&#30095; DNN&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#20808;&#39564;&#20998;&#24067;&#65292;&#20351;&#24471;&#21518;&#39564;&#20998;&#24067;&#20855;&#26377;&#29702;&#35770;&#19978;&#30340;&#26368;&#20248;&#24615;&#65288;&#21363;&#26497;&#23567;&#26497;&#22823;&#20248;&#36234;&#24615;&#21644;&#33258;&#36866;&#24212;&#24615;&#65289;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;MCMC&#31639;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;BNN&#34920;&#29616;&#33391;&#22909;&#65292;&#19982;&#22823;&#22411;DNN&#30456;&#27604;&#65292;&#23427;&#21457;&#29616;&#20102;&#31934;&#31616;&#30340;DNN&#32467;&#26500;&#65292;&#20855;&#26377;&#30456;&#20284;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
As data size and computing power increase, the architectures of deep neural networks (DNNs) have been getting more complex and huge, and thus there is a growing need to simplify such complex and huge DNNs. In this paper, we propose a novel sparse Bayesian neural network (BNN) which searches a good DNN with an appropriate complexity. We employ the masking variables at each node which can turn off some nodes according to the posterior distribution to yield a nodewise sparse DNN. We devise a prior distribution such that the posterior distribution has theoretical optimalities (i.e. minimax optimality and adaptiveness), and develop an efficient MCMC algorithm. By analyzing several benchmark datasets, we illustrate that the proposed BNN performs well compared to other existing methods in the sense that it discovers well condensed DNN architectures with similar prediction accuracy and uncertainty quantification compared to large DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;SVM&#30340;&#25351;&#25968;&#32423;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#33719;&#24471;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#27809;&#26377;&#20551;&#35774;&#30828;Tsybakov&#36793;&#38469;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23637;&#31034;&#20102;SVM&#30340;&#25351;&#25968;&#32423;&#25910;&#25947;&#36895;&#24230;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2205.10055</link><description>&lt;p&gt;
SVM&#25351;&#25968;&#32423;&#25910;&#25947;&#36895;&#24230;&#30340;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
A Case of Exponential Convergence Rates for SVM. (arXiv:2205.10055v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;SVM&#30340;&#25351;&#25968;&#32423;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#33719;&#24471;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#27809;&#26377;&#20551;&#35774;&#30828;Tsybakov&#36793;&#38469;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#23637;&#31034;&#20102;SVM&#30340;&#25351;&#25968;&#32423;&#25910;&#25947;&#36895;&#24230;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#38382;&#39064;&#36890;&#24120;&#26159;&#20171;&#32461;&#26426;&#22120;&#23398;&#20064;&#35838;&#31243;&#20013;&#25551;&#36848;&#30340;&#31532;&#19968;&#20010;&#38382;&#39064;&#12290;&#21382;&#21490;&#19978;&#65292;&#29926;&#26222;&#23612;&#20811;-&#20999;&#23572;&#27779;&#24180;&#31185;&#29702;&#35770;&#25552;&#20379;&#20102;&#20998;&#31867;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20445;&#35777;&#22522;&#20110;&#38590;&#20197;&#22788;&#29702;&#30340;&#31639;&#27861;&#65292;&#36825;&#23548;&#33268;&#20102;&#20998;&#31867;&#20013;&#20195;&#29702;&#26041;&#27861;&#30340;&#29702;&#35770;&#12290;&#20195;&#29702;&#26041;&#27861;&#25552;&#20379;&#30340;&#20445;&#35777;&#22522;&#20110;&#26657;&#20934;&#19981;&#31561;&#24335;&#65292;&#24050;&#34987;&#35777;&#26126;&#22312;&#26576;&#20123;&#36793;&#38469;&#26465;&#20214;&#19979;&#38750;&#24120;&#27425;&#20248;&#65292;&#19981;&#33021;&#25429;&#25417;&#21040;&#25351;&#25968;&#32423;&#25910;&#25947;&#29616;&#35937;&#12290;&#36825;&#20123;"&#36229;"&#24555;&#36895;&#29575;&#29616;&#22312;&#24050;&#32463;&#23545;&#20110;&#20809;&#28369;&#30340;&#20195;&#29702;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#29702;&#35299;&#65292;&#20294;&#23545;&#20110;&#19982;&#33879;&#21517;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#30456;&#20851;&#30340;&#38750;&#20809;&#28369;&#25439;&#22833;&#65288;&#22914;&#38128;&#38142;&#25439;&#22833;&#65289;&#65292;&#30011;&#38754;&#20173;&#28982;&#27169;&#31946;&#19981;&#28165;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26426;&#21046;&#26469;&#33719;&#24471;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30740;&#31350;&#20854;&#29992;&#20110;SVM&#30340;&#24773;&#20917;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;SVM&#21487;&#20197;&#23637;&#29616;&#20986;&#25351;&#25968;&#32423;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21363;&#20351;&#27809;&#26377;&#20551;&#35774;&#30828;Tsybakov&#36793;&#38469;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification is often the first problem described in introductory machine learning classes. Generalization guarantees of classification have historically been offered by Vapnik-Chervonenkis theory. Yet those guarantees are based on intractable algorithms, which has led to the theory of surrogate methods in classification. Guarantees offered by surrogate methods are based on calibration inequalities, which have been shown to be highly sub-optimal under some margin conditions, failing short to capture exponential convergence phenomena. Those "super" fast rates are becoming to be well understood for smooth surrogates, but the picture remains blurry for non-smooth losses such as the hinge loss, associated with the renowned support vector machines. In this paper, we present a simple mechanism to obtain fast convergence rates and we investigate its usage for SVM. In particular, we show that SVM can exhibit exponential convergence rates even without assuming the hard Tsybakov margin conditi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22806;&#37096;&#26377;&#25928;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#27835;&#30103;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#23545;&#31574;&#30053;&#26222;&#36866;&#24615;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2205.05561</link><description>&lt;p&gt;
&#22806;&#37096;&#26377;&#25928;&#30340;&#31574;&#30053;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Choice. (arXiv:2205.05561v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22806;&#37096;&#26377;&#25928;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#27835;&#30103;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#23545;&#31574;&#30053;&#26222;&#36866;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#31574;&#30053;&#26159;&#22806;&#37096;&#26377;&#25928;&#25110;&#24191;&#20041;&#21270;&#30340;&#65306;&#23427;&#20204;&#22312;&#38500;&#20102;&#23454;&#39564;&#65288;&#25110;&#35757;&#32451;&#65289;&#20154;&#32676;&#22806;&#30340;&#20854;&#20182;&#30446;&#26631;&#20154;&#32676;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#23545;&#20110;&#23454;&#39564;&#20154;&#32676;&#32780;&#35328;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#65288;&#20294;&#19981;&#26159;&#29305;&#24449;&#65289;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#26679;&#20570;&#26102;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#22914;&#20309;&#24433;&#21709;&#31574;&#30053;&#30340;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#23454;&#39564;&#25110;&#35266;&#23519;&#25968;&#25454;&#65288;&#20854;&#20013;&#27835;&#30103;&#26159;&#20869;&#29983;&#30340;&#65289;&#12290;&#25105;&#20204;&#30340;&#35768;&#22810;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning personalized treatment policies that are externally valid or generalizable: they perform well in other target populations besides the experimental (or training) population from which data are sampled. We first show that welfare-maximizing policies for the experimental population are robust to shifts in the distribution of outcomes (but not characteristics) between the experimental and target populations. We then develop new methods for learning policies that are robust to shifts in outcomes and characteristics. In doing so, we highlight how treatment effect heterogeneity within the experimental population affects the generalizability of policies. Our methods may be used with experimental or observational data (where treatment is endogenous). Many of our methods can be implemented with linear programming.
&lt;/p&gt;</description></item></channel></rss>