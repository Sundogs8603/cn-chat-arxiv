<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;</title><link>https://arxiv.org/abs/2403.20200</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#23725;&#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional analysis of ridge regression for non-identically distributed data with a variance profile
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20200
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#36817;&#20110;&#38646;&#26102;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#21452;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#29420;&#31435;&#20294;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#30740;&#31350;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#12290;&#20551;&#35774;&#35266;&#27979;&#21040;&#30340;&#39044;&#27979;&#21464;&#37327;&#38598;&#21512;&#26159;&#24102;&#26377;&#26041;&#24046;&#36718;&#24275;&#30340;&#38543;&#26426;&#30697;&#38453;&#65292;&#24182;&#19988;&#20854;&#32500;&#24230;&#20197;&#30456;&#24212;&#36895;&#29575;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#38543;&#26426;&#25928;&#24212;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#36825;&#31181;&#26041;&#24046;&#36718;&#24275;&#30340;&#23725;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#39044;&#27979;&#39118;&#38505;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35813;&#39118;&#38505;&#30340;&#30830;&#23450;&#24615;&#31561;&#20215;&#29289;&#20197;&#21450;&#23725;&#20272;&#35745;&#22120;&#30340;&#33258;&#30001;&#24230;&#12290;&#23545;&#20110;&#26576;&#20123;&#26041;&#24046;&#36718;&#24275;&#31867;&#21035;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#31361;&#20986;&#20102;&#22312;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#20110;&#38646;&#26102;&#65292;&#39640;&#32500;&#22238;&#24402;&#20013;&#30340;&#26368;&#23567;&#27169;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#20986;&#29616;&#21452;&#35895;&#29616;&#35937;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#20123;&#26041;&#24046;&#36718;&#24275;f...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20200v1 Announce Type: cross  Abstract: High-dimensional linear regression has been thoroughly studied in the context of independent and identically distributed data. We propose to investigate high-dimensional regression models for independent but non-identically distributed data. To this end, we suppose that the set of observed predictors (or features) is a random matrix with a variance profile and with dimensions growing at a proportional rate. Assuming a random effect model, we study the predictive risk of the ridge estimator for linear regression with such a variance profile. In this setting, we provide deterministic equivalents of this risk and of the degree of freedom of the ridge estimator. For certain class of variance profile, our work highlights the emergence of the well-known double descent phenomenon in high-dimensional regression for the minimum norm least-squares estimator when the ridge regularization parameter goes to zero. We also exhibit variance profiles f
&lt;/p&gt;</description></item><item><title>&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#25918;&#23485;&#25110;&#29978;&#33267;&#22312;&#25490;&#38500;&#25152;&#26377;&#30456;&#20851;&#39118;&#38505;&#22240;&#32032;&#34987;&#35266;&#27979;&#21040;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#32473;&#20986;&#23545;&#39640;&#39118;&#38505;&#20010;&#20307;&#20998;&#37197;&#29575;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.14713</link><description>&lt;p&gt;
&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#22240;&#32032;&#19979;&#23457;&#35745;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Auditing Fairness under Unobserved Confounding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14713
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#25918;&#23485;&#25110;&#29978;&#33267;&#22312;&#25490;&#38500;&#25152;&#26377;&#30456;&#20851;&#39118;&#38505;&#22240;&#32032;&#34987;&#35266;&#27979;&#21040;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#32473;&#20986;&#23545;&#39640;&#39118;&#38505;&#20010;&#20307;&#20998;&#37197;&#29575;&#30340;&#20449;&#24687;&#20016;&#23500;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#31995;&#32479;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#36328;&#36234;&#20154;&#21475;&#32479;&#35745;&#32447;&#23384;&#22312;&#19981;&#20844;&#24179;&#24615;&#12290;&#28982;&#32780;&#65292;&#19981;&#20844;&#24179;&#24615;&#21487;&#33021;&#38590;&#20197;&#37327;&#21270;&#65292;&#29305;&#21035;&#26159;&#22914;&#26524;&#25105;&#20204;&#23545;&#20844;&#24179;&#24615;&#30340;&#29702;&#35299;&#20381;&#36182;&#20110;&#38590;&#20197;&#34913;&#37327;&#30340;&#39118;&#38505;&#31561;&#35266;&#24565;&#65288;&#20363;&#22914;&#65292;&#23545;&#20110;&#37027;&#20123;&#27809;&#26377;&#20854;&#27835;&#30103;&#23601;&#20250;&#27515;&#20129;&#30340;&#20154;&#24179;&#31561;&#33719;&#24471;&#27835;&#30103;&#65289;&#12290;&#23457;&#35745;&#36825;&#31181;&#19981;&#20844;&#24179;&#24615;&#38656;&#35201;&#20934;&#30830;&#27979;&#37327;&#20010;&#20307;&#39118;&#38505;&#65292;&#32780;&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#30340;&#29616;&#23454;&#29615;&#22659;&#20013;&#65292;&#38590;&#20197;&#20272;&#35745;&#12290;&#22312;&#36825;&#20123;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#32032;&#8220;&#35299;&#37322;&#8221;&#26126;&#26174;&#24046;&#24322;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#33021;&#20302;&#20272;&#25110;&#39640;&#20272;&#19981;&#20844;&#24179;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#25918;&#23485;&#25110;&#65288;&#20196;&#20154;&#24778;&#35766;&#22320;&#65289;&#29978;&#33267;&#22312;&#25490;&#38500;&#25152;&#26377;&#30456;&#20851;&#39118;&#38505;&#22240;&#32032;&#34987;&#35266;&#27979;&#21040;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#23545;&#39640;&#39118;&#38505;&#20010;&#20307;&#30340;&#20998;&#37197;&#29575;&#32473;&#20986;&#20449;&#24687;&#20016;&#23500;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#21033;&#29992;&#20102;&#22312;&#35768;&#22810;&#23454;&#38469;&#29615;&#22659;&#20013;&#65288;&#20363;&#22914;&#24341;&#20837;&#26032;&#22411;&#27835;&#30103;&#65289;&#25105;&#20204;&#25317;&#26377;&#22312;&#20219;&#20309;&#20998;&#37197;&#20043;&#21069;&#30340;&#25968;&#25454;&#30340;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14713v1 Announce Type: cross  Abstract: A fundamental problem in decision-making systems is the presence of inequity across demographic lines. However, inequity can be difficult to quantify, particularly if our notion of equity relies on hard-to-measure notions like risk (e.g., equal access to treatment for those who would die without it). Auditing such inequity requires accurate measurements of individual risk, which is difficult to estimate in the realistic setting of unobserved confounding. In the case that these unobservables "explain" an apparent disparity, we may understate or overstate inequity. In this paper, we show that one can still give informative bounds on allocation rates among high-risk individuals, even while relaxing or (surprisingly) even when eliminating the assumption that all relevant risk factors are observed. We utilize the fact that in many real-world settings (e.g., the introduction of a novel treatment) we have data from a period prior to any alloc
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#20998;&#26512;&#20102;&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#36827;&#34892;&#21338;&#24328;&#26469;&#25214;&#21040;&#19968;&#31181;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.07314</link><description>&lt;p&gt;
&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;KL&#27491;&#21017;&#21270;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of Nash Learning from Human Feedback under General KL-Regularized Preference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#20998;&#26512;&#20102;&#19968;&#31181;&#20851;&#20110;&#19968;&#33324;&#20559;&#22909;&#19979;&#32435;&#20160;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#36827;&#34892;&#21338;&#24328;&#26469;&#25214;&#21040;&#19968;&#31181;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#20174;&#19968;&#20010;&#27010;&#29575;&#20559;&#22909;&#27169;&#22411;&#25552;&#20379;&#30340;&#20559;&#22909;&#20449;&#21495;&#20013;&#23398;&#20064;&#65292;&#35813;&#27169;&#22411;&#20197;&#19968;&#20010;&#25552;&#31034;&#21644;&#20004;&#20010;&#21709;&#24212;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#20135;&#29983;&#19968;&#20010;&#20998;&#25968;&#65292;&#34920;&#31034;&#23545;&#19968;&#20010;&#21709;&#24212;&#30456;&#23545;&#20110;&#21478;&#19968;&#20010;&#21709;&#24212;&#30340;&#20559;&#22909;&#31243;&#24230;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#26368;&#27969;&#34892;&#30340;RLHF&#33539;&#24335;&#26159;&#22522;&#20110;&#22870;&#21169;&#30340;&#65292;&#23427;&#20174;&#22870;&#21169;&#24314;&#27169;&#30340;&#21021;&#22987;&#27493;&#39588;&#24320;&#22987;&#65292;&#28982;&#21518;&#20351;&#29992;&#26500;&#24314;&#30340;&#22870;&#21169;&#20026;&#21518;&#32493;&#30340;&#22870;&#21169;&#20248;&#21270;&#38454;&#27573;&#25552;&#20379;&#22870;&#21169;&#20449;&#21495;&#12290;&#28982;&#32780;&#65292;&#22870;&#21169;&#20989;&#25968;&#30340;&#23384;&#22312;&#26159;&#19968;&#20010;&#24378;&#20551;&#35774;&#65292;&#22522;&#20110;&#22870;&#21169;&#30340;RLHF&#22312;&#34920;&#36798;&#33021;&#21147;&#19978;&#26377;&#23616;&#38480;&#24615;&#65292;&#19981;&#33021;&#25429;&#25417;&#21040;&#30495;&#23454;&#19990;&#30028;&#20013;&#22797;&#26434;&#30340;&#20154;&#31867;&#20559;&#22909;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;&#26368;&#36817;&#25552;&#20986;&#30340;&#23398;&#20064;&#33539;&#24335;Nash&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#65288;NLHF&#65289;&#25552;&#20379;&#20102;&#29702;&#35770;&#27934;&#23519;&#21147;&#65292;&#35813;&#23398;&#20064;&#33539;&#24335;&#32771;&#34385;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#24182;&#23558;&#23545;&#40784;&#36807;&#31243;&#23450;&#20041;&#20026;&#20004;&#20010;&#31454;&#20105;&#30340;LLM&#20043;&#38388;&#30340;&#21338;&#24328;&#12290;&#23398;&#20064;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#19968;&#33268;&#29983;&#25104;&#21709;&#24212;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback (RLHF) learns from the preference signal provided by a probabilistic preference model, which takes a prompt and two responses as input, and produces a score indicating the preference of one response against another. So far, the most popular RLHF paradigm is reward-based, which starts with an initial step of reward modeling, and the constructed reward is then used to provide a reward signal for the subsequent reward optimization stage. However, the existence of a reward function is a strong assumption and the reward-based RLHF is limited in expressivity and cannot capture the real-world complicated human preference.   In this work, we provide theoretical insights for a recently proposed learning paradigm, Nash learning from human feedback (NLHF), which considered a general preference model and formulated the alignment process as a game between two competitive LLMs. The learning objective is to find a policy that consistently generates responses
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#37319;&#29992;dropout&#25216;&#26415;&#30340;&#32479;&#35745;&#34892;&#20026;&#20855;&#26377;&#26356;&#21152;&#24494;&#22937;&#30340;&#19982;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#32852;&#31995;&#65292;dropout&#24182;&#19981;&#20687;&#39044;&#26399;&#20013;&#37027;&#26679;&#20855;&#26377;&#31283;&#23450;&#30340;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10529</link><description>&lt;p&gt;
&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;Dropout&#27491;&#21017;&#21270;&#19982;$\ell_2$-Penalization&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Dropout Regularization Versus $\ell_2$-Penalization in the Linear Model. (arXiv:2306.10529v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10529
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#37319;&#29992;dropout&#25216;&#26415;&#30340;&#32479;&#35745;&#34892;&#20026;&#20855;&#26377;&#26356;&#21152;&#24494;&#22937;&#30340;&#19982;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#32852;&#31995;&#65292;dropout&#24182;&#19981;&#20687;&#39044;&#26399;&#20013;&#37027;&#26679;&#20855;&#26377;&#31283;&#23450;&#30340;&#27491;&#21017;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#37319;&#29992;dropout&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25512;&#23548;&#20102;&#36845;&#20195;&#30340;&#26399;&#26395;&#21644;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#38750;&#28176;&#36817;&#24615;&#30028;&#38480;&#12290;&#19982;&#25991;&#29486;&#20013;&#24191;&#27867;&#24341;&#29992;&#30340;dropout&#19982;$\ell_2$&#27491;&#21017;&#21270;&#30340;&#26399;&#26395;&#32852;&#31995;&#19981;&#21516;&#30340;&#26159;&#65292;&#32467;&#26524;&#34920;&#26126;&#20102;&#30001;&#20110;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#19982;dropout&#24341;&#20837;&#30340;&#38468;&#21152;&#38543;&#26426;&#24615;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20004;&#32773;&#20043;&#38388;&#23384;&#22312;&#30528;&#26356;&#21152;&#24494;&#22937;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#31181;&#31616;&#21270;&#29256;&#30340;dropout&#65292;&#23427;&#19981;&#20855;&#26377;&#27491;&#21017;&#21270;&#20316;&#29992;&#65292;&#24182;&#25910;&#25947;&#20110;&#26368;&#23567;&#24179;&#26041;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the statistical behavior of gradient descent iterates with dropout in the linear regression model. In particular, non-asymptotic bounds for expectations and covariance matrices of the iterates are derived. In contrast with the widely cited connection between dropout and $\ell_2$-regularization in expectation, the results indicate a much more subtle relationship, owing to interactions between the gradient descent dynamics and the additional randomness induced by dropout. We also study a simplified variant of dropout which does not have a regularizing effect and converges to the least squares estimator.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25554;&#20540;&#20219;&#20309;&#25968;&#25454;&#38598;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#20840;&#23616;&#26368;&#23567;&#20540;&#20026;&#38646;&#30340;&#24615;&#36136;&#65292;&#27492;&#22806;&#36824;&#32473;&#20986;&#20102;&#35813;&#20840;&#23616;&#26368;&#23567;&#20540;&#22788;&#30340;&#24815;&#24615;&#30697;&#38453;&#30340;&#34920;&#24449;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#26469;&#23547;&#25214;&#25554;&#20540;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.10552</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Interpolation property of shallow neural networks. (arXiv:2304.10552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25554;&#20540;&#20219;&#20309;&#25968;&#25454;&#38598;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#20840;&#23616;&#26368;&#23567;&#20540;&#20026;&#38646;&#30340;&#24615;&#36136;&#65292;&#27492;&#22806;&#36824;&#32473;&#20986;&#20102;&#35813;&#20840;&#23616;&#26368;&#23567;&#20540;&#22788;&#30340;&#24815;&#24615;&#30697;&#38453;&#30340;&#34920;&#24449;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#26469;&#23547;&#25214;&#25554;&#20540;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#20989;&#25968;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#20960;&#20309;&#24615;&#36136;&#12290;&#22312;&#22823;&#22810;&#25968;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#25439;&#22833;&#20989;&#25968;&#26159;&#20984;&#20989;&#25968;&#65292;&#36825;&#31181;&#24773;&#20917;&#19979;&#25105;&#20204;&#21482;&#26377;&#19968;&#20010;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#25110;&#32773;&#26159;&#38750;&#20984;&#20989;&#25968;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25105;&#20204;&#26377;&#19968;&#20010;&#26377;&#38480;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36229;&#21442;&#25968;&#21270;&#33539;&#22260;&#20869;&#65292;&#23545;&#20110;&#38750;&#23567;&#27425;&#25968;&#22810;&#39033;&#24335;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#25554;&#20540;&#20219;&#20309;&#25968;&#25454;&#38598;&#65292;&#21363;&#25439;&#22833;&#20989;&#25968;&#20855;&#26377;&#20840;&#23616;&#26368;&#23567;&#20540;&#20026;&#38646;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#23384;&#22312;&#36825;&#26679;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#21017;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#36718;&#24275;&#26377;&#26080;&#31351;&#22810;&#20010;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#22312;&#20840;&#23616;&#26368;&#23567;&#20540;&#22788;&#27714;&#35299;&#25439;&#22833;&#20989;&#25968;&#30340;&#28023;&#22622;&#30697;&#38453;&#30340;&#34920;&#24449;&#65292;&#24182;&#22312;&#26368;&#21518;&#19968;&#33410;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#26469;&#23547;&#25214;&#25554;&#20540;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the geometry of global minima of the loss landscape of overparametrized neural networks. In most optimization problems, the loss function is convex, in which case we only have a global minima, or nonconvex, with a discrete number of global minima. In this paper, we prove that in the overparametrized regime, a shallow neural network can interpolate any data set, i.e. the loss function has a global minimum value equal to zero as long as the activation function is not a polynomial of small degree. Additionally, if such a global minimum exists, then the locus of global minima has infinitely many points. Furthermore, we give a characterization of the Hessian of the loss function evaluated at the global minima, and in the last section, we provide a practical probabilistic method of finding the interpolation point.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;Bagging&#25216;&#26415;&#21487;&#25552;&#20379;&#26080;&#20559;&#24046;&#31283;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#20998;&#24067;&#21644;&#31639;&#27861;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.12600</link><description>&lt;p&gt;
Bagging&#25552;&#20379;&#26080;&#20559;&#24046;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bagging Provides Assumption-free Stability. (arXiv:2301.12600v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Bagging&#25216;&#26415;&#21487;&#25552;&#20379;&#26080;&#20559;&#24046;&#31283;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#20998;&#24067;&#21644;&#31639;&#27861;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Bagging&#26159;&#31283;&#23450;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#19968;&#20010;&#37325;&#35201;&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#20219;&#20309;&#27169;&#22411;&#30340;&#31283;&#23450;&#24615;&#25512;&#23548;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#23545;&#25968;&#25454;&#20998;&#24067;&#12289;&#22522;&#26412;&#31639;&#27861;&#30340;&#23646;&#24615;&#25110;&#21327;&#21464;&#37327;&#30340;&#32500;&#25968;&#36827;&#34892;&#20219;&#20309;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#36866;&#29992;&#20110;&#22810;&#31181;&#21464;&#20307;&#30340;Bagging&#65292;&#24182;&#19988;&#26159;&#26368;&#20248;&#30340;&#24120;&#25968;&#12290;&#23454;&#35777;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#34920;&#26126;Bagging&#25104;&#21151;&#31283;&#23450;&#20102;&#21363;&#20351;&#26159;&#39640;&#24230;&#19981;&#31283;&#23450;&#30340;&#22522;&#26412;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bagging is an important technique for stabilizing machine learning models. In this paper, we derive a finite-sample guarantee on the stability of bagging for any model. Our result places no assumptions on the distribution of the data, on the properties of the base algorithm, or on the dimensionality of the covariates. Our guarantee applies to many variants of bagging and is optimal up to a constant. Empirical results validate our findings, showing that bagging successfully stabilizes even highly unstable base algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#21644;&#25512;&#26029;&#26102;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.04900</link><description>&lt;p&gt;
&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Recipe for Well-behaved Graph Neural Approximations of Complex Dynamics. (arXiv:2301.04900v2 [cond-mat.stat-mech] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34892;&#20026;&#33391;&#22909;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#22797;&#26434;&#21160;&#21147;&#23398;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#21644;&#25512;&#26029;&#26102;&#39044;&#27979;&#32622;&#20449;&#24230;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#36817;&#20284;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#26469;&#21457;&#29616;&#21160;&#21147;&#31995;&#32479;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#32570;&#20047;&#26126;&#30830;&#21407;&#29702;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#26412;&#25991;&#30528;&#37325;&#30740;&#31350;&#20102;&#19968;&#31867;&#30001;&#32593;&#32476;&#37051;&#25509;&#30697;&#38453;&#32806;&#21512;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#25551;&#36848;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#31995;&#32479;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#31038;&#20132;&#21644;&#31070;&#32463;&#31995;&#32479;&#65292;&#23646;&#20110;&#36825;&#31867;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#36825;&#31181;&#21160;&#21147;&#31995;&#32479;&#30340;&#20851;&#38190;&#35201;&#32032;&#65292;&#21253;&#25324;&#24517;&#35201;&#30340;&#20559;&#32622;&#21644;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#24378;&#35843;&#19982;&#38745;&#24577;&#30417;&#30563;&#23398;&#20064;&#30340;&#21306;&#21035;&#65292;&#25105;&#20204;&#25552;&#20513;&#22312;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#32463;&#20856;&#20551;&#35774;&#20043;&#22806;&#35780;&#20272;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#22312;&#25512;&#26029;&#26102;&#20272;&#35745;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#19987;&#29992;&#30340;&#31354;&#27169;&#22411;&#12290;&#36890;&#36807;&#30740;&#31350;&#21508;&#31181;&#22797;&#26434;&#32593;&#32476;&#21160;&#21147;&#23398;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven approximations of ordinary differential equations offer a promising alternative to classical methods in discovering a dynamical system model, particularly in complex systems lacking explicit first principles. This paper focuses on a complex system whose dynamics is described with a system of ordinary differential equations, coupled via a network adjacency matrix. Numerous real-world systems, including financial, social, and neural systems, belong to this class of dynamical models. We propose essential elements for approximating such dynamical systems using neural networks, including necessary biases and an appropriate neural architecture. Emphasizing the differences from static supervised learning, we advocate for evaluating generalization beyond classical assumptions of statistical learning theory. To estimate confidence in prediction during inference time, we introduce a dedicated null model. By studying various complex network dynamics, we demonstrate the neural network'
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#27979;&#26469;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2206.09821</link><description>&lt;p&gt;
&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#29992;&#20110;&#26174;&#33879;&#27874;&#39640;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Exceedance Probability Forecasting via Regression for Significant Wave Height Prediction. (arXiv:2206.09821v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#27979;&#26469;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26174;&#33879;&#27874;&#39640;&#39044;&#27979;&#26159;&#28023;&#27915;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#23545;&#20110;&#20272;&#35745;&#27874;&#33021;&#20135;&#29983;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#27492;&#22806;&#65292;&#21450;&#26102;&#39044;&#27979;&#22823;&#28010;&#30340;&#21040;&#26469;&#23545;&#20110;&#30830;&#20445;&#33322;&#28023;&#20316;&#19994;&#30340;&#23433;&#20840;&#24456;&#37325;&#35201;&#12290;&#25105;&#20204;&#23558;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#30340;&#26497;&#31471;&#20540;&#20316;&#20026;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#20272;&#35745;&#26174;&#33879;&#27874;&#39640;&#23558;&#36229;&#36807;&#39044;&#23450;&#20041;&#38408;&#20540;&#30340;&#27010;&#29575;&#12290;&#36890;&#24120;&#20351;&#29992;&#27010;&#29575;&#20108;&#20998;&#31867;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#26410;&#26469;&#35266;&#27979;&#30340;&#39044;&#27979;&#26469;&#26681;&#25454;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#12290;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#21152;&#25343;&#22823;&#21704;&#21033;&#27861;&#20811;&#26031;&#28023;&#23736;&#30340;&#28014;&#26631;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Significant wave height forecasting is a key problem in ocean data analytics. Predicting the significant wave height is crucial for estimating the energy production from waves. Moreover, the timely prediction of large waves is important to ensure the safety of maritime operations, e.g. passage of vessels. We frame the task of predicting extreme values of significant wave height as an exceedance probability forecasting problem. Accordingly, we aim at estimating the probability that the significant wave height will exceed a predefined threshold. This task is usually solved using a probabilistic binary classification model. Instead, we propose a novel approach based on a forecasting model. The method leverages the forecasts for the upcoming observations to estimate the exceedance probability according to the cumulative distribution function. We carried out experiments using data from a buoy placed in the coast of Halifax, Canada. The results suggest that the proposed methodology is better
&lt;/p&gt;</description></item></channel></rss>