<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;&#23427;&#20855;&#26377;&#27604;&#20004;&#23618;&#32593;&#32476;&#26356;&#20016;&#23500;&#30340;&#21487;&#35777;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23450;&#29702;&#65292;&#38480;&#21046;&#20102;&#30446;&#26631;&#32467;&#26500;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#23485;&#24230;&#65292;&#20197;&#23454;&#29616;&#20302;&#27979;&#35797;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.06986</link><description>&lt;p&gt;
&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38750;&#32447;&#24615;&#29305;&#24449;&#23398;&#20064;&#30340;&#21487;&#35777;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks. (arXiv:2305.06986v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;&#23427;&#20855;&#26377;&#27604;&#20004;&#23618;&#32593;&#32476;&#26356;&#20016;&#23500;&#30340;&#21487;&#35777;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23450;&#29702;&#65292;&#38480;&#21046;&#20102;&#30446;&#26631;&#32467;&#26500;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#23485;&#24230;&#65292;&#20197;&#23454;&#29616;&#20302;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#23398;&#20064;&#20998;&#23618;&#29305;&#24449;&#12290;&#28145;&#24230;&#32593;&#32476;&#25552;&#21462;&#26174;&#33879;&#29305;&#24449;&#30340;&#33021;&#21147;&#23545;&#20854;&#21331;&#36234;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#33539;&#24335;&#30340;&#39044;&#35757;&#32451;&#21644;&#24494;&#35843;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20174;&#29702;&#35770;&#35282;&#24230;&#26469;&#30475;&#65292;&#36825;&#31181;&#29305;&#24449;&#23398;&#20064;&#36807;&#31243;&#20173;&#28982;&#19981;&#22815;&#28165;&#26224;&#65292;&#29616;&#26377;&#30340;&#20998;&#26512;&#20027;&#35201;&#23616;&#38480;&#20110;&#20004;&#23618;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19977;&#23618;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#35777;&#26126;&#30340;&#27604;&#20004;&#23618;&#32593;&#32476;&#26356;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36890;&#36807;&#36880;&#23618;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#19977;&#23618;&#32593;&#32476;&#23398;&#20064;&#30340;&#29305;&#24449;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#23450;&#29702;&#65292;&#23427;&#19978;&#30028;&#20102;&#30446;&#26631;&#20855;&#26377;&#29305;&#23450;&#23618;&#27425;&#32467;&#26500;&#26102;&#23454;&#29616;&#20302;&#27979;&#35797;&#38169;&#35823;&#25152;&#38656;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#23485;&#24230;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#20363;&#21270;&#21040;&#29305;&#23450;&#30340;&#32479;&#35745;&#23398;&#23398;&#20064;&#35774;&#32622;&#20013;&#8212;&#8212;&#21333;&#25351;&#25968;&#27169;&#22411;&#21644;&#20108;&#27425;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the central questions in the theory of deep learning is to understand how neural networks learn hierarchical features. The ability of deep networks to extract salient features is crucial to both their outstanding generalization ability and the modern deep learning paradigm of pretraining and finetuneing. However, this feature learning process remains poorly understood from a theoretical perspective, with existing analyses largely restricted to two-layer networks. In this work we show that three-layer neural networks have provably richer feature learning capabilities than two-layer networks. We analyze the features learned by a three-layer network trained with layer-wise gradient descent, and present a general purpose theorem which upper bounds the sample complexity and width needed to achieve low test error when the target has specific hierarchical structure. We instantiate our framework in specific statistical learning settings -- single-index models and functions of quadratic 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#27010;&#29575;&#22320;&#20174;&#38750;&#20856;&#22411;&#38543;&#26426;&#21021;&#22987;&#21270;&#36798;&#21040;&#19968;&#20010;$\epsilon$-&#26368;&#20248;&#30697;&#38453;&#20998;&#35299;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#21021;&#22987;&#21270;&#19981;&#20165;&#22312;&#29702;&#35770;&#19978;&#26377;&#30410;&#65292;&#32780;&#19988;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.06927</link><description>&lt;p&gt;
&#30697;&#38453;&#20998;&#35299;&#20013;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of Alternating Gradient Descent for Matrix Factorization. (arXiv:2305.06927v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#27010;&#29575;&#22320;&#20174;&#38750;&#20856;&#22411;&#38543;&#26426;&#21021;&#22987;&#21270;&#36798;&#21040;&#19968;&#20010;$\epsilon$-&#26368;&#20248;&#30697;&#38453;&#20998;&#35299;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#21021;&#22987;&#21270;&#19981;&#20165;&#22312;&#29702;&#35770;&#19978;&#26377;&#30410;&#65292;&#32780;&#19988;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#24212;&#29992;&#20110;&#19981;&#23545;&#31216;&#30697;&#38453;&#20998;&#35299;&#30446;&#26631;&#30340;&#20855;&#26377;&#22266;&#23450;&#27493;&#38271;$\eta&gt;0$&#30340;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#65288;AGD&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#23545;&#20110;&#31209;&#20026;$r$&#30340;&#30697;&#38453;$\mathbf {A}\in \mathbb {R} ^ {m \times n}$&#65292;$T=\left(\left(\frac{\sigma_1(\mathbf{A})}{\sigma_r(\mathbf{A})}\right)^2\log(1/\epsilon)\right)$&#27425;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#21363;&#21487;&#20174;&#38750;&#20856;&#22411;&#38543;&#26426;&#21021;&#22987;&#21270;&#39640;&#27010;&#29575;&#22320;&#36798;&#21040;$\epsilon$-&#26368;&#20248;&#20998;&#35299;$\|\mathbf {A}\mathbf {X}_T^{\vphantom{\intercal}}\mathbf {Y}_T^{\intercal}\|_{\rm F}^2\le\epsilon\|\mathbf {A}\|_{\rm F}^2$&#12290;&#20998;&#35299;&#20013;&#22240;&#23376;&#30340;&#31209;&#20026;$d&gt;r$&#65292;&#22240;&#27492;$\mathbf{X}_T\in\mathbb{R}^{m \times d}$&#19988;$\mathbf{Y}_T\in\mathbb{R}^{n \times d}$&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#21021;&#22987;&#21270;&#19981;&#20165;&#22312;&#29702;&#35770;&#19978;&#26377;&#30410;&#65292;&#32780;&#19988;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65306;&#19968;&#33268;&#30340;PL&#19981;&#31561;&#24335;&#21644;&#19968;&#33268;&#30340;Lipschitz&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider alternating gradient descent (AGD) with fixed step size $\eta &gt; 0$, applied to the asymmetric matrix factorization objective. We show that, for a rank-$r$ matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$, $T = \left( \left(\frac{\sigma_1(\mathbf{A})}{\sigma_r(\mathbf{A})}\right)^2 \log(1/\epsilon)\right)$ iterations of alternating gradient descent suffice to reach an $\epsilon$-optimal factorization $\| \mathbf{A} \mathbf{X}_T^{\vphantom{\intercal}} \mathbf{Y}_T^{\intercal} \|_{\rm F}^2 \leq \epsilon \| \mathbf{A} \|_{\rm F}^2$ with high probability starting from an atypical random initialization. The factors have rank $d&gt;r$ so that $\mathbf{X}_T\in\mathbb{R}^{m \times d}$ and $\mathbf{Y}_T \in\mathbb{R}^{n \times d}$. Experiments suggest that our proposed initialization is not merely of theoretical benefit, but rather significantly improves convergence of gradient descent in practice. Our proof is conceptually simple: a uniform PL-inequality and uniform Lipschitz smoothne
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#25552;&#20986;&#23558;&#22240;&#26524;&#21457;&#29616;&#35270;&#20026;&#39044;&#27979;&#26410;&#35266;&#23519;&#21040;&#32852;&#21512;&#32479;&#35745;&#37327;&#30340;&#20219;&#21153;&#65292;&#36825;&#26679;&#21487;&#20197;&#26356;&#22909;&#22320;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#38598;&#21512;&#30340;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.06894</link><description>&lt;p&gt;
&#23558;&#22240;&#26524;&#21457;&#29616;&#37325;&#26032;&#35299;&#37322;&#20026;&#39044;&#27979;&#26410;&#35266;&#23519;&#21040;&#30340;&#32852;&#21512;&#32479;&#35745;&#37327;&#30340;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Reinterpreting causal discovery as the task of predicting unobserved joint statistics. (arXiv:2305.06894v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06894
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#25552;&#20986;&#23558;&#22240;&#26524;&#21457;&#29616;&#35270;&#20026;&#39044;&#27979;&#26410;&#35266;&#23519;&#21040;&#32852;&#21512;&#32479;&#35745;&#37327;&#30340;&#20219;&#21153;&#65292;&#36825;&#26679;&#21487;&#20197;&#26356;&#22909;&#22320;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#38598;&#21512;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;$X,Y,Z$&#34920;&#31034;&#38543;&#26426;&#21464;&#37327;&#38598;&#65292;&#19981;&#21516;&#30340;&#25968;&#25454;&#28304;&#21487;&#20197;&#21253;&#21547;$P_{X,Y}$&#21644;$P_{Y,Z}$&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#35748;&#20026;&#22240;&#26524;&#21457;&#29616;&#21487;&#20197;&#24110;&#21161;&#25512;&#26029;&#8220;&#26410;&#35266;&#23519;&#21040;&#30340;&#32852;&#21512;&#20998;&#24067;&#8221;$P_{X,Y,Z}$&#25110;$P_{X,Z}$&#30340;&#24615;&#36136;&#12290;&#36825;&#20123;&#24615;&#36136;&#21487;&#20197;&#26159;&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;&#22914;&#8220;&#25972;&#21512;&#22240;&#26524;&#25512;&#29702;&#8221;&#20013;&#37027;&#26679;&#65289;&#65292;&#20063;&#21487;&#20197;&#26159;&#20851;&#20110;&#20381;&#36182;&#24615;&#30340;&#23450;&#37327;&#35828;&#26126;&#12290;&#26356;&#19968;&#33324;&#22320;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#23398;&#20064;&#22330;&#26223;&#65292;&#20854;&#20013;&#36755;&#20837;&#26159;&#21464;&#37327;&#30340;&#23376;&#38598;&#65292;&#26631;&#31614;&#26159;&#35813;&#23376;&#38598;&#30340;&#26576;&#20123;&#32479;&#35745;&#23646;&#24615;&#12290;&#20849;&#21516;&#35266;&#27979;&#21464;&#37327;&#38598;&#23450;&#20041;&#20102;&#35757;&#32451;&#28857;&#65292;&#32780;&#26410;&#35266;&#23519;&#21040;&#30340;&#38598;&#21512;&#26159;&#21487;&#33021;&#30340;&#27979;&#35797;&#28857;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23398;&#20064;&#20219;&#21153;&#65292;&#25105;&#20204;&#20174;&#35266;&#23519;&#32467;&#26524;&#20013;&#25512;&#26029;&#20986;&#19968;&#20010;&#22240;&#26524;&#27169;&#22411;&#65292;&#36825;&#20010;&#22240;&#26524;&#27169;&#22411;&#21487;&#20197;&#24471;&#21040;&#26410;&#35266;&#23519;&#21040;&#38598;&#21512;&#30340;&#23646;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21487;&#20197;&#23450;&#20041;&#19968;&#20010;&#22240;&#26524;&#27169;&#22411;&#31867;&#30340;VC&#32500;&#65292;&#24182;&#20026;&#39044;&#27979;&#25512;&#23548;&#20986;&#27867;&#21270;&#30028;&#38480;&#12290;&#22240;&#27492;&#65292;&#22240;&#26524;&#21457;&#29616;&#21464;&#24471;&#26356;&#21152;&#35878;&#36874;&#21644;&#26131;&#20110;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
If $X,Y,Z$ denote sets of random variables, two different data sources may contain samples from $P_{X,Y}$ and $P_{Y,Z}$, respectively. We argue that causal discovery can help inferring properties of the `unobserved joint distributions' $P_{X,Y,Z}$ or $P_{X,Z}$. The properties may be conditional independences (as in `integrative causal inference') or also quantitative statements about dependences.  More generally, we define a learning scenario where the input is a subset of variables and the label is some statistical property of that subset. Sets of jointly observed variables define the training points, while unobserved sets are possible test points. To solve this learning task, we infer, as an intermediate step, a causal model from the observations that then entails properties of unobserved sets. Accordingly, we can define the VC dimension of a class of causal models and derive generalization bounds for the predictions.  Here, causal discovery becomes more modest and better accessible 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#26032;&#30340;&#21152;&#26435;&#25277;&#26679;&#20449;&#24515;&#24207;&#21015;&#65292;&#23545;N&#20010;&#26410;&#30693;&#20540;&#30340;&#21152;&#26435;&#24179;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#30340;&#39118;&#38505;&#38480;&#21046;&#36130;&#21153;&#23457;&#35745;&#65288;RLFA&#65289;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21512;&#24182;&#26410;&#30693;&#20540;&#30340;&#38468;&#21152;&#20449;&#24687;&#25552;&#39640;&#29983;&#25104;&#24207;&#21015;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#32622;&#20449;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.06884</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#26367;&#25442;&#21152;&#26435;&#25277;&#26679;&#36827;&#34892;&#39118;&#38505;&#38480;&#21046;&#36130;&#21153;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Risk-limiting Financial Audits via Weighted Sampling without Replacement. (arXiv:2305.06884v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#26032;&#30340;&#21152;&#26435;&#25277;&#26679;&#20449;&#24515;&#24207;&#21015;&#65292;&#23545;N&#20010;&#26410;&#30693;&#20540;&#30340;&#21152;&#26435;&#24179;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#30340;&#39118;&#38505;&#38480;&#21046;&#36130;&#21153;&#23457;&#35745;&#65288;RLFA&#65289;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21512;&#24182;&#26410;&#30693;&#20540;&#30340;&#38468;&#21152;&#20449;&#24687;&#25552;&#39640;&#29983;&#25104;&#24207;&#21015;&#30340;&#36136;&#37327;&#65292;&#20174;&#32780;&#25552;&#39640;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#39118;&#38505;&#38480;&#21046;&#36130;&#21153;&#23457;&#35745;&#65288;RLFA&#65289;&#30340;&#27010;&#24565;&#65306;&#22312;&#32473;&#23450;&#35823;&#24046;$\epsilon$&#21644;&#32622;&#20449;&#24230;$1-\delta$&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26500;&#24314;&#26032;&#30340;&#21152;&#26435;&#25277;&#26679;&#20449;&#24515;&#24207;&#21015;&#65288;CSs&#65289;&#65292;&#23545;$N$&#20010;&#26410;&#30693;&#20540;&#30340;&#21152;&#26435;&#24179;&#22343;&#20540;&#36827;&#34892;&#20272;&#35745;&#12290;&#25105;&#20204;&#21033;&#29992;&#37325;&#35201;&#26435;&#37325;&#30340;&#24819;&#27861;&#26500;&#24314;&#27979;&#35797;&#38789;&#65292;&#39318;&#20808;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20197;&#26500;&#24314;&#20219;&#24847;&#25277;&#26679;&#31574;&#30053;&#30340;CSs&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20123;&#26041;&#27861;&#26469;&#36890;&#36807;&#21512;&#24182;&#19982;&#27599;&#20010;&#39033;&#30446;&#20851;&#32852;&#30340;&#26410;&#30693;&#20540;&#30340;&#38468;&#21152;&#20449;&#24687;&#26469;&#25552;&#39640;CSs&#30340;&#36136;&#37327;&#12290;&#24403;&#38468;&#21152;&#20449;&#24687;&#36275;&#22815;&#20855;&#26377;&#39044;&#27979;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;&#23427;&#21487;&#20197;&#30452;&#25509;&#39537;&#21160;&#25277;&#26679;&#12290;&#23545;&#20110;&#31934;&#24230;&#26410;&#30693;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#36890;&#36807;&#25511;&#21046;&#21464;&#37327;&#20351;&#29992;&#38468;&#21152;&#20449;&#24687;&#30340;&#26041;&#27861;&#12290;&#20851;&#38190;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26500;&#24314;&#26159;&#33258;&#36866;&#24212;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the notion of a risk-limiting financial auditing (RLFA): given $N$ transactions, the goal is to estimate the total misstated monetary fraction~($m^*$) to a given accuracy $\epsilon$, with confidence $1-\delta$. We do this by constructing new confidence sequences (CSs) for the weighted average of $N$ unknown values, based on samples drawn without replacement according to a (randomized) weighted sampling scheme. Using the idea of importance weighting to construct test martingales, we first develop a framework to construct CSs for arbitrary sampling strategies. Next, we develop methods to improve the quality of CSs by incorporating side information about the unknown values associated with each item. We show that when the side information is sufficiently predictive, it can directly drive the sampling. Addressing the case where the accuracy is unknown a priori, we introduce a method that incorporates side information via control variates. Crucially, our construction is adaptive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21487;&#35270;&#21270;&#20219;&#20309;&#31070;&#32463;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#25152;&#20351;&#29992;&#30340;&#20013;&#38388;&#23884;&#20837;&#34920;&#31034;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#38170;&#23450;&#26041;&#21521;&#65292;&#21487;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#21644;&#21407;&#22987;&#36755;&#20837;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#12290;&#26412;&#25991;&#35828;&#26126;&#20102;&#22312;&#19968;&#20010;&#22522;&#20110;&#35282;&#24230;&#20449;&#24687;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#23384;&#22312;&#30340;&#20449;&#24687;&#20002;&#22833;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20943;&#23569;&#20449;&#24687;&#20002;&#22833;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06862</link><description>&lt;p&gt;
&#22522;&#20110;&#35282;&#24230;&#20449;&#24687;&#30340;&#31070;&#32463;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#23884;&#20837;&#31354;&#38388;&#21487;&#35270;&#21270;&#30340;&#36890;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A General Framework for Visualizing Embedding Spaces of Neural Survival Analysis Models Based on Angular Information. (arXiv:2305.06862v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#21487;&#35270;&#21270;&#20219;&#20309;&#31070;&#32463;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#25152;&#20351;&#29992;&#30340;&#20013;&#38388;&#23884;&#20837;&#34920;&#31034;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#38170;&#23450;&#26041;&#21521;&#65292;&#21487;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#21644;&#21407;&#22987;&#36755;&#20837;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#12290;&#26412;&#25991;&#35828;&#26126;&#20102;&#22312;&#19968;&#20010;&#22522;&#20110;&#35282;&#24230;&#20449;&#24687;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#23384;&#22312;&#30340;&#20449;&#24687;&#20002;&#22833;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#20943;&#23569;&#20449;&#24687;&#20002;&#22833;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#21487;&#35270;&#21270;&#31070;&#32463;&#29983;&#23384;&#20998;&#26512;&#27169;&#22411;&#25152;&#20351;&#29992;&#30340;&#20219;&#20309;&#20013;&#38388;&#23884;&#20837;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#23884;&#20837;&#31354;&#38388;&#20013;&#30340;&#25152;&#35859;&#38170;&#23450;&#26041;&#21521;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#32858;&#31867;&#25110;&#29992;&#25143;&#25552;&#20379;&#30340;&#8220;&#27010;&#24565;&#8221;&#26469;&#23450;&#20041;&#21407;&#22987;&#36755;&#20837;&#65288;&#20363;&#22914;&#65292;&#26469;&#33258;&#22899;&#24615;&#24739;&#32773;&#30340;&#29305;&#24449;&#21521;&#37327;&#21487;&#20197;&#32534;&#30721;&#8220;&#22899;&#24615;&#8221;&#27010;&#24565;&#65289;&#26469;&#20272;&#35745;&#36825;&#20123;&#38170;&#23450;&#26041;&#21521;&#12290;&#23545;&#20110;&#34920;&#26684;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21487;&#35270;&#21270;&#31574;&#30053;&#65292;&#20197;&#26174;&#31034;&#38170;&#23450;&#26041;&#21521;&#19982;&#21407;&#22987;&#20020;&#24202;&#29305;&#24449;&#21644;&#29983;&#23384;&#26102;&#38388;&#20998;&#24067;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#21487;&#35270;&#21270;&#24605;&#24819;&#22914;&#20309;&#25193;&#23637;&#21040;&#22788;&#29702;&#22270;&#20687;&#31561;&#21407;&#22987;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#26159;&#22522;&#20110;&#26597;&#30475;&#23884;&#20837;&#31354;&#38388;&#20013;&#21521;&#37327;&#20043;&#38388;&#30340;&#35282;&#24230;&#24314;&#31435;&#30340;&#65292;&#30001;&#20110;&#24573;&#30053;&#20102;&#24133;&#24230;&#20449;&#24687;&#32780;&#21487;&#33021;&#23384;&#22312;&#8220;&#20449;&#24687;&#20002;&#22833;&#8221;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23454;&#36341;&#20013;&#22914;&#20309;&#20943;&#23569;&#36825;&#31181;&#20449;&#24687;&#20002;&#22833;&#23548;&#33268;&#30340;&#8220;&#32858;&#38598;&#8221;&#20266;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general framework for visualizing any intermediate embedding representation used by any neural survival analysis model. Our framework is based on so-called anchor directions in an embedding space. We show how to estimate these anchor directions using clustering or, alternatively, using user-supplied "concepts" defined by collections of raw inputs (e.g., feature vectors all from female patients could encode the concept "female"). For tabular data, we present visualization strategies that reveal how anchor directions relate to raw clinical features and to survival time distributions. We then show how these visualization ideas extend to handling raw inputs that are images. Our framework is built on looking at angles between vectors in an embedding space, where there could be "information loss" by ignoring magnitude information. We show how this loss results in a "clumping" artifact that appears in our visualizations, and how to reduce this information loss in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#30340;&#26032;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#65292;&#21363;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#25351;&#20986;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25506;&#32034;&#30340;&#23454;&#36136;&#26159;&#35745;&#31639;&#24403;&#21069;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.06851</link><description>&lt;p&gt;
&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30340;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Algorithms Implicitly Optimize by Continuation. (arXiv:2305.06851v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#30340;&#26032;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#65292;&#21363;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36830;&#32493;&#26041;&#24335;&#38544;&#24335;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#65292;&#24182;&#25351;&#20986;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25506;&#32034;&#30340;&#23454;&#36136;&#26159;&#35745;&#31639;&#24403;&#21069;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#36890;&#24120;&#36890;&#36807;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#35299;&#20915;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#20248;&#21270;&#31574;&#30053;&#21442;&#25968;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#35299;&#37322;&#21644;&#35777;&#26126;&#36825;&#20123;&#31639;&#27861;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#30452;&#25509;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#24314;&#31435;&#22312;&#20248;&#21270;&#36830;&#32493;&#26694;&#26550;&#19979;&#12290;&#21518;&#32773;&#26159;&#19968;&#31181;&#29992;&#20110;&#20248;&#21270;&#38750;&#20984;&#20989;&#25968;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#20197;&#36830;&#32493;&#30340;&#26367;&#20195;&#30446;&#26631;&#20989;&#25968;&#24207;&#21015;&#20026;&#22522;&#30784;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#21270;&#20223;&#23556;&#39640;&#26031;&#31574;&#30053;&#24182;&#25191;&#34892;&#29109;&#27491;&#21017;&#21270;&#21487;&#20197;&#35299;&#37322;&#20026;&#36890;&#36807;&#36830;&#32493;&#38544;&#24335;&#22320;&#20248;&#21270;&#30830;&#23450;&#24615;&#31574;&#30053;&#12290;&#22522;&#20110;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35748;&#20026;&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#20013;&#30340;&#25506;&#32034;&#21253;&#25324;&#35745;&#31639;&#24403;&#21069;&#30340;&#31574;&#30053;&#25910;&#30410;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#31574;&#30053;&#30340;&#26041;&#24046;&#24212;&#35813;&#26159;&#21382;&#21490;&#20381;&#36182;&#24615;&#20989;&#25968;&#65292;&#20197;&#36991;&#20813;&#23616;&#37096;&#26368;&#20540;&#32780;&#19981;&#26159;&#20165;&#20165;&#26368;&#22823;&#21270;&#25919;&#31574;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Direct policy optimization in reinforcement learning is usually solved with policy-gradient algorithms, which optimize policy parameters via stochastic gradient ascent. This paper provides a new theoretical interpretation and justification of these algorithms. First, we formulate direct policy optimization in the optimization by continuation framework. The latter is a framework for optimizing nonconvex functions where a sequence of surrogate objective functions, called continuations, are locally optimized. Second, we show that optimizing affine Gaussian policies and performing entropy regularization can be interpreted as implicitly optimizing deterministic policies by continuation. Based on these theoretical results, we argue that exploration in policy-gradient algorithms consists in computing a continuation of the return of the policy at hand, and that the variance of policies should be history-dependent functions adapted to avoid local extrema rather than to maximize the return of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20449;&#24687;&#35774;&#35745;&#38382;&#39064;&#21450;&#20854;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#8220;&#39532;&#23572;&#31185;&#22827;&#20449;&#20196;&#21338;&#24328;&#8221;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2305.06807</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20449;&#24687;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Information Design in Multi-Agent Reinforcement Learning. (arXiv:2305.06807v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20449;&#24687;&#35774;&#35745;&#38382;&#39064;&#21450;&#20854;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#8220;&#39532;&#23572;&#31185;&#22827;&#20449;&#20196;&#21338;&#24328;&#8221;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#27169;&#20223;&#20154;&#31867;&#21644;&#21160;&#29289;&#19982;&#29615;&#22659;&#20132;&#20114;&#30340;&#26041;&#24335;&#12290;&#28982;&#32780;&#23454;&#38469;&#29615;&#22659;&#20013;&#23384;&#22312;&#20854;&#20182;&#26377;&#33258;&#24049;&#30446;&#26631;&#30340;&#26234;&#33021;&#20307;&#65292;&#23427;&#20204;&#20250;&#36866;&#24212;&#22320;&#19982;&#33258;&#24049;&#30456;&#20114;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22312;&#36825;&#20123;&#29615;&#22659;&#20013;&#25104;&#21151;&#65292;&#33258;&#20027;&#26234;&#33021;&#20307;&#38656;&#35201;&#24433;&#21709;&#20854;&#20182;&#26234;&#33021;&#20307;&#20197;&#20351;&#23427;&#20204;&#30340;&#34892;&#20026;&#26356;&#26377;&#30410;&#12290;&#20449;&#24687;&#35774;&#35745;&#26159;&#24433;&#21709;&#20854;&#20182;&#26234;&#33021;&#20307;&#34892;&#20026;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#38024;&#23545;&#19968;&#32452;RL&#20195;&#29702;&#30340;&#20449;&#24687;&#35774;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#8220;&#39532;&#23572;&#31185;&#22827;&#20449;&#20196;&#21338;&#24328;&#8221;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) mimics how humans and animals interact with the environment. The setting is somewhat idealized because, in actual tasks, other agents in the environment have their own goals and behave adaptively to the ego agent. To thrive in those environments, the agent needs to influence other agents so their actions become more helpful and less harmful. Research in computational economics distills two ways to influence others directly: by providing tangible goods (mechanism design) and by providing information (information design). This work investigates information design problems for a group of RL agents. The main challenges are two-fold. One is the information provided will immediately affect the transition of the agent trajectories, which introduces additional non-stationarity. The other is the information can be ignored, so the sender must provide information that the receivers are willing to respect. We formulate the Markov signaling game, and develop the notions 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;NNCI&#65292;&#29992;&#20110;&#23558;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#38598;&#25104;&#21040;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.06789</link><description>&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#38598;&#25104;&#26368;&#36817;&#37051;&#23621;&#20197;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Integrating nearest neighbors on neural network models for treatment effect estimation. (arXiv:2305.06789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;NNCI&#65292;&#29992;&#20110;&#23558;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#38598;&#25104;&#21040;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#23545;&#20110;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#19994;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#26469;&#35828;&#20855;&#26377;&#39640;&#24230;&#37325;&#35201;&#24615;&#12290;&#35266;&#23519;&#25968;&#25454;&#30340;&#20016;&#23500;&#24615;&#20351;&#23427;&#20204;&#36234;&#26469;&#36234;&#21463;&#21040;&#30740;&#31350;&#20154;&#21592;&#29992;&#20110;&#22240;&#26524;&#25928;&#24212;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#25454;&#23384;&#22312;&#20559;&#24046;&#21644;&#20854;&#20182;&#24369;&#28857;&#65292;&#23548;&#33268;&#22914;&#26524;&#19981;&#27491;&#30830;&#22788;&#29702;&#65292;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#20250;&#19981;&#20934;&#30830;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#37117;&#19987;&#27880;&#20110;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#20197;&#36798;&#21040;&#26356;&#31934;&#30830;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#65288;NNCI&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#26377;&#20215;&#20540;&#30340;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#38598;&#25104;&#21040;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#20013;&#65292;&#20197;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;&#25552;&#20986;&#30340;NNCI&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#19968;&#20123;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#27169;&#22411;&#65292;&#20854;&#20351;&#29992;&#35266;&#23519;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Treatment effect estimation is of high-importance for both researchers and practitioners across many scientific and industrial domains. The abundance of observational data makes them increasingly used by researchers for the estimation of causal effects. However, these data suffer from biases, from several weaknesses, leading to inaccurate causal effect estimations, if not handled properly. Therefore, several machine learning techniques have been proposed, most of them focusing on leveraging the predictive power of neural network models to attain more precise estimation of causal effects. In this work, we propose a new methodology, named Nearest Neighboring Information for Causal Inference (NNCI), for integrating valuable nearest neighboring information on neural network-based models for estimating treatment effects. The proposed NNCI methodology is applied to some of the most well established neural network-based models for treatment effect estimation with the use of observational data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.06743</link><description>&lt;p&gt;
&#38024;&#23545;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#38544;&#24335;&#33539;&#25968;&#39044;&#27979;&#22120;&#30340;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits. (arXiv:2305.06743v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#38544;&#24335;&#33539;&#25968;&#39044;&#27979;&#22120;&#65288;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#20197;Tsallis&#29109;&#20316;&#20026;prox&#20989;&#25968;&#65289;&#26159;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65288;MAB&#65289;&#30340;&#26368;&#20339;&#31639;&#27861;&#12290;&#20294;&#26159;&#65292;&#22823;&#22810;&#25968;&#22797;&#26434;&#24615;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#26377;&#30028;&#22870;&#21169;&#25110;&#20854;&#20182;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#26368;&#36817;&#26377;&#20851;&#26368;&#20339;&#20108;&#32773;&#32467;&#21512;&#31639;&#27861;&#30340;&#30740;&#31350;&#24050;&#32463;&#38024;&#23545;&#23545;&#25163;&#24615;&#21644;&#38543;&#26426;&#37325;&#23614;MAB&#35774;&#32622;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#37117;&#26159;&#26368;&#20248;&#30340;&#65292;&#20294;&#19981;&#33021;&#20805;&#20998;&#21033;&#29992;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#25552;&#20986;&#20102;&#24102;&#21098;&#36753;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#22312;&#22870;&#21169;&#20998;&#24067;&#19978;&#25552;&#20986;&#28176;&#36827;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19982;&#26368;&#22909;&#30340;&#20108;&#32773;&#32467;&#21512;&#31639;&#27861;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#36890;&#24120;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicitly Normalized Forecaster (online mirror descent with Tsallis entropy as prox-function) is known to be an optimal algorithm for adversarial multi-armed problems (MAB). However, most of the complexity results rely on bounded rewards or other restrictive assumptions. Recently closely related best-of-both-worlds algorithm were proposed for both adversarial and stochastic heavy-tailed MAB settings. This algorithm is known to be optimal in both settings, but fails to exploit data fully. In this paper, we propose Implicitly Normalized Forecaster with clipping for MAB problems with heavy-tailed distribution on rewards. We derive convergence results under mild assumptions on rewards distribution and show that the proposed method is optimal for both linear and non-linear heavy-tailed stochastic MAB problems. Also we show that algorithm usually performs better compared to best-of-two-worlds algorithm.
&lt;/p&gt;</description></item><item><title>NUBO&#26159;&#19968;&#20010;&#36879;&#26126;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20570;&#20195;&#29702;&#27169;&#22411;&#20197;&#21450;&#33719;&#21462;&#20989;&#25968;&#26469;&#25351;&#23548;&#36873;&#25321;&#20505;&#36873;&#28857;&#65292;&#19987;&#27880;&#20110;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.06709</link><description>&lt;p&gt;
NUBO&#65306;&#19968;&#20010;&#36879;&#26126;&#30340; Python &#21253;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
NUBO: A Transparent Python Package for Bayesian Optimisation. (arXiv:2305.06709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06709
&lt;/p&gt;
&lt;p&gt;
NUBO&#26159;&#19968;&#20010;&#36879;&#26126;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20570;&#20195;&#29702;&#27169;&#22411;&#20197;&#21450;&#33719;&#21462;&#20989;&#25968;&#26469;&#25351;&#23548;&#36873;&#25321;&#20505;&#36873;&#28857;&#65292;&#19987;&#27880;&#20110;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
NUBO&#65288;Newcastle University Bayesian Optimisation&#65289;&#26159;&#19968;&#20010;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#27604;&#22914;&#29289;&#29702;&#23454;&#39564;&#21644;&#35745;&#31639;&#26426;&#27169;&#25311;&#22120;&#12290;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20570;&#20195;&#29702;&#27169;&#22411;&#12289;&#24182;&#36890;&#36807;&#33719;&#21462;&#20989;&#25968;&#26469;&#36873;&#25321;&#29992;&#20110;&#20840;&#23616;&#26368;&#20248;&#21270;&#30340;&#20505;&#36873;&#28857;&#12290;NUBO&#19987;&#27880;&#20110;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20307;&#39564;&#65292;&#20197;&#20415;&#35753;&#19981;&#21516;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#26356;&#23481;&#26131;&#20351;&#29992;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
NUBO, short for Newcastle University Bayesian Optimisation, is a Bayesian optimisation framework for the optimisation of expensive-to-evaluate black-box functions, such as physical experiments and computer simulators. Bayesian optimisation is a cost-efficient optimisation strategy that uses surrogate modelling via Gaussian processes to represent an objective function and acquisition functions to guide the selection of candidate points to approximate the global optimum of the objective function. NUBO itself focuses on transparency and user experience to make Bayesian optimisation easily accessible to researchers from all disciplines. Clean and understandable code, precise references, and thorough documentation ensure transparency, while user experience is ensured by a modular and flexible design, easy-to-write syntax, and careful selection of Bayesian optimisation algorithms. NUBO allows users to tailor Bayesian optimisation to their specific problem by writing the optimisation loop the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#40065;&#26834;&#26816;&#27979;&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32858;&#31867;&#25216;&#26415;&#21644;&#30456;&#20284;&#24230;&#24230;&#37327;&#26041;&#27861;&#23454;&#29616;&#20102;&#23545;&#39046;&#20808;&#28382;&#21518;&#20272;&#35745;&#30340;&#32858;&#21512;&#65292;&#20174;&#32780;&#24378;&#21270;&#20102;&#23545;&#21407;&#22987;&#23431;&#23449;&#20013;&#30340;&#19968;&#33268;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2305.06704</link><description>&lt;p&gt;
&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#30340;&#40065;&#26834;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models. (arXiv:2305.06704v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06704
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#40065;&#26834;&#26816;&#27979;&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;&#32858;&#31867;&#25216;&#26415;&#21644;&#30456;&#20284;&#24230;&#24230;&#37327;&#26041;&#27861;&#23454;&#29616;&#20102;&#23545;&#39046;&#20808;&#28382;&#21518;&#20272;&#35745;&#30340;&#32858;&#21512;&#65292;&#20174;&#32780;&#24378;&#21270;&#20102;&#23545;&#21407;&#22987;&#23431;&#23449;&#20013;&#30340;&#19968;&#33268;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#31995;&#32479;&#20013;&#65292;&#36890;&#36807;&#21457;&#29616;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#65292;&#21487;&#20197;&#33719;&#24471;&#20851;&#38190;&#20449;&#24687;&#65292;&#36825;&#25351;&#30340;&#26159;&#20004;&#20010;&#30456;&#23545;&#26102;&#38388;&#20114;&#31227;&#30340;&#26102;&#38388;&#24207;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#21487;&#20197;&#29992;&#20110;&#25511;&#21046;&#12289;&#39044;&#27979;&#25110;&#32858;&#31867;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#26816;&#27979;&#28382;&#21518;&#22810;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#39046;&#20808;&#28382;&#21518;&#20851;&#31995;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#25152;&#35774;&#24819;&#30340;&#31649;&#36947;&#25509;&#25910;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#20316;&#20026;&#36755;&#20837;&#65292;&#24182;&#20351;&#29992;&#28369;&#21160;&#31383;&#21475;&#26041;&#27861;&#20174;&#27599;&#20010;&#36755;&#20837;&#26102;&#38388;&#24207;&#21015;&#20013;&#25552;&#21462;&#19968;&#32452;&#23376;&#24207;&#21015;&#26102;&#38388;&#24207;&#21015;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#21508;&#31181;&#32858;&#31867;&#25216;&#26415;&#65288;&#20363;&#22914;K-means++&#21644;&#35889;&#32858;&#31867;&#65289;&#65292;&#37319;&#29992;&#21508;&#31181;&#25104;&#23545;&#30456;&#20284;&#24615;&#24230;&#37327;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#12290;&#19968;&#26086;&#32858;&#31867;&#34987;&#25552;&#21462;&#20986;&#26469;&#65292;&#36328;&#32858;&#31867;&#30340;&#39046;&#20808;&#28382;&#21518;&#20272;&#35745;&#34987;&#32858;&#21512;&#36215;&#26469;&#65292;&#20197;&#22686;&#24378;&#23545;&#21407;&#22987;&#23431;&#23449;&#20013;&#19968;&#33268;&#20851;&#31995;&#30340;&#35782;&#21035;&#12290;&#30001;&#20110;&#22810;
&lt;/p&gt;
&lt;p&gt;
In multivariate time series systems, key insights can be obtained by discovering lead-lag relationships inherent in the data, which refer to the dependence between two time series shifted in time relative to one another, and which can be leveraged for the purposes of control, forecasting or clustering. We develop a clustering-driven methodology for the robust detection of lead-lag relationships in lagged multi-factor models. Within our framework, the envisioned pipeline takes as input a set of time series, and creates an enlarged universe of extracted subsequence time series from each input time series, by using a sliding window approach. We then apply various clustering techniques (e.g, K-means++ and spectral clustering), employing a variety of pairwise similarity measures, including nonlinear ones. Once the clusters have been extracted, lead-lag estimates across clusters are aggregated to enhance the identification of the consistent relationships in the original universe. Since multi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#35843;&#32422;&#26463;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#27599;&#31181;&#31454;&#20105;&#29983;&#23384;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#30830;&#20445;&#21487;&#20197;&#22312;&#35745;&#31639;&#25104;&#26412;&#19979;&#23454;&#29616;&#31934;&#30830;&#30340;&#26368;&#22823;&#20284;&#28982;&#20540;&#26368;&#20248;&#21270;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.06703</link><description>&lt;p&gt;
&#31454;&#20105;&#39118;&#38505;&#30340;&#21333;&#35843;&#31070;&#32463;&#32593;&#32476;&#65306;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Fine-Gray: Monotonic neural networks for competing risks. (arXiv:2305.06703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#35843;&#32422;&#26463;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#27599;&#31181;&#31454;&#20105;&#29983;&#23384;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#30830;&#20445;&#21487;&#20197;&#22312;&#35745;&#31639;&#25104;&#26412;&#19979;&#23454;&#29616;&#31934;&#30830;&#30340;&#26368;&#22823;&#20284;&#28982;&#20540;&#26368;&#20248;&#21270;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#26159;&#19968;&#31181;&#22788;&#29702;&#24739;&#32773;&#22240;&#26410;&#32463;&#21382;&#24863;&#20852;&#36259;&#20107;&#20214;&#32780;&#20986;&#29616;&#30340;&#8220;censoring&#8221;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#27169;&#22411;&#12290;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#27492;&#31867;&#38382;&#39064;&#20013;&#34920;&#29616;&#31361;&#20986;&#65292;&#20294;&#24448;&#24448;&#24573;&#30053;&#20102;&#31454;&#20105;&#39118;&#38505;&#23545;&#24863;&#20852;&#36259;&#20107;&#20214;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23548;&#33268;&#29983;&#23384;&#29575;&#20272;&#35745;&#23384;&#22312;&#20559;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21333;&#35843;&#32422;&#26463;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#27599;&#31181;&#31454;&#20105;&#29983;&#23384;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#30830;&#20445;&#37319;&#29992;&#33258;&#21160;&#24494;&#20998;&#26041;&#27861;&#33021;&#22815;&#22312;&#35745;&#31639;&#25104;&#26412;&#19979;&#23454;&#29616;&#31934;&#30830;&#30340;&#26368;&#22823;&#20284;&#28982;&#20540;&#26368;&#20248;&#21270;&#12290;&#36890;&#36807;&#25928;&#26524;&#23454;&#39564;&#23545;&#27604;&#23436;&#25104;&#20102;&#19968;&#20010;&#21512;&#25104;&#25968;&#25454;&#21644;&#19977;&#20010;&#21307;&#23398;&#25968;&#25454;&#38598;&#30340;&#29983;&#23384;&#25968;&#25454;&#20998;&#26512;&#12290;&#26368;&#21518;&#35752;&#35770;&#20102;&#22312;&#24320;&#21457;&#21307;&#30103;&#23454;&#36341;&#39118;&#38505;&#35780;&#20272;&#25351;&#26631;&#26102;&#32771;&#34385;&#31454;&#20105;&#39118;&#38505;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-to-event modelling, known as survival analysis, differs from standard regression as it addresses censoring in patients who do not experience the event of interest. Despite competitive performances in tackling this problem, machine learning methods often ignore other competing risks that preclude the event of interest. This practice biases the survival estimation. Extensions to address this challenge often rely on parametric assumptions or numerical estimations leading to sub-optimal survival approximations. This paper leverages constrained monotonic neural networks to model each competing survival distribution. This modelling choice ensures the exact likelihood maximisation at a reduced computational cost by using automatic differentiation. The effectiveness of the solution is demonstrated on one synthetic and three medical datasets. Finally, we discuss the implications of considering competing risks when developing risk scores for medical practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#21450;&#20854;&#21464;&#20307;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#28085;&#30422;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#65292;&#20854;&#27867;&#21270;&#30028;&#38480;&#19982;&#36830;&#32493;&#26435;&#37325;&#24046;&#24322;&#22823;&#23567;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.06648</link><description>&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#19982;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization bounds for neural ordinary differential equations and deep residual networks. (arXiv:2305.06648v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06648
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#21450;&#20854;&#21464;&#20307;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#28085;&#30422;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#65292;&#20854;&#27867;&#21270;&#30028;&#38480;&#19982;&#36830;&#32493;&#26435;&#37325;&#24046;&#24322;&#22823;&#23567;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#26159;&#19968;&#31867;&#27969;&#34892;&#30340;&#36830;&#32493;&#28145;&#24230;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#30001;&#36830;&#32493;&#26102;&#38388;&#21442;&#25968;&#21270;&#30340;ODE&#21450;&#26102;&#21464;&#30340;&#31070;&#32463;ODE&#32452;&#25104;&#30340;&#22823;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;Lipschitz&#26041;&#27861;&#25512;&#23548;&#20102;&#36825;&#20010;&#31867;&#21035;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;ODE&#21644;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#20043;&#38388;&#30340;&#31867;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#19968;&#20010;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36825;&#20010;&#30028;&#38480;&#19982;&#36830;&#32493;&#26435;&#37325;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#22823;&#23567;&#26377;&#20851;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#32467;&#26524;&#28436;&#31034;&#20102;&#36825;&#20010;&#37327;&#26159;&#22914;&#20309;&#24433;&#21709;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural ordinary differential equations (neural ODEs) are a popular family of continuous-depth deep learning models. In this work, we consider a large family of parameterized ODEs with continuous-in-time parameters, which include time-dependent neural ODEs. We derive a generalization bound for this class by a Lipschitz-based argument. By leveraging the analogy between neural ODEs and deep residual networks, our approach yields in particular a generalization bound for a class of deep residual networks. The bound involves the magnitude of the difference between successive weight matrices. We illustrate numerically how this quantity affects the generalization capability of neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;dropout&#27491;&#21017;&#21270;&#65292;dropout&#27491;&#21017;&#21270;&#20559;&#22909;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#22312;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#26041;&#38754;&#37117;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.06625</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;Dropout&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Dropout Regularization in Extended Generalized Linear Models based on Double Exponential Families. (arXiv:2305.06625v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;dropout&#27491;&#21017;&#21270;&#65292;dropout&#27491;&#21017;&#21270;&#20559;&#22909;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#22312;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#26041;&#38754;&#37117;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;dropout&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#34987;&#20805;&#20998;&#29702;&#35299;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#21452;&#25351;&#25968;&#26063;&#30340;&#25193;&#23637;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;dropout&#27491;&#21017;&#21270;&#65292;&#20854;&#20013;&#31163;&#25955;&#21442;&#25968;&#21487;&#20197;&#38543;&#29305;&#24449;&#21464;&#21270;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;dropout&#27491;&#21017;&#21270;&#20559;&#22909;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#29305;&#24449;&#65292;&#22312;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#26041;&#38754;&#37117;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#36825;&#25193;&#23637;&#20102;&#20043;&#21069;&#38024;&#23545;&#20256;&#32479;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#32467;&#26524; &#12290;&#37319;&#29992;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#23558;dropout&#24212;&#29992;&#20110;&#33258;&#36866;&#24212;B&#26679;&#26465;&#24179;&#28369;&#65292;&#20854;&#20013;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#21442;&#25968;&#37117;&#34987;&#28789;&#27963;&#22320;&#24314;&#27169;&#12290;&#37325;&#35201;&#30340;B&#26679;&#26465;&#22522;&#30784;&#20989;&#25968;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#32597;&#35265;&#30340;&#29305;&#24449;&#65292;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#35777;&#23454;&#65292;dropout&#26159;&#19968;&#31181;&#25913;&#21892;&#20102;&#32602;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#30340;&#26174;&#24335;&#24179;&#28369;&#24615;&#30340;&#22343;&#20540;&#21644;&#31163;&#25955;&#24230;&#21442;&#25968;&#30340;&#26377;&#25928;&#27491;&#21017;&#21270;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Even though dropout is a popular regularization technique, its theoretical properties are not fully understood. In this paper we study dropout regularization in extended generalized linear models based on double exponential families, for which the dispersion parameter can vary with the features. A theoretical analysis shows that dropout regularization prefers rare but important features in both the mean and dispersion, generalizing an earlier result for conventional generalized linear models. Training is performed using stochastic gradient descent with adaptive learning rate. To illustrate, we apply dropout to adaptive smoothing with B-splines, where both the mean and dispersion parameters are modelled flexibly. The important B-spline basis functions can be thought of as rare features, and we confirm in experiments that dropout is an effective form of regularization for mean and dispersion parameters that improves on a penalized maximum likelihood approach with an explicit smoothness p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06563</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation. (arXiv:2305.06563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;(STDI)&#26159;&#25968;&#25454;&#39537;&#21160;&#26234;&#33021;&#20132;&#36890;&#31995;&#32479;&#20013;&#19981;&#21487;&#36991;&#20813;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22312;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#20132;&#36890;&#25968;&#25454;&#20013;&#20272;&#35745;&#20002;&#22833;&#25968;&#25454;&#12290;&#30001;&#20110;&#20132;&#36890;&#25968;&#25454;&#20855;&#26377;&#22810;&#32500;&#21644;&#26102;&#31354;&#24615;&#36136;&#65292;&#25105;&#20204;&#23558;&#20002;&#22833;&#25968;&#25454;&#22635;&#20805;&#35270;&#20026;&#24352;&#37327;&#23436;&#25104;&#38382;&#39064;&#12290;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#35768;&#22810;&#20851;&#20110;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340; STDI &#30340;&#30740;&#31350;&#24050;&#32463;&#23637;&#24320;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#21033;&#29992;&#26102;&#31354;&#30456;&#20851;&#24615;&#21644;&#26680;&#24352;&#37327;&#31232;&#30095;&#24615;&#26469;&#25913;&#21892;&#22635;&#20805;&#24615;&#33021;&#20173;&#28982;&#38656;&#35201;&#35299;&#20915;&#12290;&#26412;&#25991;&#37325;&#26032;&#26500;&#36896;&#20102;3/4&#38454;&#27721;&#20811;&#23572;&#24352;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;(maniRTD)&#27169;&#22411;&#29992;&#20110;STDI&#12290;&#26126;&#30830;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#22810;&#32500;&#24310;&#36831;&#23884;&#20837;&#21464;&#25442;&#23558;&#20256;&#24863;&#20132;&#36890;&#29366;&#24577;&#25968;&#25454;&#34920;&#31034;&#20026;3/4&#38454;&#24352;&#37327;&#12290;&#28982;&#21518;&#65292;ManiRTD&#20351;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#20351;&#29992;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal traffic data imputation (STDI), estimating the missing data from partially observed traffic data, is an inevitable and challenging task in data-driven intelligent transportation systems (ITS). Due to traffic data's multidimensional and spatiotemporal properties, we treat the missing data imputation as a tensor completion problem. Many studies have been on STDI based on tensor decomposition in the past decade. However, how to use spatiotemporal correlations and core tensor sparsity to improve the imputation performance still needs to be solved. This paper reshapes a 3rd/4th order Hankel tensor and proposes an innovative manifold regularized Tucker decomposition (ManiRTD) model for STDI. Expressly, we represent the sensory traffic state data as the 3rd/4th tensors by introducing Multiway Delay Embedding Transforms. Then, ManiRTD improves the sparsity of the Tucker core using a sparse regularization term and employs manifold regularization and temporal constraint terms of f
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26377;&#25928;&#22330;&#35770;&#35745;&#31639;&#30340;&#22270;&#35299;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#21333;&#19968;&#26465;&#20214;&#20915;&#23450;&#20102;&#25152;&#26377;&#31070;&#32463;&#20803;&#39044;&#28608;&#27963;&#30340;&#20851;&#32852;&#20989;&#25968;&#30340;&#20020;&#30028;&#24615;&#65292;&#36825;&#21487;&#33021;&#26377;&#21161;&#20110;&#25512;&#21160;&#28145;&#24230;&#23398;&#20064;&#21644;&#22330;&#35770;&#27169;&#25311;&#30340;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2305.02334</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26377;&#25928;&#29702;&#35770;&#30340;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Structures of Neural Network Effective Theories. (arXiv:2305.02334v1 [hep-th])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02334
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26377;&#25928;&#22330;&#35770;&#35745;&#31639;&#30340;&#22270;&#35299;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#21333;&#19968;&#26465;&#20214;&#20915;&#23450;&#20102;&#25152;&#26377;&#31070;&#32463;&#20803;&#39044;&#28608;&#27963;&#30340;&#20851;&#32852;&#20989;&#25968;&#30340;&#20020;&#30028;&#24615;&#65292;&#36825;&#21487;&#33021;&#26377;&#21161;&#20110;&#25512;&#21160;&#28145;&#24230;&#23398;&#20064;&#21644;&#22330;&#35770;&#27169;&#25311;&#30340;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22270;&#35299;&#26041;&#27861;&#65292;&#29992;&#20110;&#30740;&#31350;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#29366;&#24577;&#19979;&#30340;&#26377;&#25928;&#22330;&#35770;&#65288;EFT&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#26497;&#22823;&#22320;&#31616;&#21270;&#35745;&#31639;&#26377;&#38480;&#23485;&#24230;&#20462;&#27491;&#31070;&#32463;&#20803;&#32479;&#35745;&#37327;&#30340;&#36807;&#31243;&#12290;EFT&#35745;&#31639;&#30340;&#32467;&#26500;&#20351;&#24471;&#25152;&#26377;&#31070;&#32463;&#20803;&#39044;&#28608;&#27963;&#30340;&#20851;&#32852;&#20989;&#25968;&#30340;&#20020;&#30028;&#24615;&#37117;&#21463;&#21040;&#21333;&#19968;&#26465;&#20214;&#30340;&#25511;&#21046;&#12290;&#29702;&#35299;&#36825;&#26679;&#30340;EFT&#21487;&#33021;&#26377;&#21161;&#20110;&#36827;&#23637;&#28145;&#24230;&#23398;&#20064;&#21644;&#22330;&#35770;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a diagrammatic approach to effective field theories (EFTs) corresponding to deep neural networks at initialization, which dramatically simplifies computations of finite-width corrections to neuron statistics. The structures of EFT calculations make it transparent that a single condition governs criticality of all connected correlators of neuron preactivations. Understanding of such EFTs may facilitate progress in both deep learning and field theory simulations.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#34920;&#26126;&#23545;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#36827;&#34892;&#25311;&#21512;&#21487;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13761</link><description>&lt;p&gt;
&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization. (arXiv:2304.13761v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13761
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#34920;&#26126;&#23545;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#36827;&#34892;&#25311;&#21512;&#21487;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;(GBDT)&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#39640;&#25928;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22797;&#26434;&#30340;&#32467;&#26500;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#23545;&#26410;&#35265;&#25968;&#25454;&#20013;&#30340;&#23567;&#21327;&#21464;&#37327;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#36739;&#20302;&#12290;&#26412;&#30740;&#31350;&#24212;&#29992;&#29420;&#28909;&#32534;&#30721;&#23558;GBDT&#27169;&#22411;&#36716;&#25442;&#20026;&#32447;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#26641;&#21494;&#32534;&#30721;&#20026;&#19968;&#20010;&#34394;&#25311;&#21464;&#37327;&#12290;&#36825;&#20801;&#35768;&#20351;&#29992;&#32447;&#24615;&#22238;&#24402;&#25216;&#26415;&#65292;&#20197;&#21450;&#19968;&#31181;&#26032;&#39062;&#30340;&#39118;&#38505;&#20998;&#35299;&#26041;&#27861;&#26469;&#35780;&#20272;GBDT&#27169;&#22411;&#23545;&#21327;&#21464;&#37327;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#37325;&#26032;&#25311;&#21512;&#20854;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#65292;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#20102;&#27491;&#21017;&#21270;&#23545;&#27169;&#22411;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#29420;&#28909;&#32534;&#30721;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-boosted decision trees (GBDT) are widely used and highly effective machine learning approach for tabular data modeling. However, their complex structure may lead to low robustness against small covariate perturbation in unseen data. In this study, we apply one-hot encoding to convert a GBDT model into a linear framework, through encoding of each tree leaf to one dummy variable. This allows for the use of linear regression techniques, plus a novel risk decomposition for assessing the robustness of a GBDT model against covariate perturbations. We propose to enhance the robustness of GBDT models by refitting their linear regression forms with $L_1$ or $L_2$ regularization. Theoretical results are obtained about the effect of regularization on the model performance and robustness. It is demonstrated through numerical experiments that the proposed regularization approach can enhance the robustness of the one-hot-encoded GBDT models.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#65292;&#34920;&#26126;&#26356;&#39057;&#32321;&#22320;&#19982;&#21442;&#25968;&#26381;&#21153;&#22120;&#36890;&#20449;&#20250;&#36127;&#38754;&#24433;&#21709;&#27492;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.12216</link><description>&lt;p&gt;
&#26356;&#22810;&#36890;&#20449;&#19981;&#20250;&#20351;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#21464;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
More Communication Does Not Result in Smaller Generalization Error in Federated Learning. (arXiv:2304.12216v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12216
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#35823;&#24046;&#65292;&#34920;&#26126;&#26356;&#39057;&#32321;&#22320;&#19982;&#21442;&#25968;&#26381;&#21153;&#22120;&#36890;&#20449;&#20250;&#36127;&#38754;&#24433;&#21709;&#27492;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#29615;&#22659;&#19979;&#32479;&#35745;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26377;$K$&#20010;&#35774;&#22791;&#25110;&#23458;&#25143;&#31471;&#65292;&#27599;&#20010;&#35774;&#22791;&#25345;&#26377;&#19968;&#20010;&#22823;&#23567;&#20026;$n$&#30340;&#29420;&#31435;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26412;&#22320;&#23398;&#20064;&#30340;&#20010;&#20307;&#27169;&#22411;&#36890;&#36807;&#19968;&#20010;&#20013;&#22830;&#26381;&#21153;&#22120;&#36827;&#34892;&#32858;&#21512;&#65288;&#24179;&#22343;&#65289;&#65292;&#28982;&#21518;&#21457;&#36865;&#22238;&#35774;&#22791;&#12290;&#25105;&#20204;&#32771;&#34385;&#22810;&#27425;&#65288;&#27604;&#22914;&#35828;$R\in \mathbb{N}^*$&#65289;&#27169;&#22411;&#32858;&#21512;&#24182;&#30740;&#31350;$R$&#23545;&#26368;&#32456;&#32858;&#21512;&#27169;&#22411;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19978;&#30028;&#65292;&#26126;&#30830;&#32771;&#34385;&#20102;$R$&#65288;&#38500;&#20102;&#21442;&#19982;&#35774;&#22791;&#30340;&#25968;&#37327;$K$&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;$n$&#65289;&#30340;&#24433;&#21709;&#12290;&#35266;&#23519;&#21040;&#23545;&#20110;&#22266;&#23450;&#30340;$(n,K)$&#65292;&#19978;&#30028;&#38543;$R$&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#36825;&#34920;&#26126;&#26356;&#39057;&#32321;&#22320;&#19982;&#21442;&#25968;&#26381;&#21153;&#22120;&#36890;&#20449;&#20250;&#36127;&#38754;&#24433;&#21709;&#27492;&#31867;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#30001;&#20110;&#32463;&#39564;&#39118;&#38505;&#36890;&#24120;&#21482;&#38543;&#30528;$n$&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#29702;&#35770;&#35777;&#26126;&#20102;&#20026;&#20102;&#22312;FL&#20013;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#38656;&#35201;&#26435;&#34913;&#26412;&#22320;&#23398;&#20064;&#21644;&#20840;&#23616;&#32858;&#21512;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, there are $K$ devices or clients, each holding an independent own dataset of size $n$. Individual models, learned locally via Stochastic Gradient Descent, are aggregated (averaged) by a central server into a global model and then sent back to the devices. We consider multiple (say $R \in \mathbb N^*$) rounds of model aggregation and study the effect of $R$ on the generalization error of the final aggregated model. We establish an upper bound on the generalization error that accounts explicitly for the effect of $R$ (in addition to the number of participating devices $K$ and dataset size $n$). It is observed that, for fixed $(n, K)$, the bound increases with $R$, suggesting that the generalization of such learning algorithms is negatively affected by more frequent communication with the parameter server. Combined with the fact that the empirical risk, however, generally d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23450;&#24615;&#20998;&#26512;&#65292;&#21457;&#29616;VAE&#22312;&#29983;&#29289;&#24212;&#29992;&#20013;&#25674;&#38144;&#28508;&#22312;&#21464;&#37327;&#30340;&#29305;&#24615;&#19982;&#20256;&#32479;&#26174;&#24335;&#34920;&#31034;&#26041;&#27861;&#30456;&#20284;&#12290;</title><link>http://arxiv.org/abs/2303.07487</link><description>&lt;p&gt;
&#20351;&#29992;VAE&#23398;&#20064;&#28508;&#22312;&#21464;&#37327;&#65306;&#22312;cryo-EM&#20013;&#30340;&#24212;&#29992;&#35266;&#23519;&#65288;arXiv:2303.07487v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
Using VAEs to Learn Latent Variables: Observations on Applications in cryo-EM. (arXiv:2303.07487v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23450;&#24615;&#20998;&#26512;&#65292;&#21457;&#29616;VAE&#22312;&#29983;&#29289;&#24212;&#29992;&#20013;&#25674;&#38144;&#28508;&#22312;&#21464;&#37327;&#30340;&#29305;&#24615;&#19982;&#20256;&#32479;&#26174;&#24335;&#34920;&#31034;&#26041;&#27861;&#30456;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#36817;&#20284;&#20998;&#24067;&#12290;VAE&#30340;&#32534;&#30721;&#22120;&#37096;&#20998;&#29992;&#20110;&#35748;&#35777;&#23398;&#20064;&#28508;&#22312;&#21464;&#37327;&#65292;&#20026;&#25968;&#25454;&#26679;&#26412;&#29983;&#25104;&#28508;&#22312;&#34920;&#31034;&#12290;&#26368;&#36817;&#65292;VAEs&#24050;&#29992;&#20110;&#34920;&#24449;&#29289;&#29702;&#21644;&#29983;&#29289;&#31995;&#32479;&#12290;&#22312;&#36825;&#20010;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23450;&#24615;&#22320;&#30740;&#31350;&#20102;VAE&#22312;&#29983;&#29289;&#24212;&#29992;&#20013;&#30340;&#25674;&#38144;&#29305;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#31181;&#24212;&#29992;&#20013;&#65292;&#32534;&#30721;&#22120;&#19982;&#26356;&#20256;&#32479;&#30340;&#26174;&#24335;&#28508;&#22312;&#21464;&#37327;&#34920;&#31034;&#20855;&#26377;&#23450;&#24615;&#30456;&#20284;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are a popular generative model used to approximate distributions. The encoder part of the VAE is used in amortized learning of latent variables, producing a latent representation for data samples. Recently, VAEs have been used to characterize physical and biological systems. In this case study, we qualitatively examine the amortization properties of a VAE used in biological applications. We find that in this application the encoder bears a qualitative resemblance to more traditional explicit representation of latent variables.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#22330;&#26223;&#27979;&#35797;&#26694;&#26550;&#65292;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#38598;&#20013;&#31867;&#20284;&#30340;&#20445;&#25252;&#21644;&#38750;&#20445;&#25252;&#23454;&#20363;&#26469;&#26816;&#27979;&#20998;&#31867;&#22120;&#20013;&#30340;&#27495;&#35270;&#65292;&#36890;&#36807;&#27604;&#36739;&#32452;&#38388;&#20915;&#31574;&#32467;&#26524;&#24046;&#24322;&#65292;&#26469;&#21457;&#29616;&#20010;&#20154;&#27495;&#35270;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#26356;&#22909;&#22320;&#23545;&#12300;&#32473;&#23450;&#24046;&#24322;&#30340;&#20844;&#24179;&#21407;&#21017;&#12301;&#36827;&#34892;&#25805;&#20316;&#65292;&#20197;&#25581;&#31034;&#22312;&#20844;&#24179;&#21407;&#21017;&#19979;&#30340;&#27495;&#35270;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2302.11944</link><description>&lt;p&gt;
&#27979;&#35797;&#21453;&#20107;&#23454;&#22330;&#26223;&#65306;&#25581;&#31034;&#22312;&#20844;&#24179;&#21407;&#21017;&#19979;&#30340;&#27495;&#35270;&#24046;&#24322; (arXiv:2302.11944v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference. (arXiv:2302.11944v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11944
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#22330;&#26223;&#27979;&#35797;&#26694;&#26550;&#65292;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#38598;&#20013;&#31867;&#20284;&#30340;&#20445;&#25252;&#21644;&#38750;&#20445;&#25252;&#23454;&#20363;&#26469;&#26816;&#27979;&#20998;&#31867;&#22120;&#20013;&#30340;&#27495;&#35270;&#65292;&#36890;&#36807;&#27604;&#36739;&#32452;&#38388;&#20915;&#31574;&#32467;&#26524;&#24046;&#24322;&#65292;&#26469;&#21457;&#29616;&#20010;&#20154;&#27495;&#35270;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#26356;&#22909;&#22320;&#23545;&#12300;&#32473;&#23450;&#24046;&#24322;&#30340;&#20844;&#24179;&#21407;&#21017;&#12301;&#36827;&#34892;&#25805;&#20316;&#65292;&#20197;&#25581;&#31034;&#22312;&#20844;&#24179;&#21407;&#21017;&#19979;&#30340;&#27495;&#35270;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34987;&#31216;&#20026;&#21453;&#20107;&#23454;&#22330;&#26223;&#27979;&#35797;(CST)&#30340;&#22240;&#26524;&#25968;&#25454;&#25366;&#25496;&#26694;&#26550;&#26469;&#26816;&#27979;&#20998;&#31867;&#22120;&#20013;&#30340;&#27495;&#35270;&#24773;&#20917;&#12290;CST&#26088;&#22312;&#20197;&#21487;&#25805;&#20316;&#19988;&#26377;&#24847;&#20041;&#30340;&#26041;&#24335;&#22238;&#31572;&#19968;&#31181;&#30452;&#35266;&#38382;&#39064;&#65306;&#8220;&#22914;&#26524;&#20010;&#20154;&#25110;&#25237;&#35785;&#20154;&#25152;&#23646;&#30340;&#21463;&#20445;&#25252;&#36523;&#20221;&#19981;&#21516;&#65292;&#27169;&#22411;&#30340;&#32467;&#26524;&#23558;&#20250;&#26159;&#20160;&#20040;&#65311;&#8221;&#23427;&#36890;&#36807;&#21453;&#20107;&#23454;&#25512;&#29702;&#26469;&#23545;&#27861;&#24459;&#22522;&#30784;&#30340;&#24773;&#26223;&#27979;&#35797;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#25805;&#20316;&#8220;&#32473;&#23450;&#24046;&#24322;&#30340;&#20844;&#24179;&#21407;&#21017;&#8221;&#30340;&#27010;&#24565;&#12290;&#23545;&#20110;&#20219;&#20309;&#25237;&#35785;&#20154;&#65292;&#25105;&#20204;&#22312;&#20998;&#31867;&#22120;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#20013;&#25214;&#21040;&#24182;&#27604;&#36739;&#30456;&#20284;&#30340;&#21463;&#20445;&#25252;&#21644;&#38750;&#21463;&#20445;&#25252;&#23454;&#20363;&#65292;&#26500;&#36896;&#25511;&#21046;&#32452;&#21644;&#27979;&#35797;&#32452;&#65292;&#20004;&#32452;&#30340;&#20915;&#31574;&#32467;&#26524;&#24046;&#24322;&#24847;&#21619;&#30528;&#28508;&#22312;&#30340;&#20010;&#20154;&#27495;&#35270;&#12290;&#19982;&#24773;&#22659;&#27979;&#35797;&#19981;&#21516;&#65292;&#24773;&#22659;&#27979;&#35797;&#26159;&#22260;&#32469;&#25237;&#35785;&#20154;&#26500;&#24314;&#20004;&#32452;&#65292;&#25105;&#20204;&#26681;&#25454;&#22240;&#26524;&#30693;&#35782;&#22312;&#25237;&#35785;&#20154;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27979;&#35797;&#32452;&#12290;&#21453;&#20107;&#23454;&#26088;&#22312;&#21453;&#26144;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present counterfactual situation testing (CST), a causal data mining framework for detecting discrimination in classifiers. CST aims to answer in an actionable and meaningful way the intuitive question "what would have been the model outcome had the individual, or complainant, been of a different protected status?" It extends the legally-grounded situation testing of Thanh et al. (2011) by operationalizing the notion of fairness given the difference using counterfactual reasoning. For any complainant, we find and compare similar protected and non-protected instances in the dataset used by the classifier to construct a control and test group, where a difference between the decision outcomes of the two groups implies potential individual discrimination. Unlike situation testing, which builds both groups around the complainant, we build the test group on the complainant's counterfactual generated using causal knowledge. The counterfactual is intended to reflect how the protected attrib
&lt;/p&gt;</description></item><item><title>&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(IBNNs)&#12290;&#36825;&#31181;&#31639;&#27861;&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#38598;&#21512;&#21644;&#20284;&#28982;&#20998;&#24067;&#38598;&#21512;&#36827;&#34892;&#35757;&#32451;&#65292;&#30456;&#27604;&#26631;&#20934;&#30340;BNNs&#65292;&#21487;&#20197;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#20063;&#26356;&#21152;&#40065;&#26834;&#12290;</title><link>http://arxiv.org/abs/2302.09656</link><description>&lt;p&gt;
&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Imprecise Bayesian Neural Networks. (arXiv:2302.09656v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09656
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(IBNNs)&#12290;&#36825;&#31181;&#31639;&#27861;&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#38598;&#21512;&#21644;&#20284;&#28982;&#20998;&#24067;&#38598;&#21512;&#36827;&#34892;&#35757;&#32451;&#65292;&#30456;&#27604;&#26631;&#20934;&#30340;BNNs&#65292;&#21487;&#20197;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#30340;&#19981;&#30830;&#23450;&#24615;&#24182;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#20063;&#26356;&#21152;&#40065;&#26834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20013;, &#30830;&#23450;&#19981;&#30830;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#26159;&#37325;&#35201;&#30340;&#30446;&#26631;&#12290;&#34429;&#28982;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20351;&#24471;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#33021;&#22815;&#34987;&#35780;&#20272;&#65292;&#19981;&#21516;&#26469;&#28304;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#26080;&#27861;&#21306;&#20998;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;IBNNs&#65289;&#65292;&#23427;&#20204;&#21487;&#20197;&#27010;&#25324;&#21644;&#20811;&#26381;&#26631;&#20934;BNNs&#30340;&#26576;&#20123;&#32570;&#28857;&#12290;&#26631;&#20934;BNNs&#20351;&#29992;&#21333;&#19968;&#30340;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;IBNNs&#20351;&#29992;&#21487;&#20449;&#21306;&#38388;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#12290;&#23427;&#20204;&#20801;&#35768;&#21306;&#20998;&#20808;&#39564;&#21644;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#37327;&#21270;&#12290;&#27492;&#22806;&#65292;IBNNs&#22312;&#36125;&#21494;&#26031;&#28789;&#25935;&#24230;&#20998;&#26512;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#23545;&#20998;&#24067;&#21464;&#21270;&#27604;&#26631;&#20934;BNNs&#26356;&#21152;&#40065;&#26834;&#12290;&#23427;&#20204;&#36824;&#21487;&#20197;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;PAC&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#32467;&#26524;&#38598;&#12290;&#25105;&#20204;&#23558;IBNNs&#24212;&#29992;&#20110;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65306;&#19968;&#20010;&#26159;&#20026;&#20102;&#20154;&#24037;&#33008;&#33146;&#25511;&#21046;&#27169;&#25311;&#34880;&#31958;&#21644;&#33008;&#23707;&#32032;&#21160;&#21147;&#23398;&#65292;&#21478;&#19968;&#20010;&#26159;&#36816;&#21160;&#35268;&#21010;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification and robustness to distribution shifts are important goals in machine learning and artificial intelligence. Although Bayesian neural networks (BNNs) allow for uncertainty in the predictions to be assessed, different sources of uncertainty are indistinguishable. We present imprecise Bayesian neural networks (IBNNs); they generalize and overcome some of the drawbacks of standard BNNs. These latter are trained using a single prior and likelihood distributions, whereas IBNNs are trained using credal prior and likelihood sets. They allow to distinguish between aleatoric and epistemic uncertainties, and to quantify them. In addition, IBNNs are robust in the sense of Bayesian sensitivity analysis, and are more robust than BNNs to distribution shift. They can also be used to compute sets of outcomes that enjoy PAC-like properties. We apply IBNNs to two case studies. One, to model blood glucose and insulin dynamics for artificial pancreas control, and two, for motion p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Seq2Seq-attn&#21644;Transformer&#30340;&#20449;&#36947;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#21453;&#21521;&#25216;&#26415;&#20197;&#25552;&#39640;&#27169;&#22411;&#40065;&#26834;&#24615;&#65292;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2302.00341</link><description>&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#21450;&#21453;&#21521;&#25216;&#26415;&#30340;&#20449;&#36947;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Reverse Ordering Techniques for Attention-Based Channel Prediction. (arXiv:2302.00341v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Seq2Seq-attn&#21644;Transformer&#30340;&#20449;&#36947;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#20102;&#21453;&#21521;&#25216;&#26415;&#20197;&#25552;&#39640;&#27169;&#22411;&#40065;&#26834;&#24615;&#65292;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#21033;&#29992;&#24207;&#21015;&#21040;&#24207;&#21015;&#27169;&#22411;&#65288;Seq2Seq-attn&#65289;&#21644;Transformer&#27169;&#22411;&#65292;&#22522;&#20110;&#22122;&#22768;&#35266;&#27979;&#26469;&#39044;&#27979;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#20013;&#30340;&#20449;&#36947;&#12290;&#20004;&#31181;&#27169;&#22411;&#37117;&#26159;&#20174;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#25913;&#32534;&#32780;&#26469;&#65292;&#20197;&#24212;&#23545;&#20449;&#36947;&#39044;&#27979;&#30340;&#22797;&#26434;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#21453;&#21521;&#20301;&#32622;&#32534;&#30721;&#8221;&#30340;&#26032;&#25216;&#26415;&#20197;&#25552;&#39640;Transformer&#27169;&#22411;&#22312;&#19981;&#21516;&#24207;&#21015;&#38271;&#24230;&#19979;&#30340;&#40065;&#26834;&#24615;&#12290;&#31867;&#20284;&#22320;&#65292;&#22312;&#24212;&#29992;&#27880;&#24847;&#21147;&#20043;&#21069;&#65292;Seq2Seq-attn&#27169;&#22411;&#30340;&#32534;&#30721;&#22120;&#36755;&#20986;&#20063;&#20250;&#34987;&#32763;&#36716;&#12290;&#20223;&#30495;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#21453;&#21521;&#25216;&#26415;&#20351;&#27169;&#22411;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#24207;&#21015;&#20013;&#20449;&#36947;&#30636;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#26080;&#35770;&#24207;&#21015;&#38271;&#24230;&#22914;&#20309;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#26377;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work aims to predict channels in wireless communication systems based on noisy observations, utilizing sequence-to-sequence models with attention (Seq2Seq-attn) and transformer models. Both models are adapted from natural language processing to tackle the complex challenge of channel prediction. Additionally, a new technique called reverse positional encoding is introduced in the transformer model to improve the robustness of the model against varying sequence lengths. Similarly, the encoder outputs of the Seq2Seq-attn model are reversed before applying attention. Simulation results demonstrate that the proposed ordering techniques allow the models to better capture the relationships between the channel snapshots within the sequence, irrespective of the sequence length, as opposed to existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#23545;2016-2017&#24180;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#32467;&#26524;&#34920;&#26126;&#31070;&#32463;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;ETAS&#27169;&#22411;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#30701;&#26399;&#22320;&#38663;&#39044;&#25253;&#12290;</title><link>http://arxiv.org/abs/2301.09948</link><description>&lt;p&gt;
&#29992;&#31070;&#32463;&#28857;&#36807;&#31243;&#39044;&#27979;2016-2017&#24180;&#20013;&#22830;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Forecasting the 2016-2017 Central Apennines Earthquake Sequence with a Neural Point Process. (arXiv:2301.09948v2 [physics.geo-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#23545;2016-2017&#24180;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;&#36827;&#34892;&#20102;&#39044;&#27979;&#65292;&#32467;&#26524;&#34920;&#26126;&#31070;&#32463;&#27169;&#22411;&#20248;&#20110;&#20256;&#32479;ETAS&#27169;&#22411;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#30701;&#26399;&#22320;&#38663;&#39044;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#28857;&#36807;&#31243;&#19968;&#30452;&#26159;&#22320;&#38663;&#27963;&#21160;&#28436;&#21270;&#24314;&#27169;&#39046;&#22495;&#30340;&#20027;&#27969;&#26041;&#27861;&#65292;&#20854;&#20013;Epidemic Type Aftershock Sequence (ETAS)&#27169;&#22411;&#26368;&#20026;&#27969;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#19981;&#26029;&#21457;&#23637;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#39640;&#24230;&#28789;&#27963;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#20197;&#25913;&#36827;&#29616;&#26377;&#30340;&#21442;&#25968;&#27169;&#22411;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#29616;&#26377;&#30340;&#26102;&#38388;&#31070;&#32463;&#27169;&#22411;&#25193;&#23637;&#21040;&#38663;&#32423;&#39046;&#22495;&#65292;&#25506;&#31350;&#36825;&#20123;&#28789;&#27963;&#30340;&#28857;&#36807;&#31243;&#27169;&#22411;&#26159;&#21542;&#21487;&#20197;&#24212;&#29992;&#20110;&#30701;&#26399;&#22320;&#38663;&#39044;&#25253;&#65292;&#24182;&#23637;&#31034;&#27492;&#27169;&#22411;&#22914;&#20309;&#39044;&#27979;&#39640;&#20110;&#30446;&#26631;&#38663;&#32423;&#38408;&#20540;&#30340;&#22320;&#38663;&#12290;&#26412;&#25991;&#39318;&#20808;&#35777;&#26126;&#20102;&#31070;&#32463;&#27169;&#22411;&#21487;&#20197;&#25311;&#21512;ETAS&#21512;&#25104;&#25968;&#25454;&#65292;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#26102;&#38388;&#65292;&#22240;&#20026;&#23427;&#19981;&#20381;&#36182;&#20110;&#25972;&#20010;&#24207;&#21015;&#30340;&#23436;&#25972;&#21382;&#21490;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#20013;&#27169;&#25311;&#30701;&#26399;&#20313;&#38663;&#19981;&#23436;&#25972;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#27169;&#22411;&#30340;&#34920;&#29616;&#20248;&#20110;ETAS&#12290;&#21033;&#29992;2016-2017&#24180;&#20013;&#22830;&#38463;&#24429;&#23425;&#22320;&#38663;&#24207;&#21015;&#30340;&#26032;&#22686;&#24378;&#30446;&#24405;&#65292;&#25105;&#20204;&#39044;&#27979;&#20102;&#26410;&#26469;&#30340;&#22320;&#38663;&#27963;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point processes have been dominant in modeling the evolution of seismicity for decades, with the Epidemic Type Aftershock Sequence (ETAS) model being most popular. Recent advances in machine learning have constructed highly flexible point process models using neural networks to improve upon existing parametric models. We investigate whether these flexible point process models can be applied to short-term seismicity forecasting by extending an existing temporal neural model to the magnitude domain and we show how this model can forecast earthquakes above a target magnitude threshold. We first demonstrate that the neural model can fit synthetic ETAS data, however, requiring less computational time because it is not dependent on the full history of the sequence. By artificially emulating short-term aftershock incompleteness in the synthetic dataset, we find that the neural model outperforms ETAS. Using a new enhanced catalog from the 2016-2017 Central Apennines earthquake sequence, we inv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26680;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#29305;&#24449;&#23376;&#31354;&#38388;&#21644;&#26680;&#20043;&#38388;&#30340;&#19968;&#19968;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#29109;&#24230;&#37327;&#26041;&#27861;&#29992;&#20110;&#26680;&#30340;&#27604;&#36739;&#12290;&#29305;&#21035;&#22320;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26497;&#22823;&#30456;&#20851;&#26680;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#20449;&#24687;&#29109;&#24230;&#37327;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;&#26368;&#21518;&#65292;&#25226;Fisher&#26680;&#35299;&#37322;&#20026;&#19968;&#31181;&#29305;&#27530;&#30340;&#26497;&#22823;&#30456;&#20851;&#26680;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.01410</link><description>&lt;p&gt;
&#26680;&#23376;&#31354;&#38388;&#21644;&#29305;&#24449;&#25552;&#21462;
&lt;/p&gt;
&lt;p&gt;
Kernel Subspace and Feature Extraction. (arXiv:2301.01410v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26680;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#29305;&#24449;&#23376;&#31354;&#38388;&#21644;&#26680;&#20043;&#38388;&#30340;&#19968;&#19968;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#29109;&#24230;&#37327;&#26041;&#27861;&#29992;&#20110;&#26680;&#30340;&#27604;&#36739;&#12290;&#29305;&#21035;&#22320;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26497;&#22823;&#30456;&#20851;&#26680;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#20449;&#24687;&#29109;&#24230;&#37327;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;&#26368;&#21518;&#65292;&#25226;Fisher&#26680;&#35299;&#37322;&#20026;&#19968;&#31181;&#29305;&#27530;&#30340;&#26497;&#22823;&#30456;&#20851;&#26680;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29305;&#24449;&#23376;&#31354;&#38388;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26680;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#29305;&#24449;&#23376;&#31354;&#38388;&#21644;&#26680;&#20043;&#38388;&#30340;&#19968;&#19968;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#29109;&#24230;&#37327;&#26041;&#27861;&#29992;&#20110;&#26680;&#30340;&#27604;&#36739;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#30001;Hirschfeld-Gebelein-R\'{e}nyi&#26497;&#22823;&#30456;&#20851;&#20989;&#25968;&#26500;&#25104;&#30340;&#26680;&#65292;&#31216;&#20043;&#20026;&#26497;&#22823;&#30456;&#20851;&#26680;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#20449;&#24687;&#29109;&#24230;&#37327;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#20197;&#25903;&#25345;&#21521;&#37327;&#26426;(SVM)&#20026;&#20363;&#65292;&#23558;&#26680;&#26041;&#27861;&#19982;&#29305;&#24449;&#25552;&#21462;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#34920;&#26126;&#22312;&#26497;&#22823;&#30456;&#20851;&#26680;&#19978;&#30340;&#26680;SVM&#20855;&#26377;&#26368;&#23567;&#39044;&#27979;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25226;Fisher&#26680;&#35299;&#37322;&#20026;&#19968;&#31181;&#29305;&#27530;&#30340;&#26497;&#22823;&#30456;&#20851;&#26680;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study kernel methods in machine learning from the perspective of feature subspace. We establish a one-to-one correspondence between feature subspaces and kernels and propose an information-theoretic measure for kernels. In particular, we construct a kernel from Hirschfeld--Gebelein--R\'{e}nyi maximal correlation functions, coined the maximal correlation kernel, and demonstrate its information-theoretic optimality. We use the support vector machine (SVM) as an example to illustrate a connection between kernel methods and feature extraction approaches. We show that the kernel SVM on maximal correlation kernel achieves minimum prediction error. Finally, we interpret the Fisher kernel as a special maximal correlation kernel and establish its optimality.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#24191;&#27867;&#30340;&#31354;&#38388;&#20013;&#65292;&#24182;&#23548;&#33268;&#20998;&#25968;&#21305;&#37197;&#30340;&#21407;&#22987;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2211.03595</link><description>&lt;p&gt;
&#20174;&#21435;&#22122;&#25193;&#25955;&#21040;&#21435;&#22122;&#39532;&#23572;&#31185;&#22827;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
From Denoising Diffusions to Denoising Markov Models. (arXiv:2211.03595v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.03595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#24191;&#27867;&#30340;&#31354;&#38388;&#20013;&#65292;&#24182;&#23548;&#33268;&#20998;&#25968;&#21305;&#37197;&#30340;&#21407;&#22987;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#25193;&#25955;&#26159;&#23637;&#29616;&#20986;&#21331;&#36234;&#23454;&#39564;&#24615;&#33021;&#30340;&#26368;&#20808;&#36827;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#20182;&#20204;&#36890;&#36807;&#23558;&#25968;&#25454;&#20998;&#24067;&#25193;&#25955;&#21040;&#39640;&#26031;&#20998;&#24067;&#65292;&#28982;&#21518;&#23398;&#20064;&#36870;&#36716;&#36825;&#20010;&#22122;&#22768;&#36807;&#31243;&#20197;&#33719;&#21462;&#21512;&#25104;&#25968;&#25454;&#28857;&#12290;&#21435;&#22122;&#25193;&#25955;&#20381;&#36182;&#20110;&#20351;&#29992;&#20998;&#25968;&#21305;&#37197;&#23545;&#22122;&#22768;&#25968;&#25454;&#23494;&#24230;&#30340;&#23545;&#25968;&#23548;&#25968;&#30340;&#36924;&#36817;&#12290;&#24403;&#21482;&#33021;&#20174;&#20808;&#39564;&#20998;&#24067;&#21644;&#20284;&#28982;&#20989;&#25968;&#20013;&#36827;&#34892;&#25277;&#26679;&#26102;&#65292;&#36825;&#31181;&#27169;&#22411;&#20063;&#21487;&#29992;&#20110;&#25191;&#34892;&#36817;&#20284;&#21518;&#39564;&#27169;&#25311;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#23558;&#27492;&#26041;&#27861;&#25512;&#24191;&#21040;&#19968;&#31867;&#24191;&#27867;&#30340;&#31354;&#38388;&#65292;&#24182;&#23548;&#33268;&#20998;&#25968;&#21305;&#37197;&#30340;&#21407;&#22987;&#25193;&#23637;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#24212;&#29992;&#31243;&#24207;&#35828;&#26126;&#20102;&#25152;&#24471;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusions are state-of-the-art generative models exhibiting remarkable empirical performance. They work by diffusing the data distribution into a Gaussian distribution and then learning to reverse this noising process to obtain synthetic datapoints. The denoising diffusion relies on approximations of the logarithmic derivatives of the noised data densities using score matching. Such models can also be used to perform approximate posterior simulation when one can only sample from the prior and likelihood. We propose a unifying framework generalising this approach to a wide class of spaces and leading to an original extension of score matching. We illustrate the resulting models on various applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#25215;&#35834;&#21644;&#22122;&#22768;&#35266;&#27979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#65292;&#21457;&#29616;&#24179;&#34913;&#28857;&#24635;&#26159;&#23384;&#22312;&#30340;&#65307;&#39046;&#23548;&#32773;&#30340;&#21160;&#20316;&#35266;&#27979;&#32467;&#26524;&#23545;&#20110;&#36861;&#38543;&#32773;&#26469;&#35828;&#35201;&#20040;&#26159;&#26377;&#30410;&#30340;&#65292;&#35201;&#20040;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#65307;&#35813;&#21338;&#24328;&#30340;&#25910;&#30410;&#22312;&#22343;&#34913;&#28857;&#19978;&#34987;&#19978;&#30028;&#38480;&#21046;&#20026;&#32431;&#31574;&#30053;&#19979;&#30340;SE&#30340;&#25910;&#30410;&#65292;&#19979;&#30028;&#20026;&#28151;&#21512;&#31574;&#30053;&#19979;&#30340;&#32435;&#20160;&#22343;&#34913;&#30340;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2211.01703</link><description>&lt;p&gt;
&#24102;&#25215;&#35834;&#21644;&#22122;&#22768;&#35266;&#27979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
$2 \times 2$ Zero-Sum Games with Commitments and Noisy Observations. (arXiv:2211.01703v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#25215;&#35834;&#21644;&#22122;&#22768;&#35266;&#27979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#65292;&#21457;&#29616;&#24179;&#34913;&#28857;&#24635;&#26159;&#23384;&#22312;&#30340;&#65307;&#39046;&#23548;&#32773;&#30340;&#21160;&#20316;&#35266;&#27979;&#32467;&#26524;&#23545;&#20110;&#36861;&#38543;&#32773;&#26469;&#35828;&#35201;&#20040;&#26159;&#26377;&#30410;&#30340;&#65292;&#35201;&#20040;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#65307;&#35813;&#21338;&#24328;&#30340;&#25910;&#30410;&#22312;&#22343;&#34913;&#28857;&#19978;&#34987;&#19978;&#30028;&#38480;&#21046;&#20026;&#32431;&#31574;&#30053;&#19979;&#30340;SE&#30340;&#25910;&#30410;&#65292;&#19979;&#30028;&#20026;&#28151;&#21512;&#31574;&#30053;&#19979;&#30340;&#32435;&#20160;&#22343;&#34913;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20197;&#19979;&#20551;&#35774;&#19979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#65306;$(1)$&#20854;&#20013;&#19968;&#20301;&#29609;&#23478;&#65288;&#39046;&#23548;&#32773;&#65289;&#25215;&#35834;&#36890;&#36807;&#37319;&#26679;&#32473;&#23450;&#30340;&#27010;&#29575;&#20998;&#24067;&#65288;&#31574;&#30053;&#65289;&#26469;&#36873;&#25321;&#20182;&#30340;&#21160;&#20316;;$(2)$&#39046;&#23548;&#32773;&#23459;&#24067;&#20182;&#30340;&#21160;&#20316;&#65292;&#36825;&#20010;&#21160;&#20316;&#36890;&#36807;&#20108;&#36827;&#21046;&#20449;&#36947;&#34987;&#23545;&#25163;&#65288;&#36861;&#38543;&#32773;&#65289;&#35266;&#23519;&#21040;;$(3)$&#36861;&#38543;&#32773;&#22522;&#20110;&#39046;&#23548;&#32773;&#30340;&#31574;&#30053;&#21644;&#39046;&#23548;&#32773;&#21160;&#20316;&#30340;&#22122;&#22768;&#35266;&#27979;&#26469;&#36873;&#25321;&#22905;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#24179;&#34913;&#28857;&#34987;&#35777;&#26126;&#24635;&#26159;&#23384;&#22312;&#30340;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#21363;&#20351;&#21463;&#21040;&#22122;&#22768;&#30340;&#24433;&#21709;&#65292;&#35266;&#23519;&#39046;&#23548;&#32773;&#30340;&#34892;&#21160;&#23545;&#36861;&#38543;&#32773;&#26469;&#35828;&#23454;&#36136;&#19978;&#35201;&#20040;&#26159;&#26377;&#30410;&#30340;&#65292;&#35201;&#20040;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#36825;&#20010;&#21338;&#24328;&#30340;&#22343;&#34913;&#28857;&#19978;&#65292;&#25910;&#30410;&#34987;&#19978;&#30028;&#38480;&#21046;&#20026;&#32431;&#31574;&#30053;&#19979;SE&#30340;&#25910;&#30410;&#65307;&#24182;&#19988;&#19979;&#30028;&#20026;&#32435;&#20160;&#22343;&#34913;&#30340;&#25910;&#30410;&#65292;&#36825;&#31561;&#20215;&#20110;&#28151;&#21512;&#31574;&#30053;&#19979;&#30340;SE&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#26469;&#35266;&#23519;&#22343;&#34913;&#28857;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, $2\times2$ zero-sum games are studied under the following assumptions: $(1)$ One of the players (the leader) commits to choose its actions by sampling a given probability measure (strategy); $(2)$ The leader announces its action, which is observed by its opponent (the follower) through a binary channel; and $(3)$ the follower chooses its strategy based on the knowledge of the leader's strategy and the noisy observation of the leader's action. Under these conditions, the equilibrium is shown to always exist. Interestingly, even subject to noise, observing the actions of the leader is shown to be either beneficial or immaterial for the follower. More specifically, the payoff at the equilibrium of this game is upper bounded by the payoff at the Stackelberg equilibrium (SE) in pure strategies; and lower bounded by the payoff at the Nash equilibrium, which is equivalent to the SE in mixed strategies.Finally, necessary and sufficient conditions for observing the payoff at equi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#35299;&#20915;&#22823;&#26102;&#38388;&#38271;&#24230;&#19979;&#30340;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#19988;&#20854;&#35745;&#31639;&#25104;&#26412;&#19981;&#21253;&#25324;&#20381;&#36182;&#20110;&#26102;&#38388;&#38271;&#24230;&#30340;&#39033;&#12290;</title><link>http://arxiv.org/abs/2210.07513</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36830;&#32493;&#26102;&#38388;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Continuous-in-time Limit for Bayesian Bandits. (arXiv:2210.07513v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#35299;&#20915;&#22823;&#26102;&#38388;&#38271;&#24230;&#19979;&#30340;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#19988;&#20854;&#35745;&#31639;&#25104;&#26412;&#19981;&#21253;&#25324;&#20381;&#36182;&#20110;&#26102;&#38388;&#38271;&#24230;&#30340;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#19979;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#36172;&#21338;&#26426;&#38382;&#39064;&#21046;&#23450;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#23547;&#25214;&#26368;&#20248;&#31574;&#30053;&#20197;&#26368;&#23567;&#21270;&#36125;&#21494;&#26031;&#36951;&#25022;&#12290;&#38754;&#23545;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#65292;&#24403;&#38382;&#39064;&#30340;&#26102;&#38388;&#38271;&#24230;&#25110;&#33218;&#25968;&#36739;&#22823;&#26102;&#65292;&#35745;&#31639;&#26368;&#20248;&#31574;&#30053;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#36866;&#24403;&#30340;&#37325;&#32553;&#25918;&#19979;&#65292;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#25910;&#25947;&#20110;&#19968;&#20010;&#36830;&#32493;&#30340;&#21704;&#23494;&#23572;&#39039; - &#38597;&#21508;&#27604; - &#36125;&#23572;&#26364;&#65288;HJB&#65289;&#26041;&#31243;&#12290;&#23545;&#20110;&#24120;&#35265;&#30340;&#19968;&#20123;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#21487;&#20197;&#26126;&#30830;&#33719;&#24471;&#26497;&#38480;HJB&#26041;&#31243;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#19988;&#22312;&#26080;&#27861;&#26126;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#35299;&#20915;HJB&#26041;&#31243;&#30340;&#25968;&#23383;&#26041;&#27861;&#12290;&#22522;&#20110;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#35299;&#20915;&#22823;&#26102;&#38388;&#38271;&#24230;&#19979;&#30340;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#35745;&#31639;&#25104;&#26412;&#19981;&#21253;&#25324;&#20381;&#36182;&#20110;&#26102;&#38388;&#38271;&#24230;&#30340;&#39033;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper revisits the bandit problem in the Bayesian setting. The Bayesian approach formulates the bandit problem as an optimization problem, and the goal is to find the optimal policy which minimizes the Bayesian regret. One of the main challenges facing the Bayesian approach is that computation of the optimal policy is often intractable, especially when the length of the problem horizon or the number of arms is large. In this paper, we first show that under a suitable rescaling, the Bayesian bandit problem converges toward a continuous Hamilton-Jacobi-Bellman (HJB) equation. The optimal policy for the limiting HJB equation can be explicitly obtained for several common bandit problems, and we give numerical methods to solve the HJB equation when an explicit solution is not available. Based on these results, we propose an approximate Bayes-optimal policy for solving Bayesian bandit problems with large horizons. Our method has the added benefit that its computational cost does not inc
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#26694;&#26550;&#30340;&#21327;&#26041;&#24046;&#22238;&#24402;&#20998;&#26512;(Covariance Regression with Random Forests, CovRegRF)&#34987;&#25552;&#20986;&#65292;&#21487;&#20197;&#29992;&#20110;&#20272;&#31639;&#22312;&#32473;&#23450;&#21327;&#21464;&#37327;&#24773;&#20917;&#19979;&#22810;&#20803;&#21709;&#24212;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#20851;&#26576;&#20123;&#21327;&#21464;&#37327;&#20559;&#25928;&#24212;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.08173</link><description>&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#36827;&#34892;&#21327;&#26041;&#24046;&#22238;&#24402;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Covariance regression with random forests. (arXiv:2209.08173v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.08173
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#26694;&#26550;&#30340;&#21327;&#26041;&#24046;&#22238;&#24402;&#20998;&#26512;(Covariance Regression with Random Forests, CovRegRF)&#34987;&#25552;&#20986;&#65292;&#21487;&#20197;&#29992;&#20110;&#20272;&#31639;&#22312;&#32473;&#23450;&#21327;&#21464;&#37327;&#24773;&#20917;&#19979;&#22810;&#20803;&#21709;&#24212;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#20851;&#26576;&#20123;&#21327;&#21464;&#37327;&#20559;&#25928;&#24212;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21253;&#25324;&#31070;&#32463;&#31185;&#23398;&#12289;&#27969;&#34892;&#30149;&#23398;&#12289;&#29983;&#29289;&#21307;&#23398;&#31561;&#22810;&#20010;&#39046;&#22495;&#65292;&#22522;&#20110;&#21327;&#21464;&#37327;&#25429;&#33719;&#22810;&#20803;&#21709;&#24212;&#30690;&#37327;&#30340;&#26465;&#20214;&#21327;&#26041;&#24046;&#25110;&#30456;&#20851;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#26694;&#26550;&#30340;&#21327;&#26041;&#24046;&#22238;&#24402;&#20998;&#26512;(Covariance Regression with Random Forests, CovRegRF)&#65292;&#29992;&#20110;&#20272;&#31639;&#22312;&#32473;&#23450;&#21327;&#21464;&#37327;&#24773;&#20917;&#19979;&#22810;&#20803;&#21709;&#24212;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#38543;&#26426;&#26862;&#26519;&#26641;&#30340;&#20998;&#21106;&#35268;&#21017;&#26159;&#19987;&#38376;&#35774;&#35745;&#30340;&#65292;&#20197;&#26368;&#22823;&#21270;&#23376;&#33410;&#28857;&#30340;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#20851;&#26576;&#20123;&#21327;&#21464;&#37327;&#20559;&#25928;&#24212;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#21644;&#26174;&#33879;&#24615;&#26816;&#39564;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#26174;&#31034;CovRegRF&#26041;&#27861;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#65292;&#24182;&#19988;Type-1&#35823;&#24046;&#24471;&#21040;&#20102;&#33391;&#22909;&#25511;&#21046;&#12290;&#35813;&#26041;&#27861;&#22312;&#30002;&#29366;&#33146;&#30142;&#30149;&#25968;&#25454;&#19978;&#30340;&#24212;&#29992;&#20063;&#34987;&#25552;&#20986;&#12290;CovRegRF&#24050;&#32463;&#23454;&#29616;&#22312;R&#21253;"CovRegRF"&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Capturing the conditional covariances or correlations among the elements of a multivariate response vector based on covariates is important to various fields including neuroscience, epidemiology and biomedicine. We propose a new method called Covariance Regression with Random Forests (CovRegRF) to estimate the covariance matrix of a multivariate response given a set of covariates, using a random forest framework. Random forest trees are built with a splitting rule specially designed to maximize the difference between the sample covariance matrix estimates of the child nodes. We also propose a significance test for the partial effect of a subset of covariates. We evaluate the performance of the proposed method and significance test through a simulation study which shows that the proposed method provides accurate covariance matrix estimates and that the Type-1 error is well controlled. An application of the proposed method to thyroid disease data is also presented. CovRegRF is implemente
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#29616;&#25104;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#23383;&#24149;&#29983;&#25104;&#25216;&#26415;&#65292;&#33258;&#21160;&#21457;&#29616;&#35270;&#35273;&#27169;&#22411;&#20013;&#30340;&#38169;&#35823;&#12290;&#36890;&#36807;&#29983;&#25104;&#22823;&#37327;&#21512;&#25104;&#20294;&#36924;&#30495;&#30340;&#36755;&#20837;&#65292;&#32858;&#31867;&#21644;&#25551;&#36848;&#65292;&#35780;&#20272;&#21644;&#21457;&#29616;&#20998;&#31867;&#22120;&#30340;&#22833;&#36133;&#21644;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#36825;&#20026;&#26410;&#26469;&#26500;&#24314;&#23454;&#29992;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2208.08831</link><description>&lt;p&gt;
&#21033;&#29992;&#29616;&#25104;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#23383;&#24149;&#29983;&#25104;&#25216;&#26415;&#21457;&#29616;&#35270;&#35273;&#27169;&#22411;&#20013;&#30340;&#38169;&#35823;
&lt;/p&gt;
&lt;p&gt;
Discovering Bugs in Vision Models using Off-the-shelf Image Generation and Captioning. (arXiv:2208.08831v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#29616;&#25104;&#30340;&#22270;&#20687;&#29983;&#25104;&#21644;&#23383;&#24149;&#29983;&#25104;&#25216;&#26415;&#65292;&#33258;&#21160;&#21457;&#29616;&#35270;&#35273;&#27169;&#22411;&#20013;&#30340;&#38169;&#35823;&#12290;&#36890;&#36807;&#29983;&#25104;&#22823;&#37327;&#21512;&#25104;&#20294;&#36924;&#30495;&#30340;&#36755;&#20837;&#65292;&#32858;&#31867;&#21644;&#25551;&#36848;&#65292;&#35780;&#20272;&#21644;&#21457;&#29616;&#20998;&#31867;&#22120;&#30340;&#22833;&#36133;&#21644;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#36825;&#20026;&#26410;&#26469;&#26500;&#24314;&#23454;&#29992;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#24773;&#22659;&#19979;&#33258;&#21160;&#21457;&#29616;&#35270;&#35273;&#27169;&#22411;&#30340;&#22833;&#36133;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#22823;&#37327;&#25968;&#25454;&#35757;&#32451;&#30340;&#29616;&#25104;&#22823;&#22411;&#22270;&#20687;&#21040;&#25991;&#26412;&#21644;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#26469;&#33258;&#21160;&#21457;&#29616;&#36825;&#20123;&#22833;&#36133;&#12290;&#26412;&#30740;&#31350;&#23558;&#26465;&#20214;&#25991;&#26412;&#21040;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#29992;&#20110;&#29983;&#25104;&#22823;&#37327;&#21512;&#25104;&#20294;&#36924;&#30495;&#30340;&#36755;&#20837;&#12290;&#20998;&#31867;&#38169;&#35823;&#30340;&#36755;&#20837;&#23558;&#34987;&#32858;&#31867;&#24182;&#20351;&#29992;&#23383;&#24149;&#29983;&#25104;&#27169;&#22411;&#26469;&#25551;&#36848;&#27599;&#20010;&#32858;&#31867;&#12290;&#27599;&#20010;&#32858;&#31867;&#30340;&#25551;&#36848;&#20381;&#27425;&#29992;&#20110;&#29983;&#25104;&#26356;&#22810;&#36755;&#20837;&#24182;&#35780;&#20272;&#26159;&#21542;&#29305;&#23450;&#32858;&#31867;&#24341;&#36215;&#30340;&#22833;&#36133;&#36229;&#20986;&#20102;&#39044;&#26399;&#12290;&#25105;&#20204;&#21033;&#29992;&#27492;&#27969;&#31243;&#28436;&#31034;&#20102;&#25105;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#35843;&#26597;&#22312;ImageNet&#19978;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#65292;&#25214;&#21040;&#29305;&#23450;&#22833;&#36133;&#26696;&#20363;&#24182;&#21457;&#29616;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#21487;&#20197;&#25193;&#23637;&#27492;&#26041;&#27861;&#65292;&#29983;&#25104;&#38024;&#23545;&#29305;&#23450;&#20998;&#31867;&#22120;&#26550;&#26500;&#30340;&#23545;&#25239;&#25968;&#25454;&#38598;&#12290;&#26412;&#30740;&#31350;&#20316;&#20026;&#19968;&#20010;&#23454;&#29992;&#30340;&#26694;&#26550;&#30340;&#27010;&#24565;&#39564;&#35777;&#65292;&#29992;&#20110;&#21457;&#29616;&#35270;&#35273;&#27169;&#22411;&#20013;&#30340;&#22833;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatically discovering failures in vision models under real-world settings remains an open challenge. This work demonstrates how off-the-shelf, large-scale, image-to-text and text-to-image models, trained on vast amounts of data, can be leveraged to automatically find such failures. In essence, a conditional text-to-image generative model is used to generate large amounts of synthetic, yet realistic, inputs given a ground-truth label. Misclassified inputs are clustered and a captioning model is used to describe each cluster. Each cluster's description is used in turn to generate more inputs and assess whether specific clusters induce more failures than expected. We use this pipeline to demonstrate that we can effectively interrogate classifiers trained on ImageNet to find specific failure cases and discover spurious correlations. We also show that we can scale the approach to generate adversarial datasets targeting specific classifier architectures. This work serves as a proof-of-co
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#39640;&#25928;&#19988;&#32479;&#35745;&#26368;&#20248;&#30340;&#40065;&#26834;&#20302;&#31209;&#30697;&#38453;&#21644;&#24352;&#37327;&#20272;&#35745;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#23454;&#29616;&#20934;&#30830;&#20272;&#35745;&#65292;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.00953</link><description>&lt;p&gt;
&#35745;&#31639;&#39640;&#25928;&#19988;&#32479;&#35745;&#26368;&#20248;&#30340;&#40065;&#26834;&#20302;&#31209;&#30697;&#38453;&#21644;&#24352;&#37327;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Computationally Efficient and Statistically Optimal Robust Low-rank Matrix and Tensor Estimation. (arXiv:2203.00953v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00953
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#39640;&#25928;&#19988;&#32479;&#35745;&#26368;&#20248;&#30340;&#40065;&#26834;&#20302;&#31209;&#30697;&#38453;&#21644;&#24352;&#37327;&#20272;&#35745;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#23454;&#29616;&#20934;&#30830;&#20272;&#35745;&#65292;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#36827;&#34892;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#26082;&#20855;&#26377;&#35745;&#31639;&#22797;&#26434;&#24615;&#21448;&#20855;&#26377;&#32479;&#35745;&#25361;&#25112;&#12290;&#20984;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#22312;&#32479;&#35745;&#23398;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#20294;&#30001;&#20110;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20809;&#28369;&#30340;&#65292;&#22240;&#27492;&#36973;&#21463;&#39640;&#35745;&#31639;&#25104;&#26412;&#30340;&#22256;&#25200;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#27425;&#26799;&#24230;&#19979;&#38477;&#25552;&#20986;&#20102;&#35745;&#31639;&#24555;&#36895;&#30340;&#38750;&#20984;&#26041;&#27861;&#65292;&#20294;&#19981;&#24184;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#27425;&#39640;&#26031;&#22122;&#22768;&#19979;&#65292;&#20063;&#26080;&#27861;&#25552;&#20379;&#32479;&#35745;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#26354;&#29575;&#27425;&#26799;&#24230;&#31639;&#27861;&#65288;RsGrad&#65289;&#65292;&#23427;&#19981;&#20165;&#35745;&#31639;&#39640;&#25928;&#65292;&#32780;&#19988;&#25910;&#25947;&#32447;&#24615;&#65292;&#24182;&#19988;&#22312;&#22122;&#22768;&#20026;&#39640;&#26031;&#25110;&#37325;&#23614;&#20998;&#24067;&#26102;&#20063;&#20855;&#26377;&#32479;&#35745;&#20248;&#33391;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#21644;&#20855;&#20307;&#30340;&#24212;&#29992;&#20110;&#32477;&#23545;&#25439;&#22833;&#12289;Huber&#25439;&#22833;&#21644;&#20998;&#20301;&#25439;&#22833;&#30340;&#25910;&#25947;&#29702;&#35770;&#65292;&#24182;&#23545;&#27604;&#29616;&#26377;&#38750;&#20984;&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#30340;&#23545;&#21452;&#30456;&#25910;&#25947;&#30340;&#29616;&#35937;&#36827;&#34892;&#20102;&#24778;&#20154;&#30340;&#25581;&#31034;&#12290;&#22312;&#38454;&#27573;&#19968;&#20013;&#65292;RsGrad&#30340;&#34892;&#20026;&#31867;&#20284;&#20110;&#20856;&#22411;&#30340;&#38750;&#20984;&#26041;&#27861;&#65292;&#32780;&#22312;&#38454;&#27573;&#20108;&#20013;&#65292;&#23427;&#23454;&#29616;&#20102;&#31867;&#20984;&#25910;&#25947;&#65292;&#24182;&#19988;&#20855;&#26377;&#24555;&#36895;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#65292;RsGrad&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#30697;&#38453;&#21644;&#24352;&#37327;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-rank matrix estimation under heavy-tailed noise is challenging, both computationally and statistically. Convex approaches have been proven statistically optimal but suffer from high computational costs, especially since robust loss functions are usually non-smooth. More recently, computationally fast non-convex approaches via sub-gradient descent are proposed, which, unfortunately, fail to deliver a statistically consistent estimator even under sub-Gaussian noise. In this paper, we introduce a novel Riemannian sub-gradient (RsGrad) algorithm which is not only computationally efficient with linear convergence but also is statistically optimal, be the noise Gaussian or heavy-tailed. Convergence theory is established for a general framework and specific applications to absolute loss, Huber loss, and quantile loss are investigated. Compared with existing non-convex methods, ours reveals a surprising phenomenon of dual-phase convergence. In phase one, RsGrad behaves as in a typical non-
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22810;&#39033;Logit&#36873;&#25321;&#27169;&#22411;&#30340;&#23398;&#20064;&#25490;&#24207;&#26694;&#26550;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#25429;&#25417;&#29992;&#25143;&#22312;&#25972;&#20010;&#39033;&#30446;&#21015;&#34920;&#20013;&#30340;&#36873;&#25321;&#34892;&#20026;&#65292;&#20026;&#32593;&#31449;&#35774;&#35745;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#25490;&#24207;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2009.03207</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#22810;&#39033;Logit&#36873;&#25321;&#19979;&#36827;&#34892;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Learning to Rank under Multinomial Logit Choice. (arXiv:2009.03207v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.03207
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22810;&#39033;Logit&#36873;&#25321;&#27169;&#22411;&#30340;&#23398;&#20064;&#25490;&#24207;&#26694;&#26550;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#25429;&#25417;&#29992;&#25143;&#22312;&#25972;&#20010;&#39033;&#30446;&#21015;&#34920;&#20013;&#30340;&#36873;&#25321;&#34892;&#20026;&#65292;&#20026;&#32593;&#31449;&#35774;&#35745;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#25490;&#24207;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32593;&#31449;&#35774;&#35745;&#20013;&#65292;&#23398;&#20064;&#26368;&#20339;&#20869;&#23481;&#25490;&#24207;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#23398;&#20064;&#25490;&#24207;&#65288;LTR&#65289;&#26694;&#26550;&#23558;&#36825;&#20010;&#38382;&#39064;&#24314;&#27169;&#20026;&#36873;&#25321;&#20869;&#23481;&#21015;&#34920;&#24182;&#35266;&#23519;&#29992;&#25143;&#20915;&#23450;&#28857;&#20987;&#30340;&#39034;&#24207;&#38382;&#39064;&#12290;&#22823;&#22810;&#25968;&#20197;&#21069;&#30340;LTR&#24037;&#20316;&#20551;&#35774;&#29992;&#25143;&#22312;&#21015;&#34920;&#20013;&#29420;&#31435;&#32771;&#34385;&#27599;&#20010;&#39033;&#30446;&#65292;&#24182;&#23545;&#27599;&#20010;&#39033;&#30446;&#36827;&#34892;&#20108;&#36873;&#19968;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22810;&#39033;&#24335;Logit&#65288;MNL&#65289;&#36873;&#25321;&#27169;&#22411;&#21040;LTR&#26694;&#26550;&#20013;&#65292;&#23427;&#25429;&#25417;&#21040;&#29992;&#25143;&#23558;&#26377;&#24207;&#30340;&#39033;&#30446;&#21015;&#34920;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#65292;&#20174;&#25152;&#26377;&#39033;&#30446;&#21644;&#27809;&#26377;&#28857;&#20987;&#36873;&#39033;&#20013;&#20570;&#20986;&#19968;&#20010;&#36873;&#25321;&#30340;&#34892;&#20026;&#12290;&#22312;MNL&#27169;&#22411;&#19979;&#65292;&#29992;&#25143;&#26356;&#21916;&#27426;&#26412;&#36136;&#19978;&#26356;&#26377;&#21560;&#24341;&#21147;&#30340;&#39033;&#30446;&#65292;&#25110;&#32773;&#22788;&#20110;&#21015;&#34920;&#20013;&#26356;&#21487;&#21462;&#30340;&#20301;&#32622;&#30340;&#39033;&#30446;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19978;&#32622;&#20449;&#30028;&#65288;UCB&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#24050;&#30693;&#21644;&#26410;&#30693;&#30340;&#20301;&#32622;&#20381;&#36182;&#21442;&#25968;&#30340;&#20004;&#31181;&#35774;&#32622;&#20013;&#26368;&#23567;&#21270;&#36951;&#25022;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#23548;&#33268;&#20102;&#23545;&#38382;&#39064;&#30340;$\Omega&#65288;\sqrt{JT}&#65289;$&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning the optimal ordering of content is an important challenge in website design. The learning to rank (LTR) framework models this problem as a sequential problem of selecting lists of content and observing where users decide to click. Most previous work on LTR assumes that the user considers each item in the list in isolation, and makes binary choices to click or not on each. We introduce a multinomial logit (MNL) choice model to the LTR framework, which captures the behaviour of users who consider the ordered list of items as a whole and make a single choice among all the items and a no-click option. Under the MNL model, the user favours items which are either inherently more attractive, or placed in a preferable position within the list. We propose upper confidence bound (UCB) algorithms to minimise regret in two settings where the position dependent parameters are known, and unknown. We present theoretical analysis leading to an $\Omega(\sqrt{JT})$ lower bound for the problem
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TESS&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35813;&#25361;&#25112;&#20316;&#20026;&#19968;&#31181;&#27169;&#24335;&#26816;&#27979;&#38382;&#39064;&#26469;&#35299;&#20915;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#20174;&#38543;&#26426;&#23454;&#39564;&#25968;&#25454;&#20013;&#25214;&#21040;&#21463;&#27835;&#30103;&#24433;&#21709;&#26368;&#22823;&#30340;&#23376;&#32676;&#20307;&#65292;&#21516;&#26102;&#20551;&#35774;&#26368;&#23569;&#19988;&#20855;&#26377;&#27491;&#30830;&#24615;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/1803.09159</link><description>&lt;p&gt;
&#24322;&#36136;&#37327;&#21270;&#22788;&#29702;&#25928;&#24212;&#30340;&#39640;&#25928;&#21457;&#29616;&#65306;&#22522;&#20110;&#24322;&#24120;&#27169;&#24335;&#26816;&#27979;&#30340;&#38543;&#26426;&#23454;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Discovery of Heterogeneous Quantile Treatment Effects in Randomized Experiments via Anomalous Pattern Detection. (arXiv:1803.09159v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1803.09159
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;TESS&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35813;&#25361;&#25112;&#20316;&#20026;&#19968;&#31181;&#27169;&#24335;&#26816;&#27979;&#38382;&#39064;&#26469;&#35299;&#20915;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#20174;&#38543;&#26426;&#23454;&#39564;&#25968;&#25454;&#20013;&#25214;&#21040;&#21463;&#27835;&#30103;&#24433;&#21709;&#26368;&#22823;&#30340;&#23376;&#32676;&#20307;&#65292;&#21516;&#26102;&#20551;&#35774;&#26368;&#23569;&#19988;&#20855;&#26377;&#27491;&#30830;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#20272;&#35745;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#26041;&#27861;&#36827;&#34892;&#25991;&#29486;&#32508;&#36848;&#26102;&#65292;&#27599;&#31181;&#25552;&#20986;&#30340;&#26041;&#27861;&#37117;&#20250;&#23545;&#24178;&#39044;&#25928;&#24212;&#21450;&#35201;&#26126;&#30830;&#20272;&#35745;&#30340;&#20122;&#32676;&#20307;&#20570;&#20986;&#19968;&#31995;&#21015;&#20855;&#26377;&#38480;&#21046;&#24615;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#22823;&#37096;&#20998;&#25991;&#29486;&#27809;&#26377;&#25552;&#20379;&#30830;&#23450;&#21738;&#20123;&#20122;&#32676;&#20307;&#21463;&#24433;&#21709;&#26368;&#22823;&#30340;&#26426;&#21046;&#8212;&#8212;&#38500;&#20102;&#25163;&#21160;&#26816;&#26597;&#8212;&#8212;&#24182;&#19988;&#22312;&#30830;&#23450;&#21463;&#24433;&#21709;&#26368;&#22823;&#30340;&#20122;&#32676;&#20307;&#26102;&#20063;&#24456;&#23569;&#33021;&#25552;&#20379;&#27491;&#30830;&#24615;&#20445;&#35777;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Treatment Effect Subset Scan (TESS)&#65292;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#21457;&#29616;&#22312;&#38543;&#26426;&#23454;&#39564;&#20013;&#21738;&#20123;&#20122;&#32676;&#20307;&#26368;&#26126;&#26174;&#22320;&#21463;&#21040;&#22788;&#29702;&#24433;&#21709;&#12290;&#25105;&#20204;&#23558;&#20854;&#20316;&#20026;&#19968;&#20010;&#27169;&#24335;&#26816;&#27979;&#38382;&#39064;&#26469;&#25552;&#20986;&#65292;&#36890;&#36807;&#26377;&#25928;&#22320;&#23545;&#20122;&#32676;&#20307;&#36827;&#34892;&#38750;&#21442;&#25968;&#25195;&#25551;&#32479;&#35745;&#37327;&#65288;&#26465;&#20214;&#37327;&#21270;&#22788;&#29702;&#25928;&#24212;&#30340;&#19968;&#31181;&#24230;&#37327;&#65289;&#30340;&#26368;&#22823;&#21270;&#26469;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#21463;&#24178;&#39044;&#24433;&#21709;&#26368;&#22823;&#30340;&#20998;&#24067;&#21464;&#21270;&#26368;&#22823;&#30340;&#20122;&#32676;&#20307;&#65292;&#21516;&#26102;&#23545;&#20110;&#24178;&#39044;&#25928;&#24212;&#30340;&#24433;&#21709;&#20063;&#20570;&#20986;&#26368;&#23567;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the recent literature on estimating heterogeneous treatment effects, each proposed method makes its own set of restrictive assumptions about the intervention's effects and which subpopulations to explicitly estimate. Moreover, the majority of the literature provides no mechanism to identify which subpopulations are the most affected--beyond manual inspection--and provides little guarantee on the correctness of the identified subpopulations. Therefore, we propose Treatment Effect Subset Scan (TESS), a new method for discovering which subpopulation in a randomized experiment is most significantly affected by a treatment. We frame this challenge as a pattern detection problem where we efficiently maximize a nonparametric scan statistic (a measure of the conditional quantile treatment effect) over subpopulations. Furthermore, we identify the subpopulation which experiences the largest distributional change as a result of the intervention, while making minimal assumptions about the inter
&lt;/p&gt;</description></item></channel></rss>