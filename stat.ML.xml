<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#21644;&#36816;&#34892;&#25968;&#25454;&#30340;&#29983;&#23384;&#24314;&#27169;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24555;&#29031;&#25968;&#25454;&#35757;&#32451;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#38024;&#23545;&#38750;&#21516;&#36136;&#37319;&#26679;&#25968;&#25454;&#65292;&#36890;&#36807;&#21516;&#36136;&#37319;&#26679;&#20351;&#24471;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#33021;&#22815;&#24212;&#29992;&#24182;&#20135;&#29983;&#29702;&#24819;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.18739</link><description>&lt;p&gt;
&#22522;&#20110;&#36816;&#34892;&#25968;&#25454;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#29992;&#36884;&#29983;&#23384;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Usage-Specific Survival Modeling Based on Operational Data and Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18739
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#21644;&#36816;&#34892;&#25968;&#25454;&#30340;&#29983;&#23384;&#24314;&#27169;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24555;&#29031;&#25968;&#25454;&#35757;&#32451;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#38024;&#23545;&#38750;&#21516;&#36136;&#37319;&#26679;&#25968;&#25454;&#65292;&#36890;&#36807;&#21516;&#36136;&#37319;&#26679;&#20351;&#24471;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#33021;&#22815;&#24212;&#29992;&#24182;&#20135;&#29983;&#29702;&#24819;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35268;&#21010;&#32500;&#25252;&#26102;&#65292;&#20934;&#30830;&#39044;&#27979;&#38646;&#37096;&#20214;&#25925;&#38556;&#26102;&#38388;&#33267;&#20851;&#37325;&#35201;&#65292;&#36890;&#36807;&#23545;&#36825;&#20123;&#25925;&#38556;&#26102;&#38388;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#29983;&#23384;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#34987;&#35777;&#26126;&#29305;&#21035;&#26377;&#29992;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20256;&#32479;&#29983;&#23384;&#27169;&#22411;&#65292;&#20351;&#29992;&#22312;&#29305;&#23450;&#26102;&#38388;&#36830;&#32493;&#25910;&#38598;&#21644;&#23384;&#20648;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#31216;&#20026;&#24555;&#29031;&#12290;&#36825;&#31181;&#31867;&#22411;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#24615;&#26159;&#23427;&#21487;&#20197;&#21253;&#21547;&#26469;&#33258;&#29305;&#23450;&#20010;&#20307;&#30340;&#22810;&#20010;&#24555;&#29031;&#65292;&#36825;&#23548;&#33268;&#26631;&#20934;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#26080;&#27861;&#30452;&#25509;&#24212;&#29992;&#65292;&#22240;&#20026;&#25968;&#25454;&#19981;&#26159;&#29420;&#31435;&#30340;&#12290;&#28982;&#32780;&#65292;&#35813;&#35770;&#25991;&#34920;&#26126;&#65292;&#22914;&#26524;&#25968;&#25454;&#20197;&#25152;&#26377;&#20010;&#20307;&#30340;&#25152;&#26377;&#24555;&#29031;&#26102;&#38388;&#30456;&#21516;&#30340;&#29305;&#23450;&#26684;&#24335;&#23384;&#22312;&#65292;&#31216;&#20026;&#21516;&#36136;&#37319;&#26679;&#65292;&#21017;&#21487;&#20197;&#24212;&#29992;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#24182;&#20135;&#29983;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25968;&#25454;&#24182;&#38750;&#21516;&#36136;&#37319;&#26679;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18739v1 Announce Type: new  Abstract: Accurate predictions of when a component will fail are crucial when planning maintenance, and by modeling the distribution of these failure times, survival models have shown to be particularly useful in this context. The presented methodology is based on conventional neural network-based survival models that are trained using data that is continuously gathered and stored at specific times, called snapshots. An important property of this type of training data is that it can contain more than one snapshot from a specific individual which results in that standard maximum likelihood training can not be directly applied since the data is not independent. However, the papers show that if the data is in a specific format where all snapshot times are the same for all individuals, called homogeneously sampled, maximum likelihood training can be applied and produce desirable results. In many cases, the data is not homogeneously sampled and in this
&lt;/p&gt;</description></item><item><title>&#39318;&#27425;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#37327;&#20043;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#21322;&#30417;&#30563;&#28145;&#24230;&#22240;&#26524;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2403.18717</link><description>&lt;p&gt;
&#28145;&#24230;&#22240;&#26524;&#29983;&#25104;&#27169;&#22411;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Learning for Deep Causal Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18717
&lt;/p&gt;
&lt;p&gt;
&#39318;&#27425;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#37327;&#20043;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#21322;&#30417;&#30563;&#28145;&#24230;&#22240;&#26524;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#33021;&#22815;&#22238;&#31572;&#8220;&#22914;&#26524;$y$&#21464;&#20026;$z$&#65292;$x$&#20250;&#22914;&#20309;&#21464;&#21270;&#65311;&#8221;&#36825;&#31867;&#38382;&#39064;&#30340;&#27169;&#22411;&#23545;&#20110;&#25512;&#21160;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#35757;&#32451;&#33021;&#22815;&#35299;&#20915;&#36825;&#31867;&#21453;&#20107;&#23454;&#38382;&#39064;&#30340;&#22240;&#26524;&#29983;&#25104;&#27169;&#22411;&#30446;&#21069;&#35201;&#27714;&#25152;&#26377;&#30456;&#20851;&#21464;&#37327;&#22343;&#24050;&#34987;&#35266;&#23519;&#21040;&#65292;&#24182;&#19988;&#30456;&#24212;&#30340;&#26631;&#31614;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#21487;&#29992;&#12290;&#25105;&#20204;&#39318;&#27425;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#37327;&#20043;&#38388;&#22240;&#26524;&#20851;&#31995;&#30340;&#21322;&#30417;&#30563;&#28145;&#24230;&#22240;&#26524;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#26368;&#22823;&#38480;&#24230;&#22320;&#21033;&#29992;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18717v1 Announce Type: cross  Abstract: Developing models that can answer questions of the form "How would $x$ change if $y$ had been $z$?" is fundamental for advancing medical image analysis. Training causal generative models that address such counterfactual questions, though, currently requires that all relevant variables have been observed and that corresponding labels are available in training data. However, clinical data may not have complete records for all patients and state of the art causal generative models are unable to take full advantage of this. We thus develop, for the first time, a semi-supervised deep causal generative model that exploits the causal relationships between variables to maximise the use of all available data. We explore this in the setting where each sample is either fully labelled or fully unlabelled, as well as the more clinically realistic case of having different labels missing for each sample. We leverage techniques from causal inference t
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19982;&#20020;&#24202;&#32972;&#26223;&#30456;&#19968;&#33268;&#30340;&#26032;&#39062;&#29983;&#21629;&#20307;&#24449;&#39044;&#27979;&#24615;&#33021;&#25351;&#26631;&#65292;&#36890;&#36807;&#25429;&#25417;&#19982;&#20020;&#24202;&#35268;&#33539;&#30340;&#20559;&#24046;&#12289;&#25972;&#20307;&#36235;&#21183;&#21644;&#36235;&#21183;&#20559;&#24046;&#65292;&#20026;&#26089;&#26399;&#21457;&#29616;&#19981;&#33391;&#20107;&#20214;&#38138;&#24179;&#36947;&#36335;&#12290;</title><link>https://arxiv.org/abs/2403.18668</link><description>&lt;p&gt;
&#20197;&#30456;&#20851;&#24615;&#20026;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Aiming for Relevance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18668
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19982;&#20020;&#24202;&#32972;&#26223;&#30456;&#19968;&#33268;&#30340;&#26032;&#39062;&#29983;&#21629;&#20307;&#24449;&#39044;&#27979;&#24615;&#33021;&#25351;&#26631;&#65292;&#36890;&#36807;&#25429;&#25417;&#19982;&#20020;&#24202;&#35268;&#33539;&#30340;&#20559;&#24046;&#12289;&#25972;&#20307;&#36235;&#21183;&#21644;&#36235;&#21183;&#20559;&#24046;&#65292;&#20026;&#26089;&#26399;&#21457;&#29616;&#19981;&#33391;&#20107;&#20214;&#38138;&#24179;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#65288;ICU&#65289;&#20013;&#65292;&#29983;&#21629;&#20307;&#24449;&#33267;&#20851;&#37325;&#35201;&#12290;&#23427;&#20204;&#29992;&#20110;&#36319;&#36394;&#24739;&#32773;&#30340;&#29366;&#24577;&#65292;&#24182;&#35782;&#21035;&#20020;&#24202;&#19978;&#26174;&#33879;&#30340;&#21464;&#21270;&#12290;&#39044;&#27979;&#29983;&#21629;&#20307;&#24449;&#36712;&#36857;&#23545;&#20110;&#26089;&#26399;&#21457;&#29616;&#19981;&#33391;&#20107;&#20214;&#20855;&#26377;&#37325;&#35201;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#25351;&#26631;&#22914;RMSE&#24448;&#24448;&#26080;&#27861;&#25429;&#25417;&#36825;&#20123;&#39044;&#27979;&#30340;&#30495;&#27491;&#20020;&#24202;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#29983;&#21629;&#20307;&#24449;&#39044;&#27979;&#24615;&#33021;&#25351;&#26631;&#65292;&#19982;&#20020;&#24202;&#32972;&#26223;&#30456;&#19968;&#33268;&#65292;&#20851;&#27880;&#19982;&#20020;&#24202;&#35268;&#33539;&#30340;&#20559;&#24046;&#12289;&#25972;&#20307;&#36235;&#21183;&#21644;&#36235;&#21183;&#20559;&#24046;&#12290;&#36825;&#20123;&#25351;&#26631;&#28304;&#33258;&#36890;&#36807;&#19982;ICU&#20020;&#24202;&#21307;&#29983;&#30340;&#35775;&#35848;&#33719;&#24471;&#30340;&#23454;&#35777;&#25928;&#29992;&#26354;&#32447;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#38598;&#65288;MIMIC&#21644;eICU&#65289;&#39564;&#35777;&#20102;&#36825;&#20123;&#25351;&#26631;&#30340;&#26377;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#25351;&#26631;&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20174;&#32780;&#24471;&#21040;&#22312;&#39044;&#27979;&#20020;&#24202;&#37325;&#35201;&#20107;&#20214;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#30340;&#27169;&#22411;&#12290;&#36825;&#39033;&#30740;&#31350;&#20026;&#20020;&#24202;&#23454;&#36341;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18668v1 Announce Type: cross  Abstract: Vital signs are crucial in intensive care units (ICUs). They are used to track the patient's state and to identify clinically significant changes. Predicting vital sign trajectories is valuable for early detection of adverse events. However, conventional machine learning metrics like RMSE often fail to capture the true clinical relevance of such predictions. We introduce novel vital sign prediction performance metrics that align with clinical contexts, focusing on deviations from clinical norms, overall trends, and trend deviations. These metrics are derived from empirical utility curves obtained in a previous study through interviews with ICU clinicians. We validate the metrics' usefulness using simulated and real clinical datasets (MIMIC and eICU). Furthermore, we employ these metrics as loss functions for neural networks, resulting in models that excel in predicting clinically significant events. This research paves the way for clin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#36890;&#36807;&#20998;&#27573;&#23450;&#20041;&#39118;&#38505;&#20989;&#25968;&#21644;&#23494;&#24230;&#20989;&#25968;&#65292;&#26377;&#25928;&#25193;&#23637;&#20102;&#26631;&#20934;&#27169;&#22411;&#24182;&#23637;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.18664</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#27573;&#29983;&#23384;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Network-Based Piecewise Survival Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#36890;&#36807;&#20998;&#27573;&#23450;&#20041;&#39118;&#38505;&#20989;&#25968;&#21644;&#23494;&#24230;&#20989;&#25968;&#65292;&#26377;&#25928;&#25193;&#23637;&#20102;&#26631;&#20934;&#27169;&#22411;&#24182;&#23637;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#29983;&#23384;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#26159;&#22522;&#20110;&#23545;&#26102;&#38388;&#36827;&#34892;&#20998;&#21106;&#30340;&#39118;&#38505;&#20989;&#25968;&#21644;&#23494;&#24230;&#20989;&#25968;&#30340;&#20998;&#27573;&#23450;&#20041;&#32780;&#25351;&#23450;&#30340;&#65307;&#25991;&#20013;&#23637;&#31034;&#20102;&#24120;&#25968;&#21644;&#32447;&#24615;&#20998;&#27573;&#23450;&#20041;&#65292;&#24471;&#21040;&#20102;&#22235;&#20010;&#27169;&#22411;&#30340;&#31995;&#21015;&#12290;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#24120;&#29992;&#30340;&#31163;&#25955;&#26102;&#38388;&#21644;&#20998;&#27573;&#25351;&#25968;&#27169;&#22411;&#30340;&#24310;&#20280;&#65292;&#20174;&#32780;&#20026;&#36825;&#32452;&#26631;&#20934;&#27169;&#22411;&#22686;&#21152;&#20102;&#28789;&#27963;&#24615;&#12290;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#38598;&#34920;&#26126;&#65292;&#36825;&#20123;&#27169;&#22411;&#34920;&#29616;&#33391;&#22909;&#65292;&#30456;&#36739;&#20110;&#39640;&#24230;&#34920;&#36798;&#33021;&#21147;&#30340;&#26368;&#26032;&#33021;&#37327;&#27169;&#22411;&#65292;&#20165;&#38656;&#35201;&#19968;&#23567;&#37096;&#20998;&#35745;&#31639;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18664v1 Announce Type: cross  Abstract: In this paper, a family of neural network-based survival models is presented. The models are specified based on piecewise definitions of the hazard function and the density function on a partitioning of the time; both constant and linear piecewise definitions are presented, resulting in a family of four models. The models can be seen as an extension of the commonly used discrete-time and piecewise exponential models and thereby add flexibility to this set of standard models. Using a simulated dataset the models are shown to perform well compared to the highly expressive, state-of-the-art energy-based model, while only requiring a fraction of the computation time.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#29992;&#20110;&#22312;&#39640;&#24230;&#21463;&#21040;&#31163;&#32676;&#20540;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#24674;&#22797;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#24403;&#21021;&#22987;&#21270;&#26465;&#20214;&#24471;&#21040;&#28385;&#36275;&#26102;&#65292;&#35813;&#20272;&#35745;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28508;&#22312;&#30340;&#23376;&#31354;&#38388;&#12290;</title><link>https://arxiv.org/abs/2403.18658</link><description>&lt;p&gt;
&#23545;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees for the Subspace-Constrained Tyler's Estimator
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18658
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#29992;&#20110;&#22312;&#39640;&#24230;&#21463;&#21040;&#31163;&#32676;&#20540;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#24674;&#22797;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#24403;&#21021;&#22987;&#21270;&#26465;&#20214;&#24471;&#21040;&#28385;&#36275;&#26102;&#65292;&#35813;&#20272;&#35745;&#22120;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28508;&#22312;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;&#20110;&#24674;&#22797;&#21487;&#33021;&#21463;&#21040;&#20005;&#37325;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#32422;&#26463;&#30340;Tyler&#20272;&#35745;&#22120;&#65288;STE&#65289;&#12290;&#23427;&#20551;&#35774;&#19968;&#20010;&#24369;&#30340;&#20869;&#28857;-&#22806;&#28857;&#27169;&#22411;&#65292;&#24182;&#20801;&#35768;&#20869;&#28857;&#30340;&#27604;&#20363;&#23567;&#20110;&#23548;&#33268;&#40065;&#26834;&#23376;&#31354;&#38388;&#24674;&#22797;&#38382;&#39064;&#35745;&#31639;&#22256;&#38590;&#30340;&#27604;&#20363;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#23427;&#26174;&#31034;&#22914;&#26524;STE&#30340;&#21021;&#22987;&#21270;&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#65292;&#37027;&#20040;STE&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28508;&#22312;&#30340;&#23376;&#31354;&#38388;&#12290;&#27492;&#22806;&#65292;&#23427;&#36824;&#34920;&#26126;&#22312;&#24191;&#20041;&#30340;&#24178;&#33609;&#22534;&#27169;&#22411;&#19979;&#65292;&#30001;Tyler&#30340;M-&#20272;&#35745;&#22120;&#65288;TME&#65289;&#21021;&#22987;&#21270;&#30340;STE&#21487;&#20197;&#22312;&#20869;&#28857;&#30340;&#27604;&#20363;&#22826;&#23567;&#20197;&#33267;&#20110;TME&#26080;&#27861;&#22788;&#29702;&#26102;&#24674;&#22797;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18658v1 Announce Type: cross  Abstract: This work analyzes the subspace-constrained Tyler's estimator (STE) designed for recovering a low-dimensional subspace within a dataset that may be highly corrupted with outliers. It assumes a weak inlier-outlier model and allows the fraction of inliers to be smaller than a fraction that leads to computational hardness of the robust subspace recovery problem. It shows that in this setting, if the initialization of STE, which is an iterative algorithm, satisfies a certain condition, then STE can effectively recover the underlying subspace. It further shows that under the generalized haystack model, STE initialized by the Tyler's M-estimator (TME), can recover the subspace when the fraction of iniliers is too small for TME to handle.
&lt;/p&gt;</description></item><item><title>SteinGen&#26159;&#19968;&#31181;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#26679;&#26412;&#30340;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;Stein&#26041;&#27861;&#21644;MCMC&#21160;&#21147;&#23398;&#65292;&#36866;&#29992;&#20110;&#21482;&#26377;&#19968;&#27425;&#35266;&#23519;&#21040;&#30340;&#22270;&#24418;&#65292;&#36991;&#20813;&#20102;&#21442;&#25968;&#20272;&#35745;&#30340;&#38656;&#27714;&#12290;</title><link>https://arxiv.org/abs/2403.18578</link><description>&lt;p&gt;
SteinGen: &#29983;&#25104;&#24544;&#23454;&#21644;&#22810;&#26679;&#21270;&#30340;&#22270;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
SteinGen: Generating Fidelitous and Diverse Graph Samples
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18578
&lt;/p&gt;
&lt;p&gt;
SteinGen&#26159;&#19968;&#31181;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#26679;&#26412;&#30340;&#26032;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;Stein&#26041;&#27861;&#21644;MCMC&#21160;&#21147;&#23398;&#65292;&#36866;&#29992;&#20110;&#21482;&#26377;&#19968;&#27425;&#35266;&#23519;&#21040;&#30340;&#22270;&#24418;&#65292;&#36991;&#20813;&#20102;&#21442;&#25968;&#20272;&#35745;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20445;&#30041;&#29305;&#24449;&#32467;&#26500;&#24182;&#20419;&#36827;&#26679;&#26412;&#22810;&#26679;&#24615;&#30340;&#22270;&#24418;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#29305;&#21035;&#26159;&#24403;&#22270;&#24418;&#35266;&#23519;&#25968;&#37327;&#36739;&#23569;&#26102;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20165;&#20174;&#19968;&#20010;&#35266;&#23519;&#21040;&#30340;&#22270;&#24418;&#29983;&#25104;&#22270;&#24418;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#22270;&#24418;&#30340;&#35774;&#32622;&#20013;&#20197;&#25351;&#25968;&#38543;&#26426;&#22270;&#24418;&#27169;&#22411;&#30340;&#24418;&#24335;&#34920;&#36798;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#29983;&#25104;&#36807;&#31243;SteinGen&#32467;&#21512;&#20102;Stein&#26041;&#27861;&#21644;&#22522;&#20110;MCMC&#30340;&#39532;&#23572;&#21487;&#22827;&#21160;&#21147;&#23398;&#30340;&#24605;&#24819;&#65292;&#35813;&#21160;&#21147;&#23398;&#22522;&#20110;&#30446;&#26631;&#27169;&#22411;&#30340;Stein&#31639;&#23376;&#12290;SteinGen&#20351;&#29992;&#19982;e&#30456;&#20851;&#32852;&#30340;Glauber&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18578v1 Announce Type: cross  Abstract: Generating graphs that preserve characteristic structures while promoting sample diversity can be challenging, especially when the number of graph observations is small. Here, we tackle the problem of graph generation from only one observed graph. The classical approach of graph generation from parametric models relies on the estimation of parameters, which can be inconsistent or expensive to compute due to intractable normalisation constants. Generative modelling based on machine learning techniques to generate high-quality graph samples avoids parameter estimation but usually requires abundant training samples. Our proposed generating procedure, SteinGen, which is phrased in the setting of graphs as realisations of exponential random graph models, combines ideas from Stein's method and MCMC by employing Markovian dynamics which are based on a Stein operator for the target model. SteinGen uses the Glauber dynamics associated with an e
&lt;/p&gt;</description></item><item><title>skscope&#26159;&#19968;&#20010;Python&#24211;&#65292;&#36890;&#36807;&#21482;&#38656;&#32534;&#20889;&#30446;&#26631;&#20989;&#25968;&#65292;&#23601;&#33021;&#24555;&#36895;&#23454;&#29616;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#19979;&#65292;&#20854;&#39640;&#25928;&#23454;&#29616;&#20351;&#24471;&#27714;&#35299;&#22120;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#31232;&#30095;&#35299;&#65292;&#36895;&#24230;&#27604;&#22522;&#20934;&#20984;&#27714;&#35299;&#22120;&#24555;80&#20493;&#12290;</title><link>https://arxiv.org/abs/2403.18540</link><description>&lt;p&gt;
skscope&#65306;Python&#20013;&#30340;&#24555;&#36895;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
skscope: Fast Sparsity-Constrained Optimization in Python
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18540
&lt;/p&gt;
&lt;p&gt;
skscope&#26159;&#19968;&#20010;Python&#24211;&#65292;&#36890;&#36807;&#21482;&#38656;&#32534;&#20889;&#30446;&#26631;&#20989;&#25968;&#65292;&#23601;&#33021;&#24555;&#36895;&#23454;&#29616;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#20915;&#65292;&#24182;&#19988;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#19979;&#65292;&#20854;&#39640;&#25928;&#23454;&#29616;&#20351;&#24471;&#27714;&#35299;&#22120;&#33021;&#22815;&#36805;&#36895;&#33719;&#24471;&#31232;&#30095;&#35299;&#65292;&#36895;&#24230;&#27604;&#22522;&#20934;&#20984;&#27714;&#35299;&#22120;&#24555;80&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31232;&#30095;&#32422;&#26463;&#20248;&#21270;&#65288;SCO&#65289;&#19978;&#24212;&#29992;&#36845;&#20195;&#27714;&#35299;&#22120;&#38656;&#35201;&#32321;&#29712;&#30340;&#25968;&#23398;&#25512;&#23548;&#21644;&#20180;&#32454;&#30340;&#32534;&#31243;/&#35843;&#35797;&#65292;&#36825;&#38480;&#21046;&#20102;&#36825;&#20123;&#27714;&#35299;&#22120;&#30340;&#24191;&#27867;&#24433;&#21709;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#24211;skscope&#65292;&#20197;&#20811;&#26381;&#27492;&#38556;&#30861;&#12290;&#20511;&#21161;skscope&#65292;&#29992;&#25143;&#21482;&#38656;&#32534;&#20889;&#30446;&#26631;&#20989;&#25968;&#21363;&#21487;&#35299;&#20915;SCO&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#20004;&#20010;&#20363;&#23376;&#28436;&#31034;&#20102;skscope&#30340;&#26041;&#20415;&#20043;&#22788;&#65292;&#20854;&#20013;&#21482;&#38656;&#22235;&#34892;&#20195;&#30721;&#23601;&#21487;&#20197;&#35299;&#20915;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#36235;&#21183;&#36807;&#28388;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;skscope&#30340;&#39640;&#25928;&#23454;&#29616;&#20351;&#24471;&#26368;&#20808;&#36827;&#30340;&#27714;&#35299;&#22120;&#21487;&#20197;&#24555;&#36895;&#33719;&#24471;&#31232;&#30095;&#35299;&#65292;&#32780;&#26080;&#38656;&#32771;&#34385;&#21442;&#25968;&#31354;&#38388;&#30340;&#39640;&#32500;&#24230;&#12290;&#25968;&#20540;&#23454;&#39564;&#26174;&#31034;&#65292;skscope&#20013;&#30340;&#21487;&#29992;&#27714;&#35299;&#22120;&#21487;&#20197;&#23454;&#29616;&#27604;&#22522;&#20934;&#20984;&#27714;&#35299;&#22120;&#33719;&#24471;&#30340;&#31454;&#20105;&#26494;&#24347;&#35299;&#39640;&#36798;80&#20493;&#30340;&#21152;&#36895;&#24230;&#12290;skscope&#24050;&#32463;&#21457;&#24067;&#22312;Python&#36719;&#20214;&#21253;&#32034;&#24341;&#65288;PyPI&#65289;&#21644;Conda&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18540v1 Announce Type: cross  Abstract: Applying iterative solvers on sparsity-constrained optimization (SCO) requires tedious mathematical deduction and careful programming/debugging that hinders these solvers' broad impact. In the paper, the library skscope is introduced to overcome such an obstacle. With skscope, users can solve the SCO by just programming the objective function. The convenience of skscope is demonstrated through two examples in the paper, where sparse linear regression and trend filtering are addressed with just four lines of code. More importantly, skscope's efficient implementation allows state-of-the-art solvers to quickly attain the sparse solution regardless of the high dimensionality of parameter space. Numerical experiments reveal the available solvers in skscope can achieve up to 80x speedup on the competing relaxation solutions obtained via the benchmarked convex solver. skscope is published on the Python Package Index (PyPI) and Conda, and its 
&lt;/p&gt;</description></item><item><title>MKL&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#28789;&#27963;&#26377;&#25928;&#30340;&#22810;&#32452;&#23398;&#25968;&#25454;&#38598;&#25104;&#26041;&#27861;&#65292;&#21487;&#20197;&#19982;&#22797;&#26434;&#30340;&#30417;&#30563;&#24335;&#22810;&#32452;&#23398;&#25972;&#21512;&#26041;&#27861;&#31454;&#20105;</title><link>https://arxiv.org/abs/2403.18355</link><description>&lt;p&gt;
&#30417;&#30563;&#22810;&#26680;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#22810;&#32452;&#23398;&#25968;&#25454;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Supervised Multiple Kernel Learning approaches for multi-omics data integration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18355
&lt;/p&gt;
&lt;p&gt;
MKL&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#28789;&#27963;&#26377;&#25928;&#30340;&#22810;&#32452;&#23398;&#25968;&#25454;&#38598;&#25104;&#26041;&#27861;&#65292;&#21487;&#20197;&#19982;&#22797;&#26434;&#30340;&#30417;&#30563;&#24335;&#22810;&#32452;&#23398;&#25972;&#21512;&#26041;&#27861;&#31454;&#20105;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#36890;&#37327;&#25216;&#26415;&#30340;&#36827;&#23637;&#23548;&#33268;&#36234;&#26469;&#36234;&#22810;&#30340;&#32452;&#23398;&#25968;&#25454;&#38598;&#30340;&#21487;&#29992;&#24615;&#12290;&#22810;&#31181;&#24322;&#36136;&#25968;&#25454;&#28304;&#30340;&#38598;&#25104;&#30446;&#21069;&#26159;&#29983;&#29289;&#23398;&#21644;&#29983;&#29289;&#20449;&#24687;&#23398;&#39046;&#22495;&#30340;&#19968;&#20010;&#38382;&#39064;&#12290;&#22810;&#26680;&#23398;&#20064;&#65288;MKL&#65289;&#24050;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#28789;&#27963;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#22810;&#32452;&#23398;&#36755;&#20837;&#30340;&#22810;&#26679;&#24615;&#65292;&#23613;&#31649;&#23427;&#22312;&#22522;&#22240;&#32452;&#25968;&#25454;&#25366;&#25496;&#20013;&#26159;&#19968;&#31181;&#19981;&#24120;&#29992;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#19981;&#21516;&#26680;&#34701;&#21512;&#31574;&#30053;&#30340;&#26032;&#39062;MKL&#26041;&#27861;&#12290;&#20026;&#20102;&#20174;&#36755;&#20837;&#26680;&#30340;&#20803;&#26680;&#20013;&#23398;&#20064;&#65292;&#25105;&#20204;&#23558;&#26080;&#30417;&#30563;&#38598;&#25104;&#31639;&#27861;&#35843;&#25972;&#20026;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#30417;&#30563;&#20219;&#21153;&#12290;&#25105;&#20204;&#36824;&#27979;&#35797;&#20102;&#29992;&#20110;&#26680;&#34701;&#21512;&#21644;&#20998;&#31867;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#22522;&#20110;MKL&#30340;&#27169;&#22411;&#21487;&#20197;&#19982;&#26356;&#22797;&#26434;&#12289;&#26368;&#20808;&#36827;&#30340;&#30417;&#30563;&#24335;&#22810;&#32452;&#23398;&#25972;&#21512;&#26041;&#27861;&#31454;&#20105;&#12290;&#22810;&#26680;&#23398;&#20064;&#20026;&#22810;&#32452;&#23398;&#22522;&#22240;&#32452;&#25968;&#25454;&#20013;&#30340;&#39044;&#27979;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18355v1 Announce Type: cross  Abstract: Advances in high-throughput technologies have originated an ever-increasing availability of omics datasets. The integration of multiple heterogeneous data sources is currently an issue for biology and bioinformatics. Multiple kernel learning (MKL) has shown to be a flexible and valid approach to consider the diverse nature of multi-omics inputs, despite being an underused tool in genomic data mining.We provide novel MKL approaches based on different kernel fusion strategies.To learn from the meta-kernel of input kernels, we adaptedunsupervised integration algorithms for supervised tasks with support vector machines.We also tested deep learning architectures for kernel fusion and classification.The results show that MKL-based models can compete with more complex, state-of-the-art, supervised multi-omics integrative approaches. Multiple kernel learning offers a natural framework for predictive models in multi-omics genomic data. Our resu
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;SelMix&#65292;&#19968;&#31181;&#36873;&#25321;&#24615;&#28151;&#21512;&#30340;&#24265;&#20215;&#24494;&#35843;&#25216;&#26415;&#65292;&#29992;&#20110;&#20248;&#21270;&#39044;&#35757;&#32451;&#27169;&#22411;&#20197;&#23454;&#29616;&#25152;&#38656;&#30340;&#38750;&#21487;&#20998;&#35299;&#30446;&#26631;&#12290;</title><link>https://arxiv.org/abs/2403.18301</link><description>&lt;p&gt;
&#36873;&#25321;&#24615;&#28151;&#21512;&#24494;&#35843;&#20197;&#20248;&#21270;&#38750;&#21487;&#20998;&#35299;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18301
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;SelMix&#65292;&#19968;&#31181;&#36873;&#25321;&#24615;&#28151;&#21512;&#30340;&#24265;&#20215;&#24494;&#35843;&#25216;&#26415;&#65292;&#29992;&#20110;&#20248;&#21270;&#39044;&#35757;&#32451;&#27169;&#22411;&#20197;&#23454;&#29616;&#25152;&#38656;&#30340;&#38750;&#21487;&#20998;&#35299;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#32852;&#32593;&#20351;&#29992;&#30340;&#22686;&#21152;&#23548;&#33268;&#20102;&#22823;&#37327;&#25968;&#25454;&#30340;&#29983;&#25104;&#65292;&#20174;&#32780;&#37319;&#29992;&#20102;&#21508;&#31181;&#30417;&#30563;&#21644;&#21322;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26377;&#25928;&#21033;&#29992;&#22823;&#37327;&#25968;&#25454;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#23558;&#36825;&#20123;&#27169;&#22411;&#37096;&#32626;&#21040;&#29616;&#23454;&#19990;&#30028;&#20043;&#21069;&#65292;&#24517;&#39035;&#20005;&#26684;&#35780;&#20272;&#23427;&#20204;&#22312;&#35832;&#22914;&#26368;&#22351;&#24773;&#20917;&#21484;&#22238;&#29575;&#20043;&#31867;&#30340;&#24615;&#33021;&#25351;&#26631;&#19978;&#30340;&#34920;&#29616;&#65292;&#24182;&#28385;&#36275;&#20844;&#24179;&#24615;&#31561;&#32422;&#26463;&#26465;&#20214;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#32463;&#39564;&#25216;&#26415;&#22312;&#36825;&#20123;&#23454;&#38469;&#30340;&#12289;&#38750;&#21487;&#20998;&#35299;&#30340;&#24615;&#33021;&#30446;&#26631;&#19978;&#25552;&#20379;&#20102;&#27425;&#20248;&#24615;&#33021;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#29702;&#35770;&#25216;&#26415;&#38656;&#35201;&#20026;&#27599;&#20010;&#24615;&#33021;&#30446;&#26631;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#19968;&#20010;&#26032;&#27169;&#22411;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SelMix&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#36873;&#25321;&#24615;&#28151;&#21512;&#30340;&#24265;&#20215;&#24494;&#35843;&#25216;&#26415;&#65292;&#29992;&#20110;&#38024;&#23545;&#25152;&#38656;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18301v1 Announce Type: cross  Abstract: The rise in internet usage has led to the generation of massive amounts of data, resulting in the adoption of various supervised and semi-supervised machine learning algorithms, which can effectively utilize the colossal amount of data to train models. However, before deploying these models in the real world, these must be strictly evaluated on performance measures like worst-case recall and satisfy constraints such as fairness. We find that current state-of-the-art empirical techniques offer sub-optimal performance on these practical, non-decomposable performance objectives. On the other hand, the theoretical techniques necessitate training a new model from scratch for each performance objective. To bridge the gap, we propose SelMix, a selective mixup-based inexpensive fine-tuning technique for pre-trained models, to optimize for the desired objective. The core idea of our framework is to determine a sampling distribution to perform a
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#34701;&#21512;&#22810;&#20010;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#28176;&#21464;&#21464;&#21270;&#26399;&#38388;&#20934;&#30830;&#25429;&#33719;&#38598;&#32676;&#32467;&#26500;&#24182;&#26816;&#27979;&#38598;&#32676;&#32467;&#26500;&#21464;&#21270;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.18269</link><description>&lt;p&gt;
&#36890;&#36807;&#34701;&#21512;&#28151;&#21512;&#22797;&#26434;&#24230;&#36827;&#34892;&#32858;&#31867;&#21464;&#21270;&#31526;&#21495;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Clustering Change Sign Detection by Fusing Mixture Complexity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18269
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#34701;&#21512;&#22810;&#20010;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#28176;&#21464;&#21464;&#21270;&#26399;&#38388;&#20934;&#30830;&#25429;&#33719;&#38598;&#32676;&#32467;&#26500;&#24182;&#26816;&#27979;&#38598;&#32676;&#32467;&#26500;&#21464;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26816;&#27979;&#38598;&#32676;&#32467;&#26500;&#21464;&#21270;&#30340;&#26089;&#26399;&#26041;&#27861;&#12290;&#38598;&#32676;&#32467;&#26500;&#26159;&#25351;&#20351;&#29992;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#34920;&#31034;&#25968;&#25454;&#26102;&#30340;&#31163;&#25955;&#32467;&#26500;&#29305;&#24449;&#65292;&#20363;&#22914;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#38598;&#32676;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#38598;&#32676;&#32467;&#26500;&#36880;&#28176;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#65292;&#28151;&#21512;&#22797;&#26434;&#24230;&#65288;MC&#65289;&#30340;&#27010;&#24565;&#36890;&#36807;&#32771;&#34385;&#38598;&#32676;&#27604;&#20363;&#20559;&#24046;&#21644;&#38598;&#32676;&#20043;&#38388;&#30340;&#37325;&#21472;&#26469;&#24230;&#37327;&#36830;&#32493;&#30340;&#38598;&#32676;&#22823;&#23567;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MC&#34701;&#21512;&#20316;&#20026;MC&#30340;&#25193;&#23637;&#65292;&#20197;&#22788;&#29702;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#20013;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#28151;&#21512;&#25968;&#23383;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#21512;&#24182;&#22810;&#20010;&#27169;&#22411;&#30340;&#34701;&#21512;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#28176;&#21464;&#21464;&#21270;&#30340;&#36807;&#28193;&#26399;&#38388;&#20934;&#30830;&#25429;&#33719;&#20102;&#38598;&#32676;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#26816;&#26597;MC&#34701;&#21512;&#30340;&#36807;&#28193;&#26469;&#26816;&#27979;&#38598;&#32676;&#32467;&#26500;&#21464;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18269v1 Announce Type: cross  Abstract: This paper proposes an early detection method for cluster structural changes. Cluster structure refers to discrete structural characteristics, such as the number of clusters, when data are represented using finite mixture models, such as Gaussian mixture models. We focused on scenarios in which the cluster structure gradually changed over time. For finite mixture models, the concept of mixture complexity (MC) measures the continuous cluster size by considering the cluster proportion bias and overlap between clusters. In this paper, we propose MC fusion as an extension of MC to handle situations in which multiple mixture numbers are possible in a finite mixture model. By incorporating the fusion of multiple models, our approach accurately captured the cluster structure during transitional periods of gradual change. Moreover, we introduce a method for detecting changes in the cluster structure by examining the transition of MC fusion. We
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#26469;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#36807;&#31243;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2403.18248</link><description>&lt;p&gt;
&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#26368;&#20248;&#20998;&#37197;I&#65306;&#35268;&#24459;&#24615;&#21450;&#20854;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference of Optimal Allocations I: Regularities and their Implications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#26469;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#36807;&#31243;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20986;&#20102;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;Hausdorff&#27979;&#24230;&#30340;&#27010;&#24565;&#20197;&#21450;&#20960;&#20309;&#27979;&#24230;&#35770;&#20013;&#30340;&#38754;&#31215;&#21644;&#20849;&#38754;&#31215;&#31215;&#20998;&#20844;&#24335;&#26159;&#26680;&#24515;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;Hadamard&#21487;&#24494;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20108;&#20803;&#32422;&#26463;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20540;&#20989;&#25968;&#36807;&#31243;&#20197;&#21450;&#20004;&#27493;ROC&#26354;&#32447;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#23545;&#20984;&#21644;&#23616;&#37096;Lipschitz&#27867;&#20989;&#30340;&#28145;&#21051;&#35265;&#35299;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20540;&#20989;&#25968;&#30340;&#39069;&#22806;&#19968;&#33324;Frechet&#21487;&#24494;&#24615;&#32467;&#26524;&#12290;&#36825;&#20123;&#24341;&#20154;&#20837;&#32988;&#30340;&#21457;&#29616;&#28608;&#21169;&#20102;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18248v1 Announce Type: new  Abstract: In this paper, we develp a functional differentiability approach for solving statistical optimal allocation problems. We first derive Hadamard differentiability of the value function through a detailed analysis of the general properties of the sorting operator. Central to our framework are the concept of Hausdorff measure and the area and coarea integration formulas from geometric measure theory. Building on our Hadamard differentiability results, we demonstrate how the functional delta method can be used to directly derive the asymptotic properties of the value function process for binary constrained optimal allocation problems, as well as the two-step ROC curve estimator. Moreover, leveraging profound insights from geometric functional analysis on convex and local Lipschitz functionals, we obtain additional generic Fr\'echet differentiability results for the value functions of optimal allocation problems. These compelling findings moti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20844;&#24179;&#20108;&#20803;&#20998;&#31867;&#20013;&#25511;&#21046;&#20154;&#21475;&#24046;&#24322;&#30340;&#32479;&#35745;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#26497;&#23567;&#26497;&#23567;&#26368;&#20248;&#20998;&#31867;&#38169;&#35823;&#38480;&#21046;&#20154;&#21475;&#24046;&#24322;&#21040;&#29992;&#25143;&#25351;&#23450;&#38408;&#20540;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.18216</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#30028;&#20154;&#21475;&#24046;&#24322;&#30340;&#26497;&#23567;&#26497;&#23567;&#20844;&#24179;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Fair Classification with Bounded Demographic Disparity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18216
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20844;&#24179;&#20108;&#20803;&#20998;&#31867;&#20013;&#25511;&#21046;&#20154;&#21475;&#24046;&#24322;&#30340;&#32479;&#35745;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#26497;&#23567;&#26497;&#23567;&#26368;&#20248;&#20998;&#31867;&#38169;&#35823;&#38480;&#21046;&#20154;&#21475;&#24046;&#24322;&#21040;&#29992;&#25143;&#25351;&#23450;&#38408;&#20540;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32531;&#35299;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#19981;&#20844;&#24179;&#24433;&#21709;&#23545;&#30830;&#20445;&#20844;&#24179;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#22823;&#37327;&#30740;&#31350;&#26088;&#22312;&#20943;&#23569;&#24046;&#24322;&#65292;&#20294;&#20351;&#29992;\emph{&#26377;&#38480;&#25968;&#25454;&#38598;}&#30340;&#25928;&#26524; -- &#32780;&#19981;&#26159;&#25972;&#20010;&#20154;&#21475; -- &#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20855;&#26377;&#20004;&#20010;&#21463;&#20445;&#25252;&#32676;&#20307;&#30340;&#20844;&#24179;&#20108;&#20803;&#20998;&#31867;&#30340;&#32479;&#35745;&#22522;&#30784;&#65292;&#37325;&#28857;&#26159;&#25511;&#21046;&#20154;&#21475;&#24046;&#24322;&#65292;&#21363;&#32676;&#20307;&#20043;&#38388;&#30340;&#25509;&#21463;&#29575;&#24046;&#24322;&#12290;&#23613;&#31649;&#21363;&#20351;&#26377;&#26080;&#38480;&#25968;&#25454;&#65292;&#20844;&#24179;&#21487;&#33021;&#20250;&#20197;&#20934;&#30830;&#24615;&#20026;&#20195;&#20215;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#20351;&#29992;&#26377;&#38480;&#26679;&#26412;&#20250;&#30001;&#20110;&#38656;&#35201;&#20272;&#35745;&#29305;&#23450;&#20110;&#32676;&#20307;&#30340;&#25509;&#21463;&#38408;&#20540;&#32780;&#20135;&#29983;&#39069;&#22806;&#25104;&#26412;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20877;&#23558;&#20154;&#21475;&#24046;&#24322;&#38480;&#21046;&#21040;&#29992;&#25143;&#25351;&#23450;&#38408;&#20540;&#26102;&#30340;&#26497;&#23567;&#26497;&#23567;&#26368;&#20248;&#20998;&#31867;&#38169;&#35823;&#12290;&#20026;&#20102;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;\emph{&#20844;&#24179;&#24863;&#30693;&#36229;&#39069;&#39118;&#38505;}&#30340;&#26032;&#39062;&#24230;&#37327;&#65292;&#24182;&#25512;&#23548;&#20102;&#19968;&#20010;&#26497;&#23567;&#26497;&#23567;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18216v1 Announce Type: cross  Abstract: Mitigating the disparate impact of statistical machine learning methods is crucial for ensuring fairness. While extensive research aims to reduce disparity, the effect of using a \emph{finite dataset} -- as opposed to the entire population -- remains unclear. This paper explores the statistical foundations of fair binary classification with two protected groups, focusing on controlling demographic disparity, defined as the difference in acceptance rates between the groups. Although fairness may come at the cost of accuracy even with infinite data, we show that using a finite sample incurs additional costs due to the need to estimate group-specific acceptance thresholds. We study the minimax optimal classification error while constraining demographic disparity to a user-specified threshold. To quantify the impact of fairness constraints, we introduce a novel measure called \emph{fairness-aware excess risk} and derive a minimax lower bou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32416;&#27491;&#20102;&#20266;&#23545;&#25968;&#20284;&#28982;&#26041;&#27861;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.18127</link><description>&lt;p&gt;
&#20462;&#27491;&#20266;&#23545;&#25968;&#20284;&#28982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Correction of Pseudo Log-Likelihood Method
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32416;&#27491;&#20102;&#20266;&#23545;&#25968;&#20284;&#28982;&#26041;&#27861;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22833;&#36133;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20266;&#23545;&#25968;&#20284;&#28982;&#26159;&#19968;&#31181;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#26041;&#27861;&#65292;&#21253;&#25324;&#19978;&#19979;&#25991;&#20048;&#38431;&#12289;&#31038;&#20132;&#32593;&#32476;&#30340;&#24433;&#21709;&#26368;&#22823;&#21270;&#21644;&#22240;&#26524;&#20048;&#38431;&#12290;&#28982;&#32780;&#65292;&#22312;&#20808;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#21487;&#33021;&#27809;&#26377;&#30028;&#38480;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#20182;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#27809;&#26377;&#23450;&#20041;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#19968;&#20010;&#26368;&#22823;&#20266;&#23545;&#25968;&#20284;&#28982;&#20272;&#35745;&#22833;&#36133;&#30340;&#21453;&#20363;&#65292;&#28982;&#21518;&#25552;&#20379;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#26469;&#32416;&#27491;\citep{li2017provably, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}&#20013;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18127v1 Announce Type: new  Abstract: Pseudo log-likelihood is a type of maximum likelihood estimation (MLE) method used in various fields including contextual bandits, influence maximization of social networks, and causal bandits. However, in previous literature \citep{li2017provably, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}, the log-likelihood function may not be bounded, which may result in the algorithm they proposed not well-defined. In this paper, we give a counterexample that the maximum pseudo log-likelihood estimation fails and then provide a solution to correct the algorithms in \citep{li2017provably, zhang2022online, xiong2022combinatorial, feng2023combinatorial1, feng2023combinatorial2}.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;QoIs&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26469;&#30830;&#23450;&#23454;&#39564;&#35774;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.18072</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#30446;&#26631;&#23548;&#21521;&#36125;&#21494;&#26031;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models using Markov Chain Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18072
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;QoIs&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26469;&#30830;&#23450;&#23454;&#39564;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#65288;OED&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#21270;&#30340;&#26041;&#27861;&#26469;&#37327;&#21270;&#21644;&#26368;&#22823;&#21270;&#23454;&#39564;&#25968;&#25454;&#30340;&#20215;&#20540;&#12290;&#22312;&#36125;&#21494;&#26031;&#26041;&#27861;&#19979;&#65292;&#20256;&#32479;&#30340;OED&#20250;&#26368;&#22823;&#21270;&#23545;&#27169;&#22411;&#21442;&#25968;&#30340;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#24120;&#24863;&#20852;&#36259;&#30340;&#19981;&#26159;&#21442;&#25968;&#26412;&#36523;&#65292;&#32780;&#26159;&#20381;&#36182;&#20110;&#21442;&#25968;&#30340;&#38750;&#32447;&#24615;&#26041;&#24335;&#30340;&#39044;&#27979;&#24863;&#20852;&#36259;&#37327;&#65288;QoIs&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#35266;&#27979;&#21644;&#39044;&#27979;&#27169;&#22411;&#30340;&#39044;&#27979;&#30446;&#26631;&#23548;&#21521;OED&#65288;GO-OED&#65289;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23547;&#27714;&#25552;&#20379;&#23545;QoIs&#30340;&#26368;&#22823;EIG&#30340;&#23454;&#39564;&#35774;&#35745;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;QoI EIG&#30340;&#23884;&#22871;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#65292;&#21033;&#29992;&#26680;&#23494;&#24230;&#20272;&#35745;&#26469;&#35780;&#20272;&#21518;&#39564;&#39044;&#27979;&#23494;&#24230;&#21450;&#20854;&#19982;&#20808;&#39564;&#39044;&#27979;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#12290;GO-OED&#35774;&#35745;&#36890;&#36807;&#22312;&#35774;&#35745;&#31354;&#38388;&#20013;&#26368;&#22823;&#21270;EIG&#26469;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18072v1 Announce Type: cross  Abstract: Optimal experimental design (OED) provides a systematic approach to quantify and maximize the value of experimental data. Under a Bayesian approach, conventional OED maximizes the expected information gain (EIG) on model parameters. However, we are often interested in not the parameters themselves, but predictive quantities of interest (QoIs) that depend on the parameters in a nonlinear manner. We present a computational framework of predictive goal-oriented OED (GO-OED) suitable for nonlinear observation and prediction models, which seeks the experimental design providing the greatest EIG on the QoIs. In particular, we propose a nested Monte Carlo estimator for the QoI EIG, featuring Markov chain Monte Carlo for posterior sampling and kernel density estimation for evaluating the posterior-predictive density and its Kullback-Leibler divergence from the prior-predictive. The GO-OED design is then found by maximizing the EIG over the des
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20840;&#24687;&#20840;&#23616;&#21367;&#31215;&#32593;&#32476;&#65288;HGConv&#65289;&#21644;&#20840;&#24687;&#31616;&#21270;&#34920;&#31034;&#65288;HRR&#65289;&#23646;&#24615;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#22797;&#26434;&#30340;&#26680;&#35745;&#31639;&#25110;&#35774;&#35745;&#65292;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#39046;&#22495;&#21462;&#24471;&#20102;&#26032;&#30340;SOTA&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2403.17978</link><description>&lt;p&gt;
&#29992;&#20110;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#20013;&#30340;&#38271;&#31243;&#39044;&#27979;&#20219;&#21153;&#30340;&#20840;&#24687;&#20840;&#23616;&#21367;&#31215;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Holographic Global Convolutional Networks for Long-Range Prediction Tasks in Malware Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17978
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20840;&#24687;&#20840;&#23616;&#21367;&#31215;&#32593;&#32476;&#65288;HGConv&#65289;&#21644;&#20840;&#24687;&#31616;&#21270;&#34920;&#31034;&#65288;HRR&#65289;&#23646;&#24615;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#22797;&#26434;&#30340;&#26680;&#35745;&#31639;&#25110;&#35774;&#35745;&#65292;&#22312;&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#39046;&#22495;&#21462;&#24471;&#20102;&#26032;&#30340;SOTA&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24694;&#24847;&#36719;&#20214;&#26816;&#27979;&#26159;&#19968;&#20010;&#26377;&#36259;&#19988;&#26377;&#20215;&#20540;&#30340;&#39046;&#22495;&#65292;&#22240;&#20026;&#23427;&#23545;&#29616;&#23454;&#19990;&#30028;&#26377;&#37325;&#35201;&#24433;&#21709;&#24182;&#20855;&#26377;&#29420;&#29305;&#30340;&#26426;&#22120;&#23398;&#20064;&#25361;&#25112;&#12290;&#26412;&#25991;&#30740;&#31350;&#29616;&#26377;&#30340;&#38271;&#31243;&#25216;&#26415;&#21644;&#22522;&#20934;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#22312;&#36825;&#20010;&#38382;&#39064;&#39046;&#22495;&#19981;&#22826;&#36866;&#29992;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#21033;&#29992;&#20840;&#24687;&#31616;&#21270;&#34920;&#31034;&#65288;HRR&#65289;&#23646;&#24615;&#26469;&#32534;&#30721;&#21644;&#35299;&#30721;&#24207;&#21015;&#20803;&#32032;&#29305;&#24449;&#30340;&#20840;&#24687;&#20840;&#23616;&#21367;&#31215;&#32593;&#32476;&#65288;HGConv&#65289;&#12290;&#19982;&#20854;&#20182;&#20840;&#23616;&#21367;&#31215;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#20219;&#20309;&#22797;&#26434;&#30340;&#26680;&#35745;&#31639;&#25110;&#31934;&#24515;&#35774;&#35745;&#30340;&#26680;&#12290;HGConv&#26680;&#34987;&#23450;&#20041;&#20026;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#23398;&#20064;&#30340;&#31616;&#21333;&#21442;&#25968;&#12290;&#35813;&#26041;&#27861;&#22312;Microsoft&#24694;&#24847;&#36719;&#20214;&#20998;&#31867;&#25361;&#25112;&#36187;&#12289;Drebin&#21644;EMBER&#24694;&#24847;&#36719;&#20214;&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26032;&#30340;SOTA&#32467;&#26524;&#12290;&#22312;&#24207;&#21015;&#38271;&#24230;&#30340;&#23545;&#25968;&#32423;&#22797;&#26434;&#24230;&#19979;&#65292;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;HGConv&#30340;&#36816;&#34892;&#26102;&#38388;&#26126;&#26174;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17978v1 Announce Type: cross  Abstract: Malware detection is an interesting and valuable domain to work in because it has significant real-world impact and unique machine-learning challenges. We investigate existing long-range techniques and benchmarks and find that they're not very suitable in this problem area. In this paper, we introduce Holographic Global Convolutional Networks (HGConv) that utilize the properties of Holographic Reduced Representations (HRR) to encode and decode features from sequence elements. Unlike other global convolutional methods, our method does not require any intricate kernel computation or crafted kernel design. HGConv kernels are defined as simple parameters learned through backpropagation. The proposed method has achieved new SOTA results on Microsoft Malware Classification Challenge, Drebin, and EMBER malware benchmarks. With log-linear complexity in sequence length, the empirical results demonstrate substantially faster run-time by HGConv c
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#19982;&#26368;&#20339;&#31639;&#27861;&#27604;&#36739;&#24471;&#20986;&#26032;&#30340;&#35265;&#35299;&#12290;</title><link>https://arxiv.org/abs/2403.17767</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#36125;&#21494;&#26031;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Bayes risk of semi-supervised learning with uncertain labeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17767
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#19982;&#26368;&#20339;&#31639;&#27861;&#27604;&#36739;&#24471;&#20986;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#19978;&#30340;&#21322;&#30417;&#30563;&#20998;&#31867;&#35774;&#32622;&#65292;&#20854;&#20013;&#25968;&#25454;&#30340;&#26631;&#31614;&#19981;&#20687;&#36890;&#24120;&#37027;&#26679;&#20005;&#26684;&#65292;&#32780;&#26159;&#24102;&#26377;&#19981;&#30830;&#23450;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#35813;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#19982;&#30446;&#21069;&#24050;&#30693;&#30340;&#26368;&#20339;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;&#36825;&#31181;&#27604;&#36739;&#26368;&#32456;&#20026;&#35813;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17767v1 Announce Type: cross  Abstract: This article considers a semi-supervised classification setting on a Gaussian mixture model, where the data is not labeled strictly as usual, but instead with uncertain labels. Our main aim is to compute the Bayes risk for this model. We compare the behavior of the Bayes risk and the best known algorithm for this model. This comparison eventually gives new insights over the algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;GPT-4&#22312;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#21453;&#39304;&#23545;&#30456;&#23545;&#32622;&#20449;&#24230;&#26377;&#24433;&#21709;&#65292;&#20294;&#24182;&#19981;&#19968;&#33268;&#22320;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;</title><link>https://arxiv.org/abs/2402.09654</link><description>&lt;p&gt;
GPT-4&#22312;&#22522;&#20110;USMLE&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
GPT-4's assessment of its performance in a USMLE-based case study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;GPT-4&#22312;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#21453;&#39304;&#23545;&#30456;&#23545;&#32622;&#20449;&#24230;&#26377;&#24433;&#21709;&#65292;&#20294;&#24182;&#19981;&#19968;&#33268;&#22320;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;GPT-4&#22312;&#21307;&#30103;&#24212;&#29992;&#20013;&#30340;&#34920;&#29616;&#35780;&#20272;&#12290;&#36890;&#36807;&#20351;&#29992;&#31616;&#21333;&#30340;&#25552;&#31034;&#25216;&#26415;&#65292;&#20174;&#32654;&#22269;&#21307;&#23398;&#25191;&#29031;&#32771;&#35797;&#65288;USMLE&#65289;&#38382;&#21367;&#20013;&#25552;&#21462;&#38382;&#39064;&#30340;&#26041;&#24335;&#65292;&#20219;&#21153;&#26159;&#35780;&#20272;&#27169;&#22411;&#22312;&#25552;&#38382;&#20043;&#21069;&#21644;&#25552;&#38382;&#20043;&#21518;&#30340;&#32622;&#20449;&#24230;&#24471;&#20998;&#12290;&#38382;&#21367;&#26681;&#25454;&#26159;&#21542;&#26377;&#21453;&#39304;&#20998;&#20026;&#20004;&#32452;&#65306;&#21453;&#39304;&#32452;&#65288;WF&#65289;&#21644;&#26080;&#21453;&#39304;&#32452;&#65288;NF&#65289;&#12290;&#35201;&#27714;&#27169;&#22411;&#22312;&#27599;&#20010;&#38382;&#39064;&#20043;&#21069;&#21644;&#20043;&#21518;&#25552;&#20379;&#32477;&#23545;&#21644;&#30456;&#23545;&#32622;&#20449;&#24230;&#24471;&#20998;&#12290;&#36890;&#36807;&#20351;&#29992;&#32479;&#35745;&#24037;&#20855;&#20998;&#26512;&#23454;&#39564;&#32467;&#26524;&#65292;&#30740;&#31350;&#20102;WF&#21644;NF&#32452;&#30340;&#32622;&#20449;&#24230;&#21464;&#24322;&#24615;&#12290;&#27492;&#22806;&#65292;&#36827;&#34892;&#20102;&#39034;&#24207;&#20998;&#26512;&#20197;&#35266;&#23519;WF&#21644;NF&#32452;&#30340;&#24615;&#33021;&#21464;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21453;&#39304;&#20250;&#24433;&#21709;&#30456;&#23545;&#32622;&#20449;&#24230;&#65292;&#20294;&#24182;&#19981;&#24635;&#26159;&#22686;&#21152;&#25110;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09654v1 Announce Type: new  Abstract: This study investigates GPT-4's assessment of its performance in healthcare applications. A simple prompting technique was used to prompt the LLM with questions taken from the United States Medical Licensing Examination (USMLE) questionnaire and it was tasked to evaluate its confidence score before posing the question and after asking the question. The questionnaire was categorized into two groups-questions with feedback (WF) and questions with no feedback(NF) post-question. The model was asked to provide absolute and relative confidence scores before and after each question. The experimental findings were analyzed using statistical tools to study the variability of confidence in WF and NF groups. Additionally, a sequential analysis was conducted to observe the performance variation for the WF and NF groups. Results indicate that feedback influences relative confidence but doesn't consistently increase or decrease it. Understanding the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#21033;&#29992;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#31435;&#20307;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.07868</link><description>&lt;p&gt;
&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#30340;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Nesting Particle Filters for Experimental Design in Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#21033;&#29992;&#23884;&#22871;&#31890;&#23376;&#28388;&#27874;&#22120;&#21644;&#31435;&#20307;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#20132;&#25442;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#39118;&#38505;&#25935;&#24863;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#20869;&#22806;SMC^2&#31639;&#27861;&#65292;&#20351;&#29992;&#23884;&#22871;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#65288;SMC&#65289;&#20272;&#35745;&#22120;&#26469;&#39044;&#27979;&#26399;&#26395;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#23558;&#20854;&#23884;&#20837;&#21040;&#31890;&#23376;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;pMCMC&#65289;&#26694;&#26550;&#20013;&#36827;&#34892;&#22522;&#20110;&#26799;&#24230;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;&#19982;&#26368;&#36817;&#20381;&#36182;&#20110;&#20559;&#20272;&#35745;&#22120;&#26469;&#25674;&#38144;&#20808;&#21069;&#23398;&#20064;&#35774;&#35745;&#31574;&#30053;&#30340;&#25104;&#26412;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#22312;&#19968;&#32452;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#20540;&#39564;&#35777;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel approach to Bayesian Experimental Design (BED) for non-exchangeable data that formulates it as risk-sensitive policy optimization. We develop the Inside-Out SMC^2 algorithm that uses a nested sequential Monte Carlo (SMC) estimator of the expected information gain and embeds it into a particle Markov chain Monte Carlo (pMCMC) framework to perform gradient-based policy optimization. This is in contrast to recent approaches that rely on biased estimators of the expected information gain (EIG) to amortize the cost of experiments by learning a design policy in advance. Numerical validation on a set of dynamical systems showcases the efficacy of our method in comparison to other state-of-the-art strategies.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20855;&#26377;&#37096;&#20998;&#21160;&#24577;&#30693;&#35782;&#30340;&#22312;&#32447;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#26377;&#38480;&#30340;&#20998;&#38598;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#35774;&#32622;&#19979;&#65292;&#23454;&#29616;&#20102;&#36739;&#20302;&#30340;&#36951;&#25022;&#12290;</title><link>https://arxiv.org/abs/2312.12558</link><description>&lt;p&gt;
&#20855;&#26377;&#37096;&#20998;&#21160;&#24577;&#30693;&#35782;&#30340;&#26679;&#26412;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12558
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20855;&#26377;&#37096;&#20998;&#21160;&#24577;&#30693;&#35782;&#30340;&#22312;&#32447;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#26377;&#38480;&#30340;&#20998;&#38598;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#35774;&#32622;&#19979;&#65292;&#23454;&#29616;&#20102;&#36739;&#20302;&#30340;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;Q&#23398;&#20064;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24403;&#26576;&#20123;&#20851;&#20110;&#21160;&#24577;&#30340;&#20808;&#21069;&#30693;&#35782;&#21487;&#29992;&#25110;&#21487;&#20197;&#26377;&#25928;&#23398;&#20064;&#26102;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#25353;&#29031;&#21152;&#24615;&#24178;&#25200;&#27169;&#22411;&#28436;&#21464;&#30340;&#31995;&#32479;&#65292;&#22312;&#26377;&#38480;&#30340;&#20998;&#38598;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#23545;$f$&#30340;&#23436;&#32654;&#30693;&#35782;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;$\tilde{\mathcal{O}}(\text{Poly}(H)\sqrt{T})$&#30340;&#36951;&#25022;&#65292;&#20854;&#20013;$T$&#26159;&#19982;&#31995;&#32479;&#36827;&#34892;&#20132;&#20114;&#30340;&#24635;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.12558v2 Announce Type: replace  Abstract: The problem of sample complexity of online reinforcement learning is often studied in the literature without taking into account any partial knowledge about the system dynamics that could potentially accelerate the learning process. In this paper, we study the sample complexity of online Q-learning methods when some prior knowledge about the dynamics is available or can be learned efficiently. We focus on systems that evolve according to an additive disturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$ represents the underlying system dynamics, and $W_h$ are unknown disturbances independent of states and actions. In the setting of finite episodic Markov decision processes with $S$ states, $A$ actions, and episode length $H$, we present an optimistic Q-learning algorithm that achieves $\tilde{\mathcal{O}}(\text{Poly}(H)\sqrt{T})$ regret under perfect knowledge of $f$, where $T$ is the total number of interactions with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#25506;&#35752;&#20102;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#36890;&#20449;&#22270;&#35774;&#35745;&#21644;&#22823;&#23567;&#23545;&#21518;&#39564;&#25910;&#32553;&#29575;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2311.08214</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#39057;&#29575;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Frequentist Guarantees of Distributed (Non)-Bayesian Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#25506;&#35752;&#20102;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#21442;&#25968;&#25928;&#29575;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#20197;&#21450;&#36890;&#20449;&#22270;&#35774;&#35745;&#21644;&#22823;&#23567;&#23545;&#21518;&#39564;&#25910;&#32553;&#29575;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#20998;&#26512;&#22823;&#22411;&#20998;&#25955;&#25968;&#25454;&#38598;&#30340;&#38656;&#27714;&#25512;&#21160;&#65292;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#24050;&#25104;&#20026;&#36328;&#22810;&#20010;&#39046;&#22495;&#65288;&#21253;&#25324;&#32479;&#35745;&#23398;&#12289;&#30005;&#27668;&#24037;&#31243;&#21644;&#32463;&#27982;&#23398;&#65289;&#30340;&#20851;&#38190;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#38024;&#23545;&#36890;&#36807;&#36890;&#20449;&#32593;&#32476;&#36830;&#25509;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#20998;&#24067;&#24335;(&#38750;)&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#24314;&#31435;&#20102;&#39057;&#29575;&#29305;&#24615;&#65292;&#22914;&#21518;&#39564;&#19968;&#33268;&#24615;&#12289;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#21518;&#39564;&#25910;&#32553;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36890;&#20449;&#22270;&#19978;&#30340;&#36866;&#24403;&#20551;&#35774;&#19979;&#65292;&#20998;&#24067;&#24335;&#36125;&#21494;&#26031;&#25512;&#26029;&#20445;&#30041;&#20102;&#21442;&#25968;&#25928;&#29575;&#65292;&#21516;&#26102;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#22686;&#24378;&#20102;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#30740;&#31350;&#35774;&#35745;&#21644;&#36890;&#20449;&#22270;&#30340;&#22823;&#23567;&#22914;&#20309;&#24433;&#21709;&#21518;&#39564;&#25910;&#32553;&#29575;&#26469;&#25506;&#35752;&#20102;&#32479;&#35745;&#25928;&#29575;&#21644;&#36890;&#20449;&#25928;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#26102;&#21464;&#22270;&#65292;&#24182;&#23558;&#32467;&#26524;&#24212;&#29992;&#20110;&#25351;&#25968;f
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08214v2 Announce Type: replace-cross  Abstract: Motivated by the need to analyze large, decentralized datasets, distributed Bayesian inference has become a critical research area across multiple fields, including statistics, electrical engineering, and economics. This paper establishes Frequentist properties, such as posterior consistency, asymptotic normality, and posterior contraction rates, for the distributed (non-)Bayes Inference problem among agents connected via a communication network. Our results show that, under appropriate assumptions on the communication graph, distributed Bayesian inference retains parametric efficiency while enhancing robustness in uncertainty quantification. We also explore the trade-off between statistical efficiency and communication efficiency by examining how the design and size of the communication graph impact the posterior contraction rate. Furthermore, We extend our analysis to time-varying graphs and apply our results to exponential f
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#24182;&#35782;&#21035;&#20986;&#20855;&#26377;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.16502</link><description>&lt;p&gt;
&#35780;&#20272;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#25972;&#20307;&#21644;&#37096;&#20998;&#22240;&#26524;&#33391;&#22909;&#35268;&#33539;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the overall and partial causal well-specification of nonlinear additive noise models. (arXiv:2310.16502v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16502
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#24182;&#35782;&#21035;&#20986;&#20855;&#26377;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#21487;&#33021;&#21253;&#25324;&#24322;&#26041;&#24046;&#24615;&#12290;&#25105;&#20204;&#26088;&#22312;&#35782;&#21035;&#37027;&#20123;&#21363;&#20351;&#22312;&#36825;&#31181;&#27169;&#22411;&#35268;&#33539;&#38382;&#39064;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#25512;&#26029;&#20986;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;&#25105;&#20204;&#22522;&#20110;&#23545;&#22810;&#20803;&#35266;&#27979;&#25968;&#25454;&#20998;&#24067;&#30340;&#20102;&#35299;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#28982;&#21518;&#38024;&#23545;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35752;&#35770;&#20102;&#20854;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method to detect model misspecifications in nonlinear causal additive and potentially heteroscedastic noise models. We aim to identify predictor variables for which we can infer the causal effect even in cases of such misspecification. We develop a general framework based on knowledge of the multivariate observational data distribution and we then propose an algorithm for finite sample data, discuss its asymptotic properties, and illustrate its performance on simulated and real data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#20449;&#24687;&#35770;&#21644;PAC-Bayesian&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#32852;&#31995;&#21644;&#20849;&#21516;&#28857;&#12290;&#36825;&#23545;&#20110;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#21644;&#26032;&#31639;&#27861;&#30340;&#35774;&#35745;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2309.04381</link><description>&lt;p&gt;
&#19968;&#33324;&#21270;&#30028;&#38480;&#65306;&#20449;&#24687;&#35770;&#21644;PAC-Bayesian&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds: Perspectives from Information Theory and PAC-Bayes. (arXiv:2309.04381v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04381
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#20004;&#20010;&#35270;&#35282;&#65306;&#20449;&#24687;&#35770;&#21644;PAC-Bayesian&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#32852;&#31995;&#21644;&#20849;&#21516;&#28857;&#12290;&#36825;&#23545;&#20110;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#21644;&#26032;&#31639;&#27861;&#30340;&#35774;&#35745;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#19968;&#33324;&#21270;&#12290;&#22312;&#36807;&#21435;&#30340;&#20960;&#21313;&#24180;&#37324;&#65292;PAC-Bayesian&#26041;&#27861;&#24050;&#32463;&#34987;&#30830;&#23450;&#20026;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#65292;&#29992;&#26469;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#19968;&#33324;&#21270;&#33021;&#21147;&#65292;&#24182;&#35774;&#35745;&#26032;&#30340;&#31639;&#27861;&#12290;&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#23545;&#22810;&#31181;&#23398;&#20064;&#31639;&#27861;&#65288;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#28508;&#22312;&#36866;&#29992;&#24615;&#65292;&#23427;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#36824;&#21457;&#23637;&#20102;&#19968;&#31181;&#20449;&#24687;&#35770;&#30340;&#35270;&#35282;&#65292;&#20854;&#20013;&#24314;&#31435;&#20102;&#19968;&#33324;&#21270;&#19982;&#21508;&#31181;&#20449;&#24687;&#24230;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36825;&#20010;&#26694;&#26550;&#19982;PAC-Bayesian&#26041;&#27861;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#19988;&#22312;&#20004;&#20010;&#26041;&#38754;&#37117;&#26377;&#29420;&#31435;&#21457;&#29616;&#30340;&#24456;&#22810;&#32467;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#36825;&#31181;&#24378;&#36830;&#25509;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#32479;&#19968;&#30340;&#19968;&#33324;&#21270;&#22788;&#29702;&#26041;&#27861;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#20010;&#35270;&#35282;&#20849;&#21516;&#25317;&#26377;&#30340;&#25216;&#26415;&#21644;&#32467;&#26524;&#65292;&#24182;&#35752;&#35770;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#21644;&#35299;&#37322;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#36830;&#25509;&#22914;&#20309;&#20135;&#29983;&#26032;&#30340;&#27934;&#35265;&#21644;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#20004;&#20010;&#39046;&#22495;&#30340;&#20132;&#21449;&#24212;&#29992;&#21644;&#28508;&#22312;&#30340;&#36827;&#19968;&#27493;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental question in theoretical machine learning is generalization. Over the past decades, the PAC-Bayesian approach has been established as a flexible framework to address the generalization capabilities of machine learning algorithms, and design new ones. Recently, it has garnered increased interest due to its potential applicability for a variety of learning algorithms, including deep neural networks. In parallel, an information-theoretic view of generalization has developed, wherein the relation between generalization and various information measures has been established. This framework is intimately connected to the PAC-Bayesian approach, and a number of results have been independently discovered in both strands. In this monograph, we highlight this strong connection and present a unified treatment of generalization. We present techniques and results that the two perspectives have in common, and discuss the approaches and interpretations that differ. In particular, we demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#20998;&#31867;&#31639;&#27861;&#23545;&#20110;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.11138</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#31995;&#32479;&#24322;&#24120;&#30340;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NLP-based detection of systematic anomalies among the narratives of consumer complaints. (arXiv:2308.11138v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#28040;&#36153;&#32773;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#35299;&#20915;&#20998;&#31867;&#31639;&#27861;&#23545;&#20110;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#25237;&#35785;&#21465;&#36848;&#20013;&#30340;&#31995;&#32479;&#24322;&#24120;&#65292;&#31616;&#31216;&#20026;&#31995;&#32479;&#24322;&#24120;&#12290;&#23613;&#31649;&#20998;&#31867;&#31639;&#27861;&#34987;&#29992;&#20110;&#26816;&#27979;&#26126;&#26174;&#30340;&#24322;&#24120;&#65292;&#20294;&#22312;&#36739;&#23567;&#19988;&#39057;&#32321;&#20986;&#29616;&#30340;&#31995;&#32479;&#24322;&#24120;&#24773;&#20917;&#19979;&#65292;&#31639;&#27861;&#21487;&#33021;&#20250;&#22240;&#20026;&#21508;&#31181;&#21407;&#22240;&#32780;&#22833;&#25928;&#65292;&#21253;&#25324;&#25216;&#26415;&#21407;&#22240;&#21644;&#20154;&#24037;&#20998;&#26512;&#24072;&#30340;&#33258;&#28982;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#22312;&#20998;&#31867;&#20043;&#21518;&#30340;&#19979;&#19968;&#27493;&#20013;&#65292;&#25105;&#20204;&#23558;&#25237;&#35785;&#21465;&#36848;&#36716;&#21270;&#20026;&#23450;&#37327;&#25968;&#25454;&#65292;&#28982;&#21518;&#20351;&#29992;&#19968;&#31181;&#31639;&#27861;&#26469;&#26816;&#27979;&#31995;&#32479;&#24322;&#24120;&#12290;&#25105;&#20204;&#20351;&#29992;&#28040;&#36153;&#32773;&#37329;&#34701;&#20445;&#25252;&#23616;&#30340;&#28040;&#36153;&#32773;&#25237;&#35785;&#25968;&#25454;&#24211;&#20013;&#30340;&#25237;&#35785;&#21465;&#36848;&#26469;&#35828;&#26126;&#25972;&#20010;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop an NLP-based procedure for detecting systematic nonmeritorious consumer complaints, simply called systematic anomalies, among complaint narratives. While classification algorithms are used to detect pronounced anomalies, in the case of smaller and frequent systematic anomalies, the algorithms may falter due to a variety of reasons, including technical ones as well as natural limitations of human analysts. Therefore, as the next step after classification, we convert the complaint narratives into quantitative data, which are then analyzed using an algorithm for detecting systematic anomalies. We illustrate the entire procedure using complaint narratives from the Consumer Complaint Database of the Consumer Financial Protection Bureau.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#27169;&#25311;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#30340;&#20540;&#65292;&#21487;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#65292;&#24182;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.15328</link><description>&lt;p&gt;
&#27169;&#25311;&#21453;&#20107;&#23454;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Simulating counterfactuals. (arXiv:2306.15328v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15328
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#27169;&#25311;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#30340;&#20540;&#65292;&#21487;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#65292;&#24182;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#26029;&#32771;&#34385;&#20102;&#22312;&#19982;&#23454;&#38469;&#19990;&#30028;&#23384;&#22312;&#19968;&#20123;&#35777;&#25454;&#30340;&#24179;&#34892;&#19990;&#30028;&#20013;&#36827;&#34892;&#30340;&#20551;&#35774;&#24615;&#24178;&#39044;&#12290;&#22914;&#26524;&#35777;&#25454;&#22312;&#27969;&#24418;&#19978;&#25351;&#23450;&#20102;&#26465;&#20214;&#20998;&#24067;&#65292;&#21453;&#20107;&#23454;&#21487;&#33021;&#26159;&#35299;&#26512;&#38590;&#35299;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#27169;&#25311;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#23545;&#31163;&#25955;&#21644;&#36830;&#32493;&#21464;&#37327;&#35774;&#23450;&#26465;&#20214;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#21576;&#29616;&#20026;&#31890;&#23376;&#28388;&#27874;&#22120;&#65292;&#20174;&#32780;&#23548;&#33268;&#28176;&#36817;&#26377;&#25928;&#30340;&#25512;&#26029;&#12290;&#35813;&#31639;&#27861;&#34987;&#24212;&#29992;&#20110;&#20449;&#29992;&#35780;&#20998;&#20013;&#30340;&#20844;&#24179;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference considers a hypothetical intervention in a parallel world that shares some evidence with the factual world. If the evidence specifies a conditional distribution on a manifold, counterfactuals may be analytically intractable. We present an algorithm for simulating values from a counterfactual distribution where conditions can be set on both discrete and continuous variables. We show that the proposed algorithm can be presented as a particle filter leading to asymptotically valid inference. The algorithm is applied to fairness analysis in credit scoring.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#26377;&#35777;&#25454;&#34920;&#26126;&#20854;&#20855;&#26377;&#36866;&#24403;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13829</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference using randomized group lasso estimators for general models. (arXiv:2306.13829v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13829
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#26377;&#35777;&#25454;&#34920;&#26126;&#20854;&#20855;&#26377;&#36866;&#24403;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#19982;&#24191;&#27867;&#30340;&#20998;&#24067;&#21644;&#25439;&#22833;&#20989;&#25968;&#19968;&#36215;&#20351;&#29992;&#65292;&#24320;&#21457;&#20102;&#36873;&#25321;&#24615;&#25512;&#29702;&#26041;&#27861;&#65292;&#29992;&#20110;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#25351;&#25968;&#23478;&#26063;&#20998;&#24067;&#65292;&#20197;&#21450;&#20687;&#36807;&#24230;&#31163;&#25955;&#35745;&#25968;&#25968;&#25454;&#30340;&#25311;&#28982;&#27169;&#22411;&#31561;&#65292;&#20801;&#35768;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#12290;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#30340;&#32452;&#27491;&#21017;&#21270;&#20248;&#21270;&#38382;&#39064;&#12290;&#28155;&#21152;&#30340;&#38543;&#26426;&#21270;&#20351;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#21518;&#36873;&#25321;&#20284;&#28982;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26465;&#20214;&#36873;&#25321;&#20998;&#32452;&#21327;&#21464;&#37327;&#30340;&#20107;&#20214;&#19978;&#36866;&#29992;&#20110;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;&#36825;&#20010;&#20284;&#28982;&#20063;&#25552;&#20379;&#20102;&#19968;&#20010;&#36873;&#25321;&#24615;&#28857;&#20272;&#35745;&#65292;&#36890;&#36807;&#32452;&#22871;&#32034;&#32771;&#34385;&#20102;&#36873;&#25321;&#12290;&#36873;&#25321;&#30340;&#27169;&#22411;&#20013;&#22238;&#24402;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#37319;&#29992;&#27779;&#23572;&#24503;&#31867;&#22411;&#30340;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#26377;&#30028;&#20307;&#31215;&#12290;&#20197;&#32654;&#22269;&#22269;&#23478;&#20581;&#24247;&#21644;&#33829;&#20859;&#35843;&#26597;&#30340;&#25968;&#25454;&#20026;&#20363;&#23637;&#31034;&#20102;&#32452;&#22871;&#32034;&#30340;&#36873;&#25321;&#24615;&#25512;&#29702;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference methods are developed for group lasso estimators for use with a wide class of distributions and loss functions. The method includes the use of exponential family distributions, as well as quasi-likelihood modeling for overdispersed count data, for example, and allows for categorical or grouped covariates as well as continuous covariates. A randomized group-regularized optimization problem is studied. The added randomization allows us to construct a post-selection likelihood which we show to be adequate for selective inference when conditioning on the event of the selection of the grouped covariates. This likelihood also provides a selective point estimator, accounting for the selection by the group lasso. Confidence regions for the regression parameters in the selected model take the form of Wald-type regions and are shown to have bounded volume. The selective inference method for grouped lasso is illustrated on data from the national health and nutrition examinatio
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.02158</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24418;&#25104;&#33021;&#37327;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#29454;&#26538;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Shotgun crystal structure prediction using machine-learned formation energies. (arXiv:2305.02158v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20197;&#36890;&#36807;&#25214;&#21040;&#21407;&#23376;&#26500;&#22411;&#33021;&#37327;&#26354;&#38754;&#30340;&#20840;&#23616;&#25110;&#23616;&#37096;&#26497;&#23567;&#20540;&#26469;&#39044;&#27979;&#32452;&#35013;&#21407;&#23376;&#30340;&#31283;&#23450;&#25110;&#20122;&#31283;&#23450;&#26230;&#20307;&#32467;&#26500;&#12290;&#36890;&#24120;&#65292;&#36825;&#38656;&#35201;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#36825;&#22312;&#21253;&#21547;30&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#22823;&#22411;&#31995;&#32479;&#20013;&#26159;&#19981;&#23454;&#38469;&#30340;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#31616;&#21333;&#20294;&#21151;&#33021;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#23545;&#22823;&#37327;&#34394;&#25311;&#21019;&#24314;&#30340;&#26230;&#20307;&#32467;&#26500;&#36827;&#34892;&#38750;&#36845;&#20195;&#24335;&#21333;&#27425;&#31579;&#36873;&#65292;&#20174;&#32780;&#22312;&#35299;&#20915;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stable or metastable crystal structures of assembled atoms can be predicted by finding the global or local minima of the energy surface with respect to the atomic configurations. Generally, this requires repeated first-principles energy calculations that are impractical for large systems, such as those containing more than 30 atoms in the unit cell. Here, we have made significant progress in solving the crystal structure prediction problem with a simple but powerful machine-learning workflow; using a machine-learning surrogate for first-principles energy calculations, we performed non-iterative, single-shot screening using a large library of virtually created crystal structures. The present method relies on two key technical components: transfer learning, which enables a highly accurate energy prediction of pre-relaxed crystalline states given only a small set of training samples from first-principles calculations, and generative models to create promising and diverse crystal structure
&lt;/p&gt;</description></item></channel></rss>