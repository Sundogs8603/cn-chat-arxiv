<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;</title><link>http://arxiv.org/abs/2305.11857</link><description>&lt;p&gt;
Q-malizing&#27969;&#21644;&#26080;&#31351;&#23567;&#23494;&#24230;&#27604;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Q-malizing flow and infinitesimal density ratio estimation. (arXiv:2305.11857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11857
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#20174;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#20219;&#24847;&#35775;&#38382;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#30340;Q&#30340;&#27969;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#21487;&#20197;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#30340;&#27491;&#21017;&#21270;&#27969;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20854;&#20013;&#27969;&#32593;&#32476;&#20174;&#25968;&#25454;&#20998;&#24067;P&#20256;&#36755;&#21040;&#27491;&#24577;&#20998;&#24067;&#12290;&#19968;&#31181;&#33021;&#22815;&#20174;P&#20256;&#36755;&#21040;&#20219;&#24847;Q&#30340;&#27969;&#27169;&#22411;&#65292;&#20854;&#20013;P&#21644;Q&#37117;&#21487;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#35775;&#38382;&#65292;&#23558;&#22312;&#21508;&#31181;&#24212;&#29992;&#20852;&#36259;&#20013;&#20351;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#36817;&#24320;&#21457;&#30340;&#26395;&#36828;&#38236;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#65288;DRE&#65289;&#65292;&#23427;&#38656;&#35201;&#26500;&#24314;&#20013;&#38388;&#23494;&#24230;&#20197;&#22312;P&#21644;Q&#20043;&#38388;&#24314;&#31435;&#26725;&#26753;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#30340;&#8220;Q-malizing&#27969;&#8221;&#65292;&#36890;&#36807;&#31070;&#32463;ODE&#27169;&#22411;&#36827;&#34892;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32463;&#39564;&#26679;&#26412;&#30340;&#21487;&#36870;&#20256;&#36755;&#20174;P&#21040;Q&#65288;&#21453;&#20043;&#20134;&#28982;&#65289;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#20256;&#36755;&#25104;&#26412;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#35757;&#32451;&#22909;&#30340;&#27969;&#27169;&#22411;&#20351;&#25105;&#20204;&#33021;&#22815;&#27839;&#19982;&#26102;&#38388;&#21442;&#25968;&#21270;&#30340;log&#23494;&#24230;&#36827;&#34892;&#26080;&#31351;&#23567;DRE&#65292;&#36890;&#36807;&#35757;&#32451;&#38468;&#21152;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#32593;&#32476;&#20351;&#29992;&#20998;&#31867;&#25439;&#22833;&#26469;&#20272;&#35745;log&#23494;&#24230;&#30340;&#26102;&#38388;&#20559;&#23548;&#25968;&#12290;&#36890;&#36807;&#31215;&#20998;&#26102;&#38388;&#24471;&#20998;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous normalizing flows are widely used in generative tasks, where a flow network transports from a data distribution $P$ to a normal distribution. A flow model that can transport from $P$ to an arbitrary $Q$, where both $P$ and $Q$ are accessible via finite samples, would be of various application interests, particularly in the recently developed telescoping density ratio estimation (DRE) which calls for the construction of intermediate densities to bridge between $P$ and $Q$. In this work, we propose such a ``Q-malizing flow'' by a neural-ODE model which is trained to transport invertibly from $P$ to $Q$ (and vice versa) from empirical samples and is regularized by minimizing the transport cost. The trained flow model allows us to perform infinitesimal DRE along the time-parametrized $\log$-density by training an additional continuous-time flow network using classification loss, which estimates the time-partial derivative of the $\log$-density. Integrating the time-score network
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#31163;&#32447;&#35757;&#32451;&#30340; Web &#20195;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;WebGUM&#65292;&#23558;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.11854</link><description>&lt;p&gt;
&#20351;&#29992;&#25351;&#20196;&#24494;&#35843;&#22522;&#30784;&#27169;&#22411;&#30340;&#22810;&#27169;&#24577; Web &#23548;&#33322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multimodal Web Navigation with Instruction-Finetuned Foundation Models. (arXiv:2305.11854v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#31163;&#32447;&#35757;&#32451;&#30340; Web &#20195;&#29702;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;WebGUM&#65292;&#23558;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20027; Web &#23548;&#33322;&#30340;&#36827;&#23637;&#21463;&#21040;&#20102;&#20381;&#36182;&#25968;&#21313;&#20159;&#27425;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#25506;&#32034;&#24615;&#20132;&#20114;&#21644;&#20855;&#26377;&#39046;&#22495;&#29305;&#23450;&#27169;&#22411;&#35774;&#35745;&#30340;&#24433;&#21709;&#65292;&#36825;&#20351;&#24471;&#38590;&#20197;&#21033;&#29992;&#26469;&#33258;&#20016;&#23500;&#39046;&#22495;&#22806;&#25968;&#25454;&#30340;&#27867;&#21270;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#33073;&#26426;&#35757;&#32451;&#65292;&#29992;&#20110;&#20351;&#29992;&#35270;&#35273;&#35821;&#35328;&#22522;&#30784;&#27169;&#22411;&#30340; Web &#20195;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25351;&#20196;&#36319;&#38543;&#22810;&#27169;&#24577;&#20195;&#29702;&#65292; WebGUM&#65292;&#23427;&#35266;&#23519;&#20102;&#32593;&#39029;&#25130;&#22270;&#21644; HTML &#39029;&#38754;&#65292;&#24182;&#36755;&#20986; Web &#23548;&#33322;&#25805;&#20316;&#65292;&#22914;&#21333;&#20987;&#21644;&#36755;&#20837;&#12290;WebGUM &#26159;&#36890;&#36807;&#32852;&#21512;&#24494;&#35843;&#25351;&#20196;&#24494;&#35843;&#35821;&#35328;&#27169;&#22411;&#21644;&#35270;&#35273;&#36716;&#25442;&#22120;&#22312;&#22823;&#37327;&#30340;&#28436;&#31034;&#35821;&#26009;&#24211;&#19978;&#35757;&#32451;&#30340;&#12290;&#25105;&#20204;&#20973;&#32463;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#20195;&#29702;&#30340;&#22522;&#20110;&#35270;&#35273;&#24863;&#30693;&#12289;HTML &#29702;&#35299;&#21644;&#22810;&#27493;&#25512;&#29702;&#30340;&#33021;&#21147;&#65292;&#26126;&#26174;&#20248;&#20110;&#20043;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312; MiniWoB &#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#36229;&#36807;&#20043;&#21069;&#26368;&#20339;&#33073;&#26426;&#26041;&#27861; 31.9% &#20197;&#19978;&#65292;&#25509;&#36817;&#23454;&#29616;&#22312;&#32447;&#20132;&#20114;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision transformer on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded visual perception, HTML comprehension and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB benchmark, we improve over the previous best offline methods by more than 31.9%, being close to re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22810;&#27169;&#24577;&#32852;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#27969;&#21644;&#30456;&#20851;&#24615;&#20998;&#26512;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#26356;&#21152;&#36830;&#36143;&#30340;&#36328;&#27169;&#24577;&#29983;&#25104;&#65292;&#26356;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#65292;&#21516;&#26102;&#21487;&#25193;&#23637;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#27169;&#24577;&#12290;</title><link>http://arxiv.org/abs/2305.11832</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#27969;&#21644;&#30456;&#20851;&#24615;&#20998;&#26512;&#25913;&#36827;&#22810;&#27169;&#24577;&#32852;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Improving Multimodal Joint Variational Autoencoders through Normalizing Flows and Correlation Analysis. (arXiv:2305.11832v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11832
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#22810;&#27169;&#24577;&#32852;&#21512;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#27969;&#21644;&#30456;&#20851;&#24615;&#20998;&#26512;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#26356;&#21152;&#36830;&#36143;&#30340;&#36328;&#27169;&#24577;&#29983;&#25104;&#65292;&#26356;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#65292;&#21516;&#26102;&#21487;&#25193;&#23637;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#27169;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#27169;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#33021;&#22815;&#20174;&#32852;&#21512;&#20998;&#24067;&#29983;&#25104;&#24182;&#38024;&#23545;&#20219;&#24847;&#25968;&#37327;&#30340;&#22797;&#26434;&#27169;&#24577;&#36827;&#34892;&#26465;&#20214;&#29983;&#25104;&#12290;&#21333;&#27169;&#21518;&#39564;&#20998;&#24067;&#26159;&#22522;&#20110;&#20445;&#30041;&#36328;&#27169;&#24577;&#20849;&#20139;&#20449;&#24687;&#30340;&#28145;&#24230;&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#23884;&#20837;&#36827;&#34892;&#26465;&#20214;&#29983;&#25104;&#30340;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#36830;&#36143;&#30340;&#36328;&#27169;&#24577;&#29983;&#25104;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#27491;&#21017;&#21270;&#27969;&#26469;&#20016;&#23500;&#21333;&#27169;&#21518;&#39564;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#26356;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#19987;&#23478;&#20056;&#31215;&#26469;&#20174;&#22810;&#20010;&#27169;&#24577;&#20013;&#25512;&#26029;&#19968;&#20010;&#27169;&#24577;&#65292;&#20174;&#32780;&#20351;&#24471;&#27169;&#22411;&#21487;&#25193;&#23637;&#21040;&#20219;&#24847;&#25968;&#37327;&#30340;&#27169;&#24577;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;&#20284;&#28982;&#24230;&#20272;&#35745;&#12289;&#20195;&#34920;&#24615;&#30340;&#29983;&#25104;&#21644;&#22312;&#26465;&#20214;&#29983;&#25104;&#20013;&#29305;&#21035;&#26159;&#36830;&#36143;&#24615;&#25351;&#26631;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new multimodal variational autoencoder that enables to generate from the joint distribution and conditionally to any number of complex modalities. The unimodal posteriors are conditioned on the Deep Canonical Correlation Analysis embeddings which preserve the shared information across modalities leading to more coherent cross-modal generations. Furthermore, we use Normalizing Flows to enrich the unimodal posteriors and achieve more diverse data generation. Finally, we propose to use a Product of Experts for inferring one modality from several others which makes the model scalable to any number of modalities. We demonstrate that our method improves likelihood estimates, diversity of the generations and in particular coherence metrics in the conditional generations on several datasets.
&lt;/p&gt;</description></item><item><title>&#39318;&#27425;&#25552;&#20379;&#27010;&#29575;&#27969;ODE&#23454;&#29616;&#24471;&#21040;&#22810;&#39033;&#24335;&#26102;&#38388;&#25910;&#25947;&#20445;&#35777;&#30340;&#35777;&#26126;&#65292;&#20351;&#29992;&#27424;&#38459;&#23612;Langevin&#25193;&#25955;&#30340;&#29305;&#27530;&#36873;&#25321;&#30340;&#26657;&#27491;&#27493;&#39588;&#65292;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#65292;&#20984;&#26174;&#20102;ODE&#26694;&#26550;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.11798</link><description>&lt;p&gt;
&#27010;&#29575;&#27969;ODE&#21487;&#35777;&#26126;&#36895;&#24230;&#24555;
&lt;/p&gt;
&lt;p&gt;
The probability flow ODE is provably fast. (arXiv:2305.11798v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11798
&lt;/p&gt;
&lt;p&gt;
&#39318;&#27425;&#25552;&#20379;&#27010;&#29575;&#27969;ODE&#23454;&#29616;&#24471;&#21040;&#22810;&#39033;&#24335;&#26102;&#38388;&#25910;&#25947;&#20445;&#35777;&#30340;&#35777;&#26126;&#65292;&#20351;&#29992;&#27424;&#38459;&#23612;Langevin&#25193;&#25955;&#30340;&#29305;&#27530;&#36873;&#25321;&#30340;&#26657;&#27491;&#27493;&#39588;&#65292;&#33719;&#24471;&#20102;&#26356;&#22909;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#65292;&#20984;&#26174;&#20102;ODE&#26694;&#26550;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#27010;&#29575;&#27969;ODE&#23454;&#29616;&#65288;&#36830;&#21516;&#26657;&#27491;&#27493;&#39588;&#65289;&#24471;&#21040;&#22810;&#39033;&#24335;&#26102;&#38388;&#25910;&#25947;&#20445;&#35777;&#30340;&#35777;&#26126;&#65292;&#29992;&#20110;&#22522;&#20110;&#20998;&#25968;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26159;&#22312;&#26368;&#36817;&#30340;&#32467;&#26524;&#22522;&#30784;&#19978;&#36827;&#34892;&#30340;&#65292;&#35813;&#32467;&#26524;&#33719;&#24471;&#20102;&#22522;&#20110;SDE&#30340;&#23454;&#29616;&#65288;&#21363;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#24314;&#27169;&#25110;DDPM&#65289;&#30340;&#36825;&#26679;&#30340;&#20445;&#35777;&#65292;&#20294;&#38656;&#35201;&#24320;&#21457;&#26032;&#30340;&#25216;&#26415;&#26469;&#30740;&#31350;&#26080;&#25910;&#32553;&#30340;&#30830;&#23450;&#24615;&#21160;&#24577;&#12290;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#27424;&#38459;&#23612;Langevin&#25193;&#25955;&#30340;&#29305;&#27530;&#36873;&#25321;&#30340;&#26657;&#27491;&#27493;&#39588;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#27604;DDPM&#20043;&#21069;&#20316;&#21697;&#26356;&#22909;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#65288;&#20551;&#35774;&#25968;&#25454;&#20998;&#24067;&#24179;&#28369;&#65292;&#20026;$ O&#65288;\sqrt {d}&#65289;$&#32780;&#19981;&#26159;$ O&#65288;d&#65289;$&#65289;&#65292;&#20984;&#26174;&#20102;ODE&#26694;&#26550;&#30340;&#28508;&#22312;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first polynomial-time convergence guarantees for the probability flow ODE implementation (together with a corrector step) of score-based generative modeling. Our analysis is carried out in the wake of recent results obtaining such guarantees for the SDE-based implementation (i.e., denoising diffusion probabilistic modeling or DDPM), but requires the development of novel techniques for studying deterministic dynamics without contractivity. Through the use of a specially chosen corrector step based on the underdamped Langevin diffusion, we obtain better dimension dependence than prior works on DDPM ($O(\sqrt{d})$ vs. $O(d)$, assuming smoothness of the data distribution), highlighting potential advantages of the ODE framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#24120;&#25968;&#27493;&#38271;&#26799;&#24230;&#19979;&#38477;&#22312;&#31283;&#23450;&#24615;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#20559;&#24046;&#65292;&#35777;&#26126;&#20102;&#36923;&#36753;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#30340;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20102;&#25351;&#25968;&#25439;&#22833;&#19979;&#30340;&#21457;&#25955;&#24615;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#31283;&#23450;&#24615;&#36793;&#32536;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#19981;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11788</link><description>&lt;p&gt;
&#31283;&#23450;&#24615;&#36793;&#32536;&#22788;&#30340;&#36923;&#36753;&#22238;&#24402;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability. (arXiv:2305.11788v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#24120;&#25968;&#27493;&#38271;&#26799;&#24230;&#19979;&#38477;&#22312;&#31283;&#23450;&#24615;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#20559;&#24046;&#65292;&#35777;&#26126;&#20102;&#36923;&#36753;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#30340;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20102;&#25351;&#25968;&#25439;&#22833;&#19979;&#30340;&#21457;&#25955;&#24615;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#31283;&#23450;&#24615;&#36793;&#32536;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20248;&#21270;&#20013;&#65292;&#26799;&#24230;&#19979;&#38477; (GD) &#32463;&#24120;&#22312;&#31283;&#23450;&#24615;&#36793;&#32536; (EoS) [Cohen &#31561;&#65292;2021] &#36816;&#34892;&#65292;&#20854;&#20013;&#27493;&#38271;&#34987;&#35774;&#32622;&#20026;&#22823;&#65292;&#23548;&#33268;&#30001; GD &#36845;&#20195;&#24341;&#36215;&#30340;&#38750;&#21333;&#35843;&#25439;&#22833;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312; EoS &#21306;&#22495;&#20869;&#20351;&#29992;&#24120;&#25968;&#27493;&#38271; GD &#36827;&#34892;&#36923;&#36753;&#22238;&#24402;&#30340;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#20559;&#24046;&#65292;&#23545;&#20110;&#32447;&#24615;&#21487;&#20998;&#30340;&#25968;&#25454;&#12290;&#23613;&#31649;&#23384;&#22312;&#23616;&#37096;&#25391;&#33633;&#65292;&#25105;&#20204;&#35777;&#26126;&#36923;&#36753;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#30340; GD &#22312;&#38271;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#26368;&#23567;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#19979;&#65292;&#24403;&#25237;&#24433;&#21040;&#26368;&#22823;&#36793;&#38469;&#26041;&#21521; (&#30828;&#36793; SVM &#26041;&#21521;) &#26102;&#65292;GD &#36845;&#20195;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#65292;&#24182;&#22312;&#25237;&#24433;&#21040;&#26368;&#22823;&#36793;&#32536;&#30340;&#27491;&#20132;&#34917;&#31354;&#38388;&#26102;&#65292;&#25910;&#25947;&#20110;&#26368;&#23567;&#21270;&#24378;&#20984;&#21183;&#33021;&#30340;&#22266;&#23450;&#21521;&#37327;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20063;&#34920;&#26126;&#65292;&#22312; EoS &#21306;&#22495;&#65292;GD &#36845;&#20195;&#21487;&#33021;&#22312;&#25351;&#25968;&#25439;&#22833;&#19979;&#21457;&#29983;&#28798;&#38590;&#24615;&#21457;&#25955;&#65292;&#31361;&#26174;&#20102; EoS &#21306;&#22495;&#20013; GD &#30340;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research has observed that in machine learning optimization, gradient descent (GD) often operates at the edge of stability (EoS) [Cohen, et al., 2021], where the stepsizes are set to be large, resulting in non-monotonic losses induced by the GD iterates. This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime. Despite the presence of local oscillations, we prove that the logistic loss can be minimized by GD with any constant stepsize over a long time scale. Furthermore, we prove that with any constant stepsize, the GD iterates tend to infinity when projected to a max-margin direction (the hard-margin SVM direction) and converge to a fixed vector that minimizes a strongly convex potential when projected to the orthogonal complement of the max-margin direction. In contrast, we also show that in the EoS regime, GD iterates may diverge catastrophically under the exponential loss, highlighting t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.11774</link><description>&lt;p&gt;
&#20351;&#29992;R2&#25928;&#29992;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Optimization Using the R2 Utility. (arXiv:2305.11774v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#25551;&#36848;&#22810;&#30446;&#26631;&#20043;&#38388;&#26368;&#20339;&#26435;&#34913;&#30340;&#28857;&#38598;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#30690;&#37327;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#19994;&#32773;&#24120;&#24120;&#20351;&#29992;&#26631;&#37327;&#21270;&#20989;&#25968;&#23558;&#22810;&#30446;&#26631;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#12290;&#36825;&#32452;&#26631;&#37327;&#21270;&#38382;&#39064;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#26469;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32422;&#23450;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#36890;&#29992;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#31574;&#30053;&#22914;&#20309;&#26377;&#25928;&#22320;&#23558;&#21407;&#22987;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#36716;&#21270;&#20026;&#23450;&#20041;&#22312;&#38598;&#21512;&#19978;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#26032;&#38382;&#39064;&#30340;&#36866;&#24403;&#31867;&#21035;&#30340;&#30446;&#26631;&#20989;&#25968;&#26159;R2&#25928;&#29992;&#20989;&#25968;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#26631;&#37327;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#21152;&#26435;&#31215;&#20998;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#25928;&#29992;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#21644;&#27425;&#27169;&#30340;&#38598;&#21512;&#20989;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#26377;&#25928;&#22320;&#35745;&#31639;&#20986;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of multi-objective optimization is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimization problem, practitioners often appeal to the use of scalarization functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarized problems can then be solved using traditional single-objective optimization techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimization problem into a single-objective optimization problem defined over sets. An appropriate class of objective functions for this new problem is the R2 utility function, which is defined as a weighted integral over the scalarized optimization problems. We show that this utility function is a monotone and submodular set function, which can be op
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#22270;&#19978;&#23450;&#20041;&#30340;&#36716;&#31227;&#31639;&#23376;&#21450;&#20854;&#35889;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#36716;&#31227;&#31639;&#23376;&#30340;&#26377;&#21521;&#22270;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11766</link><description>&lt;p&gt;
&#22270;&#19978;&#30340;&#36716;&#31227;&#31639;&#23376;&#65306;&#35889;&#32858;&#31867;&#21450;&#20854;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Transfer operators on graphs: Spectral clustering and beyond. (arXiv:2305.11766v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#22270;&#19978;&#23450;&#20041;&#30340;&#36716;&#31227;&#31639;&#23376;&#21450;&#20854;&#35889;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#36716;&#31227;&#31639;&#23376;&#30340;&#26377;&#21521;&#22270;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21644;&#32593;&#32476;&#22312;&#24314;&#27169;&#21644;&#20998;&#26512;&#22797;&#26434;&#30340;&#30456;&#20851;&#31995;&#32479;&#20013;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#65292;&#20363;&#22914;&#20132;&#36890;&#32593;&#32476;&#65292;&#38598;&#25104;&#30005;&#36335;&#65292;&#30005;&#21147;&#32593;&#26684;&#65292;&#24341;&#25991;&#22270;&#20197;&#21450;&#29983;&#29289;&#21644;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#12290;&#26412;&#25991;&#22312;&#22270;&#19978;&#23450;&#20041;&#20102;&#36716;&#31227;&#31639;&#23376;&#65292;&#22914;Koopman&#31639;&#23376;&#21644;Perron-Frobenius&#31639;&#23376;&#65292;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#35889;&#29305;&#24615;&#65292;&#24341;&#20837;&#20102;&#36825;&#20123;&#31639;&#23376;&#30340;Galerkin&#25237;&#24433;&#65292;&#24182;&#35828;&#26126;&#20102;&#22914;&#20309;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#38477;&#20302;&#34920;&#31034;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#21521;&#22270;&#35889;&#32858;&#31867;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;Koopman&#31639;&#23376;&#30340;&#29305;&#24449;&#20989;&#25968;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#36716;&#31227;&#31639;&#23376;&#30340;&#26377;&#21521;&#22270;&#32858;&#31867;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#25152;&#24471;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19981;&#21516;&#32858;&#31867;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphs and networks play an important role in modeling and analyzing complex interconnected systems such as transportation networks, integrated circuits, power grids, citation graphs, and biological and artificial neural networks. Graph clustering algorithms can be used to detect groups of strongly connected vertices and to derive coarse-grained models. We define transfer operators such as the Koopman operator and the Perron-Frobenius operator on graphs, study their spectral properties, introduce Galerkin projections of these operators, and illustrate how reduced representations can be estimated from data. In particular, we show that spectral clustering of undirected graphs can be interpreted in terms of eigenfunctions of the Koopman operator and propose novel clustering algorithms for directed graphs based on generalized transfer operators. We demonstrate the efficacy of the resulting algorithms on several benchmark problems and provide different interpretations of clusters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#25104;&#21151;&#30340;&#36890;&#29992;&#21322;&#31354;&#38388;&#27979;&#35797;&#23398;&#20064;&#22120;&#65292;&#21487;&#20197;&#22312;&#24191;&#27867;&#32467;&#26500;&#21270;&#30340;&#20998;&#24067;&#19978;&#24037;&#20316;&#65292;&#23454;&#29616;&#35823;&#24046;$ O&#65288;\mathrm {opt}&#65289;+\ \epsilon $&#12290;</title><link>http://arxiv.org/abs/2305.11765</link><description>&lt;p&gt;
&#21322;&#31354;&#38388;&#30340;&#27979;&#35797;&#23398;&#20064;&#22120;&#65306;&#36890;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Tester-Learners for Halfspaces: Universal Algorithms. (arXiv:2305.11765v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#25104;&#21151;&#30340;&#36890;&#29992;&#21322;&#31354;&#38388;&#27979;&#35797;&#23398;&#20064;&#22120;&#65292;&#21487;&#20197;&#22312;&#24191;&#27867;&#32467;&#26500;&#21270;&#30340;&#20998;&#24067;&#19978;&#24037;&#20316;&#65292;&#23454;&#29616;&#35823;&#24046;$ O&#65288;\mathrm {opt}&#65289;+\ \epsilon $&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#24191;&#27867;&#32467;&#26500;&#21270;&#20998;&#24067;&#19978;&#25104;&#21151;&#30340;&#21322;&#31354;&#38388;&#27979;&#35797;&#23398;&#20064;&#22120;&#65292;&#35813;&#36890;&#29992;&#27979;&#35797;&#23398;&#20064;&#22120;&#22312;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#65292;&#24182;&#20855;&#26377;&#20197;&#19979;&#20445;&#35777;&#65306;&#23398;&#20064;&#22120;&#22312;&#27979;&#35797;&#22120;&#25509;&#21463;&#30340;&#20219;&#20309;&#26631;&#35760;&#20998;&#24067;&#19978;&#23454;&#29616;&#38169;&#35823;$ O&#65288;\mathrm {opt}&#65289;+\  \epsilon $&#65292;&#27492;&#22806;&#65292;&#27979;&#35797;&#22120;&#22312;&#36793;&#32536;&#20998;&#24067;&#26159;&#28385;&#36275;Poincar\'e&#19981;&#31561;&#24335;&#30340;&#20219;&#20309;&#20998;&#24067;&#26102;&#37117;&#21487;&#20197;&#25509;&#21463;&#12290;&#19982;&#20043;&#21069;&#22312;&#21487;&#27979;&#35797;&#23398;&#20064;&#26041;&#38754;&#30340;&#24037;&#20316;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#27979;&#35797;&#22120;&#27809;&#26377;&#38024;&#23545;&#20219;&#20309;&#21333;&#19968;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#35843;&#25972;&#65292;&#32780;&#26159;&#23545;&#19968;&#25972;&#20010;&#30446;&#26631;&#20998;&#24067;&#31867;&#25104;&#21151;&#12290;Poincar\'e&#20998;&#24067;&#31867;&#21253;&#25324;&#25152;&#26377;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#24182;&#19988;&#65292;&#22914;&#26524;&#20551;&#35774;Kannan-L\'{o}vasz-Simonovits&#65288;KLS&#65289;&#29468;&#24819;&#65292;&#21017;&#21253;&#25324;&#25152;&#26377;&#23545;&#25968;&#20985;&#20998;&#24067;&#12290;&#22312;&#26631;&#31614;&#22122;&#22768;&#24050;&#30693;&#20026;Massart&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#27979;&#35797;&#23398;&#20064;&#22120;&#22312;&#19981;&#21463;&#26465;&#20214;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#25509;&#21463;&#25152;&#26377;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#24182;&#23454;&#29616;&#35823;&#24046;$ \mathrm {opt} +\  \epsilon $&#12290;
&lt;/p&gt;
&lt;p&gt;
We give the first tester-learner for halfspaces that succeeds universally over a wide class of structured distributions. Our universal tester-learner runs in fully polynomial time and has the following guarantee: the learner achieves error $O(\mathrm{opt}) + \epsilon$ on any labeled distribution that the tester accepts, and moreover, the tester accepts whenever the marginal is any distribution that satisfies a Poincar\'e inequality. In contrast to prior work on testable learning, our tester is not tailored to any single target distribution but rather succeeds for an entire target class of distributions. The class of Poincar\'e distributions includes all strongly log-concave distributions, and, assuming the Kannan--L\'{o}vasz--Simonovits (KLS) conjecture, includes all log-concave distributions. In the special case where the label noise is known to be Massart, our tester-learner achieves error $\mathrm{opt} + \epsilon$ while accepting all log-concave distributions unconditionally (withou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2305.11650</link><description>&lt;p&gt;
&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411;&#65288;EBMs&#65289;&#20026;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;EBMs &#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20173;&#28982;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#29992;&#20110;&#21487;&#25193;&#23637; EBM &#35757;&#32451;&#30340;&#24191;&#27867;&#20351;&#29992;&#30340;&#21435;&#22122;&#20998;&#25968;&#21305;&#37197;&#65288;DSM&#65289;&#26041;&#27861;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#23548;&#33268;&#33021;&#37327;&#27169;&#22411;&#23398;&#20064;&#21040;&#8220;&#22024;&#26434;&#8221;&#30340;&#25968;&#25454;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26694;&#26550;&#65306;&#65288;&#20266;&#65289;Gibbs&#37319;&#26679;&#19982;&#21160;&#37327;&#21305;&#37197;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#32463;&#36807;DSM&#35757;&#32451;&#33391;&#22909;&#30340;&#8220;&#22024;&#26434;&#8221;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#22522;&#30784;&#8220;&#24178;&#20928;&#8221;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#30456;&#20851;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) offer a versatile framework for modeling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a `noisy' data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a `noisy' model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20002;&#22833;&#27169;&#24335;&#19979;&#26377;&#25928;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37327;&#21270;&#20102;&#32570;&#22833;&#23545;&#39044;&#27979;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.11640</link><description>&lt;p&gt;
&#20219;&#24847;&#32570;&#22833;&#27169;&#24335;&#19979;&#30340;&#26080;&#20998;&#24067;&#30697;&#38453;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern. (arXiv:2305.11640v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20002;&#22833;&#27169;&#24335;&#19979;&#26377;&#25928;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37327;&#21270;&#20102;&#32570;&#22833;&#23545;&#39044;&#27979;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#34892;/&#21015;&#21487;&#20132;&#25442;&#30697;&#38453;&#20013;&#39044;&#27979;&#32570;&#22833;&#26465;&#30446;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#30697;&#38453;&#35774;&#32622;&#25552;&#20986;&#20102;&#26032;&#39062;&#21644;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#20294;&#26159;&#22312;&#36825;&#20010;&#26377;&#36259;&#30340;&#20027;&#39064;&#19978;&#23384;&#22312;&#24456;&#23569;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#31934;&#32454;&#22320;&#23450;&#20041;&#20102;&#38382;&#39064;&#65292;&#23558;&#20854;&#19982;&#23494;&#20999;&#30456;&#20851;&#30340;&#38382;&#39064;&#21306;&#20998;&#24320;&#26469;&#65292;&#24182;&#20005;&#26684;&#21010;&#20998;&#20102;&#21487;&#36798;&#25104;&#21644;&#19981;&#21487;&#33021;&#30340;&#30446;&#26631;&#30340;&#36793;&#30028;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#39044;&#27979;&#30340;&#24555;&#36895;&#20223;&#30495;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#27861;&#21033;&#29992;&#31639;&#27861;&#31283;&#23450;&#24615;&#25216;&#26415;&#21152;&#36895;&#35745;&#31639;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20002;&#22833;&#27169;&#24335;&#19979;&#26377;&#25928;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#32570;&#22833;&#23545;&#39044;&#27979;&#31934;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#26412;&#30340;&#26497;&#38480;&#32467;&#26524;&#12290;&#26469;&#33258;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#32463;&#39564;&#35777;&#25454;&#35777;&#23454;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the open problem of conformalized entry prediction in a row/column-exchangeable matrix. The matrix setting presents novel and unique challenges, but there exists little work on this interesting topic. We meticulously define the problem, differentiate it from closely related problems, and rigorously delineate the boundary between achievable and impossible goals. We then propose two practical algorithms. The first method provides a fast emulation of the full conformal prediction, while the second method leverages the technique of algorithmic stability for acceleration. Both methods are computationally efficient and can effectively safeguard coverage validity in presence of arbitrary missing pattern. Further, we quantify the impact of missingness on prediction accuracy and establish fundamental limit results. Empirical evidence from synthetic and real-world data sets corroborates the superior performance of our proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#22238;&#24402;&#27169;&#22411;&#39044;&#27979;&#20013;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#26222;&#36866;&#24615;&#21644;&#19981;&#38169;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.11586</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#34701;&#20837;&#19981;&#30830;&#23450;&#36755;&#20837;
&lt;/p&gt;
&lt;p&gt;
Bayesian approach to Gaussian process regression with uncertain inputs. (arXiv:2305.11586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#22238;&#24402;&#27169;&#22411;&#39044;&#27979;&#20013;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#26222;&#36866;&#24615;&#21644;&#19981;&#38169;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20165;&#20551;&#35774;&#27169;&#22411;&#35266;&#27979;&#25968;&#25454;&#30340;&#36755;&#20986;&#20855;&#26377;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#24212;&#29992;&#20013;&#65292;&#30001;&#20110;&#24314;&#27169;&#20551;&#35774;&#12289;&#27979;&#37327;&#35823;&#24046;&#31561;&#22240;&#32032;&#65292;&#35266;&#27979;&#25968;&#25454;&#30340;&#36755;&#20837;&#20301;&#32622;&#21487;&#33021;&#20063;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#21487;&#21464;&#24615;&#34701;&#20837;&#21040;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#12290;&#32771;&#34385;&#20004;&#31181;&#21487;&#35266;&#27979;&#37327;&#8212;&#8212;&#20855;&#26377;&#22266;&#23450;&#36755;&#20837;&#30340;&#22122;&#22768;&#27745;&#26579;&#36755;&#20986;&#21644;&#20855;&#26377;&#20808;&#39564;&#20998;&#24067;&#23450;&#20041;&#30340;&#19981;&#30830;&#23450;&#36755;&#20837;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#20197;&#25512;&#26029;&#19981;&#30830;&#23450;&#30340;&#25968;&#25454;&#20301;&#32622;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36793;&#38469;&#21270;&#26041;&#27861;&#23558;&#36825;&#20123;&#36755;&#20837;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#32435;&#20837;&#39640;&#26031;&#36807;&#31243;&#39044;&#27979;&#20013;&#12290;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#36825;&#31181;&#26032;&#22238;&#24402;&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#65292;&#22312;&#20854;&#20013;&#35266;&#23519;&#21040;&#19981;&#21516;&#27700;&#24179;&#36755;&#20837;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#26222;&#36866;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional Gaussian process regression exclusively assumes the existence of noise in the output data of model observations. In many scientific and engineering applications, however, the input locations of observational data may also be compromised with uncertainties owing to modeling assumptions, measurement errors, etc. In this work, we propose a Bayesian method that integrates the variability of input data into Gaussian process regression. Considering two types of observables -- noise-corrupted outputs with fixed inputs and those with prior-distribution-defined uncertain inputs, a posterior distribution is estimated via a Bayesian framework to infer the uncertain data locations. Thereafter, such quantified uncertainties of inputs are incorporated into Gaussian process predictions by means of marginalization. The effectiveness of this new regression technique is demonstrated through several numerical examples, in which a consistently good performance of generalization is observed, w
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#28789;&#27963;&#30340;&#29983;&#23384;&#27169;&#22411;&#38598;&#25104;&#36827;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#65292;&#23454;&#29616;&#39044;&#27979;&#23384;&#22312;&#27835;&#24840;&#20998;&#25968;&#26102;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#12290;&#35813;&#26041;&#27861;&#21487;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#20801;&#35768;&#21327;&#21464;&#37327;&#21644;&#29983;&#23384;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#39640;&#32500;&#20132;&#20114;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#30495;&#23454;&#30340;&#21327;&#21464;&#37327;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2305.11575</link><description>&lt;p&gt;
&#28145;&#24230;&#25512;&#36827;&#26102;&#38388;&#27835;&#24840;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The Deep Promotion Time Cure Model. (arXiv:2305.11575v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11575
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#28789;&#27963;&#30340;&#29983;&#23384;&#27169;&#22411;&#38598;&#25104;&#36827;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#65292;&#23454;&#29616;&#39044;&#27979;&#23384;&#22312;&#27835;&#24840;&#20998;&#25968;&#26102;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#12290;&#35813;&#26041;&#27861;&#21487;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#20801;&#35768;&#21327;&#21464;&#37327;&#21644;&#29983;&#23384;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#39640;&#32500;&#20132;&#20114;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#30495;&#23454;&#30340;&#21327;&#21464;&#37327;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28789;&#27963;&#30340;&#29983;&#23384;&#27169;&#22411;&#38598;&#25104;&#21040;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#29992;&#20110;&#39044;&#27979;&#23384;&#22312;&#27835;&#24840;&#20998;&#25968;&#26102;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#21327;&#21464;&#37327;&#21644;&#29983;&#23384;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#39640;&#32500;&#20132;&#20114;&#65292;&#24182;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20801;&#35768;&#35813;&#26041;&#27861;&#21512;&#24182;&#19968;&#20010;&#30001;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#25928;&#24212;&#30340;&#38468;&#21152;&#20998;&#35299;&#24418;&#25104;&#30340;&#24050;&#35782;&#21035;&#30340;&#39044;&#27979;&#22120;&#65292;&#24182;&#28155;&#21152;&#27491;&#20132;&#21270;&#23618;&#20197;&#25429;&#33719;&#28508;&#22312;&#30340;&#26356;&#39640;&#32500;&#20132;&#20114;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22823;&#37327;&#30340;&#32654;&#22269;&#25269;&#25276;&#36151;&#27454;&#32452;&#21512;&#12290;&#22312;&#27492;&#65292;&#25105;&#20204;&#19981;&#20165;&#21457;&#29616;&#20102;&#25105;&#20204;&#26694;&#26550;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#19988;&#21457;&#29616;&#20102;&#26356;&#30495;&#23454;&#30340;&#21327;&#21464;&#37327;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel method for predicting time-to-event in the presence of cure fractions based on flexible survivals models integrated into a deep neural network framework. Our approach allows for non-linear relationships and high-dimensional interactions between covariates and survival and is suitable for large-scale applications. Furthermore, we allow the method to incorporate an identified predictor formed of an additive decomposition of interpretable linear and non-linear effects and add an orthogonalization layer to capture potential higher dimensional interactions. We demonstrate the usefulness and computational efficiency of our method via simulations and apply it to a large portfolio of US mortgage loans. Here, we find not only a better predictive performance of our framework but also a more realistic picture of covariate effects.
&lt;/p&gt;</description></item><item><title>TSGM&#25552;&#20379;&#20102;&#19968;&#31181;&#29983;&#25104;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#28789;&#27963;&#26694;&#26550;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#24555;&#36895;&#23454;&#29616;&#33258;&#24049;&#30340;&#26041;&#27861;&#24182;&#22312;&#21487;&#20849;&#20139;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#27604;&#36739;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#29983;&#25104;&#22823;&#35268;&#27169;&#30340;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#20197;&#29992;&#20110;&#35757;&#32451;&#21644;&#39564;&#35777;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.11567</link><description>&lt;p&gt;
TSGM&#65306;&#19968;&#31181;&#29983;&#25104;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#28789;&#27963;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
TSGM: A Flexible Framework for Generative Modeling of Synthetic Time Series. (arXiv:2305.11567v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11567
&lt;/p&gt;
&lt;p&gt;
TSGM&#25552;&#20379;&#20102;&#19968;&#31181;&#29983;&#25104;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#28789;&#27963;&#26694;&#26550;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#24555;&#36895;&#23454;&#29616;&#33258;&#24049;&#30340;&#26041;&#27861;&#24182;&#22312;&#21487;&#20849;&#20139;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#27604;&#36739;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#29983;&#25104;&#22823;&#35268;&#27169;&#30340;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#20197;&#29992;&#20110;&#35757;&#32451;&#21644;&#39564;&#35777;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#23545;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#32773;&#20063;&#24456;&#26377;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#36890;&#24120;&#24456;&#23569;&#25110;&#39640;&#24230;&#25935;&#24863;&#65292;&#36825;&#20351;&#24471;&#25968;&#25454;&#22312;&#30740;&#31350;&#32773;&#21644;&#24037;&#19994;&#32452;&#32455;&#20043;&#38388;&#30340;&#20849;&#20139;&#20197;&#21450;&#29616;&#26377;&#21644;&#26032;&#30340;&#25968;&#25454;&#23494;&#38598;&#22411; ML &#26041;&#27861;&#30340;&#24212;&#29992;&#21463;&#21040;&#38480;&#21046;&#12290;&#35299;&#20915;&#36825;&#19968;&#38590;&#39064;&#30340;&#21487;&#33021;&#26041;&#27861;&#26159;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#27169;&#22411;&#65288;TSGM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#24320;&#28304;&#26694;&#26550;&#12290;TSGM&#21253;&#25324;&#24191;&#27867;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65306;&#29983;&#25104;&#27169;&#22411;&#12289;&#27010;&#29575;&#27169;&#22411;&#21644;&#22522;&#20110;&#27169;&#25311;&#22120;&#30340;&#26041;&#27861;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#25143;&#33021;&#22815;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#35780;&#20272;&#29983;&#25104;&#30340;&#25968;&#25454;&#30340;&#36136;&#37327;&#65306;&#30456;&#20284;&#24615;&#12289;&#19979;&#28216;&#25928;&#26524;&#12289;&#39044;&#27979;&#19968;&#33268;&#24615;&#12289;&#22810;&#26679;&#24615;&#21644;&#38544;&#31169;&#12290;&#35813;&#26694;&#26550;&#26159;&#21487;&#25193;&#23637;&#30340;&#65292;&#36825;&#20351;&#24471;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#24555;&#36895;&#23454;&#29616;&#33258;&#24049;&#30340;&#26041;&#27861;&#24182;&#22312;&#21487;&#20849;&#20139;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#27604;&#36739;&#12290;TSGM&#23558;&#26377;&#21161;&#20110;&#29983;&#25104;&#22823;&#35268;&#27169;&#30340;&#21512;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#21487;&#20197;&#29992;&#20110;&#35757;&#32451;&#21644;&#39564;&#35777;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporally indexed data are essential in a wide range of fields and of interest to machine learning researchers. Time series data, however, are often scarce or highly sensitive, which precludes the sharing of data between researchers and industrial organizations and the application of existing and new data-intensive ML methods. A possible solution to this bottleneck is to generate synthetic data. In this work, we introduce Time Series Generative Modeling (TSGM), an open-source framework for the generative modeling of synthetic time series. TSGM includes a broad repertoire of machine learning methods: generative models, probabilistic, and simulator-based approaches. The framework enables users to evaluate the quality of the produced data from different angles: similarity, downstream effectiveness, predictive consistency, diversity, and privacy. The framework is extensible, which allows researchers to rapidly implement their own methods and compare them in a shareable environment. TSGM w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.11509</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#25628;&#32034;&#21040;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25628;&#32034;&#26159;&#36229;&#21442;&#25968;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#24615;&#33021;&#20196;&#20154;&#24778;&#21497;&#65292;&#20294;&#24456;&#23569;&#26377;&#38750;&#21551;&#21457;&#24335;&#30340;&#29702;&#35770;&#29992;&#20110;&#25551;&#36848;&#20854;&#24037;&#20316;&#26426;&#21046;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#38543;&#26426;&#25628;&#32034;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#24182;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29615;&#22659;&#27809;&#26377;&#22122;&#22768;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#20854;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $&#65292;&#20854;&#20013;$ d_s \ge 0 $&#26159;&#24213;&#23618;&#20989;&#25968;&#30340;&#25955;&#23556;&#32500;&#24230;&#12290;&#24403;&#35266;&#23519;&#21040;&#30340;&#20989;&#25968;&#20540;&#21463;&#21040;&#26377;&#30028;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#22122;&#22768;&#24433;&#21709;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#36870;&#25193;&#25955;&#30340;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#22312;&#36828;&#31163;&#26368;&#20248;&#28857;&#26102;&#35774;&#32622;&#36739;&#22823;&#30340;&#25193;&#25955;&#31995;&#25968;&#20197;&#21450;&#22312;&#38468;&#36817;&#26102;&#35774;&#32622;&#36739;&#23567;&#30340;&#25193;&#25955;&#31995;&#25968;&#26469;&#21152;&#36895;&#25910;&#25947;&#24182;&#35843;&#33410;&#31163;&#25955;&#35823;&#24046;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11493</link><description>&lt;p&gt;
&#21487;&#36870;&#25193;&#25955;&#21152;&#36895;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#30340;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Accelerating Convergence in Global Non-Convex Optimization with Reversible Diffusion. (arXiv:2305.11493v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11493
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#36870;&#25193;&#25955;&#30340;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#22312;&#36828;&#31163;&#26368;&#20248;&#28857;&#26102;&#35774;&#32622;&#36739;&#22823;&#30340;&#25193;&#25955;&#31995;&#25968;&#20197;&#21450;&#22312;&#38468;&#36817;&#26102;&#35774;&#32622;&#36739;&#23567;&#30340;&#25193;&#25955;&#31995;&#25968;&#26469;&#21152;&#36895;&#25910;&#25947;&#24182;&#35843;&#33410;&#31163;&#25955;&#35823;&#24046;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#20013;&#65292;&#30001;&#20110;&#22312;&#20302;&#28201;&#19979;&#20854;&#31283;&#23450;&#20998;&#24067;&#38598;&#20013;&#22312;&#28508;&#22312;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#28857;&#38468;&#36817;&#65292;Langevin&#21160;&#21147;&#23398;&#24050;&#34987;&#24191;&#27867;&#22320;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#19968;&#31867;&#26356;&#20026;&#20840;&#38754;&#30340;&#38543;&#26426;&#36807;&#31243;&#8212;&#8212;&#21487;&#36870;&#25193;&#25955;&#65292;&#20197;&#21450;&#24212;&#29992;&#27431;&#25289;-&#39532;&#40065;&#38597;&#39532;&#20998;&#35299;&#36827;&#34892;&#20840;&#23616;&#38750;&#20984;&#20248;&#21270;&#12290;&#25105;&#20204;&#35774;&#35745;&#30340;&#25193;&#25955;&#31995;&#25968;&#22312;&#36828;&#31163;&#26368;&#20248;&#28857;&#26102;&#36739;&#22823;&#65292;&#22312;&#38468;&#36817;&#26102;&#36739;&#23567;&#65292;&#20174;&#32780;&#22312;&#35843;&#33410;&#31163;&#25955;&#35823;&#24046;&#30340;&#21516;&#26102;&#21152;&#36895;&#25910;&#25947;&#65292;&#36825;&#31181;&#31574;&#30053;&#21463;&#21040;&#20102;&#26223;&#35266;&#20462;&#25913;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20063;&#21487;&#20197;&#30475;&#20316;&#26159;Langevin&#21160;&#21147;&#23398;&#30340;&#26102;&#38388;&#21464;&#25442;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#23601;KL&#25955;&#24230;&#32780;&#35328;&#65292;&#30740;&#31350;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#31163;&#25955;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Langevin Dynamics has been extensively employed in global non-convex optimization due to the concentration of its stationary distribution around the global minimum of the potential function at low temperatures. In this paper, we propose to utilize a more comprehensive class of stochastic processes, known as reversible diffusion, and apply the Euler-Maruyama discretization for global non-convex optimization. We design the diffusion coefficient to be larger when distant from the optimum and smaller when near, thus enabling accelerated convergence while regulating discretization error, a strategy inspired by landscape modifications. Our proposed method can also be seen as a time change of Langevin Dynamics, and we prove convergence with respect to KL divergence, investigating the trade-off between convergence speed and discretization error. The efficacy of our proposed method is demonstrated through numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#20849;&#26354;&#25233;&#21046;&#27491;&#21017;&#21270;&#22120;&#65292;&#29992;&#20110;&#24212;&#23545;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#26131;&#21463;&#20849;&#38169;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24809;&#32602;&#38750;&#32447;&#24615;&#36716;&#25442;&#30340;&#29305;&#24449;&#21464;&#37327;&#30340;&#25104;&#23545;&#30456;&#20851;&#24615;&#65292;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11475</link><description>&lt;p&gt;
&#26354;&#32447;&#19978;&#25196;&#65306;&#22312;&#21487;&#24494;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#20849;&#26354;&#25233;&#21046;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models. (arXiv:2305.11475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#20849;&#26354;&#25233;&#21046;&#27491;&#21017;&#21270;&#22120;&#65292;&#29992;&#20110;&#24212;&#23545;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#26131;&#21463;&#20849;&#38169;&#24615;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#24809;&#32602;&#38750;&#32447;&#24615;&#36716;&#25442;&#30340;&#29305;&#24449;&#21464;&#37327;&#30340;&#25104;&#23545;&#30456;&#20851;&#24615;&#65292;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65288;GAM&#65289;&#21487;&#34920;&#36798;&#30446;&#26631;&#21464;&#37327;&#20026;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#21644;&#35299;&#37322;&#24615;&#65292;&#20854;&#20877;&#27425;&#21463;&#21040;&#27426;&#36814;&#12290;&#23613;&#31649;GAM&#30446;&#21069;&#22791;&#21463;&#28909;&#25447;&#65292;&#20294;&#20854;&#26131;&#21463;&#20849;&#38169;&#24615;&#65292;&#21363;&#29305;&#24449;&#20043;&#38388;&#30340;&#65288;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#30340;&#65289;&#20381;&#36182;&#24615;&#36804;&#20170;&#20026;&#27490;&#22823;&#22810;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20849;&#38169;&#24615;&#22914;&#20309;&#20005;&#37325;&#30772;&#22351;GAM&#30340;&#35299;&#37322;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#27861;&#65306;&#19968;&#20010;&#22312;&#38750;&#32447;&#24615;&#36716;&#25442;&#30340;&#29305;&#24449;&#21464;&#37327;&#30340;&#25104;&#23545;&#30456;&#20851;&#24615;&#19978;&#36827;&#34892;&#24809;&#32602;&#30340;&#27010;&#24565;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#22120;&#12290;&#35813;&#36807;&#31243;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#24494;&#30340;&#21152;&#24615;&#27169;&#22411;&#65292;&#22914;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#25110;&#31070;&#32463;&#39044;&#35328;&#12290;&#24182;&#19988;&#36890;&#36807;&#28040;&#38500;&#33258;&#25105;&#25269;&#28040;&#30340;&#29305;&#24449;&#36129;&#29486;&#30340;&#27495;&#20041;&#65292;&#22686;&#24378;&#20102;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#26102;&#38388;&#24207;&#21015;&#21644;&#34920;&#26684;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#22120;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurvity - i.e., (possibly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concurvity can severly impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time-series and tabular d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.11463</link><description>&lt;p&gt;
&#21033;&#29992;Riesz&#26680;&#30340;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;
&lt;/p&gt;
&lt;p&gt;
Generative Sliced MMD Flows with Riesz Kernels. (arXiv:2305.11463v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;Riesz&#26680;&#23637;&#31034;&#20102;&#29983;&#25104;&#24335;&#20998;&#21106;MMD&#27969;&#30340;&#39640;&#25928;&#35745;&#31639;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#35745;&#31639;&#20013;&#65292;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#24230;(MMD)&#27969;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;Riesz&#26680;$K(x,y)=-\|x-y\|^r$&#65292;$r \in (0,2)$&#30340;MMD&#27969;&#20855;&#26377;&#26480;&#20986;&#30340;&#24615;&#36136;&#65292;&#21487;&#20801;&#35768;&#20854;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#12290;&#39318;&#20808;&#65292;Riesz&#26680;&#30340;MMD&#19982;&#20854;&#20998;&#21106;&#29256;&#26412;&#30340;MMD&#37325;&#21512;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#22312;&#19968;&#32500;&#35774;&#32622;&#20013;&#36827;&#34892;MMD&#26799;&#24230;&#30340;&#35745;&#31639;&#12290;&#22312;&#27492;&#22788;&#65292;&#23545;&#20110;$r=1$&#65292;&#21487;&#20197;&#24212;&#29992;&#31616;&#21333;&#30340;&#25490;&#24207;&#31639;&#27861;&#23558;&#20004;&#20010;&#32463;&#39564;&#24230;&#37327;&#30340;&#22797;&#26434;&#24230;&#20174;$O(MN+N^2)$&#38477;&#20302;&#21040;$O((M+N)\log(M+N))$&#65292;&#20854;&#20013;$M$&#21644;$N$&#26159;&#25903;&#25345;&#28857;&#12290;&#23545;&#20110;&#23454;&#29616;&#65292;&#25105;&#20204;&#36890;&#36807;&#20165;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;$P$&#20010;&#20999;&#29255;&#26469;&#36817;&#20284;&#20998;&#21106;MMD&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;&#35823;&#24046;&#20855;&#26377;$O(\sqrt{d/P})$&#30340;&#22797;&#26434;&#24230;&#65292;&#20854;&#20013;$d$&#26159;&#25968;&#25454;&#32500;&#24230;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;MMD&#26799;&#24230;&#27969;&#26469;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#29978;&#33267;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancy (MMD) flows suffer from high computational costs in large scale computations. In this paper, we show that MMD flows with Riesz kernels $K(x,y) = - \|x-y\|^r$, $r \in (0,2)$ have exceptional properties which allow for their efficient computation. First, the MMD of Riesz kernels coincides with the MMD of their sliced version. As a consequence, the computation of gradients of MMDs can be performed in the one-dimensional setting. Here, for $r=1$, a simple sorting algorithm can be applied to reduce the complexity from $O(MN+N^2)$ to $O((M+N)\log(M+N))$ for two empirical measures with $M$ and $N$ support points. For the implementations we approximate the gradient of the sliced MMD by using only a finite number $P$ of slices. We show that the resulting error has complexity $O(\sqrt{d/P})$, where $d$ is the data dimension. These results enable us to train generative models by approximating MMD gradient flows by neural networks even for large scale applications. We demo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#25299;&#25169;&#8212;&#8212;&#22522;&#30784;$(k+1)$&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#21518;&#33021;&#36798;&#21040;&#30830;&#20999;&#30340;&#20849;&#35782;&#65292;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#21644;&#23567;&#30340;&#26368;&#22823;&#24230;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#29992;&#20110;&#20998;&#25955;&#24335;SGD&#12290;</title><link>http://arxiv.org/abs/2305.11420</link><description>&lt;p&gt;
&#36229;&#36234;&#25351;&#25968;&#22270;&#65306;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#30340;&#36890;&#20449;&#25928;&#29575;&#25299;&#25169;&#29992;&#20110;&#20998;&#25955;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence. (arXiv:2305.11420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#25299;&#25169;&#8212;&#8212;&#22522;&#30784;$(k+1)$&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#21518;&#33021;&#36798;&#21040;&#30830;&#20999;&#30340;&#20849;&#35782;&#65292;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#21644;&#23567;&#30340;&#26368;&#22823;&#24230;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#29992;&#20110;&#20998;&#25955;&#24335;SGD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#20110;&#20998;&#25955;&#24335;&#23398;&#20064;&#22312;&#24182;&#34892;&#35745;&#31639;&#21644;&#38544;&#31169;&#20445;&#25252;&#20013;&#30340;&#24212;&#29992;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#25351;&#20986;&#65292;&#20855;&#26377;&#26356;&#24555;&#20849;&#35782;&#29575;&#65288;&#21363;&#35889;&#38388;&#38553;&#65289;&#30340;&#24213;&#23618;&#32593;&#32476;&#25299;&#25169;&#21487;&#23548;&#33268;&#20998;&#25955;&#24335;&#23398;&#20064;&#30340;&#26356;&#22909;&#25910;&#25947;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#30340;&#25299;&#25169;&#65292;&#22914;&#25351;&#25968;&#22270;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#22823;&#30340;&#26368;&#22823;&#24230;&#25968;&#65292;&#36825;&#20250;&#23548;&#33268;&#37325;&#35201;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#22240;&#27492;&#65292;&#23547;&#27714;&#26082;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#21448;&#20855;&#26377;&#23567;&#30340;&#26368;&#22823;&#24230;&#25968;&#30340;&#25299;&#25169;&#26159;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#24555;&#36895;&#20849;&#35782;&#29575;&#21644;&#23567;&#26368;&#22823;&#24230;&#30340;&#26032;&#22411;&#25299;&#25169;&#65292;&#31216;&#20026;&#22522;&#30784;$(k+1)$ &#22270;&#12290;&#19982;&#29616;&#26377;&#30340;&#25299;&#25169;&#19981;&#21516;&#65292;&#22522;&#30784;$(k+1)$ &#22270;&#20351;&#25152;&#26377;&#33410;&#28857;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#21518;&#37117;&#33021;&#36798;&#21040;&#30830;&#20999;&#30340;&#20849;&#35782;&#65292;&#23545;&#20110;&#20219;&#20309;&#33410;&#28857;&#25968;&#21644;&#26368;&#22823;&#24230;k&#37117;&#36866;&#29992;&#12290;&#24471;&#30410;&#20110;&#36825;&#20010;&#26377;&#21033;&#30340;&#23646;&#24615;&#65292;&#22522;&#30784;$(k+1)$ &#22270;&#36171;&#20104;&#20102;&#20998;&#25955;&#24335;SGD
&lt;/p&gt;
&lt;p&gt;
Decentralized learning has recently been attracting increasing attention for its applications in parallel computation and privacy preservation. Many recent studies stated that the underlying network topology with a faster consensus rate (a.k.a. spectral gap) leads to a better convergence rate and accuracy for decentralized learning. However, a topology with a fast consensus rate, e.g., the exponential graph, generally has a large maximum degree, which incurs significant communication costs. Thus, seeking topologies with both a fast consensus rate and small maximum degree is important. In this study, we propose a novel topology combining both a fast consensus rate and small maximum degree called the Base-$(k + 1)$ Graph. Unlike the existing topologies, the Base-$(k + 1)$ Graph enables all nodes to reach the exact consensus after a finite number of iterations for any number of nodes and maximum degree k. Thanks to this favorable property, the Base-$(k + 1)$ Graph endows Decentralized SGD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#26681;&#25454;cGAN&#30340;&#21028;&#21035;&#22120;&#25968;&#25454;&#35782;&#21035;&#20986;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#65292;&#20197;&#36991;&#20813;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11400</link><description>&lt;p&gt;
&#38754;&#21521;&#26377;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#23569;&#26679;&#26412;&#36830;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Few-Shot Continual Learning for Conditional Generative Adversarial Networks. (arXiv:2305.11400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#26681;&#25454;cGAN&#30340;&#21028;&#21035;&#22120;&#25968;&#25454;&#35782;&#21035;&#20986;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#65292;&#24182;&#36890;&#36807;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#65292;&#20197;&#36991;&#20813;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25552;&#39640;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#27169;&#22411;&#30340;&#23569;&#26679;&#26412;&#36830;&#32493;&#23398;&#20064;&#20013;&#65292;&#24517;&#39035;&#23398;&#20064;&#30446;&#26631;&#27169;&#24335;&#65292;&#24182;&#22312;&#19981;&#24433;&#21709;&#20808;&#21069;&#23398;&#20064;&#21040;&#30340;&#27169;&#24335;&#30340;&#24773;&#20917;&#19979;&#20165;&#20351;&#29992;&#26377;&#38480;&#30340;&#26679;&#26412;&#12290;&#26412;&#25991;&#38024;&#23545;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#22522;&#20110;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#30340;&#27169;&#24335;&#20146;&#21644;&#21147;&#37327;&#24230;&#12290;&#25105;&#20204;&#30340;&#24230;&#37327;&#23436;&#20840;&#22522;&#20110;cGAN&#30340;&#21028;&#21035;&#22120;&#65292;&#21487;&#20197;&#35782;&#21035;&#26368;&#25509;&#36817;&#30446;&#26631;&#30340;&#29616;&#26377;&#27169;&#24335;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#21253;&#21547;&#22522;&#20110;&#26368;&#25509;&#36817;&#27169;&#24335;&#30340;&#21152;&#26435;&#26631;&#31614;&#26469;&#25193;&#23637;&#36830;&#32493;&#23398;&#20064;&#27169;&#22411;&#12290;&#20026;&#20102;&#39044;&#38450;&#28798;&#38590;&#24615;&#36951;&#24536;&#65292;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;cGAN&#30340;&#29983;&#25104;&#22120;&#29983;&#25104;&#24102;&#26631;&#31614;&#30340;&#25968;&#25454;&#26679;&#26412;&#65292;&#28982;&#21518;&#36890;&#36807;&#22238;&#25918;&#29983;&#25104;&#30340;&#25968;&#25454;&#26469;&#35757;&#32451;&#30446;&#26631;&#27169;&#24335;&#30340;cGAN&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#39640;&#29983;&#25104;&#24615;&#33021;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#36229;&#36234;&#20102;&#21508;&#31181;&#26631;&#20934;&#21644;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In few-shot continual learning for generative models, a target mode must be learned with limited samples without adversely affecting the previously learned modes. In this paper, we propose a new continual learning approach for conditional generative adversarial networks (cGAN) based on a new mode-affinity measure for generative modeling. Our measure is entirely based on the cGAN's discriminator and can identify the existing modes that are most similar to the target. Subsequently, we expand the continual learning model by including the target mode using a weighted label derived from those of the closest modes. To prevent catastrophic forgetting, we first generate labeled data samples using the cGAN's generator, and then train the cGAN model for the target mode while memory replaying with the generated data. Our experimental results demonstrate the efficacy of our approach in improving the generation performance over the baselines and the state-of-the-art approaches for various standard 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31934;&#24230;&#30697;&#38453;&#65288;GPM&#65289;&#29992;&#20110;&#25551;&#36848;&#25152;&#26377;&#25968;&#25454;&#31867;&#22411;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#65292;&#24182;&#20801;&#35768;&#21464;&#37327;&#20043;&#38388;&#30340;&#19968;&#33324;&#21151;&#33021;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39532;&#23572;&#31185;&#22827;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22788;&#29702;&#22823;&#22270;&#26102;&#65292;&#20351;&#29992;&#20102;&#32479;&#19968;&#30340;&#27491;&#21017;&#21270;&#24471;&#20998;&#21305;&#37197;&#26694;&#26550;&#20197;&#25552;&#39640;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11379</link><description>&lt;p&gt;
&#24191;&#20041;&#31934;&#24230;&#30697;&#38453;&#29992;&#20110;&#21487;&#20280;&#32553;&#20272;&#35745;&#38750;&#21442;&#25968;&#39532;&#23572;&#31185;&#22827;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Generalized Precision Matrix for Scalable Estimation of Nonparametric Markov Networks. (arXiv:2305.11379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#31934;&#24230;&#30697;&#38453;&#65288;GPM&#65289;&#29992;&#20110;&#25551;&#36848;&#25152;&#26377;&#25968;&#25454;&#31867;&#22411;&#30340;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#65292;&#24182;&#20801;&#35768;&#21464;&#37327;&#20043;&#38388;&#30340;&#19968;&#33324;&#21151;&#33021;&#20851;&#31995;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39532;&#23572;&#31185;&#22827;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22788;&#29702;&#22823;&#22270;&#26102;&#65292;&#20351;&#29992;&#20102;&#32479;&#19968;&#30340;&#27491;&#21017;&#21270;&#24471;&#20998;&#21305;&#37197;&#26694;&#26550;&#20197;&#25552;&#39640;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#31185;&#22827;&#32593;&#32476;&#32473;&#20986;&#20102;&#19968;&#32452;&#38543;&#26426;&#21464;&#37327;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#32467;&#26500;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#20391;&#37325;&#20110;&#29305;&#23450;&#30340;&#20998;&#24067;&#26063;&#65288;&#20363;&#22914;&#25351;&#25968;&#26063;&#65289;&#21644;/&#25110;&#29305;&#23450;&#30340;&#22270;&#32467;&#26500;&#65292;&#32780;&#19988;&#22823;&#22810;&#25968;&#21482;&#33021;&#22788;&#29702;&#21516;&#19968;&#31181;&#25968;&#25454;&#31867;&#22411;&#30340;&#21464;&#37327;&#65288;&#36830;&#32493;&#25110;&#31163;&#25955;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#24191;&#20041;&#31934;&#24230;&#30697;&#38453;&#65288;GPM&#65289;&#22312;&#25152;&#26377;&#25968;&#25454;&#31867;&#22411;&#65288;&#21363;&#36830;&#32493;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31867;&#22411;&#65289;&#30340;&#19968;&#33324;&#20998;&#24067;&#20013;&#25551;&#36848;&#26465;&#20214;&#29420;&#31435;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20801;&#35768;&#21464;&#37327;&#20043;&#38388;&#30340;&#19968;&#33324;&#21151;&#33021;&#20851;&#31995;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31181;&#26368;&#19968;&#33324;&#30340;&#39532;&#23572;&#31185;&#22827;&#32593;&#32476;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#12290;&#20026;&#20102;&#22788;&#29702;&#38382;&#39064;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#22823;&#22270;&#65292;&#25105;&#20204;&#23558;&#25152;&#26377;&#24773;&#20917;&#32479;&#19968;&#21040;&#19968;&#20010;&#27491;&#21017;&#21270;&#24471;&#20998;&#21305;&#37197;&#26694;&#26550;&#19979;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#24182;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#28436;&#31034;&#20102;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Markov network characterizes the conditional independence structure, or Markov property, among a set of random variables. Existing work focuses on specific families of distributions (e.g., exponential families) and/or certain structures of graphs, and most of them can only handle variables of a single data type (continuous or discrete). In this work, we characterize the conditional independence structure in general distributions for all data types (i.e., continuous, discrete, and mixed-type) with a Generalized Precision Matrix (GPM). Besides, we also allow general functional relations among variables, thus giving rise to a Markov network structure learning algorithm in one of the most general settings. To deal with the computational challenge of the problem, especially for large graphs, we unify all cases under the same umbrella of a regularized score matching framework. We validate the theoretical results and demonstrate the scalability empirically in various settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#23569;&#37327;&#30340;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;CATE&#20272;&#35745;&#38382;&#39064;&#36827;&#34892;&#20998;&#35299;&#24182;&#20351;&#29992;&#38381;&#24335;&#27714;&#35299;&#22120;&#33719;&#24471;&#21442;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#20219;&#21153;&#20043;&#38388;&#30340;&#20849;&#20139;&#21644;&#20248;&#21270;CATE&#20272;&#35745;&#34920;&#29616;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2305.11353</link><description>&lt;p&gt;
&#20855;&#26377;&#38381;&#24335;&#27714;&#35299;&#22120;&#30340;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20803;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Meta-learning for heterogeneous treatment effect estimation with closed-form solvers. (arXiv:2305.11353v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#23569;&#37327;&#30340;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;CATE&#20272;&#35745;&#38382;&#39064;&#36827;&#34892;&#20998;&#35299;&#24182;&#20351;&#29992;&#38381;&#24335;&#27714;&#35299;&#22120;&#33719;&#24471;&#21442;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#20219;&#21153;&#20043;&#38388;&#30340;&#20849;&#20139;&#21644;&#20248;&#21270;CATE&#20272;&#35745;&#34920;&#29616;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#23569;&#37327;&#30340;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23398;&#20064;&#22914;&#20309;&#20174;&#22810;&#20010;&#20219;&#21153;&#20013;&#20272;&#35745;CATE&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#30693;&#35782;&#26469;&#36827;&#34892;&#26410;&#35265;&#36807;&#30340;&#20219;&#21153;&#12290;&#22312;&#35813;&#26041;&#27861;&#20013;&#65292;&#22522;&#20110;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#25105;&#20204;&#23558;CATE&#20272;&#35745;&#38382;&#39064;&#20998;&#35299;&#20026;&#23376;&#38382;&#39064;&#12290;&#23545;&#20110;&#27599;&#20010;&#23376;&#38382;&#39064;&#65292;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#20219;&#21153;&#20849;&#20139;&#21644;&#20219;&#21153;&#29305;&#23450;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#26500;&#24314;&#25105;&#20204;&#30340;&#20272;&#35745;&#27169;&#22411;&#12290;&#36890;&#36807;&#25105;&#20204;&#30340;&#20844;&#24335;&#21270;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#21487;&#24494;&#20998;&#30340;&#38381;&#24335;&#30340;&#26368;&#20248;&#20219;&#21153;&#29305;&#23450;&#21442;&#25968;&#65292;&#36825;&#20123;&#21442;&#25968;&#33021;&#22815;&#30456;&#23545;&#20110;&#20219;&#21153;&#20849;&#20139;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#30340;&#20803;&#23398;&#20064;&#12290;&#25105;&#20204;&#35757;&#32451;&#20219;&#21153;&#20849;&#20139;&#21442;&#25968;&#65292;&#20197;&#20351;&#23569;&#31034;&#28857;&#35774;&#32622;&#19979;&#30340;CATE&#20272;&#35745;&#34920;&#29616;&#36890;&#36807;&#23558;&#20351;&#29992;&#22823;&#37327;&#25968;&#25454;&#20272;&#35745;&#30340;CATE&#19982;&#20165;&#20351;&#29992;&#23569;&#37327;&#25968;&#25454;&#20272;&#35745;&#30340;CATE&#20043;&#38388;&#30340;&#24046;&#24322;&#26368;&#23567;&#21270;&#24471;&#21040;&#25913;&#21892;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;CATE&#20272;&#35745;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article proposes a meta-learning method for estimating the conditional average treatment effect (CATE) from a few observational data. The proposed method learns how to estimate CATEs from multiple tasks and uses the knowledge for unseen tasks. In the proposed method, based on the meta-learner framework, we decompose the CATE estimation problem into sub-problems. For each sub-problem, we formulate our estimation models using neural networks with task-shared and task-specific parameters. With our formulation, we can obtain optimal task-specific parameters in a closed form that are differentiable with respect to task-shared parameters, making it possible to perform effective meta-learning. The task-shared parameters are trained such that the expected CATE estimation performance in few-shot settings is improved by minimizing the difference between a CATE estimated with a large amount of data and one estimated with just a few data. Our experimental results demonstrate that our method o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#35774;&#35745;&#21453;&#20107;&#23454;(MCD)&#26041;&#27861;&#65292;&#21487;&#24110;&#21161;&#35774;&#35745;&#24072;&#35782;&#21035;&#35774;&#35745;&#20462;&#25913;&#65292;&#25552;&#39640;&#21151;&#33021;&#24615;&#33021;&#12290;MCD&#36890;&#36807;&#25903;&#25345;&#22810;&#30446;&#26631;&#26597;&#35810;&#21644;&#35299;&#32806;&#21453;&#20107;&#23454;&#25628;&#32034;&#21644;&#37319;&#26679;&#36807;&#31243;&#26469;&#25552;&#39640;&#25928;&#29575;&#24182;&#25913;&#36827;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#25628;&#32034;&#26041;&#27861;&#65292;&#35777;&#26126;&#20854;&#22312;&#33258;&#34892;&#36710;&#35774;&#35745;&#26696;&#20363;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11308</link><description>&lt;p&gt;
&#35774;&#35745;&#20013;&#30340;&#21453;&#20107;&#23454;&#65306;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#24314;&#35758;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals for Design: A Model-Agnostic Method For Design Recommendations. (arXiv:2305.11308v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#35774;&#35745;&#21453;&#20107;&#23454;(MCD)&#26041;&#27861;&#65292;&#21487;&#24110;&#21161;&#35774;&#35745;&#24072;&#35782;&#21035;&#35774;&#35745;&#20462;&#25913;&#65292;&#25552;&#39640;&#21151;&#33021;&#24615;&#33021;&#12290;MCD&#36890;&#36807;&#25903;&#25345;&#22810;&#30446;&#26631;&#26597;&#35810;&#21644;&#35299;&#32806;&#21453;&#20107;&#23454;&#25628;&#32034;&#21644;&#37319;&#26679;&#36807;&#31243;&#26469;&#25552;&#39640;&#25928;&#29575;&#24182;&#25913;&#36827;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#25628;&#32034;&#26041;&#27861;&#65292;&#35777;&#26126;&#20854;&#22312;&#33258;&#34892;&#36710;&#35774;&#35745;&#26696;&#20363;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#35774;&#35745;&#38382;&#39064;&#21453;&#20107;&#23454;&#20248;&#21270;&#26041;&#27861;&#8212;&#8212;&#22810;&#30446;&#26631;&#35774;&#35745;&#21453;&#20107;&#23454;(MCD)&#12290;&#21453;&#20107;&#23454;&#26159;&#25351;&#21487;&#33021;&#23548;&#33268;&#19981;&#21516;&#20915;&#31574;&#25110;&#36873;&#25321;&#30340;&#20551;&#35774;&#24773;&#20917;&#12290;&#26412;&#25991;&#23558;&#21453;&#20107;&#23454;&#25628;&#32034;&#38382;&#39064;&#26694;&#26550;&#21270;&#20026;&#35774;&#35745;&#24314;&#35758;&#24037;&#20855;&#65292;&#21487;&#20197;&#24110;&#21161;&#35782;&#21035;&#23545;&#35774;&#35745;&#36827;&#34892;&#20462;&#25913;&#65292;&#20174;&#32780;&#25552;&#39640;&#21151;&#33021;&#24615;&#33021;&#12290;MCD&#36890;&#36807;&#25903;&#25345;&#22810;&#30446;&#26631;&#26597;&#35810;&#21644;&#35299;&#32806;&#21453;&#20107;&#23454;&#25628;&#32034;&#21644;&#37319;&#26679;&#36807;&#31243;&#26469;&#25552;&#39640;&#25928;&#29575;&#24182;&#20419;&#36827;&#30446;&#26631;&#26435;&#34913;&#21487;&#35270;&#21270;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#25628;&#32034;&#26041;&#27861;&#12290;&#26412;&#25991;&#20351;&#29992;&#20108;&#32500;&#27979;&#35797;&#26696;&#20363;&#35777;&#26126;&#20102;MCD&#30340;&#26680;&#24515;&#21151;&#33021;&#65292;&#28982;&#21518;&#36890;&#36807;&#19977;&#20010;&#33258;&#34892;&#36710;&#35774;&#35745;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;MCD&#22312;&#23454;&#38469;&#35774;&#35745;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#31532;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;MCD&#22312;&#25512;&#33616;&#23545;&#26597;&#35810;&#35774;&#35745;&#36827;&#34892;&#20462;&#25913;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#33258;&#34892;&#36710;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Multi-Objective Counterfactuals for Design (MCD), a novel method for counterfactual optimization in design problems. Counterfactuals are hypothetical situations that can lead to a different decision or choice. In this paper, the authors frame the counterfactual search problem as a design recommendation tool that can help identify modifications to a design, leading to better functional performance. MCD improves upon existing counterfactual search methods by supporting multi-objective queries, which are crucial in design problems, and by decoupling the counterfactual search and sampling processes, thus enhancing efficiency and facilitating objective tradeoff visualization. The paper demonstrates MCD's core functionality using a two-dimensional test case, followed by three case studies of bicycle design that showcase MCD's effectiveness in real-world design problems. In the first case study, MCD excels at recommending modifications to query designs that can significantly enha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2305.11283</link><description>&lt;p&gt;
&#20851;&#20110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;&#65288;MFC&#65289;&#21644;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#20013;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Mean-Field Model-Based Eluder Dimension (MBED)&#30340;&#26032;&#27010;&#24565;&#65292;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#36820;&#22238;&#19968;&#20010;$\epsilon$&#20248;&#30340;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;MFC&#25110;$\epsilon$&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#36866;&#29992;&#20110;MFG&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#22810;&#39033;&#24335;&#19982;&#30456;&#20851;&#21442;&#25968;&#26080;&#20851;&#65292;&#19982;&#29366;&#24577;&#12289;&#21160;&#20316;&#21644;&#20195;&#29702;&#25968;&#37327;&#26080;&#20851;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#36991;&#20813;&#20102;&#20197;&#21069;&#30340;&#24378;&#32467;&#26500;&#20551;&#35774;&#12290;&#26368;&#21518;&#65292;&#22312;tabular&#35774;&#32622;&#19979;&#65292;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26679;&#26412;&#39640;&#25928;&#30340;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#20197;&#36924;&#36817;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23454;&#26102;&#30340;&#36882;&#24402;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#25512;&#26029;&#31070;&#32463;&#36712;&#36857;&#21450;&#20854;&#21160;&#21147;&#23398;&#65292;&#33021;&#22815;&#24191;&#27867;&#36866;&#29992;&#20110;&#20219;&#24847;&#20284;&#28982;&#65292;&#21516;&#26102;&#26377;&#25928;&#36319;&#36394;&#31070;&#32463;&#20803;&#20013;&#38041;&#25104;&#20687;&#25968;&#25454;&#30340;&#21160;&#24577;&#12290;</title><link>http://arxiv.org/abs/2305.11278</link><description>&lt;p&gt;
&#23454;&#26102;&#21464;&#20998;&#26041;&#27861;&#23398;&#20064;&#31070;&#32463;&#36712;&#36857;&#21450;&#20854;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Real-Time Variational Method for Learning Neural Trajectory and its Dynamics. (arXiv:2305.11278v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23454;&#26102;&#30340;&#36882;&#24402;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#25512;&#26029;&#31070;&#32463;&#36712;&#36857;&#21450;&#20854;&#21160;&#21147;&#23398;&#65292;&#33021;&#22815;&#24191;&#27867;&#36866;&#29992;&#20110;&#20219;&#24847;&#20284;&#28982;&#65292;&#21516;&#26102;&#26377;&#25928;&#36319;&#36394;&#31070;&#32463;&#20803;&#20013;&#38041;&#25104;&#20687;&#25968;&#25454;&#30340;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#21464;&#37327;&#27169;&#22411;&#22312;&#35745;&#31639;&#31070;&#32463;&#31185;&#23398;&#20013;&#24050;&#25104;&#20026;&#25512;&#29702;&#31070;&#32463;&#35745;&#31639;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#36825;&#20419;&#36827;&#20102;&#20174;&#31070;&#32463;&#35760;&#24405;&#20013;&#25552;&#21462;&#28508;&#22312;&#31070;&#32463;&#36712;&#36857;&#30340;&#24378;&#22823;&#31163;&#32447;&#31639;&#27861;&#30340;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#23454;&#26102;&#26367;&#20195;&#26041;&#26696;&#33021;&#22815;&#20026;&#23454;&#39564;&#32773;&#31435;&#21363;&#25552;&#20379;&#21453;&#39304;&#24182;&#22686;&#24378;&#23454;&#39564;&#35774;&#35745;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#24471;&#21040;&#30340;&#20851;&#27880;&#35201;&#23569;&#24471;&#22810;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25351;&#25968;&#26063;&#21464;&#20998;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;eVKF&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#32447;&#36882;&#24402;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#26088;&#22312;&#25512;&#26029;&#28508;&#22312;&#36712;&#36857;&#21516;&#26102;&#23398;&#20064;&#20135;&#29983;&#23427;&#20204;&#30340;&#21160;&#21147;&#31995;&#32479;&#12290;eVKF&#36866;&#29992;&#20110;&#20219;&#24847;&#20284;&#28982;&#65292;&#24182;&#21033;&#29992;&#24120;&#25968;&#22522;&#26412;&#27979;&#24230;&#25351;&#25968;&#26063;&#26469;&#27169;&#25311;&#28508;&#22312;&#29366;&#24577;&#30340;&#38543;&#26426;&#24615;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#39044;&#27979;&#27493;&#39588;&#30340;&#38381;&#24335;&#21464;&#20998;&#31867;&#27604;&#65292;&#23427;&#27604;&#21478;&#19968;&#31181;&#22312;&#32447;&#21464;&#20998;&#26041;&#27861;&#20135;&#29983;&#20102;&#21487;&#35777;&#26126;&#26356;&#32039;&#30340;ELBO&#30028;&#38480;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#36319;&#36394;&#31070;&#32463;&#20803;&#20013;&#38041;&#25104;&#20687;&#25968;&#25454;&#30340;&#21160;&#24577;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation. This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings. However, despite the potential of real time alternatives to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention. In this work, we introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at inferring latent trajectories while simultaneously learning the dynamical system generating them. eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. We derive a closed-form variational analogue to the predict step of the Kalman filter which leads to a provably tighter bound on the ELBO compared to another online variational method. We validate our metho
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35777;&#25454;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#25110;&#20808;&#39564;&#20989;&#25968;&#19982;&#23884;&#22871;&#25277;&#26679;&#26080;&#27861;&#32988;&#20219;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26356;&#24555;&#36895;&#22320;&#12289;&#26356;&#26377;&#25928;&#22320;&#20272;&#31639;&#36125;&#21494;&#26031;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2305.11241</link><description>&lt;p&gt;
&#35777;&#25454;&#32593;&#32476;&#65306;&#29992;&#31616;&#21333;&#30340;&#25439;&#22833;&#20989;&#25968;&#24555;&#36895;&#12289;&#20998;&#25674;&#24335;&#22320;&#36827;&#34892;&#31070;&#32463;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison. (arXiv:2305.11241v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35777;&#25454;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#25110;&#20808;&#39564;&#20989;&#25968;&#19982;&#23884;&#22871;&#25277;&#26679;&#26080;&#27861;&#32988;&#20219;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26356;&#24555;&#36895;&#22320;&#12289;&#26356;&#26377;&#25928;&#22320;&#20272;&#31639;&#36125;&#21494;&#26031;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35777;&#25454;&#32593;&#32476;&#21487;&#22312;&#24403;&#29616;&#26377;&#30340;&#26041;&#27861;&#65288;&#22914;&#23884;&#22871;&#25277;&#26679;&#65289;&#22833;&#36133;&#12289;&#20284;&#28982;&#20989;&#25968;&#25110;&#20808;&#39564;&#20989;&#25968;&#38590;&#20197;&#22788;&#29702;&#25110;&#19981;&#30693;&#36947;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#12290;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#21487;&#30475;&#20316;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#34429;&#28982;&#29992;&#36125;&#21494;&#26031;&#27861;&#36827;&#34892;&#26368;&#20248;&#20998;&#31867;&#30340;&#35299;&#37322;&#24050;&#32463;&#20247;&#25152;&#21608;&#30693;&#65292;&#20294;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25913;&#21464;&#20102;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#20135;&#29983;&#24555;&#36895;&#12289;&#20998;&#25674;&#24335;&#30340;&#31070;&#32463;&#20272;&#35745;&#22120;&#65292;&#30452;&#25509;&#20272;&#31639;&#26041;&#20415;&#30340;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#20989;&#25968;&#12290;&#36825;&#20943;&#23569;&#20102;&#20272;&#31639;&#21333;&#20010;&#27169;&#22411;&#27010;&#29575;&#26102;&#30340;&#25968;&#23383;&#19981;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#28183;&#28431;&#22855; parity-odd power&#65288;l-POP&#65289;&#21464;&#25442;&#65292;&#24341;&#23548;&#20102;&#26032;&#30340;&#8220;l-Pop-Exponential&#8221;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#27169;&#22411;&#20013;&#23545;&#25968;&#25454;&#27010;&#29575;&#36827;&#34892;&#31070;&#32463;&#23494;&#24230;&#20272;&#35745;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#27604;&#35777;&#25454;&#32593;&#32476;&#30340;&#31934;&#24230;&#21644;&#21487;&#25193;&#23637;&#24615;&#37117;&#35201;&#20302;&#12290;&#22810;&#31181;&#23454;&#38469;&#21644;&#20154;&#36896;&#20363;&#23376;&#35777;&#26126;&#20102;&#35777;&#25454;&#32593;&#32476;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evidence Networks can enable Bayesian model comparison when state-of-the-art methods (e.g. nested sampling) fail and even when likelihoods or priors are intractable or unknown. Bayesian model comparison, i.e. the computation of Bayes factors or evidence ratios, can be cast as an optimization problem. Though the Bayesian interpretation of optimal classification is well-known, here we change perspective and present classes of loss functions that result in fast, amortized neural estimators that directly estimate convenient functions of the Bayes factor. This mitigates numerical inaccuracies associated with estimating individual model probabilities. We introduce the leaky parity-odd power (l-POP) transform, leading to the novel ``l-POP-Exponential'' loss function. We explore neural density estimation for data probability in different models, showing it to be less accurate and scalable than Evidence Networks. Multiple real-world and synthetic examples illustrate that Evidence Networks are e
&lt;/p&gt;</description></item><item><title>&#22823;&#35268;&#27169;&#24182;&#34892;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#36890;&#36807;&#25277;&#21462;$K^n$&#20010;&#21487;&#33021;&#30340;&#26679;&#26412;&#32452;&#21512;&#65292;&#36991;&#20813;&#20102;&#21407;&#26041;&#27861;&#20013;&#22823;&#37327;&#28508;&#22312;&#21464;&#37327;&#25968;&#30446;&#23548;&#33268;&#26377;&#25928;&#24615;&#19979;&#38477;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.11022</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#24182;&#34892;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;
&lt;/p&gt;
&lt;p&gt;
Massively Parallel Reweighted Wake-Sleep. (arXiv:2305.11022v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11022
&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#24182;&#34892;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#36890;&#36807;&#25277;&#21462;$K^n$&#20010;&#21487;&#33021;&#30340;&#26679;&#26412;&#32452;&#21512;&#65292;&#36991;&#20813;&#20102;&#21407;&#26041;&#27861;&#20013;&#22823;&#37327;&#28508;&#22312;&#21464;&#37327;&#25968;&#30446;&#23548;&#33268;&#26377;&#25928;&#24615;&#19979;&#38477;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#65288;RWS&#65289;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#24120;&#36890;&#29992;&#30340;&#27169;&#22411;&#25191;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#23427;&#20174;&#28508;&#22312;&#36817;&#20284;&#21518;&#39564;&#27010;&#29575;&#20013;&#25277;&#21462;$K$&#20010;&#26679;&#26412;&#65292;&#28982;&#21518;&#20351;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#25552;&#20379;&#26356;&#22909;&#30340;&#30495;&#23454;&#21518;&#39564;&#27010;&#29575;&#20272;&#35745;&#12290;RWS&#28982;&#21518;&#26356;&#26032;&#20854;&#36817;&#20284;&#21518;&#39564;&#27010;&#29575;&#65292;&#21521;&#30495;&#23454;&#21518;&#39564;&#27010;&#29575;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#20272;&#35745;&#31227;&#21160;&#12290;&#28982;&#32780;&#65292;&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#26377;&#25928;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#65292;&#25152;&#38656;&#26679;&#26412;&#25968;&#19982;&#28508;&#22312;&#21464;&#37327;&#30340;&#25968;&#37327;&#21576;&#25351;&#25968;&#20851;&#31995;&#12290;&#22312;&#25152;&#26377;&#20294;&#26368;&#23567;&#30340;&#27169;&#22411;&#20013;&#23454;&#29616;&#22914;&#27492;&#22823;&#25968;&#37327;&#30340;&#37325;&#35201;&#24615;&#26679;&#26412;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290; &#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22823;&#35268;&#27169;&#24182;&#34892;&#30340;RWS&#65292;&#36890;&#36807;&#25277;&#21462;&#25152;&#26377;$n$&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;$K$&#20010;&#26679;&#26412;&#65292;&#24182;&#21333;&#29420;&#32771;&#34385;&#25152;&#26377;$K^n$&#20010;&#21487;&#33021;&#30340;&#26679;&#26412;&#32452;&#21512;&#65292;&#36991;&#20813;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#34429;&#28982;&#32771;&#34385;$K^n$&#20010;&#32452;&#21512;&#20284;&#20046;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#20294;&#25152;&#38656;&#30340;&#35745;&#31639;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#35745;&#31639;&#32467;&#26500;&#31616;&#21270;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#23436;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reweighted wake-sleep (RWS) is a machine learning method for performing Bayesian inference in a very general class of models. RWS draws $K$ samples from an underlying approximate posterior, then uses importance weighting to provide a better estimate of the true posterior. RWS then updates its approximate posterior towards the importance-weighted estimate of the true posterior. However, recent work [Chattergee and Diaconis, 2018] indicates that the number of samples required for effective importance weighting is exponential in the number of latent variables. Attaining such a large number of importance samples is intractable in all but the smallest models. Here, we develop massively parallel RWS, which circumvents this issue by drawing $K$ samples of all $n$ latent variables, and individually reasoning about all $K^n$ possible combinations of samples. While reasoning about $K^n$ combinations might seem intractable, the required computations can be performed in polynomial time by exploiti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.10379</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#29702;&#32422;&#26463;&#30340;&#31526;&#21495;&#22238;&#24402;&#20013;&#20027;&#21160;&#23398;&#20064;&#30340;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Active Learning in Symbolic Regression Performance with Physical Constraints. (arXiv:2305.10379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#20943;&#23569;&#25152;&#38656;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36827;&#21270;&#31526;&#21495;&#22238;&#24402;&#65288;SR&#65289;&#26159;&#19968;&#31181;&#23558;&#31526;&#21495;&#26041;&#31243;&#25311;&#21512;&#21040;&#25968;&#25454;&#20013;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#31616;&#27905;&#26131;&#25026;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#25506;&#35752;&#20351;&#29992;SR&#20316;&#20026;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#26041;&#27861;&#26469;&#25552;&#20986;&#21738;&#20123;&#25968;&#25454;&#24212;&#35813;&#34987;&#37319;&#38598;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#32771;&#34385;&#29289;&#29702;&#32422;&#26463;&#12290;&#22522;&#20110;&#20027;&#21160;&#23398;&#20064;&#30340;SR&#36890;&#36807;&#8220;&#22996;&#21592;&#20250;&#26597;&#35810;&#8221;&#26469;&#25552;&#20986;&#19979;&#19968;&#27493;&#23454;&#39564;&#12290;&#29289;&#29702;&#32422;&#26463;&#21487;&#20197;&#22312;&#38750;&#24120;&#20302;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#25913;&#21892;&#25152;&#24314;&#35758;&#30340;&#26041;&#31243;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#20943;&#23569;SR&#25152;&#38656;&#30340;&#25968;&#25454;&#65292;&#24182;&#22312;&#37325;&#26032;&#21457;&#29616;&#24050;&#30693;&#26041;&#31243;&#25152;&#38656;&#30340;&#25968;&#25454;&#26041;&#38754;&#23454;&#29616;&#26368;&#26032;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evolutionary symbolic regression (SR) fits a symbolic equation to data, which gives a concise interpretable model. We explore using SR as a method to propose which data to gather in an active learning setting with physical constraints. SR with active learning proposes which experiments to do next. Active learning is done with query by committee, where the Pareto frontier of equations is the committee. The physical constraints improve proposed equations in very low data settings. These approaches reduce the data required for SR and achieves state of the art results in data required to rediscover known equations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.06743</link><description>&lt;p&gt;
&#38024;&#23545;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#38544;&#24335;&#33539;&#25968;&#39044;&#27979;&#22120;&#30340;&#20462;&#21098;
&lt;/p&gt;
&lt;p&gt;
Implicitly normalized forecaster with clipping for linear and non-linear heavy-tailed multi-armed bandits. (arXiv:2305.06743v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#65292;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#38544;&#24335;&#33539;&#25968;&#39044;&#27979;&#22120;&#65288;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#20197;Tsallis&#29109;&#20316;&#20026;prox&#20989;&#25968;&#65289;&#26159;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65288;MAB&#65289;&#30340;&#26368;&#20339;&#31639;&#27861;&#12290;&#20294;&#26159;&#65292;&#22823;&#22810;&#25968;&#22797;&#26434;&#24615;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#26377;&#30028;&#22870;&#21169;&#25110;&#20854;&#20182;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#26368;&#36817;&#26377;&#20851;&#26368;&#20339;&#20108;&#32773;&#32467;&#21512;&#31639;&#27861;&#30340;&#30740;&#31350;&#24050;&#32463;&#38024;&#23545;&#23545;&#25163;&#24615;&#21644;&#38543;&#26426;&#37325;&#23614;MAB&#35774;&#32622;&#36827;&#34892;&#20102;&#25506;&#35752;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#37117;&#26159;&#26368;&#20248;&#30340;&#65292;&#20294;&#19981;&#33021;&#20805;&#20998;&#21033;&#29992;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#22870;&#21169;&#20998;&#24067;&#37325;&#23614;&#30340;MAB&#38382;&#39064;&#25552;&#20986;&#20102;&#24102;&#21098;&#36753;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#22312;&#22870;&#21169;&#20998;&#24067;&#19978;&#25552;&#20986;&#28176;&#36827;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23545;&#20110;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#37325;&#23614;&#38543;&#26426;MAB&#38382;&#39064;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19982;&#26368;&#22909;&#30340;&#20108;&#32773;&#32467;&#21512;&#31639;&#27861;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#36890;&#24120;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicitly Normalized Forecaster (online mirror descent with Tsallis entropy as prox-function) is known to be an optimal algorithm for adversarial multi-armed problems (MAB). However, most of the complexity results rely on bounded rewards or other restrictive assumptions. Recently closely related best-of-both-worlds algorithm were proposed for both adversarial and stochastic heavy-tailed MAB settings. This algorithm is known to be optimal in both settings, but fails to exploit data fully. In this paper, we propose Implicitly Normalized Forecaster with clipping for MAB problems with heavy-tailed distribution on rewards. We derive convergence results under mild assumptions on rewards distribution and show that the proposed method is optimal for both linear and non-linear heavy-tailed stochastic MAB problems. Also we show that algorithm usually performs better compared to best-of-two-worlds algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#20307;&#31995;&#65292;&#20026;&#39046;&#22495;&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#36981;&#24490;&#25152;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.14094</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#33539;&#30068;&#22522;&#30784;&#65306;&#19968;&#31181;&#32479;&#19968;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#24418;&#24335;&#20307;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#20307;&#31995;&#65292;&#20026;&#39046;&#22495;&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#36981;&#24490;&#25152;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26088;&#22312;&#22238;&#31572;&#19982;AI&#27169;&#22411;&#37096;&#32626;&#30456;&#20851;&#30340;&#20262;&#29702;&#21644;&#27861;&#24459;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30456;&#24403;&#25968;&#37327;&#30340;&#39046;&#22495;&#29305;&#23450;&#35780;&#35770;&#24378;&#35843;&#38656;&#35201;&#19968;&#20010;&#25968;&#23398;&#22522;&#30784;&#26469;&#23450;&#20041;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#27010;&#24565;&#65292;&#21363;&#20351;&#8220;&#35299;&#37322;&#8221;&#36825;&#20010;&#26415;&#35821;&#36824;&#32570;&#20047;&#31934;&#30830;&#23450;&#20041;&#12290;&#36825;&#20123;&#35780;&#35770;&#36824;&#20027;&#24352;&#24314;&#31435;&#19968;&#20010;&#20581;&#20840;&#32780;&#32479;&#19968;&#30340;&#21487;&#35299;&#37322;AI&#24418;&#24335;&#20307;&#31995;&#65292;&#20197;&#36991;&#20813;&#20986;&#29616;&#19981;&#33391;&#25552;&#20986;&#38382;&#39064;&#65292;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#27983;&#35272;&#19968;&#20010;&#24555;&#36895;&#22686;&#38271;&#30340;&#30693;&#35782;&#20307;&#31995;&#12290;&#25454;&#20316;&#32773;&#25152;&#30693;&#65292;&#35813;&#35770;&#25991;&#26159;&#22635;&#34917;&#35813;&#31354;&#30333;&#30340;&#39318;&#27425;&#23581;&#35797;&#65292;&#36890;&#36807;&#24418;&#24335;&#21270;&#19968;&#20010;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#12290;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#21453;&#39304;&#21333;&#35843;&#33539;&#30068;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;AI&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#30340;&#24418;&#24335;&#23450;&#20041;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36981;&#24490;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#24341;&#20837;&#30340;&#29702;&#35770;&#26469;&#23545;&#24403;&#21069;&#30740;&#31350;&#30340;&#25152;&#26377;&#20027;&#35201;XAI&#31995;&#32479;&#31867;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#23545;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#30340;&#21464;&#20998;&#25193;&#25955;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#23545;&#21442;&#25968;&#24418;&#24335;&#20570;&#20986;&#24378;&#28872;&#20551;&#35774;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#22270;&#20687;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.12141</link><description>&lt;p&gt;
&#21464;&#20998;&#25193;&#25955;&#33258;&#32534;&#30721;&#22120;&#65306;&#20855;&#26377;&#26080;&#26465;&#20214;&#25193;&#25955;&#20808;&#39564;&#30340;&#28145;&#23618;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Variational Diffusion Auto-encoder: Deep Latent Variable Model with Unconditional Diffusion Prior. (arXiv:2304.12141v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#23545;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#30340;&#21464;&#20998;&#25193;&#25955;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#23427;&#36991;&#20813;&#20102;&#23545;&#21442;&#25968;&#24418;&#24335;&#20570;&#20986;&#24378;&#28872;&#20551;&#35774;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#22270;&#20687;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26159;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#30340;&#19968;&#31181;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22240;&#20026;&#39640;&#24230;&#19981;&#29616;&#23454;&#30340;&#24314;&#27169;&#20551;&#35774;&#65292;&#21363;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;p(x|z)&#21487;&#20197;&#36817;&#20284;&#20026;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#20998;&#24067;&#65292;&#25152;&#20197;&#30001;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29983;&#25104;&#30340;&#22270;&#20687;&#26159;&#27169;&#31946;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#23545;&#26465;&#20214;&#25968;&#25454;&#20998;&#24067;p(x|z)&#36827;&#34892;&#24314;&#27169;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#21019;&#24314;&#31867;&#20284;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#23545;p(x|z)&#20570;&#39640;&#26031;&#20551;&#35774;&#65292;&#29978;&#33267;&#19981;&#38656;&#35201;&#35757;&#32451;&#35299;&#30721;&#22120;&#32593;&#32476;&#12290;&#36890;&#36807;Bayes'&#35268;&#21017;&#65292;&#21487;&#20197;&#23558;&#32463;&#36807;&#35757;&#32451;&#30340;&#32534;&#30721;&#22120;&#21644;&#26080;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#32452;&#21512;&#21040;&#19968;&#36215;&#65292;&#20197;&#33719;&#24471;&#19968;&#20010;&#34920;&#36798;&#20016;&#23500;&#30340;p(x|z)&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36991;&#20813;&#20102;&#23545;&#21442;&#25968;&#24418;&#24335;p(x|z)&#20570;&#20986;&#24378;&#28872;&#20551;&#35774;&#65292;&#22240;&#27492;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#22270;&#20687;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational auto-encoders (VAEs) are one of the most popular approaches to deep generative modeling. Despite their success, images generated by VAEs are known to suffer from blurriness, due to a highly unrealistic modeling assumption that the conditional data distribution $ p(\textbf{x} | \textbf{z})$ can be approximated as an isotropic Gaussian. In this work we introduce a principled approach to modeling the conditional data distribution $p(\textbf{x} | \textbf{z})$ by incorporating a diffusion model. We show that it is possible to create a VAE-like deep latent variable model without making the Gaussian assumption on $ p(\textbf{x} | \textbf{z}) $ or even training a decoder network. A trained encoder and an unconditional diffusion model can be combined via Bayes' rule for score functions to obtain an expressive model for $ p(\textbf{x} | \textbf{z}) $. Our approach avoids making strong assumptions on the parametric form of $ p(\textbf{x} | \textbf{z}) $, and thus allows to significant
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#23398;&#20064;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#23545;&#27604;&#26694;&#26550;&#65292;&#36890;&#36807;&#35813;&#26694;&#26550;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#20855;&#22791;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26631;&#31614;&#25928;&#29575;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#23454;&#29992;BNN&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#22312;&#21322;&#30417;&#30563;&#21644;&#20302;&#39044;&#31639;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20986;&#20102;&#25968;&#25454;&#39640;&#25928;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2304.01762</link><description>&lt;p&gt;
&#23558;&#26410;&#26631;&#35760;&#25968;&#25454;&#32435;&#20837;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01762
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#23398;&#20064;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#23545;&#27604;&#26694;&#26550;&#65292;&#36890;&#36807;&#35813;&#26694;&#26550;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#26102;&#20855;&#22791;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26631;&#31614;&#25928;&#29575;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#23454;&#29992;BNN&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#22312;&#21322;&#30417;&#30563;&#21644;&#20302;&#39044;&#31639;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#23637;&#29616;&#20986;&#20102;&#25968;&#25454;&#39640;&#25928;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#20013;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#23398;&#20064;&#30340;&#23545;&#27604;&#26694;&#26550;&#65292;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#26469;&#20248;&#21270;&#12290;&#22522;&#20110;&#35813;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;BNN&#31639;&#27861;&#65292;&#21516;&#26102;&#20855;&#22791;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26631;&#31614;&#25928;&#29575;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#20013;&#30340;&#26681;&#25454;&#21407;&#21017;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21322;&#30417;&#30563;&#21644;&#20302;&#39044;&#31639;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25968;&#25454;&#39640;&#25928;&#23398;&#20064;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
&lt;/p&gt;</description></item><item><title>SAM&#26159;&#19968;&#31181;&#20248;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#33719;&#24471;&#26356;&#24179;&#22374;&#65288;&#21363;&#26356;&#19981;&#38160;&#21033;&#65289;&#30340;&#35299;&#26469;&#25913;&#21892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20004;&#20010;&#32479;&#35745;&#38382;&#39064;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#35777;&#26126;&#20102;SAM&#22312;&#39044;&#27979;&#35823;&#24046;&#26041;&#38754;&#27604;&#26799;&#24230;&#19979;&#38477;&#26377;&#26356;&#23567;&#30340;&#35823;&#24046;&#65292;&#24182;&#36866;&#29992;&#20110;&#38750;&#20984;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#35774;&#32622;&#34920;&#26126;&#65292;SAM&#30340;&#35299;&#26356;&#19981;&#38160;&#21033;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#35770;&#12290;</title><link>http://arxiv.org/abs/2302.11836</link><description>&lt;p&gt;
&#20851;&#20110;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#30340;&#32479;&#35745;&#24615;&#36136;&#65306;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
On Statistical Properties of Sharpness-Aware Minimization: Provable Guarantees. (arXiv:2302.11836v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11836
&lt;/p&gt;
&lt;p&gt;
SAM&#26159;&#19968;&#31181;&#20248;&#21270;&#26694;&#26550;&#65292;&#26088;&#22312;&#36890;&#36807;&#33719;&#24471;&#26356;&#24179;&#22374;&#65288;&#21363;&#26356;&#19981;&#38160;&#21033;&#65289;&#30340;&#35299;&#26469;&#25913;&#21892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30740;&#31350;&#20004;&#20010;&#32479;&#35745;&#38382;&#39064;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#35777;&#26126;&#20102;SAM&#22312;&#39044;&#27979;&#35823;&#24046;&#26041;&#38754;&#27604;&#26799;&#24230;&#19979;&#38477;&#26377;&#26356;&#23567;&#30340;&#35823;&#24046;&#65292;&#24182;&#36866;&#29992;&#20110;&#38750;&#20984;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#35774;&#32622;&#34920;&#26126;&#65292;SAM&#30340;&#35299;&#26356;&#19981;&#38160;&#21033;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270; (SAM) &#26159;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#33719;&#24471;&#26356;&#24179;&#22374;&#65288;&#21363;&#26356;&#19981;&#38160;&#21033;&#65289;&#30340;&#35299;&#26469;&#25913;&#21892;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#33021;&#21147;&#30340;&#26368;&#26032;&#20248;&#21270;&#26694;&#26550;&#12290;&#30001;&#20110;SAM&#22312;&#25968;&#20540;&#19978;&#21313;&#20998;&#25104;&#21151;&#65292;&#22240;&#27492;&#26368;&#36817;&#30340;&#35770;&#25991;&#30740;&#31350;&#20102;&#35813;&#26694;&#26550;&#30340;&#29702;&#35770;&#26041;&#38754;&#65292;&#24182;&#34920;&#26126;SAM&#30340;&#35299;&#30830;&#23454;&#26159;&#24179;&#22374;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;SAM&#30340;&#32479;&#35745;&#24615;&#36136;&#26041;&#38754;&#65292;&#29702;&#35770;&#25506;&#32034;&#26377;&#38480;&#12290;&#26412;&#25991;&#30452;&#25509;&#30740;&#31350;SAM&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#35299;&#37322;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;SAM&#33021;&#22815;&#36827;&#34892;&#33391;&#22909;&#30340;&#27867;&#21270;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#32479;&#35745;&#38382;&#39064;&#65292;&#21253;&#25324;&#20855;&#26377;&#38544;&#34255;&#23618;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26680;&#22238;&#24402;&#65292;&#24182;&#35777;&#26126;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;SAM&#23545;&#20110;&#26799;&#24230;&#19979;&#38477;(GD)&#30456;&#27604;&#26377;&#26356;&#23567;&#30340;&#39044;&#27979;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#28041;&#21450;&#20984;&#21644;&#38750;&#20984;&#35774;&#32622;&#65292;&#24182;&#34920;&#26126;SAM&#29305;&#21035;&#36866;&#29992;&#20110;&#38750;&#20984;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#65292;SAM&#30340;&#35299;&#20063;&#26356;&#19981;&#38160;&#21033;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization (SAM) is a recent optimization framework aiming to improve the deep neural network generalization, through obtaining flatter (i.e. less sharp) solutions. As SAM has been numerically successful, recent papers have studied the theoretical aspects of the framework and have shown SAM solutions are indeed flat. However, there has been limited theoretical exploration regarding statistical properties of SAM. In this work, we directly study the statistical performance of SAM, and present a new theoretical explanation of why SAM generalizes well. To this end, we study two statistical problems, neural networks with a hidden layer and kernel regression, and prove under certain conditions, SAM has smaller prediction error over Gradient Descent (GD). Our results concern both convex and non-convex settings, and show that SAM is particularly well-suited for non-convex problems. Additionally, we prove that in our setup, SAM solutions are less sharp as well, showing our res
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#30340;&#19981;&#21464;&#24615;&#65292;&#22914;&#26524;&#26174;&#24335;&#22320;&#34920;&#31034;&#24230;&#37327;&#24182;&#20351;&#29992;&#27491;&#30830;&#30340;&#30456;&#20851;&#21464;&#25442;&#35268;&#21017;&#65292;&#21017;&#19981;&#21464;&#24615;&#26159;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#26377;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.07384</link><description>&lt;p&gt;
&#37325;&#21442;&#25968;&#21270;&#19979;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#31354;&#38388;&#30340;&#20960;&#20309;&#23398;
&lt;/p&gt;
&lt;p&gt;
The Geometry of Neural Nets' Parameter Spaces Under Reparametrization. (arXiv:2302.07384v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07384
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#30340;&#19981;&#21464;&#24615;&#65292;&#22914;&#26524;&#26174;&#24335;&#22320;&#34920;&#31034;&#24230;&#37327;&#24182;&#20351;&#29992;&#27491;&#30830;&#30340;&#30456;&#20851;&#21464;&#25442;&#35268;&#21017;&#65292;&#21017;&#19981;&#21464;&#24615;&#26159;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#26377;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#37325;&#21442;&#25968;&#21270;&#26159;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#19968;&#31181;&#27969;&#34892;&#26041;&#27861;&#65292;&#20294;&#20063;&#21487;&#33021;&#23384;&#22312;&#38382;&#39064;&#65292;&#22914;&#22312;Hessian&#24179;&#22374;&#24230;&#27979;&#37327;&#12289;&#20248;&#21270;&#36712;&#36857;&#21644;&#27010;&#29575;&#23494;&#24230;&#27169;&#24335;&#31561;&#26041;&#38754;&#24341;&#20837;&#19981;&#19968;&#33268;&#24615;&#12290;&#36825;&#20351;&#24471;&#19979;&#28216;&#20998;&#26512;&#21464;&#24471;&#26356;&#20026;&#22797;&#26434;&#65306;&#20363;&#22914;&#65292;&#30001;&#20110;&#20219;&#24847;&#30340;&#37325;&#21442;&#25968;&#21270;&#37117;&#21487;&#20197;&#25913;&#21464;&#20108;&#32773;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#22240;&#27492;&#26080;&#27861;&#26126;&#30830;&#22320;&#23558;&#24179;&#22374;&#24230;&#19982;&#27867;&#21270;&#32852;&#31995;&#36215;&#26469;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#40654;&#26364;&#20960;&#20309;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#30340;&#19981;&#21464;&#24615;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#26469;&#30475;&#65292;&#22914;&#26524;&#25105;&#20204;&#26174;&#24335;&#22320;&#34920;&#31034;&#24230;&#37327;&#24182;&#20351;&#29992;&#27491;&#30830;&#30340;&#30456;&#20851;&#21464;&#25442;&#35268;&#21017;&#65292;&#37027;&#20040;&#19981;&#21464;&#24615;&#26159;&#20219;&#20309;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#26377;&#23646;&#24615;&#12290;&#36825;&#19968;&#28857;&#24456;&#37325;&#35201;&#65292;&#22240;&#20026;&#23613;&#31649;&#24230;&#37327;&#22987;&#32456;&#23384;&#22312;&#65292;&#20294;&#36890;&#24120;&#34987;&#38544;&#24335;&#22320;&#20551;&#23450;&#20026;&#21333;&#20301;&#30697;&#38453;&#65292;&#24182;&#22240;&#27492;&#20174;&#31526;&#21495;&#20013;&#30465;&#30053;&#65292;&#28982;&#21518;&#22312;&#37325;&#21442;&#25968;&#21270;&#19979;&#20002;&#22833;&#20102;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#34913;&#37327;&#24179;&#22374;&#24230;&#25152;&#24102;&#26469;&#30340;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model reparametrization, which follows the change-of-variable rule of calculus, is a popular way to improve the training of neural nets. But it can also be problematic since it can induce inconsistencies in, e.g., Hessian-based flatness measures, optimization trajectories, and modes of probability densities. This complicates downstream analyses: e.g. one cannot definitively relate flatness with generalization since arbitrary reparametrization changes their relationship. In this work, we study the invariance of neural nets under reparametrization from the perspective of Riemannian geometry. From this point of view, invariance is an inherent property of any neural net if one explicitly represents the metric and uses the correct associated transformation rules. This is important since although the metric is always present, it is often implicitly assumed as identity, and thus dropped from the notation, then lost under reparametrization. We discuss implications for measuring the flatness of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#20984;&#20248;&#21270;&#20013;&#65292;&#23454;&#29616;&#26368;&#20248; oracle &#22797;&#26434;&#24615;&#25152;&#24517;&#38656;&#35201;&#30340;&#20869;&#23384;&#20026;&#20108;&#27425;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702; 1-Lipschitz &#20984;&#20989;&#25968;&#26102;&#65292;&#20351;&#29992; $d^{2-\delta}$ &#20869;&#23384;&#30340;&#20219;&#20309;&#31639;&#27861;&#37117;&#38656;&#35201;&#36827;&#34892; $\tilde\Omega(d^{1+\delta/3})$ &#27425;&#26597;&#35810;&#12290;&#27492;&#22806;&#65292;&#22312;&#21487;&#34892;&#24615;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#33267;&#22810; $d^{2-\delta}$ &#23384;&#20648;&#22120;&#23481;&#37327;&#30340;&#20998;&#31163; oracle &#38656;&#35201;&#36827;&#34892; $\tilde\Omega(d^{1+\delta})$ &#27425;&#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2302.04963</link><description>&lt;p&gt;
&#20108;&#27425;&#20869;&#23384;&#26159;&#23454;&#29616;&#20984;&#20248;&#21270;&#26368;&#20248;&#26597;&#35810;&#22797;&#26434;&#24230;&#25152;&#24517;&#38656;&#30340;&#65306;&#36136;&#24515;&#26159;&#24085;&#32047;&#25176;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Quadratic Memory is Necessary for Optimal Query Complexity in Convex Optimization: Center-of-Mass is Pareto-Optimal. (arXiv:2302.04963v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#20984;&#20248;&#21270;&#20013;&#65292;&#23454;&#29616;&#26368;&#20248; oracle &#22797;&#26434;&#24615;&#25152;&#24517;&#38656;&#35201;&#30340;&#20869;&#23384;&#20026;&#20108;&#27425;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702; 1-Lipschitz &#20984;&#20989;&#25968;&#26102;&#65292;&#20351;&#29992; $d^{2-\delta}$ &#20869;&#23384;&#30340;&#20219;&#20309;&#31639;&#27861;&#37117;&#38656;&#35201;&#36827;&#34892; $\tilde\Omega(d^{1+\delta/3})$ &#27425;&#26597;&#35810;&#12290;&#27492;&#22806;&#65292;&#22312;&#21487;&#34892;&#24615;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;&#33267;&#22810; $d^{2-\delta}$ &#23384;&#20648;&#22120;&#23481;&#37327;&#30340;&#20998;&#31163; oracle &#38656;&#35201;&#36827;&#34892; $\tilde\Omega(d^{1+\delta})$ &#27425;&#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32473;&#20986;&#20102;&#20984;&#20248;&#21270;&#21450;&#30456;&#20851;&#21487;&#34892;&#24615;&#38382;&#39064;&#30340;&#26597;&#35810;&#22797;&#26434;&#24615;&#19979;&#30028;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23454;&#29616;&#20984;&#20248;&#21270;&#30340;&#19968;&#38454;&#26368;&#20248;&#24615;&#30340;&#26368;&#20248; oracle &#22797;&#26434;&#24615;&#25152;&#24517;&#38656;&#30340;&#20869;&#23384;&#26159;&#20108;&#27425;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#36825;&#34920;&#26126;&#22312;&#32500;&#24230; $d$ &#20013;&#20351;&#29992; $\tilde O(d^2)$ &#20869;&#23384;&#21644; $\tilde O(d)$ &#26597;&#35810;&#30340;&#36136;&#24515;&#20999;&#24179;&#38754;&#31639;&#27861;&#23545;&#20984;&#20248;&#21270;&#21644;&#21487;&#34892;&#24615;&#38382;&#39064;&#26469;&#35828;&#37117;&#26159;&#24085;&#32047;&#25176;&#26368;&#20248;&#30340;&#65292;&#31934;&#24230;&#20026; $1/d^4$&#65292;&#19978;&#38480;&#20026;&#23545;&#25968;&#22240;&#23376;&#12290;&#30830;&#20999;&#22320;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20026;&#20102;&#22312;&#21333;&#20301;&#29699;&#19978;&#23558; $1$-Lipschitz &#20984;&#20989;&#25968;&#26368;&#23567;&#21270;&#21040; $1/d^4$ &#30340;&#31934;&#24230;&#65292;&#20219;&#20309;&#20351;&#29992;&#33267;&#22810; $d^{2-\delta}$ &#20010;&#20869;&#23384;&#20301;&#30340;&#30830;&#23450;&#24615;&#19968;&#38454;&#31639;&#27861;&#37117;&#24517;&#39035;&#36827;&#34892; $\tilde\Omega(d^{1+\delta/3})$ &#27425;&#26597;&#35810;&#65292;&#20854;&#20013; $\delta\in[0,1]$&#12290;&#23545;&#20110;&#21487;&#34892;&#24615;&#38382;&#39064;&#65292;&#22312;&#20854;&#21482;&#26377;&#35775;&#38382;&#20998;&#31163; oracle &#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26356;&#24378;&#30340;&#26435;&#34913;&#65306;&#23545;&#20110;&#33267;&#22810; $d^{2-\delta}$ &#30340;&#23384;&#20648;&#22120;&#23481;&#37327;&#65292;&#25152;&#38656;&#30340;&#26597;&#35810;&#25968;&#37327;&#20026; $\tilde\Omega(d^{1+\delta})$&#12290;&#36825;&#35299;&#20915;&#20102; COLT 2019 &#30340;&#19968;&#20010;&#26410;&#35299;&#20915;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give query complexity lower bounds for convex optimization and the related feasibility problem. We show that quadratic memory is necessary to achieve the optimal oracle complexity for first-order convex optimization. In particular, this shows that center-of-mass cutting-planes algorithms in dimension $d$ which use $\tilde O(d^2)$ memory and $\tilde O(d)$ queries are Pareto-optimal for both convex optimization and the feasibility problem, up to logarithmic factors. Precisely, we prove that to minimize $1$-Lipschitz convex functions over the unit ball to $1/d^4$ accuracy, any deterministic first-order algorithms using at most $d^{2-\delta}$ bits of memory must make $\tilde\Omega(d^{1+\delta/3})$ queries, for any $\delta\in[0,1]$. For the feasibility problem, in which an algorithm only has access to a separation oracle, we show a stronger trade-off: for at most $d^{2-\delta}$ memory, the number of queries required is $\tilde\Omega(d^{1+\delta})$. This resolves a COLT 2019 open problem 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#24322;&#26041;&#24046;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#20989;&#25968;&#27169;&#22411;&#65292;&#35813;&#35770;&#25991;&#22312;&#27491;&#30830;&#35828;&#26126;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#12290;&#20294;&#26159;&#65292;&#22312;&#29992;&#25143;&#38169;&#35823;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24418;&#24335;&#26102;&#65292;&#20998;&#26512;&#34920;&#26126;&#22240;&#26524;&#25512;&#26029;&#30340;&#31934;&#24230;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#36873;&#25321;&#23454;&#29616;&#31283;&#23450;&#32780;&#20934;&#30830;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2301.12930</link><description>&lt;p&gt;
&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#27169;&#22411;&#20013;&#22240;&#26524;&#25512;&#26029;&#30340;&#26368;&#22823;&#20284;&#28982;&#19982;&#29420;&#31435;&#24615;&#26816;&#39564;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing. (arXiv:2301.12930v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12930
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#24322;&#26041;&#24046;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#20989;&#25968;&#27169;&#22411;&#65292;&#35813;&#35770;&#25991;&#22312;&#27491;&#30830;&#35828;&#26126;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#12290;&#20294;&#26159;&#65292;&#22312;&#29992;&#25143;&#38169;&#35823;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24418;&#24335;&#26102;&#65292;&#20998;&#26512;&#34920;&#26126;&#22240;&#26524;&#25512;&#26029;&#30340;&#31934;&#24230;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#36873;&#25321;&#23454;&#29616;&#31283;&#23450;&#32780;&#20934;&#30830;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#25512;&#26029;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#27491;&#30830;&#22240;&#26524;&#26041;&#21521;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;&#24322;&#26041;&#24046;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#20989;&#25968;&#27169;&#22411; (LSNM) &#32467;&#21512;&#20102;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#35782;&#21035;&#24615;&#20445;&#35777;&#65292;&#22312;&#27491;&#30830;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#24403;&#29992;&#25143;&#38169;&#35823;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24418;&#24335;&#26102;&#65292;&#31934;&#24230;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#31181;&#22833;&#36133;&#20027;&#35201;&#21457;&#29983;&#22312;&#21453;&#22240;&#26524;&#26041;&#21521;&#30340;&#26465;&#20214;&#26041;&#24046;&#23567;&#20110;&#22240;&#26524;&#26041;&#21521;&#30340;&#26465;&#20214;&#26041;&#24046;&#30340;&#24773;&#20917;&#19979;&#12290;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#65292;&#21457;&#29616;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#36873;&#25321;&#21487;&#20197;&#22312;&#32570;&#20047;&#22122;&#22768;&#20998;&#24067;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#31283;&#23450;&#32780;&#20934;&#30830;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental problem of causal discovery is cause-effect inference, learning the correct causal direction between two random variables. Significant progress has been made through modelling the effect as a function of its cause and a noise term, which allows us to leverage assumptions about the generating function class. The recently introduced heteroscedastic location-scale noise functional models (LSNMs) combine expressive power with identifiability guarantees. LSNM model selection based on maximizing likelihood achieves state-of-the-art accuracy, when the noise distributions are correctly specified. However, through an extensive empirical evaluation, we demonstrate that the accuracy deteriorates sharply when the form of the noise distribution is misspecified by the user. Our analysis shows that the failure occurs mainly when the conditional variance in the anti-causal direction is smaller than that in the causal direction. As an alternative, we find that causal model selection throu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#36229;&#22270;&#30340;&#22810;&#23618;&#32858;&#31867;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#21516;&#37197;&#21644;&#38750;&#21516;&#37197;&#24773;&#20917;&#19979;&#20445;&#35777;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2301.11657</link><description>&lt;p&gt;
&#20351;&#29992;&#32858;&#21512;&#30456;&#20284;&#30697;&#38453;&#30340;&#22810;&#23618;&#36229;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multilayer hypergraph clustering using the aggregate similarity matrix. (arXiv:2301.11657v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#36229;&#22270;&#30340;&#22810;&#23618;&#32858;&#31867;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#21516;&#37197;&#21644;&#38750;&#21516;&#37197;&#24773;&#20917;&#19979;&#20445;&#35777;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#36229;&#22270;&#30340;&#22810;&#23618;&#21464;&#20307;&#19978;&#25191;&#34892;&#31038;&#21306;&#24674;&#22797;&#38382;&#39064;&#65292;&#27599;&#20010;&#23618;&#19982; N &#20010;&#39030;&#28857;&#19978;&#30340; d-&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411; (HSBM) &#30340;&#29420;&#31435;&#23454;&#29616;&#30456;&#20851;&#12290;&#32473;&#20986;&#21253;&#21547;&#19982;&#27599;&#23545;&#39030;&#28857;&#30456;&#20132;&#30340;&#36229;&#36793;&#25968;&#37327;&#32858;&#21512;&#30340;&#30456;&#20284;&#30697;&#38453;&#65292;&#30446;&#26631;&#26159;&#23558; N &#20010;&#39030;&#28857;&#21010;&#20998;&#20026;&#19981;&#30456;&#20132;&#30340;&#31038;&#21306;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21322;&#23450;&#35268;&#21010; (SDP) &#26041;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#26377;&#20851;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24687;&#35770;&#26465;&#20214;&#65292;&#20445;&#35777;&#22312;&#21516;&#37197;&#21644;&#38750;&#21516;&#37197;&#24773;&#20917;&#19979;&#22343;&#33021;&#30830;&#20445;&#31934;&#30830;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the community recovery problem on a multilayer variant of the hypergraph stochastic block model (HSBM). Each layer is associated with an independent realization of a d-uniform HSBM on N vertices. Given the similarity matrix containing the aggregated number of hyperedges incident to each pair of vertices, the goal is to obtain a partition of the N vertices into disjoint communities. In this work, we investigate a semidefinite programming (SDP) approach and obtain information-theoretic conditions on the model parameters that guarantee exact recovery both in the assortative and the disassortative cases.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#20272;&#31639;&#25968;&#25454;&#27969;&#24418;&#30340;&#32500;&#24230;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2212.12611</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26263;&#20013;&#35782;&#21035;&#25968;&#25454;&#27969;&#24418;&#30340;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
Your diffusion model secretly knows the dimension of the data manifold. (arXiv:2212.12611v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#20272;&#31639;&#25968;&#25454;&#27969;&#24418;&#30340;&#32500;&#24230;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35757;&#32451;&#36807;&#30340;&#25193;&#25955;&#27169;&#22411;&#20272;&#31639;&#25968;&#25454;&#27969;&#24418;&#32500;&#24230;&#30340;&#26032;&#26694;&#26550;&#12290;&#25193;&#25955;&#27169;&#22411;&#36880;&#28176;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#26799;&#24230;&#65292;&#21363;&#22122;&#22768;&#27745;&#26579;&#29256;&#26412;&#30340;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65292;&#19981;&#21516;&#32423;&#21035;&#30340;&#27745;&#26579;&#31243;&#24230;&#23545;&#24212;&#19981;&#21516;&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#25968;&#25454;&#38598;&#32858;&#28966;&#20110;&#39640;&#32500;&#29615;&#22659;&#31354;&#38388;&#20013;&#23884;&#20837;&#30340;&#27969;&#24418;&#65292;&#37027;&#20040;&#38543;&#30528;&#22122;&#22768;&#27745;&#26579;&#31243;&#24230;&#30340;&#38477;&#20302;&#65292;&#26799;&#24230;&#20250;&#25351;&#21521;&#27969;&#24418;&#65292;&#22240;&#20026;&#36825;&#20010;&#26041;&#21521;&#26159;&#26368;&#22823;&#20284;&#28982;&#22686;&#21152;&#30340;&#26041;&#21521;&#12290;&#22240;&#27492;&#65292;&#22312;&#27745;&#26579;&#31243;&#24230;&#36739;&#20302;&#26102;&#65292;&#25193;&#25955;&#27169;&#22411;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#25454;&#27969;&#24418;&#27491;&#24120;&#21521;&#37327;&#30340;&#36924;&#36817;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20272;&#35745;&#20999;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;&#20063;&#23601;&#26159;&#25968;&#25454;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#25454;&#27969;&#24418;&#32500;&#24230;&#30340;&#31532;&#19968;&#20010;&#20272;&#31639;&#22120;&#65292;&#24182;&#19988;&#32988;&#36807;&#20102;&#24050;&#32463;&#25104;&#29087;&#30340;&#32479;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a novel framework for estimating the dimension of the data manifold using a trained diffusion model. A diffusion model approximates the score function i.e. the gradient of the log density of a noise-corrupted version of the target distribution for varying levels of corruption. We prove that, if the data concentrates around a manifold embedded in the high-dimensional ambient space, then as the level of corruption decreases, the score function points towards the manifold, as this direction becomes the direction of maximal likelihood increase. Therefore, for small levels of corruption, the diffusion model provides us with access to an approximation of the normal bundle of the data manifold. This allows us to estimate the dimension of the tangent space, thus, the intrinsic dimension of the data manifold. To the best of our knowledge, our method is the first estimator of the data manifold dimension based on diffusion models and it outperforms well established statis
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.02128</link><description>&lt;p&gt;
&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Bayesian Optimization with $\phi$-divergences. (arXiv:2203.02128v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02128
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40065;&#26834;&#24615;&#30740;&#31350;&#22240;&#20854;&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#35768;&#22810;&#31995;&#32479;&#20013;&#19981;&#21487;&#36991;&#20813;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#20854;&#20013;&#19968;&#20010;&#20363;&#23376;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#23427;&#38754;&#20020;&#30528;&#22810;&#26041;&#38754;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#20165;&#26377;&#23569;&#37327;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#36825;&#20010;&#26041;&#21521;&#12290;&#22312;&#29616;&#26377;&#30740;&#31350;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of robustness has received much attention due to its inevitability in data-driven settings where many systems face uncertainty. One such example of concern is Bayesian Optimization (BO), where uncertainty is multi-faceted, yet there only exists a limited number of works dedicated to this direction. In particular, there is the work of Kirschner et al. (2020), which bridges the existing literature of Distributionally Robust Optimization (DRO) by casting the BO problem from the lens of DRO. While this work is pioneering, it admittedly suffers from various practical shortcomings such as finite contexts assumptions, leaving behind the main question Can one devise a computationally tractable algorithm for solving this DRO-BO problem? In this work, we tackle this question to a large degree of generality by considering robustness against data-shift in $\phi$-divergences, which subsumes many popular choices, such as the $\chi^2$-divergence, Total Variation, and the extant Kullback-Lei
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#25239;&#30456;&#20851;&#22122;&#22768;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24120;&#35268;&#25200;&#21160;&#26799;&#24230;&#19979;&#38477;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#36825;&#26159;&#22240;&#20026; Anti-PGD &#33021;&#22815;&#31227;&#21160;&#21040;&#26356;&#23485;&#30340;&#26368;&#23567;&#20540;&#28857;&#65292;&#32780; GD &#21644; PGD &#20250;&#20572;&#28382;&#22312;&#27425;&#20248;&#21306;&#22495;&#29978;&#33267;&#21457;&#25955;&#12290;</title><link>http://arxiv.org/abs/2202.02831</link><description>&lt;p&gt;
&#25239;&#30456;&#20851;&#22122;&#22768;&#27880;&#20837;&#29992;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.02831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#65292;&#22312;&#19968;&#20123;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#25239;&#30456;&#20851;&#22122;&#22768;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24120;&#35268;&#25200;&#21160;&#26799;&#24230;&#19979;&#38477;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#36825;&#26159;&#22240;&#20026; Anti-PGD &#33021;&#22815;&#31227;&#21160;&#21040;&#26356;&#23485;&#30340;&#26368;&#23567;&#20540;&#28857;&#65292;&#32780; GD &#21644; PGD &#20250;&#20572;&#28382;&#22312;&#27425;&#20248;&#21306;&#22495;&#29978;&#33267;&#21457;&#25955;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20154;&#24037;&#22122;&#22768;&#27880;&#20837;&#26799;&#24230;&#19979;&#38477;&#24120;&#24120;&#34987;&#29992;&#20110;&#25913;&#21892;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36890;&#24120;&#65292;&#36825;&#31181;&#25200;&#21160;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20351;&#29992;&#30340;&#26159;&#19981;&#30456;&#20851;&#30340;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#26159;&#21542;&#20351;&#29992;&#19981;&#21516;&#31867;&#22411;&#30340;&#22122;&#22768;&#33021;&#22815;&#25552;&#20379;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#30456;&#20851;&#30340;&#25200;&#21160;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#30446;&#26631;&#20989;&#25968;&#65292;&#21457;&#29616;&#24102;&#26377;&#25239;&#30456;&#20851;&#25200;&#21160;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;"Anti-PGD"&#65289;&#27604;&#20256;&#32479;&#30340;&#26799;&#24230;&#19979;&#38477;&#21644;&#24120;&#35268;&#30340;&#65288;&#19981;&#30456;&#20851;&#30340;&#65289;&#25200;&#21160;&#26799;&#24230;&#19979;&#38477;&#26377;&#30528;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#20026;&#20102;&#25903;&#25345;&#36825;&#20123;&#23454;&#39564;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102; Anti-PGD &#33021;&#22815;&#31227;&#21160;&#21040;&#26356;&#23485;&#30340;&#26368;&#23567;&#20540;&#28857;&#65292;&#32780; GD &#21644; PGD &#20250;&#20572;&#28382;&#22312;&#27425;&#20248;&#21306;&#22495;&#29978;&#33267;&#21457;&#25955;&#12290;&#36825;&#19968;&#26032;&#39062;&#30340;&#25239;&#30456;&#20851;&#22122;&#22768;&#19982;&#27867;&#21270;&#24615;&#33021;&#30340;&#32852;&#31995;&#20026;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Injecting artificial noise into gradient descent (GD) is commonly employed to improve the performance of machine learning models. Usually, uncorrelated noise is used in such perturbed gradient descent (PGD) methods. It is, however, not known if this is optimal or whether other types of noise could provide better generalization performance. In this paper, we zoom in on the problem of correlating the perturbations of consecutive PGD steps. We consider a variety of objective functions for which we find that GD with anticorrelated perturbations ("Anti-PGD") generalizes significantly better than GD and standard (uncorrelated) PGD. To support these experimental findings, we also derive a theoretical analysis that demonstrates that Anti-PGD moves to wider minima, while GD and PGD remain stuck in suboptimal regions or even diverge. This new connection between anticorrelated noise and generalization opens the field to novel ways to exploit noise for training machine learning models.
&lt;/p&gt;</description></item></channel></rss>