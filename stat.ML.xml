<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.04493</link><description>&lt;p&gt;
&#20351;&#22270;&#20687;&#30495;&#23454;&#30340;&#22240;&#32032;&#26159;&#20160;&#20040;&#65311;
&lt;/p&gt;
&lt;p&gt;
What makes an image realistic?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04493
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#25105;&#20204;&#22312;&#29983;&#25104;&#30475;&#36215;&#26469;&#30495;&#23454;&#30340;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#65292;&#26080;&#35770;&#26159;&#22270;&#20687;&#12289;&#25991;&#26412;&#12289;&#38899;&#39057;&#36824;&#26159;&#35270;&#39057;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#20043;&#23494;&#20999;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#21363;&#37327;&#21270;&#29616;&#23454;&#20027;&#20041;&#65292;&#21363;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#22320;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#12290;&#20174;&#31639;&#27861;&#20449;&#24687;&#29702;&#35770;&#30340;&#35266;&#28857;&#20986;&#21457;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20026;&#20160;&#20040;&#36825;&#20010;&#38382;&#39064;&#24456;&#20855;&#25361;&#25112;&#24615;&#65292;&#20026;&#20160;&#20040;&#19968;&#20010;&#22909;&#30340;&#29983;&#25104;&#27169;&#22411;&#21333;&#29420;&#19981;&#33021;&#35299;&#20915;&#23427;&#65292;&#20197;&#21450;&#19968;&#20010;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24212;&#35813;&#26159;&#20160;&#20040;&#26679;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#65292;&#19981;&#20687;&#23545;&#25239;&#24615;&#35780;&#35770;&#32773;&#37027;&#26679;&#38656;&#35201;&#23545;&#25239;&#24615;&#35757;&#32451;&#12290;&#23613;&#31649;&#36890;&#29992;&#35780;&#35770;&#32773;&#24182;&#19981;&#31435;&#21363;&#23454;&#29992;&#65292;&#20294;&#23427;&#20204;&#26082;&#21487;&#20197;&#20316;&#20026;&#24341;&#23548;&#23454;&#38469;&#23454;&#29616;&#30340;&#21271;&#26497;&#26143;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04493v1 Announce Type: new  Abstract: The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;&#23545;&#20110;&#25439;&#22833;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#65292;CVaR&#21644;DRO&#30340;&#32467;&#26524;&#36828;&#36229;&#20986;&#29616;&#26377;&#30740;&#31350;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#21333;&#35843;&#20934;&#21017;&#22914;&#20542;&#26012;ERM&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;</title><link>https://arxiv.org/abs/2402.09802</link><description>&lt;p&gt;
&#20934;&#21017;&#23849;&#28291;&#21644;&#25439;&#22833;&#20998;&#24067;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Criterion collapse and loss distribution control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09802
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;&#23545;&#20110;&#25439;&#22833;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#65292;CVaR&#21644;DRO&#30340;&#32467;&#26524;&#36828;&#36229;&#20986;&#29616;&#26377;&#30740;&#31350;&#65292;&#21516;&#26102;&#21457;&#29616;&#20102;&#19968;&#20123;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;&#21333;&#35843;&#20934;&#21017;&#22914;&#20542;&#26012;ERM&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;"&#20934;&#21017;&#23849;&#28291;"&#30340;&#27010;&#24565;&#65292;&#21363;&#20248;&#21270;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#24847;&#21619;&#30528;&#21478;&#19968;&#20010;&#24230;&#37327;&#25351;&#26631;&#30340;&#26368;&#20248;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#21508;&#31181;&#23398;&#20064;&#20934;&#21017;&#19979;&#23849;&#28291;&#25104;&#35823;&#24046;&#27010;&#29575;&#26368;&#23567;&#21270;&#22120;&#30340;&#26465;&#20214;&#65292;&#20174;DRO&#21644;OCE&#39118;&#38505;&#65288;CVaR&#12289;&#20542;&#26012;ERM&#65289;&#21040;&#25991;&#29486;&#20013;&#25506;&#32034;&#30340;&#26368;&#26032;&#19978;&#21319;-&#19979;&#38477;&#31639;&#27861;&#30340;&#38750;&#21333;&#35843;&#20934;&#21017;&#65288;&#27946;&#27700;&#12289;SoftAD&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20271;&#21162;&#21033;&#20998;&#24067;&#25439;&#22833;&#30340;&#32972;&#26223;&#19979;&#65292;CVaR&#21644;DRO&#30340;&#29616;&#26377;&#32467;&#26524;&#36828;&#36828;&#36229;&#36234;&#20102;&#23849;&#28291;&#30340;&#33539;&#22260;&#65292;&#28982;&#21518;&#25193;&#22823;&#20102;&#25105;&#20204;&#30340;&#33539;&#22260;&#65292;&#21253;&#25324;&#20195;&#29702;&#25439;&#22833;&#65292;&#23637;&#31034;&#20102;&#20687;&#20542;&#26012;ERM&#36825;&#26679;&#30340;&#21333;&#35843;&#20934;&#21017;&#26080;&#27861;&#36991;&#20813;&#23849;&#28291;&#30340;&#26465;&#20214;&#65292;&#32780;&#38750;&#21333;&#35843;&#30340;&#26367;&#20195;&#26041;&#26696;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09802v1 Announce Type: cross  Abstract: In this work, we consider the notion of "criterion collapse," in which optimization of one metric implies optimality in another, with a particular focus on conditions for collapse into error probability minimizers under a wide variety of learning criteria, ranging from DRO and OCE risks (CVaR, tilted ERM) to non-monotonic criteria underlying recent ascent-descent algorithms explored in the literature (Flooding, SoftAD). We show how collapse in the context of losses with a Bernoulli distribution goes far beyond existing results for CVaR and DRO, then expand our scope to include surrogate losses, showing conditions where monotonic criteria such as tilted ERM cannot avoid collapse, whereas non-monotonic alternatives can.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26465;&#20214;&#27969;&#36827;&#34892;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#27169;&#22411;ProFITi&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#26465;&#20214;&#19979;&#26410;&#26469;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#65292;&#32780;&#19981;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#30340;&#22266;&#23450;&#24418;&#29366;&#12290;&#36890;&#36807;&#24341;&#20837;&#21487;&#36870;&#19977;&#35282;&#24418;&#27880;&#24847;&#21147;&#23618;&#21644;&#21487;&#36870;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#35813;&#27169;&#22411;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.06293</link><description>&lt;p&gt;
&#36890;&#36807;&#26465;&#20214;&#27969;&#36827;&#34892;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Forecasting of Irregular Time Series via Conditional Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06293
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26465;&#20214;&#27969;&#36827;&#34892;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#39044;&#27979;&#30340;&#26032;&#27169;&#22411;ProFITi&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#26465;&#20214;&#19979;&#26410;&#26469;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#65292;&#32780;&#19981;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#30340;&#22266;&#23450;&#24418;&#29366;&#12290;&#36890;&#36807;&#24341;&#20837;&#21487;&#36870;&#19977;&#35282;&#24418;&#27880;&#24847;&#21147;&#23618;&#21644;&#21487;&#36870;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#35813;&#27169;&#22411;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#27010;&#29575;&#39044;&#27979;&#26159;&#35768;&#22810;&#39046;&#22495;&#30340;&#37325;&#35201;&#38382;&#39064;&#65292;&#21253;&#25324;&#21307;&#30103;&#20445;&#20581;&#12289;&#22825;&#25991;&#23398;&#21644;&#27668;&#20505;&#23398;&#12290;&#30446;&#21069;&#35813;&#20219;&#21153;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#20165;&#20272;&#35745;&#21333;&#20010;&#36890;&#36947;&#21644;&#21333;&#20010;&#26102;&#38388;&#28857;&#19978;&#35266;&#27979;&#20540;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#20551;&#35774;&#20102;&#19968;&#20010;&#22266;&#23450;&#24418;&#29366;&#30340;&#21442;&#25968;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;ProFITi&#65292;&#29992;&#20110;&#20351;&#29992;&#26465;&#20214;&#24402;&#19968;&#21270;&#27969;&#23545;&#20855;&#26377;&#32570;&#22833;&#20540;&#30340;&#19981;&#35268;&#21017;&#37319;&#26679;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#12290;&#35813;&#27169;&#22411;&#23398;&#20064;&#20102;&#22312;&#36807;&#21435;&#35266;&#27979;&#21644;&#26597;&#35810;&#30340;&#36890;&#36947;&#21644;&#26102;&#38388;&#19978;&#26465;&#20214;&#19979;&#26102;&#38388;&#24207;&#21015;&#26410;&#26469;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#32780;&#19981;&#20551;&#35774;&#24213;&#23618;&#20998;&#24067;&#30340;&#22266;&#23450;&#24418;&#29366;&#12290;&#20316;&#20026;&#27169;&#22411;&#32452;&#20214;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#36870;&#19977;&#35282;&#24418;&#27880;&#24847;&#21147;&#23618;&#21644;&#19968;&#20010;&#21487;&#36870;&#30340;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#33021;&#22815;&#22312;&#25972;&#20010;&#23454;&#25968;&#32447;&#19978;&#36827;&#34892;&#36716;&#25442;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#25552;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic forecasting of irregularly sampled multivariate time series with missing values is an important problem in many fields, including health care, astronomy, and climate. State-of-the-art methods for the task estimate only marginal distributions of observations in single channels and at single timepoints, assuming a fixed-shape parametric distribution. In this work, we propose a novel model, ProFITi, for probabilistic forecasting of irregularly sampled time series with missing values using conditional normalizing flows. The model learns joint distributions over the future values of the time series conditioned on past observations and queried channels and times, without assuming any fixed shape of the underlying distribution. As model components, we introduce a novel invertible triangular attention layer and an invertible non-linear activation function on and onto the whole real line. We conduct extensive experiments on four datasets and demonstrate that the proposed model pro
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.15728</link><description>&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#30340;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15728
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#35770;&#20272;&#35745;&#26159;&#32593;&#32476;&#20998;&#26512;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#21463;&#21040;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#20174;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#39640;&#31561;&#25552;&#20986;&#20102;&#23545;&#20110;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#21644;&#38750;&#21442;&#25968;&#22270;&#35770;&#20272;&#35745;&#30340;&#22270;&#35770;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#24046;&#35823;&#24046;&#29575;&#12290;&#32479;&#35745;&#20248;&#21270;&#20272;&#35745;&#26159;&#22522;&#20110;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#27861;&#65292;&#24182;&#19988;&#22312;&#32500;&#24230;&#19978;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#24050;&#30693;&#30340;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#26159;&#22522;&#20110;&#36890;&#29992;&#22855;&#24322;&#20540;&#38408;&#20540;&#65288;USVT&#65289;&#65292;&#20294;&#26159;&#23427;&#21482;&#33021;&#36798;&#21040;&#27604;&#26497;&#23567;&#26497;&#24046;&#38169;&#35823;&#29575;&#24930;&#24471;&#22810;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;&#20154;&#20204;&#33258;&#28982;&#20250;&#24819;&#30693;&#36947;&#36825;&#26679;&#30340;&#24046;&#36317;&#26159;&#21542;&#26159;&#24517;&#35201;&#30340;&#12290;USVT&#30340;&#35745;&#31639;&#20248;&#21270;&#24615;&#25110;&#22270;&#35770;&#20272;&#35745;&#20013;&#30340;&#35745;&#31639;&#38556;&#30861;&#30340;&#23384;&#22312;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#27492;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#65292;&#24182;&#20026;&#22270;&#35770;&#20272;&#35745;&#30340;&#35745;&#31639;&#38556;&#30861;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphon estimation has been one of the most fundamental problems in network analysis and has received considerable attention in the past decade. From the statistical perspective, the minimax error rate of graphon estimation has been established by Gao et al (2015) for both stochastic block model (SBM) and nonparametric graphon estimation. The statistical optimal estimators are based on constrained least squares and have computational complexity exponential in the dimension. From the computational perspective, the best-known polynomial-time estimator is based on universal singular value thresholding (USVT), but it can only achieve a much slower estimation error rate than the minimax one. It is natural to wonder if such a gap is essential. The computational optimality of the USVT or the existence of a computational barrier in graphon estimation has been a long-standing open problem. In this work, we take the first step towards it and provide rigorous evidence for the computational barrie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2308.02058</link><description>&lt;p&gt;
&#25972;&#21512;&#40065;&#33725;&#34892;&#20026;&#21040;&#22522;&#20110;&#21327;&#21516;&#36807;&#28388;&#30340;&#25512;&#33616;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#40065;&#33725;&#34892;&#20026;&#24341;&#20837;&#22522;&#20110;&#30697;&#38453;&#20998;&#35299;&#30340;&#25512;&#33616;&#31995;&#32479;&#23398;&#20064;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#39118;&#38505;&#27700;&#24179;&#26469;&#25552;&#39640;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21253;&#21547;&#21487;&#38752;&#24615;&#27979;&#37327;&#30340;&#25512;&#33616;&#31995;&#32479;&#24448;&#24448;&#22312;&#39044;&#27979;&#20013;&#26356;&#21152;&#20445;&#23432;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#20445;&#25345;&#21487;&#38752;&#24615;&#12290;&#36825;&#23548;&#33268;&#20102;&#36825;&#20123;&#31995;&#32479;&#21487;&#20197;&#25552;&#20379;&#30340;&#35206;&#30422;&#33539;&#22260;&#21644;&#26032;&#39062;&#24615;&#30340;&#26174;&#33879;&#19979;&#38477;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#30697;&#38453;&#20998;&#35299;&#22411;&#25512;&#33616;&#31995;&#32479;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#19968;&#39033;&#26032;&#30340;&#39033;&#65292;&#31216;&#20026;&#40065;&#33725;&#34892;&#20026;&#65292;&#23427;&#21487;&#20197;&#25511;&#21046;&#22312;&#20570;&#20986;&#20851;&#20110;&#39044;&#27979;&#21487;&#38752;&#24615;&#30340;&#20915;&#31574;&#26102;&#25152;&#24076;&#26395;&#30340;&#39118;&#38505;&#27700;&#24179;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#40065;&#33725;&#34892;&#20026;&#19981;&#20165;&#20801;&#35768;&#36827;&#34892;&#39118;&#38505;&#35843;&#25511;&#65292;&#36824;&#25552;&#39640;&#20102;&#25512;&#33616;&#31995;&#32479;&#25552;&#20379;&#30340;&#39044;&#27979;&#30340;&#25968;&#37327;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
&lt;/p&gt;</description></item></channel></rss>