<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>Dagma-DCE&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#12289;&#38750;&#21442;&#25968;&#30340;&#21487;&#24494;&#22240;&#26524;&#21457;&#29616;&#26041;&#26696;&#65292;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22240;&#26524;&#24378;&#24230;&#24230;&#37327;&#23450;&#20041;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2401.02930</link><description>&lt;p&gt;
Dagma-DCE&#65306;&#21487;&#35299;&#37322;&#30340;&#12289;&#38750;&#21442;&#25968;&#30340;&#21487;&#24494;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Dagma-DCE: Interpretable, Non-Parametric Differentiable Causal Discovery. (arXiv:2401.02930v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02930
&lt;/p&gt;
&lt;p&gt;
Dagma-DCE&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#12289;&#38750;&#21442;&#25968;&#30340;&#21487;&#24494;&#22240;&#26524;&#21457;&#29616;&#26041;&#26696;&#65292;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22240;&#26524;&#24378;&#24230;&#24230;&#37327;&#23450;&#20041;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;Dagma-DCE&#65292;&#36825;&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#12289;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#21487;&#24494;&#22240;&#26524;&#21457;&#29616;&#26041;&#26696;&#12290;&#24403;&#21069;&#30340;&#38750;&#21442;&#25968;&#25110;&#36229;&#21442;&#25968;&#26041;&#27861;&#22312;&#21487;&#24494;&#22240;&#26524;&#21457;&#29616;&#20013;&#20351;&#29992;&#19981;&#36879;&#26126;&#30340;``&#29420;&#31435;&#24615;''&#20195;&#29702;&#26469;&#35777;&#26126;&#26159;&#21542;&#21253;&#21547;&#25110;&#25490;&#38500;&#22240;&#26524;&#20851;&#31995;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#23637;&#31034;&#20102;&#36825;&#20123;&#20195;&#29702;&#21487;&#33021;&#19982;&#23454;&#38469;&#30340;&#22240;&#26524;&#24378;&#24230;&#20219;&#24847;&#19981;&#21516;&#12290;&#19982;&#29616;&#26377;&#30340;&#21487;&#24494;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#30456;&#27604;&#65292;Dagma-DCE&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#22240;&#26524;&#24378;&#24230;&#24230;&#37327;&#26469;&#23450;&#20041;&#21152;&#26435;&#37051;&#25509;&#30697;&#38453;&#12290;&#22312;&#19968;&#20123;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;Dagma-DCE&#20801;&#35768;&#39046;&#22495;&#19987;&#23478;&#36827;&#34892;&#26377;&#21407;&#21017;&#30340;&#38408;&#20540;&#35774;&#23450;&#21644;&#31232;&#30095;&#24809;&#32602;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20195;&#30721;&#22312;https://github.com/DanWaxman/DAGMA-DCE&#19978;&#24320;&#28304;&#65292;&#24182;&#19988;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#36866;&#24212;&#20219;&#24847;&#30340;&#21487;&#24494;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Dagma-DCE, an interpretable and model-agnostic scheme for differentiable causal discovery. Current non- or over-parametric methods in differentiable causal discovery use opaque proxies of ``independence'' to justify the inclusion or exclusion of a causal relationship. We show theoretically and empirically that these proxies may be arbitrarily different than the actual causal strength. Juxtaposed to existing differentiable causal discovery algorithms, \textsc{Dagma-DCE} uses an interpretable measure of causal strength to define weighted adjacency matrices. In a number of simulated datasets, we show our method achieves state-of-the-art level performance. We additionally show that \textsc{Dagma-DCE} allows for principled thresholding and sparsity penalties by domain-experts. The code for our method is available open-source at https://github.com/DanWaxman/DAGMA-DCE, and can easily be adapted to arbitrary differentiable models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20449;&#24687;&#35770;&#20998;&#26512;&#30740;&#31350;&#20102;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;KL&#25955;&#24230;&#30340;&#20449;&#24687;&#35770;&#30028;&#38480;&#21644;&#20351;&#29992;&#26465;&#20214;&#20114;&#20449;&#24687;(CMI)&#30340;&#26356;&#32039;&#30028;&#38480;&#65292;&#33021;&#22815;&#20934;&#30830;&#25429;&#25417;&#22797;&#26434;&#30340;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.02904</link><description>&lt;p&gt;
&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#65306;&#20449;&#24687;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Class-wise Generalization Error: an Information-Theoretic Analysis. (arXiv:2401.02904v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20449;&#24687;&#35770;&#20998;&#26512;&#30740;&#31350;&#20102;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;KL&#25955;&#24230;&#30340;&#20449;&#24687;&#35770;&#30028;&#38480;&#21644;&#20351;&#29992;&#26465;&#20214;&#20114;&#20449;&#24687;(CMI)&#30340;&#26356;&#32039;&#30028;&#38480;&#65292;&#33021;&#22815;&#20934;&#30830;&#25429;&#25417;&#22797;&#26434;&#30340;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26222;&#36866;&#24615;&#29702;&#35770;&#36890;&#24120;&#37319;&#29992;&#25972;&#20307;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#25972;&#20010;&#25968;&#25454;&#20998;&#24067;&#19978;&#39044;&#26399;&#26222;&#36866;&#21270;&#30340;&#30028;&#38480;&#65292;&#36825;&#38544;&#21547;&#22320;&#20551;&#23450;&#27169;&#22411;&#23545;&#25152;&#26377;&#31867;&#21035;&#37117;&#20855;&#26377;&#31867;&#20284;&#30340;&#26222;&#36866;&#24615;&#12290;&#28982;&#32780;&#22312;&#23454;&#36341;&#20013;&#65292;&#19981;&#21516;&#31867;&#21035;&#30340;&#26222;&#36866;&#24615;&#24615;&#33021;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#36825;&#26080;&#27861;&#34987;&#29616;&#26377;&#30340;&#26222;&#36866;&#24615;&#30028;&#38480;&#25152;&#25429;&#25417;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#19978;&#30740;&#31350;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#35823;&#24046;&#37327;&#21270;&#20102;&#27599;&#20010;&#20010;&#20307;&#31867;&#21035;&#30340;&#26222;&#36866;&#24615;&#33021;&#21147;&#12290;&#25105;&#20204;&#21033;&#29992;KL&#25955;&#24230;&#25512;&#23548;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#35770;&#30028;&#38480;&#26469;&#34913;&#37327;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#65292;&#24182;&#36827;&#19968;&#27493;&#20351;&#29992;&#26465;&#20214;&#20114;&#20449;&#24687;(CMI)&#24471;&#21040;&#20102;&#20960;&#20010;&#26356;&#32039;&#30340;&#30028;&#38480;&#65292;&#22312;&#23454;&#36341;&#20013;&#26356;&#23481;&#26131;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#23454;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#30028;&#38480;&#20934;&#30830;&#22320;&#25429;&#25417;&#20102;&#22797;&#26434;&#30340;&#31867;&#21035;&#26222;&#36866;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing generalization theories of supervised learning typically take a holistic approach and provide bounds for the expected generalization over the whole data distribution, which implicitly assumes that the model generalizes similarly for all the classes. In practice, however, there are significant variations in generalization performance among different classes, which cannot be captured by the existing generalization bounds. In this work, we tackle this problem by theoretically studying the class-generalization error, which quantifies the generalization performance of each individual class. We derive a novel information-theoretic bound for class-generalization error using the KL divergence, and we further obtain several tighter bounds using the conditional mutual information (CMI), which are significantly easier to estimate in practice. We empirically validate our proposed bounds in different neural networks and show that they accurately capture the complex class-generalization err
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#28369;&#26680;&#31215;&#20998;&#21464;&#25442;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.02890</link><description>&lt;p&gt;
&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Nonlinear functional regression by functional deep neural network with kernel embedding. (arXiv:2401.02890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#28369;&#26680;&#31215;&#20998;&#21464;&#25442;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#65292;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#22312;&#35821;&#38899;&#35782;&#21035;&#12289;&#22270;&#20687;&#20998;&#31867;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31561;&#39046;&#22495;&#30340;&#36805;&#36895;&#21457;&#23637;&#65292;&#23427;&#20063;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#20013;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26080;&#38480;&#32500;&#30340;&#36755;&#20837;&#65292;&#25105;&#20204;&#38656;&#35201;&#19968;&#20010;&#24378;&#22823;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#26469;&#22788;&#29702;&#38750;&#32447;&#24615;&#20989;&#25968;&#22238;&#24402;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#22522;&#20110;&#24179;&#28369;&#26680;&#31215;&#20998;&#21464;&#25442;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#39640;&#25928;&#19988;&#23436;&#20840;&#25968;&#25454;&#20381;&#36182;&#30340;&#32500;&#24230;&#32553;&#20943;&#26041;&#27861;&#30340;&#20989;&#25968;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20989;&#25968;&#32593;&#32476;&#30001;&#20197;&#19979;&#27493;&#39588;&#32452;&#25104;&#65306;&#26680;&#23884;&#20837;&#27493;&#39588;&#65306;&#21033;&#29992;&#25968;&#25454;&#30456;&#20851;&#30340;&#24179;&#28369;&#26680;&#36827;&#34892;&#31215;&#20998;&#21464;&#25442;&#65307;&#25237;&#24433;&#27493;&#39588;&#65306;&#36890;&#36807;&#22522;&#20110;&#23884;&#20837;&#26680;&#30340;&#29305;&#24449;&#20989;&#25968;&#22522;&#24213;&#36827;&#34892;&#32500;&#24230;&#32553;&#20943;&#65307;&#26368;&#21518;&#26159;&#19968;&#20010;&#34920;&#36798;&#20016;&#23500;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rapid development of deep learning in various fields of science and technology, such as speech recognition, image classification, and natural language processing, recently it is also widely applied in the functional data analysis (FDA) with some empirical success. However, due to the infinite dimensional input, we need a powerful dimension reduction method for functional learning tasks, especially for the nonlinear functional regression. In this paper, based on the idea of smooth kernel integral transformation, we propose a functional deep neural network with an efficient and fully data-dependent dimension reduction method. The architecture of our functional net consists of a kernel embedding step: an integral transformation with a data-dependent smooth kernel; a projection step: a dimension reduction by projection with eigenfunction basis based on the embedding kernel; and finally an expressive deep ReLU neural network for the prediction. The utilization of smooth kernel embe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2401.02739</link><description>&lt;p&gt;
&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65306;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;
&lt;/p&gt;
&lt;p&gt;
Diffusion Variational Inference: Diffusion Models as Expressive Variational Posteriors. (arXiv:2401.02739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#65292;&#24182;&#36890;&#36807;&#21453;&#36716;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#35813;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65292;&#20860;&#23481;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#22312;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#25512;&#26029;&#65288;DDVI&#65289;&#65292;&#19968;&#31181;&#29992;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#34920;&#36798;&#24615;&#21464;&#20998;&#21518;&#39564;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#36817;&#20284;&#25512;&#26029;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#36741;&#21161;&#28508;&#21464;&#37327;&#22686;&#21152;&#20102;&#21464;&#20998;&#21518;&#39564;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#34920;&#36798;&#24615;&#30340;&#27169;&#22411;&#31867;&#65292;&#36890;&#36807;&#21453;&#36716;&#29992;&#25143;&#25351;&#23450;&#30340;&#21152;&#22122;&#36807;&#31243;&#22312;&#28508;&#31354;&#38388;&#20013;&#36827;&#34892;&#25193;&#25955;&#12290;&#25105;&#20204;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#21463;&#21040;&#35273;&#37266;-&#30561;&#30496;&#31639;&#27861;&#21551;&#21457;&#30340;&#36793;&#38469;&#20284;&#28982;&#26032;&#19979;&#30028;&#26469;&#25311;&#21512;&#36825;&#20123;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#23454;&#29616;&#65288;&#23427;&#36866;&#37197;&#20102;&#27491;&#21017;&#21270;&#30340;ELBO&#25193;&#23637;&#65289;&#65292;&#19982;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20860;&#23481;&#65292;&#24182;&#19988;&#34920;&#29616;&#20248;&#20110;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#25110;&#23545;&#25239;&#32593;&#32476;&#30340;&#26367;&#20195;&#36817;&#20284;&#21518;&#39564;&#31867;&#21035;&#12290;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#21435;&#22122;&#25193;&#25955;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;DD-VAE&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#35813;&#31639;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#23398;&#20013;&#30340;&#19968;&#20010;&#28608;&#21169;&#20219;&#21153; -- &#20174;&#20154;&#31867;&#22522;&#22240;&#32452;&#20013;&#25512;&#26029;&#28508;&#22312;&#34880;&#32479; -- &#36229;&#36807;&#20102;&#24378;&#22522;&#32447;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose denoising diffusion variational inference (DDVI), an approximate inference algorithm for latent variable models which relies on diffusion models as expressive variational posteriors. Our method augments variational posteriors with auxiliary latents, which yields an expressive class of models that perform diffusion in latent space by reversing a user-specified noising process. We fit these models by optimizing a novel lower bound on the marginal likelihood inspired by the wake-sleep algorithm. Our method is easy to implement (it fits a regularized extension of the ELBO), is compatible with black-box variational inference, and outperforms alternative classes of approximate posteriors based on normalizing flows or adversarial networks. When applied to deep latent variable models, our method yields the denoising diffusion VAE (DD-VAE) algorithm. We use this algorithm on a motivating task in biology -- inferring latent ancestry from human genomes -- outperforming strong baselines
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#38750;&#24179;&#28369;MaxPool&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#21487;&#38752;&#24615;&#65292;&#24182;&#21457;&#29616;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;AD&#20960;&#20046;&#22312;&#27599;&#20010;&#22320;&#26041;&#37117;&#19982;&#23548;&#25968;&#30456;&#31526;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#38750;&#24179;&#28369;&#25805;&#20316;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;AD&#20351;&#29992;&#30340;&#26159;&#28014;&#28857;&#25968;&#65292;&#38656;&#35201;&#25506;&#32034;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#30740;&#31350;&#19981;&#21516;&#36873;&#25321;&#30340;&#38750;&#24179;&#28369;MaxPool&#38597;&#21487;&#27604;&#30697;&#38453;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#20998;&#27495;&#21306;&#21644;&#34917;&#20607;&#21306;&#20004;&#20010;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#23376;&#38598;&#12290;</title><link>http://arxiv.org/abs/2401.02736</link><description>&lt;p&gt;
&#20851;&#20110;&#38750;&#24179;&#28369;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#21487;&#38752;&#24615;&#65306;MaxPool&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the numerical reliability of nonsmooth autodiff: a MaxPool case study. (arXiv:2401.02736v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#38750;&#24179;&#28369;MaxPool&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#30340;&#25968;&#20540;&#21487;&#38752;&#24615;&#65292;&#24182;&#21457;&#29616;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;AD&#20960;&#20046;&#22312;&#27599;&#20010;&#22320;&#26041;&#37117;&#19982;&#23548;&#25968;&#30456;&#31526;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#38750;&#24179;&#28369;&#25805;&#20316;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;AD&#20351;&#29992;&#30340;&#26159;&#28014;&#28857;&#25968;&#65292;&#38656;&#35201;&#25506;&#32034;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#30740;&#31350;&#19981;&#21516;&#36873;&#25321;&#30340;&#38750;&#24179;&#28369;MaxPool&#38597;&#21487;&#27604;&#30697;&#38453;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#20998;&#27495;&#21306;&#21644;&#34917;&#20607;&#21306;&#20004;&#20010;&#21487;&#33021;&#23548;&#33268;AD&#25968;&#20540;&#19981;&#27491;&#30830;&#30340;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#28041;&#21450;&#38750;&#24179;&#28369;MaxPool&#25805;&#20316;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#65288;AD&#65289;&#30340;&#21487;&#38752;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#31934;&#24230;&#32423;&#21035;&#65288;16&#20301;&#12289;32&#20301;&#12289;64&#20301;&#65289;&#21644;&#21367;&#31215;&#26550;&#26500;&#65288;LeNet&#12289;VGG&#21644;ResNet&#65289;&#20197;&#21450;&#19981;&#21516;&#25968;&#25454;&#38598;&#65288;MNIST&#12289;CIFAR10&#12289;SVHN&#21644;ImageNet&#65289;&#19978;&#30340;AD&#34892;&#20026;&#12290;&#23613;&#31649;AD&#21487;&#33021;&#26159;&#38169;&#35823;&#30340;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#22312;&#20960;&#20046;&#27599;&#20010;&#22320;&#26041;&#37117;&#19982;&#23548;&#25968;&#30456;&#31526;&#65292;&#21363;&#20351;&#22312;&#23384;&#22312;&#38750;&#24179;&#28369;&#25805;&#20316;&#65288;&#22914;MaxPool&#21644;ReLU&#65289;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;AD&#20351;&#29992;&#30340;&#26159;&#28014;&#28857;&#25968;&#65288;&#32780;&#19981;&#26159;&#23454;&#25968;&#65289;&#65292;&#22240;&#27492;&#38656;&#35201;&#25506;&#32034;AD&#21487;&#33021;&#22312;&#25968;&#20540;&#19978;&#19981;&#27491;&#30830;&#30340;&#23376;&#38598;&#12290;&#36825;&#20123;&#23376;&#38598;&#21253;&#25324;&#20998;&#27495;&#21306;&#65288;AD&#22312;&#23454;&#25968;&#19978;&#19981;&#27491;&#30830;&#65289;&#21644;&#34917;&#20607;&#21306;&#65288;AD&#22312;&#28014;&#28857;&#25968;&#19978;&#19981;&#27491;&#30830;&#20294;&#22312;&#23454;&#25968;&#19978;&#27491;&#30830;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;SGD&#36827;&#34892;&#35757;&#32451;&#36807;&#31243;&#65292;&#24182;&#30740;&#31350;&#20102;MaxPool&#38750;&#24179;&#28369;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#19981;&#21516;&#36873;&#25321;&#23545;&#35757;&#32451;&#36807;&#31243;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the reliability of automatic differentiation (AD) for neural networks involving the nonsmooth MaxPool operation. We investigate the behavior of AD across different precision levels (16, 32, 64 bits) and convolutional architectures (LeNet, VGG, and ResNet) on various datasets (MNIST, CIFAR10, SVHN, and ImageNet). Although AD can be incorrect, recent research has shown that it coincides with the derivative almost everywhere, even in the presence of nonsmooth operations (such as MaxPool and ReLU). On the other hand, in practice, AD operates with floating-point numbers (not real numbers), and there is, therefore, a need to explore subsets on which AD can be numerically incorrect. These subsets include a bifurcation zone (where AD is incorrect over reals) and a compensation zone (where AD is incorrect over floating-point numbers but correct over reals). Using SGD for the training process, we study the impact of different choices of the nonsmooth Jacobian for the MaxPool
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20849;&#20139;&#20027;&#21160;&#23376;&#31354;&#38388;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22810;&#20803;&#21521;&#37327;&#20540;&#20989;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#25805;&#32437;&#26799;&#24230;&#25110;&#35745;&#31639;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#23454;&#29616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SPD&#32423;&#21035;&#30340;&#26041;&#27861;&#27604;&#26799;&#24230;&#32423;&#21035;&#30340;&#26041;&#27861;&#26356;&#22909;&#65292;&#24182;&#19988;&#22312;&#27491;&#24577;&#20998;&#24067;&#24773;&#20917;&#19979;&#34920;&#29616;&#25509;&#36817;&#21521;&#37327;&#20540;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.02735</link><description>&lt;p&gt;
&#20849;&#20139;&#20027;&#21160;&#23376;&#31354;&#38388;&#29992;&#20110;&#22810;&#20803;&#21521;&#37327;&#20540;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Shared active subspace for multivariate vector-valued functions. (arXiv:2401.02735v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02735
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20849;&#20139;&#20027;&#21160;&#23376;&#31354;&#38388;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22810;&#20803;&#21521;&#37327;&#20540;&#20989;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#25805;&#32437;&#26799;&#24230;&#25110;&#35745;&#31639;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#23454;&#29616;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;SPD&#32423;&#21035;&#30340;&#26041;&#27861;&#27604;&#26799;&#24230;&#32423;&#21035;&#30340;&#26041;&#27861;&#26356;&#22909;&#65292;&#24182;&#19988;&#22312;&#27491;&#24577;&#20998;&#24067;&#24773;&#20917;&#19979;&#34920;&#29616;&#25509;&#36817;&#21521;&#37327;&#20540;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20960;&#31181;&#26041;&#27861;&#20316;&#20026;&#22522;&#32447;&#26469;&#35745;&#31639;&#22810;&#20803;&#21521;&#37327;&#20540;&#20989;&#25968;&#30340;&#20849;&#20139;&#20027;&#21160;&#23376;&#31354;&#38388;&#12290;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#21407;&#22987;&#31354;&#38388;&#19978;&#30340;&#20989;&#25968;&#35780;&#20272;&#19982;&#37325;&#26500;&#31354;&#38388;&#19978;&#30340;&#20989;&#25968;&#35780;&#20272;&#20043;&#38388;&#30340;&#20559;&#24046;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#36807;&#25805;&#32437;&#26799;&#24230;&#25110;&#20174;&#27599;&#20010;&#20998;&#37327;&#20989;&#25968;&#30340;&#26799;&#24230;&#35745;&#31639;&#30340;&#23545;&#31216;&#27491;&#23450;&#65288;&#21322;&#27491;&#23450;&#65289;&#30697;&#38453;&#26469;&#33719;&#24471;&#25152;&#26377;&#20998;&#37327;&#20989;&#25968;&#30340;&#20849;&#21516;&#32467;&#26500;&#12290;&#19982;&#29616;&#26377;&#30340;&#21482;&#36866;&#29992;&#20110;&#27491;&#24577;&#20998;&#24067;&#30340;&#21521;&#37327;&#20540;&#26041;&#27861;&#19981;&#21516;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#25968;&#25454;&#26080;&#35770;&#20854;&#28508;&#22312;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#20248;&#21270;&#38382;&#39064;&#19978;&#27979;&#35797;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#24635;&#20307;&#32780;&#35328;&#65292; SPD&#32423;&#21035;&#30340;&#26041;&#27861;&#20248;&#20110;&#26799;&#24230;&#32423;&#21035;&#30340;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27491;&#24577;&#20998;&#24067;&#24773;&#20917;&#19979;&#25509;&#36817;&#21521;&#37327;&#20540;&#26041;&#27861;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#65292;&#21482;&#38656;&#21462;SPD&#30697;&#38453;&#20043;&#21644;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes several approaches as baselines to compute a shared active subspace for multivariate vector-valued functions. The goal is to minimize the deviation between the function evaluations on the original space and those on the reconstructed one. This is done either by manipulating the gradients or the symmetric positive (semi-)definite (SPD) matrices computed from the gradients of each component function so as to get a single structure common to all component functions. These approaches can be applied to any data irrespective of the underlying distribution unlike the existing vector-valued approach that is constrained to a normal distribution. We test the effectiveness of these methods on five optimization problems. The experiments show that, in general, the SPD-level methods are superior to the gradient-level ones, and are close to the vector-valued approach in the case of a normal distribution. Interestingly, in most cases it suffices to take the sum of the SPD matrices 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#26102;&#38388;&#30340;&#19977;&#20803;&#32452;&#22352;&#26631;&#25439;&#22833;&#20989;&#25968;TripleSurv&#65292;&#36890;&#36807;&#24341;&#20837;&#26679;&#26412;&#23545;&#20043;&#38388;&#30340;&#29983;&#23384;&#26102;&#38388;&#24046;&#24322;&#26469;&#40723;&#21169;&#27169;&#22411;&#37327;&#21270;&#25490;&#21517;&#30456;&#23545;&#39118;&#38505;&#65292;&#20174;&#32780;&#25552;&#39640;&#29983;&#23384;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02708</link><description>&lt;p&gt;
TripleSurv&#65306;&#36866;&#24212;&#26102;&#38388;&#19977;&#20803;&#32452;&#22352;&#26631;&#25439;&#22833;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
TripleSurv: Triplet Time-adaptive Coordinate Loss for Survival Analysis. (arXiv:2401.02708v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02708
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#26102;&#38388;&#30340;&#19977;&#20803;&#32452;&#22352;&#26631;&#25439;&#22833;&#20989;&#25968;TripleSurv&#65292;&#36890;&#36807;&#24341;&#20837;&#26679;&#26412;&#23545;&#20043;&#38388;&#30340;&#29983;&#23384;&#26102;&#38388;&#24046;&#24322;&#26469;&#40723;&#21169;&#27169;&#22411;&#37327;&#21270;&#25490;&#21517;&#30456;&#23545;&#39118;&#38505;&#65292;&#20174;&#32780;&#25552;&#39640;&#29983;&#23384;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#26159;&#23545;&#34987;&#25130;&#23614;&#30340;&#20107;&#20214;&#26102;&#38388;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#65292;&#20854;&#20013;&#24863;&#20852;&#36259;&#30340;&#20107;&#20214;&#21487;&#33021;&#26159;&#27515;&#20129;&#12289;&#22833;&#36133;&#25110;&#29305;&#23450;&#20107;&#20214;&#30340;&#21457;&#29983;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25490;&#24207;&#25439;&#22833;&#21644;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#25439;&#22833;&#20989;&#25968;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;&#12290;&#28982;&#32780;&#65292;&#25490;&#24207;&#25439;&#22833;&#20165;&#20851;&#27880;&#29983;&#23384;&#26102;&#38388;&#25490;&#21517;&#65292;&#19981;&#32771;&#34385;&#26679;&#26412;&#23545;&#20110;&#30830;&#20999;&#29983;&#23384;&#26102;&#38388;&#20540;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;MLE&#26159;&#26080;&#30028;&#30340;&#19988;&#23481;&#26131;&#21463;&#21040;&#24322;&#24120;&#20540;&#65288;&#20363;&#22914;&#65292;&#34987;&#25130;&#23614;&#25968;&#25454;&#65289;&#30340;&#24433;&#21709;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24314;&#27169;&#24615;&#33021;&#36739;&#24046;&#12290;&#20026;&#20102;&#22788;&#29702;&#23398;&#20064;&#36807;&#31243;&#30340;&#22797;&#26434;&#24615;&#24182;&#21033;&#29992;&#26377;&#20215;&#20540;&#30340;&#29983;&#23384;&#26102;&#38388;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#26102;&#38388;&#19977;&#20803;&#32452;&#22352;&#26631;&#25439;&#22833;&#20989;&#25968;TripleSurv&#65292;&#36890;&#36807;&#23558;&#26679;&#26412;&#23545;&#20043;&#38388;&#30340;&#29983;&#23384;&#26102;&#38388;&#24046;&#24322;&#24341;&#20837;&#25490;&#24207;&#20013;&#65292;&#20197;&#40723;&#21169;&#27169;&#22411;&#37327;&#21270;&#25490;&#21517;&#30456;&#23545;&#39118;&#38505;&#65292;&#26368;&#32456;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A core challenge in survival analysis is to model the distribution of censored time-to-event data, where the event of interest may be a death, failure, or occurrence of a specific event. Previous studies have showed that ranking and maximum likelihood estimation (MLE)loss functions are widely-used for survival analysis. However, ranking loss only focus on the ranking of survival time and does not consider potential effect of samples for exact survival time values. Furthermore, the MLE is unbounded and easily subject to outliers (e.g., censored data), which may cause poor performance of modeling. To handle the complexities of learning process and exploit valuable survival time values, we propose a time-adaptive coordinate loss function, TripleSurv, to achieve adaptive adjustments by introducing the differences in the survival time between sample pairs into the ranking, which can encourage the model to quantitatively rank relative risk of pairs, ultimately enhancing the accuracy of predi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#39034;&#24207;&#20248;&#21270;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.02650</link><description>&lt;p&gt;
&#36890;&#36807;MCMC&#25913;&#36827;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26679;&#26412;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Improving sample efficiency of high dimensional Bayesian optimization with MCMC. (arXiv:2401.02650v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#36827;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#39034;&#24207;&#20248;&#21270;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#39034;&#24207;&#20248;&#21270;&#26041;&#27861;&#32463;&#24120;&#38754;&#20020;&#32500;&#24230;&#35781;&#21650;&#12290;&#30446;&#21069;&#30340;&#39640;&#26031;&#36807;&#31243;&#26041;&#27861;&#22312;&#36319;&#36394;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19978;&#20173;&#23384;&#22312;&#36127;&#25285;&#65292;&#24182;&#19988;&#38656;&#35201;&#23558;&#20248;&#21270;&#38382;&#39064;&#21010;&#20998;&#20026;&#23567;&#21306;&#22495;&#20197;&#30830;&#20445;&#25506;&#32034;&#25110;&#20551;&#35774;&#19968;&#20010;&#28508;&#22312;&#30340;&#20302;&#32500;&#32467;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#20505;&#36873;&#28857;&#36716;&#31227;&#21040;&#26356;&#26377;&#24076;&#26395;&#30340;&#20301;&#32622;&#26469;&#26377;&#25928;&#22320;&#20174;&#36817;&#20284;&#21518;&#39564;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#39640;&#26031;&#36807;&#31243;&#27748;&#26222;&#26862;&#37319;&#26679;&#35774;&#32622;&#19979;&#25552;&#20379;&#20102;&#20854;&#25910;&#25947;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#31639;&#27861;&#30340;Metropolis-Hastings&#29256;&#26412;&#21644;Langevin Dynamics&#29256;&#26412;&#22312;&#39640;&#32500;&#39034;&#24207;&#20248;&#21270;&#21644;&#24378;&#21270;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#20013;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential optimization methods are often confronted with the curse of dimensionality in high-dimensional spaces. Current approaches under the Gaussian process framework are still burdened by the computational complexity of tracking Gaussian process posteriors and need to partition the optimization problem into small regions to ensure exploration or assume an underlying low-dimensional structure. With the idea of transiting the candidate points towards more promising positions, we propose a new method based on Markov Chain Monte Carlo to efficiently sample from an approximated posterior. We provide theoretical guarantees of its convergence in the Gaussian process Thompson sampling setting. We also show experimentally that both the Metropolis-Hastings and the Langevin Dynamics version of our algorithm outperform state-of-the-art methods in high-dimensional sequential optimization and reinforcement learning benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#38750;&#20984;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#24352;&#37327;&#21015;&#36710;&#24674;&#22797;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#24038;&#27491;&#20132;TT&#26684;&#24335;&#26469;&#23454;&#29616;&#27491;&#20132;&#32467;&#26500;&#65292;&#24182;&#20351;&#29992;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20248;&#21270;&#22240;&#23376;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#24182;&#19988;&#22312;&#28385;&#36275;&#21463;&#38480;&#31561;&#35889;&#24615;&#36136;&#30340;&#26465;&#20214;&#19979;&#33021;&#22815;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#12290;</title><link>http://arxiv.org/abs/2401.02592</link><description>&lt;p&gt;
&#20445;&#35777;&#38750;&#20984;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#24352;&#37327;&#21015;&#36710;&#24674;&#22797;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery. (arXiv:2401.02592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;&#38750;&#20984;&#20998;&#35299;&#26041;&#27861;&#29992;&#20110;&#24352;&#37327;&#21015;&#36710;&#24674;&#22797;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#24038;&#27491;&#20132;TT&#26684;&#24335;&#26469;&#23454;&#29616;&#27491;&#20132;&#32467;&#26500;&#65292;&#24182;&#20351;&#29992;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20248;&#21270;&#22240;&#23376;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#24182;&#19988;&#22312;&#28385;&#36275;&#21463;&#38480;&#31561;&#35889;&#24615;&#36136;&#30340;&#26465;&#20214;&#19979;&#33021;&#22815;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;&#23545;&#20110;&#20998;&#35299;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20026;&#20102;&#36991;&#20813;&#23610;&#24230;&#27495;&#20041;&#24182;&#20415;&#20110;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#20248;&#21270;&#25152;&#35859;&#30340;&#24038;&#27491;&#20132;TT&#26684;&#24335;&#65292;&#24378;&#21046;&#20351;&#22823;&#37096;&#20998;&#22240;&#23376;&#24444;&#27492;&#27491;&#20132;&#12290;&#20026;&#20102;&#30830;&#20445;&#27491;&#20132;&#32467;&#26500;&#65292;&#25105;&#20204;&#21033;&#29992;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#65288;RGD&#65289;&#26469;&#20248;&#21270;Stiefel&#27969;&#24418;&#19978;&#30340;&#36825;&#20123;&#22240;&#23376;&#12290;&#25105;&#20204;&#39318;&#20808;&#28145;&#20837;&#30740;&#31350;TT&#20998;&#35299;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;RGD&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#38543;&#30528;&#24352;&#37327;&#38454;&#25968;&#30340;&#22686;&#21152;&#65292;&#25910;&#25947;&#36895;&#29575;&#20165;&#32463;&#21382;&#32447;&#24615;&#19979;&#38477;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24863;&#30693;&#38382;&#39064;&#65292;&#21363;&#20174;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;TT&#26684;&#24335;&#24352;&#37327;&#12290;&#20551;&#35774;&#24863;&#30693;&#31639;&#23376;&#28385;&#36275;&#21463;&#38480;&#31561;&#35889;&#24615;&#36136;&#65288;RIP&#65289;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#19979;&#65292;&#36890;&#36807;&#35889;&#21021;&#22987;&#21270;&#33719;&#24471;&#65292;RGD&#20063;&#20250;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide the first convergence guarantee for the factorization approach. Specifically, to avoid the scaling ambiguity and to facilitate theoretical analysis, we optimize over the so-called left-orthogonal TT format which enforces orthonormality among most of the factors. To ensure the orthonormal structure, we utilize the Riemannian gradient descent (RGD) for optimizing those factors over the Stiefel manifold. We first delve into the TT factorization problem and establish the local linear convergence of RGD. Notably, the rate of convergence only experiences a linear decline as the tensor order increases. We then study the sensing problem that aims to recover a TT format tensor from linear measurements. Assuming the sensing operator satisfies the restricted isometry property (RIP), we show that with a proper initialization, which could be obtained through spectral initialization, RGD also converges to the ground-truth tensor at a linear rate. Furthermore, we expand our 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#20219;&#24847;&#20803;&#32032;&#38388;&#20381;&#36182;&#19979;&#36827;&#34892;&#32467;&#26500;&#21270;&#30697;&#38453;&#20272;&#35745;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#25552;&#20986;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#22122;&#22768;&#20998;&#24067;&#19979;&#30340;&#32039;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#32467;&#26524;&#65292;&#35770;&#36848;&#20102;&#26080;&#20851;&#20302;&#31209;&#30697;&#38453;&#30340;&#32467;&#26500;&#29305;&#28857;&#12290;&#26368;&#21518;&#65292;&#35770;&#25991;&#36824;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#22312;&#32467;&#26500;&#21270;&#39532;&#23572;&#21487;&#22827;&#36716;&#31227;&#26680;&#20272;&#35745;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.02520</link><description>&lt;p&gt;
&#22312;&#20219;&#24847;&#20803;&#32032;&#38388;&#20381;&#36182;&#19979;&#30340;&#32467;&#26500;&#21270;&#30697;&#38453;&#23398;&#20064;&#19982;&#39532;&#23572;&#21487;&#22827;&#36716;&#31227;&#26680;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Structured Matrix Learning under Arbitrary Entrywise Dependence and Estimation of Markov Transition Kernel. (arXiv:2401.02520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#20219;&#24847;&#20803;&#32032;&#38388;&#20381;&#36182;&#19979;&#36827;&#34892;&#32467;&#26500;&#21270;&#30697;&#38453;&#20272;&#35745;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#25552;&#20986;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#22122;&#22768;&#20998;&#24067;&#19979;&#30340;&#32039;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#32467;&#26524;&#65292;&#35770;&#36848;&#20102;&#26080;&#20851;&#20302;&#31209;&#30697;&#38453;&#30340;&#32467;&#26500;&#29305;&#28857;&#12290;&#26368;&#21518;&#65292;&#35770;&#25991;&#36824;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#22312;&#32467;&#26500;&#21270;&#39532;&#23572;&#21487;&#22827;&#36716;&#31227;&#26680;&#20272;&#35745;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#36890;&#24120;&#22312;&#24378;&#22122;&#22768;&#20381;&#36182;&#20551;&#35774;&#19979;&#36827;&#34892;&#30740;&#31350;&#12290;&#26412;&#25991;&#32771;&#34385;&#22122;&#22768;&#20302;&#31209;&#21152;&#31232;&#30095;&#30697;&#38453;&#24674;&#22797;&#30340;&#19968;&#33324;&#26694;&#26550;&#65292;&#20854;&#20013;&#22122;&#22768;&#30697;&#38453;&#21487;&#20197;&#26469;&#33258;&#20219;&#24847;&#20855;&#26377;&#20803;&#32032;&#38388;&#20219;&#24847;&#20381;&#36182;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#20851;&#30456;&#20301;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#23427;&#22312;&#21508;&#31181;&#22122;&#22768;&#20998;&#24067;&#19979;&#37117;&#26159;&#32039;&#33268;&#30340;&#65292;&#26082;&#28385;&#36275;&#30830;&#23450;&#24615;&#19979;&#30028;&#21448;&#21305;&#37197;&#26368;&#23567;&#21270;&#39118;&#38505;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#32467;&#26524;&#65292;&#26029;&#35328;&#20004;&#20010;&#20219;&#24847;&#30340;&#20302;&#31209;&#26080;&#20851;&#30697;&#38453;&#20043;&#38388;&#30340;&#24046;&#24322;&#24517;&#39035;&#22312;&#20854;&#20803;&#32032;&#19978;&#25193;&#25955;&#33021;&#37327;&#65292;&#25442;&#21477;&#35805;&#35828;&#19981;&#33021;&#22826;&#31232;&#30095;&#65292;&#36825;&#25581;&#31034;&#20102;&#26080;&#20851;&#20302;&#31209;&#30697;&#38453;&#30340;&#32467;&#26500;&#65292;&#21487;&#33021;&#24341;&#36215;&#29420;&#31435;&#20852;&#36259;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#22312;&#20960;&#20010;&#37325;&#35201;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;&#22312;&#20272;&#35745;&#32467;&#26500;&#21270;&#39532;&#23572;&#21487;&#22827;&#36716;&#31227;&#26680;&#30340;&#38382;&#39064;&#20013;&#65292;&#37319;&#29992;&#20102;&#36825;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of structured matrix estimation has been studied mostly under strong noise dependence assumptions. This paper considers a general framework of noisy low-rank-plus-sparse matrix recovery, where the noise matrix may come from any joint distribution with arbitrary dependence across entries. We propose an incoherent-constrained least-square estimator and prove its tightness both in the sense of deterministic lower bound and matching minimax risks under various noise distributions. To attain this, we establish a novel result asserting that the difference between two arbitrary low-rank incoherent matrices must spread energy out across its entries, in other words cannot be too sparse, which sheds light on the structure of incoherent low-rank matrices and may be of independent interest. We then showcase the applications of our framework to several important statistical machine learning problems. In the problem of estimating a structured Markov transition kernel, the proposed method
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30028;&#25439;&#22833;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#21442;&#32771;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#33258;&#30001;&#21442;&#25968;&#35299;&#20915;&#20102;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28789;&#27963;&#30340;&#20551;&#35774;&#20135;&#29983;&#20102;&#26032;&#30340;&#24191;&#20041;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.01148</link><description>&lt;p&gt;
&#26080;&#30028;&#25439;&#22833;&#30340;PAC-Bayes-Chernoff&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayes-Chernoff bounds for unbounded losses. (arXiv:2401.01148v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01148
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30028;&#25439;&#22833;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#21442;&#32771;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#33258;&#30001;&#21442;&#25968;&#35299;&#20915;&#20102;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#28789;&#27963;&#30340;&#20551;&#35774;&#20135;&#29983;&#20102;&#26032;&#30340;&#24191;&#20041;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#26080;&#30028;&#25439;&#22833;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#21442;&#32771;&#30028;&#38480;&#12290;&#36825;&#20010;&#32467;&#26524;&#21487;&#20197;&#29702;&#35299;&#20026;Chernoff&#30028;&#38480;&#30340;PAC-Bayes&#29256;&#26412;&#12290;&#35777;&#26126;&#25216;&#24039;&#20381;&#36182;&#20110;&#36890;&#36807;Cram&#233;r&#21464;&#25442;&#23545;&#25439;&#22833;&#36827;&#34892;&#32479;&#19968;&#36793;&#30028;&#30340;&#23614;&#37096;&#38543;&#26426;&#21464;&#37327;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#25105;&#20204;&#20027;&#35201;&#32467;&#26524;&#30340;&#20004;&#20010;&#24212;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#35299;&#20915;&#20102;&#35768;&#22810;PAC-Bayes&#30028;&#38480;&#19978;&#30340;&#33258;&#30001;&#21442;&#25968;&#20248;&#21270;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#22312;&#25439;&#22833;&#20989;&#25968;&#19978;&#36827;&#34892;&#28789;&#27963;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#24191;&#20041;&#20102;&#20043;&#21069;&#30340;&#30028;&#38480;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#26368;&#23567;&#21270;&#26469;&#33719;&#24471;&#31867;&#20284;Gibbs&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new high-probability PAC-Bayes oracle bound for unbounded losses. This result can be understood as a PAC-Bayes version of the Chernoff bound. The proof technique relies on uniformly bounding the tail of certain random variable based on the Cram\'er transform of the loss. We highlight two applications of our main result. First, we show that our bound solves the open problem of optimizing the free parameter on many PAC-Bayes bounds. Finally, we show that our approach allows working with flexible assumptions on the loss function, resulting in novel bounds that generalize previous ones and can be minimized to obtain Gibbs-like posteriors.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#26684;&#23376;&#38598;&#25104;&#25299;&#25169;&#25551;&#36848;&#31526;&#26694;&#26550;&#65292;&#23558;&#25345;&#20037;&#22270;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#21521;&#37327;&#31354;&#38388;&#30340;&#20803;&#32032;&#65292;&#36890;&#36807;&#22522;&#20110;&#31163;&#25955;&#27979;&#24230;&#30340;&#21151;&#33021;&#65292;&#35777;&#26126;&#20102;&#37096;&#20998;&#25104;&#21592;&#22312;&#24230;&#37327;&#19978;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#31454;&#20105;&#29978;&#33267;&#36229;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2312.17093</link><description>&lt;p&gt;
LITE&#65306;&#31283;&#23450;&#30340;&#26684;&#23376;&#38598;&#25104;&#25299;&#25169;&#25551;&#36848;&#31526;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
LITE: A Stable Framework for Lattice-Integrated Embedding of Topological Descriptors. (arXiv:2312.17093v2 [math.AT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.17093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#26684;&#23376;&#38598;&#25104;&#25299;&#25169;&#25551;&#36848;&#31526;&#26694;&#26550;&#65292;&#23558;&#25345;&#20037;&#22270;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#21521;&#37327;&#31354;&#38388;&#30340;&#20803;&#32032;&#65292;&#36890;&#36807;&#22522;&#20110;&#31163;&#25955;&#27979;&#24230;&#30340;&#21151;&#33021;&#65292;&#35777;&#26126;&#20102;&#37096;&#20998;&#25104;&#21592;&#22312;&#24230;&#37327;&#19978;&#30340;&#31283;&#23450;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#31454;&#20105;&#29978;&#33267;&#36229;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25345;&#20037;&#22270;&#25551;&#36848;&#31526;&#23478;&#26063;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#36825;&#20123;&#22270;&#36716;&#21270;&#20026;&#26377;&#38480;&#32500;&#21521;&#37327;&#31354;&#38388;&#20013;&#30340;&#20803;&#32032;&#65292;&#20351;&#29992;&#22522;&#20110;&#23427;&#20204;&#25152;&#24341;&#36215;&#30340;&#31163;&#25955;&#27979;&#24230;&#30340;&#27867;&#20989;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#28966;&#28857;&#20027;&#35201;&#26159;&#22312;&#22522;&#20110;&#36523;&#20221;&#21644;&#39057;&#29575;&#30340;&#36716;&#25442;&#19978;&#65292;&#20294;&#25105;&#20204;&#24182;&#19981;&#23616;&#38480;&#20110;&#36825;&#20123;&#31867;&#22411;&#30340;&#25216;&#26415;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#36716;&#25442;&#23478;&#26063;&#31216;&#20026;LITE &#65288;Lattice Integrated Topological Embedding&#65289;&#65292;&#24182;&#19988;&#23545;&#35813;&#23478;&#26063;&#30340;&#19968;&#20123;&#25104;&#21592;&#22312;1-&#24247;&#25176;&#27931;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#24230;&#37327;&#19979;&#35777;&#26126;&#20102;&#31283;&#23450;&#24615;&#65292;&#30830;&#20445;&#23545;&#32454;&#24494;&#30340;&#25968;&#25454;&#21464;&#21270;&#20855;&#26377;&#21453;&#24212;&#24615;&#12290;&#24191;&#27867;&#30340;&#23545;&#27604;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#25551;&#36848;&#31526;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#25991;&#29486;&#20013;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#65292;&#24182;&#19988;&#32463;&#24120;&#36229;&#36234;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;&#36825;&#39033;&#30740;&#31350;&#19981;&#20165;&#20026;&#25968;&#25454;&#31185;&#23398;&#23478;&#24341;&#20837;&#20102;&#21019;&#26032;&#30340;&#35266;&#28857;&#65292;&#32780;&#19988;&#25209;&#35780;&#20102;&#30446;&#21069;&#20851;&#20110;&#21521;&#37327;&#21270;&#26041;&#27861;&#23398;&#30340;&#25991;&#29486;&#30340;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new family of descriptors for persistence diagrams. Our approach transforms these diagrams into elements of a finite-dimensional vector space using functionals based on the discrete measures they induce. While our focus is primarily on identity and frequency-based transformations, we do not restrict our approach exclusively to this types of techniques. We term this family of transformations as LITE (Lattice Integrated Topological Embedding) and prove stability for some members of this family against the 1-$Kantorovitch$-$Rubinstein$ metric, ensuring its responsiveness to subtle data variations. Extensive comparative analysis reveals that our descriptor performs competitively with the current state-of-art from the topological data analysis literature, and often surpasses, the existing methods. This research not only introduces an innovative perspective for data scientists but also critiques the current trajectory of literature on methodologies for vectorizi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31163;&#25955;&#35010;&#32541;&#32593;&#32476;&#27169;&#25311;&#20013;&#32771;&#34385;&#20869;&#22312;&#38543;&#26426;&#24615;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#39063;&#31890;&#36798;&#21040;&#31995;&#32479;&#36793;&#32536;&#30340;&#31361;&#30772;&#26102;&#38388;&#12290;&#36825;&#19968;&#26041;&#27861;&#33021;&#22815;&#35299;&#20915;&#21442;&#25968;&#36873;&#25321;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#23545;QoI&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2312.04722</link><description>&lt;p&gt;
&#22312;&#31163;&#25955;&#35010;&#32541;&#32593;&#32476;&#27169;&#25311;&#20013;&#32771;&#34385;&#20869;&#22312;&#38543;&#26426;&#24615;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Sensitivity Analysis in the Presence of Intrinsic Stochasticity for Discrete Fracture Network Simulations. (arXiv:2312.04722v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.04722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#31163;&#25955;&#35010;&#32541;&#32593;&#32476;&#27169;&#25311;&#20013;&#32771;&#34385;&#20869;&#22312;&#38543;&#26426;&#24615;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#39063;&#31890;&#36798;&#21040;&#31995;&#32479;&#36793;&#32536;&#30340;&#31361;&#30772;&#26102;&#38388;&#12290;&#36825;&#19968;&#26041;&#27861;&#33021;&#22815;&#35299;&#20915;&#21442;&#25968;&#36873;&#25321;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24615;&#23545;QoI&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22320;&#19979;&#35010;&#32541;&#32593;&#32476;&#30340;&#30452;&#25509;&#35266;&#27979;&#24448;&#24448;&#19981;&#21487;&#34892;&#65292;&#22823;&#35268;&#27169;&#30340;&#31163;&#25955;&#35010;&#32541;&#32593;&#32476;&#65288;DFN&#65289;&#27169;&#25311;&#22120;&#24120;&#29992;&#20110;&#30740;&#31350;&#39063;&#31890;&#30340;&#22320;&#19979;&#36755;&#36816;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#25311;&#22120;&#22312;&#22810;&#20010;&#24037;&#31243;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24456;&#22810;&#25104;&#21151;&#65292;&#20294;&#26159;&#28041;&#21450;&#21040;&#24863;&#20852;&#36259;&#37327;&#65288;QoI&#65289;&#30340;&#20272;&#35745;&#65292;&#22914;&#39063;&#31890;&#36798;&#21040;&#31995;&#32479;&#36793;&#32536;&#30340;&#31361;&#30772;&#26102;&#38388;&#65292;&#20250;&#21463;&#21040;&#20004;&#31181;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#24433;&#21709;&#12290;DFN&#27169;&#25311;&#22120;&#30340;&#36816;&#34892;&#38656;&#35201;&#35774;&#32622;&#22810;&#20010;&#21442;&#25968;&#20540;&#26469;&#20915;&#23450;&#35010;&#32541;&#30340;&#20301;&#32622;&#21644;&#22823;&#23567;&#12289;&#35010;&#32541;&#30340;&#23494;&#24230;&#20197;&#21450;&#25972;&#20307;&#28183;&#36879;&#24615;; &#23545;&#21442;&#25968;&#36873;&#25321;&#30340;&#19981;&#30830;&#23450;&#24615;&#23558;&#23548;&#33268;QoI&#20013;&#23384;&#22312;&#19968;&#23450;&#31243;&#24230;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#31216;&#20026;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;DFN&#27169;&#25311;&#22120;&#20381;&#36182;&#20110;&#38543;&#26426;&#36807;&#31243;&#26469;&#25918;&#32622;&#35010;&#32541;&#21644;&#25511;&#21046;&#27969;&#21160;&#65292;&#29702;&#35299;&#36825;&#31181;&#38543;&#26426;&#24615;&#22914;&#20309;&#24433;&#21709;QoI&#38656;&#35201;&#36827;&#34892;&#22810;&#27425;&#27169;&#25311;&#22120;&#30340;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale discrete fracture network (DFN) simulators are standard fare for studies involving the sub-surface transport of particles since direct observation of real world underground fracture networks is generally infeasible. While these simulators have seen numerous successes over several engineering applications, estimations on quantities of interest (QoI) - such as breakthrough time of particles reaching the edge of the system - suffer from a two distinct types of uncertainty. A run of a DFN simulator requires several parameter values to be set that dictate the placement and size of fractures, the density of fractures, and the overall permeability of the system; uncertainty on the proper parameter choices will lead to some amount of uncertainty in the QoI, called epistemic uncertainty. Furthermore, since DFN simulators rely on stochastic processes to place fractures and govern flow, understanding how this randomness affects the QoI requires several runs of the simulator at distinc
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#23545;&#27880;&#37322;&#26412;&#36523;&#21644;&#19979;&#28216;&#27169;&#22411;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#23545;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#24615;&#35821;&#35328;&#36827;&#34892;&#27880;&#37322;&#25910;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#21457;&#29616;&#27880;&#37322;&#24037;&#20855;&#30340;&#35774;&#35745;&#36873;&#25321;&#20250;&#23545;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#26126;&#26174;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2311.14212</link><description>&lt;p&gt;
&#27880;&#37322;&#25935;&#24863;&#24615;&#65306;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Annotation Sensitivity: Training Data Collection Methods Affect Model Performance. (arXiv:2311.14212v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.14212
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#23545;&#27880;&#37322;&#26412;&#36523;&#21644;&#19979;&#28216;&#27169;&#22411;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#23545;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#24615;&#35821;&#35328;&#36827;&#34892;&#27880;&#37322;&#25910;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#21457;&#29616;&#27880;&#37322;&#24037;&#20855;&#30340;&#35774;&#35745;&#36873;&#25321;&#20250;&#23545;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#26126;&#26174;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35757;&#32451;&#25968;&#25454;&#30001;&#20154;&#24037;&#27880;&#37322;&#32773;&#25910;&#38598;&#26102;&#65292;&#27880;&#37322;&#24037;&#20855;&#30340;&#35774;&#35745;&#12289;&#32473;&#20104;&#27880;&#37322;&#32773;&#30340;&#25351;&#31034;&#12289;&#27880;&#37322;&#32773;&#30340;&#29305;&#24449;&#20197;&#21450;&#20182;&#20204;&#20043;&#38388;&#30340;&#20114;&#21160;&#37117;&#21487;&#33021;&#23545;&#35757;&#32451;&#25968;&#25454;&#20135;&#29983;&#24433;&#21709;&#12290;&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#21019;&#24314;&#27880;&#37322;&#24037;&#20855;&#26102;&#30340;&#35774;&#35745;&#36873;&#25321;&#20063;&#20250;&#24433;&#21709;&#22522;&#20110;&#24471;&#21040;&#30340;&#27880;&#37322;&#35757;&#32451;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;"&#27880;&#37322;&#25935;&#24863;&#24615;"&#36825;&#20010;&#26415;&#35821;&#65292;&#29992;&#26469;&#25351;&#20195;&#27880;&#37322;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#23545;&#27880;&#37322;&#26412;&#36523;&#20197;&#21450;&#19979;&#28216;&#27169;&#22411;&#24615;&#33021;&#21644;&#39044;&#27979;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#20116;&#31181;&#23454;&#39564;&#26465;&#20214;&#19979;&#23545;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#24615;&#35821;&#35328;&#36827;&#34892;&#27880;&#37322;&#25910;&#38598;&#65292;&#38543;&#26426;&#23558;&#27880;&#37322;&#32773;&#20998;&#37197;&#21040;&#19981;&#21516;&#26465;&#20214;&#19979;&#12290;&#28982;&#21518;&#65292;&#22312;&#27599;&#20010;&#24471;&#21040;&#30340;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#23545;BERT&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#24182;&#22312;&#27599;&#20010;&#26465;&#20214;&#30340;&#20445;&#30041;&#37096;&#20998;&#19978;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20197;&#19979;&#26041;&#38754;&#26465;&#20214;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#24046;&#24322;&#65306;1&#65289;&#20167;&#24680;&#35328;&#35770;/&#20882;&#29359;&#24615;&#35821;&#35328;&#27880;&#37322;&#30340;&#27604;&#20363;&#65292;2&#65289;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
When training data are collected from human annotators, the design of the annotation instrument, the instructions given to annotators, the characteristics of the annotators, and their interactions can impact training data. This study demonstrates that design choices made when creating an annotation instrument also impact the models trained on the resulting annotations. We introduce the term annotation sensitivity to refer to the impact of annotation data collection methods on the annotations themselves and on downstream model performance and predictions. We collect annotations of hate speech and offensive language in five experimental conditions of an annotation instrument, randomly assigning annotators to conditions. We then fine-tune BERT models on each of the five resulting datasets and evaluate model performance on a holdout portion of each condition. We find considerable differences between the conditions for 1) the share of hate speech/offensive language annotations, 2) model per
&lt;/p&gt;</description></item><item><title>&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16221</link><description>&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16221
&lt;/p&gt;
&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26159;&#22797;&#26434;&#30340;&#65292;&#36890;&#24120;&#30001;&#21487;&#20998;&#35299;&#20026;&#22810;&#20010;&#23454;&#20307;&#30340;&#23545;&#35937;&#32452;&#25104;&#65288;&#20363;&#22914;&#65292;&#23558;&#22270;&#20687;&#20998;&#35299;&#20026;&#20687;&#32032;&#65292;&#23558;&#22270;&#24418;&#20998;&#35299;&#20026;&#30456;&#20114;&#36830;&#25509;&#30340;&#33410;&#28857;&#65289;&#12290;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#22312;&#20854;&#36755;&#20837;&#30340;&#24494;&#23567;&#21464;&#21270;&#19978;&#20855;&#26377;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;-&#36890;&#36807;&#22312;&#20998;&#31867;&#20043;&#21069;&#38543;&#26426;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#35777;&#22810;&#25968;&#25237;&#31080;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#23545;&#25163;&#19981;&#26159;&#20219;&#24847;&#24178;&#25200;&#25972;&#20010;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#32780;&#26159;&#23545;&#35937;&#30340;&#26576;&#20010;&#23454;&#20307;&#30340;&#23376;&#38598;&#65288;&#20363;&#22914;&#20687;&#32032;&#65289;&#26102;&#65292;&#36890;&#36807;&#38543;&#26426;&#24179;&#28369;&#23545;&#36825;&#31181;&#22797;&#26434;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#65306;&#25105;&#20204;&#36890;&#36807;&#20165;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#23454;&#20307;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#26469;&#37096;&#20998;&#24179;&#28369;&#23545;&#35937;&#12290;&#36890;&#36807;&#20197;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#33719;&#24471;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#22122;&#22768;&#20998;&#24067;&#21021;&#22987;&#21270;&#20998;&#23618;&#24179;&#28369;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2211.07866</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21512;&#24182;&#19979;&#30340;&#32437;&#21521;&#32593;&#32476;&#26377;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient Estimation for Longitudinal Network via Adaptive Merging. (arXiv:2211.07866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#32593;&#32476;&#30001;&#22810;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#26102;&#38388;&#36793;&#24207;&#21015;&#32452;&#25104;&#65292;&#20854;&#20013;&#26102;&#38388;&#36793;&#22312;&#23454;&#26102;&#20013;&#34987;&#35266;&#23519;&#21040;&#12290;&#38543;&#30528;&#22312;&#32447;&#31038;&#20132;&#24179;&#21488;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#20852;&#36215;&#65292;&#23427;&#24050;&#32463;&#21464;&#24471;&#26222;&#36941;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#24448;&#24448;&#34987;&#24573;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#32593;&#32476;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#30340;&#20248;&#21183;&#12290;&#23427;&#21512;&#24182;&#30456;&#37051;&#30340;&#31232;&#30095;&#32593;&#32476;&#65292;&#20197;&#25193;&#22823;&#35266;&#27979;&#36793;&#30340;&#25968;&#37327;&#24182;&#20943;&#23569;&#20272;&#35745;&#26041;&#24046;&#65292;&#21516;&#26102;&#36890;&#36807;&#21033;&#29992;&#26412;&#22320;&#26102;&#38388;&#32467;&#26500;&#36827;&#34892;&#33258;&#36866;&#24212;&#32593;&#32476;&#37051;&#22495;&#25511;&#21046;&#24341;&#20837;&#30340;&#20272;&#35745;&#20559;&#24046;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20419;&#36827;&#20272;&#35745;&#65292;&#20854;&#20013;&#27599;&#27425;&#36845;&#20195;&#30340;&#20272;&#35745;&#38169;&#35823;&#19978;&#30028;&#34987;&#24314;&#31435;&#12290;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#65292;&#20197;&#37327;&#21270;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#21487;&#20197;&#26174;&#30528;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal network consists of a sequence of temporal edges among multiple nodes, where the temporal edges are observed in real time. It has become ubiquitous with the rise of online social platform and e-commerce, but largely under-investigated in literature. In this paper, we propose an efficient estimation framework for longitudinal network, leveraging strengths of adaptive network merging, tensor decomposition and point process. It merges neighboring sparse networks so as to enlarge the number of observed edges and reduce estimation variance, whereas the estimation bias introduced by network merging is controlled by exploiting local temporal structures for adaptive network neighborhood. A projected gradient descent algorithm is proposed to facilitate estimation, where the upper bound of the estimation error in each iteration is established. A thorough analysis is conducted to quantify the asymptotic behavior of the proposed method, which shows that it can significantly reduce the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;TSCI&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25506;&#32034;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;&#65292;&#24182;&#35843;&#25972;&#19981;&#21516;&#24418;&#24335;&#30340;&#20854;&#20182;&#24037;&#20855;&#21464;&#37327;&#20551;&#35774;&#36829;&#32972;&#65292;&#29992;&#20110;&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.12808</link><description>&lt;p&gt;
&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;: &#25506;&#32034;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Causal Inference with Invalid Instruments: Exploring Nonlinear Treatment Models with Machine Learning. (arXiv:2203.12808v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.12808
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;TSCI&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25506;&#32034;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;&#65292;&#24182;&#35843;&#25972;&#19981;&#21516;&#24418;&#24335;&#30340;&#20854;&#20182;&#24037;&#20855;&#21464;&#37327;&#20551;&#35774;&#36829;&#32972;&#65292;&#29992;&#20110;&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#19979;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#26080;&#25928;&#24037;&#20855;&#21464;&#37327;&#30340;&#35266;&#27979;&#30740;&#31350;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#20004;&#38454;&#27573;&#26354;&#29575;&#35782;&#21035;&#8221;(TSCI)&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25506;&#32034;&#38750;&#32447;&#24615;&#27835;&#30103;&#27169;&#22411;&#65292;&#24182;&#35843;&#25972;&#19981;&#21516;&#24418;&#24335;&#30340;&#20854;&#20182;&#24037;&#20855;&#21464;&#37327;&#20551;&#35774;&#36829;&#32972;&#12290;TSCI&#30340;&#25104;&#21151;&#38656;&#35201;&#24037;&#20855;&#21464;&#37327;&#23545;&#27835;&#30103;&#30340;&#24433;&#21709;&#19982;&#20854;&#36829;&#32972;&#24418;&#24335;&#19981;&#21516;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#27493;&#26032;&#39062;&#30340;&#20559;&#24046;&#26657;&#27491;&#26469;&#28040;&#38500;&#21487;&#33021;&#39640;&#22797;&#26434;&#24230;&#26426;&#22120;&#23398;&#20064;&#25152;&#36896;&#25104;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;TSCI&#20272;&#35745;&#22120;&#21363;&#20351;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#19981;&#33021;&#19968;&#33268;&#22320;&#20272;&#35745;&#27835;&#30103;&#27169;&#22411;&#65292;&#20063;&#34987;&#35777;&#26126;&#26159;&#28176;&#36827;&#26080;&#20559;&#21644;&#27491;&#24577;&#30340;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#25968;&#25454;&#20381;&#36182;&#26041;&#27861;&#26469;&#36873;&#25321;&#20960;&#20010;&#20505;&#36873;&#36829;&#32972;&#24418;&#24335;&#20013;&#30340;&#26368;&#20339;&#24418;&#24335;&#12290;&#25105;&#20204;&#24212;&#29992;TSCI&#30740;&#31350;&#20102;&#25945;&#32946;&#23545;&#25910;&#20837;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We discuss causal inference for observational studies with possibly invalid instrumental variables. We propose a novel methodology called two-stage curvature identification (TSCI), which explores the nonlinear treatment model with machine learning and adjusts for different forms of violating the instrumental variable assumptions. The success of TSCI requires the instrumental variable's effect on treatment to differ from its violation form. A novel bias correction step is implemented to remove bias resulting from potentially high complexity of machine learning. Our proposed TSCI estimator is shown to be asymptotically unbiased and normal even if the machine learning algorithm does not consistently estimate the treatment model. We design a data-dependent method to choose the best among several candidate violation forms. We apply TSCI to study the effect of education on earnings.
&lt;/p&gt;</description></item></channel></rss>