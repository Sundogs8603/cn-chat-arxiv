<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>PyVBMC&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;Python&#24037;&#20855;&#65292;&#29992;&#20110;&#40657;&#30418;&#35745;&#31639;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#27169;&#22411;&#36873;&#25321;&#65292;&#21487;&#20197;&#22788;&#29702;&#36830;&#32493;&#21442;&#25968;&#19981;&#36229;&#36807;&#32422;10-15&#20010;&#30340;&#35745;&#31639;&#25110;&#32479;&#35745;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.09519</link><description>&lt;p&gt;
PyVBMC&#65306;Python&#20013;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PyVBMC: Efficient Bayesian inference in Python. (arXiv:2303.09519v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09519
&lt;/p&gt;
&lt;p&gt;
PyVBMC&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;Python&#24037;&#20855;&#65292;&#29992;&#20110;&#40657;&#30418;&#35745;&#31639;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#27169;&#22411;&#36873;&#25321;&#65292;&#21487;&#20197;&#22788;&#29702;&#36830;&#32493;&#21442;&#25968;&#19981;&#36229;&#36807;&#32422;10-15&#20010;&#30340;&#35745;&#31639;&#25110;&#32479;&#35745;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PyVBMC&#26159;Variational Bayesian Monte Carlo&#65288;VBMC&#65289;&#31639;&#27861;&#30340;Python&#23454;&#29616;&#65292;&#29992;&#20110;&#40657;&#30418;&#35745;&#31639;&#27169;&#22411;&#30340;&#21518;&#39564;&#21644;&#27169;&#22411;&#25512;&#26029;&#12290;VBMC&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#25928;&#21442;&#25968;&#20272;&#35745;&#21644;&#27169;&#22411;&#35780;&#20272;&#30340;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#65292;&#24403;&#27169;&#22411;&#35780;&#20272;&#26159;&#26377;&#28857;&#21040;&#38750;&#24120;&#26114;&#36149;&#65288;&#20363;&#22914;&#31532;&#20108;&#27425;&#25110;&#26356;&#22810;&#27425;&#65289;&#21644;/&#25110;&#22024;&#26434;&#26102;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;VBMC&#35745;&#31639;&#65306;
&lt;/p&gt;
&lt;p&gt;
PyVBMC is a Python implementation of the Variational Bayesian Monte Carlo (VBMC) algorithm for posterior and model inference for black-box computational models (Acerbi, 2018, 2020). VBMC is an approximate inference method designed for efficient parameter estimation and model assessment when model evaluations are mildly-to-very expensive (e.g., a second or more) and/or noisy. Specifically, VBMC computes:  - a flexible (non-Gaussian) approximate posterior distribution of the model parameters, from which statistics and posterior samples can be easily extracted;  - an approximation of the model evidence or marginal likelihood, a metric used for Bayesian model selection.  PyVBMC can be applied to any computational or statistical model with up to roughly 10-15 continuous parameters, with the only requirement that the user can provide a Python function that computes the target log likelihood of the model, or an approximation thereof (e.g., an estimate of the likelihood obtained via simulation
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#37327;&#23376;&#35745;&#31639;&#20132;&#21449;&#39046;&#22495;&#20013;&#30340;&#21069;&#27839;&#30740;&#31350;&#26041;&#21521;&#65292;&#20855;&#26377;&#24212;&#29992;&#20110;&#37327;&#23376;&#26448;&#26009;&#12289;&#29983;&#29289;&#21270;&#23398;&#21644;&#39640;&#33021;&#29289;&#29702;&#31561;&#39046;&#22495;&#30340;&#28508;&#21147;&#65292;&#20294;&#20854;&#27169;&#22411;&#30340;&#21487;&#35757;&#32451;&#24615;&#20173;&#26377;&#25361;&#25112;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#35299;&#20915;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#24403;&#21069;QML&#26041;&#27861;&#19982;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;QML&#30340;&#37327;&#23376;&#20248;&#21183;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2303.09491</link><description>&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25361;&#25112;&#19982;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Challenges and Opportunities in Quantum Machine Learning. (arXiv:2303.09491v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09491
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#37327;&#23376;&#35745;&#31639;&#20132;&#21449;&#39046;&#22495;&#20013;&#30340;&#21069;&#27839;&#30740;&#31350;&#26041;&#21521;&#65292;&#20855;&#26377;&#24212;&#29992;&#20110;&#37327;&#23376;&#26448;&#26009;&#12289;&#29983;&#29289;&#21270;&#23398;&#21644;&#39640;&#33021;&#29289;&#29702;&#31561;&#39046;&#22495;&#30340;&#28508;&#21147;&#65292;&#20294;&#20854;&#27169;&#22411;&#30340;&#21487;&#35757;&#32451;&#24615;&#20173;&#26377;&#25361;&#25112;&#65292;&#38656;&#35201;&#36827;&#19968;&#27493;&#35299;&#20915;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#24403;&#21069;QML&#26041;&#27861;&#19982;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;QML&#30340;&#37327;&#23376;&#20248;&#21183;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#20301;&#20110;&#26426;&#22120;&#23398;&#20064;&#21644;&#37327;&#23376;&#35745;&#31639;&#30340;&#20132;&#21449;&#39046;&#22495;&#65292;&#20855;&#26377;&#21152;&#36895;&#25968;&#25454;&#20998;&#26512;&#30340;&#28508;&#21147;&#65292;&#29305;&#21035;&#26159;&#22312;&#37327;&#23376;&#25968;&#25454;&#24212;&#29992;&#20110;&#37327;&#23376;&#26448;&#26009;&#12289;&#29983;&#29289;&#21270;&#23398;&#21644;&#39640;&#33021;&#29289;&#29702;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;QML&#27169;&#22411;&#30340;&#21487;&#35757;&#32451;&#24615;&#20173;&#28982;&#23384;&#22312;&#25361;&#25112;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#24403;&#21069;&#30340;QML&#26041;&#27861;&#19982;&#24212;&#29992;&#65292;&#24182;&#31361;&#20986;&#20102;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#19982;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#37325;&#28857;&#20851;&#27880;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#21644;&#37327;&#23376;&#28145;&#24230;&#23398;&#20064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;QML&#30340;&#37327;&#23376;&#20248;&#21183;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
At the intersection of machine learning and quantum computing, Quantum Machine Learning (QML) has the potential of accelerating data analysis, especially for quantum data, with applications for quantum materials, biochemistry, and high-energy physics. Nevertheless, challenges remain regarding the trainability of QML models. Here we review current methods and applications for QML. We highlight differences between quantum and classical machine learning, with a focus on quantum neural networks and quantum deep learning. Finally, we discuss opportunities for quantum advantage with QML.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#24191;&#20041;&#31209;&#21644;&#39640;&#32500;&#24773;&#20917;&#19979;&#27491;&#21322;&#23450;&#30697;&#38453;&#21435;&#22122;&#38382;&#39064;&#30340;&#26799;&#24230;&#27969;&#65292;&#25581;&#31034;&#20102;&#20854;&#20013;&#30340;&#36830;&#32493;&#30456;&#21464;&#12290;</title><link>http://arxiv.org/abs/2303.09474</link><description>&lt;p&gt;
&#24191;&#20041;&#31209;&#27491;&#21322;&#23450;&#30697;&#38453;&#21435;&#22122;&#30340;&#26799;&#24230;&#27969;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Gradient flow on extensive-rank positive semi-definite matrix denoising. (arXiv:2303.09474v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#24191;&#20041;&#31209;&#21644;&#39640;&#32500;&#24773;&#20917;&#19979;&#27491;&#21322;&#23450;&#30697;&#38453;&#21435;&#22122;&#38382;&#39064;&#30340;&#26799;&#24230;&#27969;&#65292;&#25581;&#31034;&#20102;&#20854;&#20013;&#30340;&#36830;&#32493;&#30456;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#24191;&#20041;&#31209;&#21644;&#39640;&#32500;&#24773;&#20917;&#19979;&#27491;&#21322;&#23450;&#30697;&#38453;&#21435;&#22122;&#38382;&#39064;&#30340;&#26799;&#24230;&#27969;&#12290;&#25105;&#20204;&#20351;&#29992;&#26368;&#36817;&#30340;&#32447;&#24615;&#30697;&#38453;&#29702;&#35770;&#25216;&#26415;&#25512;&#23548;&#20986;&#22266;&#23450;&#28857;&#26041;&#31243;&#65292;&#36319;&#36394;&#38382;&#39064;&#30340;&#30697;&#38453;&#22343;&#26041;&#24046;&#30340;&#23436;&#25972;&#26102;&#38388;&#28436;&#21270;&#12290;&#25152;&#24471;&#21040;&#30340;&#22266;&#23450;&#28857;&#26041;&#31243;&#30340;&#39044;&#27979;&#32467;&#26524;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#24471;&#21040;&#39564;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#20030;&#20363;&#31616;&#35201;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#24418;&#24335;&#20027;&#20041;&#30340;&#20960;&#20010;&#39044;&#27979;&#65292;&#29305;&#21035;&#26159;&#25105;&#20204;&#25581;&#31034;&#20102;&#24191;&#20041;&#31209;&#21644;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#36830;&#32493;&#30456;&#21464;&#65292;&#36825;&#20123;&#30456;&#21464;&#22312;&#36866;&#24403;&#30340;&#26497;&#38480;&#19979;&#19982;&#20302;&#31209;&#38382;&#39064;&#30340;&#32463;&#20856;&#30456;&#21464;&#26377;&#20851;&#12290;&#35813;&#24418;&#24335;&#20027;&#20041;&#26377;&#27604;&#26412;&#25991;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present a new approach to analyze the gradient flow for a positive semi-definite matrix denoising problem in an extensive-rank and high-dimensional regime. We use recent linear pencil techniques of random matrix theory to derive fixed point equations which track the complete time evolution of the matrix-mean-square-error of the problem. The predictions of the resulting fixed point equations are validated by numerical experiments. In this short note we briefly illustrate a few predictions of our formalism by way of examples, and in particular we uncover continuous phase transitions in the extensive-rank and high-dimensional regime, which connect to the classical phase transitions of the low-rank problem in the appropriate limit. The formalism has much wider applicability than shown in this communication.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#32467;&#21512;&#31867;&#20013;&#24515;&#36317;&#31163;&#21644;&#24322;&#24120;&#20540;&#25240;&#25187;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615; &#12290;</title><link>http://arxiv.org/abs/2303.09470</link><description>&lt;p&gt;
&#32467;&#21512;&#31867;&#20013;&#24515;&#36317;&#31163;&#21644;&#24322;&#24120;&#20540;&#25240;&#25187;&#30340;&#26041;&#27861;&#65292;&#25552;&#39640;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Combining Distance to Class Centroids and Outlier Discounting for Improved Learning with Noisy Labels. (arXiv:2303.09470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#32467;&#21512;&#31867;&#20013;&#24515;&#36317;&#31163;&#21644;&#24322;&#24120;&#20540;&#25240;&#25187;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615; &#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#22312;&#29289;&#21697;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#24039;&#22937;&#22320;&#20351;&#29992;&#36317;&#31163;&#31867;&#20013;&#24515;&#30340;&#26041;&#27861;&#65292;&#20877;&#32467;&#21512;&#25240;&#25187;&#31574;&#30053;&#20197;&#20943;&#23569;&#36317;&#31163;&#25152;&#26377;&#31867;&#20013;&#24515;&#65288;&#21363;&#24322;&#24120;&#20540;&#65289;&#36828;&#30340;&#26679;&#26412;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#35299;&#20915;&#20102;&#22122;&#22768;&#26631;&#31614;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#36825;&#26679;&#30340;&#24819;&#27861;&#65306;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#36317;&#31163;&#21508;&#33258;&#31867;&#20013;&#24515;&#26356;&#36828;&#30340;&#26679;&#26412;&#26356;&#21487;&#33021;&#26159;&#22122;&#22768;&#12290;&#36890;&#36807;&#22312;&#20960;&#20010;&#27969;&#34892;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#26126;&#26174;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#34920;&#29616;&#20248;&#20110;&#24403;&#21069;&#39046;&#22495;&#30340;&#26368;&#20248;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a new approach for addressing the challenge of training machine learning models in the presence of noisy labels. By combining a clever usage of distance to class centroids in the items' latent space with a discounting strategy to reduce the importance of samples far away from all the class centroids (i.e., outliers), our method effectively addresses the issue of noisy labels. Our approach is based on the idea that samples farther away from their respective class centroid in the early stages of training are more likely to be noisy. We demonstrate the effectiveness of our method through extensive experiments on several popular benchmark datasets. Our results show that our approach outperforms the state-of-the-art in this area, achieving significant improvements in classification accuracy when the dataset contains noisy labels.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#22797;&#26434;&#24230;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#35299;&#20915;Bernoulli&#20998;&#24067;&#26368;&#20339;&#33218;&#35782;&#21035;&#31561;&#20219;&#21153;&#26102;&#26080;&#27861;&#23454;&#29616;&#32479;&#19968;&#26368;&#20339;&#21487;&#36798;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.09468</link><description>&lt;p&gt;
&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#30340;&#22797;&#26434;&#24230;&#23384;&#22312;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
On the Existence of a Complexity in Fixed Budget Bandit Identification. (arXiv:2303.09468v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09468
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#22797;&#26434;&#24230;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#35299;&#20915;Bernoulli&#20998;&#24067;&#26368;&#20339;&#33218;&#35782;&#21035;&#31561;&#20219;&#21153;&#26102;&#26080;&#27861;&#23454;&#29616;&#32479;&#19968;&#26368;&#20339;&#21487;&#36798;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22266;&#23450;&#39044;&#31639;&#36172;&#21338;&#26426;&#26631;&#35782;&#20013;&#65292;&#31639;&#27861;&#25353;&#39034;&#24207;&#35266;&#23519;&#26469;&#33258;&#22810;&#20010;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#30452;&#21040;&#32473;&#23450;&#26368;&#32456;&#26102;&#38388;&#12290;&#28982;&#21518;&#65292;&#23427;&#22238;&#31572;&#20851;&#20110;&#20998;&#24067;&#38598;&#30340;&#26597;&#35810;&#12290;&#19968;&#20010;&#22909;&#30340;&#31639;&#27861;&#23558;&#26377;&#23567;&#30340;&#38169;&#35823;&#27010;&#29575;&#12290;&#34429;&#28982;&#36825;&#20010;&#27010;&#29575;&#38543;&#30528;&#26368;&#32456;&#26102;&#38388;&#30340;&#22686;&#21152;&#21576;&#25351;&#25968;&#32423;&#19979;&#38477;&#65292;&#20294;&#23545;&#20110;&#22823;&#22810;&#25968;&#26631;&#35782;&#20219;&#21153;&#65292;&#26368;&#20339;&#21487;&#36798;&#29575;&#24182;&#38750;&#31934;&#30830;&#24050;&#30693;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#22266;&#23450;&#39044;&#31639;&#20219;&#21153;&#25509;&#21463;&#22797;&#26434;&#24230;&#65288;&#23450;&#20041;&#20026;&#21333;&#20010;&#31639;&#27861;&#22312;&#25152;&#26377;&#36172;&#21338;&#38382;&#39064;&#20013;&#23454;&#29616;&#30340;&#38169;&#35823;&#27010;&#29575;&#30340;&#19979;&#38480;&#65289;&#65292;&#21017;&#35813;&#22797;&#26434;&#24230;&#30001;&#35813;&#38382;&#39064;&#30340;&#26368;&#20339;&#38750;&#33258;&#36866;&#24212;&#25277;&#26679;&#36807;&#31243;&#30830;&#23450;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20960;&#20010;&#22266;&#23450;&#39044;&#31639;&#35782;&#21035;&#20219;&#21153;&#65292;&#21253;&#25324;&#20855;&#26377;&#20004;&#20010;&#33218;&#30340;&#20271;&#21162;&#21033;&#26368;&#20339;&#33218;&#35782;&#21035;&#65292;&#19981;&#23384;&#22312;&#36825;&#26679;&#30340;&#22797;&#26434;&#24230;&#65306;&#27809;&#26377;&#21333;&#20010;&#31639;&#27861;&#33021;&#22815;&#38543;&#22788;&#23454;&#29616;&#26368;&#20339;&#21487;&#33021;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In fixed budget bandit identification, an algorithm sequentially observes samples from several distributions up to a given final time. It then answers a query about the set of distributions. A good algorithm will have a small probability of error. While that probability decreases exponentially with the final time, the best attainable rate is not known precisely for most identification tasks. We show that if a fixed budget task admits a complexity, defined as a lower bound on the probability of error which is attained by a single algorithm on all bandit problems, then that complexity is determined by the best non-adaptive sampling procedure for that problem. We show that there is no such complexity for several fixed budget identification tasks including Bernoulli best arm identification with two arms: there is no single algorithm that attains everywhere the best possible rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#31946;&#38598;&#65292;&#31216;&#20026;&#25104;&#26412;&#24863;&#30693;&#27169;&#31946;&#38598;&#65292;&#23427;&#36890;&#36807;&#21322;&#31354;&#38388;&#23450;&#20041;&#65292;&#21482;&#25490;&#38500;&#37027;&#20123;&#39044;&#35745;&#23545;&#25152;&#33719;&#24471;&#30340;&#26368;&#22351;&#24773;&#20917;&#25104;&#26412;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#39640;&#32622;&#20449;&#24230;&#19978;&#30028;&#21644;&#19968;&#33268;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.09408</link><description>&lt;p&gt;
&#20351;&#29992;&#25104;&#26412;&#24863;&#30693;&#30340;&#27169;&#31946;&#38598;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Optimization using Cost-Aware Ambiguity Sets. (arXiv:2303.09408v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#31946;&#38598;&#65292;&#31216;&#20026;&#25104;&#26412;&#24863;&#30693;&#27169;&#31946;&#38598;&#65292;&#23427;&#36890;&#36807;&#21322;&#31354;&#38388;&#23450;&#20041;&#65292;&#21482;&#25490;&#38500;&#37027;&#20123;&#39044;&#35745;&#23545;&#25152;&#33719;&#24471;&#30340;&#26368;&#22351;&#24773;&#20917;&#25104;&#26412;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#39640;&#32622;&#20449;&#24230;&#19978;&#30028;&#21644;&#19968;&#33268;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#30340;&#27169;&#31946;&#38598;&#31867;&#21035;&#65292;&#31216;&#20026;&#25104;&#26412;&#24863;&#30693;&#30340;&#27169;&#31946;&#38598;&#65292;&#20854;&#23450;&#20041;&#20026;&#21462;&#20915;&#20110;&#22312;&#29420;&#31435;&#20272;&#35745;&#30340;&#26368;&#20248;&#35299;&#22788;&#35780;&#20272;&#25104;&#26412;&#20989;&#25968;&#30340;&#21322;&#31354;&#38388;&#65292;&#22240;&#27492;&#20165;&#25490;&#38500;&#37027;&#20123;&#39044;&#35745;&#23545;&#25152;&#33719;&#24471;&#30340;&#26368;&#22351;&#24773;&#20917;&#25104;&#26412;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30001;&#27492;&#20135;&#29983;&#30340;DRO&#26041;&#27861;&#25552;&#20379;&#20102;&#39640;&#32622;&#20449;&#24230;&#30340;&#19978;&#30028;&#21644;&#26679;&#26412;&#22806;&#39044;&#26399;&#25104;&#26412;&#30340;&#19968;&#33268;&#20272;&#35745;&#65292;&#24182;&#19988;&#32463;&#39564;&#35777;&#26126;&#65292;&#23427;&#19982;&#22522;&#20110;&#25955;&#24230;&#30340;&#27169;&#31946;&#38598;&#30456;&#27604;&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#23569;&#20445;&#23432;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel class of ambiguity sets for distributionally robust optimization (DRO). These ambiguity sets, called cost-aware ambiguity sets, are defined as halfspaces which depend on the cost function evaluated at an independent estimate of the optimal solution, thus excluding only those distributions that are expected to have significant impact on the obtained worst-case cost. We show that the resulting DRO method provides both a high-confidence upper bound and a consistent estimator of the out-of-sample expected cost, and demonstrate empirically that it results in less conservative solutions compared to divergence-based ambiguity sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#26426;&#22312;&#38169;&#35823;&#35268;&#23450;&#30340;&#24773;&#22659;&#19979;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#23558;&#22312;&#19968;&#23450;&#27700;&#24179;&#20869;&#35823;&#24046;&#21644;&#26368;&#23567;&#27425;&#20248;&#38388;&#38553;&#30456;&#20114;&#21046;&#32422;&#65292;&#20197;&#24120;&#25968;&#35823;&#24046;&#19978;&#38480;&#23454;&#29616;&#38388;&#38553;&#30456;&#20851;&#30340;&#24230;&#37327;&#12290;</title><link>http://arxiv.org/abs/2303.09390</link><description>&lt;p&gt;
&#20851;&#20110;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#26426;&#20013;&#38169;&#35823;&#35268;&#23450;&#19982;&#27425;&#20248;&#38388;&#38553;&#30340;&#30456;&#20114;&#20316;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Interplay Between Misspecification and Sub-optimality Gap in Linear Contextual Bandits. (arXiv:2303.09390v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09390
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#26426;&#22312;&#38169;&#35823;&#35268;&#23450;&#30340;&#24773;&#22659;&#19979;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#23558;&#22312;&#19968;&#23450;&#27700;&#24179;&#20869;&#35823;&#24046;&#21644;&#26368;&#23567;&#27425;&#20248;&#38388;&#38553;&#30456;&#20114;&#21046;&#32422;&#65292;&#20197;&#24120;&#25968;&#35823;&#24046;&#19978;&#38480;&#23454;&#29616;&#38388;&#38553;&#30456;&#20851;&#30340;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#24773;&#22659;&#36172;&#21338;&#26426;&#22312;&#38169;&#35823;&#35268;&#23450;&#30340;&#24773;&#22659;&#19979;&#65292;&#26399;&#26395;&#22870;&#21169;&#20989;&#25968;&#21487;&#20197;&#20197;&#32447;&#24615;&#20989;&#25968;&#31867;&#26469;&#36924;&#36817;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26032;&#30340;&#25968;&#25454;&#36873;&#25321;&#26041;&#26696;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20165;&#36873;&#25321;&#20855;&#26377;&#22823;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#22659;&#21521;&#37327;&#36827;&#34892;&#22312;&#32447;&#22238;&#24402;&#12290;&#24403;&#35823;&#24046;&#35268;&#23450;&#27700;&#24179;&#34987;$\zeta&gt;0$&#25511;&#21046;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#35823;&#24046;&#19978;&#38480;&#19982;&#22909;&#30340;&#25351;&#23450;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#30456;&#21516;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#29616;&#26377;&#30340;&#31639;&#27861;&#20063;&#21487;&#20197;&#22312;&#19981;&#30693;&#36947;&#20122;&#20248;&#38388;&#38553;$\Delta$&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#38388;&#38553;&#30456;&#20851;&#30340;&#24120;&#25968;&#35823;&#24046;&#19978;&#38480;&#12290;&#22312;Lattimore et al.&#65288;2020&#65289;&#30340;&#20316;&#21697;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#34920;&#26126;&#20102;&#38169;&#35823;&#35268;&#23450;&#21644;&#27425;&#20248;&#38388;&#38553;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study linear contextual bandits in the misspecified setting, where the expected reward function can be approximated by a linear function class up to a bounded misspecification level $\zeta&gt;0$. We propose an algorithm based on a novel data selection scheme, which only selects the contextual vectors with large uncertainty for online regression. We show that, when the misspecification level $\zeta$ is dominated by $\tilde O (\Delta / \sqrt{d})$ with $\Delta$ being the minimal sub-optimality gap and $d$ being the dimension of the contextual vectors, our algorithm enjoys the same gap-dependent regret bound $\tilde O (d^2/\Delta)$ as in the well-specified setting up to logarithmic factors. In addition, we show that an existing algorithm SupLinUCB (Chu et al., 2011) can also achieve a gap-dependent constant regret bound without the knowledge of sub-optimality gap $\Delta$. Together with a lower bound adapted from Lattimore et al. (2020), our result suggests an interplay between misspecific
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65288;DALUPI&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#23398;&#20064;&#20013;&#25918;&#23485;&#20551;&#35774;&#26465;&#20214;&#24182;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#36890;&#36807;&#20943;&#23569;&#38169;&#35823;&#26469;&#20419;&#36827;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#31561;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2303.09350</link><description>&lt;p&gt;
&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation by learning using privileged information. (arXiv:2303.09350v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09350
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65288;DALUPI&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#23398;&#20064;&#20013;&#25918;&#23485;&#20551;&#35774;&#26465;&#20214;&#24182;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#36890;&#36807;&#20943;&#23569;&#38169;&#35823;&#26469;&#20419;&#36827;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#31561;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21151;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#21482;&#22312;&#24378;&#20551;&#35774;&#26465;&#20214;&#19979;&#24471;&#20197;&#23454;&#29616;&#65292;&#22914;&#21327;&#21464;&#37327;&#31227;&#20301;&#21644;&#36755;&#20837;&#39046;&#22495;&#20043;&#38388;&#30340;&#37325;&#21472;&#12290;&#21518;&#32773;&#22312;&#39640;&#32500;&#24212;&#29992;&#20013;&#32463;&#24120;&#34987;&#36829;&#21453;&#65292;&#27604;&#22914;&#22270;&#20687;&#20998;&#31867;&#65292;&#22312;&#38754;&#23545;&#36825;&#31181;&#25361;&#25112;&#26102;&#65292;&#22270;&#20687;&#20998;&#31867;&#20173;&#28982;&#26159;&#31639;&#27861;&#24320;&#21457;&#30340;&#28789;&#24863;&#21644;&#22522;&#20934;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#33719;&#21462;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#26679;&#26412;&#30340;&#26377;&#20851;&#20449;&#24687;&#33021;&#22815;&#24110;&#21161;&#25918;&#23485;&#36825;&#20123;&#20551;&#35774;&#65292;&#24182;&#22312;&#23398;&#20064;&#20013;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#20195;&#20215;&#26159;&#25910;&#38598;&#26356;&#20016;&#23500;&#30340;&#21464;&#37327;&#38598;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65288;DALUPI&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#22810;&#26631;&#31614;&#22270;&#20687;&#20998;&#31867;&#30340;&#23454;&#29992;&#31471;&#21040;&#31471;&#31639;&#27861;&#65292;&#21463;&#21040;&#25105;&#20204;&#20998;&#26512;&#30340;&#21551;&#21457;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#21253;&#25324;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#29305;&#26435;&#20449;&#24687;&#21487;&#20197;&#20943;&#23569;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Successful unsupervised domain adaptation (UDA) is guaranteed only under strong assumptions such as covariate shift and overlap between input domains. The latter is often violated in high-dimensional applications such as image classification which, despite this challenge, continues to serve as inspiration and benchmark for algorithm development. In this work, we show that access to side information about examples from the source and target domains can help relax these assumptions and increase sample efficiency in learning, at the cost of collecting a richer variable set. We call this domain adaptation by learning using privileged information (DALUPI). Tailored for this task, we propose a simple two-stage learning algorithm inspired by our analysis and a practical end-to-end algorithm for multi-label image classification. In a suite of experiments, including an application to medical image analysis, we demonstrate that incorporating privileged information in learning can reduce errors i
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;ODCGM&#65292;&#21487;&#20197;&#20248;&#21270;&#22312;&#20809;&#28369;&#27969;&#24418;&#19978;&#26368;&#23567;&#21270;&#38750;&#20984;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#31639;&#27861;&#30340;&#23454;&#29616;&#35201;&#31616;&#21333;&#24471;&#22810;&#65292;&#24182;&#19988;&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#35823;&#24046;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#36873;&#25321;&#25237;&#24433;&#24230;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;Ablin &#21644; Peyr\'e (2022)&#30340;Landing&#31639;&#27861;&#65292;&#21518;&#32773;&#26159;&#19968;&#31181;&#26368;&#36817;&#29992;&#20110;&#20248;&#21270;Stiefel&#27969;&#24418;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.09261</link><description>&lt;p&gt;
&#27491;&#20132;&#26041;&#21521;&#32422;&#26463;&#26799;&#24230;&#27861;&#65306;&#20174;&#38750;&#32447;&#24615;&#31561;&#24335;&#32422;&#26463;&#21040;Stiefel&#27969;&#24418;
&lt;/p&gt;
&lt;p&gt;
Orthogonal Directions Constrained Gradient Method: from non-linear equality constraints to Stiefel manifold. (arXiv:2303.09261v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09261
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;ODCGM&#65292;&#21487;&#20197;&#20248;&#21270;&#22312;&#20809;&#28369;&#27969;&#24418;&#19978;&#26368;&#23567;&#21270;&#38750;&#20984;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#31639;&#27861;&#30340;&#23454;&#29616;&#35201;&#31616;&#21333;&#24471;&#22810;&#65292;&#24182;&#19988;&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#35823;&#24046;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#36873;&#25321;&#25237;&#24433;&#24230;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;Ablin &#21644; Peyr\'e (2022)&#30340;Landing&#31639;&#27861;&#65292;&#21518;&#32773;&#26159;&#19968;&#31181;&#26368;&#36817;&#29992;&#20110;&#20248;&#21270;Stiefel&#27969;&#24418;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#20809;&#28369;&#27969;&#24418; $\mathcal{M}$ &#19978;&#26368;&#23567;&#21270;&#19968;&#20010;&#38750;&#20984;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#27491;&#20132;&#26041;&#21521;&#32422;&#26463;&#26799;&#24230;&#27861;(ODCGM)&#65292;&#35813;&#31639;&#27861;&#21482;&#38656;&#35201;&#35745;&#31639;&#21521;&#37327;&#31354;&#38388;&#19978;&#30340;&#25237;&#24433;&#12290;ODCGM&#34429;&#28982;&#19981;&#21487;&#34892;&#65292;&#20294;&#36845;&#20195;&#36807;&#31243;&#22987;&#32456;&#34987;&#25289;&#21521;&#27969;&#24418;&#65292;&#30830;&#20445;&#20102;ODCGM&#25910;&#25947;&#21040; $\mathcal{M}$&#12290;&#30456;&#27604;&#38656;&#35201;&#35745;&#31639;&#25910;&#32553;&#31639;&#23376;&#30340;&#20256;&#32479;&#26041;&#27861;&#65292;ODCGM&#30340;&#23454;&#29616;&#35201;&#31616;&#21333;&#24471;&#22810;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;ODCGM&#22312;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#35823;&#24046;&#22797;&#26434;&#24230;&#65292;&#20998;&#21035;&#20026; $\mathcal{O}(1/\varepsilon^2)$ &#21644; $\mathcal{O}(1/\varepsilon^4)$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#36873;&#25321;&#25237;&#24433;&#24230;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20986;Ablin &#21644; Peyr\'e (2022)&#30340;Landing&#31639;&#27861;&#65292;&#21518;&#32773;&#26159;&#19968;&#31181;&#26368;&#36817;&#29992;&#20110;&#20248;&#21270;Stiefel&#27969;&#24418;&#30340;&#31639;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26174;&#33879;&#25193;&#23637;&#20102;Ablin &#21644; Peyr\'e&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of minimizing a non-convex function over a smooth manifold $\mathcal{M}$. We propose a novel algorithm, the Orthogonal Directions Constrained Gradient Method (ODCGM) which only requires computing a projection onto a vector space. ODCGM is infeasible but the iterates are constantly pulled towards the manifold, ensuring the convergence of ODCGM towards $\mathcal{M}$. ODCGM is much simpler to implement than the classical methods which require the computation of a retraction. Moreover, we show that ODCGM exhibits the near-optimal oracle complexities $\mathcal{O}(1/\varepsilon^2)$ and $\mathcal{O}(1/\varepsilon^4)$ in the deterministic and stochastic cases, respectively. Furthermore, we establish that, under an appropriate choice of the projection metric, our method recovers the landing algorithm of Ablin and Peyr\'e (2022), a recently introduced algorithm for optimization over the Stiefel manifold. As a result, we significantly extend the analysis of Ablin and Peyr\
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25968;&#23398;&#19978;&#28548;&#28165;&#20102;&#24102;&#26377;&#27010;&#24565;&#29942;&#39048;&#32467;&#26500;&#21644;&#22810;&#20219;&#21153;&#32452;&#25104;&#30340;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#27867;&#21270;&#35823;&#24046;&#21644;&#33258;&#30001;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.09154</link><description>&lt;p&gt;
&#24102;&#26377;&#27010;&#24565;&#29942;&#39048;&#32467;&#26500;&#21644;&#22810;&#20219;&#21153;&#32452;&#25104;&#30340;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#27867;&#21270;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Generalization Error in Linear Neural Networks with Concept Bottleneck Structure and Multitask Formulation. (arXiv:2303.09154v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25968;&#23398;&#19978;&#28548;&#28165;&#20102;&#24102;&#26377;&#27010;&#24565;&#29942;&#39048;&#32467;&#26500;&#21644;&#22810;&#20219;&#21153;&#32452;&#25104;&#30340;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#27867;&#21270;&#35823;&#24046;&#21644;&#33258;&#30001;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBM&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#27010;&#24565;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;CBM&#20013;&#65292;&#27010;&#24565;&#34987;&#25554;&#20837;&#21040;&#36755;&#20986;&#23618;&#21644;&#26368;&#21518;&#19968;&#20010;&#20013;&#38388;&#23618;&#20043;&#38388;&#20316;&#20026;&#21487;&#35266;&#23519;&#20540;&#12290;&#36825;&#26377;&#21161;&#20110;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#29983;&#25104;&#36755;&#20986;&#30340;&#21407;&#22240;&#65306;&#26368;&#21518;&#19968;&#20010;&#38544;&#34255;&#23618;&#21040;&#36755;&#20986;&#23618;&#30340;&#27010;&#24565;&#23545;&#24212;&#30340;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;&#22312;CBM&#20013;&#29702;&#35299;&#27867;&#21270;&#35823;&#24046;&#34892;&#20026;&#23578;&#19981;&#21487;&#33021;&#65292;&#22240;&#20026;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#26159;&#22855;&#24322;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#24403;&#27169;&#22411;&#26159;&#22855;&#24322;&#30340;&#26102;&#65292;&#20174;&#21442;&#25968;&#21040;&#27010;&#29575;&#20998;&#24067;&#30340;&#19968;&#19968;&#26144;&#23556;&#19981;&#33021;&#21019;&#24314;&#12290;&#36825;&#31181;&#19981;&#21487;&#35782;&#21035;&#24615;&#20351;&#24471;&#20998;&#26512;&#27867;&#21270;&#24615;&#33021;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#26412;&#27425;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25968;&#23398;&#19978;&#28548;&#28165;&#20102;CBM&#30340;&#36125;&#21494;&#26031;&#27867;&#21270;&#35823;&#24046;&#21644;&#33258;&#30001;&#33021;&#65292;&#24403;&#20854;&#26550;&#26500;&#26159;&#19977;&#23618;&#30340;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#26102;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#19968;&#20010;&#22810;&#20219;&#21153;&#38382;&#39064;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#19981;&#20877;&#21482;&#26159;&#19968;&#20010;&#26631;&#31614;&#65292;&#32780;&#26159;&#19968;&#32452;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Concept bottleneck model (CBM) is a ubiquitous method that can interpret neural networks using concepts. In CBM, concepts are inserted between the output layer and the last intermediate layer as observable values. This helps in understanding the reason behind the outputs generated by the neural networks: the weights corresponding to the concepts from the last hidden layer to the output layer. However, it has not yet been possible to understand the behavior of the generalization error in CBM since a neural network is a singular statistical model in general. When the model is singular, a one to one map from the parameters to probability distributions cannot be created. This non-identifiability makes it difficult to analyze the generalization performance. In this study, we mathematically clarify the Bayesian generalization error and free energy of CBM when its architecture is three-layered linear neural networks. We also consider a multitask problem where the neural network outputs not on
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#24179;&#28369;&#25903;&#25345;&#21521;&#37327;&#26426;&#38128;&#38142;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;Bernstein&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;BernSVM&#65289;&#65292;&#24182;&#25552;&#20986;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#27714;&#35299;&#35813;&#26041;&#27861;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#31454;&#20105;&#23545;&#25163;&#20013;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.09066</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#24809;&#32602;&#20271;&#24681;&#26031;&#22374;&#25903;&#25345;&#21521;&#37327;&#26426;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Penalized Bernstein Support Vector Machines. (arXiv:2303.09066v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09066
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#24179;&#28369;&#25903;&#25345;&#21521;&#37327;&#26426;&#38128;&#38142;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;Bernstein&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;BernSVM&#65289;&#65292;&#24182;&#25552;&#20986;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#27714;&#35299;&#35813;&#26041;&#27861;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#31454;&#20105;&#23545;&#25163;&#20013;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;(SVM)&#26159;&#19968;&#31181;&#29992;&#20110;&#20108;&#20998;&#31867;&#30340;&#24378;&#22823;&#20998;&#31867;&#22120;&#65292;&#20197;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#35774;&#32622;&#20013;&#65292;SVM&#38128;&#38142;&#25439;&#22833;&#20989;&#25968;&#30340;&#19981;&#21487;&#24494;&#24615;&#21487;&#33021;&#23548;&#33268;&#35745;&#31639;&#22256;&#38590;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20381;&#36182;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24179;&#28369;&#30340;SVM&#38128;&#38142;&#25439;&#22833;&#20989;&#25968;&#29256;&#26412;&#65292;&#31216;&#20026;Bernstein&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;BernSVM&#65289;&#65292;&#36866;&#29992;&#20110;&#39640;&#32500;$p&gt;&gt; n$&#24773;&#20917;&#12290;&#30001;&#20110;BernSVM&#30446;&#26631;&#25439;&#22833;&#20989;&#25968;&#23646;&#20110;$C^2$&#31867;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#35745;&#31639;&#24809;&#32602;BernSVM&#35299;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;&#31532;&#19968;&#20010;&#31639;&#27861;&#22522;&#20110;&#26368;&#22823;&#21270;-&#20027;&#23548;&#65288;MM&#65289;&#21407;&#29702;&#30340;&#22352;&#26631;&#19979;&#38477;&#27861;&#65292;&#31532;&#20108;&#20010;&#31639;&#27861;&#26159;IRLS&#31867;&#22411;&#31639;&#27861;&#65288;&#36845;&#20195;&#37325;&#26032;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#27861;&#65289;&#12290;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#38181;&#26465;&#20214;&#21644;&#19968;&#20010;&#38480;&#21046;&#24615;&#24378;&#20984;&#24615;&#65292;&#20197;&#24314;&#31435;&#21152;&#26435;Lasso BernSVM&#20272;&#35745;&#22120;&#30340;&#19978;&#30028;&#12290;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#36924;&#36817;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#27169;&#22411;&#36873;&#25321;&#26631;&#20934;&#65292;&#29992;&#20110;&#35843;&#25972;BernSVM&#36229;&#21442;&#25968;&#12290;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#29616;&#26377;&#31454;&#20105;&#23545;&#25163;&#20013;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The support vector machines (SVM) is a powerful classifier used for binary classification to improve the prediction accuracy. However, the non-differentiability of the SVM hinge loss function can lead to computational difficulties in high dimensional settings. To overcome this problem, we rely on Bernstein polynomial and propose a new smoothed version of the SVM hinge loss called the Bernstein support vector machine (BernSVM), which is suitable for the high dimension $p &gt;&gt; n$ regime. As the BernSVM objective loss function is of the class $C^2$, we propose two efficient algorithms for computing the solution of the penalized BernSVM. The first algorithm is based on coordinate descent with maximization-majorization (MM) principle and the second one is IRLS-type algorithm (iterative re-weighted least squares). Under standard assumptions, we derive a cone condition and a restricted strong convexity to establish an upper bound for the weighted Lasso BernSVM estimator. Using a local linear ap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992; kernel &#26041;&#27861;&#23398;&#20064;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#22522;&#24577;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#38656;&#35201;&#22810;&#39033;&#24335;&#36164;&#28304;&#23454;&#29616;&#65292;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.08902</link><description>&lt;p&gt;
&#29992; Kernel &#26041;&#27861;&#23398;&#20064;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#30340;&#22522;&#24577;
&lt;/p&gt;
&lt;p&gt;
Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992; kernel &#26041;&#27861;&#23398;&#20064;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#22522;&#24577;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#38656;&#35201;&#22810;&#39033;&#24335;&#36164;&#28304;&#23454;&#29616;&#65292;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#22522;&#24577;&#30340;&#26041;&#27861;&#38656;&#35201;&#35299;&#20915;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992; kernel &#26041;&#27861;&#26469;&#20351;&#20248;&#21270;&#21464;&#24471;&#31616;&#21333;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#26696;&#26159;&#21151;&#29575;&#27861;&#30340;&#19968;&#31181;&#36817;&#20284;&#23454;&#29616;&#65292;&#20854;&#20013;&#36890;&#36807;&#30417;&#30563;&#23398;&#20064;&#26469;&#23398;&#20064;&#21151;&#29575;&#36845;&#20195;&#30340;&#19979;&#19968;&#27493;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20551;&#35774;&#30417;&#30563;&#23398;&#20064;&#26159;&#26377;&#25928;&#30340;&#65292;&#37027;&#20040;&#21487;&#20197;&#20351;&#29992;&#22810;&#39033;&#24335;&#36164;&#28304;&#23454;&#29616;&#23545;&#20219;&#24847;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#30340;&#22522;&#24577;&#24615;&#36136;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#20351;&#29992; kernel ridge &#22238;&#24402;&#65292;&#36890;&#36807;&#23545;&#19968;&#32500;&#21644;&#20108;&#32500;&#30340;&#20960;&#20010;&#20856;&#22411;&#30456;&#20114;&#20316;&#29992;&#22810;&#20307;&#37327;&#23376;&#31995;&#32479;&#36827;&#34892;&#22522;&#24577;&#30340;&#23547;&#25214;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#25968;&#20540;&#27169;&#25311;&#30340;&#35777;&#25454;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network approaches to approximate the ground state of quantum hamiltonians require the numerical solution of a highly nonlinear optimization problem. We introduce a statistical learning approach that makes the optimization trivial by using kernel methods. Our scheme is an approximate realization of the power method, where supervised learning is used to learn the next step of the power iteration. We show that the ground state properties of arbitrary gapped quantum hamiltonians can be reached with polynomial resources under the assumption that the supervised learning is efficient. Using kernel ridge regression, we provide numerical evidence that the learning assumption is verified by applying our scheme to find the ground states of several prototypical interacting many-body quantum systems, both in one and two dimensions, showing the flexibility of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#36125;&#21494;&#26031;&#31215;&#20998;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#26550;&#26500;&#20284;&#28982;&#34920;&#38754;&#26377;&#20998;&#25955;&#12289;&#29421;&#31364;&#23792;&#26102;&#26500;&#24314;&#21152;&#26435;&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#65292;&#30456;&#27604;&#24403;&#21069;&#21516;&#31867;&#26041;&#27861;&#65292;&#22312;&#27979;&#35797;&#20284;&#28982;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#26041;&#38754;&#26356;&#20026;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2303.08874</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#31215;&#20998;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
Bayesian Quadrature for Neural Ensemble Search. (arXiv:2303.08874v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#36125;&#21494;&#26031;&#31215;&#20998;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#26550;&#26500;&#20284;&#28982;&#34920;&#38754;&#26377;&#20998;&#25955;&#12289;&#29421;&#31364;&#23792;&#26102;&#26500;&#24314;&#21152;&#26435;&#38598;&#25104;&#31070;&#32463;&#32593;&#32476;&#65292;&#30456;&#27604;&#24403;&#21069;&#21516;&#31867;&#26041;&#27861;&#65292;&#22312;&#27979;&#35797;&#20284;&#28982;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#26041;&#38754;&#26356;&#20026;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#22312;&#26550;&#26500;&#20284;&#28982;&#34920;&#38754;&#26377;&#20998;&#25955;&#12289;&#29421;&#31364;&#23792;&#26102;&#25928;&#26524;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#26500;&#24314;&#22343;&#31561;&#21152;&#26435;&#30340;&#38598;&#25104;&#65292;&#36825;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#36739;&#24369;&#26550;&#26500;&#30340;&#22833;&#25928;&#27169;&#24335;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23558;&#38598;&#25104;&#35270;&#20026;&#36817;&#20284;&#36793;&#32536;&#21270;&#26550;&#26500;&#65292;&#25105;&#20204;&#20351;&#29992;&#36125;&#21494;&#26031;&#31215;&#20998;&#30340;&#24037;&#20855;&#26500;&#24314;&#38598;&#25104;&#26041;&#27861;&#8212;&#8212;&#36825;&#20123;&#24037;&#20855;&#38750;&#24120;&#36866;&#21512;&#25506;&#32034;&#26550;&#26500;&#20284;&#28982;&#34920;&#38754;&#26377;&#20998;&#25955;&#12289;&#29421;&#31364;&#23792;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#30001;&#27492;&#20135;&#29983;&#30340;&#38598;&#25104;&#30001;&#20307;&#29616;&#20854;&#24615;&#33021;&#30340;&#26550;&#26500;&#21152;&#26435;&#26435;&#37325;&#32452;&#25104;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#8212;&#8212;&#22312;&#27979;&#35797;&#20284;&#28982;&#24615;&#12289;&#20934;&#30830;&#24615;&#21644;&#26399;&#26395;&#26657;&#20934;&#35823;&#24046;&#26041;&#38754;&#8212;&#8212;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#65292;&#24182;&#36890;&#36807;&#21066;&#20943;&#30740;&#31350;&#39564;&#35777;&#20854;&#21508;&#25104;&#20998;&#30340;&#29420;&#31435;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling can improve the performance of Neural Networks, but existing approaches struggle when the architecture likelihood surface has dispersed, narrow peaks. Furthermore, existing methods construct equally weighted ensembles, and this is likely to be vulnerable to the failure modes of the weaker architectures. By viewing ensembling as approximately marginalising over architectures we construct ensembles using the tools of Bayesian Quadrature -tools which are well suited to the exploration of likelihood surfaces with dispersed, narrow peaks. Additionally, the resulting ensembles consist of architectures weighted commensurate with their performance. We show empirically -- in terms of test likelihood, accuracy, and expected calibration error -that our method outperforms state-of-the-art baselines, and verify via ablation studies that its components do so independently.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29615;&#38754;&#22352;&#26631;&#31639;&#27861;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22278;&#20540;&#22270;&#24418;&#30340;&#20960;&#20309;&#30456;&#20851;&#24615;&#27010;&#24565;&#65292;&#24182;&#25551;&#36848;&#20102;&#19968;&#20010;&#31995;&#32479;&#24615;&#30340;&#36807;&#31243;&#65292;&#29992;&#20110;&#26500;&#24314;&#26368;&#23567;&#33021;&#37327;&#30340;&#29615;&#38754;&#20540;&#22270;&#12290;</title><link>http://arxiv.org/abs/2212.07201</link><description>&lt;p&gt;
&#29615;&#38754;&#22352;&#26631;&#65306;&#26684;&#28857;&#32422;&#21270;&#23454;&#29616;&#24490;&#29615;&#22352;&#26631;&#35299;&#32806;
&lt;/p&gt;
&lt;p&gt;
Toroidal Coordinates: Decorrelating Circular Coordinates With Lattice Reduction. (arXiv:2212.07201v2 [cs.CG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29615;&#38754;&#22352;&#26631;&#31639;&#27861;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22278;&#20540;&#22270;&#24418;&#30340;&#20960;&#20309;&#30456;&#20851;&#24615;&#27010;&#24565;&#65292;&#24182;&#25551;&#36848;&#20102;&#19968;&#20010;&#31995;&#32479;&#24615;&#30340;&#36807;&#31243;&#65292;&#29992;&#20110;&#26500;&#24314;&#26368;&#23567;&#33021;&#37327;&#30340;&#29615;&#38754;&#20540;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#29615;&#38754;&#22352;&#26631;&#31639;&#27861;&#30340;&#38382;&#39064;&#65292;&#30740;&#31350;&#21457;&#29616;&#24403;&#24212;&#29992;&#20110;&#22810;&#20010;&#19978;&#21516;&#35843;&#31867;&#26102;&#65292;&#21363;&#20351;&#25152;&#36873;&#23450;&#30340;&#19978;&#21516;&#35843;&#31867;&#26159;&#32447;&#24615;&#26080;&#20851;&#30340;&#65292;&#36755;&#20986;&#30340;&#29615;&#38754;&#20540;&#22270;&#20063;&#21487;&#33021;&#20250;&#34987;&#20960;&#20309;&#30456;&#20851;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#19978;&#21516;&#35843;&#31867;&#30340;&#25972;&#25968;&#32447;&#24615;&#32452;&#21512;&#21487;&#20197;&#33719;&#24471;&#36739;&#19981;&#30456;&#20851;&#30340;&#26144;&#23556;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22278;&#20540;&#22270;&#24418;&#30340;&#20960;&#20309;&#30456;&#20851;&#24615;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#22312;&#40654;&#26364;&#27969;&#24418;&#24773;&#20917;&#19979;&#23545;&#24212;&#20110;&#29380;&#21033;&#20811;&#38647;&#24418;&#24335;&#65292;&#36825;&#26159;&#20174;&#29380;&#21033;&#20811;&#38647;&#33021;&#37327;&#23548;&#20986;&#30340;&#21452;&#32447;&#24615;&#24418;&#24335;&#12290;&#20316;&#32773;&#25551;&#36848;&#20102;&#19968;&#20010;&#31995;&#32479;&#24615;&#30340;&#36807;&#31243;&#65292;&#29992;&#20110;&#26500;&#24314;&#26368;&#23567;&#33021;&#37327;&#30340;&#29615;&#38754;&#20540;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The circular coordinates algorithm of de Silva, Morozov, and Vejdemo-Johansson takes as input a dataset together with a cohomology class representing a $1$-dimensional hole in the data; the output is a map from the data into the circle that captures this hole, and that is of minimum energy in a suitable sense. However, when applied to several cohomology classes, the output circle-valued maps can be "geometrically correlated" even if the chosen cohomology classes are linearly independent. It is shown in the original work that less correlated maps can be obtained with suitable integer linear combinations of the cohomology classes, with the linear combinations being chosen by inspection. In this paper, we identify a formal notion of geometric correlation between circle-valued maps which, in the Riemannian manifold case, corresponds to the Dirichlet form, a bilinear form derived from the Dirichlet energy. We describe a systematic procedure for constructing low energy torus-valued maps on d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#20219;&#24847;&#23485;&#24230;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#38382;&#39064;&#65292;&#24403;&#36755;&#20837;&#20026;&#39640;&#26031;&#20998;&#24067;&#65292;&#30446;&#26631;&#20026;&#22810;&#25351;&#25968;&#27169;&#22411;&#26102;&#65292;NN&#30340;&#31532;&#19968;&#23618;&#26435;&#37325;&#20250;&#25910;&#25947;&#21040;&#30495;&#23454;&#27169;&#22411;&#20013;$k$&#32500;&#20027;&#23376;&#31354;&#38388;, &#21487;&#20197;&#36890;&#36807;&#22312;&#23376;&#31354;&#38388;&#19978;&#20351;&#29992;&#22343;&#21248;&#25910;&#25947;&#24314;&#31435;&#24191;&#20041;&#35823;&#24046;&#36793;&#30028;&#20026;$O(\sqrt{{kd}/{T}})$, SGD&#35757;&#32451;&#30340;ReLU NN&#21487;&#20197;&#23398;&#20064;&#24418;&#22914;$y = f(\langle\boldsymbol{u},\boldsymbol{x}\rangle)$&#30340;&#21333;&#25351;&#25968;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2209.14863</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26377;&#25928;&#22320;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Neural Networks Efficiently Learn Low-Dimensional Representations with SGD. (arXiv:2209.14863v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14863
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#20219;&#24847;&#23485;&#24230;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#38382;&#39064;&#65292;&#24403;&#36755;&#20837;&#20026;&#39640;&#26031;&#20998;&#24067;&#65292;&#30446;&#26631;&#20026;&#22810;&#25351;&#25968;&#27169;&#22411;&#26102;&#65292;NN&#30340;&#31532;&#19968;&#23618;&#26435;&#37325;&#20250;&#25910;&#25947;&#21040;&#30495;&#23454;&#27169;&#22411;&#20013;$k$&#32500;&#20027;&#23376;&#31354;&#38388;, &#21487;&#20197;&#36890;&#36807;&#22312;&#23376;&#31354;&#38388;&#19978;&#20351;&#29992;&#22343;&#21248;&#25910;&#25947;&#24314;&#31435;&#24191;&#20041;&#35823;&#24046;&#36793;&#30028;&#20026;$O(\sqrt{{kd}/{T}})$, SGD&#35757;&#32451;&#30340;ReLU NN&#21487;&#20197;&#23398;&#20064;&#24418;&#22914;$y = f(\langle\boldsymbol{u},\boldsymbol{x}\rangle)$&#30340;&#21333;&#25351;&#25968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#20219;&#24847;&#23485;&#24230;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;(NN)&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#36755;&#20837;$ \boldsymbol{x} \in \mathbb {R}^d $&#20026;&#39640;&#26031;&#20998;&#24067;&#65292;&#30446;&#26631;$ y \in \mathbb {R}$&#36981;&#24490;&#22810;&#25351;&#25968;&#27169;&#22411;&#65292;&#21363; $ y = g(\langle\boldsymbol{u_1},\boldsymbol{x}\rangle,...,\langle\boldsymbol{u_k},\boldsymbol{x}\rangle)$ &#65292;&#20854;&#20013;&#20989;&#25968;$g$&#20026;&#26377;&#22122;&#22768;&#30340;&#36830;&#25509;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#20351;&#29992;&#24102;&#26377;&#26435;&#37325;&#34928;&#20943;&#30340;&#22312;&#32447;SGD&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;NN&#30340;&#31532;&#19968;&#23618;&#26435;&#37325;&#20250;&#25910;&#25947;&#21040;&#30495;&#23454;&#27169;&#22411;&#20013;$ \boldsymbol{u_1},...,\boldsymbol{u_k}$&#30340;$k$&#32500;&#20027;&#23376;&#31354;&#38388;&#65292;&#24403;$k \ll d$ &#26102;&#65292;&#35813;&#29616;&#35937;&#26377;&#20960;&#20010;&#37325;&#35201;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#22312;&#36825;&#20010;&#26356;&#23567;&#30340;&#23376;&#31354;&#38388;&#19978;&#20351;&#29992;&#22343;&#21248;&#25910;&#25947;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22312;SGD&#36827;&#34892;$T$&#27425;&#36845;&#20195;&#21518;&#30340;&#24191;&#20041;&#35823;&#24046;&#36793;&#30028;&#20026;$ O(\sqrt{{kd}/{T}})$&#65292;&#36825;&#19981;&#20381;&#36182;&#20110;NN&#30340;&#23485;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;SGD&#35757;&#32451;&#30340;ReLU NN&#21487;&#20197;&#23398;&#20064;&#24418;&#22914;$y = f(\langle\boldsymbol{u},\boldsymbol{x}\rangle)$&#30340;&#21333;&#25351;&#25968;&#30446;&#26631;.
&lt;/p&gt;
&lt;p&gt;
We study the problem of training a two-layer neural network (NN) of arbitrary width using stochastic gradient descent (SGD) where the input $\boldsymbol{x}\in \mathbb{R}^d$ is Gaussian and the target $y \in \mathbb{R}$ follows a multiple-index model, i.e., $y=g(\langle\boldsymbol{u_1},\boldsymbol{x}\rangle,...,\langle\boldsymbol{u_k},\boldsymbol{x}\rangle)$ with a noisy link function $g$. We prove that the first-layer weights of the NN converge to the $k$-dimensional principal subspace spanned by the vectors $\boldsymbol{u_1},...,\boldsymbol{u_k}$ of the true model, when online SGD with weight decay is used for training. This phenomenon has several important consequences when $k \ll d$. First, by employing uniform convergence on this smaller subspace, we establish a generalization error bound of $O(\sqrt{{kd}/{T}})$ after $T$ iterations of SGD, which is independent of the width of the NN. We further demonstrate that, SGD-trained ReLU NNs can learn a single-index target of the form $y=f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20197;&#21450;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#24213;&#23618;&#20132;&#20114;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2207.06950</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#21644;&#25552;&#21319;&#26041;&#27861;&#25311;&#21512;&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA Models. (arXiv:2207.06950v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20197;&#21450;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#24213;&#23618;&#20132;&#20114;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;&#24050;&#32463;&#34987;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#21457;&#29616;&#65292;&#24182;&#31216;&#20043;&#20026;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#31867;&#20284;&#20110;EBM&#65292;&#20294;&#20855;&#26377;&#19968;&#20123;&#36235;&#21521;&#26356;&#22909;&#24615;&#33021;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#37319;&#29992;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#26641;&#65292;&#24182;&#34701;&#20837;&#19968;&#31181;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#23545;&#24213;&#23618;&#20132;&#20114;&#30340;&#25429;&#25417;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36845;&#20195;&#35757;&#32451;&#26041;&#27861;&#25910;&#25947;&#20110;&#20855;&#26377;&#26356;&#22909;&#39044;&#27979;&#24615;&#33021;&#30340;&#27169;&#22411;&#65292;&#24182;&#30830;&#20445;&#30456;&#20114;&#20316;&#29992;&#22312;&#20998;&#23618;&#24847;&#20041;&#19978;&#27491;&#20132;&#20110;&#20027;&#25928;&#24212;&#12290;&#35813;&#31639;&#27861;&#19981;&#38656;&#35201;&#24191;&#27867;&#30340;&#35843;&#25972;&#65292;&#24182;&#19988;&#23454;&#29616;&#24555;&#36895;&#39640;&#25928;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-order functional ANOVA (fANOVA) models have been rediscovered in the machine learning (ML) community under the guise of inherently interpretable machine learning. Explainable Boosting Machines or EBM (Lou et al. 2013) and GAMI-Net (Yang et al. 2021) are two recently proposed ML algorithms for fitting functional main effects and second-order interactions. We propose a new algorithm, called GAMI-Tree, that is similar to EBM, but has a number of features that lead to better performance. It uses model-based trees as base learners and incorporates a new interaction filtering method that is better at capturing the underlying interactions. In addition, our iterative training method converges to a model with better predictive performance, and the embedded purification ensures that interactions are hierarchically orthogonal to main effects. The algorithm does not need extensive tuning, and our implementation is fast and efficient. We use simulated and real datasets to compare the performanc
&lt;/p&gt;</description></item><item><title>FibeRed&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21521;&#37327;&#19995;&#25551;&#36848;&#25299;&#25169;&#22797;&#26434;&#25968;&#25454;&#30340;&#32420;&#32500;&#38477;&#32500;&#26041;&#27861;&#65292;&#21033;&#29992;&#35813;&#26041;&#27861;&#21487;&#20197;&#38477;&#20302;&#25968;&#25454;&#32500;&#24230;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#22823;&#35268;&#27169;&#25299;&#25169;&#29305;&#24449;&#12290;&#31639;&#27861;&#21253;&#21547;&#20174;&#23616;&#37096;&#32447;&#24615;&#38477;&#32500;&#24471;&#21040;&#30340;&#23616;&#37096;&#34920;&#31034;&#19982;&#21021;&#22987;&#20840;&#23616;&#34920;&#31034;&#30456;&#32467;&#21512;&#30340;&#36807;&#31243;&#65292;&#24182;&#22312;&#21160;&#21147;&#23398;&#31995;&#32479;&#21644;&#21270;&#23398;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2206.06513</link><description>&lt;p&gt;
FibeRed: &#36890;&#36807;&#21521;&#37327;&#19995;&#25551;&#36848;&#25299;&#25169;&#22797;&#26434;&#25968;&#25454;&#30340;&#32420;&#32500;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FibeRed: Fiberwise Dimensionality Reduction of Topologically Complex Data with Vector Bundles. (arXiv:2206.06513v2 [cs.CG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.06513
&lt;/p&gt;
&lt;p&gt;
FibeRed&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21521;&#37327;&#19995;&#25551;&#36848;&#25299;&#25169;&#22797;&#26434;&#25968;&#25454;&#30340;&#32420;&#32500;&#38477;&#32500;&#26041;&#27861;&#65292;&#21033;&#29992;&#35813;&#26041;&#27861;&#21487;&#20197;&#38477;&#20302;&#25968;&#25454;&#32500;&#24230;&#65292;&#21516;&#26102;&#20445;&#30041;&#20854;&#22823;&#35268;&#27169;&#25299;&#25169;&#29305;&#24449;&#12290;&#31639;&#27861;&#21253;&#21547;&#20174;&#23616;&#37096;&#32447;&#24615;&#38477;&#32500;&#24471;&#21040;&#30340;&#23616;&#37096;&#34920;&#31034;&#19982;&#21021;&#22987;&#20840;&#23616;&#34920;&#31034;&#30456;&#32467;&#21512;&#30340;&#36807;&#31243;&#65292;&#24182;&#22312;&#21160;&#21147;&#23398;&#31995;&#32479;&#21644;&#21270;&#23398;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#38750;&#24179;&#20961;&#22823;&#35268;&#27169;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#21487;&#33021;&#24456;&#38590;&#29992;&#29616;&#26377;&#30340;&#38477;&#32500;&#31639;&#27861;&#23884;&#20837;&#21040;&#20302;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21521;&#37327;&#19995;&#26469;&#27169;&#25311;&#20855;&#26377;&#25299;&#25169;&#22797;&#26434;&#24615;&#30340;&#25968;&#25454;&#38598;&#65292;&#36825;&#26679;&#22522;&#31354;&#38388;&#21487;&#20197;&#32771;&#34385;&#21040;&#22823;&#35268;&#27169;&#25299;&#25169;&#65292;&#32780;&#32420;&#32500;&#21487;&#20197;&#32771;&#34385;&#21040;&#23616;&#37096;&#20960;&#20309;&#12290;&#36825;&#20801;&#35768;&#25105;&#20204;&#38477;&#20302;&#32420;&#32500;&#30340;&#32500;&#24230;&#65292;&#21516;&#26102;&#20445;&#30041;&#22823;&#35268;&#27169;&#25299;&#25169;&#32467;&#26500;&#12290;&#25105;&#20204;&#24418;&#24335;&#21270;&#20102;&#36825;&#20010;&#35266;&#28857;&#65292;&#24182;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#25968;&#25454;&#38598;&#21450;&#20854;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#21021;&#22987;&#34920;&#31034;&#20316;&#20026;&#36755;&#20837;&#65292;&#20551;&#35774;&#23427;&#33021;&#24674;&#22797;&#37096;&#20998;&#22823;&#35268;&#27169;&#25299;&#25169;&#32467;&#26500;&#65292;&#24182;&#36755;&#20986;&#19968;&#20010;&#26032;&#34920;&#31034;&#65292;&#35813;&#34920;&#31034;&#23558;&#23616;&#37096;&#32447;&#24615;&#38477;&#32500;&#24471;&#21040;&#30340;&#23616;&#37096;&#34920;&#31034;&#19982;&#21021;&#22987;&#20840;&#23616;&#34920;&#31034;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#22312;&#21160;&#21147;&#23398;&#31995;&#32479;&#21644;&#21270;&#23398;&#39046;&#22495;&#30340;&#20363;&#23376;&#20013;&#35777;&#26126;&#20102;&#36825;&#20010;&#31639;&#27861;&#12290;&#22312;&#36825;&#20123;&#20363;&#23376;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#23398;&#20064;&#25299;&#25169;&#32467;&#26500;&#21644;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Datasets with non-trivial large scale topology can be hard to embed in low-dimensional Euclidean space with existing dimensionality reduction algorithms. We propose to model topologically complex datasets using vector bundles, in such a way that the base space accounts for the large scale topology, while the fibers account for the local geometry. This allows one to reduce the dimensionality of the fibers, while preserving the large scale topology. We formalize this point of view, and, as an application, we describe an algorithm which takes as input a dataset together with an initial representation of it in Euclidean space, assumed to recover part of its large scale topology, and outputs a new representation that integrates local representations, obtained through local linear dimensionality reduction, along the initial global representation. We demonstrate this algorithm on examples coming from dynamical systems and chemistry. In these examples, our algorithm is able to learn topologica
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#32420;&#32454;&#36817;&#20284;&#20110;&#35889;&#22270;&#30340;&#31232;&#30095;&#26469;&#20998;&#26512;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#20449;&#21495;&#20998;&#35299;&#21644;&#22810;&#23610;&#24230;&#20449;&#21495;&#20998;&#26512;&#26041;&#38754;&#26159;&#20808;&#36827;&#30340;&#12290;</title><link>http://arxiv.org/abs/2204.06108</link><description>&lt;p&gt;
SRMD&#65306;&#31232;&#30095;&#38543;&#26426;&#27169;&#24335;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
SRMD: Sparse Random Mode Decomposition. (arXiv:2204.06108v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.06108
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#32420;&#32454;&#36817;&#20284;&#20110;&#35889;&#22270;&#30340;&#31232;&#30095;&#26469;&#20998;&#26512;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#20449;&#21495;&#20998;&#35299;&#21644;&#22810;&#23610;&#24230;&#20449;&#21495;&#20998;&#26512;&#26041;&#38754;&#26159;&#20808;&#36827;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#21495;&#20998;&#35299;&#21644;&#22810;&#23610;&#24230;&#20449;&#21495;&#20998;&#26512;&#25552;&#20379;&#20102;&#35768;&#22810;&#29992;&#20110;&#26102;&#39057;&#20998;&#26512;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#29305;&#24449;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#32420;&#32454;&#36817;&#20284;&#20110;&#35889;&#22270;&#30340;&#31232;&#30095;&#26469;&#20998;&#26512;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#38543;&#26426;&#21270;&#21516;&#26102;&#21457;&#29983;&#22312;&#26102;&#38388;&#31383;&#21475;&#20301;&#32622;&#21644;&#39057;&#29575;&#37319;&#26679;&#19978;&#65292;&#36825;&#38477;&#20302;&#20102;&#24635;&#20307;&#37319;&#26679;&#21644;&#35745;&#31639;&#25104;&#26412;&#12290;&#35889;&#22270;&#30340;&#31232;&#30095;&#21270;&#23548;&#33268;&#26102;&#39057;&#32858;&#31867;&#20043;&#38388;&#30340;&#23574;&#38160;&#20998;&#31163;&#65292;&#20351;&#35782;&#21035;&#22266;&#26377;&#27169;&#24335;&#26356;&#23481;&#26131;&#65292;&#22240;&#27492;&#24341;&#23548;&#20102;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#24335;&#20998;&#35299;&#12290;&#24212;&#29992;&#21253;&#25324;&#20449;&#21495;&#34920;&#24449;&#65292;&#24322;&#24120;&#20540;&#21435;&#38500;&#21644;&#27169;&#24335;&#20998;&#35299;&#12290;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#20998;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signal decomposition and multiscale signal analysis provide many useful tools for time-frequency analysis. We proposed a random feature method for analyzing time-series data by constructing a sparse approximation to the spectrogram. The randomization is both in the time window locations and the frequency sampling, which lowers the overall sampling and computational cost. The sparsification of the spectrogram leads to a sharp separation between time-frequency clusters which makes it easier to identify intrinsic modes, and thus leads to a new data-driven mode decomposition. The applications include signal representation, outlier removal, and mode decomposition. On the benchmark tests, we show that our approach outperforms other state-of-the-art decomposition methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#26469;&#22788;&#29702;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#65292;&#23545;&#21463;&#38480;&#31561;&#36317;&#24120;&#25968;&#30340;&#38480;&#21046;&#35201;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#21482;&#35201;&#26080;&#22122;&#22768;&#30446;&#26631;&#30340;&#21463;&#38480;&#31561;&#36317;&#26465;&#20214;&#23567;&#20110;1/3&#65292;&#20219;&#20309;&#38169;&#35823;&#30340;&#23616;&#37096;&#20248;&#21270;&#35299;&#24517;&#39035;&#25509;&#36817;&#20110;&#30495;&#23454;&#35299;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25214;&#21040;&#36817;&#20284;&#35299;&#12290;</title><link>http://arxiv.org/abs/2203.03899</link><description>&lt;p&gt;
&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#20248;&#21270;: &#23616;&#37096;&#26497;&#23567;&#20540;&#30340;&#20960;&#20309;&#24418;&#29366;&#21644;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Noisy Low-rank Matrix Optimization: Geometry of Local Minima and Convergence Rate. (arXiv:2203.03899v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.03899
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#26469;&#22788;&#29702;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#65292;&#23545;&#21463;&#38480;&#31561;&#36317;&#24120;&#25968;&#30340;&#38480;&#21046;&#35201;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#21482;&#35201;&#26080;&#22122;&#22768;&#30446;&#26631;&#30340;&#21463;&#38480;&#31561;&#36317;&#26465;&#20214;&#23567;&#20110;1/3&#65292;&#20219;&#20309;&#38169;&#35823;&#30340;&#23616;&#37096;&#20248;&#21270;&#35299;&#24517;&#39035;&#25509;&#36817;&#20110;&#30495;&#23454;&#35299;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25214;&#21040;&#36817;&#20284;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#20302;&#31209;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#24191;&#27867;&#12290;&#22312;&#30697;&#38453;&#24863;&#30693;&#29305;&#20363;&#20013;&#65292;&#35813;&#38382;&#39064;&#24050;&#32463;&#36890;&#36807;&#21463;&#38480;&#31561;&#36317;&#24615;&#36136;&#30340;&#27010;&#24565;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#23548;&#33268;&#20102;&#22823;&#37327;&#20851;&#20110;&#38382;&#39064;&#30340;&#20960;&#20309;&#26223;&#35266;&#21644;&#24120;&#35265;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#20165;&#22312;&#21463;&#38480;&#31561;&#36317;&#24120;&#25968;&#25509;&#36817;&#20110;0&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#22788;&#29702;&#20165;&#20855;&#26377;&#22122;&#22768;&#25968;&#25454;&#30340;&#19968;&#33324;&#30446;&#26631;&#20989;&#25968;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#26469;&#35299;&#20915;&#20197;&#19978;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#23545;&#21463;&#38480;&#31561;&#36317;&#24120;&#25968;&#30340;&#38480;&#21046;&#35201;&#23569;&#24471;&#22810;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#26080;&#22122;&#22768;&#30446;&#26631;&#30340;&#21463;&#38480;&#31561;&#36317;&#26465;&#20214;&#23567;&#20110;1/3&#65292;&#20219;&#20309;&#38169;&#35823;&#30340;&#23616;&#37096;&#20248;&#21270;&#35299;&#24517;&#39035;&#25509;&#36817;&#20110;&#30495;&#23454;&#35299;&#12290;&#36890;&#36807;&#20005;&#26684;&#30340;&#38797;&#28857;&#29305;&#24615;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#25214;&#21040;&#36817;&#20284;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is concerned with low-rank matrix optimization, which has found a wide range of applications in machine learning. This problem in the special case of matrix sensing has been studied extensively through the notion of Restricted Isometry Property (RIP), leading to a wealth of results on the geometric landscape of the problem and the convergence rate of common algorithms. However, the existing results can handle the problem in the case with a general objective function subject to noisy data only when the RIP constant is close to 0. In this paper, we develop a new mathematical framework to solve the above-mentioned problem with a far less restrictive RIP constant. We prove that as long as the RIP constant of the noiseless objective is less than $1/3$, any spurious local solution of the noisy optimization problem must be close to the ground truth solution. By working through the strict saddle property, we also show that an approximate solution can be found in polynomial time. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#22823;&#35268;&#27169;&#39564;&#35777;&#39033;&#30446;&#22240;&#32032;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#19982;&#25311;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#21644;&#25193;&#23637;&#27979;&#35797;&#19982;&#25351;&#26631;&#65292;&#20855;&#26377;&#39640;&#25928;&#20934;&#30830;&#21644;&#26377;&#25928;&#24615;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2109.09500</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22823;&#35268;&#27169;&#39564;&#35777;&#39033;&#30446;&#22240;&#32032;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#25311;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Deep Learning-Based Estimation and Goodness-of-Fit for Large-Scale Confirmatory Item Factor Analysis. (arXiv:2109.09500v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.09500
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#22823;&#35268;&#27169;&#39564;&#35777;&#39033;&#30446;&#22240;&#32032;&#20998;&#26512;&#30340;&#21442;&#25968;&#20272;&#35745;&#19982;&#25311;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#21644;&#25193;&#23637;&#27979;&#35797;&#19982;&#25351;&#26631;&#65292;&#20855;&#26377;&#39640;&#25928;&#20934;&#30830;&#21644;&#26377;&#25928;&#24615;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#22823;&#35268;&#27169;&#39564;&#35777;&#39033;&#30446;&#22240;&#32032;&#20998;&#26512;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#25311;&#21512;&#24230;&#26816;&#39564;&#26041;&#27861;&#12290;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#65292;&#25105;&#20204;&#23558;Urban&#21644;Bauer&#65288;2021&#65289;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#25193;&#23637;&#21040;&#39564;&#35777;&#24615;&#22240;&#32032;&#20998;&#26512;&#39046;&#22495;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#22788;&#29702;&#22240;&#23376;&#36733;&#33655;&#21644;&#22240;&#23376;&#30456;&#20851;&#24615;&#30340;&#38480;&#21046;&#12290;&#23545;&#20110;&#25311;&#21512;&#24230;&#26816;&#39564;&#65292;&#25105;&#20204;&#25506;&#32034;&#22522;&#20110;&#27169;&#25311;&#30340;&#27979;&#35797;&#21644;&#25351;&#26631;&#65292;&#25193;&#23637;&#20102;&#20998;&#31867;&#22120;&#20004;&#20010;&#26679;&#26412;&#27979;&#35797;&#65288;C2ST&#65289;&#65292;&#35813;&#26041;&#27861;&#27979;&#35797;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#33021;&#21542;&#21306;&#20998;&#26469;&#33258;&#25311;&#21512;&#30340;IFA&#27169;&#22411;&#30340;&#35266;&#27979;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#12290;&#25152;&#25552;&#20986;&#30340;&#25193;&#23637;&#21253;&#25324;&#36817;&#20284;&#25311;&#21512;&#26816;&#39564;&#65292;&#20854;&#20013;&#29992;&#25143;&#25351;&#23450;&#35266;&#27979;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#20013;&#24212;&#26377;&#22810;&#23569;&#21344;&#21487;&#21306;&#20998;&#37096;&#20998;&#30340;&#30334;&#20998;&#27604;&#65292;&#20197;&#21450;&#30456;&#23545;&#25311;&#21512;&#25351;&#25968;&#65288;RFI&#65289;&#65292;&#35813;&#25351;&#25968;&#31867;&#20284;&#20110;&#32467;&#26500;&#26041;&#31243;&#24314;&#27169;&#20013;&#20351;&#29992;&#30340;RFI&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65306;&#65288;1&#65289;Urban&#21644;Bauer&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#39564;&#35777;&#24615;&#25193;&#23637;&#21363;&#20351;&#23384;&#22312;&#39640;&#30456;&#20851;&#22240;&#23376;&#20063;&#21487;&#20197;&#20934;&#30830;&#22320;&#20272;&#35745;&#27169;&#22411;&#21442;&#25968;&#65307;&#65288;2&#65289;&#25152;&#25552;&#20986;&#30340;&#25311;&#21512;&#24230;&#25351;&#26631;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#27169;&#22411;&#19981;&#33391;&#25311;&#21512;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#23545;&#20110;&#22823;&#35268;&#27169;&#39564;&#35777;IFA&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate novel parameter estimation and goodness-of-fit (GOF) assessment methods for large-scale confirmatory item factor analysis (IFA) with many respondents, items, and latent factors. For parameter estimation, we extend Urban and Bauer's (2021) deep learning algorithm for exploratory IFA to the confirmatory setting by showing how to handle constraints on loadings and factor correlations. For GOF assessment, we explore simulation-based tests and indices that extend the classifier two-sample test (C2ST), a method that tests whether a deep neural network can distinguish between observed data and synthetic data sampled from a fitted IFA model. Proposed extensions include a test of approximate fit wherein the user specifies what percentage of observed and synthetic data should be distinguishable as well as a relative fit index (RFI) that is similar in spirit to the RFIs used in structural equation modeling. Via simulation studies, we show that: (1) the confirmatory extension of Urb
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#30340;&#39034;&#24207;&#20108;&#27425;&#20248;&#21270;&#31639;&#27861;&#65292;&#20855;&#22791;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#21644;&#22788;&#29702;&#31209;&#32570;&#22833;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.13015</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#31209;&#32570;&#22833;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#38750;&#32447;&#24615;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#30340;&#38543;&#26426;&#39034;&#24207;&#20108;&#27425;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Stochastic Sequential Quadratic Optimization Algorithm for Nonlinear Equality Constrained Optimization with Rank-Deficient Jacobians. (arXiv:2106.13015v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.13015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#30340;&#39034;&#24207;&#20108;&#27425;&#20248;&#21270;&#31639;&#27861;&#65292;&#20855;&#22791;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#21644;&#22788;&#29702;&#31209;&#32570;&#22833;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#33021;&#21147;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#23450;&#20041;&#20026;&#38543;&#26426;&#20989;&#25968;&#26399;&#26395;&#30340;&#24179;&#28369;&#38750;&#32447;&#24615;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#39034;&#24207;&#20108;&#27425;&#20248;&#21270;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#30340;&#32467;&#26500;&#22522;&#20110;&#19968;&#31181;&#22312;&#25991;&#29486;&#19978;&#34987;&#24191;&#27867;&#35777;&#26126;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#26377;&#25928;&#30340;&#27493;&#39588;&#20998;&#35299;&#31574;&#30053;&#65292;&#20854;&#20013;&#27599;&#20010;&#25628;&#32034;&#26041;&#21521;&#34987;&#35745;&#31639;&#20026;&#27491;&#24120;&#27493;&#39588;&#65288;&#26397;&#21521;&#32447;&#24615;&#21270;&#21487;&#34892;&#24615;&#65289;&#21644;&#20999;&#21521;&#27493;&#39588;&#65288;&#26397;&#21521;&#32422;&#26463;&#38597;&#21487;&#27604;&#30697;&#38453;&#38646;&#31354;&#38388;&#20869;&#30446;&#26631;&#19979;&#38477;&#65289;&#30340;&#24635;&#21644;&#12290;&#28982;&#32780;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#25991;&#29486;&#20013;&#26159;&#29420;&#19968;&#26080;&#20108;&#30340;&#65292;&#22240;&#20026;&#23427;&#26082;&#20801;&#35768;&#20351;&#29992;&#38543;&#26426;&#30446;&#26631;&#26799;&#24230;&#20272;&#35745;&#65292;&#21448;&#22312;&#32422;&#26463;&#38597;&#21487;&#27604;&#30697;&#38453;&#21487;&#33021;&#31209;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#25910;&#25947;&#20445;&#35777;&#12290; &#25968;&#20540;&#23454;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#27969;&#34892;&#30340;&#26367;&#20195;&#26041;&#26696;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A sequential quadratic optimization algorithm is proposed for solving smooth nonlinear equality constrained optimization problems in which the objective function is defined by an expectation of a stochastic function. The algorithmic structure of the proposed method is based on a step decomposition strategy that is known in the literature to be widely effective in practice, wherein each search direction is computed as the sum of a normal step (toward linearized feasibility) and a tangential step (toward objective decrease in the null space of the constraint Jacobian). However, the proposed method is unique from others in the literature in that it both allows the use of stochastic objective gradient estimates and possesses convergence guarantees even in the setting in which the constraint Jacobians may be rank deficient. The results of numerical experiments demonstrate that the algorithm offers superior performance when compared to popular alternatives.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36816;&#29992;&#25968;&#23398;&#21644;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#23601; ReLU &#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#19979;&#30028;&#20570;&#20102;&#25506;&#31350;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#32943;&#23450;&#20102;&#19968;&#39033;&#26087;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#29468;&#24819;&#12290;</title><link>http://arxiv.org/abs/2105.14835</link><description>&lt;p&gt;
&#20851;&#20110; ReLU &#31070;&#32463;&#32593;&#32476;&#28145;&#24230;&#19979;&#30028;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Lower Bounds on the Depth of ReLU Neural Networks. (arXiv:2105.14835v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.14835
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36816;&#29992;&#25968;&#23398;&#21644;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#23601; ReLU &#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#19979;&#30028;&#20570;&#20102;&#25506;&#31350;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#31181;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#35813;&#30740;&#31350;&#36824;&#32943;&#23450;&#20102;&#19968;&#39033;&#26087;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#29468;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36816;&#29992;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#12289;&#22810;&#38754;&#20307;&#29702;&#35770;&#21644;&#28909;&#24102;&#20960;&#20309;&#23398;&#31561;&#25216;&#26415;&#65292;&#20026;&#29702;&#35299;&#20855;&#26377; ReLU &#28608;&#27963;&#21644;&#32473;&#23450;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#25152;&#33021;&#34920;&#31034;&#30340;&#20989;&#25968;&#31867;&#20570;&#20986;&#20102;&#26356;&#22909;&#30340;&#36129;&#29486;&#12290;&#23613;&#31649;&#26222;&#36866;&#36924;&#36817;&#23450;&#29702;&#35748;&#20026;&#21333;&#23618;&#38544;&#34255;&#23618;&#23601;&#36275;&#20197;&#23398;&#20064;&#20219;&#20309;&#20989;&#25968;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#23398;&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#35814;&#32454;&#25506;&#35752;&#20102;&#28155;&#21152;&#26356;&#22810;&#23618;&#65288;&#26080;&#22823;&#23567;&#38480;&#21046;&#65289;&#26102;&#26159;&#21542;&#20005;&#26684;&#22686;&#21152;&#20102;&#21487;&#34920;&#31034;&#20989;&#25968;&#30340;&#31867;&#12290;&#20316;&#20026;&#30740;&#31350;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#32943;&#23450;&#20102; Wang &#21644; Sun&#65288;2005&#65289;&#26377;&#20851;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#30340;&#19968;&#20010;&#26087;&#29468;&#24819;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#34920;&#31034;&#20855;&#26377;&#23545;&#25968;&#28145;&#24230;&#20989;&#25968;&#25152;&#38656;&#30340;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We contribute to a better understanding of the class of functions that can be represented by a neural network with ReLU activations and a given architecture. Using techniques from mixed-integer optimization, polyhedral theory, and tropical geometry, we provide a mathematical counterbalance to the universal approximation theorems which suggest that a single hidden layer is sufficient for learning any function. In particular, we investigate whether the class of exactly representable functions strictly increases by adding more layers (with no restrictions on size). As a by-product of our investigations, we settle an old conjecture about piecewise linear functions by Wang and Sun (2005) in the affirmative. We also present upper bounds on the sizes of neural networks required to represent functions with logarithmic depth.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#38169;&#35823;&#23450;&#20301;&#20960;&#20309;&#20998;&#26512;&#31639;&#27861;&#21644;&#36830;&#32493;&#23376;&#31354;&#38388;&#20248;&#21270;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#31934;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#32422;&#26463;&#31561;&#24322;&#24615;&#24615;&#36136;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20840;&#23616;&#26368;&#20248;&#35299;&#19982;&#23616;&#37096;&#35299;&#20043;&#38388;&#30340;&#26368;&#22823;&#36317;&#31163;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2105.08232</link><description>&lt;p&gt;
&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#20960;&#20309;&#20998;&#26512;&#22312;&#31934;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#21306;&#38388;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Geometric Analysis of Noisy Low-rank Matrix Recovery in the Exact Parameterized and the Overparameterized Regimes. (arXiv:2105.08232v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.08232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#38169;&#35823;&#23450;&#20301;&#20960;&#20309;&#20998;&#26512;&#31639;&#27861;&#21644;&#36830;&#32493;&#23376;&#31354;&#38388;&#20248;&#21270;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#31934;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#32422;&#26463;&#31561;&#24322;&#24615;&#24615;&#36136;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20840;&#23616;&#26368;&#20248;&#35299;&#19982;&#23616;&#37096;&#35299;&#20043;&#38388;&#30340;&#26368;&#22823;&#36317;&#31163;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#20302;&#31209;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#30697;&#38453;&#34917;&#20840;&#12289;&#30456;&#20301;&#21516;&#27493;/&#24674;&#22797;&#12289;&#31283;&#20581;PCA&#21644;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#20272;&#35745;&#31561;&#39046;&#22495;&#37117;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32447;&#24615;&#27979;&#37327;&#25439;&#22351;&#30340;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#25628;&#32034;&#31209;r&#31561;&#20110;&#26410;&#30693;&#30495;&#23454;&#31209;r*&#30340;&#24773;&#20917;&#65288;&#31934;&#30830;&#21442;&#25968;&#21270;&#24773;&#20917;&#65289;&#65292;&#20197;&#21450;r&#22823;&#20110;r*&#30340;&#24773;&#20917;&#65288;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#65289;&#12290;&#25105;&#20204;&#37327;&#21270;&#20102;&#32422;&#26463;&#31561;&#24322;&#24615;&#24615;&#36136;&#65288;restricted isometry property&#65292;RIP&#65289;&#22312;&#22609;&#36896;&#38750;&#20984;&#20998;&#35299;&#20844;&#24335;&#30340;&#25972;&#20307;&#26223;&#35266;&#21644;&#24110;&#21161;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#25104;&#21151;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;RIP&#24120;&#25968;&#23567;&#20110; 1/(1+sqrt(r*/r))&#30340;&#20551;&#35774;&#19979;&#65292;&#23545;&#38750;&#20984;&#38382;&#39064;&#30340;&#20219;&#24847;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#30495;&#23454;&#20540;&#20043;&#38388;&#30340;&#26368;&#22823;&#36317;&#31163;&#36827;&#34892;&#20102;&#20840;&#23616;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#40065;&#26834;&#38169;&#35823;&#23450;&#20301;&#20960;&#20309;&#20998;&#26512;&#65288;Robust Error-Locating Geometric Analysis&#65292;RELGA&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#23454;&#29616;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#12290;RELGA&#31639;&#27861;&#36890;&#36807;&#32452;&#21512;&#38169;&#35823;&#23450;&#20301;&#26426;&#21046;&#21644;&#20960;&#20309;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#21363;&#20351;&#22312;&#22122;&#22768;&#27700;&#24179;&#30456;&#23545;&#36739;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#23454;&#29616;&#31934;&#30830;&#30340;&#30697;&#38453;&#24674;&#22797;&#12290;&#23545;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#65292;&#31216;&#20026;&#36830;&#32493;&#23376;&#31354;&#38388;&#20248;&#21270;&#65288;Successive Subspace Optimization&#65292;SSO&#65289;&#31639;&#27861;&#65292;&#22312;&#22122;&#22768;&#27700;&#24179;&#21644;RIP&#24120;&#25968;&#30340;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#25910;&#25947;&#21040;&#30495;&#23454;&#35299;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;SSO&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#21021;&#22987;&#21270;&#12289;&#38750;&#36864;&#21270;&#24615;&#21644;&#20960;&#20309;&#26465;&#20214;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The matrix sensing problem is an important low-rank optimization problem that has found a wide range of applications, such as matrix completion, phase synchornization/retrieval, robust PCA, and power system state estimation. In this work, we focus on the general matrix sensing problem with linear measurements that are corrupted by random noise. We investigate the scenario where the search rank $r$ is equal to the true rank $r^*$ of the unknown ground truth (the exact parametrized case), as well as the scenario where $r$ is greater than $r^*$ (the overparametrized case). We quantify the role of the restricted isometry property (RIP) in shaping the landscape of the non-convex factorized formulation and assisting with the success of local search algorithms. First, we develop a global guarantee on the maximum distance between an arbitrary local minimizer of the non-convex problem and the ground truth under the assumption that the RIP constant is smaller than $1/(1+\sqrt{r^*/r})$. We then p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#20572;&#26102;&#38382;&#39064;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#32467;&#21512;&#24494;&#35266;&#32463;&#27982;&#23398;&#20013;&#30340;Bayesian&#25581;&#31034;&#20559;&#22909;&#24605;&#36335;&#65292;&#36890;&#36807;&#35266;&#23519;Bayesian&#20915;&#31574;&#32773;&#30340;&#34892;&#21160;&#65292;&#30830;&#23450;&#20854;&#30340;&#26368;&#20248;&#24615;&#12290;&#24182;&#19988;&#36890;&#36807;&#20004;&#20010;&#20572;&#26102;&#38382;&#39064;&#31034;&#20363;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#19988;&#24050;&#22312;&#19968;&#20010;&#30495;&#23454;&#30340;&#20363;&#23376;&#20013;&#24471;&#21040;&#20102;&#39640;&#31934;&#24230;&#22320;&#39044;&#27979;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;</title><link>http://arxiv.org/abs/2007.03481</link><description>&lt;p&gt;
&#12298;Bayesian&#20572;&#26102;&#38382;&#39064;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12299;
&lt;/p&gt;
&lt;p&gt;
Necessary and Sufficient Conditions for Inverse Reinforcement Learning of Bayesian Stopping Time Problems. (arXiv:2007.03481v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.03481
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#20572;&#26102;&#38382;&#39064;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#32467;&#21512;&#24494;&#35266;&#32463;&#27982;&#23398;&#20013;&#30340;Bayesian&#25581;&#31034;&#20559;&#22909;&#24605;&#36335;&#65292;&#36890;&#36807;&#35266;&#23519;Bayesian&#20915;&#31574;&#32773;&#30340;&#34892;&#21160;&#65292;&#30830;&#23450;&#20854;&#30340;&#26368;&#20248;&#24615;&#12290;&#24182;&#19988;&#36890;&#36807;&#20004;&#20010;&#20572;&#26102;&#38382;&#39064;&#31034;&#20363;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#19988;&#24050;&#22312;&#19968;&#20010;&#30495;&#23454;&#30340;&#20363;&#23376;&#20013;&#24471;&#21040;&#20102;&#39640;&#31934;&#24230;&#22320;&#39044;&#27979;&#29992;&#25143;&#21442;&#19982;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;Bayesian&#20572;&#26102;&#38382;&#39064;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#26694;&#26550;&#12290;&#36890;&#36807;&#35266;&#23519;Bayesian&#20915;&#31574;&#32773;&#30340;&#34892;&#21160;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#24517;&#35201;&#19988;&#20805;&#20998;&#30340;&#26465;&#20214;&#26469;&#30830;&#23450;&#36825;&#20123;&#34892;&#21160;&#26159;&#21542;&#19982;&#20248;&#21270;&#25104;&#26412;&#20989;&#25968;&#19968;&#33268;&#12290;&#22312;Bayesian&#65288;&#37096;&#20998;&#35266;&#23519;&#65289;&#24773;&#20917;&#19979;&#65292;&#36870;&#21521;&#23398;&#20064;&#32773;&#33021;&#22815;&#26368;&#22909;&#22320;&#30830;&#23450;&#38024;&#23545;&#35266;&#23519;&#21040;&#30340;&#31574;&#30053;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#30340;IRL&#31639;&#27861;&#30830;&#23450;&#26368;&#20248;&#24615;&#65292;&#28982;&#21518;&#26500;&#24314;&#25104;&#26412;&#20989;&#25968;&#30340;&#20272;&#35745;&#20540;&#65292;&#26159;&#19968;&#20010;&#38598;&#21512;&#20540;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#26679;&#19968;&#20010;IRL&#30446;&#26631;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#26469;&#33258;&#24494;&#35266;&#32463;&#27982;&#23398;&#30340;Bayesian&#25581;&#31034;&#20559;&#22909;&#30340;&#26032;&#24605;&#36335;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#37325;&#35201;&#30340;&#20572;&#26102;&#38382;&#39064;&#31034;&#20363;&#65292;&#21363;&#65292;&#39034;&#24207;&#20551;&#35774;&#26816;&#39564;&#21644;Bayesian&#25628;&#32034;&#65292;&#35828;&#26126;&#20102;&#25152;&#25552;&#35758;&#30340;IRL&#26041;&#26696;&#12290;&#20316;&#20026;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;190000&#20010;&#35270;&#39057;&#30340;&#20803;&#25968;&#25454;&#30340;YouTube&#25968;&#25454;&#38598;&#35828;&#26126;&#20102;&#25152;&#25552;&#35758;&#30340;IRL&#26041;&#27861;&#22914;&#20309;&#39640;&#31934;&#24230;&#22320;&#39044;&#27979;&#22312;&#32447;&#22810;&#23186;&#20307;&#24179;&#21488;&#20013;&#29992;&#25143;&#30340;&#21442;&#19982;&#24230;&#12290;&#26368;&#21518;&#65292;&#23545;&#20110;&#35813;&#31639;&#27861;&#30340;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#20570;&#20102;&#26368;&#21518;&#35752;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents an inverse reinforcement learning~(IRL) framework for Bayesian stopping time problems. By observing the actions of a Bayesian decision maker, we provide a necessary and sufficient condition to identify if these actions are consistent with optimizing a cost function. In a Bayesian (partially observed) setting, the inverse learner can at best identify optimality wrt the observed strategies. Our IRL algorithm identifies optimality and then constructs set-valued estimates of the cost function.To achieve this IRL objective, we use novel ideas from Bayesian revealed preferences stemming from microeconomics. We illustrate the proposed IRL scheme using two important examples of stopping time problems, namely, sequential hypothesis testing and Bayesian search. As a real-world example, we illustrate using a YouTube dataset comprising metadata from 190000 videos how the proposed IRL method predicts user engagement in online multimedia platforms with high accuracy. Finally, for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#30340;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#39640;&#65292;&#38590;&#20197;&#22312;&#32447;&#39034;&#24207;&#26356;&#26032;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#25311;&#21512;&#20855;&#26377;&#38750;&#24179;&#31283;&#24615;&#36136;&#30340;&#20989;&#25968;&#12290;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/1905.10003</link><description>&lt;p&gt;
&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#38750;&#24179;&#31283;&#20989;&#25968;&#30340;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Sequential Gaussian Processes for Online Learning of Nonstationary Functions. (arXiv:1905.10003v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.10003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#30340;&#36830;&#32493;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#39640;&#65292;&#38590;&#20197;&#22312;&#32447;&#39034;&#24207;&#26356;&#26032;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#25311;&#21512;&#20855;&#26377;&#38750;&#24179;&#31283;&#24615;&#36136;&#30340;&#20989;&#25968;&#12290;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#22312;&#20272;&#35745;&#20989;&#25968;&#30340;&#19978;&#19979;&#25991;&#20013;&#24471;&#21040;&#35299;&#20915;&#65292;&#36890;&#24120;&#36825;&#20123;&#20989;&#25968;&#26159;&#26102;&#38388;&#30456;&#20851;&#30340;&#20989;&#25968;&#65292;&#24182;&#19988;&#26159;&#23454;&#26102;&#22320;&#38543;&#30528;&#35266;&#27979;&#30340;&#21040;&#26469;&#32780;&#20272;&#35745;&#30340;&#12290;&#39640;&#26031;&#36807;&#31243;&#26159;&#24314;&#27169;&#23454;&#20540;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#19968;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#36873;&#25321;&#65292;&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#20856;&#22411;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#27169;&#22411;&#23384;&#22312;&#33509;&#24178;&#19981;&#36275;&#65306;1&#65289;&#20256;&#32479;&#39640;&#26031;&#36807;&#31243;&#25512;&#26029;&#30340;&#22797;&#26434;&#24230;$O(N^{3})$&#38543;&#30528;&#35266;&#27979;&#20540;&#30340;&#20010;&#25968;N&#25104;&#22686;&#38271;&#65307;2&#65289;&#36880;&#27493;&#26356;&#26032;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#19981;&#23481;&#26131;&#65307;3&#65289;&#21327;&#26041;&#24046;&#26680;&#36890;&#24120;&#23545;&#20989;&#25968;&#26045;&#21152;&#24179;&#31283;&#24615;&#32422;&#26463;&#65292;&#32780;&#20855;&#26377;&#38750;&#24179;&#31283;&#21327;&#26041;&#24046;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#36890;&#24120;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#26469;&#25311;&#21512;&#26080;&#38480;&#28151;&#21512;&#39640;&#26031;&#36807;&#31243;&#65292;&#20197;&#25429;&#25417;&#38750;&#24179;&#31283;&#34892;&#20026;&#65292;&#21516;&#26102;&#20801;&#35768;&#22312;&#32447;&#12289;&#20998;&#24067;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning problems can be framed in the context of estimating functions, and often these are time-dependent functions that are estimated in real-time as observations arrive. Gaussian processes (GPs) are an attractive choice for modeling real-valued nonlinear functions due to their flexibility and uncertainty quantification. However, the typical GP regression model suffers from several drawbacks: 1) Conventional GP inference scales $O(N^{3})$ with respect to the number of observations; 2) Updating a GP model sequentially is not trivial; and 3) Covariance kernels typically enforce stationarity constraints on the function, while GPs with non-stationary covariance kernels are often intractable to use in practice. To overcome these issues, we propose a sequential Monte Carlo algorithm to fit infinite mixtures of GPs that capture non-stationary behavior while allowing for online, distributed inference. Our approach empirically improves performance over state-of-the-art methods fo
&lt;/p&gt;</description></item></channel></rss>