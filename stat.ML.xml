<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16221</link><description>&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16221
&lt;/p&gt;
&lt;p&gt;
&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#22312;&#22797;&#26434;&#25968;&#25454;&#19978;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#21482;&#22312;&#19968;&#20010;&#23545;&#35937;&#30340;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#65292;&#20197;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#25552;&#20379;&#20102;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#21644;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26159;&#22797;&#26434;&#30340;&#65292;&#36890;&#24120;&#30001;&#21487;&#20998;&#35299;&#20026;&#22810;&#20010;&#23454;&#20307;&#30340;&#23545;&#35937;&#32452;&#25104;&#65288;&#20363;&#22914;&#65292;&#23558;&#22270;&#20687;&#20998;&#35299;&#20026;&#20687;&#32032;&#65292;&#23558;&#22270;&#24418;&#20998;&#35299;&#20026;&#30456;&#20114;&#36830;&#25509;&#30340;&#33410;&#28857;&#65289;&#12290;&#38543;&#26426;&#24179;&#28369;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20351;&#27169;&#22411;&#22312;&#20854;&#36755;&#20837;&#30340;&#24494;&#23567;&#21464;&#21270;&#19978;&#20855;&#26377;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;-&#36890;&#36807;&#22312;&#20998;&#31867;&#20043;&#21069;&#38543;&#26426;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#35777;&#22810;&#25968;&#25237;&#31080;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#24403;&#23545;&#25163;&#19981;&#26159;&#20219;&#24847;&#24178;&#25200;&#25972;&#20010;&#23545;&#35937;&#65288;&#20363;&#22914;&#22270;&#20687;&#65289;&#65292;&#32780;&#26159;&#23545;&#35937;&#30340;&#26576;&#20010;&#23454;&#20307;&#30340;&#23376;&#38598;&#65288;&#20363;&#22914;&#20687;&#32032;&#65289;&#26102;&#65292;&#36890;&#36807;&#38543;&#26426;&#24179;&#28369;&#23545;&#36825;&#31181;&#22797;&#26434;&#25968;&#25454;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20316;&#20026;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20998;&#23618;&#38543;&#26426;&#24179;&#28369;&#65306;&#25105;&#20204;&#36890;&#36807;&#20165;&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#23454;&#20307;&#23376;&#38598;&#19978;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#26469;&#37096;&#20998;&#24179;&#28369;&#23545;&#35937;&#12290;&#36890;&#36807;&#20197;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#26377;&#38024;&#23545;&#24615;&#30340;&#26041;&#24335;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#33719;&#24471;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#22122;&#22768;&#20998;&#24067;&#21021;&#22987;&#21270;&#20998;&#23618;&#24179;&#28369;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#35777;&#26126;signSGD&#31639;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#25910;&#25947;&#24615;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#20998;&#26512;&#20013;&#30340;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;SignRVR&#21644;SignRVM&#31639;&#27861;&#65292;&#24182;&#19988;&#37117;&#20197;&#36739;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.15976</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#30340;&#22522;&#20110;&#31526;&#21495;&#38543;&#26426;&#37325;&#25490;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Sign-based Random Reshuffling Algorithms for Nonconvex Optimization. (arXiv:2310.15976v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15976
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#35777;&#26126;signSGD&#31639;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#25910;&#25947;&#24615;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#20998;&#26512;&#20013;&#30340;&#32570;&#38519;&#65292;&#25552;&#20986;&#20102;SignRVR&#21644;SignRVM&#31639;&#27861;&#65292;&#24182;&#19988;&#37117;&#20197;&#36739;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#36890;&#20449;&#25928;&#29575;&#36739;&#39640;&#65292;signSGD&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#24456;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#23545;signSGD&#30340;&#20998;&#26512;&#22522;&#20110;&#20551;&#35774;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#25968;&#25454;&#37117;&#26159;&#26377;&#25918;&#22238;&#37319;&#26679;&#30340;&#65292;&#36825;&#19982;&#23454;&#38469;&#23454;&#29616;&#20013;&#25968;&#25454;&#30340;&#38543;&#26426;&#37325;&#25490;&#21644;&#39034;&#24207;&#39304;&#36865;&#36827;&#31639;&#27861;&#30340;&#24773;&#20917;&#30456;&#30683;&#30462;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;signSGD&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#38543;&#26426;&#37325;&#25490;&#65288;SignRR&#65289;&#30340;&#39318;&#20010;&#25910;&#25947;&#32467;&#26524;&#12290;&#32473;&#23450;&#25968;&#25454;&#38598;&#22823;&#23567;$n$&#65292;&#25968;&#25454;&#36845;&#20195;&#27425;&#25968;$T$&#65292;&#21644;&#38543;&#26426;&#26799;&#24230;&#30340;&#26041;&#24046;&#38480;&#21046;$\sigma^2$&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SignRR&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;signSGD&#30456;&#21516;&#65292;&#20026;$O(\log(nT)/\sqrt{nT} + \|\sigma\|_1)$ \citep{bernstein2018signsgd}&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102; SignRVR &#21644; SignRVM&#65292;&#20998;&#21035;&#21033;&#29992;&#20102;&#26041;&#24046;&#32422;&#20943;&#26799;&#24230;&#21644;&#21160;&#37327;&#26356;&#26032;&#65292;&#37117;&#20197;$O(\log(nT)/\sqrt{nT})$&#30340;&#36895;&#24230;&#25910;&#25947;&#12290;&#19982;signSGD&#30340;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#38656;&#35201;&#27599;&#27425;&#36845;&#20195;&#20013;&#26497;&#22823;&#30340;&#25209;&#27425;&#22823;&#23567;&#19982;&#21516;&#31561;&#25968;&#37327;&#30340;&#26799;&#24230;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
signSGD is popular in nonconvex optimization due to its communication efficiency. Yet, existing analyses of signSGD rely on assuming that data are sampled with replacement in each iteration, contradicting the practical implementation where data are randomly reshuffled and sequentially fed into the algorithm. We bridge this gap by proving the first convergence result of signSGD with random reshuffling (SignRR) for nonconvex optimization. Given the dataset size $n$, the number of epochs of data passes $T$, and the variance bound of a stochastic gradient $\sigma^2$, we show that SignRR has the same convergence rate $O(\log(nT)/\sqrt{nT} + \|\sigma\|_1)$ as signSGD \citep{bernstein2018signsgd}. We then present SignRVR and SignRVM, which leverage variance-reduced gradients and momentum updates respectively, both converging at $O(\log(nT)/\sqrt{nT})$. In contrast with the analysis of signSGD, our results do not require an extremely large batch size in each iteration to be of the same order a
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#32452;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#21518;&#22788;&#29702;&#26041;&#27861;&#65292;&#20005;&#26684;&#31105;&#27490;&#25968;&#25454;&#38598;&#20013;&#30340;&#37325;&#22797;&#26679;&#26412;&#65292;&#32467;&#26524;&#34920;&#26126;&#27492;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#39034;&#24207;&#27493;&#39588;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.02842</link><description>&lt;p&gt;
&#38024;&#23545;&#32452;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#38543;&#26426;&#21518;&#22788;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Random postprocessing for combinatorial Bayesian optimization. (arXiv:2309.02842v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02842
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#32452;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#21518;&#22788;&#29702;&#26041;&#27861;&#65292;&#20005;&#26684;&#31105;&#27490;&#25968;&#25454;&#38598;&#20013;&#30340;&#37325;&#22797;&#26679;&#26412;&#65292;&#32467;&#26524;&#34920;&#26126;&#27492;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#39034;&#24207;&#27493;&#39588;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#39034;&#24207;&#26041;&#27861;&#29992;&#20110;&#31163;&#25955;&#30340;&#8220;&#40657;&#30418;&#8221;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#20248;&#21270;&#25216;&#26415;&#65292;&#36890;&#24120;&#20250;&#23545;&#32473;&#23450;&#30340;&#30446;&#26631;&#20989;&#25968;&#35775;&#38382;&#22810;&#27425;&#30456;&#21516;&#30340;&#28857;&#65292;&#23548;&#33268;&#38656;&#35201;&#24456;&#22810;&#27493;&#39588;&#25165;&#33021;&#25214;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#19968;&#31181;&#21518;&#22788;&#29702;&#26041;&#27861;&#36827;&#34892;&#20102;&#25968;&#20540;&#30740;&#31350;&#65292;&#35813;&#26041;&#27861;&#20005;&#26684;&#31105;&#27490;&#25968;&#25454;&#38598;&#20013;&#30340;&#37325;&#22797;&#26679;&#26412;&#12290;&#25105;&#20204;&#21457;&#29616;&#21518;&#22788;&#29702;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#25214;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#25152;&#38656;&#30340;&#39034;&#24207;&#27493;&#39588;&#25968;&#65292;&#29305;&#21035;&#26159;&#24403;&#37319;&#26679;&#20989;&#25968;&#26159;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#26102;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based sequential approaches to discrete "black-box" optimization, including Bayesian optimization techniques, often access the same points multiple times for a given objective function in interest, resulting in many steps to find the global optimum. Here, we numerically study the effect of a postprocessing method on Bayesian optimization that strictly prohibits duplicated samples in the dataset. We find the postprocessing method significantly reduces the number of sequential steps to find the global optimum, especially when the acquisition function is of maximum a posterior estimation. Our results provide a simple but general strategy to solve the slow convergence of Bayesian optimization for high-dimensional problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38477;&#20302;&#21442;&#25968;&#35268;&#21010;&#36873;&#25321;&#24615;&#25512;&#26029;&#35745;&#31639;&#25104;&#26412;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;p&#20540;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#26469;&#20445;&#35777;&#25152;&#38656;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.11351</link><description>&lt;p&gt;
&#21442;&#25968;&#35268;&#21010;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#20013;&#30340;&#26377;&#30028;P&#20540;
&lt;/p&gt;
&lt;p&gt;
Bounded P-values in Parametric Programming-based Selective Inference. (arXiv:2307.11351v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38477;&#20302;&#21442;&#25968;&#35268;&#21010;&#36873;&#25321;&#24615;&#25512;&#26029;&#35745;&#31639;&#25104;&#26412;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;p&#20540;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#26469;&#20445;&#35777;&#25152;&#38656;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#24615;&#25512;&#26029;&#65288;SI&#65289;&#20316;&#20026;&#19968;&#31181;&#36866;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20551;&#35774;&#26816;&#39564;&#30340;&#26377;&#21069;&#26223;&#30340;&#26694;&#26550;&#65292;&#19968;&#30452;&#21463;&#21040;&#30740;&#31350;&#20851;&#27880;&#12290;SI&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#22312;&#19968;&#20010;&#20551;&#35774;&#34987;&#36873;&#20013;&#30340;&#20107;&#20214;&#30340;&#26465;&#20214;&#19979;&#36827;&#34892;&#25512;&#26029;&#12290;&#20026;&#20102;&#36827;&#34892;SI&#65292;&#24517;&#39035;&#20197;&#21487;&#36861;&#36394;&#30340;&#24418;&#24335;&#23545;&#36825;&#20010;&#20107;&#20214;&#36827;&#34892;&#25551;&#36848;&#12290;&#24403;&#36873;&#25321;&#20107;&#20214;&#38590;&#20197;&#25551;&#36848;&#26102;&#65292;&#21487;&#20197;&#24341;&#20837;&#39069;&#22806;&#30340;&#26465;&#20214;&#20197;&#20351;&#20854;&#21487;&#22788;&#29702;&#12290;&#36825;&#20123;&#39069;&#22806;&#30340;&#26465;&#20214;&#24448;&#24448;&#20250;&#23548;&#33268;&#21151;&#25928;&#30340;&#25439;&#22833;&#65292;&#36825;&#19968;&#38382;&#39064;&#34987;&#31216;&#20026;&#36807;&#24230;&#26465;&#20214;&#21270;&#12290;&#22522;&#20110;&#21442;&#25968;&#35268;&#21010;&#30340;SI&#65288;PP-based SI&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#35299;&#20915;&#36807;&#24230;&#26465;&#20214;&#21270;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;PP-based SI&#30340;&#20027;&#35201;&#38382;&#39064;&#26159;&#30001;&#20110;&#38656;&#35201;&#23436;&#20840;&#22320;&#25506;&#32034;&#25968;&#25454;&#31354;&#38388;&#32780;&#23548;&#33268;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#36807;&#31243;&#65292;&#21516;&#26102;&#20445;&#35777;&#25152;&#38656;&#31934;&#24230;&#65292;&#36890;&#36807;&#25552;&#20986;&#35745;&#31639;p&#20540;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19977;&#31181;&#31867;&#22411;&#30340;&#25628;&#32034;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference (SI) has been actively studied as a promising framework for statistical hypothesis testing for data-driven hypotheses. The basic idea of SI is to make inferences conditional on an event that a hypothesis is selected. In order to perform SI, this event must be characterized in a traceable form. When selection event is too difficult to characterize, additional conditions are introduced for tractability. This additional conditions often causes the loss of power, and this issue is referred to as over-conditioning. Parametric programming-based SI (PP-based SI) has been proposed as one way to address the over-conditioning issue. The main problem of PP-based SI is its high computational cost due to the need to exhaustively explore the data space. In this study, we introduce a procedure to reduce the computational cost while guaranteeing the desired precision, by proposing a method to compute the upper and lower bounds of p-values. We also proposed three types of search str
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Safe-$\text{M}^3$-UCRL&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#22411;&#20013;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#25968;&#38556;&#30861;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26410;&#30693;&#36716;&#31227;&#21160;&#24577;&#24773;&#20917;&#19979;&#36798;&#21040;&#23433;&#20840;&#31574;&#30053;&#30340;&#20248;&#21270;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22823;&#35268;&#27169;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.17052</link><description>&lt;p&gt;
&#23433;&#20840;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning. (arXiv:2306.17052v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Safe-$\text{M}^3$-UCRL&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#27169;&#22411;&#20013;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21644;&#23545;&#25968;&#38556;&#30861;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#26410;&#30693;&#36716;&#31227;&#21160;&#24577;&#24773;&#20917;&#19979;&#36798;&#21040;&#23433;&#20840;&#31574;&#30053;&#30340;&#20248;&#21270;&#65292;&#25104;&#21151;&#35299;&#20915;&#20102;&#22823;&#35268;&#27169;&#22810;&#26234;&#33021;&#20307;&#21327;&#35843;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#65292;&#27604;&#22914;&#20849;&#20139;&#20132;&#36890;&#65292;&#38656;&#35201;&#21327;&#35843;&#22823;&#37327;&#30340;&#26234;&#33021;&#20307;&#12290;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#20248;&#21270;&#20195;&#34920;&#24615;&#26234;&#33021;&#20307;&#30340;&#31574;&#30053;&#26469;&#24212;&#23545;&#30001;&#27492;&#24102;&#26469;&#30340;&#21487;&#25193;&#23637;&#24615;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#21363;&#26234;&#33021;&#20307;&#20998;&#24067;&#23384;&#22312;&#20840;&#23616;&#32422;&#26463;&#30340;&#24773;&#20917;&#65288;&#20363;&#22914;&#38656;&#35201;&#28385;&#36275;&#23481;&#37327;&#32422;&#26463;&#25110;&#26368;&#23567;&#35206;&#30422;&#35201;&#27714;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Safe-$\text{M}^3$-UCRL&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#26410;&#30693;&#36716;&#31227;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#23433;&#20840;&#31574;&#30053;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#12290;&#20316;&#20026;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#65292;&#23427;&#22312;&#20445;&#35777;&#24754;&#35266;&#32422;&#26463;&#28385;&#36275;&#30340;&#21516;&#26102;&#65292;&#21033;&#29992;&#36716;&#31227;&#27169;&#22411;&#20013;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#26469;&#20351;&#29992;&#23545;&#25968;&#38556;&#30861;&#26041;&#27861;&#30830;&#20445;&#39640;&#27010;&#29575;&#12290;&#25105;&#20204;&#22312;&#35768;&#22810;&#20849;&#20139;&#20132;&#36890;&#36816;&#33829;&#21830;&#38754;&#20020;&#30340;&#36710;&#36742;&#37325;&#23450;&#20301;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;Safe-$\text{M}^3$-UCRL&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#28145;&#22323;&#20986;&#31199;&#36710;&#36712;&#36857;&#25968;&#25454;&#30340;&#20223;&#30495;&#35780;&#20272;&#20854;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#26377;&#25928;&#28385;&#36275;&#20851;&#38190;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications, e.g., in shared mobility, require coordinating a large number of agents. Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent. In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met). We propose Safe-$\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics. As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability. We showcase Safe-$\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data. Our algorithm effectively meets the demand in critica
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24605;&#36335;&#65292;&#36890;&#36807;&#25506;&#32034; GPnn &#30340;&#40065;&#26834;&#24615;&#21644;&#26497;&#38480;&#34892;&#20026;&#23454;&#29616;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65292;&#21363;&#20351;&#22312;&#20986;&#29616;&#37325;&#22823;&#23567;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#21482;&#38656;&#35201;&#33457;&#36153;&#23569;&#37327;&#30340;&#24037;&#20316;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21363;&#21487;&#23454;&#29616;&#39640; MSE &#20934;&#30830;&#24615;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#25104;&#21151;&#35299;&#20915;&#20102;&#21152;&#24615;&#22122;&#22768;&#26041;&#24046;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL &#20934;&#30830;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14731</link><description>&lt;p&gt;
&#21033;&#29992;&#26412;&#22320;&#24615;&#21644;&#40065;&#26834;&#24615;&#23454;&#29616;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Leveraging Locality and Robustness to Achieve Massively Scalable Gaussian Process Regression. (arXiv:2306.14731v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14731
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24605;&#36335;&#65292;&#36890;&#36807;&#25506;&#32034; GPnn &#30340;&#40065;&#26834;&#24615;&#21644;&#26497;&#38480;&#34892;&#20026;&#23454;&#29616;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65292;&#21363;&#20351;&#22312;&#20986;&#29616;&#37325;&#22823;&#23567;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#21482;&#38656;&#35201;&#33457;&#36153;&#23569;&#37327;&#30340;&#24037;&#20316;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21363;&#21487;&#23454;&#29616;&#39640; MSE &#20934;&#30830;&#24615;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#25104;&#21151;&#35299;&#20915;&#20102;&#21152;&#24615;&#22122;&#22768;&#26041;&#24046;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL &#20934;&#30830;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25152;&#25552;&#20379;&#30340;&#31934;&#30830;&#39044;&#27979;&#21644;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#20250;&#20135;&#29983; O(n^3) &#30340;&#25104;&#26412;&#65292;&#36825;&#23545;&#20110;&#29616;&#20195;&#22823;&#35268;&#27169;&#24212;&#29992;&#26469;&#35828;&#26159;&#38590;&#20197;&#25215;&#21463;&#30340;&#12290;&#22240;&#27492;&#65292;&#20986;&#29616;&#20102;&#22823;&#37327;&#20851;&#20110;&#35745;&#31639;&#25928;&#29575;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#36890;&#36807;&#25506;&#32034; GP &#26368;&#36817;&#37051;&#39044;&#27979;(GPnn) &#30340;&#40065;&#26834;&#24615;&#21644;&#26497;&#38480;&#34892;&#20026;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#27169;&#25311;&#35777;&#26126;&#65292;&#38543;&#30528;&#25968;&#25454;&#37327; n &#30340;&#22686;&#21152;&#65292;&#20272;&#35745;&#21442;&#25968;&#21644; GP &#27169;&#22411;&#20551;&#35774;&#30340;&#20934;&#30830;&#24615;&#23545; GPnn &#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#36880;&#28176;&#20943;&#23567;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#23454;&#29616;&#39640; MSE &#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#22312;&#20986;&#29616;&#37325;&#22823;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;, &#21482;&#38656;&#35201;&#33457;&#36153;&#23569;&#37327;&#30340;&#24037;&#20316;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21363;&#21487;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38543;&#30528; n &#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#25105;&#20204;&#21457;&#29616;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL &#20173;&#23545;&#19968;&#20010;&#21442;&#25968;&#25935;&#24863;&#65292;&#21363;&#21152;&#24615;&#22122;&#22768;&#26041;&#24046;&#65307;&#20294;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#32416;&#27491;&#36825;&#31181;&#19981;&#20934;&#30830;&#24615;&#65292;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL&#12290;
&lt;/p&gt;
&lt;p&gt;
The accurate predictions and principled uncertainty measures provided by GP regression incur O(n^3) cost which is prohibitive for modern-day large-scale applications. This has motivated extensive work on computationally efficient approximations. We introduce a new perspective by exploring robustness properties and limiting behaviour of GP nearest-neighbour (GPnn) prediction. We demonstrate through theory and simulation that as the data-size n increases, accuracy of estimated parameters and GP model assumptions become increasingly irrelevant to GPnn predictive accuracy. Consequently, it is sufficient to spend small amounts of work on parameter estimation in order to achieve high MSE accuracy, even in the presence of gross misspecification. In contrast, as n tends to infinity, uncertainty calibration and NLL are shown to remain sensitive to just one parameter, the additive noise-variance; but we show that this source of inaccuracy can be corrected for, thereby achieving both well-calibra
&lt;/p&gt;</description></item><item><title>SimFBO&#21644;&#20854;ShroFBO&#21464;&#20307;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;FBO&#26694;&#26550;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20803;&#23398;&#20064;&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.19442</link><description>&lt;p&gt;
SimFBO&#65306;&#31616;&#21333;&#12289;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;&#32852;&#37030;&#21452;&#23618;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning. (arXiv:2305.19442v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19442
&lt;/p&gt;
&lt;p&gt;
SimFBO&#21644;&#20854;ShroFBO&#21464;&#20307;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;FBO&#26694;&#26550;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20803;&#23398;&#20064;&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#30001;&#20110;&#20803;&#23398;&#20064;&#12289;&#24494;&#35843;&#12289;&#36229;&#21442;&#25968;&#35843;&#25972;&#31561;&#39046;&#22495;&#20013;&#23884;&#22871;&#20248;&#21270;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32852;&#37030;&#21452;&#23618;&#20248;&#21270;&#65288;FBO&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#36793;&#32536;&#35745;&#31639;&#20013;&#26174;&#31034;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;FBO&#31639;&#27861;&#24448;&#24448;&#28041;&#21450;&#22797;&#26434;&#30340;&#35745;&#31639;&#65292;&#24182;&#38656;&#35201;&#27599;&#27425;&#36845;&#20195;&#22810;&#20010;&#23376;&#24490;&#29615;&#65292;&#27599;&#20010;&#23376;&#24490;&#29615;&#21253;&#21547;&#22810;&#20010;&#36890;&#20449;&#36718;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SimFBO&#30340;&#31616;&#21333;&#28789;&#27963;&#30340;FBO&#26694;&#26550;&#65292;&#23427;&#26131;&#20110;&#23454;&#29616;&#65292;&#19981;&#38656;&#35201;&#23376;&#24490;&#29615;&#65292;&#24182;&#21253;&#25324;&#19968;&#31181;&#24191;&#20041;&#30340;&#26381;&#21153;&#22120;&#31471;&#32858;&#21512;&#21644;&#26356;&#26032;&#20197;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#31995;&#32479;&#32423;&#24322;&#26500;&#40065;&#26834;FBO&#65288;ShroFBO&#65289;&#20316;&#20026;SimFBO&#30340;&#21464;&#20307;&#65292;&#20854;&#23545;&#26412;&#22320;&#35745;&#31639;&#30340;&#24322;&#26500;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#21644;&#26080;&#26367;&#25442;&#30340;&#23458;&#25143;&#31471;&#37319;&#26679;&#19979;&#65292;SimFBO&#21644;ShroFBO&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#21152;&#36895;&#65292;&#21516;&#26102;&#25913;&#36827;&#20102;&#26679;&#26412;&#21644;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#20803;&#23398;&#20064;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated bilevel optimization (FBO) has shown great potential recently in machine learning and edge computing due to the emerging nested optimization structure in meta-learning, fine-tuning, hyperparameter tuning, etc. However, existing FBO algorithms often involve complicated computations and require multiple sub-loops per iteration, each of which contains a number of communication rounds. In this paper, we propose a simple and flexible FBO framework named SimFBO, which is easy to implement without sub-loops, and includes a generalized server-side aggregation and update for improving communication efficiency. We further propose System-level heterogeneity robust FBO (ShroFBO) as a variant of SimFBO with stronger resilience to heterogeneous local computation. We show that SimFBO and ShroFBO provably achieve a linear convergence speedup with partial client participation and client sampling without replacement, as well as improved sample and communication complexities. Experiments demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27979;&#37327;&#20102;Barron&#31354;&#38388;&#21644;&#35889;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#23884;&#20837;&#19981;&#31561;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.19082</link><description>&lt;p&gt;
Barron&#22411;&#31354;&#38388;&#30340;&#23884;&#20837;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Embedding Inequalities for Barron-type Spaces. (arXiv:2305.19082v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27979;&#37327;&#20102;Barron&#31354;&#38388;&#21644;&#35889;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20379;&#20102;&#23884;&#20837;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#29702;&#35299;&#39640;&#32500;&#26465;&#20214;&#19979;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#21644;&#27867;&#21270;&#24615;&#36136;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#30740;&#31350;&#20154;&#21592;&#24341;&#20837;&#20102;Barron&#31354;&#38388;$\mathcal{B}_s(\Omega)$&#21644;&#35889;Barron&#31354;&#38388;$\mathcal{F}_s(\Omega)$&#65292;&#20854;&#20013;&#25351;&#25968;$s$&#34920;&#24449;&#20102;&#36825;&#20123;&#31354;&#38388;&#20013;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#65292;$\Omega\subset\mathbb{R}^d$&#34920;&#31034;&#36755;&#20837;&#22495;&#12290;&#28982;&#32780;&#65292;&#20004;&#31181;&#31867;&#22411;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#20197;&#19979;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;&#36830;&#32493;&#23884;&#20837;&#65306;&#23545;&#20110;&#20219;&#24847;$\delta\in(0,1),s\in\mathbb{N}^{+}$&#21644;$f:\Omega \mapsto \mathbb{R}$&#65292;&#37117;&#26377;\[ \delta\gamma^{\delta-s}_{\Omega}\|f\|_{\mathcal{F}_{s-\delta}(\Omega)}\lesssim_s \|f\|_{\mathcal{B}_s(\Omega)}\lesssim_s \|f\|_{\mathcal{F}_{s+1}(\Omega)}, \]&#20854;&#20013;$\gamma_{\Omega}=\sup_{\|v\|_2=1,x\in\Omega}|v^Tx|$&#65292;$\lesssim_s$&#34920;&#31034;&#20165;&#19982;&#24179;&#28369;&#21442;&#25968;$s$&#26377;&#20851;&#30340;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the fundamental problems in deep learning theory is understanding the approximation and generalization properties of two-layer neural networks in high dimensions. In order to tackle this issue, researchers have introduced the Barron space $\mathcal{B}_s(\Omega)$ and the spectral Barron space $\mathcal{F}_s(\Omega)$, where the index $s$ characterizes the smoothness of functions within these spaces and $\Omega\subset\mathbb{R}^d$ represents the input domain. However, it is still not clear what is the relationship between the two types of Barron spaces. In this paper, we establish continuous embeddings between these spaces as implied by the following inequality: for any $\delta\in (0,1), s\in \mathbb{N}^{+}$ and $f: \Omega \mapsto\mathbb{R}$, it holds that \[ \delta\gamma^{\delta-s}_{\Omega}\|f\|_{\mathcal{F}_{s-\delta}(\Omega)}\lesssim_s \|f\|_{\mathcal{B}_s(\Omega)}\lesssim_s \|f\|_{\mathcal{F}_{s+1}(\Omega)}, \] where $\gamma_{\Omega}=\sup_{\|v\|_2=1,x\in\Omega}|v^Tx|$ and notab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#29702;&#24314;&#27169;&#26469;&#35299;&#20915;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#36127;&#36801;&#31227;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#21738;&#20123;&#28304;&#20219;&#21153;&#30340;&#23376;&#38598;&#20250;&#23545;&#30446;&#26631;&#20219;&#21153;&#26377;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2303.14582</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#27169;&#22411;&#35782;&#21035;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#36127;&#36801;&#31227;
&lt;/p&gt;
&lt;p&gt;
Identification of Negative Transfers in Multitask Learning Using Surrogate Models. (arXiv:2303.14582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#29702;&#24314;&#27169;&#26469;&#35299;&#20915;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#36127;&#36801;&#31227;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35782;&#21035;&#21738;&#20123;&#28304;&#20219;&#21153;&#30340;&#23376;&#38598;&#20250;&#23545;&#30446;&#26631;&#20219;&#21153;&#26377;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#24191;&#27867;&#24212;&#29992;&#20110;&#36890;&#36807;&#22686;&#21152;&#22810;&#20010;&#30456;&#20851;&#28304;&#20219;&#21153;&#26469;&#35757;&#32451;&#20302;&#36164;&#28304;&#30446;&#26631;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#23558;&#25152;&#26377;&#28304;&#20219;&#21153;&#19982;&#30446;&#26631;&#20219;&#21153;&#31616;&#21333;&#32452;&#21512;&#24182;&#19981;&#24635;&#26159;&#33021;&#25552;&#39640;&#30446;&#26631;&#20219;&#21153;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#22240;&#20026;&#20250;&#23384;&#22312;&#36127;&#36801;&#31227;&#12290;&#22240;&#27492;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#35782;&#21035;&#21738;&#20123;&#28304;&#20219;&#21153;&#30340;&#23376;&#38598;&#20250;&#23545;&#30446;&#26631;&#20219;&#21153;&#26377;&#30410;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#35745;&#31639;&#19978;&#24456;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#23376;&#38598;&#30340;&#25968;&#37327;&#38543;&#30528;&#28304;&#20219;&#21153;&#30340;&#25968;&#37327;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20195;&#29702;&#24314;&#27169;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#22312;&#20195;&#29702;&#24314;&#27169;&#20013;&#65292;&#25105;&#20204;&#23545;&#28304;&#20219;&#21153;&#36827;&#34892;&#37319;&#26679;&#65288;&#38543;&#26426;&#65289;&#65292;&#24182;&#39044;&#20808;&#35745;&#31639;&#23427;&#20204;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#34920;&#29616;&#65307;&#28982;&#21518;&#65292;&#25105;&#20204;&#29992;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#36924;&#36817;&#39044;&#20808;&#35745;&#31639;&#30340;&#34920;&#29616;&#65292;&#35813;&#27169;&#22411;&#20063;&#21487;&#29992;&#20110;&#39044;&#27979;&#26410;&#37319;&#26679;&#30340;&#23376;&#38598;&#30340;&#34920;&#29616;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#31034;&#20363;&#21644;&#19968;&#20010;&#29616;&#23454;&#19990;&#30028;&#30340;&#22810;&#35821;&#35328;&#24773;&#24863;&#20998;&#26512;&#20219;&#21153;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#25511;&#21046;&#39044;&#27979;&#38598;&#65288;RCPS&#65289;&#31243;&#24207;&#30340;&#25512;&#24191;&#65292;&#31216;&#20026;$K$-RCPS&#65292;&#23427;&#20801;&#35768;&#20026;&#20219;&#20309;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#36880;&#20010;&#26657;&#20934;&#30340;&#26410;&#26469;&#26679;&#26412;&#38388;&#38548;&#65292;&#24182;&#25511;&#21046;&#30456;&#23545;&#20110;&#22522;&#20934;&#30495;&#23454;&#22270;&#20687;&#30340;&#26576;&#31181;&#39118;&#38505;&#27010;&#24565;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#23567;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.03791</link><description>&lt;p&gt;
&#22914;&#20309;&#20449;&#20219;&#24744;&#30340;&#25193;&#25955;&#27169;&#22411;&#65306;&#19968;&#31181;&#20984;&#20248;&#21270;&#26041;&#27861;&#24212;&#23545;&#31526;&#21512;&#39118;&#38505;&#25511;&#21046;&#30340;&#22240;&#24335;&#20998;&#35299;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
How to Trust Your Diffusion Model: A Convex Optimization Approach to Conformal Risk Control. (arXiv:2302.03791v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#25511;&#21046;&#39044;&#27979;&#38598;&#65288;RCPS&#65289;&#31243;&#24207;&#30340;&#25512;&#24191;&#65292;&#31216;&#20026;$K$-RCPS&#65292;&#23427;&#20801;&#35768;&#20026;&#20219;&#20309;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#36880;&#20010;&#26657;&#20934;&#30340;&#26410;&#26469;&#26679;&#26412;&#38388;&#38548;&#65292;&#24182;&#25511;&#21046;&#30456;&#23545;&#20110;&#22522;&#20934;&#30495;&#23454;&#22270;&#20687;&#30340;&#26576;&#31181;&#39118;&#38505;&#27010;&#24565;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#23567;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#31616;&#31216;&#25193;&#25955;&#27169;&#22411;&#65292;&#22312;&#22810;&#20010;&#37325;&#35201;&#39046;&#22495;&#21644;&#20219;&#21153;&#20013;&#32487;&#32493;&#22686;&#38271;&#12290;&#23613;&#31649;&#23427;&#20204;&#25552;&#20379;&#20102;&#26469;&#33258;&#32463;&#39564;&#20998;&#24067;&#30340;&#39640;&#36136;&#37327;&#21644;&#22810;&#26679;&#21270;&#26679;&#26412;&#65292;&#20294;&#22312;&#20854;&#36127;&#36131;&#20219;&#22320;&#29992;&#20110;&#20851;&#38190;&#22330;&#26223;&#26041;&#38754;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#20449;&#24230;&#20173;&#23384;&#22312;&#37325;&#35201;&#38382;&#39064;&#12290;&#25910;&#25947;&#39044;&#27979;&#26159;&#19968;&#31181;&#29616;&#20195;&#24037;&#20855;&#65292;&#29992;&#20110;&#20026;&#20219;&#20309;&#40657;&#30418;&#23376;&#39044;&#27979;&#22120;&#26500;&#24314;&#26377;&#38480;&#26679;&#26412;&#12289;&#20998;&#24067;&#33258;&#30001;&#30340;&#19981;&#30830;&#23450;&#24615;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#22270;&#20687;&#21040;&#22270;&#20687;&#22238;&#24402;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#25511;&#21046;&#39044;&#27979;&#38598;&#65288;RCPS&#65289;&#31243;&#24207;&#30340;&#25512;&#24191;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;$K$-RCPS&#65292;&#23427;&#20801;&#35768;$(i)$&#20026;&#20219;&#20309;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#36880;&#20010;&#26657;&#20934;&#30340;&#26410;&#26469;&#26679;&#26412;&#38388;&#38548;&#65292;&#24182;$(ii)$&#25511;&#21046;&#30456;&#23545;&#20110;&#22522;&#20934;&#30495;&#23454;&#22270;&#20687;&#30340;&#26576;&#31181;&#39118;&#38505;&#27010;&#24565;&#65292;&#21516;&#26102;&#20445;&#25345;&#26368;&#23567;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;&#19982;&#29616;&#26377;&#30340;&#25910;&#25947;&#39118;&#38505;&#25511;&#21046;&#36807;&#31243;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#36807;&#31243;&#20381;&#38752;&#19968;&#31181;&#26032;&#22411;&#30340;&#20984;&#20248;&#21270;&#20844;&#24335;&#65292;&#20351;&#20854;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#26131;&#20110;&#23454;&#29616;&#30340;&#29305;&#28857;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22270;&#20687;&#21040;&#22270;&#20687;&#22238;&#24402;&#20219;&#21153;&#19978;&#20351;&#29992;&#24471;&#20998;&#20026;&#22522;&#30784;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#31243;&#24207;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#39640;&#24230;&#26657;&#20934;&#21644;&#33391;&#22909;&#25511;&#21046;&#30340;&#39044;&#27979;&#38388;&#38548;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative modeling, informally referred to as diffusion models, continue to grow in popularity across several important domains and tasks. While they provide high-quality and diverse samples from empirical distributions, important questions remain on the reliability and trustworthiness of these sampling procedures for their responsible use in critical scenarios. Conformal prediction is a modern tool to construct finite-sample, distribution-free uncertainty guarantees for any black-box predictor. In this work, we focus on image-to-image regression tasks and we present a generalization of the Risk-Controlling Prediction Sets (RCPS) procedure, that we term $K$-RCPS, which allows to $(i)$ provide entrywise calibrated intervals for future samples of any diffusion model, and $(ii)$ control a certain notion of risk with respect to a ground truth image with minimal mean interval length. Differently from existing conformal risk control procedures, ours relies on a novel convex opti
&lt;/p&gt;</description></item></channel></rss>