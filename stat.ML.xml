<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#27969;&#36864;&#28779;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;FAKI&#65289;&#31639;&#27861;&#65292;&#22312;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#20013;&#24212;&#29992;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#27969;&#21160;&#36864;&#28779;&#21644;&#27491;&#35268;&#21270;&#27969;&#25216;&#26415;&#65292;&#33021;&#22815;&#20197;&#26356;&#39640;&#30340;&#20934;&#30830;&#24230;&#36817;&#20284;&#38750;&#39640;&#26031;&#30446;&#26631;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;EKI&#65289;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2309.11490</link><description>&lt;p&gt;
&#26080;&#26799;&#24230;&#25512;&#26029;&#20013;&#30340;&#27969;&#36864;&#28779;&#21345;&#23572;&#26364;&#21453;&#28436;&#31639;&#27861;&#22312;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Flow Annealed Kalman Inversion for Gradient-Free Inference in Bayesian Inverse Problems. (arXiv:2309.11490v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#27969;&#36864;&#28779;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;FAKI&#65289;&#31639;&#27861;&#65292;&#22312;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#20013;&#24212;&#29992;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#27969;&#21160;&#36864;&#28779;&#21644;&#27491;&#35268;&#21270;&#27969;&#25216;&#26415;&#65292;&#33021;&#22815;&#20197;&#26356;&#39640;&#30340;&#20934;&#30830;&#24230;&#36817;&#20284;&#38750;&#39640;&#26031;&#30446;&#26631;&#65292;&#30456;&#27604;&#20110;&#26631;&#20934;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;EKI&#65289;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35768;&#22810;&#31185;&#23398;&#21453;&#38382;&#39064;&#65292;&#25105;&#20204;&#38656;&#35201;&#35780;&#20272;&#19968;&#20010;&#26114;&#36149;&#30340;&#21069;&#21521;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#35813;&#27169;&#22411;&#36890;&#24120;&#20197;&#19968;&#31181;&#26080;&#27861;&#35775;&#38382;&#20854;&#26799;&#24230;&#30340;&#24418;&#24335;&#32473;&#20986;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#24456;&#24555;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#65292;&#38656;&#35201;&#22823;&#37327;&#30340;&#20018;&#34892;&#27169;&#22411;&#35780;&#20272;&#25165;&#33021;&#25910;&#25947;&#21040;&#30446;&#26631;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27969;&#36864;&#28779;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;FAKI&#65289;&#12290;&#36825;&#26159;&#23545;&#38598;&#21512;&#21345;&#23572;&#26364;&#21453;&#28436;&#65288;EKI&#65289;&#30340;&#19968;&#33324;&#21270;&#65292;&#25105;&#20204;&#23558;&#21345;&#23572;&#26364;&#28388;&#27874;&#26356;&#26032;&#23884;&#20837;&#21040;&#28201;&#24230;&#36864;&#28779;&#26041;&#26696;&#20013;&#65292;&#24182;&#20351;&#29992;&#27491;&#35268;&#21270;&#27969;&#65288;NF&#65289;&#23558;&#19982;&#27599;&#20010;&#28201;&#24230;&#32423;&#21035;&#23545;&#24212;&#30340;&#20013;&#38388;&#27979;&#24230;&#26144;&#23556;&#21040;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#26631;&#20934;EKI&#20013;&#20351;&#29992;&#30340;&#20013;&#38388;&#27979;&#24230;&#29702;&#35770;&#19978;&#20026;&#39640;&#26031;&#20998;&#24067;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#36817;&#20284;&#38750;&#39640;&#26031;&#30446;&#26631;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#25968;&#20540;&#22522;&#20934;&#27979;&#35797;&#19978;&#23637;&#31034;&#20102;FAKI&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;&#19982;&#26631;&#20934;EKI&#30456;&#27604;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
For many scientific inverse problems we are required to evaluate an expensive forward model. Moreover, the model is often given in such a form that it is unrealistic to access its gradients. In such a scenario, standard Markov Chain Monte Carlo algorithms quickly become impractical, requiring a large number of serial model evaluations to converge on the target distribution. In this paper we introduce Flow Annealed Kalman Inversion (FAKI). This is a generalization of Ensemble Kalman Inversion (EKI), where we embed the Kalman filter updates in a temperature annealing scheme, and use normalizing flows (NF) to map the intermediate measures corresponding to each temperature level to the standard Gaussian. In doing so, we relax the Gaussian ansatz for the intermediate measures used in standard EKI, allowing us to achieve higher fidelity approximations to non-Gaussian targets. We demonstrate the performance of FAKI on two numerical benchmarks, showing dramatic improvements over standard EKI i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;Isolation Forest&#26041;&#27861;&#20013;&#25552;&#20986;&#20102;&#20004;&#20010;&#36129;&#29486;&#65292;&#20998;&#21035;&#26159;&#23545;&#35780;&#20998;&#20989;&#25968;&#30340;&#20449;&#24687;&#29702;&#35770;&#25512;&#24191;&#21644;&#22312;&#20010;&#20307;&#26641;&#20272;&#35745;&#22120;&#23618;&#38754;&#19978;&#20351;&#29992;&#22522;&#20110;&#36229;&#20307;&#31215;&#30340;&#35780;&#20998;&#20989;&#25968;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#22343;&#23545;&#19968;&#20123;&#25968;&#25454;&#38598;&#30456;&#23545;&#20110;&#26631;&#20934;Isolation Forest&#34920;&#29616;&#20986;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#19988;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#19978;&#24179;&#22343;&#34920;&#29616;&#20986;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2309.11450</link><description>&lt;p&gt;
Isolation Forest&#30340;&#20998;&#24067;&#21644;&#23481;&#37327;&#22522;&#20934;&#35780;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distribution and volume based scoring for Isolation Forests. (arXiv:2309.11450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;Isolation Forest&#26041;&#27861;&#20013;&#25552;&#20986;&#20102;&#20004;&#20010;&#36129;&#29486;&#65292;&#20998;&#21035;&#26159;&#23545;&#35780;&#20998;&#20989;&#25968;&#30340;&#20449;&#24687;&#29702;&#35770;&#25512;&#24191;&#21644;&#22312;&#20010;&#20307;&#26641;&#20272;&#35745;&#22120;&#23618;&#38754;&#19978;&#20351;&#29992;&#22522;&#20110;&#36229;&#20307;&#31215;&#30340;&#35780;&#20998;&#20989;&#25968;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#22343;&#23545;&#19968;&#20123;&#25968;&#25454;&#38598;&#30456;&#23545;&#20110;&#26631;&#20934;Isolation Forest&#34920;&#29616;&#20986;&#26174;&#33879;&#25913;&#36827;&#65292;&#24182;&#19988;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#19978;&#24179;&#22343;&#34920;&#29616;&#20986;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#24322;&#24120;&#21644;&#31163;&#32676;&#20540;&#26816;&#27979;&#26041;&#27861;Isolation Forest&#20570;&#20986;&#20102;&#20004;&#39033;&#36129;&#29486;&#12290;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#23545;&#29992;&#20110;&#32858;&#21512;&#38543;&#26426;&#26641;&#20272;&#35745;&#22120;&#30340;&#24471;&#20998;&#20989;&#25968;&#36827;&#34892;&#20102;&#20449;&#24687;&#29702;&#35770;&#19978;&#30340;&#25512;&#24191;&#12290;&#36825;&#20010;&#25512;&#24191;&#20801;&#35768;&#32771;&#34385;&#25972;&#20010;&#20998;&#24067;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#26641;&#30340;&#38598;&#25104;&#24179;&#22343;&#20540;&#12290;&#31532;&#20108;&#20010;&#36129;&#29486;&#26159;&#22312;&#21333;&#20010;&#26641;&#20272;&#35745;&#22120;&#23618;&#38754;&#19978;&#26367;&#25442;&#20102;Isolation Forest&#22522;&#20110;&#28145;&#24230;&#30340;&#24471;&#20998;&#26041;&#27861;&#65292;&#25913;&#20026;&#22522;&#20110;&#38548;&#31163;&#26641;&#21494;&#33410;&#28857;&#30340;&#36229;&#20307;&#31215;&#30340;&#24471;&#20998;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#29983;&#25104;&#30340;&#25968;&#25454;&#23545;&#36825;&#20004;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#22312;&#26469;&#33258;&#26368;&#36817;&#21644;&#35814;&#23613;&#30340;&#8220;ADBench&#8221;&#22522;&#20934;&#30340;34&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#22312;&#26576;&#20123;&#25968;&#25454;&#38598;&#19978;&#20004;&#31181;&#21464;&#20307;&#30456;&#23545;&#20110;&#26631;&#20934;&#30340;Isolation Forest&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#24182;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#19978;&#23545;&#20854;&#20013;&#19968;&#31181;&#21464;&#20307;&#24179;&#22343;&#26174;&#31034;&#20986;&#25913;&#36827;&#12290;&#20195;&#30721;&#21487;&#22797;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We make two contributions to the Isolation Forest method for anomaly and outlier detection. The first contribution is an information-theoretically motivated generalisation of the score function that is used to aggregate the scores across random tree estimators. This generalisation allows one to take into account not just the ensemble average across trees but instead the whole distribution. The second contribution is an alternative scoring function at the level of the individual tree estimator, in which we replace the depth-based scoring of the Isolation Forest with one based on hyper-volumes associated to an isolation tree's leaf nodes.  We motivate the use of both of these methods on generated data and also evaluate them on 34 datasets from the recent and exhaustive ``ADBench'' benchmark, finding significant improvement over the standard isolation forest for both variants on some datasets and improvement on average across all datasets for one of the two variants. The code to reproduce
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20316;&#20026;&#38477;&#22122;&#31639;&#27861;&#22312;&#39640;&#32500;&#22270;&#24418;&#27169;&#22411;&#20013;&#23398;&#20064;&#25193;&#25955;&#27169;&#22411;&#65292;&#20026;&#29983;&#25104;&#24314;&#27169;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#36924;&#36817;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.11420</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#38477;&#22122;&#31639;&#27861;&#65306;&#39640;&#32500;&#22270;&#24418;&#27169;&#22411;&#20013;&#25193;&#25955;&#27169;&#22411;&#30340;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Networks as Denoising Algorithms: Sample-Efficient Learning of Diffusion Models in High-Dimensional Graphical Models. (arXiv:2309.11420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11420
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20316;&#20026;&#38477;&#22122;&#31639;&#27861;&#22312;&#39640;&#32500;&#22270;&#24418;&#27169;&#22411;&#20013;&#23398;&#20064;&#25193;&#25955;&#27169;&#22411;&#65292;&#20026;&#29983;&#25104;&#24314;&#27169;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#36924;&#36817;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22522;&#20110;&#25193;&#25955;&#30340;&#29983;&#25104;&#24314;&#27169;&#20013;&#36890;&#36807;&#35780;&#20998;&#20989;&#25968;&#30340;&#36924;&#36817;&#25928;&#29575;&#12290;&#23613;&#31649;&#29616;&#26377;&#30340;&#36817;&#20284;&#29702;&#35770;&#21033;&#29992;&#20102;&#35780;&#20998;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#65292;&#20294;&#23427;&#20204;&#22312;&#26412;&#36136;&#19978;&#39640;&#32500;&#25968;&#25454;&#20013;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#22256;&#25200;&#12290;&#36825;&#31181;&#38480;&#21046;&#22312;&#22270;&#24418;&#27169;&#22411;&#65288;&#22914;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#65289;&#20013;&#23588;&#20026;&#26126;&#26174;&#65292;&#36825;&#26159;&#22270;&#20687;&#20998;&#24067;&#24120;&#35265;&#30340;&#31867;&#22411;&#65292;&#35780;&#20998;&#20989;&#25968;&#30340;&#36817;&#20284;&#25928;&#29575;&#23578;&#26410;&#30830;&#31435;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#35780;&#20998;&#20989;&#25968;&#22312;&#22270;&#24418;&#27169;&#22411;&#20013;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#38477;&#22122;&#31639;&#27861;&#36827;&#34892;&#36739;&#22909;&#30340;&#36924;&#36817;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#31639;&#27861;&#36866;&#29992;&#20110;&#39640;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#12290;&#25105;&#20204;&#22312;&#22270;&#24418;&#27169;&#22411;&#30340;&#20363;&#23376;&#20013;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#21253;&#25324;&#20234;&#36763;&#27169;&#22411;&#12289;&#26465;&#20214;&#20234;&#36763;&#27169;&#22411;&#12289;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#21644;&#31232;&#30095;&#32534;&#30721;&#27169;&#22411;&#12290;&#32467;&#21512;&#22522;&#20110;&#25193;&#25955;&#37319;&#26679;&#30340;&#29616;&#25104;&#31163;&#25955;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26679;&#26412;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the approximation efficiency of score functions by deep neural networks in diffusion-based generative modeling. While existing approximation theories utilize the smoothness of score functions, they suffer from the curse of dimensionality for intrinsically high-dimensional data. This limitation is pronounced in graphical models such as Markov random fields, common for image distributions, where the approximation efficiency of score functions remains unestablished.  To address this, we observe score functions can often be well-approximated in graphical models through variational inference denoising algorithms. Furthermore, these algorithms are amenable to efficient neural network representation. We demonstrate this in examples of graphical models, including Ising models, conditional Ising models, restricted Boltzmann machines, and sparse encoding models. Combined with off-the-shelf discretization error bounds for diffusion-based sampling, we provide an efficient sample com
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#25506;&#32034;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#23427;&#25552;&#20379;&#20102;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#25104;&#23545;&#26102;&#23646;&#24615;&#25913;&#21464;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#20915;&#31574;&#19982;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#21644;&#32422;&#26463;&#38590;&#24230;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.11343</link><description>&lt;p&gt;
&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#29702;&#35299;&#20844;&#24179;&#24615;&#32422;&#26463;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Using Property Elicitation to Understand the Impacts of Fairness Constraints. (arXiv:2309.11343v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11343
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#25506;&#32034;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#23427;&#25552;&#20379;&#20102;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#25104;&#23545;&#26102;&#23646;&#24615;&#25913;&#21464;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#20915;&#31574;&#19982;&#25968;&#25454;&#20998;&#24067;&#21464;&#21270;&#21644;&#32422;&#26463;&#38590;&#24230;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#31639;&#27861;&#36890;&#24120;&#36890;&#36807;&#20248;&#21270;&#26576;&#20010;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#28155;&#21152;&#27491;&#21017;&#21270;&#20989;&#25968;&#26469;&#26045;&#21152;&#36829;&#21453;&#32422;&#26463;&#30340;&#24809;&#32602;&#12290;&#39044;&#26399;&#22320;&#65292;&#28155;&#21152;&#36825;&#26679;&#30340;&#27491;&#21017;&#21270;&#20989;&#25968;&#21487;&#20197;&#25913;&#21464;&#30446;&#26631;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#20540;&#12290;&#30446;&#21069;&#36824;&#19981;&#28165;&#26970;&#21738;&#20123;&#27491;&#21017;&#21270;&#20989;&#25968;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#20540;&#65292;&#20197;&#21450;&#24403;&#26368;&#23567;&#21270;&#20540;&#21457;&#29983;&#21464;&#21270;&#26102;&#65292;&#23427;&#20250;&#22914;&#20309;&#21464;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#23646;&#24615;&#24341;&#23548;&#26041;&#27861;&#26469;&#21021;&#27493;&#20102;&#35299;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#19982;&#32473;&#23450;&#38382;&#39064;&#23454;&#20363;&#30340;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#32852;&#21512;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#20989;&#25968;&#25104;&#23545;&#26102;&#65292;&#23646;&#24615;&#25913;&#21464;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#30740;&#31350;&#20102;&#19968;&#20123;&#28385;&#36275;&#36825;&#20010;&#26465;&#20214;&#30340;&#27491;&#21017;&#21270;&#20989;&#25968;&#22312;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#20915;&#31574;&#22914;&#20309;&#38543;&#30528;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#21644;&#32422;&#26463;&#30340;&#38590;&#24230;&#32780;&#25913;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive algorithms are often trained by optimizing some loss function, to which regularization functions are added to impose a penalty for violating constraints. As expected, the addition of such regularization functions can change the minimizer of the objective. It is not well-understood which regularizers change the minimizer of the loss, and, when the minimizer does change, how it changes. We use property elicitation to take first steps towards understanding the joint relationship between the loss and regularization functions and the optimal decision for a given problem instance. In particular, we give a necessary and sufficient condition on loss and regularizer pairs for when a property changes with the addition of the regularizer, and examine some regularizers satisfying this condition standard in the fair machine learning literature. We empirically demonstrate how algorithmic decision-making changes as a function of both data distribution changes and hardness of the constraint
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#25968;&#25454;&#39537;&#21160;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#37096;&#24179;&#22343;&#21644;&#37319;&#26679;&#20998;&#24067;&#26469;&#23454;&#29616;&#26679;&#26412;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#20805;&#20998;&#26465;&#20214;&#21644;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#26032;&#20379;&#24212;&#21830;&#27169;&#22411;&#20013;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.11147</link><description>&lt;p&gt;
&#22522;&#20110;&#39044;&#27979;&#20248;&#21270;&#65306;&#22312;&#25968;&#25454;&#39537;&#21160;&#20248;&#21270;&#20013;&#23454;&#29616;&#26679;&#26412;&#22806;&#26368;&#20248;
&lt;/p&gt;
&lt;p&gt;
Optimize-via-Predict: Realizing out-of-sample optimality in data-driven optimization. (arXiv:2309.11147v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11147
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#30340;&#25968;&#25454;&#39537;&#21160;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#37096;&#24179;&#22343;&#21644;&#37319;&#26679;&#20998;&#24067;&#26469;&#23454;&#29616;&#26679;&#26412;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#20805;&#20998;&#26465;&#20214;&#21644;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#26032;&#20379;&#24212;&#21830;&#27169;&#22411;&#20013;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#20248;&#21270;&#30340;&#38543;&#26426;&#24418;&#24335;&#65292;&#20854;&#20013;&#20915;&#31574;&#32773;&#19981;&#30693;&#36947;&#30495;&#23454;&#20998;&#24067;&#65292;&#20294;&#30693;&#36947;&#23427;&#23646;&#20110;&#26576;&#20010;&#20551;&#35774;&#38598;&#65292;&#24182;&#25317;&#26377;&#19968;&#20010;&#21382;&#21490;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#20174;&#20013;&#33719;&#21462;&#20851;&#20110;&#20854;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#39044;&#23450;&#26041;&#26696;&#23450;&#20041;&#20026;&#23558;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#26144;&#23556;&#21040;&#20915;&#31574;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290;&#30001;&#20110;&#19981;&#23384;&#22312;&#33021;&#22815;&#27867;&#21270;&#21040;&#25972;&#20010;&#20551;&#35774;&#38598;&#30340;&#39044;&#23450;&#26041;&#26696;&#65292;&#25105;&#20204;&#23558;&#26679;&#26412;&#22806;&#26368;&#20248;&#23450;&#20041;&#20026;&#22312;&#20551;&#35774;&#38598;&#30340;&#37051;&#22495;&#20869;&#23616;&#37096;&#24179;&#22343;&#65292;&#24182;&#22312;&#37319;&#26679;&#20998;&#24067;&#19978;&#36827;&#34892;&#24179;&#22343;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23616;&#37096;&#26679;&#26412;&#22806;&#26368;&#20248;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#36825;&#24402;&#32467;&#20026;&#20551;&#35774;&#26063;&#30340;&#20805;&#20998;&#32479;&#35745;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#35299;&#20986;&#36825;&#26679;&#30340;&#26679;&#26412;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#36890;&#36807;&#37319;&#26679;&#21644;&#20108;&#20998;&#25628;&#32034;&#31639;&#27861;&#39640;&#25928;&#22320;&#23454;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#26032;&#20379;&#24212;&#21830;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#25214;&#21040;&#20102;&#36739;&#24378;&#30340;&#24635;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine a stochastic formulation for data-driven optimization wherein the decision-maker is not privy to the true distribution, but has knowledge that it lies in some hypothesis set and possesses a historical data set, from which information about it can be gleaned. We define a prescriptive solution as a decision rule mapping such a data set to decisions. As there does not exist prescriptive solutions that are generalizable over the entire hypothesis set, we define out-of-sample optimality as a local average over a neighbourhood of hypotheses, and averaged over the sampling distribution. We prove sufficient conditions for local out-of-sample optimality, which reduces to functions of the sufficient statistic of the hypothesis family. We present an optimization problem that would solve for such an out-of-sample optimal solution, and does so efficiently by a combination of sampling and bisection search algorithms. Finally, we illustrate our model on the newsvendor model, and find stron
&lt;/p&gt;</description></item><item><title>Ano-SuPs&#26159;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#21306;&#22359;&#26469;&#36827;&#34892;&#21046;&#36896;&#20135;&#21697;&#30340;&#22810;&#23610;&#24230;&#24322;&#24120;&#26816;&#27979;&#30340;&#20004;&#38454;&#27573;&#31574;&#30053;&#26041;&#27861;&#12290;&#23427;&#21487;&#20197;&#35299;&#20915;&#22270;&#20687;&#32972;&#26223;&#22797;&#26434;&#24615;&#21644;&#24322;&#24120;&#27169;&#24335;&#30340;&#25361;&#25112;&#65292;&#24182;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.11120</link><description>&lt;p&gt;
Ano-SuPs: &#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#30340;&#21306;&#22359;&#36827;&#34892;&#21046;&#36896;&#20135;&#21697;&#30340;&#22810;&#23610;&#24230;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Ano-SuPs: Multi-size anomaly detection for manufactured products by identifying suspected patches. (arXiv:2309.11120v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11120
&lt;/p&gt;
&lt;p&gt;
Ano-SuPs&#26159;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#21306;&#22359;&#26469;&#36827;&#34892;&#21046;&#36896;&#20135;&#21697;&#30340;&#22810;&#23610;&#24230;&#24322;&#24120;&#26816;&#27979;&#30340;&#20004;&#38454;&#27573;&#31574;&#30053;&#26041;&#27861;&#12290;&#23427;&#21487;&#20197;&#35299;&#20915;&#22270;&#20687;&#32972;&#26223;&#22797;&#26434;&#24615;&#21644;&#24322;&#24120;&#27169;&#24335;&#30340;&#25361;&#25112;&#65292;&#24182;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#20687;&#30340;&#31995;&#32479;&#22240;&#20854;&#25552;&#20379;&#20016;&#23500;&#30340;&#21046;&#36896;&#29366;&#24577;&#20449;&#24687;&#12289;&#20302;&#23454;&#26045;&#25104;&#26412;&#21644;&#39640;&#37319;&#38598;&#36895;&#24230;&#32780;&#21463;&#21040;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#22270;&#20687;&#32972;&#26223;&#30340;&#22797;&#26434;&#24615;&#21644;&#21508;&#31181;&#24322;&#24120;&#27169;&#24335;&#32473;&#29616;&#26377;&#30340;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#65292;&#36825;&#20123;&#26041;&#27861;&#19981;&#36275;&#20197;&#28385;&#36275;&#24314;&#27169;&#38656;&#27714;&#12290;&#27492;&#22806;&#65292;&#24322;&#24120;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#23548;&#33268;&#24322;&#24120;&#30340;&#27745;&#26579;&#38382;&#39064;&#65292;&#20351;&#24471;&#35774;&#35745;&#30340;&#27169;&#22411;&#21644;&#26041;&#27861;&#23545;&#22806;&#37096;&#24178;&#25200;&#38750;&#24120;&#25935;&#24863;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#21487;&#30097;&#21306;&#22359;&#65288;Ano-SuPs&#65289;&#26469;&#26816;&#27979;&#24322;&#24120;&#30340;&#20004;&#38454;&#27573;&#31574;&#30053;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#20004;&#27425;&#37325;&#24314;&#36755;&#20837;&#22270;&#20687;&#26469;&#26816;&#27979;&#24102;&#26377;&#24322;&#24120;&#30340;&#21306;&#22359;&#30340;&#26041;&#27861;&#65306;&#31532;&#19968;&#27493;&#26159;&#36890;&#36807;&#21435;&#38500;&#37027;&#20123;&#21487;&#30097;&#21306;&#22359;&#26469;&#33719;&#24471;&#19968;&#32452;&#27491;&#24120;&#21306;&#22359;&#65292;&#31532;&#20108;&#27493;&#26159;&#20351;&#29992;&#36825;&#20123;&#27491;&#24120;&#21306;&#22359;&#26469;&#20248;&#21270;&#23545;&#24102;&#26377;&#24322;&#24120;&#21306;&#22359;&#30340;&#35782;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Image-based systems have gained popularity owing to their capacity to provide rich manufacturing status information, low implementation costs and high acquisition rates. However, the complexity of the image background and various anomaly patterns pose new challenges to existing matrix decomposition methods, which are inadequate for modeling requirements. Moreover, the uncertainty of the anomaly can cause anomaly contamination problems, making the designed model and method highly susceptible to external disturbances. To address these challenges, we propose a two-stage strategy anomaly detection method that detects anomalies by identifying suspected patches (Ano-SuPs). Specifically, we propose to detect the patches with anomalies by reconstructing the input image twice: the first step is to obtain a set of normal patches by removing those suspected patches, and the second step is to use those normal patches to refine the identification of the patches with anomalies. To demonstrate its ef
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22312;&#22825;&#28982;&#30005;&#32593;&#35268;&#21010;&#20013;&#36873;&#25321;&#26497;&#31471;&#24773;&#26223;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#35745;&#21151;&#33021;&#28145;&#24230;&#24230;&#37327;&#26469;&#31579;&#36873;&#20986;&#26368;&#37325;&#35201;&#30340;&#24773;&#26223;&#20197;&#20943;&#36731;&#36816;&#33829;&#39118;&#38505;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#30340;Texas-7k&#30005;&#32593;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.11067</link><description>&lt;p&gt;
&#22825;&#28982;&#30005;&#32593;&#36816;&#33829;&#35745;&#21010;&#20013;&#30340;&#26497;&#31471;&#24773;&#26223;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Extreme Scenario Selection in Day-Ahead Power Grid Operational Planning. (arXiv:2309.11067v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22312;&#22825;&#28982;&#30005;&#32593;&#35268;&#21010;&#20013;&#36873;&#25321;&#26497;&#31471;&#24773;&#26223;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#35745;&#21151;&#33021;&#28145;&#24230;&#24230;&#37327;&#26469;&#31579;&#36873;&#20986;&#26368;&#37325;&#35201;&#30340;&#24773;&#26223;&#20197;&#20943;&#36731;&#36816;&#33829;&#39118;&#38505;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#30340;Texas-7k&#30005;&#32593;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#22312;&#25552;&#21069;&#19968;&#22825;&#30340;&#30005;&#32593;&#35268;&#21010;&#20013;&#24212;&#29992;&#32479;&#35745;&#21151;&#33021;&#28145;&#24230;&#24230;&#37327;&#26469;&#36873;&#25321;&#26497;&#31471;&#24773;&#26223;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#30340;&#26159;&#31579;&#36873;&#38024;&#23545;&#23454;&#38469;&#36127;&#36733;&#21644;&#21487;&#20877;&#29983;&#33021;&#28304;&#29983;&#25104;&#30340;&#27010;&#29575;&#24773;&#26223;&#65292;&#20197;&#35782;&#21035;&#23545;&#36816;&#33829;&#39118;&#38505;&#32531;&#35299;&#26368;&#37325;&#35201;&#30340;&#24773;&#26223;&#12290;&#20026;&#20102;&#22788;&#29702;&#36164;&#20135;&#31867;&#21035;&#21644;&#26085;&#20869;&#26102;&#27573;&#30340;&#22330;&#26223;&#39640;&#32500;&#24230;&#24773;&#20917;&#65292;&#25105;&#20204;&#20351;&#29992;&#21151;&#33021;&#28145;&#24230;&#24230;&#37327;&#26469;&#23376;&#36873;&#25321;&#26368;&#26377;&#21487;&#33021;&#23545;&#30005;&#32593;&#36816;&#33829;&#39118;&#38505;&#26368;&#39640;&#30340;&#24322;&#24120;&#24773;&#26223;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#21151;&#33021;&#28145;&#24230;&#24230;&#37327;&#20197;&#21450;&#19968;&#31995;&#21015;&#36816;&#33829;&#39118;&#38505;&#65292;&#21253;&#25324;&#36127;&#33655;&#21066;&#20943;&#12289;&#36816;&#33829;&#25104;&#26412;&#12289;&#22791;&#29992;&#19981;&#36275;&#21644;&#21487;&#21464;&#21487;&#20877;&#29983;&#33021;&#28304;&#21066;&#20943;&#12290;&#36890;&#36807;&#23545;&#29616;&#23454;&#30340;Texas-7k&#30005;&#32593;&#36827;&#34892;&#26696;&#20363;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#31579;&#36873;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose and analyze the application of statistical functional depth metrics for the selection of extreme scenarios in day-ahead grid planning. Our primary motivation is screening of probabilistic scenarios for realized load and renewable generation, in order to identify scenarios most relevant for operational risk mitigation. To handle the high-dimensionality of the scenarios across asset classes and intra-day periods, we employ functional measures of depth to sub-select outlying scenarios that are most likely to be the riskiest for the grid operation. We investigate a range of functional depth measures, as well as a range of operational risks, including load shedding, operational costs, reserves shortfall and variable renewable energy curtailment. The effectiveness of the proposed screening approach is demonstrated through a case study on the realistic Texas-7k grid.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#24179;&#21488;&#65292;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#33021;&#22815;&#39640;&#25928;&#20934;&#30830;&#22320;&#35782;&#21035;&#20551;&#26032;&#38395;&#65292;&#21516;&#26102;&#25552;&#20379;&#23454;&#26102;&#20998;&#26512;&#21644;&#39564;&#35777;&#26032;&#38395;&#25991;&#31456;&#30495;&#23454;&#24615;&#30340;&#29992;&#25143;&#21451;&#22909;&#24179;&#21488;&#12290;</title><link>http://arxiv.org/abs/2309.11052</link><description>&lt;p&gt;
Fake News BR: &#19968;&#31181;&#29992;&#20110;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
Fake News BR: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#24179;&#21488;&#65292;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#33021;&#22815;&#39640;&#25928;&#20934;&#30830;&#22320;&#35782;&#21035;&#20551;&#26032;&#38395;&#65292;&#21516;&#26102;&#25552;&#20379;&#23454;&#26102;&#20998;&#26512;&#21644;&#39564;&#35777;&#26032;&#38395;&#25991;&#31456;&#30495;&#23454;&#24615;&#30340;&#29992;&#25143;&#21451;&#22909;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20551;&#26032;&#38395;&#20256;&#25773;&#35823;&#23548;&#20844;&#20247;&#33286;&#35770;&#30340;&#28508;&#21147;&#65292;&#20854;&#20256;&#25773;&#24050;&#25104;&#20026;&#36817;&#26399;&#20851;&#27880;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#23545;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#20013;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#37325;&#28857;&#20851;&#27880;&#26032;&#38395;&#31867;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#21253;&#25324;TF-IDF&#21644;Word2Vec&#65292;&#20174;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#29305;&#24449;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;&#20998;&#31867;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#22914;&#36923;&#36753;&#22238;&#24402;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#38543;&#26426;&#26862;&#26519;&#12289;AdaBoost&#21644;LightGBM&#65292;&#20351;&#29992;&#21253;&#21547;&#30495;&#23454;&#21644;&#20551;&#26032;&#38395;&#25991;&#31456;&#30340;&#25968;&#25454;&#38598;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#29575;&#21644;F1&#24471;&#20998;&#19978;&#37117;&#21462;&#24471;&#20102;&#39640;&#27700;&#24179;&#65292;&#35777;&#26126;&#20102;&#20854;&#35782;&#21035;&#20551;&#26032;&#38395;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#32593;&#31449;&#24179;&#21488;FAKENEWSBR.COM&#65292;&#20197;&#20415;&#39564;&#35777;&#26032;&#38395;&#25991;&#31456;&#30340;&#30495;&#23454;&#24615;&#12290;&#25105;&#20204;&#30340;&#24179;&#21488;&#25552;&#20379;&#23454;&#26102;&#20998;&#26512;&#65292;&#20801;&#35768;&#29992;&#25143;&#26816;&#26597;&#26032;&#38395;&#25991;&#31456;&#30340;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proliferation of fake news has become a significant concern in recent times due to its potential to spread misinformation and manipulate public opinion. In this paper, we present a comprehensive study on the detection of fake news in Brazilian Portuguese, focusing on journalistic-type news. We propose a machine learning-based approach that leverages natural language processing techniques, including TF-IDF and Word2Vec, to extract features from textual data. We evaluate the performance of various classification algorithms, such as logistic regression, support vector machine, random forest, AdaBoost, and LightGBM, on a dataset containing both true and fake news articles. The proposed approach achieves a high level of accuracy and F1-Score, demonstrating its effectiveness in identifying fake news. Additionally, we develop a user-friendly web platform, FAKENEWSBR.COM, to facilitate the verification of news articles' veracity. Our platform provides real-time analysis, allowing users to 
&lt;/p&gt;</description></item><item><title>PAGER&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#21644;&#19981;&#19968;&#33268;&#20998;&#25968;&#65292;&#23545;&#26679;&#26412;&#36827;&#34892;&#20998;&#32452;&#24182;&#25552;&#20379;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2309.10977</link><description>&lt;p&gt;
PAGER: &#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#20998;&#26512;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
PAGER: A Framework for Failure Analysis of Deep Regression Models. (arXiv:2309.10977v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10977
&lt;/p&gt;
&lt;p&gt;
PAGER&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#21644;&#19981;&#19968;&#33268;&#20998;&#25968;&#65292;&#23545;&#26679;&#26412;&#36827;&#34892;&#20998;&#32452;&#24182;&#25552;&#20379;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#37096;&#32626;AI&#27169;&#22411;&#38656;&#35201;&#20027;&#21160;&#26816;&#27979;&#28508;&#22312;&#30340;&#39044;&#27979;&#25925;&#38556;&#65292;&#20197;&#38450;&#27490;&#26114;&#36149;&#30340;&#38169;&#35823;&#12290;&#23613;&#31649;&#20998;&#31867;&#38382;&#39064;&#30340;&#25925;&#38556;&#26816;&#27979;&#24050;&#32463;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#22312;&#22238;&#24402;&#20219;&#21153;&#20013;&#34920;&#24449;&#25925;&#38556;&#27169;&#24335;&#26356;&#21152;&#22797;&#26434;&#19988;&#36739;&#23569;&#30740;&#31350;&#12290;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#25110;&#19982;&#35757;&#32451;&#20998;&#24067;&#30340;&#29305;&#24449;&#19981;&#19968;&#33268;&#26469;&#34920;&#24449;&#27169;&#22411;&#39118;&#38505;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#20165;&#38752;&#19981;&#30830;&#23450;&#24615;&#26080;&#27861;&#20934;&#30830;&#34920;&#24449;&#25925;&#38556;&#65292;&#36825;&#26159;&#30001;&#20110;&#21508;&#31181;&#35823;&#24046;&#28304;&#30340;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PAGER&#65288;&#22238;&#24402;&#22120;&#30340;&#21407;&#21017;&#24615;&#27867;&#21270;&#38169;&#35823;&#20998;&#26512;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#31995;&#32479;&#26816;&#27979;&#21644;&#34920;&#24449;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#30340;&#26694;&#26550;&#12290;&#22522;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#28145;&#24230;&#27169;&#22411;&#38170;&#23450;&#24605;&#24819;&#65292;PAGER&#23558;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#21644;&#26032;&#39062;&#30340;&#12289;&#20114;&#34917;&#30340;&#19981;&#19968;&#33268;&#20998;&#25968;&#32479;&#19968;&#36215;&#26469;&#65292;&#23558;&#26679;&#26412;&#32452;&#32455;&#25104;&#19981;&#21516;&#30340;&#39118;&#38505;&#21306;&#22495;&#65292;&#20174;&#32780;&#25552;&#20379;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Safe deployment of AI models requires proactive detection of potential prediction failures to prevent costly errors. While failure detection in classification problems has received significant attention, characterizing failure modes in regression tasks is more complicated and less explored. Existing approaches rely on epistemic uncertainties or feature inconsistency with the training distribution to characterize model risk. However, we show that uncertainties are necessary but insufficient to accurately characterize failure, owing to the various sources of error. In this paper, we propose PAGER (Principled Analysis of Generalization Errors in Regressors), a framework to systematically detect and characterize failures in deep regression models. Built upon the recently proposed idea of anchoring in deep models, PAGER unifies both epistemic uncertainties and novel, complementary non-conformity scores to organize samples into different risk regimes, thereby providing a comprehensive analys
&lt;/p&gt;</description></item><item><title>SPFQ&#26159;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#37327;&#21270;&#30340;&#24555;&#36895;&#38543;&#26426;&#31639;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#30340;&#36335;&#24452;&#36319;&#36394;&#21644;&#38543;&#26426;&#37327;&#21270;&#22120;&#26377;&#25928;&#22320;&#20943;&#23569;&#32593;&#32476;&#20013;&#30340;&#20887;&#20313;&#24182;&#25552;&#39640;&#37327;&#21270;&#25928;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#24314;&#31435;&#20102;&#20840;&#32593;&#32476;&#30340;&#35823;&#24046;&#30028;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;&#20855;&#26377;&#39640;&#26031;&#26435;&#37325;&#30340;&#22810;&#23618;&#32593;&#32476;&#30340;&#37327;&#21270;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.10975</link><description>&lt;p&gt;
SPFQ:&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#37327;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#21450;&#20854;&#35823;&#24046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
SPFQ: A Stochastic Algorithm and Its Error Analysis for Neural Network Quantization. (arXiv:2309.10975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10975
&lt;/p&gt;
&lt;p&gt;
SPFQ&#26159;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#37327;&#21270;&#30340;&#24555;&#36895;&#38543;&#26426;&#31639;&#27861;&#65292;&#36890;&#36807;&#36138;&#23146;&#30340;&#36335;&#24452;&#36319;&#36394;&#21644;&#38543;&#26426;&#37327;&#21270;&#22120;&#26377;&#25928;&#22320;&#20943;&#23569;&#32593;&#32476;&#20013;&#30340;&#20887;&#20313;&#24182;&#25552;&#39640;&#37327;&#21270;&#25928;&#29575;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#24314;&#31435;&#20102;&#20840;&#32593;&#32476;&#30340;&#35823;&#24046;&#30028;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20110;&#20855;&#26377;&#39640;&#26031;&#26435;&#37325;&#30340;&#22810;&#23618;&#32593;&#32476;&#30340;&#37327;&#21270;&#35777;&#26126;&#20102;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#20943;&#23569;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20887;&#20313;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#65292;&#29616;&#26377;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#37327;&#21270;&#25216;&#26415;&#24448;&#24448;&#32570;&#20047;&#20840;&#38754;&#30340;&#35823;&#24046;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#38543;&#26426;&#31639;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#23436;&#20840;&#35757;&#32451;&#22909;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#36138;&#23146;&#30340;&#36335;&#24452;&#36319;&#36394;&#26426;&#21046;&#32467;&#21512;&#38543;&#26426;&#37327;&#21270;&#22120;&#12290;&#20854;&#35745;&#31639;&#22797;&#26434;&#24230;&#21482;&#19982;&#32593;&#32476;&#20013;&#30340;&#26435;&#37325;&#25968;&#37327;&#21576;&#32447;&#24615;&#20851;&#31995;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22823;&#22411;&#32593;&#32476;&#30340;&#39640;&#25928;&#37327;&#21270;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#39318;&#27425;&#22312;&#26080;&#31351;&#23383;&#27597;&#26465;&#20214;&#21644;&#26368;&#23567;&#30340;&#26435;&#37325;&#21644;&#36755;&#20837;&#25968;&#25454;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#20840;&#32593;&#32476;&#30340;&#35823;&#24046;&#30028;&#12290;&#20316;&#20026;&#36825;&#19968;&#32467;&#26524;&#30340;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#37327;&#21270;&#20855;&#26377;&#39640;&#26031;&#26435;&#37325;&#30340;&#22810;&#23618;&#32593;&#32476;&#26102;&#65292;&#30456;&#23545;&#24179;&#26041;&#37327;&#21270;&#35823;&#24046;e&#30340;&#35201;&#28857;
&lt;/p&gt;
&lt;p&gt;
Quantization is a widely used compression method that effectively reduces redundancies in over-parameterized neural networks. However, existing quantization techniques for deep neural networks often lack a comprehensive error analysis due to the presence of non-convex loss functions and nonlinear activations. In this paper, we propose a fast stochastic algorithm for quantizing the weights of fully trained neural networks. Our approach leverages a greedy path-following mechanism in combination with a stochastic quantizer. Its computational complexity scales only linearly with the number of weights in the network, thereby enabling the efficient quantization of large networks. Importantly, we establish, for the first time, full-network error bounds, under an infinite alphabet condition and minimal assumptions on the weights and input data. As an application of this result, we prove that when quantizing a multi-layer network having Gaussian weights, the relative square quantization error e
&lt;/p&gt;</description></item><item><title>DPpack&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;R&#21253;&#65292;&#25552;&#20379;&#20102;&#24046;&#20998;&#38544;&#31169;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#24037;&#20855;&#38598;&#21512;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20445;&#25252;&#26426;&#21046;&#21644;&#25551;&#36848;&#24615;&#32479;&#35745;&#20989;&#25968;&#12290;&#23427;&#36824;&#25552;&#20379;&#20102;&#38544;&#31169;&#20445;&#25252;&#29256;&#26412;&#30340;&#36923;&#36753;&#22238;&#24402;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#32447;&#24615;&#22238;&#24402;&#30340;&#23454;&#29616;&#65292;&#20197;&#21450;&#23545;&#27599;&#20010;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2309.10965</link><description>&lt;p&gt;
DPpack&#65306;&#19968;&#20010;&#29992;&#20110;&#24046;&#20998;&#38544;&#31169;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;R&#21253;
&lt;/p&gt;
&lt;p&gt;
DPpack: An R Package for Differentially Private Statistical Analysis and Machine Learning. (arXiv:2309.10965v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10965
&lt;/p&gt;
&lt;p&gt;
DPpack&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;R&#21253;&#65292;&#25552;&#20379;&#20102;&#24046;&#20998;&#38544;&#31169;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#24037;&#20855;&#38598;&#21512;&#65292;&#21253;&#25324;&#19981;&#21516;&#30340;&#20445;&#25252;&#26426;&#21046;&#21644;&#25551;&#36848;&#24615;&#32479;&#35745;&#20989;&#25968;&#12290;&#23427;&#36824;&#25552;&#20379;&#20102;&#38544;&#31169;&#20445;&#25252;&#29256;&#26412;&#30340;&#36923;&#36753;&#22238;&#24402;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#32447;&#24615;&#22238;&#24402;&#30340;&#23454;&#29616;&#65292;&#20197;&#21450;&#23545;&#27599;&#20010;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#26159;&#30446;&#21069;&#29992;&#20110;&#20445;&#25252;&#20010;&#20154;&#38544;&#31169;&#30340;&#26368;&#20808;&#36827;&#30340;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#21457;&#24067;&#32858;&#21512;&#32479;&#35745;&#25968;&#25454;&#25110;&#20174;&#25968;&#25454;&#20013;&#26500;&#24314;&#32479;&#35745;/&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#24320;&#28304;&#30340;R&#21253;DPpack&#65292;&#25552;&#20379;&#20102;&#22823;&#37327;&#30340;&#24046;&#20998;&#38544;&#31169;&#20998;&#26512;&#24037;&#20855;&#12290;&#24403;&#21069;&#29256;&#26412;&#30340;DPpack&#23454;&#29616;&#20102;&#19977;&#31181;&#24120;&#29992;&#30340;DP&#20445;&#25252;&#26426;&#21046;&#65306;&#25289;&#26222;&#25289;&#26031;&#65292;&#39640;&#26031;&#21644;&#25351;&#25968;&#12290;&#27492;&#22806;&#65292;DPpack&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#26131;&#20110;&#35775;&#38382;&#30340;&#38544;&#31169;&#20445;&#25252;&#25551;&#36848;&#24615;&#32479;&#35745;&#20989;&#25968;&#24037;&#20855;&#21253;&#12290;&#20854;&#20013;&#21253;&#25324;&#22343;&#20540;&#12289;&#26041;&#24046;&#12289;&#21327;&#26041;&#24046;&#21644;&#20998;&#20301;&#25968;&#65292;&#20197;&#21450;&#30452;&#26041;&#22270;&#21644;&#21015;&#32852;&#34920;&#12290;&#26368;&#21518;&#65292;DPpack&#25552;&#20379;&#20102;&#22522;&#20110;&#38544;&#31169;&#20445;&#25252;&#30340;&#36923;&#36753;&#22238;&#24402;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#32447;&#24615;&#22238;&#24402;&#30340;&#29992;&#25143;&#21451;&#22909;&#23454;&#29616;&#65292;&#20197;&#21450;&#38024;&#23545;&#27599;&#20010;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#36825;&#20010;&#22823;&#37327;&#23454;&#29616;&#30340;&#24046;&#20998;&#38544;&#31169;&#32479;&#35745;&#21644;&#27169;&#22411;&#38598;&#21512;&#20801;&#35768;&#26080;&#40635;&#28902;&#22320;&#21033;&#29992;&#24046;&#24322;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential privacy (DP) is the state-of-the-art framework for guaranteeing privacy for individuals when releasing aggregated statistics or building statistical/machine learning models from data. We develop the open-source R package DPpack that provides a large toolkit of differentially private analysis. The current version of DPpack implements three popular mechanisms for ensuring DP: Laplace, Gaussian, and exponential. Beyond that, DPpack provides a large toolkit of easily accessible privacy-preserving descriptive statistics functions. These include mean, variance, covariance, and quantiles, as well as histograms and contingency tables. Finally, DPpack provides user-friendly implementation of privacy-preserving versions of logistic regression, SVM, and linear regression, as well as differentially private hyperparameter tuning for each of these models. This extensive collection of implemented differentially private statistics and models permits hassle-free utilization of differential
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#21644;&#22806;&#22312;&#36807;&#31243;&#20043;&#38388;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#36895;&#29575;&#22312;&#36866;&#24403;&#21305;&#37197;&#24179;&#28369;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26159;&#30456;&#31561;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.10918</link><description>&lt;p&gt;
Riemannian&#27969;&#24418;&#19978;Matern&#39640;&#26031;&#36807;&#31243;&#30340;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds. (arXiv:2309.10918v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#21644;&#22806;&#22312;&#36807;&#31243;&#20043;&#38388;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#36895;&#29575;&#22312;&#36866;&#24403;&#21305;&#37197;&#24179;&#28369;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26159;&#30456;&#31561;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#35768;&#22810;&#20381;&#36182;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#34987;&#20351;&#29992;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#22312;&#20960;&#20309;&#35774;&#32622;&#19979;&#22788;&#29702;&#36825;&#20123;&#27169;&#22411;&#30340;&#35745;&#31639;&#24037;&#20855;&#65292;&#20363;&#22914;&#65292;&#24403;&#36755;&#20837;&#20301;&#20110;Riemannian&#27969;&#24418;&#19978;&#26102;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#36825;&#20123;&#20869;&#22312;&#27169;&#22411;&#22312;&#29702;&#35770;&#19978;&#26159;&#21542;&#21487;&#20197;&#35777;&#26126;&#30456;&#27604;&#20110;&#23558;&#25152;&#26377;&#30456;&#20851;&#37327;&#23884;&#20837;&#21040;$\mathbb{R}^d$&#24182;&#20351;&#29992;&#26222;&#36890;&#27431;&#20960;&#37324;&#24503;&#39640;&#26031;&#36807;&#31243;&#30340;&#38480;&#21046;&#65292;&#21487;&#20197;&#24102;&#26469;&#26356;&#22909;&#30340;&#24615;&#33021;&#65311;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#30340;&#26368;&#20248;&#25910;&#32553;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#27969;&#24418;&#21644;&#29615;&#22659;Sobolev&#31354;&#38388;&#20043;&#38388;&#30340;&#36857;&#21644;&#25193;&#23637;&#23450;&#29702;&#35777;&#26126;&#20102;&#22806;&#22312;&#36807;&#31243;&#30340;&#31867;&#20284;&#36895;&#29575;&#65306;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25152;&#24471;&#21040;&#30340;&#36895;&#29575;&#19982;&#20869;&#22312;&#36807;&#31243;&#30340;&#36895;&#29575;&#30456;&#31526;&#65292;&#21069;&#25552;&#26159;&#23427;&#20204;&#30340;&#24179;&#28369;&#21442;&#25968;&#36866;&#24403;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#19968;&#20123;&#23454;&#35777;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23545;&#36825;&#20123;&#36895;&#29575;&#30340;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Mat\'ern Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#20316;&#32773;&#36890;&#36807;&#29702;&#35770;&#19982;&#23454;&#39564;&#35777;&#26126;&#20102;&#23558;&#27880;&#24847;&#21147;&#25918;&#22312;&#19978;&#19979;&#25991;-&#26410;&#26631;&#35760;&#26679;&#26412;&#19978;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#39046;&#22495;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.09888</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#8776;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
Context $\approx$ Environment. (arXiv:2309.09888v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09888
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#20316;&#32773;&#36890;&#36807;&#29702;&#35770;&#19982;&#23454;&#39564;&#35777;&#26126;&#20102;&#23558;&#27880;&#24847;&#21147;&#25918;&#22312;&#19978;&#19979;&#25991;-&#26410;&#26631;&#35760;&#26679;&#26412;&#19978;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#39046;&#22495;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30740;&#31350;&#30340;&#20013;&#24515;&#22312;&#20110;&#20004;&#20010;&#26041;&#38754;&#12290;&#19968;&#26041;&#38754;&#65292;&#31038;&#21306;&#27491;&#22312;&#21162;&#21147;&#26500;&#24314;&#33021;&#22815;&#20002;&#24323;&#34394;&#20551;&#30456;&#20851;&#24615;&#24182;&#22312;&#26032;&#39062;&#30340;&#27979;&#35797;&#29615;&#22659;&#20013;&#26356;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#30340;&#27169;&#22411;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#27809;&#26377;&#20219;&#20309;&#25552;&#26696;&#33021;&#22815;&#20196;&#20154;&#20449;&#26381;&#22320;&#36229;&#36234;&#31616;&#21333;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22522;&#32447;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#32463;&#25104;&#20026;&#33021;&#22815;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#12289;&#26681;&#25454;&#29992;&#25143;&#36890;&#36807;&#25552;&#31034;&#26045;&#21152;&#30340;&#22810;&#31181;&#19978;&#19979;&#25991;&#32972;&#26223;&#28789;&#27963;&#27867;&#21270;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#35748;&#20026;&#19978;&#19979;&#25991;&#8776;&#29615;&#22659;&#65292;&#24182;&#20551;&#35774;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#38544;&#34255;&#30528;&#26356;&#22909;&#30340;&#39046;&#22495;&#27867;&#21270;&#20043;&#38053;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#29702;&#35770;&#19982;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27880;&#24847;&#19978;&#19979;&#25991;-&#26410;&#26631;&#35760;&#30340;&#26679;&#26412;&#30340;&#37325;&#35201;&#24615;&#65292;&#36825;&#31181;&#27880;&#24847;&#21487;&#20197;&#20351;&#25105;&#20204;&#25552;&#20986;&#30340;In-Context Risk Minimization (ICRM)&#31639;&#27861;&#32858;&#28966;&#20110;&#27979;&#35797;&#29615;&#22659;&#39118;&#38505;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two lines of work are taking the central stage in AI research. On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments. Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline. On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting. In this paper, we argue that context $\approx$ environment, and posit that in-context learning holds the key to better domain generalization. Via extensive theory and experiments, we show that paying attention to context$\unicode{x2013}\unicode{x2013}$unlabeled examples as they arrive$\unicode{x2013}\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#21644;softmax&#20998;&#31867;&#22120;&#20013;&#30340;&#36870;&#21521;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20132;&#20114;&#24335;&#25110;&#23454;&#26102;&#24212;&#29992;&#20013;&#33719;&#24471;&#20934;&#30830;&#35299;&#12290;</title><link>http://arxiv.org/abs/2309.08945</link><description>&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#21644;softmax&#20998;&#31867;&#22120;&#30340;&#36870;&#21521;&#20998;&#31867;&#65306;&#39640;&#25928;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Inverse classification with logistic and softmax classifiers: efficient optimization. (arXiv:2309.08945v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#21644;softmax&#20998;&#31867;&#22120;&#20013;&#30340;&#36870;&#21521;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20132;&#20114;&#24335;&#25110;&#23454;&#26102;&#24212;&#29992;&#20013;&#33719;&#24471;&#20934;&#30830;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#19968;&#31181;&#29305;&#23450;&#31867;&#22411;&#30340;&#38382;&#39064;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20852;&#36259;&#65292;&#21363;&#22312;&#35757;&#32451;&#22909;&#30340;&#20998;&#31867;&#22120;&#19978;&#36827;&#34892;&#26597;&#35810;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24076;&#26395;&#25214;&#21040;&#19982;&#32473;&#23450;&#36755;&#20837;&#23454;&#20363;&#26368;&#25509;&#36817;&#30340;&#23454;&#20363;&#65292;&#20197;&#20351;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#26631;&#31614;&#20197;&#25152;&#38656;&#30340;&#26041;&#24335;&#25913;&#21464;&#12290;&#36825;&#31867;&#38382;&#39064;&#21253;&#25324;&#21453;&#20107;&#23454;&#35299;&#37322;&#65292;&#23545;&#25239;&#24615;&#31034;&#20363;&#21644;&#27169;&#22411;&#21453;&#28436;&#12290;&#25152;&#26377;&#36825;&#20123;&#38382;&#39064;&#23454;&#36136;&#19978;&#37117;&#26159;&#28041;&#21450;&#36755;&#20837;&#23454;&#20363;&#21521;&#37327;&#19978;&#30340;&#22266;&#23450;&#20998;&#31867;&#22120;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#24076;&#26395;&#33021;&#22815;&#24555;&#36895;&#35299;&#20915;&#20197;&#29992;&#20110;&#20132;&#20114;&#24335;&#25110;&#23454;&#26102;&#24212;&#29992;&#12290;&#26412;&#25991;&#37325;&#28857;&#22312;&#20110;&#23545;&#36923;&#36753;&#22238;&#24402;&#21644;softmax&#20998;&#31867;&#22120;&#36825;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#20998;&#31867;&#22120;&#36827;&#34892;&#39640;&#25928;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29305;&#27530;&#24615;&#36136;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#65292;&#20248;&#21270;&#38382;&#39064;&#21487;&#20197;&#29992;&#38381;&#24335;&#35299;&#27714;&#35299;&#65292;&#23545;&#20110;softmax&#20998;&#31867;&#22120;&#65292;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#20294;&#38750;&#24120;&#24555;&#36895;&#22320;&#27714;&#35299;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#31934;&#30830;&#22320;&#35299;&#20915;&#20219;&#19968;&#24773;&#20917;&#65288;&#25509;&#36817;&#26426;&#22120;&#31934;&#24230;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, a certain type of problems have become of interest where one wants to query a trained classifier. Specifically, one wants to find the closest instance to a given input instance such that the classifier's predicted label is changed in a desired way. Examples of these ``inverse classification'' problems are counterfactual explanations, adversarial examples and model inversion. All of them are fundamentally optimization problems over the input instance vector involving a fixed classifier, and it is of interest to achieve a fast solution for interactive or real-time applications. We focus on solving this problem efficiently for two of the most widely used classifiers: logistic regression and softmax classifiers. Owing to special properties of these models, we show that the optimization can be solved in closed form for logistic regression, and iteratively but extremely fast for the softmax classifier. This allows us to solve either case exactly (to nearly machine precision)
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#26469;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.04810</link><description>&lt;p&gt;
&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;&#65306;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#20449;&#24687;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26469;&#36827;&#34892;&#20056;&#31215;&#27969;&#24418;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization. (arXiv:2309.04810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#26469;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#31354;&#38388;&#30340;&#20960;&#20309;&#32467;&#26500;&#19982;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#40784;&#65292;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20351;&#29992;&#20855;&#26377;&#24658;&#23450;&#26354;&#29575;&#30340;&#21452;&#26354;&#21644;&#29699;&#24418;&#31354;&#38388;&#65292;&#25110;&#32773;&#23427;&#20204;&#30340;&#32452;&#21512;&#65292;&#26469;&#26356;&#22909;&#22320;&#24314;&#27169;&#28508;&#22312;&#31354;&#38388;&#24182;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#32780;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#38382;&#39064;&#36824;&#27809;&#26377;&#32473;&#20104;&#36275;&#22815;&#20851;&#27880;&#12290;&#25105;&#20204;&#22312;&#25968;&#23398;&#19978;&#23450;&#20041;&#20102;&#36825;&#20010;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#31216;&#20026;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#30340;&#20505;&#36873;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#26032;&#27010;&#24565;&#36317;&#31163;&#65292;&#20197;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20026;&#20102;&#35745;&#31639;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#26597;&#35810;&#35780;&#20272;&#25628;&#32034;&#30001;&#24658;&#23450;&#26354;&#29575;&#27169;&#22411;&#31354;&#38388;&#20056;&#31215;&#32452;&#25104;&#30340;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#30340;&#21407;&#21017;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Ha
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.07843</link><description>&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) &#35813;&#35770;&#25991;&#26631;&#39064;&#24050;&#32763;&#35793;&#65306;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07843
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#21307;&#30103;&#26088;&#22312;&#36890;&#36807;&#22312;&#20010;&#20154;&#26085;&#24120;&#29983;&#27963;&#20013;&#25552;&#20379;&#24178;&#39044;&#26469;&#25552;&#39640;&#20581;&#24247;&#32467;&#26524;&#12290;&#29031;&#39038;&#20276;&#20387;&#21644;&#31038;&#20250;&#25903;&#25345;&#32593;&#32476;&#30340;&#21442;&#19982;&#32463;&#24120;&#22312;&#24110;&#21161;&#20010;&#20154;&#31649;&#29702;&#32321;&#37325;&#30340;&#21307;&#30103;&#26465;&#20214;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#20026;&#31227;&#21160;&#21307;&#30103;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#35774;&#35745;&#38024;&#23545;&#20108;&#20803;&#20851;&#31995;&#8212;&#8212;&#30446;&#26631;&#20154;&#21644;&#20854;&#29031;&#39038;&#20276;&#20387;&#20043;&#38388;&#20851;&#31995;&#8212;&#8212;&#20197;&#25552;&#39640;&#31038;&#20250;&#25903;&#25345;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#65288;Dyadic RL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#29615;&#22659;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#21450;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#20010;&#24615;&#21270;&#24178;&#39044;&#25514;&#26045;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#22810;&#32452;&#24178;&#39044;&#25514;&#26045;&#24433;&#21709;&#30528;&#20108;&#20803;&#20851;&#31995;&#22312;&#22810;&#20010;&#26102;&#38388;&#38388;&#38548;&#20869;&#12290;&#24320;&#21457;&#30340;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#38382;&#39064;&#35774;&#23450;&#65292;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#24182;&#30830;&#23450;&#20102;&#36951;&#25022;&#36793;&#30028;&#12290;&#36890;&#36807;&#27169;&#25311;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
&lt;/p&gt;</description></item><item><title>Bandit&#21453;&#39304;&#19979;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#20851;&#38190;&#22312;&#20110;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#65292;&#26080;&#35770;&#26631;&#31614;&#31354;&#38388;&#26159;&#21542;&#26080;&#30028;&#12290;</title><link>http://arxiv.org/abs/2308.04620</link><description>&lt;p&gt;
&#22810;&#31867;&#22312;&#32447;&#23398;&#20064;&#22312;Bandit&#21453;&#39304;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multiclass Online Learnability under Bandit Feedback. (arXiv:2308.04620v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04620
&lt;/p&gt;
&lt;p&gt;
Bandit&#21453;&#39304;&#19979;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#20851;&#38190;&#22312;&#20110;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#65292;&#26080;&#35770;&#26631;&#31614;&#31354;&#38388;&#26159;&#21542;&#26080;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Bandit&#21453;&#39304;&#19979;&#30340;&#22810;&#31867;&#22312;&#32447;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;(daniely2013price)&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#23637;&#31034;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#26159;&#22810;&#31867;&#22312;&#32447;&#23398;&#20064;&#30340;&#24517;&#35201;&#19988;&#20805;&#20998;&#26465;&#20214;&#65292;&#21363;&#20351;&#26631;&#31614;&#31354;&#38388;&#26159;&#26080;&#30028;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34917;&#20805;&#20102;(hanneke2023multiclass)&#30340;&#26368;&#36817;&#24037;&#20316;&#65292;&#20182;&#20204;&#22312;&#26631;&#31614;&#31354;&#38388;&#26080;&#30028;&#30340;&#20840;&#20449;&#24687;&#35774;&#32622;&#20013;&#65292;&#23637;&#31034;&#20102;Littlestone&#32500;&#24230;&#21051;&#30011;&#20102;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;INDEED&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#30340;&#25805;&#20316;&#31526;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#19988;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2304.07993</link><description>&lt;p&gt;
&#20869;&#22312;&#19978;&#19979;&#25991;&#31639;&#23376;&#23398;&#20064;&#29992;&#20110;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
In-Context Operator Learning for Differential Equation Problems. (arXiv:2304.07993v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;INDEED&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#19981;&#21516;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#30340;&#25805;&#20316;&#31526;&#65292;&#32780;&#26080;&#38656;&#37325;&#26032;&#35757;&#32451;&#65292;&#19988;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#8212;&#8212;IN-context Differential Equation Encoder-Decoder&#65288;INDEED&#65289;&#65292;&#29992;&#20110;&#20174;&#25968;&#25454;&#20013;&#21516;&#26102;&#23398;&#20064;&#25805;&#20316;&#31526;&#24182;&#22312;&#25512;&#29702;&#38454;&#27573;&#23558;&#20854;&#24212;&#29992;&#20110;&#26032;&#38382;&#39064;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#26435;&#37325;&#26356;&#26032;&#12290;&#29616;&#26377;&#26041;&#27861;&#23616;&#38480;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36924;&#36817;&#29305;&#23450;&#30340;&#26041;&#31243;&#35299;&#25110;&#29305;&#23450;&#30340;&#25805;&#20316;&#31526;&#65292;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#26041;&#31243;&#30340;&#26032;&#38382;&#39064;&#12290;&#36890;&#36807;&#35757;&#32451;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25805;&#20316;&#31526;&#23398;&#20064;&#22120;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#25670;&#33073;&#20026;&#26032;&#38382;&#39064;&#37325;&#26032;&#35757;&#32451;&#65288;&#29978;&#33267;&#24494;&#35843;&#65289;&#31070;&#32463;&#32593;&#32476;&#30340;&#22256;&#25200;&#65292;&#36824;&#21487;&#20197;&#21033;&#29992;&#25805;&#20316;&#31526;&#20043;&#38388;&#20849;&#20139;&#30340;&#20849;&#21516;&#28857;&#65292;&#36825;&#26679;&#22312;&#23398;&#20064;&#26032;&#30340;&#25805;&#20316;&#31526;&#26102;&#21482;&#38656;&#35201;&#26497;&#23569;&#30340;&#28436;&#31034;&#21363;&#21487;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#26174;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#23569;&#26679;&#26412;&#23398;&#20064;&#22120;&#30340;&#33021;&#21147;&#65292;&#29992;&#20110;&#21508;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#24494;&#20998;&#26041;&#31243;&#38382;&#39064;&#65292;&#21253;&#25324;ODE&#21644;PDE&#30340;&#27491;&#21521;&#21644;&#21453;&#21521;&#38382;&#39064;&#65292;&#21516;&#26102;&#26174;&#31034;&#23427;&#21487;&#20197;&#25512;&#24191;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new neural-network-based approach, namely IN-context Differential Equation Encoder-Decoder (INDEED), to simultaneously learn operators from data and apply it to new questions during the inference stage, without any weight update. Existing methods are limited to using a neural network to approximate a specific equation solution or a specific operator, requiring retraining when switching to a new problem with different equations. By training a single neural network as an operator learner, we can not only get rid of retraining (even fine-tuning) the neural network for new problems, but also leverage the commonalities shared across operators so that only a few demos are needed when learning a new operator. Our numerical results show the neural network's capability as a few-shot operator learner for a diversified type of differential equation problems, including forward and inverse problems of ODEs and PDEs, and also show that it can generalize its learning capabilit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#24212;&#29992;&#20110;ASR&#31995;&#32479;&#20013;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#23884;&#20837;&#25552;&#21462;&#27969;&#31243;&#21644;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#30340;&#22768;&#23398;&#27169;&#22411;&#21644;&#28155;&#21152;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#65292;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;WER&#24615;&#33021;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2301.04571</link><description>&lt;p&gt;
&#20998;&#26512;&#21644;&#25913;&#36827;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#29992;&#20110;ASR
&lt;/p&gt;
&lt;p&gt;
Analyzing And Improving Neural Speaker Embeddings for ASR. (arXiv:2301.04571v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04571
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#24212;&#29992;&#20110;ASR&#31995;&#32479;&#20013;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#23884;&#20837;&#25552;&#21462;&#27969;&#31243;&#21644;&#38598;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#30340;&#22768;&#23398;&#27169;&#22411;&#21644;&#28155;&#21152;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#65292;&#33719;&#24471;&#20102;&#26174;&#33879;&#30340;WER&#24615;&#33021;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#36890;&#36807;DNN&#27169;&#22411;&#32534;&#30721;&#35828;&#35805;&#32773;&#30340;&#35821;&#38899;&#29305;&#24449;&#65292;&#34987;&#24191;&#27867;&#29992;&#20110;&#35828;&#35805;&#32773;&#39564;&#35777;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#22312;ASR&#31995;&#32479;&#20013;&#30340;&#20351;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#38598;&#25104;&#21040;&#22522;&#20110;Conformer&#30340;&#28151;&#21512;HMM ASR&#31995;&#32479;&#20013;&#65292;&#24182;&#36827;&#34892;&#25913;&#36827;&#12290;&#23545;&#20110;ASR&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#23884;&#20837;&#25552;&#21462;&#27969;&#31243;&#65292;&#24182;&#32467;&#21512;&#21152;&#26435;&#31616;&#21333;&#21152;&#27861;&#38598;&#25104;&#26041;&#27861;&#65292;&#20351;&#24471;x-vector&#21644;c-vector&#36798;&#21040;&#19982;i-vector&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#27604;&#36739;&#21644;&#20998;&#26512;&#19981;&#21516;&#30340;&#35828;&#35805;&#20154;&#23884;&#20837;&#12290;&#25105;&#20204;&#36890;&#36807;&#20174;newbob&#23398;&#20064;&#29575;&#35843;&#24230;&#36716;&#25442;&#20026;&#21333;&#21608;&#26399;&#23398;&#20064;&#35843;&#24230;&#26469;&#25913;&#36827;&#22768;&#23398;&#27169;&#22411;&#65292;&#22312;Switchboard&#19978;&#30456;&#23545;WER&#38477;&#20302;&#20102;&#32422;3%&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#25972;&#20307;&#35757;&#32451;&#26102;&#38388;17%&#12290;&#36890;&#36807;&#36827;&#19968;&#27493;&#28155;&#21152;&#31070;&#32463;&#35828;&#35805;&#20154;&#23884;&#20837;&#65292;&#25105;&#20204;&#22312;Hub5'00&#19978;&#33719;&#24471;&#20102;&#39069;&#22806;&#32422;3%&#30340;&#30456;&#23545;WER&#25913;&#36827;&#12290;&#25105;&#20204;&#26368;&#22909;&#30340;&#22522;&#20110;Conformer&#30340;&#28151;&#21512;A
&lt;/p&gt;
&lt;p&gt;
Neural speaker embeddings encode the speaker's speech characteristics through a DNN model and are prevalent for speaker verification tasks. However, few studies have investigated the usage of neural speaker embeddings for an ASR system. In this work, we present our efforts w.r.t integrating neural speaker embeddings into a conformer based hybrid HMM ASR system. For ASR, our improved embedding extraction pipeline in combination with the Weighted-Simple-Add integration method results in x-vector and c-vector reaching on par performance with i-vectors. We further compare and analyze different speaker embeddings. We present our acoustic model improvements obtained by switching from newbob learning rate schedule to one cycle learning schedule resulting in a ~3% relative WER reduction on Switchboard, additionally reducing the overall training time by 17%. By further adding neural speaker embeddings, we gain additional ~3% relative WER improvement on Hub5'00. Our best Conformer-based hybrid A
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#32479;&#35745;&#21644;&#35745;&#31639;&#36793;&#30028;&#26469;&#20445;&#35777;&#24433;&#21709;&#35786;&#26029;&#30340;&#26377;&#25928;&#24615;&#65292;&#36890;&#36807;&#20351;&#29992;&#39640;&#25928;&#30340;&#36870;-Hessian-&#21521;&#37327;&#20056;&#31215;&#23454;&#29616;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#20013;&#20934;&#30830;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#25968;&#25454;&#28857;&#25110;&#23376;&#38598;&#12290;</title><link>http://arxiv.org/abs/2212.04014</link><description>&lt;p&gt;
&#32479;&#35745;&#21644;&#35745;&#31639;&#20445;&#35777;&#20102;&#24433;&#21709;&#35786;&#26029;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical and Computational Guarantees for Influence Diagnostics. (arXiv:2212.04014v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.04014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#32479;&#35745;&#21644;&#35745;&#31639;&#36793;&#30028;&#26469;&#20445;&#35777;&#24433;&#21709;&#35786;&#26029;&#30340;&#26377;&#25928;&#24615;&#65292;&#36890;&#36807;&#20351;&#29992;&#39640;&#25928;&#30340;&#36870;-Hessian-&#21521;&#37327;&#20056;&#31215;&#23454;&#29616;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#20013;&#20934;&#30830;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#25968;&#25454;&#28857;&#25110;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24433;&#21709;&#35786;&#26029;&#65292;&#22914;&#24433;&#21709;&#20989;&#25968;&#21644;&#36817;&#20284;&#26368;&#22823;&#24433;&#21709;&#25200;&#21160;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24212;&#29992;&#20013;&#24456;&#21463;&#27426;&#36814;&#12290;&#24433;&#21709;&#35786;&#26029;&#26159;&#29992;&#20110;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#25968;&#25454;&#28857;&#25110;&#25968;&#25454;&#23376;&#38598;&#30340;&#24378;&#22823;&#32479;&#35745;&#24037;&#20855;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#25928;&#30340;&#36870;-Hessian-&#21521;&#37327;&#20056;&#31215;&#23454;&#29616;&#24314;&#31435;&#20102;&#24433;&#21709;&#20989;&#25968;&#21644;&#36817;&#20284;&#26368;&#22823;&#24433;&#21709;&#25200;&#21160;&#30340;&#26377;&#38480;&#26679;&#26412;&#32479;&#35745;&#30028;&#38480;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#20351;&#29992;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#22522;&#20110;&#22823;&#35268;&#27169;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#27169;&#22411;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Influence diagnostics such as influence functions and approximate maximum influence perturbations are popular in machine learning and in AI domain applications. Influence diagnostics are powerful statistical tools to identify influential datapoints or subsets of datapoints. We establish finite-sample statistical bounds, as well as computational complexity bounds, for influence functions and approximate maximum influence perturbations using efficient inverse-Hessian-vector product implementations. We illustrate our results with generalized linear models and large attention based models on synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#33258;&#36866;&#24212;&#36864;&#28779;&#30340;&#26041;&#27861;&#65292;&#23558;&#33258;&#23398;&#20064;Monte Carlo&#65288;SLMC&#65289;&#26041;&#27861;&#24212;&#29992;&#20110;&#22810;&#23792;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;Monte Carlo&#26356;&#26032;&#65292;&#24182;&#35299;&#20915;&#20102;&#24314;&#35758;&#27169;&#22411;&#30340;&#27169;&#24335;&#23849;&#28291;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.14024</link><description>&lt;p&gt;
&#36808;&#21521;&#26080;&#38480;&#33258;&#23398;&#20064;&#30340;&#24182;&#34892;&#33258;&#36866;&#24212;&#36864;&#28779;&#30340;MCMC&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Toward Unlimited Self-Learning MCMC with Parallel Adaptive Annealing. (arXiv:2211.14024v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14024
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#24182;&#34892;&#33258;&#36866;&#24212;&#36864;&#28779;&#30340;&#26041;&#27861;&#65292;&#23558;&#33258;&#23398;&#20064;Monte Carlo&#65288;SLMC&#65289;&#26041;&#27861;&#24212;&#29992;&#20110;&#22810;&#23792;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;Monte Carlo&#26356;&#26032;&#65292;&#24182;&#35299;&#20915;&#20102;&#24314;&#35758;&#27169;&#22411;&#30340;&#27169;&#24335;&#23849;&#28291;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#23398;&#20064;Monte Carlo&#65288;SLMC&#65289;&#26041;&#27861;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21152;&#36895;Markov&#38142;Monte Carlo&#65288;MCMC&#65289;&#26041;&#27861;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#28508;&#22312;&#29983;&#25104;&#27169;&#22411;&#65292;SLMC&#26041;&#27861;&#23454;&#29616;&#20102;&#20855;&#26377;&#36739;&#23569;&#33258;&#30456;&#20851;&#24615;&#30340;&#39640;&#25928;Monte Carlo&#26356;&#26032;&#12290;&#28982;&#32780;&#65292;SLMC&#26041;&#27861;&#38590;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#22810;&#23792;&#20998;&#24067;&#65292;&#20854;&#20013;&#38590;&#20197;&#33719;&#24471;&#35757;&#32451;&#25968;&#25454;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24182;&#34892;&#33258;&#36866;&#24212;&#36864;&#28779;&#26041;&#27861;&#65292;&#23427;&#20351;SLMC&#26041;&#27861;&#30452;&#25509;&#24212;&#29992;&#20110;&#20855;&#26377;&#36880;&#28176;&#35757;&#32451;&#30340;&#24314;&#35758;&#20998;&#24067;&#30340;&#22810;&#23792;&#20998;&#24067;&#12290;&#24182;&#34892;&#33258;&#36866;&#24212;&#36864;&#28779;&#22522;&#20110;&#65288;i&#65289;&#24102;&#26377;&#36864;&#28779;&#30340;&#39034;&#24207;&#23398;&#20064;&#65292;&#20197;&#32487;&#25215;&#21644;&#26356;&#26032;&#27169;&#22411;&#21442;&#25968;&#65292;&#65288;ii&#65289;&#33258;&#36866;&#24212;&#36864;&#28779;&#65292;&#20197;&#33258;&#21160;&#26816;&#27979;&#27424;&#23398;&#20064;&#65292;&#65288;iii&#65289;&#24182;&#34892;&#36864;&#28779;&#65292;&#20197;&#20943;&#36731;&#24314;&#35758;&#27169;&#22411;&#30340;&#27169;&#24335;&#23849;&#28291;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#20316;&#20026;SLMC&#24314;&#35758;&#30340;VAE-SLMC&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#30340;&#24182;&#34892;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-learning Monte Carlo (SLMC) methods are recently proposed to accelerate Markov chain Monte Carlo (MCMC) methods using a machine learning model. With latent generative models, SLMC methods realize efficient Monte Carlo updates with less autocorrelation. However, SLMC methods are difficult to directly apply to multimodal distributions for which training data are difficult to obtain. To solve the limitation, we propose parallel adaptive annealing, which makes SLMC methods directly apply to multimodal distributions with a gradually trained proposal while annealing target distribution. Parallel adaptive annealing is based on (i) sequential learning with annealing to inherit and update the model parameters, (ii) adaptive annealing to automatically detect under-learning, and (iii) parallel annealing to mitigate mode collapse of proposal models. We also propose VAE-SLMC method which utilizes a variational autoencoder (VAE) as a proposal of SLMC to make efficient parallel proposals indepen
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#36229;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#21160;&#24577;&#35748;&#30693;&#27169;&#22411;&#12290;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#32500;&#24230;&#21644;&#36229;&#32479;&#35745;&#35270;&#35282;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#31995;&#32479;&#20013;&#30340;&#21160;&#24577;&#24615;&#36136;&#65292;&#24182;&#21033;&#29992;&#20223;&#30495;&#21644;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24674;&#22797;&#26102;&#21464;&#21644;&#26102;&#19981;&#21464;&#21442;&#25968;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.13165</link><description>&lt;p&gt;
&#31070;&#32463;&#36229;&#32479;&#35745;&#23398;&#29992;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#21160;&#24577;&#35748;&#30693;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Superstatistics for Bayesian Estimation of Dynamic Cognitive Model. (arXiv:2211.13165v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#36229;&#32479;&#35745;&#23398;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#20272;&#35745;&#21160;&#24577;&#35748;&#30693;&#27169;&#22411;&#12290;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#32500;&#24230;&#21644;&#36229;&#32479;&#35745;&#35270;&#35282;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#31995;&#32479;&#20013;&#30340;&#21160;&#24577;&#24615;&#36136;&#65292;&#24182;&#21033;&#29992;&#20223;&#30495;&#21644;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24674;&#22797;&#26102;&#21464;&#21644;&#26102;&#19981;&#21464;&#21442;&#25968;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#30693;&#30340;&#25968;&#23398;&#27169;&#22411;&#36890;&#24120;&#26159;&#26080;&#35760;&#24518;&#30340;&#65292;&#24573;&#30053;&#20102;&#21442;&#25968;&#30340;&#28508;&#22312;&#27874;&#21160;&#12290;&#28982;&#32780;&#65292;&#20154;&#31867;&#35748;&#30693;&#26412;&#36136;&#19978;&#26159;&#21160;&#24577;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#22312;&#26426;&#26800;&#35748;&#30693;&#27169;&#22411;&#20013;&#24341;&#20837;&#26102;&#38388;&#32500;&#24230;&#65292;&#24182;&#20174;&#36229;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#20272;&#35745;&#25152;&#24471;&#21040;&#30340;&#21160;&#24577;&#24615;&#36136;&#12290;&#36825;&#26679;&#30340;&#27169;&#22411;&#21253;&#25324;&#20102;&#19968;&#20010;&#20302;&#32423;&#35266;&#27979;&#27169;&#22411;&#21644;&#19968;&#20010;&#39640;&#32423;&#36716;&#25442;&#27169;&#22411;&#20043;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#35266;&#27979;&#27169;&#22411;&#25551;&#36848;&#20102;&#31995;&#32479;&#30340;&#23616;&#37096;&#34892;&#20026;&#65292;&#36716;&#25442;&#27169;&#22411;&#35268;&#23450;&#20102;&#35266;&#27979;&#27169;&#22411;&#21442;&#25968;&#38543;&#26102;&#38388;&#28436;&#21270;&#30340;&#26041;&#24335;&#12290;&#20026;&#20102;&#20811;&#26381;&#36229;&#32479;&#35745;&#27169;&#22411;&#22797;&#26434;&#24615;&#24102;&#26469;&#30340;&#20272;&#35745;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#24182;&#39564;&#35777;&#20102;&#19968;&#31181;&#22522;&#20110;&#20223;&#30495;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#65292;&#21487;&#20197;&#24674;&#22797;&#26102;&#21464;&#21644;&#26102;&#19981;&#21464;&#21442;&#25968;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20004;&#20010;&#24050;&#26377;&#30340;&#33021;&#22815;&#20272;&#35745;&#26102;&#21464;&#21442;&#25968;&#30340;&#26694;&#26550;&#36827;&#34892;&#22522;&#20934;&#27979;&#35797;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#25311;&#21512;&#21160;&#24577;&#29256;&#26412;&#30340;&#24046;&#20998;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mathematical models of cognition are often memoryless and ignore potential fluctuations of their parameters. However, human cognition is inherently dynamic. Thus, we propose to augment mechanistic cognitive models with a temporal dimension and estimate the resulting dynamics from a superstatistics perspective. Such a model entails a hierarchy between a low-level observation model and a high-level transition model. The observation model describes the local behavior of a system, and the transition model specifies how the parameters of the observation model evolve over time. To overcome the estimation challenges resulting from the complexity of superstatistical models, we develop and validate a simulation-based deep learning method for Bayesian inference, which can recover both time-varying and time-invariant parameters. We first benchmark our method against two existing frameworks capable of estimating time-varying parameters. We then apply our method to fit a dynamic version of the diff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#24863;&#20852;&#36259;&#28857;&#30340;&#36873;&#25321;&#21644;&#35745;&#31639;&#65292;&#25552;&#20379;&#20102;&#31283;&#23450;&#21487;&#38752;&#30340;&#31232;&#30095;&#36924;&#36817;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.07893</link><description>&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;Cover Trees&#30340;&#26368;&#23567;&#38388;&#38548;&#23454;&#29616;&#25968;&#20540;&#31283;&#23450;&#30340;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Numerically Stable Sparse Gaussian Processes via Minimum Separation using Cover Trees. (arXiv:2210.07893v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07893
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#24863;&#20852;&#36259;&#28857;&#30340;&#36873;&#25321;&#21644;&#35745;&#31639;&#65292;&#25552;&#20379;&#20102;&#31283;&#23450;&#21487;&#38752;&#30340;&#31232;&#30095;&#36924;&#36817;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#24120;&#29992;&#20110;&#36739;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#20915;&#31574;&#31995;&#32479;&#20013;&#65292;&#20363;&#22914;&#22320;&#29702;&#31354;&#38388;&#24314;&#27169;&#12289;&#36125;&#21494;&#26031;&#20248;&#21270;&#25110;&#28508;&#22312;&#39640;&#26031;&#27169;&#22411;&#20013;&#12290;&#22312;&#19968;&#20010;&#31995;&#32479;&#20013;&#65292;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#20197;&#31283;&#23450;&#21487;&#38752;&#30340;&#26041;&#24335;&#36816;&#34892;&#65292;&#20197;&#30830;&#20445;&#19982;&#31995;&#32479;&#30340;&#20854;&#20182;&#37096;&#20998;&#27491;&#30830;&#20132;&#20114;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#24863;&#20852;&#36259;&#28857;&#30340;&#21487;&#25193;&#23637;&#31232;&#30095;&#36924;&#36817;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#22238;&#39038;&#20102;&#25968;&#20540;&#31283;&#23450;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#21487;&#33021;&#19981;&#31283;&#23450;&#30340;&#20856;&#22411;&#24773;&#20917;&#12290;&#22312;&#25554;&#20540;&#25991;&#29486;&#20013;&#21407;&#22987;&#24320;&#21457;&#30340;&#31283;&#23450;&#24615;&#29702;&#35770;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23545;&#24863;&#20852;&#36259;&#28857;&#36827;&#34892;&#35745;&#31639;&#30340;&#25968;&#20540;&#31283;&#23450;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#21644;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#23545;&#20110;&#22320;&#29702;&#31354;&#38388;&#24314;&#27169;&#31561;&#20302;&#32500;&#20219;&#21153;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#35745;&#31639;&#28385;&#36275;&#36825;&#20123;&#26465;&#20214;&#30340;&#24863;&#20852;&#36259;&#28857;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are frequently deployed as part of larger machine learning and decision-making systems, for instance in geospatial modeling, Bayesian optimization, or in latent Gaussian models. Within a system, the Gaussian process model needs to perform in a stable and reliable manner to ensure it interacts correctly with other parts of the system. In this work, we study the numerical stability of scalable sparse approximations based on inducing points. To do so, we first review numerical stability, and illustrate typical situations in which Gaussian process models can be unstable. Building on stability theory originally developed in the interpolation literature, we derive sufficient and in certain cases necessary conditions on the inducing points for the computations performed to be numerically stable. For low-dimensional tasks such as geospatial modeling, we propose an automated method for computing inducing points satisfying these conditions. This is done via a modification of t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;Conformal Prediction&#26041;&#27861;&#23545;&#20110;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25214;&#20986;&#20102;&#26500;&#24314;&#21487;&#20197;&#27491;&#30830;&#35206;&#30422;&#26080;&#22122;&#22768;&#30495;&#23454;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20855;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#27491;&#30830;&#25511;&#21046;&#30340;&#35201;&#27714;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23545;&#25239;&#24615;&#26696;&#20363;&#20043;&#22806;&#65292;&#20351;&#29992;Conformal Prediction&#21644;&#39118;&#38505;&#25511;&#21046;&#25216;&#26415;&#21487;&#20197;&#23454;&#29616;&#23545;&#24178;&#20928;&#30495;&#23454;&#26631;&#31614;&#30340;&#20445;&#23432;&#39118;&#38505;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#30028;&#23610;&#23544;&#22122;&#22768;&#20462;&#27491;&#30340;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#23454;&#29616;&#27491;&#30830;&#30340;&#30495;&#23454;&#26631;&#31614;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2209.14295</link><description>&lt;p&gt;
Conformal Prediction&#23545;&#20998;&#25955;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction is Robust to Dispersive Label Noise. (arXiv:2209.14295v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;Conformal Prediction&#26041;&#27861;&#23545;&#20110;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25214;&#20986;&#20102;&#26500;&#24314;&#21487;&#20197;&#27491;&#30830;&#35206;&#30422;&#26080;&#22122;&#22768;&#30495;&#23454;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#30340;&#26465;&#20214;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20855;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#27491;&#30830;&#25511;&#21046;&#30340;&#35201;&#27714;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#23545;&#25239;&#24615;&#26696;&#20363;&#20043;&#22806;&#65292;&#20351;&#29992;Conformal Prediction&#21644;&#39118;&#38505;&#25511;&#21046;&#25216;&#26415;&#21487;&#20197;&#23454;&#29616;&#23545;&#24178;&#20928;&#30495;&#23454;&#26631;&#31614;&#30340;&#20445;&#23432;&#39118;&#38505;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#30028;&#23610;&#23544;&#22122;&#22768;&#20462;&#27491;&#30340;&#26041;&#27861;&#65292;&#20197;&#30830;&#20445;&#23454;&#29616;&#27491;&#30830;&#30340;&#30495;&#23454;&#26631;&#31614;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#26631;&#31614;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;Conformal Prediction&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;&#22238;&#24402;&#21644;&#20998;&#31867;&#38382;&#39064;&#65292;&#23545;&#20110;&#22914;&#20309;&#26500;&#24314;&#33021;&#22815;&#27491;&#30830;&#35206;&#30422;&#26410;&#35266;&#23519;&#21040;&#30340;&#26080;&#22122;&#22768;&#30495;&#23454;&#26631;&#31614;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#36827;&#34892;&#20102;&#30028;&#23450;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#27491;&#30830;&#25511;&#21046;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#65288;&#22914;&#20551;&#38452;&#24615;&#27604;&#20363;&#65289;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;Conformal Prediction&#21644;&#39118;&#38505;&#25511;&#21046;&#25216;&#26415;&#33021;&#22815;&#23454;&#29616;&#23545;&#24178;&#20928;&#30495;&#23454;&#26631;&#31614;&#30340;&#20445;&#23432;&#39118;&#38505;&#65292;&#38500;&#20102;&#22312;&#23545;&#25239;&#24615;&#26696;&#20363;&#20013;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#21487;&#20197;&#36890;&#36807;&#23545;Conformal Prediction&#31639;&#27861;&#36827;&#34892;&#26377;&#30028;&#23610;&#23544;&#30340;&#22122;&#22768;&#20462;&#27491;&#65292;&#20197;&#30830;&#20445;&#23454;&#29616;&#27491;&#30830;&#30340;&#30495;&#23454;&#26631;&#31614;&#39118;&#38505;&#65292;&#32780;&#26080;&#38656;&#32771;&#34385;&#20998;&#25968;&#25110;&#25968;&#25454;&#30340;&#35268;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the robustness of conformal prediction, a powerful tool for uncertainty quantification, to label noise. Our analysis tackles both regression and classification problems, characterizing when and how it is possible to construct uncertainty sets that correctly cover the unobserved noiseless ground truth labels. We further extend our theory and formulate the requirements for correctly controlling a general loss function, such as the false negative proportion, with noisy labels. Our theory and experiments suggest that conformal prediction and risk-controlling techniques with noisy labels attain conservative risk over the clean ground truth labels except in adversarial cases. In such cases, we can also correct for noise of bounded size in the conformal prediction algorithm in order to ensure achieving the correct risk of the ground truth labels without score or data regularity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#38750;&#32447;&#24615;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#22343;&#20540;&#20989;&#25968;&#20272;&#35745;&#65292;&#35777;&#26126;&#20102;&#31232;&#30095;&#24809;&#32602;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#35768;&#22810;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#36798;&#21040;&#20102;&#26497;&#23567;&#19979;&#30028;&#30340;&#26368;&#20248;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2207.02546</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#28145;&#24230;&#23398;&#20064;&#29992;&#20110;&#38750;&#32447;&#24615;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Adaptive deep learning for nonlinear time series models. (arXiv:2207.02546v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.02546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#38750;&#32447;&#24615;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#22343;&#20540;&#20989;&#25968;&#20272;&#35745;&#65292;&#35777;&#26126;&#20102;&#31232;&#30095;&#24809;&#32602;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#35768;&#22810;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#36798;&#21040;&#20102;&#26497;&#23567;&#19979;&#30028;&#30340;&#26368;&#20248;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#33258;&#36866;&#24212;&#20272;&#35745;&#29702;&#35770;&#65292;&#29992;&#20110;&#38750;&#24179;&#31283;&#21644;&#38750;&#32447;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#30340;&#22343;&#20540;&#20989;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#65292;&#21363;&#38750;&#24809;&#32602;&#21644;&#31232;&#30095;&#24809;&#32602;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#20026;&#19968;&#33324;&#30340;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#24314;&#31435;&#20102;&#23427;&#20204;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20272;&#35745;&#23646;&#20110;&#24191;&#27867;&#31867;&#21035;&#30340;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#27169;&#22411;&#65288;&#21253;&#25324;&#38750;&#32447;&#24615;&#24191;&#20041;&#21487;&#21152;&#33258;&#22238;&#24402;&#12289;&#21333;&#25351;&#25968;&#21644;&#38408;&#20540;&#33258;&#22238;&#24402;&#27169;&#22411;&#65289;&#22343;&#20540;&#20989;&#25968;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;&#22312;&#36825;&#20123;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#31232;&#30095;&#24809;&#32602;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#35768;&#22810;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#26159;&#33258;&#36866;&#24212;&#30340;&#65292;&#24182;&#36798;&#21040;&#26497;&#23567;&#19979;&#30028;&#30340;&#26368;&#20248;&#36895;&#29575;&#65292;&#20165;&#26377;&#22810;&#23545;&#25968;&#22240;&#23376;&#30340;&#24046;&#36317;&#12290;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#22312;&#20272;&#35745;&#20855;&#26377;&#20869;&#22312;&#20302;&#32500;&#32467;&#26500;&#21644;&#19981;&#36830;&#32493;&#25110;&#31895;&#31961;&#22343;&#20540;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we develop a general theory for adaptive nonparametric estimation of the mean function of a non-stationary and nonlinear time series model using deep neural networks (DNNs). We first consider two types of DNN estimators, non-penalized and sparse-penalized DNN estimators, and establish their generalization error bounds for general non-stationary time series. We then derive minimax lower bounds for estimating mean functions belonging to a wide class of nonlinear autoregressive (AR) models that include nonlinear generalized additive AR, single index, and threshold AR models. Building upon the results, we show that the sparse-penalized DNN estimator is adaptive and attains the minimax optimal rates up to a poly-logarithmic factor for many nonlinear AR models. Through numerical simulations, we demonstrate the usefulness of the DNN methods for estimating nonlinear AR models with intrinsic low-dimensional structures and discontinuous or rough mean functions, which is consistent
&lt;/p&gt;</description></item><item><title>&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23376;&#32676;&#36873;&#25321;&#25361;&#25112;&#65292;&#20197;&#30830;&#23450;&#22238;&#24402;&#20989;&#25968;&#36229;&#36807;&#39044;&#35774;&#38408;&#20540;&#30340;&#29305;&#24449;&#31354;&#38388;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#30830;&#23450;&#20102;&#22312;&#26679;&#26412;&#35268;&#27169;&#21644;&#31867;&#22411;I&#38169;&#35823;&#27010;&#29575;&#19978;&#36951;&#25022;&#30340;&#26368;&#20339;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2109.01077</link><description>&lt;p&gt;
&#26368;&#20339;&#23376;&#32676;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Optimal subgroup selection. (arXiv:2109.01077v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.01077
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23376;&#32676;&#36873;&#25321;&#25361;&#25112;&#65292;&#20197;&#30830;&#23450;&#22238;&#24402;&#20989;&#25968;&#36229;&#36807;&#39044;&#35774;&#38408;&#20540;&#30340;&#29305;&#24449;&#31354;&#38388;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#30830;&#23450;&#20102;&#22312;&#26679;&#26412;&#35268;&#27169;&#21644;&#31867;&#22411;I&#38169;&#35823;&#27010;&#29575;&#19978;&#36951;&#25022;&#30340;&#26368;&#20339;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20020;&#24202;&#35797;&#39564;&#21644;&#20854;&#20182;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#32463;&#24120;&#30475;&#21040;&#29305;&#24449;&#31354;&#38388;&#20013;&#20986;&#29616;&#20102;&#26377;&#36259;&#30340;&#34892;&#20026;&#21306;&#22495;&#65292;&#20294;&#19981;&#28165;&#26970;&#36825;&#20123;&#35266;&#23519;&#21040;&#30340;&#29616;&#35937;&#26159;&#21542;&#22312;&#24635;&#20307;&#27700;&#24179;&#19978;&#26377;&#25152;&#21453;&#26144;&#12290;&#38024;&#23545;&#22238;&#24402;&#35774;&#32622;&#65292;&#25105;&#20204;&#32771;&#34385;&#23376;&#32676;&#36873;&#25321;&#25361;&#25112;&#65292;&#21363;&#35782;&#21035;&#19968;&#20010;&#29305;&#24449;&#31354;&#38388;&#30340;&#21306;&#22495;&#65292;&#22312;&#35813;&#21306;&#22495;&#19978;&#65292;&#22238;&#24402;&#20989;&#25968;&#36229;&#36807;&#20102;&#39044;&#35774;&#30340;&#38408;&#20540;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#24418;&#24335;&#21270;&#20026;&#19968;&#31181;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#23547;&#25214;&#19968;&#20010;&#20302;&#22797;&#26434;&#24230;&#12289;&#25968;&#25454;&#30456;&#20851;&#30340;&#36873;&#25321;&#38598;&#65292;&#22312;&#36825;&#20010;&#36873;&#25321;&#38598;&#19978;&#65292;&#22238;&#24402;&#20989;&#25968;&#26377;&#33267;&#23569;&#19982;&#38408;&#20540;&#19968;&#26679;&#22823;&#30340;&#27010;&#29575;&#65292;&#21516;&#26102;&#35201;&#27714;&#35813;&#21306;&#22495;&#22312;&#36793;&#32536;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#36136;&#37327;&#23613;&#21487;&#33021;&#22823;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#36951;&#25022;&#27010;&#24565;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#30830;&#23450;&#20102;&#36951;&#25022;&#22312;&#26679;&#26412;&#35268;&#27169;&#21644;&#31532;&#19968;&#31867;&#38169;&#35823;&#27010;&#29575;&#19978;&#30340;&#26368;&#20248;&#20540;&#12290;&#36825;&#20010;&#26368;&#20248;&#20540;&#28041;&#21450;&#21040;&#26679;&#26412;&#22823;&#23567;&#21644;&#31867;&#22411;I&#38169;&#35823;&#27010;&#29575;&#30340;&#24494;&#22937;&#30456;&#20114;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In clinical trials and other applications, we often see regions of the feature space that appear to exhibit interesting behaviour, but it is unclear whether these observed phenomena are reflected at the population level. Focusing on a regression setting, we consider the subgroup selection challenge of identifying a region of the feature space on which the regression function exceeds a pre-determined threshold. We formulate the problem as one of constrained optimisation, where we seek a low-complexity, data-dependent selection set on which, with a guaranteed probability, the regression function is uniformly at least as large as the threshold; subject to this constraint, we would like the region to contain as much mass under the marginal feature distribution as possible. This leads to a natural notion of regret, and our main contribution is to determine the minimax optimal rate for this regret in both the sample size and the Type I error probability. The rate involves a delicate interpla
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28145;&#24230;&#27169;&#20223;&#23398;&#20064;&#39046;&#22495;&#20197;&#23454;&#38469;&#30340;&#35270;&#35282;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#37325;&#26032;&#23454;&#29616;&#20102;6&#31181;&#19981;&#21516;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#20351;&#29992;&#20849;&#21516;&#30340;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#36890;&#36807;&#23545;&#19987;&#23478;&#36712;&#36857;&#25968;&#25454;&#36827;&#34892;&#27979;&#35797;&#65292;&#27604;&#36739;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2108.01867</link><description>&lt;p&gt;
&#28145;&#24230;&#27169;&#20223;&#23398;&#20064;&#30340;&#23454;&#29992;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Pragmatic Look at Deep Imitation Learning. (arXiv:2108.01867v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.01867
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28145;&#24230;&#27169;&#20223;&#23398;&#20064;&#39046;&#22495;&#20197;&#23454;&#38469;&#30340;&#35270;&#35282;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#37325;&#26032;&#23454;&#29616;&#20102;6&#31181;&#19981;&#21516;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#20351;&#29992;&#20849;&#21516;&#30340;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#36890;&#36807;&#23545;&#19987;&#23478;&#36712;&#36857;&#25968;&#25454;&#36827;&#34892;&#27979;&#35797;&#65292;&#27604;&#36739;&#20102;&#36825;&#20123;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#27169;&#20223;&#23398;&#20064;&#65288;GAIL&#65289;&#31639;&#27861;&#30340;&#24341;&#20837;&#25512;&#21160;&#20102;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#21487;&#25193;&#23637;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#30340;&#21457;&#23637;&#12290;&#35768;&#22810;&#21518;&#32493;&#31639;&#27861;&#20351;&#29992;&#20102;&#31867;&#20284;&#30340;&#36807;&#31243;&#65292;&#23558;&#22312;&#32447;&#31574;&#30053;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#19982;&#36870;&#21521;&#24378;&#21270;&#23398;&#20064;&#30456;&#32467;&#21512;&#12290;&#26368;&#36817;&#20986;&#29616;&#20102;&#26356;&#22810;&#31181;&#31867;&#30340;&#26041;&#27861;&#65292;&#22823;&#22810;&#25968;&#20351;&#29992;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31639;&#27861;&#30340;&#24191;&#27867;&#24615;&#65292;&#20174;&#25968;&#25454;&#38598;&#21040;&#22522;&#30784;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20877;&#21040;&#35780;&#20272;&#35774;&#32622;&#37117;&#21487;&#33021;&#26377;&#25152;&#21464;&#21270;&#65292;&#36825;&#20351;&#24471;&#20844;&#27491;&#27604;&#36739;&#23427;&#20204;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23454;&#29616;&#20102;6&#31181;&#19981;&#21516;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#20854;&#20013;3&#31181;&#26356;&#26032;&#20026;&#31163;&#32447;&#31574;&#30053;&#65292;&#23558;&#23427;&#20204;&#22522;&#20110;&#19968;&#20010;&#24120;&#29992;&#30340;&#31163;&#32447;&#31574;&#30053;&#31639;&#27861;&#65288;SAC&#65289;&#65292;&#24182;&#22312;&#19968;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#19987;&#23478;&#36712;&#36857;&#25968;&#25454;&#38598;&#65288;D4RL&#65289;&#19978;&#23545;&#23427;&#20204;&#36827;&#34892;&#35780;&#20272;&#65292;&#20197;&#36827;&#34892;&#26368;&#24120;&#35265;&#30340;&#22522;&#20934;&#27979;&#35797;&#65288;MuJoCo&#65289;&#12290;&#22312;&#32473;&#25152;&#26377;&#31639;&#27861;&#30456;&#21516;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#39044;&#31639;&#20043;&#21518;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#23427;&#20204;&#22312;&#19968;&#31995;&#21015;&#19987;&#23478;&#36712;&#36857;&#27979;&#35797;&#19978;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The introduction of the generative adversarial imitation learning (GAIL) algorithm has spurred the development of scalable imitation learning approaches using deep neural networks. Many of the algorithms that followed used a similar procedure, combining on-policy actor-critic algorithms with inverse reinforcement learning. More recently there have been an even larger breadth of approaches, most of which use off-policy algorithms. However, with the breadth of algorithms, everything from datasets to base reinforcement learning algorithms to evaluation settings can vary, making it difficult to fairly compare them. In this work we re-implement 6 different IL algorithms, updating 3 of them to be off-policy, base them on a common off-policy algorithm (SAC), and evaluate them on a widely-used expert trajectory dataset (D4RL) for the most common benchmark (MuJoCo). After giving all algorithms the same hyperparameter optimisation budget, we compare their results for a range of expert trajectori
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31574;&#30053;&#65292;&#29992;&#20110;&#23558;&#21333;&#28857;&#33719;&#21462;&#20989;&#25968;&#36866;&#24212;&#20110;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#65292;&#19982;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#25209;&#37327;&#37319;&#38598;&#20989;&#25968;&#30456;&#27604;&#65292;&#24615;&#33021;&#30456;&#24403;&#65292;&#20294;&#20351;&#29992;&#30340;&#35745;&#31639;&#36164;&#28304;&#26356;&#23569;&#12290;</title><link>http://arxiv.org/abs/2106.12059</link><description>&lt;p&gt;
&#38543;&#26426;&#25209;&#37327;&#33719;&#21462;&#65306;&#28145;&#24230;&#20027;&#21160;&#23398;&#20064;&#30340;&#31616;&#21333;&#22522;&#20934;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stochastic Batch Acquisition: A Simple Baseline for Deep Active Learning. (arXiv:2106.12059v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.12059
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31574;&#30053;&#65292;&#29992;&#20110;&#23558;&#21333;&#28857;&#33719;&#21462;&#20989;&#25968;&#36866;&#24212;&#20110;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#65292;&#19982;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#25209;&#37327;&#37319;&#38598;&#20989;&#25968;&#30456;&#27604;&#65292;&#24615;&#33021;&#30456;&#24403;&#65292;&#20294;&#20351;&#29992;&#30340;&#35745;&#31639;&#36164;&#28304;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#38543;&#26426;&#31574;&#30053;&#65292;&#29992;&#20110;&#23558;&#20247;&#25152;&#21608;&#30693;&#30340;&#21333;&#28857;&#33719;&#21462;&#20989;&#25968;&#36866;&#24212;&#20110;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#12290;&#19982;&#20174;&#27744;&#38598;&#21512;&#20013;&#33719;&#21462;&#21069;K&#20010;&#28857;&#19981;&#21516;&#65292;&#22522;&#20110;&#20998;&#25968;&#25110;&#25490;&#21517;&#30340;&#37319;&#26679;&#32771;&#34385;&#21040;&#33719;&#21462;&#25968;&#25454;&#21518;&#37319;&#38598;&#20998;&#25968;&#30340;&#21464;&#21270;&#12290;&#36825;&#31181;&#31616;&#21333;&#30340;&#31574;&#30053;&#21487;&#20197;&#19982;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#26368;&#26032;&#25209;&#37327;&#37319;&#38598;&#20989;&#25968;&#65288;&#22914;BatchBALD&#25110;BADGE&#65289;&#19968;&#26679;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#20351;&#29992;&#30340;&#35745;&#31639;&#36164;&#28304;&#25968;&#37327;&#32423;&#36739;&#23569;&#12290;&#38500;&#20102;&#20026;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#25552;&#20379;&#20102;&#19968;&#20010;&#23454;&#29992;&#36873;&#39033;&#22806;&#65292;&#22312;&#21508;&#31181;&#23454;&#39564;&#29615;&#22659;&#20013;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#24847;&#22806;&#25104;&#21151;&#36824;&#20026;&#36825;&#20010;&#39046;&#22495;&#25552;&#20986;&#20102;&#19968;&#20010;&#22256;&#38590;&#30340;&#38382;&#39064;&#65306;&#36825;&#20123;&#26114;&#36149;&#30340;&#25209;&#37327;&#37319;&#38598;&#26041;&#27861;&#20309;&#26102;&#25165;&#33021;&#21457;&#25381;&#20316;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
We examine a simple stochastic strategy for adapting well-known single-point acquisition functions to allow batch active learning. Unlike acquiring the top-K points from the pool set, score- or rank-based sampling takes into account that acquisition scores change as new data are acquired. This simple strategy for adapting standard single-sample acquisition strategies can even perform just as well as compute-intensive state-of-the-art batch acquisition functions, like BatchBALD or BADGE, while using orders of magnitude less compute. In addition to providing a practical option for machine learning practitioners, the surprising success of the proposed method in a wide range of experimental settings raises a difficult question for the field: when are these expensive batch acquisition methods pulling their weight?
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34913;&#37327;&#35270;&#35273;&#35266;&#23519;&#21040;&#30340;&#23376;&#32676;&#24046;&#24322;&#30340;&#35777;&#25454;&#24378;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;"&#20154;&#32676;&#24046;&#24322;&#20934;&#21017;"&#26469;&#35780;&#20272;&#20854;&#32479;&#35745;&#26174;&#33879;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#39640;&#32500;&#21644;&#39640;&#20449;&#21495;&#29615;&#22659;&#19979;&#65292;&#20256;&#32479;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#26032;&#30340;&#24179;&#34913;&#32622;&#25442;&#26041;&#27861;&#21644;&#33258;&#21161;&#27861;&#32622;&#20449;&#21306;&#38388;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#22312;&#29616;&#20195;&#30284;&#30151;&#25968;&#25454;&#30340;&#27604;&#36739;&#20013;&#65292;&#36825;&#20123;&#26041;&#27861;&#23637;&#31034;&#20986;&#20102;&#23454;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2101.00362</link><description>&lt;p&gt;
&#34913;&#37327;&#35270;&#35273;&#35266;&#23519;&#21040;&#30340;&#23376;&#32676;&#24046;&#24322;&#30340;&#35777;&#25454;&#24378;&#24230;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Measure of Strength of Evidence for Visually Observed Differences between Subpopulations. (arXiv:2101.00362v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.00362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#34913;&#37327;&#35270;&#35273;&#35266;&#23519;&#21040;&#30340;&#23376;&#32676;&#24046;&#24322;&#30340;&#35777;&#25454;&#24378;&#24230;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;"&#20154;&#32676;&#24046;&#24322;&#20934;&#21017;"&#26469;&#35780;&#20272;&#20854;&#32479;&#35745;&#26174;&#33879;&#24615;&#12290;&#30740;&#31350;&#21457;&#29616;&#22312;&#39640;&#32500;&#21644;&#39640;&#20449;&#21495;&#29615;&#22659;&#19979;&#65292;&#20256;&#32479;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#26032;&#30340;&#24179;&#34913;&#32622;&#25442;&#26041;&#27861;&#21644;&#33258;&#21161;&#27861;&#32622;&#20449;&#21306;&#38388;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#22312;&#29616;&#20195;&#30284;&#30151;&#25968;&#25454;&#30340;&#27604;&#36739;&#20013;&#65292;&#36825;&#20123;&#26041;&#27861;&#23637;&#31034;&#20986;&#20102;&#23454;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#34913;&#37327;&#35270;&#35273;&#19978;&#35266;&#23519;&#21040;&#30340;&#23376;&#32676;&#24046;&#24322;&#30340;&#24378;&#24230;&#65292;&#25552;&#20986;&#20102;&#8220;&#20154;&#32676;&#24046;&#24322;&#20934;&#21017;&#8221;&#26469;&#35780;&#20272;&#35270;&#35273;&#19978;&#35266;&#23519;&#21040;&#30340;&#23376;&#32676;&#24046;&#24322;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#12290;&#23427;&#35299;&#20915;&#20102;&#20197;&#19979;&#25361;&#25112;&#65306;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#20998;&#24067;&#27169;&#22411;&#21487;&#33021;&#26159;&#21487;&#30097;&#30340;&#65307;&#22312;&#39640;&#20449;&#21495;&#29615;&#22659;&#20013;&#65292;&#20256;&#32479;&#30340;&#32622;&#25442;&#26816;&#39564;&#22312;&#37197;&#23545;&#27604;&#36739;&#26041;&#38754;&#25928;&#26524;&#19981;&#20339;&#12290;&#25105;&#20204;&#36824;&#20570;&#20986;&#20102;&#20004;&#39033;&#20854;&#20182;&#36129;&#29486;&#65306;&#22522;&#20110;&#20180;&#32454;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#39640;&#20449;&#21495;&#29615;&#22659;&#20013;&#65292;&#24179;&#34913;&#30340;&#32622;&#25442;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#32622;&#25442;&#26041;&#27861;&#26356;&#24378;&#22823;&#12290;&#21478;&#19968;&#20010;&#36129;&#29486;&#26159;&#36890;&#36807;&#33258;&#21161;&#27861;&#32622;&#25442;&#21464;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#65292;&#24471;&#21040;&#19968;&#20010;&#33258;&#21161;&#27861;&#32622;&#20449;&#21306;&#38388;&#12290;&#36825;&#20123;&#24819;&#27861;&#30340;&#23454;&#29992;&#24615;&#22312;&#23545;&#29616;&#20195;&#30284;&#30151;&#25968;&#25454;&#30340;&#23376;&#32676;&#27604;&#36739;&#20013;&#24471;&#21040;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
For measuring the strength of visually-observed subpopulation differences, the Population Difference Criterion is proposed to assess the statistical significance of visually observed subpopulation differences. It addresses the following challenges: in high-dimensional contexts, distributional models can be dubious; in high-signal contexts, conventional permutation tests give poor pairwise comparisons. We also make two other contributions: Based on a careful analysis we find that a balanced permutation approach is more powerful in high-signal contexts than conventional permutations. Another contribution is the quantification of uncertainty due to permutation variation via a bootstrap confidence interval. The practical usefulness of these ideas is illustrated in the comparison of subpopulations of modern cancer data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#21322;&#31354;&#38388;&#22312;Massart&#22122;&#22768;&#19979;&#30340;&#38169;&#37197;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;&#31639;&#27861;&#24182;&#22238;&#31572;&#20102;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#12290;&#36890;&#36807;&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;&#36807;&#31243;&#65292;&#23558;&#22797;&#26434;&#20998;&#31867;&#22120;&#36716;&#25442;&#20026;&#21516;&#26679;&#22909;&#30340;&#21512;&#36866;&#20998;&#31867;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#23567;&#26679;&#26412;&#30340;&#21512;&#36866;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#30697;&#24863;&#30693;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#20855;&#26377;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24615;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2006.04787</link><description>&lt;p&gt;
&#22312;&#38169;&#37197;&#24773;&#20917;&#19979;&#30340;&#20998;&#31867;&#65306;&#21322;&#31354;&#38388;&#12289;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#19982;&#21487;&#36827;&#21270;&#24615;&#30340;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Connections to Evolvability. (arXiv:2006.04787v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.04787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#21322;&#31354;&#38388;&#22312;Massart&#22122;&#22768;&#19979;&#30340;&#38169;&#37197;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;&#31639;&#27861;&#24182;&#22238;&#31572;&#20102;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#12290;&#36890;&#36807;&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;&#36807;&#31243;&#65292;&#23558;&#22797;&#26434;&#20998;&#31867;&#22120;&#36716;&#25442;&#20026;&#21516;&#26679;&#22909;&#30340;&#21512;&#36866;&#20998;&#31867;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#23567;&#26679;&#26412;&#30340;&#21512;&#36866;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#30697;&#24863;&#30693;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#20855;&#26377;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24615;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#19968;&#20123;&#20851;&#20110;&#38169;&#37197;&#24773;&#20917;&#19979;&#30340;&#20998;&#31867;&#30340;&#32463;&#20856;&#38382;&#39064;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Massart&#22122;&#22768;&#19979;&#20197;&#36895;&#29575;$\eta$&#23398;&#20064;&#21322;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;&#22312;&#26368;&#36817;&#30340;&#19968;&#39033;&#24037;&#20316;&#20013;&#65292;Diakonikolas&#12289;Goulekakis&#21644;Tzamos&#36890;&#36807;&#25552;&#20379;&#31532;&#19968;&#20010;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20102;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#23398;&#20064;&#21040;&#20934;&#30830;&#24230;$\eta + \epsilon$&#65292;&#20854;&#20013;$\epsilon &gt; 0$&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#31639;&#27861;&#36755;&#20986;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#20551;&#35774;&#65292;&#23558;&#31354;&#38388;&#20998;&#21106;&#20026;$\text{poly}(d,1/\epsilon)$&#20010;&#21306;&#22495;&#12290;&#36825;&#37324;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#26356;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;&#27492;&#36807;&#31243;&#20013;&#35299;&#20915;&#20102;&#19968;&#20123;&#24748;&#32780;&#26410;&#20915;&#30340;&#24320;&#25918;&#38382;&#39064;&#65306;(1)&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#21487;&#20197;&#23454;&#29616;$\eta + \epsilon$&#30340;Massart&#21322;&#31354;&#38388;&#21512;&#36866;&#23398;&#20064;&#22120;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#25913;&#36827;&#30028;&#38480;&#12290;(2)&#22522;&#20110;(1)&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#40657;&#30418;&#30693;&#35782;&#33976;&#39311;&#36807;&#31243;&#65292;&#23558;&#20219;&#24847;&#22797;&#26434;&#30340;&#20998;&#31867;&#22120;&#36716;&#25442;&#20026;&#21516;&#26679;&#22909;&#30340;&#21512;&#36866;&#30340;&#20998;&#31867;&#22120;&#12290;(3)&#36890;&#36807;&#21033;&#29992;&#19968;&#20010;&#31616;&#21333;&#20294;&#34987;&#24573;&#35270;&#30340;&#26426;&#21046;&#65292;&#25105;&#20204;&#22312;&#27809;&#26377;&#20219;&#20309;&#39069;&#22806;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#26500;&#36896;&#20102;&#19968;&#20010;&#23567;&#26679;&#26412;&#30340;&#21512;&#36866;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#22522;&#20110;&#30697;&#24863;&#30693;&#30340;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#24471;&#21040;&#19968;&#20010;&#20855;&#26377;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24615;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we revisit some classic problems on classification under misspecification. In particular, we study the problem of learning halfspaces under Massart noise with rate $\eta$. In a recent work, Diakonikolas, Goulekakis, and Tzamos resolved a long-standing problem by giving the first efficient algorithm for learning to accuracy $\eta + \epsilon$ for any $\epsilon &gt; 0$. However, their algorithm outputs a complicated hypothesis, which partitions space into $\text{poly}(d,1/\epsilon)$ regions. Here we give a much simpler algorithm and in the process resolve a number of outstanding open questions:  (1) We give the first proper learner for Massart halfspaces that achieves $\eta + \epsilon$. We also give improved bounds on the sample complexity achievable by polynomial time algorithms.  (2) Based on (1), we develop a blackbox knowledge distillation procedure to convert an arbitrarily complex classifier to an equally good proper classifier.  (3) By leveraging a simple but overlooked 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#23454;&#20307;&#23545;&#40784;&#25110;&#38142;&#25509;&#39044;&#27979;&#26041;&#27861;&#30340;&#25490;&#21517;&#35780;&#20272;&#30340;&#27495;&#20041;&#24615;&#12290;&#20998;&#26512;&#20102;&#24403;&#21069;&#35780;&#20272;&#25351;&#26631;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#25552;&#20986;&#20102;&#35780;&#20272;&#26041;&#27861;&#30340;&#35843;&#25972;&#65292;&#20197;&#23454;&#29616;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#20844;&#24179;&#12289;&#21487;&#27604;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2002.06914</link><description>&lt;p&gt;
&#20851;&#20110;&#23454;&#20307;&#23545;&#40784;&#25110;&#38142;&#25509;&#39044;&#27979;&#26041;&#27861;&#25490;&#21517;&#35780;&#20272;&#30340;&#27495;&#20041;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Ambiguity of Rank-Based Evaluation of Entity Alignment or Link Prediction Methods. (arXiv:2002.06914v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.06914
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#23454;&#20307;&#23545;&#40784;&#25110;&#38142;&#25509;&#39044;&#27979;&#26041;&#27861;&#30340;&#25490;&#21517;&#35780;&#20272;&#30340;&#27495;&#20041;&#24615;&#12290;&#20998;&#26512;&#20102;&#24403;&#21069;&#35780;&#20272;&#25351;&#26631;&#30340;&#19981;&#36275;&#20043;&#22788;&#65292;&#25552;&#20986;&#20102;&#35780;&#20272;&#26041;&#27861;&#30340;&#35843;&#25972;&#65292;&#20197;&#23454;&#29616;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#20844;&#24179;&#12289;&#21487;&#27604;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#20004;&#31181;&#20174;&#30693;&#35782;&#22270;&#35889;&#20013;&#22686;&#24378;&#20449;&#24687;&#30340;&#26041;&#27861;&#65306;&#38142;&#25509;&#39044;&#27979;&#21644;&#23454;&#20307;&#23545;&#40784;&#65292;&#23545;&#20854;&#35780;&#20272;&#26041;&#27861;&#36827;&#34892;&#20102;&#28145;&#20837;&#30740;&#31350;&#12290;&#24403;&#21069;&#23454;&#39564;&#35774;&#32622;&#20013;&#65292;&#37319;&#29992;&#22810;&#20010;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#26469;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#19981;&#21516;&#26041;&#38754;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20123;&#35780;&#20272;&#25351;&#26631;&#30340;&#20449;&#24687;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#20123;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#26377;&#29616;&#26377;&#30340;&#35780;&#20272;&#25351;&#26631;&#20960;&#20046;&#19981;&#33021;&#29992;&#20110;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#27604;&#36739;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#27979;&#35797;&#38598;&#22823;&#23567;&#30340;&#21464;&#21270;&#20250;&#23545;&#30456;&#21516;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#65292;&#36825;&#26159;&#22522;&#20110;&#23454;&#20307;&#23545;&#40784;&#20219;&#21153;&#24120;&#29992;&#24230;&#37327;&#26631;&#20934;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#23548;&#33268;&#20102;&#32467;&#26524;&#35299;&#37322;&#19978;&#30340;&#21508;&#31181;&#38382;&#39064;&#65292;&#21487;&#33021;&#25903;&#25345;&#35823;&#23548;&#24615;&#30340;&#32467;&#35770;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#35780;&#20272;&#26041;&#27861;&#30340;&#35843;&#25972;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#22914;&#20309;&#23454;&#29616;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#20844;&#24179;&#12289;&#21487;&#27604;&#21644;&#21487;&#35299;&#37322;&#30340;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#20379;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we take a closer look at the evaluation of two families of methods for enriching information from knowledge graphs: Link Prediction and Entity Alignment. In the current experimental setting, multiple different scores are employed to assess different aspects of model performance. We analyze the informativeness of these evaluation measures and identify several shortcomings. In particular, we demonstrate that all existing scores can hardly be used to compare results across different datasets. Moreover, we demonstrate that varying size of the test size automatically has impact on the performance of the same model based on commonly used metrics for the Entity Alignment task. We show that this leads to various problems in the interpretation of results, which may support misleading conclusions. Therefore, we propose adjustments to the evaluation and demonstrate empirically how this supports a fair, comparable, and interpretable assessment of model performance. Our code is availa
&lt;/p&gt;</description></item></channel></rss>