<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.16284</link><description>&lt;p&gt;
DoWG&#23637;&#31034;&#65306;&#19968;&#31181;&#39640;&#25928;&#30340;&#36890;&#29992;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26131;&#20110;&#23454;&#29616;&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#20248;&#21270;&#22120;&#65306;DoWG&#65288;Weighted Gradients&#30340;&#36317;&#31163;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#8212;&#8212;&#22312;&#19981;&#35843;&#25972;&#20219;&#20309;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#21305;&#37197;&#20248;&#21270;&#20984;&#20248;&#21270;&#20013;&#26368;&#20248;&#35843;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#65292;&#24182;&#19988;&#26159;&#36890;&#29992;&#30340;&#8212;&#8212;&#33258;&#21160;&#36866;&#24212;&#24179;&#28369;&#21644;&#38750;&#24179;&#28369;&#38382;&#39064;&#12290;&#19982;AdaGrad&#65292;Adam&#25110;DoG&#31561;&#27969;&#34892;&#31639;&#27861;&#35745;&#31639;&#24179;&#26041;&#26799;&#24230;&#30340;&#36816;&#34892;&#24179;&#22343;&#20540;&#19981;&#21516;&#65292;DoWG&#20445;&#25345;&#36816;&#34892;&#24179;&#22343;&#20540;&#30340;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#21152;&#26435;&#29256;&#26412;&#65292;&#36825;&#23545;&#20110;&#23454;&#29616;&#25152;&#38656;&#30340;&#24615;&#36136;&#33267;&#20851;&#37325;&#35201;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;DoWG&#26159;&#31532;&#19968;&#20010;&#19981;&#38656;&#35201;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#30340;&#26080;&#21442;&#25968;&#65292;&#39640;&#25928;&#21644;&#36890;&#29992;&#31639;&#27861;&#12290;&#23427;&#36824;&#26159;&#31532;&#19968;&#20010;&#36866;&#24212;&#20110;&#24179;&#31283;&#20248;&#21270;&#30340;&#26080;&#21442;&#25968;AdaGrad&#26679;&#24335;&#31639;&#27861;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;DoWG&#22312;&#31283;&#23450;&#30340;&#36793;&#32536;&#35757;&#32451;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#38750;&#23545;&#25239;&#24615;&#35757;&#32451;&#31070;&#32463;SDE&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#31614;&#21517;&#20869;&#26680;&#30340;&#35780;&#20998;&#35268;&#21017;&#20195;&#26367;&#20256;&#32479;&#30340;GAN&#26041;&#27861;&#12290;&#26032;&#26041;&#27861;&#30001;&#20110;&#19981;&#38656;&#35201;&#36827;&#34892;&#21160;&#24577;&#35268;&#21010;&#36816;&#31639;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.16274</link><description>&lt;p&gt;
&#26080;&#23545;&#25239;&#35757;&#32451;&#30340;&#31070;&#32463;SDE&#19982;&#31614;&#21517;&#20869;&#26680;&#35780;&#20998;
&lt;/p&gt;
&lt;p&gt;
Non-adversarial training of Neural SDEs with signature kernel scores. (arXiv:2305.16274v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16274
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#38750;&#23545;&#25239;&#24615;&#35757;&#32451;&#31070;&#32463;SDE&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#31614;&#21517;&#20869;&#26680;&#30340;&#35780;&#20998;&#35268;&#21017;&#20195;&#26367;&#20256;&#32479;&#30340;GAN&#26041;&#27861;&#12290;&#26032;&#26041;&#27861;&#30001;&#20110;&#19981;&#38656;&#35201;&#36827;&#34892;&#21160;&#24577;&#35268;&#21010;&#36816;&#31639;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;SDE&#26159;&#29992;&#20110;&#29983;&#25104;&#24207;&#21015;&#25968;&#25454;&#30340;&#36830;&#32493;&#26102;&#38388;&#29983;&#25104;&#27169;&#22411;&#12290;&#20043;&#21069;&#36890;&#36807;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#20316;&#20026;GAN&#33719;&#24471;&#20102;&#26080;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#30340;&#26368;&#26032;&#25104;&#26524;&#12290;&#28982;&#32780;&#65292;&#20687;GAN&#20307;&#31995;&#32467;&#26500;&#19968;&#26679;&#65292;&#35757;&#32451;&#26497;&#19981;&#31283;&#23450;&#65292;&#32463;&#24120;&#21463;&#21040;&#27169;&#24335;&#23849;&#28291;&#30340;&#22256;&#25200;&#65292;&#24182;&#38656;&#35201;&#19987;&#38376;&#30340;&#25216;&#26415;&#65292;&#22914;&#37325;&#37327;&#21098;&#20999;&#21644;&#26799;&#24230;&#24809;&#32602;&#65292;&#20197;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#20869;&#26680;&#30340;&#36335;&#24452;&#31354;&#38388;&#19978;&#26032;&#22411;&#30340;&#35780;&#20998;&#35268;&#21017;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#38750;&#23545;&#25239;&#24615;&#35757;&#32451;&#31070;&#32463;SDE&#30340;&#30446;&#26631;&#12290;&#36890;&#36807;&#23637;&#31034;&#27492;&#31867;&#20869;&#26680;&#20998;&#25968;&#30340;&#20005;&#26684;&#36866;&#24403;&#20197;&#21450;&#30456;&#24212;&#30340;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#20026;&#26497;&#23567;&#21270;&#22120;&#25552;&#20379;&#20102;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#20445;&#35777;&#12290;&#36890;&#36807;&#36825;&#31181;&#20844;&#24335;&#65292;&#35780;&#20272;&#29983;&#25104;&#22120;-&#21028;&#21035;&#22120;&#23545;&#31561;&#20110;&#35299;&#20915;&#19968;&#32452;&#32447;&#24615;&#36335;&#24452;&#30456;&#20851;&#30340;PDE&#65292;&#36825;&#20801;&#35768;&#35760;&#24518;&#25928;&#29575;&#30340;&#20276;&#38543;&#21453;&#21521;&#20256;&#25773;&#12290;&#27492;&#22806;&#65292;&#22240;&#20026;&#25152;&#25552;&#20986;&#30340;&#20869;&#26680;&#20998;&#25968;&#65292;&#25105;&#20204;&#19981;&#38656;&#35201;&#36890;&#36807;&#21160;&#24577;&#32534;&#31243;&#26041;&#27861;&#23545;&#35780;&#20998;&#36827;&#34892;&#24494;&#20998;&#65292;&#36825;&#23545;&#20110;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel score
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2305.16272</link><description>&lt;p&gt;
&#22312;&#21327;&#21516;&#23398;&#20064;&#21644;&#20248;&#21270;&#20013;&#28608;&#21169;&#31454;&#20105;&#23545;&#25163;&#35802;&#23454;&#34892;&#20026;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Incentivizing Honesty among Competitors in Collaborative Learning and Optimization. (arXiv:2305.16272v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16272
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#23398;&#20064;&#25216;&#26415;&#33021;&#22815;&#35753;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#27604;&#20165;&#21033;&#29992;&#21333;&#19968;&#25968;&#25454;&#28304;&#30340;&#27169;&#22411;&#25928;&#26524;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#28508;&#22312;&#30340;&#21442;&#19982;&#32773;&#26159;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#31454;&#20105;&#23545;&#25163;&#65292;&#22914;&#27599;&#20010;&#37117;&#24076;&#26395;&#36890;&#36807;&#25552;&#20379;&#26368;&#20339;&#25512;&#33616;&#26469;&#21560;&#24341;&#23458;&#25143;&#30340;&#20844;&#21496;&#12290;&#36825;&#21487;&#33021;&#20250;&#28608;&#21169;&#19981;&#35802;&#23454;&#30340;&#26356;&#26032;&#65292;&#25439;&#23475;&#20854;&#20182;&#21442;&#19982;&#32773;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#21487;&#33021;&#30772;&#22351;&#21327;&#20316;&#30340;&#22909;&#22788;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#36825;&#31181;&#20132;&#20114;&#65292;&#24182;&#22312;&#35813;&#26694;&#26550;&#20869;&#30740;&#31350;&#20102;&#20004;&#20010;&#23398;&#20064;&#20219;&#21153;&#65306;&#21333;&#36718;&#22343;&#20540;&#20272;&#35745;&#21644;&#24378;&#20984;&#30446;&#26631;&#30340;&#22810;&#36718; SGD&#12290;&#23545;&#20110;&#19968;&#31867;&#33258;&#28982;&#30340;&#21442;&#19982;&#32773;&#34892;&#20026;&#65292;&#25105;&#20204;&#21457;&#29616;&#29702;&#24615;&#30340;&#23458;&#25143;&#20250;&#34987;&#28608;&#21169;&#24378;&#28872;&#22320;&#25805;&#32437;&#20182;&#20204;&#30340;&#26356;&#26032;&#65292;&#20174;&#32780;&#38450;&#27490;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#22343;&#26377;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.16215</link><description>&lt;p&gt;
Koopman&#26680;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Koopman Kernel Regression. (arXiv:2305.16215v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16215
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#22343;&#26377;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20915;&#31574;&#21046;&#23450;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#24378;&#21270;&#23398;&#20064;&#65292;&#20381;&#36182;&#20110;&#27169;&#25311;&#22120;&#25110;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#37327;&#30340;&#26102;&#38388;&#28436;&#21464;&#65292;&#20363;&#22914;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#25110;&#31574;&#30053;&#30340;&#22870;&#21169;&#12290;&#36825;&#20123;&#22797;&#26434;&#29616;&#35937;&#30340;&#39044;&#27979;&#36890;&#24120;&#30001;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#21160;&#21147;&#31995;&#32479;&#25551;&#36848;&#65292;&#20351;&#24471;&#23427;&#20204;&#22312;&#22522;&#20110;&#20248;&#21270;&#30340;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#20351;&#29992;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;Koopman&#31639;&#23376;&#29702;&#35770;&#36890;&#36807;&#36890;&#36807;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#25551;&#36848;&#39044;&#27979;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20351;&#24471;&#31995;&#32479;&#20998;&#26512;&#21644;&#38271;&#26399;&#39044;&#27979;&#21464;&#24471;&#31616;&#21333;--&#21482;&#28041;&#21450;&#30697;&#38453;&#20056;&#27861;&#12290;&#28982;&#32780;&#65292;&#23558;&#20854;&#36716;&#21270;&#20026;&#32447;&#24615;&#31995;&#32479;&#36890;&#24120;&#26159;&#38750;&#24179;&#20961;&#30340;&#21644;&#26410;&#30693;&#30340;&#65292;&#38656;&#35201;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;&#23384;&#22312;&#21508;&#31181;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#32570;&#20047;&#20851;&#38190;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#65292;&#22240;&#27492;&#25152;&#33719;&#24471;&#30340;&#27169;&#22411;&#22312;&#25968;&#25454;&#21644;&#32500;&#24230;&#22686;&#21152;&#26102;&#30340;&#34892;&#20026;&#36890;&#24120;&#19981;&#28165;&#26970;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19978;&#36848;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#30452;&#25509;&#20174;&#21382;&#21490;&#35266;&#23519;&#20013;&#23398;&#20064;&#21040;&#26410;&#26469;&#39044;&#27979;&#22312;Koopman&#31639;&#23376;&#31354;&#38388;&#20013;&#30340;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20139;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#19982;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#21305;&#37197;&#65288;&#25110;&#20248;&#20110;&#65289;&#65292;&#21253;&#25324;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning approaches for decision making, such as reinforcement learning, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear dynamical systems. This makes system analysis and long-term predictions simple -- involving only matrix multiplications. However, the transformation to a linear system is generally non-trivial and unknown, requiring learning-based approaches. While there exists a variety of approaches, they usually lack crucial learning-theoretic guarantees, such that the behavior of the obtained models with increasing data and dimensionality is often unclear. We address the aforemention
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.16189</link><description>&lt;p&gt;
&#28779;&#26143;&#26102;&#38388;&#24207;&#21015;&#20998;&#35299;&#65306;&#19968;&#31181;&#22810;&#23610;&#24230;&#23884;&#22871;&#26041;&#27861;&#20013;&#30340;&#22240;&#23376;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Martian time-series unraveled: A multi-scale nested approach with factorial variational autoencoders. (arXiv:2305.16189v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16189
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#22312;MRO&#25968;&#25454;&#38598;&#19978;&#23637;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#28304;&#20998;&#31163;&#28041;&#21450;&#36890;&#36807;&#28151;&#21512;&#25805;&#20316;&#35760;&#24405;&#30340;&#26410;&#30693;&#28304;&#20449;&#21495;&#30340;&#20998;&#35299;&#65292;&#20854;&#20013;&#23545;&#28304;&#30340;&#20808;&#39564;&#30693;&#35782;&#26377;&#38480;&#65292;&#20165;&#21487;&#20197;&#35775;&#38382;&#20449;&#21495;&#28151;&#21512;&#25968;&#25454;&#38598;&#12290;&#36825;&#20010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#19981;&#36866;&#29992;&#30340;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#21463;&#21040;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#28304;&#23637;&#29616;&#20986;&#30340;&#22810;&#31181;&#26102;&#38388;&#23610;&#24230;&#30340;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#22810;&#23610;&#24230;&#32858;&#31867;&#21644;&#28304;&#20998;&#31163;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#23567;&#27874;&#25955;&#23556;&#21327;&#26041;&#24046;&#26469;&#25552;&#20379;&#38543;&#26426;&#36807;&#31243;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#30340;&#38750;&#39640;&#26031;&#38543;&#26426;&#36807;&#31243;&#12290;&#22312;&#36825;&#20010;&#34920;&#31034;&#31354;&#38388;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22240;&#23376;&#39640;&#26031;&#28151;&#21512;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#23427;&#34987;&#35757;&#32451;&#29992;&#20110;(1)&#27010;&#29575;&#22320;&#23545;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#28304;&#36827;&#34892;&#32858;&#31867;&#21644;&#36880;&#23618;&#38750;&#30417;&#30563;&#28304;&#20998;&#31163;&#65292;(2)&#22312;&#27599;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#25552;&#21462;&#20302;&#32500;&#34920;&#31034;&#65292;(3)&#23398;&#20064;&#28304;&#20449;&#21495;&#30340;&#22240;&#23376;&#34920;&#31034;&#65292;(4)&#22312;&#34920;&#31034;&#31354;&#38388;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#20197;&#29983;&#25104;&#26410;&#30693;&#28304;&#20449;&#21495;&#12290;&#25105;&#20204;&#22312;MRO&#19978;&#30340;&#19977;&#20010;&#39057;&#36947;&#30340;&#21487;&#35265;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised source separation involves unraveling an unknown set of source signals recorded through a mixing operator, with limited prior knowledge about the sources, and only access to a dataset of signal mixtures. This problem is inherently ill-posed and is further challenged by the variety of time-scales exhibited by sources in time series data. Existing methods typically rely on a preselected window size that limits their capacity to handle multi-scale sources. To address this issue, instead of operating in the time domain, we propose an unsupervised multi-scale clustering and source separation framework by leveraging wavelet scattering covariances that provide a low-dimensional representation of stochastic processes, capable of distinguishing between different non-Gaussian stochastic processes. Nested within this representation space, we develop a factorial Gaussian-mixture variational autoencoder that is trained to (1) probabilistically cluster sources at different time-scales a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#12290;</title><link>http://arxiv.org/abs/2305.16150</link><description>&lt;p&gt;
&#32479;&#19968;GAN&#21644;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#30340;&#31890;&#23376;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20363;&#22914;&#26799;&#24230;&#27969;&#21644;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#24778;&#20154;&#30340;&#24615;&#33021;&#32780;&#26368;&#36817;&#21463;&#21040;&#20851;&#27880;&#12290;&#20256;&#32479;&#19978;&#65292;&#36890;&#36807;&#24494;&#20998;&#26041;&#31243;&#26469;&#31227;&#21160;&#31890;&#23376;&#20998;&#24067;&#30340;&#26041;&#27861;&#34987;&#26222;&#36941;&#35748;&#20026;&#26159;&#19982;&#20197;&#21069;&#24191;&#27867;&#20351;&#29992;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30456;&#23545;&#31435;&#30340;&#65292;&#21518;&#32773;&#28041;&#21450;&#21040;&#35757;&#32451;&#19968;&#20010;&#21521;&#21069;&#30340;&#29983;&#25104;&#22120;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#36825;&#31181;&#35299;&#37322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#25512;&#24191;&#12290;&#36825;&#34920;&#26126;&#65292;&#29983;&#25104;&#22120;&#26159;&#20219;&#20309;&#36825;&#26679;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#36873;&#38468;&#20214;&#12290;&#22240;&#27492;&#65292;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#33258;&#28982;&#22320;&#20986;&#29616;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#27979;&#35797;&#36825;&#20123;&#21407;&#22987;&#27169;&#22411;&#30340;&#21487;&#34892;&#24615;&#65292;&#36825;&#20123;&#27169;&#22411;&#26159;&#25105;&#20204;&#26694;&#26550;&#21487;&#33021;&#24212;&#29992;&#30340;&#27010;&#24565;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Particle-based deep generative models, such as gradient flows and score-based diffusion models, have recently gained traction thanks to their striking performance. Their principle of displacing particle distributions by differential equations is conventionally seen as opposed to the previously widespread generative adversarial networks (GANs), which involve training a pushforward generator network. In this paper, we challenge this interpretation and propose a novel framework that unifies particle and adversarial generative models by framing generator training as a generalization of particle models. This suggests that a generator is an optional addition to any such generative model. Consequently, integrating a generator into a score-based diffusion model and training a GAN without a generator naturally emerge from our framework. We empirically test the viability of these original models as proofs of concepts of potential applications of our framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.16102</link><description>&lt;p&gt;
&#25581;&#31034;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#25351;&#30340;&#26159;&#22686;&#21152;&#32593;&#32476;&#28145;&#24230;&#23548;&#33268;&#33410;&#28857;&#34920;&#31034;&#21464;&#24471;&#30456;&#21516;&#30340;&#29616;&#35937;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#23454;&#20102;&#22270;&#21367;&#31215;&#32593;&#32476;(GCN)&#20250;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26159;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#21542;&#21487;&#20197;&#32531;&#35299;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#36824;&#23384;&#22312;&#20105;&#35758;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#35270;&#20026;&#38750;&#32447;&#24615;&#26102;&#21464;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#32467;&#21512;&#38750;&#40784;&#27425;&#30697;&#38453;&#20056;&#31215;&#21644;&#32852;&#21512;&#35889;&#21322;&#24452;&#29702;&#35770;&#30340;&#24037;&#20855;&#21644;&#25216;&#26415;&#65292;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#27969;&#34892;&#35266;&#28857;&#30456;&#21453;&#65292;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#19981;&#33021;&#38450;&#27490;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;&#65292;&#24182;&#19988;&#21576;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#23545;&#31216;GCN&#30340;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;GNN&#27169;&#22411;&#31867;&#21035;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#32771;&#34385;&#20102;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models. In particular, our analysis accounts for asymmetric, state-dep
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FAVAS&#31639;&#27861;&#65292;&#26159;&#19968;&#31181;&#29992;&#20110;&#22312;&#36164;&#28304;&#26377;&#38480;&#29615;&#22659;&#19979;&#35757;&#32451;DNNs&#30340;&#26032;&#22411;&#20013;&#24515;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;FAVAS&#31639;&#27861;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.16099</link><description>&lt;p&gt;
FAVAS: &#24102;&#26377;&#24322;&#27493;&#23458;&#25143;&#31471;&#30340;&#32852;&#37030;&#24179;&#22343;&#30340;&#26032;&#22411;&#20013;&#24515;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FAVAS: Federated AVeraging with ASynchronous clients. (arXiv:2305.16099v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FAVAS&#31639;&#27861;&#65292;&#26159;&#19968;&#31181;&#29992;&#20110;&#22312;&#36164;&#28304;&#26377;&#38480;&#29615;&#22659;&#19979;&#35757;&#32451;DNNs&#30340;&#26032;&#22411;&#20013;&#24515;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;FAVAS&#31639;&#27861;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#20013;&#24515;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;FAVAS&#65292;&#29992;&#20110;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#19979;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#23613;&#31649;&#32852;&#37030;&#23398;&#20064;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#22823;&#22411;&#26080;&#32447;&#32593;&#32476;&#19978;&#20280;&#32553;&#21516;&#27493;&#36890;&#20449;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#23458;&#25143;&#31471;&#36890;&#24120;&#20855;&#26377;&#19981;&#21516;&#30340;&#35745;&#31639;&#36164;&#28304;&#21644;&#35745;&#31639;&#36895;&#24230;&#65292;&#24322;&#27493;&#26356;&#26032;&#21487;&#33021;&#20250;&#23548;&#33268;&#26174;&#30528;&#30340;&#20559;&#24046;&#65288;&#23545;&#8220;&#24555;&#36895;&#8221;&#23458;&#25143;&#31471;&#26356;&#26377;&#21033;&#65289;&#12290;&#22240;&#27492;&#65292;FL&#30340;&#23454;&#38469;&#37096;&#32626;&#38656;&#35201;&#22788;&#29702;&#22312;&#36890;&#20449;/&#36164;&#28304;&#21463;&#38480;&#30340;&#29615;&#22659;&#20013;&#20855;&#26377;&#24378;&#28872;&#21464;&#21270;&#30340;&#35745;&#31639;&#36895;&#24230;&#30340;&#29992;&#25143;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;FAVAS&#22312;&#24179;&#28369;&#30340;&#38750;&#20984;&#29615;&#22659;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#20180;&#32454;&#27604;&#36739;&#20102;&#33719;&#24471;&#30340;&#25910;&#25947;&#20445;&#35777;&#19982;&#29616;&#26377;&#36793;&#30028;&#65288;&#22914;&#26524;&#26377;&#65289;&#30340;&#24046;&#24322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;FAVAS&#31639;&#27861;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel centralized Asynchronous Federated Learning (FL) framework, FAVAS, for training Deep Neural Networks (DNNs) in resource-constrained environments. Despite its popularity, ``classical'' federated learning faces the increasingly difficult task of scaling synchronous communication over large wireless networks. Moreover, clients typically have different computing resources and therefore computing speed, which can lead to a significant bias (in favor of ``fast'' clients) when the updates are asynchronous. Therefore, practical deployment of FL requires to handle users with strongly varying computing speed in communication/resource constrained setting. We provide convergence guarantees for FAVAS in a smooth, non-convex environment and carefully compare the obtained convergence guarantees with existing bounds, when they are available. Experimental results show that the FAVAS algorithm outperforms current methods on standard benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#31616;&#21270;&#28041;&#21450;&#35745;&#31639;&#30340;&#24433;&#21709;&#20989;&#25968;&#65292;&#25552;&#39640;&#20102;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#35757;&#32451;&#25928;&#29575;&#24182;&#20445;&#35777;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#24433;&#21709;&#20540;&#30340;&#31526;&#21495;&#21487;&#20197;&#25351;&#31034;&#35757;&#32451;&#28857;&#26159;&#29992;&#20110;&#35760;&#24518;&#36824;&#26159;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.16094</link><description>&lt;p&gt;
&#35770;&#24433;&#21709;&#20989;&#25968;&#12289;&#20998;&#31867;&#24433;&#21709;&#12289;&#30456;&#23545;&#24433;&#21709;&#12289;&#35760;&#24518;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Influence Functions, Classification Influence, Relative Influence, Memorization and Generalization. (arXiv:2305.16094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#31616;&#21270;&#28041;&#21450;&#35745;&#31639;&#30340;&#24433;&#21709;&#20989;&#25968;&#65292;&#25552;&#39640;&#20102;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#35757;&#32451;&#25928;&#29575;&#24182;&#20445;&#35777;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#24433;&#21709;&#20540;&#30340;&#31526;&#21495;&#21487;&#20197;&#25351;&#31034;&#35757;&#32451;&#28857;&#26159;&#29992;&#20110;&#35760;&#24518;&#36824;&#26159;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#35832;&#22914;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#25110;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#31995;&#32479;&#20043;&#31867;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#37117;&#35201;&#22312;&#25968;&#21313;&#20159;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#25968;&#30334;&#20159;&#25110;&#19975;&#20159;&#20010;&#21442;&#25968;&#30340;&#25903;&#25345;&#19979;&#36827;&#34892;&#35757;&#32451;&#12290;&#22914;&#20309;&#25913;&#36827;&#23398;&#20064;&#36807;&#31243;&#65292;&#38477;&#20302;&#35757;&#32451;&#36127;&#33655;&#65292;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#26159;&#38750;&#24120;&#24517;&#35201;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#20174;&#31616;&#21270;&#28041;&#21450;&#35745;&#31639;&#30340;&#24433;&#21709;&#20989;&#25968;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25506;&#32034;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#31532;&#19968;&#27493;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#24433;&#21709;&#35745;&#31639;&#21487;&#20197;&#22312;&#26174;&#33879;&#26356;&#23569;&#30340;&#21442;&#25968;&#19979;&#36827;&#34892;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#24433;&#21709;&#20540;&#30340;&#31526;&#21495;&#21487;&#20197;&#25351;&#31034;&#35757;&#32451;&#28857;&#26159;&#29992;&#20110;&#35760;&#24518;&#36824;&#26159;&#27867;&#21270;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#27491;&#24335;&#23450;&#20041;&#20102;&#23545;&#20110;&#35757;&#32451;&#28857;&#32780;&#35328;&#20160;&#20040;&#26159;&#35760;&#24518;&#21644;&#27867;&#21270;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#21363;&#20351;&#23545;&#20110;&#22823;&#22411;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#65292;&#24433;&#21709;&#20989;&#25968;&#20063;&#21487;&#20197;&#23454;&#29992;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning systems such as large scale recommendation systems or natural language processing systems are usually trained on billions of training points and are associated with hundreds of billions or trillions of parameters. Improving the learning process in such a way that both the training load is reduced and the model accuracy improved is highly desired. In this paper we take a first step toward solving this problem, studying influence functions from the perspective of simplifying the computations they involve. We discuss assumptions, under which influence computations can be performed on significantly fewer parameters. We also demonstrate that the sign of the influence value can indicate whether a training point is to memorize, as opposed to generalize upon. For this purpose we formally define what memorization means for a training point, as opposed to generalization. We conclude that influence functions can be made practical, even for large scale machine learning systems, an
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#37319;&#26679;&#35268;&#21017;EB-TC $\varepsilon$&#65292;&#29992;&#20110;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#30340;$\varepsilon$-&#26368;&#20339;&#33218;&#30340;&#36776;&#35782;&#12290;&#35813;&#35268;&#21017;&#21487;&#29992;&#20110;&#30830;&#23450;&#22266;&#23450;&#32622;&#20449;&#24230;&#25110;&#22266;&#23450;&#39044;&#31639;&#26631;&#35782;&#19988;&#20855;&#22791;&#33258;&#36866;&#24212;&#35843;&#25972;&#21208;&#25506;&#21442;&#25968;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#22312;&#20223;&#30495;&#23454;&#39564;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#38382;&#39064;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.16041</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#30830;&#23450;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#20197;&#19978;&#30340; $\varepsilon$-&#26368;&#20339;&#33218;&#36776;&#35782;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An $\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence and Beyond. (arXiv:2305.16041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16041
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#37319;&#26679;&#35268;&#21017;EB-TC $\varepsilon$&#65292;&#29992;&#20110;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#30340;$\varepsilon$-&#26368;&#20339;&#33218;&#30340;&#36776;&#35782;&#12290;&#35813;&#35268;&#21017;&#21487;&#29992;&#20110;&#30830;&#23450;&#22266;&#23450;&#32622;&#20449;&#24230;&#25110;&#22266;&#23450;&#39044;&#31639;&#26631;&#35782;&#19988;&#20855;&#22791;&#33258;&#36866;&#24212;&#35843;&#25972;&#21208;&#25506;&#21442;&#25968;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#22312;&#20223;&#30495;&#23454;&#39564;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#38382;&#39064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#37319;&#26679;&#35268;&#21017;EB-TC $\varepsilon$&#65292;&#35813;&#35268;&#21017;&#29992;&#20110;&#38543;&#26426;&#36172;&#21338;&#26426;&#20013;&#30340;$\varepsilon$-&#26368;&#20339;&#33218;&#30340;&#36776;&#35782;&#12290;&#36825;&#26159;&#31532;&#19968;&#31181;&#29992;&#20110;&#36817;&#20284;&#26368;&#20339;&#33218;&#36776;&#35782;&#30340;Top Two&#31639;&#27861;&#20998;&#26512;&#23454;&#20363;&#12290; EB-TC $\varepsilon$ &#26159;&#19968;&#31181;&#8220;&#38543;&#26102;&#21487;&#29992;&#8221;&#30340;&#37319;&#26679;&#35268;&#21017;&#65292;&#22240;&#27492;&#21487;&#20197;&#22312;&#27809;&#26377;&#39044;&#31639;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#29992;&#20110;&#30830;&#23450;&#22266;&#23450;&#32622;&#20449;&#24230;&#25110;&#22266;&#23450;&#39044;&#31639;&#26631;&#35782;&#65288;&#26080;&#38656;&#20462;&#25913;&#65289;&#12290;&#25105;&#20204;&#20026;EB-TC $\varepsilon$ &#25552;&#20379;&#20102;&#19977;&#31181;&#29702;&#35770;&#20445;&#35777;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20854;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#35774;&#32622;&#20013;&#39044;&#26399;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#26377;&#30028;&#65292;&#29305;&#21035;&#26159;&#22312;&#20854;&#21208;&#25506;&#21442;&#25968;&#30340;&#33258;&#36866;&#24212;&#35843;&#25972;&#19982;&#32452;&#21512;&#30340;&#24773;&#20917;&#19979;&#21576;&#29616;&#20854;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#20219;&#20309;&#26102;&#38388;&#21644;&#23545;&#20110;&#20219;&#20309;&#35823;&#24046;&#21442;&#25968;&#30340;&#27010;&#29575;&#19978;&#30028;&#26469;&#34917;&#20805;&#36825;&#20123;&#21457;&#29616;&#65292;&#36825;&#36827;&#19968;&#27493;&#20135;&#29983;&#20854;&#20219;&#20309;&#26102;&#38388;&#30340;&#31616;&#21333;&#36951;&#25022;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#65292;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#27604;&#65292;EB-TC $\varepsilon$ &#30340;&#24615;&#33021;&#34920;&#29616;&#20248;&#31168;&#65292;&#19988;&#36866;&#29992;&#20110;&#19981;&#21516;&#38382;&#39064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose EB-TC$\varepsilon$, a novel sampling rule for $\varepsilon$-best arm identification in stochastic bandits. It is the first instance of Top Two algorithm analyzed for approximate best arm identification. EB-TC$\varepsilon$ is an *anytime* sampling rule that can therefore be employed without modification for fixed confidence or fixed budget identification (without prior knowledge of the budget). We provide three types of theoretical guarantees for EB-TC$\varepsilon$. First, we prove bounds on its expected sample complexity in the fixed confidence setting, notably showing its asymptotic optimality in combination with an adaptive tuning of its exploration parameter. We complement these findings with upper bounds on its probability of error at any time and for any error parameter, which further yield upper bounds on its simple regret at any time. Finally, we show through numerical simulations that EB-TC$\varepsilon$ performs favorably compared to existing algorithms, in different
&lt;/p&gt;</description></item><item><title>&#22312;$L_{2}$-&#27491;&#21017;&#21270;&#32447;&#24615;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#20351;&#29992;SGD&#20250;&#20135;&#29983;&#20174;&#26356;&#39640;&#31209;&#26368;&#23567;&#20540;&#21040;&#26356;&#20302;&#31209;&#26368;&#23567;&#20540;&#30340;&#21333;&#21521;&#36339;&#36291;&#65292;&#24182;&#19988;&#19981;&#20250;&#36339;&#22238;&#12290;</title><link>http://arxiv.org/abs/2305.16038</link><description>&lt;p&gt;
$L_{2}$&#27491;&#21017;&#32447;&#24615;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#38544;&#24615;SGD&#20559;&#24046;&#65306;&#20174;&#39640;&#31209;&#21040;&#20302;&#31209;&#30340;&#21333;&#21521;&#36339;&#36291;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit bias of SGD in $L_{2}$-regularized linear DNNs: One-way jumps from high to low rank. (arXiv:2305.16038v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16038
&lt;/p&gt;
&lt;p&gt;
&#22312;$L_{2}$-&#27491;&#21017;&#21270;&#32447;&#24615;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#20351;&#29992;SGD&#20250;&#20135;&#29983;&#20174;&#26356;&#39640;&#31209;&#26368;&#23567;&#20540;&#21040;&#26356;&#20302;&#31209;&#26368;&#23567;&#20540;&#30340;&#21333;&#21521;&#36339;&#36291;&#65292;&#24182;&#19988;&#19981;&#20250;&#36339;&#22238;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#22810;&#20010;&#38544;&#34255;&#23618;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#65288;DLN&#65289;&#30340;$L_{2}$&#27491;&#21017;&#21270;&#25439;&#22833;&#20855;&#26377;&#22810;&#20010;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#23545;&#24212;&#20110;&#20855;&#26377;&#19981;&#21516;&#31209;&#30340;&#30697;&#38453;&#12290;&#22312;&#30697;&#38453;&#23436;&#25104;&#31561;&#20219;&#21153;&#20013;&#65292;&#30446;&#26631;&#26159;&#25910;&#25947;&#21040;&#26368;&#23567;&#31209;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#35813;&#23616;&#37096;&#26368;&#23567;&#20540;&#20173;&#36866;&#21512;&#35757;&#32451;&#25968;&#25454;&#12290;&#34429;&#28982;&#21487;&#20197;&#36731;&#26494;&#36991;&#20813;&#20302;&#20272;&#31209;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#36866;&#21512;&#25968;&#25454;&#65292;&#20294;&#26799;&#24230;&#19979;&#38477;&#21487;&#33021;&#20250;&#38519;&#20837;&#39640;&#20272;&#31209;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;SGD&#65292;&#24635;&#26159;&#26377;&#20174;&#26356;&#39640;&#31209;&#26368;&#23567;&#20540;&#36339;&#36291;&#21040;&#26356;&#20302;&#31209;&#26368;&#23567;&#20540;&#30340;&#27010;&#29575;&#65292;&#20294;&#36339;&#22238;&#30340;&#27010;&#29575;&#20026;&#38646;&#12290;&#26356;&#31934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31995;&#21015;&#38598;&#21512;$B_{1}\subset B_{2}\subset\cdots\subset B_{R}$&#65292;&#20351;&#24471;$B_{r}$&#21253;&#21547;&#31209;$r$&#25110;&#26356;&#23569;&#30340;&#25152;&#26377;&#26368;&#23567;&#20540;&#65288;&#32780;&#19981;&#26159;&#26356;&#22810;&#65289;&#65292;&#23545;&#20110;&#36275;&#22815;&#23567;&#30340;&#23725;&#21442;&#25968;$\lambda$&#21644;&#23398;&#20064;&#29575;$\eta$&#65292;&#23427;&#20204;&#26159;&#21560;&#25910;&#30340;&#65306;SGD&#31163;&#24320;$B_{r}$&#30340;&#27010;&#29575;&#20026;0&#65292;&#20174;&#20219;&#20309;&#36215;&#28857;&#24320;&#22987;&#65292;SGD&#36827;&#20837;$B_{r}$&#30340;&#27010;&#29575;&#38750;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $L_{2}$-regularized loss of Deep Linear Networks (DLNs) with more than one hidden layers has multiple local minima, corresponding to matrices with different ranks. In tasks such as matrix completion, the goal is to converge to the local minimum with the smallest rank that still fits the training data. While rank-underestimating minima can easily be avoided since they do not fit the data, gradient descent might get stuck at rank-overestimating minima. We show that with SGD, there is always a probability to jump from a higher rank minimum to a lower rank one, but the probability of jumping back is zero. More precisely, we define a sequence of sets $B_{1}\subset B_{2}\subset\cdots\subset B_{R}$ so that $B_{r}$ contains all minima of rank $r$ or less (and not more) that are absorbing for small enough ridge parameters $\lambda$ and learning rates $\eta$: SGD has prob. 0 of leaving $B_{r}$, and from any starting point there is a non-zero prob. for SGD to go in $B_{r}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#19979;&#30028;&#65292;&#25506;&#35752;&#20102;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#26102;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#37327;&#21450;&#20854;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.16014</link><description>&lt;p&gt;
&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#38656;&#35201;&#22810;&#23569;&#26679;&#26412;&#25165;&#33021;&#21033;&#29992;&#24179;&#28369;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many samples are needed to leverage smoothness?. (arXiv:2305.16014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#19979;&#30028;&#65292;&#25506;&#35752;&#20102;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#26102;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#37327;&#21450;&#20854;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#30340;&#26680;&#24515;&#21407;&#21017;&#20043;&#19968;&#26159;&#65292;&#30446;&#26631;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#21487;&#20197;&#25171;&#30772;&#32500;&#24230;&#28798;&#38590;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#27888;&#21202;&#23637;&#24320;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#38656;&#35201;&#36275;&#22815;&#25509;&#36817;&#19968;&#36215;&#30340;&#26679;&#26412;&#26469;&#33719;&#24471;&#39640;&#38454;&#23548;&#25968;&#30340;&#26377;&#24847;&#20041;&#20272;&#35745;&#65292;&#36825;&#22312;&#25968;&#25454;&#37327;&#30456;&#23545;&#36739;&#23567;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#20284;&#20046;&#24456;&#22256;&#38590;&#12290;&#26412;&#25991;&#36890;&#36807;&#25512;&#23548;&#24191;&#20041;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#30340;&#19979;&#30028;&#65292;&#30740;&#31350;&#20102;&#24120;&#25968;&#21644;&#30636;&#24577;&#21306;&#22495;&#22312;&#23454;&#36341;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#21364;&#21457;&#25381;&#20102;&#20027;&#23548;&#20316;&#29992;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A core principle in statistical learning is that smoothness of target functions allows to break the curse of dimensionality. However, learning a smooth function through Taylor expansions requires enough samples close to one another to get meaningful estimate of high-order derivatives, which seems hard in machine learning problems where the ratio between number of data and input dimension is relatively small. Should we really hope to break the curse of dimensionality based on Taylor expansion estimation? What happens if Taylor expansions are replaced by Fourier or wavelet expansions? By deriving a new lower bound on the generalization error, this paper investigates the role of constants and transitory regimes which are usually not depicted beyond classical learning theory statements while that play a dominant role in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38750;&#23545;&#25968;&#20984;&#20998;&#24067;&#36827;&#34892;&#36817;&#20284;&#25277;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807; Langevin Monte Carlo &#31639;&#27861;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#36825;&#20123;&#20219;&#21153;&#28304;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#22270;&#20687;&#21453;&#38382;&#39064;&#12290;&#25968;&#20540;&#27169;&#25311;&#27604;&#36739;&#20102;&#26368;&#24120;&#29992;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15988</link><description>&lt;p&gt;
&#38750;&#23545;&#25968;&#20984;&#21644;&#38750;&#20809;&#28369;&#37319;&#26679;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-Log-Concave and Nonsmooth Sampling via Langevin Monte Carlo Algorithms. (arXiv:2305.15988v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38750;&#23545;&#25968;&#20984;&#20998;&#24067;&#36827;&#34892;&#36817;&#20284;&#25277;&#26679;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807; Langevin Monte Carlo &#31639;&#27861;&#35299;&#20915;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#36825;&#20123;&#20219;&#21153;&#28304;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#22270;&#20687;&#21453;&#38382;&#39064;&#12290;&#25968;&#20540;&#27169;&#25311;&#27604;&#36739;&#20102;&#26368;&#24120;&#29992;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#38750;&#23545;&#25968;&#20984;&#20998;&#24067;&#65288;&#20363;&#22914;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#65289;&#36827;&#34892;&#36817;&#20284;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#31163;&#25955;&#36807;&#24230;&#38459;&#23612; Langevin &#25193;&#25955;&#25152;&#23548;&#20986;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#31216;&#20026; Langevin Monte Carlo &#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20004;&#31181;&#38750;&#20809;&#28369;&#24773;&#20917;&#65292;&#20854;&#20013;&#24050;&#32463;&#24320;&#21457;&#20102;&#22823;&#37327;&#30340;&#36817;&#31471; MCMC &#26041;&#27861;&#65306;(i) &#32771;&#34385;&#21040;&#38750;&#20809;&#28369;&#30340;&#20808;&#39564;&#21644;&#39640;&#26031;&#28151;&#21512;&#20284;&#28982;&#65307;(ii) &#25289;&#26222;&#25289;&#26031;&#28151;&#21512;&#20998;&#24067;&#12290;&#36825;&#26679;&#30340;&#38750;&#20809;&#28369;&#21644;&#38750;&#23545;&#25968;&#20984;&#37319;&#26679;&#20219;&#21153;&#28304;&#20110;&#24191;&#27867;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#22270;&#20687;&#21453;&#38382;&#39064;&#65292;&#22914;&#22270;&#20687;&#21453;&#35126;&#31215;&#20013;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#27169;&#25311;&#20197;&#27604;&#36739;&#26368;&#24120;&#29992;&#30340; Langevin Monte Carlo &#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of approximate sampling from non-log-concave distributions, e.g., Gaussian mixtures, which is often challenging even in low dimensions due to their multimodality. We focus on performing this task via Markov chain Monte Carlo (MCMC) methods derived from discretizations of the overdamped Langevin diffusions, which are commonly known as Langevin Monte Carlo algorithms. Furthermore, we are also interested in two nonsmooth cases for which a large class of proximal MCMC methods have been developed: (i) a nonsmooth prior is considered with a Gaussian mixture likelihood; (ii) a Laplacian mixture distribution. Such nonsmooth and non-log-concave sampling tasks arise from a wide range of applications to Bayesian inference and imaging inverse problems such as image deconvolution. We perform numerical simulations to compare the performance of most commonly used Langevin Monte Carlo algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#39532;&#23572;&#31185;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#20984;&#21644;&#24378;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#20197;&#33719;&#24471;&#26368;&#20248;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#28040;&#38500;&#20102;&#20197;&#21069;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#26465;&#20214;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#19979;&#23545;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#26159;&#21407;&#21019;&#24615;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.15938</link><description>&lt;p&gt;
&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#19968;&#38454;&#26041;&#27861;&#65306;&#20174;&#21152;&#36895;&#21040;&#21464;&#20998;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities. (arXiv:2305.15938v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28041;&#21450;&#39532;&#23572;&#31185;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#20984;&#21644;&#24378;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#20197;&#33719;&#24471;&#26368;&#20248;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#28040;&#38500;&#20102;&#20197;&#21069;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#26465;&#20214;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#19979;&#23545;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#26159;&#21407;&#21019;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#28041;&#21450;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#26469;&#29702;&#35770;&#20998;&#26512;&#19968;&#38454;&#26799;&#24230;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#38543;&#26426;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28085;&#30422;&#20102;&#38750;&#20984;&#21644;&#24378;&#20984;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#23454;&#29616;&#19968;&#20010;&#20381;&#36182;&#20110;&#24213;&#23618;&#22122;&#22768;&#24207;&#21015;&#28151;&#21512;&#26102;&#38388;&#30340;&#26368;&#20248;(&#32447;&#24615;)&#20851;&#31995;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#20801;&#35768;&#25105;&#20204;&#28040;&#38500;&#20197;&#21069;&#20851;&#20110;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#30340;&#30740;&#31350;&#20013;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#20363;&#22914;&#38656;&#35201;&#26377;&#30028;&#22495;&#21644;&#22343;&#21248;&#26377;&#30028;&#38543;&#26426;&#26799;&#24230;&#12290;&#25105;&#20204;&#22312;&#39532;&#23572;&#21487;&#22827;&#22122;&#22768;&#19979;&#23545;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#25193;&#23637;&#26159;&#21407;&#21019;&#24615;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21305;&#37197;&#24378;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#26368;&#20248;&#35299;&#30340;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper delves into stochastic optimization problems that involve Markovian noise. We present a unified approach for the theoretical analysis of first-order gradient methods for stochastic optimization and variational inequalities. Our approach covers scenarios for both non-convex and strongly convex minimization problems. To achieve an optimal (linear) dependence on the mixing time of the underlying noise sequence, we use the randomized batching scheme, which is based on the multilevel Monte Carlo method. Moreover, our technique allows us to eliminate the limiting assumptions of previous research on Markov noise, such as the need for a bounded domain and uniformly bounded stochastic gradients. Our extension to variational inequalities under Markovian noise is original. Additionally, we provide lower bounds that match the oracle complexity of our method in the case of strongly convex optimization problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;</title><link>http://arxiv.org/abs/2305.15925</link><description>&lt;p&gt;
&#20851;&#20110;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability of Markov Switching Models. (arXiv:2305.15925v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#22240;&#20854;&#22312;&#21487;&#35299;&#37322;&#24615;&#25110;&#20998;&#24067;&#27867;&#21270;&#26041;&#38754;&#30340;&#24212;&#29992;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20316;&#20026;&#23558;&#26368;&#36817;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#24207;&#21015;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#31532;&#19968;&#27493;&#30340;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#22312;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#25552;&#20986;&#20102;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifiability of latent variable models has recently gained interest in terms of its applications to interpretability or out of distribution generalisation. In this work, we study identifiability of Markov Switching Models as a first step towards extending recent results to sequential latent variable models. We present identifiability conditions within first-order Markov dependency structures, and parametrise the transition distribution via non-linear Gaussians. Our experiments showcase the applicability of our approach for regime-dependent causal discovery and high-dimensional time series segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;GAN&#26469;&#23398;&#20064;&#19968;&#20010;&#21407;&#22411;&#26230;&#26684;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#21512;&#36866;&#30340;&#22810;&#27169;&#22411;&#31243;&#24207;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31934;&#24230;&#12290;GAN&#20284;&#20046;&#26159;&#22788;&#29702;&#22797;&#26434;&#32479;&#35745;&#21160;&#21147;&#23398;&#38382;&#39064;&#30340;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.15920</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#27169;&#22411;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#23398;&#20064;&#21644;&#31934;&#30830;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Learning and accurate generation of stochastic dynamics based on multi-model Generative Adversarial Networks. (arXiv:2305.15920v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;GAN&#26469;&#23398;&#20064;&#19968;&#20010;&#21407;&#22411;&#26230;&#26684;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#21512;&#36866;&#30340;&#22810;&#27169;&#22411;&#31243;&#24207;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31934;&#24230;&#12290;GAN&#20284;&#20046;&#26159;&#22788;&#29702;&#22797;&#26434;&#32479;&#35745;&#21160;&#21147;&#23398;&#38382;&#39064;&#30340;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#24050;&#32463;&#22312;&#36828;&#31163;&#29289;&#29702;&#39046;&#22495;&#65292;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#23637;&#31034;&#20986;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#20351;&#29992;GAN&#26469;&#23398;&#20064;&#19968;&#20010;&#21407;&#22411;&#26230;&#26684;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#12290;&#36890;&#36807;&#21512;&#29702;&#22320;&#21521;&#21407;&#22987;&#25968;&#25454;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#23558;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#25439;&#22833;&#20989;&#25968;&#30340;&#20540;&#24102;&#21040;&#20102;&#23427;&#20204;&#30340;&#29702;&#24819;&#20540;&#38468;&#36817;&#12290;&#28982;&#32780;&#65292;&#20687;&#23545;&#25239;&#24615;&#26041;&#27861;&#19968;&#26679;&#65292;&#38663;&#33633;&#20173;&#28982;&#23384;&#22312;&#12290;&#36825;&#20250;&#30772;&#22351;&#27169;&#22411;&#36873;&#25321;&#21644;&#29983;&#25104;&#36712;&#36857;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#19968;&#31181;&#21512;&#36866;&#30340;&#22810;&#27169;&#22411;&#31243;&#24207;&#65292;&#22312;&#27599;&#19968;&#27493;&#38543;&#26426;&#36873;&#25321;&#29983;&#25104;&#22120;&#25512;&#36827;&#38543;&#26426;&#36712;&#36857;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31934;&#24230;&#12290;&#22522;&#20110;&#20197;&#19978;&#21457;&#29616;&#65292;GAN&#20284;&#20046;&#26159;&#22788;&#29702;&#22797;&#26434;&#32479;&#35745;&#21160;&#21147;&#23398;&#38382;&#39064;&#30340;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs) have shown immense potential in fields far from physics, such as in text and image generation. Here we use GANs to learn a prototypical stochastic process on a lattice. By suitably adding noise to the original data we succeed in bringing both the Generator and the Discriminator loss functions close to their ideal value. However, as typical for adversarial approaches, oscillations persist. This undermines model selection and the quality of the generated trajectory. We demonstrate that a suitable multi-model procedure where stochastic trajectories are advanced at each step upon randomly selecting a Generator leads to a remarkable increase in accuracy. Based on the reported findings GANs appears as a promising tool to tackle complex statistical dynamics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15912</link><description>&lt;p&gt;
&#25913;&#36827;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#30340;&#31070;&#32463;&#29305;&#24449;&#28608;&#27963;&#20540;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Neural Characteristic Activation Value Analysis for Improved ReLU Network Feature Learning. (arXiv:2305.15912v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;ReLU&#21333;&#20803;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#36827;&#34892;&#21442;&#25968;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#30340;&#35268;&#33539;&#21270;&#25216;&#26415;&#65292;&#25913;&#36827;&#20102;ReLU&#32593;&#32476;&#29305;&#24449;&#23398;&#20064;&#65292;&#25552;&#39640;&#20102;&#20248;&#21270;&#31283;&#23450;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#21333;&#20010;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#12290;&#25105;&#20204;&#23558;ReLU&#21333;&#20803;&#22312;&#36755;&#20837;&#31354;&#38388;&#20013;&#23545;&#24212;&#30340;&#29305;&#24449;&#28608;&#27963;&#20540;&#38598;&#21512;&#31216;&#20026;ReLU&#21333;&#20803;&#30340;&#29305;&#24449;&#28608;&#27963;&#38598;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29305;&#24449;&#28608;&#27963;&#38598;&#19982;ReLU&#32593;&#32476;&#20013;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#26126;&#30830;&#32852;&#31995;&#65292;&#24182;&#25581;&#31034;&#20102;&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20013;&#20351;&#29992;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#35268;&#33539;&#21270;&#25216;&#26415;&#22914;&#20309;&#35268;&#33539;&#21270;&#21644;&#31283;&#23450;SGD&#20248;&#21270;&#12290;&#21033;&#29992;&#36825;&#20123;&#27934;&#35265;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20960;&#20309;&#26041;&#27861;&#26469;&#21442;&#25968;&#21270;ReLU&#32593;&#32476;&#20197;&#25913;&#36827;&#29305;&#24449;&#23398;&#20064;&#12290;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#20102;&#20854;&#26377;&#29992;&#24615;&#65292;&#20351;&#29992;&#20102;&#19981;&#37027;&#20040;&#31934;&#24515;&#36873;&#25321;&#30340;&#21021;&#22987;&#21270;&#26041;&#26696;&#21644;&#26356;&#22823;&#30340;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#26356;&#22909;&#30340;&#20248;&#21270;&#31283;&#23450;&#24615;&#65292;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#23398;&#20064;&#20013;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#20498;&#25968;&#20542;&#21521;&#35780;&#20998;(IPS)&#30340;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#25512;&#23548;&#20986;&#20102;&#21487;&#22788;&#29702;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#35299;&#37322;&#30340;&#23398;&#20064;&#35777;&#26126;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#20309;&#31181;&#24773;&#20917;&#19979;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;IPS&#12290;</title><link>http://arxiv.org/abs/2305.15877</link><description>&lt;p&gt;
&#25351;&#25968;&#24179;&#28369;&#29992;&#20110;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Exponential Smoothing for Off-Policy Learning. (arXiv:2305.15877v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#23398;&#20064;&#20013;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#20498;&#25968;&#20542;&#21521;&#35780;&#20998;(IPS)&#30340;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#25512;&#23548;&#20986;&#20102;&#21487;&#22788;&#29702;&#12289;&#21487;&#25193;&#23637;&#12289;&#21487;&#35299;&#37322;&#30340;&#23398;&#20064;&#35777;&#26126;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#20309;&#31181;&#24773;&#20917;&#19979;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;IPS&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#20498;&#25968;&#20542;&#21521;&#35780;&#20998;&#65288;IPS&#65289;&#26469;&#23547;&#25214;&#25913;&#36827;&#30340;&#31574;&#30053;&#65292;&#36890;&#24120;&#20351;&#29992;&#35760;&#24405;&#30340;&#36172;&#21338;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;IPS&#30340;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#21452;&#21521;PAC-Bayes&#27867;&#21270;&#30028;&#38480;&#12290;&#35813;&#30028;&#38480;&#26159;&#21487;&#22788;&#29702;&#30340;&#12289;&#21487;&#25193;&#23637;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#35777;&#26126;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23398;&#20064;&#20219;&#21153;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#30456;&#20851;&#24615;&#21644;&#26377;&#21033;&#30340;&#24615;&#33021;&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#30028;&#38480;&#36866;&#29992;&#20110;&#26631;&#20934;IPS&#65292;&#22240;&#27492;&#25105;&#20204;&#33021;&#22815;&#25552;&#20379;&#20851;&#20110;&#20309;&#26102;&#27491;&#21017;&#21270;IPS&#26377;&#29992;&#30340;&#35265;&#35299;&#12290;&#21363;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#12290;&#36825;&#19982;&#22312;&#23454;&#36341;&#20013;&#65292;&#21098;&#36753;IPS&#24120;&#24120;&#27604;OPL&#20013;&#30340;&#26631;&#20934;IPS&#34920;&#29616;&#26356;&#22909;&#30340;&#20449;&#24565;&#30456;&#21453;&#12290;
&lt;/p&gt;
&lt;p&gt;
Off-policy learning (OPL) aims at finding improved policies from logged bandit data, often by minimizing the inverse propensity scoring (IPS) estimator of the risk. In this work, we investigate a smooth regularization for IPS, for which we derive a two-sided PAC-Bayes generalization bound. The bound is tractable, scalable, interpretable and provides learning certificates. In particular, it is also valid for standard IPS without making the assumption that the importance weights are bounded. We demonstrate the relevance of our approach and its favorable performance through a set of learning tasks. Since our bound holds for standard IPS, we are able to provide insight into when regularizing IPS is useful. Namely, we identify cases where regularization might not be needed. This goes against the belief that, in practice, clipped IPS often enjoys favorable performance than standard IPS in OPL.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#39318;&#20010;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#65288;&#22914;ABC&#21644;NPE&#65289;&#20013;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#24341;&#36215;&#30340;&#19981;&#21487;&#38752;&#25512;&#35770;&#12290;&#36890;&#36807;&#32422;&#26463;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#24809;&#32602;&#19982;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#26469;&#38450;&#27490;&#19981;&#21487;&#38752;&#25512;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15871</link><description>&lt;p&gt;
&#23398;&#20064;&#40065;&#26834;&#32479;&#35745;&#29992;&#20110;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#19979;&#30340;&#22522;&#20110;&#27169;&#25311;&#25512;&#35770;
&lt;/p&gt;
&lt;p&gt;
Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#39318;&#20010;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#65288;&#22914;ABC&#21644;NPE&#65289;&#20013;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#24341;&#36215;&#30340;&#19981;&#21487;&#38752;&#25512;&#35770;&#12290;&#36890;&#36807;&#32422;&#26463;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#24809;&#32602;&#19982;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#26469;&#38450;&#27490;&#19981;&#21487;&#38752;&#25512;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#26041;&#27861;&#65288;&#22914;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#65288;ABC&#65289;&#65292;&#21512;&#25104;&#20284;&#28982;&#24615;&#21644;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;NPE&#65289;&#65289;&#20381;&#36182;&#20110;&#27169;&#25311;&#32479;&#35745;&#37327;&#20197;&#25512;&#26029;&#38590;&#20197;&#35745;&#31639;&#30340;&#20284;&#28982;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#24050;&#30693;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#19979;&#20250;&#20135;&#29983;&#19981;&#21487;&#20449;&#21644;&#35823;&#23548;&#24615;&#30340;&#25512;&#35770;&#32467;&#26524;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#36890;&#29992;&#26041;&#27861;&#26469;&#22788;&#29702;&#36328;&#19981;&#21516;&#31867;&#21035;&#30340;SBI&#26041;&#27861;&#30340;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#12290;&#21033;&#29992;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#30830;&#23450;SBI&#20013;&#30340;&#35823;&#24046;&#31243;&#24230;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#27491;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#65292;&#24809;&#32602;&#37027;&#20123;&#22686;&#21152;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#12290;&#20197;NPE&#21644;ABC&#20026;&#24212;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#24037;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#26469;&#33258;&#26080;&#32447;&#30005;&#20256;&#25773;&#39046;&#22495;&#30340;&#23454;&#38469;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC), synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalises those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;&#65292;&#24182;&#35777;&#26126;&#20102;Barron&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#31867;&#20284;&#20110;Sobolev&#31354;&#38388;$H^m$&#12290;&#20854;&#20013;&#65292;&#20462;&#27491;&#21151;&#29575;&#21333;&#20301;&#28608;&#27963;&#20989;&#25968;&#22312;&#36825;&#20010;&#30740;&#31350;&#20013;&#29305;&#21035;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2305.15839</link><description>&lt;p&gt;
&#20855;&#26377;&#39640;&#38454;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Embeddings between Barron spaces with higher order activation functions. (arXiv:2305.15839v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;&#65292;&#24182;&#35777;&#26126;&#20102;Barron&#31354;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#31867;&#20284;&#20110;Sobolev&#31354;&#38388;$H^m$&#12290;&#20854;&#20013;&#65292;&#20462;&#27491;&#21151;&#29575;&#21333;&#20301;&#28608;&#27963;&#20989;&#25968;&#22312;&#36825;&#20010;&#30740;&#31350;&#20013;&#29305;&#21035;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#23485;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#24615;&#36136;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#36873;&#25321;&#12290;&#20026;&#20102;&#20102;&#35299;&#36825;&#31181;&#24433;&#21709;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#19981;&#21516;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20043;&#38388;&#30340;&#23884;&#20837;&#12290;&#36890;&#36807;&#25552;&#20379;&#29992;&#20110;&#34920;&#31034;&#20989;&#25968;$f$&#30340;&#27979;&#37327;$\mu$&#19978;&#30340;&#25512;&#36827;&#26144;&#23556;&#26469;&#35777;&#26126;&#36825;&#20123;&#23884;&#20837;&#12290;&#19968;&#31181;&#29305;&#21035;&#24863;&#20852;&#36259;&#30340;&#28608;&#27963;&#20989;&#25968;&#26159;&#32473;&#23450;&#20026;$\operatorname{RePU}_s(x)=\max(0,x)^s$&#30340;&#20462;&#27491;&#21151;&#29575;&#21333;&#20301;($\operatorname{RePU}$)&#12290;&#23545;&#20110;&#35768;&#22810;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20197;&#20351;&#29992;&#20247;&#25152;&#21608;&#30693;&#30340;&#27888;&#21202;&#20313;&#39033;&#23450;&#29702;&#26500;&#36896;&#25512;&#36827;&#26144;&#23556;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#30456;&#20851;Barron&#31354;&#38388;&#23884;&#20837;&#21040;&#20855;&#26377;$\operatorname{RePU}$&#20316;&#20026;&#28608;&#27963;&#20989;&#25968;&#30340;Barron&#31354;&#38388;&#20013;&#12290;&#27492;&#22806;&#65292;&#19982;$\operatorname{RePU}_s$&#30456;&#20851;&#30340;Barron&#31354;&#38388;&#20855;&#26377;&#31867;&#20284;&#20110;Sobolev&#31354;&#38388;$H^m$&#30340;&#20998;&#23618;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
The approximation properties of infinitely wide shallow neural networks heavily depend on the choice of the activation function. To understand this influence, we study embeddings between Barron spaces with different activation functions. These embeddings are proven by providing push-forward maps on the measures $\mu$ used to represent functions $f$. An activation function of particular interest is the rectified power unit ($\operatorname{RePU}$) given by $\operatorname{RePU}_s(x)=\max(0,x)^s$. For many commonly used activation functions, the well-known Taylor remainder theorem can be used to construct a push-forward map, which allows us to prove the embedding of the associated Barron space into a Barron space with a $\operatorname{RePU}$ as activation function. Moreover, the Barron spaces associated with the $\operatorname{RePU}_s$ have a hierarchical structure similar to the Sobolev spaces $H^m$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24102;&#24635;&#25104;&#26412;&#38480;&#21046;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#65288;CBwK&#65289;&#65292;&#36890;&#36807;&#23545;&#26415;&#35821;&#36827;&#34892;&#37325;&#26032;&#32452;&#21512;&#65292;&#23545;CBwK&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#25903;&#25345;&#23567;&#20110;$T^{3/4}$&#30340;&#24635;&#25104;&#26412;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#23545;&#20598;&#31574;&#30053;&#23454;&#29616;&#20102;&#24179;&#31561;&#30340;&#25104;&#26412;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15807</link><description>&lt;p&gt;
&#24102;&#23567;&#24635;&#25104;&#26412;&#38480;&#21046;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#19982;&#32972;&#21253;&#38382;&#39064;&#30340;&#30456;&#20851;&#24615;&#65292;&#21450;&#20854;&#23545;&#20844;&#24179;&#24615;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness. (arXiv:2305.15807v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24102;&#24635;&#25104;&#26412;&#38480;&#21046;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#65288;CBwK&#65289;&#65292;&#36890;&#36807;&#23545;&#26415;&#35821;&#36827;&#34892;&#37325;&#26032;&#32452;&#21512;&#65292;&#23545;CBwK&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#25903;&#25345;&#23567;&#20110;$T^{3/4}$&#30340;&#24635;&#25104;&#26412;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#23545;&#20598;&#31574;&#30053;&#23454;&#29616;&#20102;&#24179;&#31561;&#30340;&#25104;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#24102;&#26377;&#32972;&#21253;&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#65288;CBwK&#65289;&#65292;&#27599;&#19968;&#36718;&#33719;&#24471;&#19968;&#20010;&#26631;&#37327;&#22870;&#21169;&#21644;&#19968;&#20010;&#21521;&#37327;&#20540;&#30340;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#32047;&#35745;&#30340;&#22870;&#21169;&#65292;&#24182;&#30830;&#20445;&#32047;&#35745;&#25104;&#26412;&#20302;&#20110;&#26576;&#20010;&#39044;&#23450;&#30340;&#25104;&#26412;&#38480;&#21046;&#12290;&#25105;&#20204;&#20551;&#35774;&#29615;&#22659;&#26469;&#33258;&#19968;&#20010;&#36830;&#32493;&#38598;&#21512;&#65292;&#25104;&#26412;&#21487;&#20197;&#24102;&#31526;&#21495;&#65292;&#24182;&#19988;&#26410;&#30693;&#30340;&#26399;&#26395;&#22870;&#21169;&#21644;&#25104;&#26412;&#20989;&#25968;&#21487;&#20197;&#34987;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#20856;&#22411;&#20551;&#35774;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36804;&#20170;&#20026;&#27490;&#24635;&#25104;&#26412;&#32422;&#26463;&#33267;&#23569;&#35201;&#20026;$T^{3/4}$&#65292;&#20854;&#20013;$T$&#26159;&#36718;&#25968;&#65292;&#24182;&#19988;&#29978;&#33267;&#36890;&#24120;&#34987;&#20551;&#23450;&#20026;&#19982;$T$&#32447;&#24615;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21463;&#21040;&#40723;&#33310;&#65292;&#20351;&#29992;CBwK&#26469;&#24378;&#21046;&#23454;&#26045;&#23454;&#29616;&#32452;&#20043;&#38388;&#24179;&#22343;&#25104;&#26412;&#24179;&#31561;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#65306;&#19982;&#30456;&#24212;&#25104;&#26412;&#32422;&#26463;&#30456;&#20851;&#30340;&#39044;&#31639;&#24212;&#23613;&#21487;&#33021;&#25509;&#36817;&#20110;&#38454;&#25968;&#20026;$\sqrt{T}$&#32423;&#21035;&#30340;&#33258;&#28982;&#20559;&#24046;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#20598;&#31574;&#30053;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider contextual bandit problems with knapsacks [CBwK], a problem where at each round, a scalar reward is obtained and vector-valued costs are suffered. The learner aims to maximize the cumulative rewards while ensuring that the cumulative costs are lower than some predetermined cost constraints. We assume that contexts come from a continuous set, that costs can be signed, and that the expected reward and cost functions, while unknown, may be uniformly estimated -- a typical assumption in the literature. In this setting, total cost constraints had so far to be at least of order $T^{3/4}$, where $T$ is the number of rounds, and were even typically assumed to depend linearly on $T$. We are however motivated to use CBwK to impose a fairness constraint of equalized average costs between groups: the budget associated with the corresponding cost constraints should be as close as possible to the natural deviations, of order $\sqrt{T}$. To that end, we introduce a dual strategy based on 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;</title><link>http://arxiv.org/abs/2305.15786</link><description>&lt;p&gt;
&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#30340;&#29702;&#35770;&#20445;&#35777;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Theoretical Guarantees of Learning Ensembling Strategies with Applications to Time Series Forecasting. (arXiv:2305.15786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#38598;&#21512;&#31574;&#30053;&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#35777;&#26126;&#20102;&#22312;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#20013;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#26368;&#20248;&#21472;&#21152;&#27867;&#21270;&#19982;&#26368;&#20248;&#35299;&#24615;&#33021;&#30456;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#21512;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#29992;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#20943;&#23569;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#38024;&#23545;&#40657;&#30418;&#22522;&#23398;&#20064;&#22120;&#30340;&#22823;&#22810;&#25968;&#38598;&#21512;&#26041;&#27861;&#37117;&#23646;&#20110;&#8220;&#21472;&#21152;&#27867;&#21270;&#8221;&#33539;&#30068;&#65292;&#21363;&#35757;&#32451;&#19968;&#20010;&#25509;&#21463;&#22522;&#23398;&#20064;&#22120;&#25512;&#29702;&#20316;&#20026;&#36755;&#20837;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#34429;&#28982;&#21472;&#21152;&#27867;&#21270;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#30693;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#36873;&#25321;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#24615;&#33021;&#30340;&#8220;&#26377;&#38480;&#25110;&#26377;&#38480;&#32500;&#8221;&#21472;&#21152;&#27867;&#21270;&#20013;&#30340;&#26368;&#20339;&#21472;&#21152;&#27867;&#21270;&#24182;&#19981;&#27604;&#26368;&#20248;&#35299;&#34920;&#29616;&#8220;&#24046;&#24471;&#22810;&#8221;&#12290;&#36825;&#19968;&#32467;&#26524;&#21152;&#24378;&#21644;&#22823;&#22823;&#25193;&#23637;&#20102;Van der Laan&#31561;&#20154;&#65288;2007&#24180;&#65289;&#30340;&#32467;&#26524;&#12290;&#21463;&#21040;&#29702;&#35770;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#27010;&#29575;&#39044;&#27979;&#30340;&#32972;&#26223;&#19979;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#19981;&#21516;&#25935;&#24863;&#24615;&#30340;&#21472;&#21152;&#27867;&#21270;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling is among the most popular tools in machine learning (ML) due to its effectiveness in minimizing variance and thus improving generalization. Most ensembling methods for black-box base learners fall under the umbrella of "stacked generalization," namely training an ML algorithm that takes the inferences from the base learners as input. While stacking has been widely applied in practice, its theoretical properties are poorly understood. In this paper, we prove a novel result, showing that choosing the best stacked generalization from a (finite or finite-dimensional) family of stacked generalizations based on cross-validated performance does not perform "much worse" than the oracle best. Our result strengthens and significantly extends the results in Van der Laan et al. (2007). Inspired by the theoretical analysis, we further propose a particular family of stacked generalizations in the context of probabilistic forecasting, each one with a different sensitivity for how much the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.15759</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15759
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;(DMs)&#34987;&#24191;&#27867;&#29992;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30452;&#25509;&#22312;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20013;&#36816;&#34892;&#65292;DMs&#30340;&#20248;&#21270;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#38656;&#35201;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#12290;&#36825;&#23548;&#33268;&#30001;&#20110;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#32452;&#21512;&#24615;&#23646;&#24615;&#65292;&#22823;&#37327;&#22122;&#38899;&#27880;&#20837;&#21040;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#12290;LDMs&#20351;&#29992;&#24378;&#22823;&#30340;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20943;&#23569;&#21040;&#26356;&#20302;&#32500;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#20351;&#35757;&#32451;DMs&#26356;&#21152;&#39640;&#25928;&#21644;&#24555;&#36895;&#12290;&#19982;[Ghalebikesabi&#31561;&#20154;&#65292;2023]&#39044;&#20808;&#29992;&#20844;&#20849;&#25968;&#25454;&#39044;&#35757;&#32451;DMs&#65292;&#28982;&#21518;&#20877;&#29992;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#19981;&#21516;&#65292;&#25105;&#20204;&#20165;&#24494;&#35843;LDMs&#20013;&#19981;&#21516;&#23618;&#30340;&#27880;&#24847;&#21147;&#27169;&#22359;&#20197;&#33719;&#24471;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#65292;&#30456;&#23545;&#20110;&#25972;&#20010;DM&#24494;&#35843;&#65292;&#21487;&#20943;&#23569;&#22823;&#32422;96%&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#12290;&#20174;&#23548;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#25910;&#32553;&#29575;&#21644;&#24320;&#21457;&#30340;&#25130;&#26029;&#39640;&#26031;&#36817;&#20284;&#20004;&#20010;&#26041;&#38754;&#26469;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#20197;&#35299;&#20915;&#20043;&#21069;&#30340;&#20808;&#39564;&#31232;&#30095;&#24615;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15754</link><description>&lt;p&gt;
&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Analysis for Over-parameterized Linear Model without Sparsity. (arXiv:2305.15754v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15754
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#20808;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#12290;&#20174;&#23548;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#25910;&#32553;&#29575;&#21644;&#24320;&#21457;&#30340;&#25130;&#26029;&#39640;&#26031;&#36817;&#20284;&#20004;&#20010;&#26041;&#38754;&#26469;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21487;&#20197;&#35299;&#20915;&#20043;&#21069;&#30340;&#20808;&#39564;&#31232;&#30095;&#24615;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#20013;&#65292;&#21457;&#23637;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#21253;&#25324;&#35768;&#22810;&#20808;&#39564;&#20998;&#24067;&#65292;&#23427;&#20204;&#23548;&#33268;&#20272;&#35745;&#21442;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20808;&#39564;&#22312;&#22788;&#29702;&#25968;&#25454;&#30340;&#35889;&#29305;&#24449;&#21521;&#37327;&#32467;&#26500;&#26041;&#38754;&#26377;&#23616;&#38480;&#24615;&#65292;&#22240;&#27492;&#19981;&#36866;&#29992;&#20110;&#20998;&#26512;&#26368;&#36817;&#21457;&#23637;&#30340;&#19981;&#20551;&#35774;&#31232;&#30095;&#24615;&#30340;&#39640;&#32500;&#32447;&#24615;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#19968;&#20010;&#20381;&#36182;&#20110;&#25968;&#25454;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#20808;&#39564;&#65292;&#20294;&#19981;&#20250;&#24341;&#36215;&#21442;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23548;&#20986;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#25910;&#32553;&#29575;&#65292;&#24182;&#24320;&#21457;&#20102;&#21518;&#39564;&#20998;&#24067;&#30340;&#25130;&#26029;&#39640;&#26031;&#36817;&#20284;&#12290;&#21069;&#32773;&#35777;&#26126;&#20102;&#21518;&#39564;&#20272;&#35745;&#30340;&#25928;&#29575;&#65292;&#32780;&#21518;&#32773;&#21017;&#20351;&#29992;Bernstein-von Mises&#31867;&#22411;&#26041;&#27861;&#26469;&#37327;&#21270;&#21442;&#25968;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#20219;&#20309;&#33021;&#22815;&#22788;&#29702;&#35889;&#29305;&#24449;&#21521;&#37327;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#37117;&#21487;&#20197;&#29992;&#20110;&#38750;&#31232;&#30095;&#36229;&#21442;&#25968;&#32447;&#24615;&#27169;&#22411;&#20998;&#26512;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20808;&#21069;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In high-dimensional Bayesian statistics, several methods have been developed, including many prior distributions that lead to the sparsity of estimated parameters. However, such priors have limitations in handling the spectral eigenvector structure of data, and as a result, they are ill-suited for analyzing over-parameterized models (high-dimensional linear models that do not assume sparsity) that have been developed in recent years. This paper introduces a Bayesian approach that uses a prior dependent on the eigenvectors of data covariance matrices, but does not induce the sparsity of parameters. We also provide contraction rates of derived posterior distributions and develop a truncated Gaussian approximation of the posterior distribution. The former demonstrates the efficiency of posterior estimation, while the latter enables quantification of parameter uncertainty using a Bernstein-von Mises-type approach. These results indicate that any Bayesian method that can handle the spectrum
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20351;&#29992;&#28595;&#22823;&#21033;&#20122;&#26089;&#26399;&#21457;&#23637;&#26222;&#26597;&#25968;&#25454;&#65292;&#30740;&#31350;&#20102;&#20986;&#24109;&#24188;&#20799;&#22253;&#19982;&#20799;&#31461;&#21457;&#23637;&#33030;&#24369;&#24615;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22312;&#20986;&#24109;&#24188;&#20799;&#22253;&#27604;&#20363;&#36739;&#39640;&#30340;&#22320;&#21306;&#65292;&#20799;&#31461;&#33267;&#23569;&#23384;&#22312;&#19968;&#20010;&#21457;&#23637;&#24615;&#33030;&#24369;&#24615;&#30340;&#27604;&#20363;&#36739;&#20302;&#12290;&#20351;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#30740;&#31350;&#20154;&#21592;&#30830;&#23450;&#20102;&#26118;&#22763;&#20848;&#30465;&#20869;&#30340;&#19977;&#20010;&#19981;&#21516;&#32676;&#38598;&#65292;&#27599;&#20010;&#32676;&#38598;&#29305;&#28857;&#26159;&#19981;&#21516;&#30340;&#31038;&#20250;&#20154;&#21475;&#32479;&#35745;&#21464;&#37327;&#24433;&#21709;&#24188;&#20799;&#22253;&#20986;&#24109;&#19982;&#21457;&#23637;&#33030;&#24369;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.15746</link><description>&lt;p&gt;
&#35780;&#20272;&#28595;&#22823;&#21033;&#20122;&#26118;&#22763;&#20848;&#30465;&#20986;&#24109;&#24188;&#20799;&#22253;&#19982;&#20799;&#31461;&#21457;&#23637;&#33030;&#24369;&#24615;&#30340;&#31354;&#38388;&#32467;&#26500;&#65288;arXiv:2305.15746v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
Assessing the Spatial Structure of the Association between Attendance at Preschool and Childrens Developmental Vulnerabilities in Queensland Australia. (arXiv:2305.15746v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15746
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20351;&#29992;&#28595;&#22823;&#21033;&#20122;&#26089;&#26399;&#21457;&#23637;&#26222;&#26597;&#25968;&#25454;&#65292;&#30740;&#31350;&#20102;&#20986;&#24109;&#24188;&#20799;&#22253;&#19982;&#20799;&#31461;&#21457;&#23637;&#33030;&#24369;&#24615;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#22312;&#20986;&#24109;&#24188;&#20799;&#22253;&#27604;&#20363;&#36739;&#39640;&#30340;&#22320;&#21306;&#65292;&#20799;&#31461;&#33267;&#23569;&#23384;&#22312;&#19968;&#20010;&#21457;&#23637;&#24615;&#33030;&#24369;&#24615;&#30340;&#27604;&#20363;&#36739;&#20302;&#12290;&#20351;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#30740;&#31350;&#20154;&#21592;&#30830;&#23450;&#20102;&#26118;&#22763;&#20848;&#30465;&#20869;&#30340;&#19977;&#20010;&#19981;&#21516;&#32676;&#38598;&#65292;&#27599;&#20010;&#32676;&#38598;&#29305;&#28857;&#26159;&#19981;&#21516;&#30340;&#31038;&#20250;&#20154;&#21475;&#32479;&#35745;&#21464;&#37327;&#24433;&#21709;&#24188;&#20799;&#22253;&#20986;&#24109;&#19982;&#21457;&#23637;&#33030;&#24369;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20986;&#24109;&#24188;&#20799;&#22253;&#65288;&#20840;&#26085;&#21046;&#23398;&#26657;&#21069;&#19968;&#24180;&#65289;&#23545;&#20799;&#31461;&#22312;&#20854;&#31532;&#19968;&#24180;&#23398;&#26657;&#26399;&#38388;&#21457;&#23637;&#30340;&#24433;&#21709;&#12290;&#20351;&#29992;&#28595;&#22823;&#21033;&#20122;&#26089;&#26399;&#21457;&#23637;&#26222;&#26597;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#21457;&#29616;&#20986;&#24109;&#24188;&#20799;&#22253;&#27604;&#20363;&#36739;&#39640;&#30340;&#22320;&#21306;&#24448;&#24448;&#26377;&#36739;&#20302;&#27604;&#20363;&#30340;&#20799;&#31461;&#33267;&#23569;&#23384;&#22312;&#19968;&#20010;&#21457;&#23637;&#24615;&#33030;&#24369;&#24615;&#12290;&#21457;&#23637;&#24615;&#33030;&#24369;&#24615;&#21253;&#25324;&#19981;&#33021;&#24212;&#23545;&#25972;&#20010;&#23398;&#26657;&#26085;&#65288;&#30130;&#24811;&#12289;&#39269;&#39295;&#12289;&#31934;&#21147;&#20302;&#19979;&#65289;&#12289;&#19981;&#33021;&#19982;&#20182;&#20154;&#30456;&#22788;&#25110;&#32773;&#20855;&#26377;&#25915;&#20987;&#24615;&#65292;&#20197;&#21450;&#38405;&#35835;/&#20889;&#20316;&#25110;&#25968;&#23398;&#26041;&#38754;&#23384;&#22312;&#38382;&#39064;&#12290;&#36825;&#20123;&#21457;&#29616;&#24403;&#28982;&#20250;&#22240;&#22320;&#21306;&#32780;&#24322;&#12290;&#20351;&#29992;&#25968;&#25454;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#65292;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#35782;&#21035;&#20986;&#26118;&#22763;&#20848;&#30465;&#20869;&#30340;&#19977;&#20010;&#19981;&#21516;&#30340;&#32676;&#38598;&#65292;&#27599;&#20010;&#32676;&#38598;&#30340;&#29305;&#28857;&#26159;&#19981;&#21516;&#30340;&#31038;&#20250;&#20154;&#21475;&#32479;&#35745;&#21464;&#37327;&#24433;&#21709;&#24188;&#20799;&#22253;&#20986;&#24109;&#19982;&#21457;&#23637;&#33030;&#24369;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#36825;&#20123;&#20998;&#26512;&#26377;&#21161;&#20110;&#29702;&#35299;&#39640;&#33030;&#24369;&#24615;&#22320;&#21306;&#21644;&#35813;&#20998;&#26512;&#25552;&#20379;&#20102;&#26377;&#20851;&#22914;&#20309;&#22312;&#36825;&#20123;&#21306;&#22495;&#24212;&#29992;&#36164;&#28304;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The research explores the influence of preschool attendance (one year before full-time school) on the development of children during their first year of school. Using data collected by the Australian Early Development Census, the findings show that areas with high proportions of preschool attendance tended to have lower proportions of children with at least one developmental vulnerability. Developmental vulnerablities include not being able to cope with the school day (tired, hungry, low energy), unable to get along with others or aggressive behaviour, trouble with reading/writing or numbers. These findings, of course, vary by region. Using Data Analysis and Machine Learning, the researchers were able to identify three distinct clusters within Queensland, each characterised by different socio-demographic variables influencing the relationship between preschool attendance and developmental vulnerability. These analyses contribute to understanding regions with high vulnerability and the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2305.15742</link><description>&lt;p&gt;
&#26102;&#38388;&#21464;&#21270;&#22788;&#29702;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Generative Models for Time-Varying Treatments. (arXiv:2305.15742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26102;&#38388;&#21464;&#37327;&#22788;&#29702;&#24773;&#20917;&#19979;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#22815;&#25429;&#25417;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25512;&#26029;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#65292;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#24179;&#22343;&#22240;&#26524;&#25928;&#24212;&#26159;&#27979;&#35797;&#26032;&#30103;&#27861;&#30340;&#24120;&#29992;&#20570;&#27861;&#12290;&#28982;&#32780;&#65292;&#24179;&#22343;&#25928;&#24212;&#20250;&#25513;&#30422;&#21453;&#20107;&#23454;&#20998;&#24067;&#20013;&#37325;&#35201;&#30340;&#20010;&#20307;&#29305;&#24449;&#65292;&#21487;&#33021;&#20250;&#24341;&#36215;&#23433;&#20840;&#12289;&#20844;&#24179;&#21644;&#36947;&#24503;&#26041;&#38754;&#30340;&#25285;&#24551;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26102;&#38388;&#35774;&#32622;&#20013;&#26356;&#21152;&#20005;&#37325;&#65292;&#22240;&#20026;&#22788;&#29702;&#26159;&#26102;&#24207;&#30340;&#21644;&#26102;&#21464;&#30340;&#65292;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#20135;&#29983;&#20102;&#38169;&#32508;&#22797;&#26434;&#30340;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#20197;&#25429;&#33719;&#25972;&#20010;&#21453;&#20107;&#23454;&#20998;&#24067;&#65292;&#20801;&#35768;&#23545;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#26576;&#20123;&#32479;&#35745;&#37327;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#36825;&#20351;&#24471;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#21644;&#20844;&#20849;&#25919;&#31574;&#21046;&#23450;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#36890;&#36807;&#36793;&#38469;&#32467;&#26500;&#27169;&#22411;&#35880;&#24910;&#22320;&#35299;&#20915;&#20102;&#35266;&#23519;&#25968;&#25454;&#21644;&#30446;&#26631;&#21453;&#20107;&#23454;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#24067;&#19981;&#21305;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating average causal effects is a common practice to test new treatments. However, the average effect ''masks'' important individual characteristics in the counterfactual distribution, which may lead to safety, fairness, and ethical concerns. This issue is exacerbated in the temporal setting, where the treatment is sequential and time-varying, leading to an intricate influence on the counterfactual distribution. In this paper, we propose a novel conditional generative modeling approach to capture the whole counterfactual distribution, allowing efficient inference on certain statistics of the counterfactual distribution. This makes the proposed approach particularly suitable for healthcare and public policy making. Our generative modeling approach carefully tackles the distribution mismatch in the observed data and the targeted counterfactual distribution via a marginal structural model. Our method outperforms state-of-the-art baselines on both synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#20248;&#20110;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15703</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#30340;&#22909;&#22788;&#65306;&#23567;&#25439;&#22833;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning. (arXiv:2305.15703v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15703
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#20998;&#24067;&#24335;&#26041;&#27861;&#20248;&#20110;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#26524;&#65292;&#20294;&#20854;&#20309;&#26102;&#20309;&#22320;&#26377;&#30410;&#30340;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#22238;&#31572;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#36890;&#36807;&#23567;&#25439;&#22833;&#36793;&#30028;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#24067;&#24335;RL&#22909;&#22788;&#30340;&#19968;&#20010;&#35299;&#37322;&#65292;&#35813;&#36793;&#30028;&#19982;&#23454;&#20363;&#30456;&#20851;&#30340;&#26368;&#20248;&#25104;&#26412;&#25104;&#27604;&#20363;&#12290;&#22914;&#26524;&#26368;&#20248;&#25104;&#26412;&#24456;&#23567;&#65292;&#25105;&#20204;&#30340;&#36793;&#30028;&#20250;&#27604;&#38750;&#20998;&#24067;&#24335;&#26041;&#27861;&#26356;&#24378;&#12290;&#20316;&#20026;&#28909;&#36523;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23398;&#20064;&#25104;&#26412;&#20998;&#24067;&#20250;&#22312;&#24773;&#22659;&#23637;&#24320;&#65288;CB&#65289;&#20013;&#23548;&#33268;&#23567;&#25439;&#22833;&#21518;&#24724;&#36793;&#30028;&#65292;&#25105;&#20204;&#21457;&#29616;&#20998;&#24067;&#24335;CB&#22312;&#19977;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#19978;&#27604;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#22312;&#23454;&#35777;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;&#23545;&#20110;&#22312;&#32447;RL&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#29256;&#26412;&#31354;&#38388;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#22312;&#34920;&#26684;MDP&#20013;&#23454;&#29616;&#20102;&#23567;&#25439;&#22833;&#21518;&#24724;&#65292;&#21516;&#26102;&#22312;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#20139;&#26377;&#23567;&#25439;&#22833;PAC&#36793;&#30028;&#12290;&#20197;&#31867;&#20284;&#30340;&#35265;&#35299;&#20026;&#22522;&#30784;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#31163;&#32447;RL&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
While distributional reinforcement learning (RL) has demonstrated empirical success, the question of when and why it is beneficial has remained unanswered. In this work, we provide one explanation for the benefits of distributional RL through the lens of small-loss bounds, which scale with the instance-dependent optimal cost. If the optimal cost is small, our bounds are stronger than those from non-distributional approaches. As warmup, we show that learning the cost distribution leads to small-loss regret bounds in contextual bandits (CB), and we find that distributional CB empirically outperforms the state-of-the-art on three challenging tasks. For online RL, we propose a distributional version-space algorithm that constructs confidence sets using maximum likelihood estimation, and we prove that it achieves small-loss regret in the tabular MDPs and enjoys small-loss PAC bounds in latent variable models. Building on similar insights, we propose a distributional offline RL algorithm bas
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#20171;&#32461;&#20102;&#20989;&#25968;ANOVA&#26694;&#26550;&#21450;&#20854;&#22312;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#36824;&#27010;&#36848;&#20102;&#20004;&#31181;&#26032;&#24320;&#21457;&#30340;&#21487;&#35299;&#37322;&#24615;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#22522;&#20110;FANOVA&#21644;GAM&#30340;&#21487;&#35299;&#37322;&#30340;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65288;FANGAM-EBM&#65289;&#12290;</title><link>http://arxiv.org/abs/2305.15670</link><description>&lt;p&gt;
&#22522;&#20110;&#20989;&#25968;ANOVA&#26694;&#26550;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;: &#31639;&#27861;&#21450;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Interpretable Machine Learning based on Functional ANOVA Framework: Algorithms and Comparisons. (arXiv:2305.15670v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15670
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#35299;&#37322;&#24615;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#20171;&#32461;&#20102;&#20989;&#25968;ANOVA&#26694;&#26550;&#21450;&#20854;&#22312;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#36824;&#27010;&#36848;&#20102;&#20004;&#31181;&#26032;&#24320;&#21457;&#30340;&#21487;&#35299;&#37322;&#24615;&#25216;&#26415;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#22522;&#20110;FANOVA&#21644;GAM&#30340;&#21487;&#35299;&#37322;&#30340;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65288;FANGAM-EBM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#26089;&#26399;&#65292;&#37325;&#28857;&#26159;&#24320;&#21457;&#22797;&#26434;&#31639;&#27861;&#20197;&#33719;&#24471;&#26368;&#20339;&#39044;&#27979;&#24615;&#33021;&#12290;&#20026;&#20102;&#29702;&#35299;&#21644;&#35299;&#37322;&#27169;&#22411;&#32467;&#26524;&#65292;&#24517;&#39035;&#20381;&#38752;&#20107;&#21518;&#35299;&#37322;&#25216;&#26415;&#65292;&#36825;&#20123;&#25216;&#26415;&#24050;&#32463;&#34987;&#35777;&#26126;&#23384;&#22312;&#19968;&#23450;&#38480;&#21046;&#12290;&#26368;&#36817;&#65292;&#38543;&#30528;&#35748;&#35782;&#21040;&#21487;&#35299;&#37322;&#24615;&#21516;&#26679;&#37325;&#35201;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#22987;&#20570;&#20986;&#22949;&#21327;&#26469;&#24320;&#21457;&#22266;&#26377;&#21487;&#35299;&#37322;&#24615;&#30340;&#31639;&#27861;&#32780;&#19981;&#26159;&#36861;&#27714;&#26497;&#33268;&#39044;&#27979;&#34920;&#29616;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#21457;&#25496;&#20102;&#20989;&#25968;ANOVA&#20302;&#38454;&#27169;&#22411;&#30340;&#20351;&#29992;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#32479;&#35745;&#25991;&#29486;&#20013;&#24050;&#30693;&#12290;&#26412;&#25991;&#39318;&#20808;&#25551;&#36848;&#20102;&#20107;&#21518;&#21487;&#35299;&#37322;&#24615;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;&#20027;&#25928;&#24212;&#21644;&#20108;&#38454;&#30456;&#20114;&#20316;&#29992;&#12290;&#25509;&#19979;&#26469;&#65292;&#27010;&#36848;&#20102;&#20004;&#31181;&#26032;&#24320;&#21457;&#30340;&#25216;&#26415;:&#21487;&#35299;&#37322;&#30340;&#22686;&#24378;&#26426;&#22120;&#65288;EBM&#65289;&#65288;Lou&#31561;&#20154;&#65292;2013&#65289;&#21644;GAMI-Net&#65288;Yang&#31561;&#20154;&#65292;2021b)&#12290;&#26368;&#21518;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#65292;&#21363;&#22522;&#20110;FANOVA&#21644;GAM&#30340;&#21487;&#35299;&#37322;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65288;FANGAM-EBM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the early days of machine learning (ML), the emphasis was on developing complex algorithms to achieve best predictive performance. To understand and explain the model results, one had to rely on post hoc explainability techniques, which are known to have limitations. Recently, with the recognition that interpretability is just as important, researchers are compromising on small increases in predictive performance to develop algorithms that are inherently interpretable. While doing so, the ML community has rediscovered the use of low-order functional ANOVA (fANOVA) models that have been known in the statistical literature for some time. This paper starts with a description of challenges with post hoc explainability and reviews the fANOVA framework with a focus on main effects and second-order interactions. This is followed by an overview of two recently developed techniques: Explainable Boosting Machines or EBM (Lou et al., 2013) and GAMI-Net (Yang et al., 2021b). The paper proposes 
&lt;/p&gt;</description></item><item><title>FeDualEx&#26159;&#31532;&#19968;&#31181;&#22312;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#19979;&#21516;&#26102;&#22788;&#29702;&#38797;&#28857;&#20248;&#21270;&#21644;&#22797;&#21512;&#30446;&#26631;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15643</link><description>&lt;p&gt;
&#32852;&#37030;&#22797;&#21512;&#38797;&#28857;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Federated Composite Saddle Point Optimization. (arXiv:2305.15643v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15643
&lt;/p&gt;
&lt;p&gt;
FeDualEx&#26159;&#31532;&#19968;&#31181;&#22312;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#19979;&#21516;&#26102;&#22788;&#29702;&#38797;&#28857;&#20248;&#21270;&#21644;&#22797;&#21512;&#30446;&#26631;&#30340;&#26041;&#27861;&#65292;&#20855;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#65292;&#35299;&#20915;&#38797;&#28857;&#38382;&#39064;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#12290;&#28982;&#32780;&#29616;&#26377;&#30340;&#26041;&#27861;&#20027;&#35201;&#38024;&#23545;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#24179;&#28369;&#26080;&#32422;&#26463;&#30446;&#26631;&#20989;&#25968;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#24448;&#24448;&#28041;&#21450;&#32422;&#26463;&#25110;&#38750;&#24179;&#28369;&#27491;&#21017;&#21270;&#65292;&#36825;&#23548;&#33268;&#38656;&#35201;&#36827;&#34892;&#22797;&#21512;&#20248;&#21270;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#23545;&#20598;&#22806;&#25512;&#65288;FeDualEx&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#39069;&#22806;&#27493;&#39588;&#30340;&#21407;&#22987;&#8212;&#23545;&#20598;&#31639;&#27861;&#65292;&#26159;&#31532;&#19968;&#31181;&#22312;&#32852;&#37030;&#23398;&#20064;&#33539;&#24335;&#19979;&#21253;&#25324;&#20102;&#38797;&#28857;&#20248;&#21270;&#21644;&#22797;&#21512;&#30446;&#26631;&#30340;&#26041;&#27861;&#12290;&#25910;&#25947;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#37117;&#35777;&#26126;&#20102; FeDualEx &#22312;&#36825;&#20123;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#19979;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#23545;&#20110; FeDualEx &#30340;&#39034;&#24207;&#29256;&#26412;&#65292;&#25105;&#20204;&#20063;&#20026;&#38543;&#26426;&#22797;&#21512;&#38797;&#28857;&#35774;&#32622;&#25552;&#20379;&#20102;&#36895;&#29575;&#65292;&#36825;&#26159;&#25454;&#25105;&#20204;&#25152;&#30693;&#20043;&#21069;&#30340;&#25991;&#29486;&#20013;&#27809;&#26377;&#25214;&#21040;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) approaches for saddle point problems (SPP) have recently gained in popularity due to the critical role they play in machine learning (ML). Existing works mostly target smooth unconstrained objectives in Euclidean space, whereas ML problems often involve constraints or non-smooth regularization, which results in a need for composite optimization. Addressing these issues, we propose Federated Dual Extrapolation (FeDualEx), an extra-step primal-dual algorithm, which is the first of its kind that encompasses both saddle point optimization and composite objectives under the FL paradigm. Both the convergence analysis and the empirical evaluation demonstrate the effectiveness of FeDualEx in these challenging settings. In addition, even for the sequential version of FeDualEx, we provide rates for the stochastic composite saddle point setting which, to our knowledge, are not found in prior literature.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15612</link><description>&lt;p&gt;
&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning. (arXiv:2305.15612v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15612
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#20195;&#26367;&#23494;&#24230;&#27604;&#26469;&#20272;&#35745;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20004;&#32452;&#25968;&#25454;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#36991;&#20813;&#20102;&#20998;&#31867;&#22120;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#31185;&#23398;&#19982;&#24037;&#31243;&#30340;&#22810;&#20010;&#39046;&#22495;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#22240;&#20026;&#23427;&#33021;&#39640;&#25928;&#22320;&#25214;&#21040;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#36890;&#24120;&#65292;&#19968;&#20010;&#27010;&#29575;&#22238;&#24402;&#27169;&#22411;&#65292;&#22914;&#39640;&#26031;&#36807;&#31243;&#12289;&#38543;&#26426;&#26862;&#26519;&#21644;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#34987;&#24191;&#27867;&#29992;&#20316;&#26367;&#20195;&#20989;&#25968;&#65292;&#29992;&#20110;&#27169;&#25311;&#22312;&#32473;&#23450;&#36755;&#20837;&#21644;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#20989;&#25968;&#35780;&#20272;&#30340;&#26174;&#24335;&#20998;&#24067;&#12290;&#38500;&#20102;&#22522;&#20110;&#27010;&#29575;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#22522;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#24050;&#34987;&#25552;&#20986;&#26469;&#20272;&#35745;&#30456;&#23545;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#30456;&#23545;&#25509;&#36817;&#21644;&#30456;&#23545;&#36828;&#31163;&#30340;&#20004;&#32452;&#23494;&#24230;&#27604;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#21457;&#23637;&#36825;&#19968;&#30740;&#31350;&#65292;&#21487;&#20197;&#20351;&#29992;&#30417;&#30563;&#20998;&#31867;&#22120;&#26469;&#20272;&#35745;&#36825;&#20004;&#32452;&#30340;&#31867;&#21035;&#27010;&#29575;&#65292;&#32780;&#19981;&#26159;&#23494;&#24230;&#27604;&#12290;&#28982;&#32780;&#65292;&#27492;&#31574;&#30053;&#20013;&#20351;&#29992;&#30340;&#30417;&#30563;&#20998;&#31867;&#22120;&#20542;&#21521;&#20110;&#23545;&#20840;&#23616;&#35299;&#20915;&#26041;&#26696;&#36807;&#20110;&#33258;&#20449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of finding a global optimum of an expensive-to-evaluate black-box function efficiently. In general, a probabilistic regression model, e.g., Gaussian processes, random forests, and Bayesian neural networks, is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based Bayesian optimization, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, a supervised classifier can be employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy tend to be overconfident for a global solution candid
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#23454;&#29616;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;KL&#25955;&#24230;&#38477;&#20302;&#30340;&#26032;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#65292;&#20855;&#26377;&#27604;SVGD&#26356;&#31616;&#21333;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#23545;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20063;&#26377;&#20248;&#21270;&#65292;&#25552;&#21319;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.15577</link><description>&lt;p&gt;
&#37319;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#30340;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Variational Gradient Descent using Local Linear Models. (arXiv:2305.15577v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#23454;&#29616;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;KL&#25955;&#24230;&#38477;&#20302;&#30340;&#26032;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#65292;&#20855;&#26377;&#27604;SVGD&#26356;&#31616;&#21333;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#23545;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20063;&#26377;&#20248;&#21270;&#65292;&#25552;&#21319;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) &#33021;&#22815;&#27839;&#30528;&#36712;&#36857;&#20256;&#36755;&#31890;&#23376;&#65292;&#20174;&#32780;&#20943;&#23569;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#65292;&#20294;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#26469;&#35745;&#31639;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SVGD&#35270;&#35282;&#65292;&#23558;&#20854;&#35270;&#20026;&#21453;&#21521;KL&#26799;&#24230;&#27969;&#30340;&#23616;&#37096;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#35270;&#35282;&#21551;&#21457;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#26469;&#23454;&#29616;&#30456;&#21516;&#30446;&#30340;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#36825;&#20123;&#25552;&#35758;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#20165;&#20351;&#29992;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;&#30340;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#65292;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#35758;&#30340;&#21464;&#20998;&#26799;&#24230;&#20272;&#35745;&#22120;&#21033;&#29992;&#20102;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#20272;&#35745;&#20559;&#24046;&#19982;SVGD&#30456;&#24403;&#30340;&#25928;&#26524;&#30340;&#21516;&#26102;&#20855;&#26377;&#35745;&#31639;&#31616;&#20415;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#39640;&#32500;&#26799;&#24230;&#27969;&#30340;&#20272;&#35745;&#21487;&#20197;&#36716;&#21270;&#20026;&#19968;&#20010;&#20302;&#32500;&#20272;&#35745;&#38382;&#39064;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#22909;&#30340;&#20272;&#35745;&#31934;&#24230;&#12290;&#25105;&#20204;&#23545;&#25552;&#35758;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) can transport particles along trajectories that reduce the KL divergence between the target and particle distribution but requires the target score function to compute the update. We introduce a new perspective on SVGD that views it as a local estimator of the reversed KL gradient flow. This perspective inspires us to propose new estimators that use local linear models to achieve the same purpose. The proposed estimators can be computed using only samples from the target and particle distribution without needing the target score function. Our proposed variational gradient estimators utilize local linear models, resulting in computational simplicity while maintaining effectiveness comparable to SVGD in terms of estimation biases. Additionally, we demonstrate that under a mild assumption, the estimation of high-dimensional gradient flow can be translated into a lower-dimensional estimation problem, leading to improved estimation accuracy. We vali
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#31639;&#23376;&#30340;&#31070;&#32463;&#38543;&#26426;&#36807;&#31243;MNPs&#65292;&#36890;&#36807;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#22534;&#21472;&#31070;&#32463;&#21442;&#25968;&#21270;&#30340;&#31639;&#23376;&#26500;&#24314;&#65292;&#19981;&#24433;&#21709;&#19968;&#33268;&#24615;&#25110;&#28155;&#21152;&#38480;&#21046;&#65292;&#25552;&#20379;&#20102;&#26356;&#22823;&#30340;&#28789;&#27963;&#24615;&#21644;&#34920;&#29616;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;MNPs&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15574</link><description>&lt;p&gt;
&#22522;&#20110;&#21151;&#33021;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#31639;&#23376;&#30340;&#28145;&#24230;&#38543;&#26426;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Stochastic Processes via Functional Markov Transition Operators. (arXiv:2305.15574v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15574
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#31639;&#23376;&#30340;&#31070;&#32463;&#38543;&#26426;&#36807;&#31243;MNPs&#65292;&#36890;&#36807;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#22534;&#21472;&#31070;&#32463;&#21442;&#25968;&#21270;&#30340;&#31639;&#23376;&#26500;&#24314;&#65292;&#19981;&#24433;&#21709;&#19968;&#33268;&#24615;&#25110;&#28155;&#21152;&#38480;&#21046;&#65292;&#25552;&#20379;&#20102;&#26356;&#22823;&#30340;&#28789;&#27963;&#24615;&#21644;&#34920;&#29616;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;MNPs&#34920;&#29616;&#20986;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#36807;&#31243;&#31867;&#21035;&#31216;&#20026;&#39532;&#23572;&#31185;&#22827;&#31070;&#32463;&#36807;&#31243;(MNPs)&#65292;&#36825;&#31181;&#38543;&#26426;&#36807;&#31243;&#36890;&#36807;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#22534;&#21472;&#31070;&#32463;&#21442;&#25968;&#21270;&#30340;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#31639;&#23376;&#26500;&#24314;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20123;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#31639;&#23376;&#21487;&#20197;&#20445;&#25345;&#38543;&#26426;&#36807;&#31243;&#30340;&#21487;&#20132;&#25442;&#24615;&#21644;&#19968;&#33268;&#24615;&#12290;&#22240;&#27492;&#65292;&#22312;&#19981;&#22952;&#30861;&#19968;&#33268;&#24615;&#25110;&#28155;&#21152;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#30340;&#36845;&#20195;&#26500;&#24314;&#20026;&#31070;&#32463;&#36807;&#31243;(NPs)&#30340;&#21407;&#22987;&#26694;&#26550;&#22686;&#21152;&#20102;&#23454;&#36136;&#24615;&#30340;&#28789;&#27963;&#24615;&#21644;&#34920;&#29616;&#21147;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35828;&#26126;MNPs&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#27604;&#22522;&#20934;&#27169;&#22411;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Markov Neural Processes (MNPs), a new class of Stochastic Processes (SPs) which are constructed by stacking sequences of neural parameterised Markov transition operators in function space. We prove that these Markov transition operators can preserve the exchangeability and consistency of SPs. Therefore, the proposed iterative construction adds substantial flexibility and expressivity to the original framework of Neural Processes (NPs) without compromising consistency or adding restrictions. Our experiments demonstrate clear advantages of MNPs over baseline models on a variety of tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#21333;&#20010;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#30340;&#26412;&#22320;&#35299;&#27604;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#26356;&#22909;&#12290;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#25512;&#23548;&#12290;</title><link>http://arxiv.org/abs/2305.15572</link><description>&lt;p&gt;
&#26412;&#22320;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#21333;&#20010;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#30340;&#26412;&#22320;&#35299;&#27604;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#26356;&#22909;&#12290;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#19968;&#39033;&#26368;&#26032;&#30340;&#21457;&#23637;&#26159;&#20351;&#29992;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#65292;&#19982;&#20256;&#32479;&#30340;&#20840;&#23616;&#31574;&#30053;&#30456;&#27604;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#25991;&#29486;&#20013;&#30340;&#8220;&#20256;&#32479;&#26234;&#24935;&#8221;&#26159;&#65292;&#19987;&#27880;&#20110;&#26412;&#22320;&#20248;&#21270;&#35268;&#36991;&#20102;&#32500;&#24230;&#35781;&#21650;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#20363;&#31243;&#30340;&#39044;&#26399;&#34892;&#20026;&#25110;&#25910;&#25947;&#24615;&#20102;&#35299;&#29978;&#23569;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#26412;&#22320;&#26041;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#21457;&#29616;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#21333;&#20010;&#26412;&#22320;&#35299;&#30340;&#32479;&#35745;&#25968;&#25454;&#19982;&#20174;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#30456;&#27604;&#38750;&#24120;&#22909;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#30001;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#31532;&#19968;&#27425;&#20005;&#26684;&#20998;&#26512;&#65292;&#24182;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent development in Bayesian optimization is the use of local optimization strategies, which can deliver strong empirical performance on high-dimensional problems compared to traditional global strategies. The "folk wisdom" in the literature is that the focus on local optimization sidesteps the curse of dimensionality; however, little is known concretely about the expected behavior or convergence of Bayesian local optimization routines. We first study the behavior of the local approach, and find that the statistics of individual local solutions of Gaussian process sample paths are surprisingly good compared to what we would expect to recover from global methods. We then present the first rigorous analysis of such a Bayesian local optimization algorithm recently proposed by M\"uller et al. (2021), and derive convergence rates in both the noisy and noiseless settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#38754;&#21521;&#38543;&#26426;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#30340;&#22312;&#32447;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20046;&#26368;&#20248;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#22312;&#25968;&#23383;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.15558</link><description>&lt;p&gt;
&#38754;&#21521;&#24102;&#26377;&#38271;&#26399;&#32422;&#26463;&#30340;&#38543;&#26426;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#30340;&#22312;&#32447;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online Optimization for Randomized Network Resource Allocation with Long-Term Constraints. (arXiv:2305.15558v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#38754;&#21521;&#38543;&#26426;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#30340;&#22312;&#32447;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20046;&#26368;&#20248;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#22312;&#25968;&#23383;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#36890;&#20449;&#32593;&#32476;&#20013;&#30340;&#22312;&#32447;&#36164;&#28304;&#39044;&#30041;&#38382;&#39064;&#12290;&#32593;&#32476;&#30001;&#20004;&#20010;&#35745;&#31639;&#33410;&#28857;&#32452;&#25104;&#65292;&#36890;&#36807;&#26412;&#22320;&#36890;&#20449;&#38142;&#36335;&#36830;&#25509;&#12290;&#31995;&#32479;&#22312;&#31163;&#25955;&#26102;&#38388;&#20869;&#36816;&#34892;&#65307;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#31649;&#29702;&#21592;&#20250;&#22312;&#23454;&#38469;&#20316;&#19994;&#35831;&#27714;&#20043;&#21069;&#20026;&#26381;&#21153;&#22120;&#39044;&#30041;&#36164;&#28304;&#65292;&#36825;&#20123;&#39044;&#30041;&#20250;&#20135;&#29983;&#25104;&#26412;&#12290;&#28982;&#21518;&#65292;&#22312;&#35266;&#23519;&#21040;&#23458;&#25143;&#31471;&#35831;&#27714;&#20043;&#21518;&#65292;&#20316;&#19994;&#21487;&#33021;&#20250;&#20174;&#19968;&#20010;&#26381;&#21153;&#22120;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#26381;&#21153;&#22120;&#65292;&#20197;&#26368;&#22909;&#22320;&#36866;&#24212;&#38656;&#27714;&#65292;&#20294;&#36825;&#20250;&#20135;&#29983;&#39069;&#22806;&#30340;&#20256;&#36755;&#25104;&#26412;&#12290;&#22914;&#26524;&#26080;&#27861;&#28385;&#36275;&#26576;&#20123;&#20316;&#19994;&#35831;&#27714;&#65292;&#21017;&#20250;&#20135;&#29983;&#36829;&#35268;&#25104;&#26412;&#65292;&#38656;&#35201;&#20026;&#27599;&#20010;&#34987;&#38459;&#27490;&#30340;&#20316;&#19994;&#25903;&#20184;&#25104;&#26412;&#12290;&#30446;&#26631;&#26159;&#22312;&#26377;&#38480;&#30340;&#26102;&#38388;&#20869;&#26368;&#23567;&#21270;&#24635;&#39044;&#35746;&#25104;&#26412;&#65292;&#21516;&#26102;&#22312;&#19968;&#23450;&#39044;&#31639;&#38480;&#21046;&#19979;&#32500;&#25252;&#32047;&#31215;&#36829;&#35268;&#21644;&#20256;&#36755;&#25104;&#26412;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#21453;&#22797;&#21338;&#24328;&#38382;&#39064;&#65292;&#38024;&#23545;&#19968;&#31995;&#21015;&#25552;&#35758;&#30340;&#31574;&#30053;&#25353;&#38543;&#26426;&#39034;&#24207;&#36827;&#34892;&#39044;&#35746;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22312;&#32447;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#20197;&#26399;&#26395;&#30340;&#24635;&#25104;&#26412;&#20026;&#22522;&#30784;&#65292;&#20026;&#20219;&#20309;&#26377;&#38480;&#30340;T&#26102;&#38388;&#27573;&#12290;&#25968;&#23383;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#20960;&#31181;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study an optimal online resource reservation problem in a simple communication network. The network is composed of two compute nodes linked by a local communication link. The system operates in discrete time; at each time slot, the administrator reserves resources for servers before the actual job requests are known. A cost is incurred for the reservations made. Then, after the client requests are observed, jobs may be transferred from one server to the other to best accommodate the demands by incurring an additional transport cost. If certain job requests cannot be satisfied, there is a violation that engenders a cost to pay for each of the blocked jobs. The goal is to minimize the overall reservation cost over finite horizons while maintaining the cumulative violation and transport costs under a certain budget limit. To study this problem, we first formalize it as a repeated game against nature where the reservations are drawn randomly according to a sequence of pro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#21644;&#33258;&#36866;&#24212;&#25191;&#34892;&#31574;&#30053;&#36716;&#25442;&#25216;&#26415;&#65292;&#22312;&#30701;&#28903;&#21270;&#26102;&#38388;MDPs&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#26368;&#20248;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#26368;&#20248;&#24615;&#21644;&#38656;&#35201;&#20184;&#20986;&#39640;&#26114;&#20869;&#23384;&#35745;&#31639;&#25104;&#26412;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15546</link><description>&lt;p&gt;
&#30701;&#28903;&#21270;&#26102;&#38388;MDPs&#19978;&#20855;&#26377;&#36951;&#25022;&#26368;&#20248;&#30340;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time. (arXiv:2305.15546v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15546
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#21644;&#33258;&#36866;&#24212;&#25191;&#34892;&#31574;&#30053;&#36716;&#25442;&#25216;&#26415;&#65292;&#22312;&#30701;&#28903;&#21270;&#26102;&#38388;MDPs&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#26368;&#20248;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#26368;&#20248;&#24615;&#21644;&#38656;&#35201;&#20184;&#20986;&#39640;&#26114;&#20869;&#23384;&#35745;&#31639;&#25104;&#26412;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#22312;&#32447;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#22312;&#34920;&#26684;&#26080;&#38480;&#26102;&#27573;&#25240;&#25187;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;&#23398;&#20064;&#12290;&#29616;&#26377;&#31639;&#27861;&#35201;&#20040;&#26080;&#27861;&#23454;&#29616;&#36951;&#25022;&#26368;&#20248;&#24615;&#65292;&#35201;&#20040;&#38656;&#35201;&#20184;&#20986;&#39640;&#26114;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#22312;&#29616;&#26377;&#30340;&#26368;&#20248;&#31639;&#27861;&#20013;&#65292;&#20026;&#20102;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#25928;&#29575;&#65292;&#25152;&#26377;&#31639;&#27861;&#37117;&#35201;&#32463;&#36807;&#36739;&#38271;&#30340;&#28903;&#21270;&#26102;&#38388;&#65292;&#21363;&#21482;&#26377;&#26679;&#26412;&#23481;&#37327;&#36229;&#36807;&#19968;&#20010;&#39640;&#38408;&#20540;&#25165;&#33021;&#20445;&#35777;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#21644;&#19968;&#31181;&#24930;&#32780;&#33258;&#36866;&#24212;&#30340;&#25191;&#34892;&#31574;&#30053;&#36716;&#25442;&#25216;&#26415;&#12290;&#36825;&#26159;&#25240;&#25187;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#20855;&#26377;&#36951;&#25022;&#26368;&#20248;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#24182;&#20855;&#26377;&#20302;&#28903;&#21270;&#26102;&#38388;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
A crucial problem in reinforcement learning is learning the optimal policy. We study this in tabular infinite-horizon discounted Markov decision processes under the online setting. The existing algorithms either fail to achieve regret optimality or have to incur a high memory and computational cost. In addition, existing optimal algorithms all require a long burn-in time in order to achieve optimal sample efficiency, i.e., their optimality is not guaranteed unless sample size surpasses a high threshold. We address both open problems by introducing a model-free algorithm that employs variance reduction and a novel technique that switches the execution policy in a slow-yet-adaptive manner. This is the first regret-optimal model-free algorithm in the discounted setting, with the additional benefit of a low burn-in time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#31232;&#30095;&#32593;&#26684;&#20248;&#21270;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#26041;&#27861;&#65288;SKI&#65289;&#65292;&#22312;&#20445;&#35777;&#25554;&#20540;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#36755;&#20837;&#28857;&#32500;&#24230;&#36739;&#39640;&#24102;&#26469;&#30340;&#35745;&#31639;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#31232;&#30095;&#32593;&#26684;&#30697;&#38453;&#20056;&#27861;&#31639;&#27861;&#20197;&#21450;&#39640;&#25928;&#25554;&#20540;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14451</link><description>&lt;p&gt;
&#31232;&#30095;&#32593;&#26684;&#30340;&#26680;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Kernel Interpolation with Sparse Grids. (arXiv:2305.14451v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#31232;&#30095;&#32593;&#26684;&#20248;&#21270;&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#26041;&#27861;&#65288;SKI&#65289;&#65292;&#22312;&#20445;&#35777;&#25554;&#20540;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#36755;&#20837;&#28857;&#32500;&#24230;&#36739;&#39640;&#24102;&#26469;&#30340;&#35745;&#31639;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#31232;&#30095;&#32593;&#26684;&#30697;&#38453;&#20056;&#27861;&#31639;&#27861;&#20197;&#21450;&#39640;&#25928;&#25554;&#20540;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#26680;&#25554;&#20540;&#65288;SKI&#65289;&#36890;&#36807;&#20351;&#29992;&#24863;&#24212;&#28857;&#30340;&#23494;&#38598;&#32593;&#26684;&#25554;&#20540;&#26680;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#21152;&#36895;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#25512;&#26029;&#12290;&#23545;&#24212;&#30340;&#26680;&#30697;&#38453;&#39640;&#24230;&#32467;&#26500;&#21270;&#65292;&#22240;&#27492;&#26131;&#20110;&#24555;&#36895;&#36827;&#34892;&#32447;&#24615;&#20195;&#25968;&#35745;&#31639;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;SKI&#22312;&#36755;&#20837;&#28857;&#30340;&#32500;&#24230;&#26041;&#38754;&#30340;&#35268;&#27169;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#20026;&#23494;&#38598;&#32593;&#26684;&#22823;&#23567;&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#22312;SKI&#26694;&#26550;&#20869;&#20351;&#29992;&#31232;&#30095;&#32593;&#26684;&#12290;&#36825;&#20123;&#32593;&#26684;&#33021;&#22815;&#36827;&#34892;&#20934;&#30830;&#30340;&#25554;&#20540;&#65292;&#20294;&#28857;&#25968;&#38543;&#32500;&#24230;&#30340;&#22686;&#21152;&#26356;&#24930;&#12290;&#25105;&#20204;&#36129;&#29486;&#20102;&#19968;&#31181;&#26032;&#30340;&#36817;&#20284;&#32447;&#24615;&#26102;&#38388;&#30340;&#31232;&#30095;&#32593;&#26684;&#26680;&#30697;&#38453;&#30690;&#37327;&#20056;&#27861;&#31639;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#23558;&#31232;&#30095;&#32593;&#26684;&#19982;&#22522;&#20110;&#31616;&#21333;&#24418;&#24335;&#30340;&#39640;&#25928;&#25554;&#20540;&#26041;&#26696;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#36825;&#20123;&#25913;&#36827;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;SKI&#21487;&#20197;&#25193;&#23637;&#21040;&#26356;&#39640;&#30340;&#32500;&#24230;&#32780;&#20445;&#25345;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structured kernel interpolation (SKI) accelerates Gaussian process (GP) inference by interpolating the kernel covariance function using a dense grid of inducing points, whose corresponding kernel matrix is highly structured and thus amenable to fast linear algebra. Unfortunately, SKI scales poorly in the dimension of the input points, since the dense grid size grows exponentially with the dimension. To mitigate this issue, we propose the use of sparse grids within the SKI framework. These grids enable accurate interpolation, but with a number of points growing more slowly with dimension. We contribute a novel nearly linear time matrix-vector multiplication algorithm for the sparse grid kernel matrix. Next, we describe how sparse grids can be combined with an efficient interpolation scheme based on simplices. With these changes, we demonstrate that SKI can be scaled to higher dimensions while maintaining accuracy.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ProbDR&#21464;&#20998;&#26694;&#26550;&#65292;&#23558;&#32463;&#20856;&#38477;&#32500;&#31639;&#27861;&#35299;&#37322;&#20026;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#23436;&#25104;&#25512;&#26029;&#25805;&#20316;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#21487;&#20197;&#23436;&#25104;&#24120;&#35268;&#38477;&#32500;&#31639;&#27861;&#65292;&#36824;&#25903;&#25345;&#20351;&#29992;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#38477;&#32500;&#25805;&#20316;&#65292;&#20855;&#26377;&#24378;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2304.07658</link><description>&lt;p&gt;
&#20316;&#20026;&#27010;&#29575;&#25512;&#26029;&#30340;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dimensionality Reduction as Probabilistic Inference. (arXiv:2304.07658v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07658
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;ProbDR&#21464;&#20998;&#26694;&#26550;&#65292;&#23558;&#32463;&#20856;&#38477;&#32500;&#31639;&#27861;&#35299;&#37322;&#20026;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#23436;&#25104;&#25512;&#26029;&#25805;&#20316;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#21487;&#20197;&#23436;&#25104;&#24120;&#35268;&#38477;&#32500;&#31639;&#27861;&#65292;&#36824;&#25903;&#25345;&#20351;&#29992;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#38477;&#32500;&#25805;&#20316;&#65292;&#20855;&#26377;&#24378;&#22823;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#32500;&#31639;&#27861;&#23558;&#39640;&#32500;&#25968;&#25454;&#21387;&#32553;&#21040;&#20302;&#32500;&#34920;&#31034;&#20013;&#65292;&#21516;&#26102;&#20445;&#30041;&#25968;&#25454;&#30340;&#37325;&#35201;&#29305;&#24449;&#12290;&#38477;&#32500;&#26159;&#35768;&#22810;&#20998;&#26512;&#27969;&#31243;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#65292;&#22240;&#20026;&#23427;&#23454;&#29616;&#20102;&#25968;&#25454;&#30340;&#21487;&#35270;&#21270;&#12289;&#22122;&#22768;&#38477;&#20302;&#21644;&#39640;&#25928;&#30340;&#19979;&#28216;&#22788;&#29702;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ProbDR&#21464;&#20998;&#26694;&#26550;&#65292;&#23558;&#24191;&#27867;&#30340;&#32463;&#20856;DR&#31639;&#27861;&#35299;&#37322;&#20026;&#35813;&#26694;&#26550;&#20013;&#30340;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#12290;ProbDR&#21253;&#25324;PCA&#12289;CMDS&#12289;LLE&#12289;LE&#12289;MVU&#12289;&#25193;&#25955;&#26144;&#23556;&#12289;kPCA&#12289;Isomap&#12289;(t-)SNE&#21644;UMAP&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;&#19968;&#20010;&#20302;&#32500;&#28508;&#21464;&#37327;&#29992;&#20110;&#26500;&#24314;&#21327;&#26041;&#24046;&#12289;&#31934;&#24230;&#25110;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#21487;&#20197;&#20316;&#20026;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#19968;&#37096;&#20998;&#12290;&#25512;&#26029;&#26159;&#36890;&#36807;&#20248;&#21270;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#23436;&#25104;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#20869;&#37096;&#19968;&#33268;&#24615;&#65292;&#24182;&#34920;&#26126;&#23427;&#25903;&#25345;&#20351;&#29992;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#65288;PPL&#65289;&#36827;&#34892;DR&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26694;&#26550;&#21487;&#20197;&#23436;&#25104;&#24120;&#35268;DR&#31639;&#27861;&#30340;&#25805;&#20316;&#65292;&#24182;&#36171;&#20104;&#20102;&#23427;&#36890;&#36807;&#27010;&#29575;&#21464;&#20998;&#25512;&#26029;&#30340;&#24378;&#22823;&#34920;&#36798;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dimensionality reduction (DR) algorithms compress high-dimensional data into a lower dimensional representation while preserving important features of the data. DR is a critical step in many analysis pipelines as it enables visualisation, noise reduction and efficient downstream processing of the data. In this work, we introduce the ProbDR variational framework, which interprets a wide range of classical DR algorithms as probabilistic inference algorithms in this framework. ProbDR encompasses PCA, CMDS, LLE, LE, MVU, diffusion maps, kPCA, Isomap, (t-)SNE, and UMAP. In our framework, a low-dimensional latent variable is used to construct a covariance, precision, or a graph Laplacian matrix, which can be used as part of a generative model for the data. Inference is done by optimizing an evidence lower bound. We demonstrate the internal consistency of our framework and show that it enables the use of probabilistic programming languages (PPLs) for DR. Additionally, we illustrate that the f
&lt;/p&gt;</description></item><item><title>RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.06767</link><description>&lt;p&gt;
RAFT: &#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#29992;&#20110;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06767
&lt;/p&gt;
&lt;p&gt;
RAFT&#26694;&#26550;&#24341;&#20837;&#20102;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#40784;&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#24102;&#26469;&#30340;&#20302;&#25928;&#21644;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#22411;&#22522;&#30784;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#24191;&#27867;&#30340;&#26080;&#30417;&#30563;&#35757;&#32451;&#25968;&#25454;&#24102;&#26469;&#30340;&#38544;&#24335;&#20559;&#35265;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#23548;&#33268;&#23376;&#20248;&#26679;&#26412;&#12289;&#25197;&#26354;&#30340;&#32467;&#26524;&#21644;&#19981;&#20844;&#24179;&#65292;&#21487;&#33021;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#23558;&#36825;&#20123;&#27169;&#22411;&#19982;&#20154;&#30340;&#20262;&#29702;&#21644;&#20559;&#22909;&#23545;&#40784;&#26159;&#30830;&#20445;&#23427;&#20204;&#22312;&#30495;&#23454;&#24212;&#29992;&#20013;&#36127;&#36131;&#20219;&#21644;&#26377;&#25928;&#30340;&#37096;&#32626;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#20027;&#35201;&#37319;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288; RLHF&#65289;&#20316;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#25163;&#27573;&#12290;&#22312; RL &#31639;&#27861;&#30340;&#25351;&#23548;&#19979;&#65292;&#29992;&#20154;&#31867;&#21453;&#39304;&#25351;&#23548;&#30340;&#22870;&#21169;&#27169;&#22411;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#28982;&#32780;&#65292; RL &#31639;&#27861;&#30340;&#20302;&#25928;&#24615;&#21644;&#19981;&#31283;&#23450;&#24615;&#24120;&#24120;&#20250;&#23545;&#29983;&#25104;&#27169;&#22411;&#30340;&#25104;&#21151;&#23545;&#40784;&#20135;&#29983;&#37325;&#22823;&#38556;&#30861;&#65292;&#22240;&#27492;&#38656;&#35201;&#24320;&#21457;&#19968;&#31181;&#26356;&#20026;&#24378;&#22823;&#21644;&#31616;&#21270;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#21363;&#22870;&#21169;&#25490;&#21517;&#24494;&#35843;&#65288; RAFT &#65289;&#65292;&#26088;&#22312;&#23545;&#40784;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#19979;&#22810;&#26631;&#31614;&#25490;&#21517;&#38382;&#39064;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24182;&#39318;&#27425;&#32473;&#20986;&#22522;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#30340;&#31561;&#20215;&#31867;&#12290;</title><link>http://arxiv.org/abs/2304.03337</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#26631;&#31614;&#25490;&#21517;&#30340;&#21487;&#23398;&#20064;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Learnability of Multilabel Ranking. (arXiv:2304.03337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03337
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#19979;&#22810;&#26631;&#31614;&#25490;&#21517;&#38382;&#39064;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24182;&#39318;&#27425;&#32473;&#20986;&#22522;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#30340;&#31561;&#20215;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#22810;&#26631;&#31614;&#25490;&#21517;&#26159;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#32593;&#32476;&#25628;&#32034;&#12289;&#26032;&#38395;&#25253;&#36947;&#12289;&#25512;&#33616;&#31995;&#32479;&#31561;&#39046;&#22495;&#12290;&#20294;&#26159;&#65292;&#20851;&#20110;&#22810;&#26631;&#31614;&#25490;&#21517;&#35774;&#32622;&#20013;&#21487;&#23398;&#20064;&#24615;&#30340;&#26368;&#22522;&#26412;&#38382;&#39064;&#20173;&#26410;&#35299;&#31572;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#19979;&#22810;&#26631;&#31614;&#25490;&#21517;&#38382;&#39064;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#21516;&#26102;&#20063;&#39318;&#27425;&#32473;&#20986;&#20102;&#22522;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#30340;&#31561;&#20215;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multilabel ranking is a central task in machine learning with widespread applications to web search, news stories, recommender systems, etc. However, the most fundamental question of learnability in a multilabel ranking setting remains unanswered. In this paper, we characterize the learnability of multilabel ranking problems in both the batch and online settings for a large family of ranking losses. Along the way, we also give the first equivalence class of ranking losses based on learnability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;</title><link>http://arxiv.org/abs/2303.16372</link><description>&lt;p&gt;
&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#30340;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Lower Bounds For Training Data Reconstruction. (arXiv:2303.16372v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#21644;&#24230;&#37327;&#38544;&#31169;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#26041;&#38754;&#30340;&#40065;&#26834;&#24615;&#65292;&#24471;&#20986;&#20102;&#38750;&#28176;&#36827;&#24615;&#19979;&#30028;&#65292;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#65292;&#19988;&#25193;&#23637;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#30340;&#38544;&#31169;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19987;&#19994;&#23545;&#25163;&#36827;&#34892;&#35757;&#32451;&#25968;&#25454;&#37325;&#26500;&#25915;&#20987;&#26102;&#31169;&#26377;&#23398;&#20064;&#31639;&#27861;&#30340;&#35821;&#20041;&#20445;&#35777;&#24378;&#24230;&#12290;&#25105;&#20204;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36827;&#37327;&#32423;&#19979;&#30028;&#26469;&#30740;&#31350;&#20102;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#21644;&#24230;&#37327;&#38544;&#31169;&#65288;mDP&#65289;&#30340;&#23398;&#20064;&#22120;&#23545;&#25239;&#32773;&#37325;&#26500;&#38169;&#35823;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#23545;mDP&#30340;&#20998;&#26512;&#35206;&#30422;&#20102;&#39640;&#32500;&#24773;&#20917;&#12290;&#26412;&#25991;&#36827;&#19968;&#27493;&#23545;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;DP-SGD&#21644;Projected Noisy SGD&#36827;&#34892;&#20102;&#24230;&#37327;&#24046;&#20998;&#38544;&#31169;&#30340;&#25193;&#23637;&#38544;&#31169;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate semantic guarantees of private learning algorithms for their resilience to training Data Reconstruction Attacks (DRAs) by informed adversaries. To this end, we derive non-asymptotic minimax lower bounds on the adversary's reconstruction error against learners that satisfy differential privacy (DP) and metric differential privacy (mDP). Furthermore, we demonstrate that our lower bound analysis for the latter also covers the high dimensional regime, wherein, the input data dimensionality may be larger than the adversary's query budget. Motivated by the theoretical improvements conferred by metric DP, we extend the privacy analysis of popular deep learning algorithms such as DP-SGD and Projected Noisy SGD to cover the broader notion of metric differential privacy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16317</link><description>&lt;p&gt;
PCA-Net&#65306;&#25805;&#20316;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#19978;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Operator learning with PCA-Net: upper and lower complexity bounds. (arXiv:2303.16317v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;PCA-Net&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#65292;&#23427;&#23558;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#19982;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#20197;&#36924;&#36817;&#28508;&#22312;&#30340;&#31639;&#23376;&#12290;&#26412;&#25991;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#25913;&#36827;&#24182;&#26174;&#30528;&#25193;&#23637;&#20102;&#27492;&#26041;&#21521;&#30340;&#20197;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312;&#23450;&#24615;&#30028;&#38480;&#26041;&#38754;&#65292;&#26412;&#25991;&#24471;&#20986;&#20102;&#26032;&#39062;&#30340;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#22312;&#23545;&#28508;&#22312;&#31639;&#23376;&#21644;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#26368;&#23567;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#12290;&#22312;&#23450;&#37327;&#38480;&#21046;&#26041;&#38754;&#65292;&#26412;&#25991;&#35782;&#21035;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#20004;&#20010;&#28508;&#22312;&#38556;&#30861;&#65292;&#36890;&#36807;&#23548;&#20986;&#19979;&#30028;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#65292;&#31532;&#19968;&#20010;&#38556;&#30861;&#19982;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#26377;&#20851;&#65292;&#30001;PCA&#29305;&#24449;&#20540;&#30340;&#32531;&#24930;&#34928;&#20943;&#26469;&#34913;&#37327;&#65307;&#21478;&#19968;&#20010;&#38556;&#30861;&#28041;&#21450;&#26080;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;&#20043;&#38388;&#30340;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operators are gaining attention in computational science and engineering. PCA-Net is a recently proposed neural operator architecture which combines principal component analysis (PCA) with neural networks to approximate an underlying operator. The present work develops approximation theory for this approach, improving and significantly extending previous work in this direction. In terms of qualitative bounds, this paper derives a novel universal approximation result, under minimal assumptions on the underlying operator and the data-generating distribution. In terms of quantitative bounds, two potential obstacles to efficient operator learning with PCA-Net are identified, and made rigorous through the derivation of lower complexity bounds; the first relates to the complexity of the output distribution, measured by a slow decay of the PCA eigenvalues. The other obstacle relates the inherent complexity of the space of operators between infinite-dimensional input and output spaces, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38656;&#27714;&#20391;&#31649;&#29702;&#65288;DSM&#65289;&#26041;&#27861;&#65292;&#21363;&#25511;&#21046;&#22823;&#37327;&#30005;&#27668;&#35774;&#22791;&#36981;&#24490;&#25152;&#38656;&#28040;&#36153;&#20449;&#21495;&#30340;&#38382;&#39064;&#65292;&#31216;&#20026;MD-MFC&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#30452;&#25509;&#35299;&#20915;&#30446;&#26631;&#36319;&#36394;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#26377;&#25928;&#24615;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.08190</link><description>&lt;p&gt;
&#21033;&#29992;&#22343;&#20540;&#22330;&#23398;&#20064;&#37325;&#26032;&#26500;&#24819;&#38656;&#27714;&#20391;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Reimagining Demand-Side Management with Mean Field Learning. (arXiv:2302.08190v2 [math.OC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08190
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38656;&#27714;&#20391;&#31649;&#29702;&#65288;DSM&#65289;&#26041;&#27861;&#65292;&#21363;&#25511;&#21046;&#22823;&#37327;&#30005;&#27668;&#35774;&#22791;&#36981;&#24490;&#25152;&#38656;&#28040;&#36153;&#20449;&#21495;&#30340;&#38382;&#39064;&#65292;&#31216;&#20026;MD-MFC&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#30452;&#25509;&#35299;&#20915;&#30446;&#26631;&#36319;&#36394;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#26377;&#25928;&#24615;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24179;&#34913;&#20379;&#38656;&#30340;&#21516;&#26102;&#23558;&#21487;&#20877;&#29983;&#33021;&#28304;&#32435;&#20837;&#30005;&#32593;&#26159;&#19968;&#20010;&#22797;&#26434;&#38382;&#39064;&#65292;&#37492;&#20110;&#20854;&#38388;&#27463;&#24615;&#12290;&#38656;&#27714;&#20391;&#31649;&#29702;&#65288;DSM&#65289;&#20026;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#25552;&#20379;&#20102;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;DSM&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#25511;&#21046;&#22823;&#37327;&#30005;&#27668;&#35774;&#22791;&#36981;&#24490;&#25152;&#38656;&#28040;&#36153;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#20854;&#24314;&#27169;&#20026;&#19968;&#20010;&#26377;&#38480;&#26102;&#38388;&#27573;&#39532;&#23572;&#31185;&#22827;&#22343;&#20540;&#22330;&#25511;&#21046;&#38382;&#39064;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#65292;MD-MFC&#65292;&#20026;&#20984;&#24615;&#21644;Lipschitz&#30446;&#26631;&#20989;&#25968;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;MD-MFC&#19982;&#29616;&#26377;&#36127;&#36733;&#25511;&#21046;&#25991;&#29486;&#30340;&#21306;&#21035;&#22312;&#20110;&#20854;&#22312;&#19981;&#20351;&#29992;&#20027;&#38382;&#39064;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#30340;&#24773;&#20917;&#19979;&#30452;&#25509;&#35299;&#20915;&#30446;&#26631;&#36319;&#36394;&#38382;&#39064;&#30340;&#26377;&#25928;&#24615;&#12290;&#38236;&#20687;&#19979;&#38477;&#26041;&#26696;&#19978;&#30340;&#38750;&#26631;&#20934;Bregman&#36317;&#31163;&#20801;&#35768;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#33719;&#24471;&#31616;&#21333;&#30340;&#38381;&#24335;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#33324;&#30340;&#22343;&#20540;&#22330;&#21338;&#24328;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#27492;&#38382;&#39064;&#65292;&#20174;&#32780;&#25193;&#23637;&#20102;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Integrating renewable energy into the power grid while balancing supply and demand is a complex issue, given its intermittent nature. Demand side management (DSM) offers solutions to this challenge. We propose a new method for DSM, in particular the problem of controlling a large population of electrical devices to follow a desired consumption signal. We model it as a finite horizon Markovian mean field control problem. We develop a new algorithm, MD-MFC, which provides theoretical guarantees for convex and Lipschitz objective functions. What distinguishes MD-MFC from the existing load control literature is its effectiveness in directly solving the target tracking problem without resorting to regularization techniques on the main problem. A non-standard Bregman divergence on a mirror descent scheme allows dynamic programming to be used to obtain simple closed-form solutions. In addition, we show that general mean-field game algorithms can be applied to this problem, which expands the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#21452;&#26679;&#26412;&#26816;&#39564;&#20013;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#26680;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#32479;&#35745;&#37327;&#65292;&#20197;&#26368;&#22823;&#21270;&#26041;&#24046;&#27491;&#21017;&#21270;&#30340;MMD&#32479;&#35745;&#37327;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#36229;&#32676;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.07415</link><description>&lt;p&gt;
&#21464;&#37327;&#36873;&#25321;&#22312;&#26680;&#21452;&#26679;&#26412;&#26816;&#39564;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variable Selection for Kernel Two-Sample Tests. (arXiv:2302.07415v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#21452;&#26679;&#26412;&#26816;&#39564;&#20013;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#26680;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#32479;&#35745;&#37327;&#65292;&#20197;&#26368;&#22823;&#21270;&#26041;&#24046;&#27491;&#21017;&#21270;&#30340;MMD&#32479;&#35745;&#37327;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20854;&#36229;&#32676;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20004;&#26679;&#26412;&#26816;&#39564;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#26088;&#22312;&#36873;&#25321;&#21306;&#20998;&#20004;&#32452;&#26679;&#26412;&#30340;&#26368;&#26377;&#20449;&#24687;&#21464;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#35813;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23547;&#27714;&#19968;&#32452;&#21464;&#37327;&#65292;&#20854;&#39044;&#20808;&#30830;&#23450;&#30340;&#22823;&#23567;&#26368;&#22823;&#21270;&#26041;&#24046;&#27491;&#21017;&#21270;&#30340;MMD&#32479;&#35745;&#37327;&#12290;&#36825;&#31181;&#35745;&#31639;&#24418;&#24335;&#20063;&#23545;&#24212;&#20110;&#22312;&#25991;&#29486;&#20013;&#30740;&#31350;&#30340;&#25511;&#21046;&#31867;&#22411;I&#38169;&#35823;&#30340;&#21516;&#26102;&#26368;&#23567;&#21270;&#24322;&#36136;&#31867;&#22411;II&#38169;&#35823;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#28151;&#21512;&#25972;&#25968;&#32534;&#31243;&#20844;&#24335;&#65292;&#24182;&#25552;&#20379;&#20102;&#32447;&#24615;&#21644;&#20108;&#27425;&#31867;&#22411;&#20869;&#26680;&#20989;&#25968;&#30340;&#31934;&#30830;&#21644;&#36817;&#20284;&#31639;&#27861;&#65292;&#24182;&#20855;&#26377;&#24615;&#33021;&#20445;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the variable selection problem for two-sample tests, aiming to select the most informative variables to distinguish samples from two groups. To solve this problem, we propose a framework based on the kernel maximum mean discrepancy (MMD). Our approach seeks a group of variables with a pre-specified size that maximizes the variance-regularized MMD statistics. This formulation also corresponds to the minimization of asymptotic type-II error while controlling type-I error, as studied in the literature. We present mixed-integer programming formulations and offer exact and approximation algorithms with performance guarantees for linear and quadratic types of kernel functions. Experimental results demonstrate the superior performance of our framework.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#24207;&#21015;&#26410;&#30830;&#23450;&#20202;&#22120;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#22788;&#29702;&#21464;&#37327;&#21644;&#20165;&#26377;&#26377;&#38480;&#20202;&#22120;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#21487;&#38752;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#22312;&#25554;&#34917;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#12290;</title><link>http://arxiv.org/abs/2302.05684</link><description>&lt;p&gt;
&#24207;&#21015;&#26410;&#30830;&#23450;&#20202;&#22120;&#36873;&#25321;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Sequential Underspecified Instrument Selection for Cause-Effect Estimation. (arXiv:2302.05684v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05684
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#24207;&#21015;&#26410;&#30830;&#23450;&#20202;&#22120;&#36873;&#25321;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#22788;&#29702;&#21464;&#37327;&#21644;&#20165;&#26377;&#26377;&#38480;&#20202;&#22120;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#21487;&#38752;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#24212;&#22312;&#25554;&#34917;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24037;&#20855;&#21464;&#37327;&#65288;IV&#65289;&#26041;&#27861;&#29992;&#20110;&#20272;&#35745;&#23384;&#22312;&#26410;&#35266;&#27979;&#28151;&#28102;&#30340;&#35774;&#32622;&#20013;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#26080;&#27861;&#30452;&#25509;&#23545;&#22788;&#29702;&#21464;&#37327;&#36827;&#34892;&#23454;&#39564;&#12290;&#20202;&#22120;&#26159;&#20165;&#36890;&#36807;&#22788;&#29702;&#21464;&#37327;&#38388;&#25509;&#24433;&#21709;&#32467;&#26524;&#30340;&#21464;&#37327;&#12290;&#22823;&#22810;&#25968;IV&#24212;&#29992;&#38598;&#20013;&#22312;&#20302;&#32500;&#22788;&#29702;&#19978;&#65292;&#24182;&#19988;&#20851;&#38190;&#38656;&#35201;&#33267;&#23569;&#19982;&#22788;&#29702;&#30456;&#21516;&#25968;&#37327;&#30340;&#20202;&#22120;&#12290;&#36825;&#31181;&#20551;&#35774;&#26159;&#26377;&#38480;&#21046;&#24615;&#30340;&#65306;&#22312;&#33258;&#28982;&#31185;&#23398;&#20013;&#65292;&#25105;&#20204;&#32463;&#24120;&#23547;&#27714;&#25512;&#26029;&#39640;&#32500;&#22788;&#29702;&#65288;&#20363;&#22914;&#65292;&#22522;&#22240;&#34920;&#36798;&#25110;&#24494;&#29983;&#29289;&#32676;&#22312;&#20581;&#24247;&#21644;&#30142;&#30149;&#19978;&#30340;&#24433;&#21709;&#65289;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#20294;&#21482;&#33021;&#20351;&#29992;&#26377;&#38480;&#25968;&#37327;&#30340;&#20202;&#22120;&#65288;&#20363;&#22914;&#65292;&#33647;&#29289;&#25110;&#25239;&#29983;&#32032;&#65289;&#36827;&#34892;&#23569;&#37327;&#23454;&#39564;&#12290;&#22312;&#36825;&#31181;&#26410;&#25351;&#23450;&#30340;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#20063;&#26080;&#27861;&#22312;&#21333;&#20010;&#23454;&#39564;&#20013;&#30830;&#23450;&#23436;&#25972;&#30340;&#22788;&#29702;&#25928;&#24212;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20154;&#20204;&#20173;&#28982;&#21487;&#20197;&#21487;&#38752;&#22320;&#24674;&#22797;&#22788;&#29702;&#25928;&#24212;&#22312;&#25554;&#34917;&#23376;&#31354;&#38388;&#20013;&#30340;&#25237;&#24433;&#65292;&#24182;&#24320;&#21457;&#20102;&#25216;&#26415;&#26469;&#36830;&#32493;&#32452;&#21512;&#36825;&#26679;&#30340;&#37096;&#20998;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Instrumental variable (IV) methods are used to estimate causal effects in settings with unobserved confounding, where we cannot directly experiment on the treatment variable. Instruments are variables which only affect the outcome indirectly via the treatment variable(s). Most IV applications focus on low-dimensional treatments and crucially require at least as many instruments as treatments. This assumption is restrictive: in the natural sciences we often seek to infer causal effects of high-dimensional treatments (e.g., the effect of gene expressions or microbiota on health and disease), but can only run few experiments with a limited number of instruments (e.g., drugs or antibiotics). In such underspecified problems, the full treatment effect is not identifiable in a single experiment even in the linear case. We show that one can still reliably recover the projection of the treatment effect onto the instrumented subspace and develop techniques to consistently combine such partial es
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;CVaR&#30340;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#38024;&#23545;&#22810;&#33218;&#32769;&#34382;&#26426;&#21644;&#26631;&#31614;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#38382;&#39064;&#19978;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#20271;&#24681;&#26031;&#22374;&#22870;&#21169;&#31639;&#27861;&#21644;&#22522;&#20110;&#20215;&#20540;&#36845;&#20195;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#30340;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2302.03201</link><description>&lt;p&gt;
&#22522;&#20110;CVaR&#30340;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#30340;&#36817;&#26368;&#23567;&#21270;&#39118;&#38505;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Near-Minimax-Optimal Risk-Sensitive Reinforcement Learning with CVaR. (arXiv:2302.03201v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03201
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;CVaR&#30340;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#38024;&#23545;&#22810;&#33218;&#32769;&#34382;&#26426;&#21644;&#26631;&#31614;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#38382;&#39064;&#19978;&#65292;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#20271;&#24681;&#26031;&#22374;&#22870;&#21169;&#31639;&#27861;&#21644;&#22522;&#20110;&#20215;&#20540;&#36845;&#20195;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#25110;&#25509;&#36817;&#26368;&#20248;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;(Reinforcement Learning)&#30340;&#30446;&#26631;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;(CVaR)&#65292;&#24182;&#38024;&#23545;&#22810;&#33218;&#32769;&#34382;&#26426;&#21644;&#26631;&#31614;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#19978;&#32622;&#20449;&#30028;&#31639;&#27861;&#30340;&#20271;&#24681;&#26031;&#22374;&#22870;&#21169;&#31639;&#27861;&#65292;&#20197;&#21450;&#19968;&#31181;&#22522;&#20110;&#20215;&#20540;&#36845;&#20195;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#36830;&#32493;&#24615;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#25110;&#32773;&#25509;&#36817;&#26368;&#20248;&#30340;&#39118;&#38505;&#12290;&#36825;&#20123;&#31639;&#27861;&#37117;&#26159;&#22522;&#20110;CVaR&#25152;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study risk-sensitive Reinforcement Learning (RL), focusing on the objective of Conditional Value at Risk (CVaR) with risk tolerance $\tau$. Starting with multi-arm bandits (MABs), we show the minimax CVaR regret rate is $\Omega(\sqrt{\tau^{-1}AK})$, where $A$ is the number of actions and $K$ is the number of episodes, and that it is achieved by an Upper Confidence Bound algorithm with a novel Bernstein bonus. For online RL in tabular Markov Decision Processes (MDPs), we show a minimax regret lower bound of $\Omega(\sqrt{\tau^{-1}SAK})$ (with normalized cumulative rewards), where $S$ is the number of states, and we propose a novel bonus-driven Value Iteration procedure. We show that our algorithm achieves the optimal regret of $\widetilde O(\sqrt{\tau^{-1}SAK})$ under a continuity assumption and in general attains a near-optimal regret of $\widetilde O(\tau^{-1}\sqrt{SAK})$, which is minimax-optimal for constant $\tau$. This improves on the best available bounds. By di
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22522;&#20110;&#35760;&#24518;&#30340;&#20803;&#23398;&#20064;&#22312;&#38750;&#24179;&#31283;&#20998;&#24067;&#19978;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#21644;&#21160;&#20316;-&#35266;&#23519;&#24207;&#21015;&#65292;&#30740;&#31350;&#34920;&#26126;&#21508;&#31181;&#31867;&#22411;&#30340;&#22522;&#20110;&#35760;&#24518;&#30340;&#31070;&#32463;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#22320;&#36924;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#65292;&#24182;&#25191;&#34892;&#28508;&#22312;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2302.03067</link><description>&lt;p&gt;
&#22522;&#20110;&#35760;&#24518;&#30340;&#20803;&#23398;&#20064;&#22312;&#38750;&#24179;&#31283;&#20998;&#24067;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Memory-Based Meta-Learning on Non-Stationary Distributions. (arXiv:2302.03067v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22522;&#20110;&#35760;&#24518;&#30340;&#20803;&#23398;&#20064;&#22312;&#38750;&#24179;&#31283;&#20998;&#24067;&#19978;&#30340;&#24212;&#29992;&#65292;&#37325;&#28857;&#20851;&#27880;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#21644;&#21160;&#20316;-&#35266;&#23519;&#24207;&#21015;&#65292;&#30740;&#31350;&#34920;&#26126;&#21508;&#31181;&#31867;&#22411;&#30340;&#22522;&#20110;&#35760;&#24518;&#30340;&#31070;&#32463;&#27169;&#22411;&#21487;&#20197;&#20934;&#30830;&#22320;&#36924;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#65292;&#24182;&#25191;&#34892;&#28508;&#22312;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35760;&#24518;&#30340;&#20803;&#23398;&#20064;&#26159;&#19968;&#31181;&#36924;&#36817;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#22120;&#30340;&#25216;&#26415;&#12290;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#39034;&#24207;&#39044;&#27979;&#35823;&#24046;&#65288;&#30001;&#23545;&#25968;&#25439;&#22833;&#24230;&#37327;&#65289;&#20250;&#23548;&#33268;&#38544;&#24335;&#20803;&#23398;&#20064;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#35843;&#26597;&#24403;&#21069;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#21644;&#35757;&#32451;&#26041;&#26696;&#33021;&#21542;&#23454;&#29616;&#36825;&#31181;&#35299;&#37322;&#30340;&#28145;&#24230;&#12290;&#37325;&#28857;&#20851;&#27880;&#20855;&#26377;&#26410;&#35266;&#23519;&#21040;&#30340;&#20999;&#25442;&#28857;&#30340;&#20998;&#27573;&#24179;&#31283;&#28304;&#65292;&#24456;&#21487;&#33021;&#25429;&#25417;&#21040;&#37096;&#20998;&#21487;&#35266;&#23519;&#29615;&#22659;&#20013;&#30340;&#33258;&#28982;&#35821;&#35328;&#21644;&#21160;&#20316;-&#35266;&#23519;&#24207;&#21015;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#24449;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21508;&#31181;&#31867;&#22411;&#30340;&#22522;&#20110;&#35760;&#24518;&#30340;&#31070;&#32463;&#27169;&#22411;&#65288;&#21253;&#25324;&#21464;&#24418;&#37329;&#21018;&#27169;&#22411;&#12289;LSTM&#21644;RNN&#65289;&#21487;&#20197;&#23398;&#20064;&#20934;&#30830;&#22320;&#36924;&#36817;&#24050;&#30693;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#31639;&#27861;&#65292;&#24182;&#34920;&#29616;&#24471;&#22909;&#20687;&#22312;&#27599;&#20010;&#27573;&#20869;&#23545;&#28508;&#22312;&#20999;&#25442;&#28857;&#21644;&#25511;&#21046;&#25968;&#25454;&#20998;&#24067;&#30340;&#28508;&#22312;&#21442;&#25968;&#25191;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Memory-based meta-learning is a technique for approximating Bayes-optimal predictors. Under fairly general conditions, minimizing sequential prediction error, measured by the log loss, leads to implicit meta-learning. The goal of this work is to investigate how far this interpretation can be realized by current sequence prediction models and training regimes. The focus is on piecewise stationary sources with unobserved switching-points, which arguably capture an important characteristic of natural language and action-observation sequences in partially observable environments. We show that various types of memory-based neural models, including Transformers, LSTMs, and RNNs can learn to accurately approximate known Bayes-optimal algorithms and behave as if performing Bayesian inference over the latent switching-points and the latent parameters governing the data distribution within each segment.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992; GFlowNets &#30340;&#29702;&#35770;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#36830;&#32493;&#25110;&#28151;&#21512;&#29366;&#24577;&#31354;&#38388;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#19982;&#38750; GFlowNet &#22522;&#32447;&#30456;&#27604;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#32467;&#26524;&#65292;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#23558; GFlowNets &#24212;&#29992;&#20110;&#27010;&#29575;&#25512;&#29702;&#21644;&#21508;&#31181;&#24314;&#27169;&#35774;&#32622;&#30340;&#35270;&#35282;&#12290;</title><link>http://arxiv.org/abs/2301.12594</link><description>&lt;p&gt;
&#36830;&#32493;&#29983;&#25104;&#27969;&#32593;&#32476;&#30340;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A theory of continuous generative flow networks. (arXiv:2301.12594v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12594
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992; GFlowNets &#30340;&#29702;&#35770;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#36830;&#32493;&#25110;&#28151;&#21512;&#29366;&#24577;&#31354;&#38388;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#19982;&#38750; GFlowNet &#22522;&#32447;&#30456;&#27604;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#32467;&#26524;&#65292;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#23558; GFlowNets &#24212;&#29992;&#20110;&#27010;&#29575;&#25512;&#29702;&#21644;&#21508;&#31181;&#24314;&#27169;&#35774;&#32622;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#26159;&#19968;&#31181;&#24120;&#35268;&#21270;&#21464;&#20998;&#25512;&#29702;&#31639;&#27861;&#65292;&#34987;&#35757;&#32451;&#29992;&#20110;&#20174;&#32452;&#21512;&#23545;&#35937;&#30340;&#26410;&#24402;&#19968;&#21270;&#30446;&#26631;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;GFlowNets &#30340;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#21040;&#30446;&#21069;&#20026;&#27490;&#19968;&#30452;&#26159;&#23427;&#20204;&#20165;&#36866;&#29992;&#20110;&#31163;&#25955;&#31354;&#38388;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992; GFlowNets &#30340;&#29702;&#35770;&#65292;&#23427;&#21253;&#25324;&#29616;&#26377;&#30340;&#31163;&#25955; GFlowNets &#21644;&#36830;&#32493;&#25110;&#28151;&#21512;&#29366;&#24577;&#31354;&#38388;&#20013;&#30340; GFlowNets&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#30446;&#26631;&#36827;&#34892;&#23454;&#39564;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;&#29702;&#35770;&#30340;&#20851;&#38190;&#28857;&#20197;&#21450;&#21508;&#31181;&#20551;&#35774;&#30340;&#37325;&#35201;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#20043;&#21069;&#30740;&#31350;&#30340;&#20219;&#21153;&#20013;&#65292;&#35777;&#26126;&#20102;&#20851;&#20110;&#31163;&#25955; GFlowNets &#30340;&#35266;&#23519;&#32467;&#26524;&#22914;&#20309;&#36716;&#21270;&#20026;&#36830;&#32493;&#24773;&#20917;&#65292;&#24182;&#19982;&#38750; GFlowNet &#22522;&#32447;&#30456;&#27604;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#32467;&#26524;&#12290;&#36825;&#39033;&#24037;&#20316;&#26497;&#22823;&#22320;&#25193;&#23637;&#20102;&#23558; GFlowNets &#24212;&#29992;&#20110;&#27010;&#29575;&#25512;&#29702;&#21644;&#21508;&#31181;&#24314;&#27169;&#35774;&#32622;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative flow networks (GFlowNets) are amortized variational inference algorithms that are trained to sample from unnormalized target distributions over compositional objects. A key limitation of GFlowNets until this time has been that they are restricted to discrete spaces. We present a theory for generalized GFlowNets, which encompasses both existing discrete GFlowNets and ones with continuous or hybrid state spaces, and perform experiments with two goals in mind. First, we illustrate critical points of the theory and the importance of various assumptions. Second, we empirically demonstrate how observations about discrete GFlowNets transfer to the continuous case and show strong results compared to non-GFlowNet baselines on several previously studied tasks. This work greatly widens the perspectives for the application of GFlowNets in probabilistic inference and various modeling settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#35757;&#32451;&#27491;&#21521;&#36807;&#31243;&#20197;&#26368;&#23567;&#21270;&#29983;&#25104;&#36712;&#36857;&#30340;&#26354;&#29575;&#65292;&#26469;&#20248;&#21270;ODE/SDE-based&#29983;&#25104;&#27169;&#22411;&#30340;&#37319;&#26679;&#36895;&#24230;&#65292;&#23454;&#39564;&#34920;&#26126;&#27492;&#26041;&#27861;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2301.12003</link><description>&lt;p&gt;
&#26368;&#23567;&#21270;ODE&#29983;&#25104;&#27169;&#22411;&#36712;&#36857;&#30340;&#26354;&#29575;
&lt;/p&gt;
&lt;p&gt;
Minimizing Trajectory Curvature of ODE-based Generative Models. (arXiv:2301.12003v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#35757;&#32451;&#27491;&#21521;&#36807;&#31243;&#20197;&#26368;&#23567;&#21270;&#29983;&#25104;&#36712;&#36857;&#30340;&#26354;&#29575;&#65292;&#26469;&#20248;&#21270;ODE/SDE-based&#29983;&#25104;&#27169;&#22411;&#30340;&#37319;&#26679;&#36895;&#24230;&#65292;&#23454;&#39564;&#34920;&#26126;&#27492;&#26041;&#27861;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;ODE / SDE&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#22914;&#25193;&#25955;&#27169;&#22411;&#65292;&#30697;&#24418;&#27969;&#21644;&#27969;&#21305;&#37197;&#65292;&#23558;&#29983;&#25104;&#36807;&#31243;&#23450;&#20041;&#20026;&#22266;&#23450;&#27491;&#21521;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#20294;&#25968;&#20540;&#27169;&#25311;&#38656;&#35201;&#22810;&#27425;&#35780;&#20272;&#31070;&#32463;&#32593;&#32476;&#65292;&#23548;&#33268;&#37319;&#26679;&#36895;&#24230;&#32531;&#24930;&#12290;&#25105;&#20204;&#35748;&#20026;&#21407;&#22240;&#22312;&#20110;&#23398;&#20064;&#21040;&#30340;&#29983;&#25104;&#36712;&#36857;&#20855;&#26377;&#24456;&#39640;&#30340;&#26354;&#29575;&#65292;&#22240;&#20026;&#23427;&#19982;&#25968;&#20540;&#27714;&#35299;&#22120;&#30340;&#25130;&#26029;&#35823;&#24046;&#30452;&#25509;&#30456;&#20851;&#12290;&#22522;&#20110;&#27491;&#21521;&#36807;&#31243;&#21644;&#26354;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#27491;&#21521;&#36807;&#31243;&#20197;&#26368;&#23567;&#21270;&#29983;&#25104;&#36712;&#36857;&#30340;&#26354;&#29575;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;ODE / SDE&#27169;&#25311;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#27604;&#20808;&#21069;&#27169;&#22411;&#26356;&#20302;&#30340;&#26354;&#29575;&#65292;&#24182;&#22240;&#27492;&#38477;&#20302;&#20102;&#37319;&#26679;&#25104;&#26412;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent ODE/SDE-based generative models, such as diffusion models, rectified flows, and flow matching, define a generative process as a time reversal of a fixed forward process. Even though these models show impressive performance on large-scale datasets, numerical simulation requires multiple evaluations of a neural network, leading to a slow sampling speed. We attribute the reason to the high curvature of the learned generative trajectories, as it is directly related to the truncation error of a numerical solver. Based on the relationship between the forward process and the curvature, here we present an efficient method of training the forward process to minimize the curvature of generative trajectories without any ODE/SDE simulation. Experiments show that our method achieves a lower curvature than previous models and, therefore, decreased sampling costs while maintaining competitive performance. Code is available at https://github.com/sangyun884/fast-ode.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38388;&#26029;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#21322;&#31163;&#25955;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19978;&#26377;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#20197;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;$n^{-1/2}$&#25910;&#25947;&#65292;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#65292;&#20026;&#35299;&#20915;&#38388;&#26029;&#26144;&#23556;&#30340;&#20272;&#35745;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2301.11302</link><description>&lt;p&gt;
&#21322;&#31163;&#25955;&#24773;&#20917;&#19979;&#38388;&#26029;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#26497;&#23567;&#26497;&#22823;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Minimax estimation of discontinuous optimal transport maps: The semi-discrete case. (arXiv:2301.11302v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38388;&#26029;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#22312;&#21322;&#31163;&#25955;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19978;&#26377;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#20197;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;$n^{-1/2}$&#25910;&#25947;&#65292;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#65292;&#20026;&#35299;&#20915;&#38388;&#26029;&#26144;&#23556;&#30340;&#20272;&#35745;&#38382;&#39064;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#26679;&#26412;&#30340;&#22522;&#30784;&#19978;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;P&#21644;Q&#22312;$\mathbb{R}^d$&#19978;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#25152;&#26377;&#32479;&#35745;&#20998;&#26512;&#37117;&#35201;&#27714;&#36755;&#36816;&#26144;&#23556;&#26159;Lipschitz&#30340;&#65292;&#36825;&#26159;&#19968;&#20010;&#24378;&#30340;&#35201;&#27714;&#65292;&#29305;&#21035;&#26159;&#25490;&#38500;&#20102;&#36755;&#36816;&#26144;&#23556;&#26159;&#38388;&#26029;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#24320;&#21457;&#38388;&#26029;&#26144;&#23556;&#30340;&#20272;&#35745;&#31243;&#24207;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#25968;&#25454;&#20998;&#24067;Q&#26159;&#25903;&#25745;&#22312;$\mathbb{R}^d$&#19978;&#26377;&#38480;&#28857;&#38598;&#19978;&#30340;&#31163;&#25955;&#27979;&#24230;&#30340;&#37325;&#35201;&#29305;&#20363;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#35745;&#31639;&#19978;&#26377;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#35813;&#20272;&#35745;&#22120;&#26368;&#21021;&#30001;Pooladian&#21644;Niles-Weed(2021)&#25552;&#20986;&#65292;&#22522;&#20110;&#29109;&#26368;&#20248;&#36755;&#36816;&#65292;&#24182;&#22312;&#21322;&#31163;&#25955;&#24773;&#20917;&#19979;&#35777;&#26126;&#65292;&#23427;&#20197;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;$n^{-1/2}$&#25910;&#25947;&#65292;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#12290;&#20854;&#20182;&#26631;&#20934;&#30340;&#26144;&#23556;&#20272;&#35745;&#25216;&#26415;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#32570;&#20047;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#65292;&#24182;&#19988;&#34987;&#35777;&#26126;&#21463;&#21040;&#35781;&#21650;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the optimal transport map between two probability distributions, $P$ and $Q$ in $\mathbb R^d$, on the basis of i.i.d. samples. All existing statistical analyses of this problem require the assumption that the transport map is Lipschitz, a strong requirement that, in particular, excludes any examples where the transport map is discontinuous. As a first step towards developing estimation procedures for discontinuous maps, we consider the important special case where the data distribution $Q$ is a discrete measure supported on a finite number of points in $\mathbb R^d$. We study a computationally efficient estimator initially proposed by Pooladian and Niles-Weed (2021), based on entropic optimal transport, and show in the semi-discrete setting that it converges at the minimax-optimal rate $n^{-1/2}$, independent of dimension. Other standard map estimation techniques both lack finite-sample guarantees in this setting and provably suffer from the curse 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#22312;&#19968;&#23450;&#29366;&#24577;&#19979;&#30340;&#25910;&#25947;&#27010;&#29575;&#20026;1&#65292;&#24314;&#31435;&#20102;QTD&#19982;&#38750;&#32447;&#24615;&#24494;&#20998;&#21253;&#21547;&#24335;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2301.04462</link><description>&lt;p&gt;
&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Quantile Temporal-Difference Learning. (arXiv:2301.04462v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#22312;&#19968;&#23450;&#29366;&#24577;&#19979;&#30340;&#25910;&#25947;&#27010;&#29575;&#20026;1&#65292;&#24314;&#31435;&#20102;QTD&#19982;&#38750;&#32447;&#24615;&#24494;&#20998;&#21253;&#21547;&#24335;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65306;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#65292;&#35813;&#31639;&#27861;&#24050;&#25104;&#20026;&#22810;&#20010;&#25104;&#21151;&#30340;&#24378;&#21270;&#23398;&#20064;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#23613;&#31649;&#22312;&#23454;&#35777;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;QTD&#30340;&#29702;&#35770;&#35748;&#35782;&#19968;&#30452;&#38590;&#20197;&#25417;&#25720;&#12290;&#19982;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#38543;&#26426;&#36924;&#36817;&#24037;&#20855;&#26469;&#36827;&#34892;&#20998;&#26512;&#30340;&#32463;&#20856;TD&#23398;&#20064;&#19981;&#21516;&#65292;QTD&#30340;&#26356;&#26032;&#24182;&#19981;&#36817;&#20284;&#20110;&#25910;&#32553;&#31639;&#23376;&#65292;&#39640;&#24230;&#38750;&#32447;&#24615;&#24182;&#19988;&#21487;&#33021;&#20855;&#26377;&#22810;&#20010;&#19981;&#21160;&#28857;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#32467;&#26524;&#26159;&#35777;&#26126;&#22312;&#19982;&#19968;&#31867;&#21160;&#24577;&#35268;&#21010;&#31243;&#24207;&#30340;&#19981;&#21160;&#28857;&#30456;&#24212;&#30340;&#29366;&#24577;&#19979;&#65292;QTD&#30340;&#25910;&#25947;&#27010;&#29575;&#20026;1&#65292;&#20174;&#32780;&#35753;QTD&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#20102;&#30830;&#23450;&#24615;&#30340;&#22522;&#30784;&#12290;&#35777;&#26126;&#36890;&#36807;&#38543;&#26426;&#36924;&#36817;&#29702;&#35770;&#21644;&#38750;&#20809;&#28369;&#20998;&#26512;&#23558;QTD&#19982;&#38750;&#32447;&#24615;&#24494;&#20998;&#21253;&#21547;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyse quantile temporal-difference learning (QTD), a distributional reinforcement learning algorithm that has proven to be a key component in several successful large-scale applications of reinforcement learning. Despite these empirical successes, a theoretical understanding of QTD has proven elusive until now. Unlike classical TD learning, which can be analysed with standard stochastic approximation tools, QTD updates do not approximate contraction mappings, are highly non-linear, and may have multiple fixed points. The core result of this paper is a proof of convergence to the fixed points of a related family of dynamic programming procedures with probability 1, putting QTD on firm theoretical footing. The proof establishes connections between QTD and non-linear differential inclusions through stochastic approximation theory and non-smooth analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#20272;&#31639;&#25968;&#25454;&#27969;&#24418;&#30340;&#32500;&#24230;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2212.12611</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26263;&#20013;&#35782;&#21035;&#25968;&#25454;&#27969;&#24418;&#30340;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
Your diffusion model secretly knows the dimension of the data manifold. (arXiv:2212.12611v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#20272;&#31639;&#25968;&#25454;&#27969;&#24418;&#30340;&#32500;&#24230;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35757;&#32451;&#36807;&#30340;&#25193;&#25955;&#27169;&#22411;&#20272;&#31639;&#25968;&#25454;&#27969;&#24418;&#32500;&#24230;&#30340;&#26032;&#26694;&#26550;&#12290;&#25193;&#25955;&#27169;&#22411;&#36880;&#28176;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#26799;&#24230;&#65292;&#21363;&#22122;&#22768;&#27745;&#26579;&#29256;&#26412;&#30340;&#23545;&#25968;&#23494;&#24230;&#30340;&#26799;&#24230;&#65292;&#19981;&#21516;&#32423;&#21035;&#30340;&#27745;&#26579;&#31243;&#24230;&#23545;&#24212;&#19981;&#21516;&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#25968;&#25454;&#38598;&#32858;&#28966;&#20110;&#39640;&#32500;&#29615;&#22659;&#31354;&#38388;&#20013;&#23884;&#20837;&#30340;&#27969;&#24418;&#65292;&#37027;&#20040;&#38543;&#30528;&#22122;&#22768;&#27745;&#26579;&#31243;&#24230;&#30340;&#38477;&#20302;&#65292;&#26799;&#24230;&#20250;&#25351;&#21521;&#27969;&#24418;&#65292;&#22240;&#20026;&#36825;&#20010;&#26041;&#21521;&#26159;&#26368;&#22823;&#20284;&#28982;&#22686;&#21152;&#30340;&#26041;&#21521;&#12290;&#22240;&#27492;&#65292;&#22312;&#27745;&#26579;&#31243;&#24230;&#36739;&#20302;&#26102;&#65292;&#25193;&#25955;&#27169;&#22411;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#25454;&#27969;&#24418;&#27491;&#24120;&#21521;&#37327;&#30340;&#36924;&#36817;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20272;&#35745;&#20999;&#31354;&#38388;&#30340;&#32500;&#24230;&#65292;&#20063;&#23601;&#26159;&#25968;&#25454;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#25454;&#27969;&#24418;&#32500;&#24230;&#30340;&#31532;&#19968;&#20010;&#20272;&#31639;&#22120;&#65292;&#24182;&#19988;&#32988;&#36807;&#20102;&#24050;&#32463;&#25104;&#29087;&#30340;&#32479;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a novel framework for estimating the dimension of the data manifold using a trained diffusion model. A diffusion model approximates the score function i.e. the gradient of the log density of a noise-corrupted version of the target distribution for varying levels of corruption. We prove that, if the data concentrates around a manifold embedded in the high-dimensional ambient space, then as the level of corruption decreases, the score function points towards the manifold, as this direction becomes the direction of maximal likelihood increase. Therefore, for small levels of corruption, the diffusion model provides us with access to an approximation of the normal bundle of the data manifold. This allows us to estimate the dimension of the tangent space, thus, the intrinsic dimension of the data manifold. To the best of our knowledge, our method is the first estimator of the data manifold dimension based on diffusion models and it outperforms well established statis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20999;&#29255;&#30340;&#26041;&#24335;&#23450;&#20041;&#20102;&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#36317;&#31163;&#12290;</title><link>http://arxiv.org/abs/2212.08049</link><description>&lt;p&gt;
&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;
&lt;/p&gt;
&lt;p&gt;
Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20999;&#29255;&#30340;&#26041;&#24335;&#23450;&#20041;&#20102;&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#24050;&#32463;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#25968;&#25454;&#31185;&#23398;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21464;&#24471;&#26497;&#20854;&#27969;&#34892;&#12290;OT&#38382;&#39064;&#30340;&#26680;&#24515;&#20551;&#35774;&#26159;&#28304;&#21644;&#30446;&#26631;&#27979;&#24230;&#30340;&#24635;&#36136;&#37327;&#30456;&#31561;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#30340;&#24212;&#29992;&#12290;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#65288;OPT&#65289;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#30340;&#26041;&#27861;&#12290;&#19982;OT&#38382;&#39064;&#31867;&#20284;&#65292;OPT&#30340;&#35745;&#31639;&#20381;&#36182;&#20110;&#35299;&#20915;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65288;&#36890;&#24120;&#22312;&#39640;&#32500;&#24230;&#20013;&#65289;&#65292;&#36825;&#21487;&#33021;&#20250;&#21464;&#24471;&#35745;&#31639;&#19978;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;OPT&#38382;&#39064;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#36981;&#24490;&#20999;&#29255;OT&#36317;&#31163;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#21033;&#29992;&#20999;&#29255;&#23450;&#20041;&#20102;&#20999;&#29255;OPT&#36317;&#31163;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20999;&#29255;OPT-based&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#20540;&#23454;&#39564;&#20013;&#30340;&#35745;&#31639;&#21644;&#31934;&#24230;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;Sliced-OPT&#22312;&#22122;&#22768;&#28857;&#20113;&#37197;&#20934;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20998;&#23618;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#37319;&#26679;&#31639;&#27861;&#25104;&#21151;&#27169;&#25311;&#20102;&#20108;&#32500; $Q$ &#29366;&#24577; Potts &#27169;&#22411;&#20013;&#30340;&#19968;&#32423;&#30456;&#21464;&#65292;&#24182;&#21457;&#29616;&#35813;&#26041;&#27861;&#22312;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#26377;&#26174;&#30528;&#25913;&#36827;&#12290;&#39044;&#35757;&#32451;&#25216;&#26415;&#21487;&#20197;&#26377;&#25928;&#22320;&#35757;&#32451;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2212.04955</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#23618;&#33258;&#22238;&#24402;&#32593;&#32476;&#30340;&#19968;&#32423;&#30456;&#21464;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Simulating first-order phase transition with hierarchical autoregressive networks. (arXiv:2212.04955v2 [cond-mat.stat-mech] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.04955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20998;&#23618;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#37319;&#26679;&#31639;&#27861;&#25104;&#21151;&#27169;&#25311;&#20102;&#20108;&#32500; $Q$ &#29366;&#24577; Potts &#27169;&#22411;&#20013;&#30340;&#19968;&#32423;&#30456;&#21464;&#65292;&#24182;&#21457;&#29616;&#35813;&#26041;&#27861;&#22312;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#26377;&#26174;&#30528;&#25913;&#36827;&#12290;&#39044;&#35757;&#32451;&#25216;&#26415;&#21487;&#20197;&#26377;&#25928;&#22320;&#35757;&#32451;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#20998;&#23618;&#33258;&#22238;&#24402;&#31070;&#32463;&#65288;HAN&#65289;&#32593;&#32476;&#37319;&#26679;&#31639;&#27861;&#24212;&#29992;&#20110;&#20108;&#32500; $Q$ &#29366;&#24577; Potts &#27169;&#22411;&#65292;&#24182;&#22312; $Q=12$ &#26102;&#32469;&#36807;&#30456;&#21464;&#36827;&#34892;&#27169;&#25311;&#12290;&#25105;&#20204;&#37327;&#21270;&#20102;&#35813;&#26041;&#27861;&#22312;&#19968;&#32423;&#30456;&#21464;&#30340;&#38468;&#36817;&#34920;&#29616;&#65292;&#24182;&#23558;&#20854;&#19982; Wolff &#31751;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#30456;&#20284;&#30340;&#25968;&#20540;&#24102;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#26377;&#26174;&#30528;&#25913;&#36827;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#35757;&#32451;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#39044;&#35757;&#32451;&#25216;&#26415;&#12290;&#23427;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;&#36739;&#23567;&#30340;&#31995;&#32479;&#22823;&#23567;&#35757;&#32451;&#26576;&#20123;&#31070;&#32463;&#32593;&#32476;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#29992;&#20316;&#26356;&#22823;&#31995;&#32479;&#22823;&#23567;&#30340;&#36215;&#22987;&#37197;&#32622;&#12290;&#36825;&#26159;&#30001;&#20110;&#25105;&#20204;&#30340;&#20998;&#23618;&#26041;&#27861;&#30340;&#36882;&#24402;&#26500;&#36896;&#32780;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#20102;&#20998;&#23618;&#26041;&#27861;&#22312;&#20855;&#26377;&#21452;&#23792;&#20998;&#24067;&#30340;&#31995;&#32479;&#19978;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22312;&#30456;&#21464;&#38468;&#36817;&#30340;&#33258;&#30001;&#33021;&#21644;&#29109;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We apply the Hierarchical Autoregressive Neural (HAN) network sampling algorithm to the two-dimensional $Q$-state Potts model and perform simulations around the phase transition at $Q=12$. We quantify the performance of the approach in the vicinity of the first-order phase transition and compare it with that of the Wolff cluster algorithm. We find a significant improvement as far as the statistical uncertainty is concerned at a similar numerical effort. In order to efficiently train large neural networks we introduce the technique of pre-training. It allows to train some neural networks using smaller system sizes and then employing them as starting configurations for larger system sizes. This is possible due to the recursive construction of our hierarchical approach. Our results serve as a demonstration of the performance of the hierarchical approach for systems exhibiting bimodal distributions. Additionally, we provide estimates of the free energy and entropy in the vicinity of the ph
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#24179;&#34913;&#26435;&#37325;&#26041;&#27861;&#65288;NBW&#65289;&#65292;&#36890;&#36807;&#20248;&#21270; $f$ -&#20998;&#24067;&#30340;&#21464;&#20998;&#34920;&#31034;&#65292;&#30452;&#25509;&#20272;&#35745;&#28304;&#21644;&#24179;&#34913;&#20998;&#24067;&#20043;&#38388;&#30340;&#23494;&#24230;&#27604;&#65292;&#33719;&#24471;&#20102;&#26435;&#37325;&#65292;&#29992;&#20110;&#20272;&#35745;&#20219;&#24847;&#28151;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#24178;&#39044;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2211.07533</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24191;&#20041;&#24179;&#34913;&#26435;&#37325;
&lt;/p&gt;
&lt;p&gt;
Generalized Balancing Weights via Deep Neural Networks. (arXiv:2211.07533v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07533
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#24179;&#34913;&#26435;&#37325;&#26041;&#27861;&#65288;NBW&#65289;&#65292;&#36890;&#36807;&#20248;&#21270; $f$ -&#20998;&#24067;&#30340;&#21464;&#20998;&#34920;&#31034;&#65292;&#30452;&#25509;&#20272;&#35745;&#28304;&#21644;&#24179;&#34913;&#20998;&#24067;&#20043;&#38388;&#30340;&#23494;&#24230;&#27604;&#65292;&#33719;&#24471;&#20102;&#26435;&#37325;&#65292;&#29992;&#20110;&#20272;&#35745;&#20219;&#24847;&#28151;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#24178;&#39044;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#26159;&#35768;&#22810;&#39046;&#22495;&#20013;&#30340;&#19968;&#20010;&#20013;&#24515;&#38382;&#39064;&#12290;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#26159;&#24179;&#34913;&#21327;&#21464;&#37327;&#30340;&#26435;&#37325;&#65292;&#20351;&#24471;&#25968;&#25454;&#30340;&#20998;&#24067;&#31867;&#20284;&#20110;&#38543;&#26426;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#31070;&#32463;&#24179;&#34913;&#26435;&#37325;&#65288;NBW&#65289;&#30340;&#24191;&#20041;&#24179;&#34913;&#26435;&#37325;&#65292;&#20197;&#20272;&#35745;&#20219;&#24847;&#28151;&#21512;&#31163;&#25955;&#21644;&#36830;&#32493;&#24178;&#39044;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#20248;&#21270; $f$ -&#20998;&#24067;&#30340;&#21464;&#20998;&#34920;&#31034;&#65292;&#30452;&#25509;&#20272;&#35745;&#28304;&#21644;&#24179;&#34913;&#20998;&#24067;&#20043;&#38388;&#30340;&#23494;&#24230;&#27604;&#65292;&#33719;&#24471;&#20102;&#26435;&#37325;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102; $\alpha$-&#24046;&#24322;&#20316;&#20026;&#20248;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#29420;&#31435;&#20110;&#20854;&#22320;&#38754;&#23454;&#20917;&#20540;&#21644;&#26080;&#20559;&#23567;&#25209;&#37327;&#26799;&#24230;&#30340;&#20272;&#35745;&#22120;&#65292;&#32780;&#19988;&#23545;&#20110;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#20855;&#26377;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20197;&#19979;&#20004;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#24179;&#34913;&#26435;&#37325;&#65306;&#25552;&#39640;&#24179;&#34913;&#26435;&#37325;&#30340;&#27867;&#21270;&#24615;&#33021;&#21644;&#26816;&#26597;&#20854;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating causal effects from observational data is a central problem in many domains. A general approach is to balance covariates with weights such that the distribution of the data mimics randomization. We present generalized balancing weights, Neural Balancing Weights (NBW), to estimate the causal effects of an arbitrary mixture of discrete and continuous interventions. The weights were obtained through direct estimation of the density ratio between the source and balanced distributions by optimizing the variational representation of $f$-divergence. For this, we selected $\alpha$-divergence as it presents efficient optimization because it has an estimator whose sample complexity is independent of its ground truth value and unbiased mini-batch gradients; moreover, it is advantageous for the vanishing-gradient problem. In addition, we provide the following two methods for estimating the balancing weights: improving the generalization performance of the balancing weights and checking 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#23545;&#26368;&#22351;&#24773;&#20917;&#19979;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#26494;&#19979;&#36866;&#24403;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#23485;&#20351;&#24471;VC&#20998;&#31867;&#21487;&#36866;&#24403;&#22320;&#29992;PAC&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#20110;&#23545;&#25239;&#40065;&#26834;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.05656</link><description>&lt;p&gt;
&#22312;&#24179;&#22343;&#40065;&#26834;&#24615;&#21644;&#26368;&#22351;&#24773;&#20917;&#19979;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#36866;&#24403;&#21487;&#23398;&#20064;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Proper Learnability between Average- and Worst-case Robustness. (arXiv:2211.05656v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05656
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#23545;&#26368;&#22351;&#24773;&#20917;&#19979;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#26494;&#19979;&#36866;&#24403;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#23485;&#20351;&#24471;VC&#20998;&#31867;&#21487;&#36866;&#24403;&#22320;&#29992;PAC&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#20110;&#23545;&#25239;&#40065;&#26834;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Montasser&#31561;&#20154;[2019]&#34920;&#26126;&#65292;&#26377;&#38480;VC&#32500;&#24230;&#19981;&#36275;&#20197;&#23454;&#29616;&#36866;&#24403;&#30340;&#23545;&#25239;&#40065;&#26834;PAC&#23398;&#20064;&#12290;&#37492;&#20110;&#36825;&#31181;&#22256;&#38590;&#65292;&#23398;&#30028;&#24320;&#22987;&#30740;&#31350;&#22312;&#23545;&#26368;&#22351;&#24773;&#20917;&#19979;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#23485;&#19979;&#30340;&#36866;&#24403;&#23398;&#20064;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31995;&#21015;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#23485;&#65292;&#20351;&#24471;VC&#20998;&#31867;&#21487;&#36866;&#24403;&#22320;&#29992;PAC&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#23398;&#20064;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#25509;&#36817;&#20110;&#26631;&#20934;PAC&#23398;&#20064;&#35774;&#32622;&#25152;&#38656;&#30340;&#22797;&#26434;&#24230;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31181;&#29616;&#26377;&#30340;&#21644;&#33258;&#28982;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#40065;&#26834;&#25439;&#22833;&#30340;&#25918;&#23485;&#65292;&#26377;&#38480;&#30340;VC&#32500;&#24230;&#19981;&#36275;&#20197;&#23454;&#29616;&#36866;&#24403;&#30340;&#23398;&#20064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23545;&#20110;&#23545;&#25239;&#40065;&#26834;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, Montasser et al. [2019] showed that finite VC dimension is not sufficient for proper adversarially robust PAC learning. In light of this hardness, there is a growing effort to study what type of relaxations to the adversarially robust PAC learning setup can enable proper learnability. In this work, we initiate the study of proper learning under relaxations of the worst-case robust loss. We give a family of robust loss relaxations under which VC classes are properly PAC learnable with sample complexity close to what one would require in the standard PAC learning setup. On the other hand, we show that for an existing and natural relaxation of the worst-case robust loss, finite VC dimension is not sufficient for proper learning. Lastly, we give new generalization guarantees for the adversarially robust empirical risk minimizer.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24352;&#37327;&#21015;&#36827;&#34892;&#28145;&#24230;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#26041;&#27861;&#12290;&#37319;&#29992;&#24179;&#26041;&#24352;&#37327;&#21015;&#20998;&#35299;&#21644;&#39034;&#24207;&#20445;&#25345;&#21464;&#25442;&#32452;&#21512;&#36827;&#34892;&#21442;&#32771;&#20998;&#24067;&#30340;&#25512;&#36865;&#65292;&#36890;&#36807;&#24352;&#37327;&#21015;&#30340;&#21487;&#25193;&#23637;&#31572;&#26696;&#26500;&#24314;&#20445;&#24207;&#39640;&#32500;&#21464;&#25442;&#65292;&#35774;&#35745;&#20102;&#27604;&#29575;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#26410;&#24402;&#19968;&#21270;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#20540;&#12290;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#31232;&#26377;&#20107;&#20214;&#20272;&#35745;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#20102;&#26356;&#22909;&#30340;&#26041;&#24046;&#20943;&#23567;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2209.01941</link><description>&lt;p&gt;
&#20351;&#29992;&#24352;&#37327;&#21015;&#36827;&#34892;&#28145;&#24230;&#37325;&#35201;&#24615;&#37319;&#26679;&#21450;&#20854;&#22312;&#20808;&#39564;&#21644;&#21518;&#39564;&#26497;&#31471;&#20107;&#20214;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep importance sampling using tensor trains with application to a priori and a posteriori rare event estimation. (arXiv:2209.01941v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.01941
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24352;&#37327;&#21015;&#36827;&#34892;&#28145;&#24230;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#26041;&#27861;&#12290;&#37319;&#29992;&#24179;&#26041;&#24352;&#37327;&#21015;&#20998;&#35299;&#21644;&#39034;&#24207;&#20445;&#25345;&#21464;&#25442;&#32452;&#21512;&#36827;&#34892;&#21442;&#32771;&#20998;&#24067;&#30340;&#25512;&#36865;&#65292;&#36890;&#36807;&#24352;&#37327;&#21015;&#30340;&#21487;&#25193;&#23637;&#31572;&#26696;&#26500;&#24314;&#20445;&#24207;&#39640;&#32500;&#21464;&#25442;&#65292;&#35774;&#35745;&#20102;&#27604;&#29575;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#26410;&#24402;&#19968;&#21270;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#20540;&#12290;&#35813;&#26041;&#27861;&#22312;&#39640;&#32500;&#31232;&#26377;&#20107;&#20214;&#20272;&#35745;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#20102;&#26356;&#22909;&#30340;&#26041;&#24046;&#20943;&#23567;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#20013;&#20272;&#35745;&#31232;&#26377;&#20107;&#20214;&#27010;&#29575;&#30340;&#28145;&#24230;&#37325;&#35201;&#24615;&#37319;&#26679;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#19968;&#33324;&#37325;&#35201;&#24615;&#37319;&#26679;&#38382;&#39064;&#20013;&#30340;&#26368;&#20248;&#37325;&#35201;&#24615;&#20998;&#24067;&#36817;&#20284;&#20026;&#19968;&#20010;&#30001;&#24179;&#26041;&#24352;&#37327;&#21015;&#20998;&#35299;&#24418;&#25104;&#30340;&#39034;&#24207;&#20445;&#25345;&#21464;&#25442;&#32452;&#21512;&#19979;&#30340;&#21442;&#32771;&#20998;&#24067;&#25512;&#36865;&#12290;&#24352;&#37327;&#21015;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#31572;&#26696;&#65292;&#29992;&#20110;&#36890;&#36807;&#23494;&#24230;&#36817;&#20284;&#26500;&#24314;&#20445;&#24207;&#39640;&#32500;&#21464;&#25442;&#12290;&#27839;&#30528;&#19968;&#31995;&#21015;&#36807;&#28193;&#23494;&#24230;&#30340;&#26144;&#23556;&#32452;&#25104;&#30340;&#22320;&#22270;&#21512;&#25104;&#20943;&#36731;&#20102;&#30452;&#25509;&#36817;&#20284;&#27987;&#32553;&#23494;&#24230;&#20989;&#25968;&#30340;&#22256;&#38590;&#12290;&#20026;&#20102;&#35745;&#31639;&#26410;&#24402;&#19968;&#21270;&#27010;&#29575;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#20540;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#27604;&#29575;&#20272;&#35745;&#22120;&#65292;&#20351;&#29992;&#21333;&#29420;&#26500;&#24314;&#30340;&#24352;&#37327;&#21015;&#26684;&#24335;&#30340;&#21464;&#25442;&#32452;&#21512;&#26500;&#24314;&#21478;&#19968;&#20010;&#37325;&#35201;&#24615;&#20998;&#24067;&#26469;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#12290;&#19982;&#20256;&#32479;&#30340;&#37325;&#35201;&#24615;&#37319;&#26679;&#30456;&#27604;&#65292;&#36825;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#26041;&#24046;&#20943;&#23567;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20960;&#20010;&#39640;&#32500;&#31232;&#26377;&#20107;&#20214;&#20272;&#35745;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#30340;&#20808;&#39564;&#21644;&#21518;&#39564;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a deep importance sampling method that is suitable for estimating rare event probabilities in high-dimensional problems. We approximate the optimal importance distribution in a general importance sampling problem as the pushforward of a reference distribution under a composition of order-preserving transformations, in which each transformation is formed by a squared tensor-train decomposition. The squared tensor-train decomposition provides a scalable ansatz for building order-preserving high-dimensional transformations via density approximations. The use of composition of maps moving along a sequence of bridging densities alleviates the difficulty of directly approximating concentrated density functions. To compute expectations over unnormalized probability distributions, we design a ratio estimator that estimates the normalizing constant using a separate importance distribution, again constructed via a composition of transformations in tensor-train format. This offers bett
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24403;&#32593;&#32476;&#20013;&#23384;&#22312;&#19981;&#21305;&#37197;/&#26631;&#31614;&#28151;&#20081;&#30340;&#39030;&#28857;&#26102;&#65292;&#20004;&#20010;&#26679;&#26412;&#22270;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#21152;&#20197;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2208.08638</link><description>&lt;p&gt;
&#22312;&#38169;&#35823;&#26631;&#35760;&#30340;&#32593;&#32476;&#39030;&#28857;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21151;&#32791;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Lost in the Shuffle: Testing Power in the Presence of Errorful Network Vertex Labels. (arXiv:2208.08638v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08638
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24403;&#32593;&#32476;&#20013;&#23384;&#22312;&#19981;&#21305;&#37197;/&#26631;&#31614;&#28151;&#20081;&#30340;&#39030;&#28857;&#26102;&#65292;&#20004;&#20010;&#26679;&#26412;&#22270;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#21152;&#20197;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20004;&#20010;&#26679;&#26412;&#30340;&#32593;&#32476;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#37117;&#26159;&#22312;&#39030;&#28857;&#23545;&#24212;&#22312;&#32593;&#32476;&#20043;&#38388;&#30340;&#38544;&#21547;&#20551;&#35774;&#19979;&#36816;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24403;&#32593;&#32476;&#20013;&#23384;&#22312;&#19981;&#21305;&#37197;/&#26631;&#31614;&#28151;&#20081;&#30340;&#39030;&#28857;&#26102;&#65292;&#20004;&#20010;&#26679;&#26412;&#22270;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#12290;&#22312;&#38543;&#26426;&#28857;&#20056;&#31215;&#21644;&#38543;&#26426;&#22359;&#27169;&#22411;&#32593;&#32476;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#25506;&#35752;&#20102;&#30001;&#20110;&#28151;&#27927;&#23545;&#22522;&#20110;&#20272;&#35745;&#30340;&#36793;&#32536;&#27010;&#29575;&#30697;&#38453;&#25110;&#37051;&#25509;&#30697;&#38453;&#20043;&#38388;&#30340;Frobenius&#33539;&#25968;&#24046;&#24322;&#30340;&#19968;&#23545;&#20551;&#35774;&#26816;&#39564;&#30340;&#21151;&#29575;&#25439;&#22833;&#12290;&#21151;&#32791;&#27979;&#35797;&#30340;&#25439;&#22833;&#36890;&#36807;&#20247;&#22810;&#27169;&#25311;&#21644;&#23454;&#39564;&#36827;&#19968;&#27493;&#21152;&#24378;&#65292;&#22312;&#25991;&#29486;&#20013;&#27604;&#36739;&#20102;&#22810;&#20010;&#26368;&#36817;&#25552;&#20986;&#30340;&#27979;&#35797;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#65292;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#38543;&#26426;&#28857;&#20056;&#31215;&#22270;&#27169;&#22411;&#20013;&#22343;&#26377;&#20307;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#26469;&#33258;&#31070;&#32463;&#31185;&#23398;&#21644;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#30340;&#20004;&#20010;&#20363;&#23376;&#23637;&#31034;&#20102;&#28151;&#27927;&#21487;&#33021;&#23545;&#30495;&#23454;&#25968;&#25454;&#27979;&#35797;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many two-sample network hypothesis testing methodologies operate under the implicit assumption that the vertex correspondence across networks is a priori known. In this paper, we consider the degradation of power in two-sample graph hypothesis testing when there are misaligned/label-shuffled vertices across networks. In the context of random dot product and stochastic block model networks, we theoretically explore the power loss due to shuffling for a pair of hypothesis tests based on Frobenius norm differences between estimated edge probability matrices or between adjacency matrices. The loss in testing power is further reinforced by numerous simulations and experiments, both in the stochastic block model and in the random dot product graph model, where we compare the power loss across multiple recently proposed tests in the literature. Lastly, we demonstrate the impact that shuffling can have in real-data testing in a pair of examples from neuroscience and from social network analysi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411; (dlglm) &#21450;&#20854;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#65292;&#20854;&#20013;&#30340;&#26041;&#27861;&#33021;&#22815;&#28789;&#27963;&#22320;&#22788;&#29702;&#36755;&#20837;&#29305;&#24449;&#21644;&#21709;&#24212;&#30340;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#27169;&#25311;&#35777;&#26126;&#65292;&#22312;&#32570;&#22833;&#25968;&#25454;&#19981;&#38543;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#31561;&#39046;&#22495;&#20013;&#12290;</title><link>http://arxiv.org/abs/2207.08911</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21450;&#20854;&#22312;&#32570;&#22833;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deeply-Learned Generalized Linear Models with Missing Data. (arXiv:2207.08911v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.08911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411; (dlglm) &#21450;&#20854;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#65292;&#20854;&#20013;&#30340;&#26041;&#27861;&#33021;&#22815;&#28789;&#27963;&#22320;&#22788;&#29702;&#36755;&#20837;&#29305;&#24449;&#21644;&#21709;&#24212;&#30340;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#27169;&#25311;&#35777;&#26126;&#65292;&#22312;&#32570;&#22833;&#25968;&#25454;&#19981;&#38543;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#31561;&#39046;&#22495;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#22312;&#29983;&#29289;&#21307;&#23398;&#31185;&#23398;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#20013;&#24471;&#21040;&#20102;&#26174;&#33879;&#24212;&#29992;&#65292;&#20294;&#29616;&#20195;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#38598;&#20013;&#32570;&#22833;&#25968;&#25454;&#30340;&#26356;&#21152;&#26222;&#36941;&#21644;&#22797;&#26434;&#24615;&#32473;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;(dlglm)&#30340;&#27491;&#24335;&#22788;&#29702;&#26041;&#27861;&#65292;&#22312;&#35757;&#32451;&#26102;&#33021;&#22815;&#28789;&#27963;&#22320;&#22788;&#29702;&#36755;&#20837;&#29305;&#24449;&#21644;&#21709;&#24212;&#30340;&#21487;&#24573;&#30053;&#21644;&#19981;&#21487;&#24573;&#30053;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#27169;&#25311;&#35777;&#26126;&#65292;&#22312;&#32570;&#22833;&#25968;&#25454;&#19981;&#38543;&#26426;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20197;UCI&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#38134;&#34892;&#33829;&#38144;&#25968;&#25454;&#38598;&#20026;&#20363;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning (DL) methods have dramatically increased in popularity in recent years, with significant growth in their application to supervised learning problems in the biomedical sciences. However, the greater prevalence and complexity of missing data in modern biomedical datasets present significant challenges for DL methods. Here, we provide a formal treatment of missing data in the context of deeply learned generalized linear models, a supervised DL architecture for regression and classification problems. We propose a new architecture, \textit{dlglm}, that is one of the first to be able to flexibly account for both ignorable and non-ignorable patterns of missingness in input features and response at training time. We demonstrate through statistical simulation that our method outperforms existing approaches for supervised learning tasks in the presence of missing not at random (MNAR) missingness. We conclude with a case study of a Bank Marketing dataset from the UCI Machine Learnin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#20986;&#22810;&#20010;&#24050;&#30693;&#30340;&#27010;&#24565;&#65292;&#20197;&#30830;&#20445;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#12290;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;&#20851;&#31995;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#30340;&#21151;&#33021;&#32452;&#21512;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.13872</link><description>&lt;p&gt;
&#21518;&#39564;&#27010;&#24565;&#35299;&#37322;&#20309;&#26102;&#21487;&#35782;&#21035;&#65311;
&lt;/p&gt;
&lt;p&gt;
When are Post-hoc Conceptual Explanations Identifiable?. (arXiv:2206.13872v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#20986;&#22810;&#20010;&#24050;&#30693;&#30340;&#27010;&#24565;&#65292;&#20197;&#30830;&#20445;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#12290;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;&#20851;&#31995;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#30340;&#21151;&#33021;&#32452;&#21512;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#23884;&#20837;&#36890;&#24120;&#38656;&#35201;&#36890;&#36807;&#27010;&#24565;&#35299;&#37322;&#26469;&#29702;&#35299;&#21644;&#20998;&#35299;&#65292;&#36825;&#31181;&#38656;&#27714;&#22312;&#35299;&#37322;&#20013;&#19981;&#21253;&#21547;&#26377;&#25928;&#27010;&#24565;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#23588;&#20026;&#26174;&#33879;&#12290;&#20026;&#20102;&#25552;&#20379;&#21518;&#39564;&#35299;&#37322;&#65292;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#20250;&#22312;&#24050;&#35757;&#32451;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#25628;&#32034;&#35299;&#37322;&#24615;&#24378;&#30340;&#27010;&#24565;&#65292;&#20363;&#22914;&#29289;&#20307;&#24418;&#29366;&#25110;&#39068;&#33394;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#35748;&#20026;&#27010;&#24565;&#21457;&#29616;&#24212;&#35813;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#36825;&#24847;&#21619;&#30528;&#21487;&#20197;&#34987;&#35777;&#26126;&#22320;&#24674;&#22797;&#20986;&#22810;&#20010;&#24050;&#30693;&#30340;&#27010;&#24565;&#65292;&#20197;&#30830;&#20445;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#12290;&#20026;&#20102;&#20316;&#20026;&#19968;&#20010;&#36215;&#28857;&#65292;&#25105;&#20204;&#26126;&#30830;&#22320;&#23558;&#27010;&#24565;&#21457;&#29616;&#19982;&#20256;&#32479;&#26041;&#27861;&#65288;&#20363;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65289;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#36890;&#36807;&#34920;&#26126;&#23427;&#20204;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#29420;&#31435;&#27010;&#24565;&#26469;&#38416;&#26126;&#36825;&#19968;&#28857;&#12290;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;&#20851;&#31995;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#30340;&#21151;&#33021;&#32452;&#21512;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#21487;&#35777;&#26126;&#21487;&#35782;&#21035;&#30340;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can be used to provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts with non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outpe
&lt;/p&gt;</description></item><item><title>ForestPrune&#26159;&#19968;&#31181;&#21487;&#20197;&#36890;&#36807;&#20462;&#21098;&#28145;&#24230;&#22270;&#23618;&#26469;&#20248;&#21270;&#26641;&#38598;&#25104;&#30340;&#26032;&#39062;&#31639;&#27861;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#22312;&#20013;&#31561;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#21644;&#38598;&#25104;&#20013;&#26174;&#33879;&#21387;&#32553;&#27169;&#22411;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#24555;&#30340;&#39044;&#27979;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2206.00128</link><description>&lt;p&gt;
ForestPrune: &#32039;&#20945;&#30340;&#28145;&#24230;&#21487;&#25511;&#26641;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
ForestPrune: Compact Depth-Controlled Tree Ensembles. (arXiv:2206.00128v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00128
&lt;/p&gt;
&lt;p&gt;
ForestPrune&#26159;&#19968;&#31181;&#21487;&#20197;&#36890;&#36807;&#20462;&#21098;&#28145;&#24230;&#22270;&#23618;&#26469;&#20248;&#21270;&#26641;&#38598;&#25104;&#30340;&#26032;&#39062;&#31639;&#27861;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#22312;&#20013;&#31561;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#21644;&#38598;&#25104;&#20013;&#26174;&#33879;&#21387;&#32553;&#27169;&#22411;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#24555;&#30340;&#39044;&#27979;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26641;&#38598;&#25104;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#23454;&#29616;&#20986;&#33394;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#21487;&#33021;&#20250;&#21464;&#24471;&#24222;&#22823;&#32780;&#38590;&#20197;&#25511;&#21046;&#12290;&#36825;&#20123;&#38598;&#25104;&#36890;&#24120;&#20250;&#36827;&#34892;&#21518;&#22788;&#29702;(&#20462;&#21098;)&#65292;&#20197;&#20943;&#23569;&#20869;&#23384;&#21344;&#29992;&#24182;&#25552;&#39640;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20248;&#21270;&#26694;&#26550;ForestPrune&#65292;&#36890;&#36807;&#20174;&#21333;&#20010;&#26641;&#20013;&#20462;&#21098;&#28145;&#24230;&#22270;&#23618;&#65292;&#23545;&#26641;&#38598;&#25104;&#36827;&#34892;&#21518;&#22788;&#29702;&#12290;&#30001;&#20110;&#20915;&#31574;&#26641;&#20013;&#33410;&#28857;&#25968;&#37327;&#38543;&#30528;&#26641;&#30340;&#28145;&#24230;&#21576;&#25351;&#25968;&#22686;&#38271;&#65292;&#28145;&#26641;&#30340;&#20462;&#21098;&#21487;&#26174;&#33879;&#21387;&#32553;&#38598;&#25104;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#19987;&#38376;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;ForestPrune&#19979;&#39640;&#25928;&#22320;&#33719;&#24471;&#39640;&#36136;&#37327;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#24120;&#21487;&#20197;&#22312;&#20013;&#31561;&#35268;&#27169;&#30340;&#25968;&#25454;&#38598;&#21644;&#38598;&#25104;&#20013;&#22312;&#20960;&#31186;&#38047;&#20869;&#33719;&#24471;&#33391;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20855;&#26377;&#25968;&#19975;&#34892;&#21644;&#25968;&#30334;&#26869;&#26641;&#65292;&#32467;&#26524;&#27604;&#29616;&#26377;&#30340;&#26041;&#27861;&#24555;&#24471;&#22810;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;ForestPrune&#20135;&#29983;&#30340;&#31616;&#27905;&#27169;&#22411;&#20248;&#20110;&#29616;&#26377;&#21518;&#22788;&#29702;&#31639;&#27861;&#25552;&#21462;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tree ensembles are powerful models that achieve excellent predictive performances, but can grow to unwieldy sizes. These ensembles are often post-processed (pruned) to reduce memory footprint and improve interpretability. We present ForestPrune, a novel optimization framework to post-process tree ensembles by pruning depth layers from individual trees. Since the number of nodes in a decision tree increases exponentially with tree depth, pruning deep trees drastically compactifies ensembles. We develop a specialized optimization algorithm to efficiently obtain high-quality solutions to problems under ForestPrune. Our algorithm typically reaches good solutions in seconds for medium-size datasets and ensembles, with 10000s of rows and 100s of trees, resulting in significant speedups over existing approaches. Our experiments demonstrate that ForestPrune produces parsimonious models that outperform models extracted by existing post-processing algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#19968;&#39033;&#20851;&#20110;&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#36890;&#36807;&#21098;&#26525;&#21644;&#20923;&#32467;&#32593;&#32476;&#21442;&#25968;&#20943;&#23569;&#24050;&#35757;&#32451;&#26435;&#37325;&#25968;&#37327;&#30340;&#35843;&#26597;&#30740;&#31350;&#12290;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#20998;&#20026;&#21021;&#22987;&#21270;&#26102;&#30340;&#21098;&#26525;&#12289;&#22870;&#21169;&#24425;&#31080;&#21644;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#65292;&#32780;&#20923;&#32467;&#26435;&#37325;&#21516;&#26679;&#33021;&#22815;&#20943;&#23569;&#24050;&#35757;&#32451;&#30340;&#26435;&#37325;&#25968;&#37327;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#22312;&#38477;&#20302;&#23384;&#20648;&#21644;&#20256;&#36755;&#25104;&#26412;&#30340;&#21516;&#26102;&#25552;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2205.08099</link><description>&lt;p&gt;
&#21098;&#26525;&#21644;&#20923;&#32467;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#37096;&#20998;&#20197;&#36827;&#34892;&#38477;&#32500;&#20248;&#21270;&#30340;&#35757;&#32451;&#26041;&#27861;: &#19968;&#39033;&#35843;&#26597;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Dimensionality Reduced Training by Pruning and Freezing Parts of a Deep Neural Network, a Survey. (arXiv:2205.08099v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.08099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#19968;&#39033;&#20851;&#20110;&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#36890;&#36807;&#21098;&#26525;&#21644;&#20923;&#32467;&#32593;&#32476;&#21442;&#25968;&#20943;&#23569;&#24050;&#35757;&#32451;&#26435;&#37325;&#25968;&#37327;&#30340;&#35843;&#26597;&#30740;&#31350;&#12290;&#21098;&#26525;&#26041;&#27861;&#21487;&#20197;&#20998;&#20026;&#21021;&#22987;&#21270;&#26102;&#30340;&#21098;&#26525;&#12289;&#22870;&#21169;&#24425;&#31080;&#21644;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#65292;&#32780;&#20923;&#32467;&#26435;&#37325;&#21516;&#26679;&#33021;&#22815;&#20943;&#23569;&#24050;&#35757;&#32451;&#30340;&#26435;&#37325;&#25968;&#37327;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#22312;&#38477;&#20302;&#23384;&#20648;&#21644;&#20256;&#36755;&#25104;&#26412;&#30340;&#21516;&#26102;&#25552;&#39640;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#21442;&#25968;&#35745;&#25968;&#36798;&#21040;&#20102;&#21315;&#20159;&#32423;&#21035;&#12290;&#35757;&#32451;&#12289;&#23384;&#20648;&#21644;&#20256;&#36755;&#36825;&#26679;&#30340;&#27169;&#22411;&#26159;&#32791;&#36153;&#33021;&#37327;&#21644;&#26102;&#38388;&#30340;&#65292;&#22240;&#27492;&#20195;&#20215;&#24456;&#39640;&#12290;&#20854;&#20013;&#24456;&#22823;&#19968;&#37096;&#20998;&#25104;&#26412;&#26159;&#30001;&#32593;&#32476;&#30340;&#35757;&#32451;&#24341;&#36215;&#30340;&#12290;&#27169;&#22411;&#21387;&#32553;&#21487;&#20197;&#38477;&#20302;&#23384;&#20648;&#21644;&#20256;&#36755;&#25104;&#26412;&#65292;&#24182;&#36890;&#36807;&#20943;&#23569;&#21069;&#21521;&#25110;&#21518;&#21521;&#20256;&#36882;&#20013;&#30340;&#35745;&#31639;&#25968;&#37327;&#65292;&#36827;&#19968;&#27493;&#20351;&#35757;&#32451;&#26356;&#26377;&#25928;&#12290;&#22240;&#27492;&#65292;&#22312;&#35757;&#32451;&#26102;&#21387;&#32553;&#32593;&#32476;&#24182;&#20445;&#25345;&#39640;&#24615;&#33021;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#26412;&#25991;&#26159;&#20851;&#20110;&#22914;&#20309;&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#20943;&#23569;&#24050;&#35757;&#32451;&#26435;&#37325;&#25968;&#37327;&#30340;&#26041;&#27861;&#30340;&#35843;&#26597;&#30740;&#31350;&#12290;&#20171;&#32461;&#30340;&#22823;&#22810;&#25968;&#26041;&#27861;&#23558;&#32593;&#32476;&#21442;&#25968;&#35774;&#32622;&#20026;&#38646;&#65292;&#36825;&#34987;&#31216;&#20026;&#21098;&#26525;&#12290;&#25152;&#20171;&#32461;&#30340;&#21098;&#26525;&#26041;&#27861;&#34987;&#24402;&#31867;&#20026;&#21021;&#22987;&#21270;&#26102;&#30340;&#21098;&#26525;&#12289;&#22870;&#21169;&#24425;&#31080;&#21644;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#26102;&#20923;&#32467;&#32593;&#32476;&#19968;&#37096;&#20998;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20923;&#32467;&#26435;&#37325;&#65292;&#20063;&#21487;&#20197;&#20943;&#23569;&#24050;&#35757;&#32451;&#30340;&#26435;&#37325;&#25968;&#37327;&#12290;&#22312;&#26412;&#27425;&#35843;&#30740;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38477;&#32500;&#20248;&#21270;&#35757;&#32451;&#20013;&#21098;&#26525;&#21644;&#20923;&#32467;&#32593;&#32476;&#21442;&#25968;&#30340;&#24403;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#30340;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art deep learning models have a parameter count that reaches into the billions. Training, storing and transferring such models is energy and time consuming, thus costly. A big part of these costs is caused by training the network. Model compression lowers storage and transfer costs, and can further make training more efficient by decreasing the number of computations in the forward and/or backward pass. Thus, compressing networks also at training time while maintaining a high performance is an important research topic. This work is a survey on methods which reduce the number of trained weights in deep learning models throughout the training. Most of the introduced methods set network parameters to zero which is called pruning. The presented pruning approaches are categorized into pruning at initialization, lottery tickets and dynamic sparse training. Moreover, we discuss methods that freeze parts of a network at its random initialization. By freezing weights, the number of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#8212;&#8212;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#38480;&#21046;&#65292;&#26088;&#22312;&#35299;&#20915;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#28040;&#38500;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#26377;&#38480;&#23485;&#24230;&#27169;&#22411;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#25928;&#26524;&#65292;&#24182;&#20445;&#30041;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#30340;&#31616;&#21333;&#24615;&#12290;</title><link>http://arxiv.org/abs/2108.13097</link><description>&lt;p&gt;
&#19968;&#31181;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#34920;&#31034;&#23398;&#20064;&#30340;&#29702;&#35770;&#32473;&#20986;&#20102;&#26680;&#26041;&#27861;&#30340;&#28145;&#24230;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A theory of representation learning in deep neural networks gives a deep generalisation of kernel methods. (arXiv:2108.13097v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.13097
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#8212;&#8212;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#38480;&#21046;&#65292;&#26088;&#22312;&#35299;&#20915;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#28040;&#38500;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#26377;&#38480;&#23485;&#24230;&#27169;&#22411;&#20013;&#30340;&#34920;&#31034;&#23398;&#20064;&#25928;&#26524;&#65292;&#24182;&#20445;&#30041;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#30340;&#31616;&#21333;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#25104;&#21151;&#22522;&#20110;&#23427;&#20204;&#36328;&#22810;&#20010;&#23618;&#27425;&#23545;&#36755;&#20837;&#36827;&#34892;&#21464;&#25442;&#20197;&#24314;&#31435;&#33391;&#22909;&#30340;&#39640;&#32423;&#34920;&#31034;&#33021;&#21147;&#12290;&#22240;&#27492;&#65292;&#29702;&#35299;&#36825;&#31181;&#34920;&#31034;&#23398;&#20064;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#24120;&#35268;&#30340;&#29702;&#35770;&#26041;&#27861;&#65288;&#27491;&#24335;&#20026;NNGPs&#65289;&#28041;&#21450;&#26080;&#38480;&#23485;&#38480;&#21046;&#28040;&#38500;&#20102;&#34920;&#31034;&#23398;&#20064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#23485;&#38480;&#21046;&#8212;&#8212;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#38480;&#21046;&#65292;&#23427;&#23637;&#29616;&#20102;&#22312;&#26377;&#38480;&#23485;&#24230;&#27169;&#22411;&#20013;&#38236;&#20687;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#19968;&#20123;&#26631;&#20934;&#26080;&#38480;&#23485;&#24230;&#38480;&#21046;&#30340;&#31616;&#21333;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#36125;&#21494;&#26031;&#34920;&#31034;&#23398;&#20064;&#26497;&#38480;&#19979;&#30340;&#28145;&#23618;&#39640;&#26031;&#36807;&#31243;&#65288;DGPs&#65289;&#20855;&#26377;&#30830;&#20999;&#30340;&#22810;&#20803;&#39640;&#26031;&#21518;&#39564;&#20998;&#24067;&#65292;&#21518;&#39564;&#21327;&#26041;&#24046;&#21487;&#20197;&#36890;&#36807;&#20248;&#21270;&#19968;&#31181;&#21487;&#35299;&#37322;&#30446;&#26631;&#24471;&#21040;&#65292;&#35813;&#30446;&#26631;&#32467;&#21512;&#20102;&#22686;&#24378;&#24615;&#33021;&#30340;&#23545;&#25968;&#20284;&#28982;&#21644;&#19968;&#31995;&#21015;&#30340;KL-&#25955;&#24230;&#65292;&#20351;&#24471;&#21518;&#39564;&#20998;&#24067;&#25509;&#36817;&#20808;&#39564;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The successes of modern deep machine learning methods are founded on their ability to transform inputs across multiple layers to build good high-level representations. It is therefore critical to understand this process of representation learning. However, standard theoretical approaches (formally NNGPs) involving infinite width limits eliminate representation learning. We therefore develop a new infinite width limit, the Bayesian representation learning limit, that exhibits representation learning mirroring that in finite-width models, yet at the same time, retains some of the simplicity of standard infinite-width limits. In particular, we show that Deep Gaussian processes (DGPs) in the Bayesian representation learning limit have exactly multivariate Gaussian posteriors, and the posterior covariances can be obtained by optimizing an interpretable objective combining a log-likelihood to improve performance with a series of KL-divergences which keep the posteriors close to the prior. We
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2008.09312</link><description>&lt;p&gt;
UCB Bandits&#22312;&#23545;&#25239;&#25915;&#20987;&#20013;&#30340;&#36817;&#20046;&#26368;&#20248;&#25915;&#20987;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.09312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#22870;&#21169;&#21463;&#21040;&#23545;&#25239;&#24615;&#30772;&#22351;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#36890;&#36807;&#25805;&#20316;UCB&#21407;&#21017;&#26469;&#25289;&#21160;&#19968;&#20123;&#38750;&#26368;&#20248;&#30446;&#26631;&#33218;$T-o(T)$&#27425;&#65292;&#32047;&#31215;&#25104;&#26412;&#30340;&#26631;&#24230;&#20026;$\sqrt{\log T}$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#32047;&#31215;&#25915;&#20987;&#25104;&#26412;&#30340;&#31532;&#19968;&#20010;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#19982;&#25105;&#20204;&#30340;&#19978;&#30028;&#21305;&#37197;&#65292;&#38500;&#20102;$\log\log T$&#22240;&#23376;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a stochastic multi-arm bandit problem where rewards are subject to adversarial corruption. We propose a novel attack strategy that manipulates a UCB principle into pulling some non-optimal target arm $T - o(T)$ times with a cumulative cost that scales as $\sqrt{\log T}$, where $T$ is the number of rounds. We also prove the first lower bound on the cumulative attack cost. Our lower bound matches our upper bound up to $\log \log T$ factors, showing our attack to be near optimal.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24212;&#29992;&#23433;&#20840;&#32858;&#21512;&#21518;&#65292;&#21333;&#20010;&#35757;&#32451;&#38598;&#30340;&#36136;&#37327;&#20449;&#24687;&#20173;&#21487;&#33021;&#34987;&#25512;&#26029;&#24182;&#24402;&#22240;&#20110;&#20855;&#20307;&#21442;&#19982;&#32773;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#22270;&#20687;&#35782;&#21035;&#23454;&#39564;&#25214;&#20986;&#20102;&#21442;&#19982;&#32773;&#30456;&#23545;&#30340;&#36136;&#37327;&#25490;&#24207;&#65292;&#36827;&#32780;&#29992;&#20110;&#26816;&#27979;&#19981;&#33391;&#34892;&#20026;&#12289;&#31283;&#23450;&#35757;&#32451;&#24615;&#33021;&#20197;&#21450;&#27979;&#37327;&#21442;&#19982;&#32773;&#30340;&#20010;&#20154;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2007.06236</link><description>&lt;p&gt;
&#24102;&#26377;&#23433;&#20840;&#32858;&#21512;&#30340;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#36136;&#37327;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Quality Inference in Federated Learning with Secure Aggregation. (arXiv:2007.06236v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.06236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#24212;&#29992;&#23433;&#20840;&#32858;&#21512;&#21518;&#65292;&#21333;&#20010;&#35757;&#32451;&#38598;&#30340;&#36136;&#37327;&#20449;&#24687;&#20173;&#21487;&#33021;&#34987;&#25512;&#26029;&#24182;&#24402;&#22240;&#20110;&#20855;&#20307;&#21442;&#19982;&#32773;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#22270;&#20687;&#35782;&#21035;&#23454;&#39564;&#25214;&#20986;&#20102;&#21442;&#19982;&#32773;&#30456;&#23545;&#30340;&#36136;&#37327;&#25490;&#24207;&#65292;&#36827;&#32780;&#29992;&#20110;&#26816;&#27979;&#19981;&#33391;&#34892;&#20026;&#12289;&#31283;&#23450;&#35757;&#32451;&#24615;&#33021;&#20197;&#21450;&#27979;&#37327;&#21442;&#19982;&#32773;&#30340;&#20010;&#20154;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20445;&#38556;&#20010;&#20154;&#21644;&#21830;&#19994;&#25968;&#25454;&#30340;&#38544;&#31169;&#21644;&#26426;&#23494;&#24615;&#65292;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#26082;&#32771;&#34385;&#20102;&#25928;&#29575;&#65292;&#20063;&#27880;&#37325;&#19981;&#20849;&#20139;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#26426;&#21046;&#20173;&#21487;&#33021;&#27844;&#28431;&#25935;&#24863;&#20449;&#24687;&#12290;&#22240;&#27492;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#37319;&#29992;&#23433;&#20840;&#32858;&#21512;&#26469;&#38450;&#27490;&#24402;&#22240;&#20110;&#29305;&#23450;&#21442;&#19982;&#32773;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#21333;&#20010;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#36136;&#37327;&#65292;&#24182;&#26174;&#31034;&#21363;&#20351;&#24212;&#29992;&#20102;&#23433;&#20840;&#32858;&#21512;&#65292;&#36825;&#26679;&#30340;&#36136;&#37327;&#20449;&#24687;&#20173;&#21487;&#33021;&#34987;&#25512;&#26029;&#24182;&#24402;&#22240;&#20110;&#20855;&#20307;&#21442;&#19982;&#32773;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;&#22270;&#20687;&#35782;&#21035;&#23454;&#39564;&#65292;&#25105;&#20204;&#25512;&#26029;&#21442;&#19982;&#32773;&#30340;&#30456;&#23545;&#36136;&#37327;&#25490;&#24207;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25512;&#26029;&#20986;&#30340;&#36136;&#37327;&#20449;&#24687;&#24212;&#29992;&#20110;&#26816;&#27979;&#19981;&#33391;&#34892;&#20026;&#12289;&#31283;&#23450;&#35757;&#32451;&#24615;&#33021;&#20197;&#21450;&#27979;&#37327;&#21442;&#19982;&#32773;&#30340;&#20010;&#20154;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning algorithms are developed both for efficiency reasons and to ensure the privacy and confidentiality of personal and business data, respectively. Despite no data being shared explicitly, recent studies showed that the mechanism could still leak sensitive information. Hence, secure aggregation is utilized in many real-world scenarios to prevent attribution to specific participants. In this paper, we focus on the quality of individual training datasets and show that such quality information could be inferred and attributed to specific participants even when secure aggregation is applied. Specifically, through a series of image recognition experiments, we infer the relative quality ordering of participants. Moreover, we apply the inferred quality information to detect misbehaviours, to stabilize training performance, and to measure the individual contributions of participants.
&lt;/p&gt;</description></item></channel></rss>