<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#30340;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#25918;&#26494;&#26041;&#27861;&#65292;&#36890;&#36807;&#35843;&#29992;&#31163;&#32447;&#20248;&#21270;Oracle&#26469;&#38477;&#20302;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#30028;&#38480;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36798;&#21040;&#20102;&#20808;&#21069;&#26368;&#20339;&#30028;&#38480;&#65292;&#24182;&#19982;&#21407;&#22987;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2310.19025</link><description>&lt;p&gt;
&#12298;&#19968;&#31181;&#25913;&#36827;&#30340;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#30340;&#25918;&#26494;&#26041;&#27861;&#12299;
&lt;/p&gt;
&lt;p&gt;
An Improved Relaxation for Oracle-Efficient Adversarial Contextual Bandits. (arXiv:2310.19025v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19025
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#30340;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#25918;&#26494;&#26041;&#27861;&#65292;&#36890;&#36807;&#35843;&#29992;&#31163;&#32447;&#20248;&#21270;Oracle&#26469;&#38477;&#20302;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#30028;&#38480;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36798;&#21040;&#20102;&#20808;&#21069;&#26368;&#20339;&#30028;&#38480;&#65292;&#24182;&#19982;&#21407;&#22987;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#25918;&#26494;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#19978;&#19979;&#25991;&#26159;&#20174;&#24050;&#30693;&#20998;&#24067;&#20013;&#39034;&#24207;&#29420;&#31435;&#25277;&#21462;&#30340;&#65292;&#32780;&#25104;&#26412;&#24207;&#21015;&#21017;&#30001;&#22312;&#32447;&#23545;&#25163;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#19968;&#20010;$O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#19988;&#27599;&#36718;&#26368;&#22810;&#35843;&#29992;$O(K)$&#27425;&#31163;&#32447;&#20248;&#21270;Oracle&#65292;&#20854;&#20013;$K$&#34920;&#31034;&#21160;&#20316;&#30340;&#25968;&#37327;&#65292;$T$&#34920;&#31034;&#36718;&#25968;&#65292;$\Pi$&#34920;&#31034;&#31574;&#30053;&#38598;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#25913;&#36827;Syrgkanis&#31561;&#20154;&#22312;NeurIPS 2016&#20013;&#33719;&#24471;&#30340;$O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$&#30028;&#38480;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#20063;&#26159;&#19982;Langford&#21644;Zhang&#22312;NeurIPS 2007&#20013;&#20026;&#38543;&#26426;&#24773;&#20917;&#25552;&#20986;&#30340;&#21407;&#22987;&#30028;&#38480;&#30456;&#21305;&#37197;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an oracle-efficient relaxation for the adversarial contextual bandits problem, where the contexts are sequentially drawn i.i.d from a known distribution and the cost sequence is chosen by an online adversary. Our algorithm has a regret bound of $O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$ and makes at most $O(K)$ calls per round to an offline optimization oracle, where $K$ denotes the number of actions, $T$ denotes the number of rounds and $\Pi$ denotes the set of policies. This is the first result to improve the prior best bound of $O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$ as obtained by Syrgkanis et al. at NeurIPS 2016, and the first to match the original bound of Langford and Zhang at NeurIPS 2007 which was obtained for the stochastic case.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;&#65292;&#20943;&#23569;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.07672</link><description>&lt;p&gt;
&#29992;&#25511;&#21046;&#21464;&#37327;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Estimates of Shapley Values with Control Variates. (arXiv:2310.07672v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07672
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;&#65292;&#20943;&#23569;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#26159;&#35299;&#37322;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26368;&#27969;&#34892;&#30340;&#24037;&#20855;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#22240;&#27492;&#37319;&#29992;&#25277;&#26679;&#36817;&#20284;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#31283;&#23450;&#36825;&#20123;&#27169;&#22411;&#35299;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25511;&#21046;&#21464;&#37327;&#30340;&#33945;&#29305;&#21345;&#27931;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;ControlSHAP&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35745;&#31639;&#25110;&#24314;&#27169;&#24037;&#20316;&#12290;&#22312;&#22810;&#20010;&#39640;&#32500;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;Shapley&#20272;&#35745;&#30340;&#33945;&#29305;&#21345;&#27931;&#21464;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley values are among the most popular tools for explaining predictions of blackbox machine learning models. However, their high computational cost motivates the use of sampling approximations, inducing a considerable degree of uncertainty. To stabilize these model explanations, we propose ControlSHAP, an approach based on the Monte Carlo technique of control variates. Our methodology is applicable to any machine learning model and requires virtually no extra computation or modeling effort. On several high-dimensional datasets, we find it can produce dramatic reductions in the Monte Carlo variability of Shapley estimates.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#21033;&#29992;PAC-Bayesian&#29702;&#35770;&#20026;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#21253;&#25324;&#23545;&#21518;&#39564;&#20998;&#24067;&#12289;&#37325;&#26500;&#25439;&#22833;&#21644;&#36755;&#20837;&#19982;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.04935</link><description>&lt;p&gt;
&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#32473;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory. (arXiv:2310.04935v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04935
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#21033;&#29992;PAC-Bayesian&#29702;&#35770;&#20026;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#21253;&#25324;&#23545;&#21518;&#39564;&#20998;&#24067;&#12289;&#37325;&#26500;&#25439;&#22833;&#21644;&#36755;&#20837;&#19982;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#23427;&#20204;&#30340;&#38382;&#19990;&#20197;&#26469;&#65292;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;&#23427;&#20204;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20851;&#20110;&#23427;&#20204;&#30340;&#29702;&#35770;&#24615;&#36136;&#20173;&#23384;&#22312;&#35768;&#22810;&#38382;&#39064;&#12290;&#26412;&#25991;&#21033;&#29992;PAC-Bayesian&#29702;&#35770;&#20026;VAEs&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22522;&#20110;&#29420;&#31435;&#26679;&#26412;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#39318;&#20010;PAC-Bayesian&#30028;&#38480;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#20026;VAE&#30340;&#37325;&#26500;&#25439;&#22833;&#25552;&#20379;&#20102;&#27867;&#21270;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36755;&#20837;&#20998;&#24067;&#19982;VAE&#29983;&#25104;&#27169;&#22411;&#23450;&#20041;&#30340;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36755;&#20837;&#20998;&#24067;&#19982;VAE&#29983;&#25104;&#27169;&#22411;&#23450;&#20041;&#30340;&#20998;&#24067;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since their inception, Variational Autoencoders (VAEs) have become central in machine learning. Despite their widespread use, numerous questions regarding their theoretical properties remain open. Using PAC-Bayesian theory, this work develops statistical guarantees for VAEs. First, we derive the first PAC-Bayesian bound for posterior distributions conditioned on individual samples from the data-generating distribution. Then, we utilize this result to develop generalization guarantees for the VAE's reconstruction loss, as well as upper bounds on the distance between the input and the regenerated distributions. More importantly, we provide upper bounds on the Wasserstein distance between the input distribution and the distribution defined by the VAE's generative model.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#31561;&#20215;&#30340;&#30446;&#26631;&#20989;&#25968;&#24418;&#24335;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#65292;&#36824;&#33021;&#22815;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#65292;&#21363;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;KGF&#21644;KRR&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#23558;KRR&#27867;&#21270;&#65292;&#20351;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2306.16838</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Kernel Ridge Regression with Gradient-Based Optimization Methods. (arXiv:2306.16838v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#31561;&#20215;&#30340;&#30446;&#26631;&#20989;&#25968;&#24418;&#24335;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#19981;&#20165;&#21487;&#20197;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#65292;&#36824;&#33021;&#22815;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#65292;&#21363;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#24182;&#35777;&#26126;&#20102;KGF&#21644;KRR&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#36824;&#23558;KRR&#27867;&#21270;&#65292;&#20351;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#26159;&#32447;&#24615;&#23725;&#22238;&#24402;&#30340;&#38750;&#32447;&#24615;&#25512;&#24191;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;KRR&#30446;&#26631;&#20989;&#25968;&#30340;&#31561;&#20215;&#24418;&#24335;&#65292;&#20026;&#20351;&#29992;&#20854;&#20182;&#24809;&#32602;&#26041;&#27861;&#21644;&#20174;&#26799;&#24230;&#19979;&#38477;&#30340;&#35282;&#24230;&#30740;&#31350;&#26680;&#23725;&#22238;&#24402;&#25171;&#24320;&#20102;&#21487;&#33021;&#12290;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#38381;&#21512;&#35299;&#8212;&#8212;&#26680;&#26799;&#24230;&#27969;&#65288;KGF&#65289;&#65292;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#30340;&#27491;&#21017;&#21270;&#65292;&#35753;&#25105;&#20204;&#33021;&#22815;&#22312;KGF&#21644;KRR&#20043;&#38388;&#29702;&#35770;&#19978;&#30028;&#23450;&#24046;&#24322;&#12290;&#25105;&#20204;&#29992;$\ell_1$&#21644;$\ell_\infty$&#24809;&#32602;&#26041;&#27861;&#23558;KRR&#27867;&#21270;&#65292;&#24182;&#21033;&#29992;&#31867;&#20284;KGF&#21644;KRR&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#20351;&#29992;&#36825;&#20123;&#24809;&#32602;&#26041;&#27861;&#24471;&#21040;&#30340;&#35299;&#19982;&#20351;&#29992;&#21069;&#21521;&#20998;&#27493;&#22238;&#24402;&#65288;&#20063;&#31216;&#20026;&#22352;&#26631;&#19979;&#38477;&#65289;&#21644;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#32467;&#21512;&#25552;&#21069;&#20572;&#27490;&#24471;&#21040;&#30340;&#35299;&#38750;&#24120;&#30456;&#20284;&#12290;&#22240;&#27492;&#65292;&#20943;&#23569;&#20102;&#35745;&#31639;&#22797;&#26434;&#24230;&#37325;&#30340;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel ridge regression, KRR, is a non-linear generalization of linear ridge regression. Here, we introduce an equivalent formulation of the objective function of KRR, opening up both for using other penalties than the ridge penalty and for studying kernel ridge regression from the perspective of gradient descent. Using a continuous-time perspective, we derive a closed-form solution, kernel gradient flow, KGF, with regularization through early stopping, which allows us to theoretically bound the differences between KGF and KRR. We generalize KRR by replacing the ridge penalty with the $\ell_1$ and $\ell_\infty$ penalties and utilize the fact that analogously to the similarities between KGF and KRR, the solutions obtained when using these penalties are very similar to those obtained from forward stagewise regression (also known as coordinate descent) and sign gradient descent in combination with early stopping. Thus the need for computationally heavy proximal gradient descent algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20197;&#20943;&#23569;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21482;&#38656;&#35201;&#20351;&#29992;&#19968;&#31181;&#36741;&#21161;&#32593;&#32476;&#23601;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.05674</link><description>&lt;p&gt;
&#38754;&#21521;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#20943;&#23569;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Uncertainty Quantification and Reduction for Over-Parameterized Neural Networks. (arXiv:2306.05674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20197;&#20943;&#23569;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21482;&#38656;&#35201;&#20351;&#29992;&#19968;&#31181;&#36741;&#21161;&#32593;&#32476;&#23601;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#35780;&#20272;&#21644;&#25913;&#36827;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#19981;&#30830;&#23450;&#24615;&#19981;&#20165;&#26469;&#33258;&#25968;&#25454;&#65292;&#36824;&#26469;&#33258;&#35757;&#32451;&#36807;&#31243;&#20013;&#27880;&#20837;&#30340;&#22823;&#37327;&#22122;&#22768;&#21644;&#20559;&#24046;&#12290;&#36825;&#20123;&#22122;&#22768;&#21644;&#20559;&#24046;&#22952;&#30861;&#20102;&#32479;&#35745;&#20445;&#35777;&#30340;&#23454;&#29616;&#65292;&#24182;&#19988;&#30001;&#20110;&#38656;&#35201;&#37325;&#22797;&#30340;&#32593;&#32476;&#37325;&#26032;&#35757;&#32451;&#65292;&#23545;UQ&#25552;&#20986;&#20102;&#35745;&#31639;&#25361;&#25112;&#12290;&#22522;&#20110;&#26368;&#36817;&#30340;&#31070;&#32463;&#20999;&#21521;&#26680;&#29702;&#35770;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#26041;&#26696;&#65292;&#20197;&#36890;&#36807;&#38750;&#24120;&#20302;&#30340;&#35745;&#31639;&#37327;&#37327;&#21270;&#21644;&#20943;&#23569;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#25105;&#20204;&#31216;&#20026;&#36807;&#31243;&#22122;&#22768;&#26657;&#27491;&#65288;PNC&#65289;&#39044;&#27979;&#22120;&#65292;&#36890;&#36807;&#21482;&#20351;&#29992;&#19968;&#31181;&#36866;&#24403;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#36741;&#21161;&#32593;&#32476;&#26469;&#28040;&#38500;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#28145;&#23618;&#38598;&#25104;&#20013;&#30340;&#35768;&#22810;&#37325;&#26032;&#35757;&#32451;&#30340;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;PNC&#39044;&#27979;&#22120;&#19982;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#25105;&#20204;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#30340;&#32593;&#32476;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification (UQ) is important for reliability assessment and enhancement of machine learning models. In deep learning, uncertainties arise not only from data, but also from the training procedure that often injects substantial noises and biases. These hinder the attainment of statistical guarantees and, moreover, impose computational challenges on UQ due to the need for repeated network retraining. Building upon the recent neural tangent kernel theory, we create statistically guaranteed schemes to principally \emph{quantify}, and \emph{remove}, the procedural uncertainty of over-parameterized neural networks with very low computation effort. In particular, our approach, based on what we call a procedural-noise-correcting (PNC) predictor, removes the procedural uncertainty by using only \emph{one} auxiliary network that is trained on a suitably labeled data set, instead of many retrained networks employed in deep ensembles. Moreover, by combining our PNC predictor with su
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#32570;&#22833;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20844;&#24179;&#30340;&#20998;&#31867;&#12290;&#20256;&#32479;&#26041;&#27861;&#20250;&#21152;&#21095;&#27495;&#35270;&#12290;&#26412;&#25991;&#35777;&#26126;&#20174;&#25554;&#34917;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#20250;&#24694;&#21270;&#32452;&#20844;&#24179;&#24615;&#21644;&#24179;&#22343;&#20934;&#30830;&#24615;&#12290;&#20316;&#32773;&#25552;&#20986;&#21487;&#25193;&#23637;&#21644;&#36866;&#24212;&#24615;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#19982;&#20854;&#20182;&#20844;&#24179;&#24178;&#39044;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#22788;&#29702;&#25152;&#26377;&#21487;&#33021;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.19429</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#19979;&#30340;&#20844;&#24179;&#24615;&#24178;&#39044;&#25514;&#26045;&#30340;&#36866;&#24212;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adapting Fairness Interventions to Missing Values. (arXiv:2305.19429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#32570;&#22833;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20844;&#24179;&#30340;&#20998;&#31867;&#12290;&#20256;&#32479;&#26041;&#27861;&#20250;&#21152;&#21095;&#27495;&#35270;&#12290;&#26412;&#25991;&#35777;&#26126;&#20174;&#25554;&#34917;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#20250;&#24694;&#21270;&#32452;&#20844;&#24179;&#24615;&#21644;&#24179;&#22343;&#20934;&#30830;&#24615;&#12290;&#20316;&#32773;&#25552;&#20986;&#21487;&#25193;&#23637;&#21644;&#36866;&#24212;&#24615;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#19982;&#20854;&#20182;&#20844;&#24179;&#24178;&#39044;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#22788;&#29702;&#25152;&#26377;&#21487;&#33021;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#20013;&#25968;&#25454;&#30340;&#32570;&#22833;&#20540;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#25552;&#20986;&#20102;&#26174;&#33879;&#32780;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#19981;&#21516;&#30340;&#26063;&#32676;&#21487;&#33021;&#19981;&#20250;&#21516;&#31561;&#22320;&#21463;&#21040;&#32570;&#22833;&#25968;&#25454;&#30340;&#24433;&#21709;&#65292;&#32780;&#22788;&#29702;&#32570;&#22833;&#20540;&#30340;&#26631;&#20934;&#31243;&#24207;&#65292;&#21363;&#20808;&#23545;&#25968;&#25454;&#36827;&#34892;&#25554;&#34917;&#65292;&#28982;&#21518;&#20351;&#29992;&#25554;&#34917;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#36825;&#20010;&#36807;&#31243;&#34987;&#31216;&#20026;&#8220;&#25554;&#34917;&#20877;&#20998;&#31867;&#8221;&#65292;&#20250;&#21152;&#21095;&#27495;&#35270;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#32570;&#22833;&#20540;&#22914;&#20309;&#24433;&#21709;&#31639;&#27861;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#20174;&#25554;&#34917;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#20250;&#26174;&#33879;&#24694;&#21270;&#21487;&#20197;&#23454;&#29616;&#30340;&#32452;&#20844;&#24179;&#24615;&#21644;&#24179;&#22343;&#20934;&#30830;&#24615;&#30340;&#20540;&#12290;&#36825;&#26159;&#22240;&#20026;&#25554;&#34917;&#25968;&#25454;&#20250;&#23548;&#33268;&#25968;&#25454;&#32570;&#22833;&#27169;&#24335;&#30340;&#20002;&#22833;&#65292;&#25968;&#25454;&#32570;&#22833;&#27169;&#24335;&#36890;&#24120;&#20250;&#20256;&#36798;&#26377;&#20851;&#39044;&#27979;&#26631;&#31614;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21644;&#36866;&#24212;&#24615;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32570;&#22833;&#20540;&#30340;&#20844;&#24179;&#20998;&#31867;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;&#20844;&#24179;&#24178;&#39044;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#22788;&#29702;&#25152;&#26377;&#21487;&#33021;&#30340;&#32570;&#22833;&#27169;&#24335;&#65292;&#24182;&#20445;&#30041;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing values in real-world data pose a significant and unique challenge to algorithmic fairness. Different demographic groups may be unequally affected by missing data, and the standard procedure for handling missing values where first data is imputed, then the imputed data is used for classification -- a procedure referred to as "impute-then-classify" -- can exacerbate discrimination. In this paper, we analyze how missing values affect algorithmic fairness. We first prove that training a classifier from imputed data can significantly worsen the achievable values of group fairness and average accuracy. This is because imputing data results in the loss of the missing pattern of the data, which often conveys information about the predictive label. We present scalable and adaptive algorithms for fair classification with missing values. These algorithms can be combined with any preexisting fairness-intervention algorithm to handle all possible missing patterns while preserving informatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2305.09957</link><description>&lt;p&gt;
&#28145;&#24230;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#23545;&#24212;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep quantum neural networks form Gaussian processes. (arXiv:2305.09957v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#29992;&#20110;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#20808;&#39564;&#26465;&#20214;&#24320;&#22987;&#21021;&#22987;&#21270;&#30340;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#38544;&#34255;&#23618;&#31070;&#32463;&#20803;&#25968;&#30446;&#36275;&#22815;&#22823;&#30340;&#26497;&#38480;&#19979;&#25910;&#25947;&#21040;&#39640;&#26031;&#36807;&#31243;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#23376;&#31070;&#32463;&#32593;&#32476;&#65288;QNNs&#65289;&#20063;&#23384;&#22312;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;Haar&#38543;&#26426;&#37193;&#25110;&#27491;&#20132;&#28145;QNNs&#30340;&#26576;&#20123;&#27169;&#22411;&#30340;&#36755;&#20986;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#32500;&#24230;$d$&#36275;&#22815;&#22823;&#26102;&#20250;&#25910;&#25947;&#20110;&#39640;&#26031;&#36807;&#31243;&#12290;&#30001;&#20110;&#36755;&#20837;&#29366;&#24577;&#12289;&#27979;&#37327;&#30340;&#21487;&#35266;&#27979;&#37327;&#20197;&#21450;&#37193;&#30697;&#38453;&#30340;&#20803;&#32032;&#19981;&#29420;&#31435;&#31561;&#22240;&#32032;&#30340;&#20316;&#29992;&#65292;&#26412;&#25991;&#23545;&#36825;&#19968;&#32467;&#26524;&#30340;&#25512;&#23548;&#27604;&#32463;&#20856;&#24773;&#24418;&#26356;&#21152;&#24494;&#22937;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#19968;&#20010;&#37325;&#35201;&#21518;&#26524;&#26159;&#65292;&#36825;&#20010;&#32467;&#26524;&#24471;&#21040;&#30340;&#39640;&#26031;&#36807;&#31243;&#19981;&#33021;&#36890;&#36807;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26469;&#26377;&#25928;&#22320;&#39044;&#27979;QNN&#30340;&#36755;&#20986;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;Haar&#38543;&#26426;QNNs&#20013;&#30340;&#27979;&#37327;&#29616;&#35937;&#27604;&#20197;&#21069;&#35748;&#20026;&#30340;&#35201;&#26356;&#20005;&#37325;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28436;&#21592;&#30340;&#38598;&#20013;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that artificial neural networks initialized from independent and identically distributed priors converge to Gaussian processes in the limit of large number of neurons per hidden layer. In this work we prove an analogous result for Quantum Neural Networks (QNNs). Namely, we show that the outputs of certain models based on Haar random unitary or orthogonal deep QNNs converge to Gaussian processes in the limit of large Hilbert space dimension $d$. The derivation of this result is more nuanced than in the classical case due the role played by the input states, the measurement observable, and the fact that the entries of unitary matrices are not independent. An important consequence of our analysis is that the ensuing Gaussian processes cannot be used to efficiently predict the outputs of the QNN via Bayesian statistics. Furthermore, our theorems imply that the concentration of measure phenomenon in Haar random QNNs is much worse than previously thought, as we prove that ex
&lt;/p&gt;</description></item><item><title>PriorCVAE &#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564; MCMC &#21442;&#25968;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#26032;&#26041;&#27861;&#65292;&#21487;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#22788;&#29702;&#36229;&#21442;&#25968;&#25512;&#26029;&#19982;&#23398;&#20064;&#20808;&#39564;&#20043;&#38388;&#30340;&#20449;&#24687;&#27969;&#26029;&#35010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.04307</link><description>&lt;p&gt;
PriorCVAE: &#22522;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#30340;&#21487;&#25193;&#23637; MCMC &#21442;&#25968;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PriorCVAE: scalable MCMC parameter inference with Bayesian deep generative modelling. (arXiv:2304.04307v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04307
&lt;/p&gt;
&lt;p&gt;
PriorCVAE &#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564; MCMC &#21442;&#25968;&#25512;&#26029;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#26032;&#26041;&#27861;&#65292;&#21487;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#22788;&#29702;&#36229;&#21442;&#25968;&#25512;&#26029;&#19982;&#23398;&#20064;&#20808;&#39564;&#20043;&#38388;&#30340;&#20449;&#24687;&#27969;&#26029;&#35010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#25512;&#29702;&#36895;&#24230;&#21644;&#27169;&#22411;&#28789;&#27963;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#20855;&#26377;&#38543;&#26426;&#36807;&#31243;&#20808;&#39564;&#30340;&#27169;&#22411;&#20013;&#65288;&#22914;&#39640;&#26031;&#36807;&#31243;&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#31561;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#32534;&#30721;&#30001; GP &#20808;&#39564;&#25110;&#20854;&#26377;&#38480;&#23454;&#29616;&#24341;&#36215;&#30340;&#35745;&#31639;&#29942;&#39048;&#65292;&#24182;&#19988;&#25152;&#23398;&#29983;&#25104;&#22120;&#21487;&#20197;&#20195;&#26367; MCMC &#25512;&#26029;&#20013;&#30340;&#21407;&#22987;&#20808;&#39564;&#12290;&#34429;&#28982;&#27492;&#26041;&#27861;&#23454;&#29616;&#20102;&#24555;&#36895;&#32780;&#39640;&#25928;&#30340;&#25512;&#29702;&#65292;&#20294;&#23427;&#20002;&#22833;&#20102;&#20851;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#20449;&#24687;&#65292;&#23548;&#33268;&#36229;&#21442;&#25968;&#25512;&#26029;&#19981;&#21487;&#33021;&#21644;&#23398;&#21040;&#30340;&#20808;&#39564;&#27169;&#31946;&#19981;&#28165;&#12290;&#25105;&#20204;&#24314;&#35758;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558; VAE &#24314;&#27169;&#26465;&#20214;&#21270;&#20110;&#38543;&#26426;&#36807;&#31243;&#36229;&#21442;&#25968;&#65292;&#20197;&#20415;&#36229;&#21442;&#25968;&#19982; GP &#23454;&#29616;&#19968;&#36215;&#36827;&#34892;&#32534;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
In applied fields where the speed of inference and model flexibility are crucial, the use of Bayesian inference for models with a stochastic process as their prior, e.g. Gaussian processes (GPs) is ubiquitous. Recent literature has demonstrated that the computational bottleneck caused by GP priors or their finite realizations can be encoded using deep generative models such as variational autoencoders (VAEs), and the learned generators can then be used instead of the original priors during Markov chain Monte Carlo (MCMC) inference in a drop-in manner. While this approach enables fast and highly efficient inference, it loses information about the stochastic process hyperparameters, and, as a consequence, makes inference over hyperparameters impossible and the learned priors indistinct. We propose to resolve the aforementioned issue and disentangle the learned priors by conditioning the VAE on stochastic process hyperparameters. This way, the hyperparameters are encoded alongside GP real
&lt;/p&gt;</description></item></channel></rss>