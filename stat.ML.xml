<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#24037;&#20316;&#21033;&#29992;PAC-Bayesian&#29702;&#35770;&#20026;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#21253;&#25324;&#23545;&#21518;&#39564;&#20998;&#24067;&#12289;&#37325;&#26500;&#25439;&#22833;&#21644;&#36755;&#20837;&#19982;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.04935</link><description>&lt;p&gt;
&#20351;&#29992;PAC-Bayesian&#29702;&#35770;&#32473;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory. (arXiv:2310.04935v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04935
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#21033;&#29992;PAC-Bayesian&#29702;&#35770;&#20026;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#21253;&#25324;&#23545;&#21518;&#39564;&#20998;&#24067;&#12289;&#37325;&#26500;&#25439;&#22833;&#21644;&#36755;&#20837;&#19982;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;&#23427;&#20204;&#30340;&#38382;&#19990;&#20197;&#26469;&#65292;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21464;&#24471;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;&#23427;&#20204;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20851;&#20110;&#23427;&#20204;&#30340;&#29702;&#35770;&#24615;&#36136;&#20173;&#23384;&#22312;&#35768;&#22810;&#38382;&#39064;&#12290;&#26412;&#25991;&#21033;&#29992;PAC-Bayesian&#29702;&#35770;&#20026;VAEs&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22522;&#20110;&#29420;&#31435;&#26679;&#26412;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#39318;&#20010;PAC-Bayesian&#30028;&#38480;&#12290;&#28982;&#21518;&#65292;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#20026;VAE&#30340;&#37325;&#26500;&#25439;&#22833;&#25552;&#20379;&#20102;&#27867;&#21270;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36755;&#20837;&#20998;&#24067;&#19982;VAE&#29983;&#25104;&#27169;&#22411;&#23450;&#20041;&#30340;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36755;&#20837;&#20998;&#24067;&#19982;VAE&#29983;&#25104;&#27169;&#22411;&#23450;&#20041;&#30340;&#20998;&#24067;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since their inception, Variational Autoencoders (VAEs) have become central in machine learning. Despite their widespread use, numerous questions regarding their theoretical properties remain open. Using PAC-Bayesian theory, this work develops statistical guarantees for VAEs. First, we derive the first PAC-Bayesian bound for posterior distributions conditioned on individual samples from the data-generating distribution. Then, we utilize this result to develop generalization guarantees for the VAE's reconstruction loss, as well as upper bounds on the distance between the input and the regenerated distributions. More importantly, we provide upper bounds on the Wasserstein distance between the input distribution and the distribution defined by the VAE's generative model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.03234</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#12290;&#30001;&#20110;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#20197;&#21450;&#20854;&#35299;&#20915;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;FCCO&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;FCCO&#30340;&#30740;&#31350;&#20551;&#35774;&#20869;&#22806;&#20989;&#25968;&#37117;&#26159;&#20809;&#28369;&#30340;&#65292;&#38480;&#21046;&#20102;&#20854;&#33021;&#22815;&#35299;&#20915;&#26356;&#22810;&#31181;&#31867;&#30340;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#35282;&#24230;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#20854;&#20013;&#22806;&#20989;&#25968;&#26159;&#24369;&#20984;&#19988;&#38750;&#36882;&#20943;&#30340;&#65292;&#20869;&#20989;&#25968;&#26159;&#24369;&#20984;&#30340;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20854;&#22312;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates new families of compositional optimization problems, called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\epsilon$-stationary point of the Moreau env
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#27531;&#24046;&#20998;&#25903;&#23610;&#24230;&#21644;$\mu$P&#21442;&#25968;&#21270;&#30340;&#27531;&#24046;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#30340;&#36328;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2309.16620</link><description>&lt;p&gt;
&#27531;&#24046;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36229;&#21442;&#25968;&#36716;&#31227;&#65306;&#21160;&#24577;&#21644;&#32553;&#25918;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16620
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#27531;&#24046;&#20998;&#25903;&#23610;&#24230;&#21644;$\mu$P&#21442;&#25968;&#21270;&#30340;&#27531;&#24046;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#30340;&#36328;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#65292;&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#25104;&#26412;&#19981;&#26029;&#19978;&#21319;&#65292;&#20419;&#20351;&#20174;&#19994;&#32773;&#23547;&#25214;&#20351;&#29992;&#36739;&#23567;&#32593;&#32476;&#30340;&#20195;&#29702;&#26041;&#27861;&#36827;&#34892;&#35843;&#25972;&#12290;&#20854;&#20013;&#19968;&#20010;&#24314;&#35758;&#20351;&#29992;$\mu$P&#21442;&#25968;&#21270;&#32593;&#32476;&#65292;&#20854;&#20013;&#23567;&#23485;&#24230;&#32593;&#32476;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#36716;&#31227;&#21040;&#20219;&#24847;&#23485;&#24230;&#30340;&#32593;&#32476;&#20013;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#26041;&#26696;&#20013;&#65292;&#36229;&#21442;&#25968;&#19981;&#20250;&#22312;&#19981;&#21516;&#28145;&#24230;&#20043;&#38388;&#36716;&#31227;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;$1/\sqrt{\text{depth}}$&#30340;&#27531;&#24046;&#20998;&#25903;&#23610;&#24230;&#21644;$\mu$P&#21442;&#25968;&#21270;&#30340;&#27531;&#24046;&#32593;&#32476;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#20351;&#29992;&#36825;&#31181;&#21442;&#25968;&#21270;&#35757;&#32451;&#30340;&#27531;&#24046;&#32467;&#26500;&#65292;&#21253;&#25324;&#21367;&#31215;ResNet&#21644;Vision Transformer&#65292;&#22312;CIFAR-10&#21644;ImageNet&#19978;&#23637;&#31034;&#20102;&#36328;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#36716;&#31227;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32463;&#39564;&#21457;&#29616;&#24471;&#21040;&#20102;&#29702;&#35770;&#30340;&#25903;&#25345;&#21644;&#21160;&#26426;&#12290;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#25551;&#36848;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;
&lt;/p&gt;
&lt;p&gt;
The cost of hyperparameter tuning in deep learning has been rising with model sizes, prompting practitioners to find new tuning methods using a proxy of smaller networks. One such proposal uses $\mu$P parameterized networks, where the optimal hyperparameters for small width networks transfer to networks with arbitrarily large width. However, in this scheme, hyperparameters do not transfer across depths. As a remedy, we study residual networks with a residual branch scale of $1/\sqrt{\text{depth}}$ in combination with the $\mu$P parameterization. We provide experiments demonstrating that residual architectures including convolutional ResNets and Vision Transformers trained with this parameterization exhibit transfer of optimal hyperparameters across width and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings are supported and motivated by theory. Using recent developments in the dynamical mean field theory (DMFT) description of neural network learning dynamics, we show
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#22240;&#26524;&#25512;&#35770;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#22240;&#26524;&#25490;&#24207;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#33258;&#22238;&#24402;&#24402;&#19968;&#21270;&#27969;&#21487;&#20197;&#24674;&#22797;&#22240;&#26524;&#27169;&#22411;&#12290;&#36890;&#36807;&#23454;&#39564;&#21644;&#27604;&#36739;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#21487;&#29992;&#20110;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.05415</link><description>&lt;p&gt;
&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#65306;&#20174;&#29702;&#35770;&#21040;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Causal normalizing flows: from theory to practice. (arXiv:2306.05415v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#22240;&#26524;&#25512;&#35770;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#22240;&#26524;&#25490;&#24207;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#33258;&#22238;&#24402;&#24402;&#19968;&#21270;&#27969;&#21487;&#20197;&#24674;&#22797;&#22240;&#26524;&#27169;&#22411;&#12290;&#36890;&#36807;&#23454;&#39564;&#21644;&#27604;&#36739;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#21487;&#29992;&#20110;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#25506;&#35752;&#20102;&#21033;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#22240;&#26524;&#25512;&#35770;&#30340;&#24212;&#29992;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#21033;&#29992;&#38750;&#32447;&#24615;ICA&#30340;&#26368;&#26032;&#32467;&#26524;&#65292;&#26174;&#31034;&#20986;&#22312;&#32473;&#23450;&#22240;&#26524;&#25490;&#24207;&#30340;&#24773;&#20917;&#19979;&#65292;&#22240;&#26524;&#27169;&#22411;&#21487;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#37492;&#21035;&#20986;&#26469;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#33258;&#22238;&#24402;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#24674;&#22797;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#29992;&#20110;&#25429;&#25417;&#28508;&#22312;&#22240;&#26524;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#19981;&#21516;&#35774;&#35745;&#21644;&#23398;&#20064;&#36873;&#25321;&#30340;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#22312;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#20013;&#23454;&#29616;do-operator&#65292;&#20174;&#32780;&#22238;&#31572;&#24178;&#39044;&#21644;&#21453;&#20107;&#23454;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#32508;&#21512;&#23545;&#27604;&#30740;&#31350;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#35774;&#35745;&#21644;&#35757;&#32451;&#36873;&#25321;&#65307;&#23558;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#19982;&#20854;&#20182;&#36924;&#36817;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#65307;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#22240;&#26524;&#24402;&#19968;&#21270;&#27969;&#21487;&#29992;&#20110;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#20013;&#23384;&#22312;&#28151;&#21512;&#31163;&#25955;&#36830;&#32493;&#25968;&#25454;&#21644;&#22240;&#26524;&#22270;&#37096;&#20998;&#30693;&#35782;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#30340;&#20195;&#30721;&#21487;&#20197;&#36827;&#34892;&#35775;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we deepen on the use of normalizing flows for causal reasoning. Specifically, we first leverage recent results on non-linear ICA to show that causal models are identifiable from observational data given a causal ordering, and thus can be recovered using autoregressive normalizing flows (NFs). Second, we analyze different design and learning choices for causal normalizing flows to capture the underlying causal data-generating process. Third, we describe how to implement the do-operator in causal NFs, and thus, how to answer interventional and counterfactual questions. Finally, in our experiments, we validate our design and training choices through a comprehensive ablation study; compare causal NFs to other approaches for approximating causal models; and empirically demonstrate that causal NFs can be used to address real-world problems, where the presence of mixed discrete-continuous data and partial knowledge on the causal graph is the norm. The code for this work can be f
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#33021;&#22312;&#21463;&#38480;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#24471;&#21040;&#26657;&#20934;&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#23616;&#37096;&#26368;&#20248;&#26465;&#20214;&#21462;&#20195;&#20840;&#23616;&#26368;&#20248;&#24615;&#26465;&#20214;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2305.18764</link><description>&lt;p&gt;
&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#33021;&#24471;&#21040;&#26657;&#20934;&#30340;&#39044;&#27979;&#22120;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Optimizing a Proper Loss Yield Calibration?. (arXiv:2305.18764v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18764
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#21542;&#33021;&#22312;&#21463;&#38480;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#24471;&#21040;&#26657;&#20934;&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#23616;&#37096;&#26368;&#20248;&#26465;&#20214;&#21462;&#20195;&#20840;&#23616;&#26368;&#20248;&#24615;&#26465;&#20214;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#36866;&#24403;&#30340;&#25439;&#22833;&#20989;&#25968;&#34987;&#24191;&#27867;&#35748;&#20026;&#20250;&#24471;&#21040;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#29305;&#24615;&#30340;&#39044;&#27979;&#22120;&#65292;&#36825;&#26159;&#22240;&#20026;&#23545;&#20110;&#36825;&#26679;&#30340;&#25439;&#22833;&#65292;&#20840;&#23616;&#26368;&#20248;&#35299;&#26159;&#39044;&#27979;&#30495;&#23454;&#27010;&#29575;&#65292;&#36825;&#30830;&#23454;&#26159;&#26657;&#20934;&#30340;&#12290;&#20294;&#26159;&#65292;&#20856;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#35757;&#32451;&#26469;&#36817;&#20284;&#22320;&#26368;&#23567;&#21270;&#22312;&#21463;&#38480;&#21046;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#30340;&#25439;&#22833;&#65292;&#36825;&#20123;&#39044;&#27979;&#22120;&#26063;&#19981;&#22826;&#21487;&#33021;&#21253;&#21547;&#30495;&#23454;&#30340;&#27010;&#29575;&#12290;&#22312;&#20160;&#20040;&#24773;&#20917;&#19979;&#65292;&#20248;&#21270;&#21463;&#38480;&#21046;&#30340;&#39044;&#27979;&#22120;&#26063;&#20013;&#36866;&#24403;&#30340;&#25439;&#22833;&#21487;&#20197;&#24471;&#21040;&#26657;&#20934;&#30340;&#27169;&#22411;&#65311;&#23427;&#25552;&#20379;&#20102;&#20160;&#20040;&#31934;&#30830;&#30340;&#26657;&#20934;&#20445;&#35777;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#20123;&#38382;&#39064;&#30340;&#20005;&#26684;&#31572;&#26696;&#12290;&#25105;&#20204;&#29992;&#23616;&#37096;&#26368;&#20248;&#26465;&#20214;&#26367;&#25442;&#20840;&#23616;&#26368;&#20248;&#24615;&#26465;&#20214;&#65292;&#35813;&#26465;&#20214;&#35268;&#23450;&#20102;&#39044;&#27979;&#22120;&#65288;&#36866;&#24403;&#30340;&#65289;&#25439;&#22833;&#19981;&#33021;&#36890;&#36807;&#20351;&#29992;&#19968;&#23450;&#26063;&#32676;&#30340;Lipschitz&#20989;&#25968;&#21518;&#22788;&#29702;&#20854;&#39044;&#27979;&#32780;&#38477;&#20302;&#22826;&#22810;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#36825;&#31181;&#23616;&#37096;&#26368;&#20248;&#24615;&#36136;&#30340;&#20219;&#20309;&#39044;&#27979;&#22120;&#37117;&#28385;&#36275;Kakade-Foster(2008)&#12289;B&#322;asiok&#31561;&#20154;(2023)&#20013;&#23450;&#20041;&#30340;&#24179;&#31283;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimizing proper loss functions is popularly believed to yield predictors with good calibration properties; the intuition being that for such losses, the global optimum is to predict the ground-truth probabilities, which is indeed calibrated. However, typical machine learning models are trained to approximately minimize loss over restricted families of predictors, that are unlikely to contain the ground truth. Under what circumstances does optimizing proper loss over a restricted family yield calibrated models? What precise calibration guarantees does it give? In this work, we provide a rigorous answer to these questions. We replace the global optimality with a local optimality condition stipulating that the (proper) loss of the predictor cannot be reduced much by post-processing its predictions with a certain family of Lipschitz functions. We show that any predictor with this local optimality satisfies smooth calibration as defined in Kakade-Foster (2008), B{\l}asiok et al. (2023). L
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#23545;&#20110;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#65292;&#26368;&#20248;&#22320;&#26368;&#23567;&#21270;&#25439;&#22833;&#20250;&#23548;&#33268;&#22810;&#26657;&#20934;&#65292;&#20197;&#25552;&#20379;&#20844;&#24179;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.09424</link><description>&lt;p&gt;
&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#26657;&#20934;&#21487;&#26368;&#23567;&#21270;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Loss minimization yields multicalibration for large neural networks. (arXiv:2304.09424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#23545;&#20110;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#65292;&#26368;&#20248;&#22320;&#26368;&#23567;&#21270;&#25439;&#22833;&#20250;&#23548;&#33268;&#22810;&#26657;&#20934;&#65292;&#20197;&#25552;&#20379;&#20844;&#24179;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26657;&#20934;&#26159;&#19968;&#31181;&#20844;&#24179;&#24615;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#20379;&#36328;&#22823;&#37327;&#22242;&#20307;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;&#21363;&#20351;&#23545;&#20110;&#31616;&#21333;&#30340;&#39044;&#27979;&#22120;&#65292;&#22914;&#32447;&#24615;&#20989;&#25968;&#65292;&#22810;&#26657;&#20934;&#20063;&#34987;&#35748;&#20026;&#26159;&#19982;&#26368;&#23567;&#21270;&#25439;&#22833;&#19981;&#21516;&#30340;&#30446;&#26631;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#65288;&#20960;&#20046;&#25152;&#26377;&#30340;&#65289;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#65292;&#26368;&#20248;&#22320;&#26368;&#23567;&#21270;&#24179;&#26041;&#35823;&#24046;&#20250;&#23548;&#33268;&#22810;&#26657;&#20934;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#24449;&#26041;&#38754;&#65292;&#32780;&#19981;&#26159;&#20851;&#20110;&#31639;&#27861;&#25110;&#26679;&#26412;&#22797;&#26434;&#24615;&#32771;&#34385;&#12290;&#20197;&#21069;&#30340;&#36825;&#26679;&#30340;&#32467;&#26524;&#20165;&#36866;&#29992;&#20110;&#20960;&#20046;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#39044;&#27979;&#22120;&#65292;&#22240;&#27492;&#26159;&#34920;&#24449;&#26080;&#20851;&#30340;&#12290;&#25105;&#20204;&#24378;&#35843;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#36866;&#29992;&#20110;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#31639;&#27861;&#65292;&#22914; SGD&#65292;&#24182;&#19988;&#19981;&#24212;&#35299;&#37322;&#20026;&#8220;&#20844;&#24179;&#24615;&#20174;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#33719;&#24471;&#20813;&#36153;&#30340;&#22909;&#22788;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multicalibration is a notion of fairness that aims to provide accurate predictions across a large set of groups. Multicalibration is known to be a different goal than loss minimization, even for simple predictors such as linear functions. In this note, we show that for (almost all) large neural network sizes, optimally minimizing squared error leads to multicalibration. Our results are about representational aspects of neural networks, and not about algorithmic or sample complexity considerations. Previous such results were known only for predictors that were nearly Bayes-optimal and were therefore representation independent. We emphasize that our results do not apply to specific algorithms for optimizing neural networks, such as SGD, and they should not be interpreted as "fairness comes for free from optimizing neural networks".
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#34920;&#36798;&#21147;&#24378;&#22823;&#30340;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#65292;&#23454;&#29616;&#20102;&#23545;&#25972;&#20010;&#20307;&#31995;&#32467;&#26500;&#30340;&#25628;&#32034;&#24182;&#20419;&#36827;&#32467;&#26500;&#30340;&#35268;&#24459;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.01842</link><description>&lt;p&gt;
&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#30340;&#20998;&#23618;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#26500;&#24314;
&lt;/p&gt;
&lt;p&gt;
Construction of Hierarchical Neural Architecture Search Spaces based on Context-free Grammars. (arXiv:2211.01842v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#34920;&#36798;&#21147;&#24378;&#22823;&#30340;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#65292;&#23454;&#29616;&#20102;&#23545;&#25972;&#20010;&#20307;&#31995;&#32467;&#26500;&#30340;&#25628;&#32034;&#24182;&#20419;&#36827;&#32467;&#26500;&#30340;&#35268;&#24459;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#31616;&#21333;&#30340;&#26500;&#24314;&#22359;&#20013;&#21457;&#29616;&#31070;&#32463;&#32467;&#26500;&#26159;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;(NAS)&#30340;&#19968;&#20010;&#38271;&#26399;&#30446;&#26631;&#12290;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#26159;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#27493;&#39588;&#65292;&#20294;&#32570;&#20047;&#32479;&#19968;&#30340;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#24182;&#19988;&#36890;&#24120;&#20165;&#25628;&#32034;&#19968;&#20123;&#38480;&#23450;&#26041;&#38754;&#30340;&#26550;&#26500;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#26080;&#19978;&#19979;&#25991;&#25991;&#27861;&#30340;&#32479;&#19968;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#33258;&#28982;&#32780;&#32039;&#20945;&#22320;&#29983;&#25104;&#34920;&#36798;&#21147;&#24378;&#22823;&#30340;&#20998;&#23618;&#25628;&#32034;&#31354;&#38388;&#65292;&#27604;&#25991;&#29486;&#20013;&#24120;&#35265;&#30340;&#31354;&#38388;&#22823;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;&#36890;&#36807;&#22686;&#24378;&#21644;&#21033;&#29992;&#23427;&#20204;&#30340;&#23646;&#24615;&#65292;&#25105;&#20204;&#26377;&#25928;&#22320;&#23454;&#29616;&#20102;&#23545;&#25972;&#20010;&#20307;&#31995;&#32467;&#26500;&#30340;&#25628;&#32034;&#65292;&#24182;&#20419;&#36827;&#20102;&#32467;&#26500;&#30340;&#35268;&#24459;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#23618;&#26680;&#35774;&#35745;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#25628;&#32034;&#31574;&#30053;&#65292;&#20197;&#39640;&#25928;&#25628;&#32034;&#22914;&#27492;&#24222;&#22823;&#30340;&#31354;&#38388;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25628;&#32034;&#31354;&#38388;&#35774;&#35745;&#26694;&#26550;&#30340;&#22810;&#26679;&#24615;&#65292;&#24182;&#34920;&#26126;&#25105;&#20204;&#30340;&#25628;&#32034;&#31574;&#30053;&#21487;&#20197;&#20248;&#20110;&#29616;&#26377;&#30340;NAS&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The discovery of neural architectures from simple building blocks is a long-standing goal of Neural Architecture Search (NAS). Hierarchical search spaces are a promising step towards this goal but lack a unifying search space design framework and typically only search over some limited aspect of architectures. In this work, we introduce a unifying search space design framework based on context-free grammars that can naturally and compactly generate expressive hierarchical search spaces that are 100s of orders of magnitude larger than common spaces from the literature. By enhancing and using their properties, we effectively enable search over the complete architecture and can foster regularity. Further, we propose an efficient hierarchical kernel design for a Bayesian Optimization search strategy to efficiently search over such huge spaces. We demonstrate the versatility of our search space design framework and show that our search strategy can be superior to existing NAS approaches. Co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;MLE&#20844;&#24335;&#24182;&#20174;&#22810;&#20010;&#39057;&#29575;&#30340;&#20449;&#24687;&#20013;&#21463;&#30410;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#30456;&#23545;&#30456;&#20301;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2206.12276</link><description>&lt;p&gt;
&#22810;&#39057;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;
&lt;/p&gt;
&lt;p&gt;
Multi-Frequency Joint Community Detection and Phase Synchronization. (arXiv:2206.12276v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.12276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;MLE&#20844;&#24335;&#24182;&#20174;&#22810;&#20010;&#39057;&#29575;&#30340;&#20449;&#24687;&#20013;&#21463;&#30410;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#30456;&#23545;&#30456;&#20301;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes two simple and efficient algorithms that leverage the MLE formulation and benefit from the information across multiple frequencies to solve the joint community detection and phase synchronization problem on the stochastic block model with relative phase.
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#30456;&#23545;&#30456;&#20301;&#30340;&#38543;&#26426;&#22359;&#27169;&#22411;&#19978;&#30340;&#32852;&#21512;&#31038;&#21306;&#26816;&#27979;&#21644;&#30456;&#20301;&#21516;&#27493;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#33410;&#28857;&#37117;&#19982;&#19968;&#20010;&#26410;&#30693;&#30340;&#30456;&#20301;&#35282;&#30456;&#20851;&#32852;&#12290;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#22810;&#31181;&#23454;&#38469;&#24212;&#29992;&#65292;&#26088;&#22312;&#21516;&#26102;&#24674;&#22797;&#31751;&#32467;&#26500;&#21644;&#30456;&#20851;&#30340;&#30456;&#20301;&#35282;&#12290;&#25105;&#20204;&#36890;&#36807;&#20180;&#32454;&#30740;&#31350;&#20854;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#20844;&#24335;&#65292;&#23637;&#31034;&#20102;&#36825;&#20010;&#38382;&#39064;&#21576;&#29616;&#20986;&#8220;&#22810;&#39057;&#8221;&#32467;&#26500;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#24182;&#38750;&#28304;&#20110;&#36825;&#20010;&#35282;&#24230;&#12290;&#20026;&#27492;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;MLE&#20844;&#24335;&#24182;&#20174;&#22810;&#20010;&#39057;&#29575;&#30340;&#20449;&#24687;&#20013;&#21463;&#30410;&#12290;&#21069;&#32773;&#26159;&#22522;&#20110;&#26032;&#39062;&#30340;&#22810;&#39057;&#21015;&#20027;&#20803;QR&#20998;&#35299;&#30340;&#35889;&#26041;&#27861;&#12290;&#24212;&#29992;&#20110;&#35266;&#27979;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#30340;&#20998;&#35299;&#25552;&#20379;&#20102;&#26377;&#20851;&#31751;&#32467;&#26500;&#21644;&#30456;&#20851;&#30456;&#20301;&#35282;&#30340;&#20851;&#38190;&#20449;&#24687;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#26159;&#36845;&#20195;&#30340;&#22810;&#39057;&#29575;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the joint community detection and phase synchronization problem on the stochastic block model with relative phase, where each node is associated with an unknown phase angle. This problem, with a variety of real-world applications, aims to recover the cluster structure and associated phase angles simultaneously. We show this problem exhibits a ``multi-frequency'' structure by closely examining its maximum likelihood estimation (MLE) formulation, whereas existing methods are not originated from this perspective. To this end, two simple yet efficient algorithms that leverage the MLE formulation and benefit from the information across multiple frequencies are proposed. The former is a spectral method based on the novel multi-frequency column-pivoted QR factorization. The factorization applied to the top eigenvectors of the observation matrix provides key information about the cluster structure and associated phase angles. The second approach is an iterative multi-frequen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#21152;&#24615;&#27169;&#22411;&#65292;&#20351;&#29992;&#23569;&#37327;&#20027;&#35201;&#21644;&#25104;&#23545;&#20132;&#20114;&#25928;&#24212;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#26131;&#20110;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#30340;&#39044;&#27979;&#38754;&#65292;&#24182;&#21462;&#24471;&#20102; ROAM &#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21487;&#20197;&#25552;&#20379;&#25913;&#36827;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#21644;&#20854;&#20182;&#35843;&#26597;&#30340;&#21453;&#24212;&#29575;&#35758;&#35770;&#12290;</title><link>http://arxiv.org/abs/2108.11328</link><description>&lt;p&gt;
&#29992;&#31616;&#27905;&#21487;&#35299;&#37322;&#30340;&#21152;&#24615;&#27169;&#22411;&#21644;&#32467;&#26500;&#20132;&#20114;&#39044;&#27979;&#20154;&#21475;&#26222;&#26597;&#35843;&#26597;&#21453;&#24212;&#29575;
&lt;/p&gt;
&lt;p&gt;
Predicting Census Survey Response Rates With Parsimonious Additive Models and Structured Interactions. (arXiv:2108.11328v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.11328
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#21152;&#24615;&#27169;&#22411;&#65292;&#20351;&#29992;&#23569;&#37327;&#20027;&#35201;&#21644;&#25104;&#23545;&#20132;&#20114;&#25928;&#24212;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#29983;&#25104;&#26131;&#20110;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#30340;&#39044;&#27979;&#38754;&#65292;&#24182;&#21462;&#24471;&#20102; ROAM &#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21487;&#20197;&#25552;&#20379;&#25913;&#36827;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#21644;&#20854;&#20182;&#35843;&#26597;&#30340;&#21453;&#24212;&#29575;&#35758;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#19968;&#31995;&#21015;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#38750;&#21442;&#25968;&#27169;&#22411;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#12290;&#26412;&#30740;&#31350;&#21463;&#21040;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#33879;&#21517;&#30340; ROAM &#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#35813;&#24212;&#29992;&#20351;&#29992;&#22312;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#35268;&#21010;&#25968;&#25454;&#24211;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#35782;&#21035;&#38590;&#20197;&#35843;&#26597;&#30340;&#21306;&#22495;&#12290;&#21313;&#24180;&#21069;&#32452;&#32455;&#30340;&#19968;&#22330;&#20247;&#21253;&#31454;&#36187;&#34920;&#26126;&#65292;&#22522;&#20110;&#22238;&#24402;&#26641;&#38598;&#25104;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#39044;&#27979;&#35843;&#26597;&#21453;&#24212;&#29575;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#65307;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30340;&#40657;&#30418;&#29305;&#24615;&#65292;&#30456;&#24212;&#30340;&#27169;&#22411;&#19981;&#33021;&#29992;&#20110;&#25311;&#23450;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992; $\ell_0$-based &#24809;&#32602;&#30340;&#38750;&#21442;&#25968;&#21152;&#24615;&#27169;&#22411;&#65292;&#23427;&#20855;&#26377;&#23569;&#25968;&#20027;&#35201;&#21644;&#25104;&#23545;&#20132;&#20114;&#25928;&#24212;&#12290;&#20174;&#26041;&#27861;&#35770;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25105;&#20204;&#20272;&#35745;&#22120;&#30340;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#65292;&#24182;&#35752;&#35770;&#20102;&#23558;&#24378;&#23618;&#27425;&#20132;&#20114;&#21512;&#24182;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#65288;&#22312;Github &#19978;&#24320;&#28304;&#65289;&#20801;&#35768;&#25105;&#20204;&#29983;&#25104;&#26131;&#20110;&#21487;&#35270;&#21270;&#21644;&#35299;&#37322;&#30340;&#39044;&#27979;&#38754;&#65292;&#20174;&#32780;&#33719;&#24471;&#26377;&#20851;&#35843;&#26597;&#21453;&#24212;&#29575;&#30340;&#21487;&#34892;&#35265;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312; ROAM &#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#21487;&#20197;&#25552;&#20379;&#26377;&#20851;&#32654;&#22269;&#20154;&#21475;&#26222;&#26597;&#23616;&#21644;&#20854;&#20182;&#35843;&#26597;&#30340;&#25913;&#36827;&#35843;&#26597;&#21453;&#24212;&#29575;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider the problem of predicting survey response rates using a family of flexible and interpretable nonparametric models. The study is motivated by the US Census Bureau's well-known ROAM application which uses a linear regression model trained on the US Census Planning Database data to identify hard-to-survey areas. A crowdsourcing competition organized around ten years ago revealed that machine learning methods based on ensembles of regression trees led to the best performance in predicting survey response rates; however, the corresponding models could not be adopted for the intended application due to their black-box nature. We consider nonparametric additive models with small number of main and pairwise interaction effects using $\ell_0$-based penalization. From a methodological viewpoint, we study both computational and statistical aspects of our estimator; and discuss variants that incorporate strong hierarchical interactions. Our algorithms (opensourced on gith
&lt;/p&gt;</description></item></channel></rss>