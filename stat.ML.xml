<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#29616;&#26377;&#23450;&#20041;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.13164</link><description>&lt;p&gt;
&#20960;&#20046;&#31561;&#21464;&#24615;&#36890;&#36807;&#26446;&#20195;&#25968;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Almost Equivariance via Lie Algebra Convolutions. (arXiv:2310.13164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#29616;&#26377;&#23450;&#20041;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#30456;&#23545;&#20110;&#32676;&#20316;&#29992;&#30340;&#31561;&#21464;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#28982;&#32780;&#65292;&#36171;&#20104;&#19968;&#20010;&#26550;&#26500;&#20855;&#20307;&#30340;&#32676;&#31561;&#21464;&#24615;&#23545;&#27169;&#22411;&#25152;&#26399;&#26395;&#30475;&#21040;&#30340;&#25968;&#25454;&#21464;&#25442;&#31867;&#22411;&#26045;&#21152;&#20102;&#24378;&#22823;&#30340;&#20808;&#39564;&#12290;&#20005;&#26684;&#31561;&#21464;&#27169;&#22411;&#24378;&#21046;&#25191;&#34892;&#23545;&#31216;&#24615;&#65292;&#20294;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#24182;&#19981;&#24635;&#26159;&#31526;&#21512;&#36825;&#26679;&#30340;&#20005;&#26684;&#31561;&#21464;&#24615;&#65292;&#21487;&#33021;&#26159;&#22240;&#20026;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25110;&#20165;&#32534;&#30721;&#20102;&#36817;&#20284;&#25110;&#37096;&#20998;&#23545;&#31216;&#24615;&#30340;&#28508;&#22312;&#29289;&#29702;&#23450;&#24459;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20005;&#26684;&#31561;&#21464;&#24615;&#30340;&#20808;&#39564;&#23454;&#38469;&#19978;&#21487;&#33021;&#36807;&#20110;&#24378;&#22823;&#65292;&#23548;&#33268;&#27169;&#22411;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#30456;&#20851;&#30340;&#20027;&#39064;&#65292;&#21363;&#20960;&#20046;&#31561;&#21464;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19982;&#24403;&#21069;&#25991;&#29486;&#20013;&#29616;&#26377;&#23450;&#20041;&#19981;&#21516;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the equivariance of models with respect to a group action has become an important topic of research in machine learning. However, imbuing an architecture with a specific group equivariance imposes a strong prior on the types of data transformations that the model expects to see. While strictly-equivariant models enforce symmetries, real-world data does not always conform to such strict equivariances, be it due to noise in the data or underlying physical laws that encode only approximate or partial symmetries. In such cases, the prior of strict equivariance can actually prove too strong and cause models to underperform on real-world data. Therefore, in this work we study a closely related topic, that of almost equivariance. We provide a definition of almost equivariance that differs from those extant in the current literature and give a practical method for encoding almost equivariance in models by appealing to the Lie algebra of a Lie group. Specifically, we define Lie algebr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25968;&#25454;&#26377;&#38480;&#24773;&#20917;&#19979;&#65292;&#23545;&#39640;&#32500;&#31070;&#32463;&#34920;&#31034;&#36827;&#34892;&#24418;&#29366;&#36317;&#31163;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#23545;&#24418;&#29366;&#36317;&#31163;&#26631;&#20934;&#20272;&#35745;&#22120;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#19978;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#25361;&#25112;&#24615;&#36136;&#12290;&#20026;&#20102;&#20811;&#26381;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#39640;&#32500;&#35774;&#32622;&#19979;&#30456;&#23545;&#20110;&#26631;&#20934;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.05742</link><description>&lt;p&gt;
&#26377;&#38480;&#37319;&#26679;&#19979;&#31070;&#32463;&#34920;&#31034;&#30340;&#24418;&#29366;&#36317;&#31163;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimating Shape Distances on Neural Representations with Limited Samples. (arXiv:2310.05742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#25968;&#25454;&#26377;&#38480;&#24773;&#20917;&#19979;&#65292;&#23545;&#39640;&#32500;&#31070;&#32463;&#34920;&#31034;&#36827;&#34892;&#24418;&#29366;&#36317;&#31163;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#23545;&#24418;&#29366;&#36317;&#31163;&#26631;&#20934;&#20272;&#35745;&#22120;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#19978;&#19979;&#30028;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#25361;&#25112;&#24615;&#36136;&#12290;&#20026;&#20102;&#20811;&#26381;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#39640;&#32500;&#35774;&#32622;&#19979;&#30456;&#23545;&#20110;&#26631;&#20934;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#31185;&#23398;&#21644;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#65292;&#34913;&#37327;&#39640;&#32500;&#32593;&#32476;&#34920;&#31034;&#20043;&#38388;&#30340;&#20960;&#20309;&#30456;&#20284;&#24615;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#30340;&#30740;&#31350;&#20852;&#36259;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#20294;&#21482;&#26377;&#23569;&#25968;&#24037;&#20316;&#23545;&#23427;&#20204;&#30340;&#32479;&#35745;&#25928;&#29575;&#36827;&#34892;&#20102;&#20005;&#26684;&#20998;&#26512;&#65292;&#25110;&#32773;&#23545;&#25968;&#25454;&#26377;&#38480;&#24773;&#20917;&#19979;&#30340;&#20272;&#35745;&#22120;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#37327;&#21270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#26631;&#20934;&#24418;&#29366;&#36317;&#31163;&#20272;&#35745;&#22120;&#65288;&#30001;Williams et al. (2021)&#25552;&#20986;&#65289;&#30340;&#26368;&#22351;&#24773;&#20917;&#25910;&#25947;&#19978;&#19979;&#30028;&#12290;&#36825;&#20123;&#30028;&#38480;&#25581;&#31034;&#20102;&#22312;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#20013;&#36825;&#20010;&#38382;&#39064;&#30340;&#25361;&#25112;&#24615;&#36136;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#21487;&#35843;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#20272;&#35745;&#22120;&#22312;&#27169;&#25311;&#21644;&#31070;&#32463;&#25968;&#25454;&#19978;&#30456;&#23545;&#20110;&#26631;&#20934;&#20272;&#35745;&#22120;&#22312;&#39640;&#32500;&#35774;&#32622;&#19979;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20026;&#39640;&#32500;&#24418;&#29366;&#20998;&#26512;&#22880;&#23450;&#20102;&#20005;&#26684;&#30340;&#32479;&#35745;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measuring geometric similarity between high-dimensional network representations is a topic of longstanding interest to neuroscience and deep learning. Although many methods have been proposed, only a few works have rigorously analyzed their statistical efficiency or quantified estimator uncertainty in data-limited regimes. Here, we derive upper and lower bounds on the worst-case convergence of standard estimators of shape distance$\unicode{x2014}$a measure of representational dissimilarity proposed by Williams et al. (2021). These bounds reveal the challenging nature of the problem in high-dimensional feature spaces. To overcome these challenges, we introduce a new method-of-moments estimator with a tunable bias-variance tradeoff. We show that this estimator achieves superior performance to standard estimators in simulation and on neural data, particularly in high-dimensional settings. Thus, we lay the foundation for a rigorous statistical theory for high-dimensional shape analysis, an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24369;&#20998;&#24067;&#19981;&#21464;&#24615;&#36827;&#34892;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#34701;&#20837;&#36825;&#31181;&#19981;&#21464;&#24615;&#30340;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#21487;&#38752;&#22320;&#35782;&#21035;&#20986;&#31283;&#23450;&#30340;&#21464;&#37327;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2310.02854</link><description>&lt;p&gt;
&#36890;&#36807;&#24369;&#20998;&#24067;&#19981;&#21464;&#24615;&#23454;&#29616;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Domain Causal Representation Learning via Weak Distributional Invariances. (arXiv:2310.02854v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24369;&#20998;&#24067;&#19981;&#21464;&#24615;&#36827;&#34892;&#22810;&#39046;&#22495;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#34701;&#20837;&#36825;&#31181;&#19981;&#21464;&#24615;&#30340;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#21487;&#38752;&#22320;&#35782;&#21035;&#20986;&#31283;&#23450;&#30340;&#21464;&#37327;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#24050;&#25104;&#20026;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#26680;&#24515;&#12290;&#29305;&#21035;&#26159;&#65292;&#22810;&#39046;&#22495;&#25968;&#25454;&#38598;&#20026;&#23637;&#31034;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30456;&#23545;&#20110;&#26631;&#20934;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#20248;&#21183;&#25552;&#20379;&#20102;&#33258;&#28982;&#26426;&#20250;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#30740;&#31350;&#22312;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#36807;&#20110;&#31616;&#21270;&#25968;&#25454;&#30340;&#20551;&#35774;&#65292;&#23427;&#20204;&#24448;&#24448;&#19981;&#33021;&#36866;&#29992;&#20110;&#22810;&#39046;&#22495;&#25968;&#25454;&#38598;&#65307;&#20363;&#22914;&#65292;&#27599;&#20010;&#39046;&#22495;&#37117;&#26469;&#33258;&#19981;&#21516;&#30340;&#21333;&#33410;&#28857;&#23436;&#32654;&#24178;&#39044;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#24182;&#21033;&#29992;&#20197;&#19979;&#35266;&#23519;&#32467;&#26524;&#65306;&#22312;&#22810;&#39046;&#22495;&#25968;&#25454;&#20013;&#65292;&#24448;&#24448;&#23384;&#22312;&#19968;&#37096;&#20998;&#28508;&#21464;&#37327;&#30340;&#26576;&#20123;&#20998;&#24067;&#23646;&#24615;&#65288;&#20363;&#22914;&#25903;&#25345;&#24230;&#12289;&#26041;&#24046;&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#20043;&#38388;&#20445;&#25345;&#31283;&#23450;&#65307;&#24403;&#27599;&#20010;&#39046;&#22495;&#26469;&#33258;&#22810;&#33410;&#28857;&#19981;&#23436;&#32654;&#24178;&#39044;&#26102;&#65292;&#36825;&#20010;&#23646;&#24615;&#25104;&#31435;&#12290;&#21033;&#29992;&#36825;&#20010;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#34701;&#20837;&#36825;&#31181;&#19981;&#21464;&#24615;&#30340;&#33258;&#32534;&#30721;&#22120;&#33021;&#22815;&#21487;&#38752;&#22320;&#35782;&#21035;&#20986;&#31283;&#23450;&#30340;&#21464;&#37327;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.13775</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;The Rashomon Importance Distribution: &#25670;&#33073;&#19981;&#31283;&#23450;&#30340;&#22522;&#20110;&#21333;&#19968;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance. (arXiv:2309.13775v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13775
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#23545;&#20110;&#22238;&#31572;&#36951;&#20256;&#23398;&#12289;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#23398;&#31561;&#39046;&#22495;&#30340;&#37325;&#22823;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#35745;&#31639;&#32473;&#23450;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#32473;&#23450;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#38598;&#65292;&#21487;&#33021;&#26377;&#35768;&#22810;&#27169;&#22411;&#21516;&#26679;&#33021;&#35299;&#37322;&#30446;&#26631;&#32467;&#26524;;&#22914;&#26524;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#35299;&#37322;&#65292;&#19981;&#21516;&#30340;&#30740;&#31350;&#32773;&#21487;&#33021;&#20250;&#24471;&#20986;&#35768;&#22810;&#20914;&#31361;&#20294;&#21516;&#26679;&#26377;&#25928;&#30340;&#32467;&#35770;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#32771;&#34385;&#20102;&#32473;&#23450;&#25968;&#25454;&#38598;&#30340;&#25152;&#26377;&#21487;&#33021;&#35299;&#37322;&#65292;&#36825;&#20123;&#27934;&#23519;&#21147;&#21487;&#33021;&#19981;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#22240;&#20026;&#24182;&#38750;&#25152;&#26377;&#22909;&#30340;&#35299;&#37322;&#22312;&#21512;&#29702;&#30340;&#25968;&#25454;&#25200;&#21160;&#19979;&#37117;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#37327;&#21270;&#20102;&#22312;&#25152;&#26377;&#22909;&#30340;&#27169;&#22411;&#38598;&#21512;&#20013;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#38750;&#24120;&#28789;&#27963;&#65292;&#21487;&#20197;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We d
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.06399</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#23398;&#20064;&#20855;&#26377;&#24322;&#26500;&#20892;&#19994;&#25968;&#25454;&#38598;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28041;&#21450;&#22810;&#26679;&#20294;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#20013;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#19982;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#32852;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#65292;&#22312;&#21253;&#25324;&#20892;&#23398;&#30740;&#31350;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#37117;&#24456;&#26222;&#36941;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24120;&#24120;&#20351;&#29992;&#23618;&#27425;&#27169;&#22411;&#65292;&#20063;&#34987;&#31216;&#20026;&#22810;&#23618;&#27169;&#22411;&#65292;&#26469;&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#36866;&#24212;&#23427;&#20204;&#30340;&#19981;&#21516;&#29305;&#28857;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#32467;&#26500;&#36229;&#20986;&#20102;&#31616;&#21333;&#30340;&#24322;&#36136;&#24615;&#65292;&#22240;&#20026;&#21464;&#37327;&#36890;&#24120;&#24418;&#25104;&#22797;&#26434;&#30340;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#12290;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#26469;&#27169;&#25311;&#36825;&#31181;&#20851;&#31995;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38543;&#26426;&#25928;&#24212;&#25972;&#21512;&#21040;BN&#23398;&#20064;&#20013;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#23618;&#27425;&#25968;&#25454;&#12290;&#26469;&#33258;&#30495;&#23454;&#20892;&#23398;&#35797;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22686;&#24378;&#32467;&#26500;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
&lt;/p&gt;</description></item><item><title>&#21452;&#21521;&#27880;&#24847;&#21147;&#27169;&#22411;&#20855;&#26377;&#28151;&#21512;&#19987;&#23478;&#26435;&#37325;&#65292;&#31867;&#20284;&#20110;&#36830;&#32493;&#35789;&#34955;&#27169;&#22411;&#65288;CBOW&#65289;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#23427;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.04057</link><description>&lt;p&gt;
&#21452;&#21521;&#27880;&#24847;&#21147;&#20316;&#20026;&#36830;&#32493;&#35789;&#19987;&#23478;&#30340;&#28151;&#21512;&#29289;
&lt;/p&gt;
&lt;p&gt;
Bidirectional Attention as a Mixture of Continuous Word Experts. (arXiv:2307.04057v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04057
&lt;/p&gt;
&lt;p&gt;
&#21452;&#21521;&#27880;&#24847;&#21147;&#27169;&#22411;&#20855;&#26377;&#28151;&#21512;&#19987;&#23478;&#26435;&#37325;&#65292;&#31867;&#20284;&#20110;&#36830;&#32493;&#35789;&#34955;&#27169;&#22411;&#65288;CBOW&#65289;&#30340;&#32479;&#35745;&#27169;&#22411;&#65292;&#23427;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21452;&#21521;&#27880;&#24847;&#21147;&#30001;&#20301;&#32622;&#32534;&#30721;&#21644;&#23631;&#34109;&#35821;&#35328;&#27169;&#22411;&#65288;MLM&#65289;&#30446;&#26631;&#32452;&#25104;&#30340;&#33258;&#27880;&#24847;&#21147;&#26500;&#25104;&#65292;&#24050;&#25104;&#20026;&#29616;&#20195;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#20851;&#38190;&#32452;&#20214;&#12290;&#23613;&#31649;&#23427;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#23427;&#30340;&#32479;&#35745;&#22522;&#30784;&#65306;&#21452;&#21521;&#27880;&#24847;&#21147;&#38544;&#21547;&#22320;&#25311;&#21512;&#20102;&#20160;&#20040;&#32479;&#35745;&#27169;&#22411;&#65311;&#23427;&#19982;&#38750;&#27880;&#24847;&#26426;&#21046;&#30340;&#20808;&#39537;&#26377;&#20309;&#19981;&#21516;&#65311;&#26412;&#25991;&#25506;&#35752;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#37325;&#26032;&#21442;&#25968;&#21270;&#21518;&#65292;&#25311;&#21512;&#21333;&#23618;&#21333;&#22836;&#21452;&#21521;&#27880;&#24847;&#21147;&#31561;&#20110;&#25311;&#21512;&#20855;&#26377;&#28151;&#21512;&#19987;&#23478;&#26435;&#37325;&#30340;&#36830;&#32493;&#35789;&#34955;&#65288;CBOW&#65289;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20855;&#26377;&#22810;&#20010;&#22836;&#21644;&#22810;&#20010;&#23618;&#30340;&#21452;&#21521;&#27880;&#24847;&#21147;&#31561;&#20215;&#20110;&#22534;&#21472;&#30340;MoEs&#21644;MoEs&#30340;&#28151;&#21512;&#12290;&#36825;&#20010;&#32479;&#35745;&#35266;&#28857;&#25581;&#31034;&#20102;MoE&#22312;&#21452;&#21521;&#27880;&#24847;&#21147;&#20013;&#30340;&#29420;&#29305;&#29992;&#36884;&#65292;&#36825;&#19982;&#20854;&#22312;&#22788;&#29702;&#24322;&#26500;&#24615;&#26041;&#38754;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bidirectional attention $\unicode{x2013}$ composed of self-attention with positional encodings and the masked language model (MLM) objective $\unicode{x2013}$ has emerged as a key component of modern large language models (LLMs). Despite its empirical success, few studies have examined its statistical underpinnings: What statistical model is bidirectional attention implicitly fitting? What sets it apart from its non-attention predecessors? We explore these questions in this paper. The key observation is that fitting a single-layer single-head bidirectional attention, upon reparameterization, is equivalent to fitting a continuous bag of words (CBOW) model with mixture-of-experts (MoE) weights. Further, bidirectional attention with multiple heads and multiple layers is equivalent to stacked MoEs and a mixture of MoEs, respectively. This statistical viewpoint reveals the distinct use of MoE in bidirectional attention, which aligns with its practical effectiveness in handling heterogeneous
&lt;/p&gt;</description></item><item><title>&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#27604;&#20363;&#26497;&#38480;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#20462;&#25913;Softmax-based&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;Transformer&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#26497;&#38480;&#20998;&#24067;&#21487;&#20197;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#12290;&#36890;&#36807;&#20462;&#25913;&#27880;&#24847;&#21147;&#26426;&#21046;&#24182;&#20351;&#29992;&#27531;&#24046;&#36830;&#25509;&#65292;&#25105;&#20204;&#21487;&#20197;&#25511;&#21046;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#21644;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.17759</link><description>&lt;p&gt;
&#21463;&#24418;&#29366;&#25913;&#21464;&#30340;Transformer&#65306;&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#26497;&#38480;&#20013;&#30340;&#27880;&#24847;&#21147;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The Shaped Transformer: Attention Models in the Infinite Depth-and-Width Limit. (arXiv:2306.17759v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17759
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#27604;&#20363;&#26497;&#38480;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#20462;&#25913;Softmax-based&#27880;&#24847;&#21147;&#27169;&#22411;&#65292;&#30740;&#31350;&#20102;Transformer&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#26497;&#38480;&#20998;&#24067;&#21487;&#20197;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#25551;&#36848;&#12290;&#36890;&#36807;&#20462;&#25913;&#27880;&#24847;&#21147;&#26426;&#21046;&#24182;&#20351;&#29992;&#27531;&#24046;&#36830;&#25509;&#65292;&#25105;&#20204;&#21487;&#20197;&#25511;&#21046;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#21644;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#34920;&#31034;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#29992;&#20316;&#26816;&#26597;&#32593;&#32476;&#21487;&#35757;&#32451;&#24615;&#30340;&#20195;&#29702;&#12290;&#21463;Transformer&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#27604;&#20363;&#26497;&#38480;&#19979;&#65292;&#24102;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#20462;&#25913;Softmax-based&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#26497;&#38480;&#20998;&#24067;&#21487;&#20197;&#29992;&#28145;&#24230;&#19982;&#23485;&#24230;&#27604;&#29575;&#20026;&#32034;&#24341;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#25551;&#36848;&#12290;&#20026;&#20102;&#23454;&#29616;&#33391;&#23450;&#20041;&#30340;&#38543;&#26426;&#26497;&#38480;&#65292;Transformer&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#36890;&#36807;&#23558;Softmax&#36755;&#20986;&#23621;&#20013;&#22312;&#21333;&#20301;&#30697;&#38453;&#19978;&#65292;&#24182;&#36890;&#36807;&#23485;&#24230;&#30456;&#20851;&#30340;&#28201;&#24230;&#21442;&#25968;&#23545;Softmax logits&#36827;&#34892;&#32553;&#25918;&#26469;&#36827;&#34892;&#20462;&#25913;&#12290;&#25105;&#20204;&#36890;&#36807;&#30456;&#24212;&#30340;SDE&#30740;&#31350;&#20102;&#32593;&#32476;&#30340;&#31283;&#23450;&#24615;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#27531;&#24046;&#36830;&#25509;&#20248;&#38597;&#22320;&#25511;&#21046;&#28418;&#31227;&#21644;&#25193;&#25955;&#30340;&#23610;&#24230;&#12290;&#31283;&#23450;SDE&#30340;&#23384;&#22312;&#24847;&#21619;&#30528;&#21327;&#26041;&#24046;&#32467;&#26500;&#26159;&#33391; behaved &#30340;&#65292;&#21363;&#20351;&#23545;&#20110;&#38750;&#24120;&#22823;&#30340;&#28145;&#24230;&#21644;&#23485;&#24230;&#20063;&#26159;&#22914;&#27492;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning theory, the covariance matrix of the representations serves as a proxy to examine the network's trainability. Motivated by the success of Transformers, we study the covariance matrix of a modified Softmax-based attention model with skip connections in the proportional limit of infinite-depth-and-width. We show that at initialization the limiting distribution can be described by a stochastic differential equation (SDE) indexed by the depth-to-width ratio. To achieve a well-defined stochastic limit, the Transformer's attention mechanism is modified by centering the Softmax output at identity, and scaling the Softmax logits by a width-dependent temperature parameter. We examine the stability of the network through the corresponding SDE, showing how the scale of both the drift and diffusion can be elegantly controlled with the aid of residual connections. The existence of a stable SDE implies that the covariance structure is well-behaved, even for very large depth and widt
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#29992;&#20110;&#22823;&#35268;&#27169;&#22330;&#26223;&#19979;&#37327;&#23376;&#21487;&#20998;&#24615;&#30340;&#36817;&#20284;&#35299;&#65292;&#36890;&#36807;&#26377;&#25928;&#31639;&#27861;&#36817;&#20284;&#26597;&#25214;&#26368;&#36817;&#30340;&#21487;&#20998;&#31163;&#23494;&#24230;&#30697;&#38453;&#65292;&#24182;&#23558;&#37327;&#23376;&#21487;&#20998;&#24615;&#35270;&#20026;&#20998;&#31867;&#38382;&#39064;&#65292;&#23545;&#20219;&#20309;&#20108;&#32500;&#28151;&#21512;&#29366;&#24577;&#37117;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.09444</link><description>&lt;p&gt;
&#22522;&#20110;&#21487;&#22797;&#21046;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#22823;&#35268;&#27169;&#37327;&#23376;&#21487;&#20998;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Large-Scale Quantum Separability Through a Reproducible Machine Learning Lens. (arXiv:2306.09444v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09444
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#29992;&#20110;&#22823;&#35268;&#27169;&#22330;&#26223;&#19979;&#37327;&#23376;&#21487;&#20998;&#24615;&#30340;&#36817;&#20284;&#35299;&#65292;&#36890;&#36807;&#26377;&#25928;&#31639;&#27861;&#36817;&#20284;&#26597;&#25214;&#26368;&#36817;&#30340;&#21487;&#20998;&#31163;&#23494;&#24230;&#30697;&#38453;&#65292;&#24182;&#23558;&#37327;&#23376;&#21487;&#20998;&#24615;&#35270;&#20026;&#20998;&#31867;&#38382;&#39064;&#65292;&#23545;&#20219;&#20309;&#20108;&#32500;&#28151;&#21512;&#29366;&#24577;&#37117;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#21487;&#20998;&#24615;&#38382;&#39064;&#26159;&#25351;&#22914;&#20309;&#21028;&#26029;&#19968;&#20010;&#20108;&#20998;&#20307;&#23494;&#24230;&#30697;&#38453;&#26159;&#32416;&#32544;&#30340;&#36824;&#26159;&#21487;&#20998;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#65292;&#29992;&#20110;&#22312;&#22823;&#35268;&#27169;&#22330;&#26223;&#19979;&#25214;&#21040;&#27492;NP-&#38590;&#38382;&#39064;&#30340;&#36817;&#20284;&#35299;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;Frank-Wolfe&#30340;&#26377;&#25928;&#31639;&#27861;&#26469;&#36817;&#20284;&#26597;&#25214;&#26368;&#36817;&#30340;&#21487;&#20998;&#31163;&#23494;&#24230;&#30697;&#38453;&#65292;&#24182;&#25512;&#23548;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#27861;&#23558;&#23494;&#24230;&#30697;&#38453;&#26631;&#35760;&#20026;&#21487;&#20998;&#31163;&#30340;&#25110;&#32416;&#32544;&#30340;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#37327;&#23376;&#21487;&#20998;&#24615;&#35270;&#20026;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#20108;&#32500;&#28151;&#21512;&#29366;&#24577;&#12290;&#23545;3-&#21644;7&#32500;&#24230;&#20013;&#30340;&#37327;&#23376;&#24577;&#36827;&#34892;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#31243;&#24207;&#30340;&#25928;&#29575;&#65292;&#24182;&#35777;&#26126;&#23427;&#21487;&#20197;&#25193;&#23637;&#21040;&#19978;&#21315;&#20010;&#23494;&#24230;&#30697;&#38453;&#65292;&#24182;&#20855;&#26377;&#39640;&#37327;&#23376;&#32416;&#32544;&#26816;&#27979;&#31934;&#24230;&#12290;&#36825;&#19968;&#36827;&#23637;&#26377;&#21161;&#20110;&#22522;&#20934;&#27979;&#35797;&#37327;&#23376;&#21487;&#20998;&#24615;&#65292;&#24182;&#25903;&#25345;&#26356;&#24378;&#22823;&#30340;&#32416;&#32544;&#26816;&#27979;&#25216;&#26415;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quantum separability problem consists in deciding whether a bipartite density matrix is entangled or separable. In this work, we propose a machine learning pipeline for finding approximate solutions for this NP-hard problem in large-scale scenarios. We provide an efficient Frank-Wolfe-based algorithm to approximately seek the nearest separable density matrix and derive a systematic way for labeling density matrices as separable or entangled, allowing us to treat quantum separability as a classification problem. Our method is applicable to any two-qudit mixed states. Numerical experiments with quantum states of 3- and 7-dimensional qudits validate the efficiency of the proposed procedure, and demonstrate that it scales up to thousands of density matrices with a high quantum entanglement detection accuracy. This takes a step towards benchmarking quantum separability to support the development of more powerful entanglement detection techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20381;&#36182;&#20110;&#22797;&#26434;UGAP&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;$O(1/\sqrt{N})$&#26368;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2306.00196</link><description>&lt;p&gt;
&#20855;&#26377;&#24179;&#22343;&#22870;&#21169;&#30340;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#65306;&#25171;&#30772;&#32479;&#19968;&#20840;&#23616;&#24341;&#23376;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption. (arXiv:2306.00196v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20381;&#36182;&#20110;&#22797;&#26434;UGAP&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;$O(1/\sqrt{N})$&#26368;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#24179;&#22343;&#22870;&#21169;&#26631;&#20934;&#19979;&#30340;&#26080;&#38480;&#26102;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#65292;&#21253;&#25324;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#35774;&#32622;&#12290;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#22914;&#20309;&#35774;&#35745;&#35745;&#31639;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#20351;&#24471;&#20248;&#21270;&#24046;&#36317;&#38543;&#30528;&#33218;&#30340;&#25968;&#37327;$N$&#30340;&#22686;&#21152;&#32780;&#20943;&#23567;&#12290;&#29616;&#26377;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#32479;&#19968;&#20840;&#23616;&#24341;&#23376;&#24615;&#36136;(UGAP)&#65292;&#36825;&#26159;&#19968;&#20010;&#22797;&#26434;&#19988;&#38590;&#20197;&#39564;&#35777;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#22522;&#20110;&#27169;&#25311;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#12290;&#36825;&#26159;&#36890;&#36807;&#22312;&#27599;&#20010;&#33218;&#19978;&#27169;&#25311;&#21333;&#33218;&#31574;&#30053;&#65292;&#24182;&#20180;&#32454;&#22320;&#23558;&#30495;&#23454;&#29366;&#24577;&#24341;&#23548;&#21521;&#27169;&#25311;&#29366;&#24577;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23454;&#20363;&#21270;&#65292;&#20135;&#29983;&#19968;&#20010;&#20855;&#26377;$O(1/\sqrt{N})$&#30340;&#26368;&#20248;&#35299;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;&#22312;&#31163;&#25955;&#26102;&#38388;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#26356;&#31616;&#21333;&#30340;&#21516;&#27493;&#20551;&#35774;&#19979;&#25104;&#31435;&#65292;&#28085;&#30422;&#20102;&#19968;&#20123;&#19981;&#28385;&#36275;UGAP&#30340;&#38382;&#39064;&#23454;&#20363;&#12290;&#26356;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#22788;&#29702;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22823;&#30340;&#38382;&#39064;&#31867;&#65292;&#32780;&#19981;&#38656;&#23545;&#38382;&#39064;&#23454;&#20363;&#20570;&#20219;&#20309;&#29305;&#23450;&#30340;&#32467;&#26500;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the infinite-horizon restless bandit problem with the average reward criterion, under both discrete-time and continuous-time settings. A fundamental question is how to design computationally efficient policies that achieve a diminishing optimality gap as the number of arms, $N$, grows large. Existing results on asymptotical optimality all rely on the uniform global attractor property (UGAP), a complex and challenging-to-verify assumption. In this paper, we propose a general, simulation-based framework that converts any single-armed policy into a policy for the original $N$-armed problem. This is accomplished by simulating the single-armed policy on each arm and carefully steering the real state towards the simulated state. Our framework can be instantiated to produce a policy with an $O(1/\sqrt{N})$ optimality gap. In the discrete-time setting, our result holds under a simpler synchronization assumption, which covers some problem instances that do not satisfy UGAP. More notabl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;Selectively Adaptive Lasso&#65288;SAL&#65289;&#65292;&#23427;&#22522;&#20110;HAL&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#20445;&#30041;&#20102;&#26080;&#32500;&#24230;&#12289;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#29575;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#20063;&#20855;&#26377;&#21487;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#31639;&#27861;&#23558;&#35768;&#22810;&#22238;&#24402;&#31995;&#25968;&#33258;&#21160;&#35774;&#32622;&#20026;&#38646;&#12290;</title><link>http://arxiv.org/abs/2205.10697</link><description>&lt;p&gt;
Selectively Adaptive Lasso&#36873;&#36866;&#24212;Lasso
&lt;/p&gt;
&lt;p&gt;
The Selectively Adaptive Lasso. (arXiv:2205.10697v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;Selectively Adaptive Lasso&#65288;SAL&#65289;&#65292;&#23427;&#22522;&#20110;HAL&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#20445;&#30041;&#20102;&#26080;&#32500;&#24230;&#12289;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#29575;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#20063;&#20855;&#26377;&#21487;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#31639;&#27861;&#23558;&#35768;&#22810;&#22238;&#24402;&#31995;&#25968;&#33258;&#21160;&#35774;&#32622;&#20026;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#26041;&#27861;&#33021;&#22815;&#36827;&#34892;&#26080;&#38656;&#36807;&#22810;&#30340;&#21442;&#25968;&#20551;&#35774;&#30340;&#20989;&#25968;&#20272;&#35745;&#12290;&#34429;&#28982;&#23427;&#20204;&#21487;&#20197;&#22312;&#39044;&#27979;&#35823;&#24046;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22823;&#22810;&#25968;&#32570;&#20047;&#31867;&#21322;&#21442;&#25968;&#26377;&#25928;&#20272;&#35745;&#65288;&#20363;&#22914;&#65292;TMLE&#65292;AIPW&#65289;&#25152;&#38656;&#30340;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#12290;&#39640;&#24230;&#33258;&#36866;&#24212;Lasso&#65288;HAL&#65289;&#26159;&#21807;&#19968;&#32463;&#35777;&#26126;&#33021;&#22815;&#24555;&#36895;&#25910;&#25947;&#21040;&#24847;&#20041;&#19978;&#30340;&#22823;&#31867;&#20989;&#25968;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#19982;&#39044;&#27979;&#21464;&#37327;&#30340;&#32500;&#24230;&#26080;&#20851;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;HAL&#26080;&#27861;&#25193;&#23637;&#35745;&#31639;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;HAL&#29702;&#35770;&#30340;&#22522;&#30784;&#19978;&#26500;&#24314;&#36873;&#25321;&#33258;&#36866;&#24212;Lasso&#65288;SAL&#65289;&#65292;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#20445;&#30041;HAL&#30340;&#26080;&#32500;&#24230;&#12289;&#38750;&#21442;&#25968;&#25910;&#25947;&#29575;&#65292;&#20294;&#20063;&#33021;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20123;&#19982;&#23884;&#22871;Donsker&#31867;&#20013;&#30340;&#32463;&#39564;&#25439;&#22833;&#26368;&#23567;&#21270;&#26377;&#20851;&#30340;&#19968;&#33324;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#19968;&#31181;&#26799;&#24230;&#19979;&#38477;&#24418;&#24335;&#65292;&#20855;&#26377;&#31616;&#21333;&#30340;&#20998;&#32452;&#35268;&#21017;&#65292;&#33258;&#21160;&#23558;&#35768;&#22810;&#22238;&#24402;&#31995;&#25968;&#35774;&#20026;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning regression methods allow estimation of functions without unrealistic parametric assumptions. Although they can perform exceptionally in prediction error, most lack theoretical convergence rates necessary for semi-parametric efficient estimation (e.g. TMLE, AIPW) of parameters like average treatment effects. The Highly Adaptive Lasso (HAL) is the only regression method proven to converge quickly enough for a meaningfully large class of functions, independent of the dimensionality of the predictors. Unfortunately, HAL is not computationally scalable. In this paper we build upon the theory of HAL to construct the Selectively Adaptive Lasso (SAL), a new algorithm which retains HAL's dimension-free, nonparametric convergence rate but which also scales computationally to large high-dimensional datasets. To accomplish this, we prove some general theoretical results pertaining to empirical loss minimization in nested Donsker classes. Our resulting algorithm is a form of gradie
&lt;/p&gt;</description></item></channel></rss>