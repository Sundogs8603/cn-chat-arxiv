<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#20108;&#27425;&#30495;&#23454;&#20989;&#25968;&#20998;&#38548;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35757;&#32451;&#25968;&#37327;&#32423;&#20026;$d \:\text{polylog}(d)$&#30340;&#26679;&#26412;&#65292;&#23558;&#32593;&#32476;&#35757;&#32451;&#21040;&#20102;&#20154;&#21475;&#35823;&#24046;&#20026;$o(1)$&#30340;&#31243;&#24230;&#12290;&#36825;&#26159;&#39318;&#27425;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#19978;&#20197;&#21450;&#26631;&#20934;&#35757;&#32451;&#19979;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#19978;&#39640;&#25928;&#23398;&#20064;XOR&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d)$&#12290;</title><link>http://arxiv.org/abs/2309.15111</link><description>&lt;p&gt;
SGD&#22312;&#20855;&#26377;&#25509;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23547;&#25214;&#24182;&#35843;&#25972;&#29305;&#24449;&#65306;&#20197;XOR&#38382;&#39064;&#20026;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem. (arXiv:2309.15111v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#20108;&#27425;&#30495;&#23454;&#20989;&#25968;&#20998;&#38548;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#35757;&#32451;&#25968;&#37327;&#32423;&#20026;$d \:\text{polylog}(d)$&#30340;&#26679;&#26412;&#65292;&#23558;&#32593;&#32476;&#35757;&#32451;&#21040;&#20102;&#20154;&#21475;&#35823;&#24046;&#20026;$o(1)$&#30340;&#31243;&#24230;&#12290;&#36825;&#26159;&#39318;&#27425;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#19978;&#20197;&#21450;&#26631;&#20934;&#35757;&#32451;&#19979;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#19978;&#39640;&#25928;&#23398;&#20064;XOR&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23567;&#25209;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#20855;&#26377;&#20108;&#27425;&#30495;&#23454;&#20989;&#25968;&#20998;&#38548;&#25968;&#25454;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#20248;&#21270;&#36807;&#31243;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#20174;$d$&#32500;&#24067;&#23572;&#36229;&#31435;&#26041;&#20307;&#20013;&#30001;&#20108;&#27425;&#8220;XOR&#8221;&#20989;&#25968;$y = -x_ix_j$&#26631;&#35760;&#30340;&#25968;&#25454;&#65292;&#21487;&#20197;&#36890;&#36807;&#26631;&#20934;&#23567;&#25209;&#37327;SGD&#22312;&#36923;&#36753;&#25439;&#22833;&#19978;&#21516;&#26102;&#35757;&#32451;&#20004;&#23618;ReLU&#28608;&#27963;&#30340;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;$d \:\text{polylog}(d)$&#20010;&#26679;&#26412;&#23558;&#20854;&#35757;&#32451;&#21040;&#20154;&#21475;&#35823;&#24046;&#20026;$o(1)$&#30340;&#31243;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#27425;&#32473;&#20986;&#20102;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#19978;&#20197;&#21450;&#26631;&#20934;&#35757;&#32451;&#19979;&#65292;&#23545;&#20110;&#22312;&#21508;&#21521;&#21516;&#24615;&#25968;&#25454;&#19978;&#39640;&#25928;&#23398;&#20064;XOR&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d)$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#26159;&#23637;&#31034;&#32593;&#32476;&#28436;&#21270;&#26377;&#20004;&#20010;&#38454;&#27573;&#65306;&#19968;&#20010;&#8221;&#20449;&#21495;&#21457;&#29616;&#8220;&#38454;&#27573;&#65292;&#22312;&#27492;&#32593;&#32476;&#35268;&#27169;&#36739;&#23567;&#19988;&#35768;&#22810;&#31070;&#32463;&#20803;&#29420;&#31435;&#28436;&#21270;&#20197;&#23547;&#25214;&#29305;&#24449;&#65292;&#20197;&#21450;&#19968;&#20010;&#8221;&#20449;&#21495;&#23494;&#38598;&#8220;&#38454;&#27573;&#65292;&#20854;&#20013;&#35768;&#22810;&#31070;&#32463;&#20803;&#30456;&#20114;&#20316;&#29992;&#20197;&#20248;&#21270;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we consider the optimization process of minibatch stochastic gradient descent (SGD) on a 2-layer neural network with data separated by a quadratic ground truth function. We prove that with data drawn from the $d$-dimensional Boolean hypercube labeled by the quadratic ``XOR'' function $y = -x_ix_j$, it is possible to train to a population error $o(1)$ with $d \:\text{polylog}(d)$ samples. Our result considers simultaneously training both layers of the two-layer-neural network with ReLU activations via standard minibatch SGD on the logistic loss. To our knowledge, this work is the first to give a sample complexity of $\tilde{O}(d)$ for efficiently learning the XOR function on isotropic data on a standard neural network with standard training. Our main technique is showing that the network evolves in two phases: a $\textit{signal-finding}$ phase where the network is small and many of the neurons evolve independently to find features, and a $\textit{signal-heavy}$ phase, wher
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#20004;&#20010;&#26041;&#21521;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#36890;&#36807;&#31070;&#32463;&#20999;&#32447;&#26680;&#65288;NTK&#65289;&#21644;&#36890;&#36807;&#20984;&#37325;&#22609;ReLU&#32593;&#32476;&#30340;&#20840;&#23616;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NTK&#30456;&#36830;&#30340;&#22810;&#26680;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;&#38376;&#25511;ReLU&#32593;&#32476;&#65292;&#36890;&#36807;&#21152;&#26435;&#25968;&#25454;&#23631;&#34109;&#29305;&#24449;&#26144;&#23556;&#26469;&#23454;&#29616;&#20840;&#23616;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.15096</link><description>&lt;p&gt;
&#20462;&#22797;NTK&#65306;&#20174;&#31070;&#32463;&#32593;&#32476;&#32447;&#24615;&#21270;&#21040;&#31934;&#30830;&#30340;&#20984;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;
Fixing the NTK: From Neural Network Linearizations to Exact Convex Programs. (arXiv:2309.15096v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#20004;&#20010;&#26041;&#21521;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#36890;&#36807;&#31070;&#32463;&#20999;&#32447;&#26680;&#65288;NTK&#65289;&#21644;&#36890;&#36807;&#20984;&#37325;&#22609;ReLU&#32593;&#32476;&#30340;&#20840;&#23616;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NTK&#30456;&#36830;&#30340;&#22810;&#26680;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;&#38376;&#25511;ReLU&#32593;&#32476;&#65292;&#36890;&#36807;&#21152;&#26435;&#25968;&#25454;&#23631;&#34109;&#29305;&#24449;&#26144;&#23556;&#26469;&#23454;&#29616;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#20998;&#26512;&#20027;&#35201;&#38598;&#20013;&#22312;&#20004;&#20010;&#26041;&#21521;&#19978;&#65306;1&#65289;&#36890;&#36807;&#22312;&#38544;&#34255;&#23618;&#23485;&#24230;&#26080;&#38480;&#22823;&#21644;&#23398;&#20064;&#29575;&#26080;&#31351;&#23567;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#30340;SGD&#35757;&#32451;&#30340;&#29702;&#35770;&#27934;&#23519;&#21147;&#65288;&#20063;&#31216;&#20026;&#26799;&#24230;&#27969;&#65289;&#36890;&#36807;&#31070;&#32463;&#20999;&#32447;&#26680;&#65288;NTK&#65289;&#65307;2&#65289;&#36890;&#36807;&#38181;&#32422;&#26463;&#20984;&#37325;&#22609;ReLU&#32593;&#32476;&#30340;&#20840;&#23616;&#20248;&#21270;&#35757;&#32451;&#30446;&#26631;&#12290;&#21518;&#19968;&#31181;&#30740;&#31350;&#26041;&#21521;&#36824;&#25552;&#20379;&#20102;ReLU&#32593;&#32476;&#30340;&#21478;&#19968;&#31181;&#20844;&#24335;&#65292;&#31216;&#20026;&#38376;&#25511;ReLU&#32593;&#32476;&#65292;&#21487;&#36890;&#36807;&#39640;&#25928;&#30340;&#26080;&#32422;&#26463;&#20984;&#31243;&#24207;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#38376;&#25511;ReLU&#32593;&#32476;&#30340;&#20984;&#38382;&#39064;&#35299;&#37322;&#20026;&#20855;&#26377;&#21152;&#26435;&#25968;&#25454;&#23631;&#34109;&#29305;&#24449;&#26144;&#23556;&#30340;&#22810;&#26680;&#23398;&#20064;&#65288;MKL&#65289;&#27169;&#22411;&#65292;&#24182;&#19982;NTK&#24314;&#31435;&#20102;&#36830;&#25509;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#37027;&#20123;&#19982;&#23398;&#20064;&#30446;&#26631;&#26080;&#20851;&#30340;&#29305;&#23450;&#36873;&#25321;&#30340;&#25513;&#30721;&#26435;&#37325;&#65292;&#35813;&#26680;&#31561;&#25928;&#20110;&#38376;&#25511;ReLU&#32593;&#32476;&#22312;&#35757;&#32451;&#26679;&#26412;&#19978;&#30340;NTK&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, theoretical analyses of deep neural networks have broadly focused on two directions: 1) Providing insight into neural network training by SGD in the limit of infinite hidden-layer width and infinitesimally small learning rate (also known as gradient flow) via the Neural Tangent Kernel (NTK), and 2) Globally optimizing the regularized training objective via cone-constrained convex reformulations of ReLU networks. The latter research direction also yielded an alternative formulation of the ReLU network, called a gated ReLU network, that is globally optimizable via efficient unconstrained convex programs. In this work, we interpret the convex program for this gated ReLU network as a Multiple Kernel Learning (MKL) model with a weighted data masking feature map and establish a connection to the NTK. Specifically, we show that for a particular choice of mask weights that do not depend on the learning targets, this kernel is equivalent to the NTK of the gated ReLU network on the tra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#20998;&#31867;&#22120;&#22312;&#20108;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#36229;&#39069;&#39118;&#38505;&#26469;&#34913;&#37327;&#12290;&#30740;&#31350;&#32771;&#34385;&#20102;&#26356;&#19968;&#33324;&#30340;&#22330;&#26223;&#65292;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36731;&#26494;&#24212;&#29992;&#25968;&#20540;&#20248;&#21270;&#26041;&#27861;&#12290;&#34429;&#28982;&#20989;&#25968;&#31867;&#24456;&#22823;&#65292;&#20294;&#26080;&#32500;&#24230;&#36895;&#29575;&#26159;&#21487;&#33021;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.15075</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#36229;&#39069;&#39118;&#38505;&#25910;&#25947;&#36895;&#29575;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Excess Risk Convergence Rates of Neural Network Classifiers. (arXiv:2309.15075v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#20998;&#31867;&#22120;&#22312;&#20108;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#36229;&#39069;&#39118;&#38505;&#26469;&#34913;&#37327;&#12290;&#30740;&#31350;&#32771;&#34385;&#20102;&#26356;&#19968;&#33324;&#30340;&#22330;&#26223;&#65292;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36731;&#26494;&#24212;&#29992;&#25968;&#20540;&#20248;&#21270;&#26041;&#27861;&#12290;&#34429;&#28982;&#20989;&#25968;&#31867;&#24456;&#22823;&#65292;&#20294;&#26080;&#32500;&#24230;&#36895;&#29575;&#26159;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#31070;&#32463;&#32593;&#32476;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#25104;&#21151;&#34920;&#26126;&#65292;&#19982;&#20854;&#20182;&#26356;&#32463;&#20856;&#30340;&#20998;&#31867;&#22120;&#65288;&#22914;SVM&#25110;boosting&#20998;&#31867;&#22120;&#65289;&#30456;&#27604;&#65292;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#29420;&#29305;&#30340;&#29305;&#28857;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25554;&#20540;&#20998;&#31867;&#22120;&#22312;&#20108;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#20854;&#36229;&#39069;&#39118;&#38505;&#26469;&#34913;&#37327;&#12290;&#19982;&#25991;&#29486;&#20013;&#25152;&#35268;&#23450;&#30340;&#20856;&#22411;&#26465;&#20214;&#30456;&#27604;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#22330;&#26223;&#65292;&#23427;&#22312;&#20004;&#20010;&#26041;&#38754;&#19982;&#23454;&#38469;&#24212;&#29992;&#31867;&#20284;&#65306;&#39318;&#20808;&#65292;&#35201;&#36817;&#20284;&#30340;&#20989;&#25968;&#31867;&#21253;&#25324;&#20102;Barron&#20989;&#25968;&#20316;&#20026;&#27491;&#23376;&#38598;&#65307;&#20854;&#27425;&#65292;&#26500;&#24314;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#26367;&#20195;&#25439;&#22833;&#20989;&#25968;&#32780;&#19981;&#26159;0-1&#25439;&#22833;&#20989;&#25968;&#26469;&#23454;&#29616;&#30340;&#65292;&#20174;&#32780;&#21487;&#20197;&#36731;&#26494;&#24212;&#29992;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#25968;&#20540;&#20248;&#21270;&#26041;&#27861;&#12290;&#34429;&#28982;&#25105;&#20204;&#32771;&#34385;&#30340;&#20989;&#25968;&#31867;&#38750;&#24120;&#22823;&#65292;&#26368;&#20248;&#36895;&#29575;&#19981;&#33021;&#36229;&#36807;$n^{-\frac{1}{3}}$&#65292;&#20294;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26080;&#32500;&#24230;&#36895;&#29575;&#26159;&#21487;&#33021;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent success of neural networks in pattern recognition and classification problems suggests that neural networks possess qualities distinct from other more classical classifiers such as SVMs or boosting classifiers. This paper studies the performance of plug-in classifiers based on neural networks in a binary classification setting as measured by their excess risks. Compared to the typical settings imposed in the literature, we consider a more general scenario that resembles actual practice in two respects: first, the function class to be approximated includes the Barron functions as a proper subset, and second, the neural network classifier constructed is the minimizer of a surrogate loss instead of the $0$-$1$ loss so that gradient descent-based numerical optimizations can be easily applied. While the class of functions we consider is quite large that optimal rates cannot be faster than $n^{-\frac{1}{3}}$, it is a regime in which dimension-free rates are possible and approximat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;SOFAR&#25512;&#26029;&#65288;SOFARI&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;Neyman&#36817;&#27491;&#20132;&#25512;&#26029;&#21644;SVD&#32422;&#26463;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#23545;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#28508;&#22312;&#22240;&#23376;&#30697;&#38453;&#30340;&#20934;&#30830;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.15032</link><description>&lt;p&gt;
SOFARI:&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
SOFARI: High-Dimensional Manifold-Based Inference. (arXiv:2309.15032v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;SOFAR&#25512;&#26029;&#65288;SOFARI&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;Neyman&#36817;&#27491;&#20132;&#25512;&#26029;&#21644;SVD&#32422;&#26463;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#65292;&#23454;&#29616;&#20102;&#23545;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#28508;&#22312;&#22240;&#23376;&#30697;&#38453;&#30340;&#20934;&#30830;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;&#21508;&#31181;&#20219;&#21153;&#20013;&#25552;&#21462;&#20449;&#24687;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#31995;&#25968;&#30697;&#38453;&#20013;&#30340;&#31232;&#30095;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#30340;&#31232;&#30095;&#27491;&#20132;&#22240;&#23376;&#22238;&#24402;&#65288;SOFAR&#65289;&#26694;&#26550;&#34987;&#24341;&#20837;&#21040;&#21487;&#35299;&#37322;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#65292;&#21487;&#20197;&#21457;&#29616;&#19981;&#21516;&#23618;&#27425;&#20043;&#38388;&#26377;&#24847;&#20041;&#30340;&#28508;&#22312;&#29305;&#24449;-&#21709;&#24212;&#20851;&#32852;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31232;&#30095;SVD&#32422;&#26463;&#30340;&#27491;&#20132;&#24615;&#32422;&#26463;&#65292;&#23545;&#28508;&#22312;&#22240;&#23376;&#30697;&#38453;&#36827;&#34892;&#31934;&#30830;&#25512;&#26029;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#22522;&#20110;&#39640;&#32500;&#27969;&#24418;&#30340;SOFAR&#25512;&#26029;&#65288;SOFARI&#65289;&#65292;&#20511;&#37492;&#20102;Neyman&#36817;&#27491;&#20132;&#25512;&#26029;&#65292;&#24182;&#32467;&#21512;&#20102;SVD&#32422;&#26463;&#25152;&#26045;&#21152;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#12290;&#36890;&#36807;&#21033;&#29992;&#28508;&#22312;&#30340;Stiefel&#27969;&#24418;&#32467;&#26500;&#65292;SOFARI&#20026;&#28508;&#22312;&#24038;&#22240;&#23376;&#21521;&#37327;&#21644;&#22855;&#24322;&#20540;&#25552;&#20379;&#20102;&#20559;&#24046;&#26657;&#27491;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning is a widely used technique for harnessing information from various tasks. Recently, the sparse orthogonal factor regression (SOFAR) framework, based on the sparse singular value decomposition (SVD) within the coefficient matrix, was introduced for interpretable multi-task learning, enabling the discovery of meaningful latent feature-response association networks across different layers. However, conducting precise inference on the latent factor matrices has remained challenging due to orthogonality constraints inherited from the sparse SVD constraint. In this paper, we suggest a novel approach called high-dimensional manifold-based SOFAR inference (SOFARI), drawing on the Neyman near-orthogonality inference while incorporating the Stiefel manifold structure imposed by the SVD constraints. By leveraging the underlying Stiefel manifold structure, SOFARI provides bias-corrected estimators for both latent left factor vectors and singular values, for which we show to enj
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#21442;&#25968;&#21270;&#21464;&#20998;&#25298;&#32477;&#37319;&#26679;&#65288;VRS&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#21442;&#25968;&#21270;&#30340;&#25552;&#35758;&#20998;&#24067;&#19982;&#25298;&#32477;&#37319;&#26679;&#32467;&#21512;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#38750;&#21442;&#25968;&#20998;&#24067;&#26063;&#65292;&#26126;&#30830;&#21033;&#29992;&#24050;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#65292;&#20026;&#20855;&#26377;&#36830;&#32493;&#28508;&#21464;&#37327;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#25512;&#26029;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.14612</link><description>&lt;p&gt;
&#37325;&#21442;&#25968;&#21270;&#21464;&#20998;&#25298;&#32477;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Reparameterized Variational Rejection Sampling. (arXiv:2309.14612v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#21442;&#25968;&#21270;&#21464;&#20998;&#25298;&#32477;&#37319;&#26679;&#65288;VRS&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#21442;&#25968;&#21270;&#30340;&#25552;&#35758;&#20998;&#24067;&#19982;&#25298;&#32477;&#37319;&#26679;&#32467;&#21512;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#38750;&#21442;&#25968;&#20998;&#24067;&#26063;&#65292;&#26126;&#30830;&#21033;&#29992;&#24050;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#65292;&#20026;&#20855;&#26377;&#36830;&#32493;&#28508;&#21464;&#37327;&#30340;&#27169;&#22411;&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#25512;&#26029;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#20381;&#36182;&#20110;&#21442;&#25968;&#21270;&#30340;&#21464;&#20998;&#20998;&#24067;&#26063;&#65292;&#36873;&#25321;&#30340;&#20998;&#24067;&#26063;&#22312;&#30830;&#23450;&#21518;&#39564;&#36817;&#20284;&#30340;&#20934;&#30830;&#24615;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#31616;&#21333;&#30340;mean-field&#20998;&#24067;&#26063;&#36890;&#24120;&#23548;&#33268;&#36739;&#24046;&#30340;&#36817;&#20284;&#65292;&#32780;&#20687;&#24402;&#19968;&#21270;&#27969;&#36825;&#26679;&#30340;&#20016;&#23500;&#20998;&#24067;&#26063;&#24448;&#24448;&#38590;&#20197;&#20248;&#21270;&#65292;&#24182;&#19988;&#36890;&#24120;&#19981;&#21253;&#21547;&#24050;&#30693;&#30446;&#26631;&#20998;&#24067;&#30340;&#32467;&#26500;&#65292;&#22240;&#20026;&#20854;&#26159;&#40657;&#31665;&#30340;&#12290;&#20026;&#20102;&#25193;&#23637;&#28789;&#27963;&#30340;&#21464;&#20998;&#20998;&#24067;&#26063;&#31354;&#38388;&#65292;&#25105;&#20204;&#37325;&#26032;&#32771;&#34385;&#21464;&#20998;&#25298;&#32477;&#37319;&#26679;&#65288;VRS&#65289;[Grover et al., 2018]&#65292;&#23427;&#23558;&#21442;&#25968;&#21270;&#25552;&#35758;&#20998;&#24067;&#19982;&#25298;&#32477;&#37319;&#26679;&#32467;&#21512;&#36215;&#26469;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#20016;&#23500;&#30340;&#38750;&#21442;&#25968;&#20998;&#24067;&#26063;&#65292;&#26126;&#30830;&#21033;&#29992;&#24050;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#36890;&#36807;&#24341;&#20837;&#23545;&#25552;&#35758;&#20998;&#24067;&#21442;&#25968;&#30340;&#20302;&#26041;&#24046;&#37325;&#21442;&#25968;&#21270;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#20351;VRS&#25104;&#20026;&#20855;&#26377;&#36830;&#32493;&#28508;&#21464;&#37327;&#30340;&#21560;&#24341;&#20154;&#30340;&#25512;&#26029;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional approaches to variational inference rely on parametric families of variational distributions, with the choice of family playing a critical role in determining the accuracy of the resulting posterior approximation. Simple mean-field families often lead to poor approximations, while rich families of distributions like normalizing flows can be difficult to optimize and usually do not incorporate the known structure of the target distribution due to their black-box nature. To expand the space of flexible variational families, we revisit Variational Rejection Sampling (VRS) [Grover et al., 2018], which combines a parametric proposal distribution with rejection sampling to define a rich non-parametric family of distributions that explicitly utilizes the known target distribution. By introducing a low-variance reparameterized gradient estimator for the parameters of the proposal distribution, we make VRS an attractive inference strategy for models with continuous latent variables.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25581;&#31034;&#20102;&#22312;&#25104;&#23545;&#22330;&#26223;&#20013;&#39640;&#27700;&#24179;&#30340;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#26159;&#36890;&#36807;&#21516;&#26102;&#37325;&#35270;&#21382;&#21490;&#32463;&#39564;&#21644;&#26410;&#26469;&#22238;&#25253;&#26469;&#24418;&#25104;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.14598</link><description>&lt;p&gt;
&#35299;&#35835;&#20449;&#20219;:&#24378;&#21270;&#23398;&#20064;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Decoding trust: A reinforcement learning perspective. (arXiv:2309.14598v1 [q-bio.PE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14598
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25581;&#31034;&#20102;&#22312;&#25104;&#23545;&#22330;&#26223;&#20013;&#39640;&#27700;&#24179;&#30340;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#26159;&#36890;&#36807;&#21516;&#26102;&#37325;&#35270;&#21382;&#21490;&#32463;&#39564;&#21644;&#26410;&#26469;&#22238;&#25253;&#26469;&#24418;&#25104;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20449;&#20219;&#28216;&#25103;&#30340;&#34892;&#20026;&#23454;&#39564;&#34920;&#26126;&#65292;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#22312;&#20154;&#31867;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#36825;&#19982;&#27491;&#32479;&#32463;&#27982;&#23398;&#20013;&#20551;&#35774;&#30340;&#32463;&#27982;&#20154;&#30340;&#39044;&#27979;&#30456;&#30683;&#30462;&#12290;&#36825;&#24847;&#21619;&#30528;&#19968;&#23450;&#23384;&#22312;&#26576;&#31181;&#26426;&#21046;&#20419;&#20351;&#20182;&#20204;&#30340;&#20986;&#29616;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#35299;&#37322;&#37117;&#38656;&#35201;&#20381;&#36182;&#20110;&#19968;&#20123;&#22522;&#20110;&#27169;&#20223;&#23398;&#20064;&#30340;&#22240;&#32032;&#65292;&#21363;&#31616;&#21333;&#29256;&#26412;&#30340;&#31038;&#20250;&#23398;&#20064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#36716;&#21521;&#24378;&#21270;&#23398;&#20064;&#30340;&#33539;&#24335;&#65292;&#20010;&#20307;&#36890;&#36807;&#32047;&#31215;&#32463;&#39564;&#35780;&#20272;&#38271;&#26399;&#22238;&#25253;&#26469;&#26356;&#26032;&#20182;&#20204;&#30340;&#31574;&#30053;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;Q-learning&#31639;&#27861;&#30740;&#31350;&#20449;&#20219;&#28216;&#25103;&#65292;&#27599;&#20010;&#21442;&#19982;&#32773;&#20998;&#21035;&#19982;&#20004;&#20010;&#19981;&#26029;&#28436;&#21270;&#30340;Q&#34920;&#20851;&#32852;&#65292;&#25351;&#23548;&#20182;&#20204;&#20316;&#20026;&#20449;&#20219;&#32773;&#21644;&#25176;&#31649;&#26041;&#30340;&#20915;&#31574;&#12290;&#22312;&#25104;&#23545;&#30340;&#22330;&#26223;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#20010;&#20307;&#21516;&#26102;&#37325;&#35270;&#21382;&#21490;&#32463;&#39564;&#21644;&#26410;&#26469;&#22238;&#25253;&#26102;&#65292;&#20449;&#20219;&#21644;&#21487;&#20449;&#24230;&#27700;&#24179;&#36739;&#39640;&#12290;&#20174;&#26426;&#21046;&#19978;&#30475;&#65292;Q&#30340;&#28436;&#21270;...
&lt;/p&gt;
&lt;p&gt;
Behavioral experiments on the trust game have shown that trust and trustworthiness are universal among human beings, contradicting the prediction by assuming \emph{Homo economicus} in orthodox Economics. This means some mechanism must be at work that favors their emergence. Most previous explanations however need to resort to some factors based upon imitative learning, a simple version of social learning. Here, we turn to the paradigm of reinforcement learning, where individuals update their strategies by evaluating the long-term return through accumulated experience. Specifically, we investigate the trust game with the Q-learning algorithm, where each participant is associated with two evolving Q-tables that guide one's decision making as trustor and trustee respectively. In the pairwise scenario, we reveal that high levels of trust and trustworthiness emerge when individuals appreciate both their historical experience and returns in the future. Mechanistically, the evolution of the Q
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#24369;&#30417;&#30563;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#32479;&#35745;&#29702;&#35770;&#30740;&#31350;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#25968;&#25454;&#36873;&#25321;&#21487;&#20197;&#38750;&#24120;&#26377;&#25928;&#65292;&#26377;&#26102;&#29978;&#33267;&#21487;&#20197;&#25112;&#32988;&#23545;&#25972;&#20010;&#26679;&#26412;&#30340;&#35757;&#32451;&#12290;&#24182;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36873;&#25321;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.14563</link><description>&lt;p&gt;
&#38754;&#21521;&#24369;&#30417;&#30563;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#32479;&#35745;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Towards a statistical theory of data selection under weak supervision. (arXiv:2309.14563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#24369;&#30417;&#30563;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36827;&#34892;&#20102;&#32479;&#35745;&#29702;&#35770;&#30740;&#31350;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#25968;&#25454;&#36873;&#25321;&#21487;&#20197;&#38750;&#24120;&#26377;&#25928;&#65292;&#26377;&#26102;&#29978;&#33267;&#21487;&#20197;&#25112;&#32988;&#23545;&#25972;&#20010;&#26679;&#26412;&#30340;&#35757;&#32451;&#12290;&#24182;&#20998;&#26512;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#25968;&#25454;&#36873;&#25321;&#36873;&#25321;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#19968;&#20010;&#22823;&#23567;&#20026;N&#30340;&#26679;&#26412;&#65292;&#36873;&#25321;&#19968;&#20010;&#26356;&#23567;&#30340;&#22823;&#23567;n&lt;N&#30340;&#23376;&#26679;&#26412;&#29992;&#20110;&#32479;&#35745;&#20272;&#35745;&#25110;&#23398;&#20064;&#36890;&#24120;&#26159;&#26377;&#29992;&#30340;&#12290;&#36825;&#26679;&#30340;&#25968;&#25454;&#36873;&#25321;&#27493;&#39588;&#26377;&#21161;&#20110;&#20943;&#23569;&#25968;&#25454;&#26631;&#35760;&#30340;&#35201;&#27714;&#21644;&#23398;&#20064;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#20551;&#35774;&#32473;&#23450;&#20102;N&#20010;&#26410;&#26631;&#35760;&#30340;&#26679;&#26412;{x_i}&#65292;&#24182;&#19988;&#21487;&#20197;&#35775;&#38382;&#19968;&#20010;&#8220;&#26367;&#20195;&#27169;&#22411;&#8221;&#65292;&#23427;&#21487;&#20197;&#27604;&#38543;&#26426;&#29468;&#27979;&#26356;&#22909;&#22320;&#39044;&#27979;&#26631;&#31614;y_i&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36873;&#25321;&#19968;&#20010;&#23376;&#26679;&#26412;&#38598;{&#119857;_i}&#65292;&#20854;&#22823;&#23567;&#20026;|G|=n&lt;N&#12290;&#28982;&#21518;&#25105;&#20204;&#20026;&#36825;&#20010;&#38598;&#21512;&#33719;&#21462;&#26631;&#31614;&#65292;&#24182;&#20351;&#29992;&#23427;&#20204;&#36890;&#36807;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#36890;&#36807;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#28151;&#21512;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#22312;&#20302;&#32500;&#21644;&#39640;&#32500;&#28176;&#36817;&#24773;&#20917;&#19979;&#36827;&#34892;&#25968;&#23398;&#25512;&#23548;&#65292;&#25105;&#20204;&#35777;&#26126;&#65306;(i) &#25968;&#25454;&#36873;&#25321;&#21487;&#20197;&#38750;&#24120;&#26377;&#25928;&#65292;&#29305;&#21035;&#26159;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#20987;&#36133;&#23545;&#25972;&#20010;&#26679;&#26412;&#30340;&#35757;&#32451;&#65307;(ii) &#22312;&#25968;&#25454;&#36873;&#25321;&#26041;&#38754;&#65292;&#26576;&#20123;&#27969;&#34892;&#30340;&#36873;&#25321;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#26159;&#26377;&#25928;&#30340;&#65292;&#32780;&#22312;&#20854;&#20182;&#24773;&#20917;&#19979;&#21017;&#19981;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a sample of size $N$, it is often useful to select a subsample of smaller size $n&lt;N$ to be used for statistical estimation or learning. Such a data selection step is useful to reduce the requirements of data labeling and the computational complexity of learning. We assume to be given $N$ unlabeled samples $\{{\boldsymbol x}_i\}_{i\le N}$, and to be given access to a `surrogate model' that can predict labels $y_i$ better than random guessing. Our goal is to select a subset of the samples, to be denoted by $\{{\boldsymbol x}_i\}_{i\in G}$, of size $|G|=n&lt;N$. We then acquire labels for this set and we use them to train a model via regularized empirical risk minimization.  By using a mixture of numerical experiments on real and synthetic data, and mathematical derivations under low- and high- dimensional asymptotics, we show that: $(i)$~Data selection can be very effective, in particular beating training on the full sample in some cases; $(ii)$~Certain popular choices in data selecti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20809;&#32447;&#31995;&#32479;&#20013;&#26816;&#27979;&#21644;&#23450;&#20301;&#23567;&#21151;&#29575;&#25439;&#22833;&#30340;&#31363;&#21548;&#20107;&#20214;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#20809;&#24615;&#33021;&#30417;&#27979;&#25968;&#25454;&#21487;&#20197;&#26816;&#27979;&#36825;&#31181;&#24494;&#23567;&#30340;&#31363;&#21548;&#25439;&#22833;&#65292;&#21516;&#26102;&#36890;&#36807;&#22312;&#32447;&#25968;&#25454;&#21487;&#20197;&#26377;&#25928;&#22320;&#23450;&#20301;&#36825;&#31867;&#20107;&#20214;&#12290;</title><link>http://arxiv.org/abs/2309.14541</link><description>&lt;p&gt;
&#20809;&#38142;&#36335;&#20013;&#30340;&#31363;&#21548;&#35782;&#21035;&#21644;&#23450;&#20301;&#30340;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Cluster-based Method for Eavesdropping Identification and Localization in Optical Links. (arXiv:2309.14541v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20809;&#32447;&#31995;&#32479;&#20013;&#26816;&#27979;&#21644;&#23450;&#20301;&#23567;&#21151;&#29575;&#25439;&#22833;&#30340;&#31363;&#21548;&#20107;&#20214;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#20809;&#24615;&#33021;&#30417;&#27979;&#25968;&#25454;&#21487;&#20197;&#26816;&#27979;&#36825;&#31181;&#24494;&#23567;&#30340;&#31363;&#21548;&#25439;&#22833;&#65292;&#21516;&#26102;&#36890;&#36807;&#22312;&#32447;&#25968;&#25454;&#21487;&#20197;&#26377;&#25928;&#22320;&#23450;&#20301;&#36825;&#31867;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#27979;&#21644;&#23450;&#20301;&#20809;&#32447;&#31995;&#32479;&#20013;&#23567;&#21151;&#29575;&#25439;&#22833;&#30340;&#31363;&#21548;&#20107;&#20214;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20809;&#24615;&#33021;&#30417;&#27979;&#65288;OPM&#65289;&#25968;&#25454;&#20165;&#36890;&#36807;&#25509;&#25910;&#22120;&#25910;&#38598;&#23601;&#21487;&#20197;&#26816;&#27979;&#21040;&#36825;&#31181;&#24494;&#23567;&#30340;&#31363;&#21548;&#25439;&#22833;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36890;&#36807;&#21033;&#29992;&#22312;&#32447;OPM&#25968;&#25454;&#21487;&#20197;&#26377;&#25928;&#22320;&#23454;&#29616;&#23545;&#36825;&#31867;&#20107;&#20214;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a cluster-based method to detect and locate eavesdropping events in optical line systems characterized by small power losses. Our findings indicate that detecting such subtle losses from eavesdropping can be accomplished solely through optical performance monitoring (OPM) data collected at the receiver. On the other hand, the localization of such events can be effectively achieved by leveraging in-line OPM data.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;(Subspace-Median)&#26469;&#35299;&#20915;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#20027;&#23376;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#30740;&#31350;&#20102;&#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;Subspace-Median&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2309.14512</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;&#40065;&#26834;&#30340;&#32852;&#37030;PCA&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Resilient Federated PCA and Low Rank Matrix Recovery. (arXiv:2309.14512v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14512
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;(Subspace-Median)&#26469;&#35299;&#20915;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#20027;&#23376;&#31354;&#38388;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#30740;&#31350;&#20102;&#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;Subspace-Median&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#32852;&#37030;&#29615;&#22659;&#20013;&#20272;&#35745;&#23545;&#31216;&#30697;&#38453;&#30340;&#20027;&#23376;&#31354;&#38388;&#65288;&#21069;r&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#65289;&#30340;&#38382;&#39064;&#65292;&#24403;&#27599;&#20010;&#33410;&#28857;&#37117;&#21487;&#20197;&#35775;&#38382;&#23545;&#36825;&#20010;&#30697;&#38453;&#30340;&#20272;&#35745;&#26102;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#20351;&#36825;&#20010;&#38382;&#39064;&#20855;&#26377;&#25308;&#21344;&#24237;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#35777;&#26126;&#30340;&#25308;&#21344;&#24237;&#40065;&#26834;&#12289;&#36890;&#20449;&#39640;&#25928;&#21644;&#31169;&#23494;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#23376;&#31354;&#38388;&#20013;&#20540;&#31639;&#27861;&#65288;Subspace-Median&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#26368;&#33258;&#28982;&#30340;&#35299;&#27861;&#65292;&#22522;&#20110;&#20960;&#20309;&#20013;&#20540;&#30340;&#20462;&#25913;&#30340;&#32852;&#37030;&#24130;&#26041;&#27861;&#65292;&#24182;&#35299;&#37322;&#20026;&#20160;&#20040;&#23427;&#26159;&#26080;&#29992;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#40065;&#26834;&#23376;&#31354;&#38388;&#20272;&#35745;&#20803;&#38382;&#39064;&#30340;&#20004;&#20010;&#29305;&#27530;&#24773;&#20917; - &#32852;&#37030;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#27700;&#24179;&#32852;&#37030;&#20302;&#31209;&#21015;&#24863;&#30693;&#65288;LRCCS&#65289;&#30340;&#35889;&#21021;&#22987;&#21270;&#27493;&#39588;&#12290;&#23545;&#20110;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23376;&#31354;&#38388;&#20013;&#20540;&#31639;&#27861;&#25552;&#20379;&#20102;&#26082;&#20855;&#26377;&#40065;&#26834;&#24615;&#21448;&#20855;&#26377;&#39640;&#36890;&#20449;&#25928;&#29575;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#22343;&#20540;&#30340;&#20013;&#20301;&#25968;&#25193;&#23637;&#20063;&#34987;&#24320;&#21457;&#20986;&#26469;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we consider the problem of estimating the principal subspace (span of the top r singular vectors) of a symmetric matrix in a federated setting, when each node has access to estimates of this matrix. We study how to make this problem Byzantine resilient. We introduce a novel provably Byzantine-resilient, communication-efficient, and private algorithm, called Subspace-Median, to solve it. We also study the most natural solution for this problem, a geometric median based modification of the federated power method, and explain why it is not useful. We consider two special cases of the resilient subspace estimation meta-problem - federated principal components analysis (PCA) and the spectral initialization step of horizontally federated low rank column-wise sensing (LRCCS) in this work. For both these problems we show how Subspace Median provides a resilient solution that is also communication-efficient. Median of Means extensions are developed for both problems. Extensive simu
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#26680;&#26041;&#27861;&#26159;&#37327;&#23376;&#21644;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#26368;&#33258;&#28982;&#30340;&#32852;&#31995;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65306;&#36890;&#36807;&#24341;&#20837;&#35745;&#31639;&#26222;&#36866;&#24615;&#65292;&#20219;&#20309;&#26680;&#20989;&#25968;&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#37327;&#23376;&#29305;&#24449;&#26144;&#23556;&#21644;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;</title><link>http://arxiv.org/abs/2309.14419</link><description>&lt;p&gt;
&#20851;&#20110;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
On the expressivity of embedding quantum kernels. (arXiv:2309.14419v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14419
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26680;&#26041;&#27861;&#26159;&#37327;&#23376;&#21644;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#26368;&#33258;&#28982;&#30340;&#32852;&#31995;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65306;&#36890;&#36807;&#24341;&#20837;&#35745;&#31639;&#26222;&#36866;&#24615;&#65292;&#20219;&#20309;&#26680;&#20989;&#25968;&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#37327;&#23376;&#29305;&#24449;&#26144;&#23556;&#21644;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26680;&#26041;&#27861;&#30340;&#32972;&#26223;&#19979;&#65292;&#37327;&#23376;&#26680;&#19982;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#24314;&#31435;&#20102;&#26368;&#33258;&#28982;&#30340;&#32852;&#31995;&#12290;&#26680;&#26041;&#27861;&#20381;&#36182;&#20110;&#20869;&#31215;&#29305;&#24449;&#21521;&#37327;&#65292;&#36825;&#20123;&#29305;&#24449;&#21521;&#37327;&#23384;&#22312;&#20110;&#22823;&#22411;&#29305;&#24449;&#31354;&#38388;&#20013;&#12290;&#37327;&#23376;&#26680;&#36890;&#24120;&#36890;&#36807;&#26174;&#24335;&#26500;&#36896;&#37327;&#23376;&#29305;&#24449;&#24577;&#24182;&#35745;&#31639;&#23427;&#20204;&#30340;&#20869;&#31215;&#26469;&#35780;&#20272;&#65292;&#36825;&#37324;&#31216;&#20026;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;&#30001;&#20110;&#32463;&#20856;&#26680;&#36890;&#24120;&#22312;&#19981;&#20351;&#29992;&#29305;&#24449;&#21521;&#37327;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#35780;&#20272;&#65292;&#25105;&#20204;&#24819;&#30693;&#36947;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#30340;&#34920;&#36798;&#33021;&#21147;&#22914;&#20309;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#26159;&#21542;&#25152;&#26377;&#30340;&#37327;&#23376;&#26680;&#37117;&#21487;&#20197;&#34920;&#36798;&#20026;&#37327;&#23376;&#29305;&#24449;&#24577;&#30340;&#20869;&#31215;&#65311;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#32467;&#26524;&#26159;&#32943;&#23450;&#30340;&#65306;&#36890;&#36807;&#35843;&#29992;&#35745;&#31639;&#26222;&#36866;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#23545;&#20110;&#20219;&#20309;&#26680;&#20989;&#25968;&#65292;&#24635;&#26159;&#23384;&#22312;&#23545;&#24212;&#30340;&#37327;&#23376;&#29305;&#24449;&#26144;&#23556;&#21644;&#23884;&#20837;&#24335;&#37327;&#23376;&#26680;&#12290;&#28982;&#32780;&#65292;&#38382;&#39064;&#26356;&#20851;&#27880;&#30340;&#26159;&#26377;&#25928;&#30340;&#26500;&#36896;&#26041;&#24335;&#12290;&#22312;&#31532;&#20108;&#37096;&#20998;&#20013;
&lt;/p&gt;
&lt;p&gt;
One of the most natural connections between quantum and classical machine learning has been established in the context of kernel methods. Kernel methods rely on kernels, which are inner products of feature vectors living in large feature spaces. Quantum kernels are typically evaluated by explicitly constructing quantum feature states and then taking their inner product, here called embedding quantum kernels. Since classical kernels are usually evaluated without using the feature vectors explicitly, we wonder how expressive embedding quantum kernels are. In this work, we raise the fundamental question: can all quantum kernels be expressed as the inner product of quantum feature states? Our first result is positive: Invoking computational universality, we find that for any kernel function there always exists a corresponding quantum feature map and an embedding quantum kernel. The more operational reading of the question is concerned with efficient constructions, however. In a second part
&lt;/p&gt;</description></item><item><title>&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23884;&#20837;&#20915;&#31574;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;BPLS&#26694;&#26550;&#26469;&#35299;&#20915;&#20266;&#26631;&#31614;&#36873;&#25321;&#20013;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13926</link><description>&lt;p&gt;
&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#19968;&#20010;&#20915;&#31574;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Pseudo Label Selection is a Decision Problem. (arXiv:2309.13926v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13926
&lt;/p&gt;
&lt;p&gt;
&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23884;&#20837;&#20915;&#31574;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;BPLS&#26694;&#26550;&#26469;&#35299;&#20915;&#20266;&#26631;&#31614;&#36873;&#25321;&#20013;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20266;&#26631;&#31614;&#36873;&#25321;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#23427;&#38656;&#35201;&#19968;&#20123;&#20934;&#21017;&#26469;&#25351;&#23548;&#20266;&#26631;&#31614;&#25968;&#25454;&#30340;&#36873;&#25321;&#12290;&#36825;&#20123;&#20934;&#21017;&#34987;&#35777;&#26126;&#21487;&#20197;&#22312;&#23454;&#36341;&#20013;&#24037;&#20316;&#24471;&#30456;&#24403;&#22909;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#24448;&#24448;&#21462;&#20915;&#20110;&#26631;&#35760;&#25968;&#25454;&#19978;&#21021;&#22987;&#27169;&#22411;&#30340;&#25311;&#21512;&#24773;&#20917;&#12290;&#26089;&#26399;&#36807;&#25311;&#21512;&#21487;&#33021;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#65288;&#36890;&#24120;&#34987;&#31216;&#20026;&#30830;&#35748;&#20559;&#24046;&#65289;&#32780;&#20256;&#25773;&#21040;&#26368;&#32456;&#27169;&#22411;&#12290;&#22312;&#20004;&#39033;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20266;&#26631;&#31614;&#36873;&#25321;&#65288;PLS&#65289;&#21487;&#20197;&#33258;&#28982;&#22320;&#23884;&#20837;&#21040;&#20915;&#31574;&#29702;&#35770;&#20013;&#12290;&#36825;&#20026;BPLS&#38138;&#24179;&#20102;&#36947;&#36335;&#65292;&#23427;&#26159;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#32531;&#35299;&#30830;&#35748;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;&#20854;&#26680;&#24515;&#26159;&#19968;&#31181;&#26032;&#30340;&#36873;&#25321;&#20934;&#21017;&#65306;&#20266;&#26679;&#26412;&#21644;&#26631;&#35760;&#25968;&#25454;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#35299;&#26512;&#36817;&#20284;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#36825;&#20010;&#8220;&#20266;POS&#8221;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#26469;&#25512;&#23548;&#20986;&#36825;&#20010;&#36873;&#25321;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Labeling is a simple and effective approach to semi-supervised learning. It requires criteria that guide the selection of pseudo-labeled data. The latter have been shown to crucially affect pseudo-labeling's generalization performance. Several such criteria exist and were proven to work reasonably well in practice. However, their performance often depends on the initial model fit on labeled data. Early overfitting can be propagated to the final model by choosing instances with overconfident but wrong predictions, often called confirmation bias. In two recent works, we demonstrate that pseudo-label selection (PLS) can be naturally embedded into decision theory. This paves the way for BPLS, a Bayesian framework for PLS that mitigates the issue of confirmation bias. At its heart is a novel selection criterion: an analytical approximation of the posterior predictive of pseudo-samples and labeled data. We derive this selection criterion by proving Bayes-optimality of this "pseudo pos
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2306.02426</link><description>&lt;p&gt;
&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Resilient Constrained Learning. (arXiv:2306.02426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;&#38500;&#20102;&#20934;&#30830;&#24615;&#20043;&#22806;&#65292;&#23427;&#20204;&#24517;&#39035;&#28385;&#36275;&#22810;&#20010;&#35201;&#27714;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#40065;&#26834;&#24615;&#25110;&#23433;&#20840;&#24615;&#12290;&#36825;&#20123;&#35201;&#27714;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#24809;&#32602;&#26469;&#38544;&#24335;&#22320;&#26045;&#21152;&#65292;&#25110;&#32773;&#36890;&#36807;&#22522;&#20110;Lagrangian&#23545;&#20598;&#30340;&#32422;&#26463;&#20248;&#21270;&#26041;&#27861;&#26469;&#26174;&#24335;&#22320;&#26045;&#21152;&#12290;&#26080;&#35770;&#21738;&#31181;&#26041;&#24335;&#65292;&#25351;&#23450;&#35201;&#27714;&#37117;&#21463;&#21040;&#22949;&#21327;&#21644;&#26377;&#38480;&#30340;&#26377;&#20851;&#25968;&#25454;&#30340;&#20808;&#21069;&#30693;&#35782;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36890;&#24120;&#21482;&#33021;&#36890;&#36807;&#23454;&#38469;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#26469;&#35780;&#20272;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32422;&#26463;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21516;&#26102;&#35299;&#20915;&#23398;&#20064;&#20219;&#21153;&#30340;&#21516;&#26102;&#35843;&#25972;&#35201;&#27714;&#12290;&#20026;&#27492;&#65292;&#23427;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#20102;&#23398;&#20064;&#32422;&#26463;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#31216;&#20026;&#20855;&#26377;&#24377;&#24615;&#30340;&#32422;&#26463;&#23398;&#20064;&#65292;&#36825;&#26159;&#23545;&#29992;&#20110;&#25551;&#36848;&#29983;&#24577;&#31995;&#32479;&#30340;&#26415;&#35821;&#30340;&#19968;&#31181;&#20511;&#37492;&#12290;
&lt;/p&gt;
&lt;p&gt;
When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#20013;&#30340;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#8220;&#20808;&#25506;&#32034;&#20877;&#25191;&#34892;&#8221;&#31639;&#27861;&#36991;&#20813;&#20102;&#22256;&#38590;&#30340;&#21518;&#24724;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.08816</link><description>&lt;p&gt;
Borda Regret Minimization for Generalized Linear Dueling Bandits (&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#30340;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#31639;&#27861;)
&lt;/p&gt;
&lt;p&gt;
Borda Regret Minimization for Generalized Linear Dueling Bandits. (arXiv:2303.08816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#20013;&#30340;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#8220;&#20808;&#25506;&#32034;&#20877;&#25191;&#34892;&#8221;&#31639;&#27861;&#36991;&#20813;&#20102;&#22256;&#38590;&#30340;&#21518;&#24724;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;(Dueling bandits)&#24120;&#34987;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#65292;&#22914;&#25512;&#33616;&#31995;&#32479;&#21644;&#25490;&#21517;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#20013;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#30830;&#23450;&#20855;&#26377;&#26368;&#39640;&#21338;&#23572;&#36798;&#24471;&#20998;&#30340;&#39033;&#30446;&#65292;&#24182;&#21516;&#26102;&#26368;&#23567;&#21270;&#32047;&#35745;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#27169;&#22411;&#65292;&#23427;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#12290; &#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#26159;&#22256;&#38590;&#30340;&#12290; &#25105;&#20204;&#35777;&#26126;&#20102;&#28176;&#36817;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#21518;&#24724;&#19979;&#38480;&#26159;$\Omega(d^{2/3} T^{2/3})$&#65292;&#20854;&#20013;$d$&#26159;&#19978;&#19979;&#25991;&#21521;&#37327;&#30340;&#32500;&#25968;&#65292;$T$&#26159;&#26102;&#38388;&#36328;&#24230;&#12290;&#20026;&#20102;&#36798;&#21040;&#19979;&#38480;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;"&#20808;&#25506;&#32034;&#20877;&#25191;&#34892;"&#30340;&#31639;&#27861;&#65292;&#23427;&#20855;&#26377;&#20960;&#20046;&#21305;&#37197;&#30340;&#19978;&#38480;&#22238;&#24402;&#35823;&#24046;$\tilde{O}(d^{2/3} T^{2/3})$&#12290;&#24403;&#39033;&#30446;&#25968;&#37327;$K$&#24456;&#23567;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#36229;&#21442;&#25968;&#20197;&#36798;&#21040;&#26356;&#23567;&#30340;&#21518;&#24724;$\tilde{O}((d\log K)^{1/3}T^{2/3})$&#12290;
&lt;/p&gt;
&lt;p&gt;
Dueling bandits are widely used to model preferential feedback that is prevalent in machine learning applications such as recommendation systems and ranking. In this paper, we study the Borda regret minimization problem for dueling bandits, which aims to identify the item with the highest Borda score while minimizing the cumulative regret. We propose a new and highly expressive generalized linear dueling bandits model, which covers many existing models. Surprisingly, the Borda regret minimization problem turns out to be difficult, as we prove a regret lower bound of order $\Omega(d^{2/3} T^{2/3})$, where $d$ is the dimension of contextual vectors and $T$ is the time horizon. To attain the lower bound, we propose an explore-then-commit type algorithm, which has a nearly matching regret upper bound $\tilde{O}(d^{2/3} T^{2/3})$. When the number of items/arms $K$ is small, our algorithm can achieve a smaller regret $\tilde{O}( (d \log K)^{1/3} T^{2/3})$ with proper choices of hyperparamete
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.00848</link><description>&lt;p&gt;
&#20197;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#29702;&#35299;&#25193;&#25955;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#29992;&#19981;&#21516;&#30340;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#37117;&#26159;&#21152;&#26435;&#25439;&#22833;&#30340;&#29305;&#20363;&#65292;&#20854;&#20013;&#21152;&#26435;&#20989;&#25968;&#25351;&#23450;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#30340;&#26435;&#37325;&#12290;&#22343;&#21248;&#21152;&#26435;&#23545;&#24212;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#21407;&#21017;&#24615;&#36817;&#20284;ELBO&#30340;&#26368;&#22823;&#21270;&#12290;&#20294;&#26159;&#23454;&#38469;&#19978;&#65292;&#30001;&#20110;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#65292;&#30446;&#21069;&#30340;&#25193;&#25955;&#27169;&#22411;&#20351;&#29992;&#38750;&#22343;&#21248;&#21152;&#26435;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#65288;&#24102;&#26377;&#20219;&#20309;&#21152;&#26435;&#65289;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21487;&#20197;&#34987;&#20889;&#25104;&#19968;&#31181;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#24418;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#37117;&#26377;&#19968;&#20010;ELBO&#12290;&#22914;&#26524;&#26435;&#37325;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#65292;&#37027;&#20040;&#21152;&#26435;&#25439;&#22833;&#26159;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#30446;&#26631;&#65306;&#23427;&#22312;&#31616;&#21333;&#30340;&#25968;&#25454;&#22686;&#24378;&#19979;&#65288;&#21363;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#65289;&#19979;&#26368;&#22823;&#21270;ELBO&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#20294;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#27604;&#36739;&#21333;&#35843;&#21644;&#38750;&#21333;&#35843;&#26435;&#37325;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
&lt;/p&gt;</description></item><item><title>ddml&#26159;Stata&#20013;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#21253;&#65292;&#25903;&#25345;&#20116;&#31181;&#19981;&#21516;&#35745;&#37327;&#27169;&#22411;&#30340;&#22240;&#26524;&#21442;&#25968;&#20272;&#35745;&#65292;&#21487;&#20197;&#28789;&#27963;&#20272;&#35745;&#20869;&#29983;&#21464;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#35768;&#22810;&#29616;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31243;&#24207;&#20013;&#20860;&#23481;&#12290;&#25512;&#33616;&#19982;&#22534;&#21472;&#20272;&#35745;&#32467;&#21512;&#20351;&#29992;&#65292;&#25552;&#20379;&#20102;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2301.09397</link><description>&lt;p&gt;
ddml: Stata&#20013;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
ddml: Double/debiased machine learning in Stata. (arXiv:2301.09397v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09397
&lt;/p&gt;
&lt;p&gt;
ddml&#26159;Stata&#20013;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#21253;&#65292;&#25903;&#25345;&#20116;&#31181;&#19981;&#21516;&#35745;&#37327;&#27169;&#22411;&#30340;&#22240;&#26524;&#21442;&#25968;&#20272;&#35745;&#65292;&#21487;&#20197;&#28789;&#27963;&#20272;&#35745;&#20869;&#29983;&#21464;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#22312;&#35768;&#22810;&#29616;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31243;&#24207;&#20013;&#20860;&#23481;&#12290;&#25512;&#33616;&#19982;&#22534;&#21472;&#20272;&#35745;&#32467;&#21512;&#20351;&#29992;&#65292;&#25552;&#20379;&#20102;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;Stata&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;ddml&#30340;&#21253;&#65292;&#29992;&#20110;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DDML&#65289;&#12290;&#25903;&#25345;&#20116;&#31181;&#19981;&#21516;&#35745;&#37327;&#27169;&#22411;&#30340;&#22240;&#26524;&#21442;&#25968;&#20272;&#35745;&#65292;&#20801;&#35768;&#22312;&#26410;&#30693;&#20989;&#25968;&#24418;&#24335;&#21644;/&#25110;&#35768;&#22810;&#22806;&#29983;&#21464;&#37327;&#30340;&#35774;&#32622;&#20013;&#28789;&#27963;&#20272;&#35745;&#20869;&#29983;&#21464;&#37327;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;ddml&#19982;Stata&#20013;&#30340;&#35768;&#22810;&#29616;&#26377;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#31243;&#24207;&#20860;&#23481;&#12290;&#25105;&#20204;&#25512;&#33616;&#23558;DDML&#19982;&#22534;&#21472;&#20272;&#35745;&#32467;&#21512;&#20351;&#29992;&#65292;&#23558;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#22120;&#32452;&#21512;&#25104;&#26368;&#32456;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#33945;&#29305;&#21345;&#27931;&#35777;&#25454;&#26469;&#25903;&#25345;&#25105;&#20204;&#30340;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the package ddml for Double/Debiased Machine Learning (DDML) in Stata. Estimators of causal parameters for five different econometric models are supported, allowing for flexible estimation of causal effects of endogenous variables in settings with unknown functional forms and/or many exogenous variables. ddml is compatible with many existing supervised machine learning programs in Stata. We recommend using DDML in combination with stacking estimation which combines multiple machine learners into a final predictor. We provide Monte Carlo evidence to support our recommendation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26680;CUSUM&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#26356;&#25935;&#24863;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#26368;&#20248;&#31383;&#21475;&#38271;&#24230;&#65292;&#24341;&#20837;&#20102;&#36882;&#24402;&#35745;&#31639;&#31243;&#24207;&#26469;&#30830;&#20445;&#35745;&#31639;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#24658;&#23450;&#12290;</title><link>http://arxiv.org/abs/2211.15070</link><description>&lt;p&gt;
&#22312;&#32447;&#26680;CUSUM&#26041;&#27861;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Online Kernel CUSUM for Change-Point Detection. (arXiv:2211.15070v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26680;CUSUM&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#26356;&#25935;&#24863;&#65292;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#26368;&#20248;&#31383;&#21475;&#38271;&#24230;&#65292;&#24341;&#20837;&#20102;&#36882;&#24402;&#35745;&#31639;&#31243;&#24207;&#26469;&#30830;&#20445;&#35745;&#31639;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#24658;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#26680;Cumulative Sum (CUSUM)&#26041;&#27861;&#65292;&#29992;&#20110;&#21464;&#28857;&#26816;&#27979;&#65292;&#21033;&#29992;&#26680;&#32479;&#35745;&#37327;&#38598;&#21512;&#20013;&#30340;&#26368;&#22823;&#20540;&#26469;&#32771;&#34385;&#26410;&#30693;&#30340;&#21464;&#28857;&#20301;&#32622;&#12290;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#22914;Scan-B&#32479;&#35745;&#37327;&#65292;&#21363;&#23545;&#24212;&#20110;&#38750;&#21442;&#25968;Shewhart&#22270;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#23567;&#21464;&#21270;&#20855;&#26377;&#26356;&#39640;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#30340;&#20934;&#30830;&#20998;&#26512;&#36817;&#20284;&#20540;&#65306;&#24179;&#22343;&#36816;&#34892;&#38271;&#24230;&#65288;ARL&#65289;&#21644;&#39044;&#26399;&#26816;&#27979;&#24310;&#36831;&#65288;EDD&#65289;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#24314;&#31435;&#19968;&#20010;&#19982;ARL&#23545;&#25968;&#21516;&#38454;&#30340;&#26368;&#20248;&#31383;&#21475;&#38271;&#24230;&#65292;&#20197;&#30830;&#20445;&#30456;&#23545;&#20110;&#20855;&#26377;&#26080;&#38480;&#20869;&#23384;&#30340;&#29702;&#35770;&#27169;&#22411;&#33021;&#22815;&#20445;&#25345;&#26368;&#23567;&#21151;&#29575;&#25439;&#22833;&#12290;&#36825;&#31867;&#20284;&#20110;&#21442;&#25968;&#21464;&#28857;&#26816;&#27979;&#25991;&#29486;&#20013;&#30340;&#31383;&#21475;&#38480;&#21046;&#24191;&#20041;&#20284;&#28982;&#27604;&#65288;GLR&#65289;&#36807;&#31243;&#30340;&#32463;&#20856;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36882;&#24402;&#35745;&#31639;&#31243;&#24207;&#65292;&#29992;&#20110;&#26816;&#27979;&#32479;&#35745;&#37327;&#65292;&#20197;&#30830;&#20445;&#35745;&#31639;&#21644;&#20869;&#23384;&#22797;&#26434;&#24230;&#24658;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient online kernel Cumulative Sum (CUSUM) method for change-point detection that utilizes the maximum over a set of kernel statistics to account for the unknown change-point location. Our approach exhibits increased sensitivity to small changes compared to existing methods, such as the Scan-B statistic, which corresponds to a non-parametric Shewhart chart-type procedure. We provide accurate analytic approximations for two key performance metrics: the Average Run Length (ARL) and Expected Detection Delay (EDD), which enable us to establish an optimal window length on the order of the logarithm of ARL to ensure minimal power loss relative to an oracle procedure with infinite memory. Such a finding parallels the classic result for window-limited Generalized Likelihood Ratio (GLR) procedure in parametric change-point detection literature. Moreover, we introduce a recursive calculation procedure for detection statistics to ensure constant computational and memory complexi
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#21644;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#26356;&#26032;&#65292;&#22312;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#20013;&#25214;&#21040;&#20102;&#19968;&#20010;$\epsilon$-&#36817;&#20284;&#30340;&#31283;&#23450;&#28857;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\epsilon^{-2})$&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.09921</link><description>&lt;p&gt;
&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#27861;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Finite-time analysis of single-timescale actor-critic. (arXiv:2210.09921v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09921
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#21644;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#26356;&#26032;&#65292;&#22312;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#20013;&#25214;&#21040;&#20102;&#19968;&#20010;$\epsilon$-&#36817;&#20284;&#30340;&#31283;&#23450;&#28857;&#65292;&#24182;&#19988;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\epsilon^{-2})$&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24212;&#29992;&#20013;&#65292;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;&#26368;&#23454;&#38469;&#30340;&#21333;&#26102;&#38388;&#23610;&#24230;&#24418;&#24335;&#19979;&#65292;&#20854;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#20173;&#28982;&#19981;&#22815;&#29702;&#35299;&#12290;&#29616;&#26377;&#30340;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#20998;&#26512;&#24037;&#20316;&#20165;&#38480;&#20110;&#31616;&#21270;&#30340;i.i.d.&#37319;&#26679;&#25110;&#34920;&#26684;&#35774;&#32622;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#26356;&#23454;&#38469;&#30340;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#20013;&#65292;&#35780;&#35770;&#23478;&#37319;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#65292;&#24182;&#22312;&#27599;&#20010;&#28436;&#21592;&#27493;&#39588;&#20013;&#20351;&#29992;&#21333;&#20010;&#39532;&#23572;&#21487;&#22827;&#26679;&#26412;&#36827;&#34892;&#26356;&#26032;&#12290;&#20808;&#21069;&#30340;&#20998;&#26512;&#26080;&#27861;&#22312;&#36825;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22330;&#26223;&#20013;&#23454;&#29616;&#25910;&#25947;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#65292;&#22312;&#32447;&#21333;&#26102;&#38388;&#23610;&#24230;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#33021;&#22815;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\epsilon^{-2})$&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#19968;&#20010;$\epsilon$-&#36817;&#20284;&#30340;&#31283;&#23450;&#28857;&#65292;&#32780;&#22312;i.i.d.&#37319;&#26679;&#19979;&#65292;&#36825;&#20010;&#22797;&#26434;&#24230;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#36827;&#20026;$\mathcal{O}(\epsilon^{-2})$&#12290;&#25105;&#20204;&#30340;&#26032;&#26694;&#26550;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#19968;&#20010;
&lt;/p&gt;
&lt;p&gt;
Actor-critic methods have achieved significant success in many challenging applications. However, its finite-time convergence is still poorly understood in the most practical single-timescale form. Existing works on analyzing single-timescale actor-critic have been limited to i.i.d. sampling or tabular setting for simplicity. We investigate the more practical online single-timescale actor-critic algorithm on continuous state space, where the critic assumes linear function approximation and updates with a single Markovian sample per actor step. Previous analysis has been unable to establish the convergence for such a challenging scenario. We demonstrate that the online single-timescale actor-critic method provably finds an $\epsilon$-approximate stationary point with $\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity under standard assumptions, which can be further improved to $\mathcal{O}(\epsilon^{-2})$ under the i.i.d. sampling. Our novel framework systematically evaluates an
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#35757;&#32451;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#23545;&#20302;&#39057;&#20449;&#21495;&#20855;&#26377;&#25935;&#24863;&#24615;&#65292;&#36825;&#26159;&#22240;&#20026;&#33258;&#28982;&#22270;&#20687;&#30340;&#39057;&#29575;&#20998;&#24067;&#20351;&#22823;&#37096;&#20998;&#33021;&#37327;&#38598;&#20013;&#22312;&#20302;&#21040;&#20013;&#39057;&#12290;</title><link>http://arxiv.org/abs/2210.01257</link><description>&lt;p&gt;
&#20351;&#29992;CNN&#26469;&#27979;&#35797;&#34920;&#31034;&#25104;&#26412;&#29702;&#35770;&#30340;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Testing predictions of representation cost theory with CNNs. (arXiv:2210.01257v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01257
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#35757;&#32451;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#23545;&#20302;&#39057;&#20449;&#21495;&#20855;&#26377;&#25935;&#24863;&#24615;&#65292;&#36825;&#26159;&#22240;&#20026;&#33258;&#28982;&#22270;&#20687;&#30340;&#39057;&#29575;&#20998;&#24067;&#20351;&#22823;&#37096;&#20998;&#33021;&#37327;&#38598;&#20013;&#22312;&#20302;&#21040;&#20013;&#39057;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#32463;&#36807;&#35757;&#32451;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#23545;&#19981;&#21516;&#39057;&#29575;&#30340;&#20449;&#21495;&#20855;&#26377;&#19981;&#21516;&#30340;&#25935;&#24863;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#35768;&#22810;&#23454;&#35777;&#30740;&#31350;&#24050;&#32463;&#35760;&#24405;&#20102;CNNs&#23545;&#20302;&#39057;&#20449;&#21495;&#30340;&#25935;&#24863;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#35266;&#23519;&#21040;&#30340;&#25935;&#24863;&#24615;&#26159;&#33258;&#28982;&#22270;&#20687;&#39057;&#29575;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#24050;&#30693;&#22823;&#37096;&#20998;&#33021;&#37327;&#38598;&#20013;&#22312;&#20302;&#21040;&#20013;&#39057;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#20381;&#36182;&#20110;CNN&#30340;&#23618;&#27425;&#22312;&#39057;&#29575;&#31354;&#38388;&#20013;&#30340;&#34920;&#31034;&#65292;&#36825;&#20010;&#24819;&#27861;&#20043;&#21069;&#26366;&#34987;&#29992;&#26469;&#21152;&#36895;&#35745;&#31639;&#21644;&#30740;&#31350;&#32593;&#32476;&#35757;&#32451;&#31639;&#27861;&#30340;&#38544;&#24335;&#20559;&#24046;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#23578;&#26410;&#22312;&#27169;&#22411;&#40065;&#26834;&#24615;&#39046;&#22495;&#24212;&#29992;&#36807;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is widely acknowledged that trained convolutional neural networks (CNNs) have different levels of sensitivity to signals of different frequency. In particular, a number of empirical studies have documented CNNs sensitivity to low-frequency signals. In this work we show with theory and experiments that this observed sensitivity is a consequence of the frequency distribution of natural images, which is known to have most of its power concentrated in low-to-mid frequencies. Our theoretical analysis relies on representations of the layers of a CNN in frequency space, an idea that has previously been used to accelerate computations and study implicit bias of network training algorithms, but to the best of our knowledge has not been applied in the domain of model robustness.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#32452;&#21512;&#21644;&#20195;&#25968;&#35270;&#35282;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110; Gr&#246;bner &#22522;&#30784;&#30340; MCMC &#26041;&#27861; GrUES&#65292;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#30495;&#23454;&#32467;&#26500;&#21644;&#20272;&#35745;&#21518;&#39564;&#19978;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2210.00822</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#30340;&#32452;&#21512;&#21644;&#20195;&#25968;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Combinatorial and algebraic perspectives on the marginal independence structure of Bayesian networks. (arXiv:2210.00822v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00822
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#32452;&#21512;&#21644;&#20195;&#25968;&#35270;&#35282;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110; Gr&#246;bner &#22522;&#30784;&#30340; MCMC &#26041;&#27861; GrUES&#65292;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#30495;&#23454;&#32467;&#26500;&#21644;&#20272;&#35745;&#21518;&#39564;&#19978;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#20272;&#35745;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#25968;&#25454;&#20197;&#19968;&#20010;&#26080;&#21521;&#22270;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#34987;&#31216;&#20026;&#26080;&#26465;&#20214;&#20381;&#36182;&#22270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26080;&#26465;&#20214;&#20381;&#36182;&#22270;&#23545;&#24212;&#20110;&#20855;&#26377;&#30456;&#31561;&#29420;&#31435;&#24615;&#21644;&#20132;&#38598;&#25968;&#30340;&#22270;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19982;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26080;&#26465;&#20214;&#20381;&#36182;&#22270;&#30456;&#20851;&#30340;&#19968;&#20010;&#25299;&#25169;&#29702;&#24819;&#30340; Gr&#246;bner &#22522;&#30784;&#65292;&#28982;&#21518;&#36890;&#36807;&#39069;&#22806;&#30340;&#20108;&#39033;&#24335;&#20851;&#31995;&#23558;&#20854;&#25193;&#23637;&#20197;&#36830;&#25509;&#25152;&#26377;&#36825;&#20123;&#22270;&#30340;&#31354;&#38388;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#31181;&#21517;&#20026; GrUES (Gr&#246;bner-based Unconditional Equivalence Search) &#30340; MCMC &#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25152;&#24471;&#30340;&#31227;&#21160;&#24182;&#24212;&#29992;&#20110;&#21512;&#25104;&#39640;&#26031;&#25968;&#25454;&#12290;GrUES &#20197;&#27604;&#31616;&#21333;&#30340;&#29420;&#31435;&#24615;&#27979;&#35797;&#26356;&#39640;&#30340;&#36895;&#29575;&#24674;&#22797;&#30495;&#23454;&#30340;&#36793;&#38469;&#29420;&#31435;&#32467;&#26500;&#65292;&#21516;&#26102;&#36824;&#20135;&#29983;&#20102;&#19968;&#20010;&#21253;&#25324;&#30495;&#23454;&#32467;&#26500;&#30340;&#21518;&#39564;&#20272;&#35745;&#65292;&#20854;&#20013; $20\%$ &#30340; HPD &#32622;&#20449;&#21306;&#38388;&#21253;&#21547;&#30495;&#23454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the marginal independence structure of a Bayesian network from observational data in the form of an undirected graph called the unconditional dependence graph. We show that unconditional dependence graphs of Bayesian networks correspond to the graphs having equal independence and intersection numbers. Using this observation, a Gr\"obner basis for a toric ideal associated to unconditional dependence graphs of Bayesian networks is given and then extended by additional binomial relations to connect the space of all such graphs. An MCMC method, called GrUES (Gr\"obner-based Unconditional Equivalence Search), is implemented based on the resulting moves and applied to synthetic Gaussian data. GrUES recovers the true marginal independence structure via a penalized maximum likelihood or MAP estimate at a higher rate than simple independence tests while also yielding an estimate of the posterior, for which the $20\%$ HPD credible sets include the true struc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NN2Poly&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#31934;&#30830;&#22810;&#39033;&#24335;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#24847;&#28145;&#24230;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19988;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#65292;&#33021;&#22815;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#25552;&#20379;&#38750;&#24120;&#20934;&#30830;&#30340;&#36924;&#36817;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2112.11397</link><description>&lt;p&gt;
NN2Poly&#65306;&#29992;&#20110;&#28145;&#24230;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#39033;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NN2Poly: A polynomial representation for deep feed-forward artificial neural networks. (arXiv:2112.11397v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.11397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NN2Poly&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#31934;&#30830;&#22810;&#39033;&#24335;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#24847;&#28145;&#24230;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19988;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#65292;&#33021;&#22815;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#25552;&#20379;&#38750;&#24120;&#20934;&#30830;&#30340;&#36924;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#38750;&#24120;&#25104;&#21151;&#65292;&#20294;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#29702;&#35770;&#34892;&#20026;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;NN2Poly&#65306;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#19968;&#20010;&#26174;&#24335;&#22810;&#39033;&#24335;&#27169;&#22411;&#65292;&#20197;&#25552;&#20379;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;&#22810;&#23618;&#24863;&#30693;&#22120;&#25110;MLP&#65289;&#30340;&#31934;&#30830;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#20808;&#21069;&#24819;&#27861;&#65292;&#35813;&#24819;&#27861;&#20165;&#38480;&#20110;&#21333;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#20219;&#24847;&#28145;&#24230;MLP&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#22312;&#27599;&#23618;&#19978;&#20351;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#27888;&#21202;&#23637;&#24320;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#20960;&#20010;&#32452;&#21512;&#24615;&#36136;&#26469;&#35745;&#31639;&#25152;&#38656;&#22810;&#39033;&#24335;&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#27492;&#30446;&#26631;&#12290;&#20316;&#32773;&#35752;&#35770;&#20102;&#27492;&#26041;&#27861;&#30340;&#20027;&#35201;&#35745;&#31639;&#25361;&#25112;&#20197;&#21450;&#36890;&#36807;&#24341;&#20837;&#19968;&#20123;&#36924;&#36817;&#26469;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#20854;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#34920;&#26126;&#65292;&#23613;&#31649;NN2Poly&#26041;&#27861;&#31616;&#21333;&#19988;&#35745;&#31639;&#25104;&#26412;&#20302;&#65292;&#20294;&#23545;&#20110;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#65292;&#25552;&#20379;&#38750;&#24120;&#20934;&#30830;&#30340;&#22810;&#39033;&#24335;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability of neural networks and their underlying theoretical behavior remain an open field of study even after the great success of their practical applications, particularly with the emergence of deep learning. In this work, NN2Poly is proposed: a theoretical approach to obtain an explicit polynomial model that provides an accurate representation of an already trained fully-connected feed-forward artificial neural network (a multilayer perceptron or MLP). This approach extends a previous idea proposed in the literature, which was limited to single hidden layer networks, to work with arbitrarily deep MLPs in both regression and classification tasks. The objective of this paper is to achieve this by using a Taylor expansion on the activation function, at each layer, and then using several combinatorial properties to calculate the coefficients of the desired polynomials. Discussion is presented on the main computational challenges of this method, and the way to overcome them by i
&lt;/p&gt;</description></item><item><title>&#36335;&#24452;&#27491;&#21017;&#21270;&#20026;&#24182;&#34892;ReLU&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#32676;&#31232;&#30095;&#24615;&#24341;&#23548;&#23454;&#29616;&#20102;&#20984;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#31639;&#27861;&#65292;&#22312;&#25152;&#26377;&#25968;&#25454;&#32500;&#24230;&#19978;&#20855;&#22791;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2110.09548</link><description>&lt;p&gt;
&#36335;&#24452;&#27491;&#21017;&#21270;&#65306;&#19968;&#31181;&#23545;&#24182;&#34892;ReLU&#32593;&#32476;&#36827;&#34892;&#20984;&#24615;&#21644;&#31232;&#30095;&#24615;&#24341;&#23548;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Path Regularization: A Convexity and Sparsity Inducing Regularization for Parallel ReLU Networks. (arXiv:2110.09548v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.09548
&lt;/p&gt;
&lt;p&gt;
&#36335;&#24452;&#27491;&#21017;&#21270;&#20026;&#24182;&#34892;ReLU&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21270;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#32676;&#31232;&#30095;&#24615;&#24341;&#23548;&#23454;&#29616;&#20102;&#20984;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#31639;&#27861;&#65292;&#22312;&#25152;&#26377;&#25968;&#25454;&#32500;&#24230;&#19978;&#20855;&#22791;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#32972;&#21518;&#30340;&#22522;&#26412;&#21407;&#29702;&#26159;&#24403;&#21069;&#25991;&#29486;&#20013;&#26368;&#37325;&#35201;&#30340;&#24320;&#25918;&#38382;&#39064;&#20043;&#19968;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#26512;&#26041;&#27861;&#26469;&#25581;&#31034;&#20248;&#21270;&#26223;&#35266;&#20013;&#38544;&#34255;&#30340;&#20984;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#28145;&#24230;&#24182;&#34892;ReLU&#32593;&#32476;&#26550;&#26500;&#65292;&#20854;&#20063;&#21253;&#25324;&#26631;&#20934;&#30340;&#28145;&#24230;&#32593;&#32476;&#21644;ResNet&#20316;&#20026;&#20854;&#29305;&#20363;&#12290;&#28982;&#21518;&#25105;&#20204;&#34920;&#26126;&#65292;&#22522;&#20110;&#36335;&#24452;&#27491;&#21017;&#21270;&#30340;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#34920;&#31034;&#20026;&#19968;&#20010;&#31934;&#30830;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#31561;&#20215;&#30340;&#20984;&#38382;&#39064;&#26159;&#36890;&#36807;&#19968;&#31181;&#32676;&#31232;&#30095;&#24615;&#24341;&#23548;&#30340;&#35268;&#33539;&#36827;&#34892;&#27491;&#21017;&#21270;&#30340;&#12290;&#22240;&#27492;&#65292;&#36335;&#24452;&#27491;&#21017;&#21270;&#30340;&#24182;&#34892;ReLU&#32593;&#32476;&#21487;&#20197;&#34987;&#35270;&#20026;&#39640;&#32500;&#20013;&#19968;&#31181;&#31616;&#21270;&#30340;&#20984;&#27169;&#22411;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#30001;&#20110;&#21407;&#22987;&#30340;&#35757;&#32451;&#38382;&#39064;&#21487;&#33021;&#26080;&#27861;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35757;&#32451;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#25152;&#26377;&#25968;&#25454;&#32500;&#24230;&#19978;&#20855;&#26377;&#23436;&#20840;&#22810;&#39033;&#24335;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#36817;&#20284;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24378;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the fundamental principles behind the success of deep neural networks is one of the most important open questions in the current literature. To this end, we study the training problem of deep neural networks and introduce an analytic approach to unveil hidden convexity in the optimization landscape. We consider a deep parallel ReLU network architecture, which also includes standard deep networks and ResNets as its special cases. We then show that pathwise regularized training problems can be represented as an exact convex optimization problem. We further prove that the equivalent convex problem is regularized via a group sparsity inducing norm. Thus, a path regularized parallel ReLU network can be viewed as a parsimonious convex model in high dimensions. More importantly, since the original training problem may not be trainable in polynomial-time, we propose an approximate algorithm with a fully polynomial-time complexity in all data dimensions. Then, we prove strong glob
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#20844;&#24335;&#65292;&#31216;&#20026;&#28145;&#24230;&#29983;&#23384;&#21058;&#37327;&#21453;&#24212;&#20989;&#25968;&#65288;DeepSDRF&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20020;&#24202;&#29983;&#23384;&#25968;&#25454;&#20013;&#30340;&#36830;&#32493;&#27835;&#30103;&#25512;&#33616;&#38382;&#39064;&#12290;&#36890;&#36807;&#26657;&#27491;&#36873;&#25321;&#20559;&#24046;&#65292;DeepSDRF&#20272;&#35745;&#30340;&#27835;&#30103;&#25928;&#26524;&#21487;&#20197;&#29992;&#20110;&#24320;&#21457;&#25512;&#33616;&#31639;&#27861;&#12290;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#21307;&#23398;&#25968;&#25454;&#24211;&#19978;&#30340;&#27979;&#35797;&#20013;&#65292;DeepSDRF&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2108.10453</link><description>&lt;p&gt;
&#28145;&#24230;&#29983;&#23384;&#21058;&#37327;&#21453;&#24212;&#20989;&#25968;&#30340;&#36830;&#32493;&#27835;&#30103;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Continuous Treatment Recommendation with Deep Survival Dose Response Function. (arXiv:2108.10453v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.10453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#20844;&#24335;&#65292;&#31216;&#20026;&#28145;&#24230;&#29983;&#23384;&#21058;&#37327;&#21453;&#24212;&#20989;&#25968;&#65288;DeepSDRF&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20020;&#24202;&#29983;&#23384;&#25968;&#25454;&#20013;&#30340;&#36830;&#32493;&#27835;&#30103;&#25512;&#33616;&#38382;&#39064;&#12290;&#36890;&#36807;&#26657;&#27491;&#36873;&#25321;&#20559;&#24046;&#65292;DeepSDRF&#20272;&#35745;&#30340;&#27835;&#30103;&#25928;&#26524;&#21487;&#20197;&#29992;&#20110;&#24320;&#21457;&#25512;&#33616;&#31639;&#27861;&#12290;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#21307;&#23398;&#25968;&#25454;&#24211;&#19978;&#30340;&#27979;&#35797;&#20013;&#65292;DeepSDRF&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#20020;&#24202;&#29983;&#23384;&#25968;&#25454;&#35774;&#32622;&#20013;&#30340;&#36830;&#32493;&#27835;&#30103;&#25512;&#33616;&#38382;&#39064;&#30340;&#36890;&#29992;&#20844;&#24335;&#65292;&#31216;&#20026;&#28145;&#24230;&#29983;&#23384;&#21058;&#37327;&#21453;&#24212;&#20989;&#25968;&#65288;DeepSDRF&#65289;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#21382;&#21490;&#25968;&#25454;&#20013;&#20165;&#20165;&#36890;&#36807;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#65288;&#28151;&#26434;&#22240;&#23376;&#65289;&#23545;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#21644;&#20107;&#20214;&#21457;&#29983;&#26102;&#38388;&#32467;&#26524;&#37117;&#26377;&#24433;&#21709;&#30340;&#26465;&#20214;&#24179;&#22343;&#21058;&#37327;&#21453;&#24212;&#65288;CADR&#65289;&#20989;&#25968;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#20174;DeepSDRF&#20013;&#20272;&#35745;&#30340;&#27835;&#30103;&#25928;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#24320;&#21457;&#20855;&#26377;&#36873;&#25321;&#20559;&#24046;&#26657;&#27491;&#30340;&#25512;&#33616;&#31639;&#27861;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#38543;&#26426;&#25628;&#32034;&#21644;&#24378;&#21270;&#23398;&#20064;&#30340;&#20004;&#31181;&#25512;&#33616;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#22312;&#24739;&#32773;&#32467;&#26524;&#26041;&#38754;&#34920;&#29616;&#30456;&#20284;&#12290;&#25105;&#20204;&#22312;&#22823;&#37327;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;eICU&#30740;&#31350;&#26426;&#26500;&#65288;eRI&#65289;&#25968;&#25454;&#24211;&#19978;&#27979;&#35797;&#20102;DeepSDRF&#21644;&#30456;&#24212;&#30340;&#25512;&#33616;&#22120;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#27425;&#22312;&#21307;&#23398;&#32972;&#26223;&#19979;&#20351;&#29992;&#22240;&#26524;&#27169;&#22411;&#26469;&#35299;&#20915;&#35266;&#23519;&#25968;&#25454;&#20013;&#30340;&#36830;&#32493;&#27835;&#30103;&#25928;&#24212;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a general formulation for continuous treatment recommendation problems in settings with clinical survival data, which we call the Deep Survival Dose Response Function (DeepSDRF). That is, we consider the problem of learning the conditional average dose response (CADR) function solely from historical data in which observed factors (confounders) affect both observed treatment and time-to-event outcomes. The estimated treatment effect from DeepSDRF enables us to develop recommender algorithms with the correction for selection bias. We compared two recommender approaches based on random search and reinforcement learning and found similar performance in terms of patient outcome. We tested the DeepSDRF and the corresponding recommender on extensive simulation studies and the eICU Research Institute (eRI) database. To the best of our knowledge, this is the first time that causal models are used to address the continuous treatment effect with observational data in a medical context.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38548;&#24320;&#24335;&#35797;&#39564;&#30340;&#26368;&#20248;&#35774;&#35745;&#38382;&#39064;&#12290;&#23545;&#20110;&#38750;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#35299;&#65307;&#23545;&#20110;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;&#31934;&#24230;&#23548;&#21521;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#65288;PGAE&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#26469;&#26368;&#22823;&#21270;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#39044;&#26399;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/1911.03764</link><description>&lt;p&gt;
&#38548;&#24320;&#24335;&#35797;&#39564;&#30340;&#26368;&#20248;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Experimental Design for Staggered Rollouts. (arXiv:1911.03764v5 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.03764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38548;&#24320;&#24335;&#35797;&#39564;&#30340;&#26368;&#20248;&#35774;&#35745;&#38382;&#39064;&#12290;&#23545;&#20110;&#38750;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#35299;&#65307;&#23545;&#20110;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;&#31934;&#24230;&#23548;&#21521;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#65288;PGAE&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#26469;&#26368;&#22823;&#21270;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#39044;&#26399;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#26102;&#26399;&#20869;&#26576;&#32452;&#25968;&#25454;&#21333;&#20803;&#30340;&#27835;&#30103;&#24320;&#22987;&#26102;&#38388;&#23384;&#22312;&#24046;&#24322;&#26102;&#65292;&#23545;&#23454;&#39564;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#38382;&#39064;&#12290;&#35774;&#35745;&#38382;&#39064;&#28041;&#21450;&#36873;&#25321;&#27599;&#20010;&#25968;&#25454;&#21333;&#20803;&#30340;&#21021;&#22987;&#27835;&#30103;&#26102;&#38388;&#20197;&#20415;&#26368;&#31934;&#30830;&#22320;&#20272;&#35745;&#27835;&#30103;&#30340;&#30636;&#26102;&#25928;&#24212;&#21644;&#32047;&#31215;&#25928;&#24212;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#38750;&#33258;&#36866;&#24212;&#23454;&#39564;&#65292;&#20854;&#20013;&#25152;&#26377;&#30340;&#27835;&#30103;&#20998;&#37197;&#20915;&#31574;&#37117;&#22312;&#23454;&#39564;&#24320;&#22987;&#20043;&#21069;&#20570;&#20986;&#12290;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#26159;NP&#38590;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#26368;&#20248;&#35299;&#12290;&#22312;&#35813;&#35299;&#20915;&#26041;&#26696;&#19979;&#65292;&#27599;&#20010;&#26102;&#26399;&#36827;&#20837;&#27835;&#30103;&#30340;&#20998;&#25968;&#26368;&#21021;&#36739;&#20302;&#65292;&#28982;&#21518;&#21464;&#39640;&#65292;&#26368;&#21518;&#20877;&#27425;&#38477;&#20302;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#22312;&#25910;&#38598;&#27599;&#20010;&#26102;&#26399;&#30340;&#25968;&#25454;&#21518;&#26356;&#26032;&#32487;&#32493;&#23454;&#39564;&#21644;&#27835;&#30103;&#20998;&#37197;&#20915;&#31574;&#12290;&#23545;&#20110;&#33258;&#36866;&#24212;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;&#31934;&#24230;&#23548;&#21521;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#65288;PGAE&#65289;&#31639;&#27861;&#65292;&#23427;&#20351;&#29992;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#26469;&#26368;&#22823;&#21270;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#39044;&#26399;&#31934;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;PGAE&#31639;&#27861;&#36798;&#21040;&#20102;&#24724;&#24680;&#30340;&#19979;&#38480;&#65292;&#24724;&#24680;&#23450;&#20041;&#20026;&#26399;&#26395;&#32047;&#35745;&#24179;&#26041;&#26631;&#20934;&#35823;&#24046;&#21644;&#20219;&#24847;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#25152;&#33021;&#23454;&#29616;&#30340;&#26368;&#20339;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the design and analysis of experiments conducted on a set of units over multiple time periods where the starting time of the treatment may vary by unit. The design problem involves selecting an initial treatment time for each unit in order to most precisely estimate both the instantaneous and cumulative effects of the treatment. We first consider non-adaptive experiments, where all treatment assignment decisions are made prior to the start of the experiment. For this case, we show that the optimization problem is generally NP-hard, and we propose a near-optimal solution. Under this solution, the fraction entering treatment each period is initially low, then high, and finally low again. Next, we study an adaptive experimental design problem, where both the decision to continue the experiment and treatment assignment decisions are updated after each period's data is collected. For the adaptive case, we propose a new algorithm, the Precision-Guided Adaptive Experim
&lt;/p&gt;</description></item></channel></rss>