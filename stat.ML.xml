<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.05928</link><description>&lt;p&gt;
&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65306;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#30340;&#24179;&#26041;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#24615;&#65288;&#946;-&#28151;&#21512;&#65289;&#25968;&#25454;&#21644;&#24179;&#26041;&#25439;&#22833;&#30340;&#32479;&#35745;&#23398;&#20064;&#65292;&#22312;&#19968;&#20010;&#20551;&#35774;&#31867;&#21035;&#934;_p&#30340;&#23376;&#38598;F&#20013;&#65292;&#20854;&#20013;&#934;_p&#26159;&#33539;&#25968;&#8741;f&#8741;_&#934;_p&#8801;sup_m&#8805;1 m^{-1/p}&#8741;f&#8741;_L^m&#65292;&#20854;&#20013;p&#8712;[2&#65292;&#8734;]&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#25968;&#25454;&#30340;&#23398;&#20064;&#20013;&#23547;&#25214;&#23574;&#38160;&#30340;&#22122;&#22768;&#20132;&#20114;&#39033;&#25110;&#26041;&#24046;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#20219;&#20309;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20856;&#22411;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#26174;&#31034;&#20986;&#26041;&#24046;&#20195;&#29702;&#36890;&#36807;&#24213;&#23618;&#21327;&#21464;&#37327;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#36827;&#34892;&#20102;&#20056;&#31215;&#32553;&#20943;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#22312;&#25105;&#20204;&#30340;&#20551;&#35774;&#31867;&#21035;F&#19978;&#65292;L^2&#21644;&#934;_p&#30340;&#25299;&#25169;&#26159;&#21487;&#27604;&#36739;&#30340;&#65292;&#21363;&#934;_p&#26159;&#19968;&#20010;&#24369;&#20122;&#39640;&#26031;&#31867;&#21035;&#65306;&#8741;f&#8741;_&#934;_p&#8818;&#8741;f&#8741;_L^2^&#951;&#65292;&#20854;&#20013;&#951;&#8712;(0&#65292;1]&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#22312;&#20854;&#20027;&#23548;&#39033;&#20013;&#21482;&#23454;&#29616;&#20102;&#19968;&#31181;&#21482;&#20381;&#36182;&#20110;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#35768;&#22810;&#20381;&#36182;&#24615;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study statistical learning with dependent ($\beta$-mixing) data and square loss in a hypothesis class $\mathscr{F}\subset L_{\Psi_p}$ where $\Psi_p$ is the norm $\|f\|_{\Psi_p} \triangleq \sup_{m\geq 1} m^{-1/p} \|f\|_{L^m} $ for some $p\in [2,\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\Psi_p$ are comparable on our hypothesis class $\mathscr{F}$ -- that is, $\mathscr{F}$ is a weakly sub-Gaussian class: $\|f\|_{\Psi_p} \lesssim \|f\|_{L^2}^\eta$ for some $\eta\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30340;&#22266;&#23450;&#20998;&#37197;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20197;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#29702;&#35299;&#12290;</title><link>https://arxiv.org/abs/2402.05878</link><description>&lt;p&gt;
&#22522;&#20110;&#20808;&#39564;&#20381;&#36182;&#20998;&#37197;&#30340;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Prior-Dependent Allocations for Bayesian Fixed-Budget Best-Arm Identification in Structured Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30340;&#22266;&#23450;&#20998;&#37197;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#20197;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#23637;&#29616;&#20986;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#21152;&#28145;&#20102;&#25105;&#20204;&#23545;&#20110;&#35813;&#38382;&#39064;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#30340;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#21644;&#29615;&#22659;&#32467;&#26500;&#20351;&#29992;&#22266;&#23450;&#20998;&#37197;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#23427;&#22312;&#24615;&#33021;&#19978;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#20998;&#23618;BAI&#30340;&#39318;&#20010;&#20808;&#39564;&#20381;&#36182;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#24341;&#20837;&#20102;&#26032;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#65292;&#23427;&#33021;&#24471;&#21040;&#26356;&#32039;&#23494;&#30340;&#22810;&#33218;BAI&#30028;&#38480;&#12290;&#25105;&#20204;&#24191;&#27867;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#22266;&#23450;&#39044;&#31639;BAI&#26041;&#27861;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#19968;&#33268;&#19988;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#25913;&#36827;&#20102;&#23545;&#20110;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#20013;&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;BAI&#30340;&#29702;&#35299;&#65292;&#24182;&#31361;&#20986;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Bayesian fixed-budget best-arm identification (BAI) in structured bandits. We propose an algorithm that uses fixed allocations based on the prior information and the structure of the environment. We provide theoretical bounds on its performance across diverse models, including the first prior-dependent upper bounds for linear and hierarchical BAI. Our key contribution is introducing new proof methods that result in tighter bounds for multi-armed BAI compared to existing methods. We extensively compare our approach to other fixed-budget BAI methods, demonstrating its consistent and robust performance in various settings. Our work improves our understanding of Bayesian fixed-budget BAI in structured bandits and highlights the effectiveness of our approach in practical scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#32852;&#37030;&#23398;&#20064;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26080;&#27169;&#22411;Q-learning&#31639;&#27861;FedLCB-Q&#12290;&#36890;&#36807;&#21512;&#20316;&#21033;&#29992;&#22810;&#20010;&#20195;&#29702;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#29305;&#23450;&#30340;&#23398;&#20064;&#36895;&#29575;&#35843;&#24230;&#21644;&#32858;&#21512;&#26041;&#27861;&#65292;FedLCB-Q&#23454;&#29616;&#20102;&#32447;&#24615;&#21152;&#36895;&#12290;</title><link>https://arxiv.org/abs/2402.05876</link><description>&lt;p&gt;
&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65306;&#21512;&#20316;&#21333;&#19968;&#31574;&#30053;&#21363;&#21487;&#35206;&#30422;
&lt;/p&gt;
&lt;p&gt;
Federated Offline Reinforcement Learning: Collaborative Single-Policy Coverage Suffices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05876
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#32852;&#37030;&#23398;&#20064;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26080;&#27169;&#22411;Q-learning&#31639;&#27861;FedLCB-Q&#12290;&#36890;&#36807;&#21512;&#20316;&#21033;&#29992;&#22810;&#20010;&#20195;&#29702;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#65292;&#24182;&#20351;&#29992;&#29305;&#23450;&#30340;&#23398;&#20064;&#36895;&#29575;&#35843;&#24230;&#21644;&#32858;&#21512;&#26041;&#27861;&#65292;FedLCB-Q&#23454;&#29616;&#20102;&#32447;&#24615;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#20351;&#29992;&#31163;&#32447;&#25968;&#25454;&#26469;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#22312;&#26080;&#27861;&#22312;&#32447;&#25910;&#38598;&#25968;&#25454;&#25110;&#25104;&#26412;&#39640;&#26114;&#30340;&#20851;&#38190;&#24212;&#29992;&#20013;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#32852;&#37030;&#23398;&#20064;&#22312;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22909;&#22788;&#65292;&#24182;&#26088;&#22312;&#21512;&#20316;&#21033;&#29992;&#22810;&#20010;&#20195;&#29702;&#30340;&#31163;&#32447;&#25968;&#25454;&#38598;&#12290;&#38024;&#23545;&#26377;&#38480;&#26102;&#27573;&#30340;&#34920;&#26684;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;FedLCB-Q&#65292;&#36825;&#26159;&#19968;&#31181;&#38024;&#23545;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#37327;&#36523;&#23450;&#21046;&#30340;&#27969;&#34892;&#30340;&#26080;&#27169;&#22411;Q-learning&#31639;&#27861;&#30340;&#21464;&#31181;&#12290;FedLCB-Q&#20351;&#29992;&#26032;&#39062;&#30340;&#23398;&#20064;&#36895;&#29575;&#35843;&#24230;&#22312;&#20195;&#29702;&#22788;&#26356;&#26032;&#26412;&#22320;Q&#20989;&#25968;&#65292;&#24182;&#20351;&#29992;&#37325;&#35201;&#24615;&#24179;&#22343;&#21644;&#31934;&#24515;&#35774;&#35745;&#30340;&#24754;&#35266;&#24809;&#32602;&#39033;&#22312;&#20013;&#22830;&#26381;&#21153;&#22120;&#19978;&#32858;&#21512;&#23427;&#20204;&#12290;&#25105;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#36866;&#24403;&#36873;&#25321;&#30340;&#21442;&#25968;&#21644;&#21516;&#27493;&#26102;&#38388;&#34920;&#19979;&#65292;FedLCB-Q&#22312;&#20195;&#29702;&#25968;&#37327;&#19978;&#23454;&#29616;&#20102;&#32447;&#24615;&#21152;&#36895;&#65292;&#32780;&#19981;&#38656;&#35201;&#20010;&#21035;&#20195;&#29702;&#25317;&#26377;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL), which seeks to learn an optimal policy using offline data, has garnered significant interest due to its potential in critical applications where online data collection is infeasible or expensive. This work explores the benefit of federated learning for offline RL, aiming at collaboratively leveraging offline datasets at multiple agents. Focusing on finite-horizon episodic tabular Markov decision processes (MDPs), we design FedLCB-Q, a variant of the popular model-free Q-learning algorithm tailored for federated offline RL. FedLCB-Q updates local Q-functions at agents with novel learning rate schedules and aggregates them at a central server using importance averaging and a carefully designed pessimistic penalty term. Our sample complexity analysis reveals that, with appropriately chosen parameters and synchronization schedules, FedLCB-Q achieves linear speedup in terms of the number of agents without requiring high-quality datasets at individual age
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#32534;&#30721;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#26174;&#24335;&#22320;&#34920;&#31034;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#24182;&#22312;&#22270;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.05862</link><description>&lt;p&gt;
&#35753;&#20320;&#30340;&#22270;&#26469;&#35828;&#35805;&#65306;&#20026;LLMs&#32534;&#30721;&#32467;&#26500;&#21270;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Let Your Graph Do the Talking: Encoding Structured Data for LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#32534;&#30721;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#33021;&#22815;&#26174;&#24335;&#22320;&#34920;&#31034;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#24182;&#22312;&#22270;&#25512;&#29702;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22914;&#20309;&#26368;&#26377;&#25928;&#22320;&#23558;&#32467;&#26500;&#21270;&#25968;&#25454;&#32534;&#30721;&#25104;&#24207;&#21015;&#24418;&#24335;&#65292;&#20197;&#20379;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20351;&#29992;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26126;&#30830;&#34920;&#31034;LLMs&#30340;&#32467;&#26500;&#21270;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;GraphToken&#65292;&#23398;&#20064;&#20102;&#19968;&#31181;&#32534;&#30721;&#20989;&#25968;&#65292;&#20197;&#26174;&#24335;&#32467;&#26500;&#21270;&#20449;&#24687;&#25193;&#23637;&#25552;&#31034;&#35821;&#12290;&#19982;&#20854;&#20182;&#19987;&#27880;&#20110;&#26377;&#38480;&#39046;&#22495;&#65288;&#20363;&#22914;&#30693;&#35782;&#22270;&#34920;&#31034;&#65289;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26159;&#39318;&#27425;&#38024;&#23545;&#19968;&#33324;&#32467;&#26500;&#21270;&#25968;&#25454;&#32534;&#30721;&#36827;&#34892;&#30740;&#31350;&#65292;&#29992;&#20110;&#21508;&#31181;&#25512;&#29702;&#20219;&#21153;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26126;&#30830;&#34920;&#31034;&#22270;&#32467;&#26500;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#22270;&#25512;&#29702;&#20219;&#21153;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#22312;GraphQA&#22522;&#20934;&#27979;&#35797;&#20013;&#30475;&#21040;&#20102;&#25972;&#20307;&#30340;&#25913;&#36827; - &#22312;&#33410;&#28857;&#12289;&#36793;&#21644;&#22270;&#32423;&#20219;&#21153;&#19978;&#39640;&#36798;73%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can we best encode structured data into sequential form for use in large language models (LLMs)? In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs. Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information. Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks. We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks. Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21457;&#29616;&#65292;&#22312;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#26410;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#21462;&#20915;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36951;&#20256;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.05835</link><description>&lt;p&gt;
&#19981;&#21487;&#35265;&#25968;&#25454;&#21462;&#20915;&#20110;&#24050;&#30693;&#20449;&#24687;&#30340;&#22810;&#23569;
&lt;/p&gt;
&lt;p&gt;
How Much is Unseen Depends Chiefly on Information About the Seen
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05835
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21457;&#29616;&#65292;&#22312;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#26410;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#21462;&#20915;&#20110;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36951;&#20256;&#31639;&#27861;&#65292;&#33021;&#22815;&#26681;&#25454;&#26679;&#26412;&#25214;&#21040;&#19968;&#20010;&#20855;&#26377;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20045;&#19968;&#30475;&#21487;&#33021;&#26377;&#20123;&#36829;&#21453;&#30452;&#35273;&#65306;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#39044;&#26399;&#20013;&#65292;&#26410;&#30693;&#31181;&#32676;&#20013;&#23646;&#20110;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#27809;&#26377;&#20986;&#29616;&#30340;&#31867;&#30340;&#25968;&#25454;&#28857;&#30340;&#27604;&#20363;&#20960;&#20046;&#23436;&#20840;&#30001;&#35757;&#32451;&#25968;&#25454;&#20013;&#20986;&#29616;&#30456;&#21516;&#27425;&#25968;&#30340;&#31867;&#30340;&#25968;&#37327;$f_k$&#30830;&#23450;&#12290;&#34429;&#28982;&#22312;&#29702;&#35770;&#19978;&#25105;&#20204;&#35777;&#26126;&#20102;&#30001;&#35813;&#20272;&#35745;&#37327;&#24341;&#36215;&#30340;&#20559;&#24046;&#22312;&#26679;&#26412;&#22823;&#23567;&#25351;&#25968;&#32423;&#34928;&#20943;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#39640;&#26041;&#24046;&#38459;&#27490;&#25105;&#20204;&#30452;&#25509;&#20351;&#29992;&#23427;&#20316;&#20026;&#26679;&#26412;&#35206;&#30422;&#20272;&#35745;&#37327;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#23545;$f_k$&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#25551;&#36848;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22810;&#20010;&#19981;&#21516;&#26399;&#26395;&#20540;&#34920;&#31034;&#30340;&#25628;&#32034;&#31354;&#38388;&#65292;&#21487;&#20197;&#30830;&#23450;&#22320;&#23454;&#20363;&#21270;&#20026;&#20272;&#35745;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36716;&#21521;&#20248;&#21270;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#36951;&#20256;&#31639;&#27861;&#65292;&#20165;&#26681;&#25454;&#26679;&#26412;&#25628;&#32034;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#26368;&#23567;&#30340;&#20272;&#35745;&#37327;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#36951;&#20256;&#31639;&#27861;&#21457;&#29616;&#20102;&#20855;&#26377;&#26126;&#26174;&#36739;&#23567;&#26041;&#24046;&#30340;&#20272;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
It might seem counter-intuitive at first: We find that, in expectation, the proportion of data points in an unknown population-that belong to classes that do not appear in the training data-is almost entirely determined by the number $f_k$ of classes that do appear in the training data the same number of times. While in theory we show that the difference of the induced estimator decays exponentially in the size of the sample, in practice the high variance prevents us from using it directly for an estimator of the sample coverage. However, our precise characterization of the dependency between $f_k$'s induces a large search space of different representations of the expected value, which can be deterministically instantiated as estimators. Hence, we turn to optimization and develop a genetic algorithm that, given only the sample, searches for an estimator with minimal mean-squared error (MSE). In our experiments, our genetic algorithm discovers estimators that have a substantially smalle
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.05806</link><description>&lt;p&gt;
&#20851;&#20110;&#28145;&#24230;&#20998;&#31867;&#22120;&#30340;&#26657;&#20934;&#21644;&#31526;&#21512;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Calibration and Conformal Prediction of Deep Classifiers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#23545;&#31526;&#21512;&#39044;&#27979;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#26657;&#20934;&#23545;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20998;&#31867;&#24212;&#29992;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22522;&#20110;&#20998;&#31867;&#22120;&#30340;&#39044;&#27979;&#38656;&#35201;&#20276;&#38543;&#19968;&#20123;&#32622;&#20449;&#24230;&#25351;&#31034;&#12290;&#38024;&#23545;&#36825;&#20010;&#30446;&#26631;&#65292;&#26377;&#20004;&#31181;&#27969;&#34892;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#65306;1&#65289;&#26657;&#20934;&#65306;&#20462;&#25913;&#20998;&#31867;&#22120;&#30340;softmax&#20540;&#65292;&#20351;&#20854;&#26368;&#22823;&#20540;&#65288;&#19982;&#39044;&#27979;&#30456;&#20851;&#65289;&#26356;&#22909;&#22320;&#20272;&#35745;&#27491;&#30830;&#27010;&#29575;&#65307;&#21644;2&#65289;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#65306;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;softmax&#20540;&#30340;&#20998;&#25968;&#65292;&#20174;&#20013;&#20135;&#29983;&#19968;&#32452;&#39044;&#27979;&#65292;&#20855;&#26377;&#29702;&#35770;&#19978;&#20445;&#35777;&#27491;&#30830;&#31867;&#21035;&#36793;&#38469;&#35206;&#30422;&#30340;&#29305;&#24615;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#20004;&#31181;&#25351;&#31034;&#37117;&#21487;&#33021;&#26159;&#38656;&#35201;&#30340;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#26410;&#24471;&#21040;&#30740;&#31350;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28201;&#24230;&#32553;&#25918;&#65292;&#36825;&#26159;&#26368;&#24120;&#35265;&#30340;&#26657;&#20934;&#25216;&#26415;&#65292;&#23545;&#37325;&#35201;&#30340;CP&#26041;&#27861;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#20102;&#19968;&#39033;&#24191;&#27867;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#20854;&#20013;&#26174;&#31034;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#27934;&#23519;&#65292;&#20854;&#20013;&#21253;&#25324;&#20196;&#20154;&#24778;&#35766;&#30340;&#21457;&#29616;&#65292;&#21363;&#26657;&#20934;&#23545;&#27969;&#34892;&#30340;&#33258;&#36866;&#24212;C&#26041;&#27861;&#20135;&#29983;&#20102;&#26377;&#23475;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many classification applications, the prediction of a deep neural network (DNN) based classifier needs to be accompanied with some confidence indication. Two popular post-processing approaches for that aim are: 1) calibration: modifying the classifier's softmax values such that their maximum (associated with the prediction) better estimates the correctness probability; and 2) conformal prediction (CP): devising a score (based on the softmax values) from which a set of predictions with theoretically guaranteed marginal coverage of the correct class is produced. While in practice both types of indications can be desired, so far the interplay between them has not been investigated. Toward filling this gap, in this paper we study the effect of temperature scaling, arguably the most common calibration technique, on prominent CP methods. We start with an extensive empirical study that among other insights shows that, surprisingly, calibration has a detrimental effect on popular adaptive C
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#27010;&#29575;&#29420;&#31435;&#24615;&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;2000&#20010;&#28508;&#22312;&#28304;&#30340;&#20020;&#24202;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#22312;&#32954;&#30284;&#39044;&#27979;&#20013;&#30340;&#21028;&#21035;&#33021;&#21147;&#20248;&#20110;&#21407;&#22987;&#21464;&#37327;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#26410;&#34987;&#35786;&#26029;&#30340;&#30284;&#30151;&#30340;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2402.05802</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#21457;&#29616;&#20020;&#24202;&#30142;&#30149;&#29305;&#24449;&#30340;&#27010;&#29575;&#29420;&#31435;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Discovery of Clinical Disease Signatures Using Probabilistic Independence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05802
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#21644;&#27010;&#29575;&#29420;&#31435;&#24615;&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;2000&#20010;&#28508;&#22312;&#28304;&#30340;&#20020;&#24202;&#29305;&#24449;&#65292;&#36825;&#20123;&#29305;&#24449;&#22312;&#32954;&#30284;&#39044;&#27979;&#20013;&#30340;&#21028;&#21035;&#33021;&#21147;&#20248;&#20110;&#21407;&#22987;&#21464;&#37327;&#65292;&#24182;&#19988;&#33021;&#22815;&#35782;&#21035;&#26410;&#34987;&#35786;&#26029;&#30340;&#30284;&#30151;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20020;&#24202;&#30142;&#30149;&#30340;&#35786;&#26029;&#19981;&#22815;&#20934;&#30830;&#21487;&#33021;&#23548;&#33268;&#24456;&#22810;&#27835;&#30103;&#22833;&#36133;&#30340;&#24773;&#20917;&#65292;&#21363;&#20351;&#26159;&#24120;&#35265;&#30142;&#30149;&#21644;&#27835;&#30103;&#12290;&#36890;&#36807;&#20351;&#29992;&#36275;&#22815;&#22823;&#30340;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#20351;&#29992;&#26080;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#26469;&#26356;&#31934;&#30830;&#22320;&#23450;&#20041;&#20020;&#24202;&#30142;&#30149;&#27169;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27010;&#29575;&#29420;&#31435;&#24615;&#26469;&#35299;&#24320;&#30142;&#30149;&#28508;&#22312;&#28304;&#22240;&#23545;&#21307;&#30103;&#35760;&#24405;&#30340;&#24433;&#21709;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20174;269,099&#20221;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#30340;9195&#20010;&#21464;&#37327;&#20013;&#25512;&#26029;&#20986;&#20102;2000&#20010;&#28508;&#22312;&#28304;&#30340;&#20020;&#24202;&#29305;&#24449;&#12290;&#36825;&#20123;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#22312;&#19968;&#20010;&#32954;&#30284;&#39044;&#27979;&#20219;&#21153;&#20013;&#27604;&#21407;&#22987;&#21464;&#37327;&#26377;&#26356;&#22909;&#30340;&#21028;&#21035;&#33021;&#21147;&#65292;&#35813;&#20219;&#21153;&#23545;&#25512;&#26029;&#31639;&#27861;&#26469;&#35828;&#26159;&#26410;&#30693;&#30340;&#65292;&#33021;&#22815;&#39044;&#27979;&#20986;&#26080;&#30284;&#30151;&#21382;&#21490;&#30340;&#24739;&#32773;&#22312;&#21457;&#29616;&#23396;&#31435;&#30340;&#32954;&#32467;&#33410;&#20043;&#21069;&#30340;3&#24180;&#20869;&#30340;&#24694;&#24615;&#30142;&#30149;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20123;&#29305;&#24449;&#30340;&#35299;&#37322;&#33021;&#21147;&#26356;&#24378;&#65292;&#33021;&#22815;&#35782;&#21035;&#20986;&#35768;&#22810;&#24739;&#32773;&#20013;&#26126;&#26174;&#26410;&#34987;&#35786;&#26029;&#30340;&#30284;&#30151;&#30340;&#32467;&#33410;&#21069;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Insufficiently precise diagnosis of clinical disease is likely responsible for many treatment failures, even for common conditions and treatments. With a large enough dataset, it may be possible to use unsupervised machine learning to define clinical disease patterns more precisely. We present an approach to learning these patterns by using probabilistic independence to disentangle the imprint on the medical record of causal latent sources of disease. We inferred a broad set of 2000 clinical signatures of latent sources from 9195 variables in 269,099 Electronic Health Records. The learned signatures produced better discrimination than the original variables in a lung cancer prediction task unknown to the inference algorithm, predicting 3-year malignancy in patients with no history of cancer before a solitary lung nodule was discovered. More importantly, the signatures' greater explanatory power identified pre-nodule signatures of apparently undiagnosed cancer in many of those patients.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformers&#22312;&#19978;&#19979;&#25991;&#33258;&#22238;&#24402;&#23398;&#20064;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#27169;&#22411;&#21457;&#29616;&#20102;&#20854;&#39044;&#27979;&#19979;&#19968;&#20010;&#26631;&#35760;&#30340;&#36807;&#31243;&#12290;&#38024;&#23545;&#19981;&#21516;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21333;&#23618;&#32447;&#24615;Transformer&#23454;&#29616;&#20102;&#26799;&#24230;&#19979;&#38477;&#20197;&#21450;&#27491;&#20132;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.05787</link><description>&lt;p&gt;
Transformers&#22312;&#19978;&#19979;&#25991;&#33258;&#22238;&#24402;&#23398;&#20064;&#20013;&#30340;&#34920;&#29616;&#22914;&#20309;&#65311;
&lt;/p&gt;
&lt;p&gt;
How do Transformers perform In-Context Autoregressive Learning?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformers&#22312;&#19978;&#19979;&#25991;&#33258;&#22238;&#24402;&#23398;&#20064;&#20013;&#30340;&#34920;&#29616;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#27169;&#22411;&#21457;&#29616;&#20102;&#20854;&#39044;&#27979;&#19979;&#19968;&#20010;&#26631;&#35760;&#30340;&#36807;&#31243;&#12290;&#38024;&#23545;&#19981;&#21516;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21333;&#23618;&#32447;&#24615;Transformer&#23454;&#29616;&#20102;&#26799;&#24230;&#19979;&#38477;&#20197;&#21450;&#27491;&#20132;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformers&#22312;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#21407;&#22240;&#36824;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#31616;&#21333;&#30340;&#19979;&#19968;&#20010;&#26631;&#35760;&#39044;&#27979;&#20219;&#21153;&#19978;&#35757;&#32451;Transformer&#27169;&#22411;&#65292;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35757;&#32451;&#21518;&#30340;Transformer&#22914;&#20309;&#36890;&#36807;&#39318;&#20808;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;W&#65292;&#28982;&#21518;&#24212;&#29992;&#39044;&#27979;&#26144;&#23556;&#26469;&#39044;&#27979;&#19979;&#19968;&#20010;&#26631;&#35760;&#12290;&#25105;&#20204;&#31216;&#36825;&#20010;&#32467;&#26524;&#20026;&#19978;&#19979;&#25991;&#33258;&#22238;&#24402;&#23398;&#20064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#38024;&#23545;W&#26159;&#20132;&#25442;&#27491;&#20132;&#30697;&#38453;&#30340;&#24773;&#20917;&#65292;&#39318;&#20808;&#35777;&#26126;&#20102;&#19968;&#20010;&#35757;&#32451;&#21518;&#30340;&#21333;&#23618;&#32447;&#24615;Transformer&#22312;&#32771;&#34385;&#25193;&#23637;&#26631;&#35760;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#19968;&#27493;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#20869;&#37096;&#30446;&#26631;&#20989;&#25968;&#12290;&#24403;&#26631;&#35760;&#27809;&#26377;&#25193;&#23637;&#26102;&#65292;&#25105;&#20204;&#23545;&#20110;&#19968;&#20010;&#21333;&#23618;&#23545;&#35282;&#32447;&#32447;&#24615;&#22810;&#22836;Transformer&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22836;&#37096;&#20043;&#38388;&#30340;&#27491;&#20132;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformers have achieved state-of-the-art performance in language modeling tasks. However, the reasons behind their tremendous success are still unclear. In this paper, towards a better understanding, we train a Transformer model on a simple next token prediction task, where sequences are generated as a first-order autoregressive process $s_{t+1} = W s_t$. We show how a trained Transformer predicts the next token by first learning $W$ in-context, then applying a prediction mapping. We call the resulting procedure in-context autoregressive learning. More precisely, focusing on commuting orthogonal matrices $W$, we first show that a trained one-layer linear Transformer implements one step of gradient descent for the minimization of an inner objective function, when considering augmented tokens. When the tokens are not augmented, we characterize the global minima of a one-layer diagonal linear multi-head Transformer. Importantly, we exhibit orthogonality between heads and show that posi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#26377;&#32467;&#26500;&#32570;&#22833;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#25429;&#33719;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;</title><link>https://arxiv.org/abs/2402.05758</link><description>&lt;p&gt;
&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#32467;&#26500;&#32570;&#22833;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Latent variable model for high-dimensional point process with structured missingness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#28857;&#36807;&#31243;&#30340;&#24102;&#26377;&#32467;&#26500;&#32570;&#22833;&#30340;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#25429;&#33719;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#25968;&#25454;&#22312;&#21307;&#30103;&#20445;&#20581;&#12289;&#31038;&#20250;&#23398;&#21644;&#22320;&#38663;&#23398;&#31561;&#35768;&#22810;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#20294;&#26159;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#23545;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#23384;&#22312;&#26126;&#26174;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#26159;&#39640;&#32500;&#30340;&#65292;&#21253;&#21547;&#26377;&#32467;&#26500;&#21270;&#30340;&#32570;&#22833;&#27169;&#24335;&#65292;&#24182;&#19988;&#27979;&#37327;&#26102;&#38388;&#28857;&#21487;&#33021;&#21463;&#21040;&#26410;&#30693;&#38543;&#26426;&#36807;&#31243;&#30340;&#25511;&#21046;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#20854;&#20013;&#22823;&#22810;&#25968;&#20165;&#32771;&#34385;&#20102;&#36825;&#20123;&#25361;&#25112;&#20013;&#30340;&#19968;&#20010;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#39640;&#25928;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#33021;&#22815;&#24212;&#23545;&#25152;&#26377;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#26469;&#25429;&#33719;&#26679;&#26412;&#19982;&#20854;&#20851;&#32852;&#30340;&#32570;&#22833;&#27169;&#24335;&#20043;&#38388;&#30340;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#20063;&#29992;&#20110;&#24314;&#27169;&#24213;&#23618;&#30340;&#28857;&#36807;&#31243;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#26500;&#24314;&#20026;&#19968;&#20010;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#21516;&#26102;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#27169;&#22411;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#29702;&#26041;&#27861;&#26469;&#36827;&#34892;&#39640;&#25928;&#30340;&#27169;&#22411;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal data are important in numerous fields, such as healthcare, sociology and seismology, but real-world datasets present notable challenges for practitioners because they can be high-dimensional, contain structured missingness patterns, and measurement time points can be governed by an unknown stochastic process. While various solutions have been suggested, the majority of them have been designed to account for only one of these challenges. In this work, we propose a flexible and efficient latent-variable model that is capable of addressing all these limitations. Our approach utilizes Gaussian processes to capture temporal correlations between samples and their associated missingness masks as well as to model the underlying point process. We construct our model as a variational autoencoder together with deep neural network parameterised encoder and decoder models, and develop a scalable amortised variational inference approach for efficient model training. We demonstrate compe
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#20013;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38544;&#24615;&#20559;&#24046;&#20197;&#21450;&#20854;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#35777;&#26126;&#22312;&#29305;&#23450;&#25968;&#25454;&#35774;&#32622;&#19979;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05738</link><description>&lt;p&gt;
&#38544;&#24615;&#20559;&#24046;&#19982;&#33258;&#27880;&#24847;&#21147;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias and Fast Convergence Rates for Self-attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05738
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#33258;&#27880;&#24847;&#21147;&#32593;&#32476;&#20013;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38544;&#24615;&#20559;&#24046;&#20197;&#21450;&#20854;&#25910;&#25947;&#36895;&#29575;&#65292;&#36890;&#36807;&#35777;&#26126;&#22312;&#29305;&#23450;&#25968;&#25454;&#35774;&#32622;&#19979;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#26159;transformer&#30340;&#26680;&#24515;&#26426;&#21046;&#65292;&#23427;&#20351;&#20854;&#19982;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26377;&#25152;&#21306;&#21035;&#65292;&#24182;&#39537;&#21160;&#20854;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#24320;&#21457;&#33258;&#27880;&#24847;&#21147;&#30340;&#22522;&#26412;&#20248;&#21270;&#21407;&#21017;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#35757;&#32451;&#20855;&#26377;&#22266;&#23450;&#32447;&#24615;&#35299;&#30721;&#22120;&#30340;&#33258;&#27880;&#24847;&#21147;&#23618;&#22312;&#20108;&#20803;&#20998;&#31867;&#20013;&#30340;&#38544;&#24615;&#20559;&#24046;&#12290;&#21463;&#21040;&#22312;&#21487;&#20998;&#31163;&#25968;&#25454;&#19978;&#32447;&#24615;&#36923;&#36753;&#22238;&#24402;&#20013;GD&#30340;&#30740;&#31350;&#21551;&#21457;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#38543;&#30528;&#36845;&#20195;&#27425;&#25968;t&#26080;&#38480;&#25509;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38190;-&#26597;&#35810;&#30697;&#38453;W_t&#22312;&#23616;&#37096;&#19978;&#65288;&#30456;&#23545;&#20110;&#21021;&#22987;&#21270;&#26041;&#21521;&#65289;&#25910;&#25947;&#21040;&#19968;&#20010;&#30828;&#36793;&#30028;&#25903;&#25345;&#21521;&#37327;&#26426;&#35299;W_mm&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#22235;&#20010;&#26041;&#38754;&#22686;&#24378;&#20102;&#36825;&#20010;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#38750;&#24179;&#20961;&#30340;&#25968;&#25454;&#35774;&#32622;&#65292;&#23545;&#20110;&#36825;&#20123;&#35774;&#32622;&#65292;&#25910;&#25947;&#24615;&#26159;&#20840;&#23616;&#30340;&#65292;&#24182;&#25581;&#31034;&#20102;&#20248;&#21270;&#31354;&#38388;&#30340;&#29305;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;W_t&#21040;W_mm&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#29575;&#65292;&#24182;&#37327;&#21270;&#20102;&#31232;&#30095;&#21270;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-attention, the core mechanism of transformers, distinguishes them from traditional neural networks and drives their outstanding performance. Towards developing the fundamental optimization principles of self-attention, we investigate the implicit bias of gradient descent (GD) in training a self-attention layer with fixed linear decoder in binary classification. Drawing inspiration from the study of GD in linear logistic regression over separable data, recent work demonstrates that as the number of iterations $t$ approaches infinity, the key-query matrix $W_t$ converges locally (with respect to the initialization direction) to a hard-margin SVM solution $W_{mm}$. Our work enhances this result in four aspects. Firstly, we identify non-trivial data settings for which convergence is provably global, thus shedding light on the optimization landscape. Secondly, we provide the first finite-time convergence rate for $W_t$ to $W_{mm}$, along with quantifying the rate of sparsification in t
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#37096;&#20998;&#22522;&#20110;&#27169;&#22411;&#30340;Eluder&#32500;&#24230;&#65288;P-MBED&#65289;&#27010;&#24565;&#26469;&#34913;&#37327;&#27169;&#22411;&#31867;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#35777;&#26126;&#22312;&#22522;&#26412;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#24179;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#24182;&#19981;&#27604;&#35299;&#20915;&#23545;&#25968;&#20010;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#26356;&#20855;&#32479;&#35745;&#25361;&#25112;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05724</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#24182;&#19981;&#27604;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26356;&#21152;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#37096;&#20998;&#22522;&#20110;&#27169;&#22411;&#30340;Eluder&#32500;&#24230;&#65288;P-MBED&#65289;&#27010;&#24565;&#26469;&#34913;&#37327;&#27169;&#22411;&#31867;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#35777;&#26126;&#22312;&#22522;&#26412;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#24179;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#24182;&#19981;&#27604;&#35299;&#20915;&#23545;&#25968;&#20010;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#26356;&#20855;&#32479;&#35745;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#22522;&#20110;&#27169;&#22411;&#30340;&#20989;&#25968;&#36924;&#36817;&#19979;&#24378;&#21270;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#35813;&#26041;&#27861;&#38656;&#35201;&#31574;&#30053;&#24615;&#25506;&#32034;&#20197;&#25214;&#21040;&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#37096;&#20998;&#22522;&#20110;&#27169;&#22411;&#30340;Eluder&#32500;&#24230;&#65288;P-MBED&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#27010;&#24565;&#26469;&#25551;&#36848;&#27169;&#22411;&#31867;&#22797;&#26434;&#24230;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;P-MBED&#21487;&#20197;&#34913;&#37327;&#20174;&#32473;&#23450;&#30340;&#24179;&#22343;&#22330;&#27169;&#22411;&#31867;&#36716;&#25442;&#32780;&#26469;&#30340;&#21333;&#20010;&#26234;&#33021;&#20307;&#27169;&#22411;&#31867;&#30340;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#28508;&#22312;&#19978;&#21487;&#33021;&#27604;\citet{huang2023statistical}&#25552;&#20986;&#30340;MBED&#25351;&#25968;&#32423;&#20302;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#24182;&#24314;&#31435;&#20102;&#19982;P-MBED&#30456;&#20851;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#32467;&#26524;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22522;&#26412;&#21487;&#23454;&#29616;&#24615;&#21644;Lipschitz&#36830;&#32493;&#24615;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#24179;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#24182;&#19981;&#27604;&#35299;&#20915;&#23545;&#25968;&#20010;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#26356;&#20855;&#32479;&#35745;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#22810;&#31867;&#22411;&#24179;&#22343;&#22330;&#21338;&#24328;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of reinforcement learning (RL) in Mean-Field Games (MFGs) with model-based function approximation that requires strategic exploration to find a Nash Equilibrium policy. We introduce the Partial Model-Based Eluder Dimension (P-MBED), a more effective notion to characterize the model class complexity. Notably, P-MBED measures the complexity of the single-agent model class converted from the given mean-field model class, and potentially, can be exponentially lower than the MBED proposed by \citet{huang2023statistical}. We contribute a model elimination algorithm featuring a novel exploration strategy and establish sample complexity results polynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basic realizability and Lipschitz continuity assumptions, \emph{learning Nash Equilibrium in MFGs is no more statistically challenging than solving a logarithmic number of single-agent RL problems}. We further extend our results to Multi-Type MFGs, gen
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23485;&#38544;&#34255;&#23618;&#26641;&#29366;&#31070;&#32463;&#32593;&#32476;&#30340;&#23481;&#37327;&#65292;&#37319;&#29992;&#20840;&#38754;&#25552;&#21319;&#30340;&#38543;&#26426;&#20108;&#37325;&#24615;&#29702;&#35770;(fl RDT)&#26469;&#23545;&#23485;(TCM)&#32593;&#32476;&#30340;&#23481;&#37327;&#36827;&#34892;&#21051;&#30011;&#65292;&#24471;&#21040;&#20102;&#19968;&#31867;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#26174;&#24335;&#12289;&#38381;&#24335;&#23481;&#37327;&#35745;&#31639;&#20844;&#24335;&#12290;</title><link>https://arxiv.org/abs/2402.05719</link><description>&lt;p&gt;
&#23485;&#38544;&#34255;&#23618;&#26641;&#29366;&#31070;&#32463;&#32593;&#32476;&#20013;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#23481;&#37327;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Exact capacity of the \emph{wide} hidden layer treelike neural networks with generic activations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05719
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23485;&#38544;&#34255;&#23618;&#26641;&#29366;&#31070;&#32463;&#32593;&#32476;&#30340;&#23481;&#37327;&#65292;&#37319;&#29992;&#20840;&#38754;&#25552;&#21319;&#30340;&#38543;&#26426;&#20108;&#37325;&#24615;&#29702;&#35770;(fl RDT)&#26469;&#23545;&#23485;(TCM)&#32593;&#32476;&#30340;&#23481;&#37327;&#36827;&#34892;&#21051;&#30011;&#65292;&#24471;&#21040;&#20102;&#19968;&#31867;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#26174;&#24335;&#12289;&#38381;&#24335;&#23481;&#37327;&#35745;&#31639;&#20844;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#20110;&#26641;&#29366;&#22996;&#21592;&#20250;&#26426;&#22120;(TCM)&#31070;&#32463;&#32593;&#32476;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#26426;&#20108;&#37325;&#24615;&#29702;&#35770;(RDT)&#21450;&#20854;&#37096;&#20998;&#25552;&#21319;&#21464;&#31181;(pl RDT)&#26159;&#33021;&#22815;&#29992;&#20110;&#38750;&#24120;&#31934;&#30830;&#30340;&#32593;&#32476;&#23481;&#37327;&#20998;&#26512;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23485;&#38544;&#34255;&#23618;&#32593;&#32476;&#65292;&#24182;&#21457;&#29616;\cite{Stojnictcmspnncapdiffactrdt23}&#20013;&#38754;&#20020;&#30340;&#26576;&#20123;&#25968;&#20540;&#22256;&#38590;&#22855;&#36857;&#33324;&#22320;&#28040;&#22833;&#20102;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#37319;&#29992;&#26368;&#36817;&#21457;&#23637;&#30340;&#20840;&#38754;&#25552;&#21319;(fl) RDT&#26469;&#34920;&#24449;&#23485;($d\rightarrow \infty$) TCM&#32593;&#32476;&#30340;&#23481;&#37327;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#31867;&#38750;&#24120;&#36890;&#29992;&#30340;&#38544;&#34255;&#23618;&#28608;&#27963;&#20989;&#25968;&#30340;&#26174;&#24335;&#12289;&#38381;&#24335;&#23481;&#37327;&#21051;&#30011;&#12290;&#23613;&#31649;&#25152;&#20351;&#29992;&#30340;&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;&#25152;&#38656;&#30340;&#25968;&#20540;&#35780;&#20272;&#37327;&#65292;&#20294;&#26368;&#32456;&#30340;fl RDT&#30340;&#23454;&#29992;&#24615;&#21644;&#25104;&#21151;&#20173;&#28982;&#38656;&#35201;&#21487;&#38752;&#30340;&#25968;&#20540;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent progress in studying \emph{treelike committee machines} (TCM) neural networks (NN) in \cite{Stojnictcmspnncaprdt23,Stojnictcmspnncapliftedrdt23,Stojnictcmspnncapdiffactrdt23} showed that the Random Duality Theory (RDT) and its a \emph{partially lifted}(pl RDT) variant are powerful tools that can be used for very precise networks capacity analysis. Here, we consider \emph{wide} hidden layer networks and uncover that certain aspects of numerical difficulties faced in \cite{Stojnictcmspnncapdiffactrdt23} miraculously disappear. In particular, we employ recently developed \emph{fully lifted} (fl) RDT to characterize the \emph{wide} ($d\rightarrow \infty$) TCM nets capacity. We obtain explicit, closed form, capacity characterizations for a very generic class of the hidden layer activations. While the utilized approach significantly lowers the amount of the needed numerical evaluations, the ultimate fl RDT usefulness and success still require a solid portion of the residual numerical 
&lt;/p&gt;</description></item><item><title>REMEDI&#26159;&#19968;&#31181;&#29992;&#20110;&#25913;&#36827;&#31070;&#32463;&#29109;&#20272;&#35745;&#30340;&#26657;&#27491;&#36716;&#25442;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#30456;&#23545;&#29109;&#20272;&#35745;&#22522;&#27169;&#22411;&#30340;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05718</link><description>&lt;p&gt;
REMEDI: &#25913;&#36827;&#31070;&#32463;&#29109;&#20272;&#35745;&#30340;&#26657;&#27491;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
REMEDI: Corrective Transformations for Improved Neural Entropy Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05718
&lt;/p&gt;
&lt;p&gt;
REMEDI&#26159;&#19968;&#31181;&#29992;&#20110;&#25913;&#36827;&#31070;&#32463;&#29109;&#20272;&#35745;&#30340;&#26657;&#27491;&#36716;&#25442;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#30456;&#23545;&#29109;&#20272;&#35745;&#22522;&#27169;&#22411;&#30340;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#35770;&#37327;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#25968;&#25454;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#20351;&#24471;&#20934;&#30830;&#20272;&#35745;&#36825;&#20123;&#37327;&#30340;&#38656;&#27714;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20272;&#35745;&#23384;&#22312;&#37325;&#22823;&#25361;&#25112;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#30456;&#23545;&#36739;&#20302;&#30340;&#32500;&#24230;&#20013;&#24050;&#32463;&#22256;&#38590;&#37325;&#37325;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;REMEDI&#65292;&#29992;&#20110;&#39640;&#25928;&#20934;&#30830;&#22320;&#20272;&#35745;&#24494;&#20998;&#29109;&#65292;&#19968;&#31181;&#22522;&#26412;&#30340;&#20449;&#24687;&#35770;&#37327;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#31616;&#21333;&#33258;&#36866;&#24212;&#22522;&#27169;&#22411;&#30340;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#20854;&#30456;&#23545;&#29109;&#20174;&#25968;&#25454;&#23494;&#24230;&#20013;&#20272;&#35745;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#20272;&#35745;&#20219;&#21153;&#20013;&#24471;&#21040;&#20102;&#25913;&#36827;&#65292;&#21253;&#25324;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#33258;&#28982;&#25968;&#25454;&#30340;&#29109;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#37325;&#35201;&#30340;&#29702;&#35770;&#19968;&#33268;&#24615;&#32467;&#26524;&#25193;&#23637;&#21040;&#25105;&#20204;&#26041;&#27861;&#25152;&#38656;&#30340;&#26356;&#24191;&#20041;&#30340;&#35774;&#32622;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#25552;&#39640;&#29109;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information theoretic quantities play a central role in machine learning. The recent surge in the complexity of data and models has increased the demand for accurate estimation of these quantities. However, as the dimension grows the estimation presents significant challenges, with existing methods struggling already in relatively low dimensions. To address this issue, in this work, we introduce $\texttt{REMEDI}$ for efficient and accurate estimation of differential entropy, a fundamental information theoretic quantity. The approach combines the minimization of the cross-entropy for simple, adaptive base models and the estimation of their deviation, in terms of the relative entropy, from the data density. Our approach demonstrates improvement across a broad spectrum of estimation tasks, encompassing entropy estimation on both synthetic and natural data. Further, we extend important theoretical consistency results to a more generalized setting required by our approach. We illustrate how
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21327;&#21516;&#38750;&#21442;&#25968;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#65288;CTST&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26377;&#25928;&#21033;&#29992;&#20102;&#22270;&#32467;&#26500;&#21644;&#26368;&#23567;&#21270;&#20102;&#23545;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#20551;&#35774;&#65292;&#36890;&#36807;&#38598;&#25104;f-&#20998;&#24067;&#20272;&#35745;&#12289;&#26680;&#26041;&#27861;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#35201;&#28857;&#65292;&#23558;&#20256;&#32479;&#30340;&#22312;&#27599;&#20010;&#33410;&#28857;&#29420;&#31435;&#24212;&#29992;&#30340;&#26041;&#27861;&#20248;&#21270;&#65292;&#23545;&#22270;&#32467;&#26500;&#20013;&#30340;&#22810;&#20010;&#20004;&#26679;&#26412;&#26816;&#39564;&#38382;&#39064;&#36827;&#34892;&#20102;&#26356;&#22909;&#30340;&#22788;&#29702;&#21644;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.05715</link><description>&lt;p&gt;
&#21327;&#21516;&#38750;&#21442;&#25968;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Collaborative non-parametric two-sample testing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21327;&#21516;&#38750;&#21442;&#25968;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#65288;CTST&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26377;&#25928;&#21033;&#29992;&#20102;&#22270;&#32467;&#26500;&#21644;&#26368;&#23567;&#21270;&#20102;&#23545;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#20551;&#35774;&#65292;&#36890;&#36807;&#38598;&#25104;f-&#20998;&#24067;&#20272;&#35745;&#12289;&#26680;&#26041;&#27861;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#35201;&#28857;&#65292;&#23558;&#20256;&#32479;&#30340;&#22312;&#27599;&#20010;&#33410;&#28857;&#29420;&#31435;&#24212;&#29992;&#30340;&#26041;&#27861;&#20248;&#21270;&#65292;&#23545;&#22270;&#32467;&#26500;&#20013;&#30340;&#22810;&#20010;&#20004;&#26679;&#26412;&#26816;&#39564;&#38382;&#39064;&#36827;&#34892;&#20102;&#26356;&#22909;&#30340;&#22788;&#29702;&#21644;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22270;&#32467;&#26500;&#35774;&#32622;&#20013;&#30340;&#22810;&#20010;&#20004;&#26679;&#26412;&#26816;&#39564;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36825;&#26159;&#31354;&#38388;&#32479;&#35745;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#20013;&#30340;&#24120;&#35265;&#24773;&#26223;&#12290;&#22312;&#22266;&#23450;&#22270;&#20013;&#30340;&#27599;&#20010;&#33410;&#28857;v&#37117;&#28041;&#21450;&#21040;&#20004;&#20010;&#29305;&#23450;&#33410;&#28857;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;pdfs&#65289;p_v&#21644;q_v&#20043;&#38388;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#20551;&#35774;&#36830;&#25509;&#30340;&#33410;&#28857;&#20250;&#20135;&#29983;&#31867;&#20284;&#30340;&#26816;&#39564;&#32467;&#26524;&#30340;&#26465;&#20214;&#19979;&#65292;&#30830;&#23450;&#24212;&#25298;&#32477;&#38646;&#20551;&#35774;p_v = q_v&#30340;&#33410;&#28857;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38750;&#21442;&#25968;&#30340;&#21327;&#21516;&#20004;&#26679;&#26412;&#26816;&#39564;&#65288;CTST&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#26377;&#25928;&#21033;&#29992;&#20102;&#22270;&#32467;&#26500;&#24182;&#26368;&#23567;&#21270;&#20102;&#23545;p_v&#21644;q_v&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#38598;&#25104;&#20102;f-&#20998;&#24067;&#20272;&#35745;&#12289;&#26680;&#26041;&#27861;&#21644;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#35201;&#28857;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#23454;&#39564;&#21644;&#26816;&#27979;&#22320;&#38663;&#27963;&#21160;&#30340;&#30495;&#23454;&#20256;&#24863;&#22120;&#32593;&#32476;&#26469;&#35777;&#26126;CTST&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22312;&#27599;&#20010;&#33410;&#28857;&#29420;&#31435;&#24212;&#29992;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#22240;&#27492;&#24573;&#35270;&#20102;&#22270;&#32467;&#26500;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the multiple two-sample test problem in a graph-structured setting, which is a common scenario in fields such as Spatial Statistics and Neuroscience. Each node $v$ in fixed graph deals with a two-sample testing problem between two node-specific probability density functions (pdfs), $p_v$ and $q_v$. The goal is to identify nodes where the null hypothesis $p_v = q_v$ should be rejected, under the assumption that connected nodes would yield similar test outcomes. We propose the non-parametric collaborative two-sample testing (CTST) framework that efficiently leverages the graph structure and minimizes the assumptions over $p_v$ and $q_v$. Our methodology integrates elements from f-divergence estimation, Kernel Methods, and Multitask Learning. We use synthetic experiments and a real sensor network detecting seismic activity to demonstrate that CTST outperforms state-of-the-art non-parametric statistical tests that apply at each node independently, hence disregard the g
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#26641;&#29366;&#31070;&#32463;&#32593;&#32476;&#30340;&#23481;&#37327;&#65292;&#22522;&#20110;Random Duality Theory&#25552;&#20986;&#20102;&#36890;&#29992;&#30340;&#23481;&#37327;&#20998;&#26512;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#20854;&#20182;&#31867;&#22411;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;&#20108;&#27425;&#21644;ReLU&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.05696</link><description>&lt;p&gt;
&#22266;&#23450;&#23485;&#24230;&#30340;&#26641;&#29366;&#31070;&#32463;&#32593;&#32476;&#23481;&#37327;&#20998;&#26512;-&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Fixed width treelike neural networks capacity analysis -- generic activations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05696
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#26641;&#29366;&#31070;&#32463;&#32593;&#32476;&#30340;&#23481;&#37327;&#65292;&#22522;&#20110;Random Duality Theory&#25552;&#20986;&#20102;&#36890;&#29992;&#30340;&#23481;&#37327;&#20998;&#26512;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#20854;&#20182;&#31867;&#22411;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;&#20108;&#27425;&#21644;ReLU&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#26641;&#29366;&#22996;&#21592;&#20250;&#26426;&#65288;TCM&#65289;&#31070;&#32463;&#32593;&#32476;&#30340;&#23481;&#37327;&#12290;&#22522;&#20110;&#38543;&#26426;&#23545;&#20598;&#29702;&#35770;&#65288;RDT&#65289;&#65292;\cite{Stojnictcmspnncaprdt23}&#26368;&#36817;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#29992;&#20110;&#23427;&#20204;&#30340;&#23481;&#37327;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#22312;\cite{Stojnictcmspnncapliftedrdt23}&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25152;&#35859;&#30340;&#8220;&#37096;&#20998;&#25552;&#21319;&#8221;RDT&#65288;pl RDT&#65289;&#30340;&#21319;&#32423;&#29256;&#26412;&#12290;&#36825;&#20004;&#20010;&#24037;&#20316;&#26041;&#21521;&#37117;&#30528;&#37325;&#20110;&#20855;&#26377;&#26368;&#20856;&#22411;&#30340;&#8220;&#31526;&#21495;&#8221;&#28608;&#27963;&#20989;&#25968;&#30340;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#20855;&#26377;&#20854;&#20182;&#26356;&#19968;&#33324;&#31867;&#22411;&#28608;&#27963;&#20989;&#25968;&#30340;&#32593;&#32476;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;\cite{Stojnictcmspnncaprdt23,Stojnictcmspnncapliftedrdt23}&#30340;&#26694;&#26550;&#36275;&#22815;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#36825;&#20123;&#24773;&#20917;&#12290;&#38500;&#20102;&#26631;&#20934;&#30340;&#8220;&#32447;&#24615;&#8221;&#28608;&#27963;&#20989;&#25968;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20004;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21363;&#8220;&#20108;&#27425;&#8221;&#21644;&#8220;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#8221;&#65292;&#21487;&#20197;&#24471;&#21040;&#29305;&#21035;&#26041;&#20415;&#30340;&#32467;&#26524;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#23545;&#20110;&#27599;&#20010;&#28608;&#27963;&#20989;&#25968;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;
&lt;/p&gt;
&lt;p&gt;
We consider the capacity of \emph{treelike committee machines} (TCM) neural networks. Relying on Random Duality Theory (RDT), \cite{Stojnictcmspnncaprdt23} recently introduced a generic framework for their capacity analysis. An upgrade based on the so-called \emph{partially lifted} RDT (pl RDT) was then presented in \cite{Stojnictcmspnncapliftedrdt23}. Both lines of work focused on the networks with the most typical, \emph{sign}, activations. Here, on the other hand, we focus on networks with other, more general, types of activations and show that the frameworks of \cite{Stojnictcmspnncaprdt23,Stojnictcmspnncapliftedrdt23} are sufficiently powerful to enable handling of such scenarios as well. In addition to the standard \emph{linear} activations, we uncover that particularly convenient results can be obtained for two very commonly used activations, namely, the \emph{quadratic} and \emph{rectified linear unit (ReLU)} ones. In more concrete terms, for each of these activations, we obtai
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#25239;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#30340;&#20805;&#20998;&#32479;&#35745;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#23384;&#22312;&#21487;&#20197;&#38450;&#24481;&#32780;&#19981;&#24809;&#32602;&#20934;&#30830;&#24615;&#30340;&#26041;&#21521;&#65292;&#25581;&#31034;&#20102;&#38450;&#24481;&#38750;&#40065;&#26834;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2402.05674</link><description>&lt;p&gt;
&#39640;&#32500;&#27169;&#22411;&#30340;&#23545;&#25239;&#35757;&#32451;&#65306;&#20960;&#20309;&#21644;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
A High Dimensional Model for Adversarial Training: Geometry and Trade-Offs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#27169;&#22411;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#24182;&#32473;&#20986;&#20102;&#23545;&#25239;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#30340;&#20805;&#20998;&#32479;&#35745;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#23384;&#22312;&#21487;&#20197;&#38450;&#24481;&#32780;&#19981;&#24809;&#32602;&#20934;&#30830;&#24615;&#30340;&#26041;&#21521;&#65292;&#25581;&#31034;&#20102;&#38450;&#24481;&#38750;&#40065;&#26834;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#21363;&#32500;&#24230;$d$&#21644;&#25968;&#25454;&#28857;&#25968;$n$&#19982;&#22266;&#23450;&#27604;&#20363;$\alpha = n / d$&#21457;&#25955;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#30740;&#31350;&#20102;&#22522;&#20110;&#36793;&#38469;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#20013;&#30340;&#23545;&#25239;&#35757;&#32451;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21487;&#22788;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#30740;&#31350;&#25968;&#25454;&#21644;&#23545;&#25239;&#25915;&#20987;&#32773;&#20960;&#20309;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#25429;&#25417;&#21040;&#23545;&#25239;&#40065;&#26834;&#24615;&#25991;&#29486;&#20013;&#35266;&#23519;&#21040;&#30340;&#26680;&#24515;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#29702;&#35770;&#36129;&#29486;&#26159;&#22312;&#36890;&#29992;&#30340;&#20984;&#19988;&#38750;&#36882;&#22686;&#25439;&#22833;&#20989;&#25968;&#19979;&#65292;&#23545;&#20110;&#23545;&#25239;&#24615;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#30340;&#20805;&#20998;&#32479;&#35745;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#31934;&#30830;&#22320;&#21051;&#30011;&#25968;&#25454;&#20013;&#19982;&#26356;&#39640;&#30340;&#27867;&#21270;/&#40065;&#26834;&#24615;&#26435;&#34913;&#30456;&#20851;&#30340;&#26041;&#21521;&#65292;&#30001;&#19968;&#20010;&#40065;&#26834;&#24615;&#24230;&#37327;&#21644;&#19968;&#20010;&#26377;&#29992;&#24615;&#24230;&#37327;&#23450;&#20041;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#23384;&#22312;&#19968;&#20123;&#26041;&#21521;&#65292;&#21487;&#20197;&#36827;&#34892;&#38450;&#24481;&#32780;&#19981;&#24809;&#32602;&#20934;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#38450;&#24481;&#38750;&#40065;&#26834;&#29305;&#24449;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work investigates adversarial training in the context of margin-based linear classifiers in the high-dimensional regime where the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\alpha = n / d$. We introduce a tractable mathematical model where the interplay between the data and adversarial attacker geometries can be studied, while capturing the core phenomenology observed in the adversarial robustness literature. Our main theoretical contribution is an exact asymptotic description of the sufficient statistics for the adversarial empirical risk minimiser, under generic convex and non-increasing losses. Our result allow us to precisely characterise which directions in the data are associated with a higher generalisation/robustness trade-off, as defined by a robustness and a usefulness metric. In particular, we unveil the existence of directions which can be defended without penalising accuracy. Finally, we show the advantage of defending non-robust featu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.05639</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Instrumental Variable Regression through Stochastic Approximate Gradients
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#35777;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SAGD-IV&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#36817;&#20284;&#26799;&#24230;&#26469;&#26368;&#23567;&#21270;&#25237;&#24433;&#32676;&#20307;&#39118;&#38505;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20202;&#22120;&#21464;&#37327;&#65288;NPIV&#65289;&#22238;&#24402;&#26694;&#26550;&#12290;&#20202;&#22120;&#21464;&#37327;&#65288;IV&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35745;&#37327;&#32463;&#27982;&#23398;&#20013;&#65292;&#20197;&#35299;&#20915;&#22312;&#23384;&#22312;&#19981;&#21487;&#35266;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#30340;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#19988;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#33268;&#21147;&#20110;&#25913;&#36827;&#29616;&#26377;&#26041;&#27861;&#24182;&#22312;NPIV&#35774;&#32622;&#19979;&#35774;&#35745;&#26032;&#26041;&#27861;&#65292;&#35813;&#35774;&#32622;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#19981;&#36866;&#23450;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#31639;&#27861;&#30340;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#23454;&#39564;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#20854;&#31454;&#20105;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#22788;&#29702;&#20102;&#20108;&#20803;&#32467;&#26524;&#30340;&#24773;&#20917;&#65292;&#24182;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#32780;&#35813;&#24773;&#20917;&#22312;&#31038;&#21306;&#20013;&#27809;&#26377;&#24471;&#21040;&#19982;&#20854;&#36830;&#32493;&#23545;&#24212;&#29289;&#30340;&#21516;&#26679;&#20851;&#27880;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes SAGD-IV, a novel framework for conducting nonparametric instrumental variable (NPIV) regression by employing stochastic approximate gradients to minimize the projected populational risk. Instrumental Variables (IVs) are widely used in econometrics to address estimation problems in the presence of unobservable confounders, and the Machine Learning community has devoted significant effort to improving existing methods and devising new ones in the NPIV setting, which is known to be an ill-posed linear inverse problem. We provide theoretical support for our algorithm and further exemplify its competitive performance through empirical experiments. Furthermore, we address, with promising results, the case of binary outcomes, which has not received as much attention from the community as its continuous counterpart.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(WCE-GNN)&#23454;&#29616;&#20102;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;WCE-GNN&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05569</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Hypergraph Node Classification With Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(WCE-GNN)&#23454;&#29616;&#20102;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;WCE-GNN&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#26159;&#29992;&#26469;&#27169;&#25311;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#20851;&#38190;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#25104;&#21151;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#20855;&#26377;&#25104;&#23545;&#20132;&#20114;&#30340;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#36825;&#28608;&#21457;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#20855;&#26377;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#25968;&#25454;&#30340;&#24819;&#27861;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HyperGNNs&#65289;&#30340;&#21457;&#23637;&#12290;GNNs&#21644;HyperGNNs&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19981;&#21516;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#34987;&#35774;&#35745;&#29992;&#20110;&#22788;&#29702;&#19981;&#21516;&#20960;&#20309;&#25299;&#25169;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#22312;&#33410;&#28857;&#20998;&#31867;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#22823;&#22810;&#25968;HyperGNNs&#21487;&#20197;&#20351;&#29992;&#24102;&#26377;&#36229;&#22270;&#30340;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;GNN&#26469;&#36817;&#20284;&#12290;&#36825;&#23548;&#33268;&#20102;WCE-GNN&#65292;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;GNN&#21644;&#19968;&#20010;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#65288;WCE&#65289;&#65292;&#29992;&#20110;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23545;&#20110;&#20061;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;WCE-GNN&#19981;&#20165;&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs, with hyperedges connecting more than two nodes, are key for modelling higher-order interactions in real-world data. The success of graph neural networks (GNNs) reveals the capability of neural networks to process data with pairwise interactions. This inspires the usage of neural networks for data with higher-order interactions, thereby leading to the development of hypergraph neural networks (HyperGNNs). GNNs and HyperGNNs are typically considered distinct since they are designed for data on different geometric topologies. However, in this paper, we theoretically demonstrate that, in the context of node classification, most HyperGNNs can be approximated using a GNN with a weighted clique expansion of the hypergraph. This leads to WCE-GNN, a simple and efficient framework comprising a GNN and a weighted clique expansion (WCE), for hypergraph node classification. Experiments on nine real-world hypergraph node classification benchmarks showcase that WCE-GNN demonstrates not o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#31163;&#32447;&#25968;&#25454;&#20013;&#30340;&#38544;&#31169;&#27169;&#22411;&#20197;&#21450;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#35757;&#32451;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#24635;&#32467;&#20102;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;</title><link>https://arxiv.org/abs/2402.05525</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Model-Based Offline Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05525
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#31163;&#32447;&#25968;&#25454;&#20013;&#30340;&#38544;&#31169;&#27169;&#22411;&#20197;&#21450;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#65292;&#23454;&#29616;&#20102;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#35757;&#32451;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#36824;&#24635;&#32467;&#20102;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20855;&#26377;&#38544;&#31169;&#20445;&#35777;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#35757;&#32451;&#19968;&#20010;&#30456;&#23545;&#20110;&#25968;&#25454;&#38598;&#20013;&#27599;&#20010;&#36712;&#36857;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#31574;&#30053;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DP-MORL&#65292;&#19968;&#31181;&#24102;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#30340;MBRL&#31639;&#27861;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;DP-FedAvg&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#23398;&#20064;&#29615;&#22659;&#30340;&#38544;&#31169;&#27169;&#22411;&#65292;DP-FedAvg&#26159;&#19968;&#31181;&#20026;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#36712;&#36857;&#32423;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#30340;&#35757;&#32451;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#20248;&#21270;&#20174;&#65288;&#21463;&#32602;&#30340;&#65289;&#38544;&#31169;&#27169;&#22411;&#20013;&#25512;&#23548;&#20986;&#31574;&#30053;&#65292;&#26080;&#38656;&#36827;&#19968;&#27493;&#19982;&#31995;&#32479;&#20132;&#20114;&#25110;&#35775;&#38382;&#36755;&#20837;&#25968;&#25454;&#12290;&#25105;&#20204;&#32463;&#39564;&#35777;&#26126;&#65292;DP-MORL&#33021;&#22815;&#20174;&#31163;&#32447;&#25968;&#25454;&#20013;&#35757;&#32451;&#20986;&#20855;&#26377;&#38544;&#31169;&#20445;&#25252;&#30340;RL&#20195;&#29702;&#65292;&#24182;&#36827;&#19968;&#27493;&#27010;&#36848;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38544;&#31169;&#30340;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address offline reinforcement learning with privacy guarantees, where the goal is to train a policy that is differentially private with respect to individual trajectories in the dataset. To achieve this, we introduce DP-MORL, an MBRL algorithm coming with differential privacy guarantees. A private model of the environment is first learned from offline data using DP-FedAvg, a training method for neural networks that provides differential privacy guarantees at the trajectory level. Then, we use model-based policy optimization to derive a policy from the (penalized) private model, without any further interaction with the system or access to the input data. We empirically show that DP-MORL enables the training of private RL agents from offline data and we furthermore outline the price of privacy in this setting.
&lt;/p&gt;</description></item><item><title>&#22312;&#39640;&#20449;&#21495;&#21306;&#22495;&#20013;&#65292;&#30740;&#31350;&#20102;&#23376;&#32447;&#24615;&#26102;&#38388;&#20869;&#26816;&#27979;&#31181;&#26893;&#22242;&#20307;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#38750;&#36866;&#24212;&#24615;&#20302;&#24230;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#23610;&#24230;&#19979;&#21487;&#20197;&#26816;&#27979;&#21040;&#22242;&#20307;&#65292;&#24182;&#19988;&#26174;&#31034;&#20102;&#35813;&#31867;&#31639;&#27861;&#30340;&#35745;&#31639;&#30456;&#21464;&#12290;</title><link>https://arxiv.org/abs/2402.05451</link><description>&lt;p&gt;
&#26816;&#27979;&#23376;&#32447;&#24615;&#26102;&#38388;&#20869;&#31181;&#26893;&#30340;&#22242;&#20307;&#30340;&#20302;&#24230;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Low-degree phase transitions for detecting a planted clique in sublinear time
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05451
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#20449;&#21495;&#21306;&#22495;&#20013;&#65292;&#30740;&#31350;&#20102;&#23376;&#32447;&#24615;&#26102;&#38388;&#20869;&#26816;&#27979;&#31181;&#26893;&#22242;&#20307;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#38750;&#36866;&#24212;&#24615;&#20302;&#24230;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#23610;&#24230;&#19979;&#21487;&#20197;&#26816;&#27979;&#21040;&#22242;&#20307;&#65292;&#24182;&#19988;&#26174;&#31034;&#20102;&#35813;&#31867;&#31639;&#27861;&#30340;&#35745;&#31639;&#30456;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#30001;n&#20010;&#39030;&#28857;&#32452;&#25104;&#30340;&#38543;&#26426;&#22270;&#20013;&#26816;&#27979;&#22823;&#23567;&#20026;k&#30340;&#31181;&#26893;&#22242;&#20307;&#30340;&#38382;&#39064;&#12290;&#24403;&#22242;&#20307;&#30340;&#22823;&#23567;&#36229;&#36807;&#920;(&#8730;n)&#26102;&#65292;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#20415;&#20250;&#22686;&#22810;&#12290;&#22312;&#39640;&#20449;&#21495;&#21306;&#22495;&#65292;&#21363;k = &#920;(n^(1/2 + &#948;))&#65292;&#25105;&#20204;&#30740;&#31350;&#26356;&#24555;&#36895;&#30340;&#8212;&#8212;&#20063;&#23601;&#26159;&#23376;&#32447;&#24615;&#26102;&#38388;&#30340;&#31639;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#38750;&#36866;&#24212;&#24615;&#22320;&#26597;&#35810;&#37051;&#25509;&#30697;&#38453;&#30340;&#23376;&#38598;M&#30340;&#31639;&#27861;&#65292;&#28982;&#21518;&#35745;&#31639;&#25152;&#25581;&#31034;&#30340;&#26465;&#30446;&#30340;&#20302;&#24230;&#22810;&#39033;&#24335;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31867;&#38750;&#36866;&#24212;&#24615;&#20302;&#24230;&#31639;&#27861;&#30340;&#35745;&#31639;&#30456;&#21464;&#65306;&#22312;&#23610;&#24230;&#920;(n^&#947;)&#19979;&#65292;&#24403;&#947; &gt; 3(1/2 - &#948;)&#26102;&#65292;&#21487;&#20197;&#26816;&#27979;&#21040;&#22242;&#20307;&#65292;&#20294;&#24403;&#947; &lt; 3(1/2 - &#948;)&#26102;&#65292;&#21017;&#26080;&#27861;&#26816;&#27979;&#21040;&#22242;&#20307;&#12290;&#22240;&#27492;&#65292;&#22312;&#19981;&#36229;&#20986;&#38750;&#36866;&#24212;&#24615;&#20302;&#24230;&#31867;&#21035;&#30340;&#33539;&#22260;&#20043;&#22806;&#65292;&#26080;&#27861;&#25552;&#21319;&#26816;&#27979;&#31181;&#26893;&#22242;&#20307;&#30340;&#26368;&#20339;&#24050;&#30693;&#36816;&#34892;&#26102;&#38388;&#65292;&#21363;&#937;(n^(3(1/2-&#948;)))&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#19979;&#30028;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of detecting a planted clique of size $k$ in a random graph on $n$ vertices. When the size of the clique exceeds $\Theta(\sqrt{n})$, polynomial-time algorithms for detection proliferate. We study faster -- namely, sublinear time -- algorithms in the high-signal regime when $k = \Theta(n^{1/2 + \delta})$, for some $\delta &gt; 0$. To this end, we consider algorithms that non-adaptively query a subset $M$ of entries of the adjacency matrix and then compute a low-degree polynomial function of the revealed entries. We prove a computational phase transition for this class of non-adaptive low-degree algorithms: under the scaling $\lvert M \rvert = \Theta(n^{\gamma})$, the clique can be detected when $\gamma &gt; 3(1/2 - \delta)$ but not when $\gamma &lt; 3(1/2 - \delta)$. As a result, the best known runtime for detecting a planted clique, $\widetilde{O}(n^{3(1/2-\delta)})$, cannot be improved without looking beyond the non-adaptive low-degree class.   Our proof of the lower bo
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#26102;&#38388;&#25193;&#23637;&#65288;UTE&#65289;&#30340;&#31639;&#27861;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#21160;&#20316;&#37325;&#22797;&#21487;&#33021;&#38477;&#20302;&#24615;&#33021;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#20174;&#32780;&#35753;&#31574;&#30053;&#26681;&#25454;&#38656;&#27714;&#36827;&#34892;&#36873;&#25321;&#65292;&#23454;&#39564;&#35777;&#26126;UTE&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.05439</link><description>&lt;p&gt;
&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#26102;&#38388;&#25193;&#23637;&#21160;&#20316;
&lt;/p&gt;
&lt;p&gt;
Learning Uncertainty-Aware Temporally-Extended Actions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05439
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#26102;&#38388;&#25193;&#23637;&#65288;UTE&#65289;&#30340;&#31639;&#27861;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#21160;&#20316;&#37325;&#22797;&#21487;&#33021;&#38477;&#20302;&#24615;&#33021;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#20174;&#32780;&#35753;&#31574;&#30053;&#26681;&#25454;&#38656;&#27714;&#36827;&#34892;&#36873;&#25321;&#65292;&#23454;&#39564;&#35777;&#26126;UTE&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#26102;&#38388;&#25277;&#35937;&#65292;&#20363;&#22914;&#21160;&#20316;&#37325;&#22797;&#65292;&#26159;&#19968;&#31181;&#36890;&#36807;&#25193;&#23637;&#21160;&#20316;&#20419;&#36827;&#31574;&#30053;&#23398;&#20064;&#30340;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#20197;&#21069;&#30340;&#21160;&#20316;&#37325;&#22797;&#30740;&#31350;&#23384;&#22312;&#19968;&#20010;&#20027;&#35201;&#38480;&#21046;&#65292;&#21363;&#24403;&#37325;&#22797;&#27425;&#20248;&#21160;&#20316;&#26102;&#21487;&#33021;&#38477;&#20302;&#24615;&#33021;&#12290;&#36825;&#20010;&#38382;&#39064;&#32463;&#24120;&#25269;&#28040;&#20102;&#21160;&#20316;&#37325;&#22797;&#30340;&#20248;&#21183;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#26102;&#38388;&#25193;&#23637;&#65288;UTE&#65289;&#30340;&#26032;&#31639;&#27861;&#12290;UTE&#20351;&#29992;&#38598;&#25104;&#26041;&#27861;&#22312;&#21160;&#20316;&#25193;&#23637;&#26399;&#38388;&#20934;&#30830;&#22320;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#20010;&#29305;&#24615;&#20801;&#35768;&#31574;&#30053;&#26681;&#25454;&#20854;&#29305;&#23450;&#38656;&#27714;&#65292;&#22312;&#24378;&#35843;&#25506;&#32034;&#25110;&#37319;&#21462;&#19981;&#30830;&#23450;&#24615;-&#25269;&#21046;&#26041;&#27861;&#20043;&#38388;&#36827;&#34892;&#36873;&#25321;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Gridworld&#21644;Atari 2600&#29615;&#22659;&#20013;&#36827;&#34892;&#23454;&#39564;&#23637;&#31034;&#20102;UTE&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;UTE&#20248;&#20110;&#29616;&#26377;&#30340;&#21160;&#20316;&#37325;&#22797;&#31639;&#27861;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#20102;&#23427;&#20204;&#22266;&#26377;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reinforcement learning, temporal abstraction in the action space, exemplified by action repetition, is a technique to facilitate policy learning through extended actions. However, a primary limitation in previous studies of action repetition is its potential to degrade performance, particularly when sub-optimal actions are repeated. This issue often negates the advantages of action repetition. To address this, we propose a novel algorithm named Uncertainty-aware Temporal Extension (UTE). UTE employs ensemble methods to accurately measure uncertainty during action extension. This feature allows policies to strategically choose between emphasizing exploration or adopting an uncertainty-averse approach, tailored to their specific needs. We demonstrate the effectiveness of UTE through experiments in Gridworld and Atari 2600 environments. Our findings show that UTE outperforms existing action repetition algorithms, effectively mitigating their inherent limitations and significantly enhan
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#22312;&#31232;&#30095;&#23454;&#39564;&#25968;&#25454;&#39044;&#27979;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#65292;&#22635;&#34917;&#20102;&#24403;&#21069;&#23545;&#20854;&#24433;&#21709;&#20102;&#35299;&#19981;&#36275;&#30340;&#37325;&#35201;&#24046;&#36317;&#65292;&#24182;&#25581;&#31034;&#20986;&#20010;&#20307;&#21487;&#35843;&#21442;&#25968;&#30340;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05401</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#22312;&#31232;&#30095;&#23454;&#39564;&#25968;&#25454;&#39044;&#27979;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adaptive Activation Functions for Predictive Modeling with Sparse Experimental Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#22312;&#31232;&#30095;&#23454;&#39564;&#25968;&#25454;&#39044;&#27979;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;&#65292;&#22635;&#34917;&#20102;&#24403;&#21069;&#23545;&#20854;&#24433;&#21709;&#20102;&#35299;&#19981;&#36275;&#30340;&#37325;&#35201;&#24046;&#36317;&#65292;&#24182;&#25581;&#31034;&#20986;&#20010;&#20307;&#21487;&#35843;&#21442;&#25968;&#30340;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#20851;&#38190;&#22312;&#20110;&#36873;&#25321;&#28608;&#27963;&#20989;&#25968;&#65292;&#29992;&#20110;&#24341;&#20837;&#33021;&#22815;&#25429;&#25417;&#22797;&#26434;&#36755;&#20837;-&#36755;&#20986;&#27169;&#24335;&#30340;&#38750;&#32447;&#24615;&#32467;&#26500;&#12290;&#34429;&#28982;&#22312;&#20855;&#26377;&#20805;&#36275;&#25968;&#25454;&#30340;&#39046;&#22495;&#65288;&#20363;&#22914;&#22270;&#20687;&#20998;&#31867;&#38382;&#39064;&#65289;&#20013;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;&#25110;&#21487;&#35843;&#28608;&#27963;&#20989;&#25968;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#22312;&#25968;&#25454;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20854;&#23545;&#20998;&#31867;&#20934;&#30830;&#24615;&#21644;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#20173;&#28982;&#23384;&#22312;&#37325;&#22823;&#24046;&#36317;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#30740;&#31350;&#20004;&#31181;&#31867;&#22411;&#30340;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#26469;&#22635;&#34917;&#36825;&#20123;&#24046;&#36317;&#12290;&#36825;&#20123;&#20989;&#25968;&#22312;&#27599;&#20010;&#38544;&#34255;&#23618;&#20013;&#24341;&#20837;&#20102;&#20849;&#20139;&#21644;&#20010;&#20307;&#21487;&#35843;&#21442;&#25968;&#65292;&#24182;&#22312;&#21253;&#21547;&#23569;&#20110;&#19968;&#30334;&#20010;&#35757;&#32451;&#23454;&#20363;&#30340;&#19977;&#20010;&#27979;&#35797;&#24179;&#21488;&#20013;&#36827;&#34892;&#20102;&#25506;&#31350;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#20010;&#20307;&#21487;&#35843;&#21442;&#25968;&#30340;&#33258;&#36866;&#24212;&#28608;&#27963;&#20989;&#25968;&#65288;&#20363;&#22914;&#25351;&#25968;&#32447;&#24615;&#21333;&#20301;&#65288;ELU&#65289;&#21644;&#36719;&#21152;&#65289;&#22312;&#39044;&#27979;&#27169;&#22411;&#20013;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A pivotal aspect in the design of neural networks lies in selecting activation functions, crucial for introducing nonlinear structures that capture intricate input-output patterns. While the effectiveness of adaptive or trainable activation functions has been studied in domains with ample data, like image classification problems, significant gaps persist in understanding their influence on classification accuracy and predictive uncertainty in settings characterized by limited data availability. This research aims to address these gaps by investigating the use of two types of adaptive activation functions. These functions incorporate shared and individual trainable parameters per hidden layer and are examined in three testbeds derived from additive manufacturing problems containing fewer than one hundred training instances. Our investigation reveals that adaptive activation functions, such as Exponential Linear Unit (ELU) and Softplus, with individual trainable parameters, result in acc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#23545;&#35282;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#26435;&#34913;&#12290;&#36890;&#36807;&#20998;&#26512;&#21644;&#25968;&#20540;&#30740;&#31350;&#65292;&#21457;&#29616;&#26041;&#24046;&#37327;&#21462;&#20915;&#20110;&#38750;&#32447;&#24615;&#19982;&#19981;&#21516;&#21442;&#25968;&#32452;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24212;&#35813;&#22312;&#20272;&#35745;&#36153;&#33293;&#23572;&#20449;&#24687;&#26102;&#20104;&#20197;&#37325;&#35270;&#12290;</title><link>https://arxiv.org/abs/2402.05379</link><description>&lt;p&gt;
&#23545;&#35282;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Tradeoffs of Diagonal Fisher Information Matrix Estimators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#23545;&#35282;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#26435;&#34913;&#12290;&#36890;&#36807;&#20998;&#26512;&#21644;&#25968;&#20540;&#30740;&#31350;&#65292;&#21457;&#29616;&#26041;&#24046;&#37327;&#21462;&#20915;&#20110;&#38750;&#32447;&#24615;&#19982;&#19981;&#21516;&#21442;&#25968;&#32452;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24212;&#35813;&#22312;&#20272;&#35745;&#36153;&#33293;&#23572;&#20449;&#24687;&#26102;&#20104;&#20197;&#37325;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#25551;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#23616;&#37096;&#20960;&#20309;&#24615;&#36136;&#65292;&#23427;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#24037;&#20855;&#26469;&#29702;&#35299;&#21644;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#12290;&#37492;&#20110;&#20854;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#23454;&#36341;&#32773;&#36890;&#24120;&#20351;&#29992;&#38543;&#26426;&#20272;&#35745;&#22120;&#65292;&#24182;&#20165;&#35780;&#20272;&#23545;&#35282;&#32447;&#26465;&#30446;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#20934;&#30830;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#21462;&#20915;&#20110;&#23427;&#20204;&#20851;&#32852;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26041;&#24046;&#30340;&#30028;&#38480;&#65292;&#24182;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#32593;&#32476;&#20013;&#23454;&#20363;&#21270;&#23427;&#20204;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#21644;&#25968;&#20540;&#30740;&#31350;&#26469;&#26435;&#34913;&#36825;&#20004;&#20010;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#21457;&#29616;&#26041;&#24046;&#37327;&#21462;&#20915;&#20110;&#20851;&#20110;&#19981;&#21516;&#21442;&#25968;&#32452;&#30340;&#38750;&#32447;&#24615;&#65292;&#24403;&#20272;&#35745;&#36153;&#33293;&#23572;&#20449;&#24687;&#26102;&#19981;&#33021;&#24573;&#35270;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Fisher information matrix characterizes the local geometry in the parameter space of neural networks. It elucidates insightful theories and useful tools to understand and optimize neural networks. Given its high computational cost, practitioners often use random estimators and evaluate only the diagonal entries. We examine two such estimators, whose accuracy and sample complexity depend on their associated variances. We derive bounds of the variances and instantiate them in regression and classification networks. We navigate trade-offs of both estimators based on analytical and numerical studies. We find that the variance quantities depend on the non-linearity with respect to different parameter groups and should not be neglected when estimating the Fisher information.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#21644;&#24178;&#25200;&#21442;&#25968;&#19979;&#36827;&#34892;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#20998;&#31867;&#38382;&#39064;&#35270;&#20026;&#24102;&#26377;&#24178;&#25200;&#21442;&#25968;&#30340;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#20272;&#35745;&#20998;&#31867;&#22120;&#22312;&#25972;&#20010;&#24178;&#25200;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#19979;&#19981;&#21464;&#30340;&#25130;&#26029;&#28857;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20107;&#20214;&#30340;&#21487;&#38752;&#20998;&#31867;&#21644;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.05330</link><description>&lt;p&gt;
&#22312;&#26080;&#25311;&#26679;&#20284;&#25512;&#26029;&#30340;&#24178;&#25200;&#21442;&#25968;&#21644;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#19979;&#30340;&#20998;&#31867;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Classification under Nuisance Parameters and Generalized Label Shift in Likelihood-Free Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05330
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#21644;&#24178;&#25200;&#21442;&#25968;&#19979;&#36827;&#34892;&#20998;&#31867;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#20998;&#31867;&#38382;&#39064;&#35270;&#20026;&#24102;&#26377;&#24178;&#25200;&#21442;&#25968;&#30340;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#25105;&#20204;&#33021;&#22815;&#26377;&#25928;&#22320;&#20272;&#35745;&#20998;&#31867;&#22120;&#22312;&#25972;&#20010;&#24178;&#25200;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22312;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227;&#19979;&#19981;&#21464;&#30340;&#25130;&#26029;&#28857;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20107;&#20214;&#30340;&#21487;&#38752;&#20998;&#31867;&#21644;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25105;&#20204;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#20043;&#38388;&#65292;&#26631;&#31614;&#21644;&#28508;&#22312;&#24178;&#25200;&#21442;&#25968;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#20197;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#23545;&#20107;&#20214;&#36827;&#34892;&#20998;&#31867;&#26159;&#19968;&#20010;&#31185;&#23398;&#25361;&#25112;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#20998;&#24067;&#36716;&#31227;&#31216;&#20026;&#24191;&#20041;&#26631;&#31614;&#36716;&#31227; (GLS)&#12290;&#30452;&#25509;&#20351;&#29992;&#35266;&#27979;&#25968;&#25454; $\mathbf{X}$ &#36827;&#34892;&#20998;&#31867;&#20250;&#23548;&#33268;&#39044;&#27979;&#32467;&#26524;&#20559;&#24046;&#21644;&#26631;&#31614; $Y$ &#30340;&#26080;&#25928;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20998;&#31867;&#38382;&#39064;&#35270;&#20026;&#24102;&#26377;&#24178;&#25200;&#21442;&#25968;&#30340;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#26469;&#20811;&#26381;&#36825;&#20123;&#20559;&#24046;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#22312;&#25972;&#20010;&#24178;&#25200;&#21442;&#25968;&#31354;&#38388;&#20013;&#20272;&#35745;&#20998;&#31867;&#22120;&#30340;&#25509;&#25910;&#32773;&#25805;&#20316;&#29305;&#24615; (ROC)&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35774;&#35745;&#22312; GLS &#19979;&#19981;&#21464;&#30340;&#25130;&#26029;&#28857;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26377;&#25928;&#22320;&#36171;&#20104;&#39044;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#39046;&#22495;&#36866;&#24212;&#33021;&#21147;&#65292;&#24182;&#36820;&#22238;&#26377;&#25928;&#30340;&#39044;&#27979;&#38598;&#21512;&#65292;&#21516;&#26102;&#20445;&#25345;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
An open scientific challenge is how to classify events with reliable measures of uncertainty, when we have a mechanistic model of the data-generating process but the distribution over both labels and latent nuisance parameters is different between train and target data. We refer to this type of distributional shift as generalized label shift (GLS). Direct classification using observed data $\mathbf{X}$ as covariates leads to biased predictions and invalid uncertainty estimates of labels $Y$. We overcome these biases by proposing a new method for robust uncertainty quantification that casts classification as a hypothesis testing problem under nuisance parameters. The key idea is to estimate the classifier's receiver operating characteristic (ROC) across the entire nuisance parameter space, which allows us to devise cutoffs that are invariant under GLS. Our method effectively endows a pre-trained classifier with domain adaptation capabilities and returns valid prediction sets while maint
&lt;/p&gt;</description></item><item><title>&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05271</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#24341;&#21457;&#20102;&#28145;&#24230;&#38750;&#32447;&#24615;&#32593;&#32476;&#26435;&#37325;&#19982;&#32463;&#39564;NTK&#20043;&#38388;&#30340;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05271
&lt;/p&gt;
&lt;p&gt;
&#20102;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#21069;&#20154;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#26412;&#30740;&#31350;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#65292;&#24182;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#20174;&#36755;&#20837;-&#26631;&#31614;&#23545;&#20013;&#25552;&#21462;&#32479;&#35745;&#20449;&#24687;&#30340;&#26426;&#21046;&#26159;&#30417;&#30563;&#23398;&#20064;&#20013;&#26368;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#30830;&#23450;&#65292;&#22312;&#19968;&#33324;&#32467;&#26500;&#30340;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#26435;&#37325;&#30340;&#26684;&#25289;&#22982;&#30697;&#38453;&#19982;&#27169;&#22411;&#30340;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#25104;&#27491;&#27604;&#65292;&#36825;&#20010;&#35828;&#27861;&#34987;&#31216;&#20026;&#31070;&#32463;&#29305;&#24449;&#20998;&#26512;&#65288;NFA&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#37327;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#22914;&#20309;&#30456;&#20851;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#36825;&#31181;&#30456;&#20851;&#24615;&#30340;&#20986;&#29616;&#12290;&#25105;&#20204;&#21457;&#29616;NFA&#31561;&#20215;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#24038;&#22855;&#24322;&#32467;&#26500;&#19982;&#19982;&#36825;&#20123;&#26435;&#37325;&#30456;&#20851;&#30340;&#32463;&#39564;&#31070;&#32463;&#20999;&#32447;&#26680;&#30340;&#26174;&#33879;&#25104;&#20998;&#20043;&#38388;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20808;&#21069;&#30740;&#31350;&#20013;&#24341;&#20837;&#30340;NFA&#26159;&#30001;&#38548;&#31163;&#36825;&#31181;&#23545;&#40784;&#30340;&#20013;&#24515;&#21270;NFA&#39537;&#21160;&#30340;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#26089;&#26399;&#35757;&#32451;&#38454;&#27573;&#65292;&#21487;&#20197;&#36890;&#36807;&#35299;&#26512;&#30340;&#26041;&#24335;&#39044;&#27979;NFA&#30340;&#21457;&#23637;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
&lt;/p&gt;</description></item><item><title>&#22312;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#65292;&#26412;&#25991;&#36890;&#36807;&#26500;&#36896;Voronoi-based&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.05220</link><description>&lt;p&gt;
&#20851;&#20110;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Parameter Estimation in Deviated Gaussian Mixture of Experts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05220
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#65292;&#26412;&#25991;&#36890;&#36807;&#26500;&#36896;Voronoi-based&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#20559;&#31163;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#65292;&#20854;&#20013;&#25968;&#25454;&#30001;$(1 - \lambda^{\ast}) g_0(Y| X)+ \lambda^{\ast} \sum_{i = 1}^{k_{\ast}} p_{i}^{\ast} f(Y|(a_{i}^{\ast})^{\top}X+b_i^{\ast},\sigma_{i}^{\ast})$&#29983;&#25104;&#65292;&#20854;&#20013;$X, Y$&#20998;&#21035;&#26159;&#21327;&#21464;&#37327;&#21521;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#65292;$g_{0}(Y|X)$&#26159;&#24050;&#30693;&#20989;&#25968;&#65292;$\lambda^{\ast} \in [0, 1]$&#26159;&#30495;&#23454;&#20294;&#26410;&#30693;&#30340;&#28151;&#21512;&#27604;&#20363;&#65292;$(p_{i}^{\ast}, a_{i}^{\ast}, b_{i}^{\ast}, \sigma_{i}^{\ast})$&#23545;&#20110;$1 \leq i \leq k^{\ast}$&#26159;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#26410;&#30693;&#21442;&#25968;&#12290;&#35813;&#38382;&#39064;&#28304;&#33258;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#65292;&#24403;&#25105;&#20204;&#24076;&#26395;&#26816;&#39564;&#25968;&#25454;&#26159;&#21542;&#30001;$g_{0}(Y|X)$&#65288;&#38646;&#20551;&#35774;&#65289;&#29983;&#25104;&#65292;&#36824;&#26159;&#30001;&#25972;&#20010;&#28151;&#21512;&#65288;&#22791;&#25321;&#20551;&#35774;&#65289;&#29983;&#25104;&#12290;&#22522;&#20110;&#19987;&#23478;&#20989;&#25968;&#30340;&#20195;&#25968;&#32467;&#26500;&#21644;$g_0$&#19982;&#28151;&#21512;&#37096;&#20998;&#30340;&#21487;&#21306;&#20998;&#24615;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#26032;&#30340;&#22522;&#20110;Voronoi&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#25429;&#25417;c
&lt;/p&gt;
&lt;p&gt;
We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \lambda^{\ast}) g_0(Y| X)+ \lambda^{\ast} \sum_{i = 1}^{k_{\ast}} p_{i}^{\ast} f(Y|(a_{i}^{\ast})^{\top}X+b_i^{\ast},\sigma_{i}^{\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\lambda^{\ast} \in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\ast}, a_{i}^{\ast}, b_{i}^{\ast}, \sigma_{i}^{\ast})$ for $1 \leq i \leq k^{\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the c
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.05210</link><description>&lt;p&gt;
&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Anatomically-Controllable Medical Image Generation with Segmentation-Guided Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05210
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#20998;&#21106;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#35299;&#21078;&#21487;&#25511;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#23454;&#29616;&#23545;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#32593;&#32476;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#23454;&#29616;&#20102;&#38750;&#24120;&#39640;&#36136;&#37327;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#65292;&#21487;&#20197;&#36890;&#36807;&#20026;&#23567;&#22411;&#25110;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#25552;&#20379;&#34917;&#20805;&#65292;&#20174;&#32780;&#24110;&#21161;&#20943;&#36731;&#33719;&#21462;&#21644;&#27880;&#37322;&#26032;&#22270;&#20687;&#30340;&#36153;&#29992;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20854;&#20182;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#29983;&#25104;&#22270;&#20687;&#26102;&#38754;&#20020;&#30528;&#20840;&#23616;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#21078;&#21487;&#25511;&#30340;&#21307;&#23398;&#22270;&#20687;&#29983;&#25104;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#27599;&#20010;&#37319;&#26679;&#27493;&#39588;&#20013;&#36981;&#24490;&#22810;&#31867;&#35299;&#21078;&#20998;&#21106;&#25513;&#27169;&#65292;&#24182;&#37319;&#29992;&#38543;&#26426;&#25513;&#27169;&#28040;&#34701;&#35757;&#32451;&#31639;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#25152;&#36873;&#35299;&#21078;&#32422;&#26463;&#30340;&#26465;&#20214;&#21270;&#65292;&#21516;&#26102;&#20801;&#35768;&#20854;&#20182;&#35299;&#21078;&#21306;&#22495;&#30340;&#28789;&#27963;&#24615;&#12290;&#36825;&#20063;&#25913;&#21892;&#20102;&#32593;&#32476;&#22312;&#23436;&#20840;&#26080;&#26465;&#20214;&#65288;&#26080;&#32422;&#26463;&#29983;&#25104;&#65289;&#24773;&#20917;&#19979;&#23545;&#35299;&#21078;&#30495;&#23454;&#24615;&#30340;&#23398;&#20064;&#12290;&#36890;&#36807;&#23545;&#20083;&#33146;MRI&#21644;&#33145;&#37096;/&#39048;&#37096;&#21040;&#30406;&#33108;CT&#25968;&#25454;&#38598;&#30340;&#27604;&#36739;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#22312;&#35299;&#21078;&#30495;&#23454;&#24615;&#21644;&#36755;&#20837;&#25513;&#27169;&#20445;&#30495;&#24230;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have enabled remarkably high-quality medical image generation, which can help mitigate the expenses of acquiring and annotating new images by supplementing small or imbalanced datasets, along with other applications. However, these are hampered by the challenge of enforcing global anatomical realism in generated images. To this end, we propose a diffusion model for anatomically-controlled medical image generation. Our model follows a multi-class anatomical segmentation mask at each sampling step and incorporates a \textit{random mask ablation} training algorithm, to enable conditioning on a selected combination of anatomical constraints while allowing flexibility in other anatomical areas. This also improves the network's learning of anatomical realism for the completely unconditional (unconstrained generation) case. Comparative evaluation on breast MRI and abdominal/neck-to-pelvis CT datasets demonstrates superior anatomical realism and input mask faithfulness over st
&lt;/p&gt;</description></item><item><title>&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65288;BCI&#65289;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#21033;&#29992;&#22810;&#27493;&#39044;&#27979;&#26469;&#25552;&#20379;&#26657;&#20934;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21306;&#38388;&#12290;BCI&#22312;&#20219;&#24847;&#20998;&#24067;&#36716;&#25442;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#19979;&#23454;&#29616;&#20102;&#38271;&#26399;&#35206;&#30422;&#65292;&#19988;&#22312;&#27874;&#21160;&#29575;&#39044;&#27979;&#38382;&#39064;&#19978;&#29983;&#25104;&#26356;&#30701;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;</title><link>https://arxiv.org/abs/2402.05203</link><description>&lt;p&gt;
&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65306;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#39044;&#27979;&#21306;&#38388;&#30340;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Bellman Conformal Inference: Calibrating Prediction Intervals For Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05203
&lt;/p&gt;
&lt;p&gt;
&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65288;BCI&#65289;&#26159;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65292;&#21033;&#29992;&#22810;&#27493;&#39044;&#27979;&#26469;&#25552;&#20379;&#26657;&#20934;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21306;&#38388;&#12290;BCI&#22312;&#20219;&#24847;&#20998;&#24067;&#36716;&#25442;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#19979;&#23454;&#29616;&#20102;&#38271;&#26399;&#35206;&#30422;&#65292;&#19988;&#22312;&#27874;&#21160;&#29575;&#39044;&#27979;&#38382;&#39064;&#19978;&#29983;&#25104;&#26356;&#30701;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#36125;&#23572;&#26364;&#31526;&#21512;&#25512;&#26029;&#65288;BCI&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22260;&#32469;&#20219;&#20309;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#25552;&#20379;&#26657;&#20934;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;BCI&#33021;&#22815;&#21033;&#29992;&#22810;&#27493;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#19978;&#35299;&#20915;&#19968;&#32500;&#38543;&#26426;&#25511;&#21046;&#38382;&#39064;&#65288;SCP&#65289;&#26469;&#26174;&#24335;&#20248;&#21270;&#24179;&#22343;&#21306;&#38388;&#38271;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#21160;&#24577;&#35268;&#21010;&#31639;&#27861;&#26469;&#25214;&#21040;SCP&#30340;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20219;&#24847;&#20998;&#24067;&#36716;&#25442;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#19979;&#65292;BCI&#33021;&#22815;&#23454;&#29616;&#38271;&#26399;&#35206;&#30422;&#65292;&#21363;&#20351;&#22810;&#27493;&#39044;&#27979;&#36739;&#24046;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#20013;&#21457;&#29616;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;BCI&#36991;&#20813;&#20102;&#26080;&#20449;&#24687;&#21306;&#38388;&#65288;&#38271;&#24230;&#26080;&#38480;&#65289;&#30340;&#29983;&#25104;&#65292;&#24182;&#22312;&#27874;&#21160;&#29575;&#39044;&#27979;&#38382;&#39064;&#19978;&#29983;&#25104;&#20102;&#26126;&#26174;&#26356;&#30701;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Bellman Conformal Inference (BCI), a framework that wraps around any time series forecasting models and provides calibrated prediction intervals. Unlike the existing methods, BCI is able to leverage multi-step ahead forecasts and explicitly optimize the average interval lengths by solving a one-dimensional stochastic control problem (SCP) at each time step. In particular, we use the dynamic programming algorithm to find the optimal policy for the SCP. We prove that BCI achieves long-term coverage under arbitrary distribution shifts and temporal dependence, even with poor multi-step ahead forecasts. We find empirically that BCI avoids uninformative intervals that have infinite lengths and generates substantially shorter prediction intervals on volatility forecasting problems when compared with existing methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#24120;&#24120;&#23548;&#33268;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25214;&#21040;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.05187</link><description>&lt;p&gt;
&#22312;&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#20013;&#20803;&#23398;&#20064;&#38236;&#20687;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Meta-learning the mirror map in policy mirror descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05187
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#21457;&#29616;&#65292;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#24120;&#24120;&#23548;&#33268;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25214;&#21040;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#38236;&#20687;&#19979;&#38477;&#65288;PMD&#65289;&#26159;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#27969;&#34892;&#26694;&#26550;&#65292;&#20316;&#20026;&#19968;&#31181;&#32479;&#19968;&#35270;&#35282;&#65292;&#23427;&#21253;&#21547;&#20102;&#35768;&#22810;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#26159;&#36890;&#36807;&#36873;&#25321;&#19968;&#20010;&#38236;&#20687;&#26144;&#23556;&#32780;&#23548;&#20986;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#23613;&#31649;&#23427;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#23545;PMD&#30340;&#20840;&#38754;&#28508;&#21147;&#30340;&#25506;&#32034;&#26159;&#26377;&#38480;&#30340;&#65292;&#22823;&#37096;&#20998;&#30740;&#31350;&#38598;&#20013;&#22312;&#19968;&#20010;&#29305;&#23450;&#30340;&#38236;&#20687;&#26144;&#23556;&#19978;&#65292;&#21363;&#36127;&#29109;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#33879;&#21517;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#26041;&#27861;&#12290;&#30446;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36824;&#19981;&#30830;&#23450;&#38236;&#20687;&#26144;&#23556;&#30340;&#36873;&#25321;&#26159;&#21542;&#20250;&#23545;PMD&#30340;&#26377;&#25928;&#24615;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#20256;&#32479;&#30340;&#38236;&#20687;&#26144;&#23556;&#36873;&#25321;&#65288;NPG&#65289;&#22312;&#20960;&#20010;&#26631;&#20934;&#22522;&#20934;&#29615;&#22659;&#20013;&#32463;&#24120;&#20135;&#29983;&#19981;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#24212;&#29992;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26356;&#39640;&#25928;&#30340;&#38236;&#20687;&#26144;&#23556;&#65292;&#25552;&#39640;&#20102;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#24179;&#22343;&#24615;&#33021;&#36824;&#26159;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Policy Mirror Descent (PMD) is a popular framework in reinforcement learning, serving as a unifying perspective that encompasses numerous algorithms. These algorithms are derived through the selection of a mirror map and enjoy finite-time convergence guarantees. Despite its popularity, the exploration of PMD's full potential is limited, with the majority of research focusing on a particular mirror map -- namely, the negative entropy -- which gives rise to the renowned Natural Policy Gradient (NPG) method. It remains uncertain from existing theoretical studies whether the choice of mirror map significantly influences PMD's efficacy. In our work, we conduct empirical investigations to show that the conventional mirror map choice (NPG) often yields less-than-optimal outcomes across several standard benchmark environments. By applying a meta-learning approach, we identify more efficient mirror maps that enhance performance, both on average and in terms of best performance achieved along th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#20542;&#21521;&#20110;&#23545;&#31216;&#25490;&#21015;&#20989;&#25968;&#65292;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#20998;&#26512;&#39044;&#27979;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#27169;&#22411;&#26469;&#35299;&#20915;&#23398;&#20064;&#26354;&#32447;&#21644;&#32593;&#32476;&#36755;&#20986;&#65292;&#24182;&#22312;&#24120;&#35265;&#35774;&#32622;&#20013;&#24471;&#20986;&#23398;&#20064;&#33021;&#21147;&#30340;&#32039;&#23494;&#36793;&#30028;&#65292;&#26368;&#21518;&#36824;&#35777;&#26126;&#20102;WikiText&#25968;&#25454;&#38598;&#20855;&#26377;&#25490;&#21015;&#23545;&#31216;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05173</link><description>&lt;p&gt;
&#25506;&#32034;Transformer&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;: &#19968;&#20010;&#26469;&#33258;&#26080;&#31351;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Inductive Bias in Transformers: A View From Infinity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#20542;&#21521;&#20110;&#23545;&#31216;&#25490;&#21015;&#20989;&#25968;&#65292;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#20998;&#26512;&#39044;&#27979;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#27169;&#22411;&#26469;&#35299;&#20915;&#23398;&#20064;&#26354;&#32447;&#21644;&#32593;&#32476;&#36755;&#20986;&#65292;&#24182;&#22312;&#24120;&#35265;&#35774;&#32622;&#20013;&#24471;&#20986;&#23398;&#20064;&#33021;&#21147;&#30340;&#32039;&#23494;&#36793;&#30028;&#65292;&#26368;&#21518;&#36824;&#35777;&#26126;&#20102;WikiText&#25968;&#25454;&#38598;&#20855;&#26377;&#25490;&#21015;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;Transformer&#27169;&#22411;&#22312;&#26080;&#31351;&#30340;&#36807;&#21442;&#25968;&#21270;&#39640;&#26031;&#36807;&#31243;&#26497;&#38480;&#20013;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#24182;&#25351;&#20986;Transformer&#27169;&#22411;&#22312;&#24207;&#21015;&#31354;&#38388;&#20013;&#26356;&#20542;&#21521;&#20110;&#23545;&#31216;&#25490;&#21015;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#31216;&#32676;&#30340;&#34920;&#31034;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#22312;&#25968;&#25454;&#38598;&#23545;token&#20043;&#38388;&#30340;&#25490;&#21015;&#20855;&#26377;&#23545;&#31216;&#24615;&#26102;&#32473;&#20986;&#23450;&#37327;&#30340;&#20998;&#26512;&#39044;&#27979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;Transformer&#27169;&#22411;&#65292;&#24182;&#22312;&#26497;&#38480;&#26465;&#20214;&#19979;&#27714;&#35299;&#27169;&#22411;&#65292;&#21253;&#25324;&#23545;&#23398;&#20064;&#26354;&#32447;&#21644;&#32593;&#32476;&#36755;&#20986;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#24120;&#35265;&#30340;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#25512;&#23548;&#20986;&#23398;&#20064;&#33021;&#21147;&#30340;&#32039;&#23494;&#36793;&#30028;&#65292;&#20197;&#19978;&#19979;&#25991;&#38271;&#24230;&#20316;&#20026;&#20989;&#25968;&#30340;&#32553;&#25918;&#23450;&#24459;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;WikiText&#25968;&#25454;&#38598;&#30830;&#23454;&#20855;&#26377;&#19968;&#23450;&#31243;&#24230;&#30340;&#25490;&#21015;&#23545;&#31216;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study inductive bias in Transformers in the infinitely over-parameterized Gaussian process limit and argue transformers tend to be biased towards more permutation symmetric functions in sequence space. We show that the representation theory of the symmetric group can be used to give quantitative analytical predictions when the dataset is symmetric to permutations between tokens. We present a simplified transformer block and solve the model at the limit, including accurate predictions for the learning curves and network outputs. We show that in common setups, one can derive tight bounds in the form of a scaling law for the learnability as a function of the context length. Finally, we argue WikiText dataset, does indeed possess a degree of permutation symmetry.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32447;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#26102;&#36866;&#24212;&#21160;&#24577;&#29615;&#22659;&#21644;&#26377;&#23457;&#26597;&#25968;&#25454;&#30340;&#29983;&#23384;&#20998;&#26512;&#65292;&#36890;&#36807;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;(ONS)&#31639;&#27861;&#20272;&#35745;&#20107;&#20214;&#26102;&#38388;&#20998;&#24067;&#65292;&#24182;&#25552;&#20986;&#20102;&#20445;&#35777;ONS&#20855;&#26377;&#23545;&#25968;&#38543;&#26426;&#36951;&#25022;&#30028;&#30340;&#38543;&#26426;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.05145</link><description>&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#30340;&#22312;&#32447;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Learning Approach for Survival Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32447;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#26102;&#36866;&#24212;&#21160;&#24577;&#29615;&#22659;&#21644;&#26377;&#23457;&#26597;&#25968;&#25454;&#30340;&#29983;&#23384;&#20998;&#26512;&#65292;&#36890;&#36807;&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;(ONS)&#31639;&#27861;&#20272;&#35745;&#20107;&#20214;&#26102;&#38388;&#20998;&#24067;&#65292;&#24182;&#25552;&#20986;&#20102;&#20445;&#35777;ONS&#20855;&#26377;&#23545;&#25968;&#38543;&#26426;&#36951;&#25022;&#30028;&#30340;&#38543;&#26426;&#26041;&#27861;&#21644;&#33258;&#36866;&#24212;&#32858;&#21512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#32447;&#25968;&#23398;&#26694;&#26550;&#29992;&#20110;&#29983;&#23384;&#20998;&#26512;&#65292;&#21487;&#20197;&#23454;&#26102;&#36866;&#24212;&#21160;&#24577;&#29615;&#22659;&#21644;&#26377;&#23457;&#26597;&#25968;&#25454;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#26368;&#20248;&#20108;&#38454;&#22312;&#32447;&#20984;&#20248;&#21270;&#31639;&#27861;-&#22312;&#32447;&#29275;&#39039;&#27493;&#39588;(ONS)&#20272;&#35745;&#20107;&#20214;&#26102;&#38388;&#20998;&#24067;&#12290;&#36825;&#31181;&#20197;&#21069;&#26410;&#26366;&#25506;&#32034;&#30340;&#26041;&#27861;&#20855;&#26377;&#37325;&#22823;&#20248;&#21183;&#65292;&#21253;&#25324;&#20855;&#26377;&#38750;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#30340;&#26126;&#30830;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;ONS&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#36825;&#21462;&#20915;&#20110;&#25351;&#25968;-&#20984;&#24615;&#36136;&#24182;&#19988;&#23545;&#36951;&#25022;&#30028;&#26377;&#26174;&#33879;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#35777;ONS&#20855;&#26377;&#23545;&#25968;&#38543;&#26426;&#36951;&#25022;&#30028;&#30340;&#38543;&#26426;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32858;&#21512;&#26041;&#27861;&#65292;&#30830;&#20445;&#22312;&#20445;&#25345;&#24555;&#36895;&#36951;&#25022;&#30028;&#30340;&#21516;&#26102;&#65292;&#22312;&#36229;&#21442;&#25968;&#36873;&#25321;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#26412;&#25991;&#30340;&#21457;&#29616;&#21487;&#20197;&#36229;&#20986;&#29983;&#23384;&#20998;&#26512;&#39046;&#22495;&#65292;&#24182;&#19988;&#23545;&#20110;&#20219;&#20309;&#20855;&#26377;&#24046;&#30340;&#25351;&#25968;-&#20984;&#24615;&#21644;&#19981;&#31283;&#23450;ONS&#30340;&#24773;&#20917;&#37117;&#26159;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an online mathematical framework for survival analysis, allowing real time adaptation to dynamic environments and censored data. This framework enables the estimation of event time distributions through an optimal second order online convex optimization algorithm-Online Newton Step (ONS). This approach, previously unexplored, presents substantial advantages, including explicit algorithms with non-asymptotic convergence guarantees. Moreover, we analyze the selection of ONS hyperparameters, which depends on the exp-concavity property and has a significant influence on the regret bound. We propose a stochastic approach that guarantees logarithmic stochastic regret for ONS. Additionally, we introduce an adaptive aggregation method that ensures robustness in hyperparameter selection while maintaining fast regret bounds. The findings of this paper can extend beyond the survival analysis field, and are relevant for any case characterized by poor exp-concavity and unstable ONS. Fi
&lt;/p&gt;</description></item><item><title>&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;&#26159;&#20851;&#20110;&#23558;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23545;&#35937;&#38598;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#21644;&#32467;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.04436</link><description>&lt;p&gt;
&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;
&lt;/p&gt;
&lt;p&gt;
Continuous Multidimensional Scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04436
&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#22810;&#32500;&#26631;&#24230;&#26159;&#20851;&#20110;&#23558;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#23545;&#35937;&#38598;&#19981;&#26029;&#22686;&#21152;&#30340;&#24773;&#20917;&#19979;&#65292;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#21644;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#32500;&#26631;&#24230;(MDS)&#26159;&#23558;&#20851;&#20110;&#19968;&#32452;$n$&#20010;&#23545;&#35937;&#30340;&#36317;&#31163;&#20449;&#24687;&#23884;&#20837;&#21040;$d$&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#36807;&#31243;&#12290;&#26368;&#21021;&#30001;&#24515;&#29702;&#27979;&#37327;&#23398;&#30028;&#26500;&#24605;&#65292;MDS&#20851;&#27880;&#30340;&#26159;&#23884;&#20837;&#21040;&#19968;&#32452;&#22266;&#23450;&#23545;&#35937;&#19978;&#30340;&#19968;&#32452;&#22266;&#23450;&#36317;&#31163;&#12290;&#29616;&#20195;&#20851;&#27880;&#30340;&#38382;&#39064;&#26356;&#24120;&#28041;&#21450;&#21040;&#30740;&#31350;&#19982;&#19968;&#32452;&#19981;&#26029;&#22686;&#21152;&#30340;&#23545;&#35937;&#30456;&#20851;&#32852;&#30340;&#19968;&#31995;&#21015;&#36317;&#31163;&#30340;&#26497;&#38480;&#34892;&#20026;&#65292;&#22914;&#22312;&#38543;&#26426;&#22270;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#28176;&#36817;&#29702;&#35770;&#20013;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#28857;&#21040;&#38598;&#21512;&#26144;&#23556;&#29702;&#35770;&#20013;&#30340;&#26631;&#20934;&#32467;&#26524;&#34920;&#26126;&#65292;&#33509;$n$&#22266;&#23450;&#65292;&#21017;&#23884;&#20837;&#32467;&#26500;&#30340;&#26497;&#38480;&#26159;&#26497;&#38480;&#36317;&#31163;&#30340;&#23884;&#20837;&#32467;&#26500;&#12290;&#20294;&#22914;&#26524;$n$&#22686;&#21152;&#24590;&#20040;&#21150;&#21602;&#65311;&#37027;&#20040;&#23601;&#38656;&#35201;&#37325;&#26032;&#21046;&#23450;MDS&#65292;&#20197;&#20415;&#23558;&#25972;&#20010;&#23884;&#20837;&#38382;&#39064;&#24207;&#21015;&#35270;&#20026;&#19968;&#20010;&#22266;&#23450;&#31354;&#38388;&#20013;&#30340;&#19968;&#31995;&#21015;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#26679;&#19968;&#31181;&#37325;&#26032;&#21046;&#23450;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20123;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multidimensional scaling (MDS) is the act of embedding proximity information about a set of $n$ objects in $d$-dimensional Euclidean space. As originally conceived by the psychometric community, MDS was concerned with embedding a fixed set of proximities associated with a fixed set of objects. Modern concerns, e.g., that arise in developing asymptotic theories for statistical inference on random graphs, more typically involve studying the limiting behavior of a sequence of proximities associated with an increasing set of objects. Standard results from the theory of point-to-set maps imply that, if $n$ is fixed, then the limit of the embedded structures is the embedded structure of the limiting proximities. But what if $n$ increases? It then becomes necessary to reformulate MDS so that the entire sequence of embedding problems can be viewed as a sequence of optimization problems in a fixed space. We present such a reformulation and derive some consequences.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04022</link><description>&lt;p&gt;
&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Kernel Packets: from state space model to compactly supported basis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04022
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#29366;&#24577;&#31354;&#38388;&#65288;SS&#65289;&#27169;&#22411;&#20844;&#24335;&#21487;&#20197;&#23558;&#20854;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#38477;&#20302;&#21040;O&#65288;n&#65289;&#65288;n&#20026;&#25968;&#25454;&#28857;&#20010;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;m&#32500;&#30340;GP&#30340;SS&#27169;&#22411;&#20844;&#24335;&#31561;&#20215;&#20110;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#31216;&#20026;&#36890;&#29992;&#21491;&#26680;&#20998;&#32452;&#65288;KP&#65289;&#65306;&#19968;&#31181;&#29992;&#20110;GP&#21327;&#26041;&#24046;&#20989;&#25968;K&#30340;&#21464;&#25442;&#65292;&#20351;&#24471;&#23545;&#20110;&#20219;&#24847;$t \leq t_1$&#65292;$0 \leq j \leq m-1$&#21644;$m+1$&#20010;&#36830;&#32493;&#28857;$t_i$&#65292;&#37117;&#28385;&#36275;$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$&#65292;&#20854;&#20013;${D}_t^{(j)}f(t)$&#34920;&#31034;&#22312;$t$&#19978;&#20316;&#29992;&#30340;&#31532;j&#38454;&#23548;&#25968;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;GP&#30340;&#21521;&#21518;SS&#27169;&#22411;&#20844;&#24335;&#65292;&#24471;&#21040;&#20102;&#19979;&#19968;&#20010;$m$&#20010;&#36830;&#32493;&#28857;&#30340;&#24038;&#26680;&#20998;&#32452;&#30340;&#27010;&#24565;&#65306;$\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$&#65292;&#23545;&#20110;&#20219;&#24847;$t\geq t_{2m}$&#12290;&#36890;&#36807;&#32467;&#21512;&#24038;&#21491;&#26680;&#20998;&#32452;&#65292;&#21487;&#20197;&#35777;&#26126;&#36825;&#20123;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36866;&#24403;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#65306;&#23545;&#20110;&#20219;&#24847;$t\not\in(t_0,t_{2m})$&#21644;$j=0,\cdots,m-1$&#65292;$\phi^{(j)}(t)=0$&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j \leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and $j=0,\cdots,m-1$
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36136;&#30097;&#20102;&#25512;&#33616;&#31995;&#32479;&#23454;&#36341;&#20013;&#30446;&#21069;&#24120;&#29992;&#30340;&#8220;&#25720;&#30528;&#30707;&#22836;&#36807;&#27827;&#8221;&#26041;&#27861;&#65292;&#21628;&#21505;&#25682;&#24323;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#22534;&#26632;&#30340;&#38750;&#26631;&#20934;&#29992;&#27861;&#65292;&#20197;&#35299;&#38145;&#22870;&#21169;&#20248;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.02152</link><description>&lt;p&gt;
&#35770;&#25991;&#39064;&#30446;&#65306;&#20026;&#20160;&#20040;&#8220;&#25720;&#30528;&#30707;&#22836;&#36807;&#27827;&#8221;&#26041;&#27861;&#20027;&#23548;&#25512;&#33616;&#31995;&#32479;&#23454;&#36341;&#65307;&#21628;&#21505;&#25682;&#24323;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Why the Shooting in the Dark Method Dominates Recommender Systems Practice; A Call to Abandon Anti-Utopian Thinking
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02152
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36136;&#30097;&#20102;&#25512;&#33616;&#31995;&#32479;&#23454;&#36341;&#20013;&#30446;&#21069;&#24120;&#29992;&#30340;&#8220;&#25720;&#30528;&#30707;&#22836;&#36807;&#27827;&#8221;&#26041;&#27861;&#65292;&#21628;&#21505;&#25682;&#24323;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#22534;&#26632;&#30340;&#38750;&#26631;&#20934;&#29992;&#27861;&#65292;&#20197;&#35299;&#38145;&#22870;&#21169;&#20248;&#21270;&#30340;&#25512;&#33616;&#31995;&#32479;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#25512;&#33616;&#31995;&#32479;&#30740;&#31350;&#22788;&#20110;&#19968;&#31181;&#22855;&#29305;&#30340;&#22659;&#22320;&#12290;&#23613;&#31649;&#22312;&#36890;&#36807;A/B&#27979;&#35797;&#26469;&#34913;&#37327;&#24615;&#33021;&#26041;&#38754;&#26377;&#19968;&#20010;&#38750;&#24120;&#20005;&#26684;&#30340;&#21327;&#35758;&#65292;&#20294;&#25214;&#21040;&#35201;&#27979;&#35797;&#30340;&#8220;B&#8221;&#30340;&#26368;&#20339;&#26041;&#27861;&#24182;&#27809;&#26377;&#26126;&#30830;&#22320;&#38024;&#23545;&#24615;&#33021;&#65292;&#32780;&#26159;&#38024;&#23545;&#19968;&#20010;&#20195;&#29702;&#25351;&#26631;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;A/B&#27979;&#35797;&#30340;&#25104;&#21151;&#25110;&#22833;&#36133;&#23436;&#20840;&#21462;&#20915;&#20110;&#25152;&#25552;&#20986;&#30340;&#20195;&#29702;&#25351;&#26631;&#26159;&#21542;&#19982;&#24615;&#33021;&#30456;&#20851;&#24615;&#26356;&#22909;&#12290;&#27809;&#26377;&#21407;&#21017;&#21487;&#20197;&#22312;&#31163;&#32447;&#24773;&#20917;&#19979;&#30830;&#23450;&#19968;&#20010;&#20195;&#29702;&#25351;&#26631;&#26159;&#21542;&#27604;&#21478;&#19968;&#20010;&#26356;&#22909;&#65292;&#36825;&#20351;&#24471;&#20174;&#19994;&#32773;&#20204;&#25720;&#19981;&#30528;&#22836;&#33041;&#12290;&#26412;&#35770;&#25991;&#30340;&#30446;&#30340;&#26159;&#36136;&#30097;&#36825;&#31181;&#21453;&#20044;&#25176;&#37030;&#24605;&#32500;&#65292;&#24182;&#20027;&#24352;&#28145;&#24230;&#23398;&#20064;&#22534;&#26632;&#30340;&#38750;&#26631;&#20934;&#29992;&#27861;&#23454;&#38469;&#19978;&#26377;&#28508;&#21147;&#35299;&#38145;&#20248;&#21270;&#22870;&#21169;&#30340;&#25512;&#33616;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Applied recommender systems research is in a curious position. While there is a very rigorous protocol for measuring performance by A/B testing, best practice for finding a `B' to test does not explicitly target performance but rather targets a proxy measure. The success or failure of a given A/B test then depends entirely on if the proposed proxy is better correlated to performance than the previous proxy. No principle exists to identify if one proxy is better than another offline, leaving the practitioners shooting in the dark. The purpose of this position paper is to question this anti-Utopian thinking and argue that a non-standard use of the deep learning stacks actually has the potential to unlock reward optimizing recommendation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#39044;&#27979;&#27169;&#22411;&#30340;&#37096;&#32626;&#23545;&#20915;&#31574;&#20135;&#29983;&#26377;&#23475;&#24433;&#21709;&#30340;&#24773;&#20917;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20250;&#25104;&#20026;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;&#12290;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;&#22240;&#20026;&#23545;&#26576;&#20123;&#24739;&#32773;&#36896;&#25104;&#26356;&#31967;&#31957;&#30340;&#32467;&#26524;&#32780;&#20351;&#20854;&#39044;&#27979;&#33021;&#21147;&#21464;&#26080;&#25928;&#12290;</title><link>https://arxiv.org/abs/2312.01210</link><description>&lt;p&gt;
&#24403;&#20934;&#30830;&#30340;&#39044;&#27979;&#27169;&#22411;&#23548;&#33268;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;
&lt;/p&gt;
&lt;p&gt;
When accurate prediction models yield harmful self-fulfilling prophecies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35843;&#26597;&#39044;&#27979;&#27169;&#22411;&#30340;&#37096;&#32626;&#23545;&#20915;&#31574;&#20135;&#29983;&#26377;&#23475;&#24433;&#21709;&#30340;&#24773;&#20917;&#65292;&#21457;&#29616;&#36825;&#20123;&#27169;&#22411;&#21487;&#33021;&#20250;&#25104;&#20026;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;&#12290;&#36825;&#20123;&#27169;&#22411;&#19981;&#20250;&#22240;&#20026;&#23545;&#26576;&#20123;&#24739;&#32773;&#36896;&#25104;&#26356;&#31967;&#31957;&#30340;&#32467;&#26524;&#32780;&#20351;&#20854;&#39044;&#27979;&#33021;&#21147;&#21464;&#26080;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#26631;&#65306;&#39044;&#27979;&#27169;&#22411;&#22312;&#21307;&#23398;&#30740;&#31350;&#21644;&#23454;&#36341;&#20013;&#38750;&#24120;&#21463;&#27426;&#36814;&#12290;&#36890;&#36807;&#20026;&#29305;&#23450;&#24739;&#32773;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#24110;&#21161;&#20915;&#31574;&#22256;&#38590;&#30340;&#27835;&#30103;&#20915;&#31574;&#65292;&#24182;&#19988;&#36890;&#24120;&#34987;&#35465;&#20026;&#20010;&#24615;&#21270;&#30340;&#12289;&#25968;&#25454;&#39537;&#21160;&#30340;&#21307;&#30103;&#20445;&#20581;&#30340;&#26480;&#20986;&#20195;&#34920;&#12290;&#35768;&#22810;&#39044;&#27979;&#27169;&#22411;&#22312;&#39564;&#35777;&#30740;&#31350;&#20013;&#22522;&#20110;&#20854;&#39044;&#27979;&#20934;&#30830;&#24615;&#32780;&#37096;&#32626;&#29992;&#20110;&#20915;&#31574;&#25903;&#25345;&#12290;&#25105;&#20204;&#35843;&#26597;&#36825;&#26159;&#21542;&#26159;&#19968;&#31181;&#23433;&#20840;&#21644;&#26377;&#25928;&#30340;&#26041;&#27861;&#12290;&#26448;&#26009;&#21644;&#26041;&#27861;&#65306;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#39044;&#27979;&#27169;&#22411;&#36827;&#34892;&#20915;&#31574;&#21487;&#20197;&#23548;&#33268;&#26377;&#23475;&#30340;&#20915;&#31574;&#65292;&#21363;&#20351;&#22312;&#37096;&#32626;&#21518;&#36825;&#20123;&#39044;&#27979;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#21306;&#20998;&#24230;&#12290;&#36825;&#20123;&#27169;&#22411;&#26159;&#26377;&#23475;&#30340;&#33258;&#25105;&#23454;&#29616;&#39044;&#35328;&#65306;&#23427;&#20204;&#30340;&#37096;&#32626;&#25439;&#23475;&#20102;&#19968;&#32676;&#24739;&#32773;&#65292;&#20294;&#36825;&#20123;&#24739;&#32773;&#30340;&#26356;&#31967;&#31957;&#30340;&#32467;&#26524;&#24182;&#19981;&#20351;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#26080;&#25928;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#23545;&#36825;&#20123;&#39044;&#27979;&#27169;&#22411;&#38598;&#21512;&#30340;&#24418;&#24335;&#21270;&#25551;&#36848;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#37096;&#32626;&#21069;&#21518;&#37117;&#36827;&#34892;&#20102;&#33391;&#22909;&#26657;&#20934;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Objective: Prediction models are popular in medical research and practice. By predicting an outcome of interest for specific patients, these models may help inform difficult treatment decisions, and are often hailed as the poster children for personalized, data-driven healthcare. Many prediction models are deployed for decision support based on their prediction accuracy in validation studies. We investigate whether this is a safe and valid approach.   Materials and Methods: We show that using prediction models for decision making can lead to harmful decisions, even when the predictions exhibit good discrimination after deployment. These models are harmful self-fulfilling prophecies: their deployment harms a group of patients but the worse outcome of these patients does not invalidate the predictive power of the model.   Results: Our main result is a formal characterization of a set of such prediction models. Next we show that models that are well calibrated before and after deployment 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#39640;&#20102;&#35757;&#32451;&#30340;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2208.04508</link><description>&lt;p&gt;
&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Training Overparametrized Neural Networks in Sublinear Time
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.04508
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#27425;&#32447;&#24615;&#26102;&#38388;&#20869;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#39640;&#20102;&#35757;&#32451;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25104;&#21151;&#20184;&#20986;&#20102;&#24040;&#22823;&#30340;&#35745;&#31639;&#21644;&#33021;&#28304;&#25104;&#26412;&#65292;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#25193;&#23637;&#24615;&#27491;&#22312;&#25104;&#20026;&#20154;&#24037;&#26234;&#33021;&#36827;&#23637;&#30340;&#30495;&#27491;&#38556;&#30861;&#12290;&#23613;&#31649;&#20256;&#32479;&#30340;&#21453;&#21521;&#20256;&#25773;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#30340;&#25104;&#26412;&#27599;&#27425;&#36845;&#20195;&#24456;&#20302;&#65292;&#20294;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#20855;&#26377;&#31105;&#27490;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#26080;&#35770;&#26159;&#22312;&#29702;&#35770;&#19978;&#36824;&#26159;&#23454;&#36341;&#20013;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#31181;&#25104;&#26412;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#37319;&#29992;&#20855;&#26377;&#26356;&#24555;&#25910;&#25947;&#36895;&#24230;&#20294;&#27599;&#27425;&#36845;&#20195;&#25104;&#26412;&#26356;&#39640;&#30340;&#26367;&#20195;&#65288;&#29275;&#39039;&#31867;&#22411;&#65289;&#35757;&#32451;&#26041;&#27861;&#12290;&#23545;&#20110;&#20855;&#26377;$m=\mathrm{poly}(n)$&#20010;&#21442;&#25968;&#21644;&#36755;&#20837;&#25209;&#27425;$n$&#20010;&#25968;&#25454;&#28857;&#22312;$\mathbb{R}^d$&#20013;&#30340;&#20856;&#22411;&#31070;&#32463;&#32593;&#32476;&#65292;[Brand, Peng, Song, and Weinstein, ITCS'2021]&#30340;&#20808;&#21069;&#24037;&#20316;&#27599;&#27425;&#36845;&#20195;&#38656;&#35201;$\sim mnd+n^3$&#30340;&#26102;&#38388;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#21482;&#38656;&#35201;$m^{1-\alpha}nd+n^3$&#30340;&#25674;&#38144;&#26102;&#38388;&#65292;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of deep learning comes at a tremendous computational and energy cost, and the scalability of training massively overparametrized neural networks is becoming a real barrier to the progress of artificial intelligence (AI). Despite the popularity and low cost-per-iteration of traditional backpropagation via gradient decent, stochastic gradient descent (SGD) has prohibitive convergence rate in non-convex settings, both in theory and practice.   To mitigate this cost, recent works have proposed to employ alternative (Newton-type) training methods with much faster convergence rate, albeit with higher cost-per-iteration. For a typical neural network with $m=\mathrm{poly}(n)$ parameters and input batch of $n$ datapoints in $\mathbb{R}^d$, the previous work of [Brand, Peng, Song, and Weinstein, ITCS'2021] requires $\sim mnd + n^3$ time per iteration. In this paper, we present a novel training method that requires only $m^{1-\alpha} n d + n^3$ amortized time in the same overparametri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20010;&#24615;&#21270;PCA&#65288;PerPCA&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#20027;&#25104;&#20998;&#26469;&#32534;&#30721;&#29420;&#29305;&#21644;&#20849;&#20139;&#29305;&#24449;&#65292;&#35299;&#20915;&#20102;PCA&#38754;&#20020;&#30340;&#24322;&#36136;&#24615;&#25361;&#25112;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#21463;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#35782;&#21035;&#21644;&#24674;&#22797;&#20986;&#29420;&#29305;&#21644;&#20849;&#20139;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#32852;&#37030;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;</title><link>https://arxiv.org/abs/2207.08041</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;PCA:&#35299;&#32806;&#20849;&#20139;&#21644;&#29420;&#29305;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Personalized PCA: Decoupling Shared and Unique Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2207.08041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20010;&#24615;&#21270;PCA&#65288;PerPCA&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#20840;&#23616;&#21644;&#23616;&#37096;&#20027;&#25104;&#20998;&#26469;&#32534;&#30721;&#29420;&#29305;&#21644;&#20849;&#20139;&#29305;&#24449;&#65292;&#35299;&#20915;&#20102;PCA&#38754;&#20020;&#30340;&#24322;&#36136;&#24615;&#25361;&#25112;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#21463;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#35782;&#21035;&#21644;&#24674;&#22797;&#20986;&#29420;&#29305;&#21644;&#20849;&#20139;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#36824;&#35774;&#35745;&#20102;&#19968;&#20010;&#32852;&#37030;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;PCA&#38754;&#20020;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65306;&#24322;&#36136;&#24615;&#12290;&#24403;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#30340;&#26469;&#28304;&#65292;&#20855;&#26377;&#24322;&#36136;&#30340;&#36235;&#21183;&#65292;&#21516;&#26102;&#20173;&#28982;&#20849;&#20139;&#26576;&#20123;&#19968;&#33268;&#24615;&#26102;&#65292;&#20851;&#38190;&#26159;&#25552;&#21462;&#20849;&#20139;&#30340;&#30693;&#35782;&#65292;&#21516;&#26102;&#20445;&#30041;&#27599;&#20010;&#26469;&#28304;&#30340;&#29420;&#29305;&#29305;&#24449;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20010;&#24615;&#21270;PCA&#65288;PerPCA&#65289;&#65292;&#23427;&#20351;&#29992;&#20114;&#30456;&#27491;&#20132;&#30340;&#20840;&#23616;&#21644;&#23616;&#37096;&#20027;&#25104;&#20998;&#26469;&#32534;&#30721;&#29420;&#29305;&#21644;&#20849;&#20139;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#21363;&#20351;&#21327;&#26041;&#24046;&#30697;&#38453;&#26497;&#20854;&#19981;&#21516;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#21463;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#35782;&#21035;&#21644;&#24674;&#22797;&#20986;&#29420;&#29305;&#21644;&#20849;&#20139;&#30340;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#23436;&#20840;&#30340;&#32852;&#37030;&#31639;&#27861;&#65292;&#28789;&#24863;&#26469;&#33258;&#20998;&#24067;&#24335;Stiefel&#26799;&#24230;&#19979;&#38477;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#24191;&#20041;&#22238;&#32553;&#30340;&#26032;&#25805;&#20316;&#32452;&#26469;&#22788;&#29702;&#27491;&#20132;&#32422;&#26463;&#65292;&#21482;&#38656;&#35201;&#22312;&#26469;&#28304;&#20043;&#38388;&#20849;&#20139;&#20840;&#23616;&#20027;&#25104;&#20998;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we tackle a significant challenge in PCA: heterogeneity. When data are collected from different sources with heterogeneous trends while still sharing some congruency, it is critical to extract shared knowledge while retaining the unique features of each source. To this end, we propose personalized PCA (PerPCA), which uses mutually orthogonal global and local principal components to encode both unique and shared features. We show that, under mild conditions, both unique and shared features can be identified and recovered by a constrained optimization problem, even if the covariance matrices are immensely different. Also, we design a fully federated algorithm inspired by distributed Stiefel gradient descent to solve the problem. The algorithm introduces a new group of operations called generalized retractions to handle orthogonality constraints, and only requires global PCs to be shared across sources. We prove the linear convergence of the algorithm under suitable assumpt
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20449;&#29992;&#35780;&#20998;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24418;&#24335;&#21270;&#27979;&#35797;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#24433;&#21709;&#20844;&#24179;&#24615;&#30340;&#21464;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#21487;&#20197;&#25351;&#23548;&#20449;&#36151;&#21830;&#30417;&#27979;&#31639;&#27861;&#20844;&#24179;&#24615;&#12289;&#30417;&#31649;&#26426;&#26500;&#25511;&#21046;&#20844;&#24179;&#24615;&#65292;&#21516;&#26102;&#25552;&#39640;&#21463;&#20445;&#25252;&#32676;&#20307;&#30340;&#21033;&#30410;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#27700;&#24179;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2205.10200</link><description>&lt;p&gt;
&#20449;&#29992;&#35780;&#20998;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Fairness of Credit Scoring Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.10200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20449;&#29992;&#35780;&#20998;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#24418;&#24335;&#21270;&#27979;&#35797;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#25506;&#32034;&#20102;&#24433;&#21709;&#20844;&#24179;&#24615;&#30340;&#21464;&#37327;&#12290;&#30740;&#31350;&#32467;&#26524;&#21487;&#20197;&#25351;&#23548;&#20449;&#36151;&#21830;&#30417;&#27979;&#31639;&#27861;&#20844;&#24179;&#24615;&#12289;&#30417;&#31649;&#26426;&#26500;&#25511;&#21046;&#20844;&#24179;&#24615;&#65292;&#21516;&#26102;&#25552;&#39640;&#21463;&#20445;&#25252;&#32676;&#20307;&#30340;&#21033;&#30410;&#65292;&#21516;&#26102;&#20445;&#25345;&#39640;&#27700;&#24179;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#29992;&#24066;&#22330;&#20013;&#65292;&#31579;&#36873;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#21306;&#20998;&#22909;&#31867;&#22411;&#21644;&#22351;&#31867;&#22411;&#30340;&#20511;&#27454;&#20154;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#26679;&#20570;&#30340;&#36807;&#31243;&#20013;&#65292;&#20182;&#20204;&#36824;&#21487;&#33021;&#22312;&#20855;&#26377;&#21463;&#20445;&#25252;&#23646;&#24615;&#30340;&#20010;&#20307;&#65288;&#20363;&#22914;&#24615;&#21035;&#12289;&#24180;&#40836;&#12289;&#31181;&#26063;&#36215;&#28304;&#65289;&#21644;&#25972;&#20010;&#20154;&#32676;&#20043;&#38388;&#36827;&#34892;&#27495;&#35270;&#12290;&#36825;&#21487;&#33021;&#26159;&#26080;&#24847;&#35782;&#30340;&#65292;&#26469;&#28304;&#20110;&#35757;&#32451;&#25968;&#25454;&#38598;&#25110;&#27169;&#22411;&#26412;&#36523;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#24418;&#24335;&#21270;&#27979;&#35797;&#35780;&#20998;&#27169;&#22411;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#65292;&#20197;&#21450;&#22914;&#20309;&#30830;&#23450;&#24433;&#21709;&#20844;&#24179;&#24615;&#19981;&#36275;&#30340;&#21464;&#37327;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#21464;&#37327;&#26469;&#20248;&#21270;&#20844;&#24179;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#30417;&#27979;&#20449;&#36151;&#21830;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#12289;&#22914;&#20309;&#30001;&#30417;&#31649;&#26426;&#26500;&#25511;&#21046;&#12289;&#22914;&#20309;&#25913;&#21892;&#21463;&#20445;&#25252;&#32676;&#20307;&#30340;&#21033;&#30410;&#65292;&#21516;&#26102;&#20173;&#20445;&#25345;&#39640;&#27700;&#24179;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;
In credit markets, screening algorithms aim to discriminate between good-type and bad-type borrowers. However, when doing so, they can also discriminate between individuals sharing a protected attribute (e.g. gender, age, racial origin) and the rest of the population. This can be unintentional and originate from the training dataset or from the model itself. We show how to formally test the algorithmic fairness of scoring models and how to identify the variables responsible for any lack of fairness. We then use these variables to optimize the fairness-performance trade-off. Our framework provides guidance on how algorithmic fairness can be monitored by lenders, controlled by their regulators, improved for the benefit of protected groups, while still maintaining a high level of forecasting accuracy.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26041;&#24046;&#20449;&#24687;&#36827;&#34892;&#38754;&#26495;&#25968;&#25454;&#20013;&#32676;&#32452;&#32467;&#26500;&#20272;&#35745;&#30340;&#20809;&#35889;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#23616;&#37096;&#20998;&#26512;&#21457;&#29616;&#65292;&#20010;&#20307;&#31995;&#25968;&#20272;&#35745;&#30340;&#26041;&#24046;&#21253;&#21547;&#20102;&#20272;&#35745;&#32676;&#32452;&#32467;&#26500;&#25152;&#38656;&#30340;&#26377;&#29992;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#36866;&#29992;&#20110;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#65292;&#36824;&#36866;&#29992;&#20110;&#21482;&#25552;&#20379;&#21442;&#25968;&#20272;&#35745;&#21644;&#20272;&#35745;&#19981;&#30830;&#23450;&#24230;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2201.01793</link><description>&lt;p&gt;
&#20351;&#29992;&#26041;&#24046;&#20449;&#24687;&#36827;&#34892;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#32676;&#32452;&#32467;&#26500;&#20272;&#35745;&#30340;&#20809;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Spectral Clustering with Variance Information for Group Structure Estimation in Panel Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2201.01793
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26041;&#24046;&#20449;&#24687;&#36827;&#34892;&#38754;&#26495;&#25968;&#25454;&#20013;&#32676;&#32452;&#32467;&#26500;&#20272;&#35745;&#30340;&#20809;&#35889;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#23616;&#37096;&#20998;&#26512;&#21457;&#29616;&#65292;&#20010;&#20307;&#31995;&#25968;&#20272;&#35745;&#30340;&#26041;&#24046;&#21253;&#21547;&#20102;&#20272;&#35745;&#32676;&#32452;&#32467;&#26500;&#25152;&#38656;&#30340;&#26377;&#29992;&#20449;&#24687;&#12290;&#35813;&#26041;&#27861;&#19981;&#20165;&#36866;&#29992;&#20110;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#65292;&#36824;&#36866;&#29992;&#20110;&#21482;&#25552;&#20379;&#21442;&#25968;&#20272;&#35745;&#21644;&#20272;&#35745;&#19981;&#30830;&#23450;&#24230;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38754;&#26495;&#25968;&#25454;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#37325;&#22797;&#23545;&#20010;&#20307;&#36827;&#34892;&#35266;&#23519;&#12290;&#36890;&#24120;&#21487;&#20197;&#21512;&#29702;&#22320;&#20551;&#35774;&#23384;&#22312;&#30528;&#20849;&#20139;&#35266;&#23519;&#29305;&#24449;&#25928;&#24212;&#30340;&#20010;&#20307;&#32676;&#32452;&#65292;&#20294;&#26159;&#32676;&#32452;&#36890;&#24120;&#20107;&#20808;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#39318;&#20808;&#36827;&#34892;&#23616;&#37096;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#20010;&#20307;&#31995;&#25968;&#20272;&#35745;&#30340;&#26041;&#24046;&#21253;&#21547;&#20102;&#20272;&#35745;&#32676;&#32452;&#32467;&#26500;&#30340;&#26377;&#29992;&#20449;&#24687;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#20272;&#35745;&#19968;&#33324;&#38754;&#26495;&#25968;&#25454;&#27169;&#22411;&#20013;&#30340;&#26410;&#35266;&#27979;&#21040;&#30340;&#32676;&#32452;&#65292;&#35813;&#26041;&#27861;&#26126;&#30830;&#32771;&#34385;&#20102;&#26041;&#24046;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20010;&#20307;&#25968;&#37327;&#36739;&#22810;&#21644;/&#25110;&#27599;&#20010;&#20010;&#20307;&#26377;&#37325;&#22797;&#27979;&#37327;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#20855;&#26377;&#21487;&#35745;&#31639;&#24615;&#12290;&#36825;&#20123;&#26041;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#21482;&#25552;&#20379;&#21442;&#25968;&#20272;&#35745;&#21644;&#19968;&#20123;&#20272;&#35745;&#19981;&#30830;&#23450;&#24230;&#37327;&#32473;&#30740;&#31350;&#20154;&#21592;&#32780;&#27809;&#26377;&#20010;&#20307;&#23618;&#38754;&#25968;&#25454;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#24443;&#24213;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a panel data setting where repeated observations on individuals are available. Often it is reasonable to assume that there exist groups of individuals that share similar effects of observed characteristics, but the grouping is typically unknown in advance. We first conduct a local analysis which reveals that the variances of the individual coefficient estimates contain useful information for the estimation of group structure. We then propose a method to estimate unobserved groupings for general panel data models that explicitly account for the variance information. Our proposed method remains computationally feasible with a large number of individuals and/or repeated measurements on each individual. The developed ideas can also be applied even when individual-level data are not available and only parameter estimates together with some quantification of estimation uncertainty are given to the researcher. A thorough simulation study demonstrates superior performance of our metho
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#29109;&#27491;&#21017;&#21270;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#27491;&#21017;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#20197;&#21450;&#24555;&#36895;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2106.04096</link><description>&lt;p&gt;
&#29109;&#27491;&#21017;&#21270;&#30340;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#19982;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Entropy-Regularized Natural Policy Gradient with Linear Function Approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2106.04096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#29109;&#27491;&#21017;&#21270;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#27491;&#21017;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#20197;&#21450;&#24555;&#36895;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65288;NPG&#65289;&#26041;&#27861;&#22312;&#20855;&#26377;&#22823;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#20013;&#36890;&#36807;&#29109;&#27491;&#21017;&#21270;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#23454;&#35777;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#22312;&#20989;&#25968;&#36924;&#36817;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#36136;&#21644;&#29109;&#27491;&#21017;&#21270;&#30340;&#24433;&#21709;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#26412;&#25991;&#22312;softmax&#21442;&#25968;&#21270;&#19979;&#65292;&#24314;&#31435;&#20102;&#29109;&#27491;&#21017;&#21270;&#30340;NPG&#19982;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#20998;&#26512;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29109;&#27491;&#21017;&#21270;&#30340;NPG&#36890;&#36807;&#24179;&#22343;&#28385;&#36275;&#8220;&#28608;&#21169;&#25345;&#20037;&#24615;&#8221;&#26465;&#20214;&#65292;&#24182;&#22312;&#27491;&#21017;&#21270;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20197;$\tilde{O}(1/T)$&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#36798;&#21040;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#12290;&#36825;&#20010;&#25910;&#25947;&#32467;&#26524;&#19981;&#38656;&#35201;&#23545;&#31574;&#30053;&#36827;&#34892;&#20219;&#20309;&#20808;&#39564;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#22312;&#27987;&#24230;&#31995;&#25968;&#21644;&#22522;&#21521;&#37327;&#30340;&#36731;&#24494;&#27491;&#21017;&#24615;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29109;&#27491;&#21017;&#21270;&#30340;NPG&#22312;&#20989;&#25968;&#36924;&#36817;&#35823;&#24046;&#33539;&#22260;&#20869;&#21576;&#29616;&#8220;&#32447;&#24615;&#25910;&#25947;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural policy gradient (NPG) methods with entropy regularization achieve impressive empirical success in reinforcement learning problems with large state-action spaces. However, their convergence properties and the impact of entropy regularization remain elusive in the function approximation regime. In this paper, we establish finite-time convergence analyses of entropy-regularized NPG with linear function approximation under softmax parameterization. In particular, we prove that entropy-regularized NPG with averaging satisfies the \emph{persistence of excitation} condition, and achieves a fast convergence rate of $\tilde{O}(1/T)$ up to a function approximation error in regularized Markov decision processes. This convergence result does not require any a priori assumptions on the policies. Furthermore, under mild regularity conditions on the concentrability coefficient and basis vectors, we prove that entropy-regularized NPG exhibits \emph{linear convergence} up to a function approxim
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#23454;&#29616;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#25968;&#20540;&#24615;&#33021;&#65292;&#24212;&#29992;&#20110;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#21518;&#20063;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2401.16571</link><description>&lt;p&gt;
&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#20272;&#35745;&#20010;&#20307;&#21270;&#22810;&#27835;&#30103;&#21453;&#24212;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons. (arXiv:2401.16571v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16571
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#23454;&#29616;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#25968;&#20540;&#24615;&#33021;&#65292;&#24212;&#29992;&#20110;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#21518;&#20063;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26159;&#31934;&#30830;&#21307;&#23398;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20852;&#36259;&#22312;&#20110;&#22522;&#20110;&#19968;&#20123;&#22806;&#37096;&#21327;&#21464;&#37327;&#65292;&#30830;&#23450;&#19981;&#21516;&#27835;&#30103;&#26041;&#24335;&#30340;&#24046;&#24322;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#25105;&#20204;&#23545;&#21709;&#24212;&#26354;&#32447;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#20381;&#36182;&#20110;&#24102;&#26377;&#20849;&#20139;&#38544;&#34255;&#31070;&#32463;&#20803;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#65288;RBF&#65289;&#32593;&#32476;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26377;&#21161;&#20110;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#12290;&#25105;&#20204;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#24320;&#21457;&#20102;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#39640;&#25928;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#36827;&#34892;&#23454;&#29616;&#65292;&#36866;&#24403;&#22320;&#22788;&#29702;&#20102;&#20998;&#26512;&#21508;&#20010;&#26041;&#38754;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;MIMIC&#25968;&#25454;&#21518;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#19981;&#21516;&#27835;&#30103;&#31574;&#30053;&#23545;ICU&#20303;&#38498;&#26102;&#38388;&#21644;12&#23567;&#26102;SOFA&#35780;&#20998;&#30340;&#24433;&#21709;&#30340;&#19968;&#20123;&#26377;&#36259;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous treatment effect estimation is an important problem in precision medicine. Specific interests lie in identifying the differential effect of different treatments based on some external covariates. We propose a novel non-parametric treatment effect estimation method in a multi-treatment setting. Our non-parametric modeling of the response curves relies on radial basis function (RBF)-nets with shared hidden neurons. Our model thus facilitates modeling commonality among the treatment outcomes. The estimation and inference schemes are developed under a Bayesian framework and implemented via an efficient Markov chain Monte Carlo algorithm, appropriately accommodating uncertainty in all aspects of the analysis. The numerical performance of the method is demonstrated through simulation experiments. Applying our proposed method to MIMIC data, we obtain several interesting findings related to the impact of different treatment strategies on the length of ICU stay and 12-hour SOFA sc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03756</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#36866;&#24212;&#24615;&#23454;&#39564;&#35774;&#35745;&#19982;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#26159;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification, BAI&#65289;&#38382;&#39064;&#26469;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32473;&#23450;&#22810;&#20010;&#27835;&#30103;&#33218;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#35266;&#23519;&#19968;&#20010;&#21051;&#30011;&#23454;&#39564;&#21333;&#20301;&#30340;&#19978;&#19979;&#25991;&#65288;&#21327;&#21464;&#37327;&#65289;&#65292;&#24182;&#23558;&#35813;&#21333;&#20301;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#27835;&#30103;&#33218;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#19968;&#20010;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#39044;&#35745;&#20135;&#29983;&#26368;&#39640;&#26399;&#26395;&#32467;&#26524;&#30340;&#27835;&#30103;&#33218;&#65288;&#26368;&#20339;&#27835;&#30103;&#33218;&#65289;&#12290;&#35813;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#65288;&#31574;&#30053;&#36951;&#25022;&#65289;&#26469;&#34913;&#37327;&#65292;&#35813;&#36951;&#25022;&#34920;&#31034;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#65292;&#26368;&#20339;&#27835;&#30103;&#33218;&#21644;&#25512;&#33616;&#27835;&#30103;&#33218;&#30340;&#26465;&#20214;&#26399;&#26395;&#32467;&#26524;&#20043;&#38388;&#30340;&#26368;&#22823;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#27493;&#39588;&#26159;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#19979;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36817;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#36824;&#26263;&#31034;&#30528;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#20123;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
&lt;/p&gt;</description></item><item><title>DiffEnc&#26159;&#19968;&#31181;&#20351;&#29992;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#25968;&#25454;&#21644;&#28145;&#24230;&#30456;&#20851;&#30340;&#22343;&#20540;&#20989;&#25968;&#21644;&#21487;&#35843;&#33410;&#30340;&#22122;&#22768;&#26041;&#24046;&#27604;&#29575;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19789</link><description>&lt;p&gt;
DiffEnc: &#20351;&#29992;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DiffEnc: Variational Diffusion with a Learned Encoder. (arXiv:2310.19789v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19789
&lt;/p&gt;
&lt;p&gt;
DiffEnc&#26159;&#19968;&#31181;&#20351;&#29992;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#25968;&#25454;&#21644;&#28145;&#24230;&#30456;&#20851;&#30340;&#22343;&#20540;&#20989;&#25968;&#21644;&#21487;&#35843;&#33410;&#30340;&#22122;&#22768;&#26041;&#24046;&#27604;&#29575;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#30475;&#20316;&#26159;&#20855;&#26377;&#20004;&#31181;&#25913;&#36827;&#30340;&#20998;&#23618;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#65306;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#21442;&#25968;&#20849;&#20139;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#22312;&#23618;&#27425;&#32467;&#26500;&#19978;&#29420;&#31435;&#35745;&#31639;&#25439;&#22833;&#12290;&#25105;&#20204;&#23545;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#20102;&#20004;&#20010;&#21464;&#21270;&#65292;&#20445;&#30041;&#20102;&#36825;&#20123;&#20248;&#21183;&#30340;&#21516;&#26102;&#22686;&#21152;&#20102;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#19982;&#25968;&#25454;&#21644;&#28145;&#24230;&#30456;&#20851;&#30340;&#22343;&#20540;&#20989;&#25968;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#20462;&#25913;&#21518;&#30340;&#25193;&#25955;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;DiffEnc&#22312;CIFAR-10&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35753;&#21453;&#21521;&#32534;&#30721;&#36807;&#31243;&#30340;&#22122;&#22768;&#26041;&#24046;&#19982;&#29983;&#25104;&#36807;&#31243;&#30340;&#27604;&#29575;&#25104;&#20026;&#19968;&#20010;&#33258;&#30001;&#30340;&#26435;&#37325;&#21442;&#25968;&#65292;&#32780;&#19981;&#26159;&#22266;&#23450;&#20026;1&#12290;&#36825;&#24102;&#26469;&#20102;&#29702;&#35770;&#19978;&#30340;&#27934;&#23519;&#21147;&#65306;&#23545;&#20110;&#26377;&#38480;&#28145;&#24230;&#23618;&#27425;&#65292;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#21487;&#20197;&#29992;&#20316;&#21152;&#26435;&#25193;&#25955;&#25439;&#22833;&#26041;&#27861;&#30340;&#30446;&#26631;&#65292;&#24182;&#29992;&#20110;&#19987;&#38376;&#20026;&#25512;&#29702;&#32780;&#20248;&#21270;&#22122;&#22768;&#35843;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models may be viewed as hierarchical variational autoencoders (VAEs) with two improvements: parameter sharing for the conditional distributions in the generative process and efficient computation of the loss as independent terms over the hierarchy. We consider two changes to the diffusion model that retain these advantages while adding flexibility to the model. Firstly, we introduce a data- and depth-dependent mean function in the diffusion process, which leads to a modified diffusion loss. Our proposed framework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly, we let the ratio of the noise variance of the reverse encoder process and the generative process be a free weight parameter rather than being fixed to 1. This leads to theoretical insights: For a finite depth hierarchy, the evidence lower bound (ELBO) can be used as an objective for a weighted diffusion loss approach and for optimizing the noise schedule specifically for inference. For the infinite
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06312</link><description>&lt;p&gt;
&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Discovering Mixtures of Structural Causal Models from Time Series Data. (arXiv:2310.06312v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06312
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#21457;&#29616;&#28151;&#21512;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37329;&#34701;&#12289;&#27668;&#20505;&#31185;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#29616;&#20195;&#25216;&#26415;&#21487;&#20197;&#22788;&#29702;&#21464;&#37327;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#21644;&#28789;&#27963;&#30340;&#22122;&#22768;&#20998;&#24067;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#31616;&#21270;&#20551;&#35774;&#65292;&#21363;&#25968;&#25454;&#26469;&#33258;&#30456;&#21516;&#30340;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25918;&#26494;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#20174;&#26469;&#28304;&#20110;&#19981;&#21516;&#22240;&#26524;&#27169;&#22411;&#28151;&#21512;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#21457;&#29616;&#12290;&#25105;&#20204;&#25512;&#26029;&#20102;&#28508;&#22312;&#30340;&#32467;&#26500;&#24615;&#22240;&#26524;&#27169;&#22411;&#65292;&#20197;&#21450;&#27599;&#20010;&#26679;&#26412;&#23646;&#20110;&#29305;&#23450;&#28151;&#21512;&#25104;&#20998;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#20010;&#31471;&#23545;&#31471;&#30340;&#35757;&#32451;&#36807;&#31243;&#65292;&#26368;&#22823;&#21270;&#20102;&#25968;&#25454;&#20284;&#28982;&#30340;&#35777;&#25454;&#19979;&#30028;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22240;&#26524;&#21457;&#29616;&#20219;&#21153;&#20013;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#22522;&#20934;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#24403;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#30340;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
In fields such as finance, climate science, and neuroscience, inferring causal relationships from time series data poses a formidable challenge. While contemporary techniques can handle nonlinear relationships between variables and flexible noise distributions, they rely on the simplifying assumption that data originates from the same underlying causal model. In this work, we relax this assumption and perform causal discovery from time series data originating from mixtures of different causal models. We infer both the underlying structural causal models and the posterior probability for each sample belonging to a specific mixture component. Our approach employs an end-to-end training process that maximizes an evidence-lower bound for data likelihood. Through extensive experimentation on both synthetic and real-world datasets, we demonstrate that our method surpasses state-of-the-art benchmarks in causal discovery tasks, particularly when the data emanates from diverse underlying causal
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38416;&#36848;&#20102;&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19979;&#30028;&#65292;&#37325;&#28857;&#26159;&#20223;&#23556;&#21464;&#25442;&#65292;&#24182;&#24212;&#29992;&#20110;&#27969;&#22411;&#23398;&#20064;&#21644;&#25163;&#20889;&#25968;&#25454;&#38598;&#27169;&#25311;&#12290;</title><link>http://arxiv.org/abs/2310.03945</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#30340;&#20223;&#23556;&#21464;&#25442;&#30340;Wasserstein&#36317;&#31163;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Wasserstein distances for affine transformations of random vectors. (arXiv:2310.03945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38416;&#36848;&#20102;&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19979;&#30028;&#65292;&#37325;&#28857;&#26159;&#20223;&#23556;&#21464;&#25442;&#65292;&#24182;&#24212;&#29992;&#20110;&#27969;&#22411;&#23398;&#20064;&#21644;&#25163;&#20889;&#25968;&#25454;&#38598;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#38416;&#36848;&#20102;&#20851;&#20110;&#22312;Wasserstein&#31354;&#38388;&#20013;&#29992;&#20110;&#25968;&#25454;&#27969;&#22411;&#23398;&#20064;&#30340;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#20108;&#27425;Wasserstein&#36317;&#31163;&#30340;&#19968;&#20123;&#24050;&#30693;&#19979;&#30028;&#65292;&#37325;&#28857;&#26159;&#20223;&#23556;&#21464;&#25442;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#35745;&#31639;&#21327;&#26041;&#24046;&#30697;&#38453;&#20043;&#38388;&#30340;Bures&#36317;&#31163;&#65292;&#32473;&#20986;&#20102;&#26059;&#36716;&#30340;&#38543;&#26426;&#21521;&#37327;&#22312;&#20855;&#26377;&#19981;&#30456;&#20851;&#20998;&#37327;&#30340;$\mathbb{R}^2$&#31354;&#38388;&#20013;&#30340;&#20855;&#20307;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#20223;&#23556;&#21464;&#25442;&#30340;&#32452;&#21512;&#30340;&#19978;&#30028;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#24212;&#29992;&#20110;&#21021;&#22987;&#25968;&#25454;&#27979;&#24230;&#30340;&#20016;&#23500;&#30340;&#24494;&#20998;&#21516;&#32986;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#30028;&#24212;&#29992;&#20110;&#21253;&#25324;&#22312;$\mathbb{R}^2$&#20013;&#30340;&#19968;&#32500;&#27969;&#22411;&#19978;&#30340;&#21508;&#31181;&#20998;&#24067;&#65292;&#24182;&#35828;&#26126;&#20102;&#36825;&#20123;&#30028;&#30340;&#36136;&#37327;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#27969;&#22411;&#23398;&#20064;&#26694;&#26550;&#20013;&#21487;&#20197;&#24212;&#29992;&#20110;&#27169;&#25311;&#25163;&#20889;&#25968;&#23383;&#25110;&#23383;&#27597;&#25968;&#25454;&#38598;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
We expound on some known lower bounds of the quadratic Wasserstein distance between random vectors in $\mathbb{R}^n$ with an emphasis on affine transformations that have been used in manifold learning of data in Wasserstein space. In particular, we give concrete lower bounds for rotated copies of random vectors in $\mathbb{R}^2$ with uncorrelated components by computing the Bures metric between the covariance matrices. We also derive upper bounds for compositions of affine maps which yield a fruitful variety of diffeomorphisms applied to an initial data measure. We apply these bounds to various distributions including those lying on a 1-dimensional manifold in $\mathbb{R}^2$ and illustrate the quality of the bounds. Finally, we give a framework for mimicking handwritten digit or alphabet datasets that can be applied in a manifold learning framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#25104;&#26412;&#20989;&#25968;&#26469;&#23547;&#25214;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03970</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;
&lt;/p&gt;
&lt;p&gt;
Optimal partitioning of directed acyclic graphs with dependent costs between clusters. (arXiv:2308.03970v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03970
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#20855;&#26377;&#20381;&#36182;&#25104;&#26412;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#36827;&#34892;&#26368;&#20248;&#20998;&#21306;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20248;&#21270;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#25104;&#26412;&#20989;&#25968;&#26469;&#23547;&#25214;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20013;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#32479;&#35745;&#25512;&#26029;&#22330;&#26223;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#32593;&#32476;&#12289;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#23558;&#22522;&#30784;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#21010;&#20998;&#25104;&#38598;&#32676;&#26469;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#26368;&#20248;&#21010;&#20998;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#35201;&#20248;&#21270;&#30340;&#25104;&#26412;&#21462;&#20915;&#20110;&#38598;&#32676;&#20869;&#30340;&#33410;&#28857;&#20197;&#21450;&#36890;&#36807;&#29238;&#33410;&#28857;&#21644;/&#25110;&#23376;&#33410;&#28857;&#36830;&#25509;&#30340;&#38598;&#32676;&#20043;&#38388;&#30340;&#26144;&#23556;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#20381;&#36182;&#38598;&#32676;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DCMAP&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#20855;&#26377;&#20381;&#36182;&#38598;&#32676;&#30340;&#26368;&#20248;&#38598;&#32676;&#26144;&#23556;&#12290;&#22312;&#22522;&#20110;DAG&#21644;&#38598;&#32676;&#26144;&#23556;&#30340;&#20219;&#24847;&#23450;&#20041;&#30340;&#27491;&#25104;&#26412;&#20989;&#25968;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;DCMAP&#25910;&#25947;&#20110;&#25214;&#21040;&#25152;&#26377;&#26368;&#20248;&#38598;&#32676;&#65292;&#24182;&#22312;&#36884;&#20013;&#36820;&#22238;&#25509;&#36817;&#26368;&#20248;&#35299;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#23545;&#20351;&#29992;&#35745;&#31639;&#25104;&#26412;&#20989;&#25968;&#30340;&#19968;&#20010;&#28023;&#33609;&#22797;&#26434;&#31995;&#32479;&#30340;DBN&#27169;&#22411;&#20855;&#26377;&#26102;&#38388;&#25928;&#29575;&#24615;&#12290;&#23545;&#20110;&#19968;&#20010;25&#20010;&#21644;50&#20010;&#33410;&#28857;&#30340;DBN&#65292;&#25628;&#32034;&#31354;&#38388;&#22823;&#23567;&#20998;&#21035;&#20026;$9.91\times 10^9$&#21644;$1.5$
&lt;/p&gt;
&lt;p&gt;
Many statistical inference contexts, including Bayesian Networks (BNs), Markov processes and Hidden Markov Models (HMMS) could be supported by partitioning (i.e.~mapping) the underlying Directed Acyclic Graph (DAG) into clusters. However, optimal partitioning is challenging, especially in statistical inference as the cost to be optimised is dependent on both nodes within a cluster, and the mapping of clusters connected via parent and/or child nodes, which we call dependent clusters. We propose a novel algorithm called DCMAP for optimal cluster mapping with dependent clusters. Given an arbitrarily defined, positive cost function based on the DAG and cluster mappings, we show that DCMAP converges to find all optimal clusters, and returns near-optimal solutions along the way. Empirically, we find that the algorithm is time-efficient for a DBN model of a seagrass complex system using a computation cost function. For a 25 and 50-node DBN, the search space size was $9.91\times 10^9$ and $1.5
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.12971</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#30340;&#39044;&#27979;&#65306;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Big Data - Supply Chain Management Framework for Forecasting: Data Preprocessing and Machine Learning Techniques. (arXiv:2307.12971v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22823;&#25968;&#25454;-&#20379;&#24212;&#38142;&#31649;&#29702;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#20379;&#24212;&#38142;&#39044;&#27979;&#65292;&#20248;&#21270;&#25805;&#20316;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#65292;&#24182;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#31995;&#32479;&#22320;&#35782;&#21035;&#21644;&#27604;&#36739;&#20998;&#26512;&#26368;&#20808;&#36827;&#30340;&#20379;&#24212;&#38142;&#39044;&#27979;&#31574;&#30053;&#21644;&#25216;&#26415;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#22823;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20110;&#20379;&#24212;&#38142;&#31649;&#29702;&#20013;&#65292;&#21253;&#25324;&#38382;&#39064;&#35782;&#21035;&#12289;&#25968;&#25454;&#26469;&#28304;&#12289;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12289;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;&#12289;&#36229;&#21442;&#25968;&#35843;&#20248;&#12289;&#24615;&#33021;&#35780;&#20272;&#21644;&#20248;&#21270;&#65292;&#20197;&#21450;&#39044;&#27979;&#23545;&#20154;&#21147;&#12289;&#24211;&#23384;&#21644;&#25972;&#20010;&#20379;&#24212;&#38142;&#30340;&#24433;&#21709;&#12290;&#39318;&#20808;&#35752;&#35770;&#20102;&#26681;&#25454;&#20379;&#24212;&#38142;&#31574;&#30053;&#25910;&#38598;&#25968;&#25454;&#30340;&#38656;&#27714;&#20197;&#21450;&#22914;&#20309;&#25910;&#38598;&#25968;&#25454;&#12290;&#25991;&#31456;&#35752;&#35770;&#20102;&#26681;&#25454;&#21608;&#26399;&#25110;&#20379;&#24212;&#38142;&#30446;&#26631;&#38656;&#35201;&#19981;&#21516;&#31867;&#22411;&#30340;&#39044;&#27979;&#12290;&#25512;&#33616;&#20351;&#29992;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#21644;&#35823;&#24046;&#27979;&#37327;&#31995;&#32479;&#26469;&#20248;&#21270;&#34920;&#29616;&#26368;&#20339;&#30340;&#27169;&#22411;&#12290;&#36824;&#35752;&#35770;&#20102;&#24187;&#24433;&#24211;&#23384;&#23545;&#39044;&#27979;&#30340;&#19981;&#21033;&#24433;&#21709;&#20197;&#21450;&#31649;&#29702;&#20915;&#31574;&#20381;&#36182;&#20379;&#24212;&#38142;&#32489;&#25928;&#25351;&#26631;&#26469;&#30830;&#23450;&#27169;&#22411;&#24615;&#33021;&#21442;&#25968;&#21644;&#25913;&#36827;&#36816;&#33829;&#31649;&#29702;&#12289;&#36879;&#26126;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article intends to systematically identify and comparatively analyze state-of-the-art supply chain (SC) forecasting strategies and technologies. A novel framework has been proposed incorporating Big Data Analytics in SC Management (problem identification, data sources, exploratory data analysis, machine-learning model training, hyperparameter tuning, performance evaluation, and optimization), forecasting effects on human-workforce, inventory, and overall SC. Initially, the need to collect data according to SC strategy and how to collect them has been discussed. The article discusses the need for different types of forecasting according to the period or SC objective. The SC KPIs and the error-measurement systems have been recommended to optimize the top-performing model. The adverse effects of phantom inventory on forecasting and the dependence of managerial decisions on the SC KPIs for determining model performance parameters and improving operations management, transparency, and 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#22312;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20256;&#32479;&#30340;&#38543;&#26426;&#20248;&#21270;&#29702;&#35770;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05251</link><description>&lt;p&gt;
&#29992;&#20110;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#30340;&#26368;&#23567;&#21270;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to minimize robust density power-based divergences for general parametric density models. (arXiv:2307.05251v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31283;&#20581;&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#22312;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#24212;&#29992;&#20256;&#32479;&#30340;&#38543;&#26426;&#20248;&#21270;&#29702;&#35770;&#26469;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#21151;&#29575;&#20998;&#27495;&#65288;DPD&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#31283;&#20581;&#22320;&#20272;&#35745;&#35266;&#27979;&#25968;&#25454;&#28508;&#22312;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#23427;&#21253;&#25324;&#19968;&#20010;&#35201;&#20272;&#35745;&#30340;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#30340;&#24130;&#30340;&#31215;&#20998;&#39033;&#12290;&#34429;&#28982;&#23545;&#20110;&#19968;&#20123;&#29305;&#23450;&#30340;&#23494;&#24230;&#65288;&#22914;&#27491;&#24577;&#23494;&#24230;&#21644;&#25351;&#25968;&#23494;&#24230;&#65289;&#21487;&#20197;&#24471;&#21040;&#31215;&#20998;&#39033;&#30340;&#26174;&#24335;&#24418;&#24335;&#65292;&#20294;DPD&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#20351;&#24471;&#20854;&#26080;&#27861;&#24212;&#29992;&#20110;&#26356;&#19968;&#33324;&#30340;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#65292;&#36825;&#24050;&#32463;&#36229;&#36807;&#20102;DPD&#25552;&#20986;&#30340;25&#24180;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#19968;&#33324;&#21442;&#25968;&#23494;&#24230;&#27169;&#22411;&#26368;&#23567;&#21270;DPD&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#21442;&#32771;&#38543;&#26426;&#20248;&#21270;&#30340;&#20256;&#32479;&#29702;&#35770;&#35828;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#26410;&#24402;&#19968;&#21270;&#27169;&#22411;&#26469;&#26368;&#23567;&#21270;&#21478;&#19968;&#20010;&#22522;&#20110;&#23494;&#24230;&#21151;&#29575;&#30340;&#947;-&#31163;&#24046;[Kanamori&#21644;Fujisawa&#65288;2015&#65289;&#65292;Biometrika]&#12290;
&lt;/p&gt;
&lt;p&gt;
Density power divergence (DPD) [Basu et al. (1998), Biometrika], designed to estimate the underlying distribution of the observations robustly, comprises an integral term of the power of the parametric density models to be estimated. While the explicit form of the integral term can be obtained for some specific densities (such as normal density and exponential density), its computational intractability has prohibited the application of DPD-based estimation to more general parametric densities, over a quarter of a century since the proposal of DPD. This study proposes a stochastic optimization approach to minimize DPD for general parametric density models and explains its adequacy by referring to conventional theories on stochastic optimization. The proposed approach also can be applied to the minimization of another density power-based $\gamma$-divergence with the aid of unnormalized models [Kanamori and Fujisawa (2015), Biometrika].
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#30340;&#21442;&#25968;&#20272;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2307.04191</link><description>&lt;p&gt;
&#20851;&#20110;&#36923;&#36753;&#22238;&#24402;&#20013;&#21442;&#25968;&#20272;&#35745;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the sample complexity of estimation in logistic regression. (arXiv:2307.04191v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#30340;&#21442;&#25968;&#20272;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#26159;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#26368;&#24120;&#35265;&#30340;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#65292;&#20197;$\ell_2$&#35823;&#24046;&#20026;&#38480;&#65292;&#20272;&#35745;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#21442;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32771;&#34385;&#20102;&#32500;&#24230;&#21644;&#36870;&#28201;&#24230;&#30340;&#24433;&#21709;&#12290;&#36870;&#28201;&#24230;&#25511;&#21046;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#20449;&#22122;&#27604;&#12290;&#34429;&#28982;&#36923;&#36753;&#22238;&#24402;&#30340;&#24191;&#20041;&#30028;&#38480;&#21644;&#28176;&#36817;&#24615;&#33021;&#24050;&#32463;&#26377;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#20851;&#20110;&#21442;&#25968;&#20272;&#35745;&#30340;&#38750;&#28176;&#36817;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#20043;&#21069;&#30340;&#20998;&#26512;&#20013;&#27809;&#26377;&#35752;&#35770;&#20854;&#19982;&#35823;&#24046;&#21644;&#36870;&#28201;&#24230;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#20855;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65288;&#25110;&#20020;&#30028;&#28857;&#65289;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
The logistic regression model is one of the most popular data generation model in noisy binary classification problems. In this work, we study the sample complexity of estimating the parameters of the logistic regression model up to a given $\ell_2$ error, in terms of the dimension and the inverse temperature, with standard normal covariates. The inverse temperature controls the signal-to-noise ratio of the data generation process. While both generalization bounds and asymptotic performance of the maximum-likelihood estimator for logistic regression are well-studied, the non-asymptotic sample complexity that shows the dependence on error and the inverse temperature for parameter estimation is absent from previous analyses. We show that the sample complexity curve has two change-points (or critical points) in terms of the inverse temperature, clearly separating the low, moderate, and high temperature regimes.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#22312;&#21327;&#20316;&#31185;&#23398;&#20013;&#20351;&#29992;&#28608;&#21169;&#29702;&#35770;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#30740;&#31350;&#32773;&#21644;&#20915;&#31574;&#32773;&#30340;&#19981;&#21516;&#28608;&#21169;&#26426;&#21046;&#65292;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#25112;&#30053;&#34892;&#20026;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2307.03748</link><description>&lt;p&gt;
&#28608;&#21169;&#29702;&#35770;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#22312;&#21327;&#20316;&#31185;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Incentive-Theoretic Bayesian Inference for Collaborative Science. (arXiv:2307.03748v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03748
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#22312;&#21327;&#20316;&#31185;&#23398;&#20013;&#20351;&#29992;&#28608;&#21169;&#29702;&#35770;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#30740;&#31350;&#32773;&#21644;&#20915;&#31574;&#32773;&#30340;&#19981;&#21516;&#28608;&#21169;&#26426;&#21046;&#65292;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#25112;&#30053;&#34892;&#20026;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20195;&#31185;&#23398;&#30740;&#31350;&#26159;&#19968;&#39033;&#20998;&#24067;&#24335;&#30340;&#12289;&#21327;&#20316;&#30340;&#24037;&#20316;&#65292;&#30001;&#30740;&#31350;&#22242;&#38431;&#12289;&#30417;&#31649;&#26426;&#26500;&#12289;&#36164;&#21161;&#26426;&#26500;&#12289;&#21830;&#19994;&#21512;&#20316;&#20249;&#20276;&#21644;&#31185;&#23398;&#26426;&#26500;&#32452;&#25104;&#65292;&#24444;&#27492;&#20114;&#21160;&#24182;&#38754;&#23545;&#19981;&#21516;&#30340;&#28608;&#21169;&#12290;&#20026;&#20102;&#20445;&#25345;&#31185;&#23398;&#20005;&#35880;&#24615;&#65292;&#32479;&#35745;&#26041;&#27861;&#24212;&#35813;&#35748;&#35782;&#21040;&#36825;&#31181;&#24773;&#20917;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20551;&#35774;&#26816;&#39564;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#26377;&#19968;&#20010;&#20195;&#29702;&#20154;&#65288;&#20363;&#22914;&#30740;&#31350;&#20154;&#21592;&#25110;&#21046;&#33647;&#20844;&#21496;&#65289;&#23545;&#26410;&#30693;&#21442;&#25968;&#25317;&#26377;&#31169;&#20154;&#20808;&#39564;&#30693;&#35782;&#65292;&#36824;&#26377;&#19968;&#20010;&#22996;&#25176;&#20154;&#65288;&#22914;&#25919;&#31574;&#21046;&#23450;&#32773;&#25110;&#30417;&#31649;&#26426;&#26500;&#65289;&#24076;&#26395;&#26681;&#25454;&#21442;&#25968;&#20540;&#20570;&#20986;&#20915;&#31574;&#12290;&#20195;&#29702;&#20154;&#26681;&#25454;&#20182;&#20204;&#30340;&#31169;&#20154;&#20808;&#39564;&#36873;&#25321;&#26159;&#21542;&#36827;&#34892;&#32479;&#35745;&#35797;&#39564;&#65292;&#28982;&#21518;&#35797;&#39564;&#30340;&#32467;&#26524;&#30001;&#22996;&#25176;&#20154;&#29992;&#26469;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22996;&#25176;&#20154;&#22914;&#20309;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#65292;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#25112;&#30053;&#34892;&#20026;&#25152;&#36879;&#38706;&#30340;&#20449;&#24687;&#65292;&#20063;&#23601;&#26159;&#20182;&#20204;&#36873;&#25321;&#26159;&#21542;&#36827;&#34892;&#35797;&#39564;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#35745;&#31639;p&#20540;&#65292;&#20174;&#32780;&#32508;&#21512;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#34892;&#20026;&#21644;&#35797;&#39564;&#30340;&#32467;&#26524;&#36827;&#34892;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contemporary scientific research is a distributed, collaborative endeavor, carried out by teams of researchers, regulatory institutions, funding agencies, commercial partners, and scientific bodies, all interacting with each other and facing different incentives. To maintain scientific rigor, statistical methods should acknowledge this state of affairs. To this end, we study hypothesis testing when there is an agent (e.g., a researcher or a pharmaceutical company) with a private prior about an unknown parameter and a principal (e.g., a policymaker or regulator) who wishes to make decisions based on the parameter value. The agent chooses whether to run a statistical trial based on their private prior and then the result of the trial is used by the principal to reach a decision. We show how the principal can conduct statistical inference that leverages the information that is revealed by an agent's strategic behavior -- their choice to run a trial or not. In particular, we show how the p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#30340;&#28789;&#27963;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#35299;&#20915;&#22312;&#30495;&#23454;&#19990;&#30028;&#35774;&#32622;&#20013;&#25968;&#25454;&#20849;&#20139;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#33258;&#36866;&#24212;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#21644;&#31995;&#32479;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02388</link><description>&lt;p&gt;
&#20351;&#29992;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning with Summary Statistics. (arXiv:2307.02388v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02388
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#30340;&#28789;&#27963;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#35299;&#20915;&#22312;&#30495;&#23454;&#19990;&#30028;&#35774;&#32622;&#20013;&#25968;&#25454;&#20849;&#20139;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#33258;&#36866;&#24212;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#21644;&#31995;&#32479;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#21487;&#20197;&#25972;&#21512;&#26469;&#33258;&#22810;&#20010;&#26469;&#28304;&#30340;&#25968;&#25454;&#65292;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#25552;&#39640;&#25972;&#20307;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#35774;&#32622;&#20013;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#24212;&#29992;&#21463;&#21040;&#25968;&#25454;&#20849;&#20139;&#38480;&#21046;&#30340;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#22312;&#21307;&#30103;&#39046;&#22495;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#26469;&#33258;&#21508;&#31181;&#26469;&#28304;&#30340;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#65292;&#22522;&#20110;Lepski&#26041;&#27861;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#22312;&#20165;&#26377;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#26102;&#20801;&#35768;&#25968;&#25454;&#39537;&#21160;&#30340;&#35843;&#21442;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#38750;&#28176;&#36817;&#20998;&#26512;&#25551;&#36848;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#37325;&#21472;&#24230;&#30340;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#21644;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#36328;&#20998;&#26512;&#32437;&#21521;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#35757;&#32451;&#30456;&#20851;&#27169;&#22411;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning has emerged as a powerful machine learning paradigm for integrating data from multiple sources, leveraging similarities between tasks to improve overall model performance. However, the application of multi-task learning to real-world settings is hindered by data-sharing constraints, especially in healthcare settings. To address this challenge, we propose a flexible multi-task learning framework utilizing summary statistics from various sources. Additionally, we present an adaptive parameter selection approach based on a variant of Lepski's method, allowing for data-driven tuning parameter selection when only summary statistics are available. Our systematic non-asymptotic analysis characterizes the performance of the proposed methods under various regimes of the sample complexity and overlap. We demonstrate our theoretical findings and the performance of the method through extensive simulations. This work offers a more flexible tool for training related models across
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;&#12290;&#35813;&#24230;&#37327;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#36719;&#39044;&#27979;&#30340;&#20998;&#24067;&#27169;&#24335;&#65292;&#35782;&#21035;&#20986;&#34987;&#35823;&#20998;&#31867;&#30340;&#26679;&#26412;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#22810;&#20010;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#25913;&#36827;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35823;&#20998;&#31867;&#26816;&#27979;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.01710</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#27979;&#24230;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
A Data-Driven Measure of Relative Uncertainty for Misclassification Detection. (arXiv:2306.01710v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;&#12290;&#35813;&#24230;&#37327;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#36719;&#39044;&#27979;&#30340;&#20998;&#24067;&#27169;&#24335;&#65292;&#35782;&#21035;&#20986;&#34987;&#35823;&#20998;&#31867;&#30340;&#26679;&#26412;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#22810;&#20010;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#25913;&#36827;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35823;&#20998;&#31867;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35823;&#20998;&#31867;&#26816;&#27979;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#23427;&#21487;&#20197;&#35782;&#21035;&#27169;&#22411;&#39044;&#27979;&#19981;&#21487;&#38752;&#30340;&#23454;&#20363;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#19981;&#30830;&#23450;&#24615;&#27979;&#24230;&#22914;&#39321;&#20892;&#29109;&#24182;&#19981;&#33021;&#25552;&#20379;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#24335;&#26469;&#25512;&#26029;&#27169;&#22411;&#39044;&#27979;&#30340;&#23454;&#38469;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25968;&#25454;&#39537;&#21160;&#30456;&#23545;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#29992;&#20110;&#35823;&#20998;&#31867;&#26816;&#27979;&#12290;&#36890;&#36807;&#23398;&#20064;&#36719;&#39044;&#27979;&#30340;&#20998;&#24067;&#27169;&#24335;&#65292;&#25105;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#21487;&#20197;&#22522;&#20110;&#39044;&#27979;&#30340;&#31867;&#27010;&#29575;&#26631;&#35782;&#34987;&#35823;&#20998;&#31867;&#30340;&#26679;&#26412;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#26681;&#25454;&#25152;&#25552;&#20986;&#30340;&#24230;&#37327;&#65292;&#19982;&#35823;&#20998;&#31867;&#23454;&#20363;&#23545;&#24212;&#30340;&#36719;&#39044;&#27979;&#21487;&#33021;&#20855;&#26377;&#24456;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21363;&#20351;&#23427;&#20204;&#30340;&#39321;&#20892;&#29109;&#21487;&#33021;&#24456;&#20302;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22810;&#20010;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#23454;&#35777;&#25913;&#36827;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#35823;&#20998;&#31867;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Misclassification detection is an important problem in machine learning, as it allows for the identification of instances where the model's predictions are unreliable. However, conventional uncertainty measures such as Shannon entropy do not provide an effective way to infer the real uncertainty associated with the model's predictions. In this paper, we introduce a novel data-driven measure of relative uncertainty to an observer for misclassification detection. By learning patterns in the distribution of soft-predictions, our uncertainty measure can identify misclassified samples based on the predicted class probabilities. Interestingly, according to the proposed measure, soft-predictions that correspond to misclassified instances can carry a large amount of uncertainty, even though they may have low Shannon entropy. We demonstrate empirical improvements over multiple image classification tasks, outperforming state-of-the-art misclassification detection methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#22312;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#35777;&#26126;&#20102;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.19510</link><description>&lt;p&gt;
&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#20855;&#26377;&#26377;&#21033;&#30340;&#25439;&#22833;&#26223;&#35266;
&lt;/p&gt;
&lt;p&gt;
Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape. (arXiv:2305.19510v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#22312;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#35777;&#26126;&#20102;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#65292;&#20108;&#23618;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#20351;&#29992;&#20102;&#21442;&#25968;&#26144;&#23556;&#30340;Jacobian&#30697;&#38453;&#30340;&#31209;&#26469;&#20272;&#35745;&#23616;&#37096;&#21644;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#30340;&#32500;&#24230;&#12290;&#20351;&#29992;&#38543;&#26426;&#20108;&#36827;&#21046;&#30697;&#38453;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#30340;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#29616;&#22823;&#22810;&#25968;&#21306;&#22495;&#20855;&#26377;&#23436;&#25972;&#30340;&#31209;&#25110;&#32570;&#20047;&#31209;&#65292;&#20197;&#23454;&#39564;&#30340;&#26041;&#24335;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#36825;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the loss landscape of two-layer mildly overparameterized ReLU neural networks on a generic finite input dataset for the squared error loss. Our approach involves bounding the dimension of the sets of local and global minima using the rank of the Jacobian of the parameterization map. Using results on random binary matrices, we show most activation patterns correspond to parameter regions with no bad differentiable local minima. Furthermore, for one-dimensional input data, we show most activation regions realizable by the network contain a high dimensional set of global minima and no bad local minima. We experimentally confirm these results by finding a phase transition from most regions having full rank to many regions having deficient rank depending on the amount of overparameterization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#27010;&#29575;&#22320;&#20174;&#38750;&#20856;&#22411;&#38543;&#26426;&#21021;&#22987;&#21270;&#36798;&#21040;&#19968;&#20010;$\epsilon$-&#26368;&#20248;&#30697;&#38453;&#20998;&#35299;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#21021;&#22987;&#21270;&#19981;&#20165;&#22312;&#29702;&#35770;&#19978;&#26377;&#30410;&#65292;&#32780;&#19988;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.06927</link><description>&lt;p&gt;
&#30697;&#38453;&#20998;&#35299;&#20013;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence of Alternating Gradient Descent for Matrix Factorization. (arXiv:2305.06927v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#27010;&#29575;&#22320;&#20174;&#38750;&#20856;&#22411;&#38543;&#26426;&#21021;&#22987;&#21270;&#36798;&#21040;&#19968;&#20010;$\epsilon$-&#26368;&#20248;&#30697;&#38453;&#20998;&#35299;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#21021;&#22987;&#21270;&#19981;&#20165;&#22312;&#29702;&#35770;&#19978;&#26377;&#30410;&#65292;&#32780;&#19988;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#24212;&#29992;&#20110;&#19981;&#23545;&#31216;&#30697;&#38453;&#20998;&#35299;&#30446;&#26631;&#30340;&#20855;&#26377;&#22266;&#23450;&#27493;&#38271;$\eta&gt;0$&#30340;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#65288;AGD&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#23545;&#20110;&#31209;&#20026;$r$&#30340;&#30697;&#38453;$\mathbf {A}\in \mathbb {R} ^ {m \times n}$&#65292;$T=\left(\left(\frac{\sigma_1(\mathbf{A})}{\sigma_r(\mathbf{A})}\right)^2\log(1/\epsilon)\right)$&#27425;&#20132;&#26367;&#26799;&#24230;&#19979;&#38477;&#21363;&#21487;&#20174;&#38750;&#20856;&#22411;&#38543;&#26426;&#21021;&#22987;&#21270;&#39640;&#27010;&#29575;&#22320;&#36798;&#21040;$\epsilon$-&#26368;&#20248;&#20998;&#35299;$\|\mathbf {A}\mathbf {X}_T^{\vphantom{\intercal}}\mathbf {Y}_T^{\intercal}\|_{\rm F}^2\le\epsilon\|\mathbf {A}\|_{\rm F}^2$&#12290;&#20998;&#35299;&#20013;&#22240;&#23376;&#30340;&#31209;&#20026;$d&gt;r$&#65292;&#22240;&#27492;$\mathbf{X}_T\in\mathbb{R}^{m \times d}$&#19988;$\mathbf{Y}_T\in\mathbb{R}^{n \times d}$&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#21021;&#22987;&#21270;&#19981;&#20165;&#22312;&#29702;&#35770;&#19978;&#26377;&#30410;&#65292;&#32780;&#19988;&#22312;&#23454;&#36341;&#20013;&#26174;&#33879;&#25552;&#39640;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65306;&#19968;&#33268;&#30340;PL&#19981;&#31561;&#24335;&#21644;&#19968;&#33268;&#30340;Lipschitz&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider alternating gradient descent (AGD) with fixed step size $\eta &gt; 0$, applied to the asymmetric matrix factorization objective. We show that, for a rank-$r$ matrix $\mathbf{A} \in \mathbb{R}^{m \times n}$, $T = \left( \left(\frac{\sigma_1(\mathbf{A})}{\sigma_r(\mathbf{A})}\right)^2 \log(1/\epsilon)\right)$ iterations of alternating gradient descent suffice to reach an $\epsilon$-optimal factorization $\| \mathbf{A} \mathbf{X}_T^{\vphantom{\intercal}} \mathbf{Y}_T^{\intercal} \|_{\rm F}^2 \leq \epsilon \| \mathbf{A} \|_{\rm F}^2$ with high probability starting from an atypical random initialization. The factors have rank $d&gt;r$ so that $\mathbf{X}_T\in\mathbb{R}^{m \times d}$ and $\mathbf{Y}_T \in\mathbb{R}^{n \times d}$. Experiments suggest that our proposed initialization is not merely of theoretical benefit, but rather significantly improves convergence of gradient descent in practice. Our proof is conceptually simple: a uniform PL-inequality and uniform Lipschitz smoothne
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#23450;&#38181;&#20013;&#30340;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#30340;&#21487;&#25193;&#23637;&#20960;&#20309;&#26694;&#26550;&#65292;&#21033;&#29992;&#26497;&#24191;&#20041;&#29305;&#24449;&#20540;&#26377;&#25928;&#22320;&#20998;&#26512;&#21644;&#22788;&#29702;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#25968;&#25454;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#27492;&#20960;&#20309;&#26041;&#27861;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#22411; SPD &#30697;&#38453;&#36845;&#20195;&#24179;&#22343;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07347</link><description>&lt;p&gt;
&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#26497;&#20540;&#29305;&#24449;&#20540;&#24046;&#20998;&#20960;&#20309;
&lt;/p&gt;
&lt;p&gt;
Differential geometry with extreme eigenvalues in the positive semidefinite cone. (arXiv:2304.07347v1 [math.DG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21322;&#23450;&#38181;&#20013;&#30340;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#30340;&#21487;&#25193;&#23637;&#20960;&#20309;&#26694;&#26550;&#65292;&#21033;&#29992;&#26497;&#24191;&#20041;&#29305;&#24449;&#20540;&#26377;&#25928;&#22320;&#20998;&#26512;&#21644;&#22788;&#29702;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#25968;&#25454;&#12290;&#21516;&#26102;&#65292;&#22522;&#20110;&#27492;&#20960;&#20309;&#26041;&#27861;&#65292;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#22411; SPD &#30697;&#38453;&#36845;&#20195;&#24179;&#22343;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#20854;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#27491;&#23450;&#30697;&#38453; (SPD) &#25968;&#25454;&#30340;&#24494;&#20998;&#20960;&#20309;&#26041;&#27861;&#24050;&#34987;&#25104;&#21151;&#24212;&#29992;&#20110;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#21307;&#23398;&#25104;&#20687;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#20960;&#20309;&#33539;&#24335;&#30340;&#35889;&#35745;&#31639;&#25104;&#26412;&#39640;&#26114;&#65292;&#38590;&#20197;&#22312;&#39640;&#32500;&#24230;&#21644;&#22823;&#35268;&#27169;&#25968;&#25454;&#19979;&#23454;&#29616;&#12290;&#26412;&#25991;&#22522;&#20110;&#21322;&#23450;&#38181;&#30340;&#24076;&#23572;&#20271;&#29305;&#21644;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#25552;&#20986;&#20102;&#35745;&#31639;&#26497;&#24191;&#20041;&#29305;&#24449;&#20540;&#30340;&#21487;&#25193;&#23637;&#20960;&#20309;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#22522;&#20110;&#27748;&#26222;&#26862;&#20960;&#20309;&#23398;&#30340;&#27979;&#22320;&#31354;&#38388;&#32467;&#26500;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26500;&#30340;&#22810;&#20010;&#23646;&#24615;&#12290;&#27492;&#22806;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#22522;&#20110;&#35813;&#20960;&#20309;&#26041;&#27861;&#30340;&#26032;&#22411; SPD &#30697;&#38453;&#36845;&#20195;&#24179;&#22343;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#26377;&#38480;&#20010; SPD &#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#20854;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential geometric approaches to the analysis and processing of data in the form of symmetric positive definite (SPD) matrices have had notable successful applications to numerous fields including computer vision, medical imaging, and machine learning. The dominant geometric paradigm for such applications has consisted of a few Riemannian geometries associated with spectral computations that are costly at high scale and in high dimensions. We present a route to a scalable geometric framework for the analysis and processing of SPD-valued data based on the efficient computation of extreme generalized eigenvalues through the Hilbert and Thompson geometries of the semidefinite cone. We explore a particular geodesic space structure based on Thompson geometry in detail and establish several properties associated with this structure. Furthermore, we define a novel iterative mean of SPD matrices based on this geometry and prove its existence and uniqueness for a given finite collection of 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;Bradley-Terry-Luce&#21644;Plackett-Luce&#27169;&#22411;&#19979;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#25552;&#20379;&#20102;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#22312;&#35777;&#26126;&#20102;&#30495;&#23454;MLE&#21644;&#20197;&#25104;&#23545;&#27604;&#36739;&#24418;&#24335;&#26367;&#20195;&#30340;&#22791;&#36873;MLE&#37117;&#21487;&#20197;&#22312;PL&#27169;&#22411;&#19979;&#25910;&#25947;&#30340;&#21516;&#26102;&#65292;&#20063;&#34920;&#26126;&#20102;&#30495;&#23454;MLE&#30340;&#39640;&#25928;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;RLHF&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;IRL&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11270</link><description>&lt;p&gt;
&#20351;&#29992;&#26469;&#33258;&#25104;&#23545;&#25110;$K$&#20803;&#27604;&#36739;&#30340;&#20154;&#31867;&#21453;&#39304;&#30340;&#35268;&#33539;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons. (arXiv:2301.11270v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11270
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;Bradley-Terry-Luce&#21644;Plackett-Luce&#27169;&#22411;&#19979;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#25552;&#20379;&#20102;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#22312;&#35777;&#26126;&#20102;&#30495;&#23454;MLE&#21644;&#20197;&#25104;&#23545;&#27604;&#36739;&#24418;&#24335;&#26367;&#20195;&#30340;&#22791;&#36873;MLE&#37117;&#21487;&#20197;&#22312;PL&#27169;&#22411;&#19979;&#25910;&#25947;&#30340;&#21516;&#26102;&#65292;&#20063;&#34920;&#26126;&#20102;&#30495;&#23454;MLE&#30340;&#39640;&#25928;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;RLHF&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;IRL&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#30495;&#23454;&#22870;&#21169;&#20989;&#25968;&#20026;&#32447;&#24615;&#20989;&#25968;&#26102;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#22312;Bradley-Terry-Luce&#65288;BTL&#65289;&#27169;&#22411;&#21644;Plackett-Luce&#65288;PL&#65289;&#27169;&#22411;&#19979;&#22343;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#22522;&#20110;&#23398;&#24471;&#30340;&#22870;&#21169;&#27169;&#22411;&#35757;&#32451;&#31574;&#30053;&#26102;&#65292;MLE&#20250;&#22833;&#36133;&#65292;&#32780;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#25552;&#20379;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;PL&#27169;&#22411;&#19979;&#65292;&#30495;&#23454;MLE&#21644;&#23558;$k$&#20803;&#27604;&#36739;&#25286;&#20998;&#20026;&#25104;&#23545;&#27604;&#36739;&#30340;&#22791;&#36873;MLE&#37117;&#25910;&#25947;&#12290;&#32780;&#30495;&#23454;MLE&#26159;&#28176;&#36817;&#26356;&#20026;&#39640;&#25928;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#39564;&#35777;&#20102;&#29616;&#26377;RLHF&#31639;&#27861;&#65288;&#22914;InstructGPT&#65289;&#30340;&#23454;&#39564;&#25104;&#21151;&#65292;&#24182;&#20026;&#31639;&#27861;&#35774;&#35745;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;&#26368;&#22823;&#29109;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;(IRL)&#38382;&#39064;&#65292;&#24182;&#20026;&#20854;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound fo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2209.10053</link><description>&lt;p&gt;
&#32463;&#39564;&#36807;&#31243;&#30340;&#23454;&#20363;&#30456;&#20851;&#30340;&#19968;&#33268;&#23614;&#37096;&#30028;
&lt;/p&gt;
&lt;p&gt;
Instance-dependent uniform tail bounds for empirical processes. (arXiv:2209.10053v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10053
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#31867;&#20026;&#25351;&#26631;&#65292;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;&#36890;&#36807;&#23558;&#26631;&#20934;&#36890;&#29992;&#38142;&#25509;&#35770;&#35777;&#24341;&#20837;&#19968;&#20010;&#26368;&#21021;&#30340;&#8220;&#27844;&#27668;&#8221;&#27493;&#39588;&#26469;&#24314;&#31435;&#23614;&#37096;&#30028;&#12290;&#29983;&#25104;&#30340;&#23614;&#37096;&#30028;&#26377;&#19968;&#20010;&#20027;&#35201;&#30340;&#22797;&#26434;&#24230;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#19968;&#20010;&#20851;&#20110;&#27844;&#27668;&#20989;&#25968;&#31867;&#30340; Talagrand $\gamma$ &#20989;&#25968;&#30340;&#21464;&#20307;&#65292;&#20197;&#21450;&#19968;&#20010;&#23454;&#20363;&#30456;&#20851;&#30340;&#20559;&#24046;&#39033;&#65292;&#36890;&#36807;&#19968;&#20010;&#36866;&#24403;&#32553;&#25918;&#30340;&#36866;&#24403;&#33539;&#25968;&#30340;&#29256;&#26412;&#26469;&#34913;&#37327;&#12290;&#36825;&#20123;&#39033;&#37117;&#20351;&#29992;&#22522;&#20110;&#30456;&#20851;&#30340;&#27597;&#20989;&#25968;&#30340;&#26576;&#20123;&#31995;&#25968;&#26469;&#34920;&#36798;&#12290;&#24403;&#20989;&#25968;&#31867;&#22312;&#32473;&#23450;&#30340;&#65288;&#25351;&#25968;&#22411;&#65289;Orlicz&#31354;&#38388;&#20013;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26356;&#26126;&#30830;&#30340;&#36817;&#20284;&#20540;&#26469;&#25551;&#36848;&#25152;&#25552;&#21040;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We formulate a uniform tail bound for empirical processes indexed by a class of functions, in terms of the individual deviations of the functions rather than the worst-case deviation in the considered class. The tail bound is established by introducing an initial "deflation" step to the standard generic chaining argument. The resulting tail bound has a main complexity component, a variant of Talagrand's $\gamma$ functional for the deflated function class, as well as an instance-dependent deviation term, measured by an appropriately scaled version of a suitable norm. Both of these terms are expressed using certain coefficients formulated based on the relevant cumulant generating functions. We also provide more explicit approximations for the mentioned coefficients, when the function class lies in a given (exponential type) Orlicz space.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2102.10019</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#30340;&#19981;&#24179;&#31561;&#24433;&#21709;&#65306;&#24179;&#26435;&#34892;&#21160;&#19982;&#24179;&#26435;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
The Disparate Impact of Uncertainty: Affirmative Action vs. Affirmative Information. (arXiv:2102.10019v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.10019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#23545;&#19981;&#21516;&#20154;&#32676;&#30340;&#24433;&#21709;&#26159;&#19981;&#24179;&#31561;&#30340;&#65292;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#65292;&#36825;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proves that uncertainty has a disparate impact on different demographic groups, with varying types of errors. The proposed strategy, called Affirmative Information, can eliminate this disparity and broaden access to opportunity, serving as an alternative to Affirmative Action.
&lt;/p&gt;
&lt;p&gt;
&#20687;&#36151;&#27454;&#25209;&#20934;&#12289;&#21307;&#30103;&#24178;&#39044;&#21644;&#22823;&#23398;&#24405;&#21462;&#36825;&#26679;&#30340;&#20851;&#38190;&#20915;&#31574;&#26159;&#22312;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#39044;&#27979;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#30830;&#23450;&#24615;&#20855;&#26377;&#19981;&#24179;&#31561;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#23427;&#20250;&#22312;&#25152;&#26377;&#20154;&#21475;&#32676;&#20307;&#20013;&#20135;&#29983;&#35823;&#24046;&#65292;&#20294;&#35823;&#24046;&#30340;&#31867;&#22411;&#20250;&#26377;&#31995;&#32479;&#24615;&#30340;&#21464;&#21270;&#65306;&#24179;&#22343;&#32467;&#26524;&#36739;&#39640;&#30340;&#32676;&#20307;&#36890;&#24120;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38451;&#24615;&#29575;&#65292;&#32780;&#24179;&#22343;&#32467;&#26524;&#36739;&#20302;&#30340;&#32676;&#20307;&#21017;&#34987;&#20998;&#37197;&#26356;&#39640;&#30340;&#20551;&#38452;&#24615;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#39069;&#22806;&#30340;&#25968;&#25454;&#33719;&#21462;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#24046;&#24322;&#24182;&#25193;&#22823;&#26426;&#20250;&#30340;&#33719;&#21462;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#24179;&#26435;&#20449;&#24687;&#30340;&#31574;&#30053;&#21487;&#20197;&#20316;&#20026;&#24179;&#26435;&#34892;&#21160;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Critical decisions like loan approvals, medical interventions, and college admissions are guided by predictions made in the presence of uncertainty. In this paper, we prove that uncertainty has a disparate impact. While it imparts errors across all demographic groups, the types of errors vary systematically: Groups with higher average outcomes are typically assigned higher false positive rates, while those with lower average outcomes are assigned higher false negative rates. We show that additional data acquisition can eliminate the disparity and broaden access to opportunity. The strategy, which we call Affirmative Information, could stand as an alternative to Affirmative Action.
&lt;/p&gt;</description></item></channel></rss>