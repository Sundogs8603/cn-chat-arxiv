<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19653</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#30340;&#26080;&#38480;&#25968;&#25454;&#35745;&#21010;&#21319;&#32423;VAE&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models. (arXiv:2310.19653v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19653
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#34920;&#31034;&#23398;&#20064;&#27169;&#22411;&#65292;&#20294;&#20854;&#32534;&#30721;&#22120;&#23481;&#26131;&#36807;&#25311;&#21512;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;&#19981;&#26159;&#30495;&#23454;&#65288;&#36830;&#32493;&#65289;&#25968;&#25454;&#20998;&#24067;$p_{\mathrm{data}}(\mathbf{x})$&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#22266;&#23450;&#32534;&#30721;&#22120;&#36991;&#20813;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#34920;&#31034;&#19981;&#22826;&#21487;&#35299;&#37322;&#65292;&#20294;&#31616;&#21270;&#20102;&#35757;&#32451;&#65292;&#21487;&#20197;&#31934;&#30830;&#21644;&#36830;&#32493;&#22320;&#36924;&#36817;$p_{\mathrm{data}}(\mathbf{x})$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#35757;&#32451;&#65292;&#21487;&#20197;&#26377;&#25928;&#20943;&#36731;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#36825;&#20123;&#32467;&#26524;&#26377;&#20123;&#20986;&#20154;&#24847;&#26009;&#65292;&#22240;&#20026;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20351;&#29992;&#21478;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#65292;&#29983;&#25104;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#35757;&#32451;&#30340;VAE&#30340;&#27867;&#21270;&#24615;&#33021;&#12289;&#20998;&#25674;&#24046;&#36317;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are popular models for representation learning but their encoders are susceptible to overfitting (Cremer et al., 2018) because they are trained on a finite training set instead of the true (continuous) data distribution $p_{\mathrm{data}}(\mathbf{x})$. Diffusion models, on the other hand, avoid this issue by keeping the encoder fixed. This makes their representations less interpretable, but it simplifies training, enabling accurate and continuous approximations of $p_{\mathrm{data}}(\mathbf{x})$. In this paper, we show that overfitting encoders in VAEs can be effectively mitigated by training on samples from a pre-trained diffusion model. These results are somewhat unexpected as recent findings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in generative performance when models are trained on data generated by another generative model. We analyze generalization performance, amortization gap, and robustness of VAEs trained with our pro
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#21327;&#21464;&#37327;&#35843;&#25972;&#21644;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#21033;&#29992;&#30340;&#31574;&#30053;&#65292;&#22312;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#29992;&#20110;&#26377;&#25928;&#21644;&#24555;&#36895;&#20915;&#31574;&#12290;&#36890;&#36807;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#26500;&#24314;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;&#65292;&#21033;&#29992;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#20135;&#29983;&#25968;&#23383;&#23402;&#29983;&#27010;&#29575;&#20998;&#24067;&#65292;&#20174;&#32780;&#36827;&#34892;&#21333;&#19968;&#21327;&#21464;&#37327;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2310.18027</link><description>&lt;p&gt;
&#20855;&#26377;&#21472;&#21152;&#28151;&#21512;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Prognostic Covariate Adjustment With Additive Mixture Priors. (arXiv:2310.18027v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18027
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#21327;&#21464;&#37327;&#35843;&#25972;&#21644;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#21033;&#29992;&#30340;&#31574;&#30053;&#65292;&#22312;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#29992;&#20110;&#26377;&#25928;&#21644;&#24555;&#36895;&#20915;&#31574;&#12290;&#36890;&#36807;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#26500;&#24314;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;&#65292;&#21033;&#29992;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#20135;&#29983;&#25968;&#23383;&#23402;&#29983;&#27010;&#29575;&#20998;&#24067;&#65292;&#20174;&#32780;&#36827;&#34892;&#21333;&#19968;&#21327;&#21464;&#37327;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65288;RCTs&#65289;&#20013;&#36827;&#34892;&#26377;&#25928;&#21644;&#24555;&#36895;&#30340;&#20915;&#31574;&#38656;&#35201;&#26080;&#20559;&#21644;&#20934;&#30830;&#30340;&#27835;&#30103;&#25928;&#26524;&#25512;&#26029;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#19968;&#35201;&#27714;&#65292;&#26377;&#20004;&#31181;&#31574;&#30053;&#65306;&#35843;&#25972;&#19982;&#32467;&#26524;&#39640;&#24230;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65292;&#20197;&#21450;&#36890;&#36807;&#36125;&#21494;&#26031;&#23450;&#29702;&#21033;&#29992;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#39044;&#21518;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031;PROCOVA&#65292;&#23558;&#36825;&#20004;&#31181;&#31574;&#30053;&#32467;&#21512;&#36215;&#26469;&#12290;&#21327;&#21464;&#37327;&#35843;&#25972;&#22522;&#20110;&#29983;&#25104;&#22411;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#31639;&#27861;&#65292;&#26500;&#24314;&#20102;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21442;&#19982;&#32773;&#30340;&#25968;&#23383;&#23402;&#29983;&#29983;&#25104;&#22120;&#65288;DTG&#65289;&#12290;DTG&#36890;&#36807;&#21382;&#21490;&#23545;&#29031;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#20026;&#27599;&#20010;&#21442;&#19982;&#32773;&#30340;&#23545;&#29031;&#32467;&#26524;&#20135;&#29983;&#20102;&#19968;&#20010;&#25968;&#23383;&#23402;&#29983;&#65288;DT&#65289;&#27010;&#29575;&#20998;&#24067;&#12290;DT&#20998;&#24067;&#30340;&#26399;&#26395;&#23450;&#20041;&#20102;&#29992;&#20110;&#35843;&#25972;&#30340;&#21333;&#19968;&#21327;&#21464;&#37327;&#12290;&#21382;&#21490;&#23545;&#29031;&#20449;&#24687;&#36890;&#36807;&#20855;&#26377;&#20004;&#20010;&#32452;&#25104;&#37096;&#20998;&#30340;&#21472;&#21152;&#28151;&#21512;&#20808;&#39564;&#36827;&#34892;&#21033;&#29992;&#65306;&#22522;&#20110;&#20808;&#39564;&#20449;&#24687;&#30830;&#23450;&#30340;&#19968;&#20010;&#20449;&#24687;&#20808;&#39564;&#27010;&#29575;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Effective and rapid decision-making from randomized controlled trials (RCTs) requires unbiased and precise treatment effect inferences. Two strategies to address this requirement are to adjust for covariates that are highly correlated with the outcome, and to leverage historical control information via Bayes' theorem. We propose a new Bayesian prognostic covariate adjustment methodology, referred to as Bayesian PROCOVA, that combines these two strategies. Covariate adjustment is based on generative artificial intelligence (AI) algorithms that construct a digital twin generator (DTG) for RCT participants. The DTG is trained on historical control data and yields a digital twin (DT) probability distribution for each participant's control outcome. The expectation of the DT distribution defines the single covariate for adjustment. Historical control information are leveraged via an additive mixture prior with two components: an informative prior probability distribution specified based on h
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.11122</link><description>&lt;p&gt;
&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Amortized Bayesian Inference. (arXiv:2310.11122v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25935;&#24863;&#24615;&#24863;&#30693;&#30340;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#37325;&#20849;&#20139;&#21644;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#30340;&#35757;&#32451;&#65292;&#20197;&#21450;&#23545;&#25968;&#25454;&#25200;&#21160;&#21644;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#26159;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#36827;&#34892;&#27010;&#29575;&#25512;&#29702;&#21644;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#29616;&#20195;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#31243;&#20013;&#30340;&#22522;&#26412;&#36873;&#25321;&#28041;&#21450;&#20284;&#28982;&#20989;&#25968;&#21644;&#20808;&#39564;&#20998;&#24067;&#30340;&#35268;&#33539;&#12289;&#21518;&#39564;&#36924;&#36817;&#22120;&#21644;&#25968;&#25454;&#12290;&#27599;&#20010;&#36873;&#25321;&#37117;&#21487;&#20197;&#26174;&#30528;&#24433;&#21709;&#22522;&#20110;&#27169;&#22411;&#30340;&#25512;&#26029;&#21644;&#21518;&#32493;&#20915;&#31574;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#26041;&#38754;&#30340;&#26041;&#27861;&#65292;&#23558;&#25935;&#24863;&#24615;&#20998;&#26512;&#25972;&#21512;&#21040;&#25674;&#38144;&#36125;&#21494;&#26031;&#25512;&#26029;&#65288;ABI&#65292;&#21363;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#25311;&#25512;&#26029;&#65289;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#26435;&#37325;&#20849;&#20139;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#32534;&#30721;&#26367;&#20195;&#20284;&#28982;&#21644;&#20808;&#39564;&#35268;&#33539;&#20043;&#38388;&#30340;&#32467;&#26500;&#30456;&#20284;&#24615;&#65292;&#20197;&#26368;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#25512;&#26029;&#26469;&#35780;&#20272;&#23545;&#21508;&#31181;&#25968;&#25454;&#25200;&#21160;&#25110;&#39044;&#22788;&#29702;&#31243;&#24207;&#30340;&#25935;&#24863;&#24615;&#12290;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#27604;&#65292;&#36825;&#20004;&#20010;&#27493;&#39588;&#37117;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference is a powerful framework for making probabilistic inferences and decisions under uncertainty. Fundamental choices in modern Bayesian workflows concern the specification of the likelihood function and prior distributions, the posterior approximator, and the data. Each choice can significantly influence model-based inference and subsequent decisions, thereby necessitating sensitivity analysis. In this work, we propose a multifaceted approach to integrate sensitivity analyses into amortized Bayesian inference (ABI, i.e., simulation-based inference with neural networks). First, we utilize weight sharing to encode the structural similarities between alternative likelihood and prior specifications in the training process with minimal computational overhead. Second, we leverage the rapid inference of neural networks to assess sensitivity to various data perturbations or pre-processing procedures. In contrast to most other Bayesian approaches, both steps circumvent the costly
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#27934;&#23519;&#29616;&#35937;&#21487;&#33021;&#26159;&#30001;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#35757;&#32451;&#21160;&#24577;&#36807;&#28193;&#21040;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#36319;&#36394;&#36275;&#22815;&#30340;&#32479;&#35745;&#37327;&#65292;&#21457;&#29616;&#27934;&#23519;&#26159;&#22312;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#21518;&#65292;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#25214;&#21040;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20043;&#21518;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.06110</link><description>&lt;p&gt;
&#20174;&#25042;&#24816;&#21040;&#20016;&#23500;&#35757;&#32451;&#21160;&#24577;&#30340;&#27934;&#23519;&#21147;
&lt;/p&gt;
&lt;p&gt;
Grokking as the Transition from Lazy to Rich Training Dynamics. (arXiv:2310.06110v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06110
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#27934;&#23519;&#29616;&#35937;&#21487;&#33021;&#26159;&#30001;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#35757;&#32451;&#21160;&#24577;&#36807;&#28193;&#21040;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#36319;&#36394;&#36275;&#22815;&#30340;&#32479;&#35745;&#37327;&#65292;&#21457;&#29616;&#27934;&#23519;&#26159;&#22312;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#21518;&#65292;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#25214;&#21040;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#20043;&#21518;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#27934;&#23519;&#29616;&#35937;&#65292;&#21363;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#25439;&#22833;&#22312;&#27979;&#35797;&#25439;&#22833;&#20043;&#21069;&#22823;&#24133;&#19979;&#38477;&#65292;&#21487;&#33021;&#26159;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#20174;&#25042;&#24816;&#30340;&#35757;&#32451;&#21160;&#24577;&#36716;&#21464;&#20026;&#20016;&#23500;&#30340;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#26426;&#21046;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27809;&#26377;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;Vanilla&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#22810;&#39033;&#24335;&#22238;&#24402;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#35813;&#35757;&#32451;&#23637;&#29616;&#20102;&#26080;&#27861;&#29992;&#29616;&#26377;&#29702;&#35770;&#35299;&#37322;&#30340;&#27934;&#23519;&#29616;&#35937;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#35813;&#32593;&#32476;&#27979;&#35797;&#25439;&#22833;&#30340;&#36275;&#22815;&#32479;&#35745;&#37327;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#36319;&#36394;&#36825;&#20123;&#32479;&#35745;&#37327;&#25581;&#31034;&#20102;&#27934;&#23519;&#29616;&#35937;&#30340;&#21457;&#29983;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#39318;&#20808;&#23581;&#35797;&#20351;&#29992;&#21021;&#22987;&#29305;&#24449;&#25311;&#21512;&#26680;&#22238;&#24402;&#35299;&#20915;&#26041;&#26696;&#65292;&#25509;&#30528;&#22312;&#35757;&#32451;&#25439;&#22833;&#24050;&#32463;&#24456;&#20302;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21518;&#26399;&#29305;&#24449;&#23398;&#20064;&#65292;&#20174;&#32780;&#25214;&#21040;&#20102;&#19968;&#20010;&#33021;&#22815;&#27867;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#27934;&#23519;&#20135;&#29983;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#29305;&#24449;&#23398;&#20064;&#30340;&#36895;&#29575;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#32553;&#25918;&#32593;&#32476;&#21442;&#25968;&#26469;&#31934;&#30830;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose that the grokking phenomenon, where the train loss of a neural network decreases much earlier than its test loss, can arise due to a neural network transitioning from lazy training dynamics to a rich, feature learning regime. To illustrate this mechanism, we study the simple setting of vanilla gradient descent on a polynomial regression problem with a two layer neural network which exhibits grokking without regularization in a way that cannot be explained by existing theories. We identify sufficient statistics for the test loss of such a network, and tracking these over training reveals that grokking arises in this setting when the network first attempts to fit a kernel regression solution with its initial features, followed by late-time feature learning where a generalizing solution is identified after train loss is already low. We find that the key determinants of grokking are the rate of feature learning -- which can be controlled precisely by parameters that scale the ne
&lt;/p&gt;</description></item><item><title>Lion&#26159;&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#23613;&#31649;&#20854;&#29702;&#35770;&#22522;&#30784;&#19981;&#26126;&#30830;&#65292;&#20294;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2310.05898</link><description>&lt;p&gt;
&#29422;&#23376;&#31192;&#23494;&#22320;&#35299;&#20915;&#21463;&#38480;&#21046;&#20248;&#21270;&#38382;&#39064;&#65306;&#27491;&#22914;&#26446;&#38597;&#26222;&#35834;&#22827;&#25152;&#39044;&#27979;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts. (arXiv:2310.05898v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05898
&lt;/p&gt;
&lt;p&gt;
Lion&#26159;&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;&#65292;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#23613;&#31649;&#20854;&#29702;&#35770;&#22522;&#30784;&#19981;&#26126;&#30830;&#65292;&#20294;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31243;&#24207;&#25628;&#32034;&#21457;&#29616;&#30340;&#26032;&#20248;&#21270;&#22120;Lion&#65288;&#36827;&#21270;&#30340;&#31526;&#21495;&#21160;&#37327;&#65289;&#22312;&#35757;&#32451;&#22823;&#22411;AI&#27169;&#22411;&#26041;&#38754;&#26174;&#31034;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#23427;&#22312;&#35757;&#32451;&#25928;&#26524;&#19978;&#19982;AdamW&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#20869;&#23384;&#25928;&#29575;&#12290;&#27491;&#22914;&#25105;&#20204;&#21487;&#20197;&#20174;&#38543;&#26426;&#25628;&#32034;&#31243;&#24207;&#30340;&#32467;&#26524;&#20013;&#26399;&#24453;&#30340;&#65292;Lion&#38598;&#25104;&#20102;&#20960;&#20010;&#29616;&#26377;&#31639;&#27861;&#30340;&#20803;&#32032;&#65292;&#21253;&#25324;&#31526;&#21495;&#21160;&#37327;&#12289;&#29420;&#31435;&#30340;&#26435;&#37325;&#34928;&#20943;&#12289;Polak&#21644;Nesterov&#21160;&#37327;&#65292;&#20294;&#21448;&#19981;&#23646;&#20110;&#20219;&#20309;&#29616;&#26377;&#30340;&#29702;&#35770;&#22522;&#30784;&#20248;&#21270;&#22120;&#31867;&#21035;&#12290;&#22240;&#27492;&#65292;&#23613;&#31649;Lion&#20316;&#20026;&#24191;&#27867;&#20219;&#21153;&#30340;&#36890;&#29992;&#20248;&#21270;&#22120;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#19981;&#26126;&#30830;&#12290;&#36825;&#31181;&#32570;&#20047;&#29702;&#35770;&#30340;&#26126;&#30830;&#24615;&#38480;&#21046;&#20102;&#36827;&#19968;&#27493;&#22686;&#24378;&#21644;&#25193;&#23637;Lion&#30340;&#21487;&#33021;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#25581;&#24320;Lion&#30340;&#31070;&#31192;&#38754;&#32433;&#12290;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#21644;&#31163;&#25955;&#26102;&#38388;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;Lion&#26159;&#19968;&#31181;&#29702;&#35770;&#19978;&#26032;&#39062;&#19988;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26368;&#23567;&#21270;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;$f(x)$&#30340;&#21516;&#26102;&#24378;&#21046;&#25191;&#34892;&#36793;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.  This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#24433;&#21709;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#34892;&#20026;&#65292;&#22312;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;&#19981;&#21516;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.01769</link><description>&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#20943;&#32531;&#30697;&#38453;&#24863;&#30693;&#20013;&#30340;&#26799;&#24230;&#19979;&#38477;&#65306;&#23545;&#31216;&#24615;&#21644;&#21021;&#22987;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization. (arXiv:2310.01769v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01769
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#24433;&#21709;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#34892;&#20026;&#65292;&#22312;&#23545;&#31216;&#21644;&#38750;&#23545;&#31216;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;&#19981;&#21516;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#38416;&#36848;&#20102;&#36807;&#21442;&#25968;&#21270;&#22914;&#20309;&#25913;&#21464;&#26799;&#24230;&#19979;&#38477;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#34892;&#20026;&#12290;&#22312;&#23545;&#31216;&#35774;&#32622;&#20013;&#65292;&#36890;&#36807;&#23545;&#31216;&#21442;&#25968;&#21270;&#23398;&#20064;&#26410;&#30693;&#30340;&#21322;&#27491;&#23450;&#30697;&#38453;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65288;$k&gt;r$&#65289;&#38543;&#26426;&#21021;&#22987;&#21270;&#26799;&#24230;&#19979;&#38477;&#30340;&#26032;&#22411;$\Omega (1/T^2)$&#19979;&#30028;&#65292;&#19982;&#31934;&#30830;&#21442;&#25968;&#21270;&#24773;&#20917;&#65288;$k=r$&#65289;&#30340;&#25910;&#25947;&#36895;&#24230;$\exp (-\Omega (T))$&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#23545;&#31216;&#35774;&#32622;&#65292;&#20854;&#20013;$M^* \in \mathbb{R}^{n_1 \times n_2}$&#26159;&#26410;&#30693;&#30697;&#38453;&#65292;&#37319;&#29992;&#38750;&#23545;&#31216;&#21442;&#25968;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper rigorously shows how over-parameterization changes the convergence behaviors of gradient descent (GD) for the matrix sensing problem, where the goal is to recover an unknown low-rank ground-truth matrix from near-isotropic linear measurements. First, we consider the symmetric setting with the symmetric parameterization where $M^* \in \mathbb{R}^{n \times n}$ is a positive semi-definite unknown matrix of rank $r \ll n$, and one uses a symmetric parameterization $XX^\top$ to learn $M^*$. Here $X \in \mathbb{R}^{n \times k}$ with $k &gt; r$ is the factor matrix. We give a novel $\Omega (1/T^2)$ lower bound of randomly initialized GD for the over-parameterized case ($k &gt;r$) where $T$ is the number of iterations. This is in stark contrast to the exact-parameterization scenario ($k=r$) where the convergence rate is $\exp (-\Omega (T))$. Next, we study asymmetric setting where $M^* \in \mathbb{R}^{n_1 \times n_2}$ is the unknown matrix of rank $r \ll \min\{n_1,n_2\}$, and one uses an 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;</title><link>http://arxiv.org/abs/2310.01225</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#20195;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65306;&#24433;&#21709;&#12289;&#21069;&#26223;&#21644;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A path-norm toolkit for modern networks: consequences, promises and challenges. (arXiv:2310.01225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36866;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#65292;&#21487;&#20197;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#24674;&#22797;&#25110;&#36229;&#36234;&#20102;&#24050;&#30693;&#30340;&#36335;&#24452;&#33539;&#25968;&#30028;&#38480;&#65292;&#24182;&#25361;&#25112;&#20102;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#19968;&#20123;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#23436;&#20840;&#33021;&#22815;&#21253;&#25324;&#20855;&#26377;&#20559;&#24046;&#12289;&#36339;&#36291;&#36830;&#25509;&#21644;&#26368;&#22823;&#27744;&#21270;&#30340;&#36890;&#29992;DAG ReLU&#32593;&#32476;&#30340;&#36335;&#24452;&#33539;&#25968;&#24037;&#20855;&#21253;&#12290;&#36825;&#20010;&#24037;&#20855;&#21253;&#19981;&#20165;&#36866;&#29992;&#20110;&#26368;&#24191;&#27867;&#30340;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#21487;&#20197;&#24674;&#22797;&#25110;&#36229;&#36234;&#24050;&#30693;&#30340;&#27492;&#31867;&#33539;&#25968;&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#36335;&#24452;&#33539;&#25968;&#36824;&#20139;&#26377;&#36335;&#24452;&#33539;&#25968;&#30340;&#24120;&#35268;&#20248;&#28857;&#65306;&#35745;&#31639;&#31616;&#20415;&#12289;&#23545;&#32593;&#32476;&#30340;&#23545;&#31216;&#24615;&#20855;&#26377;&#19981;&#21464;&#24615;&#65292;&#22312;&#21069;&#39304;&#32593;&#32476;&#19978;&#27604;&#25805;&#20316;&#31526;&#33539;&#25968;&#30340;&#20056;&#31215;&#65288;&#21478;&#19968;&#31181;&#24120;&#29992;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65289;&#20855;&#26377;&#26356;&#22909;&#30340;&#38160;&#24230;&#12290;&#24037;&#20855;&#21253;&#30340;&#22810;&#21151;&#33021;&#24615;&#21644;&#26131;&#20110;&#23454;&#26045;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#25968;&#20540;&#35780;&#20272;&#22312;ImageNet&#19978;&#23545;ResNet&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#26469;&#25361;&#25112;&#22522;&#20110;&#36335;&#24452;&#33539;&#25968;&#30340;&#20855;&#20307;&#25215;&#35834;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces the first toolkit around path-norms that is fully able to encompass general DAG ReLU networks with biases, skip connections and max pooling. This toolkit notably allows us to establish generalization bounds for real modern neural networks that are not only the most widely applicable path-norm based ones, but also recover or beat the sharpest known bounds of this type. These extended path-norms further enjoy the usual benefits of path-norms: ease of computation, invariance under the symmetries of the network, and improved sharpness on feedforward networks compared to the product of operators' norms, another complexity measure most commonly used.  The versatility of the toolkit and its ease of implementation allow us to challenge the concrete promises of path-norm-based generalization bounds, by numerically evaluating the sharpest known bounds for ResNets on ImageNet.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#30340;&#22122;&#22768;&#20960;&#20309;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#21457;&#29616;&#22122;&#22768;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24449;&#26377;&#21033;&#30340;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;SGD&#22312;&#36867;&#33073;&#23574;&#38160;&#26497;&#23567;&#20540;&#26102;&#19982;GD&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#36867;&#33073;&#26041;&#21521;&#22312;&#24179;&#22374;&#26041;&#21521;&#19978;&#26377;&#26174;&#33879;&#20998;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.00692</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#22122;&#22768;&#20960;&#20309;&#65306;&#23450;&#37327;&#21644;&#20998;&#26512;&#29305;&#24449;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Noise Geometry of Stochastic Gradient Descent: A Quantitative and Analytical Characterization. (arXiv:2310.00692v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#30340;&#22122;&#22768;&#20960;&#20309;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#21457;&#29616;&#22122;&#22768;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24449;&#26377;&#21033;&#30340;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;SGD&#22312;&#36867;&#33073;&#23574;&#38160;&#26497;&#23567;&#20540;&#26102;&#19982;GD&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#36867;&#33073;&#26041;&#21521;&#22312;&#24179;&#22374;&#26041;&#21521;&#19978;&#26377;&#26174;&#33879;&#20998;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#30340;&#22122;&#22768;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#29305;&#24449;&#26377;&#21033;&#30340;&#19968;&#33268;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#31181;&#29616;&#35937;&#30340;&#29702;&#35770;&#21644;&#23450;&#37327;&#35299;&#37322;&#20173;&#28982;&#19981;&#36275;&#12290;&#26412;&#25991;&#23545;&#36807;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#19978;&#36848;&#8220;&#22122;&#22768;&#20960;&#20309;&#8221;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#32454;&#33268;&#22320;&#30740;&#31350;&#20102;&#24179;&#22343;&#21644;&#26041;&#21521;&#30340;&#19968;&#33268;&#24615;&#65292;&#29305;&#21035;&#20851;&#27880;&#26679;&#26412;&#22823;&#23567;&#21644;&#36755;&#20837;&#25968;&#25454;&#36864;&#21270;&#23545;&#19968;&#33268;&#24615;&#24378;&#24230;&#30340;&#24433;&#21709;&#12290;&#20316;&#20026;&#29305;&#23450;&#24212;&#29992;&#65292;&#25105;&#20204;&#21033;&#29992;&#22122;&#22768;&#20960;&#20309;&#29305;&#24449;&#30740;&#31350;&#20102;SGD&#22914;&#20309;&#20174;&#23574;&#38160;&#26497;&#23567;&#20540;&#20013;&#36867;&#33073;&#65292;&#21457;&#29616;&#36867;&#33073;&#26041;&#21521;&#22312;&#24179;&#22374;&#26041;&#21521;&#19978;&#26377;&#26174;&#33879;&#20998;&#37327;&#65292;&#36825;&#19982;&#21482;&#22312;&#26368;&#23574;&#38160;&#26041;&#21521;&#36867;&#33073;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;GD&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical studies have demonstrated that the noise in stochastic gradient descent (SGD) aligns favorably with the local geometry of loss landscape. However, theoretical and quantitative explanations for this phenomenon remain sparse. In this paper, we offer a comprehensive theoretical investigation into the aforementioned {\em noise geometry} for over-parameterized linear (OLMs) models and two-layer neural networks. We scrutinize both average and directional alignments, paying special attention to how factors like sample size and input data degeneracy affect the alignment strength. As a specific application, we leverage our noise geometry characterizations to study how SGD escapes from sharp minima, revealing that the escape direction has significant components along flat directions. This is in stark contrast to GD, which escapes only along the sharpest directions. To substantiate our theoretical findings, both synthetic and real-world experiments are provided.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Forman-Ricci&#26354;&#29575;&#25193;&#23637;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#31163;&#25955;&#26354;&#29575;&#65292;&#21487;&#20197;&#28155;&#21152;&#25110;&#21024;&#38500;&#36793;&#20197;&#20943;&#36731;&#36825;&#20004;&#31181;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2309.09384</link><description>&lt;p&gt;
&#20351;&#29992;Forman-Ricci&#26354;&#29575;&#30340;&#25193;&#23637;&#26469;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Mitigating Over-Smoothing and Over-Squashing using Augmentations of Forman-Ricci Curvature. (arXiv:2309.09384v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09384
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Forman-Ricci&#26354;&#29575;&#25193;&#23637;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#31163;&#25955;&#26354;&#29575;&#65292;&#21487;&#20197;&#28155;&#21152;&#25110;&#21024;&#38500;&#36793;&#20197;&#20943;&#36731;&#36825;&#20004;&#31181;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#22270;&#32467;&#26500;&#25968;&#25454;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#26368;&#36817;&#25551;&#36848;&#20102;&#20960;&#20010;&#28508;&#22312;&#30340;&#38519;&#38449;&#12290;&#36825;&#20123;&#21253;&#25324;&#26080;&#27861;&#20934;&#30830;&#21033;&#29992;&#32534;&#30721;&#22312;&#38271;&#36317;&#31163;&#36830;&#25509;&#20013;&#30340;&#20449;&#24687;&#65288;&#36807;&#24230;&#21387;&#32553;&#65289;&#65292;&#20197;&#21450;&#22312;&#32593;&#32476;&#28145;&#24230;&#22686;&#21152;&#26102;&#38590;&#20197;&#21306;&#20998;&#38468;&#36817;&#33410;&#28857;&#30340;&#23398;&#20064;&#34920;&#31034;&#65288;&#36807;&#24230;&#24179;&#28369;&#65289;&#12290;&#19968;&#31181;&#26377;&#25928;&#30340;&#34920;&#24449;&#36825;&#20004;&#31181;&#25928;&#24212;&#30340;&#26041;&#27861;&#26159;&#31163;&#25955;&#26354;&#29575;&#65306;&#23548;&#33268;&#36807;&#24230;&#21387;&#32553;&#25928;&#24212;&#30340;&#38271;&#36317;&#31163;&#36830;&#25509;&#20855;&#26377;&#20302;&#26354;&#29575;&#65292;&#32780;&#23548;&#33268;&#36807;&#24230;&#24179;&#28369;&#30340;&#36793;&#20855;&#26377;&#39640;&#26354;&#29575;&#12290;&#36825;&#20010;&#35266;&#23519;&#24341;&#21457;&#20102;&#19968;&#20123;&#37325;&#36830;&#25216;&#26415;&#65292;&#36890;&#36807;&#22686;&#21152;&#25110;&#21024;&#38500;&#36793;&#26469;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#21033;&#29992;&#22270;&#29305;&#24449;&#65288;&#22914;&#26354;&#29575;&#25110;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#35889;&#65289;&#30340;&#37325;&#36830;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22522;&#20110;&#26354;&#29575;&#30340;&#26041;&#27861;&#65292;&#36890;&#24120;&#38656;&#35201;&#26114;&#36149;&#30340;&#23376;&#22270;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
While Graph Neural Networks (GNNs) have been successfully leveraged for learning on graph-structured data across domains, several potential pitfalls have been described recently. Those include the inability to accurately leverage information encoded in long-range connections (over-squashing), as well as difficulties distinguishing the learned representations of nearby nodes with growing network depth (over-smoothing). An effective way to characterize both effects is discrete curvature: Long-range connections that underlie over-squashing effects have low curvature, whereas edges that contribute to over-smoothing have high curvature. This observation has given rise to rewiring techniques, which add or remove edges to mitigate over-smoothing and over-squashing. Several rewiring approaches utilizing graph characteristics, such as curvature or the spectrum of the graph Laplacian, have been proposed. However, existing methods, especially those based on curvature, often require expensive subr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26080;&#20284;&#28982;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#23545;&#24050;&#30693;&#23646;&#20110;&#20004;&#20010;&#31867;&#21035;&#30340;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#38382;&#39064;&#65292;&#22312;&#26080;&#20284;&#28982;&#25512;&#26029;&#39046;&#22495;&#65292;&#36890;&#36807;&#23558;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#27491;&#21521;&#27169;&#25311;&#33719;&#24471;&#65292;&#26410;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#23454;&#39564;&#25910;&#38598;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#26435;&#34913;m&#21644;n&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.09043</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#26080;&#20284;&#28982;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Kernel-Based Tests for Likelihood-Free Hypothesis Testing. (arXiv:2308.09043v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26080;&#20284;&#28982;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#23545;&#24050;&#30693;&#23646;&#20110;&#20004;&#20010;&#31867;&#21035;&#30340;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#38382;&#39064;&#65292;&#22312;&#26080;&#20284;&#28982;&#25512;&#26029;&#39046;&#22495;&#65292;&#36890;&#36807;&#23558;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#27491;&#21521;&#27169;&#25311;&#33719;&#24471;&#65292;&#26410;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#23454;&#39564;&#25910;&#38598;&#65292;&#32473;&#20986;&#20102;&#19968;&#20010;&#26435;&#34913;m&#21644;n&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20004;&#20010;&#24179;&#34913;&#31867;&#21035;&#30340;n&#20010;&#35266;&#27979;&#20013;&#65292;&#32771;&#34385;&#23545;&#39069;&#22806;m&#20010;&#24050;&#30693;&#23646;&#20110;&#20854;&#20013;&#19968;&#20010;&#31867;&#21035;&#30340;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#20219;&#21153;&#12290;&#35813;&#38382;&#39064;&#30340;&#29305;&#27530;&#24773;&#20917;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#65306;&#24403;&#23436;&#20840;&#20102;&#35299;&#31867;&#21035;&#20998;&#24067;&#26102;&#65288;n=&#8734;&#65289;&#65292;&#26368;&#20248;&#35299;&#26159;&#20351;&#29992;&#20284;&#28982;&#27604;&#26816;&#39564;&#65307;&#24403;m=1&#26102;&#65292;&#23545;&#24212;&#20108;&#20998;&#31867;&#38382;&#39064;&#65307;&#24403;m&#8776;n&#26102;&#65292;&#31561;&#21516;&#20110;&#20004;&#26679;&#26412;&#26816;&#39564;&#12290;&#20013;&#38388;&#30340;&#24773;&#20917;&#20986;&#29616;&#22312;&#26080;&#20284;&#28982;&#25512;&#26029;&#39046;&#22495;&#65292;&#20854;&#20013;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#36816;&#34892;&#27491;&#21521;&#27169;&#25311;&#33719;&#24471;&#65292;&#32780;&#26410;&#26631;&#35760;&#26679;&#26412;&#36890;&#36807;&#23454;&#39564;&#25910;&#38598;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;m&#21644;n&#20043;&#38388;&#23384;&#22312;&#26681;&#26412;&#24615;&#30340;&#26435;&#34913;&#65306;&#22686;&#21152;&#25968;&#25454;&#26679;&#26412;m&#20250;&#20943;&#23569;&#25152;&#38656;&#30340;&#35757;&#32451;/&#27169;&#25311;&#25968;&#25454;&#37327;n&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#65288;a&#65289;&#24341;&#20837;&#20102;&#19968;&#20010;&#24120;&#24120;&#36935;&#21040;&#30340;&#24773;&#20917;&#65292;&#21363;&#26410;&#26631;&#35760;&#26679;&#26412;&#26469;&#33258;&#20004;&#20010;&#31867;&#21035;&#30340;&#28151;&#21512;&#29289;&#65307;&#65288;b&#65289;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#39118;&#38505;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#39118;&#38505;&#23450;&#20041;&#20026;&#35823;&#20998;&#31867;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given $n$ observations from two balanced classes, consider the task of labeling an additional $m$ inputs that are known to all belong to \emph{one} of the two classes. Special cases of this problem are well-known: with complete knowledge of class distributions ($n=\infty$) the problem is solved optimally by the likelihood-ratio test; when $m=1$ it corresponds to binary classification; and when $m\approx n$ it is equivalent to two-sample testing. The intermediate settings occur in the field of likelihood-free inference, where labeled samples are obtained by running forward simulations and the unlabeled sample is collected experimentally. In recent work it was discovered that there is a fundamental trade-off between $m$ and $n$: increasing the data sample $m$ reduces the amount $n$ of training/simulation data needed. In this work we (a) introduce a generalization where unlabeled samples come from a mixture of the two classes -- a case often encountered in practice; (b) study the minimax 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#27969;&#21305;&#37197;&#30340;&#31561;&#21464;CNF&#35757;&#32451;&#30446;&#26631;&#65292;&#21487;&#20197;&#25552;&#39640;&#31561;&#21464;CNF&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.15030</link><description>&lt;p&gt;
&#31561;&#21464;&#27969;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Equivariant flow matching. (arXiv:2306.15030v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#27969;&#21305;&#37197;&#30340;&#31561;&#21464;CNF&#35757;&#32451;&#30446;&#26631;&#65292;&#21487;&#20197;&#25552;&#39640;&#31561;&#21464;CNF&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#21270;&#27969;&#26159;&#19968;&#31867;&#29305;&#21035;&#36866;&#29992;&#20110;&#29289;&#29702;&#23398;&#20013;&#27010;&#29575;&#20998;&#24067;&#24314;&#27169;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;&#20854;&#20013;&#65292;&#27969;&#30340;&#20934;&#30830;&#20284;&#28982;&#24615;&#36136;&#21487;&#20197;&#23454;&#29616;&#23545;&#24050;&#30693;&#30446;&#26631;&#33021;&#37327;&#20989;&#25968;&#30340;&#21152;&#26435;&#37325;&#37325;&#21644;&#26080;&#20559;&#35266;&#27979;&#37327;&#30340;&#35745;&#31639;&#12290;&#20363;&#22914;&#65292;Boltzmann&#29983;&#25104;&#22120;&#36890;&#36807;&#35757;&#32451;&#27969;&#29983;&#25104;&#22788;&#20110;&#24179;&#34913;&#29366;&#24577;&#30340;&#22810;&#20307;&#31995;&#32479;&#65288;&#22914;&#23567;&#20998;&#23376;&#21644;&#34507;&#30333;&#36136;&#65289;&#26679;&#26412;&#65292;&#35299;&#20915;&#20102;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#37319;&#26679;&#38382;&#39064;&#12290;&#20026;&#20102;&#26500;&#24314;&#26377;&#25928;&#30340;&#27169;&#22411;&#65292;&#20063;&#24456;&#20851;&#38190;&#23558;&#30446;&#26631;&#33021;&#37327;&#30340;&#23545;&#31216;&#24615;&#32435;&#20837;&#27169;&#22411;&#20013;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#31561;&#21464;&#36830;&#32493;&#26631;&#20934;&#21270;&#27969;&#65288;CNF&#65289;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;CNF&#30340;&#35757;&#32451;&#21644;&#26679;&#26412;&#29983;&#25104;&#30340;&#35745;&#31639;&#24320;&#38144;&#36739;&#22823;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#23454;&#38469;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31561;&#21464;&#27969;&#21305;&#37197;&#65292;&#19968;&#31181;&#26032;&#30340;&#31561;&#21464;CNF&#35757;&#32451;&#30446;&#26631;&#65292;&#20854;&#22522;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#26368;&#20248;&#36755;&#36816;&#27969;&#21305;&#37197;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows are a class of deep generative models that are especially interesting for modeling probability distributions in physics, where the exact likelihood of flows allows reweighting to known target energy functions and computing unbiased observables. For instance, Boltzmann generators tackle the long-standing sampling problem in statistical physics by training flows to produce equilibrium samples of many-body systems such as small molecules and proteins. To build effective models for such systems, it is crucial to incorporate the symmetries of the target energy into the model, which can be achieved by equivariant continuous normalizing flows (CNFs). However, CNFs can be computationally expensive to train and generate samples from, which has hampered their scalability and practical application. In this paper, we introduce equivariant flow matching, a new training objective for equivariant CNFs that is based on the recently proposed optimal transport flow matching. Equivarian
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2306.11380</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Take on Gaussian Process Networks. (arXiv:2306.11380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11380
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#65288;GPNs&#65289;&#26159;&#19968;&#31867;&#26377;&#21521;&#22270;&#27169;&#22411;&#65292;&#20854;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#32593;&#32476;&#20013;&#27599;&#20010;&#21464;&#37327;&#32473;&#23450;&#20854;&#29238;&#21464;&#37327;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#35813;&#27169;&#22411;&#20801;&#35768;&#20197;&#32039;&#20945;&#20294;&#28789;&#27963;&#30340;&#26041;&#24335;&#25551;&#36848;&#36830;&#32493;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#20165;&#20570;&#26368;&#23569;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;GPNs&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#38656;&#35201;&#35745;&#31639;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21363;&#20351;&#22312;&#20302;&#32500;&#24773;&#20917;&#19979;&#65292;&#36825;&#20063;&#26159;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#12290;&#26412;&#25991;&#23454;&#29616;&#20102;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#26469;&#20174;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#36981;&#24490;&#36125;&#21494;&#26031;&#33539;&#24335;&#65292;&#36890;&#36807;&#36793;&#32536;&#20284;&#28982;&#27604;&#36739;&#27169;&#22411;&#65292;&#24182;&#35745;&#31639;GPN&#29305;&#24449;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20854;&#21518;&#39564;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows describing continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features. Simulation studies show that our method outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its poste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#65292;&#25552;&#39640;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07119</link><description>&lt;p&gt;
&#22522;&#20110;&#8220;&#24179;&#22343;&#8221;&#30340;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#30340;&#25913;&#36827;&#65292;&#20197;&#39135;&#21697;&#38656;&#27714;&#39044;&#27979;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Improving Forecasts for Heterogeneous Time Series by "Averaging", with Application to Food Demand Forecast. (arXiv:2306.07119v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#65292;&#25552;&#39640;&#24322;&#36136;&#24615;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24120;&#35265;&#39044;&#27979;&#22330;&#26223;&#26159;&#32771;&#34385;&#19968;&#32452;&#21487;&#33021;&#24322;&#36136;&#24615;&#30340;&#30456;&#21516;&#39046;&#22495;&#26102;&#38388;&#24207;&#21015;&#12290;&#30001;&#20110;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#19981;&#21516;&#29305;&#24615;&#65292;&#22914;&#38271;&#24230;&#31561;&#65292;&#30452;&#25509;&#23545;&#27599;&#20010;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#39044;&#27979;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#20013;&#30340;&#30456;&#20284;&#24230;&#24230;&#37327;&#25214;&#21040;&#30456;&#20284;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#20197;k&#26368;&#36817;&#37051;&#30340;&#26041;&#24335;&#26500;&#24314;&#37051;&#22495;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#26469;&#25913;&#36827;&#21487;&#33021;&#31616;&#21333;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#25552;&#20986;&#20102;&#20960;&#31181;&#25191;&#34892;&#24179;&#22343;&#30340;&#26041;&#27861;&#65292;&#24182;&#29702;&#35770;&#35777;&#26126;&#20102;&#24179;&#22343;&#23545;&#20110;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#35786;&#26029;&#24037;&#20855;&#65292;&#20801;&#35768;&#28145;&#20837;&#29702;&#35299;&#35813;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common forecasting setting in real world applications considers a set of possibly heterogeneous time series of the same domain. Due to different properties of each time series such as length, obtaining forecasts for each individual time series in a straight-forward way is challenging. This paper proposes a general framework utilizing a similarity measure in Dynamic Time Warping to find similar time series to build neighborhoods in a k-Nearest Neighbor fashion, and improve forecasts of possibly simple models by averaging. Several ways of performing the averaging are suggested, and theoretical arguments underline the usefulness of averaging for forecasting. Additionally, diagnostics tools are proposed allowing a deep understanding of the procedure.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FAVAS&#31639;&#27861;&#65292;&#26159;&#19968;&#31181;&#29992;&#20110;&#22312;&#36164;&#28304;&#26377;&#38480;&#29615;&#22659;&#19979;&#35757;&#32451;DNNs&#30340;&#26032;&#22411;&#20013;&#24515;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;FAVAS&#31639;&#27861;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.16099</link><description>&lt;p&gt;
FAVAS: &#24102;&#26377;&#24322;&#27493;&#23458;&#25143;&#31471;&#30340;&#32852;&#37030;&#24179;&#22343;&#30340;&#26032;&#22411;&#20013;&#24515;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
FAVAS: Federated AVeraging with ASynchronous clients. (arXiv:2305.16099v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;FAVAS&#31639;&#27861;&#65292;&#26159;&#19968;&#31181;&#29992;&#20110;&#22312;&#36164;&#28304;&#26377;&#38480;&#29615;&#22659;&#19979;&#35757;&#32451;DNNs&#30340;&#26032;&#22411;&#20013;&#24515;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;FAVAS&#31639;&#27861;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#20013;&#24515;&#21270;&#24322;&#27493;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;FAVAS&#65292;&#29992;&#20110;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#19979;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;&#23613;&#31649;&#32852;&#37030;&#23398;&#20064;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#22823;&#22411;&#26080;&#32447;&#32593;&#32476;&#19978;&#20280;&#32553;&#21516;&#27493;&#36890;&#20449;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#23458;&#25143;&#31471;&#36890;&#24120;&#20855;&#26377;&#19981;&#21516;&#30340;&#35745;&#31639;&#36164;&#28304;&#21644;&#35745;&#31639;&#36895;&#24230;&#65292;&#24322;&#27493;&#26356;&#26032;&#21487;&#33021;&#20250;&#23548;&#33268;&#26174;&#30528;&#30340;&#20559;&#24046;&#65288;&#23545;&#8220;&#24555;&#36895;&#8221;&#23458;&#25143;&#31471;&#26356;&#26377;&#21033;&#65289;&#12290;&#22240;&#27492;&#65292;FL&#30340;&#23454;&#38469;&#37096;&#32626;&#38656;&#35201;&#22788;&#29702;&#22312;&#36890;&#20449;/&#36164;&#28304;&#21463;&#38480;&#30340;&#29615;&#22659;&#20013;&#20855;&#26377;&#24378;&#28872;&#21464;&#21270;&#30340;&#35745;&#31639;&#36895;&#24230;&#30340;&#29992;&#25143;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;FAVAS&#22312;&#24179;&#28369;&#30340;&#38750;&#20984;&#29615;&#22659;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#20180;&#32454;&#27604;&#36739;&#20102;&#33719;&#24471;&#30340;&#25910;&#25947;&#20445;&#35777;&#19982;&#29616;&#26377;&#36793;&#30028;&#65288;&#22914;&#26524;&#26377;&#65289;&#30340;&#24046;&#24322;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;FAVAS&#31639;&#27861;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#24403;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a novel centralized Asynchronous Federated Learning (FL) framework, FAVAS, for training Deep Neural Networks (DNNs) in resource-constrained environments. Despite its popularity, ``classical'' federated learning faces the increasingly difficult task of scaling synchronous communication over large wireless networks. Moreover, clients typically have different computing resources and therefore computing speed, which can lead to a significant bias (in favor of ``fast'' clients) when the updates are asynchronous. Therefore, practical deployment of FL requires to handle users with strongly varying computing speed in communication/resource constrained setting. We provide convergence guarantees for FAVAS in a smooth, non-convex environment and carefully compare the obtained convergence guarantees with existing bounds, when they are available. Experimental results show that the FAVAS algorithm outperforms current methods on standard benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.05014</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#38454;&#28140;&#28779;&#38543;&#26426;&#28418;&#31227;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Linear Inverse Problems using Higher-Order Annealed Langevin Diffusion. (arXiv:2305.05014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#38454; Langevin &#28418;&#31227;&#30340;&#32447;&#24615;&#21453;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#22788;&#29702;&#30340;&#20108;&#38454;&#21644;&#19977;&#38454; Langevin &#21160;&#21147;&#23398;&#65292;&#36825;&#20123;&#21160;&#21147;&#23398;&#26126;&#26174;&#22320;&#20174;&#25105;&#20204;&#24863;&#20852;&#36259;&#30340;&#26410;&#30693;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#21516;&#26102;&#27604;&#20854;&#19968;&#38454;&#23545;&#24212;&#29289;&#21644;&#20004;&#31181;&#21160;&#21147;&#23398;&#30340;&#38750;&#39044;&#22788;&#29702;&#29256;&#26412;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#31181;&#39044;&#22788;&#29702;&#21160;&#21147;&#23398;&#26159;&#33391;&#23450;&#20041;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#38750;&#39044;&#22788;&#29702;&#24773;&#20917;&#30456;&#21516;&#30340;&#21807;&#19968;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#21152;&#20837;&#20102;&#19968;&#20010;&#28140;&#28779;&#36807;&#31243;&#65292;&#36825;&#20855;&#26377;&#21452;&#37325;&#20248;&#28857;&#65292;&#19968;&#26041;&#38754;&#36827;&#19968;&#27493;&#21152;&#36895;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21478;&#19968;&#26041;&#38754;&#65292;&#20801;&#35768;&#25105;&#20204;&#36866;&#24212;&#26410;&#30693;&#21464;&#37327;&#20026;&#31163;&#25955;&#30340;&#24773;&#20917;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#65288;MIMO &#31526;&#21495;&#26816;&#27979;&#21644;&#36890;&#36947;&#20272;&#35745;&#65289;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#30456;&#23545;&#20110;&#31454;&#20105;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#65289;&#25152;&#23454;&#29616;&#30340;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a solution for linear inverse problems based on higher-order Langevin diffusion. More precisely, we propose pre-conditioned second-order and third-order Langevin dynamics that provably sample from the posterior distribution of our unknown variables of interest while being computationally more efficient than their first-order counterpart and the non-conditioned versions of both dynamics. Moreover, we prove that both pre-conditioned dynamics are well-defined and have the same unique invariant distributions as the non-conditioned cases. We also incorporate an annealing procedure that has the double benefit of further accelerating the convergence of the algorithm and allowing us to accommodate the case where the unknown variables are discrete. Numerical experiments in two different tasks (MIMO symbol detection and channel estimation) showcase the generality of our method and illustrate the high performance achieved relative to competing approaches (including learning-based ones)
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#24615;&#33021;&#39564;&#35777;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23545;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2301.11873</link><description>&lt;p&gt;
&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11873
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#24615;&#33021;&#39564;&#35777;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23545;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#65288;BMC&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#31454;&#20105;&#35745;&#31639;&#27169;&#22411;&#30340;&#30456;&#23545;&#20248;&#21183;&#65292;&#24182;&#23558;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#21040;&#27169;&#22411;&#36873;&#25321;&#20915;&#31574;&#20013;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39640;&#32500;&#23884;&#22871;&#21442;&#25968;&#32467;&#26500;&#65292;BMC&#22312;&#24120;&#35265;&#30340;&#23618;&#27425;&#27169;&#22411;&#20013;&#24120;&#24120;&#38590;&#20197;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38590;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#20219;&#20309;&#21487;&#23454;&#20363;&#21270;&#20026;&#27010;&#29575;&#31243;&#24207;&#30340;&#23618;&#27425;&#27169;&#22411;&#38598;&#36827;&#34892;BMC&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26041;&#27861;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#23427;&#21487;&#20197;&#22312;&#20219;&#20309;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#20043;&#21069;&#65292;&#23545;&#21518;&#39564;&#27169;&#22411;&#27010;&#29575;&#36827;&#34892;&#39640;&#25928;&#30340;&#37325;&#26032;&#20272;&#35745;&#21644;&#24555;&#36895;&#24615;&#33021;&#39564;&#35777;&#12290;&#22312;&#19968;&#31995;&#21015;&#24191;&#27867;&#30340;&#39564;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#27604;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26725;&#24335;&#25277;&#26679;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25152;&#26377;BMC&#35774;&#32622;&#20013;&#20986;&#33394;&#30340;&#20998;&#25674;&#25512;&#26029;&#33021;&#21147;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#20808;&#21069;&#34987;&#35748;&#20026;&#26159;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian model comparison (BMC) offers a principled approach for assessing the relative merits of competing computational models and propagating uncertainty into model selection decisions. However, BMC is often intractable for the popular class of hierarchical models due to their high-dimensional nested parameter structure. To address this intractability, we propose a deep learning method for performing BMC on any set of hierarchical models which can be instantiated as probabilistic programs. Since our method enables amortized inference, it allows efficient re-estimation of posterior model probabilities and fast performance validation prior to any real-data application. In a series of extensive validation studies, we benchmark the performance of our method against the state-of-the-art bridge sampling method and demonstrate excellent amortized inference across all BMC settings. We then showcase our method by comparing four hierarchical evidence accumulation models that have previously b
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#39640;&#25928;&#22320;&#35782;&#21035;&#39118;&#38505;&#34913;&#37327;&#23450;&#20041;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#39640;&#27010;&#29575;&#36793;&#30028;&#26694;&#21644;&#36873;&#25321;&#19979;&#19968;&#20010;&#35780;&#20272;&#28857;&#30340;&#26041;&#27861;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.11588</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#39118;&#38505;&#34913;&#37327;
&lt;/p&gt;
&lt;p&gt;
Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty. (arXiv:2301.11588v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11588
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#39640;&#25928;&#22320;&#35782;&#21035;&#39118;&#38505;&#34913;&#37327;&#23450;&#20041;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#39640;&#27010;&#29575;&#36793;&#30028;&#26694;&#21644;&#36873;&#25321;&#19979;&#19968;&#20010;&#35780;&#20272;&#28857;&#30340;&#26041;&#27861;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;MOBO&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#65288;IU&#65289;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#35782;&#21035;&#30001;&#39118;&#38505;&#34913;&#37327;&#23450;&#20041;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65288;PF&#65289;&#12290;&#29616;&#26377;&#30340;IU&#19979;&#24085;&#32047;&#25176;&#20248;&#21270;&#30340;BO&#26041;&#27861;&#26159;&#29305;&#23450;&#39118;&#38505;&#25110;&#32773;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#65292;&#32780;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#28041;&#21450;&#19968;&#33324;&#39118;&#38505;&#34913;&#37327;&#24182;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#26041;&#27861;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20551;&#35774;&#40657;&#31665;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;GP&#27169;&#22411;&#26500;&#24314;&#39118;&#38505;&#34913;&#37327;&#30340;&#39640;&#27010;&#29575;&#36793;&#30028;&#26694;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20943;&#23569;&#38750;&#25903;&#37197;&#36793;&#30028;&#26694;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#25311;&#36317;&#31163;&#30340;&#26368;&#22823;&#20540;&#23450;&#20041;&#30340;&#26368;&#22823;&#26368;&#23567;&#36317;&#31163;&#36873;&#25321;&#19979;&#19968;&#20010;&#35780;&#20272;&#28857;&#30340;&#26041;&#27861;&#12290;&#20316;&#20026;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20013;&#36820;&#22238;&#20219;&#24847;&#31934;&#30830;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we propose a novel multi-objective Bayesian optimization (MOBO) method to efficiently identify the Pareto front (PF) defined by risk measures for black-box functions under the presence of input uncertainty (IU). Existing BO methods for Pareto optimization in the presence of IU are risk-specific or without theoretical guarantees, whereas our proposed method addresses general risk measures and has theoretical guarantees. The basic idea of the proposed method is to assume a Gaussian process (GP) model for the black-box function and to construct high-probability bounding boxes for the risk measures using the GP model. Furthermore, in order to reduce the uncertainty of non-dominated bounding boxes, we propose a method of selecting the next evaluation point using a maximin distance defined by the maximum value of a quasi distance based on bounding boxes. As theoretical analysis, we prove that the algorithm can return an arbitrary-accurate solution in a finite number of iterati
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25913;&#36827;Moment Accountant&#26041;&#27861;&#65292;DP-SGD&#20855;&#26377;&#21487;&#20851;&#38381;&#24418;&#24335;&#30340;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#65292;&#24182;&#19988;&#20854;&#20445;&#35777;&#25509;&#36817;&#26159;&#32039;&#23494;&#30340;&#65292;&#20855;&#26377;&#26368;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2102.09030</link><description>&lt;p&gt;
&#35770;DP-SGD&#30340;Moment Accountant&#26041;&#27861;&#30340;&#32039;&#23494;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Tightness of the Moment Accountant for DP-SGD. (arXiv:2102.09030v8 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.09030
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25913;&#36827;Moment Accountant&#26041;&#27861;&#65292;DP-SGD&#20855;&#26377;&#21487;&#20851;&#38381;&#24418;&#24335;&#30340;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#65292;&#24182;&#19988;&#20854;&#20445;&#35777;&#25509;&#36817;&#26159;&#32039;&#23494;&#30340;&#65292;&#20855;&#26377;&#26368;&#23567;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#20379;&#24046;&#20998;&#38544;&#31169;&#65292;&#22312;&#24046;&#20998;&#38544;&#31169;SGD&#65288;DP-SGD&#65289;&#20013;&#65292;&#22312;&#25191;&#34892;&#21098;&#20999;&#25805;&#20316;&#21518;&#65292;&#21521;&#26412;&#22320;SGD&#26356;&#26032;&#28155;&#21152;&#26631;&#20934;&#24046;&#20026;$ \sigma $&#30340;&#39640;&#26031;&#22122;&#22768;&#12290;&#36890;&#36807;&#38750;&#24179;&#20961;&#22320;&#25913;&#36827;Moment Accountant&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#23553;&#38381;&#24418;&#24335;&#30340;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#65306;&#22914;&#26524;$ \sigma=\sqrt{ 2(\epsilon+\ln(1/\delta))/\epsilon} $&#65292;&#21017;DP-SGD&#26159;$ (\epsilon \leq 1/2&#65292;\delta = 1 / N) $-DP&#65292;&#20854;&#20013;$T$&#33267;&#23569;&#20026;$ \approx 2k^2/\epsilon$&#65292; $(2/e)^2k^2-1/2\geq \ln(N)$&#65292;&#20854;&#20013;$T$&#26159;&#22238;&#21512;&#30340;&#24635;&#25968;&#65292;$ K = kN $&#26159;&#26799;&#24230;&#35745;&#31639;&#30340;&#24635;&#25968;&#65292;&#20854;&#20013;$ k $&#29992;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;$N$&#30340;&#26102;&#20195;&#25968;&#37327;&#26469;&#34913;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#34920;&#36798;&#24335;&#25509;&#36817;&#32039;&#65292;&#22312;$T$&#23567;&#20110;&#32422;&#20026;$ 8 $&#20493;&#20110;&#19979;&#30028;$ \approx 2k^2/\epsilon$&#30340;&#24120;&#25968;&#22240;&#23376;&#26102;&#65292;$(\epsilon&#65292;\delta)$-DP&#20445;&#35777;&#23558;&#34987;&#36829;&#21453;&#12290;&#36873;&#25321;&#26368;&#23567;&#21487;&#33021;&#20540;&#30340;$T \approx 2k^2/\epsilon$&#19981;&#20165;&#20250;&#23548;&#33268;&#25509;&#36817;&#23494;&#38598;&#30340;DP&#20445;&#35777;&#65292;&#32780;&#19988;&#36824;&#20250;&#26368;&#23567;&#21270;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to provide differential privacy, Gaussian noise with standard deviation $\sigma$ is added to local SGD updates after performing a clipping operation in Differential Private SGD (DP-SGD). By non-trivially improving the moment account method we prove a closed form $(\epsilon,\delta)$-DP guarantee: DP-SGD is $(\epsilon\leq 1/2,\delta=1/N)$-DP if $\sigma=\sqrt{2(\epsilon +\ln(1/\delta))/\epsilon}$ with $T$ at least $\approx 2k^2/\epsilon$ and $(2/e)^2k^2-1/2\geq \ln(N)$, where $T$ is the total number of rounds, and $K=kN$ is the total number of gradient computations where $k$ measures $K$ in number of epochs of size $N$ of the local data set. We prove that our expression is close to tight in that if $T$ is more than a constant factor $\approx 8$ smaller than the lower bound $\approx 2k^2/\epsilon$, then the $(\epsilon,\delta)$-DP guarantee is violated. Choosing the smallest possible value $T\approx 2k^2/\epsilon$ not only leads to a close to tight DP guarantee, but also minimizes 
&lt;/p&gt;</description></item></channel></rss>