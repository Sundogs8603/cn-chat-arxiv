<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22810;&#20010;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#20013;&#35782;&#21035;&#26368;&#39640;&#23481;&#37327;&#20449;&#36947;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23481;&#37327;&#20272;&#35745;&#22120;&#21644;&#32553;&#23567;&#24046;&#36317;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#20004;&#31181;&#38468;&#21152;&#31639;&#27861;&#65292;&#23427;&#20204;&#33021;&#22815;&#36755;&#20986;&#25509;&#36817;&#26368;&#22823;&#23481;&#37327;&#30340;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#12290;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#20351;&#29992;&#65292;&#24182;&#19988;&#20855;&#26377;&#19968;&#23450;&#30340;&#32622;&#20449;&#24230;&#12290;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#25152;&#38656;&#30340;&#32622;&#20449;&#24230;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2401.10204</link><description>&lt;p&gt;
&#26368;&#22823;&#23481;&#37327;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Maximal-Capacity Discrete Memoryless Channel Identification. (arXiv:2401.10204v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22810;&#20010;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#20013;&#35782;&#21035;&#26368;&#39640;&#23481;&#37327;&#20449;&#36947;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23481;&#37327;&#20272;&#35745;&#22120;&#21644;&#32553;&#23567;&#24046;&#36317;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#20004;&#31181;&#38468;&#21152;&#31639;&#27861;&#65292;&#23427;&#20204;&#33021;&#22815;&#36755;&#20986;&#25509;&#36817;&#26368;&#22823;&#23481;&#37327;&#30340;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#12290;&#36825;&#20123;&#31639;&#27861;&#33021;&#22815;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#20351;&#29992;&#65292;&#24182;&#19988;&#20855;&#26377;&#19968;&#23450;&#30340;&#32622;&#20449;&#24230;&#12290;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#25152;&#38656;&#30340;&#32622;&#20449;&#24230;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#22810;&#20010;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#20013;&#35782;&#21035;&#26368;&#39640;&#23481;&#37327;&#20449;&#36947;&#30340;&#38382;&#39064;&#12290;&#23558;&#35813;&#38382;&#39064;&#30475;&#20316;&#32431;&#25506;&#32034;&#30340;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#26681;&#25454;&#35757;&#32451;&#24207;&#21015;&#26469;&#24863;&#30693;&#36890;&#20449;&#20449;&#36947;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#23481;&#37327;&#20272;&#35745;&#22120;&#65292;&#24182;&#25512;&#23548;&#20102;&#20272;&#35745;&#35823;&#24046;&#30340;&#32039;&#23494;&#32622;&#20449;&#21306;&#38388;&#12290;&#22522;&#20110;&#35813;&#23481;&#37327;&#20272;&#35745;&#22120;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;BestChanID&#30340;&#32553;&#23567;&#24046;&#36317;&#31639;&#27861;&#65292;&#23427;&#23545;&#23481;&#37327;&#36798;&#21040;&#30340;&#36755;&#20837;&#20998;&#24067;&#26080;&#24863;&#30693;&#65292;&#24182;&#19988;&#20445;&#35777;&#20197;&#39044;&#26399;&#32622;&#20449;&#24230;&#36755;&#20986;&#23481;&#37327;&#26368;&#22823;&#30340;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#12290;&#27492;&#22806;&#65292;&#36824;&#24341;&#20837;&#20102;&#20004;&#31181;&#38468;&#21152;&#31639;&#27861;NaiveChanSel&#21644;MedianChanEl&#65292;&#23427;&#20204;&#33021;&#22815;&#20197;&#19968;&#23450;&#30340;&#32622;&#20449;&#24230;&#36755;&#20986;&#25509;&#36817;&#26368;&#22823;&#23481;&#37327;&#30340;&#31163;&#25955;&#26080;&#35760;&#24518;&#20449;&#36947;&#12290;&#27599;&#20010;&#31639;&#27861;&#22312;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#30410;&#22788;&#65292;&#24182;&#21487;&#20197;&#20316;&#20026;BestChanID&#20013;&#30340;&#23376;&#20363;&#31243;&#20351;&#29992;&#12290;&#20998;&#26512;&#20102;&#25152;&#26377;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20197;&#25152;&#38656;&#30340;&#32622;&#20449;&#24230;&#20989;&#25968;&#20026;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of identifying the channel with the highest capacity among several discrete memoryless channels (DMCs) is considered. The problem is cast as a pure-exploration multi-armed bandit problem, which follows the practical use of training sequences to sense the communication channel statistics. A capacity estimator is proposed and tight confidence bounds on the estimator error are derived. Based on this capacity estimator, a gap-elimination algorithm termed BestChanID is proposed, which is oblivious to the capacity-achieving input distribution and is guaranteed to output the DMC with the largest capacity, with a desired confidence. Furthermore, two additional algorithms NaiveChanSel and MedianChanEl, that output with certain confidence a DMC with capacity close to the maximal, are introduced. Each of those algorithms is beneficial in a different regime and can be used as a subroutine in BestChanID. The sample complexity of all algorithms is analyzed as a function of the desired co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#37051;&#22495;&#31579;&#36873;&#25511;&#21046;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#34394;&#35686;&#29575;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#24050;&#23384;&#22312;&#30340;&#20272;&#35745;&#22120;&#23481;&#26131;&#20986;&#29616;&#34394;&#35686;&#36793;&#32536;&#26816;&#27979;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#26159;&#26080;&#21442;&#25968;&#30340;&#65292;&#26080;&#38656;&#29992;&#25143;&#35843;&#25972;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.09979</link><description>&lt;p&gt;
&#36890;&#36807;&#37051;&#22495;&#31579;&#36873;&#25511;&#21046;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#34394;&#35686;&#29575;
&lt;/p&gt;
&lt;p&gt;
False Discovery Rate Control for Gaussian Graphical Models via Neighborhood Screening. (arXiv:2401.09979v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09979
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#37051;&#22495;&#31579;&#36873;&#25511;&#21046;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#34394;&#35686;&#29575;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#35299;&#20915;&#20102;&#24050;&#23384;&#22312;&#30340;&#20272;&#35745;&#22120;&#23481;&#26131;&#20986;&#29616;&#34394;&#35686;&#36793;&#32536;&#26816;&#27979;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#26159;&#26080;&#21442;&#25968;&#30340;&#65292;&#26080;&#38656;&#29992;&#25143;&#35843;&#25972;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#22270;&#27169;&#22411;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#23427;&#20204;&#23558;&#21464;&#37327;&#20043;&#38388;&#30340;&#32479;&#35745;&#20851;&#31995;&#24314;&#27169;&#25104;&#19968;&#20010;&#22270;&#65292;&#20854;&#20013;&#20004;&#20010;&#21464;&#37327;&#20043;&#38388;&#30340;&#36793;&#34920;&#31034;&#26465;&#20214;&#30456;&#20851;&#24615;&#12290;&#28982;&#32780;&#65292;&#24050;&#32463;&#24314;&#31435;&#30340;&#20272;&#35745;&#22120;&#65292;&#22914;&#22270;&#24418;&#22871;&#32034;&#25110;&#37051;&#22495;&#36873;&#25321;&#65292;&#24050;&#30693;&#23481;&#26131;&#20986;&#29616;&#22823;&#37327;&#34394;&#35686;&#36793;&#32536;&#26816;&#27979;&#12290;&#34394;&#35686;&#26816;&#27979;&#21487;&#33021;&#20250;&#23548;&#33268;&#19981;&#20934;&#30830;&#29978;&#33267;&#38169;&#35823;&#30340;&#31185;&#23398;&#35299;&#37322;&#65292;&#22312;&#29983;&#29289;&#21307;&#23398;&#25110;&#20581;&#24247;&#25252;&#29702;&#31561;&#24212;&#29992;&#20013;&#20855;&#26377;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#33410;&#28857;&#30340;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#26469;&#23398;&#20064;&#22270;&#65292;&#24182;&#22312;&#33258;&#25105;&#20272;&#35745;&#27700;&#24179;&#19978;&#21487;&#25511;&#21046;&#25152;&#36873;&#36793;&#32536;&#38598;&#21512;&#30340;&#34394;&#35686;&#29575;&#12290;&#19968;&#31181;&#26032;&#39062;&#30340;&#20010;&#20307;&#37051;&#22495;&#34701;&#21512;&#26041;&#27861;&#20135;&#29983;&#20102;&#19968;&#20010;&#26080;&#21521;&#22270;&#20272;&#35745;&#20540;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#26080;&#21442;&#25968;&#30340;&#65292;&#19981;&#38656;&#35201;&#29992;&#25143;&#36827;&#34892;&#35843;&#25972;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#19982;&#31454;&#20105;&#30340;&#34394;&#35686;&#29575;&#25511;&#21046;&#26041;&#27861;&#36827;&#34892;&#20102;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian graphical models emerge in a wide range of fields. They model the statistical relationships between variables as a graph, where an edge between two variables indicates conditional dependence. Unfortunately, well-established estimators, such as the graphical lasso or neighborhood selection, are known to be susceptible to a high prevalence of false edge detections. False detections may encourage inaccurate or even incorrect scientific interpretations, with major implications in applications, such as biomedicine or healthcare. In this paper, we introduce a nodewise variable selection approach to graph learning and provably control the false discovery rate of the selected edge set at a self-estimated level. A novel fusion method of the individual neighborhoods outputs an undirected graph estimate. The proposed method is parameter-free and does not require tuning by the user. Benchmarks against competing false discovery rate controlling methods in numerical experiments considering 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#21517;&#20026;FREED&#30340;RL&#27169;&#22411;&#65292;&#36890;&#36807;&#22797;&#21046;&#12289;&#23457;&#26597;&#21644;&#31616;&#21270;&#65292;&#20351;&#20854;&#22312;&#34507;&#30333;&#36136;&#26465;&#20214;&#19979;&#30340;&#20998;&#23376;&#29983;&#25104;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#36136;&#37327;&#21644;&#24615;&#33021;</title><link>http://arxiv.org/abs/2401.09840</link><description>&lt;p&gt;
FREED++:&#36890;&#36807;&#24443;&#24213;&#30340;&#22797;&#21046;&#25913;&#21892;&#22522;&#20110;&#29255;&#27573;&#30340;&#20998;&#23376;&#29983;&#25104;&#30340;RL&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction. (arXiv:2401.09840v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09840
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#21517;&#20026;FREED&#30340;RL&#27169;&#22411;&#65292;&#36890;&#36807;&#22797;&#21046;&#12289;&#23457;&#26597;&#21644;&#31616;&#21270;&#65292;&#20351;&#20854;&#22312;&#34507;&#30333;&#36136;&#26465;&#20214;&#19979;&#30340;&#20998;&#23376;&#29983;&#25104;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#36136;&#37327;&#21644;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26032;&#22411;&#27835;&#30103;&#33647;&#29289;&#30340;&#29702;&#24615;&#35774;&#35745;&#26088;&#22312;&#25214;&#21040;&#20855;&#26377;&#25152;&#38656;&#29983;&#29289;&#21151;&#33021;&#30340;&#20998;&#23376;&#32467;&#26500;&#65292;&#20363;&#22914;&#65292;&#36890;&#36807;&#19982;&#29305;&#23450;&#34507;&#30333;&#36136;&#32467;&#21512;&#26469;&#28608;&#27963;&#25110;&#25233;&#21046;&#23427;&#12290;&#20998;&#23376;&#23545;&#25509;&#26159;&#35780;&#20272;&#34507;&#30333;&#36136;-&#20998;&#23376;&#30456;&#20114;&#20316;&#29992;&#30340;&#24120;&#35265;&#25216;&#26415;&#12290;&#26368;&#36817;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25509;&#35780;&#20998;&#65288;DS&#65289;&#20316;&#20026;&#22870;&#21169;&#26469;&#29983;&#25104;&#20998;&#23376;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22797;&#21046;&#12289;&#23457;&#26597;&#21644;&#25913;&#36827;&#20102;&#26368;&#36817;&#29992;&#20110;&#20998;&#23376;&#29983;&#25104;&#30340;RL&#27169;&#22411;FREED&#65288;arXiv&#65306;2110.01219&#65289;&#12290;&#23545;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24191;&#27867;&#35780;&#20272;&#25581;&#31034;&#20102;&#19968;&#20123;&#23616;&#38480;&#24615;&#21644;&#25361;&#25112;&#65292;&#23613;&#31649;&#23545;&#19977;&#20010;&#30446;&#26631;&#34507;&#30333;&#36136;&#25253;&#21578;&#20102;&#26480;&#20986;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#20462;&#22797;&#20102;&#35768;&#22810;&#23454;&#29616;&#38169;&#35823;&#65292;&#31616;&#21270;&#20102;&#27169;&#22411;&#24182;&#25552;&#39640;&#20102;&#20854;&#36136;&#37327;&#65292;&#22823;&#22823;&#25193;&#23637;&#20102;&#23454;&#39564;&#33539;&#22260;&#65292;&#24182;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#34507;&#30333;&#36136;&#26465;&#20214;&#19979;&#20998;&#23376;&#29983;&#25104;&#26041;&#27861;&#36827;&#34892;&#20102;&#20934;&#30830;&#27604;&#36739;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#39640;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it. Molecular docking is a common technique for evaluating protein-molecule interactions. Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward. In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (arXiv:2110.01219). Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins. Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation. We show that the res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#21363;&#26368;&#23567;&#19981;&#19968;&#33268;&#24230;&#37327;&#65288;LDM&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#20915;&#31574;&#36793;&#30028;&#24773;&#20917;&#19979;&#30340;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#26597;&#35810;&#20855;&#26377;&#26368;&#23567;LDM&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#21487;&#20197;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.09787</link><description>&lt;p&gt;
&#26597;&#35810;&#26131;&#20110;&#32763;&#36716;&#26679;&#26412;&#30340;&#28145;&#24230;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Querying Easily Flip-flopped Samples for Deep Active Learning. (arXiv:2401.09787v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#21363;&#26368;&#23567;&#19981;&#19968;&#33268;&#24230;&#37327;&#65288;LDM&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#22797;&#26434;&#20915;&#31574;&#36793;&#30028;&#24773;&#20917;&#19979;&#30340;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#26597;&#35810;&#20855;&#26377;&#26368;&#23567;LDM&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#21487;&#20197;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#36890;&#36807;&#36873;&#25321;&#21644;&#26597;&#35810;&#26410;&#26631;&#35760;&#25968;&#25454;&#26469;&#25552;&#39640;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#19968;&#31181;&#26377;&#25928;&#30340;&#36873;&#25321;&#31574;&#30053;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#20197;&#35299;&#37322;&#20026;&#26679;&#26412;&#30340;&#20449;&#24687;&#37327;&#24230;&#37327;&#12290;&#26679;&#26412;&#21040;&#20915;&#31574;&#36793;&#30028;&#30340;&#36317;&#31163;&#26159;&#19968;&#31181;&#33258;&#28982;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#65292;&#20294;&#36890;&#24120;&#38590;&#20197;&#35745;&#31639;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22810;&#31867;&#20998;&#31867;&#20219;&#21153;&#20013;&#24418;&#25104;&#30340;&#22797;&#26434;&#20915;&#31574;&#36793;&#30028;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#26368;&#23567;&#19981;&#19968;&#33268;&#24230;&#37327;&#8221;&#65288;LDM&#65289;&#65292;&#23450;&#20041;&#20026;&#39044;&#27979;&#26631;&#31614;&#19981;&#19968;&#33268;&#30340;&#26368;&#23567;&#27010;&#29575;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;LDM&#30340;&#20272;&#35745;&#22120;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#26159;&#28176;&#36817;&#19968;&#33268;&#30340;&#12290;&#35813;&#20272;&#35745;&#22120;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21442;&#25968;&#25200;&#21160;&#36731;&#26494;&#23454;&#29616;&#22312;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#20351;&#29992;&#12290;&#22522;&#20110;LDM&#30340;&#20027;&#21160;&#23398;&#20064;&#36890;&#36807;&#26597;&#35810;&#20855;&#26377;&#26368;&#23567;LDM&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#26469;&#25191;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Active learning is a machine learning paradigm that aims to improve the performance of a model by strategically selecting and querying unlabeled data. One effective selection strategy is to base it on the model's predictive uncertainty, which can be interpreted as a measure of how informative a sample is. The sample's distance to the decision boundary is a natural measure of predictive uncertainty, but it is often intractable to compute, especially for complex decision boundaries formed in multiclass classification tasks. To address this issue, this paper proposes the {\it least disagree metric} (LDM), defined as the smallest probability of disagreement of the predicted label, and an estimator for LDM proven to be asymptotically consistent under mild assumptions. The estimator is computationally efficient and can be easily implemented for deep learning models using parameter perturbation. The LDM-based active learning is performed by querying unlabeled data with the smallest LDM. Exper
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65288;GLOW&#65289;&#65292;&#32467;&#21512;&#23494;&#24230;&#27604;&#29575;&#27169;&#22411;&#21644;&#20540;&#20989;&#25968;&#27169;&#22411;&#65292;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#29942;&#39048;&#38382;&#39064;&#65292;&#21363;&#22914;&#20309;&#22312;&#27809;&#26377;&#21021;&#22987;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#25910;&#38598;&#20855;&#26377;&#33391;&#22909;&#35206;&#30422;&#24230;&#30340;&#25506;&#32034;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2401.09681</link><description>&lt;p&gt;
&#21033;&#29992;&#23494;&#24230;&#27604;&#29575;&#36827;&#34892;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Harnessing Density Ratios for Online Reinforcement Learning. (arXiv:2401.09681v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09681
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65288;GLOW&#65289;&#65292;&#32467;&#21512;&#23494;&#24230;&#27604;&#29575;&#27169;&#22411;&#21644;&#20540;&#20989;&#25968;&#27169;&#22411;&#65292;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#35299;&#20915;&#20102;&#29942;&#39048;&#38382;&#39064;&#65292;&#21363;&#22914;&#20309;&#22312;&#27809;&#26377;&#21021;&#22987;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#25910;&#38598;&#20855;&#26377;&#33391;&#22909;&#35206;&#30422;&#24230;&#30340;&#25506;&#32034;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#21457;&#23637;&#26041;&#21521;&#19968;&#30452;&#26159;&#24179;&#34892;&#30340;&#65292;&#20294;&#23427;&#20204;&#24320;&#22987;&#26174;&#31034;&#20986;&#21487;&#33021;&#32479;&#19968;&#30340;&#36857;&#35937;&#65292;&#20854;&#20013;&#19968;&#20010;&#29615;&#22659;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;&#25216;&#26415;&#36890;&#24120;&#22312;&#21478;&#19968;&#20010;&#29615;&#22659;&#20013;&#20855;&#26377;&#33258;&#28982;&#30340;&#23545;&#24212;&#29289;&#12290;&#28982;&#32780;&#65292;&#23494;&#24230;&#27604;&#29575;&#24314;&#27169;&#30340;&#27010;&#24565;&#65292;&#36825;&#26159;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26032;&#20852;&#33539;&#24335;&#65292;&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#24456;&#23569;&#20986;&#29616;&#65292;&#20063;&#35768;&#26377;&#20805;&#36275;&#30340;&#29702;&#30001;&#65306;&#23494;&#24230;&#27604;&#29575;&#30340;&#23384;&#22312;&#21644;&#26377;&#30028;&#24615;&#20381;&#36182;&#20110;&#20855;&#26377;&#33391;&#22909;&#35206;&#30422;&#24230;&#30340;&#25506;&#32034;&#24615;&#25968;&#25454;&#38598;&#30340;&#35775;&#38382;&#24615;&#65292;&#20294;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26680;&#24515;&#25361;&#25112;&#26159;&#22312;&#27809;&#26377;&#21021;&#22987;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#25910;&#38598;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126; - &#20063;&#35768;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159; - &#22522;&#20110;&#23494;&#24230;&#27604;&#29575;&#30340;&#31639;&#27861;&#20855;&#26377;&#22312;&#32447;&#23545;&#24212;&#29289;&#12290;&#20551;&#23450;&#21482;&#23384;&#22312;&#20855;&#26377;&#33391;&#22909;&#35206;&#30422;&#24230;&#30340;&#25506;&#32034;&#24615;&#20998;&#24067;&#65292;&#21363;&#32467;&#26500;&#26465;&#20214;&#24050;&#30693;&#20026;coverability&#65288;Xie&#31561;&#65292;2023&#65289;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65288;GLOW&#65289;&#65292;&#23427;&#21033;&#29992;&#23494;&#24230;&#27604;&#29575;&#21487;&#23454;&#29616;&#24615;&#21644;&#20540;&#20989;&#25968;&#21487;&#23454;&#29616;&#24615;&#26469;&#36827;&#34892;&#39640;&#25928;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
The theories of offline and online reinforcement learning, despite having evolved in parallel, have begun to show signs of the possibility for a unification, with algorithms and analysis techniques for one setting often having natural counterparts in the other. However, the notion of density ratio modeling, an emerging paradigm in offline RL, has been largely absent from online RL, perhaps for good reason: the very existence and boundedness of density ratios relies on access to an exploratory dataset with good coverage, but the core challenge in online RL is to collect such a dataset without having one to start. In this work we show -- perhaps surprisingly -- that density ratio-based algorithms have online counterparts. Assuming only the existence of an exploratory distribution with good coverage, a structural condition known as coverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses density ratio realizability and value function realizability to perform sample-effici
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20010;&#23616;&#37096;&#32447;&#24615;&#20998;&#31867;&#22120;&#32452;&#21512;&#30340;&#26032;&#22411;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#25552;&#20379;&#20102;&#21487;&#25193;&#23637;&#30340;&#27867;&#21270;&#22810;&#26680;&#23398;&#20064;&#35757;&#32451;&#31639;&#27861;&#65292;&#22635;&#34917;&#20102;&#39640;&#20934;&#30830;&#24615;&#20294;&#32531;&#24930;&#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21644;&#24555;&#36895;&#20294;&#20302;&#20934;&#30830;&#24615;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2401.09629</link><description>&lt;p&gt;
&#22810;&#20010;&#23616;&#37096;&#32447;&#24615;&#26680;&#26426;&#22120;
&lt;/p&gt;
&lt;p&gt;
Multiple Locally Linear Kernel Machines. (arXiv:2401.09629v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20010;&#23616;&#37096;&#32447;&#24615;&#20998;&#31867;&#22120;&#32452;&#21512;&#30340;&#26032;&#22411;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#65292;&#25552;&#20379;&#20102;&#21487;&#25193;&#23637;&#30340;&#27867;&#21270;&#22810;&#26680;&#23398;&#20064;&#35757;&#32451;&#31639;&#27861;&#65292;&#22635;&#34917;&#20102;&#39640;&#20934;&#30830;&#24615;&#20294;&#32531;&#24930;&#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21644;&#24555;&#36895;&#20294;&#20302;&#20934;&#30830;&#24615;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20010;&#23616;&#37096;&#32447;&#24615;&#20998;&#31867;&#22120;&#32452;&#21512;&#30340;&#26032;&#22411;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#20010;$l_1$&#22810;&#26680;&#23398;&#20064;&#38382;&#39064;&#65292;&#20351;&#29992;&#35768;&#22810;&#23616;&#37096;&#32447;&#24615;&#26680;&#12290;&#30001;&#20110;&#36825;&#26679;&#30340;&#26680;&#20989;&#25968;&#25968;&#37327;&#24222;&#22823;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#27867;&#21270;&#22810;&#26680;&#23398;&#20064;&#35757;&#32451;&#31639;&#27861;&#26469;&#22788;&#29702;&#27969;&#24335;&#26680;&#20989;&#25968;&#12290;&#22312;&#25512;&#26029;&#26102;&#38388;&#26041;&#38754;&#65292;&#24471;&#21040;&#30340;&#20998;&#31867;&#22120;&#22635;&#34917;&#20102;&#39640;&#20934;&#30830;&#24615;&#20294;&#32531;&#24930;&#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#65288;&#22914;&#20256;&#32479;&#30340;&#22810;&#26680;&#23398;&#20064;&#65289;&#21644;&#24555;&#36895;&#20294;&#20302;&#20934;&#30830;&#24615;&#30340;&#32447;&#24615;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose a new non-linear classifier based on a combination of locally linear classifiers. A well known optimization formulation is given as we cast the problem in a $\ell_1$ Multiple Kernel Learning (MKL) problem using many locally linear kernels. Since the number of such kernels is huge, we provide a scalable generic MKL training algorithm handling streaming kernels. With respect to the inference time, the resulting classifier fits the gap between high accuracy but slow non-linear classifiers (such as classical MKL) and fast but low accuracy linear classifiers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22522;&#20110;&#26641;&#30340;&#25554;&#34917;&#26041;&#27861;&#20316;&#20026;MICE PMM&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#36827;&#34892;&#25512;&#29702;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#26641;&#30340;&#25554;&#34917;&#26041;&#27861;&#23545;&#31995;&#25968;&#20272;&#35745;&#12289;&#31867;&#22411;I&#35823;&#24046;&#21644;&#21151;&#25928;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.09602</link><description>&lt;p&gt;
&#35780;&#20272;&#22522;&#20110;&#26641;&#30340;&#25554;&#34917;&#26041;&#27861;&#20316;&#20026;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#29992;&#20110;&#32472;&#21046;&#25512;&#29702;&#30340;MICE PMM&#30340;&#26367;&#20195;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Evaluating tree-based imputation methods as an alternative to MICE PMM for drawing inference in empirical studies. (arXiv:2401.09602v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09602
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22522;&#20110;&#26641;&#30340;&#25554;&#34917;&#26041;&#27861;&#20316;&#20026;MICE PMM&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#36827;&#34892;&#25512;&#29702;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#26641;&#30340;&#25554;&#34917;&#26041;&#27861;&#23545;&#31995;&#25968;&#20272;&#35745;&#12289;&#31867;&#22411;I&#35823;&#24046;&#21644;&#21151;&#25928;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#26159;&#32479;&#35745;&#20998;&#26512;&#20013;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#36890;&#24120;&#36890;&#36807;&#25554;&#34917;&#31243;&#24207;&#26469;&#35299;&#20915;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#26377;&#25928;&#24615;&#23545;&#23427;&#20204;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#30340;&#24212;&#29992;&#38750;&#24120;&#37325;&#35201;&#12290;&#23613;&#31649;&#22810;&#37325;&#38142;&#24335;&#26041;&#31243;&#25554;&#34917;&#65288;MICE&#65289;&#19982;&#39044;&#27979;&#22343;&#20540;&#21305;&#37197;&#65288;PMM&#65289;&#34987;&#35748;&#20026;&#26159;&#31038;&#20250;&#31185;&#23398;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#20294;&#22797;&#26434;&#25968;&#25454;&#38598;&#30340;&#22686;&#21152;&#21487;&#33021;&#38656;&#35201;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26356;&#20808;&#36827;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#65292;&#22522;&#20110;&#26641;&#30340;&#25554;&#34917;&#26041;&#27861;&#24050;&#32463;&#25104;&#20026;&#31454;&#20105;&#28608;&#28872;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24615;&#33021;&#21644;&#26377;&#25928;&#24615;&#24182;&#19981;&#23436;&#20840;&#20102;&#35299;&#65292;&#23588;&#20854;&#26159;&#19982;&#26631;&#20934;&#30340;MICE PMM&#30456;&#27604;&#12290;&#36825;&#22312;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#25512;&#29702;&#23588;&#20026;&#26126;&#26174;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#21508;&#31181;&#25554;&#34917;&#26041;&#27861;&#23545;&#31995;&#25968;&#20272;&#35745;&#12289;&#31867;&#22411;I&#35823;&#24046;&#21644;&#21151;&#25928;&#30340;&#24433;&#21709;&#65292;&#20197;&#33719;&#24471;&#21487;&#20197;&#24110;&#21161;&#23454;&#35777;&#30740;&#31350;&#20154;&#21592;&#26356;&#26377;&#25928;&#22320;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;MI&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#24182;&#23545;&#22810;&#37325;&#25554;&#34917;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dealing with missing data is an important problem in statistical analysis that is often addressed with imputation procedures. The performance and validity of such methods are of great importance for their application in empirical studies. While the prevailing method of Multiple Imputation by Chained Equations (MICE) with Predictive Mean Matching (PMM) is considered standard in the social science literature, the increase in complex datasets may require more advanced approaches based on machine learning. In particular, tree-based imputation methods have emerged as very competitive approaches. However, the performance and validity are not completely understood, particularly compared to the standard MICE PMM. This is especially true for inference in linear models. In this study, we investigate the impact of various imputation methods on coefficient estimation, Type I error, and power, to gain insights that can help empirical researchers deal with missingness more effectively. We explore MI
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#33258;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#23398;&#20064;&#21151;&#33021;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#34920;&#31034;&#65292;&#24182;&#36991;&#20813;&#20102;&#39044;&#22788;&#29702;&#30340;&#38656;&#35201;&#12290;</title><link>http://arxiv.org/abs/2401.09499</link><description>&lt;p&gt;
&#21151;&#33021;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#24179;&#28369;&#21644;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Functional Autoencoder for Smoothing and Representation Learning. (arXiv:2401.09499v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#33258;&#32534;&#30721;&#22120;&#65292;&#29992;&#20110;&#23398;&#20064;&#21151;&#33021;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#34920;&#31034;&#65292;&#24182;&#36991;&#20813;&#20102;&#39044;&#22788;&#29702;&#30340;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#20013;&#24120;&#29992;&#30340;&#27969;&#31243;&#26159;&#23558;&#31163;&#25955;&#35266;&#27979;&#25968;&#25454;&#36716;&#25442;&#20026;&#24179;&#28369;&#20989;&#25968;&#65292;&#28982;&#21518;&#36890;&#36807;&#19968;&#20010;&#26377;&#38480;&#32500;&#24230;&#30340;&#31995;&#25968;&#21521;&#37327;&#26469;&#34920;&#31034;&#36825;&#20123;&#20989;&#25968;&#20197;&#24635;&#32467;&#20449;&#24687;&#12290;&#29616;&#26377;&#30340;&#25968;&#25454;&#24179;&#28369;&#21644;&#38477;&#32500;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#23398;&#20064;&#32447;&#24615;&#26144;&#23556;&#65292;&#20294;&#20165;&#23398;&#20064;&#32447;&#24615;&#34920;&#31034;&#21487;&#33021;&#19981;&#36275;&#22815;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21151;&#33021;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#34920;&#31034;&#65292;&#32780;&#26080;&#38656;&#39044;&#22788;&#29702;&#12290;&#25105;&#20204;&#35774;&#35745;&#32534;&#30721;&#22120;&#37319;&#29992;&#25237;&#24433;&#23618;&#65292;&#35745;&#31639;&#21151;&#33021;&#25968;&#25454;&#21644;&#35266;&#23519;&#26102;&#38388;&#25139;&#19978;&#30340;&#21151;&#33021;&#26435;&#37325;&#30340;&#21152;&#26435;&#20869;&#31215;&#65292;&#35299;&#30721;&#22120;&#24212;&#29992;&#24674;&#22797;&#23618;&#65292;&#20351;&#29992;&#19968;&#32452;&#39044;&#20808;&#30830;&#23450;&#30340;&#26377;&#38480;&#32500;&#24230;&#21521;&#37327;&#23558;&#20174;&#21151;&#33021;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#21521;&#37327;&#26144;&#23556;&#22238;&#21151;&#33021;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common pipeline in functional data analysis is to first convert the discretely observed data to smooth functions, and then represent the functions by a finite-dimensional vector of coefficients summarizing the information. Existing methods for data smoothing and dimensional reduction mainly focus on learning the linear mappings from the data space to the representation space, however, learning only the linear representations may not be sufficient. In this study, we propose to learn the nonlinear representations of functional data using neural network autoencoders designed to process data in the form it is usually collected without the need of preprocessing. We design the encoder to employ a projection layer computing the weighted inner product of the functional data and functional weights over the observed timestamp, and the decoder to apply a recovery layer that maps the finite-dimensional vector extracted from the functional data back to functional space using a set of predetermine
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#20302;&#25104;&#26412;&#28909;&#32447;&#39118;&#36895;&#35745;&#30001;&#20110;&#27668;&#28201;&#21464;&#21270;&#32780;&#23548;&#33268;&#30340;&#31934;&#24230;&#25439;&#22833;&#38382;&#39064;&#65292;&#37319;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#36827;&#34892;&#27010;&#29575;&#26657;&#20934;&#65292;&#24182;&#22312;&#23454;&#39564;&#39564;&#35777;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#22312;&#23454;&#38469;&#20351;&#29992;&#21069;&#36827;&#34892;&#26657;&#20934;&#65292;&#21487;&#20197;&#20272;&#35745;&#20856;&#22411;&#29615;&#22659;&#28201;&#24230;&#19979;&#30340;&#39118;&#36895;&#65292;&#24182;&#25552;&#20379;&#27599;&#20010;&#36895;&#24230;&#27979;&#37327;&#30340;&#21487;&#38752;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.09492</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#23454;&#29616;&#28909;&#32447;&#39118;&#36895;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#33258;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian Process Regression. (arXiv:2401.09492v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#20302;&#25104;&#26412;&#28909;&#32447;&#39118;&#36895;&#35745;&#30001;&#20110;&#27668;&#28201;&#21464;&#21270;&#32780;&#23548;&#33268;&#30340;&#31934;&#24230;&#25439;&#22833;&#38382;&#39064;&#65292;&#37319;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#36827;&#34892;&#27010;&#29575;&#26657;&#20934;&#65292;&#24182;&#22312;&#23454;&#39564;&#39564;&#35777;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#22312;&#23454;&#38469;&#20351;&#29992;&#21069;&#36827;&#34892;&#26657;&#20934;&#65292;&#21487;&#20197;&#20272;&#35745;&#20856;&#22411;&#29615;&#22659;&#28201;&#24230;&#19979;&#30340;&#39118;&#36895;&#65292;&#24182;&#25552;&#20379;&#27599;&#20010;&#36895;&#24230;&#27979;&#37327;&#30340;&#21487;&#38752;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20811;&#26381;&#20302;&#25104;&#26412;&#28909;&#32447;&#39118;&#36895;&#35745;&#30001;&#20110;&#27668;&#28201;&#21464;&#21270;&#32780;&#23548;&#33268;&#30340;&#31934;&#24230;&#25439;&#22833;&#65292;&#26412;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#36827;&#34892;&#27010;&#29575;&#26657;&#20934;&#12290;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#21644;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#26088;&#22312;&#26681;&#25454;&#19968;&#20010;&#25110;&#22810;&#20010;&#24050;&#30693;&#30340;&#36755;&#20837;&#21464;&#37327;&#39044;&#27979;&#26410;&#30693;&#30340;&#30446;&#26631;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#39564;&#35777;&#65292;&#22312;&#25512;&#26029;&#23454;&#38469;&#39118;&#36895;&#20540;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;&#36890;&#36807;&#22312;&#23454;&#38469;&#20351;&#29992;&#21069;&#65292;&#23545;&#28909;&#32447;&#39118;&#36895;&#35745;&#36827;&#34892;&#32771;&#34385;&#27668;&#28201;&#30340;&#26657;&#20934;&#65292;&#21487;&#20197;&#20272;&#35745;&#20856;&#22411;&#29615;&#22659;&#28201;&#24230;&#33539;&#22260;&#20869;&#30340;&#39118;&#36895;&#65292;&#24182;&#19988;&#20026;&#27599;&#20010;&#36895;&#24230;&#27979;&#37327;&#20540;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expensive ultrasonic anemometers are usually required to measure wind speed accurately. The aim of this work is to overcome the loss of accuracy of a low cost hot-wire anemometer caused by the changes of air temperature, by means of a probabilistic calibration using Gaussian Process Regression. Gaussian Process Regression is a non-parametric, Bayesian, and supervised learning method designed to make predictions of an unknown target variable as a function of one or more known input variables. Our approach is validated against real datasets, obtaining a good performance in inferring the actual wind speed values. By performing, before its real use in the field, a calibration of the hot-wire anemometer taking into account air temperature, permits that the wind speed can be estimated for the typical range of ambient temperatures, including a grounded uncertainty estimation for each speed measure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#19968;&#32423;&#21407;&#29702;&#20986;&#21457;&#65292;&#25512;&#23548;&#20986;&#20102;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#30693;&#35782;&#36861;&#36394;&#30340;&#21442;&#25968;&#31354;&#38388;&#19978;&#26045;&#21152;&#30340;&#32422;&#26463;&#65292;&#35299;&#20915;&#20102;&#30446;&#21069;&#31639;&#27861;&#20013;&#23384;&#22312;&#30340;&#19968;&#31995;&#21015;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.09456</link><description>&lt;p&gt;
&#20174;&#19968;&#32423;&#21407;&#29702;&#20986;&#21457;&#30340;&#36125;&#21494;&#26031;&#30693;&#35782;&#36861;&#36394;&#30340;&#21442;&#25968;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Parametric Constraints for Bayesian Knowledge Tracing from First Principles. (arXiv:2401.09456v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#19968;&#32423;&#21407;&#29702;&#20986;&#21457;&#65292;&#25512;&#23548;&#20986;&#20102;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#30693;&#35782;&#36861;&#36394;&#30340;&#21442;&#25968;&#31354;&#38388;&#19978;&#26045;&#21152;&#30340;&#32422;&#26463;&#65292;&#35299;&#20915;&#20102;&#30446;&#21069;&#31639;&#27861;&#20013;&#23384;&#22312;&#30340;&#19968;&#31995;&#21015;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#30693;&#35782;&#36861;&#36394;(BKT)&#26159;&#19968;&#20010;&#23398;&#20064;&#32773;&#25484;&#25569;&#29366;&#24577;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#23545;&#24212;&#19968;&#20010;&#30693;&#35782;&#32452;&#20214;&#12290;&#23427;&#23558;&#23398;&#20064;&#32773;&#30340;&#25484;&#25569;&#29366;&#24577;&#35270;&#20026;&#19968;&#20010;&#8220;&#38544;&#34255;&#8221;&#30340;&#25110;&#28508;&#22312;&#30340;&#20108;&#20803;&#21464;&#37327;&#65292;&#24182;&#26681;&#25454;&#23398;&#20064;&#32773;&#21709;&#24212;&#30340;&#27491;&#30830;&#24615;&#26356;&#26032;&#27492;&#29366;&#24577;&#65292;&#20351;&#29992;&#20195;&#34920;&#29366;&#24577;&#36716;&#25442;&#27010;&#29575;&#30340;&#21442;&#25968;&#12290;BKT&#36890;&#24120;&#34987;&#34920;&#31034;&#20026;&#19968;&#20010;&#38544;&#34255;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#32780;&#26399;&#26395;&#26368;&#22823;&#21270;(EM)&#31639;&#27861;&#29992;&#20110;&#25512;&#26029;&#36825;&#20123;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#35813;&#31639;&#27861;&#21487;&#33021;&#38754;&#20020;&#22810;&#32452;&#21487;&#34892;&#30340;&#21442;&#25968;&#38598;&#12289;&#38519;&#20837;&#23616;&#37096;&#26368;&#23567;&#20540;&#12289;&#20135;&#29983;&#36864;&#21270;&#30340;&#21442;&#25968;&#20540;&#20197;&#21450;&#25311;&#21512;&#36807;&#31243;&#20013;&#30340;&#39640;&#35745;&#31639;&#25104;&#26412;&#31561;&#38382;&#39064;&#12290;&#26412;&#25991;&#37319;&#29992;&#8220;&#20174;&#19968;&#32423;&#21407;&#29702;&#8221;&#26041;&#27861;&#65292;&#25512;&#23548;&#20986;&#21487;&#20197;&#23545;BKT&#21442;&#25968;&#31354;&#38388;&#26045;&#21152;&#30340;&#32422;&#26463;&#12290;&#20174;&#27010;&#29575;&#30340;&#22522;&#26412;&#25968;&#23398;&#30495;&#29702;&#20986;&#21457;&#65292;&#36880;&#27493;&#24314;&#31435;&#23545;&#20110;BKT&#21442;&#25968;&#22312;&#30495;&#23454;&#31995;&#32479;&#20013;&#25152;&#26399;&#26395;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's state of mastery corresponding to a knowledge component. It considers the learner's state of mastery as a "hidden" or latent binary variable and updates this state based on the observed correctness of the learner's response using parameters that represent transition probabilities between states. BKT is often represented as a Hidden Markov Model and the Expectation-Maximization (EM) algorithm is used to infer these parameters. However, this algorithm can suffer from several issues including producing multiple viable sets of parameters, settling into a local minima, producing degenerate parameter values, and a high computational cost during fitting. This paper takes a "from first principles" approach to deriving constraints that can be imposed on the BKT parameter space. Starting from the basic mathematical truths of probability and building up to the behaviors expected of the BKT parameters in real systems, this pa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#38543;&#26426;&#38598;&#21512;&#29702;&#35770;&#26410;&#26469;&#30340;&#21457;&#23637;&#35758;&#31243;&#65292;&#21253;&#25324;&#25512;&#24191;&#32479;&#35745;&#25512;&#29702;&#12289;&#21457;&#23637;&#20960;&#20309;&#26041;&#27861;&#12289;&#24212;&#29992;&#20110;&#27668;&#20505;&#21464;&#21270;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2401.09435</link><description>&lt;p&gt;
&#38543;&#26426;&#38598;&#21512;&#25512;&#29702;&#65306;&#26410;&#26469;&#24037;&#20316;&#30340;&#35758;&#31243;
&lt;/p&gt;
&lt;p&gt;
Reasoning with random sets: An agenda for the future. (arXiv:2401.09435v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#38543;&#26426;&#38598;&#21512;&#29702;&#35770;&#26410;&#26469;&#30340;&#21457;&#23637;&#35758;&#31243;&#65292;&#21253;&#25324;&#25512;&#24191;&#32479;&#35745;&#25512;&#29702;&#12289;&#21457;&#23637;&#20960;&#20309;&#26041;&#27861;&#12289;&#24212;&#29992;&#20110;&#27668;&#20505;&#21464;&#21270;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#38543;&#26426;&#38598;&#21512;&#21644;&#20449;&#24565;&#20989;&#25968;&#29702;&#35770;&#26410;&#26469;&#24037;&#20316;&#30340;&#28508;&#22312;&#35758;&#31243;&#65292;&#28041;&#21450;&#19968;&#20123;&#20851;&#38190;&#38382;&#39064;&#65306;&#21457;&#23637;&#19968;&#20010;&#23436;&#25972;&#30340;&#32479;&#35745;&#25512;&#29702;&#19982;&#38543;&#26426;&#38598;&#21512;&#30340;&#29702;&#35770;&#65292;&#21253;&#25324;&#36923;&#36753;&#22238;&#24402;&#21644;&#32463;&#20856;&#27010;&#29575;&#27861;&#21017;&#30340;&#25512;&#24191;&#65307;&#36827;&#19968;&#27493;&#21457;&#23637;&#22522;&#20110;&#20960;&#20309;&#26041;&#27861;&#30340;&#19981;&#30830;&#23450;&#24615;&#29702;&#35770;&#65292;&#21253;&#25324;&#19968;&#33324;&#38543;&#26426;&#38598;&#21512;&#12289;&#26356;&#24191;&#27867;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#21644;&#26367;&#20195;&#30340;&#20960;&#20309;&#34920;&#31034;&#26041;&#27861;&#65307;&#23558;&#36825;&#19968;&#20840;&#26032;&#29702;&#35770;&#24212;&#29992;&#20110;&#27668;&#20505;&#21464;&#21270;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#31561;&#39640;&#24433;&#21709;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we discuss a potential agenda for future work in the theory of random sets and belief functions, touching upon a number of focal issues: the development of a fully-fledged theory of statistical reasoning with random sets, including the generalisation of logistic regression and of the classical laws of probability; the further development of the geometric approach to uncertainty, to include general random sets, a wider range of uncertainty measures and alternative geometric representations; the application of this new theory to high-impact areas such as climate change, machine learning and statistical learning theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#36825;&#20123;&#26041;&#27861;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#65292;&#24182;&#20855;&#26377;&#23545;&#22240;&#26524;&#20851;&#31995;&#39034;&#24207;&#30340;&#29305;&#27530;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2401.07231</link><description>&lt;p&gt;
&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#21457;&#29616;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#21450;&#20854;&#22312;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Use of Prior Knowledge to Discover Causal Additive Models with Unobserved Variables and its Application to Time Series Data. (arXiv:2401.07231v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07231
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#65292;&#24182;&#25193;&#23637;&#20102;&#36825;&#20123;&#26041;&#27861;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#36825;&#20123;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#65292;&#24182;&#20855;&#26377;&#23545;&#22240;&#26524;&#20851;&#31995;&#39034;&#24207;&#30340;&#29305;&#27530;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#29992;&#20110;&#20855;&#26377;&#26410;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#21487;&#21152;&#27169;&#22411;&#65288;CAM-UV&#65289;&#30340;&#26041;&#27861;&#12290;CAM-UV&#20551;&#35774;&#22240;&#26524;&#20989;&#25968;&#37319;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#30340;&#24418;&#24335;&#65292;&#24182;&#23384;&#22312;&#28508;&#22312;&#30340;&#28151;&#28102;&#21464;&#37327;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#36827;&#34892;&#39640;&#25928;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#19982;&#20854;&#20182;&#29616;&#26377;&#30340;&#22240;&#26524;&#20989;&#25968;&#27169;&#22411;&#19981;&#21516;&#65292;&#21407;&#22987;&#30340;CAM-UV&#31639;&#27861;&#19981;&#23547;&#27714;&#35266;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#39034;&#24207;&#65292;&#32780;&#26159;&#26088;&#22312;&#30830;&#23450;&#27599;&#20010;&#35266;&#27979;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#20013;&#25552;&#20986;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#65292;&#20363;&#22914;&#29702;&#35299;&#26576;&#20123;&#21464;&#37327;&#19981;&#33021;&#25104;&#20026;&#29305;&#23450;&#21464;&#37327;&#30340;&#21407;&#22240;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#34701;&#20837;&#22240;&#26524;&#22312;&#26102;&#38388;&#19978;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#25105;&#20204;&#23558;&#31532;&#19968;&#20010;&#31639;&#27861;&#25193;&#23637;&#20026;&#31532;&#20108;&#31181;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#21457;&#29616;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#31532;&#19968;&#20010;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes two methods for causal additive models with unobserved variables (CAM-UV). CAM-UV assumes that the causal functions take the form of generalized additive models and that latent confounders are present. First, we propose a method that leverages prior knowledge for efficient causal discovery. Then, we propose an extension of this method for inferring causality in time series data. The original CAM-UV algorithm differs from other existing causal function models in that it does not seek the causal order between observed variables, but rather aims to identify the causes for each observed variable. Therefore, the first proposed method in this paper utilizes prior knowledge, such as understanding that certain variables cannot be causes of specific others. Moreover, by incorporating the prior knowledge that causes precedes their effects in time, we extend the first algorithm to the second method for causal discovery in time series data. We validate the first proposed method
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#27867;&#20989;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#20855;&#26377;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2312.16360</link><description>&lt;p&gt;
&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#21450;&#20854;&#26102;&#31354;&#31163;&#25955;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mean-field underdamped Langevin dynamics and its spacetime discretization. (arXiv:2312.16360v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.16360
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#38750;&#32447;&#24615;&#27867;&#20989;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#20855;&#26377;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;N&#31890;&#23376;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#19968;&#31867;&#38750;&#32447;&#24615;&#27867;&#20989;&#12290;&#36825;&#31181;&#20844;&#24335;&#30340;&#38382;&#39064;&#31034;&#20363;&#21253;&#25324;&#35757;&#32451;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#12289;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26368;&#23567;&#21270;&#21644;&#26680;&#26031;&#22374;&#24046;&#24322;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#22343;&#22330;&#27424;&#38459;&#23612;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30340;&#26032;&#39062;&#26102;&#31354;&#31163;&#25955;&#21270;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#24555;&#36895;&#28151;&#21512;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20840;&#23616;&#25910;&#25947;&#65292;&#22635;&#34917;&#20102;&#21160;&#21147;&#23398;&#19982;&#23454;&#38469;&#23454;&#26045;&#20043;&#38388;&#30340;&#29702;&#35770;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method called the N-particle underdamped Langevin algorithm for optimizing a special class of non-linear functionals defined over the space of probability measures. Examples of problems with this formulation include training mean-field neural networks, maximum mean discrepancy minimization and kernel Stein discrepancy minimization. Our algorithm is based on a novel spacetime discretization of the mean-field underdamped Langevin dynamics, for which we provide a new, fast mixing guarantee. In addition, we demonstrate that our algorithm converges globally in total variation distance, bridging the theoretical gap between the dynamics and its practical implementation.
&lt;/p&gt;</description></item><item><title>&#36870;&#21521;&#35782;&#21035; (INVERT) &#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#25509;&#23398;&#20064;&#21040;&#30340;&#31070;&#32463;&#34920;&#31034;&#19982;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#65292;&#23454;&#29616;&#20102;&#23545;&#31070;&#32463;&#34920;&#31034;&#30340;&#26631;&#35760;&#24182;&#25552;&#20379;&#20102;&#32479;&#35745;&#26174;&#33879;&#24615;&#35780;&#20272;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2311.13594</link><description>&lt;p&gt;
&#22312;&#36870;&#21521;&#35782;&#21035;&#20013;&#26631;&#35760;&#31070;&#32463;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Labeling Neural Representations with Inverse Recognition. (arXiv:2311.13594v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.13594
&lt;/p&gt;
&lt;p&gt;
&#36870;&#21521;&#35782;&#21035; (INVERT) &#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#25509;&#23398;&#20064;&#21040;&#30340;&#31070;&#32463;&#34920;&#31034;&#19982;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#65292;&#23454;&#29616;&#20102;&#23545;&#31070;&#32463;&#34920;&#31034;&#30340;&#26631;&#35760;&#24182;&#25552;&#20379;&#20102;&#32479;&#35745;&#26174;&#33879;&#24615;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#22312;&#23398;&#20064;&#22797;&#26434;&#30340;&#23618;&#32423;&#25968;&#25454;&#34920;&#31034;&#26041;&#38754;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#36825;&#20123;&#34920;&#31034;&#30340;&#24615;&#36136;&#20173;&#28982;&#22823;&#37096;&#20998;&#26410;&#30693;&#12290;&#29616;&#26377;&#30340;&#20840;&#23616;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#22914;&#32593;&#32476;&#35299;&#21078;(Network Dissection)&#65292;&#23384;&#22312;&#35832;&#22810;&#38480;&#21046;&#65292;&#22914;&#20381;&#36182;&#20998;&#21106;&#36974;&#32617;&#12289;&#32570;&#20047;&#32479;&#35745;&#26174;&#33879;&#24615;&#26816;&#39564;&#21644;&#39640;&#35745;&#31639;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Inverse Recognition (INVERT)&#26041;&#27861;&#65292;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20854;&#21306;&#20998;&#36825;&#20123;&#27010;&#24565;&#30340;&#33021;&#21147;&#65292;&#23558;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#19982;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#30456;&#36830;&#25509;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;INVERT&#33021;&#22815;&#22788;&#29702;&#19981;&#21516;&#31867;&#22411;&#30340;&#31070;&#32463;&#20803;&#65292;&#35745;&#31639;&#22797;&#26434;&#24230;&#26356;&#20302;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#20998;&#21106;&#36974;&#32617;&#30340;&#21487;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;INVERT&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#24230;&#37327;&#65292;&#35780;&#20272;&#34920;&#31034;&#21644;&#20854;&#30456;&#24212;&#35299;&#37322;&#20043;&#38388;&#30340;&#23545;&#40784;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;INVERT&#30340;&#24212;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks (DNNs) demonstrate remarkable capabilities in learning complex hierarchical data representations, but the nature of these representations remains largely unknown. Existing global explainability methods, such as Network Dissection, face limitations such as reliance on segmentation masks, lack of statistical significance testing, and high computational demands. We propose Inverse Recognition (INVERT), a scalable approach for connecting learned representations with human-understandable concepts by leveraging their capacity to discriminate between these concepts. In contrast to prior work, INVERT is capable of handling diverse types of neurons, exhibits less computational complexity, and does not rely on the availability of segmentation masks. Moreover, INVERT provides an interpretable metric assessing the alignment between the representation and its corresponding explanation and delivering a measure of statistical significance. We demonstrate the applicability of INVE
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;Lipschitz&#24120;&#25968;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19978;&#19979;&#30028;&#65292;&#24182;&#21305;&#37197;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2311.01356</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;
&lt;/p&gt;
&lt;p&gt;
On the Lipschitz constant of random neural networks. (arXiv:2311.01356v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;Lipschitz&#24120;&#25968;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19978;&#19979;&#30028;&#65292;&#24182;&#21305;&#37197;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#35777;&#30740;&#31350;&#24191;&#27867;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#23545;&#36755;&#20837;&#30340;&#24494;&#23567;&#23545;&#25239;&#24615;&#25200;&#21160;&#38750;&#24120;&#25935;&#24863;&#12290;&#36825;&#20123;&#25152;&#35859;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26368;&#22351;&#24773;&#20917;&#40065;&#26834;&#24615;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#26469;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#20010;&#37327;&#30340;&#29702;&#35770;&#32467;&#26524;&#22312;&#25991;&#29486;&#20013;&#20165;&#26377;&#23569;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#21363;&#36873;&#25321;&#38543;&#26426;&#26435;&#37325;&#24182;&#37319;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#23558;Lipschitz&#24120;&#25968;&#21051;&#30011;&#21040;&#19968;&#20010;&#32477;&#23545;&#25968;&#20540;&#24120;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Lipschitz&#24120;&#25968;&#30340;&#19978;&#19979;&#30028;&#12290;&#36825;&#20123;&#30028;&#21305;&#37197;&#21040;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical studies have widely demonstrated that neural networks are highly sensitive to small, adversarial perturbations of the input. The worst-case robustness against these so-called adversarial examples can be quantified by the Lipschitz constant of the neural network. However, only few theoretical results regarding this quantity exist in the literature. In this paper, we initiate the study of the Lipschitz constant of random ReLU neural networks, i.e., neural networks whose weights are chosen at random and which employ the ReLU activation function. For shallow neural networks, we characterize the Lipschitz constant up to an absolute numerical constant. Moreover, we extend our analysis to deep neural networks of sufficiently large width where we prove upper and lower bounds for the Lipschitz constant. These bounds match up to a logarithmic factor that depends on the depth.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;LogEI&#20316;&#20026;&#19968;&#31867;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#33719;&#24471;&#20989;&#25968;&#65292;&#20855;&#26377;&#19982;&#20256;&#32479;&#30340;EI&#20989;&#25968;&#30456;&#21516;&#25110;&#36817;&#20284;&#30456;&#31561;&#30340;&#26368;&#20248;&#35299;&#65292;&#20294;&#25968;&#20540;&#19978;&#26356;&#23481;&#26131;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.20708</link><description>&lt;p&gt;
&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26399;&#26395;&#25913;&#36827;&#30340;&#24847;&#22806;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
Unexpected Improvements to Expected Improvement for Bayesian Optimization. (arXiv:2310.20708v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.20708
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;LogEI&#20316;&#20026;&#19968;&#31867;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#33719;&#24471;&#20989;&#25968;&#65292;&#20855;&#26377;&#19982;&#20256;&#32479;&#30340;EI&#20989;&#25968;&#30456;&#21516;&#25110;&#36817;&#20284;&#30456;&#31561;&#30340;&#26368;&#20248;&#35299;&#65292;&#20294;&#25968;&#20540;&#19978;&#26356;&#23481;&#26131;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#25913;&#36827;&#65288;EI&#65289;&#21487;&#20197;&#35828;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#26368;&#27969;&#34892;&#30340;&#33719;&#24471;&#20989;&#25968;&#65292;&#24182;&#19988;&#24050;&#32463;&#22312;&#24456;&#22810;&#25104;&#21151;&#30340;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24212;&#29992;&#12290;&#20294;&#26159;&#65292;EI&#30340;&#24615;&#33021;&#24448;&#24448;&#34987;&#19968;&#20123;&#26032;&#26041;&#27861;&#36229;&#36234;&#12290;&#23588;&#20854;&#26159;&#65292;EI&#21450;&#20854;&#21464;&#31181;&#22312;&#24182;&#34892;&#21644;&#22810;&#30446;&#26631;&#35774;&#32622;&#20013;&#24456;&#38590;&#36827;&#34892;&#20248;&#21270;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#33719;&#24471;&#20540;&#22312;&#35768;&#22810;&#21306;&#22495;&#20013;&#25968;&#20540;&#19978;&#21464;&#20026;&#38646;&#12290;&#24403;&#35266;&#27979;&#27425;&#25968;&#22686;&#21152;&#12289;&#25628;&#32034;&#31354;&#38388;&#30340;&#32500;&#24230;&#22686;&#21152;&#25110;&#32422;&#26463;&#26465;&#20214;&#30340;&#25968;&#37327;&#22686;&#21152;&#26102;&#65292;&#36825;&#31181;&#22256;&#38590;&#36890;&#24120;&#20250;&#22686;&#21152;&#65292;&#23548;&#33268;&#24615;&#33021;&#22312;&#25991;&#29486;&#20013;&#19981;&#19968;&#33268;&#19988;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#20122;&#20248;&#21270;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;LogEI&#65292;&#36825;&#26159;&#19968;&#31867;&#26032;&#30340;&#37319;&#26679;&#20989;&#25968;&#12290;&#19982;&#26631;&#20934;EI&#30456;&#27604;&#65292;&#36825;&#20123;LogEI&#20989;&#25968;&#30340;&#25104;&#21592;&#35201;&#20040;&#20855;&#26377;&#30456;&#21516;&#30340;&#26368;&#20248;&#35299;&#65292;&#35201;&#20040;&#20855;&#26377;&#36817;&#20284;&#30456;&#31561;&#30340;&#26368;&#20248;&#35299;&#65292;&#20294;&#25968;&#20540;&#19978;&#26356;&#23481;&#26131;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25968;&#20540;&#30149;&#24577;&#22312;&#8220;&#32463;&#20856;&#8221;&#20998;&#26512;EI&#12289;&#26399;&#26395;&#36229;&#20307;&#31215;&#25913;&#36827;&#65288;EHVI&#65289;&#20197;&#21450;&#23427;&#20204;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Expected Improvement (EI) is arguably the most popular acquisition function in Bayesian optimization and has found countless successful applications, but its performance is often exceeded by that of more recent methods. Notably, EI and its variants, including for the parallel and multi-objective settings, are challenging to optimize because their acquisition values vanish numerically in many regions. This difficulty generally increases as the number of observations, dimensionality of the search space, or the number of constraints grow, resulting in performance that is inconsistent across the literature and most often sub-optimal. Herein, we propose LogEI, a new family of acquisition functions whose members either have identical or approximately equal optima as their canonical counterparts, but are substantially easier to optimize numerically. We demonstrate that numerical pathologies manifest themselves in "classic" analytic EI, Expected Hypervolume Improvement (EHVI), as well as their
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18913</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#21435;&#38500;&#20559;&#35265;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27491;&#22312;&#25104;&#20026;&#21508;&#31181;&#35821;&#35328;&#20219;&#21153;&#30340;&#39318;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23481;&#37327;&#30340;&#22686;&#38271;&#65292;&#27169;&#22411;&#24456;&#23481;&#26131;&#20381;&#36182;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#21051;&#26495;&#21360;&#35937;&#25152;&#20135;&#29983;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#27169;&#22411;&#32452;&#20214;&#65292;&#24182;&#21457;&#29616;&#20013;&#19978;&#23618;&#21069;&#39304;&#23618;&#26368;&#23481;&#26131;&#20256;&#36882;&#20559;&#35265;&#12290;&#26681;&#25454;&#20998;&#26512;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#25237;&#24433;&#23558;&#36825;&#20123;&#23618;&#20056;&#20197;&#27169;&#22411;&#36827;&#34892;&#36866;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;DAMA&#36890;&#36807;&#21508;&#31181;&#24230;&#37327;&#25351;&#26631;&#26126;&#26174;&#20943;&#23569;&#20102;&#20559;&#35265;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#22312;&#21518;&#32493;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#20195;&#30721;&#65292;&#36890;&#36807;&#37325;&#26032;&#35757;&#32451;&#65292;&#20445;&#25345;&#20102;LLaMA&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21516;&#26102;&#20559;&#35265;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#20108;&#38454;&#30697;&#26465;&#20214;&#19979;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.03686</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#33719;&#24471;&#25193;&#25955;&#27169;&#22411;&#30340;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence Bounds for Diffusion Models via Stochastic Localization. (arXiv:2308.03686v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03686
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#20108;&#38454;&#30697;&#26465;&#20214;&#19979;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#20174;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#36817;&#20284;&#26679;&#26412;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#31181;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#22810;&#39033;&#24335;&#30028;&#38480;&#65292;&#20551;&#35774;$L^2$&#20934;&#30830;&#30340;&#24471;&#20998;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#24050;&#30693;&#30340;&#26368;&#20339;&#30028;&#38480;&#35201;&#20040;&#23545;&#25968;&#25454;&#32500;&#24230;&#26159;&#36229;&#32447;&#24615;&#30340;&#65292;&#35201;&#20040;&#38656;&#35201;&#24378;&#24179;&#28369;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#20551;&#35774;&#21482;&#38656;&#35201;&#25968;&#25454;&#20998;&#24067;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#25910;&#25947;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#23545;&#20110;&#25968;&#25454;&#32500;&#24230;&#26159;&#32447;&#24615;&#30340;&#65288;&#20056;&#20197;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25193;&#25955;&#27169;&#22411;&#26368;&#22810;&#38656;&#35201;$\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$&#27493;&#65292;&#23601;&#21487;&#20197;&#23558;&#24102;&#26377;&#26041;&#24046;&#20026;$\delta$&#30340;&#39640;&#26031;&#22122;&#22768;&#25439;&#22351;&#30340;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#22312;Kullback--Leibler&#25955;&#24230;&#19979;&#36817;&#20284;&#21040;$\varepsilon^2$&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#21069;&#20154;&#30340;Girsanov&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#20110;&#21453;&#21521;SD&#31163;&#25955;&#21270;&#35823;&#24046;&#30340;&#31934;&#32454;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;RKHS&#36924;&#36817;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20013;&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;&#20110;&#20219;&#24847;&#32534;&#30721;&#22120;&#65292;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#21319;&#21487;&#20197;&#25552;&#39640;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.00788</link><description>&lt;p&gt;
&#36890;&#36807;RKHS&#36924;&#36817;&#29702;&#35299;&#22522;&#20110;&#22686;&#24191;&#30340;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation. (arXiv:2306.00788v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;RKHS&#36924;&#36817;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20013;&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;&#20110;&#20219;&#24847;&#32534;&#30721;&#22120;&#65292;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#21319;&#21487;&#20197;&#25552;&#39640;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#26159;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#65288;&#22914;&#23545;&#27604;&#23398;&#20064;&#21644;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#65289;&#23454;&#29616;&#32463;&#39564;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#20043;&#19968;&#65292;&#20294;&#20854;&#22312;&#23398;&#20064;&#22909;&#30340;&#34920;&#31034;&#26041;&#38754;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#24314;&#31435;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#36924;&#36817;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#39030;&#37096;&#29305;&#24449;&#31354;&#38388;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#27934;&#23519;&#21147;&#23545;&#22522;&#20110;&#22686;&#24191;&#30340;&#39044;&#35757;&#32451;&#36827;&#34892;&#32479;&#35745;&#20998;&#26512;&#12290;&#25105;&#20204;&#20174;&#20445;&#25345;&#31561;&#36317;&#30340;&#23646;&#24615;&#20986;&#21457;&#65292;&#36825;&#26159;&#30001;&#22686;&#24378;&#32473;&#20986;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#20851;&#38190;&#20960;&#20309;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20027;&#35201;&#23450;&#29702;&#20026;&#20219;&#24847;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#25509;&#36817;&#32039;&#23494;&#30340;&#19978;&#38480;&#65292;&#29992;&#20110;&#20272;&#35745;&#36890;&#36807;&#22312;&#32534;&#30721;&#22120;&#20043;&#19978;&#25311;&#21512;&#32447;&#24615;&#25506;&#27979;&#22120;&#32780;&#20135;&#29983;&#30340;&#20272;&#35745;&#35823;&#24046;&#21644;&#32534;&#30721;&#22120;&#23398;&#20064;&#30340;RKHS&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#20027;&#35201;&#23450;&#29702;&#34920;&#26126;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;RKHS&#20989;&#25968;&#20219;&#24847;&#31934;&#30830;&#22320;&#36924;&#36817;&#22686;&#24191;&#20989;&#25968;&#12290;&#36825;&#20010;&#32467;&#26524;&#24847;&#21619;&#30528;&#65292;&#38543;&#30528;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#39640;&#65292;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#20063;&#20250;&#25552;&#39640;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Good data augmentation is one of the key factors that lead to the empirical success of self-supervised representation learning such as contrastive learning and masked language modeling, yet theoretical understanding of its role in learning good representations remains limited. Recent work has built the connection between self-supervised learning and approximating the top eigenspace of a graph Laplacian operator. Learning a linear probe on top of such features can naturally be connected to RKHS regression. In this work, we use this insight to perform a statistical analysis of augmentation-based pretraining. We start from the isometry property, a key geometric characterization of the target function given by the augmentation. Our first main theorem provides, for an arbitrary encoder, near tight bounds for both the estimation error incurred by fitting the linear probe on top of the encoder, and the approximation error entailed by the fitness of the RKHS the encoder learns. Our second main
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;BA&#31639;&#27861;&#30340;&#19968;&#31181;&#26032;&#30340;&#20462;&#25913;&#65292;&#36890;&#36807;&#35753;&#20056;&#25968;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36890;&#36807;&#19968;&#32500;&#27714;&#26681;&#26469;&#26356;&#26032;&#65292;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#30452;&#25509;&#35745;&#31639;&#25152;&#38656;&#22833;&#30495;&#30340;RD&#20989;&#25968;&#65292;&#32780;&#26080;&#38656;&#20687;&#21407;&#22987;&#31639;&#27861;&#19968;&#26679;&#25506;&#32034;&#25972;&#20010;RD&#26354;&#32447;&#12290;</title><link>http://arxiv.org/abs/2305.02650</link><description>&lt;p&gt;
Blahut&#21644;Arimoto&#30340;&#20027;&#39064;&#21464;&#20307;
&lt;/p&gt;
&lt;p&gt;
Variations on a Theme by Blahut and Arimoto. (arXiv:2305.02650v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;BA&#31639;&#27861;&#30340;&#19968;&#31181;&#26032;&#30340;&#20462;&#25913;&#65292;&#36890;&#36807;&#35753;&#20056;&#25968;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#36890;&#36807;&#19968;&#32500;&#27714;&#26681;&#26469;&#26356;&#26032;&#65292;&#36825;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#30452;&#25509;&#35745;&#31639;&#25152;&#38656;&#22833;&#30495;&#30340;RD&#20989;&#25968;&#65292;&#32780;&#26080;&#38656;&#20687;&#21407;&#22987;&#31639;&#27861;&#19968;&#26679;&#25506;&#32034;&#25972;&#20010;RD&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Blahut-Arimoto&#65288;BA&#65289;&#31639;&#27861;&#22312;&#35745;&#31639;&#36895;&#29575;&#22833;&#30495;&#65288;RD&#65289;&#20989;&#25968;&#26041;&#38754;&#36215;&#30528;&#22522;&#30784;&#24615;&#20316;&#29992;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20132;&#26367;&#26368;&#23567;&#21270;&#24102;&#26377;&#22266;&#23450;&#20056;&#25968;&#30340;Lagrangian&#20855;&#26377;&#29702;&#24819;&#30340;&#21333;&#35843;&#25910;&#25947;&#23646;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;BA&#31639;&#27861;&#30340;&#26032;&#39062;&#20462;&#25913;&#65292;&#20351;&#20056;&#25968;&#27599;&#27425;&#36845;&#20195;&#36890;&#36807;&#30456;&#23545;&#20110;&#21333;&#35843;&#21333;&#21464;&#37327;&#20989;&#25968;&#30340;&#19968;&#32500;&#27714;&#26681;&#27493;&#39588;&#26356;&#26032;&#65292;&#36825;&#21487;&#20197;&#36890;&#36807;&#29275;&#39039;&#27861;&#26377;&#25928;&#23454;&#29616;&#12290;&#36825;&#20801;&#35768;&#20197;&#28789;&#27963;&#21644;&#39640;&#25928;&#30340;&#26041;&#24335;&#26356;&#26032;&#20056;&#25968;&#65292;&#20811;&#26381;&#20102;&#21407;&#22987;BA&#31639;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#65292;&#20854;&#20013;&#20056;&#25968;&#22312;&#25972;&#20010;&#36845;&#20195;&#36807;&#31243;&#20013;&#37117;&#26159;&#22266;&#23450;&#30340;&#12290;&#22240;&#27492;&#65292;&#20462;&#25913;&#21518;&#30340;&#31639;&#27861;&#33021;&#22815;&#30452;&#25509;&#35745;&#31639;&#25152;&#38656;&#22833;&#30495;&#30340;RD&#20989;&#25968;&#65292;&#32780;&#19981;&#20687;&#21407;&#22987;BA&#31639;&#27861;&#19968;&#26679;&#25506;&#32034;&#25972;&#20010;RD&#26354;&#32447;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#20462;&#25913;&#21518;&#30340;&#31639;&#27861;&#20173;&#20250;&#25910;&#25947;&#21040;RD&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Blahut-Arimoto (BA) algorithm has played a fundamental role in the numerical computation of rate-distortion (RD) functions. This algorithm possesses a desirable monotonic convergence property by alternatively minimizing its Lagrangian with a fixed multiplier. In this paper, we propose a novel modification of the BA algorithm, letting the multiplier be updated in each iteration via a one-dimensional root-finding step with respect to a monotonic univariate function, which can be efficiently implemented by Newton's method. This allows the multiplier to be updated in a flexible and efficient manner, overcoming a major drawback of the original BA algorithm wherein the multiplier is fixed throughout iterations. Consequently, the modified algorithm is capable of directly computing the RD function for a given target distortion, without exploring the entire RD curve as in the original BA algorithm. A theoretical analysis shows that the modified algorithm still converges to the RD function a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2304.05527</link><description>&lt;p&gt;
&#19968;&#31181;&#20351;&#29992;&#30830;&#23450;&#24615;&#30446;&#26631;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;&#65306;&#26356;&#24555;&#65292;&#26356;&#31934;&#30830;&#65292;&#26356;&#40657;&#12290;
&lt;/p&gt;
&lt;p&gt;
Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box. (arXiv:2304.05527v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#65288;ADVI&#65289;&#25552;&#20379;&#20102;&#22810;&#31181;&#29616;&#20195;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#24555;&#36895;&#26131;&#29992;&#30340;&#21518;&#39564;&#36817;&#20284;&#26041;&#27861;&#12290;&#28982;&#32780;&#23427;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#32570;&#20047;&#26126;&#30830;&#30340;&#25910;&#25947;&#26631;&#20934;&#65292;&#24182;&#19988;&#38656;&#35201;&#35843;&#25972;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;ADVI&#32487;&#25215;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#36739;&#24046;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;DADVI&#29992;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;MFVB&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#36825;&#19968;&#25216;&#26415;&#22312;&#38543;&#26426;&#20248;&#21270;&#25991;&#29486;&#20013;&#34987;&#31216;&#20026;&#8220;&#26679;&#26412;&#24179;&#22343;&#36817;&#20284;&#8221;&#65288;SAA&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#20294;&#30830;&#23450;&#30340;&#30446;&#26631;&#65292;DADVI&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#32780;&#19988;&#19982;&#26631;&#20934;&#22343;&#20540;&#22330;ADVI&#19981;&#21516;&#30340;&#26159;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#19982;&#29616;&#26377;&#30340;&#26368;&#22351;&#24773;&#20917;&#29702;&#35770;&#30456;&#21453;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#65292;DADVI&#21644;SAA&#21487;&#20197;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor posterior uncertainty estimates of mean-field variational Bayes (MFVB). We introduce ``deterministic ADVI'' (DADVI) to address these issues. DADVI replaces the intractable MFVB objective with a fixed Monte Carlo approximation, a technique known in the stochastic optimization literature as the ``sample average approximation'' (SAA). By optimizing an approximate but deterministic objective, DADVI can use off-the-shelf second-order optimization, and, unlike standard mean-field ADVI, is amenable to more accurate posterior linear response (LR) covariance estimates. In contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, DADVI and the SAA can perform 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#35757;&#32451;&#20855;&#26377;ReLU&#21644;&#32447;&#24615;&#38408;&#20540;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#23450;&#32500;&#24230;&#19979;&#30340;NP&#38590;&#24230;&#12290; &#22238;&#31572;&#20102;&#20004;&#20010;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#22312;&#20108;&#32500;&#24773;&#20917;&#19979;&#26159;NP&#38590;&#30340;&#65292;&#27492;&#22806;&#22312;ReLU&#26696;&#20363;&#20013;&#35777;&#26126;&#20102;&#22266;&#23450;&#21442;&#25968;&#38382;&#39064;&#30340;&#21442;&#25968;&#21270;&#22266;&#23450;&#22797;&#26434;&#24230;&#32500;&#25968;&#21644;ReLU&#25968;&#37327;&#30340;&#32452;&#21512;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.17045</link><description>&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#22312;&#22266;&#23450;&#32500;&#24230;&#19978;&#26159;NP&#38590;&#30340;
&lt;/p&gt;
&lt;p&gt;
Training Neural Networks is NP-Hard in Fixed Dimension. (arXiv:2303.17045v1 [cs.CC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17045
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#35757;&#32451;&#20855;&#26377;ReLU&#21644;&#32447;&#24615;&#38408;&#20540;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22266;&#23450;&#32500;&#24230;&#19979;&#30340;NP&#38590;&#24230;&#12290; &#22238;&#31572;&#20102;&#20004;&#20010;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#22312;&#20108;&#32500;&#24773;&#20917;&#19979;&#26159;NP&#38590;&#30340;&#65292;&#27492;&#22806;&#22312;ReLU&#26696;&#20363;&#20013;&#35777;&#26126;&#20102;&#22266;&#23450;&#21442;&#25968;&#38382;&#39064;&#30340;&#21442;&#25968;&#21270;&#22266;&#23450;&#22797;&#26434;&#24230;&#32500;&#25968;&#21644;ReLU&#25968;&#37327;&#30340;&#32452;&#21512;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36755;&#20837;&#25968;&#25454;&#32500;&#24230;&#21644;&#38544;&#34255;&#31070;&#32463;&#20803;&#25968;&#37327;&#26041;&#38754;&#23545;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#21442;&#25968;&#21270;&#22797;&#26434;&#24615;&#30340;&#30740;&#31350;&#65292;&#32771;&#34385;ReLU&#21644;&#32447;&#24615;&#38408;&#20540;&#28608;&#27963;&#20989;&#25968;&#12290;&#23613;&#31649;&#36825;&#20123;&#38382;&#39064;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#36817;&#24180;&#26469;&#24050;&#32463;&#34987;&#22810;&#27425;&#30740;&#31350;&#65292;&#20294;&#20173;&#26377;&#20960;&#20010;&#38382;&#39064;&#23578;&#26410;&#35299;&#20915;&#12290;&#25105;&#20204;&#22238;&#31572;&#20102;Arora et al. [ICLR '18]&#21644;Khalife&#21644;Basu [IPCO '22]&#30340;&#38382;&#39064;&#65292;&#26174;&#31034;&#20004;&#20010;&#38382;&#39064;&#22312;&#20108;&#32500;&#24773;&#20917;&#19979;&#37117;&#26159;NP&#38590;&#30340;&#65292;&#36825;&#25490;&#38500;&#20102;&#20219;&#20309;&#24120;&#25968;&#32500;&#24230;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#22238;&#31572;&#20102;Froese&#31561;&#20154;[JAIR '22]&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#20855;&#26377;&#38646;&#22521;&#35757;&#35823;&#24046;&#30340;&#22235;&#20010;ReLU(&#25110;&#20004;&#20010;&#32447;&#24615;&#38408;&#20540;&#31070;&#32463;&#20803;)&#30340;W [1]-hardness&#12290;&#26368;&#21518;&#65292;&#22312;ReLU&#26696;&#20363;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21442;&#25968;&#21270;&#22266;&#23450;&#22797;&#26434;&#24230;&#32500;&#25968;&#21644;ReLU&#25968;&#37327;&#30340;&#32452;&#21512;&#21442;&#25968;&#65292;&#22914;&#26524;&#32593;&#32476;&#34987;&#20551;&#23450;&#20026;&#35745;&#31639;&#20984;&#26144;&#23556;&#65292;&#21017;&#21487;&#29992;&#20110;&#22266;&#23450;&#21442;&#25968;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20960;&#20046;&#23436;&#20840;&#35299;&#20915;&#20102;&#36825;&#20123;&#21442;&#25968;&#30340;&#22797;&#26434;&#24615;&#29366;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the parameterized complexity of training two-layer neural networks with respect to the dimension of the input data and the number of hidden neurons, considering ReLU and linear threshold activation functions. Albeit the computational complexity of these problems has been studied numerous times in recent years, several questions are still open. We answer questions by Arora et al. [ICLR '18] and Khalife and Basu [IPCO '22] showing that both problems are NP-hard for two dimensions, which excludes any polynomial-time algorithm for constant dimension. We also answer a question by Froese et al. [JAIR '22] proving W[1]-hardness for four ReLUs (or two linear threshold neurons) with zero training error. Finally, in the ReLU case, we show fixed-parameter tractability for the combined parameter number of dimensions and number of ReLUs if the network is assumed to compute a convex map. Our results settle the complexity status regarding these parameters almost completely.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#35843;&#25972;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#25552;&#39640;&#20272;&#35745;&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#20445;&#25345;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.15579</link><description>&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#35843;&#25972;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Adjusted Wasserstein Distributionally Robust Estimator in Statistical Learning. (arXiv:2303.15579v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32479;&#35745;&#23398;&#20064;&#20013;&#30340;&#35843;&#25972;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#25552;&#39640;&#20272;&#35745;&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#20445;&#25345;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#32479;&#35745;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#35843;&#25972;&#30340;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#8212;&#8212;&#22522;&#20110;Wasserstein&#20998;&#24067;&#40065;&#26834;&#20272;&#35745;&#65288;WDRO&#65289;&#30340;&#38750;&#32447;&#24615;&#36716;&#25442;&#12290;&#36825;&#31181;&#36716;&#25442;&#23558;&#25552;&#39640;WDRO&#30340;&#32479;&#35745;&#24615;&#33021;&#65292;&#22240;&#20026;&#35843;&#25972;&#21518;&#30340;WDRO&#20272;&#35745;&#22120;&#28176;&#36827;&#26080;&#20559;&#24182;&#19988;&#22343;&#26041;&#35823;&#24046;&#36235;&#36817;&#20110;&#38646;&#12290;&#35843;&#25972;&#21518;&#30340;WDRO&#19981;&#20250;&#21066;&#24369;WDRO&#30340;&#26679;&#26412;&#22806;&#24615;&#33021;&#20445;&#35777;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35843;&#25972;WDRO&#20272;&#35745;&#22120;&#30340;&#23384;&#22312;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#32473;&#20986;&#20102;&#35745;&#31639;&#35843;&#25972;WDRO&#20272;&#35745;&#22120;&#30340;&#36807;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#22914;&#20309;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#24320;&#21457;&#35843;&#25972;WDRO&#20272;&#35745;&#22120;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#35843;&#25972;&#21518;&#30340;&#20272;&#35745;&#22120;&#27604;&#32463;&#20856;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#22909;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an adjusted Wasserstein distributionally robust estimator -- based on a nonlinear transformation of the Wasserstein distributionally robust (WDRO) estimator in statistical learning. This transformation will improve the statistical performance of WDRO because the adjusted WDRO estimator is asymptotically unbiased and has an asymptotically smaller mean squared error. The adjusted WDRO will not mitigate the out-of-sample performance guarantee of WDRO. Sufficient conditions for the existence of the adjusted WDRO estimator are presented, and the procedure for the computation of the adjusted WDRO estimator is given. Specifically, we will show how the adjusted WDRO estimator is developed in the generalized linear model. Numerical experiments demonstrate the favorable practical performance of the adjusted estimator over the classic one.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#39640;&#33021;&#29289;&#29702;&#20107;&#20214;&#65292;&#21487;&#29992;&#20110;&#21442;&#25968;&#21270;&#30340;&#20107;&#20214;&#29983;&#25104;&#65292;&#24322;&#24120;&#20449;&#21495;&#25506;&#27979;&#20197;&#21450;&#31890;&#23376;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2302.00695</link><description>&lt;p&gt;
&#22810;&#21151;&#33021;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#22312;&#39640;&#33021;&#29289;&#29702;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Versatile Energy-Based Probabilistic Models for High Energy Physics. (arXiv:2302.00695v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#30340;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#39640;&#33021;&#29289;&#29702;&#20107;&#20214;&#65292;&#21487;&#29992;&#20110;&#21442;&#25968;&#21270;&#30340;&#20107;&#20214;&#29983;&#25104;&#65292;&#24322;&#24120;&#20449;&#21495;&#25506;&#27979;&#20197;&#21450;&#31890;&#23376;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#19968;&#31181;&#32463;&#20856;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#20855;&#26377;&#33021;&#37327;&#20989;&#25968;&#24418;&#24335;&#28789;&#27963;&#24615;&#30340;&#22825;&#28982;&#20248;&#21183;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#24314;&#27169;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#19982;&#36825;&#20123;&#36827;&#23637;&#19968;&#33268;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#22810;&#21151;&#33021;&#33021;&#37327;&#27010;&#29575;&#27169;&#22411;&#65292;&#29992;&#20110;&#25551;&#36848;&#26469;&#33258;&#22823;&#22411;&#24378;&#23376;&#23545;&#25758;&#26426;&#30340;&#39640;&#33021;&#29289;&#29702;&#20107;&#20214;&#12290;&#35813;&#26694;&#26550;&#22522;&#20110;&#19968;&#20010;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#25551;&#36848;&#20102;&#26356;&#39640;&#38454;&#30340;&#31890;&#23376;&#38388;&#30456;&#20114;&#20316;&#29992;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#32534;&#30721;&#20307;&#31995;&#32467;&#26500;&#21644;&#38544;&#24335;&#29983;&#25104;&#12290;&#22312;&#24212;&#29992;&#26041;&#38754;&#65292;&#23427;&#21487;&#20197;&#20316;&#20026;&#24378;&#22823;&#30340;&#21442;&#25968;&#21270;&#20107;&#20214;&#29983;&#25104;&#22120;&#29992;&#20110;&#29289;&#29702;&#20223;&#30495;&#65292;&#19968;&#31181;&#27867;&#29992;&#30340;&#26080;&#20551;&#35774;&#20851;&#32852;&#30340;&#24322;&#24120;&#20449;&#21495;&#25506;&#27979;&#22120;&#65292;&#20197;&#21450;&#29992;&#20110;&#31890;&#23376;&#35782;&#21035;&#30340;&#22686;&#24378;&#20107;&#20214;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a classical generative modeling approach, energy-based models have the natural advantage of flexibility in the form of the energy function. Recently, energy-based models have achieved great success in modeling high-dimensional data in computer vision and natural language processing. In line with these advancements, we build a multi-purpose energy-based probabilistic model for High Energy Physics events at the Large Hadron Collider. This framework builds on a powerful generative model and describes higher-order inter-particle interactions.It suits different encoding architectures and builds on implicit generation. As for applicational aspects, it can serve as a powerful parameterized event generator for physics simulation, a generic anomalous signal detector free from spurious correlations, and an augmented event classifier for particle identification.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#26041;&#24046;-&#21327;&#26041;&#24046;&#21442;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#65292;&#23558;&#20132;&#21449;&#39564;&#35777;&#38382;&#39064;&#36716;&#21270;&#20026;&#31616;&#21333;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22823;&#22411;BHRMs&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2011.14238</link><description>&lt;p&gt;
Bayesian&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Approximate Cross-validated Mean Estimates for Bayesian Hierarchical Regression Models. (arXiv:2011.14238v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.14238
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;&#30340;&#36817;&#20284;&#20132;&#21449;&#39564;&#35777;&#22343;&#20540;&#20272;&#35745;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#26041;&#24046;-&#21327;&#26041;&#24046;&#21442;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#65292;&#23558;&#20132;&#21449;&#39564;&#35777;&#38382;&#39064;&#36716;&#21270;&#20026;&#31616;&#21333;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#22823;&#22411;BHRMs&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#36125;&#21494;&#26031;&#23618;&#27425;&#22238;&#24402;&#27169;&#22411;(BHRMs)&#30340;&#20132;&#21449;&#39564;&#35777;&#39044;&#27979;&#20272;&#35745;&#12290;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#20197;&#20854;&#33021;&#22815;&#24314;&#27169;&#22797;&#26434;&#30340;&#20381;&#36182;&#32467;&#26500;&#24182;&#25552;&#20379;&#27010;&#29575;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#32780;&#21463;&#21040;&#27426;&#36814;&#65292;&#20294;&#36816;&#34892;&#30340;&#35745;&#31639;&#24320;&#38144;&#24456;&#22823;&#12290;&#22240;&#27492;&#65292;&#20132;&#21449;&#39564;&#35777;(CV)&#19981;&#26159;&#35780;&#20272;BHRMs&#39044;&#27979;&#24615;&#33021;&#30340;&#24120;&#35265;&#23454;&#36341;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36991;&#20813;&#20102;&#20026;&#27599;&#20010;&#20132;&#21449;&#39564;&#35777;&#25240;&#21472;&#37325;&#26032;&#36816;&#34892;&#35745;&#31639;&#24320;&#38144;&#26114;&#36149;&#30340;&#20272;&#35745;&#26041;&#27861;&#30340;&#38656;&#35201;&#65292;&#20351;CV&#22312;&#22823;&#22411;BHRMs&#20013;&#26356;&#21487;&#34892;&#12290;&#36890;&#36807;&#22312;&#26041;&#24046;-&#21327;&#26041;&#24046;&#21442;&#25968;&#19978;&#36827;&#34892;&#26465;&#20214;&#65292;&#23558;CV&#38382;&#39064;&#20174;&#22522;&#20110;&#27010;&#29575;&#30340;&#25277;&#26679;&#36716;&#21270;&#20026;&#31616;&#21333;&#29087;&#24713;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36825;&#20135;&#29983;&#30340;&#20272;&#35745;&#19982;&#23436;&#25972;&#30340;CV&#31561;&#25928;&#12290;&#25105;&#20204;&#25552;&#20379;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#22312;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#21644;&#27169;&#25311;&#20013;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel procedure for obtaining cross-validated predictive estimates for Bayesian hierarchical regression models (BHRMs). Bayesian hierarchical models are popular for their ability to model complex dependence structures and provide probabilistic uncertainty estimates, but can be computationally expensive to run. Cross-validation (CV) is therefore not a common practice to evaluate the predictive performance of BHRMs. Our method circumvents the need to re-run computationally costly estimation methods for each cross-validation fold and makes CV more feasible for large BHRMs. By conditioning on the variance-covariance parameters, we shift the CV problem from probability-based sampling to a simple and familiar optimization problem. In many cases, this produces estimates which are equivalent to full CV. We provide theoretical results and demonstrate its efficacy on publicly available data and in simulations.
&lt;/p&gt;</description></item></channel></rss>