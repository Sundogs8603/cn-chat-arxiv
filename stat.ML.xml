<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#21019;&#24314;&#20102;COB&#21407;&#27833;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#23558;&#36164;&#20135;&#20215;&#26684;&#36716;&#21270;&#20026;&#27874;&#21160;&#24615;&#20195;&#29702;&#65292;&#24182;&#29983;&#25104;&#19982;&#29616;&#23454;&#19990;&#30028;&#20107;&#20214;&#30456;&#19968;&#33268;&#30340;&#19978;&#19979;&#25991;&#20219;&#21153;&#26631;&#31614;&#65292;&#36825;&#20123;&#26631;&#31614;&#33021;&#26222;&#36941;&#25552;&#21319;&#22810;&#20010;&#39044;&#27979;&#26102;&#27573;&#19978;&#22235;&#31181;&#25345;&#32493;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#26377;&#26395;&#21152;&#36895;&#37329;&#34701;&#39046;&#22495;&#20013;&#30340;&#21019;&#26032;&#12290;</title><link>http://arxiv.org/abs/2308.10846</link><description>&lt;p&gt;
&#20855;&#26377;&#20998;&#24067;&#21464;&#21270;&#30340;&#29616;&#23454;&#19990;&#30028;&#26102;&#38388;&#24207;&#21015;&#22522;&#20934;&#25968;&#25454;&#38598;&#65306;&#20840;&#29699;&#21407;&#27833;&#20215;&#26684;&#21644;&#27874;&#21160;&#24615;
&lt;/p&gt;
&lt;p&gt;
Real World Time Series Benchmark Datasets with Distribution Shifts: Global Crude Oil Price and Volatility. (arXiv:2308.10846v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21019;&#24314;&#20102;COB&#21407;&#27833;&#22522;&#20934;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#23558;&#36164;&#20135;&#20215;&#26684;&#36716;&#21270;&#20026;&#27874;&#21160;&#24615;&#20195;&#29702;&#65292;&#24182;&#29983;&#25104;&#19982;&#29616;&#23454;&#19990;&#30028;&#20107;&#20214;&#30456;&#19968;&#33268;&#30340;&#19978;&#19979;&#25991;&#20219;&#21153;&#26631;&#31614;&#65292;&#36825;&#20123;&#26631;&#31614;&#33021;&#26222;&#36941;&#25552;&#21319;&#22810;&#20010;&#39044;&#27979;&#26102;&#27573;&#19978;&#22235;&#31181;&#25345;&#32493;&#23398;&#20064;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#26377;&#26395;&#21152;&#36895;&#37329;&#34701;&#39046;&#22495;&#20013;&#30340;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37329;&#34701;&#39046;&#22495;&#20013;&#65292;&#32570;&#20047;&#24102;&#26377;&#20219;&#21153;&#26631;&#31614;&#30340;&#26102;&#38388;&#24207;&#21015;&#22522;&#20934;&#25968;&#25454;&#38598;&#38459;&#30861;&#20102;&#25345;&#32493;&#23398;&#20064;&#30340;&#36827;&#23637;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;COB&#65292;&#21363;&#21407;&#27833;&#22522;&#20934;&#25968;&#25454;&#38598;&#12290;COB&#21253;&#25324;&#23637;&#31034;&#26174;&#33879;&#20998;&#24067;&#21464;&#21270;&#30340;30&#24180;&#36164;&#20135;&#20215;&#26684;&#65292;&#24182;&#22522;&#20110;&#36825;&#20123;&#20998;&#24067;&#21464;&#21270;&#29983;&#25104;&#30456;&#24212;&#30340;&#20219;&#21153;&#65288;&#21363;&#21046;&#24230;&#65289;&#26631;&#31614;&#65292;&#20854;&#20013;&#21253;&#25324;&#20840;&#29699;&#26368;&#37325;&#35201;&#30340;&#19977;&#31181;&#21407;&#27833;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#21253;&#25324;&#23558;&#36164;&#20135;&#20215;&#26684;&#25968;&#25454;&#36716;&#21270;&#20026;&#27874;&#21160;&#24615;&#20195;&#29702;&#65292;&#20351;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#27169;&#22411;&#25311;&#21512;&#65292;&#29983;&#25104;&#19982;&#29616;&#23454;&#19990;&#30028;&#20107;&#20214;&#30456;&#19968;&#33268;&#30340;&#19978;&#19979;&#25991;&#20219;&#21153;&#26631;&#31614;&#65292;&#24182;&#23558;&#36825;&#20123;&#26631;&#31614;&#20197;&#21450;&#36890;&#29992;&#31639;&#27861;&#20844;&#24320;&#25552;&#20379;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21253;&#21547;&#36825;&#20123;&#20219;&#21153;&#26631;&#31614;&#23545;&#22235;&#31181;&#25345;&#32493;&#23398;&#20064;&#31639;&#27861;&#65288;&#21253;&#25324;&#19968;&#20123;&#26368;&#26032;&#25216;&#26415;&#65289;&#22312;&#22810;&#20010;&#39044;&#27979;&#26102;&#27573;&#19978;&#30340;&#24615;&#33021;&#26222;&#36941;&#25552;&#21319;&#12290;&#25105;&#20204;&#24076;&#26395;&#36825;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#33021;&#21152;&#36895;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scarcity of task-labeled time-series benchmarks in the financial domain hinders progress in continual learning. Addressing this deficit would foster innovation in this area. Therefore, we present COB, Crude Oil Benchmark datasets. COB includes 30 years of asset prices that exhibit significant distribution shifts and optimally generates corresponding task (i.e., regime) labels based on these distribution shifts for the three most important crude oils in the world. Our contributions include creating real-world benchmark datasets by transforming asset price data into volatility proxies, fitting models using expectation-maximization (EM), generating contextual task labels that align with real-world events, and providing these labels as well as the general algorithm to the public. We show that the inclusion of these task labels universally improves performance on four continual learning algorithms, some state-of-the-art, over multiple forecasting horizons. We hope these benchmarks accel
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#35821;&#35328;&#22270;&#20687;&#27169;&#22411;&#21644;&#21333;&#20010;&#31232;&#30095;&#32447;&#24615;&#23618;&#30340;&#21487;&#35299;&#37322;&#26694;&#26550;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#25512;&#26029;&#26469;&#23454;&#29616;&#27010;&#24565;&#20043;&#38388;&#30340;&#31232;&#30095;&#24615;&#65292;&#36798;&#21040;&#20102;&#27604;&#26368;&#36817;&#30340;CBM&#26041;&#27861;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.10782</link><description>&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#27010;&#24565;&#21457;&#29616;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Sparse Linear Concept Discovery Models. (arXiv:2308.10782v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#35821;&#35328;&#22270;&#20687;&#27169;&#22411;&#21644;&#21333;&#20010;&#31232;&#30095;&#32447;&#24615;&#23618;&#30340;&#21487;&#35299;&#37322;&#26694;&#26550;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#25512;&#26029;&#26469;&#23454;&#29616;&#27010;&#24565;&#20043;&#38388;&#30340;&#31232;&#30095;&#24615;&#65292;&#36798;&#21040;&#20102;&#27604;&#26368;&#36817;&#30340;CBM&#26041;&#27861;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#23433;&#20840;&#20851;&#38190;&#22330;&#26223;&#20013;&#20063;&#22823;&#35268;&#27169;&#37319;&#29992;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#65292;&#36825;&#20351;&#24471;&#30740;&#31350;&#30028;&#30340;&#20851;&#27880;&#28857;&#36716;&#21521;&#20102;&#21019;&#36896;&#22266;&#26377;&#21487;&#35299;&#37322;&#27169;&#22411;&#12290;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411; (CBMs) &#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#38544;&#34255;&#23618;&#19982;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#30456;&#36830;&#65292;&#20801;&#35768;&#23545;&#32593;&#32476;&#20915;&#31574;&#36827;&#34892;&#35843;&#26597;&#21644;&#20462;&#27491;&#12290;&#28982;&#32780;&#65292;CBMs&#36890;&#24120;&#23384;&#22312;&#20197;&#19979;&#38382;&#39064;&#65306;(i) &#24615;&#33021;&#19979;&#38477;&#21644;(ii) &#35299;&#37322;&#24615;&#19981;&#22914;&#39044;&#26399;&#65292;&#22240;&#20026;&#27599;&#20010;&#20915;&#31574;&#37117;&#28041;&#21450;&#21040;&#35768;&#22810;&#27010;&#24565;&#30340;&#36129;&#29486;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26497;&#20854;&#30452;&#35266;&#30340;&#21487;&#35299;&#37322;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22522;&#20110;&#23545;&#27604;&#35821;&#35328;&#22270;&#20687;&#27169;&#22411;&#21644;&#21333;&#20010;&#31232;&#30095;&#32447;&#24615;&#23618;&#12290;&#19982;&#20854;&#20182;&#30456;&#20851;&#26041;&#27861;&#25130;&#28982;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#30340;&#31232;&#30095;&#24615;&#26159;&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20271;&#21162;&#21033;&#20998;&#24067;&#36827;&#34892;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#21407;&#29702;&#30340;&#27010;&#24565;&#25512;&#26029;&#23454;&#29616;&#30340;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#25152;&#34920;&#26126;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#19981;&#20165;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#26368;&#36817;&#30340;CBM&#26041;&#27861;&#65292;&#32780;&#19988;&#22312;&#35299;&#37322;&#24615;&#26041;&#38754;&#20063;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#32972;&#21253;&#30340;&#32858;&#31867;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#19981;&#30693;&#36947;&#32858;&#31867;&#25104;&#21592;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29616;&#23376;&#32447;&#24615;&#36951;&#25022;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21482;&#38656;&#23545;&#19968;&#20010;&#38543;&#26426;&#36873;&#25321;&#30340;&#33218;&#23376;&#38598;&#36827;&#34892;&#19968;&#27425;&#32858;&#31867;&#12290;</title><link>http://arxiv.org/abs/2308.10722</link><description>&lt;p&gt;
&#24102;&#32972;&#21253;&#30340;&#32858;&#31867;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Clustered Linear Contextual Bandits with Knapsacks. (arXiv:2308.10722v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#32972;&#21253;&#30340;&#32858;&#31867;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#19981;&#30693;&#36947;&#32858;&#31867;&#25104;&#21592;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29616;&#23376;&#32447;&#24615;&#36951;&#25022;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21482;&#38656;&#23545;&#19968;&#20010;&#38543;&#26426;&#36873;&#25321;&#30340;&#33218;&#23376;&#38598;&#36827;&#34892;&#19968;&#27425;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#32858;&#31867;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20854;&#20013;&#22870;&#21169;&#21644;&#36164;&#28304;&#28040;&#32791;&#26159;&#32858;&#31867;&#29305;&#23450;&#32447;&#24615;&#27169;&#22411;&#30340;&#32467;&#26524;&#12290;&#33218;&#34987;&#20998;&#25104;&#32858;&#31867;&#65292;&#32780;&#32858;&#31867;&#25104;&#21592;&#23545;&#31639;&#27861;&#26159;&#26410;&#30693;&#30340;&#12290;&#22312;&#19968;&#20010;&#26102;&#38388;&#27573;&#20869;&#25289;&#21160;&#19968;&#20010;&#33218;&#23548;&#33268;&#22870;&#21169;&#21644;&#23545;&#22810;&#31181;&#36164;&#28304;&#30340;&#28040;&#32791;&#65292;&#24182;&#19988;&#20219;&#20309;&#36164;&#28304;&#30340;&#24635;&#28040;&#32791;&#36229;&#36807;&#32422;&#26463;&#24847;&#21619;&#30528;&#31639;&#27861;&#30340;&#32456;&#27490;&#12290;&#22240;&#27492;&#65292;&#26368;&#22823;&#21270;&#24635;&#22870;&#21169;&#38656;&#35201;&#23398;&#20064;&#20851;&#20110;&#22870;&#21169;&#21644;&#36164;&#28304;&#28040;&#32791;&#30340;&#27169;&#22411;&#65292;&#36824;&#26377;&#32858;&#31867;&#25104;&#21592;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#22312;&#26102;&#38388;&#27573;&#25968;&#37327;&#30340;&#23376;&#32447;&#24615;&#36951;&#25022;&#19979;&#23454;&#29616;&#65292;&#32780;&#19981;&#38656;&#35201;&#35775;&#38382;&#25152;&#26377;&#33218;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#34920;&#26126;&#21482;&#38656;&#35201;&#23545;&#19968;&#20010;&#38543;&#26426;&#36873;&#25321;&#30340;&#33218;&#23376;&#38598;&#36827;&#34892;&#19968;&#27425;&#32858;&#31867;&#23601;&#36275;&#22815;&#20102;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22797;&#26434;&#30340;&#32452;&#21512;&#25216;&#26415;&#65292;&#32467;&#21512;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#24102;&#32422;&#26463;&#30340;&#36172;&#21338;&#26426;&#39046;&#22495;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#65292;&#36890;&#36807;&#28040;&#38500;&#20808;&#39564;&#30693;&#35782;&#38656;&#27714;&#21644;&#25511;&#21046;&#20998;&#24067;&#28418;&#31227;&#65292;&#35813;&#31639;&#27861;&#22312;&#36951;&#25022;&#30028;&#38480;&#26041;&#38754;&#20855;&#26377;&#31361;&#20986;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2308.10675</link><description>&lt;p&gt;
&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#20013;&#30340;&#26368;&#20339;&#26041;&#26696;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback. (arXiv:2308.10675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10675
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#65292;&#36890;&#36807;&#28040;&#38500;&#20808;&#39564;&#30693;&#35782;&#38656;&#27714;&#21644;&#25511;&#21046;&#20998;&#24067;&#28418;&#31227;&#65292;&#35813;&#31639;&#27861;&#22312;&#36951;&#25022;&#30028;&#38480;&#26041;&#38754;&#20855;&#26377;&#31361;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#21487;&#21464;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#22823;&#24310;&#36831;$d_{\mathrm{max}}$&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;&#38656;&#27714;&#65292;&#24182;&#22312;&#20004;&#20010;&#24773;&#26223;&#19979;&#25552;&#20379;&#26356;&#32039;&#23494;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#25913;&#36827;&#20102;Masoudian&#31561;&#20154;[2022]&#30340;&#20808;&#21069;&#24037;&#20316;&#12290;&#31639;&#27861;&#21644;&#23427;&#30340;&#36951;&#25022;&#30028;&#38480;&#26159;&#22522;&#20110;&#26410;&#35299;&#20915;&#30340;&#35266;&#27979;&#27425;&#25968;&#65288;&#22312;&#34892;&#21160;&#26102;&#38388;&#35266;&#23519;&#21040;&#30340;&#25968;&#37327;&#65289;&#32780;&#19981;&#26159;&#24310;&#36831;&#25110;&#26368;&#22823;&#24310;&#36831;&#65288;&#21482;&#26377;&#24403;&#21453;&#39304;&#21040;&#36798;&#26102;&#25165;&#33021;&#35266;&#23519;&#21040;&#30340;&#25968;&#37327;&#65289;&#12290;&#19968;&#20010;&#20027;&#35201;&#30340;&#36129;&#29486;&#26159;&#22522;&#20110;&#26377;&#20559;&#25439;&#22833;&#20272;&#35745;&#22120;&#21644;&#36339;&#36807;&#20855;&#26377;&#36807;&#22823;&#24310;&#36831;&#35266;&#27979;&#30340;&#26032;&#22411;&#20998;&#24067;&#28418;&#31227;&#25511;&#21046;&#12290;&#21478;&#19968;&#20010;&#20027;&#35201;&#30340;&#36129;&#29486;&#26159;&#35777;&#26126;&#20102;&#20855;&#26377;&#24310;&#36831;&#21453;&#39304;&#30340;&#24378;&#21270;&#36866;&#24212;&#24615;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#26159;&#30001;&#22312;&#36339;&#36807;&#20855;&#26377;&#36807;&#22823;&#24310;&#36831;&#35266;&#27979;&#21518;&#30340;&#32047;&#31215;&#26410;&#35299;&#20915;&#35266;&#27979;&#27425;&#25968;&#26469;&#25551;&#36848;&#30340;&#65292;&#32780;&#19981;&#26159;&#24310;&#36831;&#25110;&#26368;&#22823;&#24310;&#36831;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\mathrm{max}}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35777;&#25454;&#23398;&#20064;&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#19968;&#30830;&#23450;&#24615;&#21069;&#21521;&#20256;&#36882;&#27169;&#22411;&#26469;&#25429;&#25417;&#36830;&#32493;&#30446;&#26631;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.10650</link><description>&lt;p&gt;
&#28145;&#24230;&#35777;&#25454;&#23398;&#20064;&#29992;&#20110;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Deep Evidential Learning for Bayesian Quantile Regression. (arXiv:2308.10650v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35777;&#25454;&#23398;&#20064;&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#19968;&#30830;&#23450;&#24615;&#21069;&#21521;&#20256;&#36882;&#27169;&#22411;&#26469;&#25429;&#25417;&#36830;&#32493;&#30446;&#26631;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#35745;&#31639;&#20195;&#20215;&#39640;&#65292;&#22240;&#27492;&#24076;&#26395;&#33021;&#20174;&#21333;&#19968;&#30830;&#23450;&#24615;&#21069;&#21521;&#20256;&#36882;&#27169;&#22411;&#20013;&#33719;&#24471;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#24456;&#22256;&#38590;&#65292;&#22240;&#20026;&#21333;&#19968;&#21069;&#21521;&#20256;&#36882;&#27169;&#22411;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#19981;&#23545;&#26435;&#37325;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#19988;&#24120;&#24120;&#23545;&#30446;&#26631;&#20998;&#24067;&#20570;&#20986;&#20551;&#35774;&#65292;&#22914;&#20551;&#35774;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#36825;&#22312;&#22238;&#24402;&#20219;&#21153;&#20013;&#20250;&#26377;&#38480;&#21046;&#65292;&#22240;&#20026;&#22343;&#20540;&#21644;&#26631;&#20934;&#24046;&#26080;&#27861;&#20934;&#30830;&#24314;&#27169;&#30446;&#26631;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#22312;&#19981;&#20551;&#35774;&#39640;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#36830;&#32493;&#30446;&#26631;&#20998;&#24067;&#30340;&#20998;&#20301;&#25968;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22522;&#20110;&#35777;&#25454;&#23398;&#20064;&#65292;&#21487;&#20197;&#20351;&#29992;&#21333;&#19968;&#30830;&#23450;&#24615;&#21069;&#21521;&#20256;&#36882;&#27169;&#22411;&#25429;&#25417;&#38543;&#26426;&#19982;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#39640;&#25928;&#19988;&#21487;&#25193;&#23637;&#21040;&#22823;&#22411;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncerta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Gau&#223;-Legendre&#31215;&#20998;&#21152;&#36895;&#31070;&#32463;ODE&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#30456;&#24212;&#30340;ODE&#21644;&#36716;&#31227;&#21442;&#25968;&#30340;&#26041;&#24335;&#25193;&#23637;&#21040;SDE&#35757;&#32451;&#65292;&#21152;&#24555;&#20102;&#31070;&#32463;ODE&#30340;&#35757;&#32451;&#36895;&#24230;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#22411;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#20063;&#25552;&#20379;&#20102;&#19968;&#31181;&#35757;&#32451;&#22522;&#20110;SDE&#30340;&#27169;&#22411;&#30340;&#26032;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2308.10644</link><description>&lt;p&gt;
&#20351;&#29992;Gau&#223;-Legendre&#31215;&#20998;&#21152;&#36895;&#31070;&#32463;ODE&#30340;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Faster Training of Neural ODEs Using Gau{\ss}-Legendre Quadrature. (arXiv:2308.10644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Gau&#223;-Legendre&#31215;&#20998;&#21152;&#36895;&#31070;&#32463;ODE&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#30456;&#24212;&#30340;ODE&#21644;&#36716;&#31227;&#21442;&#25968;&#30340;&#26041;&#24335;&#25193;&#23637;&#21040;SDE&#35757;&#32451;&#65292;&#21152;&#24555;&#20102;&#31070;&#32463;ODE&#30340;&#35757;&#32451;&#36895;&#24230;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#22411;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#20063;&#25552;&#20379;&#20102;&#19968;&#31181;&#35757;&#32451;&#22522;&#20110;SDE&#30340;&#27169;&#22411;&#30340;&#26032;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;ODE&#22312;&#29983;&#25104;&#27169;&#22411;&#21644;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#34920;&#29616;&#20986;&#24378;&#22823;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20276;&#38543;&#26041;&#27861;&#35757;&#32451;&#23427;&#20204;&#27604;&#31163;&#25955;&#27169;&#22411;&#24930;&#65292;&#22240;&#20026;&#38656;&#35201;&#25968;&#20540;&#35299;ODE&#12290;&#20026;&#20102;&#21152;&#36895;&#31070;&#32463;ODE&#65292;&#24120;&#29992;&#30340;&#26041;&#27861;&#26159;&#23545;&#35299;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#24433;&#21709;&#27169;&#22411;&#30340;&#34920;&#36798;&#33021;&#21147;&#65307;&#24403;&#36712;&#36857;&#26412;&#36523;&#24456;&#37325;&#35201;&#26102;&#65292;&#36825;&#19968;&#28857;&#23588;&#20026;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#31070;&#32463;ODE&#35757;&#32451;&#30340;&#21478;&#19968;&#31181;&#26041;&#27861;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#36890;&#36807;&#20351;&#29992;Gau&#223;-Legendre&#31215;&#20998;&#27604;ODE&#26041;&#27861;&#26356;&#24555;&#22320;&#27714;&#35299;&#31215;&#20998;&#65292;&#21516;&#26102;&#20445;&#25345;&#20869;&#23384;&#25928;&#29575;&#65292;&#21152;&#36895;&#20276;&#38543;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#35757;&#32451;&#30456;&#24212;&#30340;ODE&#24182;&#36716;&#31227;&#21442;&#25968;&#65292;&#23558;&#36825;&#31181;&#24819;&#27861;&#25193;&#23637;&#21040;&#20351;&#29992;Wong-Zakai&#23450;&#29702;&#35757;&#32451;SDE&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23548;&#33268;&#20102;&#31070;&#32463;ODE&#30340;&#24555;&#36895;&#35757;&#32451;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22823;&#22411;&#27169;&#22411;&#12290;&#23427;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#35757;&#32451;&#22522;&#20110;SDE&#30340;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#36125;&#21494;&#26031;&#32593;&#32476;&#20998;&#26512;&#22797;&#26434;&#31995;&#32479;&#32423;&#32852;&#34892;&#20026;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#25551;&#36848;&#20107;&#20214;&#22312;&#31995;&#32479;&#20013;&#20256;&#25773;&#24182;&#35782;&#21035;&#21487;&#33021;&#23548;&#33268;&#32423;&#32852;&#34892;&#20026;&#30340;&#31995;&#32479;&#29366;&#24577;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#20855;&#26377;&#31616;&#21333;&#30340;&#22270;&#24418;&#34920;&#31034;&#21644;&#21487;&#35299;&#37322;&#30340;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2308.10606</link><description>&lt;p&gt;
&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#36125;&#21494;&#26031;&#32593;&#32476;&#20998;&#26512;&#22797;&#26434;&#31995;&#32479;&#20013;&#30340;&#32423;&#32852;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks. (arXiv:2308.10606v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#36125;&#21494;&#26031;&#32593;&#32476;&#20998;&#26512;&#22797;&#26434;&#31995;&#32479;&#32423;&#32852;&#34892;&#20026;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#33021;&#22815;&#25551;&#36848;&#20107;&#20214;&#22312;&#31995;&#32479;&#20013;&#20256;&#25773;&#24182;&#35782;&#21035;&#21487;&#33021;&#23548;&#33268;&#32423;&#32852;&#34892;&#20026;&#30340;&#31995;&#32479;&#29366;&#24577;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#20855;&#26377;&#31616;&#21333;&#30340;&#22270;&#24418;&#34920;&#31034;&#21644;&#21487;&#35299;&#37322;&#30340;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20107;&#20214;&#30456;&#20114;&#20316;&#29992;&#30340;&#31995;&#32479;&#21487;&#33021;&#34920;&#29616;&#20986;&#20107;&#20214;&#22312;&#26102;&#38388;&#19978;&#32858;&#38598;&#30340;&#32423;&#32852;&#34892;&#20026;&#12290;&#34429;&#28982;&#32423;&#32852;&#26412;&#36523;&#21487;&#33021;&#20174;&#25968;&#25454;&#20013;&#26174;&#32780;&#26131;&#35265;&#65292;&#20294;&#29702;&#35299;&#35302;&#21457;&#23427;&#20204;&#30340;&#31995;&#32479;&#29366;&#24577;&#38750;&#24120;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36830;&#32493;&#26102;&#38388;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;CTBNs&#65289;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#22797;&#26434;&#31995;&#32479;&#20013;&#30340;&#32423;&#32852;&#34892;&#20026;&#12290;&#36825;&#20010;&#26694;&#26550;&#20801;&#35768;&#25105;&#20204;&#25551;&#36848;&#20107;&#20214;&#22914;&#20309;&#22312;&#31995;&#32479;&#20013;&#20256;&#25773;&#65292;&#24182;&#35782;&#21035;&#21487;&#33021;&#30340;&#23432;&#21355;&#29366;&#24577;&#65292;&#21363;&#21487;&#33021;&#23548;&#33268;&#21363;&#23558;&#21457;&#29983;&#32423;&#32852;&#34892;&#20026;&#30340;&#31995;&#32479;&#29366;&#24577;&#12290;&#27492;&#22806;&#65292;CTBNs&#20855;&#26377;&#31616;&#21333;&#30340;&#22270;&#24418;&#34920;&#31034;&#21644;&#21487;&#35299;&#37322;&#30340;&#36755;&#20986;&#65292;&#36825;&#23545;&#20110;&#19982;&#39046;&#22495;&#19987;&#23478;&#30340;&#27807;&#36890;&#38750;&#24120;&#37325;&#35201;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#20174;CTBNs&#20013;&#25552;&#21462;&#30693;&#35782;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#20010;&#22823;&#22411;&#24037;&#19994;&#31995;&#32479;&#20013;&#30340;&#35686;&#25253;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interacting systems of events may exhibit cascading behavior where events tend to be temporally clustered. While the cascades themselves may be obvious from the data, it is important to understand which states of the system trigger them. For this purpose, we propose a modeling framework based on continuous-time Bayesian networks (CTBNs) to analyze cascading behavior in complex systems. This framework allows us to describe how events propagate through the system and to identify likely sentry states, that is, system states that may lead to imminent cascading behavior. Moreover, CTBNs have a simple graphical representation and provide interpretable outputs, both of which are important when communicating with domain experts. We also develop new methods for knowledge extraction from CTBNs and we apply the proposed methodology to a data set of alarms in a large industrial system.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36828;&#31243;&#36861;&#36394;&#28798;&#23475;&#28779;&#28798;&#30340;&#21355;&#26143;&#28909;&#28857;&#25968;&#25454;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#23545;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20801;&#35768;&#26681;&#25454;&#38656;&#35201;&#35843;&#25972;&#21442;&#25968;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#20301;&#32622;&#21644;&#21355;&#26143;&#25968;&#25454;&#28304;&#12290;</title><link>http://arxiv.org/abs/2308.10505</link><description>&lt;p&gt;
&#29992;&#20110;&#36828;&#31243;&#36861;&#36394;&#28798;&#23475;&#28779;&#28798;&#30340;&#21355;&#26143;&#28909;&#28857;&#25968;&#25454;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely. (arXiv:2308.10505v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36828;&#31243;&#36861;&#36394;&#28798;&#23475;&#28779;&#28798;&#30340;&#21355;&#26143;&#28909;&#28857;&#25968;&#25454;&#32858;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#31354;&#38388;&#21644;&#26102;&#38388;&#19978;&#23545;&#28857;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20801;&#35768;&#26681;&#25454;&#38656;&#35201;&#35843;&#25972;&#21442;&#25968;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#20301;&#32622;&#21644;&#21355;&#26143;&#25968;&#25454;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#31354;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#22312;R&#36719;&#20214;&#21253;spotoroo&#20013;&#23454;&#29616;&#12290;&#26412;&#30740;&#31350;&#21463;&#21040;2019-2020&#24180;&#28595;&#22823;&#21033;&#20122;&#28798;&#38590;&#24615;&#28779;&#28798;&#30340;&#24433;&#21709;&#65292;&#24182;&#20511;&#21161;&#21355;&#26143;&#28909;&#28857;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#21463;&#21040;&#20004;&#31181;&#24050;&#26377;&#30340;&#26102;&#31354;&#32858;&#31867;&#31639;&#27861;&#30340;&#21551;&#21457;&#65292;&#22312;&#31354;&#38388;&#19978;&#25913;&#36827;&#20102;&#28857;&#30340;&#32858;&#31867;&#65292;&#24182;&#22312;&#36830;&#32493;&#30340;&#26102;&#38388;&#27573;&#20869;&#36319;&#36394;&#20854;&#36816;&#21160;&#12290;&#21516;&#26102;&#65292;&#35813;&#31639;&#27861;&#36824;&#20801;&#35768;&#26681;&#25454;&#38656;&#35201;&#35843;&#25972;&#37325;&#35201;&#21442;&#25968;&#65292;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#20301;&#32622;&#21644;&#21355;&#26143;&#25968;&#25454;&#28304;&#12290;&#20351;&#29992;&#28595;&#22823;&#21033;&#20122;&#32500;&#22810;&#21033;&#20122;&#24030;&#30340;&#28779;&#28798;&#25968;&#25454;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a spatiotemporal clustering algorithm and its implementation in the R package spotoroo. This work is motivated by the catastrophic bushfires in Australia throughout the summer of 2019-2020 and made possible by the availability of satellite hotspot data. The algorithm is inspired by two existing spatiotemporal clustering algorithms but makes enhancements to cluster points spatially in conjunction with their movement across consecutive time periods. It also allows for the adjustment of key parameters, if required, for different locations and satellite data sources. Bushfire data from Victoria, Australia, is used to illustrate the algorithm and its use within the package.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#38408;&#20540;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;ATH&#65289;&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;KPI&#30340;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26681;&#25454;&#25968;&#25454;&#20998;&#24067;&#30340;&#23616;&#37096;&#23646;&#24615;&#21160;&#24577;&#35843;&#25972;&#26816;&#27979;&#38408;&#20540;&#65292;&#24182;&#36866;&#24212;&#20110;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#30340;&#21464;&#21270;&#65292;&#20197;&#26368;&#23567;&#21270;&#35823;&#25253;&#21644;&#24212;&#23545;&#27010;&#24565;&#28418;&#31227;&#12290;</title><link>http://arxiv.org/abs/2308.10504</link><description>&lt;p&gt;
&#36866;&#24212;&#24615;&#38408;&#20540;&#21551;&#21457;&#24335;&#26041;&#27861;&#29992;&#20110;KPI&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adaptive Thresholding Heuristic for KPI Anomaly Detection. (arXiv:2308.10504v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10504
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#38408;&#20540;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;ATH&#65289;&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;KPI&#30340;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26681;&#25454;&#25968;&#25454;&#20998;&#24067;&#30340;&#23616;&#37096;&#23646;&#24615;&#21160;&#24577;&#35843;&#25972;&#26816;&#27979;&#38408;&#20540;&#65292;&#24182;&#36866;&#24212;&#20110;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#30340;&#21464;&#21270;&#65292;&#20197;&#26368;&#23567;&#21270;&#35823;&#25253;&#21644;&#24212;&#23545;&#27010;&#24565;&#28418;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26102;&#38388;&#24207;&#21015;&#39046;&#22495;&#20013;&#65292;&#24050;&#32463;&#25506;&#32034;&#20102;&#22823;&#37327;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#28982;&#32780;&#20174;&#21830;&#19994;&#35282;&#24230;&#35762;&#65292;&#24182;&#19981;&#26159;&#25152;&#26377;&#30340;&#24322;&#24120;&#37117;&#26159;&#25105;&#20204;&#20851;&#24515;&#30340;&#12290;&#29616;&#26377;&#30340;&#24322;&#24120;&#26816;&#27979;&#35299;&#20915;&#26041;&#26696;&#23616;&#38480;&#20110;&#26576;&#20123;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#38480;&#21046;&#20102;&#20854;&#22312;&#26356;&#24191;&#27867;&#30340;&#24322;&#24120;&#26816;&#27979;&#22330;&#26223;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#32593;&#32476;KPI&#65288;&#20851;&#38190;&#24615;&#33021;&#25351;&#26631;&#65289;&#24448;&#24448;&#34920;&#29616;&#20986;&#38543;&#26426;&#34892;&#20026;&#65292;&#20135;&#29983;&#32479;&#35745;&#24322;&#24120;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#19981;&#20250;&#23545;&#19994;&#21153;&#36816;&#33829;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#38656;&#35201;&#19968;&#31181;&#21551;&#21457;&#24335;&#26041;&#27861;&#26469;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;KPI&#20013;&#24322;&#24120;&#30340;&#21830;&#19994;&#23450;&#20041;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#38408;&#20540;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;ATH&#65289;&#65292;&#36890;&#36807;&#26681;&#25454;&#25968;&#25454;&#20998;&#24067;&#30340;&#23616;&#37096;&#23646;&#24615;&#21160;&#24577;&#35843;&#25972;&#26816;&#27979;&#38408;&#20540;&#65292;&#24182;&#36866;&#24212;&#20110;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#30340;&#21464;&#21270;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#39044;&#26399;&#30340;&#21608;&#26399;&#24615;&#21644;&#35266;&#23519;&#21040;&#30340;&#24322;&#24120;&#27604;&#20363;&#26469;&#30830;&#23450;&#38408;&#20540;&#65292;&#20197;&#26368;&#23567;&#21270;&#35823;&#25253;&#21644;&#24212;&#23545;&#27010;&#24565;&#28418;&#31227;&#12290;ATH&#21487;&#20197;&#19982;&#20219;&#20309;&#22522;&#30784;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
A plethora of outlier detectors have been explored in the time series domain, however, in a business sense, not all outliers are anomalies of interest. Existing anomaly detection solutions are confined to certain outlier detectors limiting their applicability to broader anomaly detection use cases. Network KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour producing statistical outliers, most of which do not adversely affect business operations. Thus, a heuristic is required to capture the business definition of an anomaly for time series KPI. This article proposes an Adaptive Thresholding Heuristic (ATH) to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns. The heuristic derives the threshold based on the expected periodicity and the observed proportion of anomalies minimizing false positives and addressing concept drift. ATH can be used in conjunction with any underlying s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#35774;&#35745;&#30340;&#21435;&#20013;&#24515;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GradientCoin&#65292;&#31867;&#20284;&#20110;&#27604;&#29305;&#24065;&#29616;&#37329;&#31995;&#32479;&#30340;&#36816;&#20316;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#20013;&#21270;&#21644;&#23433;&#20840;&#24615;&#30340;&#38382;&#39064;&#65292;&#20294;&#23454;&#26045;&#38590;&#24230;&#36739;&#22823;&#65292;&#32463;&#27982;&#19978;&#36739;&#26631;&#20934;&#27604;&#29305;&#24065;&#31995;&#32479;&#34920;&#29616;&#19981;&#20339;&#12290;</title><link>http://arxiv.org/abs/2308.10502</link><description>&lt;p&gt;
GradientCoin:&#19968;&#20010;&#28857;&#23545;&#28857;&#30340;&#21435;&#20013;&#24515;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
GradientCoin: A Peer-to-Peer Decentralized Large Language Models. (arXiv:2308.10502v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10502
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#35774;&#35745;&#30340;&#21435;&#20013;&#24515;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;GradientCoin&#65292;&#31867;&#20284;&#20110;&#27604;&#29305;&#24065;&#29616;&#37329;&#31995;&#32479;&#30340;&#36816;&#20316;&#26041;&#24335;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38598;&#20013;&#21270;&#21644;&#23433;&#20840;&#24615;&#30340;&#38382;&#39064;&#65292;&#20294;&#23454;&#26045;&#38590;&#24230;&#36739;&#22823;&#65292;&#32463;&#27982;&#19978;&#36739;&#26631;&#20934;&#27604;&#29305;&#24065;&#31995;&#32479;&#34920;&#29616;&#19981;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;2008&#24180;&#27604;&#29305;&#24065;&#30005;&#23376;&#29616;&#37329;&#31995;&#32479;&#25552;&#20986;&#20197;&#26469;&#65292;&#27604;&#29305;&#24065;&#24050;&#32463;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#20102;&#36807;&#21435;&#21313;&#24180;&#30340;&#32463;&#27982;&#31995;&#32479;&#12290;&#33258;2022&#24180;&#20197;&#26469;&#65292;&#22914;GPT&#31561;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35768;&#22810;&#29616;&#23454;&#29983;&#27963;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#36229;&#36234;&#20154;&#31867;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23384;&#22312;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#12290;&#20363;&#22914;&#65292;&#27169;&#22411;&#26159;&#38598;&#20013;&#21270;&#30340;&#65292;&#30001;&#29305;&#23450;&#21333;&#20301;&#25511;&#21046;&#12290;&#19968;&#20010;&#24369;&#28857;&#26159;&#65292;&#22914;&#26524;&#35813;&#21333;&#20301;&#20915;&#23450;&#20851;&#38381;&#27169;&#22411;&#65292;&#21017;&#26080;&#27861;&#20877;&#20351;&#29992;&#12290;&#31532;&#20108;&#20010;&#24369;&#28857;&#26159;&#32570;&#20047;&#23545;&#36825;&#20010;&#27169;&#22411;&#32972;&#21518;&#30340;&#20445;&#35777;&#24046;&#24322;&#65292;&#22240;&#20026;&#26576;&#20123;&#19981;&#35802;&#23454;&#30340;&#21333;&#20301;&#21487;&#33021;&#35774;&#35745;&#33258;&#24049;&#30340;&#27169;&#22411;&#24182;&#20026;&#20854;&#25552;&#20379;&#19981;&#20581;&#24247;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32431;&#29702;&#35770;&#35774;&#35745;&#30340;&#21435;&#20013;&#24515;&#21270;&#35821;&#35328;&#27169;&#22411;&#65292;&#20854;&#36816;&#20316;&#26041;&#24335;&#31867;&#20284;&#20110;&#27604;&#29305;&#24065;&#29616;&#37329;&#31995;&#32479;&#12290;&#28982;&#32780;&#65292;&#23454;&#26045;&#36825;&#26679;&#30340;&#31995;&#32479;&#21487;&#33021;&#20250;&#36935;&#21040;&#21508;&#31181;&#23454;&#38469;&#22256;&#38590;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#26032;&#31995;&#32479;&#22312;&#32463;&#27982;&#23398;&#19978;&#19981;&#22826;&#21487;&#33021;&#27604;&#26631;&#20934;&#30340;&#27604;&#29305;&#24065;&#31995;&#32479;&#34920;&#29616;&#26356;&#22909;&#12290;&#22240;&#27492;&#65292;&#21435;&#20013;&#24515;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#21160;&#26426;&#26159;&#20160;&#20040;&#21602;&#65311;
&lt;/p&gt;
&lt;p&gt;
Since 2008, after the proposal of a Bitcoin electronic cash system, Bitcoin has fundamentally changed the economic system over the last decade. Since 2022, large language models (LLMs) such as GPT have outperformed humans in many real-life tasks. However, these large language models have several practical issues. For example, the model is centralized and controlled by a specific unit. One weakness is that if that unit decides to shut down the model, it cannot be used anymore. The second weakness is the lack of guaranteed discrepancy behind this model, as certain dishonest units may design their own models and feed them unhealthy training data.  In this work, we propose a purely theoretical design of a decentralized LLM that operates similarly to a Bitcoin cash system. However, implementing such a system might encounter various practical difficulties. Furthermore, this new system is unlikely to perform better than the standard Bitcoin system in economics. Therefore, the motivation for d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#32534;&#30721;&#22120;&#21644;&#33258;&#21160;&#24494;&#20998;&#26469;&#37325;&#26500;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#20013;&#32570;&#22833;&#21464;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#65292;&#24182;&#22312;&#35813;&#35757;&#32451;&#20043;&#21518;&#22266;&#23450;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#36755;&#20837;&#21644;&#36755;&#20986;&#29305;&#24449;&#32452;&#21512;&#30340;&#37325;&#26500;&#12290;&#35813;&#26041;&#27861;&#22312;&#24378;&#38750;&#32447;&#24615;&#30005;&#23376;&#20803;&#20214;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#23545;&#20110;&#32570;&#22833;&#30340;&#21464;&#37327;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2308.10496</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#32534;&#30721;&#22120;&#21644;&#33258;&#21160;&#24494;&#20998;&#26469;&#37325;&#26500;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32570;&#22833;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series. (arXiv:2308.10496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#32534;&#30721;&#22120;&#21644;&#33258;&#21160;&#24494;&#20998;&#26469;&#37325;&#26500;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#20013;&#32570;&#22833;&#21464;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#65292;&#24182;&#22312;&#35813;&#35757;&#32451;&#20043;&#21518;&#22266;&#23450;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#65292;&#21487;&#20197;&#23454;&#29616;&#19981;&#21516;&#36755;&#20837;&#21644;&#36755;&#20986;&#29305;&#24449;&#32452;&#21512;&#30340;&#37325;&#26500;&#12290;&#35813;&#26041;&#27861;&#22312;&#24378;&#38750;&#32447;&#24615;&#30005;&#23376;&#20803;&#20214;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#23545;&#20110;&#32570;&#22833;&#30340;&#21464;&#37327;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#29616;&#26377;&#30340;&#40657;&#30418;&#24314;&#27169;&#26041;&#27861;&#21463;&#21040;&#22266;&#23450;&#36755;&#20837;&#21644;&#36755;&#20986;&#29305;&#24449;&#32452;&#21512;&#30340;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#37325;&#26500;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32570;&#22833;&#21464;&#37327;&#12290;&#37319;&#29992;&#24120;&#35268;&#26041;&#24335;&#35757;&#32451;&#19968;&#20010;&#33258;&#32534;&#30721;&#22120;&#65292;&#23558;&#27599;&#20010;&#29305;&#24449;&#37117;&#25918;&#22312;&#20004;&#20391;&#65292;&#28982;&#21518;&#22312;&#35813;&#35757;&#32451;&#20043;&#21518;&#22266;&#23450;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#12290;&#28982;&#21518;&#65292;&#23558;&#25628;&#32034;&#30340;&#21464;&#37327;&#23450;&#20041;&#20026;&#33258;&#32534;&#30721;&#22120;&#36755;&#20837;&#22788;&#30340;&#32570;&#22833;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#33258;&#21160;&#24494;&#20998;&#36827;&#34892;&#20248;&#21270;&#12290;&#36825;&#31181;&#20248;&#21270;&#26159;&#38024;&#23545;&#21487;&#29992;&#29305;&#24449;&#25439;&#22833;&#35745;&#31639;&#36827;&#34892;&#30340;&#12290;&#36890;&#36807;&#23558;&#25628;&#32034;&#30340;&#21464;&#37327;&#23450;&#20041;&#20026;&#32570;&#22833;&#21464;&#37327;&#24182;&#23545;&#20854;&#36827;&#34892;&#37325;&#26500;&#65292;&#21487;&#20197;&#23454;&#29616;&#35757;&#32451;&#27169;&#22411;&#30340;&#19981;&#21516;&#36755;&#20837;&#21644;&#36755;&#20986;&#29305;&#24449;&#32452;&#21512;&#12290;&#32780;&#19988;&#65292;&#26080;&#38656;&#20877;&#27425;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#21363;&#21487;&#26356;&#25913;&#32452;&#21512;&#12290;&#35813;&#26041;&#27861;&#22312;&#19968;&#20010;&#24378;&#38750;&#32447;&#24615;&#30005;&#23376;&#20803;&#20214;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#23545;&#20110;&#22235;&#20010;&#21464;&#37327;&#20013;&#30340;&#19968;&#20010;&#32570;&#22833;&#65292;&#35813;&#26041;&#27861;&#25928;&#26524;&#33391;&#22909;&#65292;&#29978;&#33267;&#23545;&#20110;&#22810;&#20010;&#32570;&#22833;&#21464;&#37327;&#20063;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20851;&#27880;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#21495;&#22312;&#22266;&#23450;&#22270;&#19978;&#30340;&#23398;&#20064;&#35774;&#32622;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36890;&#36807;&#22270;&#31895;&#21270;&#23454;&#29616;&#12290;&#36825;&#31687;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;&#36817;&#20284;&#23545;&#31216;&#24615;...</title><link>http://arxiv.org/abs/2308.10436</link><description>&lt;p&gt;
&#36817;&#20284;&#31561;&#21464;&#22270;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Approximately Equivariant Graph Networks. (arXiv:2308.10436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#36890;&#36807;&#32771;&#34385;&#20449;&#21495;&#22312;&#22266;&#23450;&#22270;&#19978;&#30340;&#23398;&#20064;&#35774;&#32622;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36890;&#36807;&#22270;&#31895;&#21270;&#23454;&#29616;&#12290;&#36825;&#31687;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;&#36817;&#20284;&#23545;&#31216;&#24615;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#23545;&#22270;&#20013;&#30340;&#33410;&#28857;&#37325;&#26032;&#25490;&#24207;&#20855;&#26377;&#32622;&#25442;&#31561;&#21464;&#24615;&#12290;GNNs&#30340;&#36825;&#31181;&#23545;&#31216;&#24615;&#24120;&#34987;&#19982;&#27431;&#20960;&#37324;&#24471;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#30340;&#24179;&#31227;&#31561;&#21464;&#24615;&#27604;&#36739;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#23545;&#31216;&#24615;&#26412;&#36136;&#19978;&#26159;&#19981;&#21516;&#30340;&#65306;CNNs&#30340;&#24179;&#31227;&#31561;&#21464;&#24615;&#23545;&#24212;&#20110;&#20316;&#29992;&#20110;&#22270;&#20687;&#20449;&#21495;&#30340;&#22266;&#23450;&#22495;&#30340;&#23545;&#31216;&#24615;&#65288;&#26377;&#26102;&#31216;&#20026;&#20027;&#21160;&#23545;&#31216;&#24615;&#65289;&#65292;&#32780;&#22312;GNNs&#20013;&#65292;&#20219;&#20309;&#32622;&#25442;&#37117;&#20316;&#29992;&#20110;&#22270;&#20449;&#21495;&#21644;&#22270;&#22495;&#65288;&#26377;&#26102;&#25551;&#36848;&#20026;&#34987;&#21160;&#23545;&#31216;&#24615;&#65289;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;GNNs&#30340;&#20027;&#21160;&#23545;&#31216;&#24615;&#65292;&#32771;&#34385;&#20449;&#21495;&#22312;&#19968;&#20010;&#22266;&#23450;&#22270;&#19978;&#36827;&#34892;&#23398;&#20064;&#30340;&#24773;&#20917;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;GNNs&#30340;&#33258;&#28982;&#23545;&#31216;&#24615;&#26159;&#22270;&#30340;&#33258;&#21516;&#26500;&#12290;&#30001;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#22270;&#24448;&#24448;&#26159;&#38750;&#23545;&#31216;&#30340;&#65292;&#25105;&#20204;&#36890;&#36807;&#24418;&#24335;&#21270;&#22270;&#31895;&#21270;&#26469;&#25918;&#26494;&#23545;&#31216;&#24615;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20559;&#24046;-&#26041;&#24046;&#20844;&#24335;&#26469;&#34913;&#37327;...
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that qu
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#27748;&#26222;&#26862;&#25277;&#26679;&#25506;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#21160;&#20316;&#38598;&#21512;&#22823;&#23567;&#20026;&#25351;&#25968;&#32423;&#21035;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2308.10238</link><description>&lt;p&gt;
Thompson Sampling&#29992;&#20110;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit. (arXiv:2308.10238v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10238
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#27748;&#26222;&#26862;&#25277;&#26679;&#25506;&#32034;&#31639;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#21160;&#20316;&#38598;&#21512;&#22823;&#23567;&#20026;&#25351;&#25968;&#32423;&#21035;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#23454;&#20540;&#32452;&#21512;&#32431;&#25506;&#32034;&#65288;R-CPE-MAB&#65289;&#38382;&#39064;&#12290;&#22312;R-CPE-MAB&#20013;&#65292;&#29609;&#23478;&#20174;&#32473;&#23450;&#30340;d&#20010;&#38543;&#26426;&#33218;&#20013;&#36873;&#25321;&#19968;&#20010;&#65292;&#27599;&#20010;&#33218;s&#30340;&#22870;&#21169;&#36981;&#24490;&#26410;&#30693;&#20998;&#24067;&#65292;&#20854;&#24179;&#22343;&#20540;&#20026;&#956;s&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#20013;&#65292;&#29609;&#23478;&#25289;&#21160;&#19968;&#20010;&#33218;&#24182;&#35266;&#23519;&#20854;&#22870;&#21169;&#12290;&#29609;&#23478;&#30340;&#30446;&#26631;&#26159;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#33218;&#25289;&#21160;&#27425;&#25968;&#26469;&#30830;&#23450;&#26368;&#20248;&#21160;&#20316;&#960;* = argmax&#960;&#8712;A &#956;T&#960;&#65292;&#20854;&#20013;A&#26159;&#26377;&#38480;&#22823;&#23567;&#30340;&#23454;&#20540;&#21160;&#20316;&#38598;&#21512;&#12290;&#20043;&#21069;&#30340;&#26041;&#27861;&#20551;&#35774;&#21160;&#20316;&#38598;&#21512;A&#30340;&#22823;&#23567;&#22312;d&#30340;&#22810;&#39033;&#24335;&#32423;&#21035;&#19978;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#27748;&#26222;&#26862;&#25277;&#26679;&#25506;&#32034;&#65288;GenTS-Explore&#65289;&#31639;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#21487;&#20197;&#35299;&#20915;&#21160;&#20316;&#38598;&#21512;&#22823;&#23567;&#22312;d&#30340;&#25351;&#25968;&#32423;&#21035;&#19978;&#30340;&#31639;&#27861;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#38382;&#39064;&#30456;&#20851;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown distribution with mean $\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#12290;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#22312;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.10145</link><description>&lt;p&gt;
Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#29992;&#20110;&#26465;&#20214;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Geodesic Generator for Conditional Distributions. (arXiv:2308.10145v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10145
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#12290;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#22312;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#32473;&#23450;&#29305;&#23450;&#26631;&#31614;&#30340;&#26679;&#26412;&#38656;&#35201;&#20272;&#35745;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;Wasserstein&#36317;&#31163;&#30340;&#21487;&#22788;&#29702;&#30340;&#19978;&#30028;&#65292;&#20197;&#24314;&#31435;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26465;&#20214;&#29983;&#25104;&#31639;&#27861;&#65292;&#20854;&#20013;&#26465;&#20214;&#20998;&#24067;&#23436;&#20840;&#30001;&#30001;&#32479;&#35745;&#36317;&#31163;&#23450;&#20041;&#30340;&#24230;&#37327;&#31354;&#38388;&#26469;&#34920;&#24449;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#26469;&#25552;&#20986;&#20102;Wasserstein&#20960;&#20309;&#29983;&#25104;&#22120;&#65292;&#19968;&#31181;&#23398;&#20064;Wasserstein&#20960;&#20309;&#30340;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#22120;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23398;&#20064;&#35266;&#23519;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#26368;&#20248;&#36755;&#36816;&#26144;&#23556;&#12290;&#32473;&#23450;&#20004;&#20010;&#35266;&#23519;&#22495;&#26631;&#31614;&#65292;&#26410;&#35266;&#23519;&#21040;&#30340;&#20013;&#38388;&#22495;&#30340;&#26465;&#20214;&#20998;&#24067;&#20301;&#20110;&#32473;&#23450;&#30340;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#20960;&#20309;&#20013;&#12290;&#22312;&#20197;&#20809;&#29031;&#26465;&#20214;&#20026;&#22495;&#26631;&#31614;&#30340;&#20154;&#33080;&#22270;&#20687;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the \textit{Wasserstein geodesic generator}, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#29992;&#20110;&#27169;&#25311;&#19981;&#26029;&#22686;&#38271;&#30340;&#31038;&#20132;&#32593;&#32476;&#20013;&#22810;&#26679;&#30340;&#20114;&#24800;&#34892;&#20026;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#29992;&#25143;&#23545;&#21463;&#27426;&#36814;&#29992;&#25143;&#30340;&#21560;&#24341;&#21147;&#20197;&#21450;&#20182;&#20204;&#23545;&#38142;&#25509;&#30340;&#24322;&#36136;&#24615;&#22238;&#24212;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#20027;&#20041;&#30340;&#25311;&#21512;&#25216;&#26415;&#65292;&#24182;&#24212;&#29992;&#20110;Facebook&#30041;&#35328;&#32593;&#32476;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.10113</link><description>&lt;p&gt;
&#29992;&#20855;&#26377;&#24322;&#36136;&#20114;&#24800;&#30340;&#38543;&#26426;&#32593;&#32476;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Modeling Random Networks with Heterogeneous Reciprocity. (arXiv:2308.10113v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10113
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#65292;&#29992;&#20110;&#27169;&#25311;&#19981;&#26029;&#22686;&#38271;&#30340;&#31038;&#20132;&#32593;&#32476;&#20013;&#22810;&#26679;&#30340;&#20114;&#24800;&#34892;&#20026;&#12290;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#29992;&#25143;&#23545;&#21463;&#27426;&#36814;&#29992;&#25143;&#30340;&#21560;&#24341;&#21147;&#20197;&#21450;&#20182;&#20204;&#23545;&#38142;&#25509;&#30340;&#24322;&#36136;&#24615;&#22238;&#24212;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#20027;&#20041;&#30340;&#25311;&#21512;&#25216;&#26415;&#65292;&#24182;&#24212;&#29992;&#20110;Facebook&#30041;&#35328;&#32593;&#32476;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#24800;&#24615;&#65292;&#25110;&#32773;&#35828;&#20010;&#20307;&#21576;&#29616;&#34892;&#20026;&#30340;&#36235;&#21516;&#24615;&#65292;&#26159;&#25551;&#36848;&#31038;&#20132;&#32593;&#32476;&#20013;&#20449;&#24687;&#20132;&#27969;&#30340;&#20851;&#38190;&#25351;&#26631;&#12290;&#31038;&#20132;&#32593;&#32476;&#20013;&#30340;&#29992;&#25143;&#24448;&#24448;&#21576;&#29616;&#19981;&#21516;&#31243;&#24230;&#30340;&#20114;&#24800;&#34892;&#20026;&#12290;&#36825;&#31181;&#34892;&#20026;&#30340;&#24046;&#24322;&#21487;&#33021;&#34920;&#26126;&#23384;&#22312;&#20197;&#19981;&#21516;&#36895;&#29575;&#20114;&#25442;&#38142;&#25509;&#30340;&#31038;&#21306;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#27169;&#25311;&#19981;&#26029;&#22686;&#38271;&#30340;&#31038;&#20132;&#32593;&#32476;&#20013;&#22810;&#26679;&#30340;&#20114;&#24800;&#34892;&#20026;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#24322;&#36136;&#20114;&#24800;&#24615;&#30340;&#20248;&#20808;&#36830;&#25509;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#27169;&#25311;&#20102;&#29992;&#25143;&#23545;&#21463;&#27426;&#36814;&#29992;&#25143;&#30340;&#21560;&#24341;&#21147;&#65292;&#20197;&#21450;&#20182;&#20204;&#23545;&#38142;&#25509;&#30340;&#24322;&#36136;&#24615;&#22238;&#24212;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#20027;&#20041;&#30340;&#29992;&#20110;&#22823;&#22411;&#32593;&#32476;&#30340;&#27169;&#22411;&#25311;&#21512;&#25216;&#26415;&#65292;&#20197;&#21450;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#21464;&#20998;&#26367;&#20195;&#26041;&#27861;&#12290;&#21516;&#26102;&#32771;&#34385;&#20102;&#24050;&#30693;&#21644;&#26410;&#30693;&#31038;&#21306;&#25968;&#37327;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20998;&#26512;&#19968;&#20010;Facebook&#30041;&#35328;&#32593;&#32476;&#65292;&#20854;&#20013;&#29992;&#25143;&#20855;&#26377;&#38750;&#22343;&#21248;&#30340;&#20114;&#24800;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities are known and unknown are both considered. We apply the presented methods to the analysis of a Facebook wallpost network where users have non-uniform reciprocal behav
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#21305;&#37197;&#30340;&#21322;&#38544;&#24335;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;SIVI-SM&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#21322;&#38544;&#24335;&#21464;&#20998;&#23478;&#26063;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#22788;&#29702;&#19981;&#21487;&#35745;&#31639;&#30340;&#21464;&#20998;&#23494;&#24230;&#26469;&#23454;&#29616;&#19982;MCMC&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#21508;&#31181;&#36125;&#21494;&#26031;&#25512;&#26029;&#20219;&#21153;&#20013;&#20248;&#20110;&#22522;&#20110;ELBO&#30340;SIVI&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.10014</link><description>&lt;p&gt;
&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#23454;&#29616;&#30340;&#21322;&#38544;&#24335;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Semi-Implicit Variational Inference via Score Matching. (arXiv:2308.10014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.10014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#21305;&#37197;&#30340;&#21322;&#38544;&#24335;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;SIVI-SM&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#21322;&#38544;&#24335;&#21464;&#20998;&#23478;&#26063;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#22788;&#29702;&#19981;&#21487;&#35745;&#31639;&#30340;&#21464;&#20998;&#23494;&#24230;&#26469;&#23454;&#29616;&#19982;MCMC&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#21508;&#31181;&#36125;&#21494;&#26031;&#25512;&#26029;&#20219;&#21153;&#20013;&#20248;&#20110;&#22522;&#20110;ELBO&#30340;SIVI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#38544;&#24335;&#21464;&#20998;&#25512;&#26029;&#65288;SIVI&#65289;&#36890;&#36807;&#32771;&#34385;&#20197;&#23618;&#27425;&#26041;&#24335;&#23450;&#20041;&#30340;&#38544;&#24335;&#21464;&#20998;&#20998;&#24067;&#65292;&#26497;&#22823;&#22320;&#20016;&#23500;&#20102;&#21464;&#20998;&#23478;&#26063;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21464;&#20998;&#20998;&#24067;&#30340;&#19981;&#21487;&#35745;&#31639;&#23494;&#24230;&#65292;&#24403;&#21069;&#30340;SIVI&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#26367;&#20195;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#25110;&#20351;&#29992;&#26114;&#36149;&#30340;&#20869;&#24490;&#29615;MCMC&#36816;&#34892;&#20197;&#36827;&#34892;&#26080;&#20559;ELBO&#30340;&#35757;&#32451;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SIVI-SM&#65292;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#21305;&#37197;&#30340;&#26367;&#20195;&#35757;&#32451;&#30446;&#26631;&#30340;SIVI&#26032;&#26041;&#27861;&#12290;&#21033;&#29992;&#21322;&#38544;&#24335;&#21464;&#20998;&#23478;&#26063;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20801;&#35768;&#20351;&#29992;&#21435;&#22122;&#24471;&#20998;&#21305;&#37197;&#33258;&#28982;&#22788;&#29702;&#19981;&#21487;&#35745;&#31639;&#30340;&#21464;&#20998;&#23494;&#24230;&#30340;&#26368;&#23567;&#26368;&#22823;&#24418;&#24335;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;SIVI-SM&#22312;&#21508;&#31181;&#36125;&#21494;&#26031;&#25512;&#26029;&#20219;&#21153;&#20013;&#20960;&#20046;&#19982;MCMC&#30340;&#20934;&#30830;&#24615;&#19968;&#33268;&#65292;&#24182;&#19988;&#20248;&#20110;&#22522;&#20110;ELBO&#30340;SIVI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-implicit variational inference (SIVI) greatly enriches the expressiveness of variational families by considering implicit variational distributions defined in a hierarchical manner. However, due to the intractable densities of variational distributions, current SIVI approaches often use surrogate evidence lower bounds (ELBOs) or employ expensive inner-loop MCMC runs for unbiased ELBOs for training. In this paper, we propose SIVI-SM, a new method for SIVI based on an alternative training objective via score matching. Leveraging the hierarchical structure of semi-implicit variational families, the score matching objective allows a minimax formulation where the intractable variational densities can be naturally handled with denoising score matching. We show that SIVI-SM closely matches the accuracy of MCMC and outperforms ELBO-based SIVI methods in a variety of Bayesian inference tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#21518;&#39564;&#26399;&#26395;&#34920;&#31034;&#26469;&#20272;&#35745;&#19982;&#35774;&#35745;&#21464;&#37327;&#30456;&#20851;&#30340;&#26799;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;UEEG-MCMC&#21644;BEEG-AP&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#19978;&#37117;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.09888</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26799;&#24230;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design. (arXiv:2308.09888v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09888
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#20013;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#36890;&#36807;&#21518;&#39564;&#26399;&#26395;&#34920;&#31034;&#26469;&#20272;&#35745;&#19982;&#35774;&#35745;&#21464;&#37327;&#30456;&#20851;&#30340;&#26799;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;UEEG-MCMC&#21644;BEEG-AP&#20004;&#31181;&#20272;&#35745;&#26041;&#27861;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#19978;&#37117;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#26088;&#22312;&#25214;&#21040;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26368;&#20339;&#23454;&#39564;&#26465;&#20214;&#65292;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#20248;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#20026;&#20102;&#39640;&#25928;&#22320;&#20248;&#21270;EIG&#65292;&#24448;&#24448;&#38656;&#35201;&#26799;&#24230;&#20449;&#24687;&#65292;&#22240;&#27492;&#20272;&#35745;EIG&#30340;&#26799;&#24230;&#33021;&#21147;&#23545;&#20110;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#35813;&#24037;&#20316;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#24320;&#21457;&#20272;&#35745;EIG&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23454;&#29616;EIG&#30340;&#39640;&#25928;&#20248;&#21270;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19982;&#35774;&#35745;&#21464;&#37327;&#30456;&#20851;&#30340;EIG&#26799;&#24230;&#30340;&#21518;&#39564;&#26399;&#26395;&#34920;&#31034;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;EIG&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;UEEG-MCMC&#21033;&#29992;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#29983;&#25104;&#30340;&#21518;&#39564;&#26679;&#26412;&#26469;&#20272;&#35745;EIG&#26799;&#24230;&#65292;&#32780;BEEG-AP&#21017;&#19987;&#27880;&#20110;&#36890;&#36807;&#21453;&#22797;&#20351;&#29992;&#21442;&#25968;&#26679;&#26412;&#26469;&#23454;&#29616;&#39640;&#27169;&#25311;&#25928;&#29575;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#21516;&#30340;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#19978;&#37117;&#33021;&#33719;&#24471;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Experimental Design (BED), which aims to find the optimal experimental conditions for Bayesian inference, is usually posed as to optimize the expected information gain (EIG). The gradient information is often needed for efficient EIG optimization, and as a result the ability to estimate the gradient of EIG is essential for BED problems. The primary goal of this work is to develop methods for estimating the gradient of EIG, which, combined with the stochastic gradient descent algorithms, result in efficient optimization of EIG. Specifically, we first introduce a posterior expected representation of the EIG gradient with respect to the design variables. Based on this, we propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate the EIG gradient, and BEEG-AP that focuses on achieving high simulation efficiency by repeatedly using parameter samples. Theoretical analysis and numerica
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#37096;&#20998;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#21644;&#25551;&#36848;A/B&#27979;&#35797;&#20013;&#30340;&#32593;&#32476;&#24178;&#25200;&#12290;&#36890;&#36807;&#32771;&#34385;&#28508;&#22312;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#21644;&#24314;&#31435;&#36866;&#21512;&#30340;&#26333;&#20809;&#26144;&#23556;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#23454;&#39564;&#21644;&#30495;&#23454;&#22823;&#35268;&#27169;&#27979;&#35797;&#20013;&#30340;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.09790</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#25551;&#36848;A/B&#27979;&#35797;&#20013;&#32593;&#32476;&#24178;&#25200;&#30340;&#20004;&#37096;&#20998;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Two-Part Machine Learning Approach to Characterizing Network Interference in A/B Testing. (arXiv:2308.09790v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#37096;&#20998;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35782;&#21035;&#21644;&#25551;&#36848;A/B&#27979;&#35797;&#20013;&#30340;&#32593;&#32476;&#24178;&#25200;&#12290;&#36890;&#36807;&#32771;&#34385;&#28508;&#22312;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#21644;&#24314;&#31435;&#36866;&#21512;&#30340;&#26333;&#20809;&#26144;&#23556;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#23454;&#39564;&#21644;&#30495;&#23454;&#22823;&#35268;&#27169;&#27979;&#35797;&#20013;&#30340;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#32593;&#32476;&#24178;&#25200;&#29616;&#35937;&#30340;&#24433;&#21709;&#65292;&#25511;&#21046;&#23454;&#39564;&#25110;"A/B&#27979;&#35797;"&#30340;&#21487;&#38752;&#24615;&#36890;&#24120;&#20250;&#21463;&#21040;&#25439;&#23475;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#21644;&#25551;&#36848;&#24322;&#36136;&#32593;&#32476;&#24178;&#25200;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32771;&#34385;&#20102;&#28508;&#22312;&#30340;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#65292;&#24182;&#33258;&#21160;&#21270;&#20102;"&#26333;&#20809;&#26144;&#23556;"&#30830;&#23450;&#30340;&#20219;&#21153;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#20004;&#20010;&#20027;&#35201;&#38480;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;"&#22240;&#26524;&#32593;&#32476;&#27169;&#24335;"&#65292;&#24182;&#37319;&#29992;&#36879;&#26126;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#24314;&#31435;&#26368;&#36866;&#21512;&#21453;&#26144;&#28508;&#22312;&#32593;&#32476;&#24178;&#25200;&#27169;&#24335;&#30340;&#26333;&#20809;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#20004;&#20010;&#21512;&#25104;&#23454;&#39564;&#21644;&#19968;&#20010;&#28041;&#21450;100-200&#19975;Instagram&#29992;&#25143;&#30340;&#30495;&#23454;&#22823;&#35268;&#27169;&#27979;&#35797;&#20013;&#30340;&#27169;&#25311;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#34920;&#29616;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#22914;&#22522;&#20110;&#35774;&#35745;&#30340;&#38598;&#32676;&#38543;&#26426;&#21270;&#21644;&#22522;&#20110;&#20998;&#26512;&#30340;&#37051;&#22495;&#26333;&#20809;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reliability of controlled experiments, or "A/B tests," can often be compromised due to the phenomenon of network interference, wherein the outcome for one unit is influenced by other units. To tackle this challenge, we propose a machine learning-based method to identify and characterize heterogeneous network interference. Our approach accounts for latent complex network structures and automates the task of "exposure mapping'' determination, which addresses the two major limitations in the existing literature. We introduce "causal network motifs'' and employ transparent machine learning models to establish the most suitable exposure mapping that reflects underlying network interference patterns. Our method's efficacy has been validated through simulations on two synthetic experiments and a real-world, large-scale test involving 1-2 million Instagram users, outperforming conventional methods such as design-based cluster randomization and analysis-based neighborhood exposure mapping. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;AdaSPS&#21644;AdaSLS&#20004;&#31181;&#26032;&#30340;&#21464;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;SGD&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#19979;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#24182;&#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#20445;&#25345;&#32447;&#24615;&#21644;&#20122;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.06058</link><description>&lt;p&gt;
&#24102;&#26377;Polyak&#27493;&#38271;&#21644;&#32447;&#24615;&#25628;&#32034;&#30340;&#33258;&#36866;&#24212;SGD: &#40065;&#26834;&#25910;&#25947;&#21644;&#26041;&#24046;&#20943;&#23567;
&lt;/p&gt;
&lt;p&gt;
Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence and Variance Reduction. (arXiv:2308.06058v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;AdaSPS&#21644;AdaSLS&#20004;&#31181;&#26032;&#30340;&#21464;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;SGD&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#19979;&#30340;&#25910;&#25947;&#38382;&#39064;&#65292;&#24182;&#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#20445;&#25345;&#32447;&#24615;&#21644;&#20122;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#30340;&#38543;&#26426;Polyak&#27493;&#38271; (SPS) &#21644;&#38543;&#26426;&#32447;&#24615;&#25628;&#32034; (SLS) &#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#26174;&#31034;&#20986;&#20102;&#26174;&#33879;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#19979;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#21482;&#33021;&#20445;&#35777;&#25910;&#25947;&#21040;&#19968;&#20010;&#35299;&#30340;&#37051;&#22495;&#65292;&#21487;&#33021;&#23548;&#33268;&#27604;&#21021;&#22987;&#29468;&#27979;&#26356;&#24046;&#30340;&#36755;&#20986;&#32467;&#26524;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#20154;&#20026;&#20943;&#23567;&#33258;&#36866;&#24212;&#27493;&#38271;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064; (Orvieto et al. [2022])&#65292;&#20294;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#20984;&#20989;&#25968;&#21644;&#36229;&#21442;&#25968;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#21464;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20570;&#20986;&#20102;&#20004;&#20010;&#36129;&#29486;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SPS&#21644;SLS&#21464;&#31181;&#65292;&#20998;&#21035;&#31216;&#20026;AdaSPS&#21644;AdaSLS&#65292;&#23427;&#20204;&#22312;&#38750;&#25554;&#20540;&#29615;&#22659;&#20013;&#20445;&#35777;&#25910;&#25947;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#36229;&#21442;&#25968;&#27169;&#22411;&#26102;&#20445;&#25345;&#20984;&#20989;&#25968;&#21644;&#24378;&#20984;&#20989;&#25968;&#30340;&#20122;&#32447;&#24615;&#21644;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;AdaSLS&#19981;&#38656;&#35201;&#23545;&#38382;&#39064;&#30456;&#20851;&#21442;&#25968;&#30340;&#20102;&#35299;&#65292;&#32780;AdaSPS&#21482;&#38656;&#35201;&#26368;&#20248;&#20989;&#25968;&#20540;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recently proposed stochastic Polyak stepsize (SPS) and stochastic line-search (SLS) for SGD have shown remarkable effectiveness when training over-parameterized models. However, in non-interpolation settings, both algorithms only guarantee convergence to a neighborhood of a solution which may result in a worse output than the initial guess. While artificially decreasing the adaptive stepsize has been proposed to address this issue (Orvieto et al. [2022]), this approach results in slower convergence rates for convex and over-parameterized models. In this work, we make two contributions: Firstly, we propose two new variants of SPS and SLS, called AdaSPS and AdaSLS, which guarantee convergence in non-interpolation settings and maintain sub-linear and linear convergence rates for convex and strongly convex functions when training over-parameterized models. AdaSLS requires no knowledge of problem-dependent parameters, and AdaSPS requires only a lower bound of the optimal function value 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2306.10590</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#21542;&#22312;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#20266;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#19979;&#30340;&#26377;&#25928;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#29256;&#26412;&#30340;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#25253;&#36947;&#30340;&#20197;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;(DML)&#20272;&#35745;&#37327;&#20026;&#20013;&#24515;&#30340;&#21517;&#20041;$(1-\alpha)$Wald&#32622;&#20449;&#21306;&#38388;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#65292;&#23545;Rotnitzky&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#21452;&#37325;&#31283;&#20581;(DR)&#20989;&#25968;&#31867;&#30340;&#20219;&#20309;&#25104;&#21592;&#36827;&#34892;&#26816;&#39564;&#12290;DR&#20989;&#25968;&#31867;&#22312;&#32463;&#27982;&#23398;&#21644;&#29983;&#29289;&#32479;&#35745;&#23398;&#20013;&#20855;&#26377;&#24191;&#27867;&#21644;&#26680;&#24515;&#30340;&#37325;&#35201;&#24615;&#12290;&#23427;&#20005;&#26684;&#21253;&#25324;&#20004;&#20010;&#31867;&#21035;&#65292;&#21363;(i)&#21487;&#20197;&#34987;&#20889;&#25104;&#26465;&#20214;&#26399;&#26395;&#30340;&#20223;&#23556;&#20989;&#25968;&#26399;&#26395;&#30340;&#22343;&#26041;&#36830;&#32493;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#26159;&#30001;Chernozhukov&#31561;&#20154;&#30740;&#31350;&#30340;&#65292;&#20197;&#21450;Robins&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#31867;&#21035;&#12290;&#30446;&#21069;DR&#20989;&#25968;&#30340;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#20540;&#26159;DML&#20272;&#35745;&#20540;&#12290;$\hat{\psi}_{1}$&#30340;&#20559;&#24046;&#21462;&#20915;&#20110;&#20004;&#20010;&#36741;&#21161;&#20989;&#25968;$b$&#21644;$p$&#30340;&#20272;&#35745;&#29575;&#30340;&#20056;&#31215;&#12290;&#26368;&#24120;&#35265;&#30340;&#26159;&#65292;&#20998;&#26512;&#24072;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#20197;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#26368;&#23567;&#21270;SGD&#22312;&#32447;&#23398;&#20064;&#30340;&#21518;&#24724;&#65292;&#33021;&#22815;&#23545;&#20998;&#24067;&#36716;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#36866;&#29992;&#20110;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#36890;&#24120;&#20250;&#22312;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#65292;&#33021;&#22815;&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2303.15634</link><description>&lt;p&gt;
&#23398;&#20064;&#36895;&#29575;&#34920;&#22312;&#20998;&#24067;&#36716;&#31227;&#26465;&#20214;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Learning Rate Schedules in the Presence of Distribution Shift. (arXiv:2303.15634v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15634
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#20197;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#26368;&#23567;&#21270;SGD&#22312;&#32447;&#23398;&#20064;&#30340;&#21518;&#24724;&#65292;&#33021;&#22815;&#23545;&#20998;&#24067;&#36716;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#36866;&#29992;&#20110;&#20984;&#25439;&#22833;&#20989;&#25968;&#21644;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#36890;&#24120;&#20250;&#22312;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#65292;&#33021;&#22815;&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#20102;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#20197;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#26102;&#26368;&#23567;&#21270;SGD&#22312;&#32447;&#23398;&#20064;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#36890;&#36807;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#26032;&#39062;&#20998;&#26512;&#65292;&#23436;&#20840;&#34920;&#24449;&#20102;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#12290;&#23545;&#20110;&#19968;&#33324;&#30340;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#23398;&#20064;&#36895;&#29575;&#34920;&#65292;&#23545;&#20998;&#24067;&#36716;&#31227;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#21482;&#26377;&#24120;&#25968;&#24046;&#24322;&#30340;&#21518;&#24724;&#19978;&#19979;&#30028;&#12290;&#23545;&#20110;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#22522;&#20110;&#20272;&#35745;&#27169;&#22411;&#30340;&#26799;&#24230;&#33539;&#25968;&#23450;&#20041;&#20102;&#19968;&#31181;&#21518;&#24724;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#26102;&#38388;&#34920;&#65292;&#20197;&#26368;&#23567;&#21270;&#24635;&#39044;&#26399;&#21518;&#24724;&#30340;&#19978;&#38480;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#25105;&#20204;&#39044;&#35745;&#25439;&#22833;&#39046;&#22495;&#30340;&#21464;&#21270;&#38656;&#35201;&#26356;&#22810;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#26368;&#20248;&#23398;&#20064;&#36895;&#29575;&#34920;&#36890;&#24120;&#20250;&#22312;&#25968;&#25454;&#20998;&#24067;&#36716;&#31227;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#38024;&#23545;&#39640;&#32500;&#22238;&#24402;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#39564;&#65292;&#20197;&#35828;&#26126;&#36825;&#20123;&#23398;&#20064;&#36895;&#29575;&#34920;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We design learning rate schedules that minimize regret for SGD-based online learning in the presence of a changing data distribution. We fully characterize the optimal learning rate schedule for online linear regression via a novel analysis with stochastic differential equations. For general convex loss functions, we propose new learning rate schedules that are robust to distribution shift, and we give upper and lower bounds for the regret that only differ by constants. For non-convex loss functions, we define a notion of regret based on the gradient norm of the estimated models and propose a learning schedule that minimizes an upper bound on the total expected regret. Intuitively, one expects changing loss landscapes to require more exploration, and we confirm that optimal learning rate schedules typically increase in the presence of distribution shift. Finally, we provide experiments for high-dimensional regression models and neural networks to illustrate these learning rate schedule
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20960;&#20046;&#32447;&#24615;&#26102;&#38388;&#20869;&#29992;&#40065;&#26834;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35266;&#23519;&#20960;&#20046;&#32447;&#24615;&#25968;&#37327;&#30340;&#26465;&#30446;&#21363;&#21487;&#24674;&#22797;&#30697;&#38453;$M$&#65292;&#27492;&#26041;&#27861;&#20811;&#26381;&#20102;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#38656;&#35201;&#31934;&#30830;&#35745;&#31639;&#30340;&#38480;&#21046;&#65292;&#26356;&#31526;&#21512;&#23454;&#38469;&#23454;&#29616;&#20013;&#23545;&#25928;&#29575;&#30340;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2302.11068</link><description>&lt;p&gt;
&#29992;&#40065;&#26834;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#26102;&#38388;&#20869;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time. (arXiv:2302.11068v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20960;&#20046;&#32447;&#24615;&#26102;&#38388;&#20869;&#29992;&#40065;&#26834;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35266;&#23519;&#20960;&#20046;&#32447;&#24615;&#25968;&#37327;&#30340;&#26465;&#30446;&#21363;&#21487;&#24674;&#22797;&#30697;&#38453;$M$&#65292;&#27492;&#26041;&#27861;&#20811;&#26381;&#20102;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#38656;&#35201;&#31934;&#30830;&#35745;&#31639;&#30340;&#38480;&#21046;&#65292;&#26356;&#31526;&#21512;&#23454;&#38469;&#23454;&#29616;&#20013;&#23545;&#25928;&#29575;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#30697;&#38453;$M\in \mathbb{R}^{m\times n}$&#65292;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#35201;&#27714;&#25105;&#20204;&#36890;&#36807;&#21482;&#35266;&#23519;&#19968;&#32452;&#25351;&#23450;&#30340;&#26465;&#30446;$\Omega\subseteq [m]\times [n]$&#26469;&#25214;&#21040;$M$&#30340;&#31209;&#20026;$k$&#30340;&#36817;&#20284;$UV^\top$&#65292;&#20854;&#20013;$U\in \mathbb{R}^{m\times k}$&#65292;$V\in \mathbb{R}^{n\times k}$&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#19968;&#31181;&#34987;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;--&#20132;&#26367;&#26368;&#23567;&#21270;&#26694;&#26550;&#12290;Jain&#12289;Netrapalli&#21644;Sanghavi~\cite{jns13}&#35777;&#26126;&#20102;&#22914;&#26524;$M$&#30340;&#34892;&#21644;&#21015;&#26159;&#19981;&#30456;&#24178;&#30340;&#65292;&#37027;&#20040;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#35266;&#23519;&#20960;&#20046;&#32447;&#24615;&#25968;&#37327;&#30340;&#26465;&#30446;&#21487;&#38752;&#22320;&#24674;&#22797;&#30697;&#38453;$M$&#12290;&#34429;&#28982;&#26679;&#26412;&#22797;&#26434;&#24230;&#20043;&#21518;&#34987;&#25913;&#36827;~\cite{glz17}&#65292;&#20294;&#20132;&#26367;&#26368;&#23567;&#21270;&#27493;&#39588;&#35201;&#27714;&#31934;&#30830;&#35745;&#31639;&#12290;&#36825;&#38459;&#30861;&#20102;&#26356;&#39640;&#25928;&#31639;&#27861;&#30340;&#24320;&#21457;&#65292;&#24182;&#26410;&#25551;&#36848;&#20132;&#26367;&#26368;&#23567;&#21270;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#20854;&#20013;&#26356;&#26032;&#36890;&#24120;&#26159;&#36817;&#20284;&#25191;&#34892;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in \mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a few entries specified by a set of entries $\Omega\subseteq [m]\times [n]$. In particular, we examine an approach that is widely used in practice -- the alternating minimization framework. Jain, Netrapalli and Sanghavi~\cite{jns13} showed that if $M$ has incoherent rows and columns, then alternating minimization provably recovers the matrix $M$ by observing a nearly linear in $n$ number of entries. While the sample complexity has been subsequently improved~\cite{glz17}, alternating minimization steps are required to be computed exactly. This hinders the development of more efficient algorithms and fails to depict the practical implementation of alternating minimization, where the updates are usually performed approximately in favor of efficiency.  In this p
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#35889;&#26041;&#27861;&#21644;&#35856;&#25391;&#23376;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#30340;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30740;&#31350;&#65292;&#36890;&#36807;&#29289;&#29702;&#35770;&#35777;&#25512;&#23548;&#20986;&#19968;&#31867;&#26032;&#22411;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35266;&#27979;&#21040;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09580</link><description>&lt;p&gt;
&#22522;&#20110;&#28151;&#21512;&#35889;&#26041;&#27861;&#21644;&#35856;&#25391;&#23376;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#30340;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes based on a Hybrid Spectral Method and the Harmonic Oscillator. (arXiv:2302.09580v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09580
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#35889;&#26041;&#27861;&#21644;&#35856;&#25391;&#23376;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#30340;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30740;&#31350;&#65292;&#36890;&#36807;&#29289;&#29702;&#35770;&#35777;&#25512;&#23548;&#20986;&#19968;&#31867;&#26032;&#22411;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35266;&#27979;&#21040;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#25552;&#20379;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#20989;&#25968;&#12290;&#21327;&#26041;&#24046;&#26680;&#26159;&#39640;&#26031;&#36807;&#31243;&#30340;&#20027;&#35201;&#24341;&#25806;&#65292;&#21253;&#21547;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#12290;&#23545;&#20110;&#20855;&#26377;&#26102;&#31354;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#65292;&#21512;&#36866;&#30340;&#26680;&#24212;&#35813;&#24314;&#27169;&#32852;&#21512;&#30340;&#26102;&#31354;&#20381;&#36182;&#20851;&#31995;&#12290;&#21487;&#20998;&#31163;&#30340;&#26102;&#31354;&#21327;&#26041;&#24046;&#26680;&#25552;&#20379;&#20102;&#31616;&#21333;&#21644;&#35745;&#31639;&#25928;&#29575;&#36739;&#39640;&#30340;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38750;&#21487;&#20998;&#31163;&#26680;&#21253;&#21547;&#20102;&#26356;&#22909;&#22320;&#25429;&#25417;&#35266;&#27979;&#21040;&#30340;&#30456;&#20851;&#24615;&#30340;&#26102;&#31354;&#20132;&#20114;&#20316;&#29992;&#12290;&#22823;&#22810;&#25968;&#20855;&#26377;&#26174;&#24335;&#34920;&#36798;&#24335;&#30340;&#38750;&#21487;&#20998;&#31163;&#26680;&#26159;&#22522;&#20110;&#25968;&#23398;&#32771;&#34385;&#65288;&#21487;&#20801;&#35768;&#26465;&#20214;&#65289;&#32780;&#38750;&#22522;&#20110;&#31532;&#19968;&#21407;&#29702;&#23548;&#20986;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#35770;&#35777;&#30340;&#28151;&#21512;&#35889;&#26041;&#27861;&#26469;&#29983;&#25104;&#21327;&#26041;&#24046;&#26680;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#25512;&#23548;&#20102;&#19968;&#31867;&#26032;&#22411;&#30340;&#29289;&#29702;&#21160;&#26426;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#65292;&#23427;&#20204;&#30340;&#26681;&#28304;&#26469;&#33258;&#38543;&#26426;&#32447;&#24615;...
&lt;/p&gt;
&lt;p&gt;
Gaussian processes provide a flexible, non-parametric framework for the approximation of functions in high-dimensional spaces. The covariance kernel is the main engine of Gaussian processes, incorporating correlations that underpin the predictive distribution. For applications with spatiotemporal datasets, suitable kernels should model joint spatial and temporal dependence. Separable space-time covariance kernels offer simplicity and computational efficiency. However, non-separable kernels include space-time interactions that better capture observed correlations. Most non-separable kernels that admit explicit expressions are based on mathematical considerations (admissibility conditions) rather than first-principles derivations. We present a hybrid spectral approach for generating covariance kernels which is based on physical arguments. We use this approach to derive a new class of physically motivated, non-separable covariance kernels which have their roots in the stochastic, linear, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#22303;&#22320;&#35206;&#30422;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#21355;&#26143;&#22270;&#20687;&#26102;&#38388;&#24207;&#21015;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#33021;&#21457;&#29616;&#22303;&#22320;&#35206;&#30422;&#31867;&#21035;&#20043;&#38388;&#30340;&#26377;&#36259;&#20449;&#24687;&#20851;&#31995;&#65292;&#21516;&#26102;&#36890;&#36807;&#40723;&#21169;&#26102;&#38388;&#36830;&#32493;&#30340;&#25200;&#21160;&#26469;&#24471;&#21040;&#26356;&#31232;&#30095;&#19988;&#21487;&#35299;&#37322;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2301.01520</link><description>&lt;p&gt;
&#25506;&#32034;&#21487;&#35299;&#37322;&#30340;&#22303;&#22320;&#35206;&#30422;&#26144;&#23556;&#65306;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#30340;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Towards Explainable Land Cover Mapping: a Counterfactual-based Strategy. (arXiv:2301.01520v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.01520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#20107;&#23454;&#30340;&#31574;&#30053;&#65292;&#29992;&#20110;&#22303;&#22320;&#35206;&#30422;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#21355;&#26143;&#22270;&#20687;&#26102;&#38388;&#24207;&#21015;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#33021;&#21457;&#29616;&#22303;&#22320;&#35206;&#30422;&#31867;&#21035;&#20043;&#38388;&#30340;&#26377;&#36259;&#20449;&#24687;&#20851;&#31995;&#65292;&#21516;&#26102;&#36890;&#36807;&#40723;&#21169;&#26102;&#38388;&#36830;&#32493;&#30340;&#25200;&#21160;&#26469;&#24471;&#21040;&#26356;&#31232;&#30095;&#19988;&#21487;&#35299;&#37322;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#35299;&#37322;&#26159;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35299;&#37322;&#24615;&#30340;&#26032;&#20852;&#24037;&#20855;&#12290;&#22312;&#32473;&#23450;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#26041;&#27861;&#23547;&#25214;&#24182;&#21521;&#29992;&#25143;&#26174;&#31034;&#20915;&#31574;&#36793;&#30028;&#19978;&#31867;&#20284;&#30340;&#26679;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22303;&#22320;&#35206;&#30422;&#20998;&#31867;&#20219;&#21153;&#30340;&#22810;&#31867;&#21035;&#35774;&#32622;&#20013;&#30340;&#21355;&#26143;&#22270;&#20687;&#26102;&#38388;&#24207;&#21015;&#30340;&#23545;&#25239;&#29983;&#25104;&#21453;&#20107;&#23454;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#30340;&#19968;&#20010;&#29420;&#29305;&#29305;&#28857;&#26159;&#22312;&#32473;&#23450;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#24773;&#20917;&#19979;&#23545;&#30446;&#26631;&#31867;&#21035;&#27809;&#26377;&#20808;&#39564;&#20551;&#35774;&#12290;&#36825;&#31181;&#22266;&#26377;&#30340;&#28789;&#27963;&#24615;&#20801;&#35768;&#21457;&#29616;&#22303;&#22320;&#35206;&#30422;&#31867;&#21035;&#20043;&#38388;&#30340;&#26377;&#36259;&#20449;&#24687;&#20851;&#31995;&#12290;&#21478;&#19968;&#20010;&#29305;&#28857;&#26159;&#40723;&#21169;&#21453;&#20107;&#23454;&#19982;&#21407;&#22987;&#26679;&#26412;&#20043;&#38388;&#20165;&#22312;&#19968;&#20010;&#23567;&#32780;&#32039;&#20945;&#30340;&#26102;&#38388;&#27573;&#20869;&#26377;&#25152;&#19981;&#21516;&#12290;&#36825;&#20123;&#26102;&#38388;&#36830;&#32493;&#30340;&#25200;&#21160;&#20801;&#35768;&#24471;&#21040;&#26356;&#31232;&#30095;&#19988;&#22240;&#27492;&#26356;&#21487;&#35299;&#37322;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#24378;&#21046;&#29983;&#25104;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#21512;&#29702;&#24615;/&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual explanations are an emerging tool to enhance interpretability of deep learning models. Given a sample, these methods seek to find and display to the user similar samples across the decision boundary. In this paper, we propose a generative adversarial counterfactual approach for satellite image time series in a multi-class setting for the land cover classification task. One of the distinctive features of the proposed approach is the lack of prior assumption on the targeted class for a given counterfactual explanation. This inherent flexibility allows for the discovery of interesting information on the relationship between land cover classes. The other feature consists of encouraging the counterfactual to differ from the original sample only in a small and compact temporal segment. These time-contiguous perturbations allow for a much sparser and, thus, interpretable solution. Furthermore, plausibility/realism of the generated counterfactual explanations is enforced via the
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#20559;&#24046;&#21644;&#22806;&#25512;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#24658;&#23450;&#27493;&#38271;&#21644;Markov&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;LSA&#36845;&#20195;&#20250;&#25910;&#25947;&#21040;&#21807;&#19968;&#30340;&#26497;&#38480;&#21644;&#31283;&#23450;&#20998;&#24067;&#65292;&#24182;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#30340;&#20960;&#20309;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#36825;&#20010;&#26497;&#38480;&#30340;&#20559;&#24046;&#19982;&#27493;&#38271;&#25104;&#27604;&#20363;&#65292;&#30452;&#33267;&#26356;&#39640;&#38454;&#39033;&#12290;&#22312;&#21487;&#36870;&#38142;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#20559;&#24046;&#19982;Markov&#25968;&#25454;&#30340;&#28151;&#21512;&#26102;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2210.00953</link><description>&lt;p&gt;
Markov&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#20559;&#24046;&#21644;&#22806;&#25512;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Bias and Extrapolation in Markovian Linear Stochastic Approximation with Constant Stepsizes. (arXiv:2210.00953v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#20559;&#24046;&#21644;&#22806;&#25512;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#24658;&#23450;&#27493;&#38271;&#21644;Markov&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;LSA&#36845;&#20195;&#20250;&#25910;&#25947;&#21040;&#21807;&#19968;&#30340;&#26497;&#38480;&#21644;&#31283;&#23450;&#20998;&#24067;&#65292;&#24182;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#30340;&#20960;&#20309;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#65292;&#36825;&#20010;&#26497;&#38480;&#30340;&#20559;&#24046;&#19982;&#27493;&#38271;&#25104;&#27604;&#20363;&#65292;&#30452;&#33267;&#26356;&#39640;&#38454;&#39033;&#12290;&#22312;&#21487;&#36870;&#38142;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#20559;&#24046;&#19982;Markov&#25968;&#25454;&#30340;&#28151;&#21512;&#26102;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;&#24658;&#23450;&#27493;&#38271;&#21644;Markov&#25968;&#25454;&#30340;&#32447;&#24615;&#38543;&#26426;&#36924;&#36817;&#65288;LSA&#65289;&#12290;&#23558;&#25968;&#25454;&#21644;LSA&#36845;&#20195;&#30340;&#32852;&#21512;&#36807;&#31243;&#35270;&#20026;&#26102;&#38388;&#40784;&#27425;Markov&#38142;&#65292;&#25105;&#20204;&#35777;&#26126;&#20854;&#22312;Wasserstein&#36317;&#31163;&#19979;&#25910;&#25947;&#21040;&#21807;&#19968;&#30340;&#26497;&#38480;&#21644;&#31283;&#23450;&#20998;&#24067;&#65292;&#24182;&#24314;&#31435;&#20102;&#38750;&#28176;&#36827;&#30340;&#20960;&#20309;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#35813;&#26497;&#38480;&#30340;&#20559;&#24046;&#21521;&#37327;&#21487;&#20197;&#36890;&#36807;&#27493;&#38271;&#23637;&#24320;&#20026;&#26080;&#38480;&#32423;&#25968;&#12290;&#22240;&#27492;&#65292;&#20559;&#24046;&#19982;&#27493;&#38271;&#25104;&#27604;&#20363;&#65292;&#30452;&#33267;&#26356;&#39640;&#38454;&#39033;&#12290;&#36825;&#20010;&#32467;&#26524;&#19982;i.i.d.&#25968;&#25454;&#19979;&#30340;LSA&#24418;&#25104;&#23545;&#27604;&#65292;&#20854;&#20013;&#20559;&#24046;&#20026;&#38646;&#12290;&#22312;&#21487;&#36870;&#38142;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20559;&#24046;&#19982;Markov&#25968;&#25454;&#30340;&#28151;&#21512;&#26102;&#38388;&#20043;&#38388;&#20851;&#31995;&#30340;&#19968;&#33324;&#29305;&#24449;&#65292;&#24314;&#31435;&#20102;&#23427;&#20204;&#22823;&#33268;&#25104;&#27491;&#27604;&#30340;&#32467;&#35770;&#12290;&#34429;&#28982;Polyak-Ruppert&#23614;&#24179;&#22343;&#20943;&#23569;&#20102;LSA&#36845;&#20195;&#30340;&#26041;&#24046;&#65292;&#20294;&#24182;&#19981;&#24433;&#21709;&#20559;&#24046;&#12290;&#20197;&#19978;&#29305;&#24449;&#20351;&#25105;&#20204;&#33021;&#22815;&#23637;&#31034;
&lt;/p&gt;
&lt;p&gt;
We consider Linear Stochastic Approximation (LSA) with a constant stepsize and Markovian data. Viewing the joint process of the data and LSA iterate as a time-homogeneous Markov chain, we prove its convergence to a unique limiting and stationary distribution in Wasserstein distance and establish non-asymptotic, geometric convergence rates. Furthermore, we show that the bias vector of this limit admits an infinite series expansion with respect to the stepsize. Consequently, the bias is proportional to the stepsize up to higher order terms. This result stands in contrast with LSA under i.i.d. data, for which the bias vanishes. In the reversible chain setting, we provide a general characterization of the relationship between the bias and the mixing time of the Markovian data, establishing that they are roughly proportional to each other.  While Polyak-Ruppert tail-averaging reduces the variance of the LSA iterates, it does not affect the bias. The above characterization allows us to show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20110;&#22312;&#26080;&#38480;&#32500;&#24230;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#20351;&#29992;&#30340;&#26680;Stein&#24046;&#24322;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#21033;&#29992;&#20613;&#37324;&#21494;&#34920;&#31034;&#20998;&#31163;&#27979;&#24230;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;KSD&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.04552</link><description>&lt;p&gt;
&#29992;&#20110;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#27979;&#24230;&#30340;&#26680;Stein&#24046;&#24322;&#30340;&#20613;&#37324;&#21494;&#34920;&#31034;&#21450;&#20854;&#22312;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Fourier representation of kernel Stein discrepancy with application to Goodness-of-Fit tests for measures on infinite dimensional Hilbert spaces. (arXiv:2206.04552v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20110;&#22312;&#26080;&#38480;&#32500;&#24230;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#27979;&#24230;&#20351;&#29992;&#30340;&#26680;Stein&#24046;&#24322;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#20102;&#21033;&#29992;&#20613;&#37324;&#21494;&#34920;&#31034;&#20998;&#31163;&#27979;&#24230;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;KSD&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;Stein&#24046;&#24322;(KSD)&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20110;&#26680;&#30340;&#27979;&#24230;&#24046;&#24322;&#25351;&#26631;&#65292;&#24120;&#29992;&#20110;&#23558;&#29992;&#25143;&#20174;&#20505;&#36873;&#27979;&#24230;&#20013;&#25910;&#38598;&#30340;&#26679;&#26412;&#19982;&#25351;&#23450;&#30340;&#30446;&#26631;&#27979;&#24230;&#36827;&#34892;&#27604;&#36739;&#30340;&#22330;&#26223;&#12290;KSD&#24050;&#32463;&#22312;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#12289;&#21442;&#25968;&#25512;&#26029;&#12289;MCMC&#36755;&#20986;&#35780;&#20272;&#21644;&#29983;&#25104;&#27169;&#22411;&#31561;&#22810;&#20010;&#39046;&#22495;&#24471;&#21040;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#35813;&#26041;&#27861;&#20165;&#38480;&#20110;&#26377;&#38480;&#32500;&#25968;&#25454;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;KSD&#22312;&#21487;&#20998;&#31163;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#39318;&#20010;&#20998;&#26512;&#65292;&#20363;&#22914;&#20989;&#25968;&#25968;&#25454;&#12290;&#20027;&#35201;&#32467;&#26524;&#26159;&#36890;&#36807;&#23558;&#27979;&#24230;&#26041;&#31243;&#29702;&#35770;&#19982;&#26680;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24471;&#21040;&#20102;KSD&#30340;&#26032;&#39062;&#20613;&#37324;&#21494;&#34920;&#31034;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;KSD&#33021;&#22815;&#21306;&#20998;&#27979;&#24230;&#65292;&#22240;&#27492;&#22312;&#23454;&#36341;&#20013;&#26159;&#26377;&#25928;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36890;&#36807;&#35299;&#32806;&#26680;&#20989;&#25968;&#19982;Stein&#31639;&#23376;&#30340;&#25928;&#24212;&#65292;&#25552;&#39640;&#20102;KSD&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein discrepancy (KSD) is a widely used kernel-based measure of discrepancy between probability measures. It is often employed in the scenario where a user has a collection of samples from a candidate probability measure and wishes to compare them against a specified target probability measure. KSD has been employed in a range of settings including goodness-of-fit testing, parametric inference, MCMC output assessment and generative modelling. However, so far the method has been restricted to finite-dimensional data. We provide the first analysis of KSD in the generality of data lying in a separable Hilbert space, for example functional data. The main result is a novel Fourier representation of KSD obtained by combining the theory of measure equations with kernel methods. This allows us to prove that KSD can separate measures and thus is valid to use in practice. Additionally, our results improve the interpretability of KSD by decoupling the effect of the kernel and Stein operat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25991;&#31456;&#23558;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#24314;&#27169;&#20026;&#29366;&#24577;&#31354;&#38388;&#26694;&#26550;&#65292;&#24182;&#21033;&#29992;&#32463;&#20856;&#25511;&#21046;&#29702;&#35770;&#20013;&#30340;&#20256;&#36882;&#20989;&#25968;&#33539;&#24335;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Adam&#21464;&#20307;&#65292;&#31216;&#20026;AdamSSM&#12290;&#35813;&#31639;&#27861;&#22312;&#22522;&#20934;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2206.02034</link><description>&lt;p&gt;
&#19968;&#20010;&#25511;&#21046;&#29702;&#35770;&#26694;&#26550;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#33258;&#36866;&#24212;&#26799;&#24230;&#20248;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Control Theoretic Framework for Adaptive Gradient Optimizers in Machine Learning. (arXiv:2206.02034v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25991;&#31456;&#23558;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#24314;&#27169;&#20026;&#29366;&#24577;&#31354;&#38388;&#26694;&#26550;&#65292;&#24182;&#21033;&#29992;&#32463;&#20856;&#25511;&#21046;&#29702;&#35770;&#20013;&#30340;&#20256;&#36882;&#20989;&#25968;&#33539;&#24335;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Adam&#21464;&#20307;&#65292;&#31216;&#20026;AdamSSM&#12290;&#35813;&#31639;&#27861;&#22312;&#22522;&#20934;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#24050;&#32463;&#22312;&#20248;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#21464;&#24471;&#27969;&#34892;&#36215;&#26469;&#65292;&#26368;&#36817;&#30340;&#20363;&#23376;&#21253;&#25324;AdaGrad&#21644;Adam&#12290;&#34429;&#28982;Adam&#36890;&#24120;&#25910;&#25947;&#26356;&#24555;&#65292;&#20294;&#26159;Adam&#30340;&#19968;&#20123;&#21464;&#20307;&#65292;&#27604;&#22914;AdaBelief&#31639;&#27861;&#65292;&#24050;&#32463;&#34987;&#25552;&#20986;&#26469;&#22686;&#24378;Adam&#19982;&#32463;&#20856;&#38543;&#26426;&#26799;&#24230;&#26041;&#27861;&#30456;&#27604;&#30340;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#26694;&#26550;&#29992;&#20110;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#29366;&#24577;&#31354;&#38388;&#26694;&#26550;&#20013;&#24314;&#27169;&#33258;&#36866;&#24212;&#26799;&#24230;&#26041;&#27861;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#31616;&#21270;&#33258;&#36866;&#24212;&#20248;&#21270;&#22120;&#65288;&#22914;AdaGrad&#12289;Adam&#21644;AdaBelief&#65289;&#30340;&#25910;&#25947;&#35777;&#26126;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#32463;&#20856;&#25511;&#21046;&#29702;&#35770;&#20013;&#30340;&#20256;&#36882;&#20989;&#25968;&#33539;&#24335;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Adam&#21464;&#20307;&#65292;&#31216;&#20026;AdamSSM&#12290;&#25105;&#20204;&#22312;&#20256;&#36882;&#20989;&#25968;&#20013;&#20174;&#24179;&#26041;&#26799;&#24230;&#21040;&#20108;&#38454;&#30697;&#20272;&#35745;&#20013;&#28155;&#21152;&#20102;&#19968;&#20010;&#21512;&#36866;&#30340;&#26497;&#28857;-&#38646;&#28857;&#23545;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;AdamSSM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#22312;&#22522;&#20934;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#24212;&#29992;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adaptive gradient methods have become popular in optimizing deep neural networks; recent examples include AdaGrad and Adam. Although Adam usually converges faster, variations of Adam, for instance, the AdaBelief algorithm, have been proposed to enhance Adam's poor generalization ability compared to the classical stochastic gradient method. This paper develops a generic framework for adaptive gradient methods that solve non-convex optimization problems. We first model the adaptive gradient methods in a state-space framework, which allows us to present simpler convergence proofs of adaptive optimizers such as AdaGrad, Adam, and AdaBelief. We then utilize the transfer function paradigm from classical control theory to propose a new variant of Adam, coined AdamSSM. We add an appropriate pole-zero pair in the transfer function from squared gradients to the second moment estimate. We prove the convergence of the proposed AdamSSM algorithm. Applications on benchmark machine learning tasks of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#19988;&#22312;&#25628;&#32034;&#21644;&#20195;&#29702;&#27169;&#22411;&#38454;&#27573;&#37117;&#20855;&#26377;&#21019;&#26032;&#20043;&#22788;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#28151;&#21512;&#27169;&#22411;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.01409</link><description>&lt;p&gt;
&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Hybrid Models for Mixed Variables in Bayesian Optimization. (arXiv:2206.01409v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.01409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#19988;&#22312;&#25628;&#32034;&#21644;&#20195;&#29702;&#27169;&#22411;&#38454;&#27573;&#37117;&#20855;&#26377;&#21019;&#26032;&#20043;&#22788;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#28151;&#21512;&#27169;&#22411;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23450;&#37327;&#65288;&#36830;&#32493;&#21644;&#25972;&#25968;&#65289;&#21644;&#23450;&#24615;&#65288;&#20998;&#31867;&#65289;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#23558;&#33945;&#29305;&#21345;&#27931;&#26641;&#25628;&#32034;&#32467;&#26500;&#65288;MCTS&#65289;&#29992;&#20110;&#20998;&#31867;&#21464;&#37327;&#65292;&#24182;&#23558;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#29992;&#20110;&#36830;&#32493;&#21464;&#37327;&#12290;&#22312;&#25628;&#32034;&#38454;&#27573;&#20013;&#65292;&#25105;&#20204;&#23558;&#39057;&#29575;&#27966;&#30340;&#19978;&#32622;&#20449;&#24230;&#26641;&#25628;&#32034;&#65288;UCTS&#65289;&#21644;&#36125;&#21494;&#26031;&#29380;&#21033;&#20811;&#38647;&#25628;&#32034;&#31574;&#30053;&#36827;&#34892;&#23545;&#27604;&#65292;&#23637;&#31034;&#20102;&#26641;&#32467;&#26500;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#34701;&#21512;&#12290;&#22312;&#20195;&#29702;&#27169;&#22411;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#38024;&#23545;&#28151;&#21512;&#21464;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#22312;&#32447;&#26680;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#65292;&#21253;&#25324;&#21160;&#24577;&#26680;&#36873;&#25321;&#12289;&#29420;&#29305;&#30340;UCTS&#65288;hybridM&#65289;&#21644;&#36125;&#21494;&#26031;&#26356;&#26032;&#31574;&#30053;&#65288;hybridD&#65289;&#65292;&#23558;&#25105;&#20204;&#30340;&#28151;&#21512;&#27169;&#22411;&#23450;&#20301;&#20026;&#28151;&#21512;&#21464;&#37327;&#20195;&#29702;&#27169;&#22411;&#30340;&#36827;&#27493;&#12290;&#25968;&#20540;&#23454;&#39564;&#20984;&#26174;&#20102;&#28151;&#21512;&#27169;&#22411;&#30340;&#20248;&#36234;&#24615;&#65292;&#20984;&#26174;&#20102;&#23427;&#20204;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new type of hybrid models for Bayesian optimization (BO) adept at managing mixed variables, encompassing both quantitative (continuous and integer) and qualitative (categorical) types. Our proposed new hybrid models merge Monte Carlo Tree Search structure (MCTS) for categorical variables with Gaussian Processes (GP) for continuous ones. Addressing efficiency in searching phase, we juxtapose the original (frequentist) upper confidence bound tree search (UCTS) and the Bayesian Dirichlet search strategies, showcasing the tree architecture's integration into Bayesian optimization. Central to our innovation in surrogate modeling phase is online kernel selection for mixed-variable BO. Our innovations, including dynamic kernel selection, unique UCTS (hybridM) and Bayesian update strategies (hybridD), position our hybrid models as an advancement in mixed-variable surrogate models. Numerical experiments underscore the hybrid models' superiority, highlighting their potentia
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#20013;&#35745;&#25968;&#21644;&#37319;&#26679;&#26377;&#21521;&#26080;&#29615;&#22270;&#12290;&#35813;&#31639;&#27861;&#35299;&#20915;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#38271;&#26399;&#26410;&#35299;&#20915;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#39564;&#35777;&#65292;&#21487;&#20197;&#22312;&#27963;&#36291;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#21644;&#22240;&#26524;&#25928;&#24212;&#35782;&#21035;&#26041;&#38754;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2205.02654</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#22312;&#35745;&#25968;&#21644;&#37319;&#26679;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent DAGs with Applications. (arXiv:2205.02654v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#20013;&#35745;&#25968;&#21644;&#37319;&#26679;&#26377;&#21521;&#26080;&#29615;&#22270;&#12290;&#35813;&#31639;&#27861;&#35299;&#20915;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#38271;&#26399;&#26410;&#35299;&#20915;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#20013;&#24471;&#21040;&#39564;&#35777;&#65292;&#21487;&#20197;&#22312;&#27963;&#36291;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#21644;&#22240;&#26524;&#25928;&#24212;&#35782;&#21035;&#26041;&#38754;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22270;&#24418;&#22240;&#26524;&#20998;&#26512;&#20013;&#65292;&#20174;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#20013;&#35745;&#25968;&#21644;&#37319;&#26679;&#26377;&#21521;&#26080;&#29615;&#22270;&#26159;&#22522;&#26412;&#20219;&#21153;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#20219;&#21153;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#23436;&#25104;&#65292;&#35299;&#20915;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#38271;&#26399;&#26410;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26377;&#25928;&#19988;&#26131;&#20110;&#23454;&#29616;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#30340;&#37027;&#26679;&#65292;&#36825;&#20123;&#31361;&#30772;&#20351;&#24471;&#22312;&#27963;&#36291;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#21644;&#22240;&#26524;&#25928;&#24212;&#35782;&#21035;&#26041;&#38754;&#65292;&#23545;&#20110;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#65292;&#21407;&#26412;&#35748;&#20026;&#19981;&#21487;&#34892;&#30340;&#31574;&#30053;&#23454;&#38469;&#21487;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counting and sampling directed acyclic graphs from a Markov equivalence class are fundamental tasks in graphical causal analysis. In this paper we show that these tasks can be performed in polynomial time, solving a long-standing open problem in this area. Our algorithms are effective and easily implementable. As we show in experiments, these breakthroughs make thought-to-be-infeasible strategies in active learning of causal structures and causal effect identification with regard to a Markov equivalence class practically applicable.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#33258;&#20030;&#27861;&#26469;&#36827;&#34892;&#40657;&#30418;&#36873;&#25321;&#24615;&#25512;&#26029;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#36890;&#36807;&#37325;&#22797;&#29983;&#25104;&#33258;&#20030;&#25968;&#25454;&#21644;&#36816;&#34892;&#36873;&#25321;&#31639;&#27861;&#65292;&#25105;&#20204;&#33021;&#22815;&#20272;&#35745;&#36873;&#25321;&#20107;&#20214;&#30340;&#27010;&#29575;&#65292;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#36827;&#34892;&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;&#36825;&#20010;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#32570;&#20047;&#31934;&#30830;&#25551;&#36848;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.14504</link><description>&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#33258;&#20030;&#27861;&#36827;&#34892;&#40657;&#30418;&#36873;&#25321;&#24615;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Black-box Selective Inference via Bootstrapping. (arXiv:2203.14504v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.14504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#33258;&#20030;&#27861;&#26469;&#36827;&#34892;&#40657;&#30418;&#36873;&#25321;&#24615;&#25512;&#26029;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#36890;&#36807;&#37325;&#22797;&#29983;&#25104;&#33258;&#20030;&#25968;&#25454;&#21644;&#36816;&#34892;&#36873;&#25321;&#31639;&#27861;&#65292;&#25105;&#20204;&#33021;&#22815;&#20272;&#35745;&#36873;&#25321;&#20107;&#20214;&#30340;&#27010;&#29575;&#65292;&#24182;&#22312;&#27492;&#22522;&#30784;&#19978;&#36827;&#34892;&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;&#36825;&#20010;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#32570;&#20047;&#31934;&#30830;&#25551;&#36848;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#38656;&#35201;&#23545;&#36873;&#25321;&#20107;&#20214;&#36827;&#34892;&#31934;&#30830;&#25551;&#36848;&#65292;&#20294;&#36890;&#24120;&#38500;&#20102;&#19968;&#20123;&#31034;&#20363;&#65288;&#22914;&#22871;&#32034;&#27861;&#65289;&#22806;&#65292;&#24456;&#38590;&#33719;&#24471;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#26469;&#20272;&#35745;&#36873;&#25321;&#20107;&#20214;&#65292;&#20174;&#32780;&#20419;&#36827;&#22312;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#30340;&#21487;&#34892;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#37325;&#22797;&#29983;&#25104;&#33258;&#20030;&#25968;&#25454;&#24182;&#22312;&#26032;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#36873;&#25321;&#31639;&#27861;&#26469;&#36827;&#34892;&#12290;&#21033;&#29992;&#36873;&#25321;&#31639;&#27861;&#30340;&#36755;&#20986;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#36873;&#25321;&#27010;&#29575;&#20272;&#35745;&#20026;&#29305;&#23450;&#25688;&#35201;&#32479;&#35745;&#37327;&#30340;&#20989;&#25968;&#12290;&#36825;&#23548;&#33268;&#20102;&#22312;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#30340;&#25968;&#25454;&#20998;&#24067;&#30340;&#20272;&#35745;&#65292;&#20026;&#26465;&#20214;&#36873;&#25321;&#24615;&#25512;&#26029;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#20445;&#35777;&#65292;&#20551;&#35774;&#30456;&#20851;&#32479;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24120;&#24615;&#21644;&#36873;&#25321;&#27010;&#29575;&#30340;&#20934;&#30830;&#20272;&#35745;&#12290;&#36890;&#36807;&#22810;&#31181;&#32570;&#20047;&#31934;&#30830;&#25551;&#36848;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional selective inference requires an exact characterization of the selection event, which is often unavailable except for a few examples like the lasso. This work addresses this challenge by introducing a generic approach to estimate the selection event, facilitating feasible inference conditioned on the selection event. The method proceeds by repeatedly generating bootstrap data and running the selection algorithm on the new datasets. Using the outputs of the selection algorithm, we can estimate the selection probability as a function of certain summary statistics. This leads to an estimate of the distribution of the data conditioned on the selection event, which forms the basis for conditional selective inference. We provide a theoretical guarantee assuming both asymptotic normality of relevant statistics and accurate estimation of the selection probability. The applicability of the proposed method is demonstrated through a variety of problems that lack exact characterizations
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26680;&#26816;&#39564;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#27979;&#35797;&#65292;&#31216;&#20026;MMDAgg&#65292;&#20197;&#35299;&#20915;&#24179;&#28369;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2110.15073</link><description>&lt;p&gt;
MMD&#32858;&#21512;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
MMD Aggregated Two-Sample Test. (arXiv:2110.15073v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.15073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26680;&#26816;&#39564;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#27979;&#35797;&#65292;&#31216;&#20026;MMDAgg&#65292;&#20197;&#35299;&#20915;&#24179;&#28369;&#21442;&#25968;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#38750;&#21442;&#25968;&#21452;&#26679;&#26412;&#26680;&#26816;&#39564;&#12290;&#39318;&#20808;&#65292;&#23545;&#20110;&#22266;&#23450;&#30340;&#26680;&#65292;&#25105;&#20204;&#20351;&#29992;&#25490;&#21015;&#25110;&#37326;&#34542;&#33258;&#20030;&#65288;wild bootstrap&#65289;&#26500;&#36896;&#20102;&#19968;&#20010;MMD&#26816;&#39564;&#65292;&#36825;&#20004;&#31181;&#27969;&#34892;&#30340;&#25968;&#20540;&#31243;&#24207;&#21487;&#30830;&#23450;&#27979;&#35797;&#38408;&#20540;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#27979;&#35797;&#21487;&#20197;&#22312;&#38750;&#28176;&#36817;&#24773;&#20917;&#19979;&#25511;&#21046;I&#22411;&#38169;&#35823;&#30340;&#27010;&#29575;&#12290;&#22240;&#27492;&#65292;&#21363;&#20351;&#22312;&#23567;&#26679;&#26412;&#24773;&#20917;&#19979;&#65292;&#23427;&#20173;&#28982;&#20445;&#25345;&#33391;&#22909;&#30340;&#26657;&#20934;&#24615;&#65292;&#36825;&#19982;&#20197;&#21069;&#30340;MMD&#27979;&#35797;&#19981;&#21516;&#65292;&#21069;&#32773;&#21482;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#20445;&#35777;&#27491;&#30830;&#30340;&#27979;&#35797;&#27700;&#24179;&#12290;&#24403;&#23494;&#24230;&#24046;&#24322;&#22312;Sobolev&#29699;&#20013;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;MMD&#26816;&#39564;&#22312;&#29305;&#23450;&#30340;&#26680;&#20989;&#25968;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#35813;&#26680;&#20989;&#25968;&#20381;&#36182;&#20110;Sobolev&#29699;&#30340;&#24179;&#28369;&#21442;&#25968;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20010;&#21442;&#25968;&#26159;&#26410;&#30693;&#30340;&#65292;&#22240;&#27492;&#19981;&#33021;&#20351;&#29992;&#20855;&#26377;&#29305;&#23450;&#26680;&#30340;&#26368;&#20248;MMD&#26816;&#39564;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#24179;&#22343;&#27979;&#35797;&#65292;&#31216;&#20026;MMDAgg&#12290;&#27979;&#35797;&#21151;&#29575;&#22312;Sobolev&#29699;&#30340;&#24179;&#28369;&#21442;&#25968;&#19978;&#26368;&#22823;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose two novel nonparametric two-sample kernel tests based on the Maximum Mean Discrepancy (MMD). First, for a fixed kernel, we construct an MMD test using either permutations or a wild bootstrap, two popular numerical procedures to determine the test threshold. We prove that this test controls the probability of type I error non-asymptotically. Hence, it can be used reliably even in settings with small sample sizes as it remains well-calibrated, which differs from previous MMD tests which only guarantee correct test level asymptotically. When the difference in densities lies in a Sobolev ball, we prove minimax optimality of our MMD test with a specific kernel depending on the smoothness parameter of the Sobolev ball. In practice, this parameter is unknown and, hence, the optimal MMD test with this particular kernel cannot be used. To overcome this issue, we construct an aggregated test, called MMDAgg, which is adaptive to the smoothness parameter. The test power is maximised ove
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31038;&#20132;&#32593;&#32476;&#27169;&#22411;&#20013;&#26816;&#27979;&#24322;&#24120;&#36793;&#32536;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#21487;&#20132;&#25442;&#24615;&#21644;&#19968;&#33268;&#39044;&#27979;&#29702;&#35770;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2109.12727</link><description>&lt;p&gt;
&#22312;&#36793;&#32536;&#21487;&#20132;&#25442;&#30340;&#31038;&#20132;&#32593;&#32476;&#27169;&#22411;&#20013;&#30340;&#24322;&#24120;&#36793;&#32536;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Anomalous Edge Detection in Edge Exchangeable Social Network Models. (arXiv:2109.12727v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12727
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31038;&#20132;&#32593;&#32476;&#27169;&#22411;&#20013;&#26816;&#27979;&#24322;&#24120;&#36793;&#32536;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#21487;&#20132;&#25442;&#24615;&#21644;&#19968;&#33268;&#39044;&#27979;&#29702;&#35770;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27169;&#25311;&#31038;&#20132;&#32593;&#32476;&#30340;&#26377;&#21521;&#22270;&#20013;&#26816;&#27979;&#24322;&#24120;&#36793;&#32536;&#12290;&#25105;&#20204;&#21033;&#29992;&#36793;&#32536;&#21487;&#20132;&#25442;&#24615;&#20316;&#20026;&#37492;&#21035;&#24322;&#24120;&#36793;&#32536;&#21644;&#27491;&#24120;&#36793;&#32536;&#30340;&#26631;&#20934;&#12290;&#28982;&#21518;&#25105;&#20204;&#22522;&#20110;&#19968;&#33268;&#39044;&#27979;&#29702;&#35770;&#25552;&#20986;&#20102;&#19968;&#31181;&#24322;&#24120;&#26816;&#27979;&#22120;&#65307;&#35813;&#26816;&#27979;&#22120;&#20855;&#26377;&#20445;&#35777;&#30340;&#35823;&#21028;&#29575;&#19978;&#30028;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#31639;&#27861;&#30456;&#23545;&#20110;&#22522;&#20934;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies detecting anomalous edges in directed graphs that model social networks. We exploit edge exchangeability as a criterion for distinguishing anomalous edges from normal edges. Then we present an anomaly detector based on conformal prediction theory; this detector has a guaranteed upper bound for false positive rate. In numerical experiments, we show that the proposed algorithm achieves superior performance to baseline methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#19982;&#32852;&#21512;&#31354;&#38388;&#30340;Wasserstein&#36317;&#31163;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#22495;&#19981;&#21464;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.04923</link><description>&lt;p&gt;
&#36890;&#36807;&#32852;&#21512;Wasserstein&#36317;&#31163;&#26368;&#23567;&#21270;&#23398;&#20064;&#22495;&#19981;&#21464;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization. (arXiv:2106.04923v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.04923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#19982;&#32852;&#21512;&#31354;&#38388;&#30340;Wasserstein&#36317;&#31163;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#22495;&#19981;&#21464;&#34920;&#31034;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#39046;&#22495;&#20559;&#31227;&#24456;&#24120;&#35265;&#65292;&#20363;&#22914;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#30340;&#26469;&#28304;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24212;&#35813;&#22312;&#19981;&#32771;&#34385;&#36825;&#20123;&#39046;&#22495;&#20559;&#31227;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#33391;&#22909;&#65292;&#20363;&#22914;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#22495;&#19981;&#21464;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#24120;&#35265;&#30340;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#20989;&#25968;&#23545;&#27169;&#22411;&#22312;&#19981;&#21516;&#39046;&#22495;&#19978;&#30340;&#19968;&#33268;&#34920;&#29616;&#27809;&#26377;&#24378;&#26377;&#21147;&#30340;&#20445;&#38556;&#65292;&#29305;&#21035;&#26159;&#27169;&#22411;&#22312;&#26576;&#20010;&#39046;&#22495;&#19978;&#30340;&#34920;&#29616;&#26159;&#21542;&#26159;&#20197;&#25439;&#23475;&#20854;&#20182;&#39046;&#22495;&#34920;&#29616;&#20026;&#20195;&#20215;&#30340;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#26032;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#36890;&#36807;&#25552;&#20986;&#32463;&#20856;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#25439;&#22833;&#21644;&#32852;&#21512;&#31354;&#38388;&#65288;&#34920;&#31034;&#31354;&#38388;&#21644;&#36755;&#20986;&#31354;&#38388;&#65289;&#20013;&#30340;Wasserstein&#36317;&#31163;&#20043;&#38388;&#30340;&#19968;&#32452;&#25968;&#23398;&#20851;&#31995;&#12290;&#25105;&#20204;&#35777;&#26126;&#20998;&#31867;&#25110;&#22238;&#24402;&#25439;&#22833;&#19982;GAN&#31867;&#22411;&#30340;&#39046;&#22495;&#21028;&#21035;&#22120;&#32467;&#21512;&#26102;&#24418;&#25104;&#20102;&#30495;&#23454;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#12290;&#36825;&#24847;&#21619;&#30528;&#26356;&#19981;&#21464;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain shifts in the training data are common in practical applications of machine learning; they occur for instance when the data is coming from different sources. Ideally, a ML model should work well independently of these shifts, for example, by learning a domain-invariant representation. However, common ML losses do not give strong guarantees on how consistently the ML model performs for different domains, in particular, whether the model performs well on a domain at the expense of its performance on another domain. In this paper, we build new theoretical foundations for this problem, by contributing a set of mathematical relations between classical losses for supervised ML and the Wasserstein distance in joint space (i.e. representation and output space). We show that classification or regression losses, when combined with a GAN-type discriminator between domains, form an upper-bound to the true Wasserstein distance between domains. This implies a more invariant representation and
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21028;&#21035;&#36125;&#21494;&#26031;&#28388;&#27874;&#30340;&#26041;&#27861;&#65292;&#20026;&#38543;&#26426;&#29275;&#39039;&#27861;&#22312;&#26368;&#23567;&#21270;&#23545;&#25968;&#20984;&#20989;&#25968;&#20013;&#25552;&#20379;&#20102;&#21160;&#21147;&#12290;&#36890;&#36807;&#32771;&#34385;&#25972;&#20010;&#21382;&#21490;&#20449;&#24687;&#24418;&#25104;&#26356;&#26032;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#36845;&#20195;&#24320;&#22987;&#26102;&#20943;&#24369;&#26087;&#35266;&#27979;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2104.12949</link><description>&lt;p&gt;
&#21028;&#21035;&#36125;&#21494;&#26031;&#28388;&#27874;&#20026;&#38543;&#26426;&#29275;&#39039;&#27861;&#22312;&#26368;&#23567;&#21270;&#23545;&#25968;&#20984;&#20989;&#25968;&#20013;&#25552;&#20379;&#21160;&#21147;
&lt;/p&gt;
&lt;p&gt;
Discriminative Bayesian filtering lends momentum to the stochastic Newton method for minimizing log-convex functions. (arXiv:2104.12949v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.12949
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21028;&#21035;&#36125;&#21494;&#26031;&#28388;&#27874;&#30340;&#26041;&#27861;&#65292;&#20026;&#38543;&#26426;&#29275;&#39039;&#27861;&#22312;&#26368;&#23567;&#21270;&#23545;&#25968;&#20984;&#20989;&#25968;&#20013;&#25552;&#20379;&#20102;&#21160;&#21147;&#12290;&#36890;&#36807;&#32771;&#34385;&#25972;&#20010;&#21382;&#21490;&#20449;&#24687;&#24418;&#25104;&#26356;&#26032;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22312;&#36845;&#20195;&#24320;&#22987;&#26102;&#20943;&#24369;&#26087;&#35266;&#27979;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26368;&#23567;&#21270;&#19968;&#32452;&#23545;&#25968;&#20984;&#20989;&#25968;&#30340;&#24179;&#22343;&#20540;&#65292;&#38543;&#26426;&#29275;&#39039;&#27861;&#36890;&#36807;&#23545;&#23436;&#25972;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#36827;&#34892;&#23376;&#37319;&#26679;&#29256;&#26412;&#30340;&#36845;&#20195;&#26356;&#26032;&#20854;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#20248;&#21270;&#38382;&#39064;&#32622;&#20110;&#19968;&#31181;&#20855;&#26377;&#21028;&#21035;&#24615;&#35266;&#27979;&#36807;&#31243;&#30340;&#28508;&#22312;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#39034;&#24207;&#36125;&#21494;&#26031;&#25512;&#26029;&#32972;&#26223;&#20013;&#12290;&#24212;&#29992;&#36125;&#21494;&#26031;&#28388;&#27874;&#21487;&#20197;&#24471;&#21040;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#22312;&#24418;&#25104;&#26356;&#26032;&#26102;&#32771;&#34385;&#20102;&#26799;&#24230;&#21644;&#28023;&#26862;&#30697;&#38453;&#30340;&#25972;&#20010;&#21382;&#21490;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;&#30697;&#38453;&#30340;&#26465;&#20214;&#65292;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#26087;&#35266;&#27979;&#30340;&#24433;&#21709;&#38543;&#26102;&#38388;&#20943;&#24369;&#65292;&#31867;&#20284;&#20110;Polyak&#30340;&#37325;&#29699;&#21160;&#21147;&#12290;&#36890;&#36807;&#19968;&#20010;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#24182;&#22238;&#39038;&#20102;&#38543;&#26426;&#29275;&#39039;&#27861;&#30340;&#20854;&#20182;&#30456;&#20851;&#21019;&#26032;&#12290;
&lt;/p&gt;
&lt;p&gt;
To minimize the average of a set of log-convex functions, the stochastic Newton method iteratively updates its estimate using subsampled versions of the full objective's gradient and Hessian. We contextualize this optimization problem as sequential Bayesian inference on a latent state-space model with a discriminatively-specified observation process. Applying Bayesian filtering then yields a novel optimization algorithm that considers the entire history of gradients and Hessians when forming an update. We establish matrix-based conditions under which the effect of older observations diminishes over time, in a manner analogous to Polyak's heavy ball momentum. We illustrate various aspects of our approach with an example and review other relevant innovations for the stochastic Newton method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2012.14331</link><description>&lt;p&gt;
&#19968;&#31181;&#25972;&#21512;&#21644;&#20998;&#31867;&#27491;&#24577;&#20998;&#24067;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.14331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#27491;&#24577;&#27010;&#29575;&#20998;&#24067;&#22312;&#27169;&#25311;&#19981;&#30830;&#23450;&#24615;&#20915;&#31574;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#38656;&#35201;&#22312;&#29305;&#23450;&#21306;&#22495;&#20869;&#23545;&#36825;&#20123;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#65292;&#36825;&#22312;&#19981;&#21516;&#30340;&#27169;&#22411;&#20013;&#21487;&#20197;&#26377;&#24456;&#22823;&#30340;&#24046;&#24322;&#12290;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#65292;&#30446;&#21069;&#19981;&#23384;&#22312;&#36890;&#29992;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#12289;&#26631;&#20934;&#25968;&#20540;&#26041;&#27861;&#25110;&#36719;&#20214;&#26469;&#35745;&#31639;&#36825;&#20123;&#31215;&#20998;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25968;&#23398;&#32467;&#26524;&#21644;&#24320;&#28304;&#36719;&#20214;&#65292;&#21487;&#20197;&#25552;&#20379;&#20197;&#19979;&#20869;&#23481;&#65306;&#65288;i&#65289;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#20219;&#24847;&#22495;&#20869;&#27861;&#21521;&#30340;&#27010;&#29575;&#65292;&#65288;ii&#65289;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#27010;&#29575;&#23494;&#24230;&#12289;&#32047;&#31215;&#20998;&#24067;&#21644;&#36870;&#32047;&#31215;&#20998;&#24067;&#65292;&#65288;iii&#65289;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#31867;&#35823;&#24046;&#12289;&#36125;&#21494;&#26031;&#26368;&#20248;&#36776;&#21035;&#25351;&#25968;&#20197;&#21450;&#20854;&#19982;&#24037;&#20316;&#29305;&#24449;&#26354;&#32447;&#30340;&#20851;&#31995;&#65292;&#65288;iv&#65289;&#27492;&#31867;&#38382;&#39064;&#30340;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#65288;v&#65289;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#29983;&#29289;&#21644;&#24515;&#29702;&#23398;&#26469;&#28436;&#31034;&#36825;&#20123;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#22312;&#23481;&#37327;&#22823;&#12289;&#22797;&#26434;&#24615;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#31639;&#27861;&#19981;&#31283;&#23450;&#24615;&#12289;&#38750;&#40065;&#26834;&#24615;&#21644;&#23574;&#38160;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#20102;&#30740;&#31350;&#32467;&#26524;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/1710.05468</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#27867;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Generalization in Deep Learning. (arXiv:1710.05468v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1710.05468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#22312;&#23481;&#37327;&#22823;&#12289;&#22797;&#26434;&#24615;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#31639;&#27861;&#19981;&#31283;&#23450;&#24615;&#12289;&#38750;&#40065;&#26834;&#24615;&#21644;&#23574;&#38160;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#20102;&#30740;&#31350;&#32467;&#26524;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#22312;&#23481;&#37327;&#22823;&#12289;&#22797;&#26434;&#24615;&#39640;&#12289;&#21487;&#33021;&#23384;&#22312;&#31639;&#27861;&#19981;&#31283;&#23450;&#24615;&#12289;&#38750;&#40065;&#26834;&#24615;&#21644;&#23574;&#38160;&#26497;&#23567;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#22238;&#24212;&#20102;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#25552;&#20379;&#28145;&#24230;&#23398;&#20064;&#38750;&#34394;&#31354;&#27867;&#21270;&#20445;&#35777;&#30340;&#26041;&#27861;&#12290;&#22522;&#20110;&#29702;&#35770;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35752;&#35770;&#20102;&#25105;&#20204;&#30740;&#31350;&#32467;&#26524;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper provides theoretical insights into why and how deep learning can generalize well, despite its large capacity, complexity, possible algorithmic instability, nonrobustness, and sharp minima, responding to an open question in the literature. We also discuss approaches to provide non-vacuous generalization guarantees for deep learning. Based on theoretical observations, we propose new open problems and discuss the limitations of our results.
&lt;/p&gt;</description></item></channel></rss>