<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#24120;&#35265;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27979;&#35797;&#22522;&#20934;&#20013;155&#20010;MDP&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#24403;&#26368;&#39640;Q&#20540;&#30340;&#21160;&#20316;&#22312;&#38543;&#26426;&#31574;&#30053;&#19979;Q&#20540;&#26368;&#39640;&#26102;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24448;&#24448;&#20250;&#25104;&#21151;&#65307;&#21453;&#20043;&#65292;&#21017;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#36739;&#39640;&#12290;</title><link>http://arxiv.org/abs/2304.09853</link><description>&lt;p&gt;
&#29992;&#26377;&#25928;&#30340;&#35270;&#37326;&#36830;&#25509;&#24378;&#21270;&#23398;&#20064;&#29702;&#35770;&#21644;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Bridging RL Theory and Practice with the Effective Horizon. (arXiv:2304.09853v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#24120;&#35265;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#27979;&#35797;&#22522;&#20934;&#20013;155&#20010;MDP&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#26512;&#65292;&#21457;&#29616;&#24403;&#26368;&#39640;Q&#20540;&#30340;&#21160;&#20316;&#22312;&#38543;&#26426;&#31574;&#30053;&#19979;Q&#20540;&#26368;&#39640;&#26102;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24448;&#24448;&#20250;&#25104;&#21151;&#65307;&#21453;&#20043;&#65292;&#21017;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#36739;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#26576;&#20123;&#29615;&#22659;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#20854;&#20182;&#29615;&#22659;&#20013;&#21364;&#22833;&#36133;&#24471;&#38750;&#24120;&#20005;&#37325;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#24378;&#21270;&#23398;&#20064;&#29702;&#35770;&#24212;&#35813;&#33021;&#22815;&#35299;&#37322;&#36825;&#31181;&#29616;&#35937;&#65292;&#25552;&#20379;&#39044;&#27979;&#23454;&#38469;&#24615;&#33021;&#30340;&#30028;&#38480;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24403;&#21069;&#30340;&#29702;&#35770;&#36824;&#27809;&#26377;&#36825;&#31181;&#33021;&#21147;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#21253;&#21547;155&#20010;MDP&#30340;&#26032;&#25968;&#25454;&#38598;BRIDGE&#65292;&#23558;&#26631;&#20934;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#19982;&#20043;&#21069;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20808;&#21069;&#30028;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#21457;&#29616;&#20102;&#19968;&#20010;&#24847;&#24819;&#19981;&#21040;&#30340;&#24615;&#36136;&#65306;&#24403;&#26368;&#39640;Q&#20540;&#30340;&#21160;&#20316;&#22312;&#38543;&#26426;&#31574;&#30053;&#19979;&#30340;Q&#20540;&#20063;&#26159;&#26368;&#39640;&#30340;&#26102;&#65292;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#24448;&#24448;&#20250;&#25104;&#21151;&#65307;&#21453;&#20043;&#65292;&#22833;&#36133;&#30340;&#21487;&#33021;&#24615;&#36739;&#39640;&#12290;&#22522;&#20110;&#36825;&#19968;&#24615;&#36136;&#65292;&#25105;&#20204;&#23558;&#20854;&#27010;&#25324;&#20026;&#19968;&#20010;&#26032;&#30340;MDP&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#31216;&#20026;&#26377;&#25928;&#30340;&#35270;&#37326;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning (RL) works impressively in some environments and fails catastrophically in others. Ideally, RL theory should be able to provide an understanding of why this is, i.e. bounds predictive of practical performance. Unfortunately, current theory does not quite have this ability. We compare standard deep RL algorithms to prior sample complexity prior bounds by introducing a new dataset, BRIDGE. It consists of 155 MDPs from common deep RL benchmarks, along with their corresponding tabular representations, which enables us to exactly compute instance-dependent bounds. We find that prior bounds do not correlate well with when deep RL succeeds vs. fails, but discover a surprising property that does. When actions with the highest Q-values under the random policy also have the highest Q-values under the optimal policy, deep RL tends to succeed; when they don't, deep RL tends to fail. We generalize this property into a new complexity measure of an MDP that we call the eff
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#21644;&#21151;&#29575;&#20998;&#26512;&#30830;&#23450;&#20102;&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#35780;&#20998;&#35268;&#21017;&#30340;&#21487;&#38752;&#24615;&#21306;&#22495;&#65292;&#24182;&#22312;&#30005;&#21147;&#29983;&#20135;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#32467;&#26524;&#23545;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#30340;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.09836</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#39044;&#27979;&#35780;&#20272;&#20013;&#30340;&#21487;&#38752;&#24615;&#21306;&#22495;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts. (arXiv:2304.09836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#21644;&#21151;&#29575;&#20998;&#26512;&#30830;&#23450;&#20102;&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#35780;&#20998;&#35268;&#21017;&#30340;&#21487;&#38752;&#24615;&#21306;&#22495;&#65292;&#24182;&#22312;&#30005;&#21147;&#29983;&#20135;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#32467;&#26524;&#23545;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#35780;&#20272;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#36827;&#34892;&#35780;&#20272;&#65292;&#21363;&#23545;&#20110;&#22522;&#20934;&#20998;&#24067;&#26399;&#26395;&#26368;&#23567;&#30340;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;&#36825;&#19968;&#23646;&#24615;&#19981;&#33021;&#20445;&#35777;&#20855;&#26377;&#33391;&#22909;&#30340;&#21306;&#20998;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#31687;&#31995;&#32479;&#30340;&#26377;&#38480;&#26679;&#26412;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#30740;&#31350;&#65292;&#36890;&#36807;&#21151;&#29575;&#20998;&#26512;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#20998;&#25968;&#35268;&#21017;&#30340;&#8220;&#21487;&#38752;&#24615;&#21306;&#22495;&#8221;&#65292;&#21363;&#23427;&#21487;&#20197;&#21487;&#38752;&#22320;&#35782;&#21035;&#39044;&#27979;&#35823;&#24046;&#30340;&#19968;&#32452;&#23454;&#38469;&#26465;&#20214;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#20840;&#38754;&#30340;&#20154;&#36896;&#22522;&#20934;&#27979;&#35797;&#19978;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35813;&#27979;&#35797;&#19987;&#38376;&#35774;&#35745;&#20197;&#27979;&#35797;&#22522;&#20934;&#20998;&#24067;&#19982;&#39044;&#27979;&#20998;&#24067;&#20043;&#38388;&#30340;&#20960;&#20010;&#20851;&#38190;&#24046;&#24322;&#65292;&#24182;&#36890;&#36807;&#22312;&#30005;&#21147;&#29983;&#20135;&#38382;&#39064;&#19978;&#24212;&#29992;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#30340;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22312;&#22810;&#20803;&#27010;&#29575;&#39044;&#27979;&#30340;&#35780;&#20272;&#20013;&#30340;&#37325;&#22823;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate probabilistic time series forecasts are commonly evaluated via proper scoring rules, i.e., functions that are minimal in expectation for the ground-truth distribution. However, this property is not sufficient to guarantee good discrimination in the non-asymptotic regime. In this paper, we provide the first systematic finite-sample study of proper scoring rules for time-series forecasting evaluation. Through a power analysis, we identify the "region of reliability" of a scoring rule, i.e., the set of practical conditions where it can be relied on to identify forecasting errors. We carry out our analysis on a comprehensive synthetic benchmark, specifically designed to test several key discrepancies between ground-truth and forecast distributions, and we gauge the generalizability of our findings to real-world tasks with an application to an electricity production problem. Our results reveal critical shortcomings in the evaluation of multivariate probabilistic forecasts as co
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#31232;&#30095;&#24674;&#22797;&#20013;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22797;&#26434;&#24230;&#37327;&#26377;&#21161;&#20110;&#25552;&#39640;&#20854;&#27867;&#21270;&#21644;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;</title><link>http://arxiv.org/abs/2304.09802</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#21644;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization and Estimation Error Bounds for Model-based Neural Networks. (arXiv:2304.09802v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09802
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#31232;&#30095;&#24674;&#22797;&#20013;&#34920;&#29616;&#20986;&#36739;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#22797;&#26434;&#24230;&#37327;&#26377;&#21161;&#20110;&#25552;&#39640;&#20854;&#27867;&#21270;&#21644;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20219;&#21153;&#65288;&#22914;&#31232;&#30095;&#32534;&#30721;&#21644;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#65289;&#20013;&#25552;&#20379;&#20102;&#26080;&#19982;&#20262;&#27604;&#30340;&#24615;&#33021;&#12290;&#30001;&#20110;&#19982;&#20256;&#24863;&#27169;&#22411;&#30340;&#24378;&#20851;&#32852;&#65292;&#36825;&#20123;&#32593;&#32476;&#26159;&#21487;&#35299;&#37322;&#30340;&#24182;&#32487;&#25215;&#20102;&#38382;&#39064;&#30340;&#20808;&#21069;&#32467;&#26500;&#12290;&#23454;&#36341;&#20013;&#65292;&#19982;ReLU&#31070;&#32463;&#32593;&#32476;&#30456;&#27604;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#29616;&#35937;&#22312;&#29702;&#35770;&#19978;&#36824;&#27809;&#26377;&#24471;&#21040;&#35299;&#20915;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#22797;&#26434;&#24230;&#37327;&#65288;&#21253;&#25324;&#20840;&#23616;&#21644;&#23616;&#37096;Rademacher&#22797;&#26434;&#24230;&#65289;&#30340;&#26041;&#27861;&#65292;&#20026;&#22522;&#20110;&#27169;&#22411;&#30340;&#32593;&#32476;&#25552;&#20379;&#27867;&#21270;&#21644;&#20272;&#35745;&#35823;&#24046;&#30340;&#19978;&#38480;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#32593;&#32476;&#22312;&#31232;&#30095;&#24674;&#22797;&#26041;&#38754;&#30340;&#27867;&#21270;&#33021;&#21147;&#20248;&#20110;&#24120;&#35268;&#30340;ReLU&#32593;&#32476;&#65292;&#24182;&#23548;&#20986;&#20801;&#35768;&#26500;&#24314;&#20855;&#26377;&#39640;&#20445;&#35777;&#24615;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32593;&#32476;&#30340;&#23454;&#38469;&#35774;&#35745;&#35268;&#21017;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#35265;&#35299;&#20026;&#28145;&#24230;&#23398;&#20064;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#19968;&#20123;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based neural networks provide unparalleled performance for various tasks, such as sparse coding and compressed sensing problems. Due to the strong connection with the sensing model, these networks are interpretable and inherit prior structure of the problem. In practice, model-based neural networks exhibit higher generalization capability compared to ReLU neural networks. However, this phenomenon was not addressed theoretically. Here, we leverage complexity measures including the global and local Rademacher complexities, in order to provide upper bounds on the generalization and estimation errors of model-based networks. We show that the generalization abilities of model-based networks for sparse recovery outperform those of regular ReLU networks, and derive practical design rules that allow to construct model-based networks with guaranteed high generalization. We demonstrate through a series of experiments that our theoretical insights shed light on a few behaviours experienced 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#21644;&#25237;&#24433;&#36861;&#36394;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20415;&#23452;&#12289;&#39640;&#25928;&#22320;&#29983;&#25104;&#26102;&#24577;&#23494;&#24230;&#24314;&#27169;&#65292;&#20854;&#26368;&#20248;&#26144;&#23556;&#19982;&#24658;&#31561;&#26144;&#23556;&#25509;&#36817;&#65292;&#35757;&#32451;&#36807;&#31243;&#39640;&#24230;&#24182;&#34892;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.09663</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#21644;&#25237;&#24433;&#36861;&#36394;&#30340;&#26102;&#21464;&#23494;&#24230;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling of Time-Dependent Densities via Optimal Transport and Projection Pursuit. (arXiv:2304.09663v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816;&#21644;&#25237;&#24433;&#36861;&#36394;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20415;&#23452;&#12289;&#39640;&#25928;&#22320;&#29983;&#25104;&#26102;&#24577;&#23494;&#24230;&#24314;&#27169;&#65292;&#20854;&#26368;&#20248;&#26144;&#23556;&#19982;&#24658;&#31561;&#26144;&#23556;&#25509;&#36817;&#65292;&#35757;&#32451;&#36807;&#31243;&#39640;&#24230;&#24182;&#34892;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#27969;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#23545;&#20110;&#26102;&#24577;&#23494;&#24230;&#29983;&#25104;&#24314;&#27169;&#25152;&#24102;&#26469;&#30340;&#35745;&#31639;&#22256;&#38590;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20415;&#23452;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#23427;&#38656;&#35201;&#26368;&#23569;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#21487;&#20197;&#24456;&#22909;&#22320;&#25193;&#23637;&#21040;&#39640;&#32500;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#25237;&#24433;&#30340;&#26368;&#20248;&#36755;&#36816;&#27714;&#35299;&#22120; [Meng&#31561;&#65292;2019] &#26469;&#36830;&#25509;&#36830;&#32493;&#30340;&#26679;&#26412;&#65292;&#28982;&#21518;&#20351;&#29992;&#20256;&#36755;&#26679;&#26465; [Chewi&#31561;&#65292;2020] &#26469;&#25554;&#20540;&#28436;&#21270;&#30340;&#23494;&#24230;&#12290;&#24403;&#37319;&#26679;&#39057;&#29575;&#36275;&#22815;&#39640;&#26102;&#65292;&#26368;&#20248;&#26144;&#23556;&#25509;&#36817;&#20110;&#24658;&#31561;&#26144;&#23556;&#65292;&#22240;&#27492;&#35745;&#31639;&#25928;&#29575;&#39640;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#36807;&#31243;&#21487;&#20197;&#39640;&#24230;&#24182;&#34892;&#21270;&#65292;&#22240;&#20026;&#25152;&#26377;&#26368;&#20248;&#26144;&#23556;&#26159;&#29420;&#31435;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#20165;&#22522;&#20110;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#32780;&#19981;&#26159;&#26368;&#23567;&#21270;&#38750;&#20984;&#30446;&#26631;&#20989;&#25968;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36731;&#26494;&#20998;&#26512;&#21644;&#25511;&#21046;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the computational difficulties incurred by popular deep learning algorithms for the generative modeling of temporal densities, we propose a cheap alternative which requires minimal hyperparameter tuning and scales favorably to high dimensional problems. In particular, we use a projection-based optimal transport solver [Meng et al., 2019] to join successive samples and subsequently use transport splines [Chewi et al., 2020] to interpolate the evolving density. When the sampling frequency is sufficiently high, the optimal maps are close to the identity and are thus computationally efficient to compute. Moreover, the training process is highly parallelizable as all optimal maps are independent and can thus be learned simultaneously. Finally, the approach is based solely on numerical linear algebra rather than minimizing a nonconvex objective function, allowing us to easily analyze and control the algorithm. We present several numerical experiments on both synthetic and real-w
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#26080;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#36235;&#20110;&#26080;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2304.09576</link><description>&lt;p&gt;
&#21033;&#29992;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Leveraging the two timescale regime to demonstrate convergence of neural networks. (arXiv:2304.09576v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09576
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#26080;&#38656;&#31070;&#32463;&#20803;&#25968;&#37327;&#36235;&#20110;&#26080;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#22312;&#20869;&#23618;&#27493;&#38271;&#36828;&#23567;&#20110;&#22806;&#23618;&#27493;&#38271;&#30340;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#12290;&#22312;&#36825;&#20010;&#21046;&#24230;&#19979;&#65292;&#22312;&#31616;&#21333;&#30340;&#21333;&#21464;&#37327;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#25910;&#25947;&#20110;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#38656;&#35201;&#31070;&#32463;&#20803;&#25968;&#37327;&#36235;&#20110;&#26080;&#38480;&#65292;&#36825;&#20351;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#21516;&#20110;&#26368;&#36817;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#22914;&#31070;&#32463;&#20999;&#21521;&#26680;&#25110;&#24179;&#22343;&#22330;&#21046;&#24230;&#12290;&#25105;&#20204;&#25552;&#20379;&#23454;&#39564;&#35828;&#26126;&#65292;&#26174;&#31034;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25353;&#29031;&#25105;&#20204;&#23545;&#26799;&#24230;&#27969;&#30340;&#25551;&#36848;&#36827;&#34892;&#34892;&#20026;&#65292;&#24182;&#22240;&#27492;&#22312;&#21452;&#26102;&#38388;&#23610;&#24230;&#21046;&#24230;&#19979;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#20294;&#22312;&#27492;&#21046;&#24230;&#20043;&#22806;&#21487;&#33021;&#22833;&#36133;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the training dynamics of shallow neural networks, in a two-timescale regime in which the stepsizes for the inner layer are much smaller than those for the outer layer. In this regime, we prove convergence of the gradient flow to a global optimum of the non-convex optimization problem in a simple univariate setting. The number of neurons need not be asymptotically large for our result to hold, distinguishing our result from popular recent approaches such as the neural tangent kernel or mean-field regimes. Experimental illustration is provided, showing that the stochastic gradient descent behaves according to our description of the gradient flow and thus converges to a global optimum in the two-timescale regime, but can fail outside of this regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#22122;&#20313;&#24358;&#30456;&#20284;&#24230;&#65288;dCS&#65289;&#25439;&#22833;&#20989;&#25968;&#65292; &#21487;&#20197;&#29992;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#40065;&#26834;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2304.09552</link><description>&lt;p&gt;
&#21435;&#22122;&#20313;&#24358;&#30456;&#20284;&#24230;&#65306;&#19968;&#31181;&#29702;&#35770;&#39537;&#21160;&#30340;&#26377;&#25928;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Denoising Cosine Similarity: A Theory-Driven Approach for Efficient Representation Learning. (arXiv:2304.09552v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#22122;&#20313;&#24358;&#30456;&#20284;&#24230;&#65288;dCS&#65289;&#25439;&#22833;&#20989;&#25968;&#65292; &#21487;&#20197;&#29992;&#20110;&#22312;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#40065;&#26834;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#23398;&#20064;&#24050;&#32463;&#22312;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#21644;&#23454;&#36341;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#22823;&#30340;&#24433;&#21709;&#65292;&#22240;&#20026;&#23427;&#33021;&#22815;&#23398;&#20064;&#20986;&#21487;&#20197;&#26377;&#25928;&#24212;&#29992;&#20110;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#24456;&#23569;&#20851;&#27880;&#21040;&#34920;&#31034;&#23398;&#20064;&#38454;&#27573;&#20013;&#20351;&#29992;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#36890;&#24120;&#20250;&#21463;&#21040;&#22122;&#22768;&#27745;&#26579;&#65292;&#36825;&#21487;&#33021;&#20250;&#38477;&#20302;&#23398;&#20064;&#20986;&#30340;&#34920;&#31034;&#24418;&#24335;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#40065;&#26834;&#34920;&#31034;&#24418;&#24335;&#30340;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#21463;&#21040;&#26368;&#36817;&#21435;&#22122;&#30456;&#20851;&#24037;&#20316;&#21644;&#22522;&#20110;&#20313;&#24358;&#30456;&#20284;&#24230;&#30446;&#26631;&#20989;&#25968;&#22312;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21435;&#22122;&#20313;&#24358;&#30456;&#20284;&#24230;&#65288;dCS&#65289;&#25439;&#22833;&#20989;&#25968;&#12290;dCS&#25439;&#22833;&#26159;&#19968;&#31181;&#20462;&#25913;&#36807;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#25439;&#22833;&#20989;&#25968;&#65292;&#20855;&#26377;&#21435;&#22122;&#23646;&#24615;&#65292;&#36825;&#19968;&#28857;&#24471;&#21040;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#30740;&#31350;&#30340;&#25903;&#25345;&#12290;&#20026;&#20102;&#20351;dCS&#25439;&#22833;&#21487;&#23454;&#29616;&#65292;&#25105;&#20204;&#36824;&#26500;&#24314;&#20102;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;dCS&#25439;&#22833;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation learning has been increasing its impact on the research and practice of machine learning, since it enables to learn representations that can apply to various downstream tasks efficiently. However, recent works pay little attention to the fact that real-world datasets used during the stage of representation learning are commonly contaminated by noise, which can degrade the quality of learned representations. This paper tackles the problem to learn robust representations against noise in a raw dataset. To this end, inspired by recent works on denoising and the success of the cosine-similarity-based objective functions in representation learning, we propose the denoising Cosine-Similarity (dCS) loss. The dCS loss is a modified cosine-similarity loss and incorporates a denoising property, which is supported by both our theoretical and empirical findings. To make the dCS loss implementable, we also construct the estimators of the dCS loss with statistical guarantees. Finally,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;&#23545;&#20110;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#65292;&#26368;&#20248;&#22320;&#26368;&#23567;&#21270;&#25439;&#22833;&#20250;&#23548;&#33268;&#22810;&#26657;&#20934;&#65292;&#20197;&#25552;&#20379;&#20844;&#24179;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.09424</link><description>&lt;p&gt;
&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#26657;&#20934;&#21487;&#26368;&#23567;&#21270;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Loss minimization yields multicalibration for large neural networks. (arXiv:2304.09424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#23545;&#20110;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#65292;&#26368;&#20248;&#22320;&#26368;&#23567;&#21270;&#25439;&#22833;&#20250;&#23548;&#33268;&#22810;&#26657;&#20934;&#65292;&#20197;&#25552;&#20379;&#20844;&#24179;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26657;&#20934;&#26159;&#19968;&#31181;&#20844;&#24179;&#24615;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#20379;&#36328;&#22823;&#37327;&#22242;&#20307;&#30340;&#20934;&#30830;&#39044;&#27979;&#12290;&#21363;&#20351;&#23545;&#20110;&#31616;&#21333;&#30340;&#39044;&#27979;&#22120;&#65292;&#22914;&#32447;&#24615;&#20989;&#25968;&#65292;&#22810;&#26657;&#20934;&#20063;&#34987;&#35748;&#20026;&#26159;&#19982;&#26368;&#23567;&#21270;&#25439;&#22833;&#19981;&#21516;&#30340;&#30446;&#26631;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#65288;&#20960;&#20046;&#25152;&#26377;&#30340;&#65289;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#22823;&#23567;&#65292;&#26368;&#20248;&#22320;&#26368;&#23567;&#21270;&#24179;&#26041;&#35823;&#24046;&#20250;&#23548;&#33268;&#22810;&#26657;&#20934;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#24449;&#26041;&#38754;&#65292;&#32780;&#19981;&#26159;&#20851;&#20110;&#31639;&#27861;&#25110;&#26679;&#26412;&#22797;&#26434;&#24615;&#32771;&#34385;&#12290;&#20197;&#21069;&#30340;&#36825;&#26679;&#30340;&#32467;&#26524;&#20165;&#36866;&#29992;&#20110;&#20960;&#20046;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#39044;&#27979;&#22120;&#65292;&#22240;&#27492;&#26159;&#34920;&#24449;&#26080;&#20851;&#30340;&#12290;&#25105;&#20204;&#24378;&#35843;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#19981;&#36866;&#29992;&#20110;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#31639;&#27861;&#65292;&#22914; SGD&#65292;&#24182;&#19988;&#19981;&#24212;&#35299;&#37322;&#20026;&#8220;&#20844;&#24179;&#24615;&#20174;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#33719;&#24471;&#20813;&#36153;&#30340;&#22909;&#22788;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multicalibration is a notion of fairness that aims to provide accurate predictions across a large set of groups. Multicalibration is known to be a different goal than loss minimization, even for simple predictors such as linear functions. In this note, we show that for (almost all) large neural network sizes, optimally minimizing squared error leads to multicalibration. Our results are about representational aspects of neural networks, and not about algorithmic or sample complexity considerations. Previous such results were known only for predictors that were nearly Bayes-optimal and were therefore representation independent. We emphasize that our results do not apply to specific algorithms for optimizing neural networks, such as SGD, and they should not be interpreted as "fairness comes for free from optimizing neural networks".
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#24314;&#31435;&#20102;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#65292;&#25581;&#31034;&#20102;&#31232;&#30095;&#24615;&#21644;&#20989;&#25968;&#31354;&#38388;&#36873;&#25321;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#21644;&#20854;&#22312;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;Sobolev&#31354;&#38388;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#23545;&#31232;&#30095;&#24615;&#21644;&#24179;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.09398</link><description>&lt;p&gt;
&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#26497;&#23567;&#26497;&#22823;&#20449;&#21495;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Minimax Signal Detection in Sparse Additive Models. (arXiv:2304.09398v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09398
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#20013;&#30340;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#24314;&#31435;&#20102;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#65292;&#25581;&#31034;&#20102;&#31232;&#30095;&#24615;&#21644;&#20989;&#25968;&#31354;&#38388;&#36873;&#25321;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#21644;&#20854;&#22312;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;Sobolev&#31354;&#38388;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#23545;&#31232;&#30095;&#24615;&#21644;&#24179;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#30340;&#24314;&#27169;&#38656;&#27714;&#20013;&#65292;&#31232;&#30095;&#21152;&#24615;&#27169;&#22411;&#26159;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#31232;&#30095;&#21152;&#24615;&#20449;&#21495;&#26816;&#27979;&#30340;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#38750;&#28176;&#36817;&#30340;&#65292;&#24182;&#36866;&#29992;&#20110;&#21333;&#21464;&#37327;&#20998;&#37327;&#20989;&#25968;&#23646;&#20110;&#19968;&#33324;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#24773;&#20917;&#12290;&#19982;&#20272;&#35745;&#29702;&#35770;&#19981;&#21516;&#65292;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#36895;&#29575;&#25581;&#31034;&#20102;&#31232;&#30095;&#24615;&#21644;&#20989;&#25968;&#31354;&#38388;&#36873;&#25321;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#36890;&#29992;&#20989;&#25968;&#31354;&#38388;&#30340;&#33258;&#36866;&#24212;&#27979;&#35797;&#36895;&#29575;&#65307;&#22312;&#26576;&#20123;&#31354;&#38388;&#20013;&#65292;&#33258;&#36866;&#24212;&#24615;&#26159;&#21487;&#33021;&#30340;&#65292;&#32780;&#22312;&#20854;&#20182;&#31354;&#38388;&#20013;&#21017;&#20250;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#20195;&#20215;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;Sobolev&#31354;&#38388;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#23545;&#31232;&#30095;&#24615;&#21644;&#24179;&#28369;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#65292;&#24182;&#26356;&#27491;&#20102;&#25991;&#29486;&#20013;&#23384;&#22312;&#30340;&#19968;&#20123;&#35828;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse additive models are an attractive choice in circumstances calling for modelling flexibility in the face of high dimensionality. We study the signal detection problem and establish the minimax separation rate for the detection of a sparse additive signal. Our result is nonasymptotic and applicable to the general case where the univariate component functions belong to a generic reproducing kernel Hilbert space. Unlike the estimation theory, the minimax separation rate reveals a nontrivial interaction between sparsity and the choice of function space. We also investigate adaptation to sparsity and establish an adaptive testing rate for a generic function space; adaptation is possible in some spaces while others impose an unavoidable cost. Finally, adaptation to both sparsity and smoothness is studied in the setting of Sobolev space, and we correct some existing claims in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2304.09310</link><description>&lt;p&gt;
&#33258;&#36866;&#24212; $\tau$-Lasso&#65306;&#20854;&#20581;&#22766;&#24615;&#21644;&#26368;&#20248;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Adaptive $\tau$-Lasso: Its Robustness and Oracle Properties. (arXiv:2304.09310v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#40065;&#26834;&#30340;&#33258;&#36866;&#24212; $\tau$-Lasso &#20272;&#35745;&#22120;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20197;&#38477;&#20302;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#23427;&#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#26032;&#22411;&#27491;&#21017;&#21270;&#40065;&#26834; $\tau$-&#22238;&#24402;&#20272;&#35745;&#22120;&#65292;&#20197;&#24212;&#23545;&#21709;&#24212;&#21464;&#37327;&#21644;&#21327;&#21464;&#37327;&#30340;&#20005;&#37325;&#27745;&#26579;&#12290;&#25105;&#20204;&#31216;&#36825;&#31181;&#20272;&#35745;&#22120;&#20026;&#33258;&#36866;&#24212; $\tau$-Lasso&#65292;&#23427;&#23545;&#24322;&#24120;&#20540;&#21644;&#39640;&#26464;&#26438;&#28857;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21516;&#26102;&#37319;&#29992;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#26469;&#20943;&#23569;&#30495;&#23454;&#22238;&#24402;&#31995;&#25968;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#33258;&#36866;&#24212; $\ell_1$-&#33539;&#25968;&#24809;&#32602;&#39033;&#20026;&#27599;&#20010;&#22238;&#24402;&#31995;&#25968;&#20998;&#37197;&#19968;&#20010;&#26435;&#37325;&#12290;&#23545;&#20110;&#22266;&#23450;&#25968;&#37327;&#30340;&#39044;&#27979;&#21464;&#37327; $p$&#65292;&#25105;&#20204;&#26174;&#31034;&#20986;&#33258;&#36866;&#24212; $\tau$-Lasso &#20855;&#26377;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#21644;&#30495;&#23454;&#25903;&#25345;&#19979;&#22238;&#24402;&#21521;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#20551;&#23450;&#24050;&#30693;&#30495;&#23454;&#22238;&#24402;&#21521;&#37327;&#30340;&#25903;&#25345;&#12290;&#28982;&#21518;&#25105;&#20204;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#26029;&#28857;&#21644;&#24433;&#21709;&#20989;&#25968;&#26469;&#34920;&#24449;&#20854;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#26469;&#27604;&#36739;&#19981;&#21516;&#30340;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a new regularized version of the robust $\tau$-regression estimator for analyzing high-dimensional data sets subject to gross contamination in the response variables and covariates. We call the resulting estimator adaptive $\tau$-Lasso that is robust to outliers and high-leverage points and simultaneously employs adaptive $\ell_1$-norm penalty term to reduce the bias associated with large true regression coefficients. More specifically, this adaptive $\ell_1$-norm penalty term assigns a weight to each regression coefficient. For a fixed number of predictors $p$, we show that the adaptive $\tau$-Lasso has the oracle property with respect to variable-selection consistency and asymptotic normality for the regression vector corresponding to the true support, assuming knowledge of the true regression vector support. We then characterize its robustness via the finite-sample breakdown point and the influence function. We carry-out extensive simulations to compare the per
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24207;&#21015;&#23398;&#20064;&#26469;&#39640;&#25928;&#20248;&#21270;&#22810;&#20010;&#30456;&#20114;&#20914;&#31361;&#30446;&#26631;&#30340;&#22797;&#26434;&#31995;&#32479;&#30340;&#25968;&#25454;&#39537;&#21160;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2304.09278</link><description>&lt;p&gt;
&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#24207;&#21015;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#21152;&#36895;&#21644;&#20248;&#21270;&#22810;&#30446;&#26631;&#21046;&#36896;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
A Data Driven Sequential Learning Framework to Accelerate and Optimize Multi-Objective Manufacturing Decisions. (arXiv:2304.09278v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24207;&#21015;&#23398;&#20064;&#26469;&#39640;&#25928;&#20248;&#21270;&#22810;&#20010;&#30456;&#20114;&#20914;&#31361;&#30446;&#26631;&#30340;&#22797;&#26434;&#31995;&#32479;&#30340;&#25968;&#25454;&#39537;&#21160;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21046;&#36896;&#20855;&#26377;&#29305;&#23450;&#24615;&#36136;&#25110;&#24615;&#36136;&#32452;&#21512;&#30340;&#20808;&#36827;&#26448;&#26009;&#21644;&#20135;&#21697;&#36890;&#24120;&#26159;&#24517;&#35201;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25214;&#21040;&#33021;&#22815;&#29983;&#25104;&#36825;&#20123;&#24615;&#36136;&#29702;&#24819;&#32452;&#21512;&#30340;&#26368;&#20339;&#37197;&#26041;&#25110;&#22788;&#29702;&#26465;&#20214;&#33267;&#20851;&#37325;&#35201;&#12290;&#22823;&#22810;&#25968;&#26102;&#20505;&#65292;&#38656;&#35201;&#36827;&#34892;&#36275;&#22815;&#25968;&#37327;&#30340;&#23454;&#39564;&#25165;&#33021;&#29983;&#25104;Pareto&#21069;&#27839;&#12290;&#28982;&#32780;&#65292;&#21046;&#36896;&#23454;&#39564;&#36890;&#24120;&#24456;&#26114;&#36149;&#65292;&#29978;&#33267;&#36827;&#34892;&#19968;&#27425;&#23454;&#39564;&#20063;&#21487;&#33021;&#26159;&#19968;&#20010;&#32791;&#26102;&#30340;&#36807;&#31243;&#12290;&#22240;&#27492;&#65292;&#30830;&#23450;&#26368;&#20339;&#25968;&#25454;&#25910;&#38598;&#20301;&#32622;&#20197;&#33719;&#24471;&#23545;&#36807;&#31243;&#30340;&#26368;&#20840;&#38754;&#29702;&#35299;&#38750;&#24120;&#20851;&#38190;&#12290;&#24207;&#21015;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#36827;&#34892;&#20013;&#30340;&#23454;&#39564;&#20013;&#20027;&#21160;&#23398;&#20064;&#65292;&#36845;&#20195;&#26356;&#26032;&#22522;&#30784;&#20248;&#21270;&#20363;&#31243;&#65292;&#24182;&#38543;&#26102;&#35843;&#25972;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#21033;&#29992;&#24207;&#21015;&#23398;&#20064;&#26469;&#39640;&#25928;&#20248;&#21270;&#20855;&#26377;&#22810;&#20010;&#30456;&#20114;&#20914;&#31361;&#30446;&#26631;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manufacturing advanced materials and products with a specific property or combination of properties is often warranted. To achieve that it is crucial to find out the optimum recipe or processing conditions that can generate the ideal combination of these properties. Most of the time, a sufficient number of experiments are needed to generate a Pareto front. However, manufacturing experiments are usually costly and even conducting a single experiment can be a time-consuming process. So, it's critical to determine the optimal location for data collection to gain the most comprehensive understanding of the process. Sequential learning is a promising approach to actively learn from the ongoing experiments, iteratively update the underlying optimization routine, and adapt the data collection process on the go. This paper presents a novel data-driven Bayesian optimization framework that utilizes sequential learning to efficiently optimize complex systems with multiple conflicting objectives. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#32447;&#24615;&#20989;&#25968;&#26500;&#24314;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#20998;&#26512;&#36825;&#31181;&#20132;&#21449;&#30456;&#20851;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.09242</link><description>&lt;p&gt;
&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#20998;&#26512;&#22312;&#32447;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Framework for Analyzing Online Cross-correlators using Price's Theorem and Piecewise-Linear Decomposition. (arXiv:2304.09242v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38750;&#32447;&#24615;&#20989;&#25968;&#26500;&#24314;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#26469;&#20998;&#26512;&#36825;&#31181;&#20132;&#21449;&#30456;&#20851;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#20272;&#35745;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#21449;&#30456;&#20851;&#25110;&#30456;&#20284;&#24230;&#26159;&#20449;&#21495;&#26816;&#27979;&#12289;&#39640;&#32500;&#35745;&#31639;&#12289;&#32852;&#24819;&#35760;&#24518;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#26500;&#24314;&#20855;&#26377;&#26356;&#39640;&#20449;&#22122;&#27604;&#65288;SNR&#65289;&#30340;&#20132;&#21449;&#30456;&#20851;&#22120;&#30340;&#22823;&#37327;&#31616;&#21333;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;Price&#23450;&#29702;&#21644;&#20998;&#27573;&#32447;&#24615;&#20998;&#35299;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#20197;&#20998;&#26512;&#20351;&#29992;&#28151;&#21512;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#26500;&#24314;&#30340;&#20132;&#21449;&#30456;&#20851;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Precise estimation of cross-correlation or similarity between two random variables lies at the heart of signal detection, hyperdimensional computing, associative memories, and neural networks. Although a vast literature exists on different methods for estimating cross-correlations, the question what is the best and simplest method to estimate cross-correlations using finite samples ? is still not clear. In this paper, we first argue that the standard empirical approach might not be the optimal method even though the estimator exhibits uniform convergence to the true cross-correlation. Instead, we show that there exists a large class of simple non-linear functions that can be used to construct cross-correlators with a higher signal-to-noise ratio (SNR). To demonstrate this, we first present a general mathematical framework using Price's Theorem that allows us to analyze cross-correlators constructed using a mixture of piece-wise linear functions. Using this framework and high-dimensiona
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30740;&#31350;&#20102;&#35299;&#26512;&#24230;&#20989;&#25968;&#20026;&#38750;&#20984;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#26426;&#22120;&#23398;&#20064;&#22122;&#22768;&#30340;&#23610;&#24230;&#19982;&#30446;&#26631;&#20989;&#25968;&#30456;&#31561;&#26102;&#65292;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#21021;&#22987;&#21270;&#21518;&#65292;&#20197;&#27491;&#30340;&#27010;&#29575;&#33021;&#22815;&#25910;&#25947;&#21040;&#35813;&#21306;&#22495;&#20869;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2304.09221</link><description>&lt;p&gt;
&#22522;&#20110;&#23616;&#37096;Lajasiewicz&#26465;&#20214;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of stochastic gradient descent under a local Lajasiewicz condition for deep neural networks. (arXiv:2304.09221v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09221
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30740;&#31350;&#20102;&#35299;&#26512;&#24230;&#20989;&#25968;&#20026;&#38750;&#20984;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#26426;&#22120;&#23398;&#20064;&#22122;&#22768;&#30340;&#23610;&#24230;&#19982;&#30446;&#26631;&#20989;&#25968;&#30456;&#31561;&#26102;&#65292;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#21021;&#22987;&#21270;&#21518;&#65292;&#20197;&#27491;&#30340;&#27010;&#29575;&#33021;&#22815;&#25910;&#25947;&#21040;&#35813;&#21306;&#22495;&#20869;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#35299;&#26512;&#24230;&#20989;&#25968;&#20026;&#38750;&#20984;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#26377;&#38480;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#36890;&#36807;&#21152;&#20837;&#26368;&#23567;&#30340;&#39069;&#22806;&#20551;&#35774;&#24182;&#20445;&#35777;&#26426;&#22120;&#23398;&#20064;&#22122;&#22768;&#30340;&#23610;&#24230;&#19982;&#30446;&#26631;&#20989;&#25968;&#30456;&#31561;&#65292;&#35777;&#26126;&#20102;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#21021;&#22987;&#21270;&#26102;&#65292;&#20197;&#27491;&#30340;&#27010;&#29575;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36845;&#20195;&#25910;&#25947;&#21040;&#35813;&#21306;&#22495;&#20869;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#26412;&#25991;&#30340;&#20851;&#38190;&#26159;&#30830;&#20445;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#25972;&#20010;&#36712;&#36857;&#20197;&#27491;&#30340;&#27010;&#29575;&#20445;&#30041;&#22312;&#23616;&#37096;&#21306;&#22495;&#20869;&#12290;&#25991;&#31456;&#25552;&#20379;&#20102;&#36127;&#38754;&#20998;&#26512;&#65292;&#34920;&#26126;&#20351;&#29992;Robbins-Monro&#31867;&#22411;&#30340;&#27493;&#38271;&#20043;&#38388;&#20855;&#26377;&#26377;&#30028;&#22122;&#22768;&#30340;&#20551;&#35774;&#19981;&#36275;&#20197;&#20445;&#25345;&#35813;&#20851;&#38190;&#37096;&#20998;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend the global convergence result of Chatterjee \cite{chatterjee2022convergence} by considering the stochastic gradient descent (SGD) for non-convex objective functions. With minimal additional assumptions that can be realized by finitely wide neural networks, we prove that if we initialize inside a local region where the \L{}ajasiewicz condition holds, with a positive probability, the stochastic gradient iterates converge to a global minimum inside this region. A key component of our proof is to ensure that the whole trajectories of SGD stay inside the local region with a positive probability. For that, we assume the SGD noise scales with the objective function, which is called machine learning noise and achievable in many real examples. Furthermore, we provide a negative argument to show why using the boundedness of noise with Robbins-Monro type step sizes is not enough to keep the key component valid.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#22238;&#24402;&#30340;&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#65292;&#21457;&#29616;&#22914;&#26524;&#27809;&#26377;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#20294;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#29616;&#35937;&#65292;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.06326</link><description>&lt;p&gt;
&#29702;&#35299;&#26680;&#22238;&#24402;&#23545;&#25239;&#35757;&#32451;&#20013;&#30340;&#36807;&#25311;&#21512;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Understanding Overfitting in Adversarial Training in Kernel Regression. (arXiv:2304.06326v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06326
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#22238;&#24402;&#30340;&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#65292;&#21457;&#29616;&#22914;&#26524;&#27809;&#26377;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#20294;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#29616;&#35937;&#65292;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#26159;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#30340;&#24120;&#35265;&#26041;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20877;&#29983;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#27491;&#21017;&#21270;&#22238;&#24402;&#30340;&#23545;&#25239;&#35757;&#32451;&#21644;&#24102;&#22122;&#22768;&#30340;&#25968;&#25454;&#22686;&#24378;&#12290;&#24403;&#25915;&#20987;&#21644;&#22122;&#22768;&#22823;&#23567;&#20197;&#21450;&#27491;&#21017;&#21270;&#21442;&#25968;&#36235;&#21521;&#20110;&#38646;&#26102;&#65292;&#24314;&#31435;&#20102;&#36825;&#20123;&#25216;&#26415;&#30340;&#26497;&#38480;&#20844;&#24335;&#12290;&#26681;&#25454;&#35813;&#26497;&#38480;&#20844;&#24335;&#65292;&#20998;&#26512;&#20102;&#29305;&#23450;&#24773;&#20917;&#24182;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#27809;&#26377;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#20855;&#26377;&#22823;&#20110;&#26631;&#20934;&#26680;&#22238;&#24402;&#30340;&#24191;&#20041;&#35823;&#24046;&#21644;Lipschitz&#24120;&#25968;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#20248;&#20110;&#26631;&#20934;&#26680;&#22238;&#24402;&#65292;&#36798;&#21040;&#26356;&#23567;&#30340;&#24191;&#20041;&#35823;&#24046;&#21644;Lipschitz&#24120;&#25968;&#12290;&#36825;&#20123;&#21457;&#29616;&#25903;&#25345;&#23545;&#25239;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#36807;&#25311;&#21512;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#20197;&#21450;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#33021;&#22815;&#32531;&#35299;&#36825;&#31181;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training and data augmentation with noise are widely adopted techniques to enhance the performance of neural networks. This paper investigates adversarial training and data augmentation with noise in the context of regularized regression in a reproducing kernel Hilbert space (RKHS). We establish the limiting formula for these techniques as the attack and noise size, as well as the regularization parameter, tend to zero. Based on this limiting formula, we analyze specific scenarios and demonstrate that, without appropriate regularization, these two methods may have larger generalization error and Lipschitz constant than standard kernel regression. However, by selecting the appropriate regularization parameter, these two methods can outperform standard kernel regression and achieve smaller generalization error and Lipschitz constant. These findings support the empirical observations that adversarial training can lead to overfitting, and appropriate regularization methods, suc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;RHMC&#37319;&#26679;&#22810;&#38754;&#20307;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#23454;&#29616;&#26356;&#24555;&#30340;&#28151;&#21512;&#36895;&#24230;&#65292;&#20854;&#20013;&#28151;&#21512;&#36895;&#24230;&#30001;$m^{1/3}n^{4/3}$&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.00480</link><description>&lt;p&gt;
&#24102;&#38556;&#30861;&#30340;&#37319;&#26679;&#65306;&#36890;&#36807;Lewis&#26435;&#37325;&#23454;&#29616;&#26356;&#24555;&#30340;&#28151;&#21512;
&lt;/p&gt;
&lt;p&gt;
Sampling with Barriers: Faster Mixing via Lewis Weights. (arXiv:2303.00480v2 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00480
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;RHMC&#37319;&#26679;&#22810;&#38754;&#20307;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#23454;&#29616;&#26356;&#24555;&#30340;&#28151;&#21512;&#36895;&#24230;&#65292;&#20854;&#20013;&#28151;&#21512;&#36895;&#24230;&#30001;$m^{1/3}n^{4/3}$&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;Riemannian Hamiltonian Monte Carlo&#65288;RHMC&#65289;&#37319;&#26679;&#30001;$\R^n$&#20013;$m$&#20010;&#19981;&#31561;&#24335;&#23450;&#20041;&#30340;&#22810;&#38754;&#20307;&#30340;&#26041;&#27861;&#12290;&#20854;&#20013;&#30340;&#24230;&#37327;&#25353;&#20855;&#26377;&#20984;&#38556;&#30861;&#20989;&#25968;&#30340;&#28023;&#26862;&#30697;&#38453;&#23450;&#20041;&#12290;RHMC&#30456;&#23545;&#20110;&#27431;&#20960;&#37324;&#24471;&#26041;&#27861;&#65288;&#22914;&#29699;&#34892;&#36208;&#65292;hit-and-run&#21644;Dikin&#34892;&#36208;&#65289;&#30340;&#20248;&#21183;&#22312;&#20110;&#33021;&#22815;&#36808;&#20986;&#26356;&#38271;&#30340;&#27493;&#20240;&#12290;&#28982;&#32780;&#65292;&#22312;&#20808;&#21069;&#25152;&#26377;&#30340;&#24037;&#20316;&#20013;&#65292;&#28151;&#21512;&#36895;&#24230;&#37117;&#19982;&#19981;&#31561;&#24335;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;Lewis&#26435;&#37325;&#38556;&#30861;&#21644;&#26631;&#20934;&#23545;&#25968;&#38556;&#30861;&#30340;&#28151;&#21512;&#65292;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;RHMC&#30340;&#28151;&#21512;&#36895;&#24230;&#30001;$\tilde O(m^{1/3}n^{4/3})$&#30028;&#38480;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;&#30340;&#26368;&#20339;&#30028;&#38480;$\tilde O(mn^{2/3})$&#65288;&#22522;&#20110;&#23545;&#25968;&#38556;&#30861;&#65289;&#12290;&#36825;&#32487;&#32493;&#20102;&#26368;&#20248;&#21270;&#21644;&#37319;&#26679;&#20043;&#38388;&#30340;&#19968;&#33324;&#30456;&#20284;&#20043;&#22788;&#65292;&#21518;&#32773;&#36890;&#24120;&#23548;&#33268;&#26032;&#24037;&#20855;&#21644;&#26356;&#31934;&#32454;&#30340;&#20998;&#26512;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#24517;&#39035;&#20811;&#26381;&#28041;&#21450;Hamiltonian&#26354;&#32447;&#30340;&#24179;&#28369;&#24615;&#21644;&#33258;&#20849;&#36717;&#24615;&#30340;&#20960;&#20010;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze Riemannian Hamiltonian Monte Carlo (RHMC) for sampling a polytope defined by $m$ inequalities in $\R^n$ endowed with the metric defined by the Hessian of a convex barrier function. The advantage of RHMC over Euclidean methods such as the ball walk, hit-and-run and the Dikin walk is in its ability to take longer steps. However, in all previous work, the mixing rate has a linear dependence on the number of inequalities. We introduce a hybrid of the Lewis weights barrier and the standard logarithmic barrier and prove that the mixing rate for the corresponding RHMC is bounded by $\tilde O(m^{1/3}n^{4/3})$, improving on the previous best bound of $\tilde O(mn^{2/3})$ (based on the log barrier). This continues the general parallels between optimization and sampling, with the latter typically leading to new tools and more refined analysis. To prove our main results, we have to overcomes several challenges relating to the smoothness of Hamiltonian curves and the self-concordance pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#20998;&#26512;&#20102;&#31070;&#32463;&#31639;&#31526;&#21450;&#20854;&#34893;&#29983;&#32467;&#26500;&#30340;&#27867;&#21270;&#29305;&#24615;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#26680;&#31215;&#20998;&#31639;&#31526;&#26469;&#20195;&#26367;&#33258;&#20851;&#27880;&#26426;&#21046;&#21644;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#23481;&#37327;&#30340;&#35757;&#32451;&#35838;&#31243;&#65292;&#32467;&#26524;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.11509</link><description>&lt;p&gt;
&#32454;&#35843;&#31070;&#32463;&#31639;&#31526;&#32467;&#26500;&#20197;&#25552;&#39640;&#35757;&#32451;&#21644;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning Neural-Operator architectures for training and generalization. (arXiv:2301.11509v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20998;&#26512;&#20102;&#31070;&#32463;&#31639;&#31526;&#21450;&#20854;&#34893;&#29983;&#32467;&#26500;&#30340;&#27867;&#21270;&#29305;&#24615;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#26680;&#31215;&#20998;&#31639;&#31526;&#26469;&#20195;&#26367;&#33258;&#20851;&#27880;&#26426;&#21046;&#21644;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#23481;&#37327;&#30340;&#35757;&#32451;&#35838;&#31243;&#65292;&#32467;&#26524;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#20840;&#38754;&#20998;&#26512;&#20102;&#31070;&#32463;&#31639;&#31526;&#65288;NOs&#65289;&#21450;&#20854;&#34893;&#29983;&#32467;&#26500;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#36890;&#36807;&#23545;&#27979;&#35797;&#25439;&#22833;&#30340;&#32463;&#39564;&#35780;&#20272;&#12289;&#22522;&#20110;&#22797;&#26434;&#24615;&#30340;&#27867;&#21270;&#30028;&#38480;&#30340;&#20998;&#26512;&#20197;&#21450;&#23545;&#25439;&#22833;&#26223;&#35266;&#21487;&#35270;&#21270;&#30340;&#23450;&#24615;&#35780;&#20272;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26088;&#22312;&#25552;&#39640;NOs&#27867;&#21270;&#33021;&#21147;&#30340;&#20462;&#25913;&#12290;&#21463;Transformer&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;${\textit{s}}{\text{NO}}+\varepsilon$&#65292;&#35813;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#26680;&#31215;&#20998;&#31639;&#31526;&#26469;&#20195;&#26367;&#33258;&#20851;&#27880;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20276;&#38543;&#30528;&#25439;&#22833;&#26223;&#35266;&#21487;&#35270;&#21270;&#30340;&#23450;&#24615;&#21464;&#21270;&#65292;&#24615;&#33021;&#26174;&#33879;&#25552;&#39640;&#20102;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#29468;&#27979;&#65292;Transformer&#30340;&#24067;&#23616;&#20351;&#20248;&#21270;&#31639;&#27861;&#33021;&#22815;&#25214;&#21040;&#26356;&#22909;&#30340;&#26497;&#23567;&#20540;&#65292;&#24182;&#19988;&#38543;&#26426;&#28145;&#24230;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#30001;&#20110;&#35757;&#32451;&#21160;&#24577;&#30340;&#20005;&#26684;&#20998;&#26512;&#26159;&#28145;&#24230;&#23398;&#20064;&#26368;&#31361;&#20986;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#65292;&#22240;&#27492;&#25105;&#20204;&#36824;&#25512;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35757;&#32451;&#35838;&#31243;&#65292;&#37325;&#28857;&#26159;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#23481;&#37327;&#65292;&#20174;&#32780;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work provides a comprehensive analysis of the generalization properties of Neural Operators (NOs) and their derived architectures. Through empirical evaluation of the test loss, analysis of the complexity-based generalization bounds, and qualitative assessments of the visualization of the loss landscape, we investigate modifications aimed at enhancing the generalization capabilities of NOs. Inspired by the success of Transformers, we propose ${\textit{s}}{\text{NO}}+\varepsilon$, which introduces a kernel integral operator in lieu of self-Attention. Our results reveal significantly improved performance across datasets and initializations, accompanied by qualitative changes in the visualization of the loss landscape. We conjecture that the layout of Transformers enables the optimization algorithm to find better minima, and stochastic depth, improve the generalization performance. As a rigorous analysis of training dynamics is one of the most prominent unsolved problems in deep lear
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#20998;&#20301;&#25968;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#36866;&#24212;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#30340;&#24322;&#36136;&#24615;&#21644;&#37325;&#23614;&#20998;&#24067;&#12290;&#26681;&#25454;&#31934;&#24515;&#36873;&#25321;&#30340;&#21487;&#36716;&#31227;&#28304;&#22495;&#24314;&#31435;&#20102;&#36716;&#31227;&#23398;&#20064;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20551;&#35774;&#26816;&#39564;&#31243;&#24207;&#65292;&#20197;&#23454;&#29616;&#19968;&#27493;&#23436;&#25104;&#12290;</title><link>http://arxiv.org/abs/2211.14578</link><description>&lt;p&gt;
&#39640;&#32500;&#20998;&#20301;&#25968;&#22238;&#24402;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical inference for transfer learning with high-dimensional quantile regression. (arXiv:2211.14578v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#20998;&#20301;&#25968;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#36866;&#24212;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#30340;&#24322;&#36136;&#24615;&#21644;&#37325;&#23614;&#20998;&#24067;&#12290;&#26681;&#25454;&#31934;&#24515;&#36873;&#25321;&#30340;&#21487;&#36716;&#31227;&#28304;&#22495;&#24314;&#31435;&#20102;&#36716;&#31227;&#23398;&#20064;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20551;&#35774;&#26816;&#39564;&#31243;&#24207;&#65292;&#20197;&#23454;&#29616;&#19968;&#27493;&#23436;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#37325;&#35201;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#21033;&#29992;&#28304;&#22495;&#20013;&#30340;&#20449;&#24687;&#26469;&#25552;&#39640;&#30446;&#26631;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#39640;&#32500;&#25968;&#25454;&#26222;&#36941;&#23384;&#22312;&#24322;&#36136;&#24615;&#21644;/&#25110;&#37325;&#23614;&#20998;&#24067;&#65292;&#20294;&#30446;&#21069;&#30340;&#36716;&#31227;&#23398;&#20064;&#26041;&#27861;&#26410;&#33021;&#20805;&#20998;&#32771;&#34385;&#36825;&#20123;&#38382;&#39064;&#65292;&#21487;&#33021;&#20250;&#24433;&#21709;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#20998;&#20301;&#25968;&#22238;&#24402;&#27169;&#22411;&#26694;&#26550;&#19979;&#25552;&#20986;&#20102;&#19968;&#31181;&#36716;&#31227;&#23398;&#20064;&#36807;&#31243;&#65292;&#20197;&#36866;&#24212;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#30340;&#24322;&#36136;&#24615;&#21644;&#37325;&#23614;&#20998;&#24067;&#12290;&#25105;&#20204;&#26681;&#25454;&#31934;&#24515;&#36873;&#25321;&#30340;&#21487;&#36716;&#31227;&#28304;&#22495;&#24314;&#31435;&#20102;&#36716;&#31227;&#23398;&#20064;&#20272;&#35745;&#37327;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#26174;&#31034;&#22312;&#20851;&#38190;&#36873;&#25321;&#26631;&#20934;&#21644;&#36739;&#22823;&#30340;&#28304;&#20219;&#21153;&#26679;&#26412;&#37327;&#19979;&#21487;&#20197;&#23454;&#29616;&#26356;&#20302;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;&#20551;&#35774;&#26816;&#39564;&#31243;&#24207;&#65292;&#29992;&#20110;&#39640;&#32500;&#20998;&#20301;&#25968;&#22238;&#24402;&#31995;&#25968;&#30340;&#21508;&#20010;&#20998;&#37327;&#65292;&#36890;&#36807;&#20513;&#23548;&#21452;&#37325;&#36716;&#31227;&#23398;&#20064;&#20272;&#35745;&#37327;&#65292;&#23454;&#29616;&#19968;&#27493;&#23436;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning has become an essential technique to exploit information from the source domain to boost performance of the target task. Despite the prevalence in high-dimensional data, heterogeneity and/or heavy tails are insufficiently accounted for by current transfer learning approaches and thus may undermine the resulting performance. We propose a transfer learning procedure in the framework of high-dimensional quantile regression models to accommodate the heterogeneity and heavy tails in the source and target domains. We establish error bounds of the transfer learning estimator based on delicately selected transferable source domains, showing that lower error bounds can be achieved for critical selection criterion and larger sample size of source tasks. We further propose valid confidence interval and hypothesis test procedures for individual component of high-dimensional quantile regression coefficients by advocating a double transfer learning estimator, which is the one-step 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#30340;&#20998;&#21306;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#26159;&#31532;&#19968;&#31181;&#22312;&#32852;&#37030;&#36125;&#21494;&#26031;&#23398;&#20064;&#29615;&#22659;&#19979;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.11595</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#20998;&#21306;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially private partitioned variational inference. (arXiv:2209.11595v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.11595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#30340;&#20998;&#21306;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#26159;&#31532;&#19968;&#31181;&#22312;&#32852;&#37030;&#36125;&#21494;&#26031;&#23398;&#20064;&#29615;&#22659;&#19979;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20998;&#24067;&#22312;&#22810;&#20010;&#35774;&#22791;&#19978;&#30340;&#25935;&#24863;&#25968;&#25454;&#20013;&#23398;&#20064;&#38544;&#31169;&#20445;&#25252;&#27169;&#22411;&#26159;&#19968;&#20010;&#26085;&#30410;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#36890;&#24120;&#22312;&#32852;&#37030;&#23398;&#20064;&#32972;&#26223;&#19979;&#36827;&#34892;&#35268;&#21010;&#65292;&#30446;&#26631;&#26159;&#22312;&#20445;&#25345;&#25968;&#25454;&#20998;&#24067;&#30340;&#21516;&#26102;&#23398;&#20064;&#21333;&#20010;&#20840;&#23616;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36125;&#21494;&#26031;&#23398;&#20064;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#33258;&#28982;&#22320;&#25903;&#25345;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#23545;&#20110;&#38598;&#20013;&#30340;&#38750;&#38544;&#31169;&#25968;&#25454;&#65292;&#36125;&#21494;&#26031;&#23398;&#20064;&#20063;&#36890;&#24120;&#26159;&#19981;&#21487;&#25805;&#20316;&#30340;&#65292;&#22240;&#27492;&#21464;&#20998;&#25512;&#26029;&#31561;&#36817;&#20284;&#25216;&#26415;&#26159;&#24517;&#38656;&#30340;&#12290;&#36817;&#26399;&#65292;&#36890;&#36807;&#20998;&#21306;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21464;&#20998;&#25512;&#26029;&#24050;&#32463;&#25193;&#23637;&#21040;&#38750;&#38544;&#31169;&#32852;&#37030;&#23398;&#20064;&#30340;&#24773;&#20917;&#12290;&#23545;&#20110;&#38544;&#31169;&#20445;&#25252;&#65292;&#30446;&#21069;&#30340;&#40644;&#37329;&#26631;&#20934;&#34987;&#31216;&#20026;&#24046;&#20998;&#38544;&#31169;&#12290;&#24046;&#20998;&#38544;&#31169;&#22312;&#25968;&#23398;&#19978;&#23450;&#20041;&#20102;&#19968;&#20010;&#24378;&#30340;&#38544;&#31169;&#20445;&#25252;&#27010;&#24565;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#30340;&#20998;&#21306;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;&#65292;&#26159;&#31532;&#19968;&#31181;&#36890;&#36807;&#20998;&#21306;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#22312;&#32852;&#37030;&#36125;&#21494;&#26031;&#23398;&#20064;&#29615;&#22659;&#19979;&#23454;&#29616;&#24046;&#20998;&#38544;&#31169;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#20154;&#36896;&#21644;&#30495;&#23454;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning a privacy-preserving model from sensitive data which are distributed across multiple devices is an increasingly important problem. The problem is often formulated in the federated learning context, with the aim of learning a single global model while keeping the data distributed. Moreover, Bayesian learning is a popular approach for modelling, since it naturally supports reliable uncertainty estimates. However, Bayesian learning is generally intractable even with centralised non-private data and so approximation techniques such as variational inference are a necessity. Variational inference has recently been extended to the non-private federated learning setting via the partitioned variational inference algorithm. For privacy protection, the current gold standard is called differential privacy. Differential privacy guarantees privacy in a strong, mathematically clearly defined sense.  In this paper, we present differentially private partitioned variational inference, the first
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982;&#31639;&#27861;&#21644;&#20998;&#24067;&#26080;&#20851;&#30340;&#38750;&#28176;&#36827;&#24615;&#26435;&#34913;&#26041;&#27861;&#65292;&#26469;&#34913;&#37327;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#27169;&#22411;&#22823;&#23567;&#12289;&#27979;&#35797;&#25439;&#22833;&#21644;&#35757;&#32451;&#25439;&#22833;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#27979;&#35797;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#33394;&#30340;&#27169;&#22411;&#35201;&#20040;&#26159;&#32463;&#20856;&#30340;&#65292;&#35201;&#20040;&#26159;&#29616;&#20195;&#30340;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#24403;&#30333;&#21270;&#29305;&#24449;&#30340;&#26497;&#38480;&#35889;&#20998;&#24067;&#20026;Marchenko-Pastur&#26102;&#30340;&#26356;&#20026;&#31934;&#30830;&#30340;&#28176;&#36827;&#20998;&#26512;&#65292;&#20351;&#24471;&#20998;&#26512;&#26356;&#21152;&#31934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2207.11621</link><description>&lt;p&gt;
&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#27169;&#22411;&#22823;&#23567;&#12289;&#27979;&#35797;&#25439;&#22833;&#21644;&#35757;&#32451;&#25439;&#22833;&#20043;&#38388;&#30340;&#36890;&#29992;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
A Universal Trade-off Between the Model Size, Test Loss, and Training Loss of Linear Predictors. (arXiv:2207.11621v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11621
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982;&#31639;&#27861;&#21644;&#20998;&#24067;&#26080;&#20851;&#30340;&#38750;&#28176;&#36827;&#24615;&#26435;&#34913;&#26041;&#27861;&#65292;&#26469;&#34913;&#37327;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#27169;&#22411;&#22823;&#23567;&#12289;&#27979;&#35797;&#25439;&#22833;&#21644;&#35757;&#32451;&#25439;&#22833;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#21457;&#29616;&#27979;&#35797;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#33394;&#30340;&#27169;&#22411;&#35201;&#20040;&#26159;&#32463;&#20856;&#30340;&#65292;&#35201;&#20040;&#26159;&#29616;&#20195;&#30340;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#24403;&#30333;&#21270;&#29305;&#24449;&#30340;&#26497;&#38480;&#35889;&#20998;&#24067;&#20026;Marchenko-Pastur&#26102;&#30340;&#26356;&#20026;&#31934;&#30830;&#30340;&#28176;&#36827;&#20998;&#26512;&#65292;&#20351;&#24471;&#20998;&#26512;&#26356;&#21152;&#31934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982;&#31639;&#27861;&#21644;&#20998;&#24067;&#26080;&#20851;&#30340;&#38750;&#28176;&#36827;&#24615;&#26435;&#34913;&#26041;&#27861;&#65292;&#26469;&#34913;&#37327;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#27169;&#22411;&#22823;&#23567;&#12289;&#36229;&#39069;&#27979;&#35797;&#25439;&#22833;&#21644;&#35757;&#32451;&#25439;&#22833;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#33394;&#30340;&#27169;&#22411;&#35201;&#20040;&#26159;&#8220;&#32463;&#20856;&#8221;&#30340;&#8212;&#8212;&#20854;&#35757;&#32451;&#25439;&#22833;&#25509;&#36817;&#22122;&#22768;&#27700;&#24179;&#65292;&#35201;&#20040;&#26159;&#8220;&#29616;&#20195;&#30340;&#8221;&#8212;&#8212;&#20854;&#21442;&#25968;&#25968;&#37327;&#36828;&#36828;&#36229;&#36807;&#20165;&#20165;&#33021;&#31934;&#30830;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#25152;&#38656;&#30340;&#26368;&#23567;&#21442;&#25968;&#25968;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#24403;&#30333;&#21270;&#29305;&#24449;&#30340;&#26497;&#38480;&#35889;&#20998;&#24067;&#20026;Marchenko-Pastur&#26102;&#30340;&#26356;&#20026;&#31934;&#30830;&#30340;&#28176;&#36827;&#20998;&#26512;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#25554;&#20540;&#39030;&#28857;&#38468;&#36817;&#65292;&#21363;&#21442;&#25968;&#25968;&#37327;&#21018;&#22909;&#36275;&#20197;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#26102;&#65292;Marchenko-Pastur&#20998;&#26512;&#26356;&#21152;&#31934;&#30830;&#65292;&#32780;&#38543;&#30528;&#36807;&#24230;&#21442;&#25968;&#21270;&#31243;&#24230;&#30340;&#22686;&#21152;&#65292;&#23427;&#24688;&#22909;&#19982;&#26080;&#20998;&#24067;&#38480;&#21046;&#30340;&#29702;&#35770;&#19978;&#30028;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we establish an algorithm and distribution independent non-asymptotic trade-off between the model size, excess test loss, and training loss of linear predictors. Specifically, we show that models that perform well on the test data (have low excess loss) are either "classical" -- have training loss close to the noise level, or are "modern" -- have a much larger number of parameters compared to the minimum needed to fit the training data exactly.  We also provide a more precise asymptotic analysis when the limiting spectral distribution of the whitened features is Marchenko-Pastur. Remarkably, while the Marchenko-Pastur analysis is far more precise near the interpolation peak, where the number of parameters is just enough to fit the training data, it coincides exactly with the distribution independent bound as the level of overparametrization increases.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;RL&#31639;&#27861;PARTED&#65292;&#23427;&#36890;&#36807;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#30340;&#22870;&#21169;&#37325;&#26032;&#20998;&#37197;&#23558;&#36712;&#36857;&#22238;&#25253;&#20998;&#35299;&#20026;&#27599;&#27493;&#20195;&#29702;&#22870;&#21169;&#65292;&#28982;&#21518;&#22522;&#20110;&#23398;&#20064;&#30340;&#20195;&#29702;&#22870;&#21169;&#25191;&#34892;&#24754;&#35266;&#20540;&#36845;&#20195;&#65292;&#29992;&#20110;&#35299;&#20915;&#36712;&#36857;&#22870;&#21169;&#38590;&#20197;&#24456;&#22909;&#22320;&#21033;&#29992;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2206.06426</link><description>&lt;p&gt;
&#24102;&#36712;&#36857;&#22870;&#21169;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#21487;&#35777;&#25928;&#29575;&#24615;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Offline Reinforcement Learning with Trajectory-Wise Reward. (arXiv:2206.06426v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.06426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;RL&#31639;&#27861;PARTED&#65292;&#23427;&#36890;&#36807;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#30340;&#22870;&#21169;&#37325;&#26032;&#20998;&#37197;&#23558;&#36712;&#36857;&#22238;&#25253;&#20998;&#35299;&#20026;&#27599;&#27493;&#20195;&#29702;&#22870;&#21169;&#65292;&#28982;&#21518;&#22522;&#20110;&#23398;&#20064;&#30340;&#20195;&#29702;&#22870;&#21169;&#25191;&#34892;&#24754;&#35266;&#20540;&#36845;&#20195;&#65292;&#29992;&#20110;&#35299;&#20915;&#36712;&#36857;&#22870;&#21169;&#38590;&#20197;&#24456;&#22909;&#22320;&#21033;&#29992;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#26174;&#33879;&#25104;&#21151;&#20005;&#37325;&#20381;&#36182;&#20110;&#35266;&#27979;&#27599;&#20010;&#35775;&#38382;&#30340;&#29366;&#24577;-&#21160;&#20316;&#23545;&#30340;&#22870;&#21169;&#12290;&#28982;&#32780;&#22312;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#65292;&#20195;&#29702;&#21482;&#33021;&#35266;&#23519;&#34920;&#31034;&#25972;&#20010;&#36712;&#36857;&#36136;&#37327;&#30340;&#24471;&#20998;&#65292;&#31216;&#20026;"&#36712;&#36857;&#22870;&#21169;"&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#30340;RL&#26041;&#27861;&#24456;&#38590;&#24456;&#22909;&#22320;&#21033;&#29992;&#36712;&#36857;&#22870;&#21169;&#65292;&#24182;&#19988;&#21487;&#33021;&#20250;&#22312;&#31574;&#30053;&#35780;&#20272;&#20013;&#20135;&#29983;&#22823;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#35823;&#24046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;RL&#31639;&#27861;PARTED&#65292;&#23427;&#36890;&#36807;&#22522;&#20110;&#26368;&#23567;&#20108;&#20056;&#30340;&#22870;&#21169;&#37325;&#26032;&#20998;&#37197;&#23558;&#36712;&#36857;&#22238;&#25253;&#20998;&#35299;&#20026;&#27599;&#27493;&#20195;&#29702;&#22870;&#21169;&#65292;&#28982;&#21518;&#22522;&#20110;&#23398;&#20064;&#30340;&#20195;&#29702;&#22870;&#21169;&#25191;&#34892;&#24754;&#35266;&#20540;&#36845;&#20195;&#12290;&#20026;&#20102;&#30830;&#20445;PARTED&#26500;&#24314;&#30340;&#20540;&#20989;&#25968;&#22987;&#32456;&#23545;&#26368;&#20248;&#20540;&#20989;&#25968;&#24754;&#35266;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#24809;&#32602;&#39033;&#26469;&#25269;&#28040;&#20195;&#29702;&#22870;&#21169;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The remarkable success of reinforcement learning (RL) heavily relies on observing the reward of every visited state-action pair. In many real world applications, however, an agent can observe only a score that represents the quality of the whole trajectory, which is referred to as the {\em trajectory-wise reward}. In such a situation, it is difficult for standard RL methods to well utilize trajectory-wise reward, and large bias and variance errors can be incurred in policy evaluation. In this work, we propose a novel offline RL algorithm, called Pessimistic vAlue iteRaTion with rEward Decomposition (PARTED), which decomposes the trajectory return into per-step proxy rewards via least-squares-based reward redistribution, and then performs pessimistic value iteration based on the learned proxy reward. To ensure the value functions constructed by PARTED are always pessimistic with respect to the optimal ones, we design a new penalty term to offset the uncertainty of the proxy reward. For 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#31867;&#19982;&#26368;&#26032;&#31639;&#27861;&#31361;&#30772;&#65292;&#31163;&#32447;RL&#31639;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#21644;&#26426;&#22120;&#20154;&#31561;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2203.01387</link><description>&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#32508;&#36848;&#65306;&#20998;&#31867;&#12289;&#22238;&#39038;&#21644;&#26410;&#35299;&#20915;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems. (arXiv:2203.01387v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01387
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#31867;&#19982;&#26368;&#26032;&#31639;&#27861;&#31361;&#30772;&#65292;&#31163;&#32447;RL&#31639;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#21644;&#26426;&#22120;&#20154;&#31561;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#35299;&#20915;&#20197;&#24448;&#26080;&#27861;&#22788;&#29702;&#30340;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#22914;&#20174;&#20687;&#32032;&#35266;&#23519;&#20013;&#29609;&#22797;&#26434;&#28216;&#25103;&#12289;&#19982;&#20154;&#31867;&#36827;&#34892;&#23545;&#35805;&#20197;&#21450;&#25511;&#21046;&#26426;&#22120;&#20154;&#26234;&#33021;&#20307;&#12290;&#28982;&#32780;&#65292;&#20173;&#26377;&#35768;&#22810;&#39046;&#22495;&#30001;&#20110;&#19982;&#29615;&#22659;&#20114;&#21160;&#30340;&#39640;&#25104;&#26412;&#21644;&#21361;&#38505;&#32780;&#26080;&#27861;&#29992;RL&#35299;&#20915;&#12290;&#31163;&#32447;RL&#26159;&#19968;&#31181;&#33539;&#24335;&#65292;&#23427;&#20165;&#20174;&#20197;&#21069;&#25910;&#38598;&#30340;&#20132;&#20114;&#30340;&#38745;&#24577;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#65292;&#22240;&#27492;&#21487;&#20197;&#20174;&#22823;&#22411;&#21644;&#22810;&#26679;&#21270;&#30340;&#22521;&#35757;&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#31574;&#30053;&#12290;&#26377;&#25928;&#30340;&#31163;&#32447;RL&#31639;&#27861;&#27604;&#22312;&#32447;RL&#31639;&#27861;&#20855;&#26377;&#26356;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#21644;&#26426;&#22120;&#20154;&#31561;&#23454;&#38469;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#20998;&#31867;&#27861;&#65292;&#23545;&#31163;&#32447;RL&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#35813;&#39046;&#22495;&#26368;&#26032;&#30340;&#31639;&#27861;&#31361;&#30772;&#36827;&#34892;&#20102;&#20840;&#38754;&#22238;&#39038;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the widespread adoption of deep learning, reinforcement learning (RL) has experienced a dramatic increase in popularity, scaling to previously intractable problems, such as playing complex games from pixel observations, sustaining conversations with humans, and controlling robotic agents. However, there is still a wide range of domains inaccessible to RL due to the high cost and danger of interacting with the environment. Offline RL is a paradigm that learns exclusively from static datasets of previously collected interactions, making it feasible to extract policies from large and diverse training datasets. Effective offline RL algorithms have a much wider range of applications than online RL, being particularly appealing for real-world applications, such as education, healthcare, and robotics. In this work, we contribute with a unifying taxonomy to classify offline RL methods. Furthermore, we provide a comprehensive review of the latest algorithmic breakthroughs in the field usin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31163;&#32676;&#20540;&#25239;&#24615;&#20272;&#35745;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#28176;&#36827;&#20998;&#20301;&#25968;&#31639;&#27861;&#35299;&#20915;&#31163;&#32676;&#20540;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#21487;&#20280;&#32553;&#31639;&#27861;&#26469;&#20445;&#35777;&#24555;&#36895;&#25910;&#25947;&#24615;&#21644;&#36229;&#36234;M-&#20272;&#35745;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2112.08471</link><description>&lt;p&gt;
&#22312;&#28176;&#36827;&#20998;&#20301;&#25968;&#20013;&#33719;&#24471;&#31163;&#32676;&#20540;&#25239;&#24615;&#65306;&#24555;&#36895;&#31639;&#27861;&#21644;&#29702;&#35770;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Gaining Outlier Resistance with Progressive Quantiles: Fast Algorithms and Theoretical Studies. (arXiv:2112.08471v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.08471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31163;&#32676;&#20540;&#25239;&#24615;&#20272;&#35745;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#28176;&#36827;&#20998;&#20301;&#25968;&#31639;&#27861;&#35299;&#20915;&#31163;&#32676;&#20540;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#21487;&#20280;&#32553;&#31639;&#27861;&#26469;&#20445;&#35777;&#24555;&#36895;&#25910;&#25947;&#24615;&#21644;&#36229;&#36234;M-&#20272;&#35745;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32676;&#20540;&#22312;&#22823;&#25968;&#25454;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#21487;&#33021;&#20005;&#37325;&#24433;&#21709;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31163;&#32676;&#20540;&#25239;&#24615;&#20272;&#35745;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22686;&#24378;&#20219;&#24847;&#32473;&#23450;&#25439;&#22833;&#20989;&#25968;&#30340;&#40065;&#26834;&#24615;&#12290;&#23427;&#19982;&#20462;&#21098;&#26041;&#27861;&#26377;&#30528;&#23494;&#20999;&#30340;&#32852;&#31995;&#65292;&#24182;&#20026;&#25152;&#26377;&#26679;&#26412;&#25552;&#20379;&#20102;&#26174;&#24335;&#30340;&#31163;&#32676;&#25351;&#26631;&#65292;&#20174;&#32780;&#26041;&#20415;&#35745;&#31639;&#12289;&#29702;&#35770;&#21644;&#21442;&#25968;&#35843;&#25972;&#12290;&#20026;&#20102;&#35299;&#20915;&#20984;&#24615;&#21644;&#19981;&#20809;&#28369;&#24615;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21487;&#20280;&#32553;&#30340;&#31639;&#27861;&#65292;&#24182;&#20445;&#35777;&#20102;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#25216;&#26415;&#65292;&#20197;&#20943;&#36731;&#23545;&#36215;&#22987;&#28857;&#30340;&#35201;&#27714;&#65292;&#20351;&#24471;&#22312;&#24120;&#35268;&#25968;&#25454;&#38598;&#19978;&#65292;&#25968;&#25454;&#37325;&#26032;&#37319;&#26679;&#30340;&#27425;&#25968;&#21487;&#20197;&#22823;&#22823;&#20943;&#23569;&#12290;&#22522;&#20110;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#32508;&#21512;&#22788;&#29702;&#65292;&#25105;&#20204;&#33021;&#22815;&#36827;&#34892;&#36229;&#36234;M-&#20272;&#35745;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;&#12290;&#24471;&#21040;&#30340;&#40065;&#26834;&#20272;&#35745;&#37327;&#65292;&#34429;&#28982;&#19981;&#19968;&#23450;&#26159;&#20840;&#23616;&#29978;&#33267;&#26159;&#23616;&#37096;&#26368;&#20248;&#65292;&#20294;&#22312;&#24191;&#27867;&#30340;&#32479;&#35745;&#27169;&#22411;&#20013;&#20855;&#26377;&#28176;&#36817;&#30340;&#26368;&#23567;&#22823;&#35823;&#24046;&#29575;&#26368;&#20248;&#24615;&#65292;&#21253;&#25324;&#21442;&#25968;&#21644;&#38750;&#21442;&#25968;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Outliers widely occur in big-data applications and may severely affect statistical estimation and inference. In this paper, a framework of outlier-resistant estimation is introduced to robustify an arbitrarily given loss function. It has a close connection to the method of trimming and includes explicit outlyingness parameters for all samples, which in turn facilitates computation, theory, and parameter tuning. To tackle the issues of nonconvexity and nonsmoothness, we develop scalable algorithms with implementation ease and guaranteed fast convergence. In particular, a new technique is proposed to alleviate the requirement on the starting point such that on regular datasets, the number of data resamplings can be substantially reduced. Based on combined statistical and computational treatments, we are able to perform nonasymptotic analysis beyond M-estimation. The obtained resistant estimators, though not necessarily globally or even locally optimal, enjoy minimax rate optimality in bo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#21152;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;(SLR)&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#27169;&#22411;&#21644;&#27714;&#35299;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2109.12701</link><description>&lt;p&gt;
&#31232;&#30095;&#21152;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;: &#19968;&#31181;&#31163;&#25955;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sparse Plus Low Rank Matrix Decomposition: A Discrete Optimization Approach. (arXiv:2109.12701v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.12701
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#21152;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#38382;&#39064;(SLR)&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#27169;&#22411;&#21644;&#27714;&#35299;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#31181;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#31232;&#30095;&#21152;&#20302;&#31209;&#20998;&#35299;&#38382;&#39064;(SLR)&#65292;&#21363;&#23558;&#25439;&#22351;&#30340;&#25968;&#25454;&#30697;&#38453;&#20998;&#35299;&#20026;&#21253;&#21547;&#22522;&#26412;&#30495;&#20540;&#30340;&#20302;&#31209;&#30697;&#38453;&#21644;&#21253;&#21547;&#25200;&#21160;&#30340;&#31232;&#30095;&#30697;&#38453;&#12290; SLR&#26159;&#36816;&#31609;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#22522;&#30784;&#38382;&#39064;&#65292;&#22312;&#25968;&#25454;&#21387;&#32553;&#12289;&#28508;&#22312;&#35821;&#20041;&#32034;&#24341;&#12289;&#21327;&#21516;&#36807;&#28388;&#21644;&#21307;&#23398;&#25104;&#20687;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#20986;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#25955;&#27169;&#22411;&#65292;&#24182;&#35774;&#35745;&#20102;&#20132;&#26367;&#26368;&#23567;&#21270;&#21551;&#21457;&#24335;&#31639;&#27861;&#20197;&#21450;&#26032;&#30340;&#21322;&#23450;&#26494;&#24347;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#33258;&#23450;&#20041;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#21033;&#29992;&#25105;&#20204;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#21644;&#20984;&#26494;&#24347;&#26469;&#35299;&#20915;&#23567;&#35268;&#27169;&#30340;SLR&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#21487;&#20197;&#35299;&#20915; $n=10000$ &#30340;&#38382;&#39064;&#35268;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Sparse Plus Low-Rank decomposition problem (SLR), which is the problem of decomposing a corrupted data matrix into a sparse matrix of perturbations plus a low-rank matrix containing the ground truth. SLR is a fundamental problem in Operations Research and Machine Learning which arises in various applications, including data compression, latent semantic indexing, collaborative filtering, and medical imaging. We introduce a novel formulation for SLR that directly models its underlying discreteness. For this formulation, we develop an alternating minimization heuristic that computes high-quality solutions and a novel semidefinite relaxation that provides meaningful bounds for the solutions returned by our heuristic. We also develop a custom branch-and-bound algorithm that leverages our heuristic and convex relaxations to solve small instances of SLR to certifiable (near) optimality. Given an input $n$-by-$n$ matrix, our heuristic scales to solve instances where $n=10000$ in m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#37319;&#26679;&#25104;&#26412;&#30340;&#36830;&#32493;&#26102;&#38388;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#36830;&#32493;&#26102;&#38388;&#37324;&#65292;&#23398;&#20064;&#32773;&#35201;&#22312;&#33719;&#24471;&#26356;&#39640;&#22870;&#21169;&#21644;&#25215;&#25285;&#37319;&#26679;&#25104;&#26412;&#20043;&#38388;&#36827;&#34892;&#26377;&#25928;&#24179;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36798;&#21040;&#19979;&#30028;&#30340;&#31639;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#19982;&#20256;&#32479;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19981;&#21516;&#30340;&#29305;&#27530;&#29616;&#35937;&#65292;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2107.05289</link><description>&lt;p&gt;
&#24102;&#37319;&#26679;&#25104;&#26412;&#30340;&#36830;&#32493;&#26102;&#38388;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Continuous Time Bandits With Sampling Costs. (arXiv:2107.05289v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.05289
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#37319;&#26679;&#25104;&#26412;&#30340;&#36830;&#32493;&#26102;&#38388;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#36830;&#32493;&#26102;&#38388;&#37324;&#65292;&#23398;&#20064;&#32773;&#35201;&#22312;&#33719;&#24471;&#26356;&#39640;&#22870;&#21169;&#21644;&#25215;&#25285;&#37319;&#26679;&#25104;&#26412;&#20043;&#38388;&#36827;&#34892;&#26377;&#25928;&#24179;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36798;&#21040;&#19979;&#30028;&#30340;&#31639;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#19982;&#20256;&#32479;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#19981;&#21516;&#30340;&#29305;&#27530;&#29616;&#35937;&#65292;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;(Continuous Time Multi-arm Bandit Problem&#65292;CTMAB)&#12290;&#22312;&#32473;&#23450;&#26102;&#38388;&#27573;&#20869;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#23545;&#33218;&#36827;&#34892;&#20219;&#24847;&#27425;&#37319;&#26679;&#65292;&#27599;&#27425;&#37319;&#26679;&#37117;&#33021;&#33719;&#24471;&#38543;&#26426;&#22870;&#21169;&#65292;&#20294;&#37319;&#26679;&#39057;&#29575;&#30340;&#25552;&#39640;&#20250;&#24102;&#26469;&#39069;&#22806;&#30340;&#24809;&#32602;/&#25104;&#26412;&#12290;&#22240;&#27492;&#65292;&#23384;&#22312;&#33719;&#24471;&#26356;&#39640;&#22870;&#21169;&#19982;&#25215;&#25285;&#37319;&#26679;&#25104;&#26412;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;&#26412;&#25991;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#23398;&#20064;&#31639;&#27861;&#65292;&#20351;&#36951;&#25022;&#65288;regret&#65292;&#23450;&#20041;&#20026;&#23398;&#20064;&#31639;&#27861;&#19982;&#29702;&#35770;&#26368;&#20248;&#31574;&#30053;&#25910;&#30410;&#20043;&#38388;&#30340;&#24046;&#20540;&#65289;&#36798;&#21040;&#26368;&#23567;&#12290;CTMAB&#19982;&#36890;&#24120;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;(Multi-armed Bandit Problem&#65292;MAB)&#26377;&#26681;&#26412;&#30340;&#21306;&#21035;&#65292;&#20363;&#22914;&#65292;&#22312;CTMAB&#20013;&#65292;&#21333;&#33218;&#24773;&#20917;&#37117;&#19981;&#26159;&#24494;&#19981;&#36275;&#36947;&#30340;&#65292;&#22240;&#20026;&#26368;&#20248;&#37319;&#26679;&#39057;&#29575;&#21462;&#20915;&#20110;&#33218;&#30340;&#22343;&#20540;&#65292;&#32780;&#35813;&#22343;&#20540;&#38656;&#35201;&#34987;&#20272;&#35745;&#12290;&#26412;&#25991;&#39318;&#20808;&#24314;&#31435;&#20102;&#25152;&#26377;&#31639;&#27861;&#21487;&#36798;&#21040;&#30340;&#36951;&#25022;&#19979;&#30028;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25968;&#22240;&#23376;&#19978;&#36798;&#21040;&#19979;&#30028;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;&#21333;&#33218;&#24773;&#20917;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19979;&#38480;&#21644;&#19978;&#38480;&#22823;&#33268;&#31526;&#21512;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22312;&#32463;&#20856;MAB&#38382;&#39064;&#20013;&#19981;&#23384;&#22312;&#30340;&#20196;&#20154;&#24778;&#35766;&#30340;&#29616;&#35937;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a continuous-time multi-arm bandit problem (CTMAB), where the learner can sample arms any number of times in a given interval and obtain a random reward from each sample, however, increasing the frequency of sampling incurs an additive penalty/cost. Thus, there is a tradeoff between obtaining large reward and incurring sampling cost as a function of the sampling frequency. The goal is to design a learning algorithm that minimizes regret, that is defined as the difference of the payoff of the oracle policy and that of the learning algorithm. CTMAB is fundamentally different than the usual multi-arm bandit problem (MAB), e.g., even the single-arm case is non-trivial in CTMAB, since the optimal sampling frequency depends on the mean of the arm, which needs to be estimated. We first establish lower bounds on the regret achievable with any algorithm and then propose algorithms that achieve the lower bound up to logarithmic factors. For the single-arm case, we show that the lower
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#38750;&#21033;&#26222;&#24076;&#33576;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#38382;&#39064;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#25915;&#20987;&#27169;&#22411;&#24110;&#21161;&#29702;&#35299;&#20869;&#22312;&#23646;&#24615;&#65292;&#35777;&#26126;&#20102;&#27492;&#31867;&#25915;&#20987;&#32773;&#21487;&#20197;&#25112;&#32988;&#25152;&#26377;&#24517;&#39035;&#23545;&#20854;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#31639;&#27861;&#65292;&#20294;&#20063;&#25552;&#20986;&#20102;&#20811;&#26381;&#27492;&#31867;&#25915;&#20987;&#32773;&#30340;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#24182;&#20026;&#26368;&#36817;&#37051;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2010.06154</link><description>&lt;p&gt;
&#38750;&#21033;&#26222;&#24076;&#33576;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Robustness of Non-Lipschitz Networks. (arXiv:2010.06154v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.06154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#38750;&#21033;&#26222;&#24076;&#33576;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#38382;&#39064;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#25915;&#20987;&#27169;&#22411;&#24110;&#21161;&#29702;&#35299;&#20869;&#22312;&#23646;&#24615;&#65292;&#35777;&#26126;&#20102;&#27492;&#31867;&#25915;&#20987;&#32773;&#21487;&#20197;&#25112;&#32988;&#25152;&#26377;&#24517;&#39035;&#23545;&#20854;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#31639;&#27861;&#65292;&#20294;&#20063;&#25552;&#20986;&#20102;&#20811;&#26381;&#27492;&#31867;&#25915;&#20987;&#32773;&#30340;&#26041;&#27861;&#65292;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#24182;&#20026;&#26368;&#36817;&#37051;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#24050;&#32463;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#28145;&#24230;&#32593;&#32476;&#20173;&#28982;&#26497;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#20854;&#20013;&#19968;&#20010;&#26681;&#26412;&#24615;&#30340;&#25361;&#25112;&#26159;&#65306;&#21363;&#20351;&#36755;&#20837;&#30053;&#24494;&#25200;&#21160;&#65292;&#20063;&#21487;&#33021;&#20250;&#20135;&#29983;&#32593;&#32476;&#26368;&#32456;&#23618;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#22823;&#24133;&#31227;&#21160;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#25915;&#20987;&#27169;&#22411;&#26469;&#25277;&#35937;&#36825;&#20010;&#25361;&#25112;&#65292;&#20197;&#24110;&#21161;&#29702;&#35299;&#23427;&#30340;&#20869;&#22312;&#23646;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;&#25163;&#21487;&#20197;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#20219;&#24847;&#36317;&#31163;&#19978;&#31227;&#21160;&#25968;&#25454;&#65292;&#20294;&#21482;&#33021;&#22312;&#38543;&#26426;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#20869;&#36827;&#34892;&#25805;&#20316;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#25915;&#20987;&#32773;&#21487;&#20197;&#38750;&#24120;&#24378;&#22823;&#65306;&#23427;&#20204;&#21487;&#20197;&#25112;&#32988;&#20219;&#20309;&#24517;&#39035;&#23545;&#20854;&#25910;&#21040;&#30340;&#25152;&#26377;&#36755;&#20837;&#36827;&#34892;&#20998;&#31867;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20801;&#35768;&#31639;&#27861;&#25918;&#24323;&#22788;&#29702;&#19981;&#23547;&#24120;&#30340;&#36755;&#20837;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#31867;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#30456;&#23545;&#20998;&#31163;&#24471;&#24456;&#22909;&#26102;&#65292;&#36825;&#31181;&#25915;&#20987;&#32773;&#26159;&#21487;&#20197;&#34987;&#20811;&#26381;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20197;&#20351;&#29992;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#35774;&#32622;&#31639;&#27861;&#21442;&#25968;&#20197;&#20248;&#21270;&#31934;&#24230;-&#25918;&#24323;&#26435;&#34913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#26368;&#36817;&#37051;&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite significant advances, deep networks remain highly susceptible to adversarial attack. One fundamental challenge is that small input perturbations can often produce large movements in the network's final-layer feature space. In this paper, we define an attack model that abstracts this challenge, to help understand its intrinsic properties. In our model, the adversary may move data an arbitrary distance in feature space but only in random low-dimensional subspaces. We prove such adversaries can be quite powerful: defeating any algorithm that must classify any input it is given. However, by allowing the algorithm to abstain on unusual inputs, we show such adversaries can be overcome when classes are reasonably well-separated in feature space. We further provide strong theoretical guarantees for setting algorithm parameters to optimize over accuracy-abstention trade-offs using data-driven methods. Our results provide new robustness guarantees for nearest-neighbor style algorithms, a
&lt;/p&gt;</description></item></channel></rss>