<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PRESTO&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26144;&#23556;&#20381;&#36182;&#20110;&#28508;&#22312;&#34920;&#31034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22810;&#20803;&#23431;&#23449;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#25345;&#32493;&#21516;&#35843;&#26469;&#27979;&#37327;&#28508;&#22312;&#31354;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#32479;&#35745;&#25512;&#29702;&#23427;&#20204;&#30340;&#20998;&#24067;&#12290;&#21487;&#20197;&#29992;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#26816;&#27979;&#24322;&#24120;&#23884;&#20837;&#21644;&#39640;&#25928;&#23548;&#33322;&#36229;&#21442;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01514</link><description>&lt;p&gt;
&#26144;&#23556;&#28508;&#22312;&#34920;&#31034;&#30340;&#22810;&#20803;&#23431;&#23449;
&lt;/p&gt;
&lt;p&gt;
Mapping the Multiverse of Latent Representations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01514
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PRESTO&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26144;&#23556;&#20381;&#36182;&#20110;&#28508;&#22312;&#34920;&#31034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22810;&#20803;&#23431;&#23449;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#25345;&#32493;&#21516;&#35843;&#26469;&#27979;&#37327;&#28508;&#22312;&#31354;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#32479;&#35745;&#25512;&#29702;&#23427;&#20204;&#30340;&#20998;&#24067;&#12290;&#21487;&#20197;&#29992;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#26816;&#27979;&#24322;&#24120;&#23884;&#20837;&#21644;&#39640;&#25928;&#23548;&#33322;&#36229;&#21442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21709;&#24212;&#26368;&#36817;&#23545;&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#26469;&#24212;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#38752;&#24615;&#21644;&#31283;&#20581;&#24615;&#38382;&#39064;&#30340;&#21628;&#21505;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PRESTO&#65292;&#19968;&#31181;&#31995;&#32479;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26144;&#23556;&#20381;&#36182;&#20110;&#28508;&#22312;&#34920;&#31034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22810;&#20803;&#23431;&#23449;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20294;&#23545;&#23427;&#20204;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#20173;&#28982;&#19981;&#34987;&#20805;&#20998;&#29702;&#35299;&#65292;&#23548;&#33268;&#20102;&#19981;&#24517;&#35201;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#21487;&#38752;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#25345;&#32493;&#21516;&#35843;&#26469;&#34920;&#24449;&#19981;&#21516;&#32452;&#21512;&#30340;&#22810;&#26679;&#21270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12289;(&#36229;)&#21442;&#25968;&#37197;&#32622;&#21644;&#25968;&#25454;&#38598;&#25152;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#27979;&#37327;&#23427;&#20204;&#20043;&#38388;&#30340;&#25104;&#23545;(&#38750;)&#30456;&#20284;&#24615;&#24182;&#23545;&#20854;&#20998;&#24067;&#36827;&#34892;&#32479;&#35745;&#25512;&#29702;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#25152;&#35777;&#26126;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#27969;&#31243;&#20445;&#25345;&#20102;&#28508;&#22312;&#34920;&#31034;&#38598;&#21512;&#30340;&#29702;&#24819;&#29305;&#24615;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#26816;&#27979;&#24322;&#24120;&#23884;&#20837;&#25110;&#39640;&#25928;&#26377;&#25928;&#22320;&#23548;&#33322;&#36229;&#21442;&#12290;
&lt;/p&gt;
&lt;p&gt;
Echoing recent calls to counter reliability and robustness concerns in machine learning via multiverse analysis, we present PRESTO, a principled framework for mapping the multiverse of machine-learning models that rely on latent representations. Although such models enjoy widespread adoption, the variability in their embeddings remains poorly understood, resulting in unnecessary complexity and untrustworthy representations. Our framework uses persistent homology to characterize the latent spaces arising from different combinations of diverse machine-learning methods, (hyper)parameter configurations, and datasets, allowing us to measure their pairwise (dis)similarity and statistically reason about their distributions. As we demonstrate both theoretically and empirically, our pipeline preserves desirable properties of collections of latent representations, and it can be leveraged to perform sensitivity analysis, detect anomalous embeddings, or efficiently and effectively navigate hyperpa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#22343;&#22330;&#21644;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#21442;&#25968;&#20998;&#24067;&#30340;&#25439;&#22833;&#26223;&#35266;&#34429;&#28982;&#39640;&#24230;&#38750;&#20984;&#65292;&#20294;&#21464;&#24471;&#30456;&#24403;&#28201;&#21644;&#65292;&#24182;&#24314;&#31435;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#33719;&#24471;&#20855;&#20307;&#30340;&#25913;&#36827;&#36895;&#29575;&#65292;&#36825;&#23558;&#26377;&#21161;&#20110;&#22686;&#24378;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01258</link><description>&lt;p&gt;
Transformers&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29305;&#24449;&#65306;&#20851;&#20110;&#27880;&#24847;&#21147;&#22330;&#26223;&#20013;&#30340;&#38750;&#20984;&#22343;&#22330;&#21160;&#24577;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transformers Learn Nonlinear Features In Context: Nonconvex Mean-field Dynamics on the Attention Landscape
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#22343;&#22330;&#21644;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#21442;&#25968;&#20998;&#24067;&#30340;&#25439;&#22833;&#26223;&#35266;&#34429;&#28982;&#39640;&#24230;&#38750;&#20984;&#65292;&#20294;&#21464;&#24471;&#30456;&#24403;&#28201;&#21644;&#65292;&#24182;&#24314;&#31435;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#33719;&#24471;&#20855;&#20307;&#30340;&#25913;&#36827;&#36895;&#29575;&#65292;&#36825;&#23558;&#26377;&#21161;&#20110;&#22686;&#24378;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#19968;&#29616;&#35937;&#20135;&#29983;&#30340;&#29616;&#26377;&#29702;&#35770;&#30740;&#31350;&#20165;&#38480;&#20110;&#23545;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#21333;&#23618;&#27880;&#24847;&#21147;&#30340;&#21160;&#24577;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#30001;&#20840;&#36830;&#25509;&#23618;&#21644;&#32447;&#24615;&#27880;&#24847;&#21147;&#23618;&#32452;&#25104;&#30340;Transformer&#30340;&#20248;&#21270;&#12290;MLP&#20805;&#24403;&#20102;&#19968;&#20010;&#24120;&#35265;&#30340;&#38750;&#32447;&#24615;&#34920;&#31034;&#25110;&#29305;&#24449;&#26144;&#23556;&#65292;&#26497;&#22823;&#22320;&#22686;&#24378;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#22343;&#22330;&#21644;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#21442;&#25968;&#20998;&#24067;&#30340;&#26080;&#38480;&#32500;&#25439;&#22833;&#26223;&#35266;&#65292;&#34429;&#28982;&#39640;&#24230;&#38750;&#20984;&#65292;&#20294;&#21464;&#24471;&#30456;&#24403;&#28201;&#21644;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#22343;&#22330;&#21160;&#24577;&#30340;&#20108;&#38454;&#31283;&#23450;&#24615;&#65292;&#24182;&#34920;&#26126;Wasserstein&#26799;&#24230;&#27969;&#20960;&#20046;&#24635;&#26159;&#36991;&#24320;&#38797;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#33719;&#24471;&#36828;&#31163;&#20020;&#30028;&#28857;&#21644;&#25509;&#36817;&#20020;&#30028;&#28857;&#30340;&#20855;&#20307;&#25913;&#36827;&#36895;&#29575;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models based on the Transformer architecture have demonstrated impressive capabilities to learn in context. However, existing theoretical studies on how this phenomenon arises are limited to the dynamics of a single layer of attention trained on linear regression tasks. In this paper, we study the optimization of a Transformer consisting of a fully connected layer followed by a linear attention layer. The MLP acts as a common nonlinear representation or feature map, greatly enhancing the power of in-context learning. We prove in the mean-field and two-timescale limit that the infinite-dimensional loss landscape for the distribution of parameters, while highly nonconvex, becomes quite benign. We also analyze the second-order stability of mean-field dynamics and show that Wasserstein gradient flow almost always avoids saddle points. Furthermore, we establish novel methods for obtaining concrete improvement rates both away from and near critical points. This represents the 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.20233</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Functional Bilevel Optimization for Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20233
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#35270;&#35282;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#34987;&#26368;&#23567;&#21270;&#12290;&#36825;&#20123;&#31867;&#22411;&#30340;&#38382;&#39064;&#36890;&#24120;&#36890;&#36807;&#22312;&#21442;&#25968;&#35774;&#32622;&#19979;&#24320;&#21457;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#23545;&#20110;&#39044;&#27979;&#20989;&#25968;&#30340;&#21442;&#25968;&#24378;&#20984;&#12290;&#20989;&#25968;&#35270;&#35282;&#19981;&#20381;&#36182;&#20110;&#27492;&#20551;&#35774;&#65292;&#29305;&#21035;&#20801;&#35768;&#20351;&#29992;&#36229;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20869;&#37096;&#39044;&#27979;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#36866;&#21512;&#33258;&#28982;&#20989;&#25968;&#21452;&#23618;&#32467;&#26500;&#30340;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20233v1 Announce Type: cross  Abstract: In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks, which admit natural functional bilevel structures.
&lt;/p&gt;</description></item><item><title>&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#20559;&#22909;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#29702;&#24615;&#21407;&#21017;&#34701;&#20837;&#23398;&#20064;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.11782</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20174;&#20559;&#22909;&#21644;&#36873;&#25321;&#20013;&#23398;&#20064;&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A tutorial on learning from preferences and choices with Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11782
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#20559;&#22909;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#29702;&#24615;&#21407;&#21017;&#34701;&#20837;&#23398;&#20064;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#22909;&#24314;&#27169;&#20301;&#20110;&#32463;&#27982;&#23398;&#12289;&#20915;&#31574;&#29702;&#35770;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#29702;&#35299;&#20010;&#20307;&#30340;&#20559;&#22909;&#21450;&#20854;&#36873;&#25321;&#26041;&#24335;&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#26356;&#25509;&#36817;&#20182;&#20204;&#26399;&#26395;&#30340;&#20135;&#21697;&#65292;&#20026;&#36328;&#39046;&#22495;&#30340;&#26356;&#39640;&#25928;&#12289;&#20010;&#24615;&#21270;&#24212;&#29992;&#38138;&#24179;&#36947;&#36335;&#12290;&#27492;&#25945;&#31243;&#30340;&#30446;&#26631;&#26159;&#25552;&#20379;&#19968;&#20010;&#36830;&#36143;&#12289;&#20840;&#38754;&#30340;&#20559;&#22909;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#28436;&#31034;&#22914;&#20309;&#23558;&#29702;&#24615;&#21407;&#21017;&#65288;&#26469;&#33258;&#32463;&#27982;&#23398;&#21644;&#20915;&#31574;&#29702;&#35770;&#65289;&#26080;&#32541;&#22320;&#32435;&#20837;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#36890;&#36807;&#21512;&#36866;&#22320;&#23450;&#21046;&#20284;&#28982;&#20989;&#25968;&#65292;&#36825;&#19968;&#26694;&#26550;&#20351;&#24471;&#33021;&#22815;&#26500;&#24314;&#28085;&#30422;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#12289;&#36776;&#35782;&#38480;&#21046;&#21644;&#23545;&#35937;&#21644;&#26631;&#31614;&#20559;&#22909;&#30340;&#22810;&#37325;&#20914;&#31361;&#25928;&#29992;&#24773;&#26223;&#30340;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11782v1 Announce Type: new  Abstract: Preference modelling lies at the intersection of economics, decision theory, machine learning and statistics. By understanding individuals' preferences and how they make choices, we can build products that closely match their expectations, paving the way for more efficient and personalised applications across a wide range of domains. The objective of this tutorial is to present a cohesive and comprehensive framework for preference learning with Gaussian Processes (GPs), demonstrating how to seamlessly incorporate rationality principles (from economics and decision theory) into the learning process. By suitably tailoring the likelihood function, this framework enables the construction of preference learning models that encompass random utility models, limits of discernment, and scenarios with multiple conflicting utilities for both object- and label-preference. This tutorial builds upon established research while simultaneously introducin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#20043;&#38388;&#25554;&#20540;&#65292;&#23454;&#29616;&#20102;&#37319;&#26679;&#36895;&#24230;&#21644;&#37319;&#26679;&#36136;&#37327;&#30340;&#24179;&#34913;&#12290;</title><link>https://arxiv.org/abs/2403.06807</link><description>&lt;p&gt;
&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Multistep Consistency Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.06807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#20043;&#38388;&#25554;&#20540;&#65292;&#23454;&#29616;&#20102;&#37319;&#26679;&#36895;&#24230;&#21644;&#37319;&#26679;&#36136;&#37327;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30456;&#23545;&#23481;&#26131;&#35757;&#32451;&#65292;&#20294;&#29983;&#25104;&#26679;&#26412;&#38656;&#35201;&#35768;&#22810;&#27493;&#39588;&#12290;&#19968;&#33268;&#24615;&#27169;&#22411;&#26356;&#38590;&#35757;&#32451;&#65292;&#20294;&#21487;&#20197;&#22312;&#19968;&#20010;&#27493;&#39588;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#65306;&#36890;&#36807;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;TRACT&#30340;&#32479;&#19968;&#65292;&#21487;&#20197;&#22312;&#19968;&#33268;&#24615;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65306;&#22312;&#37319;&#26679;&#36895;&#24230;&#21644;&#37319;&#26679;&#36136;&#37327;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;1&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#26159;&#20256;&#32479;&#30340;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#32780;&#25105;&#20204;&#23637;&#31034;&#20102;$\infty$&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#26159;&#25193;&#25955;&#27169;&#22411;&#12290;&#22810;&#27493;&#19968;&#33268;&#24615;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#23558;&#26679;&#26412;&#39044;&#31639;&#20174;&#21333;&#27493;&#22686;&#21152;&#21040;2-8&#27493;&#65292;&#25105;&#20204;&#21487;&#20197;&#26356;&#36731;&#26494;&#22320;&#35757;&#32451;&#27169;&#22411;&#65292;&#29983;&#25104;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#65292;&#21516;&#26102;&#20445;&#30041;&#22823;&#37096;&#20998;&#37319;&#26679;&#36895;&#24230;&#20248;&#21183;&#12290;&#22312;Imagenet 64&#19978;8&#27493;&#36798;&#21040;1.4&#30340;FID&#65292;&#22312;Imagenet128&#19978;8&#27493;&#36798;&#21040;2.1&#30340;FID&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.06807v1 Announce Type: new  Abstract: Diffusion models are relatively easy to train but require many steps to generate samples. Consistency models are far more difficult to train, but generate samples in a single step.   In this paper we propose Multistep Consistency Models: A unification between Consistency Models (Song et al., 2023) and TRACT (Berthelot et al., 2023) that can interpolate between a consistency model and a diffusion model: a trade-off between sampling speed and sampling quality. Specifically, a 1-step consistency model is a conventional consistency model whereas we show that a $\infty$-step consistency model is a diffusion model.   Multistep Consistency Models work really well in practice. By increasing the sample budget from a single step to 2-8 steps, we can train models more easily that generate higher quality samples, while retaining much of the sampling speed benefits. Notable results are 1.4 FID on Imagenet 64 in 8 step and 2.1 FID on Imagenet128 in 8 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#38543;&#26426;&#23376;&#38598;&#30340;&#21021;&#22987;&#26435;&#37325;&#26469;&#20943;&#23569;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLT&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#20174;&#32780;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#38477;&#20302;&#20102;SLT&#25628;&#32034;&#31354;&#38388;&#65292;&#20445;&#35777;&#20102;SLT&#22312;&#36825;&#31181;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#20013;&#30340;&#23384;&#22312;&#12290;</title><link>https://arxiv.org/abs/2402.14029</link><description>&lt;p&gt;
&#20923;&#32467;&#32593;&#32476;&#20013;&#30340;&#37096;&#20998;&#25628;&#32034;&#36275;&#20197;&#25214;&#21040;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;
&lt;/p&gt;
&lt;p&gt;
Partial Search in a Frozen Network is Enough to Find a Strong Lottery Ticket
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14029
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#20923;&#32467;&#38543;&#26426;&#23376;&#38598;&#30340;&#21021;&#22987;&#26435;&#37325;&#26469;&#20943;&#23569;&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLT&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#20174;&#32780;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#38477;&#20302;&#20102;SLT&#25628;&#32034;&#31354;&#38388;&#65292;&#20445;&#35777;&#20102;SLT&#22312;&#36825;&#31181;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#20013;&#30340;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14029v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#36328;&#36234; &#25688;&#35201;&#65306;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31264;&#23494;&#32593;&#32476;&#21253;&#21547;&#21487;&#20197;&#22312;&#19981;&#36827;&#34892;&#26435;&#37325;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#39640;&#20934;&#30830;&#24230;&#30340;&#23376;&#32593;&#32476;--&#24378;&#22823;&#30340;&#24425;&#31080;&#31080;&#35777;&#65288;SLTs&#65289;&#12290;&#26368;&#36817;&#65292;Gadhikar&#31561;&#20154;&#65288;2023&#24180;&#65289;&#22312;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;SLTs&#20063;&#21487;&#20197;&#22312;&#38543;&#26426;&#20462;&#21098;&#30340;&#28304;&#32593;&#32476;&#20013;&#25214;&#21040;&#65292;&#20174;&#32780;&#20943;&#23569;SLT&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#36825;&#38480;&#21046;&#20102;&#23545;&#29978;&#33267;&#27604;&#28304;&#32593;&#32476;&#26356;&#31232;&#30095;&#30340;SLTs&#30340;&#25628;&#32034;&#65292;&#23548;&#33268;&#30001;&#20110;&#24847;&#22806;&#30340;&#39640;&#31232;&#30095;&#24615;&#32780;&#20934;&#30830;&#24230;&#36739;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#29420;&#31435;&#20110;&#25152;&#38656;SLT&#31232;&#30095;&#24615;&#30340;&#20219;&#24847;&#27604;&#29575;&#20943;&#23569;SLT&#25628;&#32034;&#31354;&#38388;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20923;&#32467;&#19968;&#37096;&#20998;&#21021;&#22987;&#26435;&#37325;&#30340;&#38543;&#26426;&#23376;&#38598;&#65292;&#23558;&#20854;&#25490;&#38500;&#22312;&#25628;&#32034;&#31354;&#38388;&#20043;&#22806;--&#21363;&#65292;&#36890;&#36807;&#27704;&#20037;&#20462;&#21098;&#23427;&#20204;&#25110;&#23558;&#23427;&#20204;&#38145;&#23450;&#20026;SLT&#30340;&#22266;&#23450;&#37096;&#20998;&#12290;&#20107;&#23454;&#19978;&#65292;&#36890;&#36807;&#25105;&#20204;&#19982;&#38543;&#26426;&#20923;&#32467;&#21464;&#37327;&#30340;&#23376;&#38598;&#21644;&#36924;&#36817;&#65292;&#22312;&#36825;&#31181;&#20943;&#23569;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#65292;SLT&#30340;&#23384;&#22312;&#22312;&#29702;&#35770;&#19978;&#26159;&#24471;&#21040;&#20445;&#35777;&#30340;&#12290;&#38500;&#27492;&#20043;&#22806;&#65292;&#36824;&#21487;&#20197;&#20943;&#23569;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14029v1 Announce Type: cross  Abstract: Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning -- strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated theoretically and experimentally that SLTs can also be found within a randomly pruned source network, thus reducing the SLT search space. However, this limits the search to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method that reduces the SLT search space by an arbitrary ratio that is independent of the desired SLT sparsity. A random subset of the initial weights is excluded from the search space by freezing it -- i.e., by either permanently pruning them or locking them as a fixed part of the SLT. Indeed, the SLT existence in such a reduced search space is theoretically guaranteed by our subset-sum approximation with randomly frozen variables. In addition to reducin
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#35299;&#20915;&#20102;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#30340;&#39281;&#21644;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#21644;&#22823;&#35268;&#27169;&#28145;&#24230;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#38598;&#25104;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.13891</link><description>&lt;p&gt;
&#20811;&#26381;&#36845;&#20195;&#27491;&#21017;&#21270;&#20013;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#39281;&#21644;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Overcoming Saturation in Density Ratio Estimation by Iterated Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13891
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#35299;&#20915;&#20102;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#30340;&#39281;&#21644;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#21644;&#22823;&#35268;&#27169;&#28145;&#24230;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#38598;&#25104;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26377;&#38480;&#26679;&#26412;&#20013;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#30340;&#27604;&#29575;&#65292;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#22823;&#31867;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#26680;&#26041;&#27861;&#23384;&#22312;&#38169;&#35823;&#39281;&#21644;&#38382;&#39064;&#65292;&#36825;&#38459;&#30861;&#20102;&#31639;&#27861;&#22312;&#39640;&#24230;&#35268;&#21017;&#23398;&#20064;&#38382;&#39064;&#19978;&#23454;&#29616;&#24555;&#36895;&#38169;&#35823;&#25910;&#25947;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#39281;&#21644;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#20197;&#23454;&#29616;&#24555;&#36895;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#20197;&#21450;&#22823;&#35268;&#27169;&#35780;&#20272;&#28145;&#24230;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#38598;&#25104;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13891v1 Announce Type: new  Abstract: Estimating the ratio of two probability densities from finitely many samples, is a central task in machine learning and statistics. In this work, we show that a large class of kernel methods for density ratio estimation suffers from error saturation, which prevents algorithms from achieving fast error convergence rates on highly regular learning problems. To resolve saturation, we introduce iterated regularization in density ratio estimation to achieve fast error rates. Our methods outperform its non-iteratively regularized versions on benchmarks for density ratio estimation as well as on large-scale evaluations for importance-weighted ensembling of deep unsupervised domain adaptation models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#30340;&#27010;&#24565;&#20316;&#20026;&#23548;&#33268;&#31867;&#21035;&#24046;&#24322;&#30340;&#28508;&#22312;&#26469;&#28304;&#65292;&#24182;&#30740;&#31350;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#20559;&#35265;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20026;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#31867;&#21035;&#24046;&#24322;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#22312;&#22810;&#20010;&#39044;&#35757;&#32451;&#32534;&#30721;&#22120;&#20013;&#39564;&#35777;&#20102;&#36825;&#31181;&#32852;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.11742</link><description>&lt;p&gt;
&#24179;&#34913;&#25968;&#25454;&#65292;&#19981;&#24179;&#34913;&#20809;&#35889;&#65306;&#25581;&#31034;&#20855;&#26377;&#20809;&#35889;&#19981;&#24179;&#34913;&#30340;&#31867;&#21035;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Balanced Data, Imbalanced Spectra: Unveiling Class Disparities with Spectral Imbalance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11742
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#30340;&#27010;&#24565;&#20316;&#20026;&#23548;&#33268;&#31867;&#21035;&#24046;&#24322;&#30340;&#28508;&#22312;&#26469;&#28304;&#65292;&#24182;&#30740;&#31350;&#20102;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#20559;&#35265;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#20026;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#31867;&#21035;&#24046;&#24322;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#22312;&#22810;&#20010;&#39044;&#35757;&#32451;&#32534;&#30721;&#22120;&#20013;&#39564;&#35777;&#20102;&#36825;&#31181;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#27169;&#22411;&#34987;&#26399;&#26395;&#22312;&#19981;&#21516;&#31867;&#21035;&#19978;&#34920;&#29616;&#21516;&#26679;&#33391;&#22909;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#20204;&#30340;&#34920;&#29616;&#24448;&#24448;&#23384;&#22312;&#36739;&#22823;&#24046;&#36317;&#12290;&#36825;&#20010;&#31867;&#21035;&#20559;&#35265;&#38382;&#39064;&#22312;&#26679;&#26412;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#22312;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#30456;&#23545;&#34987;&#24573;&#35270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29305;&#24449;&#20013;&#30340;&#20809;&#35889;&#19981;&#24179;&#34913;&#27010;&#24565;&#20316;&#20026;&#31867;&#21035;&#24046;&#24322;&#30340;&#28508;&#22312;&#26469;&#28304;&#65292;&#24182;&#30740;&#31350;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#20559;&#35265;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#30340;&#32852;&#31995;&#12290;&#20026;&#20102;&#24314;&#31435;&#20809;&#35889;&#19981;&#24179;&#34913;&#19982;&#31867;&#21035;&#24046;&#36317;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#30740;&#31350;&#31867;&#21035;&#24046;&#24322;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25512;&#23548;&#20102;&#39640;&#32500;&#28151;&#21512;&#27169;&#22411;&#35774;&#23450;&#20013;&#27599;&#31867;&#38169;&#35823;&#30340;&#31934;&#30830;&#34920;&#36798;&#24335;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;11&#20010;&#19981;&#21516;&#30340;&#26368;&#20808;&#36827;&#30340;&#39044;&#35757;&#32451;&#32534;&#30721;&#22120;&#20013;&#30740;&#31350;&#20102;&#36825;&#19968;&#29616;&#35937;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#22914;&#20309;&#29992;&#20110;&#27604;&#36739;&#32534;&#30721;&#22120;&#30340;&#36136;&#37327;&#65292;&#20197;&#21450;&#35780;&#20272;&#21644;&#32452;&#21512;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11742v1 Announce Type: new  Abstract: Classification models are expected to perform equally well for different classes, yet in practice, there are often large gaps in their performance. This issue of class bias is widely studied in cases of datasets with sample imbalance, but is relatively overlooked in balanced datasets. In this work, we introduce the concept of spectral imbalance in features as a potential source for class disparities and study the connections between spectral imbalance and class bias in both theory and practice. To build the connection between spectral imbalance and class gap, we develop a theoretical framework for studying class disparities and derive exact expressions for the per-class error in a high-dimensional mixture model setting. We then study this phenomenon in 11 different state-of-the-art pretrained encoders and show how our proposed framework can be used to compare the quality of encoders, as well as evaluate and combine data augmentation stra
&lt;/p&gt;</description></item><item><title>&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#32570;&#20047;&#37096;&#20998;&#21453;&#39304;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#31574;&#30053;&#26469;&#30830;&#20445;&#25152;&#26377;&#23376;&#32676;&#20307;&#37117;&#34987;&#25506;&#32034;&#12289;&#38450;&#27490;&#38169;&#35823;&#20998;&#31867;&#12289;&#20197;&#21450;&#25910;&#25947;&#21040;&#26399;&#26395;&#30340;&#20998;&#31867;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.11338</link><description>&lt;p&gt;
&#20855;&#26377;&#37096;&#20998;&#21453;&#39304;&#30340;&#20844;&#24179;&#20998;&#31867;&#65306;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fair Classification with Partial Feedback: An Exploration-Based Data-Collection Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25506;&#32034;&#30340;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#32570;&#20047;&#37096;&#20998;&#21453;&#39304;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#31574;&#30053;&#26469;&#30830;&#20445;&#25152;&#26377;&#23376;&#32676;&#20307;&#37117;&#34987;&#25506;&#32034;&#12289;&#38450;&#27490;&#38169;&#35823;&#20998;&#31867;&#12289;&#20197;&#21450;&#25910;&#25947;&#21040;&#26399;&#26395;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39044;&#27979;&#22330;&#26223;&#65288;&#20363;&#22914;&#20449;&#36151;&#25918;&#27454;&#65289;&#20013;&#65292;&#21482;&#26377;&#36807;&#21435;&#34987;&#31215;&#26497;&#20998;&#31867;&#30340;&#26679;&#26412;&#25165;&#20250;&#35266;&#23519;&#21040;&#30495;&#23454;&#32467;&#26524;&#12290;&#36825;&#20123;&#36807;&#21435;&#30340;&#35266;&#23519;&#32467;&#26524;&#24418;&#25104;&#20102;&#29992;&#20110;&#35757;&#32451;&#20998;&#31867;&#22120;&#20197;&#36827;&#34892;&#26410;&#26469;&#39044;&#27979;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#32570;&#20047;&#20851;&#20110;&#36807;&#21435;&#65288;&#38169;&#35823;&#22320;&#65289;&#34987;&#36127;&#38754;&#20998;&#31867;&#30340;&#26679;&#26412;&#32467;&#26524;&#30340;&#20449;&#24687;&#65292;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21033;&#29992;&#21487;&#29992;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#24182;&#25552;&#20379;&#19968;&#31995;&#21015;&#25506;&#32034;&#31574;&#30053;&#26469;&#25910;&#38598;&#20851;&#20110;&#21542;&#21017;&#20250;&#34987;&#24573;&#30053;&#30340;&#23376;&#32676;&#20307;&#30340;&#32467;&#26524;&#25968;&#25454;&#12290;&#23545;&#20110;&#20219;&#20309;&#25506;&#32034;&#31574;&#30053;&#65292;&#35813;&#26041;&#27861;&#37117;&#20855;&#26377;&#20197;&#19979;&#20445;&#35777;&#65306;&#65288;1&#65289;&#25152;&#26377;&#23376;&#32676;&#20307;&#37117;&#24471;&#21040;&#20102;&#25506;&#32034;&#65292;&#65288;2&#65289;&#20551;&#38451;&#24615;&#30340;&#27604;&#20363;&#21463;&#21040;&#20102;&#38480;&#21046;&#65292;&#65288;3&#65289;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#25910;&#25947;&#21040;&#19968;&#20010;&#8220;&#26399;&#26395;&#8221;&#30340;&#20998;&#31867;&#22120;&#12290;&#27491;&#30830;&#30340;&#25506;&#32034;&#31574;&#30053;&#21462;&#20915;&#20110;&#19978;&#19979;&#25991;&#65307;&#23427;&#21487;&#20197;&#36873;&#25321;&#20197;&#25913;&#21892;&#23398;&#20064;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11338v1 Announce Type: cross  Abstract: In many predictive contexts (e.g., credit lending), true outcomes are only observed for samples that were positively classified in the past. These past observations, in turn, form training datasets for classifiers that make future predictions. However, such training datasets lack information about the outcomes of samples that were (incorrectly) negatively classified in the past and can lead to erroneous classifiers. We present an approach that trains a classifier using available data and comes with a family of exploration strategies to collect outcome data about subpopulations that otherwise would have been ignored. For any exploration strategy, the approach comes with guarantees that (1) all sub-populations are explored, (2) the fraction of false positives is bounded, and (3) the trained classifier converges to a "desired" classifier. The right exploration strategy is context-dependent; it can be chosen to improve learning guarantees 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23616;&#38480;&#24615;&#65292;&#21457;&#29616;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#27867;&#21270;&#33021;&#21147;&#19981;&#36275;&#30340;&#21407;&#22240;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;SAMformer&#65292;&#36890;&#36807;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#36991;&#20813;&#20102;&#38519;&#20837;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#24182;&#22312;&#24120;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#12290;</title><link>https://arxiv.org/abs/2402.10198</link><description>&lt;p&gt;
&#20351;&#29992;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#36890;&#36947;&#27880;&#24847;&#21147;&#35299;&#38145;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#22312;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#23616;&#38480;&#24615;&#65292;&#21457;&#29616;&#20854;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#27867;&#21270;&#33021;&#21147;&#19981;&#36275;&#30340;&#21407;&#22240;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;SAMformer&#65292;&#36890;&#36807;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#36991;&#20813;&#20102;&#38519;&#20837;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#65292;&#24182;&#22312;&#24120;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#36229;&#36807;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#26550;&#26500;&#22312;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21462;&#24471;&#20102;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#22810;&#20803;&#38271;&#26399;&#39044;&#27979;&#26041;&#38754;&#65292;&#23427;&#20204;&#20173;&#28982;&#19981;&#22914;&#26356;&#31616;&#21333;&#30340;&#32447;&#24615;&#22522;&#32447;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#19968;&#20010;&#29609;&#20855;&#32447;&#24615;&#39044;&#27979;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#23613;&#31649;Transformer&#20855;&#26377;&#39640;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#25910;&#25947;&#21040;&#30495;&#27491;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;Transformer&#30340;&#27880;&#24847;&#21147;&#26159;&#36896;&#25104;&#20854;&#20302;&#27867;&#21270;&#33021;&#21147;&#30340;&#21407;&#22240;&#12290;&#22522;&#20110;&#36825;&#19968;&#35748;&#35782;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27973;&#23618;&#36731;&#37327;&#32423;&#30340;Transformer&#27169;&#22411;&#65292;&#22312;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#25104;&#21151;&#36991;&#20813;&#20102;&#22351;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20010;&#32467;&#26524;&#36866;&#29992;&#20110;&#25152;&#26377;&#24120;&#29992;&#30340;&#23454;&#38469;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;&#29305;&#21035;&#26159;&#65292;&#30456;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;TSMixer&#65292;SAMformer&#30340;&#24179;&#22343;&#24615;&#33021;&#25552;&#39640;&#20102;14.33%&#65292;&#24182;&#19988;&#21442;&#25968;&#25968;&#37327;&#20943;&#23569;&#20102;&#32422;4&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10198v1 Announce Type: new  Abstract: Transformer-based architectures achieved breakthrough performance in natural language processing and computer vision, yet they remain inferior to simpler linear baselines in multivariate long-term forecasting. To better understand this phenomenon, we start by studying a toy linear forecasting problem for which we show that transformers are incapable of converging to their true solution despite their high expressive power. We further identify the attention of transformers as being responsible for this low generalization capacity. Building upon this insight, we propose a shallow lightweight transformer model that successfully escapes bad local minima when optimized with sharpness-aware optimization. We empirically demonstrate that this result extends to all commonly used real-world multivariate time series datasets. In particular, SAMformer surpasses the current state-of-the-art model TSMixer by 14.33% on average, while having ~4 times few
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31574;&#30053;&#26799;&#24230;&#22312;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#25511;&#21046;&#20013;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#38382;&#39064;&#65292;&#21457;&#29616;&#22806;&#25512;&#31243;&#24230;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#31995;&#32479;&#30340;&#25506;&#32034;&#31243;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.07875</link><description>&lt;p&gt;
&#32447;&#24615;&#20108;&#27425;&#25511;&#21046;&#20013;&#31574;&#30053;&#26799;&#24230;&#30340;&#38544;&#24615;&#20559;&#24046;&#65306;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31574;&#30053;&#26799;&#24230;&#22312;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#25511;&#21046;&#20013;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#38382;&#39064;&#65292;&#21457;&#29616;&#22806;&#25512;&#31243;&#24230;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#31995;&#32479;&#30340;&#25506;&#32034;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#21487;&#20197;&#20197;&#22810;&#31181;&#26041;&#24335;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#65292;&#20854;&#20013;&#19968;&#20123;&#22312;&#26410;&#35265;&#65288;&#27979;&#35797;&#65289;&#25968;&#25454;&#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#32780;&#20854;&#20182;&#19968;&#20123;&#21017;&#19981;&#28982;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#32463;&#24120;&#23637;&#29616;&#20986;&#19968;&#31181;&#38544;&#24615;&#20559;&#24046;&#65292;&#23548;&#33268;&#22312;&#26410;&#35265;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;&#36825;&#31181;&#38544;&#24615;&#20559;&#24046;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#22312;&#26368;&#20248;&#25511;&#21046;&#65288;&#24378;&#21270;&#23398;&#20064;&#65289;&#20013;&#21364;&#20102;&#35299;&#24471;&#36739;&#23569;&#12290;&#22312;&#37027;&#37324;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#24212;&#29992;&#20110;&#31995;&#32479;&#30340;&#25511;&#21046;&#22120;&#34987;&#31216;&#20026;&#31574;&#30053;&#26799;&#24230;&#65292;&#24182;&#19988;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#23398;&#20064;&#30340;&#25511;&#21046;&#22120;&#22312;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#31243;&#24230;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#31574;&#30053;&#26799;&#24230;&#22312;&#23545;&#26410;&#35265;&#21021;&#22987;&#29366;&#24577;&#30340;&#22806;&#25512;&#26041;&#38754;&#30340;&#38544;&#24615;&#20559;&#24046;&#12290;&#25105;&#20204;&#20197;&#22522;&#26412;&#30340;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#65288;LQR&#65289;&#38382;&#39064;&#20026;&#37325;&#28857;&#65292;&#30830;&#31435;&#20102;&#22806;&#25512;&#31243;&#24230;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#31995;&#32479;&#22312;&#21021;&#22987;&#29366;&#24577;&#19979;&#24341;&#36215;&#30340;&#25506;&#32034;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In modern machine learning, models can often fit training data in numerous ways, some of which perform well on unseen (test) data, while others do not. Remarkably, in such cases gradient descent frequently exhibits an implicit bias that leads to excellent performance on unseen data. This implicit bias was extensively studied in supervised learning, but is far less understood in optimal control (reinforcement learning). There, learning a controller applied to a system via gradient descent is known as policy gradient, and a question of prime importance is the extent to which a learned controller extrapolates to unseen initial states. This paper theoretically studies the implicit bias of policy gradient in terms of extrapolation to unseen initial states. Focusing on the fundamental Linear Quadratic Regulator (LQR) problem, we establish that the extent of extrapolation depends on the degree of exploration induced by the system when commencing from initial states included in training. Exper
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;</title><link>https://arxiv.org/abs/2402.07723</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#37325;&#23614;SDEs&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization Bounds for Heavy-Tailed SDEs through the Fractional Fokker-Planck Equation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07723
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#19988;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#65292;&#30028;&#38480;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#20960;&#24180;&#26469;&#65292;&#29702;&#35299;&#37325;&#23614;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#21033;&#29992;&#37325;&#23614;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20316;&#20026;&#20195;&#29702;&#26469;&#38416;&#26126;&#38543;&#26426;&#20248;&#21270;&#22120;&#30340;&#26377;&#36259;&#26041;&#38754;&#26102;&#65292;&#20808;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#25552;&#20379;&#39044;&#26399;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#35201;&#20040;&#24341;&#20837;&#20102;&#19981;&#21487;&#35745;&#31639;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#32570;&#28857;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#37325;&#23614;SDE&#30340;&#39640;&#27010;&#29575;&#27867;&#21270;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#19981;&#21547;&#20219;&#20309;&#38750;&#24179;&#20961;&#30340;&#20449;&#24687;&#35770;&#26415;&#35821;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22522;&#20110;&#20272;&#35745;&#19982;&#25152;&#35859;&#30340;&#20998;&#25968;&#38459;&#23612;&#24211;&#20177;&#26041;&#31243;&#30456;&#20851;&#32852;&#30340;&#29109;&#27969;&#65292;&#24320;&#21457;&#20102;&#26032;&#30340;&#35777;&#26126;&#25216;&#26415;&#65288;&#36825;&#26159;&#19968;&#31181;&#25511;&#21046;&#30456;&#24212;&#37325;&#23614;SDE&#20998;&#24067;&#28436;&#21270;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#65289;&#12290;&#38500;&#20102;&#33719;&#24471;&#39640;&#27010;&#29575;&#30028;&#38480;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#30028;&#38480;&#30456;&#23545;&#20110;&#21442;&#25968;&#32500;&#24230;&#30340;&#20381;&#36182;&#24615;&#35201;&#22909;&#20110;p&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the generalization properties of heavy-tailed stochastic optimization algorithms has attracted increasing attention over the past years. While illuminating interesting aspects of stochastic optimizers by using heavy-tailed stochastic differential equations as proxies, prior works either provided expected generalization bounds, or introduced non-computable information theoretic terms. Addressing these drawbacks, in this work, we prove high-probability generalization bounds for heavy-tailed SDEs which do not contain any nontrivial information theoretic terms. To achieve this goal, we develop new proof techniques based on estimating the entropy flows associated with the so-called fractional Fokker-Planck equation (a partial differential equation that governs the evolution of the distribution of the corresponding heavy-tailed SDE). In addition to obtaining high-probability bounds, we show that our bounds have a better dependence on the dimension of parameters as compared to p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.07588</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Rethinking Scaling Laws for Learning in Strategic Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#37096;&#32626;&#21453;&#26144;&#20986;&#19968;&#20010;&#20849;&#35782;&#65306;&#27169;&#22411;&#36234;&#26377;&#34920;&#36798;&#33021;&#21147;&#65292;&#36234;&#25317;&#26377;&#22823;&#37327;&#25968;&#25454;&#65292;&#23601;&#33021;&#25913;&#21892;&#24615;&#33021;&#12290;&#38543;&#30528;&#27169;&#22411;&#22312;&#21508;&#31181;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#37096;&#32626;&#65292;&#23427;&#20204;&#19981;&#21487;&#36991;&#20813;&#22320;&#38754;&#20020;&#30528;&#25112;&#30053;&#29615;&#22659;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#27169;&#22411;&#19982;&#25112;&#30053;&#20114;&#21160;&#23545;&#27604;&#20363;&#23450;&#24459;&#30340;&#30456;&#20114;&#20316;&#29992;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36825;&#20010;&#33258;&#28982;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#27604;&#20363;&#23450;&#24459;&#35266;&#28857;&#65292;&#21363;&#24615;&#33021;&#24182;&#19981;&#19968;&#23450;&#38543;&#30528;&#27169;&#22411;&#30340;&#25193;&#22823;&#21644;/&#25110;&#34920;&#36798;&#33021;&#21147;&#30340;&#22686;&#24378;&#65288;&#21363;&#20351;&#26377;&#26080;&#38480;&#25968;&#25454;&#65289;&#32780;&#21333;&#35843;&#25552;&#39640;&#12290;&#25105;&#20204;&#36890;&#36807;&#25112;&#30053;&#22238;&#24402;&#12289;&#25112;&#30053;&#20998;&#31867;&#21644;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#20363;&#23376;&#23637;&#31034;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#20363;&#23376;&#23637;&#31034;&#20102;&#25112;&#30053;&#29615;&#22659;&#20013;&#30340;&#38480;&#21046;&#27169;&#22411;&#25110;&#31574;&#30053;&#31867;&#30340;&#34920;&#36798;&#33021;&#21147;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects scaling laws. We find that strategic interactions can break the conventional view of scaling laws$\unicode{x2013}$meaning that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning through examples of strategic environments in which$\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\uni
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#36827;&#34892;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#22122;&#22768;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#38544;&#24615;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#23545;&#31216;&#24615;&#20250;&#23548;&#33268;&#19981;&#21516;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#20854;&#20013;&#19968;&#31867;&#23545;&#31216;&#24615;&#21487;&#20197;&#33258;&#28982;&#25910;&#25947;&#65292;&#32780;&#21478;&#19968;&#31867;&#23545;&#31216;&#24615;&#20960;&#20046;&#24635;&#26159;&#21457;&#25955;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#36866;&#29992;&#20110;&#27809;&#26377;&#23545;&#31216;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20110;&#29702;&#35299;&#35757;&#32451;&#21160;&#24577;&#21644;&#35299;&#37322;&#30456;&#20851;&#23454;&#38469;&#38382;&#39064;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.07193</link><description>&lt;p&gt;
&#26799;&#24230;&#22122;&#22768;&#30340;&#38544;&#24615;&#20559;&#35265;&#65306;&#20174;&#23545;&#31216;&#24615;&#35282;&#24230;&#26469;&#30475;
&lt;/p&gt;
&lt;p&gt;
The Implicit Bias of Gradient Noise: A Symmetry Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07193
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23545;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#36827;&#34892;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#26799;&#24230;&#22122;&#22768;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#38544;&#24615;&#20559;&#35265;&#12290;&#25105;&#20204;&#21457;&#29616;&#19981;&#21516;&#31867;&#22411;&#30340;&#23545;&#31216;&#24615;&#20250;&#23548;&#33268;&#19981;&#21516;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#20854;&#20013;&#19968;&#31867;&#23545;&#31216;&#24615;&#21487;&#20197;&#33258;&#28982;&#25910;&#25947;&#65292;&#32780;&#21478;&#19968;&#31867;&#23545;&#31216;&#24615;&#20960;&#20046;&#24635;&#26159;&#21457;&#25955;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#36866;&#29992;&#20110;&#27809;&#26377;&#23545;&#31216;&#24615;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20110;&#29702;&#35299;&#35757;&#32451;&#21160;&#24577;&#21644;&#35299;&#37322;&#30456;&#20851;&#23454;&#38469;&#38382;&#39064;&#20855;&#26377;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#25439;&#22833;&#20989;&#25968;&#23384;&#22312;&#36830;&#32493;&#23545;&#31216;&#24615;&#26102;&#30340;&#23398;&#20064;&#21160;&#24577;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#35828;&#26126;&#20102;SGD&#21644;&#26799;&#24230;&#19979;&#38477;&#20043;&#38388;&#30340;&#20998;&#27495;&#26159;&#22810;&#20040;&#24040;&#22823;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26681;&#25454;&#23545;&#31216;&#24615;&#23545;&#23398;&#20064;&#21160;&#24577;&#30340;&#24433;&#21709;&#26041;&#24335;&#65292;&#25105;&#20204;&#21487;&#20197;&#23558;&#19968;&#26063;&#23545;&#31216;&#24615;&#20998;&#20026;&#20004;&#31867;&#12290;&#23545;&#20110;&#19968;&#31867;&#23545;&#31216;&#24615;&#65292;SGD&#33258;&#28982;&#22320;&#25910;&#25947;&#21040;&#20855;&#26377;&#24179;&#34913;&#21644;&#23545;&#40784;&#26799;&#24230;&#22122;&#22768;&#30340;&#35299;&#12290;&#23545;&#20110;&#21478;&#19968;&#31867;&#23545;&#31216;&#24615;&#65292;SGD&#20960;&#20046;&#24635;&#26159;&#21457;&#25955;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#20013;&#27809;&#26377;&#23545;&#31216;&#24615;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20381;&#28982;&#36866;&#29992;&#24182;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#29702;&#35299;&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#26222;&#36941;&#30340;&#65292;&#23427;&#21482;&#20381;&#36182;&#20110;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#65292;&#32780;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#32454;&#33410;&#26080;&#20851;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#29702;&#35770;&#23545;&#20110;&#36880;&#27493;&#21464;&#24418;&#21644;&#24179;&#22374;&#21270;&#25552;&#20379;&#20102;&#35299;&#37322;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#24120;&#35265;&#30340;&#23454;&#38469;&#38382;&#39064;&#65292;&#22914;&#34920;&#31034;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize the learning dynamics of stochastic gradient descent (SGD) when continuous symmetry exists in the loss function, where the divergence between SGD and gradient descent is dramatic. We show that depending on how the symmetry affects the learning dynamics, we can divide a family of symmetry into two classes. For one class of symmetry, SGD naturally converges to solutions that have a balanced and aligned gradient noise. For the other class of symmetry, SGD will almost always diverge. Then, we show that our result remains applicable and can help us understand the training dynamics even when the symmetry is not present in the loss function. Our main result is universal in the sense that it only depends on the existence of the symmetry and is independent of the details of the loss function. We demonstrate that the proposed theory offers an explanation of progressive sharpening and flattening and can be applied to common practical problems such as representation normalization, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#38382;&#39064;&#65292;&#36825;&#26159;&#39318;&#20010;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.06886</link><description>&lt;p&gt;
Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#30340;&#26377;&#21407;&#21017;&#30340;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24809;&#32602;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;Bilevel&#24378;&#21270;&#23398;&#20064;&#21644;RLHF&#38382;&#39064;&#65292;&#36825;&#26159;&#39318;&#20010;&#26377;&#21407;&#21017;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Bilevel&#20248;&#21270;&#24050;&#34987;&#24212;&#29992;&#20110;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24212;&#29992;&#20165;&#38480;&#20110;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#20855;&#26377;&#33391;&#24615;&#32467;&#26500;&#30340;&#38745;&#24577;&#30446;&#26631;&#20989;&#25968;&#12290;&#20294;&#26159;&#65292;&#28608;&#21169;&#35774;&#35745;&#12289;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;(RL)&#21644;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;RLHF&#31561;Bilevel&#38382;&#39064;&#36890;&#24120;&#34987;&#24314;&#27169;&#20026;&#36229;&#36234;&#31616;&#21333;&#38745;&#24577;&#30446;&#26631;&#32467;&#26500;&#30340;&#21160;&#24577;&#30446;&#26631;&#20989;&#25968;&#65292;&#36825;&#32473;&#20351;&#29992;&#29616;&#26377;Bilevel&#35299;&#20915;&#26041;&#26696;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#26032;&#30340;Bilevel&#38382;&#39064;&#31867;&#21035;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#24418;&#24335;&#24341;&#20837;&#20102;&#35299;&#20915;Bilevel RL&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#21407;&#21017;&#24615;&#31639;&#27861;&#26694;&#26550;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#30740;&#31350;&#38382;&#39064;&#30340;&#26223;&#35266;&#21450;&#20854;&#22522;&#20110;&#24809;&#32602;&#30340;&#65288;&#31574;&#30053;&#65289;&#26799;&#24230;&#31639;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;Stackelberg&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#12289;&#26469;&#33258;&#20154;&#31867;&#21453;&#39304;&#30340;RL&#21644;&#28608;&#21169;&#35774;&#35745;&#20013;&#36827;&#34892;&#27169;&#25311;&#26469;&#35777;&#26126;&#25105;&#20204;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization has been recently applied to many machine learning tasks. However, their applications have been restricted to the supervised learning setting, where static objective functions with benign structures are considered. But bilevel problems such as incentive design, inverse reinforcement learning (RL), and RL from human feedback (RLHF) are often modeled as dynamic objective functions that go beyond the simple static objective structures, which pose significant challenges of using existing bilevel solutions. To tackle this new class of bilevel problems, we introduce the first principled algorithmic framework for solving bilevel RL problems through the lens of penalty formulation. We provide theoretical studies of the problem landscape and its penalty-based (policy) gradient algorithms. We demonstrate the effectiveness of our algorithms via simulations in the Stackelberg Markov game, RL from human feedback and incentive design.
&lt;/p&gt;</description></item><item><title>SMC&#24182;&#34892;&#25193;&#23637;&#26041;&#27861;pSMC&#20855;&#26377;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#20855;&#26377;&#26377;&#30028;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#35201;&#27714;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06173</link><description>&lt;p&gt;
SMC&#23601;&#26159;&#20320;&#38656;&#35201;&#30340;&#65306;&#24182;&#34892;&#24378;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
SMC Is All You Need: Parallel Strong Scaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06173
&lt;/p&gt;
&lt;p&gt;
SMC&#24182;&#34892;&#25193;&#23637;&#26041;&#27861;pSMC&#20855;&#26377;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#20855;&#26377;&#26377;&#30028;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#21644;&#20869;&#23384;&#35201;&#27714;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#19968;&#33324;&#26694;&#26550;&#20013;&#65292;&#30446;&#26631;&#20998;&#24067;&#21482;&#33021;&#25353;&#27604;&#20363;&#24120;&#25968;&#36827;&#34892;&#35780;&#20272;&#12290;&#20256;&#32479;&#30340;&#19968;&#33268;Bayesian&#26041;&#27861;&#65292;&#22914;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;(SMC)&#21644;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;(MCMC)&#65292;&#20855;&#26377;&#26080;&#30028;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#35201;&#27714;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#24182;&#34892;&#30340;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;(pSMC)&#26041;&#27861;&#65292;&#21487;&#20197;&#35777;&#26126;&#23427;&#20855;&#26377;&#24182;&#34892;&#24378;&#25193;&#23637;&#24615;&#65292;&#21363;&#22914;&#26524;&#20801;&#35768;&#24322;&#27493;&#36827;&#31243;&#25968;&#37327;&#22686;&#38271;&#65292;&#26102;&#38388;&#22797;&#26434;&#24615;(&#21644;&#27599;&#20010;&#33410;&#28857;&#30340;&#20869;&#23384;)&#20173;&#28982;&#20445;&#25345;&#26377;&#30028;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;pSMC&#20855;&#26377;MSE$=O(1/NR)$&#30340;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$N$&#34920;&#31034;&#27599;&#20010;&#22788;&#29702;&#22120;&#20013;&#30340;&#36890;&#20449;&#26679;&#26412;&#25968;&#37327;&#65292;$R$&#34920;&#31034;&#22788;&#29702;&#22120;&#25968;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#36866;&#24403;&#22823;&#30340;&#38382;&#39064;&#30456;&#20851;$N$&#65292;&#24403;$R\rightarrow \infty$&#26102;&#65292;&#35813;&#26041;&#27861;&#20197;&#22266;&#23450;&#26377;&#38480;&#30340;&#26102;&#38388;&#22797;&#26434;&#24615;Cost$=O(1)$&#25910;&#25947;&#21040;&#26080;&#31351;&#23567;&#31934;&#24230;MSE$=O(\varepsilon^2)$&#65292;&#27809;&#26377;&#25928;&#29575;&#27844;&#28431;&#65292;&#21363;&#35745;&#31639;&#22797;&#26434;&#24615;Cost$=O(\varepsilon)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the general framework of Bayesian inference, the target distribution can only be evaluated up-to a constant of proportionality. Classical consistent Bayesian methods such as sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC) have unbounded time complexity requirements. We develop a fully parallel sequential Monte Carlo (pSMC) method which provably delivers parallel strong scaling, i.e. the time complexity (and per-node memory) remains bounded if the number of asynchronous processes is allowed to grow. More precisely, the pSMC has a theoretical convergence rate of MSE$ = O(1/NR)$, where $N$ denotes the number of communicating samples in each processor and $R$ denotes the number of processors. In particular, for suitably-large problem-dependent $N$, as $R \rightarrow \infty$ the method converges to infinitesimal accuracy MSE$=O(\varepsilon^2)$ with a fixed finite time-complexity Cost$=O(1)$ and with no efficiency leakage, i.e. computational complexity Cost$=O(\varepsilon
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEAK&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#30340;&#26816;&#39564;&#12290;PEAK&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.06122</link><description>&lt;p&gt;
&#20351;&#29992;PEAK&#36827;&#34892;&#31397;&#25506;&#65306;&#22810;&#20010;&#25968;&#25454;&#27969;&#22343;&#20540;&#30340;&#39034;&#24207;&#12289;&#38750;&#21442;&#25968;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Peeking with PEAK: Sequential, Nonparametric Composite Hypothesis Tests for Means of Multiple Data Streams
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06122
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PEAK&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#30340;&#26816;&#39564;&#12290;PEAK&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#39034;&#24207;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#22343;&#20540;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21517;&#20026;PEAK&#65288;&#22522;&#20110;&#26399;&#26395;&#24179;&#22343;&#36164;&#20135;&#30340;&#31397;&#25506;&#65289;&#65292;&#22522;&#20110;&#27979;&#35797;&#21363;&#21338;&#24328;&#30340;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#22312;&#20219;&#20309;&#20572;&#27490;&#26102;&#38388;&#19978;&#30340;&#38750;&#28176;&#36827;&#945;&#27700;&#24179;&#27979;&#35797;&#12290;PEAK&#22312;&#35745;&#31639;&#19978;&#21487;&#34892;&#65292;&#24182;&#19988;&#33021;&#22815;&#26377;&#25928;&#25298;&#32477;&#22312;&#28385;&#36275;&#25105;&#20204;&#30340;&#38750;&#21442;&#25968;&#20551;&#35774;&#26465;&#20214;&#30340;&#25152;&#26377;&#28508;&#22312;&#20998;&#24067;&#20013;&#38169;&#35823;&#30340;&#20551;&#35774;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#22810;&#20010;&#25968;&#25454;&#27969;&#30340;&#32852;&#21512;&#22797;&#21512;&#20551;&#35774;&#26816;&#39564;&#12290;&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#21644;&#38408;&#20540;&#35782;&#21035;&#20219;&#21153;&#20013;&#23545;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel nonparametric sequential test for composite hypotheses for means of multiple data streams. Our proposed method, \emph{peeking with expectation-based averaged capital} (PEAK), builds upon the testing-as-betting framework and provides a non-asymptotic $\alpha$-level test across any stopping time. PEAK is computationally tractable and efficiently rejects hypotheses that are incorrect across all potential distributions that satisfy our nonparametric assumption, enabling joint composite hypothesis testing on multiple streams of data. We numerically validate our theoretical findings under the best arm identification and threshold identification in the bandit setting, illustrating the computational efficiency of our method against state-of-the-art testing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#37096;&#20998;&#22522;&#20110;&#27169;&#22411;&#30340;Eluder&#32500;&#24230;&#65288;P-MBED&#65289;&#27010;&#24565;&#26469;&#34913;&#37327;&#27169;&#22411;&#31867;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#35777;&#26126;&#22312;&#22522;&#26412;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#24179;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#24182;&#19981;&#27604;&#35299;&#20915;&#23545;&#25968;&#20010;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#26356;&#20855;&#32479;&#35745;&#25361;&#25112;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.05724</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#24182;&#19981;&#27604;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26356;&#21152;&#22256;&#38590;
&lt;/p&gt;
&lt;p&gt;
Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#37096;&#20998;&#22522;&#20110;&#27169;&#22411;&#30340;Eluder&#32500;&#24230;&#65288;P-MBED&#65289;&#27010;&#24565;&#26469;&#34913;&#37327;&#27169;&#22411;&#31867;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#35777;&#26126;&#22312;&#22522;&#26412;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#24179;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#24182;&#19981;&#27604;&#35299;&#20915;&#23545;&#25968;&#20010;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#26356;&#20855;&#32479;&#35745;&#25361;&#25112;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24179;&#22343;&#22330;&#21338;&#24328;&#20013;&#22522;&#20110;&#27169;&#22411;&#30340;&#20989;&#25968;&#36924;&#36817;&#19979;&#24378;&#21270;&#23398;&#20064;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#35813;&#26041;&#27861;&#38656;&#35201;&#31574;&#30053;&#24615;&#25506;&#32034;&#20197;&#25214;&#21040;&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#37096;&#20998;&#22522;&#20110;&#27169;&#22411;&#30340;Eluder&#32500;&#24230;&#65288;P-MBED&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#27010;&#24565;&#26469;&#25551;&#36848;&#27169;&#22411;&#31867;&#22797;&#26434;&#24230;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;P-MBED&#21487;&#20197;&#34913;&#37327;&#20174;&#32473;&#23450;&#30340;&#24179;&#22343;&#22330;&#27169;&#22411;&#31867;&#36716;&#25442;&#32780;&#26469;&#30340;&#21333;&#20010;&#26234;&#33021;&#20307;&#27169;&#22411;&#31867;&#30340;&#22797;&#26434;&#24230;&#65292;&#24182;&#19988;&#28508;&#22312;&#19978;&#21487;&#33021;&#27604;\citet{huang2023statistical}&#25552;&#20986;&#30340;MBED&#25351;&#25968;&#32423;&#20302;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#65292;&#20855;&#26377;&#26032;&#39062;&#30340;&#25506;&#32034;&#31574;&#30053;&#65292;&#24182;&#24314;&#31435;&#20102;&#19982;P-MBED&#30456;&#20851;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#32467;&#26524;&#65292;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22522;&#26412;&#21487;&#23454;&#29616;&#24615;&#21644;Lipschitz&#36830;&#32493;&#24615;&#20551;&#35774;&#19979;&#65292;&#23398;&#20064;&#24179;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#24182;&#19981;&#27604;&#35299;&#20915;&#23545;&#25968;&#20010;&#21333;&#20010;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#26356;&#20855;&#32479;&#35745;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#22810;&#31867;&#22411;&#24179;&#22343;&#22330;&#21338;&#24328;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the sample complexity of reinforcement learning (RL) in Mean-Field Games (MFGs) with model-based function approximation that requires strategic exploration to find a Nash Equilibrium policy. We introduce the Partial Model-Based Eluder Dimension (P-MBED), a more effective notion to characterize the model class complexity. Notably, P-MBED measures the complexity of the single-agent model class converted from the given mean-field model class, and potentially, can be exponentially lower than the MBED proposed by \citet{huang2023statistical}. We contribute a model elimination algorithm featuring a novel exploration strategy and establish sample complexity results polynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basic realizability and Lipschitz continuity assumptions, \emph{learning Nash Equilibrium in MFGs is no more statistically challenging than solving a logarithmic number of single-agent RL problems}. We further extend our results to Multi-Type MFGs, gen
&lt;/p&gt;</description></item><item><title>Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#30001;Stein Variational Gradient Descent&#31639;&#27861;&#23454;&#29616;&#65292;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#27604;&#36739;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#23588;&#20854;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;</title><link>https://arxiv.org/abs/2402.04689</link><description>&lt;p&gt;
Stein Boltzmann&#25277;&#26679;&#65306;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stein Boltzmann Sampling: A Variational Approach for Global Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04689
&lt;/p&gt;
&lt;p&gt;
Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#26159;&#19968;&#31181;&#20840;&#23616;&#20248;&#21270;&#30340;&#21464;&#20998;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#30001;Stein Variational Gradient Descent&#31639;&#27861;&#23454;&#29616;&#65292;&#20855;&#26377;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#27604;&#36739;&#20102;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#65292;&#23588;&#20854;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#33021;&#22815;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24182;&#26377;&#25928;&#21033;&#29992;&#39044;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27969;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;Lipschitz&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#65292;&#31216;&#20026;Stein Boltzmann&#25277;&#26679;&#65288;SBS&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20174;Boltzmann&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#35813;&#20998;&#24067;&#22312;&#20248;&#21270;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#38598;&#21512;&#19978;&#28176;&#36817;&#22343;&#21248;&#12290;&#20505;&#36873;&#35299;&#36890;&#36807;Stein Variational Gradient Descent&#31639;&#27861;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#24341;&#20837;&#20102;&#20004;&#31181;SBS&#21464;&#20307;&#65292;&#24182;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#19982;&#20960;&#31181;&#26368;&#20808;&#36827;&#30340;&#20840;&#23616;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#27604;&#36739;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#35774;&#35745;&#12289;&#29702;&#35770;&#32467;&#26524;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;SBS&#29305;&#21035;&#36866;&#21512;&#20316;&#20026;&#39640;&#25928;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#30340;&#24310;&#32493;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#22312;&#24456;&#22909;&#22320;&#21033;&#29992;&#39044;&#31639;&#30340;&#21516;&#26102;&#20135;&#29983;&#26356;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a new flow-based method for global optimization of Lipschitz functions, called Stein Boltzmann Sampling (SBS). Our method samples from the Boltzmann distribution that becomes asymptotically uniform over the set of the minimizers of the function to be optimized. Candidate solutions are sampled via the \emph{Stein Variational Gradient Descent} algorithm. We prove the asymptotic convergence of our method, introduce two SBS variants, and provide a detailed comparison with several state-of-the-art global optimization algorithms on various benchmark functions. The design of our method, the theoretical results, and our experiments, suggest that SBS is particularly well-suited to be used as a continuation of efficient global optimization methods as it can produce better solutions while making a good use of the budget.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35745;&#31639;&#38480;&#21046;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#33539;&#25968;&#30340;&#30456;&#21464;&#34892;&#20026;&#65292;&#24182;&#19988;&#24314;&#31435;&#20102;&#26377;&#25928;&#21464;&#20307;&#30340;&#19978;&#30028;&#26465;&#20214;&#12290;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#26500;&#36896;&#30340;&#31034;&#20363;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#35745;&#31639;&#26102;&#38388;&#19979;&#30028;&#12289;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;</title><link>https://arxiv.org/abs/2402.04520</link><description>&lt;p&gt;
&#20851;&#20110;&#29616;&#20195;Hopfield&#27169;&#22411;&#35745;&#31639;&#38480;&#21046;&#30340;&#19968;&#20010;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04520
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#35745;&#31639;&#38480;&#21046;&#65292;&#21457;&#29616;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#24335;&#33539;&#25968;&#30340;&#30456;&#21464;&#34892;&#20026;&#65292;&#24182;&#19988;&#24314;&#31435;&#20102;&#26377;&#25928;&#21464;&#20307;&#30340;&#19978;&#30028;&#26465;&#20214;&#12290;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#26500;&#36896;&#30340;&#31034;&#20363;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#35745;&#31639;&#26102;&#38388;&#19979;&#30028;&#12289;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#32454;&#31890;&#24230;&#22797;&#26434;&#24615;&#20998;&#26512;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#35760;&#24518;&#26816;&#32034;&#21160;&#21147;&#23398;&#30340;&#35745;&#31639;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22522;&#20110;&#27169;&#24335;&#30340;&#33539;&#25968;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#29616;&#20195;Hopfield&#27169;&#22411;&#30340;&#25928;&#29575;&#36827;&#34892;&#30456;&#21464;&#34892;&#20026;&#30340;&#21051;&#30011;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;&#36755;&#20837;&#26597;&#35810;&#27169;&#24335;&#21644;&#35760;&#24518;&#27169;&#24335;&#30340;&#33539;&#25968;&#30340;&#19978;&#30028;&#26631;&#20934;&#12290;&#20165;&#22312;&#36825;&#20010;&#26631;&#20934;&#20043;&#19979;&#65292;&#20551;&#35774;&#28385;&#36275;Strong Exponential Time Hypothesis (SETH)&#65292;&#23384;&#22312;&#23376;&#20108;&#27425;&#65288;&#39640;&#25928;&#65289;&#21464;&#20307;&#30340;&#29616;&#20195;Hopfield&#27169;&#22411;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#24403;&#26377;&#25928;&#26631;&#20934;&#25104;&#31435;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#20195;Hopfield&#27169;&#22411;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#30340;&#26377;&#25928;&#26500;&#36896;&#30340;&#27491;&#24335;&#31034;&#20363;&#12290;&#36825;&#21253;&#25324;&#19968;&#20010;&#35745;&#31639;&#26102;&#38388;&#30340;&#19979;&#30028;&#23548;&#20986;&#65292;&#19982;$\Max\{$&#23384;&#20648;&#30340;&#35760;&#24518;&#27169;&#24335;&#25968;&#37327;&#65292;&#36755;&#20837;&#26597;&#35810;&#24207;&#21015;&#30340;&#38271;&#24230;$\}$&#32447;&#24615;&#32553;&#25918;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35760;&#24518;&#26816;&#32034;&#35823;&#24046;&#30028;&#21644;&#25351;&#25968;&#35760;&#24518;&#23481;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the computational limits of the memory retrieval dynamics of modern Hopfield models from the fine-grained complexity analysis. Our key contribution is the characterization of a phase transition behavior in the efficiency of all possible modern Hopfield models based on the norm of patterns. Specifically, we establish an upper bound criterion for the norm of input query patterns and memory patterns. Only below this criterion, sub-quadratic (efficient) variants of the modern Hopfield model exist, assuming the Strong Exponential Time Hypothesis (SETH). To showcase our theory, we provide a formal example of efficient constructions of modern Hopfield models using low-rank approximation when the efficient criterion holds. This includes a derivation of a lower bound on the computational time, scaling linearly with $\Max\{$# of stored memory patterns, length of input query sequence$\}$. In addition, we prove its memory retrieval error bound and exponential memory capacity.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20302;&#31209;MDPs&#19978;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#24182;&#36798;&#21040;&#20102;$O(\epsilon^{-2})$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#35813;&#31639;&#27861;&#36824;&#25903;&#25345;&#39069;&#22806;&#22870;&#21169;&#20449;&#21495;&#30340;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2402.04493</link><description>&lt;p&gt;
&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#31181;&#22522;&#26412;&#23545;&#20598;&#31639;&#27861;&#22312;&#20302;&#31209;MDPs&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual Algorithm for Offline Constrained Reinforcement Learning with Low-Rank MDPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04493
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20302;&#31209;MDPs&#19978;&#30340;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#24182;&#36798;&#21040;&#20102;$O(\epsilon^{-2})$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#35813;&#31639;&#27861;&#36824;&#25903;&#25345;&#39069;&#22806;&#22870;&#21169;&#20449;&#21495;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#31181;&#26368;&#22823;&#21270;&#26399;&#26395;&#32047;&#31215;&#22870;&#21169;&#30340;&#31574;&#30053;&#12290;&#26368;&#36817;&#65292;&#23545;&#20110;&#20302;&#31209;MDPs&#25110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#26159;&#29616;&#26377;&#31639;&#27861;&#22312;&#25214;&#21040;$\epsilon$-&#20248;&#21270;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$O(\epsilon^{-2})$&#26102;&#65292;&#35201;&#20040;&#38656;&#35201;&#22343;&#21248;&#30340;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#65292;&#35201;&#20040;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#25240;&#25187;&#26080;&#31351;&#26102;&#27573;&#35774;&#32622;&#19979;&#65292;&#29992;&#20110;&#20302;&#31209;MDPs&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#26412;&#23545;&#20598;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#22312;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#35813;&#35774;&#32622;&#20013;&#31532;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#36798;&#21040;$O(\epsilon^{-2})$&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20248;&#20110;&#26368;&#36817;&#30340;&#19968;&#39033;&#24037;&#20316;&#65292;&#20854;&#38656;&#35201;$O(\epsilon^{-4})$&#20010;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#25903;&#25345;&#39069;&#22806;&#22870;&#21169;&#20449;&#21495;&#30340;&#32422;&#26463;&#65292;&#23558;&#20043;&#21069;&#30340;&#24037;&#20316;&#25193;&#23637;&#21040;&#31163;&#32447;&#32422;&#26463;&#24378;&#21270;&#23398;&#20064;&#35774;&#32622;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward using a pre-collected dataset. Offline RL with low-rank MDPs or general function approximation has been widely studied recently, but existing algorithms with sample complexity $O(\epsilon^{-2})$ for finding an $\epsilon$-optimal policy either require a uniform data coverage assumptions or are computationally inefficient. In this paper, we propose a primal dual algorithm for offline RL with low-rank MDPs in the discounted infinite-horizon setting. Our algorithm is the first computationally efficient algorithm in this setting that achieves sample complexity of $O(\epsilon^{-2})$ with partial data coverage assumption. This improves upon a recent work that requires $O(\epsilon^{-4})$ samples. Moreover, our algorithm extends the previous work to the offline constrained RL setting by supporting constraints on additional reward signals.
&lt;/p&gt;</description></item><item><title>SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.03819</link><description>&lt;p&gt;
SMOTE&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#30740;&#31350;&#65306;&#20851;&#20110;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#30340;&#38480;&#21046;&#21644;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Theoretical and experimental study of SMOTE: limitations and comparisons of rebalancing strategies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03819
&lt;/p&gt;
&lt;p&gt;
SMOTE&#26159;&#19968;&#31181;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#30340;&#24120;&#29992;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#65292;&#23427;&#36890;&#36807;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;SMOTE&#30340;&#23494;&#24230;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#36793;&#30028;&#38468;&#36817;&#36880;&#28176;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;BorderLine SMOTE&#31574;&#30053;&#30340;&#21512;&#29702;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#19982;&#20854;&#20182;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#32456;&#21457;&#29616;&#65292;&#22312;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#30340;&#24773;&#20917;&#19979;&#65292;SMOTE&#12289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
SMOTE&#65288;Synthetic Minority Oversampling Technique&#65289;&#26159;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#24120;&#29992;&#30340;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;SMOTE&#65288;&#40664;&#35748;&#21442;&#25968;&#65289;&#36890;&#36807;&#31616;&#21333;&#22797;&#21046;&#21407;&#22987;&#23569;&#25968;&#26679;&#26412;&#26469;&#37325;&#26032;&#29983;&#25104;&#21407;&#22987;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#23569;&#25968;&#26679;&#26412;&#20998;&#24067;&#30340;&#25903;&#25345;&#36793;&#30028;&#38468;&#36817;&#65292;SMOTE&#30340;&#23494;&#24230;&#20250;&#20943;&#23567;&#65292;&#20174;&#32780;&#39564;&#35777;&#20102;&#24120;&#35265;&#30340;BorderLine SMOTE&#31574;&#30053;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;SMOTE&#30456;&#20851;&#31574;&#30053;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#29616;&#26377;&#30340;&#37325;&#26032;&#24179;&#34913;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21482;&#26377;&#24403;&#25968;&#25454;&#38598;&#26497;&#24230;&#19981;&#24179;&#34913;&#26102;&#25165;&#38656;&#35201;&#37325;&#26032;&#24179;&#34913;&#31574;&#30053;&#12290;&#23545;&#20110;&#36825;&#31181;&#25968;&#25454;&#38598;&#65292;SMOTE&#12289;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#25110;&#27424;&#37319;&#26679;&#31243;&#24207;&#26159;&#26368;&#20339;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic Minority Oversampling Technique (SMOTE) is a common rebalancing strategy for handling imbalanced data sets. Asymptotically, we prove that SMOTE (with default parameter) regenerates the original distribution by simply copying the original minority samples. We also prove that SMOTE density vanishes near the boundary of the support of the minority distribution, therefore justifying the common BorderLine SMOTE strategy. Then we introduce two new SMOTE-related strategies, and compare them with state-of-the-art rebalancing procedures. We show that rebalancing strategies are only required when the data set is highly imbalanced. For such data sets, SMOTE, our proposals, or undersampling procedures are the best strategies.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65288;VAE-AD&#27979;&#35797;&#65289;&#65292;&#36890;&#36807;&#37327;&#21270;&#24322;&#24120;&#21306;&#22495;&#30340;&#21487;&#38752;&#24615;&#65292;&#21487;&#20197;&#25511;&#21046;&#35823;&#26816;&#30340;&#27010;&#29575;&#21040;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.03724</link><description>&lt;p&gt;
&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32479;&#35745;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Statistical Test for Anomaly Detections by Variational Auto-Encoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#30340;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65288;VAE-AD&#27979;&#35797;&#65289;&#65292;&#36890;&#36807;&#37327;&#21270;&#24322;&#24120;&#21306;&#22495;&#30340;&#21487;&#38752;&#24615;&#65292;&#21487;&#20197;&#25511;&#21046;&#35823;&#26816;&#30340;&#27010;&#29575;&#21040;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#65288;AD&#65289;&#30340;&#21487;&#38752;&#24615;&#35780;&#20272;&#12290;&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#22522;&#20110;VAE&#30340;AD&#24050;&#32463;&#22312;&#21508;&#20010;&#35282;&#24230;&#36827;&#34892;&#20102;&#31215;&#26497;&#30340;&#30740;&#31350;&#65292;&#20174;&#26041;&#27861;&#24320;&#21457;&#21040;&#24212;&#29992;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#24403;AD&#30340;&#32467;&#26524;&#29992;&#20110;&#39640;&#39118;&#38505;&#30340;&#20915;&#31574;&#26102;&#65292;&#22914;&#21307;&#23398;&#35786;&#26029;&#65292;&#38656;&#35201;&#30830;&#20445;&#26816;&#27979;&#21040;&#30340;&#24322;&#24120;&#30340;&#21487;&#38752;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;VAE-AD&#27979;&#35797;&#20316;&#20026;&#22312;&#32479;&#35745;&#26816;&#39564;&#26694;&#26550;&#19979;&#37327;&#21270;&#22522;&#20110;VAE&#30340;AD&#30340;&#32479;&#35745;&#21487;&#38752;&#24615;&#30340;&#26041;&#27861;&#12290;&#21033;&#29992;VAE-AD&#27979;&#35797;&#65292;&#21487;&#20197;&#20197;p&#20540;&#30340;&#24418;&#24335;&#37327;&#21270;VAE&#26816;&#27979;&#21040;&#30340;&#24322;&#24120;&#21306;&#22495;&#30340;&#21487;&#38752;&#24615;&#12290;&#36825;&#24847;&#21619;&#30528;&#65292;&#22914;&#26524;&#22312;p&#20540;&#20302;&#20110;&#26576;&#20010;&#38408;&#20540;&#26102;&#23459;&#24067;&#20026;&#24322;&#24120;&#65292;&#21017;&#21487;&#20197;&#23558;&#35823;&#26816;&#30340;&#27010;&#29575;&#25511;&#21046;&#22312;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#12290;&#30001;&#20110;VAE-AD&#27979;&#35797;&#26159;&#22522;&#20110;&#19968;&#31181;&#31216;&#20026;&#36873;&#25321;&#24615;&#25512;&#29702;&#30340;&#26032;&#32479;&#35745;&#25512;&#26029;&#26694;&#26550;&#26500;&#24314;&#30340;&#65292;&#20854;&#26377;&#25928;&#24615;&#26159;&#30830;&#20445;&#34987;&#35777;&#26126;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we consider the reliability assessment of anomaly detection (AD) using Variational Autoencoder (VAE). Over the last decade, VAE-based AD has been actively studied in various perspective, from method development to applied research. However, when the results of ADs are used in high-stakes decision-making, such as in medical diagnosis, it is necessary to ensure the reliability of the detected anomalies. In this study, we propose the VAE-AD Test as a method for quantifying the statistical reliability of VAE-based AD within the framework of statistical testing. Using the VAE-AD Test, the reliability of the anomaly regions detected by a VAE can be quantified in the form of p-values. This means that if an anomaly is declared when the p-value is below a certain threshold, it is possible to control the probability of false detection to a desired level. Since the VAE-AD Test is constructed based on a new statistical inference framework called selective inference, its validity is 
&lt;/p&gt;</description></item><item><title>&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#24212;&#35813;&#26159;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#29702;&#35770;&#65292;&#20174;&#26356;&#23436;&#25972;&#30340;&#35282;&#24230;&#25506;&#31350;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.02287</link><description>&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#22522;&#30784;&#30340;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Future Directions in Foundations of Graph Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02287
&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#24212;&#35813;&#26159;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#29702;&#35770;&#65292;&#20174;&#26356;&#23436;&#25972;&#30340;&#35282;&#24230;&#25506;&#31350;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22270;&#25968;&#25454;&#22312;&#19981;&#21516;&#23398;&#31185;&#65288;&#20174;&#29983;&#21629;&#31185;&#23398;&#21040;&#31038;&#20250;&#31185;&#23398;&#21644;&#24037;&#31243;&#31185;&#23398;&#65289;&#19978;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#24341;&#36215;&#20102;&#20154;&#20204;&#27987;&#21402;&#30340;&#20852;&#36259;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#25105;&#20204;&#23545;GNNs&#24615;&#36136;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#38750;&#24120;&#19981;&#23436;&#25972;&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#21457;&#23637;&#20027;&#35201;&#38598;&#20013;&#22312;&#38416;&#26126;GNNs&#31895;&#31890;&#24230;&#34920;&#36798;&#33021;&#21147;&#26041;&#38754;&#65292;&#20027;&#35201;&#37319;&#29992;&#32452;&#21512;&#25216;&#24039;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#19982;&#23454;&#36341;&#24182;&#19981;&#23436;&#20840;&#19968;&#33268;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#38543;&#26426;&#19968;&#38454;&#20248;&#21270;&#25216;&#26415;&#35757;&#32451;GNNs&#26102;&#65292;&#23545;GNNs&#30340;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#31687;&#23450;&#20301;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#38656;&#35201;&#23558;&#27880;&#24847;&#21147;&#36716;&#31227;&#21040;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#19978;&#26469;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#30340;&#30456;&#20114;&#20851;&#31995;&#30340;&#26356;&#20840;&#38754;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across a broad spectrum of disciplines, from life to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains highly incomplete. Recent theoretical advancements primarily focus on elucidating the coarse-grained expressive power of GNNs, predominantly employing combinatorial techniques. However, these studies do not perfectly align with practice, particularly in understanding the generalization behavior of GNNs when trained with stochastic first-order optimization techniques. In this position paper, we argue that the graph machine learning community needs to shift its attention to developing a more balanced theory of graph machine learning, focusing on a more thorough understanding of the interplay of expressive power, generalization, and optimization.
&lt;/p&gt;</description></item><item><title>&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.00809</link><description>&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#30340;&#31435;&#22330;&#35770;&#25991;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Bayesian Deep Learning in the Age of Large-Scale AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00809
&lt;/p&gt;
&lt;p&gt;
&#12298;&#22312;&#22823;&#35268;&#27169;&#20154;&#24037;&#26234;&#33021;&#26102;&#20195;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#12299;&#36825;&#31687;&#31435;&#22330;&#35770;&#25991;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21508;&#31181;&#19981;&#21516;&#35774;&#32622;&#19979;&#30340;&#20248;&#21183;&#65292;&#24182;&#25351;&#20986;&#20102;&#19982;&#20043;&#30456;&#20851;&#30340;&#25361;&#25112;&#21644;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#37325;&#28857;&#23558;&#25918;&#22312;&#22914;&#20309;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#20197;&#21457;&#25381;&#23427;&#20204;&#30340;&#20840;&#37096;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#30340;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#20154;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#28041;&#21450;&#22823;&#35268;&#27169;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20219;&#21153;&#20013;&#23454;&#29616;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#26356;&#24191;&#27867;&#30340;&#35270;&#35282;&#25581;&#31034;&#20102;&#35768;&#22810;&#34987;&#24573;&#35270;&#30340;&#24230;&#37327;&#26631;&#20934;&#12289;&#20219;&#21153;&#21644;&#25968;&#25454;&#31867;&#22411;&#65292;&#22914;&#19981;&#30830;&#23450;&#24615;&#12289;&#20027;&#21160;&#21644;&#25345;&#32493;&#23398;&#20064;&#20197;&#21450;&#31185;&#23398;&#25968;&#25454;&#65292;&#36825;&#20123;&#26041;&#38754;&#38656;&#35201;&#20851;&#27880;&#12290;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#65288;BDL&#65289;&#26159;&#19968;&#26465;&#26377;&#21069;&#26223;&#30340;&#36947;&#36335;&#65292;&#21487;&#20197;&#22312;&#36825;&#20123;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#25552;&#20379;&#20248;&#21183;&#12290;&#26412;&#25991;&#35748;&#20026;BDL&#21487;&#20197;&#25552;&#21319;&#28145;&#24230;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#23427;&#37325;&#26032;&#23457;&#35270;&#20102;BDL&#30340;&#20248;&#21183;&#12289;&#25215;&#35748;&#20102;&#29616;&#26377;&#30340;&#25361;&#25112;&#65292;&#24182;&#37325;&#28857;&#20171;&#32461;&#20102;&#19968;&#20123;&#26088;&#22312;&#35299;&#20915;&#36825;&#20123;&#38556;&#30861;&#30340;&#26377;&#36259;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;&#23637;&#26395;&#26410;&#26469;&#65292;&#35752;&#35770;&#38598;&#20013;&#22312;&#21487;&#33021;&#30340;&#26041;&#24335;&#19978;&#65292;&#23558;&#22823;&#35268;&#27169;&#22522;&#30784;&#27169;&#22411;&#19982;BDL&#30456;&#32467;&#21512;&#65292;&#20197;&#20805;&#20998;&#21457;&#25381;&#23427;&#20204;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the current landscape of deep learning research, there is a predominant emphasis on achieving high predictive accuracy in supervised tasks involving large image and language datasets. However, a broader perspective reveals a multitude of overlooked metrics, tasks, and data types, such as uncertainty, active and continual learning, and scientific data, that demand attention. Bayesian deep learning (BDL) constitutes a promising avenue, offering advantages across these diverse settings. This paper posits that BDL can elevate the capabilities of deep learning. It revisits the strengths of BDL, acknowledges existing challenges, and highlights some exciting research avenues aimed at addressing these obstacles. Looking ahead, the discussion focuses on possible ways to combine large-scale foundation models with BDL to unlock their full potential.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20855;&#26377;&#37096;&#20998;&#21160;&#24577;&#30693;&#35782;&#30340;&#22312;&#32447;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#26377;&#38480;&#30340;&#20998;&#38598;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#35774;&#32622;&#19979;&#65292;&#23454;&#29616;&#20102;&#36739;&#20302;&#30340;&#36951;&#25022;&#12290;</title><link>https://arxiv.org/abs/2312.12558</link><description>&lt;p&gt;
&#20855;&#26377;&#37096;&#20998;&#21160;&#24577;&#30693;&#35782;&#30340;&#26679;&#26412;&#39640;&#25928;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12558
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20855;&#26377;&#37096;&#20998;&#21160;&#24577;&#30693;&#35782;&#30340;&#22312;&#32447;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#26377;&#38480;&#30340;&#20998;&#38598;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#35774;&#32622;&#19979;&#65292;&#23454;&#29616;&#20102;&#36739;&#20302;&#30340;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;Q&#23398;&#20064;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24403;&#26576;&#20123;&#20851;&#20110;&#21160;&#24577;&#30340;&#20808;&#21069;&#30693;&#35782;&#21487;&#29992;&#25110;&#21487;&#20197;&#26377;&#25928;&#23398;&#20064;&#26102;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#25353;&#29031;&#21152;&#24615;&#24178;&#25200;&#27169;&#22411;&#28436;&#21464;&#30340;&#31995;&#32479;&#65292;&#22312;&#26377;&#38480;&#30340;&#20998;&#38598;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;Q&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#23545;$f$&#30340;&#23436;&#32654;&#30693;&#35782;&#26465;&#20214;&#19979;&#23454;&#29616;&#20102;$\tilde{\mathcal{O}}(\text{Poly}(H)\sqrt{T})$&#30340;&#36951;&#25022;&#65292;&#20854;&#20013;$T$&#26159;&#19982;&#31995;&#32479;&#36827;&#34892;&#20132;&#20114;&#30340;&#24635;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.12558v2 Announce Type: replace  Abstract: The problem of sample complexity of online reinforcement learning is often studied in the literature without taking into account any partial knowledge about the system dynamics that could potentially accelerate the learning process. In this paper, we study the sample complexity of online Q-learning methods when some prior knowledge about the dynamics is available or can be learned efficiently. We focus on systems that evolve according to an additive disturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$ represents the underlying system dynamics, and $W_h$ are unknown disturbances independent of states and actions. In the setting of finite episodic Markov decision processes with $S$ states, $A$ actions, and episode length $H$, we present an optimistic Q-learning algorithm that achieves $\tilde{\mathcal{O}}(\text{Poly}(H)\sqrt{T})$ regret under perfect knowledge of $f$, where $T$ is the total number of interactions with
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#26469;&#35774;&#35745;&#21487;&#38752;&#22320;&#25490;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;SHAP&#21644;LIME&#31561;&#24120;&#29992;&#26041;&#27861;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#23548;&#33268;&#30340;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.15800</link><description>&lt;p&gt;
&#20351;&#29992;SHAP&#21644;LIME&#36827;&#34892;&#21487;&#35777;&#26126;&#31283;&#23450;&#30340;&#29305;&#24449;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Provably Stable Feature Rankings with SHAP and LIME. (arXiv:2401.15800v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15800
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#26469;&#35774;&#35745;&#21487;&#38752;&#22320;&#25490;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;SHAP&#21644;LIME&#31561;&#24120;&#29992;&#26041;&#27861;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#23548;&#33268;&#30340;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#22240;&#26159;&#20102;&#35299;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#30340;&#26222;&#36941;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#35780;&#20998;&#36755;&#20837;&#21464;&#37327;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#22914;SHAP&#21644;LIME&#65292;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#32780;&#20855;&#26377;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#12290;&#20511;&#37492;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#27491;&#30830;&#25490;&#21517;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#24402;&#22240;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;RankSHAP&#20445;&#35777;$K$&#20010;&#26368;&#39640;Shapley&#20540;&#20855;&#26377;&#36229;&#36807;$1-\alpha$&#30340;&#27491;&#30830;&#25490;&#24207;&#27010;&#29575;&#12290;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#36824;&#22312;&#20043;&#21069;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#20026;LIME&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#30830;&#20445;&#20197;&#27491;&#30830;&#39034;&#24207;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature attributions are ubiquitous tools for understanding the predictions of machine learning models. However, popular methods for scoring input variables such as SHAP and LIME suffer from high instability due to random sampling. Leveraging ideas from multiple hypothesis testing, we devise attribution methods that correctly rank the most important features with high probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley values have the proper ordering with probability exceeding $1-\alpha$. Empirical results demonstrate its validity and impressive computational efficiency. We also build on previous work to yield similar results for LIME, ensuring the most important features are selected in the right order.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.10989</link><description>&lt;p&gt;
&#20855;&#26377;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#30340;&#21487;&#35777;&#20280;&#32553;&#24615;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Provably Scalable Black-Box Variational Inference with Structured Variational Families. (arXiv:2401.10989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#20855;&#26377;&#28385;&#31209;&#21327;&#26041;&#24046;&#36924;&#36817;&#30340;&#21464;&#20998;&#26063;&#22312;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20013;&#34920;&#29616;&#19981;&#20339;&#65292;&#26080;&#35770;&#26159;&#20174;&#23454;&#35777;&#19978;&#36824;&#26159;&#29702;&#35770;&#19978;&#12290;&#20107;&#23454;&#19978;&#65292;&#26368;&#36817;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#30456;&#27604;&#65292;&#28385;&#31209;&#21464;&#20998;&#26063;&#22312;&#38382;&#39064;&#30340;&#32500;&#24230;&#19978;&#25193;&#23637;&#24471;&#24456;&#24046;&#12290;&#36825;&#23545;&#20855;&#26377;&#26412;&#22320;&#21464;&#37327;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#23588;&#20026;&#20851;&#38190;&#65292;&#23427;&#20204;&#30340;&#32500;&#24230;&#38543;&#30528;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#32780;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#22797;&#26434;&#24615;&#23545;&#25968;&#25454;&#38598;&#22823;&#23567;N&#23384;&#22312;&#26126;&#30830;&#30340;O(N^2)&#20381;&#36182;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#26576;&#20123;&#23610;&#24230;&#30697;&#38453;&#32467;&#26500;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#36845;&#20195;&#22797;&#26434;&#24615;O(N)&#65292;&#20174;&#32780;&#19982;N&#30340;&#32553;&#25918;&#26356;&#22909;&#22320;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#29616;&#23454;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Variational families with full-rank covariance approximations are known not to work well in black-box variational inference (BBVI), both empirically and theoretically. In fact, recent computational complexity results for BBVI have established that full-rank variational families scale poorly with the dimensionality of the problem compared to e.g. mean field families. This is particularly critical to hierarchical Bayesian models with local variables; their dimensionality increases with the size of the datasets. Consequently, one gets an iteration complexity with an explicit $\mathcal{O}(N^2)$ dependence on the dataset size $N$. In this paper, we explore a theoretical middle ground between mean-field variational families and full-rank families: structured variational families. We rigorously prove that certain scale matrix structures can achieve a better iteration complexity of $\mathcal{O}(N)$, implying better scaling with respect to $N$. We empirically verify our theoretical results on l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20581;&#22766;&#21644;&#20849;&#36717;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;RCGP&#65289;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#27867;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#23454;&#29616;&#20102;&#21487;&#38752;&#30340;&#38381;&#24335;&#26356;&#26032;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2311.00463</link><description>&lt;p&gt;
&#20581;&#22766;&#21644;&#20849;&#36717;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Robust and Conjugate Gaussian Process Regression. (arXiv:2311.00463v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20581;&#22766;&#21644;&#20849;&#36717;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;RCGP&#65289;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#27867;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#23454;&#29616;&#20102;&#21487;&#38752;&#30340;&#38381;&#24335;&#26356;&#26032;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23454;&#29616;&#38381;&#24335;&#26465;&#20214;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#22238;&#24402;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#35266;&#27979;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#24378;&#20551;&#35774;&#22312;&#23454;&#38469;&#20013;&#32463;&#24120;&#34987;&#36829;&#21453;&#65292;&#23548;&#33268;&#19981;&#21487;&#38752;&#30340;&#25512;&#26029;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#27867;&#21270;&#36125;&#21494;&#26031;&#25512;&#26029;&#20197;&#20960;&#20046;&#27809;&#26377;&#39069;&#22806;&#20195;&#20215;&#23454;&#29616;&#21487;&#38752;&#21644;&#20849;&#36717;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;RCGP&#65289;&#22238;&#24402;&#12290;RCGP&#20855;&#26377;&#24456;&#39640;&#30340;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#22312;&#26631;&#20934;GP&#36866;&#29992;&#30340;&#25152;&#26377;&#24773;&#20917;&#19979;&#36827;&#34892;&#31934;&#30830;&#30340;&#20849;&#36717;&#38381;&#24335;&#26356;&#26032;&#12290;&#20026;&#20102;&#23637;&#31034;&#20854;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#65292;&#25105;&#20204;&#23558;RCGP&#24212;&#29992;&#20110;&#20174;&#36125;&#21494;&#26031;&#20248;&#21270;&#21040;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#30340;&#21508;&#31181;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
To enable closed form conditioning, a common assumption in Gaussian process (GP) regression is independent and identically distributed Gaussian observation noise. This strong and simplistic assumption is often violated in practice, which leads to unreliable inferences and uncertainty quantification. Unfortunately, existing methods for robustifying GPs break closed-form conditioning, which makes them less attractive to practitioners and significantly more computationally expensive. In this paper, we demonstrate how to perform provably robust and conjugate Gaussian process (RCGP) regression at virtually no additional cost using generalised Bayesian inference. RCGP is particularly versatile as it enables exact conjugate closed form updates in all settings where standard GPs admit them. To demonstrate its strong empirical performance, we deploy RCGP for problems ranging from Bayesian optimisation to sparse variational Gaussian processes.
&lt;/p&gt;</description></item><item><title>&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#65292;&#36890;&#36807;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#31639;&#27861;&#65288;LDP&#65289;&#65292;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;LDP&#26681;&#25454;&#19982;&#26333;&#20809;-&#32467;&#26524;&#23545;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#23558;&#21464;&#37327;&#38598;&#21512;Z&#36827;&#34892;&#20998;&#21306;&#65292;&#24182;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.17816</link><description>&lt;p&gt;
Local Discovery by Partitioning: &#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around Exposure-Outcome Pairs. (arXiv:2310.17816v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17816
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#65292;&#36890;&#36807;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#31639;&#27861;&#65288;LDP&#65289;&#65292;&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;LDP&#26681;&#25454;&#19982;&#26333;&#20809;-&#32467;&#26524;&#23545;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#23558;&#21464;&#37327;&#38598;&#21512;Z&#36827;&#34892;&#20998;&#21306;&#65292;&#24182;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;&#35813;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#22312;&#26377;&#38480;&#20808;&#39564;&#30693;&#35782;&#19979;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#32473;&#23450;&#19968;&#20010;{X,Y}&#30340;&#26333;&#20809;-&#32467;&#26524;&#23545;&#21644;&#19968;&#20010;&#26410;&#30693;&#22240;&#26524;&#32467;&#26500;&#30340;&#21464;&#37327;&#38598;&#21512;Z&#65292;&#23616;&#37096;&#20998;&#21306;&#21457;&#29616;&#65288;LDP&#65289;&#31639;&#27861;&#23558;Z&#21010;&#20998;&#25104;&#19982;{X,Y}&#30456;&#20851;&#30340;&#23376;&#38598;&#12290;&#25105;&#20204;&#21015;&#20030;&#20102;&#20219;&#24847;Z&#30340;8&#20010;&#31351;&#20030;&#19988;&#20114;&#19981;&#37325;&#22797;&#30340;&#20998;&#21306;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#20998;&#31867;&#27861;&#21306;&#20998;&#28151;&#28102;&#22240;&#32032;&#21644;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#12290;LDP&#30340;&#21160;&#26426;&#26159;&#26377;&#25928;&#30340;&#35843;&#25972;&#38598;&#35782;&#21035;&#65292;&#20294;&#36991;&#20813;&#20102;&#33258;&#21160;&#21464;&#37327;&#36873;&#25321;&#26041;&#27861;&#20013;&#24120;&#35265;&#30340;&#39044;&#22788;&#29702;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;LDP&#23545;&#20110;&#28385;&#36275;&#36275;&#22815;&#22270;&#24418;&#26465;&#20214;&#30340;&#20219;&#20309;Z&#37117;&#36820;&#22238;&#19968;&#20010;&#26377;&#25928;&#30340;&#35843;&#25972;&#38598;&#12290;&#22312;&#26356;&#24378;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#21306;&#26631;&#31614;&#30340;&#28176;&#36817;&#27491;&#30830;&#24615;&#12290;&#24635;&#29420;&#31435;&#24615;&#27979;&#35797;&#22312;|Z|&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#26159;&#20108;&#27425;&#30340;&#65292;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#27425;&#20108;&#27425;&#30340;&#36816;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#23545;&#29702;&#35770;&#20445;&#35777;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work addresses the problem of automated covariate selection under limited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable set Z of unknown causal structure, the Local Discovery by Partitioning (LDP) algorithm partitions Z into subsets defined by their relation to {X,Y}. We enumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z and leverage this taxonomy to differentiate confounders from other variable types. LDP is motivated by valid adjustment set identification, but avoids the pretreatment assumption commonly made by automated covariate selection methods. We provide theoretical guarantees that LDP returns a valid adjustment set for any Z that meets sufficient graphical conditions. Under stronger conditions, we prove that partition labels are asymptotically correct. Total independence tests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed empirically. We numerically validate our theoretical guarantees on synthetic 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;AdamQLR&#65292;&#23427;&#26159;&#19968;&#20010;&#36890;&#36807;&#23558;K-FAC&#20013;&#30340;&#25216;&#26415;&#19982;Adam&#30340;&#26356;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;Adam&#34892;&#20026;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;AdamQLR&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#25512;&#24191;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.14963</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#38454;&#36879;&#38236;&#30475;Adam
&lt;/p&gt;
&lt;p&gt;
Adam through a Second-Order Lens. (arXiv:2310.14963v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14963
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;AdamQLR&#65292;&#23427;&#26159;&#19968;&#20010;&#36890;&#36807;&#23558;K-FAC&#20013;&#30340;&#25216;&#26415;&#19982;Adam&#30340;&#26356;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;Adam&#34892;&#20026;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;AdamQLR&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#25512;&#24191;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#30740;&#31350;&#23384;&#22312;&#19968;&#31181;&#32039;&#24352;&#29366;&#24577;&#65292;&#21363;&#31532;&#19968;&#38454;&#26799;&#24230;&#27861;&#65288;&#22914;SGD&#21644;Adam&#65289;&#30340;&#35745;&#31639;&#25928;&#29575;&#19982;&#31532;&#20108;&#38454;&#26354;&#29575;&#27861;&#65288;&#22914;&#25311;&#29275;&#39039;&#26041;&#27861;&#21644;K-FAC&#65289;&#30340;&#29702;&#35770;&#25928;&#29575;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#12290;&#25105;&#20204;&#35797;&#22270;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#32467;&#21512;&#21040;&#19968;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#31639;&#27861;&#20013;&#12290;&#27880;&#24847;&#21040;&#20108;&#38454;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#31283;&#23450;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;&#22914;Levenberg-Marquardt&#38459;&#23612;&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;AdamQLR&#65306;&#19968;&#20010;&#23558;K-FAC&#20013;&#30340;&#38459;&#23612;&#21644;&#23398;&#20064;&#29575;&#36873;&#25321;&#25216;&#26415;&#19982;Adam&#25552;&#20986;&#30340;&#26356;&#26032;&#26041;&#21521;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;Adam&#22312;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35268;&#27169;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;AdamQLR&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19982;&#31454;&#20105;&#24615;&#25512;&#24191;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Research into optimisation for deep learning is characterised by a tension between the computational efficiency of first-order, gradient-based methods (such as SGD and Adam) and the theoretical efficiency of second-order, curvature-based methods (such as quasi-Newton methods and K-FAC). We seek to combine the benefits of both approaches into a single computationally-efficient algorithm. Noting that second-order methods often depend on stabilising heuristics (such as Levenberg-Marquardt damping), we propose AdamQLR: an optimiser combining damping and learning rate selection techniques from K-FAC (Martens and Grosse, 2015) with the update directions proposed by Adam, inspired by considering Adam through a second-order lens. We evaluate AdamQLR on a range of regression and classification tasks at various scales, achieving competitive generalisation performance vs runtime.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#23398;&#29983;&#36827;&#34892;&#22240;&#26524;&#19982;&#39044;&#27979;&#24615;&#23450;&#20301;&#30340;&#27604;&#36739;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#39046;&#22495;&#23454;&#39564;&#20013;&#40723;&#21169;&#23545;&#35937;&#36873;&#25321;&#30340;&#20215;&#20540;&#12290;&#36825;&#39033;&#22823;&#35268;&#27169;&#23454;&#22320;&#23454;&#39564;&#25581;&#31034;&#20102;&#23450;&#20301;&#24178;&#39044;&#23545;&#20110;&#19981;&#21516;&#23398;&#29983;&#30340;&#25928;&#26524;&#65292;&#20026;&#24178;&#39044;&#31574;&#30053;&#30340;&#20248;&#21270;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2310.08672</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#40723;&#21169;&#23545;&#35937;&#36873;&#25321;&#65306;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#39046;&#22495;&#23454;&#39564;&#20013;&#30340;&#22240;&#26524;&#19982;&#39044;&#27979;&#24615;&#30446;&#26631;&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Machine Learning Who to Nudge: Causal vs Predictive Targeting in a Field Experiment on Student Financial Aid Renewal. (arXiv:2310.08672v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08672
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#23398;&#29983;&#36827;&#34892;&#22240;&#26524;&#19982;&#39044;&#27979;&#24615;&#23450;&#20301;&#30340;&#27604;&#36739;&#65292;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#39046;&#22495;&#23454;&#39564;&#20013;&#40723;&#21169;&#23545;&#35937;&#36873;&#25321;&#30340;&#20215;&#20540;&#12290;&#36825;&#39033;&#22823;&#35268;&#27169;&#23454;&#22320;&#23454;&#39564;&#25581;&#31034;&#20102;&#23450;&#20301;&#24178;&#39044;&#23545;&#20110;&#19981;&#21516;&#23398;&#29983;&#30340;&#25928;&#26524;&#65292;&#20026;&#24178;&#39044;&#31574;&#30053;&#30340;&#20248;&#21270;&#25552;&#20379;&#20102;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24773;&#22659;&#19979;&#65292;&#24178;&#39044;&#21487;&#33021;&#23545;&#26576;&#20123;&#20154;&#27604;&#20854;&#20182;&#20154;&#26356;&#26377;&#25928;&#65292;&#22240;&#27492;&#23450;&#20301;&#24178;&#39044;&#21487;&#33021;&#26159;&#26377;&#30410;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#35268;&#27169;&#24222;&#22823;&#30340;&#23454;&#22320;&#23454;&#39564;&#65288;&#36229;&#36807;53,000&#21517;&#22823;&#23398;&#29983;&#65289;&#26469;&#20998;&#26512;&#22312;&#23398;&#29983;&#21161;&#23398;&#37329;&#32493;&#31614;&#21069;&#20351;&#29992;&#8220;&#40723;&#21169;&#8221;&#31574;&#30053;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;&#22522;&#32447;&#26041;&#27861;&#36827;&#34892;&#23450;&#20301;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22522;&#20110;&#19968;&#20010;&#20272;&#35745;&#24322;&#36136;&#22788;&#29702;&#25928;&#24212;&#30340;&#22240;&#26524;&#26862;&#26519;&#36827;&#34892;&#23450;&#20301;&#65292;&#24182;&#26681;&#25454;&#20272;&#35745;&#20986;&#30340;&#25317;&#26377;&#26368;&#39640;&#22788;&#29702;&#25928;&#24212;&#30340;&#23398;&#29983;&#26469;&#36827;&#34892;&#22788;&#29702;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#35780;&#20272;&#20004;&#31181;&#26367;&#20195;&#30340;&#23450;&#20301;&#31574;&#30053;&#65292;&#19968;&#31181;&#26159;&#38024;&#23545;&#22312;&#27809;&#26377;&#24178;&#39044;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#21040;&#20302;&#21161;&#23398;&#37329;&#32493;&#31614;&#27010;&#29575;&#30340;&#23398;&#29983;&#65292;&#21478;&#19968;&#31181;&#26159;&#38024;&#23545;&#39044;&#27979;&#21040;&#39640;&#27010;&#29575;&#30340;&#23398;&#29983;&#12290;&#39044;&#27979;&#30340;&#22522;&#32447;&#32467;&#26524;&#24182;&#19981;&#26159;&#23450;&#20301;&#30340;&#29702;&#24819;&#26631;&#20934;&#65292;&#32780;&#19988;&#22312;&#20808;&#39564;&#19978;&#20063;&#19981;&#28165;&#26970;&#26159;&#20248;&#20808;&#32771;&#34385;&#20302;&#12289;&#39640;&#36824;&#26159;&#20013;&#38388;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many settings, interventions may be more effective for some individuals than others, so that targeting interventions may be beneficial. We analyze the value of targeting in the context of a large-scale field experiment with over 53,000 college students, where the goal was to use "nudges" to encourage students to renew their financial-aid applications before a non-binding deadline. We begin with baseline approaches to targeting. First, we target based on a causal forest that estimates heterogeneous treatment effects and then assigns students to treatment according to those estimated to have the highest treatment effects. Next, we evaluate two alternative targeting policies, one targeting students with low predicted probability of renewing financial aid in the absence of the treatment, the other targeting those with high probability. The predicted baseline outcome is not the ideal criterion for targeting, nor is it a priori clear whether to prioritize low, high, or intermediate predic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#65288;NDMs&#65289;&#65292;&#23427;&#26159;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23398;&#20064;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#38750;&#32447;&#24615;&#21464;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#26080;&#38656;&#27169;&#25311;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#21464;&#20998;&#30028;&#23545;NDMs&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#22312;&#26631;&#20934;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#21487;&#23398;&#20064;&#21464;&#25442;&#30340;NDMs&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08337</link><description>&lt;p&gt;
&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Diffusion Models. (arXiv:2310.08337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#65288;NDMs&#65289;&#65292;&#23427;&#26159;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23398;&#20064;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#38750;&#32447;&#24615;&#21464;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#26080;&#38656;&#27169;&#25311;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#21464;&#20998;&#30028;&#23545;NDMs&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#22312;&#26631;&#20934;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#21487;&#23398;&#20064;&#21464;&#25442;&#30340;NDMs&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#35768;&#22810;&#29983;&#25104;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#22823;&#22810;&#25968;&#25193;&#25955;&#27169;&#22411;&#21482;&#20801;&#35768;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#32447;&#24615;&#36716;&#25442;&#65292;&#21463;&#21040;&#20102;&#19968;&#23450;&#30340;&#38480;&#21046;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26356;&#24191;&#27867;&#30340;&#21464;&#25442;&#23478;&#26063;&#21487;&#33021;&#26377;&#21161;&#20110;&#26356;&#26377;&#25928;&#22320;&#35757;&#32451;&#29983;&#25104;&#20998;&#24067;&#65292;&#31616;&#21270;&#36870;&#36807;&#31243;&#24182;&#32553;&#23567;&#30495;&#23454;&#36127;&#23545;&#25968;&#20284;&#28982;&#21644;&#21464;&#20998;&#36817;&#20284;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#65288;NDMs&#65289;&#65292;&#23427;&#26159;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23398;&#20064;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#38750;&#32447;&#24615;&#21464;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#19968;&#20010;&#26080;&#38656;&#27169;&#25311;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#21464;&#20998;&#30028;&#23545;NDMs&#36827;&#34892;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;NDMs&#30340;&#26102;&#38388;&#36830;&#32493;&#24418;&#24335;&#65292;&#36890;&#36807;&#20351;&#29992;&#29616;&#25104;&#30340;&#25968;&#20540;ODE&#21644;SDE&#27714;&#35299;&#22120;&#65292;&#21487;&#20197;&#24555;&#36895;&#21487;&#38752;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#26631;&#20934;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#21487;&#23398;&#20064;&#21464;&#25442;&#30340;NDMs&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have shown remarkable performance on many generative tasks. Despite recent success, most diffusion models are restricted in that they only allow linear transformation of the data distribution. In contrast, broader family of transformations can potentially help train generative distributions more efficiently, simplifying the reverse process and closing the gap between the true negative log-likelihood and the variational approximation. In this paper, we present Neural Diffusion Models (NDMs), a generalization of conventional diffusion models that enables defining and learning time-dependent non-linear transformations of data. We show how to optimise NDMs using a variational bound in a simulation-free setting. Moreover, we derive a time-continuous formulation of NDMs, which allows fast and reliable inference using off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the utility of NDMs with learnable transformations through experiments on standard image ge
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28151;&#21512;&#40654;&#26364;&#25193;&#25955;&#36807;&#31243;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#24418;&#19978;&#26500;&#24314;&#29983;&#25104;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#19982;&#29616;&#26377;&#30340;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#21644;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.07216</link><description>&lt;p&gt;
&#22312;&#27969;&#24418;&#19978;&#36890;&#36807;&#40654;&#26364;&#25193;&#25955;&#36807;&#31243;&#30340;&#28151;&#21512;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Modeling on Manifolds Through Mixture of Riemannian Diffusion Processes. (arXiv:2310.07216v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07216
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#40654;&#26364;&#25193;&#25955;&#36807;&#31243;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#24418;&#19978;&#26500;&#24314;&#29983;&#25104;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#19982;&#29616;&#26377;&#30340;&#29983;&#25104;&#27169;&#22411;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#25928;&#29575;&#21644;&#26356;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#24314;&#27169;&#25968;&#25454;&#30340;&#20998;&#24067;&#23545;&#20110;&#26469;&#33258;&#19981;&#21516;&#31185;&#23398;&#39046;&#22495;&#30340;&#35768;&#22810;&#24212;&#29992;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#27969;&#24418;&#19978;&#30340;&#29983;&#25104;&#27169;&#22411;&#23384;&#22312;&#30528;&#35745;&#31639;&#22797;&#26434;&#30340;&#25955;&#24230;&#25110;&#20381;&#36182;&#20110;&#28909;&#26680;&#30340;&#36817;&#20284;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#38480;&#21046;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#31616;&#21333;&#20960;&#20309;&#24418;&#29366;&#19978;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#38459;&#30861;&#20102;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#40654;&#26364;&#25193;&#25955;&#28151;&#21512;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#27969;&#24418;&#19978;&#26500;&#24314;&#29983;&#25104;&#36807;&#31243;&#30340;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#23427;&#26159;&#19968;&#32452;&#20197;&#31471;&#28857;&#26465;&#20214;&#25193;&#25955;&#36807;&#31243;&#20316;&#20026;&#28151;&#21512;&#30340;&#29983;&#25104;&#36807;&#31243;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20808;&#21069;&#25193;&#25955;&#27169;&#22411;&#30340;&#21435;&#22122;&#26041;&#27861;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#65292;&#29983;&#25104;&#36807;&#31243;&#30340;&#29305;&#24615;&#26159;&#23427;&#30340;&#28418;&#31227;&#23548;&#21521;&#19982;&#27969;&#24418;&#30340;&#20960;&#20309;&#24418;&#29366;&#30456;&#23545;&#24212;&#30340;&#26368;&#21487;&#33021;&#30340;&#32456;&#28857;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#35757;&#32451;&#30446;&#26631;&#65292;&#29992;&#20110;&#23398;&#20064;&#28151;&#21512;&#36807;&#31243;&#65292;&#23427;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20110;&#19968;&#33324;&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#34920;&#29616;&#24471;&#24456;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning the distribution of data on Riemannian manifolds is crucial for modeling data from non-Euclidean space, which is required by many applications from diverse scientific fields. Yet, existing generative models on manifolds suffer from expensive divergence computation or rely on approximations of heat kernel. These limitations restrict their applicability to simple geometries and hinder scalability to high dimensions. In this work, we introduce the Riemannian Diffusion Mixture, a principled framework for building a generative process on manifolds as a mixture of endpoint-conditioned diffusion processes instead of relying on the denoising approach of previous diffusion models, for which the generative process is characterized by its drift guiding toward the most probable endpoint with respect to the geometry of the manifold. We further propose a simple yet efficient training objective for learning the mixture process, that is readily applicable to general manifolds. Our method outp
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LSL-GFN&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#36895;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#39640;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.02823</link><description>&lt;p&gt;
&#23398;&#20064;&#28201;&#24230;&#26465;&#20214;&#19979;&#23610;&#24230;&#26631;&#37327;&#21270;&#30340;GFlowNets
&lt;/p&gt;
&lt;p&gt;
Learning to Scale Logits for Temperature-Conditional GFlowNets. (arXiv:2310.02823v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02823
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;LSL-GFN&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#21487;&#20197;&#22823;&#22823;&#21152;&#36895;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#65292;&#20174;&#32780;&#25552;&#39640;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
GFlowNets&#26159;&#19968;&#31181;&#27010;&#29575;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#38543;&#26426;&#31574;&#30053;&#26469;&#39034;&#24207;&#29983;&#25104;&#32452;&#21512;&#32467;&#26500;&#65292;&#20363;&#22914;&#20998;&#23376;&#22270;&#12290;&#23427;&#20204;&#30340;&#35757;&#32451;&#30446;&#26631;&#26159;&#25353;&#27604;&#20363;&#37319;&#26679;&#20855;&#26377;&#30456;&#24212;&#28201;&#24230;&#35843;&#33410;&#30340;&#23545;&#35937;&#30340;&#22870;&#21169;&#12290;&#22312;GFlowNets&#20013;&#65292;&#28201;&#24230;&#26465;&#20214;&#19979;&#30340;GFlowNets&#20195;&#34920;&#20102;&#19968;&#31995;&#21015;&#30001;&#28201;&#24230;&#32034;&#24341;&#30340;&#31574;&#30053;&#65292;&#27599;&#20010;&#31574;&#30053;&#19982;&#30456;&#24212;&#30340;&#28201;&#24230;&#35843;&#33410;&#22870;&#21169;&#20989;&#25968;&#30456;&#20851;&#32852;&#12290;&#28201;&#24230;&#26465;&#20214;&#19979;&#30340;GFlowNets&#30340;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#36890;&#36807;&#35843;&#25972;&#28201;&#24230;&#26469;&#25511;&#21046;&#23545;GFlowNets&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23398;&#20064;&#28201;&#24230;&#26465;&#20214;&#19979;&#23610;&#24230;&#26631;&#37327;&#21270;&#30340;GFlowNets&#65288;LSL-GFN&#65289;&#30340;&#26032;&#22411;&#26550;&#26500;&#35774;&#35745;&#65292;&#23427;&#26497;&#22823;&#22320;&#21152;&#36895;&#20102;&#28201;&#24230;&#26465;&#20214;&#19979;GFlowNets&#30340;&#35757;&#32451;&#12290;&#23427;&#22522;&#20110;&#19968;&#20010;&#24605;&#24819;&#65292;&#21363;&#20043;&#21069;&#25552;&#20986;&#30340;&#28201;&#24230;&#26465;&#20214;&#26041;&#27861;&#22312;&#28145;&#24230;&#32593;&#32476;&#30340;&#35757;&#32451;&#20013;&#24341;&#20837;&#20102;&#25968;&#20540;&#25361;&#25112;&#65292;&#22240;&#20026;&#19981;&#21516;&#30340;&#28201;&#24230;&#21487;&#33021;&#23548;&#33268;&#38750;&#24120;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
GFlowNets are probabilistic models that learn a stochastic policy that sequentially generates compositional structures, such as molecular graphs. They are trained with the objective of sampling such objects with probability proportional to the object's reward. Among GFlowNets, the temperature-conditional GFlowNets represent a family of policies indexed by temperature, and each is associated with the correspondingly tempered reward function. The major benefit of temperature-conditional GFlowNets is the controllability of GFlowNets' exploration and exploitation through adjusting temperature. We propose Learning to Scale Logits for temperature-conditional GFlowNets (LSL-GFN), a novel architectural design that greatly accelerates the training of temperature-conditional GFlowNets. It is based on the idea that previously proposed temperature-conditioning approaches introduced numerical challenges in the training of the deep network because different temperatures may give rise to very differe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#25439;&#22833;&#20989;&#25968;&#23545;&#31216;&#24615;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23398;&#20064;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#65292;&#24341;&#20837;&#30340;&#27599;&#20010;&#38236;&#20687;&#23545;&#31216;&#24615;&#37117;&#20250;&#23548;&#33268;&#19968;&#31181;&#32467;&#26500;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#29992;&#20110;&#23454;&#29616;&#31232;&#30095;&#24615;&#12289;&#20302;&#31209;&#24615;&#21644;&#21516;&#36136;&#38598;&#25104;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#37322;&#32593;&#32476;&#22609;&#24615;&#20007;&#22833;&#21644;&#23849;&#28291;&#29616;&#35937;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2309.16932</link><description>&lt;p&gt;
&#23545;&#31216;&#24615;&#23548;&#33268;&#23398;&#20064;&#30340;&#32467;&#26500;&#24615;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Symmetry Leads to Structured Constraint of Learning. (arXiv:2309.16932v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25581;&#31034;&#20102;&#25439;&#22833;&#20989;&#25968;&#23545;&#31216;&#24615;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23398;&#20064;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#65292;&#24341;&#20837;&#30340;&#27599;&#20010;&#38236;&#20687;&#23545;&#31216;&#24615;&#37117;&#20250;&#23548;&#33268;&#19968;&#31181;&#32467;&#26500;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#29992;&#20110;&#23454;&#29616;&#31232;&#30095;&#24615;&#12289;&#20302;&#31209;&#24615;&#21644;&#21516;&#36136;&#38598;&#25104;&#65292;&#24182;&#25552;&#20379;&#20102;&#35299;&#37322;&#32593;&#32476;&#22609;&#24615;&#20007;&#22833;&#21644;&#23849;&#28291;&#29616;&#35937;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#24120;&#35265;&#30340;&#26550;&#26500;&#35774;&#35745;&#65292;&#23545;&#31216;&#24615;&#22312;&#24403;&#20195;&#31070;&#32463;&#32593;&#32476;&#20013;&#24191;&#27867;&#23384;&#22312;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#25439;&#22833;&#20989;&#25968;&#23545;&#31216;&#24615;&#23545;&#24433;&#21709;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23398;&#20064;&#34892;&#20026;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25439;&#22833;&#20989;&#25968;&#30340;&#27599;&#20010;&#38236;&#20687;&#23545;&#31216;&#24615;&#37117;&#20250;&#23548;&#33268;&#19968;&#31181;&#32467;&#26500;&#24615;&#32422;&#26463;&#65292;&#24403;&#26435;&#37325;&#34928;&#20943;&#25110;&#26799;&#24230;&#22122;&#22768;&#36739;&#22823;&#26102;&#65292;&#36825;&#31181;&#32422;&#26463;&#23558;&#25104;&#20026;&#39318;&#36873;&#35299;&#12290;&#20316;&#20026;&#30452;&#25509;&#25512;&#35770;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#23548;&#33268;&#31232;&#30095;&#24615;&#65292;&#26059;&#36716;&#23545;&#31216;&#24615;&#23548;&#33268;&#20302;&#31209;&#24615;&#65292;&#32622;&#25442;&#23545;&#31216;&#24615;&#23548;&#33268;&#21516;&#36136;&#38598;&#25104;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29702;&#35770;&#26694;&#26550;&#21487;&#20197;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21487;&#22609;&#24615;&#20007;&#22833;&#21644;&#21508;&#31181;&#23849;&#28291;&#29616;&#35937;&#65292;&#24182;&#25552;&#20986;&#20102;&#22914;&#20309;&#21033;&#29992;&#23545;&#31216;&#24615;&#35774;&#35745;&#21487;&#24494;&#20998;&#23454;&#26045;&#30828;&#24615;&#32422;&#26463;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to common architecture designs, symmetries exist extensively in contemporary neural networks. In this work, we unveil the importance of the loss function symmetries in affecting, if not deciding, the learning behavior of machine learning models. We prove that every mirror symmetry of the loss function leads to a structured constraint, which becomes a favored solution when either the weight decay or gradient noise is large. As direct corollaries, we show that rescaling symmetry leads to sparsity, rotation symmetry leads to low rankness, and permutation symmetry leads to homogeneous ensembling. Then, we show that the theoretical framework can explain the loss of plasticity and various collapse phenomena in neural networks and suggest how symmetries can be used to design algorithms to enforce hard constraints in a differentiable way.
&lt;/p&gt;</description></item><item><title>PAGER&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#21644;&#19981;&#19968;&#33268;&#20998;&#25968;&#65292;&#23545;&#26679;&#26412;&#36827;&#34892;&#20998;&#32452;&#24182;&#25552;&#20379;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2309.10977</link><description>&lt;p&gt;
PAGER: &#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#20998;&#26512;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
PAGER: A Framework for Failure Analysis of Deep Regression Models. (arXiv:2309.10977v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10977
&lt;/p&gt;
&lt;p&gt;
PAGER&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#21644;&#19981;&#19968;&#33268;&#20998;&#25968;&#65292;&#23545;&#26679;&#26412;&#36827;&#34892;&#20998;&#32452;&#24182;&#25552;&#20379;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23433;&#20840;&#37096;&#32626;AI&#27169;&#22411;&#38656;&#35201;&#20027;&#21160;&#26816;&#27979;&#28508;&#22312;&#30340;&#39044;&#27979;&#25925;&#38556;&#65292;&#20197;&#38450;&#27490;&#26114;&#36149;&#30340;&#38169;&#35823;&#12290;&#23613;&#31649;&#20998;&#31867;&#38382;&#39064;&#30340;&#25925;&#38556;&#26816;&#27979;&#24050;&#32463;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#22312;&#22238;&#24402;&#20219;&#21153;&#20013;&#34920;&#24449;&#25925;&#38556;&#27169;&#24335;&#26356;&#21152;&#22797;&#26434;&#19988;&#36739;&#23569;&#30740;&#31350;&#12290;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#25110;&#19982;&#35757;&#32451;&#20998;&#24067;&#30340;&#29305;&#24449;&#19981;&#19968;&#33268;&#26469;&#34920;&#24449;&#27169;&#22411;&#39118;&#38505;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#20165;&#38752;&#19981;&#30830;&#23450;&#24615;&#26080;&#27861;&#20934;&#30830;&#34920;&#24449;&#25925;&#38556;&#65292;&#36825;&#26159;&#30001;&#20110;&#21508;&#31181;&#35823;&#24046;&#28304;&#30340;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PAGER&#65288;&#22238;&#24402;&#22120;&#30340;&#21407;&#21017;&#24615;&#27867;&#21270;&#38169;&#35823;&#20998;&#26512;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#31995;&#32479;&#26816;&#27979;&#21644;&#34920;&#24449;&#28145;&#24230;&#22238;&#24402;&#27169;&#22411;&#25925;&#38556;&#30340;&#26694;&#26550;&#12290;&#22522;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#28145;&#24230;&#27169;&#22411;&#38170;&#23450;&#24605;&#24819;&#65292;PAGER&#23558;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#21644;&#26032;&#39062;&#30340;&#12289;&#20114;&#34917;&#30340;&#19981;&#19968;&#33268;&#20998;&#25968;&#32479;&#19968;&#36215;&#26469;&#65292;&#23558;&#26679;&#26412;&#32452;&#32455;&#25104;&#19981;&#21516;&#30340;&#39118;&#38505;&#21306;&#22495;&#65292;&#20174;&#32780;&#25552;&#20379;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Safe deployment of AI models requires proactive detection of potential prediction failures to prevent costly errors. While failure detection in classification problems has received significant attention, characterizing failure modes in regression tasks is more complicated and less explored. Existing approaches rely on epistemic uncertainties or feature inconsistency with the training distribution to characterize model risk. However, we show that uncertainties are necessary but insufficient to accurately characterize failure, owing to the various sources of error. In this paper, we propose PAGER (Principled Analysis of Generalization Errors in Regressors), a framework to systematically detect and characterize failures in deep regression models. Built upon the recently proposed idea of anchoring in deep models, PAGER unifies both epistemic uncertainties and novel, complementary non-conformity scores to organize samples into different risk regimes, thereby providing a comprehensive analys
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08598</link><description>&lt;p&gt;
&#26680;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#24178;&#25200;&#21442;&#25968;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26631;&#37327;&#30446;&#26631;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#37319;&#29992;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#65289;&#26367;&#25442;&#26410;&#30693;&#24178;&#25200;&#21442;&#25968;&#26159;&#26041;&#20415;&#30340;&#65292;&#20294;&#22240;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#32780;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#36991;&#20813;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#30340;&#27425;&#20248;&#36873;&#25321;&#65292;&#29616;&#20195;&#26041;&#27861;&#20250;&#36827;&#34892;&#25554;&#20540;&#39044;&#20272;&#30340;&#21435;&#20559;&#24046;&#25805;&#20316;&#65292;&#22914;&#26377;&#30446;&#26631;&#26368;&#23567;&#25439;&#22833;&#20272;&#35745;&#65288;TMLE&#65289;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#31561;&#12290;&#29616;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#38656;&#35201;&#23558;&#30446;&#26631;&#21442;&#25968;&#30340;&#24433;&#21709;&#20989;&#25968;&#65288;IF&#65289;&#20316;&#20026;&#36755;&#20837;&#65292;&#28982;&#32780;&#65292;IF&#30340;&#25512;&#23548;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#25554;&#20837;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#65288;i&#65289;&#39640;&#25928;&#12289;&#65288;ii&#65289;&#19981;&#38656;&#35201;&#23454;&#29616;IF&#12289;&#65288;iii&#65289;&#21487;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.04848</link><description>&lt;p&gt;
&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21644;&#25913;&#36827;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Interpreting and Improving Diffusion Models Using the Euclidean Distance Function. (arXiv:2306.04848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#35299;&#37322;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#22120;&#12290;&#37319;&#26679;&#22120;&#34920;&#29616;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#33021;&#22815;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21435;&#22122;&#30452;&#35273;&#19978;&#19982;&#25237;&#24433;&#26377;&#20851;&#12290;&#20107;&#23454;&#19978;&#65292;&#22312;&#27969;&#24418;&#20551;&#35774;&#19979;&#65292;&#28155;&#21152;&#38543;&#26426;&#22122;&#22768;&#36817;&#20284;&#31561;&#20215;&#20110;&#27491;&#20132;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#23398;&#20064;&#21435;&#22122;&#36817;&#20284;&#20110;&#23398;&#20064;&#25237;&#24433;&#12290;&#26412;&#25991;&#21033;&#29992;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#23558;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#20989;&#25968;&#30340;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#21435;&#22122;&#22120;&#25237;&#24433;&#35823;&#24046;&#30340;&#31616;&#21333;&#20551;&#35774;&#65292;&#25552;&#20379;DDIM&#65288;Denoising Diffusion Implicit Models&#65289;&#37319;&#26679;&#22120;&#30340;&#31616;&#21333;&#25910;&#25947;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#29702;&#35770;&#32467;&#26524;&#30340;&#27934;&#35265;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23545;DDIM&#30340;&#20004;&#20010;&#31616;&#21333;&#20462;&#25913;&#30340;&#26032;&#37319;&#26679;&#22120;&#12290;&#20165;&#38656;&#35201;5-10&#20010;&#20989;&#25968;&#35780;&#20272;&#65292;&#25105;&#20204;&#30340;&#37319;&#26679;&#22120;&#23601;&#33021;&#22312;&#39044;&#35757;&#32451;&#30340;CIFAR-10&#21644;CelebA&#27169;&#22411;&#19978;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;FID&#24471;&#20998;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#19978;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising is intuitively related to projection. Indeed, under the manifold hypothesis, adding random noise is approximately equivalent to orthogonal perturbation. Hence, learning to denoise is approximately learning to project. In this paper, we use this observation to reinterpret denoising diffusion models as approximate gradient descent applied to the Euclidean distance function. We then provide straight-forward convergence analysis of the DDIM sampler under simple assumptions on the projection-error of the denoiser. Finally, we propose a new sampler based on two simple modifications to DDIM using insights from our theoretical results. In as few as 5-10 function evaluations, our sampler achieves state-of-the-art FID scores on pretrained CIFAR-10 and CelebA models and can generate high quality samples on latent diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#20984;&#32422;&#26463;&#38598;&#24773;&#20917;&#19979;&#30340;&#26354;&#32447;&#31354;&#38388;&#22312;&#32447;&#27979;&#22320;&#20984;&#20248;&#21270;&#30340;&#26080;&#25237;&#24433;&#31639;&#27861;&#65292;&#33719;&#24471;&#20102;&#27425;&#32447;&#24615;&#36951;&#25022;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.19349</link><description>&lt;p&gt;
&#20851;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#26080;&#25237;&#24433;&#22312;&#32447;&#23398;&#20064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Riemannian Projection-free Online Learning. (arXiv:2305.19349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#20984;&#32422;&#26463;&#38598;&#24773;&#20917;&#19979;&#30340;&#26354;&#32447;&#31354;&#38388;&#22312;&#32447;&#27979;&#22320;&#20984;&#20248;&#21270;&#30340;&#26080;&#25237;&#24433;&#31639;&#27861;&#65292;&#33719;&#24471;&#20102;&#27425;&#32447;&#24615;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25237;&#24433;&#25805;&#20316;&#26159;&#35768;&#22810;&#20248;&#21270;&#31639;&#27861;&#65288;&#20363;&#22914;&#22312;&#32447;&#26799;&#24230;&#19979;&#38477;[OGD]&#65289;&#20013;&#24378;&#21046;&#32422;&#26463;&#21644;&#23454;&#29616;&#26368;&#20248;&#36951;&#25022;&#36793;&#30028;&#25152;&#24517;&#38656;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#39640;&#32500;&#35774;&#32622;&#25110;&#20855;&#26377;&#30149;&#24577;&#32422;&#26463;&#38598;&#26102;&#65292;&#23427;&#20250;&#21463;&#21040;&#35745;&#31639;&#22797;&#26434;&#24230;&#38480;&#21046;&#12290;&#26080;&#25237;&#24433;&#31639;&#27861;&#36890;&#36807;&#29992;&#26356;&#26377;&#25928;&#30340;&#20248;&#21270;&#23376;&#31243;&#24207;&#21462;&#20195;&#25237;&#24433;&#39044;&#27979;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#36825;&#20123;&#26041;&#27861;&#20027;&#35201;&#22312;&#27431;&#20960;&#37324;&#24471;&#35774;&#32622;&#20013;&#24320;&#21457;&#65292;&#24182;&#19988;&#34429;&#28982;&#36234;&#26469;&#36234;&#22810;&#22320;&#20851;&#27880;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#65292;&#20294;&#22312;&#23581;&#35797;&#21033;&#29992;&#26080;&#25237;&#24433;&#24037;&#20855;&#26041;&#38754;&#22522;&#26412;&#19978;&#27809;&#26377;&#24037;&#20316;&#12290;&#19968;&#20010;&#26126;&#26174;&#30340;&#38382;&#39064;&#26159;&#65292;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#38750;&#24179;&#20961;&#30340;&#20223;&#23556;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#26354;&#32447;&#31354;&#38388;&#19978;&#36827;&#34892;&#22312;&#32447;&#27979;&#22320;&#20984;&#20248;&#21270;&#65292;&#20197;&#33719;&#24471;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#20445;&#35777;&#65306;&#24403;&#25105;&#20204;&#35775;&#38382;&#65288;a&#65289;&#26102;
&lt;/p&gt;
&lt;p&gt;
The projection operation is a critical component in a wide range of optimization algorithms, such as online gradient descent (OGD), for enforcing constraints and achieving optimal regret bounds. However, it suffers from computational complexity limitations in high-dimensional settings or when dealing with ill-conditioned constraint sets. Projection-free algorithms address this issue by replacing the projection oracle with more efficient optimization subroutines. But to date, these methods have been developed primarily in the Euclidean setting, and while there has been growing interest in optimization on Riemannian manifolds, there has been essentially no work in trying to utilize projection-free tools here. An apparent issue is that non-trivial affine functions are generally non-convex in such domains. In this paper, we present methods for obtaining sub-linear regret guarantees in online geodesically convex optimization on curved spaces for two scenarios: when we have access to (a) a s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#65292;&#20351;&#29992;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20855;&#26377;&#38750;&#24120;&#24555;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#23588;&#20854;&#26159;&#24403;&#26368;&#22823;&#29305;&#24449;&#20540;&#30456;&#21516;&#26102;&#12290;&#36864;&#21270;&#33258;&#30001;&#31639;&#27861;&#27604;Riemannian&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19978;&#21487;&#20197;&#20943;&#23569;29&#65285;&#12290;</title><link>http://arxiv.org/abs/2305.19206</link><description>&lt;p&gt;
&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#30340;&#26799;&#24230;&#19979;&#38477;&#20840;&#23616;&#24555;&#36895;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fast global convergence of gradient descent for low-rank matrix approximation. (arXiv:2305.19206v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19206
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#65292;&#20351;&#29992;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20855;&#26377;&#38750;&#24120;&#24555;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#23588;&#20854;&#26159;&#24403;&#26368;&#22823;&#29305;&#24449;&#20540;&#30456;&#21516;&#26102;&#12290;&#36864;&#21270;&#33258;&#30001;&#31639;&#27861;&#27604;Riemannian&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19978;&#21487;&#20197;&#20943;&#23569;29&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27714;&#35299;&#20302;&#31209;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#23545;&#20110;&#23545;&#31216;&#30697;&#38453;&#36924;&#36817;&#65292;&#26799;&#24230;&#19979;&#38477;&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#22312;&#20351;&#29992;&#38543;&#26426;&#23567;&#20540;&#21021;&#22987;&#21270;&#26102;&#20855;&#26377;&#38750;&#24120;&#24555;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#21363;&#20351;&#26159;&#22312;&#20013;&#31561;&#22823;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#24773;&#20917;&#19979;&#65292;&#21253;&#25324;&#20351;&#29992;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#29305;&#27530;&#24773;&#20917;&#22312;&#20869;&#65292;&#24403;&#26368;&#22823;&#29305;&#24449;&#20540;&#30456;&#21516;&#26102;&#65292;&#26799;&#24230;&#19979;&#38477;&#22312;&#24555;&#36895;&#25910;&#25947;&#26041;&#38754;&#20063;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#20998;&#26512;&#20197;&#35299;&#20915;&#38750;&#23545;&#31216;&#30697;&#38453;&#36924;&#36817;&#38382;&#39064;&#65292;&#24182;&#35843;&#26597;&#20102;&#19968;&#31181;&#19981;&#20381;&#36182;&#25237;&#24433;&#30340;&#29305;&#24449;&#31354;&#38388;&#35745;&#31639;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#24378;&#28872;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;&#29305;&#21035;&#22320;&#65292;&#36864;&#21270;&#33258;&#30001;&#31639;&#27861;&#20248;&#20110;&#23545;&#24212;&#30340;Riemannian&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23548;&#33268;&#36816;&#34892;&#26102;&#38388;&#26174;&#30528;&#20943;&#23569;&#20102;29&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates gradient descent for solving low-rank matrix approximation problems. We begin by establishing the local linear convergence of gradient descent for symmetric matrix approximation. Building on this result, we prove the rapid global convergence of gradient descent, particularly when initialized with small random values. Remarkably, we show that even with moderate random initialization, which includes small random initialization as a special case, gradient descent achieves fast global convergence in scenarios where the top eigenvalues are identical. Furthermore, we extend our analysis to address asymmetric matrix approximation problems and investigate the effectiveness of a retraction-free eigenspace computation method. Numerical experiments strongly support our theory. In particular, the retraction-free algorithm outperforms the corresponding Riemannian gradient descent method, resulting in a significant 29\% reduction in runtime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#23725;&#27491;&#21017;&#21270;&#30340;&#21435;&#22122;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20250;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2305.14689</link><description>&lt;p&gt;
&#22522;&#20110;&#23725;&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#21435;&#22122;&#38382;&#39064;&#30340;&#27424;&#21442;&#25968;&#21270;&#21452;&#35895;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Under-Parameterized Double Descent for Ridge Regularized Least Squares Denoising of Data on a Line. (arXiv:2305.14689v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#23725;&#27491;&#21017;&#21270;&#30340;&#21435;&#22122;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20250;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#35757;&#32451;&#25968;&#25454;&#28857;&#25968;&#12289;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#25968;&#21644;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#24050;&#26377;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21487;&#33021;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#65292;&#32780;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21017;&#26222;&#36941;&#23384;&#22312;&#26631;&#20934;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20363;&#23376;&#65292;&#21487;&#20197;&#35777;&#26126;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21487;&#20197;&#21457;&#29983;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;&#32771;&#34385;&#23884;&#20837;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#21435;&#22122;&#38382;&#39064;&#20013;&#30340;&#23725;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#31181;&#28176;&#36817;&#20934;&#30830;&#30340;&#24191;&#20041;&#35823;&#24046;&#20844;&#24335;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#26679;&#26412;&#21644;&#21442;&#25968;&#30340;&#21452;&#35895;&#25928;&#24212;&#65292;&#21452;&#23792;&#35895;&#20301;&#20110;&#25554;&#20540;&#28857;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#21306;&#22495;&#20043;&#38388;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#21452;&#35895;&#26354;&#32447;&#30340;&#39640;&#23792;&#23545;&#24212;&#20110;&#20272;&#35745;&#37327;&#30340;&#33539;&#25968;&#26354;&#32447;&#30340;&#39640;&#23792;&#12290;
&lt;/p&gt;
&lt;p&gt;
The relationship between the number of training data points, the number of parameters in a statistical model, and the generalization capabilities of the model has been widely studied. Previous work has shown that double descent can occur in the over-parameterized regime, and believe that the standard bias-variance trade-off holds in the under-parameterized regime. In this paper, we present a simple example that provably exhibits double descent in the under-parameterized regime. For simplicity, we look at the ridge regularized least squares denoising problem with data on a line embedded in high-dimension space. By deriving an asymptotically accurate formula for the generalization error, we observe sample-wise and parameter-wise double descent with the peak in the under-parameterized regime rather than at the interpolation point or in the over-parameterized regime.  Further, the peak of the sample-wise double descent curve corresponds to a peak in the curve for the norm of the estimator,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#35774;&#35745;&#21453;&#20107;&#23454;(MCD)&#26041;&#27861;&#65292;&#21487;&#24110;&#21161;&#35774;&#35745;&#24072;&#35782;&#21035;&#35774;&#35745;&#20462;&#25913;&#65292;&#25552;&#39640;&#21151;&#33021;&#24615;&#33021;&#12290;MCD&#36890;&#36807;&#25903;&#25345;&#22810;&#30446;&#26631;&#26597;&#35810;&#21644;&#35299;&#32806;&#21453;&#20107;&#23454;&#25628;&#32034;&#21644;&#37319;&#26679;&#36807;&#31243;&#26469;&#25552;&#39640;&#25928;&#29575;&#24182;&#25913;&#36827;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#25628;&#32034;&#26041;&#27861;&#65292;&#35777;&#26126;&#20854;&#22312;&#33258;&#34892;&#36710;&#35774;&#35745;&#26696;&#20363;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11308</link><description>&lt;p&gt;
&#35774;&#35745;&#20013;&#30340;&#21453;&#20107;&#23454;&#65306;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#35774;&#35745;&#24314;&#35758;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals for Design: A Model-Agnostic Method For Design Recommendations. (arXiv:2305.11308v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#35774;&#35745;&#21453;&#20107;&#23454;(MCD)&#26041;&#27861;&#65292;&#21487;&#24110;&#21161;&#35774;&#35745;&#24072;&#35782;&#21035;&#35774;&#35745;&#20462;&#25913;&#65292;&#25552;&#39640;&#21151;&#33021;&#24615;&#33021;&#12290;MCD&#36890;&#36807;&#25903;&#25345;&#22810;&#30446;&#26631;&#26597;&#35810;&#21644;&#35299;&#32806;&#21453;&#20107;&#23454;&#25628;&#32034;&#21644;&#37319;&#26679;&#36807;&#31243;&#26469;&#25552;&#39640;&#25928;&#29575;&#24182;&#25913;&#36827;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#25628;&#32034;&#26041;&#27861;&#65292;&#35777;&#26126;&#20854;&#22312;&#33258;&#34892;&#36710;&#35774;&#35745;&#26696;&#20363;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#35774;&#35745;&#38382;&#39064;&#21453;&#20107;&#23454;&#20248;&#21270;&#26041;&#27861;&#8212;&#8212;&#22810;&#30446;&#26631;&#35774;&#35745;&#21453;&#20107;&#23454;(MCD)&#12290;&#21453;&#20107;&#23454;&#26159;&#25351;&#21487;&#33021;&#23548;&#33268;&#19981;&#21516;&#20915;&#31574;&#25110;&#36873;&#25321;&#30340;&#20551;&#35774;&#24773;&#20917;&#12290;&#26412;&#25991;&#23558;&#21453;&#20107;&#23454;&#25628;&#32034;&#38382;&#39064;&#26694;&#26550;&#21270;&#20026;&#35774;&#35745;&#24314;&#35758;&#24037;&#20855;&#65292;&#21487;&#20197;&#24110;&#21161;&#35782;&#21035;&#23545;&#35774;&#35745;&#36827;&#34892;&#20462;&#25913;&#65292;&#20174;&#32780;&#25552;&#39640;&#21151;&#33021;&#24615;&#33021;&#12290;MCD&#36890;&#36807;&#25903;&#25345;&#22810;&#30446;&#26631;&#26597;&#35810;&#21644;&#35299;&#32806;&#21453;&#20107;&#23454;&#25628;&#32034;&#21644;&#37319;&#26679;&#36807;&#31243;&#26469;&#25552;&#39640;&#25928;&#29575;&#24182;&#20419;&#36827;&#30446;&#26631;&#26435;&#34913;&#21487;&#35270;&#21270;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#25628;&#32034;&#26041;&#27861;&#12290;&#26412;&#25991;&#20351;&#29992;&#20108;&#32500;&#27979;&#35797;&#26696;&#20363;&#35777;&#26126;&#20102;MCD&#30340;&#26680;&#24515;&#21151;&#33021;&#65292;&#28982;&#21518;&#36890;&#36807;&#19977;&#20010;&#33258;&#34892;&#36710;&#35774;&#35745;&#26696;&#20363;&#30740;&#31350;&#23637;&#31034;&#20102;MCD&#22312;&#23454;&#38469;&#35774;&#35745;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#31532;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;MCD&#22312;&#25512;&#33616;&#23545;&#26597;&#35810;&#35774;&#35745;&#36827;&#34892;&#20462;&#25913;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#33258;&#34892;&#36710;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Multi-Objective Counterfactuals for Design (MCD), a novel method for counterfactual optimization in design problems. Counterfactuals are hypothetical situations that can lead to a different decision or choice. In this paper, the authors frame the counterfactual search problem as a design recommendation tool that can help identify modifications to a design, leading to better functional performance. MCD improves upon existing counterfactual search methods by supporting multi-objective queries, which are crucial in design problems, and by decoupling the counterfactual search and sampling processes, thus enhancing efficiency and facilitating objective tradeoff visualization. The paper demonstrates MCD's core functionality using a two-dimensional test case, followed by three case studies of bicycle design that showcase MCD's effectiveness in real-world design problems. In the first case study, MCD excels at recommending modifications to query designs that can significantly enha
&lt;/p&gt;</description></item><item><title>NUBO&#26159;&#19968;&#20010;&#36879;&#26126;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20570;&#20195;&#29702;&#27169;&#22411;&#20197;&#21450;&#33719;&#21462;&#20989;&#25968;&#26469;&#25351;&#23548;&#36873;&#25321;&#20505;&#36873;&#28857;&#65292;&#19987;&#27880;&#20110;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20307;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.06709</link><description>&lt;p&gt;
NUBO&#65306;&#19968;&#20010;&#36879;&#26126;&#30340; Python &#21253;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
NUBO: A Transparent Python Package for Bayesian Optimisation. (arXiv:2305.06709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06709
&lt;/p&gt;
&lt;p&gt;
NUBO&#26159;&#19968;&#20010;&#36879;&#26126;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20570;&#20195;&#29702;&#27169;&#22411;&#20197;&#21450;&#33719;&#21462;&#20989;&#25968;&#26469;&#25351;&#23548;&#36873;&#25321;&#20505;&#36873;&#28857;&#65292;&#19987;&#27880;&#20110;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20307;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
NUBO&#65288;Newcastle University Bayesian Optimisation&#65289;&#26159;&#19968;&#20010;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#27604;&#22914;&#29289;&#29702;&#23454;&#39564;&#21644;&#35745;&#31639;&#26426;&#27169;&#25311;&#22120;&#12290;&#23427;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20570;&#20195;&#29702;&#27169;&#22411;&#12289;&#24182;&#36890;&#36807;&#33719;&#21462;&#20989;&#25968;&#26469;&#36873;&#25321;&#29992;&#20110;&#20840;&#23616;&#26368;&#20248;&#21270;&#30340;&#20505;&#36873;&#28857;&#12290;NUBO&#19987;&#27880;&#20110;&#36879;&#26126;&#24230;&#21644;&#29992;&#25143;&#20307;&#39564;&#65292;&#20197;&#20415;&#35753;&#19981;&#21516;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#26356;&#23481;&#26131;&#20351;&#29992;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
NUBO, short for Newcastle University Bayesian Optimisation, is a Bayesian optimisation framework for the optimisation of expensive-to-evaluate black-box functions, such as physical experiments and computer simulators. Bayesian optimisation is a cost-efficient optimisation strategy that uses surrogate modelling via Gaussian processes to represent an objective function and acquisition functions to guide the selection of candidate points to approximate the global optimum of the objective function. NUBO itself focuses on transparency and user experience to make Bayesian optimisation easily accessible to researchers from all disciplines. Clean and understandable code, precise references, and thorough documentation ensure transparency, while user experience is ensured by a modular and flexible design, easy-to-write syntax, and careful selection of Bayesian optimisation algorithms. NUBO allows users to tailor Bayesian optimisation to their specific problem by writing the optimisation loop the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#26631;&#23450;&#26041;&#27861;&#65292;&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#26469;&#28040;&#38500;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#40060;&#30524;&#22270;&#29255;&#20013;&#27178;&#21521;&#35282;&#24230;&#27495;&#20041;&#65292;&#21516;&#26102;&#24674;&#22797;&#26059;&#36716;&#21644;&#28040;&#38500;&#40060;&#30524;&#22833;&#30495;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20248;&#21270;&#30340;&#23545;&#35282;&#32447;&#28857;&#32531;&#35299;&#22270;&#20687;&#20013;&#32570;&#20047;&#28040;&#22833;&#28857;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2303.17166</link><description>&lt;p&gt;
&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#36827;&#34892;&#28145;&#24230;&#21333;&#24352;&#22270;&#29255;&#25668;&#20687;&#26426;&#26631;&#23450;&#65292;&#22312;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#22312;&#19981;&#27169;&#31946;&#30340;&#24773;&#20917;&#19979;&#36824;&#21407;&#40060;&#30524;&#22270;&#29255;
&lt;/p&gt;
&lt;p&gt;
Deep Single Image Camera Calibration by Heatmap Regression to Recover Fisheye Images Under ManhattanWorld AssumptionWithout Ambiguity. (arXiv:2303.17166v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#26631;&#23450;&#26041;&#27861;&#65292;&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#26469;&#28040;&#38500;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#40060;&#30524;&#22270;&#29255;&#20013;&#27178;&#21521;&#35282;&#24230;&#27495;&#20041;&#65292;&#21516;&#26102;&#24674;&#22797;&#26059;&#36716;&#21644;&#28040;&#38500;&#40060;&#30524;&#22833;&#30495;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20248;&#21270;&#30340;&#23545;&#35282;&#32447;&#28857;&#32531;&#35299;&#22270;&#20687;&#20013;&#32570;&#20047;&#28040;&#22833;&#28857;&#30340;&#24773;&#20917;&#65292;&#24182;&#22312;&#23454;&#39564;&#35777;&#26126;&#20854;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27491;&#20132;&#19990;&#30028;&#22352;&#26631;&#31995;&#20013;&#65292;&#26364;&#21704;&#39039;&#19990;&#30028;&#27839;&#30528;&#38271;&#26041;&#20307;&#24314;&#31569;&#29289;&#24191;&#27867;&#29992;&#20110;&#21508;&#31181;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#26364;&#21704;&#39039;&#19990;&#30028;&#38656;&#35201;&#25913;&#36827;&#65292;&#22240;&#20026;&#22270;&#20687;&#20013;&#30340;&#27178;&#21521;&#35282;&#24230;&#30340;&#21407;&#28857;&#26159;&#20219;&#24847;&#30340;&#65292;&#21363;&#20855;&#26377;&#22235;&#20493;&#36718;&#25442;&#23545;&#31216;&#30340;&#27178;&#21521;&#35282;&#24230;&#30340;&#27495;&#20041;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25668;&#20687;&#26426;&#21644;&#34892;&#39542;&#26041;&#21521;&#30340;&#36947;&#36335;&#26041;&#21521;&#30340;&#24179;&#35282;&#23450;&#20041;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#30340;&#26631;&#23450;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#28909;&#24230;&#22270;&#22238;&#24402;&#26469;&#28040;&#38500;&#27495;&#20041;&#65292;&#31867;&#20284;&#20110;&#23039;&#24577;&#20272;&#35745;&#20851;&#38190;&#28857;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25105;&#20204;&#30340;&#20004;&#20010;&#20998;&#25903;&#32593;&#32476;&#24674;&#22797;&#26059;&#36716;&#24182;&#20174;&#19968;&#33324;&#22330;&#26223;&#22270;&#20687;&#20013;&#28040;&#38500;&#40060;&#30524;&#22833;&#30495;&#12290;&#20026;&#20102;&#32531;&#35299;&#22270;&#20687;&#20013;&#32570;&#20047;&#28040;&#22833;&#28857;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20855;&#26377;&#31354;&#38388;&#22343;&#21248;&#24615;&#26368;&#20339;&#30340;&#23545;&#35282;&#32447;&#28857;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26364;&#21704;&#39039;&#19990;&#30028;&#20551;&#35774;&#19979;&#23545;&#40060;&#30524;&#22270;&#20687;&#30340;&#28145;&#24230;&#21333;&#24352;&#22270;&#29255;&#25668;&#20687;&#26426;&#26631;&#23450;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#27809;&#26377;&#27495;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
In orthogonal world coordinates, a Manhattan world lying along cuboid buildings is widely useful for various computer vision tasks. However, the Manhattan world has much room for improvement because the origin of pan angles from an image is arbitrary, that is, four-fold rotational symmetric ambiguity of pan angles. To address this problem, we propose a definition for the pan-angle origin based on the directions of the roads with respect to a camera and the direction of travel. We propose a learning-based calibration method that uses heatmap regression to remove the ambiguity by each direction of labeled image coordinates, similar to pose estimation keypoints. Simultaneously, our two-branched network recovers the rotation and removes fisheye distortion from a general scene image. To alleviate the lack of vanishing points in images, we introduce auxiliary diagonal points that have the optimal 3D arrangement of spatial uniformity. Extensive experiments demonstrated that our method outperf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09826</link><description>&lt;p&gt;
&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#23398;&#20064;&#20013;&#30340;&#34920;&#36798;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Expressivity of Persistent Homology in Graph Learning. (arXiv:2302.09826v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09826
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#25345;&#32493;&#21516;&#35843;&#25216;&#26415;&#22312;&#25429;&#25417;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;&#38271;&#31243;&#22270;&#24615;&#36136;&#26041;&#38754;&#34920;&#29616;&#20986;&#30340;&#39640;&#34920;&#36798;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#35745;&#31639;&#25299;&#25169;&#23398;&#20013;&#30340;&#19968;&#39033;&#25216;&#26415;&#65292;&#25345;&#32493;&#21516;&#35843;&#23637;&#29616;&#20986;&#22312;&#22270;&#20998;&#31867;&#26041;&#38754;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#23427;&#33021;&#22815;&#36890;&#36807;&#39640;&#38454;&#25299;&#25169;&#29305;&#24449;&#8212;&#8212;&#22914;&#20219;&#24847;&#38271;&#24230;&#30340;&#29615;&#8212;&#8212;&#20197;&#21450;&#22810;&#23610;&#24230;&#25299;&#25169;&#25551;&#36848;&#31526;&#25429;&#25417;&#38271;&#31243;&#22270;&#24615;&#36136;&#65292;&#20174;&#32780;&#25552;&#39640;&#23545;&#20855;&#26377;&#26174;&#33879;&#25299;&#25169;&#32467;&#26500;&#30340;&#25968;&#25454;&#38598;&#8212;&#8212;&#22914;&#20998;&#23376;&#8212;&#8212;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#25345;&#32493;&#21516;&#35843;&#30340;&#29702;&#35770;&#24615;&#36136;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#23578;&#26410;&#24471;&#21040;&#27491;&#24335;&#35780;&#20272;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#25552;&#20379;&#25345;&#32493;&#21516;&#35843;&#22312;&#22270;&#20013;&#30340;&#31616;&#35201;&#20171;&#32461;&#20197;&#21450;&#23545;&#20854;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#34920;&#36798;&#24615;&#36827;&#34892;&#29702;&#35770;&#35752;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#24357;&#21512;&#35745;&#31639;&#25299;&#25169;&#23398;&#21644;&#22270;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology, a technique from computational topology, has recently shown strong empirical performance in the context of graph classification. Being able to capture long range graph properties via higher-order topological features, such as cycles of arbitrary length, in combination with multi-scale topological descriptors, has improved predictive performance for data sets with prominent topological structures, such as molecules. At the same time, the theoretical properties of persistent homology have not been formally assessed in this context. This paper intends to bridge the gap between computational topology and graph machine learning by providing a brief introduction to persistent homology in the context of graphs, as well as a theoretical discussion and empirical analysis of its expressivity for graph learning tasks.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#21704;&#23494;&#39039;&#27969;&#24418;&#20013;&#35782;&#21035;&#20986;&#26222;&#36941;&#30340;&#31070;&#32463;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#23545;&#19981;&#21516;&#29289;&#29702;&#31995;&#32479;&#30340;&#24555;&#36895;&#36866;&#24212;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2212.01168</link><description>&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;&#22312;&#21704;&#23494;&#39039;&#27969;&#24418;&#20013;&#35782;&#21035;&#26222;&#36941;&#30340;&#31070;&#32463;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Identifying Generalized Neural Representation Across Hamiltonian Manifolds via Meta-learning. (arXiv:2212.01168v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.01168
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#21704;&#23494;&#39039;&#27969;&#24418;&#20013;&#35782;&#21035;&#20986;&#26222;&#36941;&#30340;&#31070;&#32463;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#23545;&#19981;&#21516;&#29289;&#29702;&#31995;&#32479;&#30340;&#24555;&#36895;&#36866;&#24212;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#29289;&#29702;&#23398;&#20013;&#28145;&#24230;&#23398;&#20064;&#30340;&#36827;&#23637;&#38598;&#20013;&#22312;&#36890;&#36807;&#23558;&#29289;&#29702;&#20808;&#39564;&#25110;&#24402;&#32435;&#20559;&#35265;&#24341;&#20837;&#31070;&#32463;&#32593;&#32476;&#26469;&#21457;&#29616;&#30446;&#26631;&#31995;&#32479;&#30340;&#20849;&#20139;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#29305;&#23450;&#20110;&#31995;&#32479;&#65292;&#19981;&#20801;&#35768;&#36731;&#26494;&#36866;&#24212;&#30001;&#19981;&#21516;&#29289;&#29702;&#27861;&#21017;&#39537;&#21160;&#30340;&#26032;&#29289;&#29702;&#31995;&#32479;&#12290;&#20363;&#22914;&#65292;&#35757;&#32451;&#20110;&#36136;&#28857;&#24377;&#31783;&#31995;&#32479;&#30340;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#20934;&#30830;&#39044;&#27979;&#21452;&#20307;&#31995;&#32479;&#25110;&#20219;&#20309;&#20855;&#26377;&#19981;&#21516;&#29289;&#29702;&#27861;&#21017;&#30340;&#31995;&#32479;&#30340;&#34892;&#20026;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#25105;&#20204;&#30340;&#31995;&#32479;&#65292;&#24182;&#37319;&#29992;&#20803;&#23398;&#20064;&#31639;&#27861;&#20351;&#27169;&#22411;&#22312;&#19968;&#31995;&#21015;&#20219;&#21153;&#20013;&#31215;&#32047;&#32463;&#39564;&#65292;&#24182;&#20351;&#20854;&#36866;&#24212;&#26032;&#30340;&#29289;&#29702;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#23398;&#20064;&#36328;&#21508;&#31181;&#21704;&#23494;&#39039;&#27969;&#24418;&#30340;&#36890;&#29992;&#34920;&#31034;&#65292;&#36825;&#26159;&#21704;&#23494;&#39039;&#31995;&#32479;&#25968;&#25454;&#20998;&#24067;&#30340;&#20849;&#21516;&#29305;&#24449;&#12290;&#25105;&#20204;&#20351;&#29992;&#30001;&#19981;&#21516;&#31995;&#32479;&#32452;&#25104;&#30340;&#25968;&#25454;&#38598;&#35757;&#32451;&#27169;&#22411;&#65292;&#27599;&#20010;&#31995;&#32479;&#37117;&#26377;&#20854;&#33258;&#36523;&#22266;&#26377;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#35780;&#20272;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in deep learning for physics have focused on discovering shared representations of target systems by incorporating physics priors or inductive biases into neural networks. However, these approaches are system-specific and do not allow for easy adaptation to new physical systems governed by different laws. For example, a neural network trained on a mass-spring system cannot accurately predict the behavior of a two-body system or any other system with different governing physics. In this work, we model our system with a graph neural network and employ a meta-learning algorithm to enable the model to gain experience over a distribution of tasks and make it adapt to new physics. Our approach aims to learn a general representation across the various Hamiltonian manifolds, which is a common feature of the data distribution of Hamiltonian systems. We train our model using a dataset of different physical systems, each governed by its own inherent dynamics, and evaluate its 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;GFlowNets&#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#32852;&#21512;&#23398;&#20064;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#26426;&#21046;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#20063;&#33021;&#19982;&#20960;&#20010;&#22522;&#32447;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2211.02763</link><description>&lt;p&gt;
GFlowNets&#19982;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#22240;&#26524;&#32467;&#26500;&#21644;&#26426;&#21046;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian learning of Causal Structure and Mechanisms with GFlowNets and Variational Bayes. (arXiv:2211.02763v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;GFlowNets&#21644;&#21464;&#20998;&#36125;&#21494;&#26031;&#32852;&#21512;&#23398;&#20064;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#26426;&#21046;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#20063;&#33021;&#19982;&#20960;&#20010;&#22522;&#32447;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#26088;&#22312;&#23398;&#20064;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#19978;&#30340;&#21518;&#39564;&#20998;&#24067;&#21644;&#23450;&#20041;&#29238;&#21464;&#37327;&#21644;&#23376;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26426;&#21046;&#12290;&#26412;&#25991;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#32852;&#21512;&#23398;&#20064;&#22240;&#26524;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#26426;&#21046;&#65292;&#31216;&#20026;&#21464;&#20998;&#36125;&#21494;&#26031;DAG-GFlowNet&#65288;VBG&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;GFlowNets&#25193;&#23637;&#20102;&#36125;&#21494;&#26031;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#19981;&#20165;&#23398;&#20064;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#36824;&#23398;&#20064;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;VBG&#22312;&#24314;&#27169;DAG&#21644;&#26426;&#21046;&#30340;&#21518;&#39564;&#20998;&#24067;&#26102;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#38750;&#32447;&#24615;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#32780;&#19988;&#36824;&#33021;&#19982;&#20960;&#20010;&#22522;&#32447;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian causal structure learning aims to learn a posterior distribution over directed acyclic graphs (DAGs), and the mechanisms that define the relationship between parent and child variables. By taking a Bayesian approach, it is possible to reason about the uncertainty of the causal model. The notion of modelling the uncertainty over models is particularly crucial for causal structure learning since the model could be unidentifiable when given only a finite amount of observational data. In this paper, we introduce a novel method to jointly learn the structure and mechanisms of the causal model using Variational Bayes, which we call Variational Bayes-DAG-GFlowNet (VBG). We extend the method of Bayesian causal structure learning using GFlowNets to learn not only the posterior distribution over the structure, but also the parameters of a linear-Gaussian model. Our results on simulated data suggest that VBG is competitive against several baselines in modelling the posterior over DAGs an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#20195;&#29702;&#20351;&#29992;&#22797;&#26434;&#30340;&#8220;&#40657;&#30418;&#8221;&#39044;&#27979;&#20989;&#25968;&#36827;&#34892;&#20915;&#31574;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#31639;&#27861;&#20915;&#31574;&#36827;&#34892;&#26368;&#20248;&#35843;&#25511;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#38480;&#21046;&#20195;&#29702;&#20351;&#29992;&#36879;&#26126;&#24230;&#36275;&#22815;&#39640;&#30340;&#39044;&#27979;&#20989;&#25968;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#38024;&#23545;&#28608;&#21169;&#20559;&#24046;&#28304;&#22836;&#30340;&#30446;&#26631;&#21270;&#24037;&#20855;&#21487;&#20197;&#25552;&#20379;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#25913;&#21892;&#31119;&#21033;&#12290;</title><link>http://arxiv.org/abs/2110.03443</link><description>&lt;p&gt;
&#25581;&#24320;&#40657;&#30418;&#23376;&#65306;&#35843;&#25511;&#31639;&#27861;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Unpacking the Black Box: Regulating Algorithmic Decisions. (arXiv:2110.03443v2 [econ.GN] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#20195;&#29702;&#20351;&#29992;&#22797;&#26434;&#30340;&#8220;&#40657;&#30418;&#8221;&#39044;&#27979;&#20989;&#25968;&#36827;&#34892;&#20915;&#31574;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#31639;&#27861;&#20915;&#31574;&#36827;&#34892;&#26368;&#20248;&#35843;&#25511;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#38480;&#21046;&#20195;&#29702;&#20351;&#29992;&#36879;&#26126;&#24230;&#36275;&#22815;&#39640;&#30340;&#39044;&#27979;&#20989;&#25968;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#38024;&#23545;&#28608;&#21169;&#20559;&#24046;&#28304;&#22836;&#30340;&#30446;&#26631;&#21270;&#24037;&#20855;&#21487;&#20197;&#25552;&#20379;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#25913;&#21892;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#19968;&#20010;&#20195;&#29702;&#20351;&#29992;&#22797;&#26434;&#30340;&#8220;&#40657;&#30418;&#8221;&#39044;&#27979;&#20989;&#25968;&#36827;&#34892;&#20915;&#31574;&#65288;&#22914;&#36151;&#27454;&#12289;&#21307;&#30103;&#27979;&#35797;&#25110;&#25307;&#32856;&#65289;&#19988;&#22996;&#25176;&#20154;&#22312;&#20102;&#35299;&#20195;&#29702;&#30340;&#40657;&#30418;&#27169;&#22411;&#26041;&#38754;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#22320;&#35843;&#25511;&#39044;&#27979;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#35825;&#23548;&#19981;&#36275;&#65292;&#19988;&#26368;&#20248;&#39044;&#27979;&#20989;&#25968;&#36275;&#22815;&#22797;&#26434;&#65292;&#23558;&#20195;&#29702;&#38480;&#21046;&#22312;&#36275;&#22815;&#36879;&#26126;&#30340;&#39044;&#27979;&#20989;&#25968;&#20013;&#26159;&#20302;&#25928;&#30340;&#12290;&#31639;&#27861;&#23457;&#35745;&#26377;&#21161;&#20110;&#25552;&#39640;&#31119;&#21033;&#65292;&#20294;&#20854;&#25910;&#30410;&#21462;&#20915;&#20110;&#23457;&#35745;&#24037;&#20855;&#30340;&#35774;&#35745;&#12290;&#35768;&#22810;&#35299;&#37322;&#24037;&#20855;&#20542;&#21521;&#20110;&#26368;&#23567;&#21270;&#25972;&#20307;&#20449;&#24687;&#25439;&#22833;&#65292;&#20294;&#36825;&#36890;&#24120;&#26159;&#20302;&#25928;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#38598;&#20013;&#20110;&#35299;&#37322;&#39044;&#27979;&#20989;&#25968;&#30340;&#24179;&#22343;&#34892;&#20026;&#12290;&#38024;&#23545;&#24615;&#30340;&#24037;&#20855;&#65292;&#22914;&#38024;&#23545;&#28608;&#21169;&#20559;&#24046;&#28304;&#22836;&#65288;&#22914;&#36807;&#22810;&#30340;&#20551;&#38451;&#24615;&#25110;&#31181;&#26063;&#24046;&#24322;&#65289;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#25552;&#20379;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#29702;&#35770;&#30340;&#23454;&#35777;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how to optimally regulate prediction algorithms in a world where an agent uses complex 'black-box' prediction functions to make decisions such as lending, medical testing, or hiring, and where a principal is limited in how much she can learn about the agent's black-box model. We show that limiting agents to prediction functions that are simple enough to be fully transparent is inefficient as long as the misalignment is limited and first-best prediction functions are sufficiently complex. Algorithmic audits can improve welfare, but the gains depend on the design of the audit tools. Tools that focus on minimizing overall information loss, the focus of many explainer tools, will generally be inefficient since they focus on explaining the average behavior of the prediction function. Targeted tools that focus on the source of incentive misalignment, e.g., excess false positives or racial disparities, can provide second-best solutions. We provide empirical support for our theoretical
&lt;/p&gt;</description></item></channel></rss>