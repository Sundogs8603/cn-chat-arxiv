<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#20013;&#27602;&#25915;&#20987;&#30340;&#32858;&#21512;&#38450;&#24481;&#31574;&#30053;&#30340;&#23454;&#36341;&#26041;&#38754;&#65292;&#24182;&#38024;&#23545;Deep Partition Aggregation&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#25928;&#29575;&#12289;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22522;&#20110;&#32553;&#25918;&#22522;&#30784;&#27169;&#22411;&#30340;&#26041;&#27861;&#33021;&#22815;&#25552;&#39640;&#32858;&#21512;&#38450;&#24481;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.16415</link><description>&lt;p&gt;
&#20851;&#20110;&#25968;&#25454;&#20013;&#27602;&#25915;&#20987;&#30340;&#32858;&#21512;&#38450;&#24481;&#30340;&#23454;&#36341;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;
On Practical Aspects of Aggregation Defenses against Data Poisoning Attacks. (arXiv:2306.16415v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16415
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#20013;&#27602;&#25915;&#20987;&#30340;&#32858;&#21512;&#38450;&#24481;&#31574;&#30053;&#30340;&#23454;&#36341;&#26041;&#38754;&#65292;&#24182;&#38024;&#23545;Deep Partition Aggregation&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#25928;&#29575;&#12289;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#22522;&#20110;&#32553;&#25918;&#22522;&#30784;&#27169;&#22411;&#30340;&#26041;&#27861;&#33021;&#22815;&#25552;&#39640;&#32858;&#21512;&#38450;&#24481;&#30340;&#35757;&#32451;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#26469;&#35828;&#65292;&#25968;&#25454;&#30340;&#22686;&#21152;&#19981;&#20165;&#24102;&#26469;&#26426;&#20250;&#65292;&#20063;&#24102;&#26469;&#39118;&#38505;&#65292;&#22240;&#20026;&#24694;&#24847;&#35757;&#32451;&#26679;&#26412;&#21487;&#20197;&#25805;&#32437;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#12290;&#36825;&#31181;&#25915;&#20987;&#34987;&#31216;&#20026;&#25968;&#25454;&#20013;&#27602;&#12290;&#36817;&#26399;&#23545;&#25239;&#25968;&#25454;&#20013;&#27602;&#30340;&#38450;&#24481;&#31574;&#30053;&#30340;&#36827;&#23637;&#31361;&#20986;&#20102;&#32858;&#21512;&#26041;&#26696;&#22312;&#23454;&#29616;&#35748;&#35777;&#20013;&#27602;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#23454;&#36341;&#24433;&#21709;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;Deep Partition Aggregation&#65292;&#19968;&#31181;&#20195;&#34920;&#24615;&#30340;&#32858;&#21512;&#38450;&#24481;&#65292;&#24182;&#35780;&#20272;&#20102;&#20854;&#23454;&#38469;&#26041;&#38754;&#65292;&#21253;&#25324;&#25928;&#29575;&#12289;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#35780;&#20272;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#34987;&#35843;&#25972;&#21040;64&#215;64&#20998;&#36776;&#29575;&#30340;ImageNet&#25968;&#25454;&#38598;&#65292;&#20197;&#20415;&#22312;&#27604;&#20197;&#21069;&#26356;&#22823;&#30340;&#35268;&#27169;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#23454;&#29992;&#30340;&#22522;&#20110;&#32553;&#25918;&#22522;&#30784;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#23427;&#25913;&#21892;&#20102;&#32858;&#21512;&#38450;&#24481;&#30340;&#35757;&#32451;&#21644;&#25512;&#29702;&#25928;&#29575;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25903;&#25345;&#25968;&#25454;&#21078;&#20998;&#30340;&#23454;&#35777;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing access to data poses both opportunities and risks in deep learning, as one can manipulate the behaviors of deep learning models with malicious training samples. Such attacks are known as data poisoning. Recent advances in defense strategies against data poisoning have highlighted the effectiveness of aggregation schemes in achieving state-of-the-art results in certified poisoning robustness. However, the practical implications of these approaches remain unclear. Here we focus on Deep Partition Aggregation, a representative aggregation defense, and assess its practical aspects, including efficiency, performance, and robustness. For evaluations, we use ImageNet resized to a resolution of 64 by 64 to enable evaluations at a larger scale than previous ones. Firstly, we demonstrate a simple yet practical approach to scaling base models, which improves the efficiency of training and inference for aggregation defenses. Secondly, we provide empirical evidence supporting the data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#65292;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.16406</link><description>&lt;p&gt;
&#36890;&#29992;&#24418;&#24335;&#19979;&#30340;&#39640;&#25928;&#19988;&#22810;&#37325;&#31283;&#20581;&#30340;&#39118;&#38505;&#20272;&#35745;&#26041;&#27861;&#22312;&#25968;&#25454;&#36716;&#31227;&#20013;
&lt;/p&gt;
&lt;p&gt;
Efficient and Multiply Robust Risk Estimation under General Forms of Dataset Shift. (arXiv:2306.16406v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#65292;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#65292;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#32463;&#24120;&#38754;&#20020;&#26469;&#33258;&#24863;&#20852;&#36259;&#24635;&#20307;&#30340;&#26377;&#38480;&#25968;&#25454;&#30340;&#25361;&#25112;&#12290;&#19968;&#31181;&#35299;&#20915;&#26041;&#27861;&#26159;&#21033;&#29992;&#26469;&#33258;&#36741;&#21161;&#28304;&#24635;&#20307;&#30340;&#25968;&#25454;&#65292;&#36825;&#20123;&#25968;&#25454;&#19982;&#30446;&#26631;&#39046;&#22495;&#30340;&#26576;&#20123;&#26465;&#20214;&#20998;&#24067;&#30456;&#21516;&#25110;&#20197;&#20854;&#20182;&#26041;&#24335;&#30456;&#36830;&#12290;&#21033;&#29992;&#36825;&#31181;"&#25968;&#25454;&#36716;&#31227;"&#26465;&#20214;&#30340;&#25216;&#26415;&#34987;&#31216;&#20026;"&#39046;&#22495;&#36866;&#24212;"&#25110;"&#36801;&#31227;&#23398;&#20064;"&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#20851;&#20110;&#25968;&#25454;&#36716;&#31227;&#30340;&#25991;&#29486;&#65292;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#36741;&#21161;&#24635;&#20307;&#26469;&#25552;&#39640;&#30446;&#26631;&#24635;&#20307;&#19978;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#39118;&#38505;&#35780;&#20272;&#30340;&#20934;&#30830;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#19979;&#39640;&#25928;&#20272;&#35745;&#30446;&#26631;&#24635;&#20307;&#39118;&#38505;&#30340;&#19968;&#33324;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#36890;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#26465;&#20214;&#65292;&#20854;&#20013;&#21253;&#25324;&#19977;&#31181;&#27969;&#34892;&#26465;&#20214;&#8212;&#8212;&#21327;&#21464;&#37327;&#12289;&#26631;&#31614;&#21644;&#27010;&#24565;&#36716;&#31227;&#8212;&#8212;&#20316;&#20026;&#29305;&#20363;&#12290;&#25105;&#20204;&#20801;&#35768;&#37096;&#20998;&#38750;&#37325;&#21472;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical machine learning methods often face the challenge of limited data available from the population of interest. One remedy is to leverage data from auxiliary source populations, which share some conditional distributions or are linked in other ways with the target domain. Techniques leveraging such \emph{dataset shift} conditions are known as \emph{domain adaptation} or \emph{transfer learning}. Despite extensive literature on dataset shift, limited works address how to efficiently use the auxiliary populations to improve the accuracy of risk evaluation for a given machine learning task in the target population.  In this paper, we study the general problem of efficiently estimating target population risk under various dataset shift conditions, leveraging semiparametric efficiency theory. We consider a general class of dataset shift conditions, which includes three popular conditions -- covariate, label and concept shift -- as special cases. We allow for partially non-overlappi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#36125;&#32034;&#22827;&#36807;&#31243;&#25512;&#24191;&#21040;&#26102;&#31354;&#39046;&#22495;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#26102;&#31354;&#37325;&#24314;&#12290;&#36890;&#36807;&#26367;&#25442;&#38543;&#26426;&#31995;&#25968;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20445;&#25345;&#36793;&#32536;&#29305;&#24449;&#24182;&#27169;&#25311;&#21160;&#24577;&#21464;&#21270;&#22270;&#20687;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16378</link><description>&lt;p&gt;
&#36125;&#32034;&#22827;&#20808;&#39564;&#22312;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#26102;&#31354;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal Besov Priors for Bayesian Inverse Problems. (arXiv:2306.16378v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;&#36125;&#32034;&#22827;&#36807;&#31243;&#25512;&#24191;&#21040;&#26102;&#31354;&#39046;&#22495;&#65292;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#20013;&#30340;&#26102;&#31354;&#37325;&#24314;&#12290;&#36890;&#36807;&#26367;&#25442;&#38543;&#26426;&#31995;&#25968;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20445;&#25345;&#36793;&#32536;&#29305;&#24449;&#24182;&#27169;&#25311;&#21160;&#24577;&#21464;&#21270;&#22270;&#20687;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31185;&#23398;&#25216;&#26415;&#30340;&#24555;&#36895;&#21457;&#23637;&#20419;&#20351;&#23545;&#25429;&#25417;&#25968;&#25454;&#29305;&#24449;&#65288;&#22914;&#31361;&#21464;&#25110;&#26126;&#26174;&#23545;&#27604;&#24230;&#65289;&#30340;&#36866;&#24403;&#32479;&#35745;&#24037;&#20855;&#30340;&#38656;&#27714;&#12290;&#35768;&#22810;&#25968;&#25454;&#31185;&#23398;&#24212;&#29992;&#38656;&#35201;&#20174;&#20855;&#26377;&#19981;&#36830;&#32493;&#24615;&#25110;&#22855;&#24322;&#24615;&#30340;&#26102;&#38388;&#30456;&#20851;&#23545;&#35937;&#24207;&#21015;&#20013;&#36827;&#34892;&#26102;&#31354;&#37325;&#24314;&#65292;&#22914;&#24102;&#26377;&#36793;&#32536;&#30340;&#21160;&#24577;&#35745;&#31639;&#26426;&#26029;&#23618;&#24433;&#20687;&#65288;CT&#65289;&#22270;&#20687;&#12290;&#20256;&#32479;&#30340;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#20196;&#20154;&#28385;&#24847;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#23427;&#20204;&#24448;&#24448;&#25552;&#20379;&#36807;&#24230;&#24179;&#28369;&#30340;&#20808;&#39564;&#20505;&#36873;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#38543;&#26426;&#31995;&#25968;&#30340;&#23567;&#27874;&#23637;&#24320;&#23450;&#20041;&#30340;&#36125;&#32034;&#22827;&#36807;&#31243;&#65288;BP&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#36825;&#31867;&#36125;&#21494;&#26031;&#36870;&#38382;&#39064;&#30340;&#26356;&#21512;&#36866;&#30340;&#20808;&#39564;&#12290;BP&#22312;&#25104;&#20687;&#20998;&#26512;&#20013;&#34920;&#29616;&#20986;&#20248;&#20110;GP&#30340;&#24615;&#33021;&#65292;&#33021;&#22815;&#20135;&#29983;&#20445;&#30041;&#36793;&#32536;&#29305;&#24449;&#30340;&#37325;&#24314;&#32467;&#26524;&#65292;&#20294;&#27809;&#26377;&#33258;&#21160;&#22320;&#32435;&#20837;&#21160;&#24577;&#21464;&#21270;&#22270;&#20687;&#20013;&#30340;&#26102;&#38388;&#30456;&#20851;&#24615;&#12290;&#26412;&#25991;&#23558;BP&#25512;&#24191;&#21040;&#26102;&#31354;&#39046;&#22495;&#65288;STBP&#65289;&#65292;&#36890;&#36807;&#22312;&#23567;&#27874;&#23637;&#24320;&#20013;&#26367;&#25442;&#38543;&#26426;&#31995;&#25968;&#65292;&#23454;&#29616;&#20102;&#26102;&#31354;&#30456;&#20851;&#24615;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fast development in science and technology has driven the need for proper statistical tools to capture special data features such as abrupt changes or sharp contrast. Many applications in the data science seek spatiotemporal reconstruction from a sequence of time-dependent objects with discontinuity or singularity, e.g. dynamic computerized tomography (CT) images with edges. Traditional methods based on Gaussian processes (GP) may not provide satisfactory solutions since they tend to offer over-smooth prior candidates. Recently, Besov process (BP) defined by wavelet expansions with random coefficients has been proposed as a more appropriate prior for this type of Bayesian inverse problems. While BP outperforms GP in imaging analysis to produce edge-preserving reconstructions, it does not automatically incorporate temporal correlation inherited in the dynamically changing images. In this paper, we generalize BP to the spatiotemporal domain (STBP) by replacing the random coefficients in 
&lt;/p&gt;</description></item><item><title>cuSLINK&#26159;&#19968;&#31181;&#22312;GPU&#19978;&#23454;&#29616;&#30340;&#21333;&#38142;&#25509;&#32858;&#31867;&#31639;&#27861;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#26500;&#24314;&#27169;&#22359;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25968;&#25454;&#25366;&#25496;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.16354</link><description>&lt;p&gt;
cuSLINK: GPU&#19978;&#30340;&#21333;&#38142;&#25509;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
cuSLINK: Single-linkage Agglomerative Clustering on the GPU. (arXiv:2306.16354v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16354
&lt;/p&gt;
&lt;p&gt;
cuSLINK&#26159;&#19968;&#31181;&#22312;GPU&#19978;&#23454;&#29616;&#30340;&#21333;&#38142;&#25509;&#32858;&#31867;&#31639;&#27861;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#26500;&#24314;&#27169;&#22359;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25968;&#25454;&#25366;&#25496;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;cuSLINK&#65292;&#35813;&#31639;&#27861;&#26159;&#23545;GPU&#19978;&#30340;SLINK&#31639;&#27861;&#30340;&#19968;&#31181;&#26032;&#22411;&#21644;&#26368;&#20808;&#36827;&#30340;&#25913;&#36827;&#65292;&#23427;&#21482;&#38656;&#35201;$O(Nk)$&#30340;&#31354;&#38388;&#65292;&#24182;&#20351;&#29992;&#21442;&#25968;$k$&#26469;&#26435;&#34913;&#31354;&#38388;&#21644;&#26102;&#38388;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#39062;&#19988;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#26500;&#24314;&#27169;&#22359;&#65292;&#36825;&#20123;&#26500;&#24314;&#27169;&#22359;&#21253;&#25324;&#38024;&#23545;$k$-NN&#22270;&#26500;&#24314;&#12289;&#29983;&#25104;&#26641;&#21644;&#26641;&#29366;&#22270;&#32858;&#31867;&#30340;&#39640;&#24230;&#20248;&#21270;&#30340;&#35745;&#31639;&#27169;&#24335;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#36825;&#20123;&#22522;&#26412;&#27169;&#22359;&#22312;GPU&#19978;&#20840;&#38754;&#23454;&#29616;cuSLINK&#65292;&#36827;&#19968;&#27493;&#20351;&#24471;&#21407;&#26412;&#38590;&#20197;&#22788;&#29702;&#30340;&#24191;&#27867;&#30340;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#25366;&#25496;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#25104;&#20026;&#21487;&#33021;&#12290;&#38500;&#20102;&#22312;&#27969;&#34892;&#30340;HDBSCAN&#31639;&#27861;&#20013;&#26159;&#20027;&#35201;&#30340;&#35745;&#31639;&#29942;&#39048;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;cuSLINK&#31639;&#27861;&#30340;&#20840;&#38754;&#24433;&#21709;&#36824;&#28085;&#30422;&#20102;&#19968;&#31995;&#21015;&#37325;&#35201;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#31038;&#20132;&#32593;&#32476;&#21644;&#35745;&#31639;&#26426;&#32593;&#32476;&#20013;&#30340;&#32858;&#31867;&#20998;&#26512;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#12290;&#29992;&#25143;&#21487;&#20197;&#22312;https://docs.rapids.ai/api/cuml/latest/api/#agg&#33719;&#21462;cuSLINK&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose cuSLINK, a novel and state-of-the-art reformulation of the SLINK algorithm on the GPU which requires only $O(Nk)$ space and uses a parameter $k$ to trade off space and time. We also propose a set of novel and reusable building blocks that compose cuSLINK. These building blocks include highly optimized computational patterns for $k$-NN graph construction, spanning trees, and dendrogram cluster extraction. We show how we used our primitives to implement cuSLINK end-to-end on the GPU, further enabling a wide range of real-world data mining and machine learning applications that were once intractable. In addition to being a primary computational bottleneck in the popular HDBSCAN algorithm, the impact of our end-to-end cuSLINK algorithm spans a large range of important applications, including cluster analysis in social and computer networks, natural language processing, and computer vision. Users can obtain cuSLINK at https://docs.rapids.ai/api/cuml/latest/api/#agg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#36793;&#30028;&#21322;&#31354;&#38388;&#30340;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#31639;&#27861;&#20043;&#38388;&#30340;&#22266;&#26377;&#24046;&#36317;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.16352</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#36793;&#30028;&#21322;&#31354;&#38388;&#30340;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Information-Computation Tradeoffs for Learning Margin Halfspaces with Random Classification Noise. (arXiv:2306.16352v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23398;&#20064;&#20855;&#26377;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#30340;&#36793;&#30028;&#21322;&#31354;&#38388;&#30340;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#31639;&#27861;&#20043;&#38388;&#30340;&#22266;&#26377;&#24046;&#36317;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#20998;&#31867;&#22122;&#22768;&#23398;&#20064;&#947;-&#36793;&#30028;&#21322;&#31354;&#38388;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;&#65292;&#34920;&#26126;&#20102;&#38382;&#39064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#19982;&#35745;&#31639;&#25928;&#29575;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#20043;&#38388;&#23384;&#22312;&#22266;&#26377;&#24046;&#36317;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#38382;&#39064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#20026;&#920;(1/ (&#947;^2 &#949;))&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#20026;O(1/ (&#947;^2 &#949;^2))&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#31639;&#27861;&#21644;&#20302;&#27425;&#22810;&#39033;&#24335;&#27979;&#35797;&#30340;&#19979;&#30028;&#65292;&#36825;&#34920;&#26126;&#22312;&#35745;&#31639;&#25928;&#29575;&#31639;&#27861;&#20013;&#65292;&#26679;&#26412;&#22797;&#26434;&#24615;&#23545;1/&#949;&#30340;&#20108;&#27425;&#20381;&#36182;&#26159;&#22266;&#26377;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26263;&#31034;&#20102;&#20219;&#20309;&#26377;&#25928;&#30340;SQ&#23398;&#20064;&#22120;&#25110;&#20302;&#27425;&#27979;&#35797;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#20026;&#937;(1/ (&#947;^(1/2) &#949;^2))&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of PAC learning $\gamma$-margin halfspaces with Random Classification Noise. We establish an information-computation tradeoff suggesting an inherent gap between the sample complexity of the problem and the sample complexity of computationally efficient algorithms. Concretely, the sample complexity of the problem is $\widetilde{\Theta}(1/(\gamma^2 \epsilon))$. We start by giving a simple efficient algorithm with sample complexity $\widetilde{O}(1/(\gamma^2 \epsilon^2))$. Our main result is a lower bound for Statistical Query (SQ) algorithms and low-degree polynomial tests suggesting that the quadratic dependence on $1/\epsilon$ in the sample complexity is inherent for computationally efficient algorithms. Specifically, our results imply a lower bound of $\widetilde{\Omega}(1/(\gamma^{1/2} \epsilon^2))$ on the sample complexity of any efficient SQ learner or low-degree test.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;Stein&#26041;&#27861;&#25512;&#23548;&#20986;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#36890;&#36807;&#39640;&#26031;&#24179;&#28369;&#25216;&#26415;&#23558;&#24179;&#28369;&#24230;&#37327;&#36716;&#21270;&#20026;Wasserstein&#36317;&#31163;&#12290;&#36890;&#36807;&#29305;&#27530;&#21270;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36924;&#36817;&#30340;&#39318;&#20010;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.16308</link><description>&lt;p&gt;
&#36890;&#36807;Stein&#26041;&#27861;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36827;&#34892;&#36924;&#36817;&#21450;&#20854;&#22312;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Gaussian random field approximation via Stein's method with applications to wide random neural networks. (arXiv:2306.16308v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;Stein&#26041;&#27861;&#25512;&#23548;&#20986;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#36890;&#36807;&#39640;&#26031;&#24179;&#28369;&#25216;&#26415;&#23558;&#24179;&#28369;&#24230;&#37327;&#36716;&#21270;&#20026;Wasserstein&#36317;&#31163;&#12290;&#36890;&#36807;&#29305;&#27530;&#21270;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36924;&#36817;&#30340;&#39318;&#20010;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;Stein&#26041;&#27861;&#25512;&#23548;&#20986;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#65288;$W_1$&#65289;&#30340;&#19978;&#30028;&#65292;&#35813;&#36317;&#31163;&#26159;&#36830;&#32493;&#38543;&#26426;&#22330;&#19982;&#39640;&#26031;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#26031;&#24179;&#28369;&#25216;&#26415;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#24179;&#28369;&#24230;&#37327;&#20013;&#30340;&#19978;&#30028;&#36716;&#21270;&#20026;$W_1$&#36317;&#31163;&#12290;&#24179;&#28369;&#24615;&#26159;&#22522;&#20110;&#20351;&#29992;Laplacian&#31639;&#23376;&#30340;&#24130;&#26500;&#24314;&#30340;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#35774;&#35745;&#25104;&#19982;Cameron-Martin&#25110;Reproducing Kernel Hilbert Space&#30456;&#20851;&#32852;&#30340;&#39640;&#26031;&#36807;&#31243;&#20855;&#26377;&#26131;&#25805;&#20316;&#30340;&#29305;&#24449;&#12290;&#36825;&#20010;&#29305;&#24449;&#20351;&#25105;&#20204;&#33021;&#22815;&#36229;&#36234;&#20043;&#21069;&#25991;&#29486;&#20013;&#32771;&#34385;&#30340;&#19968;&#32500;&#21306;&#38388;&#22411;&#25351;&#26631;&#38598;&#12290;&#36890;&#36807;&#29305;&#21270;&#25105;&#20204;&#30340;&#19968;&#33324;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#22312;&#20219;&#24847;&#28145;&#24230;&#21644;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36924;&#36817;&#30340;&#39318;&#20010;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#19978;&#30028;&#26126;&#30830;&#22320;&#29992;&#32593;&#32476;&#23485;&#24230;&#21644;&#38543;&#26426;&#26435;&#37325;&#30340;&#30697;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive upper bounds on the Wasserstein distance ($W_1$), with respect to $\sup$-norm, between any continuous $\mathbb{R}^d$ valued random field indexed by the $n$-sphere and the Gaussian, based on Stein's method. We develop a novel Gaussian smoothing technique that allows us to transfer a bound in a smoother metric to the $W_1$ distance. The smoothing is based on covariance functions constructed using powers of Laplacian operators, designed so that the associated Gaussian process has a tractable Cameron-Martin or Reproducing Kernel Hilbert Space. This feature enables us to move beyond one dimensional interval-based index sets that were previously considered in the literature. Specializing our general result, we obtain the first bounds on the Gaussian random field approximation of wide random neural networks of any depth and Lipschitz activation functions at the random field level. Our bounds are explicitly expressed in terms of the widths of the network and moments of the random wei
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#65292;&#20197;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#30446;&#21069;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36827;&#34892;&#29305;&#24449;&#26500;&#24314;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23384;&#22312;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.16297</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#26102;&#21464;&#35843;&#33410;&#22240;&#32032;&#30340;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#20272;&#35745;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Meta-Learning Method for Estimation of Causal Excursion Effects to Assess Time-Varying Moderation. (arXiv:2306.16297v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16297
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#65292;&#20197;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#30446;&#21069;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#65292;&#32780;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36827;&#34892;&#29305;&#24449;&#26500;&#24314;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23384;&#22312;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#31359;&#25140;&#25216;&#26415;&#21644;&#26234;&#33021;&#25163;&#26426;&#25552;&#20379;&#30340;&#25968;&#23383;&#21270;&#20581;&#24247;&#24178;&#39044;&#30340;&#21452;&#37325;&#38761;&#21629;&#26174;&#33879;&#22686;&#21152;&#20102;&#31227;&#21160;&#20581;&#24247;&#65288;mHealth&#65289;&#24178;&#39044;&#22312;&#21508;&#20010;&#20581;&#24247;&#31185;&#23398;&#39046;&#22495;&#30340;&#21487;&#21450;&#24615;&#21644;&#37319;&#32435;&#29575;&#12290;&#39034;&#24207;&#38543;&#26426;&#23454;&#39564;&#31216;&#20026;&#24494;&#38543;&#26426;&#35797;&#39564;&#65288;MRTs&#65289;&#24050;&#32463;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#29992;&#20110;&#23454;&#35777;&#35780;&#20272;&#36825;&#20123;mHealth&#24178;&#39044;&#32452;&#25104;&#37096;&#20998;&#30340;&#26377;&#25928;&#24615;&#12290;MRTs&#20135;&#29983;&#20102;&#19968;&#31867;&#26032;&#30340;&#22240;&#26524;&#20272;&#35745;&#37327;&#65292;&#31216;&#20026;&#8220;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#8221;&#65292;&#20351;&#20581;&#24247;&#31185;&#23398;&#23478;&#33021;&#22815;&#35780;&#20272;&#24178;&#39044;&#25928;&#26524;&#38543;&#26102;&#38388;&#30340;&#21464;&#21270;&#25110;&#36890;&#36807;&#20010;&#20307;&#29305;&#24449;&#12289;&#29615;&#22659;&#25110;&#36807;&#21435;&#30340;&#21453;&#24212;&#26469;&#35843;&#33410;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#29992;&#20110;&#20272;&#35745;&#22240;&#26524;&#20559;&#31163;&#25928;&#24212;&#30340;&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#38656;&#35201;&#39044;&#20808;&#25351;&#23450;&#35266;&#23519;&#21040;&#30340;&#39640;&#32500;&#21382;&#21490;&#30340;&#29305;&#24449;&#26469;&#26500;&#24314;&#37325;&#35201;&#24178;&#25200;&#21442;&#25968;&#30340;&#24037;&#20316;&#27169;&#22411;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#33258;&#21160;&#29305;&#24449;&#26500;&#24314;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#20854;&#26420;&#32032;&#24212;&#29992;&#23548;&#33268;&#20102;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Twin revolutions in wearable technologies and smartphone-delivered digital health interventions have significantly expanded the accessibility and uptake of mobile health (mHealth) interventions across various health science domains. Sequentially randomized experiments called micro-randomized trials (MRTs) have grown in popularity to empirically evaluate the effectiveness of these mHealth intervention components. MRTs have given rise to a new class of causal estimands known as "causal excursion effects", which enable health scientists to assess how intervention effectiveness changes over time or is moderated by individual characteristics, context, or responses in the past. However, current data analysis methods for estimating causal excursion effects require pre-specified features of the observed high-dimensional history to construct a working model of an important nuisance parameter. While machine learning algorithms are ideal for automatic feature construction, their naive application
&lt;/p&gt;</description></item><item><title>&#26368;&#20248;&#36755;&#36816;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#36801;&#31227;&#23398;&#20064;&#31561;&#39046;&#22495;&#65292;&#24182;&#19988;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#21457;&#23637;&#20063;&#19982;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#30456;&#20114;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.16156</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#20248;&#36755;&#36816;&#30340;&#26368;&#26032;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Recent Advances in Optimal Transport for Machine Learning. (arXiv:2306.16156v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16156
&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#36755;&#36816;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#26368;&#26032;&#36827;&#23637;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#36801;&#31227;&#23398;&#20064;&#31561;&#39046;&#22495;&#65292;&#24182;&#19988;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#21457;&#23637;&#20063;&#19982;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#30456;&#20114;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26368;&#20248;&#36755;&#36816;&#34987;&#25552;&#20986;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#27604;&#36739;&#21644;&#25805;&#20316;&#27010;&#29575;&#20998;&#24067;&#30340;&#27010;&#29575;&#26694;&#26550;&#12290;&#36825;&#20010;&#26694;&#26550;&#28304;&#20110;&#20854;&#20016;&#23500;&#30340;&#21382;&#21490;&#21644;&#29702;&#35770;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22914;&#29983;&#25104;&#24314;&#27169;&#21644;&#36801;&#31227;&#23398;&#20064;&#12290;&#22312;&#36825;&#39033;&#35843;&#26597;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#26368;&#20248;&#36755;&#36816;&#22312;2012&#24180;&#33267;2022&#24180;&#26399;&#38388;&#23545;&#26426;&#22120;&#23398;&#20064;&#30340;&#36129;&#29486;&#65292;&#37325;&#28857;&#20851;&#27880;&#26426;&#22120;&#23398;&#20064;&#30340;&#22235;&#20010;&#23376;&#39046;&#22495;&#65306;&#26377;&#30417;&#30563;&#23398;&#20064;&#12289;&#26080;&#30417;&#30563;&#23398;&#20064;&#12289;&#36801;&#31227;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#31361;&#20986;&#20102;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#24182;&#19982;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#30456;&#20114;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, Optimal Transport has been proposed as a probabilistic framework in Machine Learning for comparing and manipulating probability distributions. This is rooted in its rich history and theory, and has offered new solutions to different problems in machine learning, such as generative modeling and transfer learning. In this survey we explore contributions of Optimal Transport for Machine Learning over the period 2012 -- 2022, focusing on four sub-fields of Machine Learning: supervised, unsupervised, transfer and reinforcement learning. We further highlight the recent development in computational Optimal Transport, and its interplay with Machine Learning practice.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#28041;&#21450;&#24369;&#38271;&#31243;&#30456;&#20114;&#20316;&#29992;&#30340;&#21508;&#31181;&#25512;&#29702;&#38382;&#39064;&#65292;&#21253;&#25324;&#21387;&#32553;&#24863;&#30693;&#21644;&#24863;&#30693;&#22120;&#23398;&#20064;&#12290;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.16097</link><description>&lt;p&gt;
&#31232;&#30095;&#34920;&#31034;&#12289;&#25512;&#29702;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sparse Representations, Inference and Learning. (arXiv:2306.16097v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16097
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#28041;&#21450;&#24369;&#38271;&#31243;&#30456;&#20114;&#20316;&#29992;&#30340;&#21508;&#31181;&#25512;&#29702;&#38382;&#39064;&#65292;&#21253;&#25324;&#21387;&#32553;&#24863;&#30693;&#21644;&#24863;&#30693;&#22120;&#23398;&#20064;&#12290;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#21487;&#20197;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#32479;&#35745;&#29289;&#29702;&#23398;&#24050;&#32463;&#35777;&#26126;&#26159;&#25506;&#31350;&#26426;&#22120;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#22823;&#32500;&#25512;&#29702;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;&#32479;&#35745;&#29289;&#29702;&#23398;&#25552;&#20379;&#20102;&#20998;&#26512;&#24037;&#20855;&#26469;&#30740;&#31350;&#20854;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#31639;&#27861;&#26469;&#35299;&#20915;&#20010;&#21035;&#23454;&#20363;&#12290;&#22312;&#36825;&#20123;&#31508;&#35760;&#20013;&#65292;&#25105;&#20204;&#23558;&#22522;&#20110;2022&#24180;Les Houches&#22799;&#23395;&#23398;&#26657;&#20013;Marc M\'ezard&#30340;&#35762;&#24231;&#65292;&#20171;&#32461;&#19968;&#31181;&#21487;&#20197;&#22312;&#24369;&#38271;&#31243;&#30456;&#20114;&#20316;&#29992;&#30340;&#21508;&#31181;&#38382;&#39064;&#20013;&#20351;&#29992;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21253;&#25324;&#21387;&#32553;&#24863;&#30693;&#38382;&#39064;&#25110;&#24863;&#30693;&#22120;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#30475;&#21040;&#36825;&#20123;&#38382;&#39064;&#22914;&#20309;&#22312;&#22797;&#21046;&#23545;&#31216;&#32423;&#21035;&#19978;&#36827;&#34892;&#30740;&#31350;&#65292;&#20351;&#29992;&#20013;&#33108;&#26041;&#27861;&#30340;&#21457;&#23637;&#65292;&#26082;&#20316;&#20026;&#29702;&#35770;&#24037;&#20855;&#65292;&#20063;&#20316;&#20026;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years statistical physics has proven to be a valuable tool to probe into large dimensional inference problems such as the ones occurring in machine learning. Statistical physics provides analytical tools to study fundamental limitations in their solutions and proposes algorithms to solve individual instances. In these notes, based on the lectures by Marc M\'ezard in 2022 at the summer school in Les Houches, we will present a general framework that can be used in a large variety of problems with weak long-range interactions, including the compressed sensing problem, or the problem of learning in a perceptron. We shall see how these problems can be studied at the replica symmetric level, using developments of the cavity methods, both as a theoretical tool and as an algorithm.
&lt;/p&gt;</description></item><item><title>BayesFlow&#26159;&#19968;&#20010;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25674;&#36824;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#21151;&#33021;&#65292;&#29992;&#25143;&#21487;&#20197;&#22312;&#27169;&#22411;&#20223;&#30495;&#19978;&#35757;&#32451;&#23450;&#21046;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#20219;&#20309;&#21518;&#32493;&#24212;&#29992;&#12290;&#36825;&#31181;&#25674;&#36824;&#36125;&#21494;&#26031;&#25512;&#26029;&#33021;&#22815;&#24555;&#36895;&#20934;&#30830;&#22320;&#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#23454;&#29616;&#20102;&#23545;&#19981;&#21487;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#30340;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2306.16015</link><description>&lt;p&gt;
BayesFlow: &#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#25674;&#36824;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;
&lt;/p&gt;
&lt;p&gt;
BayesFlow: Amortized Bayesian Workflows With Neural Networks. (arXiv:2306.16015v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16015
&lt;/p&gt;
&lt;p&gt;
BayesFlow&#26159;&#19968;&#20010;Python&#24211;&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25674;&#36824;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#21151;&#33021;&#65292;&#29992;&#25143;&#21487;&#20197;&#22312;&#27169;&#22411;&#20223;&#30495;&#19978;&#35757;&#32451;&#23450;&#21046;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#20219;&#20309;&#21518;&#32493;&#24212;&#29992;&#12290;&#36825;&#31181;&#25674;&#36824;&#36125;&#21494;&#26031;&#25512;&#26029;&#33021;&#22815;&#24555;&#36895;&#20934;&#30830;&#22320;&#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#23454;&#29616;&#20102;&#23545;&#19981;&#21487;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#30340;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#36125;&#21494;&#26031;&#25512;&#26029;&#28041;&#21450;&#19968;&#31995;&#21015;&#35745;&#31639;&#25216;&#26415;&#65292;&#29992;&#20110;&#20272;&#35745;&#12289;&#39564;&#35777;&#21644;&#20174;&#27010;&#29575;&#27169;&#22411;&#20013;&#24471;&#20986;&#32467;&#35770;&#65292;&#20316;&#20026;&#25968;&#25454;&#20998;&#26512;&#20013;&#26377;&#21407;&#21017;&#30340;&#24037;&#20316;&#27969;&#30340;&#19968;&#37096;&#20998;&#12290;&#36125;&#21494;&#26031;&#24037;&#20316;&#27969;&#20013;&#30340;&#20856;&#22411;&#38382;&#39064;&#21253;&#25324;&#36817;&#20284;&#19981;&#21487;&#35745;&#31639;&#21518;&#39564;&#20998;&#24067;&#20197;&#36866;&#24212;&#19981;&#21516;&#30340;&#27169;&#22411;&#31867;&#22411;&#65292;&#20197;&#21450;&#36890;&#36807;&#22797;&#26434;&#24615;&#21644;&#39044;&#27979;&#24615;&#33021;&#27604;&#36739;&#21516;&#19968;&#36807;&#31243;&#30340;&#31454;&#20105;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;Python&#24211;BayesFlow&#65292;&#29992;&#20110;&#22522;&#20110;&#20223;&#30495;&#35757;&#32451;&#24050;&#24314;&#31435;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#29992;&#20110;&#25674;&#36824;&#25968;&#25454;&#21387;&#32553;&#21644;&#25512;&#26029;&#12290;&#22312;BayesFlow&#20013;&#23454;&#29616;&#30340;&#25674;&#36824;&#36125;&#21494;&#26031;&#25512;&#26029;&#20351;&#29992;&#25143;&#33021;&#22815;&#22312;&#27169;&#22411;&#20223;&#30495;&#19978;&#35757;&#32451;&#23450;&#21046;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23558;&#36825;&#20123;&#32593;&#32476;&#37325;&#29992;&#20110;&#27169;&#22411;&#30340;&#20219;&#20309;&#21518;&#32493;&#24212;&#29992;&#12290;&#30001;&#20110;&#35757;&#32451;&#22909;&#30340;&#32593;&#32476;&#21487;&#20197;&#20960;&#20046;&#21363;&#26102;&#22320;&#25191;&#34892;&#25512;&#26029;&#65292;&#22240;&#27492;&#21069;&#26399;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#24456;&#24555;&#23601;&#33021;&#22815;&#25674;&#36824;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern Bayesian inference involves a mixture of computational techniques for estimating, validating, and drawing conclusions from probabilistic models as part of principled workflows for data analysis. Typical problems in Bayesian workflows are the approximation of intractable posterior distributions for diverse model types and the comparison of competing models of the same process in terms of their complexity and predictive performance. This manuscript introduces the Python library BayesFlow for simulation-based training of established neural network architectures for amortized data compression and inference. Amortized Bayesian inference, as implemented in BayesFlow, enables users to train custom neural networks on model simulations and re-use these networks for any subsequent application of the models. Since the trained networks can perform inference almost instantaneously, the upfront neural network training is quickly amortized.
&lt;/p&gt;</description></item><item><title>&#22909;&#22855;&#22238;&#25918;&#26159;&#19968;&#31181;&#38024;&#23545;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#30340;&#20248;&#20808;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22909;&#22855;&#24230;&#22522;&#30784;&#30340;&#20248;&#20808;&#20449;&#21495;&#65292;&#23427;&#25552;&#39640;&#20102;&#25506;&#32034;&#24615;&#33021;&#65292;&#24182;&#22312;Crafter&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25104;&#32489;&#12290;</title><link>http://arxiv.org/abs/2306.15934</link><description>&lt;p&gt;
&#23545;&#20110;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#36866;&#24212;&#24615;&#30340;&#22909;&#22855;&#22238;&#25918;
&lt;/p&gt;
&lt;p&gt;
Curious Replay for Model-based Adaptation. (arXiv:2306.15934v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15934
&lt;/p&gt;
&lt;p&gt;
&#22909;&#22855;&#22238;&#25918;&#26159;&#19968;&#31181;&#38024;&#23545;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#20195;&#29702;&#30340;&#20248;&#20808;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22909;&#22855;&#24230;&#22522;&#30784;&#30340;&#20248;&#20808;&#20449;&#21495;&#65292;&#23427;&#25552;&#39640;&#20102;&#25506;&#32034;&#24615;&#33021;&#65292;&#24182;&#22312;Crafter&#22522;&#20934;&#27979;&#35797;&#20013;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25104;&#32489;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#24517;&#39035;&#33021;&#22815;&#22312;&#29615;&#22659;&#25913;&#21464;&#26102;&#24555;&#36895;&#36866;&#24212;&#12290;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#22312;&#36825;&#26041;&#38754;&#20570;&#24471;&#19981;&#22909;&#65292;&#37096;&#20998;&#21407;&#22240;&#26159;&#23427;&#20204;&#22914;&#20309;&#21033;&#29992;&#36807;&#21435;&#30340;&#32463;&#39564;&#26469;&#35757;&#32451;&#20854;&#19990;&#30028;&#27169;&#22411;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22909;&#22855;&#22238;&#25918;&#30340;&#26041;&#27861;&#65292;&#23427;&#26159;&#38024;&#23545;&#22522;&#20110;&#27169;&#22411;&#30340;&#20195;&#29702;&#30340;&#19968;&#31181;&#20248;&#20808;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22909;&#22855;&#24230;&#22522;&#30784;&#30340;&#20248;&#20808;&#20449;&#21495;&#12290;&#20351;&#29992;&#22909;&#22855;&#22238;&#25918;&#30340;&#20195;&#29702;&#22312;&#21463;&#21040;&#21160;&#29289;&#34892;&#20026;&#21551;&#21457;&#30340;&#25506;&#32034;&#33539;&#24335;&#21644;Crafter&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;&#24102;&#26377;&#22909;&#22855;&#22238;&#25918;&#30340;DreamerV3&#22312;Crafter&#19978;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;19.4&#30340;&#24179;&#22343;&#20998;&#25968;&#65292;&#22823;&#22823;&#25913;&#21892;&#20102;&#20043;&#21069;DreamerV3&#20351;&#29992;&#22343;&#21248;&#22238;&#25918;&#26102;&#30340;&#26368;&#39640;&#20998;&#25968;14.5&#65292;&#24182;&#19988;&#22312;Deepmind Control Suite&#19978;&#30340;&#24615;&#33021;&#20063;&#30456;&#20284;&#12290;&#22909;&#22855;&#22238;&#25918;&#30340;&#20195;&#30721;&#21487;&#20197;&#22312;https://github.com/AutonomousAgentsLab/curiousreplay&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Agents must be able to adapt quickly as an environment changes. We find that existing model-based reinforcement learning agents are unable to do this well, in part because of how they use past experiences to train their world model. Here, we present Curious Replay -- a form of prioritized experience replay tailored to model-based agents through use of a curiosity-based priority signal. Agents using Curious Replay exhibit improved performance in an exploration paradigm inspired by animal behavior and on the Crafter benchmark. DreamerV3 with Curious Replay surpasses state-of-the-art performance on Crafter, achieving a mean score of 19.4 that substantially improves on the previous high score of 14.5 by DreamerV3 with uniform replay, while also maintaining similar performance on the Deepmind Control Suite. Code for Curious Replay is available at https://github.com/AutonomousAgentsLab/curiousreplay
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#20351;&#29992;&#38543;&#26426;&#31995;&#25968;&#23725;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20272;&#35745;&#39118;&#38505;&#25110;&#39044;&#27979;&#39118;&#38505;&#26469;&#30830;&#23450;&#30446;&#26631;&#27169;&#22411;&#21644;&#28304;&#27169;&#22411;&#30340;&#22238;&#24402;&#31995;&#25968;&#30340;&#26368;&#20248;&#26435;&#37325;&#65292;&#24182;&#20351;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24471;&#20986;&#20102;&#26368;&#20248;&#26435;&#37325;&#30340;&#26497;&#38480;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.15915</link><description>&lt;p&gt;
&#29992;&#38543;&#26426;&#31995;&#25968;&#23725;&#22238;&#24402;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning with Random Coefficient Ridge Regression. (arXiv:2306.15915v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#20351;&#29992;&#38543;&#26426;&#31995;&#25968;&#23725;&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#20272;&#35745;&#39118;&#38505;&#25110;&#39044;&#27979;&#39118;&#38505;&#26469;&#30830;&#23450;&#30446;&#26631;&#27169;&#22411;&#21644;&#28304;&#27169;&#22411;&#30340;&#22238;&#24402;&#31995;&#25968;&#30340;&#26368;&#20248;&#26435;&#37325;&#65292;&#24182;&#20351;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24471;&#20986;&#20102;&#26368;&#20248;&#26435;&#37325;&#30340;&#26497;&#38480;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#65292;&#38543;&#26426;&#31995;&#25968;&#23725;&#22238;&#24402;&#25552;&#20379;&#20102;&#22266;&#23450;&#31995;&#25968;&#22238;&#24402;&#30340;&#19968;&#20010;&#37325;&#35201;&#26367;&#20195;&#26041;&#26696;&#65292;&#24403;&#25928;&#26524;&#34987;&#26399;&#26395;&#20026;&#23567;&#20294;&#19981;&#20026;&#38646;&#26102;&#12290;&#26412;&#25991;&#32771;&#34385;&#22312;&#36801;&#31227;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#21644;&#39044;&#27979;&#38543;&#26426;&#31995;&#25968;&#23725;&#22238;&#24402;&#65292;&#22312;&#30446;&#26631;&#27169;&#22411;&#30340;&#35266;&#27979;&#20540;&#20043;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#26469;&#33258;&#19981;&#21516;&#20294;&#21487;&#33021;&#30456;&#20851;&#30340;&#22238;&#24402;&#27169;&#22411;&#30340;&#28304;&#26679;&#26412;&#12290;&#28304;&#27169;&#22411;&#23545;&#30446;&#26631;&#27169;&#22411;&#30340;&#20449;&#24687;&#37327;&#21487;&#20197;&#36890;&#36807;&#22238;&#24402;&#31995;&#25968;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26469;&#37327;&#21270;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#30446;&#26631;&#27169;&#22411;&#22238;&#24402;&#31995;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#23427;&#20204;&#26159;&#30446;&#26631;&#27169;&#22411;&#21644;&#28304;&#27169;&#22411;&#23725;&#20272;&#35745;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#20013;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#26368;&#23567;&#21270;&#32463;&#39564;&#20272;&#35745;&#39118;&#38505;&#25110;&#39044;&#27979;&#39118;&#38505;&#26469;&#30830;&#23450;&#12290;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#22312;$p/n \rightarrow \gamma$&#30340;&#26465;&#20214;&#19979;&#65292;&#24471;&#20986;&#20102;&#26368;&#20248;&#26435;&#37325;&#30340;&#26497;&#38480;&#20540;&#65292;&#20854;&#20013;$p$&#26159;...
&lt;/p&gt;
&lt;p&gt;
Ridge regression with random coefficients provides an important alternative to fixed coefficients regression in high dimensional setting when the effects are expected to be small but not zeros. This paper considers estimation and prediction of random coefficient ridge regression in the setting of transfer learning, where in addition to observations from the target model, source samples from different but possibly related regression models are available. The informativeness of the source model to the target model can be quantified by the correlation between the regression coefficients. This paper proposes two estimators of regression coefficients of the target model as the weighted sum of the ridge estimates of both target and source models, where the weights can be determined by minimizing the empirical estimation risk or prediction risk. Using random matrix theory, the limiting values of the optimal weights are derived under the setting when $p/n \rightarrow \gamma$, where $p$ is the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#38543;&#26426;&#24494;&#31215;&#20998;&#12289;&#21464;&#20998;&#36125;&#21494;&#26031;&#29702;&#35770;&#21644;&#31232;&#30095;&#23398;&#20064;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#20934;&#30830;&#22320;&#21457;&#29616;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;SPDEs&#65289;&#12290;&#20316;&#32773;&#24212;&#29992;&#35813;&#26041;&#27861;&#25104;&#21151;&#22320;&#35782;&#21035;&#20102;&#38543;&#26426;&#28909;&#26041;&#31243;&#12289;&#38543;&#26426;Allen-Cahn&#26041;&#31243;&#21644;&#38543;&#26426;Nagumo&#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.15873</link><description>&lt;p&gt;
&#29992;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#26029;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#21457;&#29616;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Discovering stochastic partial differential equations from limited data using variational Bayes inference. (arXiv:2306.15873v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15873
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#38543;&#26426;&#24494;&#31215;&#20998;&#12289;&#21464;&#20998;&#36125;&#21494;&#26031;&#29702;&#35770;&#21644;&#31232;&#30095;&#23398;&#20064;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#20174;&#26377;&#38480;&#25968;&#25454;&#20013;&#20934;&#30830;&#22320;&#21457;&#29616;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;SPDEs&#65289;&#12290;&#20316;&#32773;&#24212;&#29992;&#35813;&#26041;&#27861;&#25104;&#21151;&#22320;&#35782;&#21035;&#20102;&#38543;&#26426;&#28909;&#26041;&#31243;&#12289;&#38543;&#26426;Allen-Cahn&#26041;&#31243;&#21644;&#38543;&#26426;Nagumo&#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;SPDEs&#65289;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#23558;&#38543;&#26426;&#24494;&#31215;&#20998;&#12289;&#21464;&#20998;&#36125;&#21494;&#26031;&#29702;&#35770;&#21644;&#31232;&#30095;&#23398;&#20064;&#30340;&#27010;&#24565;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#23637;&#30340;Kramers-Moyal&#23637;&#24320;&#24418;&#24335;&#65292;&#20197;&#21709;&#24212;&#29366;&#24577;&#26469;&#34920;&#31034;SPDE&#30340;&#28418;&#31227;&#21644;&#25193;&#25955;&#39033;&#65292;&#24182;&#20351;&#29992;&#24102;&#26377;&#31232;&#30095;&#23398;&#20064;&#25216;&#26415;&#30340;Spike-and-Slab&#20808;&#39564;&#26469;&#39640;&#25928;&#20934;&#30830;&#22320;&#21457;&#29616;&#28508;&#22312;&#30340;SPDEs&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24050;&#32463;&#24212;&#29992;&#20110;&#19977;&#20010;&#20856;&#22411;&#30340;SPDEs&#65292;&#20998;&#21035;&#26159;&#38543;&#26426;&#28909;&#26041;&#31243;&#12289;&#38543;&#26426;Allen-Cahn&#26041;&#31243;&#21644;&#38543;&#26426;Nagumo&#26041;&#31243;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#26377;&#38480;&#25968;&#25454;&#20013;&#30340;&#28508;&#22312;SPDEs&#12290;&#36825;&#26159;&#39318;&#27425;&#23581;&#35797;&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;SPDEs&#65292;&#23545;&#20110;&#21508;&#31181;&#31185;&#23398;&#24212;&#29992;&#65292;&#22914;&#27668;&#20505;&#24314;&#27169;&#12289;&#37329;&#34701;&#39044;&#27979;&#21644;&#21270;&#23398;&#21160;&#21147;&#23398;&#65292;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework for discovering Stochastic Partial Differential Equations (SPDEs) from data. The proposed approach combines the concepts of stochastic calculus, variational Bayes theory, and sparse learning. We propose the extended Kramers-Moyal expansion to express the drift and diffusion terms of an SPDE in terms of state responses and use Spike-and-Slab priors with sparse learning techniques to efficiently and accurately discover the underlying SPDEs. The proposed approach has been applied to three canonical SPDEs, (a) stochastic heat equation, (b) stochastic Allen-Cahn equation, and (c) stochastic Nagumo equation. Our results demonstrate that the proposed approach can accurately identify the underlying SPDEs with limited data. This is the first attempt at discovering SPDEs from data, and it has significant implications for various scientific applications, such as climate modeling, financial forecasting, and chemical kinetics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.15865</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#20272;&#35745;&#20174;&#20854;&#31169;&#19979;&#35266;&#23519;&#30340;&#26679;&#26412;&#20013;&#26410;&#30693;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#20294;&#20182;&#20204;&#20063;&#38754;&#20020;&#38544;&#31169;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32858;&#21512;&#26041;&#26696;&#30340;&#30446;&#26631;&#26159;&#22312;&#26102;&#38388;&#21644;&#32593;&#32476;&#20013;&#39640;&#25928;&#22320;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#65292;&#21516;&#26102;&#28385;&#36275;&#20195;&#29702;&#30340;&#38544;&#31169;&#38656;&#27714;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36229;&#36234;&#20182;&#20204;&#26412;&#22320;&#38468;&#36817;&#30340;&#21327;&#35843;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#21442;&#19982;&#30340;&#20195;&#29702;&#33021;&#22815;&#20174;&#31163;&#32447;&#25110;&#38543;&#26102;&#38388;&#22312;&#32447;&#33719;&#21462;&#30340;&#31169;&#26377;&#20449;&#21495;&#20013;&#20272;&#35745;&#23436;&#25972;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#24182;&#20445;&#25252;&#20854;&#20449;&#21495;&#21644;&#32593;&#32476;&#38468;&#36817;&#30340;&#38544;&#31169;&#12290;&#36825;&#26159;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#23454;&#29616;&#30340;&#65292;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#20132;&#25442;&#30340;&#20272;&#35745;&#25968;&#25454;&#20013;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30450;&#30446;&#37319;&#26679;&#22120;&#24212;&#29992;&#20197;&#35299;&#20915;&#20998;&#31163;&#35774;&#32622;&#19979;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20855;&#26377;&#20302;&#31209;&#24207;&#21015;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#32431;&#25506;&#32034;&#38382;&#39064;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.15856</link><description>&lt;p&gt;
&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#30450;&#30446;&#37319;&#26679;&#22120;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Pure exploration in multi-armed bandits with low rank structure using oblivious sampler. (arXiv:2306.15856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30450;&#30446;&#37319;&#26679;&#22120;&#24212;&#29992;&#20197;&#35299;&#20915;&#20998;&#31163;&#35774;&#32622;&#19979;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#20855;&#26377;&#20302;&#31209;&#24207;&#21015;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#32431;&#25506;&#32034;&#38382;&#39064;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#22870;&#21169;&#24207;&#21015;&#30340;&#20302;&#31209;&#32467;&#26500;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32431;&#25506;&#32034;&#38382;&#39064;&#20013;&#30340;&#20998;&#31163;&#35774;&#32622;&#65292;&#20854;&#20013;&#25506;&#32034;&#31574;&#30053;&#26080;&#27861;&#25509;&#25910;&#20854;&#25506;&#32034;&#30340;&#21453;&#39304;&#12290;&#30001;&#20110;&#36825;&#31181;&#20998;&#31163;&#35774;&#32622;&#65292;&#25506;&#32034;&#31574;&#30053;&#38656;&#35201;&#30450;&#30446;&#22320;&#37319;&#26679;&#33218;&#12290;&#36890;&#36807;&#24341;&#20837;&#22870;&#21169;&#21521;&#37327;&#30340;&#26680;&#20449;&#24687;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#26102;&#38388;&#21464;&#21270;&#21644;&#22266;&#23450;&#24773;&#20917;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#30028;&#20026;$O(d\sqrt{(\ln N)/n})$&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20302;&#31209;&#24207;&#21015;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19978;&#30028;&#19982;&#19979;&#30028;&#20043;&#38388;&#23384;&#22312;$O(\sqrt{\ln N})$&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the low rank structure of the reward sequence of the pure exploration problems. Firstly, we propose the separated setting in pure exploration problem, where the exploration strategy cannot receive the feedback of its explorations. Due to this separation, it requires that the exploration strategy to sample the arms obliviously. By involving the kernel information of the reward vectors, we provide efficient algorithms for both time-varying and fixed cases with regret bound $O(d\sqrt{(\ln N)/n})$. Then, we show the lower bound to the pure exploration in multi-armed bandits with low rank sequence. There is an $O(\sqrt{\ln N})$ gap between our upper bound and the lower bound.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#22312;&#32447;&#24066;&#22330;&#21046;&#24230;&#26816;&#27979;&#21644;&#21046;&#24230;&#32858;&#31867;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#32500;&#21644;&#36335;&#24452;&#20381;&#36182;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#36335;&#24452;&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#20248;&#21270;&#20102;&#38024;&#23545;&#26032;&#36827;&#25968;&#25454;&#23569;&#30340;&#24773;&#20917;&#30340;&#21453;&#24212;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#35813;&#26041;&#27861;&#20063;&#36866;&#29992;&#20110;&#39640;&#32500;&#24230;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#20197;&#21450;&#33258;&#30456;&#20851;&#24615;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.15835</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#30340;&#22312;&#32447;&#24066;&#22330;&#21046;&#24230;&#26816;&#27979;&#21644;&#21046;&#24230;&#32858;&#31867;&#26041;&#27861;&#23545;&#20110;&#22810;&#32500;&#21644;&#36335;&#24452;&#20381;&#36182;&#30340;&#25968;&#25454;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Non-parametric online market regime detection and regime clustering for multidimensional and path-dependent data structures. (arXiv:2306.15835v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#22312;&#32447;&#24066;&#22330;&#21046;&#24230;&#26816;&#27979;&#21644;&#21046;&#24230;&#32858;&#31867;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#32500;&#21644;&#36335;&#24452;&#20381;&#36182;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#30456;&#20284;&#24230;&#24230;&#37327;&#36827;&#34892;&#36335;&#24452;&#26679;&#26412;&#26816;&#39564;&#65292;&#24182;&#20248;&#21270;&#20102;&#38024;&#23545;&#26032;&#36827;&#25968;&#25454;&#23569;&#30340;&#24773;&#20917;&#30340;&#21453;&#24212;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#35813;&#26041;&#27861;&#20063;&#36866;&#29992;&#20110;&#39640;&#32500;&#24230;&#12289;&#38750;&#39532;&#23572;&#21487;&#22827;&#20197;&#21450;&#33258;&#30456;&#20851;&#24615;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#30340;&#22312;&#32447;&#24066;&#22330;&#21046;&#24230;&#26816;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#22810;&#32500;&#25968;&#25454;&#32467;&#26500;&#65292;&#21033;&#29992;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#19978;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#36335;&#24452;&#26679;&#26412;&#26816;&#39564;&#12290;&#35813;&#30456;&#20284;&#24230;&#24230;&#37327;&#24050;&#32463;&#22312;&#26368;&#36817;&#30340;&#23567;&#35268;&#27169;&#25968;&#25454;&#29615;&#22659;&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#20316;&#20026;&#37492;&#21035;&#22120;&#36827;&#34892;&#20102;&#21457;&#23637;&#21644;&#24212;&#29992;&#65292;&#24182;&#22312;&#27492;&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#20197;&#36866;&#24212;&#26032;&#36827;&#25968;&#25454;&#37327;&#29305;&#21035;&#23569;&#30340;&#24773;&#20917;&#65292;&#20197;&#21152;&#24555;&#21453;&#24212;&#36895;&#24230;&#12290;&#22312;&#21516;&#26679;&#30340;&#21407;&#21017;&#19979;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#30340;&#21046;&#24230;&#32858;&#31867;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#25105;&#20204;&#20043;&#21069;&#30340;&#24037;&#20316;&#12290;&#25152;&#25552;&#20986;&#30340;&#21046;&#24230;&#32858;&#31867;&#25216;&#26415;&#34987;&#35774;&#35745;&#20026;&#21069;&#26399;&#24066;&#22330;&#20998;&#26512;&#24037;&#20855;&#65292;&#21487;&#20197;&#35782;&#21035;&#20986;&#22823;&#33268;&#30456;&#20284;&#30340;&#24066;&#22330;&#27963;&#21160;&#26399;&#38388;&#65292;&#20294;&#26032;&#30340;&#32467;&#26524;&#21516;&#26102;&#36866;&#29992;&#20110;&#22522;&#20110;&#36335;&#24452;&#30340;&#12289;&#39640;&#32500;&#24230;&#30340;&#21644;&#38750;&#39532;&#23572;&#21487;&#22827;&#30340;&#35774;&#32622;&#65292;&#20197;&#21450;&#34920;&#29616;&#20986;&#33258;&#30456;&#20851;&#24615;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we present a non-parametric online market regime detection method for multidimensional data structures using a path-wise two-sample test derived from a maximum mean discrepancy-based similarity metric on path space that uses rough path signatures as a feature map. The latter similarity metric has been developed and applied as a discriminator in recent generative models for small data environments, and has been optimised here to the setting where the size of new incoming data is particularly small, for faster reactivity.  On the same principles, we also present a path-wise method for regime clustering which extends our previous work. The presented regime clustering techniques were designed as ex-ante market analysis tools that can identify periods of approximatively similar market activity, but the new results also apply to path-wise, high dimensional-, and to non-Markovian settings as well as to data structures that exhibit autocorrelation.  We demonstrate our clustering t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#27169;&#22411;&#65292;&#20854;&#20013;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#21521;&#27599;&#20010;&#21442;&#19982;&#35757;&#32451;&#31034;&#20363;&#21457;&#36865;&#39069;&#22806;&#20449;&#24687;&#24182;&#20445;&#30041;&#19968;&#37096;&#20998;&#20013;&#22830;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#23398;&#20064;&#21644;&#36951;&#24536;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#26041;&#26696;&#65292;&#29992;&#20110;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2306.15744</link><description>&lt;p&gt;
&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Ticketed Learning-Unlearning Schemes. (arXiv:2306.15744v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15744
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#27169;&#22411;&#65292;&#20854;&#20013;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#21521;&#27599;&#20010;&#21442;&#19982;&#35757;&#32451;&#31034;&#20363;&#21457;&#36865;&#39069;&#22806;&#20449;&#24687;&#24182;&#20445;&#30041;&#19968;&#37096;&#20998;&#20013;&#22830;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#23398;&#20064;&#21644;&#36951;&#24536;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#26041;&#26696;&#65292;&#29992;&#20110;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#25152;&#23450;&#20041;&#30340;&#23398;&#20064;-&#36951;&#24536;&#33539;&#24335;&#12290;&#39318;&#20808;&#65292;&#32473;&#23450;&#19968;&#20010;&#25968;&#25454;&#38598;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#22909;&#30340;&#39044;&#27979;&#22120;&#65292;&#20363;&#22914;&#26368;&#23567;&#21270;&#26576;&#20010;&#25439;&#22833;&#20989;&#25968;&#30340;&#39044;&#27979;&#22120;&#12290;&#38543;&#21518;&#65292;&#32473;&#23450;&#20219;&#20309;&#24076;&#26395;&#36951;&#24536;&#30340;&#31034;&#20363;&#23376;&#38598;&#65292;&#30446;&#26631;&#26159;&#22312;&#19981;&#30693;&#36947;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#19968;&#20010;&#19982;&#22312;&#24184;&#23384;&#31034;&#20363;&#19978;&#20174;&#22836;&#24320;&#22987;&#23398;&#20064;&#26102;&#25152;&#29983;&#25104;&#30340;&#39044;&#27979;&#22120;&#23436;&#20840;&#30456;&#21516;&#30340;&#22909;&#30340;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#27169;&#22411;&#65292;&#20854;&#20013;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23567;&#22411;&#65288;&#21152;&#23494;&#30340;&#65289;&#8220;&#31080;&#25454;&#8221;&#21521;&#27599;&#20010;&#21442;&#19982;&#35757;&#32451;&#31034;&#20363;&#21457;&#36865;&#39069;&#22806;&#30340;&#20449;&#24687;&#65292;&#24182;&#20445;&#30041;&#19968;&#23567;&#37096;&#20998;&#8220;&#20013;&#22830;&#8221;&#20449;&#24687;&#20197;&#20379;&#20197;&#21518;&#20351;&#29992;&#12290;&#38543;&#21518;&#65292;&#24076;&#26395;&#36951;&#24536;&#30340;&#31034;&#20363;&#23558;&#20854;&#31080;&#25454;&#25552;&#20132;&#32473;&#36951;&#24536;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36824;&#20351;&#29992;&#20013;&#22830;&#20449;&#24687;&#36820;&#22238;&#19968;&#20010;&#26032;&#30340;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31080;&#25454;&#21270;&#23398;&#20064;-&#36951;&#24536;&#26041;&#26696;&#65292;&#29992;&#20110;&#24191;&#27867;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the learning--unlearning paradigm defined as follows. First given a dataset, the goal is to learn a good predictor, such as one minimizing a certain loss. Subsequently, given any subset of examples that wish to be unlearnt, the goal is to learn, without the knowledge of the original training dataset, a good predictor that is identical to the predictor that would have been produced when learning from scratch on the surviving examples.  We propose a new ticketed model for learning--unlearning wherein the learning algorithm can send back additional information in the form of a small-sized (encrypted) ``ticket'' to each participating training example, in addition to retaining a small amount of ``central'' information for later. Subsequently, the examples that wish to be unlearnt present their tickets to the unlearning algorithm, which additionally uses the central information to return a new predictor. We provide space-efficient ticketed learning--unlearning schemes for a broad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#26412;&#22320;&#20998;&#24067;&#22810;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#38544;&#31169;&#20445;&#25252;&#26469;&#36827;&#34892;&#20849;&#35782;&#31038;&#21306;&#26816;&#27979;&#21644;&#20272;&#35745;&#12290;&#37319;&#29992;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#23545;&#32593;&#32476;&#36793;&#36827;&#34892;&#25200;&#21160;&#65292;&#36890;&#36807;&#38544;&#31169;&#20445;&#25252;&#20998;&#24067;&#24335;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#25200;&#21160;&#37051;&#25509;&#30697;&#38453;&#19978;&#25191;&#34892;&#65292;&#20197;&#38450;&#27490;&#31038;&#21306;&#20043;&#38388;&#30340;&#25269;&#28040;&#12290;&#21516;&#26102;&#65292;&#24320;&#21457;&#20102;&#20004;&#27493;&#20559;&#24046;&#35843;&#25972;&#36807;&#31243;&#26469;&#28040;&#38500;&#25200;&#21160;&#21644;&#32593;&#32476;&#30697;&#38453;&#24102;&#26469;&#30340;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2306.15709</link><description>&lt;p&gt;
&#20445;&#25252;&#38544;&#31169;&#30340;&#26412;&#22320;&#20998;&#24067;&#22810;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Privacy-Preserving Community Detection for Locally Distributed Multiple Networks. (arXiv:2306.15709v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25252;&#38544;&#31169;&#30340;&#26412;&#22320;&#20998;&#24067;&#22810;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#21033;&#29992;&#38544;&#31169;&#20445;&#25252;&#26469;&#36827;&#34892;&#20849;&#35782;&#31038;&#21306;&#26816;&#27979;&#21644;&#20272;&#35745;&#12290;&#37319;&#29992;&#38543;&#26426;&#21709;&#24212;&#26426;&#21046;&#23545;&#32593;&#32476;&#36793;&#36827;&#34892;&#25200;&#21160;&#65292;&#36890;&#36807;&#38544;&#31169;&#20445;&#25252;&#20998;&#24067;&#24335;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#25200;&#21160;&#37051;&#25509;&#30697;&#38453;&#19978;&#25191;&#34892;&#65292;&#20197;&#38450;&#27490;&#31038;&#21306;&#20043;&#38388;&#30340;&#25269;&#28040;&#12290;&#21516;&#26102;&#65292;&#24320;&#21457;&#20102;&#20004;&#27493;&#20559;&#24046;&#35843;&#25972;&#36807;&#31243;&#26469;&#28040;&#38500;&#25200;&#21160;&#21644;&#32593;&#32476;&#30697;&#38453;&#24102;&#26469;&#30340;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#22810;&#23618;&#32593;&#32476;&#30001;&#20110;&#38544;&#31169;&#12289;&#25152;&#26377;&#26435;&#21644;&#36890;&#20449;&#25104;&#26412;&#30340;&#21407;&#22240;&#65292;&#24120;&#24120;&#20197;&#26412;&#22320;&#21644;&#20998;&#24067;&#24335;&#30340;&#26041;&#24335;&#23384;&#20648;&#21644;&#20998;&#26512;&#12290;&#20851;&#20110;&#22522;&#20110;&#36825;&#20123;&#25968;&#25454;&#30340;&#27169;&#22411;&#21270;&#32479;&#35745;&#26041;&#27861;&#29992;&#20110;&#31038;&#21306;&#26816;&#27979;&#30340;&#25991;&#29486;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#26412;&#22320;&#23384;&#20648;&#21644;&#35745;&#31639;&#30340;&#32593;&#32476;&#25968;&#25454;&#30340;&#22810;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#20013;&#30340;&#20849;&#35782;&#31038;&#21306;&#26816;&#27979;&#21644;&#20272;&#35745;&#65292;&#24182;&#37319;&#29992;&#38544;&#31169;&#20445;&#25252;&#12290;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#38544;&#31169;&#20445;&#25252;&#20998;&#24067;&#24335;&#35889;&#32858;&#31867;&#65288;ppDSC&#65289;&#30340;&#26032;&#31639;&#27861;&#12290;&#20026;&#20102;&#20445;&#25252;&#36793;&#30340;&#38544;&#31169;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#38543;&#26426;&#21709;&#24212;&#65288;RR&#65289;&#26426;&#21046;&#26469;&#25200;&#21160;&#32593;&#32476;&#36793;&#65292;&#35813;&#26426;&#21046;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#30340;&#24378;&#27010;&#24565;&#12290;ppDSC&#31639;&#27861;&#22312;&#24179;&#26041;&#30340;RR&#25200;&#21160;&#37051;&#25509;&#30697;&#38453;&#19978;&#25191;&#34892;&#65292;&#20197;&#38450;&#27490;&#19981;&#21516;&#23618;&#20043;&#38388;&#30340;&#31038;&#21306;&#30456;&#20114;&#25269;&#28040;&#12290;&#20026;&#20102;&#28040;&#38500;RR&#21644;&#24179;&#26041;&#32593;&#32476;&#30697;&#38453;&#25152;&#24102;&#26469;&#30340;&#20559;&#24046;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#27493;&#20559;&#24046;&#35843;&#25972;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern multi-layer networks are commonly stored and analyzed in a local and distributed fashion because of the privacy, ownership, and communication costs. The literature on the model-based statistical methods for community detection based on these data is still limited. This paper proposes a new method for consensus community detection and estimation in a multi-layer stochastic block model using locally stored and computed network data with privacy protection. A novel algorithm named privacy-preserving Distributed Spectral Clustering (ppDSC) is developed. To preserve the edges' privacy, we adopt the randomized response (RR) mechanism to perturb the network edges, which satisfies the strong notion of differential privacy. The ppDSC algorithm is performed on the squared RR-perturbed adjacency matrices to prevent possible cancellation of communities among different layers. To remove the bias incurred by RR and the squared network matrices, we develop a two-step bias-adjustment procedure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24182;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2306.15282</link><description>&lt;p&gt;
&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#22312;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variational Latent Discrete Representation for Time Series Modelling. (arXiv:2306.15282v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21464;&#20998;&#28508;&#22312;&#31163;&#25955;&#34920;&#31034;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#37319;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24182;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#22312;&#28145;&#24230;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24615;&#33021;&#19982;&#20854;&#36830;&#32493;&#23545;&#24212;&#29289;&#30456;&#23218;&#32654;&#12290;&#34429;&#28982;&#23427;&#20204;&#20173;&#28982;&#38754;&#20020;&#21508;&#31181;&#23454;&#29616;&#25361;&#25112;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#20026;&#28508;&#22312;&#31354;&#38388;&#30340;&#26356;&#22909;&#35299;&#37322;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#21516;&#26102;&#26356;&#30452;&#25509;&#22320;&#34920;&#31034;&#33258;&#28982;&#31163;&#25955;&#29616;&#35937;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#26041;&#27861;&#24314;&#35758;&#20998;&#21035;&#22312;&#31163;&#25955;&#28508;&#22312;&#25968;&#25454;&#19978;&#35757;&#32451;&#38750;&#24120;&#39640;&#32500;&#30340;&#20808;&#39564;&#27169;&#22411;&#65292;&#36825;&#26412;&#36523;&#23601;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#28508;&#22312;&#25968;&#25454;&#27169;&#22411;&#65292;&#20854;&#20013;&#31163;&#25955;&#29366;&#24577;&#26159;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#23427;&#20801;&#35768;&#24555;&#36895;&#31471;&#21040;&#31471;&#35757;&#32451;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#31569;&#31649;&#29702;&#25968;&#25454;&#38598;&#21644;&#20844;&#24320;&#21487;&#29992;&#30340;&#30005;&#21147;&#21464;&#21387;&#22120;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete latent space models have recently achieved performance on par with their continuous counterparts in deep variational inference. While they still face various implementation challenges, these models offer the opportunity for a better interpretation of latent spaces, as well as a more direct representation of naturally discrete phenomena. Most recent approaches propose to train separately very high-dimensional prior models on the discrete latent data which is a challenging task on its own. In this paper, we introduce a latent data model where the discrete state is a Markov chain, which allows fast end-to-end training. The performance of our generative model is assessed on a building management dataset and on the publicly available Electricity Transformer Dataset.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#26434;&#25968;&#25454;&#38598;&#20013;&#30340;&#24213;&#23618;&#32553;&#25918;&#23450;&#24459;&#21644;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#31867;&#27604;&#20026;&#29289;&#29702;&#31995;&#32479;&#65292;&#24182;&#24212;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#29305;&#24449;-&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#37327;&#30340;&#35268;&#24459;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#26080;&#20851;&#38543;&#26426;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#38271;&#31243;&#30456;&#20851;&#24615;&#23436;&#20840;&#24674;&#22797;&#32553;&#25918;&#34892;&#20026;&#12290;&#21516;&#26102;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#37117;&#23646;&#20110;&#28151;&#27788;&#31995;&#32479;&#65292;&#24182;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#22823;&#23567;&#19978;&#21363;&#21487;&#20307;&#29616;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.14975</link><description>&lt;p&gt;
&#22797;&#26434;&#25968;&#25454;&#38598;&#30340;&#24213;&#23618;&#32553;&#25918;&#23450;&#24459;&#21644;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets. (arXiv:2306.14975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#26434;&#25968;&#25454;&#38598;&#20013;&#30340;&#24213;&#23618;&#32553;&#25918;&#23450;&#24459;&#21644;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#31867;&#27604;&#20026;&#29289;&#29702;&#31995;&#32479;&#65292;&#24182;&#24212;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#29305;&#24449;-&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#37327;&#30340;&#35268;&#24459;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#26080;&#20851;&#38543;&#26426;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#24341;&#20837;&#38271;&#31243;&#30456;&#20851;&#24615;&#23436;&#20840;&#24674;&#22797;&#32553;&#25918;&#34892;&#20026;&#12290;&#21516;&#26102;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#37117;&#23646;&#20110;&#28151;&#27788;&#31995;&#32479;&#65292;&#24182;&#22312;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#22823;&#23567;&#19978;&#21363;&#21487;&#20307;&#29616;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#32479;&#35745;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22797;&#26434;&#25968;&#25454;&#38598;&#21644;&#20154;&#24037;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#20013;&#37117;&#20986;&#29616;&#30340;&#26222;&#36941;&#29305;&#24449;&#12290;&#25105;&#20204;&#23558;&#25968;&#25454;&#31867;&#27604;&#20026;&#29289;&#29702;&#31995;&#32479;&#65292;&#24182;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#23398;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#25581;&#31034;&#20854;&#24213;&#23618;&#32467;&#26500;&#12290;&#25105;&#20204;&#37325;&#28857;&#20998;&#26512;&#20102;&#29305;&#24449;-&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#20998;&#26512;&#20102;&#20854;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#32467;&#26524;&#26159;&#65306;(i) &#22823;&#37096;&#20998;&#29305;&#24449;&#20540;&#21576;&#29616;&#30340;&#24130;&#24459;&#32553;&#25918;&#22312;&#26080;&#30456;&#20851;&#38543;&#26426;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;(ii) &#36890;&#36807;&#31616;&#21333;&#22320;&#24341;&#20837;&#38271;&#31243;&#30456;&#20851;&#24615;&#65292;&#21487;&#20197;&#23436;&#20840;&#24674;&#22797;&#36825;&#31181;&#32553;&#25918;&#34892;&#20026;&#21040;&#21512;&#25104;&#25968;&#25454;&#20013;&#65292;(iii) &#20174;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#35282;&#24230;&#30475;&#65292;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#23646;&#20110;&#21516;&#19968;&#20010;&#26222;&#36866;&#24615;&#31867;&#21035;&#65292;&#37117;&#26159;&#28151;&#27788;&#31995;&#32479;&#32780;&#38750;&#21487;&#31215;&#31995;&#32479;&#65292;(iv) &#39044;&#26399;&#30340;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#32479;&#35745;&#34892;&#20026;&#22312;&#30456;&#23545;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#22823;&#23567;&#19978;&#23601;&#24050;&#32463;&#22312;&#32463;&#39564;&#21327;&#26041;&#24046;&#30697;&#38453;&#20013;&#24471;&#21040;&#20307;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study universal traits which emerge both in real-world complex datasets, as well as in artificially generated ones. Our approach is to analogize data to a physical system and employ tools from statistical physics and Random Matrix Theory (RMT) to reveal their underlying structure. We focus on the feature-feature covariance matrix, analyzing both its local and global eigenvalue statistics. Our main observations are: (i) The power-law scalings that the bulk of its eigenvalues exhibit are vastly different for uncorrelated random data compared to real-world data, (ii) this scaling behavior can be completely recovered by introducing long range correlations in a simple way to the synthetic data, (iii) both generated and real-world datasets lie in the same universality class from the RMT perspective, as chaotic rather than integrable systems, (iv) the expected RMT statistical behavior already manifests for empirical covariance matrices at dataset sizes significantly smaller than those conv
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;</title><link>http://arxiv.org/abs/2306.07252</link><description>&lt;p&gt;
&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07252
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#24120;&#35265;&#38750;&#20195;&#34920;&#24615;&#33410;&#28857;&#37319;&#26679;&#26426;&#21046;&#19979;&#30340;&#32593;&#32476;&#25968;&#25454;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#37319;&#26679;&#26426;&#21046;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#36229;&#24635;&#20307;&#30340;&#36873;&#25321;&#35268;&#21017;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#30740;&#31350;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#37319;&#26679;&#23376;&#38453;&#21015;&#22312;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#26159;&#21487;&#20132;&#25442;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#36890;&#36807;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;&#26469;&#37319;&#26679;&#26102;&#65292;&#21152;&#26435;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#21464;&#20307;&#21487;&#20197;&#23545;&#20154;&#21475;&#29420;&#31435;&#36873;&#25321;&#33410;&#28857;&#30340;&#39044;&#27979;&#38598;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.00074</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#40784;&#26657;&#20934;&#29992;&#20110;AI&#36741;&#21161;&#20915;&#31574;&#21046;&#23450;
&lt;/p&gt;
&lt;p&gt;
Human-Aligned Calibration for AI-Assisted Decision Making. (arXiv:2306.00074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20351;&#29992;&#20108;&#20803;&#20998;&#31867;&#22120;&#25552;&#20379;&#20915;&#31574;&#25903;&#25345;&#26102;&#65292;&#23427;&#36890;&#24120;&#25552;&#20379;&#26631;&#31614;&#39044;&#27979;&#21644;&#32622;&#20449;&#24230;&#20540;&#12290;&#28982;&#21518;&#65292;&#20915;&#31574;&#32773;&#24212;&#20351;&#29992;&#32622;&#20449;&#24230;&#20540;&#26469;&#26657;&#20934;&#23545;&#39044;&#27979;&#30340;&#20449;&#20219;&#31243;&#24230;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;&#20204;&#32463;&#24120;&#35748;&#20026;&#32622;&#20449;&#24230;&#20540;&#24212;&#23545;&#39044;&#27979;&#26631;&#31614;&#19982;&#23454;&#38469;&#26631;&#31614;&#21305;&#37197;&#30340;&#27010;&#29575;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22810;&#26465;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#65292;&#20915;&#31574;&#32773;&#38590;&#20197;&#20351;&#29992;&#36825;&#20123;&#32622;&#20449;&#24230;&#20540;&#24456;&#22909;&#22320;&#30830;&#23450;&#20309;&#26102;&#20449;&#20219;&#39044;&#27979;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#39318;&#20808;&#26159;&#29702;&#35299;&#20026;&#20160;&#20040;&#65292;&#28982;&#21518;&#30740;&#31350;&#22914;&#20309;&#26500;&#24314;&#26356;&#26377;&#29992;&#30340;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#39318;&#20808;&#35748;&#20026;&#65292;&#22312;&#24191;&#27867;&#31867;&#30340;&#25928;&#29992;&#20989;&#25968;&#20013;&#65292;&#23384;&#22312;&#25968;&#25454;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#29702;&#24615;&#20915;&#31574;&#32773;&#36890;&#24120;&#38590;&#20197;&#20351;&#29992;&#20197;&#19978;&#32622;&#20449;&#24230;&#20540;&#21457;&#29616;&#26368;&#20339;&#20915;&#31574;&#25919;&#31574;&#8212;&#8212;&#26368;&#20339;&#30340;&#20915;&#31574;&#32773;&#38656;&#35201;&#20154;&#31867;&#23545;&#40784;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20182;&#20204;&#22312;&#25152;&#38754;&#20020;&#30340;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#19978;&#30340;&#20010;&#20154;&#20559;&#22909;&#30340;&#26032;&#26041;&#27861;&#26469;&#26500;&#36896;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#30340;&#32622;&#20449;&#24230;&#20540;&#27604;&#20351;&#29992;&#26631;&#20934;&#32622;&#20449;&#24230;&#24230;&#37327;&#23548;&#33268;&#26356;&#22909;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exist data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values -- an optimal decision maker wou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;</title><link>http://arxiv.org/abs/2305.19535</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#25968;&#25454;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#32447;&#23398;&#20064;&#30340;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-rank extended Kalman filtering for online learning of neural networks from streaming data. (arXiv:2305.19535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#29702;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#21487;&#33021;&#38750;&#24179;&#31283;&#30340;&#25968;&#25454;&#27969;&#20013;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;EKF&#65289;&#65292;&#20294;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#30340;&#21518;&#39564;&#31934;&#24230;&#30697;&#38453;&#20998;&#35299;&#65292;&#20854;&#27599;&#27493;&#30340;&#25104;&#26412;&#19982;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#19982;&#22522;&#20110;&#38543;&#26426;&#21464;&#20998;&#25512;&#29702;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#23436;&#20840;&#30830;&#23450;&#30340;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#27493;&#38271;&#35843;&#25972;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#23548;&#33268;&#26356;&#24555;&#65288;&#26356;&#39640;&#25928;&#65289;&#30340;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#29992;&#20316;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#30340;&#19968;&#37096;&#20998;&#26102;&#23454;&#29616;&#26356;&#24555;&#36895;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15408</link><description>&lt;p&gt;
&#20174;&#29702;&#35770;&#35282;&#24230;&#25581;&#31034;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#22885;&#31192;
&lt;/p&gt;
&lt;p&gt;
Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;"&#24605;&#32500;&#38142;"&#25552;&#31034;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#25968;&#23398;&#25110;&#25512;&#29702;&#30340;&#22797;&#26434;&#20219;&#21153;&#20013;&#12290;&#23613;&#31649;&#33719;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#26426;&#21046;&#20197;&#21450;&#23427;&#22914;&#20309;&#37322;&#25918;LLMs&#30340;&#28508;&#21147;&#20173;&#28982;&#26159;&#31070;&#31192;&#30340;&#12290;&#26412;&#25991;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#22238;&#31572;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#20219;&#20309;&#26377;&#38480;&#28145;&#24230;&#30340;Transformer&#37117;&#19981;&#33021;&#30452;&#25509;&#36755;&#20986;&#27491;&#30830;&#30340;&#22522;&#26412;&#31639;&#26415;/&#26041;&#31243;&#20219;&#21153;&#30340;&#31572;&#26696;&#65292;&#38500;&#38750;&#27169;&#22411;&#22823;&#23567;&#38543;&#30528;&#36755;&#20837;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#36229;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#36896;&#35777;&#26126;&#65292;&#22823;&#23567;&#24658;&#23450;&#30340;&#33258;&#22238;&#24402;Transformer&#36275;&#20197;&#36890;&#36807;&#20351;&#29992;&#24120;&#29992;&#30340;&#25968;&#23398;&#35821;&#35328;&#24418;&#24335;&#29983;&#25104;&#8220;&#24605;&#32500;&#38142;&#8221;&#25512;&#23548;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.12809</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#26469;&#32763;&#36716;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yang&#31561;&#20154;&#21457;&#29616;&#65292;&#20165;&#21024;&#38500;1%&#30340;&#35757;&#32451;&#25968;&#25454;&#23601;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#32467;&#26524;&#32763;&#36716;&#12290;&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#30340;&#26222;&#36941;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#19968;&#20010;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#21487;&#21542;&#23548;&#33268;&#27979;&#35797;&#32467;&#26524;&#32763;&#36716;&#65311;&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#36825;&#31181;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22987;&#32456;&#33021;&#22815;&#20135;&#29983;&#25104;&#21151;&#30340;&#32467;&#26524;&#12290;&#36825;&#31181;&#26426;&#21046;&#26377;&#22810;&#37325;&#20316;&#29992;&#65306;&#65288;1&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#34917;&#20805;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24674;&#22797;&#21487;&#33021;&#38169;&#35823;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#65307;&#65288;2&#65289;&#35780;&#20272;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#26412;&#25991;&#21457;&#29616;&#23376;&#38598;&#30340;&#22823;&#23567;&#19982;&#35757;&#32451;&#38598;&#20013;&#22122;&#22768;&#25968;&#25454;&#30340;&#27604;&#20363;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#20851;&#31995;&#65307;&#65288;3&#65289;&#25552;&#20379;&#20102;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#30340;&#35265;&#35299;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#20195;&#34920;&#20102;&#23545;&#35782;&#21035;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#38382;&#39064;&#30340;&#31532;&#19968;&#27425;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02657</link><description>&lt;p&gt;
&#28145;&#24230;&#23485;&#26494;&#24347;&#31070;&#32463;&#32593;&#32476;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Optimality of Deep Wide Neural Networks. (arXiv:2305.02657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#26377;&#30028;&#22495;$\mathcal X \subset \mathbb R^{d}$&#19978;&#30340;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#39318;&#20808;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#34987;&#30456;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22238;&#24402;&#25152;&#23436;&#20840;&#25551;&#32472;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#35889;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22312;$\mathcal{X}$&#19978;&#20026;&#27491;&#23450;&#65292;&#20854;&#29305;&#24449;&#20540;&#34928;&#20943;&#29575;&#20026;$(d+1)/d$&#12290;&#30001;&#20110;&#26680;&#22238;&#24402;&#20013;&#24050;&#32463;&#24314;&#31435;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the generalization ability of deep wide feedforward ReLU neural networks defined on a bounded domain $\mathcal X \subset \mathbb R^{d}$. We first demonstrate that the generalization ability of the neural network can be fully characterized by that of the corresponding deep neural tangent kernel (NTK) regression. We then investigate on the spectral properties of the deep NTK and show that the deep NTK is positive definite on $\mathcal{X}$ and its eigenvalue decay rate is $(d+1)/d$. Thanks to the well established theories in kernel regression, we then conclude that multilayer wide neural networks trained by gradient descent with proper early stopping achieve the minimax rate, provided that the regression function lies in the reproducing kernel Hilbert space (RKHS) associated with the corresponding NTK. Finally, we illustrate that the overfitted multilayer wide neural networks can not generalize well on $\mathbb S^{d}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22522;&#20110;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;&#65292;&#37325;&#35201;&#21457;&#29616;&#26159;&#20219;&#20309;&#26816;&#39564;&#30340;&#28176;&#36817;&#21151;&#29575;&#20989;&#25968;&#37117;&#21487;&#20197;&#19982;&#19968;&#31181;&#26497;&#38480;&#23454;&#39564;&#20013;&#21305;&#37197;&#30340;&#26816;&#39564;&#30456;&#21305;&#37197;&#65292;&#36825;&#20010;&#32467;&#26524;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#19968;&#20010;&#24378;&#22823;&#30340;&#20805;&#20998;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.00403</link><description>&lt;p&gt;
&#22522;&#20110;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal tests following sequential experiments. (arXiv:2305.00403v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22522;&#20110;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;&#65292;&#37325;&#35201;&#21457;&#29616;&#26159;&#20219;&#20309;&#26816;&#39564;&#30340;&#28176;&#36817;&#21151;&#29575;&#20989;&#25968;&#37117;&#21487;&#20197;&#19982;&#19968;&#31181;&#26497;&#38480;&#23454;&#39564;&#20013;&#21305;&#37197;&#30340;&#26816;&#39564;&#30456;&#21305;&#37197;&#65292;&#36825;&#20010;&#32467;&#26524;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#19968;&#20010;&#24378;&#22823;&#30340;&#20805;&#20998;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#39034;&#24207;&#23454;&#39564;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#12290;&#34429;&#28982;&#36825;&#20123;&#23454;&#39564;&#19981;&#19968;&#23450;&#26159;&#20026;&#20102;&#36827;&#34892;&#20551;&#35774;&#26816;&#39564;&#32780;&#35774;&#35745;&#30340;&#65292;&#20294;&#30740;&#31350;&#20154;&#21592;&#20173;&#28982;&#21487;&#33021;&#23545;&#23454;&#39564;&#23436;&#25104;&#21518;&#30340;&#26816;&#39564;&#24863;&#20852;&#36259;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#20998;&#26512;&#23427;&#20204;&#30340;&#28176;&#36817;&#24615;&#36136;&#26469;&#24110;&#21161;&#21457;&#23637;&#39034;&#24207;&#23454;&#39564;&#30340;&#26368;&#20248;&#26816;&#39564;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#21457;&#29616;&#26159;&#65292;&#20219;&#20309;&#26816;&#39564;&#30340;&#28176;&#36817;&#21151;&#29575;&#20989;&#25968;&#37117;&#21487;&#20197;&#19982;&#26497;&#38480;&#23454;&#39564;&#20013;&#21305;&#37197;&#30340;&#26816;&#39564;&#30456;&#21305;&#37197;&#65292;&#22312;&#36825;&#20010;&#26497;&#38480;&#23454;&#39564;&#20013;&#65292;&#23545;&#20110;&#27599;&#31181;&#22788;&#29702;&#65292;&#35266;&#23519;&#20135;&#29983;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#23545;&#36825;&#20123;&#36807;&#31243;&#30340;&#28418;&#31227;&#36827;&#34892;&#25512;&#26029;&#12290;&#36825;&#20010;&#32467;&#26524;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#65292;&#21253;&#25324;&#19968;&#20010;&#24378;&#22823;&#30340;&#20805;&#20998;&#24615;&#32467;&#26524;&#65306;&#20219;&#20309;&#20505;&#36873;&#26816;&#39564;&#26041;&#27861;&#21482;&#38656;&#35201;&#20381;&#36182;&#20110;&#19968;&#32452;&#22266;&#23450;&#30340;&#32479;&#35745;&#37327;&#65292;&#32780;&#19981;&#26159;&#39034;&#24207;&#23454;&#39564;&#30340;&#31867;&#22411;&#12290;&#36825;&#20123;&#32479;&#35745;&#37327;&#26159;&#27599;&#31181;&#22788;&#29702;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#34987;&#37319;&#26679;&#30340;&#27425;&#25968;&#65292;&#20197;&#21450;&#24471;&#20998;&#30340;&#26368;&#32456;&#20540;&#65288;&#23545;&#20110;&#21442;&#25968;&#27169;&#22411;&#65289;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen tremendous advances in the theory and application of sequential experiments. While these experiments are not always designed with hypothesis testing in mind, researchers may still be interested in performing tests after the experiment is completed. The purpose of this paper is to aid in the development of optimal tests for sequential experiments by analyzing their asymptotic properties. Our key finding is that the asymptotic power function of any test can be matched by a test in a limit experiment where a Gaussian process is observed for each treatment, and inference is made for the drifts of these processes. This result has important implications, including a powerful sufficiency result: any candidate test only needs to rely on a fixed set of statistics, regardless of the type of sequential experiment. These statistics are the number of times each treatment has been sampled by the end of the experiment, along with final value of the score (for parametric models)
&lt;/p&gt;</description></item><item><title>PyVBMC&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;Python&#24037;&#20855;&#65292;&#29992;&#20110;&#40657;&#30418;&#35745;&#31639;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#27169;&#22411;&#36873;&#25321;&#65292;&#21487;&#20197;&#22788;&#29702;&#36830;&#32493;&#21442;&#25968;&#19981;&#36229;&#36807;&#32422;10-15&#20010;&#30340;&#35745;&#31639;&#25110;&#32479;&#35745;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2303.09519</link><description>&lt;p&gt;
PyVBMC&#65306;Python&#20013;&#39640;&#25928;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
PyVBMC: Efficient Bayesian inference in Python. (arXiv:2303.09519v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09519
&lt;/p&gt;
&lt;p&gt;
PyVBMC&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;Python&#24037;&#20855;&#65292;&#29992;&#20110;&#40657;&#30418;&#35745;&#31639;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#27169;&#22411;&#36873;&#25321;&#65292;&#21487;&#20197;&#22788;&#29702;&#36830;&#32493;&#21442;&#25968;&#19981;&#36229;&#36807;&#32422;10-15&#20010;&#30340;&#35745;&#31639;&#25110;&#32479;&#35745;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PyVBMC&#26159;Variational Bayesian Monte Carlo&#65288;VBMC&#65289;&#31639;&#27861;&#30340;Python&#23454;&#29616;&#65292;&#29992;&#20110;&#40657;&#30418;&#35745;&#31639;&#27169;&#22411;&#30340;&#21518;&#39564;&#21644;&#27169;&#22411;&#25512;&#26029;&#12290;VBMC&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#25928;&#21442;&#25968;&#20272;&#35745;&#21644;&#27169;&#22411;&#35780;&#20272;&#30340;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#65292;&#24403;&#27169;&#22411;&#35780;&#20272;&#26159;&#26377;&#28857;&#21040;&#38750;&#24120;&#26114;&#36149;&#65288;&#20363;&#22914;&#31532;&#20108;&#27425;&#25110;&#26356;&#22810;&#27425;&#65289;&#21644;/&#25110;&#22024;&#26434;&#26102;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;VBMC&#35745;&#31639;&#65306;
&lt;/p&gt;
&lt;p&gt;
PyVBMC is a Python implementation of the Variational Bayesian Monte Carlo (VBMC) algorithm for posterior and model inference for black-box computational models (Acerbi, 2018, 2020). VBMC is an approximate inference method designed for efficient parameter estimation and model assessment when model evaluations are mildly-to-very expensive (e.g., a second or more) and/or noisy. Specifically, VBMC computes:  - a flexible (non-Gaussian) approximate posterior distribution of the model parameters, from which statistics and posterior samples can be easily extracted;  - an approximation of the model evidence or marginal likelihood, a metric used for Bayesian model selection.  PyVBMC can be applied to any computational or statistical model with up to roughly 10-15 continuous parameters, with the only requirement that the user can provide a Python function that computes the target log likelihood of the model, or an approximation thereof (e.g., an estimate of the likelihood obtained via simulation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#30028;&#38480;&#65292;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#32447;&#24615;&#32479;&#35745;&#65292;&#25105;&#20204;&#20851;&#27880;&#30028;&#38480;&#19982;&#28151;&#21512;&#26102;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#37319;&#29992;&#27850;&#26494;&#20998;&#35299;&#30340;&#35777;&#26126;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2303.05838</link><description>&lt;p&gt;
&#32447;&#24615;&#32479;&#35745;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#32599;&#26862;&#22612;&#23572;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Rosenthal-type inequalities for linear statistics of Markov chains. (arXiv:2303.05838v2 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#30028;&#38480;&#65292;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#32447;&#24615;&#32479;&#35745;&#65292;&#25105;&#20204;&#20851;&#27880;&#30028;&#38480;&#19982;&#28151;&#21512;&#26102;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#37319;&#29992;&#27850;&#26494;&#20998;&#35299;&#30340;&#35777;&#26126;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#30028;&#38480;&#65292;&#29992;&#20110;&#20960;&#20309;&#36941;&#21382;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21487;&#21152;&#20989;&#25968;&#65292;&#31867;&#20284;&#20110;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#30340;&#32599;&#26862;&#22612;&#23572;&#21644;&#20271;&#24681;&#26031;&#22374;&#19981;&#31561;&#24335;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#30028;&#38480;&#19982;&#30456;&#24212;&#38142;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#32599;&#26862;&#22612;&#23572;&#19981;&#31561;&#24335;&#30340;&#38797;&#28857;&#29256;&#26412;&#20013;&#30340;&#24120;&#37327;&#20197;&#21450;&#34920;&#24449;&#24213;&#23618;&#39532;&#23572;&#21487;&#22827;&#26680;&#28151;&#21512;&#29305;&#24615;&#30340;&#24120;&#37327;&#30456;&#20851;&#30340;&#26126;&#30830;&#30028;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#35777;&#26126;&#25216;&#26415;&#26159;&#26032;&#39062;&#30340;&#65292;&#24182;&#19988;&#22522;&#20110;&#27850;&#26494;&#20998;&#35299;&#30340;&#21453;&#22797;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we establish novel deviation bounds for additive functionals of geometrically ergodic Markov chains similar to Rosenthal and Bernstein inequalities for sums of independent random variables. We pay special attention to the dependence of our bounds on the mixing time of the corresponding chain. More precisely, we establish explicit bounds that are linked to the constants from the martingale version of the Rosenthal inequality, as well as the constants that characterize the mixing properties of the underlying Markov kernel. Finally, our proof technique is, up to our knowledge, new and based on a recurrent application of the Poisson decomposition.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#36817;&#31471;&#37319;&#26679;&#31639;&#27861;&#65292;&#24212;&#29992;&#20102;&#36817;&#20284;&#25298;&#32477;&#37319;&#26679;&#23454;&#29616;&#20102;&#21463;&#38480;&#39640;&#26031;&#39044;&#27979;&#32773;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2302.10081</link><description>&lt;p&gt;
&#37319;&#26679;&#38382;&#39064;&#20013;&#19968;&#31181;&#25913;&#36827;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#36817;&#31471;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improved dimension dependence of a proximal algorithm for sampling. (arXiv:2302.10081v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10081
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#32500;&#24230;&#20381;&#36182;&#24615;&#30340;&#36817;&#31471;&#37319;&#26679;&#31639;&#27861;&#65292;&#24212;&#29992;&#20102;&#36817;&#20284;&#25298;&#32477;&#37319;&#26679;&#23454;&#29616;&#20102;&#21463;&#38480;&#39640;&#26031;&#39044;&#27979;&#32773;&#65292;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#26679;&#31639;&#27861;&#65292;&#22312;&#25152;&#26377;&#32463;&#20856;&#24773;&#20917;&#65288;&#24378;&#23545;&#25968;&#20985;&#12289;&#23545;&#25968;&#20985;&#12289;&#23545;&#25968; Sobolev &#19981;&#31561;&#24335; (LSI)&#12289;Poincar&#233; &#19981;&#31561;&#24335;&#65289;&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#21322;&#20809;&#28369;&#25110;&#22797;&#21512;&#21183;&#20989;&#25968;&#35774;&#32622;&#20013;&#37117;&#23454;&#29616;&#20102;&#20248;&#36234;&#30340;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;~\citet{lee2021structured} &#20013;&#24341;&#20837;&#30340;&#36817;&#31471;&#37319;&#26679;&#22120;&#12290;&#36817;&#31471;&#37319;&#26679;&#22120;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#21463;&#38480;&#39640;&#26031;&#39044;&#27979;&#32773; (RGO) &#30340;&#24615;&#33021;&#65292;&#36825;&#26159;&#36817;&#31471;&#37319;&#26679;&#22120;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#26412;&#24037;&#20316;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22522;&#20110;&#36817;&#20284;&#25298;&#32477;&#37319;&#26679;&#23454;&#29616; RGO &#30340;&#19981;&#31934;&#30830;&#24615;&#12290;&#20026;&#20102;&#30028;&#23450; RGO &#30340;&#19981;&#31934;&#30830;&#24615;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#38024;&#23545;&#39640;&#26031;&#20998;&#24067;&#19978;&#21322;&#20809;&#28369;&#20989;&#25968;&#30340;&#26032;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#25193;&#23637;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340; Lipschitz &#20989;&#25968;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#12290;&#23558;&#25105;&#20204;&#30340; RGO &#23454;&#29616;&#24212;&#29992;&#20110;&#36817;&#31471;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#22312;&#20960;&#20046;&#25152;&#26377;&#35774;&#32622;&#20013;&#37117;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;
&lt;/p&gt;
&lt;p&gt;
We propose a sampling algorithm that achieves superior complexity bounds in all the classical settings (strongly log-concave, log-concave, Logarithmic-Sobolev inequality (LSI), Poincar\'e inequality) as well as more general settings with semi-smooth or composite potentials. Our algorithm is based on the proximal sampler introduced in~\citet{lee2021structured}. The performance of this proximal sampler is determined by that of the restricted Gaussian oracle (RGO), a key step in the proximal sampler. The main contribution of this work is an inexact realization of RGO based on approximate rejection sampling. To bound the inexactness of RGO, we establish a new concentration inequality for semi-smooth functions over Gaussian distributions, extending the well-known concentration inequality for Lipschitz functions. Applying our RGO implementation to the proximal sampler, we achieve state-of-the-art complexity bounds in almost all settings. For instance, for strongly log-concave distributions, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#22810;&#20010;&#34987;&#21160;&#23545;&#31216;&#24615;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#23562;&#37325;&#34987;&#21160;&#23545;&#31216;&#24615;&#30340; dos and don'ts&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#34987;&#21160;&#23545;&#31216;&#24615;&#19982;&#22240;&#26524;&#24314;&#27169;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#22312;&#23398;&#20064;&#38382;&#39064;&#30340;&#30446;&#26631;&#26159;&#26679;&#26412;&#22806;&#25512;&#24191;&#26102;&#65292;&#23454;&#29616;&#34987;&#21160;&#23545;&#31216;&#24615;&#23588;&#20854;&#26377;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.13724</link><description>&lt;p&gt;
&#36808;&#21521;&#23436;&#20840;&#21327;&#21464;&#30340;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards fully covariant machine learning. (arXiv:2301.13724v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#22810;&#20010;&#34987;&#21160;&#23545;&#31216;&#24615;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#20851;&#20110;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#23562;&#37325;&#34987;&#21160;&#23545;&#31216;&#24615;&#30340; dos and don'ts&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#34987;&#21160;&#23545;&#31216;&#24615;&#19982;&#22240;&#26524;&#24314;&#27169;&#30340;&#20851;&#31995;&#65292;&#24182;&#25351;&#20986;&#22312;&#23398;&#20064;&#38382;&#39064;&#30340;&#30446;&#26631;&#26159;&#26679;&#26412;&#22806;&#25512;&#24191;&#26102;&#65292;&#23454;&#29616;&#34987;&#21160;&#23545;&#31216;&#24615;&#23588;&#20854;&#26377;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#20309;&#23545;&#25968;&#25454;&#30340;&#34920;&#31034;&#37117;&#28041;&#21450;&#21040;&#20219;&#24847;&#30340;&#30740;&#31350;&#32773;&#36873;&#25321;&#12290;&#30001;&#20110;&#36825;&#20123;&#36873;&#25321;&#26159;&#22806;&#37096;&#20110;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#65292;&#27599;&#20010;&#36873;&#25321;&#37117;&#23548;&#33268;&#20102;&#19968;&#20010;&#30830;&#20999;&#30340;&#23545;&#31216;&#24615;&#65292;&#23545;&#24212;&#20110;&#23558;&#19968;&#20010;&#21487;&#33021;&#30340;&#34920;&#31034;&#36716;&#21270;&#20026;&#21478;&#19968;&#20010;&#34920;&#31034;&#30340;&#21464;&#25442;&#32676;&#12290;&#36825;&#20123;&#34987;&#21160;&#23545;&#31216;&#24615;&#21253;&#25324;&#22352;&#26631;&#33258;&#30001;&#24230;&#12289;&#35268;&#33539;&#23545;&#31216;&#24615;&#21644;&#21333;&#20301;&#21327;&#21464;&#24615;&#65292;&#22312;&#29289;&#29702;&#23398;&#20013;&#37117;&#20135;&#29983;&#20102;&#37325;&#35201;&#30340;&#32467;&#26524;&#12290;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#26368;&#26126;&#26174;&#30340;&#34987;&#21160;&#23545;&#31216;&#24615;&#26159;&#22270;&#30340;&#37325;&#26032;&#26631;&#35760;&#25110;&#32622;&#25442;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29702;&#35299;&#36825;&#20123;&#34987;&#21160;&#23545;&#31216;&#24615;&#23545;&#26426;&#22120;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#22914;&#26524;&#35201;&#23562;&#37325;&#34987;&#21160;&#23545;&#31216;&#24615;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#30340;&#24212;&#35813;&#21644;&#19981;&#24212;&#35813;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19982;&#22240;&#26524;&#24314;&#27169;&#30340;&#32852;&#31995;&#65292;&#24182;&#35748;&#20026;&#22312;&#23398;&#20064;&#38382;&#39064;&#30340;&#30446;&#26631;&#26159;&#26679;&#26412;&#22806;&#25512;&#24191;&#26102;&#65292;&#23454;&#29616;&#34987;&#21160;&#23545;&#31216;&#24615;&#29305;&#21035;&#26377;&#20215;&#20540;&#12290;&#36825;&#31687;&#35770;&#25991;&#26159;&#27010;&#24565;&#24615;&#30340;&#65306;&#23427;&#22312;&#29289;&#29702;&#23398;&#30340;&#35821;&#35328;&#20043;&#38388;&#36827;&#34892;&#32763;&#35793;&#12290;
&lt;/p&gt;
&lt;p&gt;
Any representation of data involves arbitrary investigator choices. Because those choices are external to the data-generating process, each choice leads to an exact symmetry, corresponding to the group of transformations that takes one possible representation to another. These are the passive symmetries; they include coordinate freedom, gauge symmetry, and units covariance, all of which have led to important results in physics. In machine learning, the most visible passive symmetry is the relabeling or permutation symmetry of graphs. Our goal is to understand the implications for machine learning of the many passive symmetries in play. We discuss dos and don'ts for machine learning practice if passive symmetries are to be respected. We discuss links to causal modeling, and argue that the implementation of passive symmetries is particularly valuable when the goal of the learning problem is to generalize out of sample. This paper is conceptual: It translates among the languages of physic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#20013;&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#26550;&#26500;&#22312;&#35813;&#35774;&#32622;&#19979;&#30340;&#34920;&#29616;&#35777;&#25454;&#65292;&#21457;&#29616;&#20102;&#19968;&#31867;&#32593;&#32476;&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#23398;&#20064;&#20102;&#26368;&#23567;&#24230;&#25554;&#20540;&#22120;&#65292;&#24182;&#23545;&#38271;&#24230;&#26222;&#36890;&#21270;&#29616;&#35937;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2301.13105</link><description>&lt;p&gt;
&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#12289;&#36923;&#36753;&#25512;&#29702;&#21644;&#23398;&#20301;&#35838;&#31243;&#30340;&#27010;&#36848;
&lt;/p&gt;
&lt;p&gt;
Generalization on the Unseen, Logic Reasoning and Degree Curriculum. (arXiv:2301.13105v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13105
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36923;&#36753;&#25512;&#29702;&#20219;&#21153;&#20013;&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#26550;&#26500;&#22312;&#35813;&#35774;&#32622;&#19979;&#30340;&#34920;&#29616;&#35777;&#25454;&#65292;&#21457;&#29616;&#20102;&#19968;&#31867;&#32593;&#32476;&#27169;&#22411;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#23398;&#20064;&#20102;&#26368;&#23567;&#24230;&#25554;&#20540;&#22120;&#65292;&#24182;&#23545;&#38271;&#24230;&#26222;&#36890;&#21270;&#29616;&#35937;&#25552;&#20379;&#20102;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#36923;&#36753;&#65288;&#24067;&#23572;&#65289;&#20989;&#25968;&#30340;&#23398;&#20064;&#65292;&#37325;&#28857;&#22312;&#20110;&#23545;&#26410;&#30693;&#25968;&#25454;&#30340;&#27867;&#21270;&#65288;GOTU&#65289;&#35774;&#23450;&#65292;&#36825;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#20998;&#24067;&#22806;&#27867;&#21270;&#30340;&#26696;&#20363;&#12290;&#36825;&#26159;&#30001;&#20110;&#26576;&#20123;&#25512;&#29702;&#20219;&#21153;&#65288;&#20363;&#22914;&#31639;&#26415;/&#36923;&#36753;&#65289;&#20013;&#25968;&#25454;&#30340;&#20016;&#23500;&#32452;&#21512;&#24615;&#36136;&#20351;&#24471;&#20195;&#34920;&#24615;&#25968;&#25454;&#37319;&#26679;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#19988;&#22312;GOTU&#19979;&#25104;&#21151;&#23398;&#20064;&#20026;&#31532;&#19968;&#20010;&#8220;&#25512;&#29702;&#8221;&#23398;&#20064;&#32773;&#23637;&#31034;&#20102;&#19968;&#20010;&#23567;&#25554;&#22270;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;(S)GD&#35757;&#32451;&#30340;&#19981;&#21516;&#32593;&#32476;&#26550;&#26500;&#22312;GOTU&#19979;&#30340;&#34920;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#25454;&#65292;&#35777;&#26126;&#20102;&#19968;&#20010;&#31867;&#21035;&#30340;&#32593;&#32476;&#27169;&#22411;&#65288;&#21253;&#25324;Transformer&#30340;&#23454;&#20363;&#12289;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#23545;&#35282;&#32447;&#32447;&#24615;&#32593;&#32476;&#65289;&#22312;&#26410;&#30693;&#25968;&#25454;&#19978;&#23398;&#20064;&#20102;&#26368;&#23567;&#24230;&#25554;&#20540;&#22120;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;&#20854;&#20182;&#20855;&#26377;&#26356;&#22823;&#23398;&#20064;&#36895;&#29575;&#25110;&#22343;&#22330;&#32593;&#32476;&#30340;&#23454;&#20363;&#36798;&#21040;&#20102;&#28183;&#28431;&#26368;&#23567;&#24230;&#35299;&#12290;&#36825;&#20123;&#21457;&#29616;&#24102;&#26469;&#20102;&#20004;&#20010;&#24433;&#21709;&#65306;&#65288;1&#65289;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#38271;&#24230;&#26222;&#36890;&#21270;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
This paper considers the learning of logical (Boolean) functions with focus on the generalization on the unseen (GOTU) setting, a strong case of out-of-distribution generalization. This is motivated by the fact that the rich combinatorial nature of data in certain reasoning tasks (e.g., arithmetic/logic) makes representative data sampling challenging, and learning successfully under GOTU gives a first vignette of an 'extrapolating' or 'reasoning' learner. We then study how different network architectures trained by (S)GD perform under GOTU and provide both theoretical and experimental evidence that for a class of network models including instances of Transformers, random features models, and diagonal linear networks, a min-degree-interpolator is learned on the unseen. We also provide evidence that other instances with larger learning rates or mean-field networks reach leaky min-degree solutions. These findings lead to two implications: (1) we provide an explanation to the length genera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32467;&#21512;&#39118;&#38505;&#22235;&#26041;&#29702;&#35770;&#65292;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;SVR&#30340;&#20004;&#31181;&#24418;&#24335;&#23545;&#24212;&#20110;&#31561;&#25928;&#35823;&#24046;&#24230;&#37327;&#30340;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#21152;&#19978;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#12290;&#36890;&#36807;&#26500;&#36896;&#22522;&#26412;&#39118;&#38505;&#22235;&#26041;&#26694;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SVR&#26159;&#23545;&#20004;&#20010;&#23545;&#31216;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24179;&#22343;&#25968;&#30340;&#28176;&#36817;&#26080;&#20559;&#20272;&#35745;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$\varepsilon$-SVR&#21644;$\nu$-SVR&#22312;&#19968;&#33324;&#38543;&#26426;&#29615;&#22659;&#19979;&#30340;&#31561;&#20215;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.09178</link><description>&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;: &#39118;&#38505;&#22235;&#26041;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Support Vector Regression: Risk Quadrangle Framework. (arXiv:2212.09178v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09178
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32467;&#21512;&#39118;&#38505;&#22235;&#26041;&#29702;&#35770;&#65292;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#65292;SVR&#30340;&#20004;&#31181;&#24418;&#24335;&#23545;&#24212;&#20110;&#31561;&#25928;&#35823;&#24046;&#24230;&#37327;&#30340;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#21152;&#19978;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#12290;&#36890;&#36807;&#26500;&#36896;&#22522;&#26412;&#39118;&#38505;&#22235;&#26041;&#26694;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SVR&#26159;&#23545;&#20004;&#20010;&#23545;&#31216;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24179;&#22343;&#25968;&#30340;&#28176;&#36817;&#26080;&#20559;&#20272;&#35745;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;$\varepsilon$-SVR&#21644;$\nu$-SVR&#22312;&#19968;&#33324;&#38543;&#26426;&#29615;&#22659;&#19979;&#30340;&#31561;&#20215;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22522;&#26412;&#30340;&#39118;&#38505;&#22235;&#26041;&#29702;&#35770;&#30340;&#32972;&#26223;&#19979;&#30740;&#31350;&#20102;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;SVR&#65289;&#65292;&#35813;&#29702;&#35770;&#23558;&#20248;&#21270;&#12289;&#39118;&#38505;&#31649;&#29702;&#21644;&#32479;&#35745;&#20272;&#35745;&#32852;&#31995;&#36215;&#26469;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;SVR&#30340;&#20004;&#31181;&#24418;&#24335;&#65292;$\varepsilon$-SVR&#21644;$\nu$-SVR&#65292;&#37117;&#23545;&#24212;&#20110;&#31561;&#25928;&#35823;&#24046;&#24230;&#37327;&#65288;&#20998;&#21035;&#20026;Vapnik&#35823;&#24046;&#21644;CVaR&#33539;&#25968;&#65289;&#30340;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#21152;&#19978;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#12290;&#36825;&#20123;&#35823;&#24046;&#24230;&#37327;&#21448;&#23450;&#20041;&#20102;&#30456;&#24212;&#30340;&#39118;&#38505;&#22235;&#26041;&#26694;&#12290;&#36890;&#36807;&#26500;&#36896;&#19982;SVR&#23545;&#24212;&#30340;&#22522;&#26412;&#39118;&#38505;&#22235;&#26041;&#26694;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SVR&#26159;&#20004;&#20010;&#23545;&#31216;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#24179;&#22343;&#25968;&#30340;&#28176;&#36817;&#26080;&#20559;&#20272;&#35745;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#19968;&#33324;&#38543;&#26426;&#29615;&#22659;&#20013;&#35777;&#26126;&#20102;$\varepsilon$-SVR&#21644;$\nu$-SVR&#30340;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;SVR&#34987;&#34920;&#36848;&#20026;&#24102;&#26377;&#27491;&#21017;&#21270;&#24809;&#32602;&#39033;&#30340;&#27491;&#21017;&#20559;&#31163;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25512;&#23548;&#20102;&#22312;&#39118;&#38505;&#22235;&#26041;&#26694;&#26550;&#20013;&#30340;SVR&#30340;&#23545;&#20598;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates Support Vector Regression (SVR) in the context of the fundamental risk quadrangle theory, which links optimization, risk management, and statistical estimation. It is shown that both formulations of SVR, $\varepsilon$-SVR and $\nu$-SVR, correspond to the minimization of equivalent error measures (Vapnik error and CVaR norm, respectively) with a regularization penalty. These error measures, in turn, define the corresponding risk quadrangles. By constructing the fundamental risk quadrangle, which corresponds to SVR, we show that SVR is the asymptotically unbiased estimator of the average of two symmetric conditional quantiles. Further, we prove the equivalence of the $\varepsilon$-SVR and $\nu$-SVR in a general stochastic setting. Additionally, SVR is formulated as a regular deviation minimization problem with a regularization penalty. Finally, the dual formulation of SVR in the risk quadrangle framework is derived.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#39640;&#26031;&#36807;&#31243;&#30340;&#22797;&#21512;&#26680;&#26469;&#23558;&#20808;&#39564;&#30693;&#35782;&#34701;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#38544;&#24335;&#23450;&#20041;&#30340;&#31070;&#32463;&#32593;&#32476;&#26680;&#20989;&#25968;&#21644;&#36873;&#25321;&#30340;&#31532;&#20108;&#20010;&#26680;&#20989;&#25968;&#65292;&#21487;&#20197;&#27169;&#25311;&#24050;&#30693;&#29305;&#24615;&#65292;&#24182;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.07384</link><description>&lt;p&gt;
&#36890;&#36807;&#38544;&#24335;&#22797;&#21512;&#26680;&#23558;&#20808;&#39564;&#30693;&#35782;&#34701;&#20837;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.07384
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#21644;&#39640;&#26031;&#36807;&#31243;&#30340;&#22797;&#21512;&#26680;&#26469;&#23558;&#20808;&#39564;&#30693;&#35782;&#34701;&#20837;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#38544;&#24335;&#23450;&#20041;&#30340;&#31070;&#32463;&#32593;&#32476;&#26680;&#20989;&#25968;&#21644;&#36873;&#25321;&#30340;&#31532;&#20108;&#20010;&#26680;&#20989;&#25968;&#65292;&#21487;&#20197;&#27169;&#25311;&#24050;&#30693;&#29305;&#24615;&#65292;&#24182;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#23548;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#23398;&#20064;&#20197;&#20808;&#39564;&#30693;&#35782;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#35768;&#22810;&#24050;&#30693;&#29305;&#24615;&#65292;&#22914;&#31354;&#38388;&#24179;&#28369;&#24615;&#25110;&#23395;&#33410;&#24615;&#65292;&#22312;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20013;&#36890;&#36807;&#36873;&#25321;&#36866;&#24403;&#30340;&#26680;&#20989;&#25968;&#26469;&#24314;&#27169;&#26159;&#30452;&#25509;&#30340;&#12290;&#35768;&#22810;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#21487;&#20197;&#36890;&#36807;&#24314;&#27169;&#36825;&#20123;&#24050;&#30693;&#29305;&#24615;&#26469;&#25913;&#36827;&#12290;&#20363;&#22914;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNNs&#65289;&#24191;&#27867;&#29992;&#20110;&#36965;&#24863;&#65292;&#36825;&#21463;&#21040;&#24378;&#28872;&#30340;&#23395;&#33410;&#25928;&#24212;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#20351;&#29992;&#30001;&#31070;&#32463;&#32593;&#32476;&#38544;&#24335;&#23450;&#20041;&#30340;&#26680;&#20989;&#25968;&#19982;&#36873;&#25321;&#29992;&#20110;&#24314;&#27169;&#24050;&#30693;&#29305;&#24615;&#30340;&#31532;&#20108;&#20010;&#26680;&#20989;&#25968;&#65288;&#20363;&#22914;&#23395;&#33410;&#24615;&#65289;&#30456;&#32467;&#21512;&#30340;&#22797;&#21512;&#26680;&#26469;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#21644;GP&#30340;&#24314;&#27169;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#28145;&#24230;&#32593;&#32476;&#21644;&#22522;&#20110;Nystrom&#36817;&#20284;&#30340;&#39640;&#25928;&#26144;&#23556;&#30456;&#32467;&#21512;&#26469;&#23454;&#29616;&#36825;&#19968;&#24819;&#27861;&#65292;&#23558;&#20854;&#31216;&#20026;&#38544;&#24335;&#22797;&#21512;&#26680;&#65288;ICK&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#37319;&#29992;&#26679;&#26412;&#20248;&#21270;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#23436;&#25972;&#30340;GP&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;ICK&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#22312;&#36965;&#24863;&#21644;&#26102;&#38388;&#24207;&#21015;&#30340;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is challenging to guide neural network (NN) learning with prior knowledge. In contrast, many known properties, such as spatial smoothness or seasonality, are straightforward to model by choosing an appropriate kernel in a Gaussian process (GP). Many deep learning applications could be enhanced by modeling such known properties. For example, convolutional neural networks (CNNs) are frequently used in remote sensing, which is subject to strong seasonal effects. We propose to blend the strengths of deep learning and the clear modeling capabilities of GPs by using a composite kernel that combines a kernel implicitly defined by a neural network with a second kernel function chosen to model known properties (e.g., seasonality). We implement this idea by combining a deep network and an efficient mapping based on the Nystrom approximation, which we call Implicit Composite Kernel (ICK). We then adopt a sample-then-optimize approach to approximate the full GP posterior distribution. We demons
&lt;/p&gt;</description></item><item><title>PARNN&#26159;&#19968;&#31181;&#27010;&#29575;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#20855;&#26377;&#38750;&#24179;&#31283;&#24615;&#12289;&#38750;&#32447;&#24615;&#12289;&#38750;&#21608;&#26399;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#21644;&#28151;&#27788;&#27169;&#24335;&#30340;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#39044;&#27979;&#21306;&#38388;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2204.09640</link><description>&lt;p&gt;
&#20934;&#30830;&#30340;&#38271;&#26399;&#39044;&#27979;&#30340;&#27010;&#29575;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Probabilistic AutoRegressive Neural Networks for Accurate Long-range Forecasting. (arXiv:2204.09640v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.09640
&lt;/p&gt;
&lt;p&gt;
PARNN&#26159;&#19968;&#31181;&#27010;&#29575;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#20855;&#26377;&#38750;&#24179;&#31283;&#24615;&#12289;&#38750;&#32447;&#24615;&#12289;&#38750;&#21608;&#26399;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#21644;&#28151;&#27788;&#27169;&#24335;&#30340;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#39044;&#27979;&#21306;&#38388;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26159;&#19968;&#20010;&#20005;&#37325;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#24212;&#29992;&#33539;&#22260;&#20174;&#32929;&#31080;&#20215;&#26684;&#21040;&#26089;&#26399;&#20256;&#26579;&#30149;&#39044;&#27979;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20294;&#23454;&#38469;&#39044;&#27979;&#38382;&#39064;&#36890;&#24120;&#38656;&#35201;&#23558;&#20256;&#32479;&#39044;&#27979;&#26041;&#27861;&#21644;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#28151;&#21512;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#27010;&#29575;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;PARNN&#65289;&#65292;&#33021;&#22815;&#22788;&#29702;&#34920;&#29616;&#20986;&#38750;&#24179;&#31283;&#24615;&#12289;&#38750;&#32447;&#24615;&#12289;&#38750;&#21608;&#26399;&#24615;&#12289;&#38271;&#26399;&#20381;&#36182;&#21644;&#28151;&#27788;&#27169;&#24335;&#30340;&#22797;&#26434;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;PARNN&#26159;&#36890;&#36807;&#25913;&#36827;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;ARNN&#65289;&#20351;&#29992;&#33258;&#22238;&#24402;&#31215;&#20998;&#31227;&#21160;&#24179;&#22343;&#65288;ARIMA&#65289;&#21453;&#39304;&#35823;&#24046;&#36827;&#34892;&#26500;&#24314;&#30340;&#65292;&#32467;&#21512;&#20102;&#20004;&#31181;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#8220;&#30333;&#30418;&#23376;&#33324;&#8221;&#30340;&#39044;&#27979;&#34892;&#20026;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;PARNN&#27169;&#22411;&#36890;&#36807;&#39044;&#27979;&#21306;&#38388;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#20351;&#20854;&#19982;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#24037;&#20855;&#21306;&#21035;&#24320;&#26469;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecasting time series data is a critical area of research with applications spanning from stock prices to early epidemic prediction. While numerous statistical and machine learning methods have been proposed, real-life prediction problems often require hybrid solutions that bridge classical forecasting approaches and modern neural network models. In this study, we introduce the Probabilistic AutoRegressive Neural Networks (PARNN), capable of handling complex time series data exhibiting non-stationarity, nonlinearity, non-seasonality, long-range dependence, and chaotic patterns. PARNN is constructed by improving autoregressive neural networks (ARNN) using autoregressive integrated moving average (ARIMA) feedback error, combining the explainability, scalability, and "white-box-like" prediction behavior of both models. Notably, the PARNN model provides uncertainty quantification through prediction intervals, setting it apart from advanced deep learning tools. Through comprehensive compu
&lt;/p&gt;</description></item><item><title>PyDTS&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#29983;&#23384;&#25968;&#25454;&#21322;&#21442;&#25968;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#30340;Python&#21253;&#65292;&#25903;&#25345;&#21253;&#25324;LASSO&#21644;&#24377;&#24615;&#32593;&#31561;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2204.05731</link><description>&lt;p&gt;
PyDTS&#65306;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#31454;&#20105;&#39118;&#38505;&#65288;&#27491;&#21017;&#21270;&#65289;&#22238;&#24402;&#30340; Python &#21253;
&lt;/p&gt;
&lt;p&gt;
PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks. (arXiv:2204.05731v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.05731
&lt;/p&gt;
&lt;p&gt;
PyDTS&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#29983;&#23384;&#25968;&#25454;&#21322;&#21442;&#25968;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#30340;Python&#21253;&#65292;&#25903;&#25345;&#21253;&#25324;LASSO&#21644;&#24377;&#24615;&#32593;&#31561;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#33267;&#20107;&#20214;&#20998;&#26512;&#65288;&#29983;&#23384;&#20998;&#26512;&#65289;&#29992;&#20110;&#21709;&#24212;&#26102;&#38388;&#26159;&#25351;&#39044;&#23450;&#20107;&#20214;&#21457;&#29983;&#30340;&#26102;&#38388;&#12290;&#30001;&#20110;&#26102;&#38388;&#26412;&#36523;&#26159;&#31163;&#25955;&#30340;&#25110;&#30001;&#20110;&#23558;&#22833;&#36133;&#26102;&#38388;&#20998;&#32452;&#20026;&#38388;&#38548;&#25110;&#33293;&#20837;&#27979;&#37327;&#65292;&#22240;&#27492;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#26377;&#26102;&#26159;&#31163;&#25955;&#30340;&#12290;&#27492;&#22806;&#65292;&#20010;&#20307;&#30340;&#22833;&#36133;&#21487;&#33021;&#26159;&#20960;&#31181;&#19981;&#21516;&#30340;&#22833;&#36133;&#31867;&#22411;&#20043;&#19968;&#65292;&#31216;&#20026;&#31454;&#20105;&#39118;&#38505;&#65288;&#20107;&#20214;&#65289;&#12290;&#22823;&#22810;&#25968;&#29983;&#23384;&#22238;&#24402;&#20998;&#26512;&#30340;&#26041;&#27861;&#21644;&#36719;&#20214;&#21253;&#20551;&#23450;&#26102;&#38388;&#26159;&#22312;&#36830;&#32493;&#23610;&#24230;&#19978;&#27979;&#37327;&#30340;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#23558;&#26631;&#20934;&#30340;&#36830;&#32493;&#26102;&#38388;&#27169;&#22411;&#24212;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#25968;&#25454;&#21487;&#33021;&#23548;&#33268;&#31163;&#25955;&#26102;&#38388;&#27169;&#22411;&#30340;&#20272;&#35745;&#22120;&#23384;&#22312;&#20559;&#24046;&#12290;&#20171;&#32461;&#20102; Python &#21253; PyDTS&#65292;&#29992;&#20110;&#27169;&#25311;&#65292;&#20272;&#35745;&#21644;&#35780;&#20272;&#31163;&#25955;&#26102;&#38388;&#29983;&#23384;&#25968;&#25454;&#30340;&#21322;&#21442;&#25968;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#12290;&#35813;&#21253;&#23454;&#29616;&#20102;&#24555;&#36895;&#36807;&#31243;&#65292;&#20351;&#26377;&#25928;&#22320;&#21253;&#25324;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;&#65292;&#22914; LASSO &#21644;&#24377;&#24615;&#32593;&#32476;&#31561;&#12290;&#19968;&#20010;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Time-to-event analysis (survival analysis) is used when the response of interest is the time until a pre-specified event occurs. Time-to-event data are sometimes discrete either because time itself is discrete or due to grouping of failure times into intervals or rounding off measurements. In addition, the failure of an individual could be one of several distinct failure types, known as competing risks (events). Most methods and software packages for survival regression analysis assume that time is measured on a continuous scale. It is well-known that naively applying standard continuous-time models with discrete-time data may result in biased estimators of the discrete-time models. The Python package PyDTS, for simulating, estimating and evaluating semi-parametric competing-risks models for discrete-time survival data, is introduced. The package implements a fast procedure that enables including regularized regression methods, such as LASSO and elastic net, among others. A simulation 
&lt;/p&gt;</description></item><item><title>Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2002.01368</link><description>&lt;p&gt;
&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#25193;&#23637;&#31867;&#21035;&#30340;&#24320;&#25918;&#38598;&#23398;&#20064;&#65288;Open-LACU&#65289;
&lt;/p&gt;
&lt;p&gt;
Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.01368
&lt;/p&gt;
&lt;p&gt;
Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#21644;&#24320;&#25918;&#24335;&#35782;&#21035;&#65288;OSR&#65289;&#65292;&#24050;&#32463;&#36827;&#34892;&#20102;&#35768;&#22810;&#23581;&#35797;&#20197;&#21512;&#25104;&#21333;&#20010;&#35757;&#32451;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#27599;&#27425;&#23581;&#35797;&#37117;&#36829;&#21453;&#20102;&#24320;&#25918;&#38598;&#23450;&#20041;&#65292;&#22240;&#20026;&#36825;&#20123;&#26041;&#27861;&#22312;&#26410;&#26631;&#35760;&#30340;&#35757;&#32451;&#38598;&#20013;&#21253;&#21547;&#26032;&#39062;&#30340;&#31867;&#21035;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#20854;&#20013;&#20998;&#31867;&#22120;&#33021;&#22815;&#22312;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#36827;&#34892;&#25512;&#24191;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#32972;&#26223;&#31867;&#21035;&#21644;&#26410;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#26410;&#30693;&#31867;&#21035;&#12290;&#36890;&#36807;&#20998;&#31867;&#36825;&#20004;&#31181;&#26032;&#39062;&#31867;&#21035;&#30340;&#26041;&#24335;&#65292;Open-LACU&#33021;&#22815;&#25552;&#39640;&#35757;&#32451;&#30340;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#24182;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#23545;&#31216;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#38750;&#23545;&#31216;&#23567;&#27874;&#65292;&#23427;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#29616;&#26377;&#22270;&#24418;&#25955;&#23556;&#26550;&#26500;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20026;&#22270;&#24418;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/1911.06253</link><description>&lt;p&gt;
&#20102;&#35299;&#20855;&#26377;&#38750;&#23545;&#31216;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Understanding Graph Neural Networks with Asymmetric Geometric Scattering Transforms. (arXiv:1911.06253v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.06253
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#23545;&#31216;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31867;&#38750;&#23545;&#31216;&#23567;&#27874;&#65292;&#23427;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#29616;&#26377;&#22270;&#24418;&#25955;&#23556;&#26550;&#26500;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#20026;&#26410;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20026;&#22270;&#24418;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25955;&#23556;&#21464;&#25442;&#26159;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#65292;&#20316;&#20026;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#12290;&#26368;&#36817;&#65292;&#26377;&#20960;&#31687;&#24037;&#20316;&#24341;&#20837;&#20102;&#25955;&#23556;&#21464;&#25442;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#35774;&#32622;&#65288;&#22914;&#22270;&#24418;&#65289;&#20013;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;&#36825;&#20123;&#26500;&#36896;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#38750;&#24120;&#19968;&#33324;&#30340;&#38750;&#23545;&#31216;&#23567;&#27874;&#31867;&#30340;&#22270;&#24418;&#31383;&#21475;&#21270;&#21644;&#38750;&#31383;&#21475;&#21270;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#38750;&#23545;&#31216;&#22270;&#24418;&#25955;&#23556;&#21464;&#25442;&#19982;&#23545;&#31216;&#25955;&#23556;&#21464;&#25442;&#26377;&#35768;&#22810;&#30456;&#21516;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#30340;&#26500;&#36896;&#32479;&#19968;&#21644;&#25193;&#23637;&#20102;&#29616;&#26377;&#22270;&#24418;&#25955;&#23556;&#26550;&#26500;&#30340;&#24050;&#30693;&#29702;&#35770;&#32467;&#26524;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#24341;&#20837;&#22823;&#37327;&#24102;&#26377;&#21487;&#35777;&#26126;&#31283;&#23450;&#24615;&#21644;&#19981;&#21464;&#24615;&#20445;&#35777;&#30340;&#32593;&#32476;&#65292;&#26377;&#21161;&#20110;&#24357;&#21512;&#20960;&#20309;&#25955;&#23556;&#21644;&#20854;&#20182;&#22270;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;&#26410;&#26469;&#30340;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#20026;&#22270;&#24418;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scattering transform is a multilayered wavelet-based deep learning architecture that acts as a model of convolutional neural networks. Recently, several works have introduced generalizations of the scattering transform for non-Euclidean settings such as graphs. Our work builds upon these constructions by introducing windowed and non-windowed geometric scattering transforms for graphs based upon a very general class of asymmetric wavelets. We show that these asymmetric graph scattering transforms have many of the same theoretical guarantees as their symmetric counterparts. As a result, the proposed construction unifies and extends known theoretical results for many of the existing graph scattering architectures. In doing so, this work helps bridge the gap between geometric scattering and other graph neural networks by introducing a large family of networks with provable stability and invariance guarantees. These results lay the groundwork for future deep learning architectures for g
&lt;/p&gt;</description></item></channel></rss>