<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20010;&#20307;&#21270;&#30340;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#21518;&#39564;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#23616;&#37096;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#23450;&#20041;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#35780;&#20272;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#21487;&#20197;&#38598;&#25104;&#21518;&#22788;&#29702;&#25193;&#23637;&#27493;&#39588;&#20197;&#20445;&#35777;&#21518;&#39564;&#20272;&#35745;&#30340;&#26080;&#20559;&#24615;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.02413</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#27169;&#25311;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Simulation-Based Inference with Quantile Regression. (arXiv:2401.02413v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02413
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20010;&#20307;&#21270;&#30340;&#20998;&#20301;&#25968;&#26469;&#20272;&#35745;&#21518;&#39564;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#23616;&#37096;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#23450;&#20041;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#35780;&#20272;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#21487;&#20197;&#38598;&#25104;&#21518;&#22788;&#29702;&#25193;&#23637;&#27493;&#39588;&#20197;&#20445;&#35777;&#21518;&#39564;&#20272;&#35745;&#30340;&#26080;&#20559;&#24615;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#20960;&#20046;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#27169;&#25311;&#25512;&#26029;&#65288;Simulation-Based Inference&#65292;SBI&#65289;&#26041;&#27861;&#8212;&#8212;&#31070;&#32463;&#20998;&#20301;&#25968;&#20272;&#35745;&#65288;Neural Quantile Estimation&#65292;NQE&#65289;&#12290;NQE&#36890;&#36807;&#33258;&#22238;&#24402;&#26041;&#24335;&#23398;&#20064;&#27599;&#20010;&#21518;&#39564;&#32500;&#24230;&#30340;&#21333;&#19968;&#32500;&#24230;&#20998;&#20301;&#25968;&#65292;&#20197;&#25968;&#25454;&#21644;&#20043;&#21069;&#30340;&#21518;&#39564;&#32500;&#24230;&#20026;&#26465;&#20214;&#12290;&#21518;&#39564;&#26679;&#26412;&#36890;&#36807;&#20351;&#29992;&#21333;&#35843;&#19977;&#27425;&#22467;&#23572;&#31859;&#29305;&#26679;&#26465;&#25554;&#20540;&#39044;&#27979;&#20998;&#20301;&#25968;&#36827;&#34892;&#33719;&#21462;&#65292;&#24182;&#23545;&#23614;&#37096;&#34892;&#20026;&#21644;&#22810;&#27169;&#24577;&#20998;&#24067;&#36827;&#34892;&#20102;&#29305;&#27530;&#22788;&#29702;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#23616;&#37096;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#65288;CDF&#65289;&#30340;&#36125;&#21494;&#26031;&#21487;&#20449;&#21306;&#38388;&#30340;&#26367;&#20195;&#23450;&#20041;&#65292;&#20854;&#35780;&#20272;&#36895;&#24230;&#27604;&#20256;&#32479;&#30340;&#26368;&#39640;&#21518;&#39564;&#23494;&#24230;&#21306;&#22495;&#65288;HPDR&#65289;&#24555;&#24471;&#22810;&#12290;&#22312;&#27169;&#25311;&#39044;&#31639;&#26377;&#38480;&#21644;/&#25110;&#24050;&#30693;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#23558;&#21518;&#22788;&#29702;&#25193;&#23637;&#27493;&#39588;&#38598;&#25104;&#21040;NQE&#20013;&#65292;&#20197;&#30830;&#20445;&#21518;&#39564;&#20272;&#35745;&#30340;&#26080;&#20559;&#24615;&#65292;&#19988;&#38468;&#21152;&#30340;&#35745;&#31639;&#25104;&#26412;&#21487;&#20197;&#24573;&#30053;&#19981;&#35745;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;NQE&#26041;&#27861;&#36798;&#21040;&#20102;&#26368;&#26032;&#30340;&#30740;&#31350;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Neural Quantile Estimation (NQE), a novel Simulation-Based Inference (SBI) method based on conditional quantile regression. NQE autoregressively learns individual one dimensional quantiles for each posterior dimension, conditioned on the data and previous posterior dimensions. Posterior samples are obtained by interpolating the predicted quantiles using monotonic cubic Hermite spline, with specific treatment for the tail behavior and multi-modal distributions. We introduce an alternative definition for the Bayesian credible region using the local Cumulative Density Function (CDF), offering substantially faster evaluation than the traditional Highest Posterior Density Region (HPDR). In case of limited simulation budget and/or known model misspecification, a post-processing broadening step can be integrated into NQE to ensure the unbiasedness of the posterior estimation with negligible additional computational cost. We demonstrate that the proposed NQE method achieves state-of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#23384;&#22312;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#30740;&#31350;&#24418;&#24335;&#21270;&#21644;&#32479;&#19968;&#20102;&#25552;&#39640;&#27867;&#21270;&#24615;&#21644;&#20811;&#26381;&#36807;&#25311;&#21512;&#30340;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2401.02349</link><description>&lt;p&gt;
&#20998;&#26512;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#27867;&#21270;&#24615;&#33021;&#30340;&#35843;&#26597;
&lt;/p&gt;
&lt;p&gt;
A Survey Analyzing Generalization in Deep Reinforcement Learning. (arXiv:2401.02349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#23384;&#22312;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#30740;&#31350;&#24418;&#24335;&#21270;&#21644;&#32479;&#19968;&#20102;&#25552;&#39640;&#27867;&#21270;&#24615;&#21644;&#20811;&#26381;&#36807;&#25311;&#21512;&#30340;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#39640;&#32500;&#29366;&#24577;&#25110;&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#38382;&#39064;&#65292;&#24378;&#21270;&#23398;&#20064;&#30740;&#31350;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#37325;&#35201;&#30340;&#25104;&#21151;&#21644;&#20851;&#27880;&#12290;&#23613;&#31649;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30446;&#21069;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#27491;&#22312;&#34987;&#24212;&#29992;&#65292;&#20174;&#21307;&#30103;&#24212;&#29992;&#21040;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#65292;&#20294;&#20851;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30340;&#27867;&#21270;&#33021;&#21147;&#20173;&#26377;&#35768;&#22810;&#24453;&#35299;&#31572;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#27010;&#36848;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#36935;&#21040;&#36807;&#25311;&#21512;&#38382;&#39064;&#30340;&#26681;&#26412;&#21407;&#22240;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23545;&#25552;&#39640;&#27867;&#21270;&#24615;&#21644;&#20811;&#26381;&#29366;&#24577;-&#21160;&#20316;&#20540;&#20989;&#25968;&#20013;&#30340;&#36807;&#25311;&#21512;&#30340;&#19981;&#21516;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#24418;&#24335;&#21270;&#21644;&#32479;&#19968;&#12290;&#25105;&#20204;&#30456;&#20449;&#25105;&#20204;&#30340;&#30740;&#31350;&#21487;&#20197;&#20026;&#24403;&#21069;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#36827;&#23637;&#25552;&#20379;&#19968;&#20010;&#31616;&#27905;&#31995;&#32479;&#30340;&#32479;&#19968;&#20998;&#26512;&#65292;&#24182;&#26377;&#21161;&#20110;&#26500;&#24314;&#20581;&#22766;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning research obtained significant success and attention with the utilization of deep neural networks to solve problems in high dimensional state or action spaces. While deep reinforcement learning policies are currently being deployed in many different fields from medical applications to self driving vehicles, there are still ongoing questions the field is trying to answer on the generalization capabilities of deep reinforcement learning policies. In this paper, we will outline the fundamental reasons why deep reinforcement learning policies encounter overfitting problems that limit their robustness and generalization capabilities. Furthermore, we will formalize and unify the diverse solution approaches to increase generalization, and overcome overfitting in state-action value functions. We believe our study can provide a compact systematic unified analysis for the current advancements in deep reinforcement learning, and help to construct robust deep neural policies 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#20989;&#25968;&#65292;&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#25429;&#25417;&#22122;&#22768;&#24182;&#35843;&#25972;&#21442;&#25968;&#26469;&#22686;&#24378;&#23545;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#12290;&#23454;&#35777;&#27979;&#35797;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02325</link><description>&lt;p&gt;
&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#21487;&#35299;&#37322;&#21442;&#25968;&#35843;&#25972;&#30340;&#40065;&#26834;&#20998;&#20301;&#25968;Huber&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
A Robust Quantile Huber Loss With Interpretable Parameter Adjustment In Distributional Reinforcement Learning. (arXiv:2401.02325v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02325
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#20989;&#25968;&#65292;&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#20013;&#36890;&#36807;&#25429;&#25417;&#22122;&#22768;&#24182;&#35843;&#25972;&#21442;&#25968;&#26469;&#22686;&#24378;&#23545;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#12290;&#23454;&#35777;&#27979;&#35797;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#26368;&#23567;&#21270;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#20989;&#25968;&#26469;&#20272;&#35745;&#22238;&#25253;&#20998;&#24067;&#65292;&#35813;&#20989;&#25968;&#20174;&#39640;&#26031;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#35745;&#31639;&#20013;&#20135;&#29983;&#65292;&#25429;&#25417;&#21040;&#24403;&#21069;&#21644;&#30446;&#26631;&#20998;&#20301;&#25968;&#20540;&#20013;&#30340;&#22122;&#22768;&#12290;&#19982;&#32463;&#20856;&#30340;&#20998;&#20301;&#25968;Huber&#25439;&#22833;&#30456;&#27604;&#65292;&#36825;&#31181;&#21019;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#22686;&#24378;&#20102;&#23545;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#36817;&#20284;&#25968;&#25454;&#20013;&#22122;&#22768;&#30340;&#25968;&#37327;&#26469;&#35843;&#25972;&#21442;&#25968;&#12290;&#23454;&#35777;&#27979;&#35797;&#22312;&#20998;&#24067;&#24378;&#21270;&#23398;&#20064;&#30340;&#24120;&#35265;&#24212;&#29992;Atari&#28216;&#25103;&#21644;&#26368;&#36817;&#30340;&#23545;&#20914;&#31574;&#30053;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distributional Reinforcement Learning (RL) estimates return distribution mainly by learning quantile values via minimizing the quantile Huber loss function, entailing a threshold parameter often selected heuristically or via hyperparameter search, which may not generalize well and can be suboptimal. This paper introduces a generalized quantile Huber loss function derived from Wasserstein distance (WD) calculation between Gaussian distributions, capturing noise in predicted (current) and target (Bellman-updated) quantile values. Compared to the classical quantile Huber loss, this innovative loss function enhances robustness against outliers. Notably, the classical Huber loss function can be seen as an approximation of our proposed loss, enabling parameter adjustment by approximating the amount of noise in the data during the learning process. Empirical tests on Atari games, a common application in distributional RL, and a recent hedging strategy using distributional RL, validate the eff
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#21464;&#37327;t&#20998;&#24067;&#30340;&#40065;&#26834;&#21452;&#32447;&#24615;&#22240;&#23376;&#20998;&#26512;&#65288;tbfa&#65289;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#37325;&#23614;&#25110;&#21463;&#27745;&#26579;&#30340;&#30697;&#38453;&#25968;&#25454;&#20013;&#21516;&#26102;&#25552;&#21462;&#34892;&#21644;&#21015;&#21464;&#37327;&#30340;&#20844;&#20849;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2401.02203</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#21464;&#37327;t&#20998;&#24067;&#30340;&#40065;&#26834;&#21452;&#32447;&#24615;&#22240;&#23376;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Robust bilinear factor analysis based on the matrix-variate $t$ distribution. (arXiv:2401.02203v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30697;&#38453;&#21464;&#37327;t&#20998;&#24067;&#30340;&#40065;&#26834;&#21452;&#32447;&#24615;&#22240;&#23376;&#20998;&#26512;&#65288;tbfa&#65289;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#37325;&#23614;&#25110;&#21463;&#27745;&#26579;&#30340;&#30697;&#38453;&#25968;&#25454;&#20013;&#21516;&#26102;&#25552;&#21462;&#34892;&#21644;&#21015;&#21464;&#37327;&#30340;&#20844;&#20849;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22810;&#20803;t&#20998;&#24067;&#30340;&#22240;&#23376;&#20998;&#26512;&#65288;tfa&#65289;&#26159;&#19968;&#31181;&#22312;&#37325;&#23614;&#25110;&#21463;&#27745;&#26579;&#25968;&#25454;&#19978;&#25552;&#21462;&#20844;&#20849;&#22240;&#23376;&#30340;&#26377;&#29992;&#30340;&#40065;&#26834;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;tfa&#21482;&#36866;&#29992;&#20110;&#21521;&#37327;&#25968;&#25454;&#12290;&#24403;tfa&#24212;&#29992;&#20110;&#30697;&#38453;&#25968;&#25454;&#26102;&#65292;&#36890;&#24120;&#20250;&#20808;&#23558;&#30697;&#38453;&#35266;&#27979;&#21521;&#37327;&#21270;&#12290;&#36825;&#24102;&#26469;&#20102;&#20004;&#20010;&#25361;&#25112;&#65306;&#65288;i&#65289;&#25968;&#25454;&#30340;&#22266;&#26377;&#30697;&#38453;&#32467;&#26500;&#34987;&#30772;&#22351;&#65292;&#65288;ii&#65289;&#40065;&#26834;&#24615;&#21487;&#33021;&#20002;&#22833;&#65292;&#22240;&#20026;&#21521;&#37327;&#21270;&#30340;&#30697;&#38453;&#25968;&#25454;&#36890;&#24120;&#20250;&#23548;&#33268;&#36739;&#39640;&#30340;&#25968;&#25454;&#32500;&#24230;&#65292;&#36825;&#23481;&#26131;&#23548;&#33268;tfa&#30340;&#23849;&#28291;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#26412;&#25991;&#20174;&#30697;&#38453;&#25968;&#25454;&#30340;&#20869;&#22312;&#32467;&#26500;&#20986;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#22240;&#23376;&#20998;&#26512;&#27169;&#22411;&#65292;&#21363;&#22522;&#20110;&#30697;&#38453;&#21464;&#37327;t&#20998;&#24067;&#30340;&#21452;&#32447;&#24615;&#22240;&#23376;&#20998;&#26512;&#65288;tbfa&#65289;&#12290;&#20854;&#21019;&#26032;&#20043;&#22788;&#22312;&#20110;&#23427;&#33021;&#22815;&#21516;&#26102;&#23545;&#24863;&#20852;&#36259;&#30340;&#34892;&#21644;&#21015;&#21464;&#37327;&#20174;&#37325;&#23614;&#25110;&#21463;&#27745;&#26579;&#30340;&#30697;&#38453;&#25968;&#25454;&#20013;&#25552;&#21462;&#20844;&#20849;&#22240;&#23376;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#39640;&#25928;&#31639;&#27861;&#26469;&#27714;&#35299;&#27169;&#22411;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Factor Analysis based on multivariate $t$ distribution ($t$fa) is a useful robust tool for extracting common factors on heavy-tailed or contaminated data. However, $t$fa is only applicable to vector data. When $t$fa is applied to matrix data, it is common to first vectorize the matrix observations. This introduces two challenges for $t$fa: (i) the inherent matrix structure of the data is broken, and (ii) robustness may be lost, as vectorized matrix data typically results in a high data dimension, which could easily lead to the breakdown of $t$fa. To address these issues, starting from the intrinsic matrix structure of matrix data, a novel robust factor analysis model, namely bilinear factor analysis built on the matrix-variate $t$ distribution ($t$bfa), is proposed in this paper. The novelty is that it is capable to simultaneously extract common factors for both row and column variables of interest on heavy-tailed or contaminated matrix data. Two efficient algorithms for maximum likeli
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.02080</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#29992;&#20110;&#39640;&#25928;&#37319;&#26679;Boltzmann&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Energy based diffusion generator for efficient sampling of Boltzmann distributions. (arXiv:2401.02080v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02080
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#27169;&#22411;&#21644;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#25193;&#25955;&#29983;&#25104;&#22120;&#30340;&#26032;&#22411;&#37319;&#26679;&#22120;&#65292;&#29992;&#20110;&#20174;&#20219;&#24847;&#30446;&#26631;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#37319;&#26679;&#27169;&#22411;&#37319;&#29992;&#31867;&#20284;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#65292;&#21033;&#29992;&#35299;&#30721;&#22120;&#23558;&#26469;&#33258;&#31616;&#21333;&#20998;&#24067;&#30340;&#28508;&#22312;&#21464;&#37327;&#36716;&#25442;&#20026;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#38543;&#26426;&#21464;&#37327;&#65292;&#24182;&#35774;&#35745;&#20102;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#32534;&#30721;&#22120;&#12290;&#21033;&#29992;&#25193;&#25955;&#27169;&#22411;&#23545;&#22797;&#26434;&#20998;&#24067;&#30340;&#24378;&#22823;&#24314;&#27169;&#33021;&#21147;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#29983;&#25104;&#26679;&#26412;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#20934;&#30830;&#21464;&#20998;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24191;&#20041;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#30340;&#35299;&#30721;&#22120;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#37319;&#26679;&#24615;&#33021;&#12290;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#22797;&#26434;&#20998;&#24067;&#20989;&#25968;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#20854;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel sampler called the energy based diffusion generator for generating samples from arbitrary target distributions. The sampling model employs a structure similar to a variational autoencoder, utilizing a decoder to transform latent variables from a simple distribution into random variables approximating the target distribution, and we design an encoder based on the diffusion model. Leveraging the powerful modeling capacity of the diffusion model for complex distributions, we can obtain an accurate variational estimate of the Kullback-Leibler divergence between the distributions of the generated samples and the target. Moreover, we propose a decoder based on generalized Hamiltonian dynamics to further enhance sampling performance. Through empirical evaluation, we demonstrate the effectiveness of our method across various complex distribution functions, showcasing its superiority compared to existing methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21746;&#23398;&#25991;&#29486;&#30340;&#26032;&#30340;&#20449;&#20219;&#26694;&#26550;$\mathcal{U}$-&#20449;&#20219;&#24230;&#65292;&#29992;&#20110;&#35780;&#20272;AI&#31995;&#32479;&#30340;&#20449;&#20219;&#24615;&#65292;&#35813;&#26694;&#26550;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#20197;&#20811;&#26381;&#20559;&#35265;&#21644;&#35823;&#23548;&#24615;&#20449;&#20219;&#35780;&#20272;&#30340;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2401.02062</link><description>&lt;p&gt;
U-&#20449;&#20219;&#27169;&#22411; - &#20915;&#31574;&#20013;&#30340;&#21487;&#38752;&#24615;&#12289;&#33021;&#21147;&#21644;&#20449;&#24515;
&lt;/p&gt;
&lt;p&gt;
U-Trustworthy Models.Reliability, Competence, and Confidence in Decision-Making. (arXiv:2401.02062v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02062
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21746;&#23398;&#25991;&#29486;&#30340;&#26032;&#30340;&#20449;&#20219;&#26694;&#26550;$\mathcal{U}$-&#20449;&#20219;&#24230;&#65292;&#29992;&#20110;&#35780;&#20272;AI&#31995;&#32479;&#30340;&#20449;&#20219;&#24615;&#65292;&#35813;&#26694;&#26550;&#25361;&#25112;&#20102;&#20256;&#32479;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#26041;&#26696;&#20197;&#20811;&#26381;&#20559;&#35265;&#21644;&#35823;&#23548;&#24615;&#20449;&#20219;&#35780;&#20272;&#30340;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;&#39044;&#27979;&#27169;&#22411;&#20013;&#20559;&#35265;&#21644;&#27495;&#35270;&#30340;&#25285;&#24551;&#26085;&#30410;&#22686;&#38271;&#65292;&#20154;&#24037;&#26234;&#33021;&#31038;&#21306;&#36234;&#26469;&#36234;&#20851;&#27880;&#35780;&#20272;AI&#31995;&#32479;&#30340;&#20449;&#20219;&#24615;&#12290;&#20256;&#32479;&#19978;&#65292;&#20449;&#20219;&#30340;AI&#25991;&#29486;&#20381;&#36182;&#20110;&#27010;&#29575;&#26694;&#26550;&#21644;&#26657;&#20934;&#20316;&#20026;&#20449;&#20219;&#30340;&#20808;&#20915;&#26465;&#20214;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#31163;&#24320;&#20102;&#36825;&#20010;&#35266;&#28857;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#21746;&#23398;&#25991;&#29486;&#20013;&#20851;&#20110;&#20449;&#20219;&#30340;&#21551;&#31034;&#30340;&#26032;&#30340;&#20449;&#20219;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31934;&#30830;&#30340;&#25968;&#23398;&#23450;&#20041;&#65292;&#31216;&#20026;$\mathcal{U}$-&#20449;&#20219;&#24230;&#65292;&#19987;&#38376;&#20026;&#26368;&#22823;&#21270;&#25928;&#29992;&#20989;&#25968;&#30340;&#20219;&#21153;&#23376;&#38598;&#37327;&#36523;&#23450;&#21046;&#12290;&#25105;&#20204;&#35748;&#20026;&#19968;&#20010;&#27169;&#22411;&#30340;$\mathcal{U}$-&#20449;&#20219;&#24230;&#21462;&#20915;&#20110;&#23427;&#22312;&#36825;&#20010;&#20219;&#21153;&#23376;&#38598;&#20013;&#26368;&#22823;&#21270;&#36125;&#21494;&#26031;&#25928;&#29992;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#32452;&#32467;&#26524;&#25361;&#25112;&#20102;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#23637;&#31034;&#23427;&#21487;&#33021;&#20559;&#21521;&#19981;&#22826;&#21487;&#20449;&#30340;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#35823;&#23548;&#24615;&#20449;&#20219;&#35780;&#20272;&#30340;&#39118;&#38505;&#12290;&#22312;$\mathcal{U}$-&#20449;&#20219;&#24230;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#24182;&#25552;&#39640;&#27169;&#22411;&#30340;&#20449;&#20219;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
With growing concerns regarding bias and discrimination in predictive models, the AI community has increasingly focused on assessing AI system trustworthiness. Conventionally, trustworthy AI literature relies on the probabilistic framework and calibration as prerequisites for trustworthiness. In this work, we depart from this viewpoint by proposing a novel trust framework inspired by the philosophy literature on trust. We present a precise mathematical definition of trustworthiness, termed $\mathcal{U}$-trustworthiness, specifically tailored for a subset of tasks aimed at maximizing a utility function. We argue that a model's $\mathcal{U}$-trustworthiness is contingent upon its ability to maximize Bayes utility within this task subset. Our first set of results challenges the probabilistic framework by demonstrating its potential to favor less trustworthy models and introduce the risk of misleading trustworthiness assessments. Within the context of $\mathcal{U}$-trustworthiness, we prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#21449;&#29109;&#31867;&#21035;&#19981;&#24179;&#34913;&#23398;&#20064;&#20013;&#30340;&#31070;&#32463;&#25240;&#21472;&#29616;&#35937;&#65292;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#25240;&#21472;&#20173;&#28982;&#23384;&#22312;&#65292;&#20294;&#31867;&#22343;&#20540;&#30340;&#20960;&#20309;&#29305;&#24615;&#20250;&#21457;&#29983;&#20559;&#31227;&#12290;</title><link>http://arxiv.org/abs/2401.02058</link><description>&lt;p&gt;
&#20351;&#29992;&#26080;&#32422;&#26463;ReLU&#29305;&#24449;&#27169;&#22411;&#36827;&#34892;&#20132;&#21449;&#29109;&#31867;&#21035;&#19981;&#24179;&#34913;&#23398;&#20064;&#30340;&#31070;&#32463;&#25240;&#21472;
&lt;/p&gt;
&lt;p&gt;
Neural Collapse for Cross-entropy Class-Imbalanced Learning with Unconstrained ReLU Feature Model. (arXiv:2401.02058v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20132;&#21449;&#29109;&#31867;&#21035;&#19981;&#24179;&#34913;&#23398;&#20064;&#20013;&#30340;&#31070;&#32463;&#25240;&#21472;&#29616;&#35937;&#65292;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#25240;&#21472;&#20173;&#28982;&#23384;&#22312;&#65292;&#20294;&#31867;&#22343;&#20540;&#30340;&#20960;&#20309;&#29305;&#24615;&#20250;&#21457;&#29983;&#20559;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#30340;&#33539;&#24335;&#21253;&#25324;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#65292;&#23558;&#35757;&#32451;&#25439;&#22833;&#20540;&#25512;&#21521;&#38646;&#65292;&#21363;&#20351;&#35757;&#32451;&#35823;&#24046;&#24050;&#32463;&#28040;&#22833;&#12290;&#22312;&#35757;&#32451;&#30340;&#26368;&#21518;&#38454;&#27573;&#65292;&#35266;&#23519;&#21040;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#20250;&#25240;&#21472;&#21040;&#23427;&#20204;&#30340;&#31867;&#22343;&#20540;&#65292;&#24182;&#19988;&#36825;&#20123;&#31867;&#22343;&#20540;&#20250;&#25910;&#25947;&#21040;&#19968;&#20010;&#31616;&#21333;&#20856;&#22411;&#31561;&#35282;&#32039;&#26694;&#65288;ETF&#65289;&#30340;&#39030;&#28857;&#12290;&#36825;&#19968;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#25240;&#21472;&#65288;NC&#65289;&#12290;&#20026;&#20102;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#36825;&#19968;&#29616;&#35937;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#20351;&#29992;&#20102;&#19968;&#20010;&#31616;&#21270;&#30340;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#26469;&#35777;&#26126;NC&#20986;&#29616;&#22312;&#35757;&#32451;&#38382;&#39064;&#30340;&#20840;&#23616;&#35299;&#20013;&#12290;&#28982;&#32780;&#65292;&#24403;&#35757;&#32451;&#25968;&#25454;&#38598;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#26102;&#65292;&#19968;&#20123;NC&#29305;&#24615;&#23558;&#19981;&#20877;&#25104;&#31435;&#12290;&#20363;&#22914;&#65292;&#24403;&#25439;&#22833;&#25910;&#25947;&#26102;&#65292;&#31867;&#22343;&#20540;&#20960;&#20309;&#20250;&#20559;&#31163;&#31616;&#21333;&#20856;&#22411;&#31561;&#35282;&#32039;&#26694;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;NC&#25512;&#24191;&#21040;&#19981;&#24179;&#34913;&#24773;&#20917;&#19979;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#21644;&#26080;&#32422;&#26463;ReLU&#29305;&#24449;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#35757;&#32451;&#38382;&#39064;&#30340;&#20840;&#23616;&#35299;&#20013;&#65292;&#24403;&#23384;&#22312;&#31867;&#21035;&#19981;&#24179;&#34913;&#26102;&#65292;NC&#20173;&#28982;&#23384;&#22312;&#65292;&#20294;&#23545;&#20110;&#31867;&#22343;&#20540;&#30340;&#20960;&#20309;&#29305;&#24615;&#20250;&#21457;&#29983;&#20559;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;
The current paradigm of training deep neural networks for classification tasks includes minimizing the empirical risk that pushes the training loss value towards zero, even after the training error has been vanished. In this terminal phase of training, it has been observed that the last-layer features collapse to their class-means and these class-means converge to the vertices of a simplex Equiangular Tight Frame (ETF). This phenomenon is termed as Neural Collapse (NC). To theoretically understand this phenomenon, recent works employ a simplified unconstrained feature model to prove that NC emerges at the global solutions of the training problem. However, when the training dataset is class-imbalanced, some NC properties will no longer be true. For example, the class-means geometry will skew away from the simplex ETF when the loss converges. In this paper, we generalize NC to imbalanced regime for cross-entropy loss under the unconstrained ReLU feature model. We prove that, while the wi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25345;&#32493;&#33021;&#37327;&#26041;&#27861;&#30740;&#31350;&#20102;${\Lambda}$CDM&#23431;&#23449;&#23398;&#20013;&#30340;&#23618;&#27425;&#32858;&#31867;&#65292;&#21457;&#29616;&#25345;&#32493;&#33021;&#37327;&#19982;&#32418;&#31227;&#20540;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#25581;&#31034;&#20102;&#23431;&#23449;&#32467;&#26500;&#30340;&#21160;&#21147;&#23398;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2401.01988</link><description>&lt;p&gt;
${\Lambda}$CDM&#23431;&#23449;&#23398;&#20013;&#30340;&#23618;&#27425;&#32858;&#31867;&#36890;&#36807;&#25345;&#32493;&#33021;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Clustering in ${\Lambda}$CDM Cosmologies via Persistence Energy. (arXiv:2401.01988v1 [astro-ph.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01988
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25345;&#32493;&#33021;&#37327;&#26041;&#27861;&#30740;&#31350;&#20102;${\Lambda}$CDM&#23431;&#23449;&#23398;&#20013;&#30340;&#23618;&#27425;&#32858;&#31867;&#65292;&#21457;&#29616;&#25345;&#32493;&#33021;&#37327;&#19982;&#32418;&#31227;&#20540;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#24615;&#65292;&#25581;&#31034;&#20102;&#23431;&#23449;&#32467;&#26500;&#30340;&#21160;&#21147;&#23398;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#30340;&#20808;&#36827;&#26041;&#27861;&#65292;&#30740;&#31350;&#23431;&#23449;&#32593;&#32476;&#30340;&#32467;&#26500;&#28436;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#21040;&#21033;&#29992;&#25345;&#32493;&#20449;&#21495;&#36825;&#19968;&#21019;&#26032;&#26041;&#27861;&#65292;&#23558;&#25345;&#32493;&#22270;&#37325;&#26032;&#27010;&#24565;&#21270;&#20026;$\mathbb R^2_+$&#31354;&#38388;&#20013;&#30340;&#20449;&#21495;&#65292;&#20174;&#32780;&#23454;&#29616;&#25345;&#32493;&#22270;&#30340;&#23884;&#20837;&#12290;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19977;&#31181;&#20856;&#22411;&#30340;&#23431;&#23449;&#32467;&#26500;&#65306;&#22242;&#31751;&#12289;&#32420;&#32500;&#21644;&#34394;&#31354;&#12290;&#20854;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#21457;&#29616;&#26159;&#25345;&#32493;&#33021;&#37327;&#19982;&#32418;&#31227;&#20540;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#23558;&#25345;&#32493;&#21516;&#35843;&#19982;&#23431;&#23449;&#32467;&#26500;&#30340;&#28436;&#21270;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#23431;&#23449;&#32467;&#26500;&#21160;&#21147;&#23398;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this research, we investigate the structural evolution of the cosmic web, employing advanced methodologies from Topological Data Analysis. Our approach involves leveraging $Persistence$ $Signals$, an innovative method from recent literature that facilitates the embedding of persistence diagrams into vector spaces by re-conceptualizing them as signals in $\mathbb R^2_+$. Utilizing this methodology, we analyze three quintessential cosmic structures: clusters, filaments, and voids. A central discovery is the correlation between $Persistence$ $Energy$ and redshift values, linking persistent homology with cosmic evolution and providing insights into the dynamics of cosmic structures.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.01981</link><description>&lt;p&gt;
&#36229;&#36234;&#36951;&#25022;&#65306;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#20960;&#20309;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Beyond Regrets: Geometric Metrics for Bayesian Optimization. (arXiv:2401.01981v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.01981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21487;&#20197;&#27604;&#36739;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#22312;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#26102;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#38024;&#23545;&#40657;&#30418;&#23376;&#30446;&#26631;&#20989;&#25968;&#30340;&#21407;&#21017;&#24615;&#20248;&#21270;&#31574;&#30053;&#12290;&#23427;&#22312;&#31185;&#23398;&#21457;&#29616;&#21644;&#23454;&#39564;&#35774;&#35745;&#31561;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#25928;&#26524;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#36890;&#24120;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#22522;&#20110;&#36951;&#25022;&#30340;&#24230;&#37327;&#26469;&#35780;&#20272;&#30340;&#65292;&#22914;&#30636;&#26102;&#36951;&#25022;&#12289;&#31616;&#21333;&#36951;&#25022;&#21644;&#32047;&#31215;&#36951;&#25022;&#12290;&#36825;&#20123;&#24230;&#37327;&#20165;&#20381;&#36182;&#20110;&#20989;&#25968;&#35780;&#20272;&#65292;&#22240;&#27492;&#23427;&#20204;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#35299;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#65292;&#20063;&#19981;&#32771;&#34385;&#26597;&#35810;&#28857;&#26412;&#36523;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#20204;&#19981;&#33021;&#21306;&#20998;&#26159;&#21542;&#25104;&#21151;&#25214;&#21040;&#20102;&#22810;&#20010;&#20840;&#23616;&#35299;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#20063;&#19981;&#33021;&#35780;&#20272;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#32473;&#23450;&#25628;&#32034;&#31354;&#38388;&#20013;&#21033;&#29992;&#21644;&#25506;&#32034;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22235;&#20010;&#26032;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#21363;&#31934;&#30830;&#24230;&#12289;&#21484;&#22238;&#29575;&#12289;&#24179;&#22343;&#24230;&#21644;&#24179;&#22343;&#36317;&#31163;&#12290;&#36825;&#20123;&#24230;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#32771;&#34385;&#26597;&#35810;&#28857;&#21644;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#20960;&#20309;&#29305;&#24615;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a principled optimization strategy for a black-box objective function. It shows its effectiveness in a wide variety of real-world applications such as scientific discovery and experimental design. In general, the performance of Bayesian optimization is assessed by regret-based metrics such as instantaneous, simple, and cumulative regrets. These metrics only rely on function evaluations, so that they do not consider geometric relationships between query points and global solutions, or query points themselves. Notably, they cannot discriminate if multiple global solutions are successfully found. Moreover, they do not evaluate Bayesian optimization's abilities to exploit and explore a search space given. To tackle these issues, we propose four new geometric metrics, i.e., precision, recall, average degree, and average distance. These metrics allow us to compare Bayesian optimization algorithms considering the geometry of both query points and global optima, or que
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#30340;&#27010;&#29575;&#24314;&#27169;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#27599;&#20010;&#20107;&#20214;&#19982;&#19968;&#32452;&#39033;&#30446;&#30456;&#20851;&#32852;&#30340;&#24773;&#20917;&#12290;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#20219;&#20309;&#24378;&#24230;&#20026;&#22522;&#30784;&#30340;&#36882;&#24402;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22238;&#31572;&#20851;&#20110;&#24207;&#21015;&#21382;&#21490;&#26465;&#20214;&#19979;&#30340;&#27010;&#29575;&#26597;&#35810;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.15045</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#30340;&#27010;&#29575;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Modeling for Sequences of Sets in Continuous-Time. (arXiv:2312.15045v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#30340;&#27010;&#29575;&#24314;&#27169;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#27599;&#20010;&#20107;&#20214;&#19982;&#19968;&#32452;&#39033;&#30446;&#30456;&#20851;&#32852;&#30340;&#24773;&#20917;&#12290;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#20219;&#20309;&#24378;&#24230;&#20026;&#22522;&#30784;&#30340;&#36882;&#24402;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22238;&#31572;&#20851;&#20110;&#24207;&#21015;&#21382;&#21490;&#26465;&#20214;&#19979;&#30340;&#27010;&#29575;&#26597;&#35810;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#26102;&#38388;&#20107;&#20214;&#25968;&#25454;&#30340;&#32479;&#35745;&#21442;&#25968;&#27169;&#22411;&#24037;&#20855;&#31665;&#20013;&#65292;&#31070;&#32463;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#26159;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#34917;&#20805;&#12290;&#36825;&#20123;&#27169;&#22411;&#36866;&#29992;&#20110;&#27599;&#20010;&#20107;&#20214;&#19982;&#21333;&#20010;&#39033;&#30446;&#65288;&#21333;&#20010;&#20107;&#20214;&#31867;&#22411;&#25110;&#8220;&#26631;&#35760;&#8221;&#65289;&#30456;&#20851;&#32852;&#30340;&#24207;&#21015;&#65292;&#20294;&#19981;&#36866;&#29992;&#20110;&#27599;&#20010;&#20107;&#20214;&#19982;&#19968;&#32452;&#39033;&#30446;&#30456;&#20851;&#32852;&#30340;&#23454;&#38469;&#24773;&#20917;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#38598;&#21512;&#25968;&#20540;&#25968;&#25454;&#24314;&#27169;&#26694;&#26550;&#65292;&#19982;&#20219;&#20309;&#22522;&#20110;&#24378;&#24230;&#30340;&#36882;&#24402;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#20860;&#23481;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#25512;&#29702;&#26041;&#27861;&#65292;&#21487;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#22238;&#31572;&#35832;&#22914;&#8220;&#22312;&#32771;&#34385;&#24207;&#21015;&#21382;&#21490;&#30340;&#26465;&#20214;&#19979;&#65292;&#39033;&#30446;A&#22312;&#39033;&#30446;B&#20043;&#21069;&#35266;&#23519;&#21040;&#30340;&#27010;&#29575;&#8221;&#31561;&#27010;&#29575;&#26597;&#35810;&#38382;&#39064;&#12290;&#30001;&#20110;&#38382;&#39064;&#35774;&#32622;&#30340;&#36830;&#32493;&#26102;&#38388;&#24615;&#36136;&#21644;&#27599;&#20010;&#20107;&#20214;&#30340;&#28508;&#22312;&#32467;&#26524;&#31354;&#38388;&#30340;&#32452;&#21512;&#26497;&#22823;&#65292;&#23545;&#20110;&#31070;&#32463;&#27169;&#22411;&#26469;&#35828;&#65292;&#35745;&#31639;&#36825;&#20123;&#26597;&#35810;&#30340;&#31934;&#30830;&#31572;&#26696;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural marked temporal point processes have been a valuable addition to the existing toolbox of statistical parametric models for continuous-time event data. These models are useful for sequences where each event is associated with a single item (a single type of event or a "mark") -- but such models are not suited for the practical situation where each event is associated with a set of items. In this work, we develop a general framework for modeling set-valued data in continuous-time, compatible with any intensity-based recurrent neural point process model. In addition, we develop inference methods that can use such models to answer probabilistic queries such as "the probability of item $A$ being observed before item $B$," conditioned on sequence history. Computing exact answers for such queries is generally intractable for neural models due to both the continuous-time nature of the problem setting and the combinatorially-large space of potential outcomes for each event. To address th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;Shannon&#29109;&#21644;Kullback-Leibler&#25955;&#24230;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#39640;&#26031;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;KL&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20174;&#31435;&#26041;&#38477;&#20302;&#21040;&#20108;&#27425;&#12290;</title><link>http://arxiv.org/abs/2312.01520</link><description>&lt;p&gt;
Bayesian&#32593;&#32476;&#30340;&#29109;&#21644;Kullback-Leibler&#25955;&#24230;&#65306;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39640;&#25928;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation. (arXiv:2312.01520v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.01520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;Shannon&#29109;&#21644;Kullback-Leibler&#25955;&#24230;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#19968;&#31995;&#21015;&#25968;&#20540;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;&#27492;&#22806;&#65292;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#39640;&#26031;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;KL&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#20174;&#31435;&#26041;&#38477;&#20302;&#21040;&#20108;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;&#23427;&#20204;&#30340;&#22270;&#32467;&#26500;&#21487;&#20197;&#22788;&#29702;&#39640;&#32500;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#20998;&#20026;&#31232;&#30095;&#30340;&#19968;&#31995;&#21015;&#36739;&#23567;&#38382;&#39064;&#65292;&#36825;&#26159;Judea Pearl&#30340;&#22240;&#26524;&#24615;&#30340;&#22522;&#30784;&#65292;&#20063;&#20915;&#23450;&#20102;&#23427;&#20204;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#21487;&#29702;&#35299;&#24615;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#20851;&#20110;&#22914;&#20309;&#22312;&#26368;&#24120;&#35265;&#30340;&#20998;&#24067;&#20551;&#35774;&#19979;&#35745;&#31639;BNs&#30340;Shannon&#29109;&#21644;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#30340;&#36164;&#28304;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;BNs&#30340;&#22270;&#32467;&#26500;&#25552;&#20379;&#20102;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#65292;&#24182;&#29992;&#19968;&#25972;&#22871;&#25968;&#20540;&#31034;&#20363;&#35828;&#26126;&#20102;&#23427;&#20204;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#23558;&#39640;&#26031;BNs&#30340;KL&#35745;&#31639;&#22797;&#26434;&#24230;&#20174;&#31435;&#26041;&#38477;&#20302;&#21040;&#20108;&#27425;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide them into a sparse collection of smaller ones, underlies Judea Pearl's causality, and determines their explainability and interpretability. Despite their popularity, there are almost no resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#31639;&#27861;&#65292;&#20174;&#38750;&#20984;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#12290;&#31639;&#27861;&#35299;&#20915;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#65292;&#24182;&#20445;&#35777;&#20102;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.06815</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#30340;&#26694;&#26550;&#12289;&#31639;&#27861;&#21644;&#25910;&#25947;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
On Model Compression for Neural Networks: Framework, Algorithm, and Convergence Guarantee. (arXiv:2303.06815v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#31639;&#27861;&#65292;&#20174;&#38750;&#20984;&#20248;&#21270;&#30340;&#35282;&#24230;&#26469;&#36827;&#34892;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#12290;&#31639;&#27861;&#35299;&#20915;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#38382;&#39064;&#65292;&#24182;&#20445;&#35777;&#20102;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#21387;&#32553;&#23545;&#20110;&#37096;&#32626;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#22312;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#35745;&#31639;&#35774;&#22791;&#30340;&#20869;&#23384;&#21644;&#23384;&#20648;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#12290;&#26412;&#25991;&#20851;&#27880;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21387;&#32553;&#25216;&#26415;&#65306;&#20302;&#31209;&#36924;&#36817;&#21644;&#26435;&#37325;&#35009;&#21098;&#65292;&#36825;&#20123;&#25216;&#26415;&#30446;&#21069;&#38750;&#24120;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#20302;&#31209;&#36924;&#36817;&#21644;&#26435;&#37325;&#35009;&#21098;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#24635;&#26159;&#20250;&#36973;&#21463;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#25439;&#22833;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#26694;&#26550;&#65292;&#20174;&#38750;&#20984;&#20248;&#21270;&#30340;&#26032;&#35270;&#35282;&#35774;&#35745;&#20102;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#36827;&#34892;&#27169;&#22411;&#21387;&#32553;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22359;&#22352;&#26631;&#19979;&#38477;&#65288;BCD&#65289;&#31639;&#27861;NN-BCD&#26469;&#35299;&#20915;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#19968;&#20010;&#20248;&#28857;&#26159;&#21487;&#20197;&#33719;&#24471;&#20855;&#26377;&#38381;&#24335;&#24418;&#24335;&#30340;&#39640;&#25928;&#36845;&#20195;&#26041;&#26696;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#26799;&#24230;&#28040;&#22833;/&#29190;&#28856;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#20102;Kurdyka-{\L}ojasiewicz (K{\L})&#24615;&#36136;&#65292;&#20445;&#35777;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model compression is a crucial part of deploying neural networks (NNs), especially when the memory and storage of computing devices are limited in many applications. This paper focuses on two model compression techniques: low-rank approximation and weight pruning in neural networks, which are very popular nowadays. However, training NN with low-rank approximation and weight pruning always suffers significant accuracy loss and convergence issues. In this paper, a holistic framework is proposed for model compression from a novel perspective of nonconvex optimization by designing an appropriate objective function. Then, we introduce NN-BCD, a block coordinate descent (BCD) algorithm to solve the nonconvex optimization. One advantage of our algorithm is that an efficient iteration scheme can be derived with closed-form, which is gradient-free. Therefore, our algorithm will not suffer from vanishing/exploding gradient problems. Furthermore, with the Kurdyka-{\L}ojasiewicz (K{\L}) property o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;</title><link>http://arxiv.org/abs/2211.05408</link><description>&lt;p&gt;
&#29992;&#26680;&#26031;&#22374;&#31163;&#24046;&#25511;&#21046;&#30697;
&lt;/p&gt;
&lt;p&gt;
Controlling Moments with Kernel Stein Discrepancies. (arXiv:2211.05408v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#25511;&#21046;&#24615;&#36136;&#65292;&#21457;&#29616;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#65292;&#25552;&#20986;&#20102;&#21487;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#30340;&#19979;&#28216;&#25193;&#25955;KSD&#65292;&#24182;&#19988;&#21457;&#23637;&#20102;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26031;&#22374;&#31163;&#24046;&#65288;KSD&#65289;&#29992;&#20110;&#34913;&#37327;&#20998;&#24067;&#36924;&#36817;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#30446;&#26631;&#23494;&#24230;&#20855;&#26377;&#19981;&#21487;&#35745;&#31639;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#26102;&#35745;&#31639;&#12290;&#26174;&#33879;&#30340;&#24212;&#29992;&#21253;&#25324;&#35786;&#26029;&#36817;&#20284;MCMC&#37319;&#26679;&#22120;&#21644;&#38750;&#24402;&#19968;&#21270;&#32479;&#35745;&#27169;&#22411;&#30340;&#36866;&#37197;&#24230;&#26816;&#39564;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;KSD&#30340;&#25910;&#25947;&#25511;&#21046;&#24615;&#36136;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#29992;&#20110;&#24369;&#25910;&#25947;&#25511;&#21046;&#30340;&#26631;&#20934;KSD&#26080;&#27861;&#25511;&#21046;&#30697;&#30340;&#25910;&#25947;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#20805;&#20998;&#26465;&#20214;&#65292;&#19979;&#28216;&#25193;&#25955;KSD&#21487;&#20197;&#21516;&#26102;&#25511;&#21046;&#30697;&#21644;&#24369;&#25910;&#25947;&#12290;&#20316;&#20026;&#19968;&#20010;&#30452;&#25509;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#23545;&#20110;&#27599;&#20010;$q&gt;0$&#65292;&#31532;&#19968;&#32452;&#24050;&#30693;&#21487;&#20197;&#20934;&#30830;&#25551;&#36848;$q$-Wasserstein&#25910;&#25947;&#30340;KSD&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein discrepancies (KSDs) measure the quality of a distributional approximation and can be computed even when the target density has an intractable normalizing constant. Notable applications include the diagnosis of approximate MCMC samplers and goodness-of-fit tests for unnormalized statistical models. The present work analyzes the convergence control properties of KSDs. We first show that standard KSDs used for weak convergence control fail to control moment convergence. To address this limitation, we next provide sufficient conditions under which alternative diffusion KSDs control both moment and weak convergence. As an immediate consequence we develop, for each $q &gt; 0$, the first KSDs known to exactly characterize $q$-Wasserstein convergence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20999;&#29255;GE-Kriging&#65288;SGE-Kriging&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20989;&#25968;&#36924;&#36817;&#20013;&#30340;&#30456;&#20851;&#30697;&#38453;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2204.03562</link><description>&lt;p&gt;
&#39640;&#32500;&#20989;&#25968;&#36924;&#36817;&#30340;&#20999;&#29255;&#26799;&#24230;&#22686;&#24378;&#20811;&#37324;&#37329;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sliced gradient-enhanced Kriging for high-dimensional function approximation. (arXiv:2204.03562v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.03562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20999;&#29255;GE-Kriging&#65288;SGE-Kriging&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20989;&#25968;&#36924;&#36817;&#20013;&#30340;&#30456;&#20851;&#30697;&#38453;&#21644;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#22686;&#24378;&#20811;&#37324;&#37329;&#65288;GE-Kriging&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#36924;&#36817;&#26114;&#36149;&#35745;&#31639;&#27169;&#22411;&#30340;&#24050;&#24314;&#31435;&#30340;&#20195;&#29702;&#24314;&#27169;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22266;&#26377;&#30456;&#20851;&#30697;&#38453;&#30340;&#22823;&#23567;&#20197;&#21450;&#30456;&#20851;&#30340;&#39640;&#32500;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#65292;&#23427;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#21464;&#24471;&#19981;&#23454;&#29992;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#20999;&#29255;GE-Kriging&#65288;SGE-Kriging&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#20943;&#23567;&#30456;&#20851;&#30697;&#38453;&#30340;&#22823;&#23567;&#21644;&#36229;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#35757;&#32451;&#26679;&#26412;&#38598;&#25286;&#20998;&#20026;&#22810;&#20010;&#20999;&#29255;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#23450;&#29702;&#20351;&#29992;&#20999;&#29255;&#20284;&#28982;&#20989;&#25968;&#26469;&#36924;&#36817;&#23436;&#25972;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#22312;&#20999;&#29255;&#20284;&#28982;&#20989;&#25968;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22810;&#20010;&#23567;&#30340;&#30456;&#20851;&#30697;&#38453;&#26469;&#25551;&#36848;&#26679;&#26412;&#38598;&#30340;&#30456;&#20851;&#24615;&#65292;&#32780;&#19981;&#26159;&#19968;&#20010;&#22823;&#30340;&#30697;&#38453;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#36229;&#21442;&#25968;&#19982;&#23548;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#23558;&#21407;&#22987;&#30340;&#39640;&#32500;&#36229;&#21442;&#25968;&#35843;&#25972;&#38382;&#39064;&#26367;&#25442;&#20026;&#19968;&#20010;&#20302;&#32500;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-enhanced Kriging (GE-Kriging) is a well-established surrogate modelling technique for approximating expensive computational models. However, it tends to get impractical for high-dimensional problems due to the size of the inherent correlation matrix and the associated high-dimensional hyper-parameter tuning problem. To address these issues, a new method, called sliced GE-Kriging (SGE-Kriging), is developed in this paper for reducing both the size of the correlation matrix and the number of hyper-parameters. We first split the training sample set into multiple slices, and invoke Bayes' theorem to approximate the full likelihood function via a sliced likelihood function, in which multiple small correlation matrices are utilized to describe the correlation of the sample set rather than one large one. Then, we replace the original high-dimensional hyper-parameter tuning problem with a low-dimensional counterpart by learning the relationship between the hyper-parameters and the der
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#19979;&#30340;&#24179;&#22343;&#20998;&#24067;&#20248;&#21270;&#24179;&#28369;&#25439;&#22833;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#32852;&#37030;&#20302;&#31209;&#26799;&#24230;&#19979;&#38477;&#65288;FedLRGD&#65289;&#31639;&#27861;&#26469;&#21033;&#29992;&#25968;&#25454;&#30340;&#24179;&#28369;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#20248;&#21270;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2201.01954</link><description>&lt;p&gt;
&#24179;&#22343;&#20998;&#24067;&#20248;&#21270;&#24179;&#28369;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Federated Optimization of Smooth Loss Functions. (arXiv:2201.01954v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.01954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#19979;&#30340;&#24179;&#22343;&#20998;&#24067;&#20248;&#21270;&#24179;&#28369;&#25439;&#22833;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#32852;&#37030;&#20302;&#31209;&#26799;&#24230;&#19979;&#38477;&#65288;FedLRGD&#65289;&#31639;&#27861;&#26469;&#21033;&#29992;&#25968;&#25454;&#30340;&#24179;&#28369;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#22909;&#30340;&#20248;&#21270;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#19979;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#65292;&#20854;&#20013;&#19968;&#20010;&#20013;&#22830;&#26381;&#21153;&#22120;&#20351;&#29992;&#23384;&#20648;&#22312;$m$&#20010;&#23458;&#25143;&#31471;&#19978;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#26368;&#23567;&#21270;ERM&#30446;&#26631;&#20989;&#25968;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32852;&#37030;&#24179;&#22343;&#65288;FedAve&#65289;&#31639;&#27861;&#26159;&#30830;&#23450;ERM&#38382;&#39064;&#30340;$\epsilon$&#36817;&#20284;&#35299;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#31867;&#20284;&#20110;&#26631;&#20934;&#20248;&#21270;&#31639;&#27861;&#65292;FedAve&#30340;&#25910;&#25947;&#20998;&#26512;&#20165;&#20381;&#36182;&#20110;&#20248;&#21270;&#21442;&#25968;&#20013;&#25439;&#22833;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#12290;&#28982;&#32780;&#65292;&#25439;&#22833;&#20989;&#25968;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#36890;&#24120;&#20063;&#38750;&#24120;&#24179;&#28369;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#31181;&#39069;&#22806;&#30340;&#24179;&#28369;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#20302;&#31209;&#26799;&#24230;&#19979;&#38477;&#65288;FedLRGD&#65289;&#31639;&#27861;&#12290;&#30001;&#20110;&#25968;&#25454;&#30340;&#24179;&#28369;&#24615;&#22312;&#25439;&#22833;&#20989;&#25968;&#19978;&#24341;&#20837;&#20102;&#36817;&#20284;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#22312;&#26381;&#21153;&#22120;&#21644;&#23458;&#25143;&#31471;&#20043;&#38388;&#36827;&#34892;&#20102;&#20960;&#36718;&#36890;&#20449;&#65292;&#20197;&#23398;&#20064;&#26381;&#21153;&#22120;&#21487;&#20197;&#29992;&#26469;&#36817;&#20284;&#23458;&#25143;&#31471;&#26799;&#24230;&#30340;&#26435;&#37325;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26381;&#21153;&#22120;&#19978;&#35299;&#20915;ERM&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study empirical risk minimization (ERM) within a federated learning framework, where a central server minimizes an ERM objective function using training data that is stored across $m$ clients. In this setting, the Federated Averaging (FedAve) algorithm is the staple for determining $\epsilon$-approximate solutions to the ERM problem. Similar to standard optimization algorithms, the convergence analysis of FedAve only relies on smoothness of the loss function in the optimization parameter. However, loss functions are often very smooth in the training data too. To exploit this additional smoothness, we propose the Federated Low Rank Gradient Descent (FedLRGD) algorithm. Since smoothness in data induces an approximate low rank structure on the loss function, our method first performs a few rounds of communication between the server and clients to learn weights that the server can use to approximate clients' gradients. Then, our method solves the ERM problem at the server 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#21516;&#36136; Ising &#27169;&#22411;&#20013;&#37325;&#35201;&#37327;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30340;&#34920;&#29616;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/1712.02195</link><description>&lt;p&gt;
&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#30340;&#21516;&#36136; Ising &#27169;&#22411;&#30340;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast approximations in the homogeneous Ising model for use in scene analysis. (arXiv:1712.02195v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1712.02195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#21516;&#36136; Ising &#27169;&#22411;&#20013;&#37325;&#35201;&#37327;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30340;&#34920;&#29616;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Ising &#27169;&#22411;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#37117;&#24456;&#37325;&#35201;&#65292;&#20294;&#20854;&#24402;&#19968;&#21270;&#24120;&#25968;&#12289;&#27963;&#21160;&#39030;&#28857;&#25968;&#30340;&#24179;&#22343;&#20540;&#21644;&#33258;&#26059;&#30456;&#20114;&#20316;&#29992;&#30340;&#22343;&#20540;&#38590;&#20197;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#36817;&#20284;&#20540;&#65292;&#20351;&#24471;&#22312;&#21516;&#36136;&#24773;&#20917;&#19979;&#21487;&#20197;&#25968;&#20540;&#35745;&#31639;&#36825;&#20123;&#37327;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24615;&#33021;&#33391;&#22909;&#65292;&#19988;&#25152;&#38656;&#26102;&#38388;&#21482;&#26159;&#37027;&#20123;&#38543;&#26426;&#26041;&#27861;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#20540;&#22312;&#25191;&#34892;&#21151;&#33021;&#30913;&#20849;&#25391;&#28608;&#27963;&#26816;&#27979;&#23454;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#20197;&#21450;&#26893;&#29289;&#29983;&#20135;&#20013;&#24180;&#22686;&#37327;&#31354;&#38388;&#22270;&#26696;&#30340;&#21508;&#21521;&#24322;&#24615;&#30340;&#20284;&#28982;&#27604;&#26816;&#39564;&#20013;&#24471;&#21040;&#20102;&#20307;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Ising model is important in statistical modeling and inference in many applications, however its normalizing constant, mean number of active vertices and mean spin interaction are intractable to compute. We provide accurate approximations that make it possible to numerically calculate these quantities in the homogeneous case. Simulation studies indicate good performance when compared to Markov Chain Monte Carlo methods and at a tiny fraction of the time taken by those stochastic approaches. The value of our approximations is illustrated in performing Bayesian inference in a functional Magnetic Resonance Imaging activation detection experiment, and also in likelihood ratio testing for anisotropy in the spatial patterns of yearly increases in pistachio tree yields.
&lt;/p&gt;</description></item></channel></rss>