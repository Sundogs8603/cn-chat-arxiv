<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#36817;&#20284;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#65292;&#25104;&#21151;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#34920;&#29616;&#20986;&#33394;.</title><link>https://arxiv.org/abs/2403.04764</link><description>&lt;p&gt;
&#23558;Thompson&#25277;&#26679;&#36951;&#25022;&#19982;Sigma&#27604;&#29575;&#65288;TS-RSR&#65289;&#26368;&#23567;&#21270;&#65306;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32463;&#36807;&#35777;&#26126;&#30340;&#39640;&#25928;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04764
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#36817;&#20284;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#65292;&#25104;&#21151;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#34920;&#29616;&#20986;&#33394;.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#65292;&#20854;&#20013;&#25277;&#26679;&#36890;&#36807;&#26368;&#23567;&#21270;Thompson&#25277;&#26679;&#26041;&#27861;&#30340;&#36951;&#25022;&#19982;&#19981;&#30830;&#23450;&#24615;&#27604;&#29575;&#26469;&#36827;&#34892;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#33021;&#22815;&#21327;&#35843;&#27599;&#20010;&#25209;&#27425;&#20013;&#36873;&#25321;&#30340;&#21160;&#20316;&#65292;&#20197;&#26368;&#23567;&#21270;&#28857;&#20043;&#38388;&#30340;&#20887;&#20313;&#65292;&#21516;&#26102;&#20851;&#27880;&#20855;&#26377;&#39640;&#39044;&#27979;&#22343;&#20540;&#25110;&#39640;&#19981;&#30830;&#23450;&#24615;&#30340;&#28857;&#12290;&#25105;&#20204;&#23545;&#31639;&#27861;&#30340;&#36951;&#25022;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#20174;&#25968;&#23383;&#19978;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#31995;&#21015;&#38750;&#20984;&#27979;&#35797;&#20989;&#25968;&#19978;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#22312;&#24179;&#22343;&#20540;&#19978;&#27604;&#20960;&#20010;&#31454;&#20105;&#23545;&#25163;&#30340;&#22522;&#20934;&#25209;&#37327;BO&#31639;&#27861;&#34920;&#29616;&#25552;&#39640;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04764v1 Announce Type: new  Abstract: This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#20445;&#25345;&#26041;&#24046;&#30340;&#32858;&#21512;&#20989;&#25968;&#65288;VPA&#65289;&#65292;&#35813;&#20989;&#25968;&#22312;&#32500;&#25345;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#39640;&#20102;&#21069;&#21521;&#21644;&#21518;&#21521;&#21160;&#21147;&#23398;&#65292;&#36827;&#32780;&#23548;&#33268;&#20102;&#22686;&#24378;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#25913;&#21892;&#30340;&#23398;&#20064;&#21160;&#24577;&#12290;</title><link>https://arxiv.org/abs/2403.04747</link><description>&lt;p&gt;
GNN-VPA: &#19968;&#31181;&#29992;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#24046;&#20445;&#25345;&#32858;&#21512;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04747
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#20445;&#25345;&#26041;&#24046;&#30340;&#32858;&#21512;&#20989;&#25968;&#65288;VPA&#65289;&#65292;&#35813;&#20989;&#25968;&#22312;&#32500;&#25345;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#39640;&#20102;&#21069;&#21521;&#21644;&#21518;&#21521;&#21160;&#21147;&#23398;&#65292;&#36827;&#32780;&#23548;&#33268;&#20102;&#22686;&#24378;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#25913;&#21892;&#30340;&#23398;&#20064;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#29305;&#21035;&#26159;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#29289;&#29702;&#23398;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#20998;&#23376;&#24314;&#27169;&#31561;&#21508;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#33394;&#12290;GNNs&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#29305;&#21035;&#26159;&#22312;&#21306;&#20998;&#38750;&#21516;&#26500;&#22270;&#30340;&#33021;&#21147;&#65292;&#20851;&#38190;&#21462;&#20915;&#20110;&#29992;&#20110;&#28040;&#24687;&#32858;&#21512;&#21644;&#22270;&#32423;&#35835;&#20986;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#24212;&#29992;&#20449;&#21495;&#20256;&#25773;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20445;&#25345;&#26041;&#24046;&#30340;&#32858;&#21512;&#20989;&#25968;&#65288;VPA&#65289;&#65292;&#35813;&#20989;&#25968;&#20445;&#25345;&#20102;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#21069;&#21521;&#21644;&#21518;&#21521;&#21160;&#21147;&#23398;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;VPA&#23548;&#33268;&#20102;&#27969;&#34892;&#30340;GNN&#26550;&#26500;&#30340;&#39044;&#27979;&#24615;&#33021;&#25552;&#39640;&#65292;&#21516;&#26102;&#25913;&#21892;&#20102;&#23398;&#20064;&#21160;&#24577;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#33021;&#20026;&#26080;&#24402;&#19968;&#21270;&#25110;&#33258;&#24402;&#19968;&#21270;&#30340;GNNs&#38138;&#24179;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04747v1 Announce Type: cross  Abstract: Graph neural networks (GNNs), and especially message-passing neural networks, excel in various domains such as physics, drug discovery, and molecular modeling. The expressivity of GNNs with respect to their ability to discriminate non-isomorphic graphs critically depends on the functions employed for message aggregation and graph-level readout. By applying signal propagation theory, we propose a variance-preserving aggregation function (VPA) that maintains expressivity, but yields improved forward and backward dynamics. Experiments demonstrate that VPA leads to increased predictive performance for popular GNN architectures as well as improved learning dynamics. Our results could pave the way towards normalizer-free or self-normalizing GNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#22312;&#38750;&#39640;&#26031;&#25104;&#20998;&#20998;&#26512;&#20013;&#65292;&#23545;&#20110;&#21306;&#20998;&#26631;&#20934;&#22810;&#20803;&#39640;&#26031;&#21644;&#22312;&#38543;&#26426;&#38544;&#34255;&#26041;&#21521;&#19978;&#34892;&#20026;&#31867;&#20284;&#26576;&#19968;&#32500;&#20998;&#24067;&#32780;&#22312;&#27491;&#20132;&#34917;&#19978;&#34892;&#20026;&#31867;&#20284;&#26631;&#20934;&#39640;&#26031;&#30340;&#38382;&#39064;&#65292;&#20808;&#21069;&#34987;&#35201;&#27714;&#30340;&#21345;&#26041;&#26465;&#20214;&#23454;&#38469;&#19978;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.04744</link><description>&lt;p&gt;
SQ&#22312;&#36739;&#24369;&#20551;&#35774;&#19979;&#29992;&#20110;&#38750;&#39640;&#26031;&#25104;&#20998;&#20998;&#26512;&#30340;&#19979;&#38480;
&lt;/p&gt;
&lt;p&gt;
SQ Lower Bounds for Non-Gaussian Component Analysis with Weaker Assumptions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04744
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#22312;&#38750;&#39640;&#26031;&#25104;&#20998;&#20998;&#26512;&#20013;&#65292;&#23545;&#20110;&#21306;&#20998;&#26631;&#20934;&#22810;&#20803;&#39640;&#26031;&#21644;&#22312;&#38543;&#26426;&#38544;&#34255;&#26041;&#21521;&#19978;&#34892;&#20026;&#31867;&#20284;&#26576;&#19968;&#32500;&#20998;&#24067;&#32780;&#22312;&#27491;&#20132;&#34917;&#19978;&#34892;&#20026;&#31867;&#20284;&#26631;&#20934;&#39640;&#26031;&#30340;&#38382;&#39064;&#65292;&#20808;&#21069;&#34987;&#35201;&#27714;&#30340;&#21345;&#26041;&#26465;&#20214;&#23454;&#38469;&#19978;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32479;&#35745;&#26597;&#35810;&#65288;SQ&#65289;&#27169;&#22411;&#20013;&#38750;&#39640;&#26031;&#25104;&#20998;&#20998;&#26512;&#65288;NGCA&#65289;&#30340;&#22797;&#26434;&#24615;&#12290; &#20808;&#21069;&#30340;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#31181;&#19968;&#33324;&#26041;&#27861;&#65292;&#29992;&#20110;&#35777;&#26126;&#36825;&#19968;&#20219;&#21153;&#30340;SQ&#19979;&#30028;&#65292;&#24182;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#19978;&#19979;&#25991;&#12290; &#29305;&#21035;&#22320;&#65292;&#24050;&#30693;&#23545;&#20110;&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#30340;&#20219;&#20309;&#19968;&#32500;&#20998;&#24067;$A$&#65292;&#21306;&#20998;&#26631;&#20934;&#22810;&#20803;&#39640;&#26031;&#21644;&#22312;&#38543;&#26426;&#38544;&#34255;&#26041;&#21521;&#19978;&#30340;&#34892;&#20026;&#31867;&#20284;$A$&#32780;&#22312;&#27491;&#20132;&#34917;&#19978;&#34892;&#20026;&#31867;&#20284;&#26631;&#20934;&#39640;&#26031;&#30340;&#20998;&#24067;&#26159;SQ-hard&#30340;&#12290; &#25152;&#38656;&#26465;&#20214;&#26159;&#65288;1&#65289;$A$&#19982;&#26631;&#20934;&#19968;&#32500;&#39640;&#26031;&#21305;&#37197;&#35768;&#22810;&#20302;&#38454;&#30697;&#65292;&#21644;&#65288;2&#65289;$A$&#30456;&#23545;&#20110;&#26631;&#20934;&#39640;&#26031;&#30340;&#21345;&#26041;&#33539;&#25968;&#26159;&#26377;&#38480;&#30340;&#12290; &#34429;&#28982;&#28385;&#36275;&#30697;&#21305;&#37197;&#26465;&#20214;&#23545;&#20110;&#38590;&#24230;&#26159;&#24517;&#35201;&#30340;&#65292;&#20294;&#21345;&#26041;&#26465;&#20214;&#20165;&#20986;&#20110;&#25216;&#26415;&#21407;&#22240;&#32780;&#34987;&#35201;&#27714;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21518;&#19968;&#20010;&#26465;&#20214;&#23454;&#38469;&#19978;&#24182;&#38750;&#24517;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04744v1 Announce Type: new  Abstract: We study the complexity of Non-Gaussian Component Analysis (NGCA) in the Statistical Query (SQ) model. Prior work developed a general methodology to prove SQ lower bounds for this task that have been applicable to a wide range of contexts. In particular, it was known that for any univariate distribution $A$ satisfying certain conditions, distinguishing between a standard multivariate Gaussian and a distribution that behaves like $A$ in a random hidden direction and like a standard Gaussian in the orthogonal complement, is SQ-hard. The required conditions were that (1) $A$ matches many low-order moments with the standard univariate Gaussian, and (2) the chi-squared norm of $A$ with respect to the standard Gaussian is finite. While the moment-matching condition is necessary for hardness, the chi-squared condition was only required for technical reasons. In this work, we establish that the latter condition is indeed not necessary. In partic
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#27425;&#20108;&#27425;&#26102;&#38388;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#24694;&#24847;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#40065;&#26834;&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;</title><link>https://arxiv.org/abs/2403.04726</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#40065;&#26834;&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;&#30340;&#27425;&#20108;&#27425;&#26102;&#38388;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Sub-Quadratic Time Algorithm for Robust Sparse Mean Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04726
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#27425;&#20108;&#27425;&#26102;&#38388;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#24694;&#24847;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#40065;&#26834;&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#24694;&#24847;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;&#30340;&#31639;&#27861;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#31639;&#27861;&#35266;&#27979;&#21040;&#20174;$\mathcal{N}(\mu,\mathbf{I}_d)$&#20013;&#30340;\emph{&#21463;&#25439;&#23475;}&#26679;&#26412;&#38598;&#65292;&#20854;&#20013;&#26410;&#30693;&#22343;&#20540;$\mu \in \mathbb{R}^d$&#34987;&#38480;&#21046;&#20026;$k$-&#31232;&#30095;&#12290;&#19968;&#31995;&#21015;&#20808;&#21069;&#30340;&#30740;&#31350;&#24037;&#20316;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;$\mathrm{poly}(k,\log d, 1/\epsilon)$&#21644;&#36816;&#34892;&#26102;&#38388;$d^2 \mathrm{poly}(k,\log d,1/\epsilon)$&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#20013;$\epsilon$&#26159;&#27745;&#26579;&#20998;&#25968;&#12290;&#29305;&#21035;&#26159;&#65292;&#29616;&#26377;&#31639;&#27861;&#30340;&#26368;&#24555;&#36816;&#34892;&#26102;&#38388;&#26159;&#20108;&#27425;&#30340;($\Omega(d^2)$)&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#21487;&#33021;&#26159;&#31105;&#27490;&#24615;&#30340;&#12290;&#29616;&#26377;&#31639;&#27861;&#36816;&#34892;&#26102;&#38388;&#30340;&#20108;&#27425;&#38556;&#30861;&#28304;&#20110;&#36825;&#20123;&#31639;&#27861;&#23545;&#26679;&#26412;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20381;&#36182;&#65292;&#20854;&#22823;&#23567;&#20026;$d^2$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#19968;&#31181;&#29992;&#20110;&#40065;&#26834;&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#23427;&#22312;\emph{&#27425;&#20108;&#27425;}&#26102;&#38388;&#20869;&#36816;&#34892;&#65292;&#20351;&#29992;$\mathrm{poly}
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04726v1 Announce Type: cross  Abstract: We study the algorithmic problem of sparse mean estimation in the presence of adversarial outliers. Specifically, the algorithm observes a \emph{corrupted} set of samples from $\mathcal{N}(\mu,\mathbf{I}_d)$, where the unknown mean $\mu \in \mathbb{R}^d$ is constrained to be $k$-sparse. A series of prior works has developed efficient algorithms for robust sparse mean estimation with sample complexity $\mathrm{poly}(k,\log d, 1/\epsilon)$ and runtime $d^2 \mathrm{poly}(k,\log d,1/\epsilon)$, where $\epsilon$ is the fraction of contamination. In particular, the fastest runtime of existing algorithms is quadratic ($\Omega(d^2)$), which can be prohibitive in high dimensions. This quadratic barrier in the runtime stems from the reliance of these algorithms on the sample covariance matrix, which is of size $d^2$. Our main contribution is an algorithm for robust sparse mean estimation which runs in \emph{subquadratic} time using $\mathrm{poly
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;ShapleyBO&#26694;&#26550;&#65292;&#29992;Shapley&#20540;&#35299;&#37322;&#36125;&#21494;&#26031;&#20248;&#21270;&#25552;&#35758;&#65292;&#37327;&#21270;&#27599;&#20010;&#21442;&#25968;&#23545;&#20110;&#20248;&#21270;&#36807;&#31243;&#30340;&#36129;&#29486;&#65292;&#24182;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#25506;&#32034;&#36129;&#29486;&#12290;</title><link>https://arxiv.org/abs/2403.04629</link><description>&lt;p&gt;
&#29992;Shapley&#20540;&#35299;&#37322;&#36125;&#21494;&#26031;&#20248;&#21270;&#20419;&#36827;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21327;&#20316;
&lt;/p&gt;
&lt;p&gt;
Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04629
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;ShapleyBO&#26694;&#26550;&#65292;&#29992;Shapley&#20540;&#35299;&#37322;&#36125;&#21494;&#26031;&#20248;&#21270;&#25552;&#35758;&#65292;&#37327;&#21270;&#27599;&#20010;&#21442;&#25968;&#23545;&#20110;&#20248;&#21270;&#36807;&#31243;&#30340;&#36129;&#29486;&#65292;&#24182;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#25506;&#32034;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#19982;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#24050;&#25104;&#20026;&#35299;&#20915;&#40657;&#21283;&#23376;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21487;&#25110;&#32570;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;BO&#26412;&#36523;&#20063;&#24120;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#40657;&#21283;&#23376;&#65292;&#32570;&#20047;&#25552;&#20379;&#20026;&#20309;&#25552;&#35758;&#35780;&#20272;&#26576;&#20123;&#21442;&#25968;&#30340;&#29702;&#30001;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;ShapleyBO&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#21338;&#24328;&#35770;Shapley&#20540;&#35299;&#37322;BO&#25552;&#35758;&#30340;&#26694;&#26550;&#12290;&#23427;&#37327;&#21270;&#20102;&#27599;&#20010;&#21442;&#25968;&#23545;BO&#30340;&#25910;&#33719;&#20989;&#25968;&#30340;&#36129;&#29486;&#12290;&#21033;&#29992;Shapley&#20540;&#30340;&#32447;&#24615;&#24615;&#65292;&#25105;&#20204;&#33021;&#22815;&#36827;&#19968;&#27493;&#30830;&#23450;&#27599;&#20010;&#21442;&#25968;&#23545;&#20110;&#20687;&#32622;&#20449;&#36793;&#30028;&#36825;&#26679;&#30340;&#21152;&#27861;&#25910;&#33719;&#20989;&#25968;&#25512;&#21160;BO&#30340;&#25506;&#32034;&#21644;&#24320;&#21457;&#30340;&#24378;&#24230;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;ShapleyBO&#33021;&#22815;&#35299;&#20915;&#25506;&#32034;&#23545;&#20110;&#21208;&#25506;aleatoric&#21644;&#35748;&#35782;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04629v1 Announce Type: cross  Abstract: Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26041;&#27861; RAHMC&#65292;&#36890;&#36807;&#24341;&#20837;&#25705;&#25830;&#31995;&#25968;&#65292;&#37319;&#29992;&#32791;&#25955;&#21160;&#21147;&#23398;&#26469;&#20987;&#36864;&#21644;&#21560;&#24341;&#37319;&#26679;&#22120;&#65292;&#20174;&#32780;&#39640;&#25928;&#22320;&#20174;&#22810;&#27169;&#24577;&#20998;&#24067;&#20013;&#25277;&#26679;&#12290;</title><link>https://arxiv.org/abs/2403.04607</link><description>&lt;p&gt;
&#20987;&#36864;-&#21560;&#24341;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;
&lt;/p&gt;
&lt;p&gt;
Repelling-Attracting Hamiltonian Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04607
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26041;&#27861; RAHMC&#65292;&#36890;&#36807;&#24341;&#20837;&#25705;&#25830;&#31995;&#25968;&#65292;&#37319;&#29992;&#32791;&#25955;&#21160;&#21147;&#23398;&#26469;&#20987;&#36864;&#21644;&#21560;&#24341;&#37319;&#26679;&#22120;&#65292;&#20174;&#32780;&#39640;&#25928;&#22320;&#20174;&#22810;&#27169;&#24577;&#20998;&#24067;&#20013;&#25277;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#65288;HMC&#65289;&#30340;&#21464;&#31181;&#65292;&#31216;&#20026;&#20987;&#36864;-&#21560;&#24341;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#65288;RAHMC&#65289;&#65292;&#29992;&#20110;&#20174;&#22810;&#27169;&#24577;&#20998;&#24067;&#20013;&#36827;&#34892;&#25277;&#26679;&#12290; RAHMC&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#36828;&#31163;&#20256;&#32479;HMC&#20445;&#23432;&#21160;&#21147;&#23398;&#65292;&#36716;&#32780;&#36716;&#21521;&#20849;&#24418;&#21704;&#23494;&#39039;&#31995;&#32479;&#30340;&#32791;&#25955;&#21160;&#21147;&#23398;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;RAHMC&#21253;&#25324;&#20004;&#20010;&#38454;&#27573;&#65306;&#19968;&#31181;&#27169;&#20987;&#36864;&#38454;&#27573;&#65292;&#40723;&#21169;&#37319;&#26679;&#22120;&#36828;&#31163;&#39640;&#27010;&#29575;&#23494;&#24230;&#21306;&#22495;&#65307;&#21478;&#19968;&#20010;&#27169;&#21560;&#24341;&#38454;&#27573;&#65292;&#26377;&#21161;&#20110;&#37319;&#26679;&#22120;&#25214;&#21040;&#24182;&#20572;&#30041;&#22312;&#26367;&#20195;&#27169;&#24335;&#38468;&#36817;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#20010;&#39069;&#22806;&#30340;&#35843;&#33410;&#21442;&#25968;--&#25705;&#25830;&#31995;&#25968;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36866;&#24212;&#30446;&#26631;&#20998;&#24067;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20363;&#22914;&#27169;&#24335;&#21644;&#23494;&#24230;&#33034;&#65292;&#21487;&#20197;&#29983;&#25104;&#36234;&#36807;&#20302;&#27010;&#29575;&#38556;&#30861;&#30340;&#25552;&#35758;&#65292;&#19988;&#20960;&#20046;&#19981;&#22686;&#21152;&#35745;&#31639;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04607v1 Announce Type: cross  Abstract: We propose a variant of Hamiltonian Monte Carlo (HMC), called the Repelling-Attracting Hamiltonian Monte Carlo (RAHMC), for sampling from multimodal distributions. The key idea that underpins RAHMC is a departure from the conservative dynamics of Hamiltonian systems, which form the basis of traditional HMC, and turning instead to the dissipative dynamics of conformal Hamiltonian systems. In particular, RAHMC involves two stages: a mode-repelling stage to encourage the sampler to move away from regions of high probability density; and, a mode-attracting stage, which facilitates the sampler to find and settle near alternative modes. We achieve this by introducing just one additional tuning parameter -- the coefficient of friction. The proposed method adapts to the geometry of the target distribution, e.g., modes and density ridges, and can generate proposals that cross low-probability barriers with little to no computational overhead in 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#21644;self-normalized&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#32447;&#24615;&#28151;&#21512;MDPs&#20013;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.04568</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#31639;&#27861;&#29992;&#20110;&#24102;&#26377;&#21290;&#22839;&#25152;&#24605;&#21453;&#39304;&#21644;&#26410;&#30693;&#36716;&#31227;&#30340;&#25932;&#23545;&#32447;&#24615;&#28151;&#21512;MDPs
&lt;/p&gt;
&lt;p&gt;
Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04568
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#21644;self-normalized&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#32447;&#24615;&#28151;&#21512;MDPs&#20013;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#12289;&#26410;&#30693;&#36716;&#31227;&#21644;&#22312;&#21290;&#22839;&#25152;&#24605;&#21453;&#39304;&#35774;&#32622;&#20013;&#30340;&#25932;&#23545;&#25439;&#22833;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#36716;&#31227;&#26680;&#20026;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#30340;&#32447;&#24615;&#28151;&#21512;MDPs&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#39640;&#27010;&#29575;&#19979;&#36798;&#21040;&#20102;$\widetilde{O}(d\sqrt{HS^3K} + \sqrt{HSAK})$&#30340;&#36951;&#25022;&#20540;&#65292;&#20854;&#20013;$d$&#26159;&#29305;&#24449;&#26144;&#23556;&#30340;&#32500;&#24230;&#65292;$S$&#26159;&#29366;&#24577;&#31354;&#38388;&#30340;&#22823;&#23567;&#65292;$A$&#26159;&#21160;&#20316;&#31354;&#38388;&#30340;&#22823;&#23567;&#65292;$H$&#26159;&#27599;&#38598;&#38271;&#24230;&#65292;$K$&#26159;&#38598;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20005;&#26684;&#25913;&#36827;&#20102;Zhao&#31561;&#20154;(2023a)&#20013;&#24050;&#30693;&#30340;&#26368;&#20339;$\widetilde{O}(dS^2 \sqrt{K} + \sqrt{HSAK})$&#32467;&#26524;&#65292;&#22240;&#20026;$H \leq S$&#30001;&#23618;&#27425;MDP&#32467;&#26500;&#25104;&#31435;&#12290;&#25105;&#20204;&#30340;&#36827;&#23637;&#20027;&#35201;&#24402;&#22240;&#20110;(i)&#19968;&#31181;&#26032;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#36716;&#31227;&#21442;&#25968;&#65292;&#21033;&#29992;&#20102;&#25152;&#26377;&#29366;&#24577;&#30340;&#35775;&#38382;&#20449;&#24687;&#65292;&#32780;&#19981;&#20687;&#20197;&#21069;&#30340;&#24037;&#20316;&#21482;&#29992;&#19968;&#20010;&#29366;&#24577;&#65292;&#20197;&#21450;(ii)&#19968;&#31181;&#26032;&#30340;self-normalized&#20998;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04568v1 Announce Type: new  Abstract: We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model. We propose a new algorithm that attains an $\widetilde{O}(d\sqrt{HS^3K} + \sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes. Our result strictly improves the previous best-known $\widetilde{O}(dS^2 \sqrt{K} + \sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \leq S$ holds by the layered MDP structure. Our advancements are primarily attributed to (i) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (ii) a new self-normalized conc
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2403.04493</link><description>&lt;p&gt;
&#20351;&#22270;&#20687;&#30495;&#23454;&#30340;&#22240;&#32032;&#26159;&#20160;&#20040;&#65311;
&lt;/p&gt;
&lt;p&gt;
What makes an image realistic?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04493
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#20316;&#20026;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#37324;&#65292;&#25105;&#20204;&#22312;&#29983;&#25104;&#30475;&#36215;&#26469;&#30495;&#23454;&#30340;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#65292;&#26080;&#35770;&#26159;&#22270;&#20687;&#12289;&#25991;&#26412;&#12289;&#38899;&#39057;&#36824;&#26159;&#35270;&#39057;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#20043;&#23494;&#20999;&#30456;&#20851;&#30340;&#38382;&#39064;&#65292;&#21363;&#37327;&#21270;&#29616;&#23454;&#20027;&#20041;&#65292;&#21363;&#35774;&#35745;&#33021;&#22815;&#21487;&#38752;&#22320;&#21306;&#20998;&#30495;&#23454;&#25968;&#25454;&#21644;&#19981;&#30495;&#23454;&#25968;&#25454;&#30340;&#20989;&#25968;&#12290;&#20174;&#31639;&#27861;&#20449;&#24687;&#29702;&#35770;&#30340;&#35266;&#28857;&#20986;&#21457;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20026;&#20160;&#20040;&#36825;&#20010;&#38382;&#39064;&#24456;&#20855;&#25361;&#25112;&#24615;&#65292;&#20026;&#20160;&#20040;&#19968;&#20010;&#22909;&#30340;&#29983;&#25104;&#27169;&#22411;&#21333;&#29420;&#19981;&#33021;&#35299;&#20915;&#23427;&#65292;&#20197;&#21450;&#19968;&#20010;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#24212;&#35813;&#26159;&#20160;&#20040;&#26679;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36890;&#29992;&#35780;&#35770;&#32773;&#30340;&#27010;&#24565;&#65292;&#19981;&#20687;&#23545;&#25239;&#24615;&#35780;&#35770;&#32773;&#37027;&#26679;&#38656;&#35201;&#23545;&#25239;&#24615;&#35757;&#32451;&#12290;&#23613;&#31649;&#36890;&#29992;&#35780;&#35770;&#32773;&#24182;&#19981;&#31435;&#21363;&#23454;&#29992;&#65292;&#20294;&#23427;&#20204;&#26082;&#21487;&#20197;&#20316;&#20026;&#24341;&#23548;&#23454;&#38469;&#23454;&#29616;&#30340;&#21271;&#26497;&#26143;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04493v1 Announce Type: new  Abstract: The last decade has seen tremendous progress in our ability to generate realistic-looking data, be it images, text, audio, or video. Here, we discuss the closely related problem of quantifying realism, that is, designing functions that can reliably tell realistic data from unrealistic data. This problem turns out to be significantly harder to solve and remains poorly understood, despite its prevalence in machine learning and recent breakthroughs in generative AI. Drawing on insights from algorithmic information theory, we discuss why this problem is challenging, why a good generative model alone is insufficient to solve it, and what a good solution would look like. In particular, we introduce the notion of a universal critic, which unlike adversarial critics does not require adversarial training. While universal critics are not immediately practical, they can serve both as a North Star for guiding practical implementations and as a tool 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;"Signature Isolation Forest"&#65292;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#30340;&#31614;&#21517;&#21464;&#25442;&#21435;&#38500;&#20102;Functional Isolation Forest&#30340;&#32447;&#24615;&#20869;&#31215;&#21644;&#35789;&#20856;&#36873;&#25321;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2403.04405</link><description>&lt;p&gt;
Signature Isolation Forest
&lt;/p&gt;
&lt;p&gt;
Signature Isolation Forest
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04405
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;"Signature Isolation Forest"&#65292;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#30340;&#31614;&#21517;&#21464;&#25442;&#21435;&#38500;&#20102;Functional Isolation Forest&#30340;&#32447;&#24615;&#20869;&#31215;&#21644;&#35789;&#20856;&#36873;&#25321;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Functional Isolation Forest (FIF)&#26159;&#19968;&#31181;&#38024;&#23545;&#21151;&#33021;&#25968;&#25454;&#35774;&#35745;&#30340;&#26368;&#26032;&#19968;&#27969;&#24322;&#24120;&#26816;&#27979;(AD)&#31639;&#27861;&#12290;&#23427;&#20381;&#36182;&#20110;&#19968;&#31181;&#26641;&#20998;&#21306;&#36807;&#31243;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#26354;&#32447;&#35266;&#27979;&#25237;&#24433;&#21040;&#36890;&#36807;&#32447;&#24615;&#20869;&#31215;&#32472;&#21046;&#30340;&#35789;&#20856;&#19978;&#26469;&#35745;&#31639;&#24322;&#24120;&#24471;&#20998;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#8220;Signature Isolation Forest&#8221;&#65292;&#19968;&#31181;&#21033;&#29992;&#31895;&#36335;&#24452;&#29702;&#35770;&#31614;&#21517;&#21464;&#25442;&#30340;&#26032;&#39062;AD&#31639;&#27861;&#31867;&#65292;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#25552;&#20986;&#20004;&#31181;&#31639;&#27861;&#26469;&#28040;&#38500;FIF&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36825;&#20004;&#31181;&#31639;&#27861;&#29305;&#21035;&#38024;&#23545;FIF&#20869;&#31215;&#30340;&#32447;&#24615;&#24615;&#21644;&#35789;&#20856;&#30340;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04405v1 Announce Type: cross  Abstract: Functional Isolation Forest (FIF) is a recent state-of-the-art Anomaly Detection (AD) algorithm designed for functional data. It relies on a tree partition procedure where an abnormality score is computed by projecting each curve observation on a drawn dictionary through a linear inner product. Such linear inner product and the dictionary are a priori choices that highly influence the algorithm's performances and might lead to unreliable results, particularly with complex datasets. This work addresses these challenges by introducing \textit{Signature Isolation Forest}, a novel AD algorithm class leveraging the rough path theory's signature transform. Our objective is to remove the constraints imposed by FIF through the proposition of two algorithms which specifically target the linearity of the FIF inner product and the choice of the dictionary. We provide several numerical experiments, including a real-world applications benchmark sho
&lt;/p&gt;</description></item><item><title>&#31616;&#21333;&#25351;&#25968;&#24179;&#28369;&#22312;&#20248;&#21270;&#19968;&#31995;&#21015;&#39640;&#26031;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#26102;&#33258;&#28982;&#20135;&#29983;&#20986;&#36882;&#24402;&#26041;&#31243;&#65292;&#35813;&#26041;&#27861;&#21487;&#21487;&#38752;&#22320;&#20272;&#35745;&#22522;&#30784;&#36235;&#21183;&#65292;&#20026;&#20854;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.04345</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#39062;&#30340;&#25351;&#25968;&#24179;&#28369;&#29702;&#35770;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Novel Theoretical Framework for Exponential Smoothing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04345
&lt;/p&gt;
&lt;p&gt;
&#31616;&#21333;&#25351;&#25968;&#24179;&#28369;&#22312;&#20248;&#21270;&#19968;&#31995;&#21015;&#39640;&#26031;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#26102;&#33258;&#28982;&#20135;&#29983;&#20986;&#36882;&#24402;&#26041;&#31243;&#65292;&#35813;&#26041;&#27861;&#21487;&#21487;&#38752;&#22320;&#20272;&#35745;&#22522;&#30784;&#36235;&#21183;&#65292;&#20026;&#20854;&#40065;&#26834;&#24615;&#25552;&#20379;&#20102;&#26032;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31616;&#21333;&#25351;&#25968;&#24179;&#28369;&#26159;&#19968;&#31181;&#32463;&#20856;&#25216;&#26415;&#65292;&#36890;&#36807;&#23558;&#25351;&#25968;&#36882;&#20943;&#30340;&#26435;&#37325;&#20998;&#37197;&#32473;&#36807;&#21435;&#30340;&#35266;&#23519;&#32467;&#26524;&#65292;&#36890;&#36807;&#36882;&#24402;&#26041;&#31243;&#24179;&#28369;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65307;&#26377;&#26102;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#32463;&#39564;&#27861;&#21017;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#35270;&#35282;&#65292;&#20854;&#20013;&#23450;&#20041;&#31616;&#21333;&#25351;&#25968;&#24179;&#28369;&#30340;&#36882;&#24402;&#26041;&#31243;&#33258;&#28982;&#21457;&#29983;&#20026;&#20248;&#21270;&#19968;&#31995;&#21015;&#39640;&#26031;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19978;&#21319;&#26041;&#26696;&#12290;&#22312;&#36825;&#31181;&#20998;&#26512;&#35270;&#35282;&#19979;&#65292;&#25105;&#20204;&#30340;&#20027;&#23450;&#29702;&#34920;&#26126;&#65292;-&#22312;&#19968;&#33324;&#35774;&#32622;&#19979;-&#31616;&#21333;&#25351;&#25968;&#24179;&#28369;&#25910;&#25947;&#21040;&#36235;&#21183;&#31283;&#24577;&#38543;&#26426;&#36807;&#31243;&#30340;&#36235;&#21183;&#37051;&#22495;&#12290;&#36825;&#20026;&#25351;&#25968;&#24179;&#28369;&#31243;&#24207;&#20135;&#29983;&#21487;&#38752;&#30340;&#22522;&#30784;&#36235;&#21183;&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#38416;&#26126;&#20102;&#25991;&#29486;&#20013;&#20851;&#20110;&#31616;&#21333;&#25351;&#25968;&#24179;&#28369;&#30340;&#40065;&#26834;&#24615;&#30340;&#38271;&#26399;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04345v1 Announce Type: cross  Abstract: Simple Exponential Smoothing is a classical technique used for smoothing time series data by assigning exponentially decreasing weights to past observations through a recursive equation; it is sometimes presented as a rule of thumb procedure. We introduce a novel theoretical perspective where the recursive equation that defines simple exponential smoothing occurs naturally as a stochastic gradient ascent scheme to optimize a sequence of Gaussian log-likelihood functions. Under this lens of analysis, our main theorem shows that -in a general setting- simple exponential smoothing converges to a neighborhood of the trend of a trend-stationary stochastic process. This offers a novel theoretical assurance that the exponential smoothing procedure yields reliable estimators of the underlying trend shedding light on long-standing observations in the literature regarding the robustness of simple exponential smoothing.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;CNN-LSTM&#19977;&#38454;&#27573;&#27169;&#22411;PEnet&#65292;&#36890;&#36807;CNN&#23545;&#25968;&#25454;&#29305;&#24449;&#36827;&#34892;&#27987;&#32553;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#20197;&#21450;&#38271;&#24207;&#21015;&#35266;&#27979;&#30340;&#22686;&#24378;&#25512;&#26029;&#36895;&#24230;&#21644;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;SDE&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.04246</link><description>&lt;p&gt;
&#22522;&#20110;CNN-LSTM&#30340;Levy&#39537;&#21160;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#20272;&#35745;&#30340;&#39640;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Efficient CNN-LSTM based Parameter Estimation of Levy Driven Stochastic Differential Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;CNN-LSTM&#19977;&#38454;&#27573;&#27169;&#22411;PEnet&#65292;&#36890;&#36807;CNN&#23545;&#25968;&#25454;&#29305;&#24449;&#36827;&#34892;&#27987;&#32553;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#20197;&#21450;&#38271;&#24207;&#21015;&#35266;&#27979;&#30340;&#22686;&#24378;&#25512;&#26029;&#36895;&#24230;&#21644;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#20174;&#32780;&#22312;&#20272;&#35745;SDE&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#30001;&#38750;&#39640;&#26031;&#22122;&#22768;&#39537;&#21160;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#25361;&#25112;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#20215;&#26684;&#27874;&#21160;&#21644;&#20256;&#26579;&#30149;&#20256;&#25773;&#31561;&#21160;&#24577;&#29616;&#35937;&#33267;&#20851;&#37325;&#35201;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;LSTM&#32593;&#32476;&#22312;&#20272;&#35745;alpha&#31283;&#23450;Levy&#39537;&#21160;&#30340;SDE&#21442;&#25968;&#26041;&#38754;&#30340;&#28508;&#21147;&#65292;&#20294;&#38754;&#20020;&#39640;&#26102;&#38388;&#22797;&#26434;&#24230;&#21644;LSTM&#38142;&#25509;&#23646;&#24615;&#30340;&#38480;&#21046;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;PEnet&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;CNN-LSTM&#30340;&#19977;&#38454;&#27573;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#65292;&#20855;&#26377;&#20248;&#36234;&#30340;&#20934;&#30830;&#24615;&#21644;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#32467;&#26500;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;CNN&#23545;&#21021;&#22987;&#25968;&#25454;&#29305;&#24449;&#36827;&#34892;&#27987;&#32553;&#65292;&#20026;&#38271;&#24207;&#21015;&#35266;&#27979;&#25552;&#20379;&#22686;&#24378;&#30340;&#25512;&#26029;&#36895;&#24230;&#65292;&#24182;&#20855;&#26377;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#20801;&#35768;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#22797;&#26434;&#30340;SDE&#22330;&#26223;&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;PEnet&#22312;&#20272;&#35745;SDE&#20013;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04246v1 Announce Type: cross  Abstract: This study addresses the challenges in parameter estimation of stochastic differential equations driven by non-Gaussian noises, which are critical in understanding dynamic phenomena such as price fluctuations and the spread of infectious diseases. Previous research highlighted the potential of LSTM networks in estimating parameters of alpha stable Levy driven SDEs but faced limitations including high time complexity and constraints of the LSTM chaining property. To mitigate these issues, we introduce the PEnet, a novel CNN-LSTM-based three-stage model that offers an end to end approach with superior accuracy and adaptability to varying data structures, enhanced inference speed for long sequence observations through initial data feature condensation by CNN, and high generalization capability, allowing its application to various complex SDE scenarios. Experiments on synthetic datasets confirm PEnet significant advantage in estimating SDE
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27491;&#21017;&#21270;DeepIV&#65288;RDIV&#65289;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#36991;&#20813;IV&#22238;&#24402;&#21807;&#19968;&#26631;&#35782;&#12289;&#26497;&#23567;&#26497;&#22823;&#35745;&#31639;&#39044;&#35328;&#21644;&#32570;&#20047;&#27169;&#22411;&#36873;&#25321;&#36807;&#31243;&#31561;&#38480;&#21046;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#12290;</title><link>https://arxiv.org/abs/2403.04236</link><description>&lt;p&gt;
&#20855;&#26377;&#27169;&#22411;&#36873;&#25321;&#30340;&#27491;&#21017;&#21270;DeepIV
&lt;/p&gt;
&lt;p&gt;
Regularized DeepIV with Model Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04236
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27491;&#21017;&#21270;DeepIV&#65288;RDIV&#65289;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#33021;&#22815;&#36991;&#20813;IV&#22238;&#24402;&#21807;&#19968;&#26631;&#35782;&#12289;&#26497;&#23567;&#26497;&#22823;&#35745;&#31639;&#39044;&#35328;&#21644;&#32570;&#20047;&#27169;&#22411;&#36873;&#25321;&#36807;&#31243;&#31561;&#38480;&#21046;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24037;&#20855;&#21464;&#37327;&#65288;IV&#65289;&#22238;&#24402;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#12290;&#34429;&#28982;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#24341;&#20837;&#20102;&#28789;&#27963;&#30340;IV&#20272;&#35745;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#20250;&#36935;&#21040;&#20197;&#19979;&#19968;&#20010;&#25110;&#22810;&#20010;&#38480;&#21046;&#65306;&#65288;1&#65289;&#23558;IV&#22238;&#24402;&#38480;&#21046;&#20026;&#21807;&#19968;&#26631;&#35782;&#65307;&#65288;2&#65289;&#38656;&#35201;&#26497;&#23567;&#26497;&#22823;&#35745;&#31639;&#39044;&#35328;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#19981;&#31283;&#23450;&#65307;&#65288;3&#65289;&#32570;&#20047;&#27169;&#22411;&#36873;&#25321;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#36991;&#20813;&#25152;&#26377;&#19977;&#20010;&#38480;&#21046;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#21644;&#20998;&#26512;&#65292;&#21516;&#26102;&#20173;&#28982;&#33021;&#22815;&#23454;&#29616;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#27491;&#21017;&#21270;DeepIV&#65288;RDIV&#65289;&#22238;&#24402;&#30340;&#26080;&#26497;&#23567;&#26497;&#22823;&#35745;&#31639;&#39044;&#35328;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25910;&#25947;&#21040;&#26368;&#23567;&#33539;&#25968;IV&#35299;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20998;&#20026;&#20004;&#20010;&#38454;&#27573;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#23398;&#20064;&#21327;&#21464;&#37327;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#25152;&#23398;&#21040;&#30340;&#20998;&#24067;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;Tikhonov&#27491;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#26469;&#23398;&#20064;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04236v1 Announce Type: new  Abstract: In this paper, we study nonparametric estimation of instrumental variable (IV) regressions. While recent advancements in machine learning have introduced flexible methods for IV estimation, they often encounter one or more of the following limitations: (1) restricting the IV regression to be uniquely identified; (2) requiring minimax computation oracle, which is highly unstable in practice; (3) absence of model selection procedure. In this paper, we present the first method and analysis that can avoid all three limitations, while still enabling general function approximation. Specifically, we propose a minimax-oracle-free method called Regularized DeepIV (RDIV) regression that can converge to the least-norm IV solution. Our method consists of two stages: first, we learn the conditional distribution of covariates, and by utilizing the learned distribution, we learn the estimator by minimizing a Tikhonov-regularized loss function. We furth
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#20102;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#33021;&#30001;&#31561;&#25928;&#39640;&#26031;&#27169;&#22411;&#21644;&#26377;&#25928;&#20808;&#39564;&#30830;&#23450;&#65292;&#20449;&#21495;&#37325;&#26500;&#38656;&#35201;&#22686;&#38271;&#30340;&#20449;&#22122;&#27604;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#38024;&#23545;&#38750;&#32447;&#24615;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#30340;&#28176;&#36817;&#35823;&#24046;&#29305;&#24449;&#21270;&#21644;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.04234</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Fundamental limits of Non-Linear Low-Rank Matrix Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04234
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#20102;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#33021;&#30001;&#31561;&#25928;&#39640;&#26031;&#27169;&#22411;&#21644;&#26377;&#25928;&#20808;&#39564;&#30830;&#23450;&#65292;&#20449;&#21495;&#37325;&#26500;&#38656;&#35201;&#22686;&#38271;&#30340;&#20449;&#22122;&#27604;&#26465;&#20214;&#65292;&#24182;&#25552;&#20379;&#20102;&#38024;&#23545;&#38750;&#32447;&#24615;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#30340;&#28176;&#36817;&#35823;&#24046;&#29305;&#24449;&#21270;&#21644;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#38750;&#32447;&#24615;&#21644;&#22024;&#26434;&#35266;&#27979;&#20013;&#20272;&#35745;&#20302;&#31209;&#30697;&#38453;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#26222;&#36866;&#24615;&#32467;&#26524;&#65292;&#34920;&#26126;&#36125;&#21494;&#26031;&#26368;&#20248;&#34920;&#29616;&#30001;&#19968;&#20010;&#31561;&#25928;&#39640;&#26031;&#27169;&#22411;&#21644;&#19968;&#20010;&#26377;&#25928;&#20808;&#39564;&#25152;&#20915;&#23450;&#65292;&#20854;&#21442;&#25968;&#23436;&#20840;&#30001;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#23637;&#24320;&#30830;&#23450;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#34920;&#26126;&#20026;&#20102;&#20934;&#30830;&#37325;&#26500;&#20449;&#21495;&#65292;&#20449;&#22122;&#27604;&#38656;&#35201;&#22686;&#38271;&#20026;$N^{\frac 12 (1-1/k_F)}$&#65292;&#20854;&#20013;$k_F$&#26159;&#20989;&#25968;&#30340;&#31532;&#19968;&#20010;&#38750;&#38646;&#36153;&#33293;&#23572;&#20449;&#24687;&#31995;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26368;&#23567;&#21487;&#36798;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#30340;&#28176;&#36817;&#29305;&#24449;&#21270;&#21644;&#19968;&#31181;&#36817;&#20284;&#20256;&#36882;&#28040;&#24687;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#31867;&#20284;&#20110;&#38382;&#39064;&#30340;&#32447;&#24615;&#29256;&#26412;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#20102;MMSE&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#36890;&#36807;&#26041;&#27861;&#20363;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#32467;&#21512;&#36125;&#21494;&#26031;&#38477;&#22122;&#23454;&#29616;&#30340;&#28176;&#36817;&#35823;&#24046;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;MMSE&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04234v1 Announce Type: cross  Abstract: We consider the task of estimating a low-rank matrix from non-linear and noisy observations. We prove a strong universality result showing that Bayes-optimal performances are characterized by an equivalent Gaussian model with an effective prior, whose parameters are entirely determined by an expansion of the non-linear function. In particular, we show that to reconstruct the signal accurately, one requires a signal-to-noise ratio growing as $N^{\frac 12 (1-1/k_F)}$, where $k_F$ is the first non-zero Fisher information coefficient of the function. We provide asymptotic characterization for the minimal achievable mean squared error (MMSE) and an approximate message-passing algorithm that reaches the MMSE under conditions analogous to the linear version of the problem. We also provide asymptotic errors achieved by methods such as principal component analysis combined with Bayesian denoising, and compare them with Bayes-optimal MMSE.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;</title><link>https://arxiv.org/abs/2403.04082</link><description>&lt;p&gt;
&#36890;&#36807;&#25554;&#20540;&#36827;&#34892;&#25512;&#26029;&#65306;&#23545;&#27604;&#34920;&#31034;&#21487;&#35777;&#26126;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04082
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20174;&#32780;&#21551;&#29992;&#35268;&#21010;&#21644;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#25105;&#20204;&#22914;&#20309;&#22238;&#31572;&#35832;&#22914;&#8220;&#26410;&#26469;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#8221;&#21644;&#8220;&#25105;&#20204;&#26159;&#22914;&#20309;&#21040;&#36798;&#36825;&#37324;&#30340;&#65311;&#8221;&#36825;&#31867;&#27010;&#29575;&#25512;&#26029;&#38382;&#39064;&#22312;&#35266;&#27979;&#20540;&#20026;&#39640;&#32500;&#26102;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#38382;&#39064;&#22914;&#20309;&#36890;&#36807;&#23398;&#20064;&#34920;&#31034;&#30340;&#32039;&#20945;&#38381;&#24335;&#35299;&#20915;&#26041;&#26696;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#23545;&#27604;&#23398;&#20064;&#30340;&#21464;&#20307;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#34920;&#26126;&#65292;&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#32534;&#30721;&#20102;&#27010;&#29575;&#27604;&#12290;&#36890;&#36807;&#23558;&#20043;&#21069;&#30340;&#24037;&#20316;&#25193;&#23637;&#20197;&#34920;&#26126;&#34920;&#31034;&#30340;&#36793;&#38469;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#65292;&#25105;&#20204;&#38543;&#21518;&#35777;&#26126;&#34920;&#31034;&#30340;&#32852;&#21512;&#20998;&#24067;&#20063;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#36825;&#20123;&#32467;&#26524;&#20849;&#21516;&#34920;&#26126;&#65292;&#36890;&#36807;&#26102;&#38388;&#23545;&#27604;&#23398;&#20064;&#23398;&#21040;&#30340;&#34920;&#31034;&#36981;&#24490;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#19968;&#31181;&#22270;&#24418;&#27169;&#22411;&#65292;&#20854;&#20013;&#23545;&#34920;&#31034;&#36827;&#34892;&#30340;&#25512;&#26029;&#65288;&#20363;&#22914;&#39044;&#27979;&#12289;&#35268;&#21010;&#65289;&#23545;&#24212;&#20110;&#21453;&#28436;&#20302;&#32500;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04082v1 Announce Type: new  Abstract: Given time series data, how can we answer questions like "what will happen in the future?" and "how did we get here?" These sorts of probabilistic inference questions are challenging when observations are high-dimensional. In this paper, we show how these questions can have compact, closed form solutions in terms of learned representations. The key idea is to apply a variant of contrastive learning to time series data. Prior work already shows that the representations learned by contrastive learning encode a probability ratio. By extending prior work to show that the marginal distribution over representations is Gaussian, we can then prove that joint distribution of representations is also Gaussian. Taken together, these results show that representations learned via temporal contrastive learning follow a Gauss-Markov chain, a graphical model where inference (e.g., prediction, planning) over representations corresponds to inverting a low-
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#30830;&#23450;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#35268;&#27169;&#65292;&#20197;&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#23376;&#32452;&#20013;&#20272;&#35745;&#26465;&#20214;&#21453;&#20107;&#23454;&#26399;&#26395;&#65292;&#36890;&#36807;&#23558;&#21407;&#22987;&#30446;&#26631;&#36716;&#21270;&#20026;&#21516;&#26102;&#25512;&#26029;&#38382;&#39064;&#26469;&#35299;&#20915;&#20272;&#35745;&#35823;&#24046;&#22686;&#21152;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#19988;&#20801;&#35768;&#22312;&#22266;&#23450;&#30340;&#26679;&#26412;&#22823;&#23567;&#39044;&#31639;&#19979;&#36870;&#36716;&#38382;&#39064;&#20197;&#30830;&#23450;&#21487;&#34892;&#30340;&#27835;&#30103;&#25163;&#33218;&#25968;&#37327;&#25110;&#20998;&#21306;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.04039</link><description>&lt;p&gt;
&#29992;&#20110;&#26465;&#20214;&#21453;&#20107;&#23454;&#22343;&#20540;&#20272;&#35745;&#30340;&#26679;&#26412;&#35268;&#27169;&#35268;&#21010;: &#19968;&#20010;K&#33218;&#38543;&#26426;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Sample size planning for conditional counterfactual mean estimation with a K-armed randomized experiment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04039
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#20102;&#22914;&#20309;&#30830;&#23450;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#35268;&#27169;&#65292;&#20197;&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#23376;&#32452;&#20013;&#20272;&#35745;&#26465;&#20214;&#21453;&#20107;&#23454;&#26399;&#26395;&#65292;&#36890;&#36807;&#23558;&#21407;&#22987;&#30446;&#26631;&#36716;&#21270;&#20026;&#21516;&#26102;&#25512;&#26029;&#38382;&#39064;&#26469;&#35299;&#20915;&#20272;&#35745;&#35823;&#24046;&#22686;&#21152;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#19988;&#20801;&#35768;&#22312;&#22266;&#23450;&#30340;&#26679;&#26412;&#22823;&#23567;&#39044;&#31639;&#19979;&#36870;&#36716;&#38382;&#39064;&#20197;&#30830;&#23450;&#21487;&#34892;&#30340;&#27835;&#30103;&#25163;&#33218;&#25968;&#37327;&#25110;&#20998;&#21306;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35752;&#35770;&#22914;&#20309;&#30830;&#23450;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#35268;&#27169;&#65292;&#20197;&#20272;&#35745;&#25968;&#25454;&#39537;&#21160;&#23376;&#32452;&#20013;&#30340;&#26465;&#20214;&#21453;&#20107;&#23454;&#26399;&#26395;&#65292;&#35813;&#23376;&#32452;&#21487;&#20197;&#30001;&#20219;&#20309;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#31639;&#27861;&#36755;&#20986;&#65292;&#21253;&#25324;&#26681;&#25454;&#39044;&#27979;&#20998;&#25968;&#30456;&#20284;&#30340;&#29992;&#25143;&#36827;&#34892;&#20998;&#32452;&#25110;&#26681;&#25454;&#23398;&#20064;&#30340;&#31574;&#30053;&#26641;&#36827;&#34892;&#20998;&#32452;&#12290;&#22312;&#20180;&#32454;&#35268;&#23450;&#25512;&#26029;&#30446;&#26631;&#12289;&#26368;&#23567;&#32622;&#20449;&#27700;&#24179;&#21644;&#26368;&#22823;&#35823;&#24046;&#36793;&#38469;&#21518;&#65292;&#20851;&#38190;&#26159;&#23558;&#21407;&#22987;&#30446;&#26631;&#36716;&#21270;&#20026;&#19968;&#20010;&#21516;&#26102;&#25512;&#26029;&#38382;&#39064;&#65292;&#25512;&#33616;&#30340;&#26679;&#26412;&#22823;&#23567;&#20197;&#25269;&#28040;&#20272;&#35745;&#35823;&#24046;&#30340;&#22686;&#21152;&#21487;&#33021;&#24615;&#30452;&#25509;&#19982;&#35201;&#36827;&#34892;&#30340;&#25512;&#26029;&#25968;&#37327;&#30456;&#20851;&#12290;&#22312;&#32473;&#23450;&#22266;&#23450;&#26679;&#26412;&#35268;&#27169;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#38382;&#39064;&#21453;&#36716;&#20026;&#20851;&#20110;&#21487;&#34892;&#27835;&#30103;&#25163;&#33218;&#25968;&#37327;&#25110;&#20998;&#21306;&#22797;&#26434;&#24615;&#65288;&#20363;&#22914;&#65292;&#20915;&#31574;&#26641;&#21494;&#23376;&#25968;&#37327;&#65289;&#30340;&#38382;&#39064;&#12290;&#20351;&#29992;&#31574;&#30053;&#26641;&#23398;&#20064;&#23376;&#32452;&#65292;&#25105;&#20204;&#35780;&#20272;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04039v1 Announce Type: new  Abstract: We cover how to determine a sufficiently large sample size for a $K$-armed randomized experiment in order to estimate conditional counterfactual expectations in data-driven subgroups. The sub-groups can be output by any feature space partitioning algorithm, including as defined by binning users having similar predictive scores or as defined by a learned policy tree. After carefully specifying the inference target, a minimum confidence level, and a maximum margin of error, the key is to turn the original goal into a simultaneous inference problem where the recommended sample size to offset an increased possibility of estimation error is directly related to the number of inferences to be conducted. Given a fixed sample size budget, our result allows us to invert the question to one about the feasible number of treatment arms or partition complexity (e.g. number of decision tree leaves). Using policy trees to learn sub-groups, we evaluate o
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;&#23398;&#20064;&#20013;&#36890;&#36807;&#20803;&#31639;&#27861;&#32467;&#21512;&#22312;&#32447;&#22238;&#24402;&#39044;&#27979;&#22120;&#20272;&#35745;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#65292;&#24182;&#23558;&#22312;&#32447;&#23398;&#20064;&#39044;&#27979;&#36716;&#25442;&#20026;&#31526;&#21512;&#32422;&#26463;&#30340;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#35777;&#22312;&#27599;&#19968;&#36718;&#39640;&#27010;&#29575;&#22320;&#28385;&#36275;&#23433;&#20840;&#32422;&#26463;&#12290;&#31639;&#27861;&#30340;&#21518;&#24724;&#21463;&#21040;&#22312;&#32447;&#22238;&#24402;&#21644;&#22312;&#32447;&#23398;&#20064;&#39044;&#27979;&#22120;&#30340;&#38480;&#21046;&#65292;&#27169;&#22411;&#31867;&#20013;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#30340;&#36867;&#36991;&#32500;&#24230;&#65292;&#20197;&#21450;&#25429;&#25417;&#23433;&#20840;&#23398;&#20064;&#22256;&#38590;&#30340;&#26032;&#39062;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2403.04033</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#30693;&#32422;&#26463;&#30340;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Online Learning with Unknown Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04033
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#20013;&#36890;&#36807;&#20803;&#31639;&#27861;&#32467;&#21512;&#22312;&#32447;&#22238;&#24402;&#39044;&#27979;&#22120;&#20272;&#35745;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#65292;&#24182;&#23558;&#22312;&#32447;&#23398;&#20064;&#39044;&#27979;&#36716;&#25442;&#20026;&#31526;&#21512;&#32422;&#26463;&#30340;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#35777;&#22312;&#27599;&#19968;&#36718;&#39640;&#27010;&#29575;&#22320;&#28385;&#36275;&#23433;&#20840;&#32422;&#26463;&#12290;&#31639;&#27861;&#30340;&#21518;&#24724;&#21463;&#21040;&#22312;&#32447;&#22238;&#24402;&#21644;&#22312;&#32447;&#23398;&#20064;&#39044;&#27979;&#22120;&#30340;&#38480;&#21046;&#65292;&#27169;&#22411;&#31867;&#20013;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#30340;&#36867;&#36991;&#32500;&#24230;&#65292;&#20197;&#21450;&#25429;&#25417;&#23433;&#20840;&#23398;&#20064;&#22256;&#38590;&#30340;&#26032;&#39062;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#22312;&#27599;&#19968;&#36718;&#24517;&#39035;&#36981;&#23432;&#19968;&#20010;&#26410;&#30693;&#30340;&#23433;&#20840;&#32422;&#26463;&#12290;&#30446;&#26631;&#26159;&#22312;&#21516;&#26102;&#28385;&#36275;&#23433;&#20840;&#32422;&#26463;&#24182;&#22312;&#21518;&#35270;&#19979;&#26368;&#23567;&#21270;&#23545;&#26368;&#20339;&#23433;&#20840;&#21160;&#20316;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20803;&#31639;&#27861;&#65292;&#21033;&#29992;&#22312;&#32447;&#22238;&#24402;&#39044;&#27979;&#22120;&#26469;&#20272;&#35745;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#65292;&#24182;&#23558;&#22312;&#32447;&#23398;&#20064;&#39044;&#27979;&#36716;&#25442;&#20026;&#31526;&#21512;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#30340;&#39044;&#27979;&#12290;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#21518;&#24724;&#21487;&#20197;&#36890;&#36807;&#22312;&#32447;&#22238;&#24402;&#21644;&#22312;&#32447;&#23398;&#20064;&#39044;&#27979;&#22120;&#30340;&#21518;&#24724;&#12289;&#21253;&#21547;&#26410;&#30693;&#23433;&#20840;&#32422;&#26463;&#30340;&#27169;&#22411;&#31867;&#30340;&#36867;&#36991;&#32500;&#24230;&#65292;&#20197;&#21450;&#19968;&#20010;&#25429;&#25417;&#23433;&#20840;&#23398;&#20064;&#22256;&#38590;&#31243;&#24230;&#30340;&#26032;&#39062;&#22797;&#26434;&#24230;&#24230;&#37327;&#26469;&#30028;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04033v1 Announce Type: cross  Abstract: We consider the problem of online learning where the sequence of actions played by the learner must adhere to an unknown safety constraint at every round. The goal is to minimize regret with respect to the best safe action in hindsight while simultaneously satisfying the safety constraint with high probability on each round. We provide a general meta-algorithm that leverages an online regression oracle to estimate the unknown safety constraint, and converts the predictions of an online learning oracle to predictions that adhere to the unknown safety constraint. On the theoretical side, our algorithm's regret can be bounded by the regret of the online regression and online learning oracles, the eluder dimension of the model class containing the unknown safety constraint, and a novel complexity measure that captures the difficulty of safe learning. We complement our result with an asymptotic lower bound that shows that the aforementioned
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#27169;&#25311;&#29305;&#24449;&#25351;&#23548;&#21644;&#24378;&#21270;&#23398;&#20064;&#20248;&#21270;&#30340;&#21019;&#26032;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#26368;&#20339;&#26377;&#25928;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.04015</link><description>&lt;p&gt;
&#36890;&#36807;&#21333;&#20010;&#39044;&#35757;&#32451;&#30340;&#22686;&#24378;&#22411;&#20195;&#29702;&#24341;&#23548;&#30340;&#27169;&#25311;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Knockoff-Guided Feature Selection via A Single Pre-trained Reinforced Agent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04015
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#27169;&#25311;&#29305;&#24449;&#25351;&#23548;&#21644;&#24378;&#21270;&#23398;&#20064;&#20248;&#21270;&#30340;&#21019;&#26032;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29305;&#24449;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#26368;&#20339;&#26377;&#25928;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#36890;&#36807;&#28040;&#38500;&#20887;&#20313;&#29305;&#24449;&#26469;&#20934;&#22791;&#25968;&#25454;&#30340;AI&#21487;&#29992;&#24615;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#20998;&#20026;&#20004;&#31867;&#65306;i&#65289;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#65292;&#26681;&#25454;&#29305;&#24449;&#19982;&#30446;&#26631;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#35782;&#21035;&#26368;&#20339;&#29305;&#24449;&#23376;&#38598;&#65307;ii&#65289;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#65292;&#36890;&#36807;&#25429;&#33719;&#29305;&#24449;&#38598;&#20013;&#30340;&#22522;&#26412;&#20449;&#24687;&#32780;&#38750;&#20351;&#29992;&#30446;&#26631;&#21464;&#37327;&#26469;&#20943;&#23569;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#24230;&#12290;&#28982;&#32780;&#65292;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#30001;&#20110;&#20381;&#36182;&#30446;&#26631;&#21464;&#37327;&#21644;&#19979;&#28216;ML&#20219;&#21153;&#32780;&#23548;&#33268;&#32791;&#26102;&#19988;&#27867;&#21270;&#33021;&#21147;&#26377;&#38480;&#12290;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#21463;&#38480;&#20110;&#25512;&#23548;&#20986;&#30340;&#29305;&#24449;&#31354;&#38388;&#26159;&#28508;&#22312;&#19988;&#19981;&#21487;&#36861;&#36394;&#30340;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#29305;&#24449;&#36873;&#25321;&#26694;&#26550;&#65292;&#36890;&#36807;&#27169;&#25311;&#29305;&#24449;&#25351;&#23548;&#24182;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#20248;&#21270;&#65292;&#20197;&#35782;&#21035;&#26368;&#20339;&#26377;&#25928;&#30340;&#29305;&#24449;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04015v1 Announce Type: cross  Abstract: Feature selection prepares the AI-readiness of data by eliminating redundant features. Prior research falls into two primary categories: i) Supervised Feature Selection, which identifies the optimal feature subset based on their relevance to the target variable; ii) Unsupervised Feature Selection, which reduces the feature space dimensionality by capturing the essential information within the feature set instead of using target variable. However, SFS approaches suffer from time-consuming processes and limited generalizability due to the dependence on the target variable and downstream ML tasks. UFS methods are constrained by the deducted feature space is latent and untraceable. To address these challenges, we introduce an innovative framework for feature selection, which is guided by knockoff features and optimized through reinforcement learning, to identify the optimal and effective feature subset. In detail, our method involves gener
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#39062;&#39640;&#25928;&#30340;&#36924;&#36817;&#25216;&#26415;&#65292;&#29992;&#20110;&#24207;&#36143;&#27169;&#22411;&#30340;&#36793;&#32536;&#21270;&#65292;&#36825;&#20123;&#25216;&#26415;&#26159;&#27169;&#22411;&#26080;&#20851;&#30340;&#65292;&#20165;&#20381;&#36182;&#20110;&#39044;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#19979;&#19968;&#27493;&#26465;&#20214;&#20998;&#24067;&#30340;&#35775;&#38382;&#21644;&#37319;&#26679;&#12290;</title><link>https://arxiv.org/abs/2403.04005</link><description>&lt;p&gt;
&#20851;&#20110;&#27010;&#29575;&#24207;&#21015;&#27169;&#22411;&#36793;&#32536;&#21270;&#30340;&#39640;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Efficient Marginalization of Probabilistic Sequence Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04005
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#26032;&#39062;&#39640;&#25928;&#30340;&#36924;&#36817;&#25216;&#26415;&#65292;&#29992;&#20110;&#24207;&#36143;&#27169;&#22411;&#30340;&#36793;&#32536;&#21270;&#65292;&#36825;&#20123;&#25216;&#26415;&#26159;&#27169;&#22411;&#26080;&#20851;&#30340;&#65292;&#20165;&#20381;&#36182;&#20110;&#39044;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#19979;&#19968;&#27493;&#26465;&#20214;&#20998;&#24067;&#30340;&#35775;&#38382;&#21644;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#25968;&#25454;&#32463;&#24120;&#34920;&#29616;&#20986;&#24207;&#21015;&#20381;&#36182;&#24615;&#65292;&#28085;&#30422;&#20154;&#31867;&#34892;&#20026;&#12289;&#21307;&#23398;&#12289;&#37329;&#34701;&#21644;&#27668;&#20505;&#27169;&#25311;&#31561;&#21508;&#20010;&#39046;&#22495;&#12290;&#27010;&#29575;&#26041;&#27861;&#25429;&#25417;&#20102;&#36825;&#20123;&#32972;&#26223;&#19979;&#39044;&#27979;&#30456;&#20851;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#65292;&#20854;&#20013;&#33258;&#22238;&#24402;&#27169;&#22411;&#23588;&#20026;&#31361;&#20986;&#12290;&#26412;&#35770;&#25991;&#30528;&#37325;&#20110;&#20351;&#29992;&#33258;&#22238;&#24402;&#27169;&#22411;&#22238;&#31572;&#36229;&#20986;&#21333;&#27493;&#39044;&#27979;&#33539;&#22260;&#30340;&#22797;&#26434;&#27010;&#29575;&#26597;&#35810;&#65292;&#27604;&#22914;&#26410;&#26469;&#20107;&#20214;&#30340;&#26102;&#38388;&#23433;&#25490;&#25110;&#26576;&#19968;&#20107;&#20214;&#21457;&#29983;&#22312;&#21478;&#19968;&#20107;&#20214;&#20043;&#21069;&#30340;&#21487;&#33021;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31995;&#21015;&#26032;&#39062;&#39640;&#25928;&#30340;&#36924;&#36817;&#25216;&#26415;&#65292;&#29992;&#20110;&#24207;&#36143;&#27169;&#22411;&#30340;&#36793;&#32536;&#21270;&#65292;&#36825;&#20123;&#25216;&#26415;&#26159;&#27169;&#22411;&#26080;&#20851;&#30340;&#65292;&#20165;&#20381;&#36182;&#20110;&#39044;&#35757;&#32451;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#19979;&#19968;&#27493;&#26465;&#20214;&#20998;&#24067;&#30340;&#35775;&#38382;&#21644;&#37319;&#26679;&#65292;&#21253;&#25324;&#20256;&#32479;&#21442;&#25968;&#27169;&#22411;&#20197;&#21450;&#26368;&#26032;&#30340;&#31070;&#32463;&#33258;&#22238;&#24402;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04005v1 Announce Type: cross  Abstract: Real-world data often exhibits sequential dependence, across diverse domains such as human behavior, medicine, finance, and climate modeling. Probabilistic methods capture the inherent uncertainty associated with prediction in these contexts, with autoregressive models being especially prominent. This dissertation focuses on using autoregressive models to answer complex probabilistic queries that go beyond single-step prediction, such as the timing of future events or the likelihood of a specific event occurring before another. In particular, we develop a broad class of novel and efficient approximation techniques for marginalization in sequential models that are model-agnostic. These techniques rely solely on access to and sampling from next-step conditional distributions of a pre-trained autoregressive model, including both traditional parametric models as well as more recent neural autoregressive models. Specific approaches are pres
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29615;&#22659;-&#22266;&#26377;&#32500;&#24230;&#24046;&#24322;&#30340;&#27010;&#24565;&#65292;&#35770;&#25991;&#35777;&#26126;&#20102;&#32500;&#24230;&#24046;&#24322;&#20351;&#24178;&#20928;&#35757;&#32451;&#30340;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#25968;&#25454;&#31354;&#38388;&#33073;&#31163;&#27969;&#24418;&#26041;&#21521;&#30340;&#23545;&#25239;&#25200;&#21160;&#25915;&#20987;&#12290;</title><link>https://arxiv.org/abs/2403.03967</link><description>&lt;p&gt;
&#29615;&#22659;-&#22266;&#26377;&#32500;&#24230;&#24046;&#24322;&#23545;&#23545;&#25239;&#33030;&#24369;&#24615;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03967
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29615;&#22659;-&#22266;&#26377;&#32500;&#24230;&#24046;&#24322;&#30340;&#27010;&#24565;&#65292;&#35770;&#25991;&#35777;&#26126;&#20102;&#32500;&#24230;&#24046;&#24322;&#20351;&#24178;&#20928;&#35757;&#32451;&#30340;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#25968;&#25454;&#31354;&#38388;&#33073;&#31163;&#27969;&#24418;&#26041;&#21521;&#30340;&#23545;&#25239;&#25200;&#21160;&#25915;&#20987;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#20171;&#32461;&#20102;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#23384;&#22312;&#19988;&#23545;&#20154;&#31867;&#26469;&#35828;&#20960;&#20046;&#26080;&#27861;&#23519;&#35273;&#36825;&#19968;&#20107;&#23454;&#65292;&#22312;&#29702;&#35770;&#19978;&#20173;&#28982;&#30456;&#24403;&#31070;&#31192;&#12290;&#25991;&#31456;&#24341;&#20837;&#20102;&#20004;&#31181;&#23545;&#25239;&#25915;&#20987;&#30340;&#27010;&#24565;&#65306;&#33258;&#28982;&#25110;&#22312;&#27969;&#24418;&#19978;&#30340;&#25915;&#20987;&#65292;&#36825;&#20123;&#25915;&#20987;&#26159;&#21487;&#20197;&#34987;&#20154;&#31867;/&#31070;&#35861;&#24863;&#30693;&#21040;&#30340;&#65307;&#38750;&#33258;&#28982;&#25110;&#33073;&#31163;&#27969;&#24418;&#30340;&#25915;&#20987;&#65292;&#36825;&#20123;&#25915;&#20987;&#21017;&#26080;&#27861;&#34987;&#24863;&#30693;&#21040;&#12290;&#25991;&#31456;&#35748;&#20026;&#33073;&#31163;&#27969;&#24418;&#30340;&#25915;&#20987;&#23384;&#22312;&#26159;&#25968;&#25454;&#22266;&#26377;&#32500;&#24230;&#19982;&#29615;&#22659;&#32500;&#24230;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#24517;&#28982;&#32467;&#26524;&#12290;&#23545;&#20110;2&#23618;ReLU&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#32500;&#24230;&#24046;&#24322;&#19981;&#24433;&#21709;&#20174;&#35266;&#27979;&#25968;&#25454;&#31354;&#38388;&#20013;&#25277;&#21462;&#26679;&#26412;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#23427;&#20173;&#20250;&#20351;&#24178;&#20928;&#35757;&#32451;&#30340;&#27169;&#22411;&#26356;&#23481;&#26131;&#21463;&#21040;&#25968;&#25454;&#31354;&#38388;&#33073;&#31163;&#27969;&#24418;&#26041;&#21521;&#30340;&#23545;&#25239;&#25200;&#21160;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#25552;&#20379;&#20102;&#22312;/&#33073;&#31163;&#27969;&#24418;&#25915;&#20987;&#30340;$\ell_2,\ell_{\infty}$&#25915;&#20987;&#24378;&#24230;&#19982;&#32500;&#24230;&#24046;&#24322;&#20043;&#38388;&#26126;&#30830;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03967v1 Announce Type: new  Abstract: The existence of adversarial attacks on machine learning models imperceptible to a human is still quite a mystery from a theoretical perspective. In this work, we introduce two notions of adversarial attacks: natural or on-manifold attacks, which are perceptible by a human/oracle, and unnatural or off-manifold attacks, which are not. We argue that the existence of the off-manifold attacks is a natural consequence of the dimension gap between the intrinsic and ambient dimensions of the data. For 2-layer ReLU networks, we prove that even though the dimension gap does not affect generalization performance on samples drawn from the observed data space, it makes the clean-trained model more vulnerable to adversarial perturbations in the off-manifold direction of the data space. Our main results provide an explicit relationship between the $\ell_2,\ell_{\infty}$ attack strength of the on/off-manifold attack and the dimension gap.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#20110;$k$-PCA&#31639;&#27861;&#20013;&#36817;&#20284;&#21442;&#25968;&#36864;&#21270;&#30340;&#36793;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#26356;&#20026;&#31934;&#30830;&#30340;&#30028;&#38480;</title><link>https://arxiv.org/abs/2403.03905</link><description>&lt;p&gt;
&#40657;&#30418;$k$-to-$1$-PCA&#38477;&#32500;&#65306;&#29702;&#35770;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Black-Box $k$-to-$1$-PCA Reductions: Theory and Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03905
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#20110;$k$-PCA&#31639;&#27861;&#20013;&#36817;&#20284;&#21442;&#25968;&#36864;&#21270;&#30340;&#36793;&#30028;&#24471;&#21040;&#20102;&#26174;&#33879;&#26356;&#20026;&#31934;&#30830;&#30340;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
$k$-&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;$k$-PCA&#65289;&#38382;&#39064;&#26159;&#19968;&#31181;&#22522;&#26412;&#30340;&#31639;&#27861;&#21407;&#35821;&#65292;&#22312;&#25968;&#25454;&#20998;&#26512;&#21644;&#38477;&#32500;&#24212;&#29992;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#22312;&#32479;&#35745;&#29615;&#22659;&#20013;&#65292;$k$-PCA&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#19968;&#20010;&#20998;&#24067;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39030;&#37096;&#29305;&#24449;&#31354;&#38388;&#65292;&#25105;&#20204;&#21482;&#33021;&#36890;&#36807;&#26679;&#26412;&#38544;&#24335;&#35775;&#38382;&#36825;&#20010;&#30697;&#38453;&#12290;&#21463;&#36825;&#20123;&#38544;&#24335;&#35774;&#32622;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20998;&#26512;&#40657;&#30418;&#32553;&#20943;&#26041;&#27861;&#20316;&#20026;&#35774;&#35745;$k$-PCA&#31639;&#27861;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#36890;&#36807;&#40657;&#30418;$1$-PCA&#39044;&#35328;&#27169;&#25311;&#23545;&#26410;&#30693;&#30446;&#26631;&#30697;&#38453;&#30340;&#35775;&#38382;&#65292;&#35813;&#39044;&#35328;&#36820;&#22238;&#19968;&#20010;&#36817;&#20284;&#30340;&#39030;&#37096;&#29305;&#24449;&#21521;&#37327;&#65292;&#26681;&#25454;&#20004;&#20010;&#27969;&#34892;&#30340;&#36817;&#20284;&#27010;&#24565;&#12290;&#23613;&#31649;&#36825;&#31181;&#40657;&#30418;&#26041;&#27861;&#21487;&#33021;&#26159;&#35774;&#35745;$k$-PCA&#31639;&#27861;&#20013;&#26368;&#33258;&#28982;&#30340;&#22522;&#20110;&#38477;&#32500;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#36882;&#24402;&#35843;&#29992;$1$-PCA&#39044;&#35328;&#35843;&#29992;&#20102;$k$&#27425;&#65292;&#20197;&#21069;&#24456;&#38590;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03905v1 Announce Type: cross  Abstract: The $k$-principal component analysis ($k$-PCA) problem is a fundamental algorithmic primitive that is widely-used in data analysis and dimensionality reduction applications. In statistical settings, the goal of $k$-PCA is to identify a top eigenspace of the covariance matrix of a distribution, which we only have implicit access to via samples. Motivated by these implicit settings, we analyze black-box deflation methods as a framework for designing $k$-PCA algorithms, where we model access to the unknown target matrix via a black-box $1$-PCA oracle which returns an approximate top eigenvector, under two popular notions of approximation. Despite being arguably the most natural reduction-based approach to $k$-PCA algorithm design, such black-box methods, which recursively call a $1$-PCA oracle $k$ times, were previously poorly-understood.   Our main contribution is significantly sharper bounds on the approximation parameter degradation of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#35270;&#20026;&#23884;&#20837;&#21040;&#26356;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;RKHS&#20013;&#35889;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#28909;&#26680;&#29983;&#25104;&#30340;&#25193;&#25955;&#31354;&#38388;&#65292;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#25216;&#26415;&#25512;&#23548;&#20102;&#20851;&#20110;&#24191;&#20041;&#33539;&#25968;&#30340;&#32039;&#25910;&#25947;&#19978;&#30028;&#65292;&#20351;&#20272;&#35745;&#22120;&#22312;&#24378;&#24847;&#20041;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.03669</link><description>&lt;p&gt;
&#36890;&#36807;&#25193;&#25955;&#22312;&#27969;&#24418;&#19978;&#30340;&#35889;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Spectral Algorithms on Manifolds through Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65292;&#23558;&#36755;&#20837;&#25968;&#25454;&#35270;&#20026;&#23884;&#20837;&#21040;&#26356;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;RKHS&#20013;&#35889;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#28909;&#26680;&#29983;&#25104;&#30340;&#25193;&#25955;&#31354;&#38388;&#65292;&#36890;&#36807;&#31215;&#20998;&#31639;&#23376;&#25216;&#26415;&#25512;&#23548;&#20102;&#20851;&#20110;&#24191;&#20041;&#33539;&#25968;&#30340;&#32039;&#25910;&#25947;&#19978;&#30028;&#65292;&#20351;&#20272;&#35745;&#22120;&#22312;&#24378;&#24847;&#20041;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#24212;&#29992;&#30340;&#35889;&#31639;&#27861;&#30340;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#19968;&#33324;&#26680;&#20989;&#25968;&#19978;&#65292;&#32463;&#24120;&#24573;&#30053;&#36755;&#20837;&#29305;&#24449;&#31354;&#38388;&#30340;&#22266;&#26377;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#35270;&#35282;&#65292;&#20027;&#24352;&#36755;&#20837;&#25968;&#25454;&#20301;&#20110;&#19968;&#20010;&#23884;&#20837;&#21040;&#26356;&#39640;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20302;&#32500;&#27969;&#24418;&#20869;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;RKHS&#20013;&#35889;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#37027;&#20123;&#30001;&#28909;&#26680;&#29983;&#25104;&#30340;&#65292;&#34987;&#31216;&#20026;&#25193;&#25955;&#31354;&#38388;&#30340;&#31354;&#38388;&#12290;&#36890;&#36807;&#32467;&#21512;&#36755;&#20837;&#30340;&#27969;&#24418;&#32467;&#26500;&#65292;&#25105;&#20204;&#37319;&#29992;&#31215;&#20998;&#31639;&#23376;&#25216;&#26415;&#25512;&#23548;&#20102;&#20851;&#20110;&#24191;&#20041;&#33539;&#25968;&#30340;&#32039;&#25910;&#25947;&#19978;&#30028;&#65292;&#36825;&#34920;&#26126;&#20272;&#35745;&#22120;&#22312;&#24378;&#24847;&#20041;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20989;&#25968;&#65292;&#24847;&#21619;&#30528;&#20989;&#25968;&#26412;&#36523;&#21450;&#20854;&#23548;&#25968;&#21516;&#26102;&#25910;&#25947;&#12290;&#36825;&#20123;&#30028;&#25552;&#20379;&#20102;&#20004;&#20010;&#37325;&#35201;&#20248;&#21183;&#65306;&#39318;&#20808;&#65292;&#23427;&#20204;&#26159;&#23436;&#20840;&#36830;&#32493;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03669v1 Announce Type: cross  Abstract: The existing research on spectral algorithms, applied within a Reproducing Kernel Hilbert Space (RKHS), has primarily focused on general kernel functions, often neglecting the inherent structure of the input feature space. Our paper introduces a new perspective, asserting that input data are situated within a low-dimensional manifold embedded in a higher-dimensional Euclidean space. We study the convergence performance of spectral algorithms in the RKHSs, specifically those generated by the heat kernels, known as diffusion spaces. Incorporating the manifold structure of the input, we employ integral operator techniques to derive tight convergence upper bounds concerning generalized norms, which indicates that the estimators converge to the target function in strong sense, entailing the simultaneous convergence of the function itself and its derivatives. These bounds offer two significant advantages: firstly, they are exclusively contin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#27169;&#25311;&#20102;&#27668;&#32568;&#21387;&#21147;&#21644;&#24490;&#29615;&#21464;&#21270;&#65292;&#20197;&#35299;&#20915;&#26080;&#27861;&#25429;&#25417;&#24490;&#29615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#23545;&#20110;&#29123;&#28903;&#25511;&#21046;&#35774;&#35745;&#38750;&#24120;&#37325;&#35201;</title><link>https://arxiv.org/abs/2403.03602</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#30340;&#20855;&#26377;&#24490;&#29615;&#21464;&#21270;&#30340;&#27668;&#32568;&#21387;&#21147;&#27169;&#22411;&#29992;&#20110;&#29123;&#28903;&#25511;&#21046;&#65306;RCCI&#21457;&#21160;&#26426;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Data-Based In-Cylinder Pressure Model with Cyclic Variations for Combustion Control: A RCCI Engine Application
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03602
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#27169;&#25311;&#20102;&#27668;&#32568;&#21387;&#21147;&#21644;&#24490;&#29615;&#21464;&#21270;&#65292;&#20197;&#35299;&#20915;&#26080;&#27861;&#25429;&#25417;&#24490;&#29615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#23545;&#20110;&#29123;&#28903;&#25511;&#21046;&#35774;&#35745;&#38750;&#24120;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27668;&#32568;&#21387;&#21147;&#22522;&#30784;&#25511;&#21046;&#26159;&#20808;&#36827;&#30340;&#39044;&#28151;&#21512;&#29123;&#28903;&#27010;&#24565;&#30340;&#20851;&#38190;&#25512;&#21160;&#22240;&#32032;&#65292;&#38500;&#20102;&#30830;&#20445;&#31283;&#20581;&#19988;&#23433;&#20840;&#30340;&#25805;&#20316;&#22806;&#65292;&#36824;&#21487;&#20197;&#23454;&#29616;&#27668;&#32568;&#21387;&#21147;&#21644;&#28909;&#37322;&#25918;&#30340;&#22609;&#36896;&#12290;&#36825;&#38656;&#35201;&#24555;&#36895;&#30340;&#38754;&#21521;&#25511;&#21046;&#30340;&#29123;&#28903;&#27169;&#22411;&#12290;&#22810;&#24180;&#26469;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#24179;&#22343;&#20540;&#27169;&#22411;&#65292;&#21487;&#20197;&#39044;&#27979;&#29123;&#28903;&#25351;&#26631;&#65288;&#20363;&#22914;&#65292;&#24635;&#30340;&#25351;&#31034;&#24179;&#22343;&#26377;&#25928;&#21387;&#21147;&#65292;&#25110;&#37322;&#25918;&#24635;&#28909;&#37327;&#30340;&#26354;&#36724;&#26059;&#36716;&#35282;&#24230;&#65289;&#65292;&#25110;&#32773;&#39044;&#27979;&#23436;&#25972;&#30340;&#27668;&#32568;&#21387;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#26080;&#27861;&#25429;&#25417;&#24490;&#29615;&#21464;&#21270;&#65292;&#36825;&#23545;&#20110;&#29123;&#28903;&#27010;&#24565;&#30340;&#25511;&#21046;&#35774;&#35745;&#33267;&#20851;&#37325;&#35201;&#65292;&#20363;&#22914;&#65292;&#21453;&#24212;&#24615;&#25511;&#21046;&#21387;&#32553;&#28857;&#28779;&#65292;&#36825;&#21487;&#33021;&#20250;&#36973;&#21463;&#22823;&#24133;&#24230;&#30340;&#24490;&#29615;&#21464;&#21270;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#23545;&#27668;&#32568;&#21387;&#21147;&#21644;&#24490;&#29615;&#21464;&#21270;&#36827;&#34892;&#20102;&#24314;&#27169;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#20027;&#25104;&#20998;&#20998;&#35299;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#12290;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03602v1 Announce Type: cross  Abstract: Cylinder pressure-based control is a key enabler for advanced pre-mixed combustion concepts. Besides guaranteeing robust and safe operation, it allows for cylinder pressure and heat release shaping. This requires fast control-oriented combustion models. Over the years, mean-value models have been proposed that can predict combustion measures (e.g., Gross Indicated Mean Effective Pressure, or the crank angle where 50% of the total heat is released) or models that predict the full in-cylinder pressure. However, these models are not able to capture cyclic variations. This is important in the control design for combustion concepts, like Reactivity Controlled Compression Ignition, that can suffer from large cyclic variations. In this study, the in-cylinder pressure and cyclic variation are modelled using a data-based approach. The model combines Principle Component Decomposition and Gaussian Process Regression. A detailed study is performed
&lt;/p&gt;</description></item><item><title>CoRMF&#26159;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#39640;&#25928;&#20234;&#36763;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#21033;&#29992;&#20851;&#38190;&#26377;&#24207;&#33258;&#26059;&#24207;&#21015;&#21644;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#21464;&#20998;&#22343;&#22330;&#21644; RNN &#20043;&#38388;&#30340;&#32479;&#19968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;&#20234;&#36763;&#27169;&#22411;&#30340;&#39640;&#25928;&#25506;&#32034;&#12290;</title><link>https://arxiv.org/abs/2403.03391</link><description>&lt;p&gt;
CoRMF: &#20020;&#30028;&#26377;&#24207;&#24490;&#29615;&#22343;&#22330;&#20234;&#36763;&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
CoRMF: Criticality-Ordered Recurrent Mean Field Ising Solver
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03391
&lt;/p&gt;
&lt;p&gt;
CoRMF&#26159;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#39640;&#25928;&#20234;&#36763;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#21033;&#29992;&#20851;&#38190;&#26377;&#24207;&#33258;&#26059;&#24207;&#21015;&#21644;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#21464;&#20998;&#22343;&#22330;&#21644; RNN &#20043;&#38388;&#30340;&#32479;&#19968;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;&#20234;&#36763;&#27169;&#22411;&#30340;&#39640;&#25928;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;RNN&#30340;&#39640;&#25928;&#20234;&#36763;&#27169;&#22411;&#27714;&#35299;&#22120;&#65292;&#31216;&#20026;Criticality-ordered Recurrent Mean Field (CoRMF)&#65292;&#29992;&#20110;&#21069;&#21521;&#20234;&#36763;&#38382;&#39064;&#12290;&#22312;&#20854;&#26680;&#24515;&#37096;&#20998;&#65292;&#36890;&#36807;&#36138;&#23146;&#31639;&#27861;&#23545;N&#20010;&#33258;&#26059;&#30340;&#20234;&#36763;&#27169;&#22411;&#36827;&#34892;&#20102;&#20851;&#38190;&#26377;&#24207;&#33258;&#26059;&#24207;&#21015;&#30340;&#24341;&#20837;&#65292;&#20174;&#32780;&#21487;&#20197;&#21033;&#29992;&#33258;&#22238;&#24402;&#22343;&#22330;&#22240;&#23376;&#20998;&#35299;&#65292;&#24182;&#36890;&#36807;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;(RNNs)&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20004;&#20010;&#26174;&#33879;&#29305;&#28857;&#65306;(i)&#36890;&#36807;&#21033;&#29992;&#24213;&#23618;&#20234;&#36763;&#22270;&#30340;&#36817;&#20284;&#26641;&#32467;&#26500;&#65292;&#26032;&#33719;&#24471;&#30340;&#20851;&#38190;&#24615;&#39034;&#24207;&#20351;&#21464;&#20998;&#22343;&#22330;&#21644;RNN&#20043;&#38388;&#24471;&#20197;&#32479;&#19968;&#65292;&#20174;&#32780;&#20801;&#35768;&#26377;&#25928;&#22320;&#21033;&#29992;&#27010;&#29575;&#25512;&#26029;&#26469;&#25506;&#31350;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#30340;&#20234;&#36763;&#27169;&#22411;;(ii)&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#27169;&#22359;&#21270;&#12289;&#29420;&#31435;&#20110;&#27169;&#22411;&#32780;&#21448;&#36275;&#22815;&#34920;&#36798;&#33021;&#21147;&#65292;&#22240;&#27492;&#21487;&#20197;&#23436;&#20840;&#36866;&#29992;&#20110;&#20219;&#20309;&#21069;&#21521;&#20234;&#36763;&#25512;&#29702;&#38382;&#39064;&#65292;&#32780;&#19988;&#24037;&#20316;&#37327;&#26497;&#23567;&#12290;&#35745;&#31639;&#19978;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26041;&#24046;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03391v1 Announce Type: cross  Abstract: We propose an RNN-based efficient Ising model solver, the Criticality-ordered Recurrent Mean Field (CoRMF), for forward Ising problems. In its core, a criticality-ordered spin sequence of an $N$-spin Ising model is introduced by sorting mission-critical edges with greedy algorithm, such that an autoregressive mean-field factorization can be utilized and optimized with Recurrent Neural Networks (RNNs). Our method has two notable characteristics: (i) by leveraging the approximated tree structure of the underlying Ising graph, the newly-obtained criticality order enables the unification between variational mean-field and RNN, allowing the generally intractable Ising model to be efficiently probed with probabilistic inference; (ii) it is well-modulized, model-independent while at the same time expressive enough, and hence fully applicable to any forward Ising inference problems with minimal effort. Computationally, by using a variance-redu
&lt;/p&gt;</description></item><item><title>&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#32463;&#39564;&#35777;&#25454;&#26174;&#31034;&#20854;&#22312;&#20989;&#25968;&#20272;&#35745;&#21644;&#21327;&#26041;&#24046;&#24314;&#27169;&#20013;&#20811;&#26381;&#20102;&#39640;&#32500;&#36755;&#20837;&#22256;&#38590;&#65292;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>https://arxiv.org/abs/2402.02746</link><description>&lt;p&gt;
&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#36275;&#20197;&#24212;&#23545;
&lt;/p&gt;
&lt;p&gt;
Standard Gaussian Process is All You Need for High-Dimensional Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02746
&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934; Gaussian &#36807;&#31243;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#32463;&#39564;&#35777;&#25454;&#26174;&#31034;&#20854;&#22312;&#20989;&#25968;&#20272;&#35745;&#21644;&#21327;&#26041;&#24046;&#24314;&#27169;&#20013;&#20811;&#26381;&#20102;&#39640;&#32500;&#36755;&#20837;&#22256;&#38590;&#65292;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#20197;&#26469;&#65292;&#20154;&#20204;&#26222;&#36941;&#35748;&#20026;&#20351;&#29992;&#26631;&#20934; Gaussian &#36807;&#31243;&#65288;GP&#65289;&#36827;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#65292;&#21363;&#26631;&#20934; BO&#65292;&#22312;&#39640;&#32500;&#20248;&#21270;&#38382;&#39064;&#20013;&#25928;&#26524;&#19981;&#20339;&#12290;&#36825;&#31181;&#35266;&#24565;&#21487;&#20197;&#37096;&#20998;&#24402;&#22240;&#20110; Gaussian &#36807;&#31243;&#22312;&#21327;&#26041;&#24046;&#24314;&#27169;&#21644;&#20989;&#25968;&#20272;&#35745;&#20013;&#23545;&#39640;&#32500;&#36755;&#20837;&#30340;&#22256;&#38590;&#12290;&#34429;&#28982;&#36825;&#20123;&#25285;&#24551;&#30475;&#36215;&#26469;&#21512;&#29702;&#65292;&#20294;&#32570;&#20047;&#25903;&#25345;&#36825;&#31181;&#35266;&#28857;&#30340;&#32463;&#39564;&#35777;&#25454;&#12290;&#26412;&#25991;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#38382;&#39064;&#19978;&#65292;&#20351;&#29992;&#26631;&#20934; GP &#22238;&#24402;&#36827;&#34892;&#39640;&#32500;&#20248;&#21270;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#26631;&#20934; GP &#30340;&#34920;&#29616;&#22987;&#32456;&#20301;&#20110;&#26368;&#20339;&#33539;&#22260;&#20869;&#65292;&#24448;&#24448;&#27604;&#19987;&#38376;&#20026;&#39640;&#32500;&#20248;&#21270;&#35774;&#35745;&#30340;&#29616;&#26377; BO &#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#19982;&#21051;&#26495;&#21360;&#35937;&#30456;&#21453;&#65292;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934; GP &#21487;&#20197;&#20316;&#20026;&#23398;&#20064;&#39640;&#32500;&#30446;&#26631;&#20989;&#25968;&#30340;&#33021;&#21147;&#24378;&#22823;&#30340;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#24378;&#32467;&#26500;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#26631;&#20934; GP &#36827;&#34892; BO &#21487;&#20197;&#33719;&#24471;&#38750;&#24120;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been a long-standing and widespread belief that Bayesian Optimization (BO) with standard Gaussian process (GP), referred to as standard BO, is ineffective in high-dimensional optimization problems. This perception may partly stem from the intuition that GPs struggle with high-dimensional inputs for covariance modeling and function estimation. While these concerns seem reasonable, empirical evidence supporting this belief is lacking. In this paper, we systematically investigated BO with standard GP regression across a variety of synthetic and real-world benchmark problems for high-dimensional optimization. Surprisingly, the performance with standard GP consistently ranks among the best, often outperforming existing BO methods specifically designed for high-dimensional optimization by a large margin. Contrary to the stereotype, we found that standard GP can serve as a capable surrogate for learning high-dimensional target functions. Without strong structural assumptions, BO wit
&lt;/p&gt;</description></item><item><title>&#32467;&#21512;&#25286;&#20998;&#32622;&#20449;&#39044;&#27979;&#21644;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#31867;&#22270;&#20687;&#20998;&#31867;&#20013;&#30340;&#20998;&#24067;&#22806;&#35206;&#30422;&#29575;&#22522;&#20110;&#27169;&#22411;&#22312;&#26657;&#20934;&#38598;&#19978;&#30340;&#20449;&#24515;&#27700;&#24179;&#65292;&#21487;&#33021;&#20250;&#24433;&#21709;&#27169;&#22411;&#23545;&#20998;&#24067;&#22806;&#25968;&#25454;&#30340;&#22788;&#29702;&#12290;</title><link>https://arxiv.org/abs/2311.12688</link><description>&lt;p&gt;
&#20851;&#20110;&#32467;&#21512;&#25286;&#20998;&#32622;&#20449;&#39044;&#27979;&#21644;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#20998;&#24067;&#22806;&#35206;&#30422;&#29575;
&lt;/p&gt;
&lt;p&gt;
On the Out-of-Distribution Coverage of Combining Split Conformal Prediction and Bayesian Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12688
&lt;/p&gt;
&lt;p&gt;
&#32467;&#21512;&#25286;&#20998;&#32622;&#20449;&#39044;&#27979;&#21644;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#22810;&#31867;&#22270;&#20687;&#20998;&#31867;&#20013;&#30340;&#20998;&#24067;&#22806;&#35206;&#30422;&#29575;&#22522;&#20110;&#27169;&#22411;&#22312;&#26657;&#20934;&#38598;&#19978;&#30340;&#20449;&#24515;&#27700;&#24179;&#65292;&#21487;&#33021;&#20250;&#24433;&#21709;&#27169;&#22411;&#23545;&#20998;&#24067;&#22806;&#25968;&#25454;&#30340;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#21644;&#32622;&#20449;&#39044;&#27979;&#26159;&#20004;&#31181;&#29992;&#20110;&#20256;&#36798;&#19981;&#30830;&#23450;&#24615;&#24182;&#22686;&#21152;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23433;&#20840;&#24615;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20851;&#27880;&#23558;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#19982;&#25286;&#20998;&#32622;&#20449;&#39044;&#27979;&#30456;&#32467;&#21512;&#23545;&#20998;&#24067;&#22806;&#35206;&#30422;&#29575;&#30340;&#24433;&#21709;&#65307;&#29305;&#21035;&#26159;&#22312;&#22810;&#31867;&#22270;&#20687;&#20998;&#31867;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#24314;&#35758;&#65292;&#22914;&#26524;&#27169;&#22411;&#22312;&#26657;&#20934;&#38598;&#19978;&#36890;&#24120;&#32570;&#20047;&#20449;&#24515;&#65292;&#37027;&#20040;&#24471;&#21040;&#30340;&#32622;&#20449;&#38598;&#21487;&#33021;&#19982;&#31616;&#21333;&#39044;&#27979;&#21487;&#20449;&#38598;&#30456;&#27604;&#65292;&#34920;&#29616;&#20986;&#26356;&#31967;&#31957;&#30340;&#20998;&#24067;&#22806;&#35206;&#30422;&#12290;&#30456;&#21453;&#65292;&#22914;&#26524;&#27169;&#22411;&#22312;&#26657;&#20934;&#38598;&#19978;&#36807;&#20110;&#33258;&#20449;&#65292;&#20351;&#29992;&#32622;&#20449;&#39044;&#27979;&#21487;&#33021;&#20250;&#25913;&#21892;&#20998;&#24067;&#22806;&#35206;&#30422;&#12290;&#25105;&#20204;&#35780;&#20272;&#23558;&#25286;&#20998;&#32622;&#20449;&#26041;&#27861;&#19982;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12289;&#28145;&#24230;&#38598;&#21512;&#21644;&#22343;&#22330;&#21464;&#20998;&#25512;&#29702;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#30340;&#39044;&#27979;&#38598;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#32467;&#21512;B
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.12688v2 Announce Type: replace  Abstract: Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining B
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39034;&#24207;&#31070;&#32463;&#20284;&#28982;&#26041;&#27861;&#65292;&#36890;&#36807;&#32435;&#20837;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#65292;&#20351;&#20854;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#33021;&#22815;&#35782;&#21035;&#25968;&#25454;&#30340;&#29305;&#24449;&#12290;</title><link>https://arxiv.org/abs/2301.13368</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30340;&#35823;&#24046;&#40065;&#26834;&#39034;&#24207;&#31070;&#32463;&#20284;&#28982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Misspecification-robust Sequential Neural Likelihood for Simulation-based Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.13368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39034;&#24207;&#31070;&#32463;&#20284;&#28982;&#26041;&#27861;&#65292;&#36890;&#36807;&#32435;&#20837;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#65292;&#20351;&#20854;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#33021;&#22815;&#35782;&#21035;&#25968;&#25454;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#25311;&#25512;&#26029;&#25216;&#26415;&#23545;&#20110;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#26426;&#26800;&#21644;&#21487;&#27169;&#25311;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#20256;&#32479;&#32479;&#35745;&#26041;&#27861;(&#22914;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#21644;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;)&#30340;&#30740;&#31350;&#20013;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#22312;&#35268;&#23450;&#33391;&#22909;&#21644;&#38169;&#35823;&#35268;&#23450;&#30340;&#35774;&#32622;&#19979;&#36827;&#34892;&#30740;&#31350;&#65292;&#20294;&#30001;&#20110;&#28010;&#36153;&#27169;&#22411;&#27169;&#25311;&#32780;&#23548;&#33268;&#25928;&#29575;&#20302;&#19979;&#12290;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#22914;&#39034;&#24207;&#31070;&#32463;&#20284;&#28982;(SNL)&#65292;&#36890;&#36807;&#21033;&#29992;&#25152;&#26377;&#27169;&#22411;&#27169;&#25311;&#26469;&#35757;&#32451;&#31070;&#32463;&#20195;&#29702;&#20284;&#28982;&#20989;&#25968;&#65292;&#36991;&#20813;&#20102;&#36825;&#31181;&#28010;&#36153;&#12290;&#28982;&#32780;&#65292;SNL&#22312;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#30340;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#19981;&#21487;&#38752;&#65292;&#21487;&#33021;&#23548;&#33268;&#22260;&#32469;&#19981;&#20934;&#30830;&#21442;&#25968;&#20272;&#35745;&#30340;&#36807;&#20110;&#33258;&#20449;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SNL&#26041;&#27861;&#65292;&#36890;&#36807;&#32435;&#20837;&#39069;&#22806;&#30340;&#35843;&#25972;&#21442;&#25968;&#65292;&#20351;&#20854;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#33021;&#22815;&#35782;&#21035;&#25968;&#25454;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.13368v2 Announce Type: replace-cross  Abstract: Simulation-based inference techniques are indispensable for parameter estimation of mechanistic and simulable models with intractable likelihoods. While traditional statistical approaches like approximate Bayesian computation and Bayesian synthetic likelihood have been studied under well-specified and misspecified settings, they often suffer from inefficiencies due to wasted model simulations. Neural approaches, such as sequential neural likelihood (SNL) avoid this wastage by utilising all model simulations to train a neural surrogate for the likelihood function. However, the performance of SNL under model misspecification is unreliable and can result in overconfident posteriors centred around an inaccurate parameter estimate. In this paper, we propose a novel SNL method, which through the incorporation of additional adjustment parameters, is robust to model misspecification and capable of identifying features of the data that 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#19968;&#38454;&#24809;&#32602;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#23547;&#25214;$\varepsilon$-KKT&#35299;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#30830;&#31435;&#20102;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2301.01716</link><description>&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#30340;&#19968;&#38454;&#24809;&#32602;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
First-order penalty methods for bilevel optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.01716
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#19968;&#38454;&#24809;&#32602;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#23547;&#25214;$\varepsilon$-KKT&#35299;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#30830;&#31435;&#20102;&#20854;&#25805;&#20316;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#26080;&#32422;&#26463;&#21644;&#26377;&#32422;&#26463;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#19979;&#23618;&#26159;&#21487;&#33021;&#26159;&#38750;&#20809;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#32780;&#19978;&#23618;&#26159;&#21487;&#33021;&#26159;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;$\varepsilon$-KKT&#35299;&#30340;&#27010;&#24565;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;$\varepsilon$-KKT&#35299;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#20250;&#23548;&#33268;&#19968;&#20010;$O(\sqrt{\varepsilon})$&#25110;$O(\varepsilon)$-&#22522;&#20110;&#36229;&#26799;&#24230;&#30340;&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#38454;&#24809;&#32602;&#26041;&#27861;&#26469;&#23547;&#25214;&#23427;&#20204;&#30340;$\varepsilon$-KKT&#35299;&#65292;&#20854;&#23376;&#38382;&#39064;&#23454;&#38469;&#19978;&#26159;&#19968;&#20010;&#32467;&#26500;&#21270;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#36890;&#36807;&#20316;&#32773;&#26368;&#36817;&#24320;&#21457;&#30340;&#19968;&#38454;&#26041;&#27861;&#36866;&#24403;&#22320;&#35299;&#20915;&#12290;&#22312;&#36866;&#24403;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;&#23427;&#20204;&#30340;&#22522;&#26412;&#25805;&#20316;&#34913;&#37327;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#30340;&#24809;&#32602;&#26041;&#27861;&#30340;&#8220;&#25805;&#20316;&#22797;&#26434;&#24230;&#8221;&#20998;&#21035;&#20026;$O(\varepsilon^{-4}\log\varepsilon^{-1})$&#21644;$O(\varepsilon^{-7}\log\varepsilon^{-1})$&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.01716v2 Announce Type: replace-cross  Abstract: In this paper we study a class of unconstrained and constrained bilevel optimization problems in which the lower level is a possibly nonsmooth convex optimization problem, while the upper level is a possibly nonconvex optimization problem. We introduce a notion of $\varepsilon$-KKT solution for them and show that an $\varepsilon$-KKT solution leads to an $O(\sqrt{\varepsilon})$- or $O(\varepsilon)$-hypergradient based stionary point under suitable assumptions. We also propose first-order penalty methods for finding an $\varepsilon$-KKT solution of them, whose subproblems turn out to be a structured minimax problem and can be suitably solved by a first-order method recently developed by the authors. Under suitable assumptions, an \emph{operation complexity} of $O(\varepsilon^{-4}\log\varepsilon^{-1})$ and $O(\varepsilon^{-7}\log\varepsilon^{-1})$, measured by their fundamental operations, is established for the proposed penalty 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#37327;&#21270;&#32654;&#22269;&#26497;&#31471;&#26862;&#26519;&#28779;&#28798;&#30340;&#39118;&#38505;</title><link>https://arxiv.org/abs/2208.07581</link><description>&lt;p&gt;
&#32654;&#22269;&#26497;&#31471;&#26862;&#26519;&#28779;&#28798;&#30340;&#26102;&#31354;&#22238;&#24402;&#24314;&#27169;&#65306;&#37096;&#20998;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Regression modelling of spatiotemporal extreme U.S. wildfires via partially-interpretable neural networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.07581
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#37327;&#21270;&#32654;&#22269;&#26497;&#31471;&#26862;&#26519;&#28779;&#28798;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29615;&#22659;&#32972;&#26223;&#19979;&#30340;&#39118;&#38505;&#31649;&#29702;&#38656;&#35201;&#29702;&#35299;&#39537;&#21160;&#26497;&#31471;&#20107;&#20214;&#30340;&#26426;&#21046;&#12290;&#29992;&#20110;&#37327;&#21270;&#36825;&#31181;&#39118;&#38505;&#30340;&#26377;&#29992;&#25351;&#26631;&#26159;&#21709;&#24212;&#21464;&#37327;&#30340;&#26497;&#31471;&#20998;&#20301;&#25968;&#65292;&#20854;&#26465;&#20214;&#26159;&#25551;&#36848;&#27668;&#20505;&#12289;&#29983;&#29289;&#22280;&#21644;&#29615;&#22659;&#29366;&#24577;&#31561;&#39044;&#27979;&#21464;&#37327;&#12290;&#20856;&#22411;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#20998;&#20301;&#25968;&#20301;&#20110;&#21487;&#35266;&#27979;&#25968;&#25454;&#33539;&#22260;&#20043;&#22806;&#65292;&#22240;&#27492;&#65292;&#20026;&#20102;&#36827;&#34892;&#20272;&#35745;&#65292;&#38656;&#35201;&#22312;&#22238;&#24402;&#26694;&#26550;&#20869;&#25351;&#23450;&#21442;&#25968;&#26497;&#20540;&#27169;&#22411;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#21033;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26497;&#31471;&#20998;&#20301;&#25968;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2208.07581v4 Announce Type: replace-cross  Abstract: Risk management in many environmental settings requires an understanding of the mechanisms that drive extreme events. Useful metrics for quantifying such risk are extreme quantiles of response variables conditioned on predictor variables that describe, e.g., climate, biosphere and environmental states. Typically these quantiles lie outside the range of observable data and so, for estimation, require specification of parametric extreme value models within a regression framework. Classical approaches in this context utilise linear or additive relationships between predictor and response variables and suffer in either their predictive capabilities or computational efficiency; moreover, their simplicity is unlikely to capture the truly complex structures that lead to the creation of extreme wildfires. In this paper, we propose a new methodological framework for performing extreme quantile regression using artificial neutral network
&lt;/p&gt;</description></item><item><title>&#35752;&#35770;&#20102;&#21452;Lipschitz&#27491;&#35268;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#38590;&#20197;&#36924;&#36817;&#30340;&#30446;&#26631;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32473;&#20986;&#19979;&#30028;&#21051;&#30011;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#26368;&#21518;&#35752;&#35770;&#20102;&#20351;&#29992;&#26356;&#22797;&#26434;&#30340;&#28508;&#22312;&#20998;&#24067;&#31561;&#28508;&#22312;&#25913;&#36827;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2107.07232</link><description>&lt;p&gt;
&#35770;&#21452;Lipschitz&#27491;&#35268;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
On the expressivity of bi-Lipschitz normalizing flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2107.07232
&lt;/p&gt;
&lt;p&gt;
&#35752;&#35770;&#20102;&#21452;Lipschitz&#27491;&#35268;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#38590;&#20197;&#36924;&#36817;&#30340;&#30446;&#26631;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32473;&#20986;&#19979;&#30028;&#21051;&#30011;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#36317;&#31163;&#65292;&#26368;&#21518;&#35752;&#35770;&#20102;&#20351;&#29992;&#26356;&#22797;&#26434;&#30340;&#28508;&#22312;&#20998;&#24067;&#31561;&#28508;&#22312;&#25913;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#21487;&#36870;&#20989;&#25968;&#33509;&#20854;&#33258;&#36523;&#21644;&#20854;&#36870;&#20989;&#25968;&#22343;&#20855;&#26377;&#26377;&#30028;Lipschitz&#24120;&#25968;&#65292;&#21017;&#31216;&#20043;&#20026;&#21452;Lipschitz&#20989;&#25968;&#12290; &#22914;&#20170;&#65292;&#22823;&#22810;&#25968;&#27491;&#35268;&#21270;&#27969;&#36890;&#36807;&#35774;&#35745;&#25110;&#35757;&#32451;&#32780;&#25104;&#20026;&#21452;Lipschitz&#65292;&#20197;&#38480;&#21046;&#25968;&#20540;&#35823;&#24046; (&#31561;&#31561;)&#12290; &#26412;&#25991;&#35752;&#35770;&#20102;&#21452;Lipschitz&#27491;&#35268;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#24182;&#30830;&#23450;&#20102;&#19968;&#20123;&#38590;&#20197;&#29992;&#36825;&#31181;&#27169;&#22411;&#36924;&#36817;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290; &#20854;&#27425;&#65292;&#25105;&#20204;&#36890;&#36807;&#32473;&#20986;&#33509;&#24178;&#29305;&#21035;&#19981;&#21033;&#20998;&#24067;&#19982;&#20854;&#26368;&#20339;&#36924;&#36817;&#20043;&#38388;&#30340;&#24635;&#21464;&#20998;&#36317;&#31163;&#30340;&#33509;&#24178;&#19979;&#30028;&#65292;&#21051;&#30011;&#20102;&#21452;Lipschitz&#27491;&#35268;&#21270;&#27969;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290; &#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19968;&#20123;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#26356;&#22797;&#26434;&#30340;&#28508;&#22312;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2107.07232v3 Announce Type: replace  Abstract: An invertible function is bi-Lipschitz if both the function and its inverse have bounded Lipschitz constants. Nowadays, most Normalizing Flows are bi-Lipschitz by design or by training to limit numerical errors (among other things). In this paper, we discuss the expressivity of bi-Lipschitz Normalizing Flows and identify several target distributions that are difficult to approximate using such models. Then, we characterize the expressivity of bi-Lipschitz Normalizing Flows by giving several lower bounds on the Total Variation distance between these particularly unfavorable distributions and their best possible approximation. Finally, we discuss potential remedies which include using more complex latent distributions.
&lt;/p&gt;</description></item><item><title>&#23558;&#38543;&#26426;&#26799;&#24230;&#30340;&#21333;&#27493;&#25191;&#34892;&#26041;&#24335;&#25512;&#24191;&#20026;&#22238;&#39038;&#36924;&#36817;&#26041;&#27861;&#65288;RA&#65289;&#65292;&#22312;&#27599;&#27425;&#36845;&#20195;&#26399;&#38388;&#36890;&#36807;&#21487;&#33021;&#22810;&#27493;&#30340;&#30830;&#23450;&#24615;&#27714;&#35299;&#22120;&#25552;&#39640;&#32479;&#35745;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2103.04392</link><description>&lt;p&gt;
&#19968;&#31181;&#24179;&#28369;&#38543;&#26426;&#20248;&#21270;&#30340;&#22238;&#39038;&#36924;&#36817;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Retrospective Approximation Approach for Smooth Stochastic Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2103.04392
&lt;/p&gt;
&lt;p&gt;
&#23558;&#38543;&#26426;&#26799;&#24230;&#30340;&#21333;&#27493;&#25191;&#34892;&#26041;&#24335;&#25512;&#24191;&#20026;&#22238;&#39038;&#36924;&#36817;&#26041;&#27861;&#65288;RA&#65289;&#65292;&#22312;&#27599;&#27425;&#36845;&#20195;&#26399;&#38388;&#36890;&#36807;&#21487;&#33021;&#22810;&#27493;&#30340;&#30830;&#23450;&#24615;&#27714;&#35299;&#22120;&#25552;&#39640;&#32479;&#35745;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#65288;SG&#65289;&#26159;&#35299;&#20915;&#20855;&#26377;&#24179;&#28369;&#65288;&#38750;&#20984;&#65289;&#30446;&#26631;&#20989;&#25968;$f$&#21644;&#38543;&#26426;&#19968;&#38454;oracle&#30340;&#38543;&#26426;&#20248;&#21270;&#65288;SO&#65289;&#38382;&#39064;&#30340;&#20107;&#23454;&#19978;&#30340;&#36845;&#20195;&#25216;&#26415;&#12290; &#22312;&#27599;&#27425;&#36845;&#20195;&#26399;&#38388;&#65292;"&#30830;&#23450;&#24615;&#27714;&#35299;&#22120;"&#23545;&#23376;&#37319;&#26679;&#30340;&#30830;&#23450;&#24615;&#38382;&#39064;&#25191;&#34892;&#21487;&#33021;&#22810;&#20010;&#27493;&#39588;&#65292;&#24182;&#22312;&#20174;&#32479;&#35745;&#25928;&#29575;&#30340;&#35282;&#24230;&#35270;&#20026;&#36827;&#19968;&#27493;&#27714;&#35299;&#19981;&#24517;&#35201;&#26102;&#20572;&#27490;&#12290; &#22240;&#27492;&#65292;RA&#31995;&#32479;&#22320;&#23558;&#24341;&#20154;&#27880;&#30446;&#30340;&#20869;&#23481;&#21464;&#24471;&#20005;&#35880;--&#22312;&#27599;&#27425;&#36845;&#20195;&#26399;&#38388;&#65292;&#8220;&#25554;&#20837;&#8221;&#19968;&#20010;&#35299;&#31639;&#22120;&#65292;&#20363;&#22914;&#65292;L-BFGS&#32447;&#25628;&#32034;&#25110;Newton-CG&#65292;&#24182;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2103.04392v3 Announce Type: replace-cross  Abstract: Stochastic Gradient (SG) is the defacto iterative technique to solve stochastic optimization (SO) problems with a smooth (non-convex) objective $f$ and a stochastic first-order oracle. SG's attractiveness is due in part to its simplicity of executing a single step along the negative subsampled gradient direction to update the incumbent iterate. In this paper, we question SG's choice of executing a single step as opposed to multiple steps between subsample updates. Our investigation leads naturally to generalizing SG into Retrospective Approximation (RA) where, during each iteration, a "deterministic solver" executes possibly multiple steps on a subsampled deterministic problem and stops when further solving is deemed unnecessary from the standpoint of statistical efficiency. RA thus rigorizes what is appealing for implementation -- during each iteration, "plug in" a solver, e.g., L-BFGS line search or Newton-CG, as is, and solv
&lt;/p&gt;</description></item><item><title>&#20004;&#31181;&#26041;&#27861;&#22312;&#24102;&#32570;&#22833;&#20540;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#34920;&#29616;&#20986;&#19968;&#33268;&#24615;&#65292;&#24403;&#32570;&#22833;&#20540;&#19981;&#20855;&#20449;&#24687;&#24615;&#26102;&#65292;&#20351;&#29992;&#24120;&#25968;&#36827;&#34892;&#25554;&#34917;&#26159;&#19968;&#31181;&#31616;&#21333;&#19988;&#37325;&#35201;&#30340;&#23454;&#36341;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/1902.06931</link><description>&lt;p&gt;
&#20851;&#20110;&#24102;&#32570;&#22833;&#20540;&#30340;&#30417;&#30563;&#23398;&#20064;&#30340;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the consistency of supervised learning with missing values
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1902.06931
&lt;/p&gt;
&lt;p&gt;
&#20004;&#31181;&#26041;&#27861;&#22312;&#24102;&#32570;&#22833;&#20540;&#30340;&#30417;&#30563;&#23398;&#20064;&#20013;&#34920;&#29616;&#20986;&#19968;&#33268;&#24615;&#65292;&#24403;&#32570;&#22833;&#20540;&#19981;&#20855;&#20449;&#24687;&#24615;&#26102;&#65292;&#20351;&#29992;&#24120;&#25968;&#36827;&#34892;&#25554;&#34917;&#26159;&#19968;&#31181;&#31616;&#21333;&#19988;&#37325;&#35201;&#30340;&#23454;&#36341;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#35774;&#32622;&#20013;&#65292;&#25968;&#25454;&#23384;&#22312;&#32570;&#22833;&#20540;&#65292;&#36825;&#20351;&#24471;&#20998;&#26512;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20016;&#23500;&#30340;&#25991;&#29486;&#28041;&#21450;&#32570;&#22833;&#20540;&#22312;&#25512;&#26029;&#26694;&#26550;&#20013;&#30340;&#22788;&#29702;&#65306;&#20174;&#19981;&#23436;&#25972;&#30340;&#34920;&#20013;&#20272;&#35745;&#21442;&#25968;&#21450;&#20854;&#26041;&#24046;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32771;&#34385;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65306;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20013;&#20986;&#29616;&#32570;&#22833;&#20540;&#26102;&#39044;&#27979;&#30446;&#26631;&#12290;&#25105;&#20204;&#34920;&#26126;&#20102;&#20004;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#20013;&#30340;&#19968;&#33268;&#24615;&#12290;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#32467;&#26524;&#26159;&#65292;&#24403;&#32570;&#22833;&#20540;&#19981;&#20855;&#20449;&#24687;&#24615;&#26102;&#65292;&#20351;&#29992;&#24120;&#25968;&#36827;&#34892;&#25554;&#34917;&#65292;&#20363;&#22914;&#22312;&#23398;&#20064;&#20043;&#21069;&#20351;&#29992;&#22343;&#20540;&#65292;&#26159;&#19968;&#33268;&#30340;&#12290;&#36825;&#19982;&#25512;&#26029;&#35774;&#32622;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#65292;&#25512;&#26029;&#35774;&#32622;&#20013;&#24120;&#29992;&#30340;&#22343;&#20540;&#25554;&#34917;&#26041;&#27861;&#34987;&#25351;&#36131;&#25197;&#26354;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#36825;&#26679;&#19968;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#33021;&#22815;&#20445;&#25345;&#19968;&#33268;&#24615;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36866;&#29992;&#20110;&#23436;&#25972;&#35266;&#27979;&#30340;&#39044;&#27979;&#22120;&#21487;&#20197;&#36890;&#36807;&#22810;&#37325;&#25554;&#34917;&#22312;&#19981;&#23436;&#25972;&#25968;&#25454;&#19978;&#36827;&#34892;&#26368;&#20339;&#39044;&#27979;&#12290;&#26368;&#21518;&#65292;&#20026;&#20102;&#27604;&#36739;&#25554;&#34917;
&lt;/p&gt;
&lt;p&gt;
arXiv:1902.06931v4 Announce Type: replace-cross  Abstract: In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data,through multiple imputation.Finally, to compare imput
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#20123;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;Hoeffding&#20998;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2310.06567</link><description>&lt;p&gt;
&#36890;&#36807;Hoeffding&#20998;&#35299;&#30340;&#25512;&#24191;&#65292;&#29702;&#35299;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Understanding black-box models with dependent inputs through a generalization of Hoeffding's decomposition. (arXiv:2310.06567v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06567
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#37322;&#26377;&#20851;&#20381;&#36182;&#36755;&#20837;&#30340;&#40657;&#31665;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#20123;&#21512;&#29702;&#30340;&#20551;&#35774;&#19979;&#65292;&#38750;&#32447;&#24615;&#20989;&#25968;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#36825;&#20010;&#26694;&#26550;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;Hoeffding&#20998;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#40657;&#31665;&#27169;&#22411;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#33021;&#22815;&#23558;&#38750;&#20114;&#19981;&#30456;&#20851;&#38543;&#26426;&#36755;&#20837;&#30340;&#24179;&#26041;&#21487;&#31215;&#20989;&#25968;&#21807;&#19968;&#20998;&#35299;&#20026;&#27599;&#20010;&#21487;&#33021;&#23376;&#38598;&#30340;&#20989;&#25968;&#20043;&#21644;&#12290;&#28982;&#32780;&#65292;&#22788;&#29702;&#36755;&#20837;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#21487;&#33021;&#24456;&#22797;&#26434;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#19977;&#20010;&#25968;&#23398;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#65306;&#27010;&#29575;&#35770;&#12289;&#20989;&#25968;&#20998;&#26512;&#21644;&#32452;&#21512;&#25968;&#23398;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#36755;&#20837;&#19978;&#30340;&#20004;&#20010;&#21512;&#29702;&#20551;&#35774;&#19979;&#65288;&#38750;&#23436;&#32654;&#30340;&#20989;&#25968;&#20381;&#36182;&#24615;&#21644;&#38750;&#36864;&#21270;&#30340;&#38543;&#26426;&#20381;&#36182;&#24615;&#65289;&#65292;&#24635;&#26159;&#21487;&#20197;&#21807;&#19968;&#20998;&#35299;&#36825;&#26679;&#19968;&#20010;&#20989;&#25968;&#12290;&#36825;&#31181;&#8220;&#35268;&#33539;&#20998;&#35299;&#8221;&#30456;&#23545;&#30452;&#35266;&#65292;&#25581;&#31034;&#20102;&#38750;&#32447;&#24615;&#30456;&#20851;&#36755;&#20837;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#32447;&#24615;&#29305;&#24615;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#26377;&#25928;&#22320;&#25512;&#24191;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;Hoeffding&#20998;&#35299;&#65292;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#12290;&#40657;&#31665;&#27169;&#22411;&#30340;&#26012;&#25237;&#24433;&#20026;&#26032;&#39062;&#30340;&#21487;&#35299;&#37322;&#24615;&#25351;&#26631;&#25552;&#20379;&#20102;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the main challenges for interpreting black-box models is the ability to uniquely decompose square-integrable functions of non-mutually independent random inputs into a sum of functions of every possible subset of variables. However, dealing with dependencies among inputs can be complicated. We propose a novel framework to study this problem, linking three domains of mathematics: probability theory, functional analysis, and combinatorics. We show that, under two reasonable assumptions on the inputs (non-perfect functional dependence and non-degenerate stochastic dependence), it is always possible to decompose uniquely such a function. This ``canonical decomposition'' is relatively intuitive and unveils the linear nature of non-linear functions of non-linearly dependent inputs. In this framework, we effectively generalize the well-known Hoeffding decomposition, which can be seen as a particular case. Oblique projections of the black-box model allow for novel interpretability indic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SFAVEL&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#36716;&#21270;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#23454;&#29616;&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#12290;&#36825;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#65292;&#21516;&#26102;&#20445;&#30041;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.16540</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#30340;&#20107;&#23454;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16540
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SFAVEL&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#36716;&#21270;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#23454;&#29616;&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#12290;&#36825;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#65292;&#21516;&#26102;&#20445;&#30041;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#26088;&#22312;&#36890;&#36807;&#21487;&#38752;&#30693;&#35782;&#24211;&#20013;&#30340;&#35777;&#25454;&#26469;&#39564;&#35777;&#20027;&#24352;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#24418;&#24335;&#30340;&#25968;&#25454;&#27880;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#31639;&#27861;&#24517;&#39035;&#20026;&#27599;&#20010;&#20027;&#24352;&#29983;&#25104;&#26082;&#35821;&#20041;&#26126;&#30830;&#21448;&#32039;&#20945;&#30340;&#29305;&#24449;&#65292;&#20197;&#20415;&#19982;&#28304;&#20449;&#24687;&#36827;&#34892;&#35821;&#20041;&#23545;&#40784;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#21069;&#32773;&#36890;&#36807;&#23398;&#20064;&#21253;&#21547;&#20027;&#24352;&#21450;&#20854;&#30456;&#24212;&#26631;&#31614;&#30340;&#27880;&#37322;&#35821;&#26009;&#24211;&#26469;&#35299;&#20915;&#23545;&#40784;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SFAVEL&#65288;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#30340;&#33258;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#33976;&#39311;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#32780;&#26080;&#38656;&#27880;&#37322;&#12290;&#36825;&#26159;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#30340;&#65292;&#35813;&#20989;&#25968;&#40723;&#21169;&#29305;&#24449;&#22312;&#20445;&#25345;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;&#21644;&#35777;&#25454;&#23545;&#40784;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36798;&#21040;&#26032;&#39062;&#30340;&#29366;&#24577;&#19968;.
&lt;/p&gt;
&lt;p&gt;
Unsupervised fact verification aims to verify a claim using evidence from a trustworthy knowledge base without any kind of data annotation. To address this challenge, algorithms must produce features for every claim that are both semantically meaningful, and compact enough to find a semantic alignment with the source information. In contrast to previous work, which tackled the alignment problem by learning over annotated corpora of claims and their corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via Language Model Distillation), a novel unsupervised framework that leverages pre-trained language models to distil self-supervised features into high-quality claim-fact alignments without the need for annotations. This is enabled by a novel contrastive loss function that encourages features to attain high-quality claim and evidence alignments whilst preserving the semantic relationships across the corpora. Notably, we present results that achieve a new state-of-the
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#32771;&#34385;&#20102;&#22312;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#26102;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#20010;&#36873;&#39033;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#25351;&#26631;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.14785</link><description>&lt;p&gt;
&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#19982;&#27425;&#35201;&#36873;&#39033;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
A correlation-based fuzzy cluster validity index with secondary options detector. (arXiv:2308.14785v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#32771;&#34385;&#20102;&#22312;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#26102;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#20010;&#36873;&#39033;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#25351;&#26631;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#32858;&#31867;&#20998;&#26512;&#26102;&#65292;&#26368;&#20339;&#32858;&#31867;&#25968;&#37327;&#26159;&#20027;&#35201;&#20851;&#27880;&#28857;&#20043;&#19968;&#12290;&#24050;&#32463;&#24341;&#20837;&#20102;&#22810;&#20010;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#26377;&#22810;&#20010;&#36873;&#39033;&#21487;&#20197;&#20316;&#20026;&#26368;&#32456;&#30340;&#32858;&#31867;&#25968;&#37327;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#22312;&#36825;&#20010;&#39046;&#22495;&#24573;&#35270;&#20102;&#36825;&#19968;&#26041;&#38754;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#31216;&#20026;Wiroonsri-Preedasawakul&#65288;WP&#65289;&#25351;&#26631;&#12290;&#35813;&#25351;&#26631;&#26681;&#25454;&#19968;&#23545;&#25968;&#25454;&#28857;&#30340;&#23454;&#38469;&#36317;&#31163;&#19982;&#30456;&#24212;&#23545;&#30340;&#35843;&#25972;&#36136;&#24515;&#20043;&#38388;&#30340;&#36317;&#31163;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26469;&#23450;&#20041;&#12290;&#25105;&#20204;&#35780;&#20272;&#24182;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#25351;&#26631;&#19982;Xie-Beni&#65292;Pakhira-Bandyopadhyay-Maulik&#65292;Tang&#65292;Wu-Li&#65292;&#24191;&#20041;C&#21644;Kwon2&#31561;&#20960;&#20010;&#29616;&#26377;&#25351;&#26631;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65306;&#20154;&#24037;&#25968;&#25454;&#38598;&#65292;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#24102;&#26377;&#31561;&#32423;&#30340;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#20351;&#29992;&#27169;&#31946;c-mea&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The optimal number of clusters is one of the main concerns when applying cluster analysis. Several cluster validity indexes have been introduced to address this problem. However, in some situations, there is more than one option that can be chosen as the final number of clusters. This aspect has been overlooked by most of the existing works in this area. In this study, we introduce a correlation-based fuzzy cluster validity index known as the Wiroonsri-Preedasawakul (WP) index. This index is defined based on the correlation between the actual distance between a pair of data points and the distance between adjusted centroids with respect to that pair. We evaluate and compare the performance of our index with several existing indexes, including Xie-Beni, Pakhira-Bandyopadhyay-Maulik, Tang, Wu-Li, generalized C, and Kwon2. We conduct this evaluation on four types of datasets: artificial datasets, real-world datasets, simulated datasets with ranks, and image datasets, using the fuzzy c-mea
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.11838</link><description>&lt;p&gt;
&#19968;&#20010;&#20851;&#20110;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Benchmark Study on Calibration. (arXiv:2308.11838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11838
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#30340;&#22522;&#20934;&#30740;&#31350;&#65292;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#31354;&#38388;&#25506;&#32034;&#20102;&#27169;&#22411;&#26657;&#20934;&#23646;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#26174;&#31034;&#65292;&#27169;&#22411;&#26657;&#20934;&#21487;&#20197;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65292;&#24182;&#21487;&#20197;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#36825;&#20123;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#65292;&#23427;&#20204;&#24448;&#24448;&#38754;&#20020;&#26657;&#20934;&#38382;&#39064;&#65292;&#23613;&#31649;&#39044;&#27979;&#20934;&#30830;&#24615;&#26377;&#25152;&#25552;&#39640;&#12290;&#35768;&#22810;&#30740;&#31350;&#36890;&#36807;&#25968;&#25454;&#39044;&#22788;&#29702;&#12289;&#20351;&#29992;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#21644;&#35757;&#32451;&#26694;&#26550;&#26469;&#25913;&#21892;&#26657;&#20934;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23545;&#26657;&#20934;&#23646;&#24615;&#30340;&#30740;&#31350;&#26377;&#28857;&#34987;&#24573;&#35270;&#20102;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#65288;NAS&#65289;&#25628;&#32034;&#31354;&#38388;&#65292;&#22312;&#20840;&#38754;&#25506;&#32034;&#26657;&#20934;&#23646;&#24615;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#19968;&#20010;&#35814;&#23613;&#30340;&#27169;&#22411;&#26550;&#26500;&#31354;&#38388;&#12290;&#25105;&#20204;&#29305;&#21035;&#21019;&#24314;&#20102;&#19968;&#20010;&#27169;&#22411;&#26657;&#20934;&#25968;&#25454;&#38598;&#12290;&#35813;&#25968;&#25454;&#38598;&#22312;&#24191;&#27867;&#20351;&#29992;&#30340;NATS-Bench&#25628;&#32034;&#31354;&#38388;&#20013;&#35780;&#20272;&#20102;90&#20010;&#22522;&#20110;&#21306;&#38388;&#30340;&#26657;&#20934;&#24230;&#37327;&#21644;12&#20010;&#20854;&#20182;&#26657;&#20934;&#24230;&#37327;&#65292;&#28085;&#30422;&#20102;117,702&#20010;&#29420;&#29305;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26088;&#22312;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#25968;&#25454;&#38598;&#22238;&#31572;&#35813;&#39046;&#22495;&#19968;&#20123;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#65288;i&#65289;&#27169;&#22411;&#26657;&#20934;&#33021;&#21542;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#27867;&#21270;&#65311;&#65288;ii&#65289;&#33021;&#21542;&#21516;&#26102;&#20860;&#39038;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26657;&#20934;&#24615;&#33021;&#65311;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks are increasingly utilized in various machine learning tasks. However, as these models grow in complexity, they often face calibration issues, despite enhanced prediction accuracy. Many studies have endeavored to improve calibration performance through data preprocessing, the use of specific loss functions, and training frameworks. Yet, investigations into calibration properties have been somewhat overlooked. Our study leverages the Neural Architecture Search (NAS) search space, offering an exhaustive model architecture space for thorough calibration properties exploration. We specifically create a model calibration dataset. This dataset evaluates 90 bin-based and 12 additional calibration measurements across 117,702 unique neural networks within the widely employed NATS-Bench search space. Our analysis aims to answer several longstanding questions in the field, using our proposed dataset: (i) Can model calibration be generalized across different tasks? (ii) Can rob
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#35774;&#35745;&#20102;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#31181;&#20027;&#27969;&#37319;&#26679;&#22120;&#30340;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#39640;&#20102;&#24635;&#27493;&#25968;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.09251</link><description>&lt;p&gt;
&#38754;&#21521;&#25193;&#25955;&#24335;&#29983;&#25104;&#27169;&#22411;&#30340;&#38750;&#28176;&#36827;&#24555;&#36895;&#25910;&#25947;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative Models. (arXiv:2306.09251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#35774;&#35745;&#20102;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#31181;&#20027;&#27969;&#37319;&#26679;&#22120;&#30340;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#39640;&#20102;&#24635;&#27493;&#25968;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#21453;&#36716;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#36807;&#31243;&#23558;&#22122;&#38899;&#36716;&#21270;&#20026;&#26032;&#25968;&#25454;&#23454;&#20363;&#65292;&#22312;&#24403;&#20195;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#20013;&#24050;&#25104;&#20026;&#22522;&#30707;&#12290;&#34429;&#28982;&#23427;&#20204;&#30340;&#23454;&#29992;&#24615;&#29616;&#22312;&#24050;&#34987;&#24191;&#27867;&#35748;&#21487;&#65292;&#20294;&#20854;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#19981;&#22815;&#25104;&#29087;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#20197;&#29702;&#35299;&#31163;&#25955;&#26102;&#38388;&#19979;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#65288;Stein&#65289;&#24471;&#20998;&#20989;&#25968;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#38024;&#23545;&#19968;&#31181;&#27969;&#34892;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#22120;&#65288;&#22522;&#20110;&#27010;&#29575;&#27969;ODE&#65289;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982; $T$&#65288;&#24635;&#27493;&#25968;&#65289;&#25104;&#27604;&#20363;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25913;&#36827;&#20102;&#36807;&#21435;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#21478;&#19968;&#31181;&#20027;&#27969;&#30340;&#38543;&#26426;&#37319;&#26679;&#22120;&#65288;&#21363;&#19968;&#31181;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#65289;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#20010;&#19982; $1/\sqrt{T}$ &#25104;&#27604;&#20363;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#29702;&#35770;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23545;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#21482;&#20316;&#20986;&#26368;&#23567;&#30340;&#20551;&#35774;&#65288;&#20363;&#22914;&#65292;&#27809;&#26377;&#24179;&#28369;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models, which convert noise into new data instances by learning to reverse a Markov diffusion process, have become a cornerstone in contemporary generative modeling. While their practical power has now been widely recognized, the theoretical underpinnings remain far from mature. In this work, we develop a suite of non-asymptotic theory towards understanding the data generation process of diffusion models in discrete time, assuming access to reliable estimates of the (Stein) score functions. For a popular deterministic sampler (based on the probability flow ODE), we establish a convergence rate proportional to $1/T$ (with $T$ the total number of steps), improving upon past results; for another mainstream stochastic sampler (i.e., a type of the denoising diffusion probabilistic model (DDPM)), we derive a convergence rate proportional to $1/\sqrt{T}$, matching the state-of-the-art theory. Our theory imposes only minimal assumptions on the target data distribution (e.g., no smoot
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24403;&#22870;&#21169;&#21576;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#23454;&#20363;&#30456;&#20851;&#31639;&#27861;&#65292;&#24182;&#24471;&#21040;&#20102;&#26497;&#23567;&#26368;&#22823;&#21270;&#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.06836</link><description>&lt;p&gt;
&#29992;&#20989;&#25968;&#36924;&#36817;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#20013;&#37325;&#23614;&#22870;&#21169;&#38382;&#39064;&#30340;&#26497;&#23567;&#26368;&#22823;&#21270;&#31639;&#27861;&#21644;&#23454;&#20363;&#30456;&#20851;&#36951;&#25022;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
Tackling Heavy-Tailed Rewards in Reinforcement Learning with Function Approximation: Minimax Optimal and Instance-Dependent Regret Bounds. (arXiv:2306.06836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24403;&#22870;&#21169;&#21576;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#23454;&#20363;&#30456;&#20851;&#31639;&#27861;&#65292;&#24182;&#24471;&#21040;&#20102;&#26497;&#23567;&#26368;&#22823;&#21270;&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26377;&#35768;&#22810;&#24037;&#20316;&#37117;&#19987;&#27880;&#20110;&#20026;&#26377;&#30028;&#22870;&#21169;&#30340;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#26377;&#25928;&#31639;&#27861;&#65292;&#20294;&#24403;&#22870;&#21169;&#21576;&#29616;&#8220;&#37325;&#23614;&#8221;&#20998;&#24067;&#26102;&#8212;&#8212;&#21363;&#23384;&#22312;&#26576;&#20010; $\epsilon\in(0,1]$ &#20351;&#24471;&#20165;&#26377;&#26377;&#38480;&#30340;$(1+\epsilon)$-&#38454;&#30697;&#8212;&#8212;&#26159;&#21542;&#23384;&#22312;&#23545;&#22823;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#36827;&#34892;&#37319;&#26679;&#25110;&#26102;&#25928;&#24615;&#31639;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340; RL &#20013;&#30340;&#36825;&#31181;&#22870;&#21169;&#26426;&#21046;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#37325;&#23614;&#32447;&#24615;&#36172;&#33218;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#8212;&#8212;\textsc{Heavy-OFUL}&#65292;&#20854;&#23454;&#29616;&#20102;&#19968;&#31181;&#23454;&#20363;&#30456;&#20851;&#30340; $T$-round &#36951;&#25022;&#24230;&#37327;&#65292;&#20026; $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$&#65292;&#36825;&#26159;&#36825;&#31181;&#31867;&#22411;&#30340;\emph{&#31532;&#19968;&#31687;}&#25991;&#31456;&#12290;$\nu_t^{1+\epsilon}$&#26159;&#31532; $t$ &#36718;&#22870;&#21169;&#30340; $(1+\epsilon)$-&#38454;&#20013;&#24515;&#30697;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#22312;&#24212;&#29992;&#20110; st &#30340;&#26368;&#22351;&#24773;&#20917;&#26102;&#65292;&#19978;&#36848;&#30028;&#26159;&#26497;&#23567;&#20540;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
While numerous works have focused on devising efficient algorithms for reinforcement learning (RL) with uniformly bounded rewards, it remains an open question whether sample or time-efficient algorithms for RL with large state-action space exist when the rewards are \emph{heavy-tailed}, i.e., with only finite $(1+\epsilon)$-th moments for some $\epsilon\in(0,1]$. In this work, we address the challenge of such rewards in RL with linear function approximation. We first design an algorithm, \textsc{Heavy-OFUL}, for heavy-tailed linear bandits, achieving an \emph{instance-dependent} $T$-round regret of $\tilde{O}\big(d T^{\frac{1-\epsilon}{2(1+\epsilon)}} \sqrt{\sum_{t=1}^T \nu_t^2} + d T^{\frac{1-\epsilon}{2(1+\epsilon)}}\big)$, the \emph{first} of this kind. Here, $d$ is the feature dimension, and $\nu_t^{1+\epsilon}$ is the $(1+\epsilon)$-th central moment of the reward at the $t$-th round. We further show the above bound is minimax optimal when applied to the worst-case instances in st
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21019;&#24314;&#32422;&#26463;&#22495;&#30340;&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#22522;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#35825;&#23548;&#30340;&#23545;&#25968;&#38556;&#30861;&#24230;&#37327;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#12290;&#36825;&#20123;&#26041;&#27861;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#24212;&#29992;&#33539;&#22260;&#25193;&#23637;&#21040;&#20102;&#26426;&#22120;&#20154;&#21644;&#34507;&#30333;&#35774;&#35745;&#31561;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2304.05364</link><description>&lt;p&gt;
&#32422;&#26463;&#22495;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Models for Constrained Domains. (arXiv:2304.05364v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21019;&#24314;&#32422;&#26463;&#22495;&#30340;&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#22522;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#35825;&#23548;&#30340;&#23545;&#25968;&#38556;&#30861;&#24230;&#37327;&#65292;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#12290;&#36825;&#20123;&#26041;&#27861;&#23558;&#25193;&#25955;&#27169;&#22411;&#30340;&#24212;&#29992;&#33539;&#22260;&#25193;&#23637;&#21040;&#20102;&#26426;&#22120;&#20154;&#21644;&#34507;&#30333;&#35774;&#35745;&#31561;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#26159;&#26032;&#36817;&#28044;&#29616;&#30340;&#19968;&#31181;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#22312;&#26080;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#35821;&#38899;&#29983;&#25104;&#31561;&#20247;&#22810;&#39046;&#22495;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#25104;&#26524;&#12290;&#23427;&#20204;&#30001;&#30772;&#22351;&#25968;&#25454;&#30340;&#21152;&#22122;&#36807;&#31243;&#21644;&#23450;&#20041;&#20026;&#21152;&#22122;&#25193;&#25955;&#30340;&#26102;&#38388;&#21453;&#28436;&#30340;&#21518;&#21521;&#38454;&#27573;&#32452;&#25104;&#12290;&#20197;&#36825;&#20123;&#25104;&#21151;&#20026;&#22522;&#30784;&#65292;&#25193;&#25955;&#27169;&#22411;&#26368;&#36817;&#25193;&#23637;&#21040;&#20102;&#40654;&#26364;&#27969;&#24418;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#40654;&#26364;&#25193;&#25955;&#27169;&#22411;&#35201;&#27714;&#22312;&#25152;&#26377;&#26102;&#38388;&#19978;&#23450;&#20041;&#27979;&#22320;&#32447;&#12290;&#34429;&#28982;&#35813;&#35774;&#32622;&#21253;&#25324;&#35768;&#22810;&#37325;&#35201;&#24212;&#29992;&#65292;&#20294;&#19981;&#21253;&#25324;&#30001;&#19981;&#31561;&#24335;&#32422;&#26463;&#38598;&#23450;&#20041;&#30340;&#27969;&#24418;&#65292;&#36825;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#65292;&#22914;&#26426;&#22120;&#20154;&#21644;&#34507;&#30333;&#35774;&#35745;&#20013;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#24357;&#21512;&#36825;&#20010;&#24046;&#36317;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22522;&#20110;&#19981;&#31561;&#24335;&#32422;&#26463;&#35825;&#23548;&#30340;&#23545;&#25968;&#38556;&#30861;&#24230;&#37327;&#30340;&#21152;&#22122;&#36807;&#31243;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;&#23556;&#24067;&#26391;&#36816;&#21160;&#30340;&#21152;&#22122;&#36807;&#31243;&#12290;&#30001;&#20110;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#19981;&#33021;&#30452;&#25509;&#24212;&#29992;&#20110;&#32422;&#26463;&#22495;&#65292;&#22240;&#27492;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#21019;&#24314;&#32422;&#26463;&#22495;&#30340;&#38477;&#22122;&#25193;&#25955;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a recent class of generative models which achieve state-of-the-art results in many domains such as unconditional image generation and text-to-speech tasks. They consist of a noising process destroying the data and a backward stage defined as the time-reversal of the noising diffusion. Building on their success, diffusion models have recently been extended to the Riemannian manifold setting. Yet, these Riemannian diffusion models require geodesics to be defined for all times. While this setting encompasses many important applications, it does not include manifolds defined via a set of inequality constraints, which are ubiquitous in many scientific domains such as robotics and protein design. In this work, we introduce two methods to bridge this gap. First, we design a noising process based on the logarithmic barrier metric induced by the inequality constraints. Second, we introduce a noising process based on the reflected Brownian motion. As existing diffu
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2211.14960</link><description>&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#30340;&#26631;&#31614;&#23545;&#40784;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Label Alignment Regularization for Distribution Shift. (arXiv:2211.14960v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14960
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#26469;&#23454;&#29616;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#36825;&#20010;&#26041;&#27861;&#36890;&#36807;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#65292;&#32780;&#19981;&#26159;&#27491;&#21017;&#21270;&#34920;&#31034;&#12290;&#36890;&#36807;&#28040;&#38500;&#23545;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#35813;&#26041;&#27861;&#23637;&#31034;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#26631;&#31614;&#23545;&#40784;&#23646;&#24615;&#65288;LAP&#65289;&#65292;&#21363;&#25968;&#25454;&#38598;&#20013;&#25152;&#26377;&#26631;&#31614;&#30340;&#21521;&#37327;&#22823;&#37096;&#20998;&#22312;&#25968;&#25454;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#12290;&#21463;&#21040;&#36825;&#19968;&#35266;&#23519;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#40723;&#21169;&#30446;&#26631;&#22495;&#20013;&#30340;&#39044;&#27979;&#19982;&#20854;&#21069;&#20960;&#20010;&#22855;&#24322;&#21521;&#37327;&#23545;&#40784;&#12290;&#19982;&#20256;&#32479;&#30340;&#39046;&#22495;&#36866;&#24212;&#26041;&#27861;&#19987;&#27880;&#20110;&#27491;&#21017;&#21270;&#34920;&#31034;&#19981;&#21516;&#65292;&#25105;&#20204;&#30456;&#21453;&#65292;&#36890;&#36807;&#22312;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#20013;&#20351;&#29992;LAP&#65292;&#29992;&#27491;&#21017;&#21270;&#20998;&#31867;&#22120;&#19982;&#26080;&#30417;&#30563;&#30446;&#26631;&#25968;&#25454;&#23545;&#40784;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#19968;&#23450;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#20301;&#20110;&#30446;&#26631;&#22495;&#25968;&#25454;&#30340;&#21069;&#20960;&#20010;&#21491;&#22855;&#24322;&#21521;&#37327;&#30340;&#24352;&#25104;&#31354;&#38388;&#20869;&#65292;&#24182;&#19982;&#26368;&#20248;&#35299;&#23545;&#40784;&#12290;&#36890;&#36807;&#28040;&#38500;&#32463;&#20856;&#39046;&#22495;&#36866;&#24212;&#29702;&#35770;&#20013;&#24120;&#35265;&#30340;&#26368;&#20248;&#32852;&#21512;&#39118;&#38505;&#20551;&#35774;&#30340;&#20381;&#36182;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has highlighted the label alignment property (LAP) in supervised learning, where the vector of all labels in the dataset is mostly in the span of the top few singular vectors of the data matrix. Drawing inspiration from this observation, we propose a regularization method for unsupervised domain adaptation that encourages alignment between the predictions in the target domain and its top singular vectors. Unlike conventional domain adaptation approaches that focus on regularizing representations, we instead regularize the classifier to align with the unsupervised target data, guided by the LAP in both the source and target domains. Theoretical analysis demonstrates that, under certain assumptions, our solution resides within the span of the top right singular vectors of the target domain data and aligns with the optimal solution. By removing the reliance on the commonly used optimal joint risk assumption found in classic domain adaptation theory, we showcase the effectivene
&lt;/p&gt;</description></item></channel></rss>