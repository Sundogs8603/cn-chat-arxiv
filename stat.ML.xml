<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#20984;&#38598;&#30340;&#27010;&#29575;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65292;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#20449;&#20219;&#38598;&#65292;&#24182;&#25512;&#23548;&#20986;bounds&#12290;</title><link>https://rss.arxiv.org/abs/2402.00957</link><description>&lt;p&gt;
&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Credal Learning Theory
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#20984;&#38598;&#30340;&#27010;&#29575;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65292;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#20449;&#20219;&#38598;&#65292;&#24182;&#25512;&#23548;&#20986;bounds&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#22522;&#30784;&#65292;&#20026;&#20174;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#20013;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#30340;&#39118;&#38505;&#25552;&#20379;&#29702;&#35770;&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#37096;&#32626;&#20013;&#65292;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#20250;&#21464;&#21270;&#65292;&#23548;&#33268;&#39046;&#22495;&#36866;&#24212;/&#27867;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#8220;&#20449;&#20219;&#8221;&#23398;&#20064;&#29702;&#35770;&#30340;&#22522;&#30784;&#65292;&#20351;&#29992;&#27010;&#29575;&#30340;&#20984;&#38598;&#65288;&#20449;&#20219;&#38598;&#65289;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#26679;&#30340;&#20449;&#20219;&#38598;&#21487;&#20197;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#26469;&#12290;&#23545;&#20110;&#26377;&#38480;&#20551;&#35774;&#31354;&#38388;&#65288;&#26080;&#35770;&#26159;&#21542;&#21487;&#23454;&#29616;&#65289;&#21644;&#26080;&#38480;&#27169;&#22411;&#31354;&#38388;&#65292;&#25512;&#23548;&#20986;&#30028;&#38480;&#65292;&#36825;&#30452;&#25509;&#25512;&#24191;&#20102;&#32463;&#20856;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#31454;&#20105;&#20998;&#26512;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35843;&#25972;FTRL&#23398;&#20064;&#29575;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#24120;&#25968;&#22240;&#23376;&#20869;&#36798;&#21040;&#26368;&#20339;&#31454;&#20105;&#27604;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#24403;&#24809;&#32602;&#39033;&#20855;&#26377;&#36817;&#20284;&#21333;&#35843;&#24615;&#26102;&#30340;&#31454;&#20105;&#27604;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00715</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#30340;FTRL&#31639;&#27861;&#30340;&#31454;&#20105;&#27604;&#20998;&#26512;&#21644;&#26368;&#20339;&#26041;&#26696;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adaptive Learning Rate for Follow-the-Regularized-Leader: Competitive Ratio Analysis and Best-of-Both-Worlds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00715
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#31454;&#20105;&#20998;&#26512;&#26694;&#26550;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35843;&#25972;FTRL&#23398;&#20064;&#29575;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#24120;&#25968;&#22240;&#23376;&#20869;&#36798;&#21040;&#26368;&#20339;&#31454;&#20105;&#27604;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#24403;&#24809;&#32602;&#39033;&#20855;&#26377;&#36817;&#20284;&#21333;&#35843;&#24615;&#26102;&#30340;&#31454;&#20105;&#27604;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Follow-The-Regularized-Leader (FTRL)&#34987;&#35748;&#20026;&#26159;&#22312;&#32447;&#23398;&#20064;&#20013;&#19968;&#31181;&#26377;&#25928;&#19988;&#22810;&#21151;&#33021;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#23398;&#20064;&#29575;&#30340;&#24688;&#24403;&#36873;&#25321;&#23545;&#20110;&#20943;&#23567;&#21518;&#24724;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#35843;&#25972;FTRL&#23398;&#20064;&#29575;&#30340;&#38382;&#39064;&#26500;&#24314;&#20026;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#31454;&#20105;&#20998;&#26512;&#26694;&#26550;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#31454;&#20105;&#27604;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#23398;&#20064;&#29575;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20351;&#20854;&#22312;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#20869;&#36798;&#21040;&#19979;&#30028;&#30340;&#19978;&#30028;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35828;&#26126;&#20102;&#26368;&#20248;&#31454;&#20105;&#27604;&#26159;&#30001;&#24809;&#32602;&#39033;&#30340;&#32452;&#25104;&#37096;&#20998;&#30340;&#65288;&#36817;&#20284;&#65289;&#21333;&#35843;&#24615;&#25152;&#20915;&#23450;&#30340;&#65292;&#34920;&#26126;&#22914;&#26524;&#24809;&#32602;&#39033;&#30340;&#32452;&#25104;&#37096;&#20998;&#24418;&#25104;&#21333;&#35843;&#38750;&#22686;&#24207;&#21015;&#65292;&#21017;&#21487;&#20197;&#23454;&#29616;&#24120;&#25968;&#31454;&#20105;&#27604;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#22312;&#24809;&#32602;&#39033;$\xi$&#36817;&#20284;&#21333;&#35843;&#38750;&#22686;&#26102;&#30340;&#32039;&#23494;&#31454;&#20105;&#27604;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26356;&#26032;&#35268;&#21017;&#34987;&#31216;&#20026;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00715v1 Announce Type: new  Abstract: Follow-The-Regularized-Leader (FTRL) is known as an effective and versatile approach in online learning, where appropriate choice of the learning rate is crucial for smaller regret. To this end, we formulate the problem of adjusting FTRL's learning rate as a sequential decision-making problem and introduce the framework of competitive analysis. We establish a lower bound for the competitive ratio and propose update rules for learning rate that achieves an upper bound within a constant factor of this lower bound. Specifically, we illustrate that the optimal competitive ratio is characterized by the (approximate) monotonicity of components of the penalty term, showing that a constant competitive ratio is achievable if the components of the penalty term form a monotonically non-increasing sequence, and derive a tight competitive ratio when penalty terms are $\xi$-approximately monotone non-increasing. Our proposed update rule, referred to a
&lt;/p&gt;</description></item><item><title>&#19987;&#23478;&#20915;&#31574;&#32773;&#30340;&#34892;&#21160;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#20854;&#39046;&#22495;&#30693;&#35782;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#20197;&#24110;&#21161;&#22312;&#21516;&#19968;&#39046;&#22495;&#20869;&#36827;&#34892;&#25512;&#26029;&#65292;&#20174;&#32780;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#21033;&#29992;&#19987;&#19994;&#30693;&#35782;&#20316;&#20026;&#24402;&#32435;&#20559;&#24046;&#21487;&#33021;&#26159;&#26377;&#30410;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.00694</link><description>&lt;p&gt;
&#23450;&#20041;&#19987;&#19994;&#30693;&#35782;&#65306;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Defining Expertise: Applications to Treatment Effect Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00694
&lt;/p&gt;
&lt;p&gt;
&#19987;&#23478;&#20915;&#31574;&#32773;&#30340;&#34892;&#21160;&#33258;&#28982;&#22320;&#32534;&#30721;&#20102;&#20854;&#39046;&#22495;&#30693;&#35782;&#30340;&#19968;&#37096;&#20998;&#65292;&#21487;&#20197;&#24110;&#21161;&#22312;&#21516;&#19968;&#39046;&#22495;&#20869;&#36827;&#34892;&#25512;&#26029;&#65292;&#20174;&#32780;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#21033;&#29992;&#19987;&#19994;&#30693;&#35782;&#20316;&#20026;&#24402;&#32435;&#20559;&#24046;&#21487;&#33021;&#26159;&#26377;&#30410;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#36890;&#24120;&#26159;&#20854;&#39046;&#22495;&#30340;&#19987;&#23478;&#65292;&#24182;&#22522;&#20110;&#20854;&#39046;&#22495;&#30693;&#35782;&#37319;&#21462;&#34892;&#21160;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#39046;&#22495;&#20013;&#19987;&#19994;&#30693;&#35782;&#30340;&#37325;&#35201;&#24615;&#65292;&#20197;&#21450;&#21033;&#29992;&#19987;&#19994;&#30693;&#35782;&#20316;&#20026;&#24402;&#32435;&#20559;&#24046;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00694v1 Announce Type: cross  Abstract: Decision-makers are often experts of their domain and take actions based on their domain knowledge. Doctors, for instance, may prescribe treatments by predicting the likely outcome of each available treatment. Actions of an expert thus naturally encode part of their domain knowledge, and can help make inferences within the same domain: Knowing doctors try to prescribe the best treatment for their patients, we can tell treatments prescribed more frequently are likely to be more effective. Yet in machine learning, the fact that most decision-makers are experts is often overlooked, and "expertise" is seldom leveraged as an inductive bias. This is especially true for the literature on treatment effect estimation, where often the only assumption made about actions is that of overlap. In this paper, we argue that expertise - particularly the type of expertise the decision-makers of a domain are likely to have - can be informative in designin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00680</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Scalable Learning of Item Response Theory Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00680
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;IRT&#65289;&#27169;&#22411;&#26088;&#22312;&#35780;&#20272; $n$ &#21517;&#32771;&#29983;&#30340;&#28508;&#22312;&#33021;&#21147;&#20197;&#21450; $m$ &#20010;&#27979;&#39564;&#39033;&#30446;&#30340;&#38544;&#21547;&#38590;&#24230;&#29305;&#24449;&#65292;&#36825;&#20123;&#39033;&#30446;&#26159;&#20174;&#34920;&#26126;&#20854;&#23545;&#24212;&#31572;&#26696;&#36136;&#37327;&#30340;&#20998;&#31867;&#25968;&#25454;&#20013;&#24471;&#20986;&#30340;&#12290;&#20256;&#32479;&#30340;&#24515;&#29702;&#27979;&#37327;&#35780;&#20272;&#22522;&#20110;&#30456;&#23545;&#36739;&#23569;&#30340;&#32771;&#29983;&#21644;&#39033;&#30446;&#65292;&#20363;&#22914;&#19968;&#20010;&#30001; $200$ &#21517;&#23398;&#29983;&#35299;&#20915;&#21253;&#21547; $10$ &#36947;&#39064;&#30446;&#30340;&#32771;&#35797;&#30340;&#29677;&#32423;&#12290;&#32780;&#36817;&#24180;&#26469;&#30340;&#20840;&#29699;&#22823;&#35268;&#27169;&#35780;&#20272;&#65292;&#22914;PISA&#65292;&#25110;&#20114;&#32852;&#32593;&#30740;&#31350;&#65292;&#21487;&#33021;&#23548;&#33268;&#21442;&#19982;&#32773;&#25968;&#37327;&#26174;&#33879;&#22686;&#21152;&#12290;&#27492;&#22806;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#65292;&#31639;&#27861;&#25198;&#28436;&#32771;&#29983;&#35282;&#33394;&#65292;&#25968;&#25454;&#20998;&#26512;&#38382;&#39064;&#25198;&#28436;&#39033;&#30446;&#35282;&#33394;&#65292;$n$ &#21644; $m$ &#37117;&#21487;&#33021;&#21464;&#24471;&#38750;&#24120;&#22823;&#65292;&#25361;&#25112;&#35745;&#31639;&#30340;&#25928;&#29575;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;&#20026;&#20102;&#20174;&#22823;&#25968;&#25454;&#20013;&#23398;&#20064;IRT&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#27169;&#22411;&#19982;&#36923;&#36753;&#22238;&#24402;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#21518;&#32773;&#21487;&#20197;&#20351;&#29992;s&#20934;&#30830;&#22320;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00680v1 Announce Type: new  Abstract: Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using s
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00666</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharp bounds for the max-sliced Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00666
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#22312;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20174;$n$&#20010;&#26679;&#26412;&#20013;&#33719;&#24471;&#30340;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#26399;&#26395;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;Banach&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00666v1 Announce Type: cross  Abstract: We obtain sharp upper and lower bounds for the expected max-sliced 1-Wasserstein distance between a probability measure on a separable Hilbert space and its empirical distribution from $n$ samples. A version of this result for probability measures on Banach spaces is also obtained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38388;&#25509;&#21442;&#25968;&#21270;CAEs&#65288;IP-CAEs&#65289;&#26469;&#35299;&#20915;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;&#65288;CAEs&#65289;&#22312;&#31283;&#23450;&#32852;&#21512;&#20248;&#21270;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;IP-CAEs&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#19988;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2403.00563</link><description>&lt;p&gt;
&#38388;&#25509;&#21442;&#25968;&#21270;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Indirectly Parameterized Concrete Autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38388;&#25509;&#21442;&#25968;&#21270;CAEs&#65288;IP-CAEs&#65289;&#26469;&#35299;&#20915;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;&#65288;CAEs&#65289;&#22312;&#31283;&#23450;&#32852;&#21512;&#20248;&#21270;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;IP-CAEs&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26174;&#33879;&#19988;&#19968;&#33268;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#22312;&#25968;&#25454;&#39640;&#32500;&#25110;&#33719;&#21462;&#23436;&#25972;&#29305;&#24449;&#38598;&#25104;&#26412;&#39640;&#26114;&#30340;&#24773;&#20917;&#19979;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#23884;&#20837;&#24335;&#29305;&#24449;&#36873;&#25321;&#30340;&#21457;&#23637;&#22312;&#24191;&#27867;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#20855;&#20307;&#33258;&#32534;&#30721;&#22120;&#65288;CAEs&#65289;&#34987;&#35748;&#20026;&#26159;&#23884;&#20837;&#24335;&#29305;&#24449;&#36873;&#25321;&#20013;&#30340;&#26368;&#20808;&#36827;&#25216;&#26415;&#65292;&#20294;&#21487;&#33021;&#38590;&#20197;&#23454;&#29616;&#31283;&#23450;&#30340;&#32852;&#21512;&#20248;&#21270;&#65292;&#20174;&#32780;&#24433;&#21709;&#20854;&#35757;&#32451;&#26102;&#38388;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#21457;&#29616;&#36825;&#31181;&#19981;&#31283;&#23450;&#24615;&#19982;CAE&#23398;&#20064;&#37325;&#22797;&#36873;&#25321;&#26377;&#20851;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26377;&#25928;&#30340;&#25913;&#36827;&#65306;&#38388;&#25509;&#21442;&#25968;&#21270;CAEs&#65288;IP-CAEs&#65289;&#12290;IP-CAEs&#23398;&#20064;&#19968;&#20010;&#23884;&#20837;&#21644;&#20174;&#23427;&#21040;Gumbel-Softmax&#20998;&#24067;&#21442;&#25968;&#30340;&#26144;&#23556;&#12290;&#23613;&#31649;&#23454;&#29616;&#31616;&#21333;&#65292;IP-CAE&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#37325;&#26500;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#22343;&#34920;&#29616;&#20986;&#26174;&#33879;&#19988;&#19968;&#33268;&#30340;&#25913;&#36827;&#65292;&#26080;&#35770;&#26159;&#22312;&#27867;&#21270;&#36824;&#26159;&#35757;&#32451;&#26102;&#38388;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00563v1 Announce Type: new  Abstract: Feature selection is a crucial task in settings where data is high-dimensional or acquiring the full set of features is costly. Recent developments in neural network-based embedded feature selection show promising results across a wide range of applications. Concrete Autoencoders (CAEs), considered state-of-the-art in embedded feature selection, may struggle to achieve stable joint optimization, hurting their training time and generalization. In this work, we identify that this instability is correlated with the CAE learning duplicate selections. To remedy this, we propose a simple and effective improvement: Indirectly Parameterized CAEs (IP-CAEs). IP-CAEs learn an embedding and a mapping from it to the Gumbel-Softmax distributions' parameters. Despite being simple to implement, IP-CAE exhibits significant and consistent improvements over CAE in both generalization and training time across several datasets for reconstruction and classifi
&lt;/p&gt;</description></item><item><title>&#23558;$\varepsilon$-greedy&#31574;&#30053;&#24341;&#20837;Thompson&#37319;&#26679;&#20197;&#25913;&#36827;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#24320;&#21457;&#21151;&#33021;&#65292;&#24182;&#23454;&#35777;&#34920;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.00540</link><description>&lt;p&gt;
Epsilon-Greedy Thompson Sampling&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Epsilon-Greedy Thompson Sampling to Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00540
&lt;/p&gt;
&lt;p&gt;
&#23558;$\varepsilon$-greedy&#31574;&#30053;&#24341;&#20837;Thompson&#37319;&#26679;&#20197;&#25913;&#36827;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#24320;&#21457;&#21151;&#33021;&#65292;&#24182;&#23454;&#35777;&#34920;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Thompson&#37319;&#26679;&#65288;TS&#65289;&#34987;&#35748;&#20026;&#26159;&#35299;&#20915;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24320;&#21457;-&#25506;&#32034;&#22256;&#22659;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290; &#34429;&#28982;&#23427;&#36890;&#36807;&#38543;&#26426;&#29983;&#25104;&#21644;&#26368;&#22823;&#21270;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#21518;&#39564;&#30340;&#26679;&#26412;&#36335;&#24452;&#26469;&#20248;&#20808;&#36827;&#34892;&#25506;&#32034;&#65292;&#20294;TS&#22312;&#27599;&#27425;&#25191;&#34892;&#25506;&#32034;&#21518;&#36890;&#36807;&#25910;&#38598;&#20851;&#20110;&#30495;&#23454;&#30446;&#26631;&#20989;&#25968;&#30340;&#20449;&#24687;&#26469;&#24369;&#21270;&#20854;&#24320;&#21457;&#21151;&#33021;&#12290; &#26412;&#30740;&#31350;&#23558;&#22312;TS&#20013;&#24341;&#20837;$\varepsilon$-greedy&#31574;&#30053;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#30340;&#36873;&#25321;&#31574;&#30053;&#65292;&#20197;&#25913;&#36827;&#20854;&#24320;&#21457;&#21151;&#33021;&#12290; &#25105;&#20204;&#39318;&#20808;&#25551;&#36848;&#20102;TS&#24212;&#29992;&#20110;BO&#30340;&#20004;&#20010;&#26497;&#31471;&#65292;&#21363;&#36890;&#29992;TS&#21644;&#26679;&#26412;&#24179;&#22343;TS&#12290;&#21069;&#32773;&#21644;&#21518;&#32773;&#20998;&#21035;&#25552;&#20513;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290; &#28982;&#21518;&#25105;&#20204;&#20351;&#29992;$\varepsilon$-greedy&#31574;&#30053;&#22312;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#38543;&#26426;&#20999;&#25442;&#12290; $\varepsilon \in (0,1)$&#30340;&#23567;&#20540;&#20248;&#20808;&#32771;&#34385;&#24320;&#21457;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290; &#25105;&#20204;&#23454;&#35777;&#34920;&#26126;$\varepsilon$-greedy T
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00540v1 Announce Type: new  Abstract: Thompson sampling (TS) serves as a solution for addressing the exploitation-exploration dilemma in Bayesian optimization (BO). While it prioritizes exploration by randomly generating and maximizing sample paths of Gaussian process (GP) posteriors, TS weakly manages its exploitation by gathering information about the true objective function after each exploration is performed. In this study, we incorporate the epsilon-greedy ($\varepsilon$-greedy) policy, a well-established selection strategy in reinforcement learning, into TS to improve its exploitation. We first delineate two extremes of TS applied for BO, namely the generic TS and a sample-average TS. The former and latter promote exploration and exploitation, respectively. We then use $\varepsilon$-greedy policy to randomly switch between the two extremes. A small value of $\varepsilon \in (0,1)$ prioritizes exploitation, and vice versa. We empirically show that $\varepsilon$-greedy T
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ML-UQ&#26657;&#20934;&#32479;&#35745;&#37327;&#30340;&#20351;&#29992;&#38382;&#39064;&#65292;&#21457;&#29616;&#19968;&#20123;&#32479;&#35745;&#37327;&#23545;&#20110;&#29983;&#25104;&#20998;&#24067;&#30340;&#36873;&#25321;&#36807;&#20110;&#25935;&#24863;&#65292;&#21487;&#33021;&#24433;&#21709;&#26657;&#20934;&#35786;&#26029;&#12290;</title><link>https://arxiv.org/abs/2403.00423</link><description>&lt;p&gt;
&#20351;&#29992;&#27169;&#25311;&#21442;&#32771;&#20540;&#39564;&#35777;ML-UQ&#26657;&#20934;&#32479;&#35745;&#37327;&#65306;&#19968;&#39033;&#25935;&#24863;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Validation of ML-UQ calibration statistics using simulated reference values: a sensitivity analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;ML-UQ&#26657;&#20934;&#32479;&#35745;&#37327;&#30340;&#20351;&#29992;&#38382;&#39064;&#65292;&#21457;&#29616;&#19968;&#20123;&#32479;&#35745;&#37327;&#23545;&#20110;&#29983;&#25104;&#20998;&#24067;&#30340;&#36873;&#25321;&#36807;&#20110;&#25935;&#24863;&#65292;&#21487;&#33021;&#24433;&#21709;&#26657;&#20934;&#35786;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20123;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;ML-UQ&#65289;&#26657;&#20934;&#32479;&#35745;&#37327;&#27809;&#26377;&#39044;&#23450;&#20041;&#30340;&#21442;&#32771;&#20540;&#65292;&#20027;&#35201;&#29992;&#20110;&#27604;&#36739;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#26657;&#20934;&#20960;&#20046;&#20174;&#19981;&#34987;&#39564;&#35777;&#65292;&#35786;&#26029;&#30041;&#32473;&#35835;&#32773;&#30340;&#21028;&#26029;&#12290;&#25552;&#20986;&#20102;&#22522;&#20110;&#23454;&#38469;&#19981;&#30830;&#23450;&#24615;&#23548;&#20986;&#30340;&#21512;&#25104;&#26657;&#20934;&#25968;&#25454;&#38598;&#30340;&#27169;&#25311;&#21442;&#32771;&#20540;&#65292;&#20197;&#24357;&#34917;&#36825;&#19968;&#38382;&#39064;&#12290;&#30001;&#20110;&#29992;&#20110;&#27169;&#25311;&#21512;&#25104;&#35823;&#24046;&#30340;&#29983;&#25104;&#27010;&#29575;&#20998;&#24067;&#36890;&#24120;&#27809;&#26377;&#32422;&#26463;&#65292;&#25152;&#20197;&#27169;&#25311;&#21442;&#32771;&#20540;&#23545;&#29983;&#25104;&#20998;&#24067;&#36873;&#25321;&#30340;&#25935;&#24863;&#24615;&#21487;&#33021;&#20250;&#25104;&#20026;&#38382;&#39064;&#65292;&#23545;&#26657;&#20934;&#35786;&#26029;&#20135;&#29983;&#24576;&#30097;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#21508;&#20010;&#26041;&#38754;&#65292;&#24182;&#26174;&#31034;&#19968;&#20123;&#32479;&#35745;&#37327;&#23545;&#20110;&#29992;&#20110;&#39564;&#35777;&#26102;&#29983;&#25104;&#20998;&#24067;&#30340;&#36873;&#25321;&#36807;&#20110;&#25935;&#24863;&#65292;&#24403;&#29983;&#25104;&#20998;&#24067;&#26410;&#30693;&#26102;&#12290;&#20363;&#22914;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00423v1 Announce Type: cross  Abstract: Some popular Machine Learning Uncertainty Quantification (ML-UQ) calibration statistics do not have predefined reference values and are mostly used in comparative studies. In consequence, calibration is almost never validated and the diagnostic is left to the appreciation of the reader. Simulated reference values, based on synthetic calibrated datasets derived from actual uncertainties, have been proposed to palliate this problem. As the generative probability distribution for the simulation of synthetic errors is often not constrained, the sensitivity of simulated reference values to the choice of generative distribution might be problematic, shedding a doubt on the calibration diagnostic. This study explores various facets of this problem, and shows that some statistics are excessively sensitive to the choice of generative distribution to be used for validation when the generative distribution is unknown. This is the case, for instan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#32479;&#19968;&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#8220;&#36890;&#36807;&#36845;&#20195;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#8221;&#29616;&#35937;&#65292;&#25552;&#39640;&#20102;&#20808;&#21069;&#20998;&#26512;&#30340;&#27700;&#24179;&#65292;&#24182;&#30001;&#27492;&#33719;&#24471;&#20102;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#26356;&#32039;&#23494;&#30340;&#38544;&#31169;&#26680;&#31639;&#12290;</title><link>https://arxiv.org/abs/2403.00278</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#24179;&#31227;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Shifted Interpolation for Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#32479;&#19968;&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#8220;&#36890;&#36807;&#36845;&#20195;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#8221;&#29616;&#35937;&#65292;&#25552;&#39640;&#20102;&#20808;&#21069;&#20998;&#26512;&#30340;&#27700;&#24179;&#65292;&#24182;&#30001;&#27492;&#33719;&#24471;&#20102;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#26356;&#32039;&#23494;&#30340;&#38544;&#31169;&#26680;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21927;&#22179;&#30340;&#26799;&#24230;&#19979;&#38477;&#21450;&#20854;&#21464;&#31181;&#26159;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#20013;&#20027;&#23548;&#30340;&#31639;&#27861;&#12290;&#37327;&#21270;&#23427;&#20204;&#30340;&#38544;&#31169;&#27844;&#28431;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#28982;&#32780;&#21363;&#20351;&#22312;&#20984;&#25439;&#22833;&#30340;&#22522;&#30784;&#35774;&#32622;&#20013;&#65292;&#32039;&#33268;&#30340;&#34920;&#24449;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;$f$-&#24046;&#20998;&#38544;&#31169;&#30340;&#32479;&#19968;&#26694;&#26550;&#19979;&#24314;&#31435;&#65288;&#21644;&#25913;&#36827;&#65289;&#8220;&#36890;&#36807;&#36845;&#20195;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#8221;&#29616;&#35937;&#65292;&#25552;&#39640;&#20102;&#20808;&#21069;&#20998;&#26512;&#30340;&#27700;&#24179;--&#36825;&#31181;&#26041;&#27861;&#32039;&#32039;&#25429;&#25417;&#20102;&#38544;&#31169;&#25439;&#22833;&#30340;&#25152;&#26377;&#26041;&#38754;&#65292;&#24182;&#31435;&#21363;&#33719;&#24471;&#20102;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#65288;&#22914;$(\varepsilon,\delta)$-DP&#21644;Renyi DP&#65289;&#26356;&#32039;&#23494;&#30340;&#38544;&#31169;&#26680;&#31639;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#35265;&#35299;&#26159;&#26500;&#24314;&#20102;&#25581;&#31034;&#20102;&#27969;&#34892;&#30340;&#24179;&#31227;&#25955;&#24230;&#35770;&#35777;&#30340;&#24179;&#31227;&#25554;&#20540;&#36807;&#31243;&#65292;&#20351;&#24471;&#36229;&#36234;&#22522;&#20110;&#25955;&#24230;&#30340;&#24046;&#20998;&#38544;&#31169;&#25918;&#23485;&#30340;&#27867;&#21270;&#25104;&#20026;&#21487;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#23548;&#33268;&#20102;&#22312;&#24378;&#20984;&#22522;&#30784;&#35774;&#32622;&#20013;&#30340;&#31532;&#19968;&#20010;&#31934;&#30830;&#38544;&#31169;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00278v1 Announce Type: new  Abstract: Noisy gradient descent and its variants are the predominant algorithms for differentially private machine learning. It is a fundamental question to quantify their privacy leakage, yet tight characterizations remain open even in the foundational setting of convex losses. This paper improves over previous analyses by establishing (and refining) the "privacy amplification by iteration" phenomenon in the unifying framework of $f$-differential privacy--which tightly captures all aspects of the privacy loss and immediately implies tighter privacy accounting in other notions of differential privacy, e.g., $(\varepsilon,\delta)$-DP and Renyi DP. Our key technical insight is the construction of shifted interpolated processes that unravel the popular shifted-divergences argument, enabling generalizations beyond divergence-based relaxations of DP. Notably, this leads to the first exact privacy analysis in the foundational setting of strongly convex
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#20999;&#32447;&#26680;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39640;&#32500;&#24230;&#24773;&#24418;&#19979;&#23545;&#23485;&#32780;&#20840;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26377;&#25928;&#21387;&#32553;&#12290;</title><link>https://arxiv.org/abs/2403.00258</link><description>&lt;p&gt;
&#8220;&#26080;&#25439;&#8221;&#21387;&#32553;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65306;&#19968;&#31181;&#39640;&#32500;&#31070;&#32463;&#20999;&#32447;&#26680;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
"Lossless" Compression of Deep Neural Networks: A High-dimensional Neural Tangent Kernel Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#31070;&#32463;&#20999;&#32447;&#26680;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39640;&#32500;&#24230;&#24773;&#24418;&#19979;&#23545;&#23485;&#32780;&#20840;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26377;&#25928;&#21387;&#32553;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#38750;&#24120;&#24378;&#22823;&#65307;&#28982;&#32780;&#65292;&#36825;&#26159;&#20197;&#22686;&#21152;&#28145;&#24230;&#24182;&#20351;&#27599;&#19968;&#23618;&#30340;&#21442;&#25968;&#26356;&#22810;&#20026;&#20195;&#20215;&#30340;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#35757;&#32451;&#21644;&#25512;&#26029;&#21464;&#24471;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#20851;&#38190;&#38480;&#21046;&#65292;&#20154;&#20204;&#33268;&#21147;&#20110;&#23545;&#36825;&#20123;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#21387;&#32553;&#65288;&#22914;&#31232;&#30095;&#21270;&#21644;/&#25110;&#37327;&#21270;&#65289;&#65292;&#20197;&#20415;&#23427;&#20204;&#21487;&#20197;&#37096;&#32626;&#22312;&#20302;&#21151;&#32791;&#30340;&#29289;&#32852;&#32593;&#35774;&#22791;&#19978;&#12290;&#26412;&#25991;&#22522;&#20110;&#31070;&#32463;&#20999;&#32447;&#26680;&#65288;NTK&#65289;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#65288;RMT&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21387;&#32553;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#23485;&#32780;&#20840;&#36830;&#25509;&#30340;\emph{&#28145;}&#31070;&#32463;&#32593;&#32476;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#39640;&#32500;&#24230;&#24773;&#24418;&#19979;&#65292;&#24403;&#25968;&#25454;&#28857;&#30340;&#25968;&#37327;$n$&#21644;&#23427;&#20204;&#30340;&#32500;&#24230;$p$&#37117;&#24456;&#22823;&#65292;&#24182;&#19988;&#25968;&#25454;&#36981;&#24490;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26102;&#65292;&#23545;&#20110;&#19968;&#22823;&#31867;DNN&#65292;NTK&#30697;&#38453;&#20043;&#38388;&#23384;&#22312;\emph{&#28176;&#36817;&#35889;&#31561;&#20215;}&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00258v1 Announce Type: cross  Abstract: Modern deep neural networks (DNNs) are extremely powerful; however, this comes at the price of increased depth and having more parameters per layer, making their training and inference more computationally challenging. In an attempt to address this key limitation, efforts have been devoted to the compression (e.g., sparsification and/or quantization) of these large-scale machine learning models, so that they can be deployed on low-power IoT devices. In this paper, building upon recent advances in neural tangent kernel (NTK) and random matrix theory (RMT), we provide a novel compression approach to wide and fully-connected \emph{deep} neural nets. Specifically, we demonstrate that in the high-dimensional regime where the number of data points $n$ and their dimension $p$ are both large, and under a Gaussian mixture model for the data, there exists \emph{asymptotic spectral equivalence} between the NTK matrices for a large family of DNN m
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#19977;&#20010;&#26041;&#21521;&#19978;&#25512;&#36827;&#20102;&#22240;&#26524;&#36172;&#21338;&#26426;&#30340;&#32467;&#26524;&#65306;&#22312;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#19979;&#36827;&#34892;&#24178;&#39044;&#35774;&#35745;&#65292;&#23454;&#29616;&#24191;&#20041;&#36719;&#24178;&#39044;&#20197;&#21450;&#25552;&#20379;&#19968;&#33324;&#30340;&#36951;&#25022;&#19978;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.00233</link><description>&lt;p&gt;
&#20855;&#26377;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;&#24178;&#39044;&#30340;&#22240;&#26524;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Causal Bandits with General Causal Models and Interventions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00233
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#19977;&#20010;&#26041;&#21521;&#19978;&#25512;&#36827;&#20102;&#22240;&#26524;&#36172;&#21338;&#26426;&#30340;&#32467;&#26524;&#65306;&#22312;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#19979;&#36827;&#34892;&#24178;&#39044;&#35774;&#35745;&#65292;&#23454;&#29616;&#24191;&#20041;&#36719;&#24178;&#39044;&#20197;&#21450;&#25552;&#20379;&#19968;&#33324;&#30340;&#36951;&#25022;&#19978;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22240;&#26524;&#36172;&#21338;&#26426;&#65288;CBs&#65289;&#29992;&#20110;&#22240;&#26524;&#31995;&#32479;&#20013;&#24178;&#39044;&#30340;&#39034;&#24207;&#35774;&#35745;&#12290;&#20854;&#30446;&#26631;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;&#19982;&#20107;&#21518;&#26368;&#20339;&#24178;&#39044;&#24207;&#21015;&#30456;&#27604;&#30340;&#32047;&#31215;&#36951;&#25022;&#24230;&#37327;&#26469;&#20248;&#21270;&#22870;&#21169;&#20989;&#25968;&#12290;&#26412;&#25991;&#23558;CBs&#30340;&#32467;&#26524;&#25512;&#36827;&#20102;&#19977;&#20010;&#26041;&#21521;&#12290;&#39318;&#20808;&#65292;&#20551;&#35774;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCMs&#65289;&#26410;&#30693;&#65292;&#24182;&#19988;&#20219;&#24847;&#20174;Lipschitz&#36830;&#32493;&#20989;&#25968;&#31867;$\mathcal{F}$&#20013;&#32472;&#21046;&#12290;&#29616;&#26377;&#32467;&#26524;&#36890;&#24120;&#38598;&#20013;&#22312;&#65288;&#24191;&#20041;&#65289;&#32447;&#24615;SCMs&#19978;&#12290;&#20854;&#27425;&#65292;&#20551;&#35774;&#24178;&#39044;&#26159;&#24191;&#20041;&#36719;&#24178;&#39044;&#65292;&#20855;&#26377;&#20219;&#24847;&#25152;&#38656;&#31890;&#24230;&#30340;&#27700;&#24179;&#65292;&#23548;&#33268;&#26080;&#38480;&#25968;&#37327;&#30340;&#21487;&#33021;&#24178;&#39044;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#29616;&#26377;&#25991;&#29486;&#36890;&#24120;&#37319;&#29992;&#21407;&#23376;&#21644;&#30828;&#24178;&#39044;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36951;&#25022;&#30340;&#19968;&#33324;&#19978;&#19979;&#30028;&#12290;&#19978;&#30028;&#21253;&#21547;&#65288;&#24182;&#25913;&#36827;&#65289;&#29305;&#27530;&#24773;&#20917;&#30340;&#24050;&#30693;&#30028;&#38480;&#12290;&#19979;&#30028;&#26159;gene
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00233v1 Announce Type: cross  Abstract: This paper considers causal bandits (CBs) for the sequential design of interventions in a causal system. The objective is to optimize a reward function via minimizing a measure of cumulative regret with respect to the best sequence of interventions in hindsight. The paper advances the results on CBs in three directions. First, the structural causal models (SCMs) are assumed to be unknown and drawn arbitrarily from a general class $\mathcal{F}$ of Lipschitz-continuous functions. Existing results are often focused on (generalized) linear SCMs. Second, the interventions are assumed to be generalized soft with any desired level of granularity, resulting in an infinite number of possible interventions. The existing literature, in contrast, generally adopts atomic and hard interventions. Third, we provide general upper and lower bounds on regret. The upper bounds subsume (and improve) known bounds for special cases. The lower bounds are gene
&lt;/p&gt;</description></item><item><title>&#24490;&#29615;MCMC&#26159;&#19968;&#31181;&#26032;&#30340;MCMC&#26694;&#26550;&#65292;&#21487;&#20197;&#24456;&#22909;&#22320;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#30340;&#23616;&#37096;&#24418;&#29366;&#65292;&#20294;&#22312;&#24930;&#28151;&#21512;&#26680;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#26469;&#33258;&#26399;&#26395;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2403.00230</link><description>&lt;p&gt;
&#20851;&#20110;&#24490;&#29615;MCMC&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
On Cyclical MCMC Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00230
&lt;/p&gt;
&lt;p&gt;
&#24490;&#29615;MCMC&#26159;&#19968;&#31181;&#26032;&#30340;MCMC&#26694;&#26550;&#65292;&#21487;&#20197;&#24456;&#22909;&#22320;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#30340;&#23616;&#37096;&#24418;&#29366;&#65292;&#20294;&#22312;&#24930;&#28151;&#21512;&#26680;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#26469;&#33258;&#26399;&#26395;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24490;&#29615;MCMC&#26159;&#24352;&#31561;&#20154;(2019&#24180;)&#26368;&#36817;&#25552;&#20986;&#30340;&#19968;&#31181;&#26032;&#30340;MCMC&#26694;&#26550;&#65292;&#26088;&#22312;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#39640;&#32500;&#22810;&#27169;&#21518;&#39564;&#20998;&#24067;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#29983;&#25104;&#19968;&#20010;&#38750;&#40784;&#27425;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#20197;&#26102;&#38388;&#21608;&#26399;&#24615;&#22320;&#36319;&#36394;&#30446;&#26631;&#20998;&#24067;&#30340;&#28201;&#21644;&#29256;&#26412;&#26469;&#24037;&#20316;&#12290;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#23637;&#31034;&#20102;&#65292;&#22312;&#20351;&#29992;&#24555;&#28151;&#21512;&#30340;&#39532;&#23572;&#21487;&#22827;&#26680;&#21644;&#36275;&#22815;&#38271;&#30340;&#21608;&#26399;&#30340;&#35774;&#32622;&#19979;&#65292;&#24490;&#29615;MCMC&#20250;&#25910;&#25947;&#21040;&#26399;&#26395;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22312;&#36739;&#24120;&#35265;&#30340;&#24930;&#28151;&#21512;&#26680;&#35774;&#32622;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#26469;&#33258;&#26399;&#26395;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#19968;&#20010;&#20855;&#26377;&#19981;&#21516;&#26041;&#24046;&#30340;&#31616;&#21333;&#28151;&#21512;&#31034;&#20363;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#26174;&#31034;&#24490;&#29615;MCMC&#26080;&#27861;&#25910;&#25947;&#21040;&#26399;&#26395;&#26497;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24490;&#29615;MCMC&#36890;&#24120;&#24456;&#22909;&#22320;&#20272;&#35745;&#20102;&#27599;&#20010;&#27169;&#24335;&#21608;&#22260;&#30446;&#26631;&#20998;&#24067;&#30340;&#23616;&#37096;&#24418;&#29366;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00230v1 Announce Type: cross  Abstract: Cyclical MCMC is a novel MCMC framework recently proposed by Zhang et al. (2019) to address the challenge posed by high-dimensional multimodal posterior distributions like those arising in deep learning. The algorithm works by generating a nonhomogeneous Markov chain that tracks -- cyclically in time -- tempered versions of the target distribution. We show in this work that cyclical MCMC converges to the desired probability distribution in settings where the Markov kernels used are fast mixing, and sufficiently long cycles are employed. However in the far more common settings of slow mixing kernels, the algorithm may fail to produce samples from the desired distribution. In particular, in a simple mixture example with unequal variance, we show by simulation that cyclical MCMC fails to converge to the desired limit. Finally, we show that cyclical MCMC typically estimates well the local shape of the target distribution around each mode, 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24674;&#22797;&#28508;&#21464;&#37327;&#23454;&#29616;&#26367;&#20195;&#35843;&#25972;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#35843;&#25972;&#21518;&#30340;&#22238;&#24402;&#30446;&#26631;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#20026;&#26465;&#20214;&#29420;&#31435;&#24773;&#20917;&#19979;&#30340;&#22238;&#24402;&#21464;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#35843;&#25972;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.00202</link><description>&lt;p&gt;
&#36890;&#36807;&#24674;&#22797;&#28508;&#21464;&#37327;&#36827;&#34892;&#26367;&#20195;&#35843;&#25972;
&lt;/p&gt;
&lt;p&gt;
Substitute adjustment via recovery of latent variables
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00202
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24674;&#22797;&#28508;&#21464;&#37327;&#23454;&#29616;&#26367;&#20195;&#35843;&#25972;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#35843;&#25972;&#21518;&#30340;&#22238;&#24402;&#30446;&#26631;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#20026;&#26465;&#20214;&#29420;&#31435;&#24773;&#20917;&#19979;&#30340;&#22238;&#24402;&#21464;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#35843;&#25972;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00202v1 &#36890;&#21578;&#31867;&#22411;: &#36328;&#30028; &#25688;&#35201;: deconfounder&#34987;&#25552;&#35758;&#20316;&#20026;&#19968;&#20010;&#22312;&#26377;&#22810;&#20010;&#21407;&#22240;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#24773;&#20917;&#19979;&#20272;&#35745;&#22240;&#26524;&#21442;&#25968;&#30340;&#26041;&#27861;&#12290;&#23427;&#22522;&#20110;&#20174;&#35266;&#23519;&#21040;&#30340;&#21407;&#22240;&#24674;&#22797;&#28508;&#21464;&#37327;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#35299;&#37322;&#19982;&#32479;&#35745;&#20272;&#35745;&#38382;&#39064;&#21306;&#20998;&#24320;&#26469;&#65292;&#24182;&#23637;&#31034;deconfounder&#36890;&#24120;&#20272;&#35745;&#35843;&#25972;&#21518;&#30340;&#22238;&#24402;&#30446;&#26631;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#20026;&#24674;&#22797;&#30340;&#28508;&#21464;&#37327;&#35843;&#25972;&#30340;&#32467;&#26524;&#22238;&#24402;&#26469;&#20570;&#21040;&#36825;&#19968;&#28857;&#65292;&#31216;&#20026;&#26367;&#20195;&#29289;&#12290;&#25105;&#20204;&#23558;&#19981;&#28041;&#21450;&#22240;&#26524;&#20551;&#35774;&#30340;&#19968;&#33324;&#31639;&#27861;&#31216;&#20026;&#26367;&#20195;&#35843;&#25972;&#12290;&#25105;&#20204;&#25552;&#20379;&#29702;&#35770;&#32467;&#26524;&#26469;&#25903;&#25345;&#24403;&#22312;&#32473;&#23450;&#28508;&#21464;&#37327;&#30340;&#26465;&#20214;&#19979;&#22238;&#24402;&#21464;&#37327;&#26159;&#26465;&#20214;&#29420;&#31435;&#26102;&#65292;&#26367;&#20195;&#35843;&#25972;&#20272;&#35745;&#35843;&#25972;&#21518;&#30340;&#22238;&#24402;&#21442;&#25968;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#25105;&#20204;&#30340;&#26367;&#20195;&#35843;&#25972;&#31639;&#27861;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#23427;&#20272;&#35745;&#20855;&#26377;&#26368;&#23567;&#27169;&#22411;&#20551;&#35774;&#30340;&#30246;&#20551;&#35774;&#30446;&#26631;&#21442;&#25968;&#12290;&#28982;&#21518;&#25105;&#20204;&#32473;&#20986;&#20102;&#26377;&#38480;&#26679;&#26412;&#30028;&#38480;&#21644;&#28176;&#36827;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00202v1 Announce Type: cross  Abstract: The deconfounder was proposed as a method for estimating causal parameters in a context with multiple causes and unobserved confounding. It is based on recovery of a latent variable from the observed causes. We disentangle the causal interpretation from the statistical estimation problem and show that the deconfounder in general estimates adjusted regression target parameters. It does so by outcome regression adjusted for the recovered latent variable termed the substitute. We refer to the general algorithm, stripped of causal assumptions, as substitute adjustment. We give theoretical results to support that substitute adjustment estimates adjusted regression parameters when the regressors are conditionally independent given the latent variable. We also introduce a variant of our substitute adjustment algorithm that estimates an assumption-lean target parameter with minimal model assumptions. We then give finite sample bounds and asymp
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#39640;&#24230;&#38750;&#22343;&#21248;&#37319;&#26679;&#26465;&#20214;&#19979;&#20302;&#31209;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#30340;&#20837;&#21475;&#29305;&#23450;&#30028;&#38480;&#65292;&#36890;&#36807;&#23450;&#21046;&#27599;&#20010;&#26465;&#30446;&#30340;&#35823;&#24046;&#19978;&#30028;&#26469;&#21305;&#37197;&#19968;&#23450;&#26465;&#20214;&#19979;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;</title><link>https://arxiv.org/abs/2403.00184</link><description>&lt;p&gt;
&#20302;&#31209;&#30697;&#38453;&#23436;&#25104;&#22312;&#39640;&#24230;&#38750;&#22343;&#21248;&#37319;&#26679;&#19979;&#30340;&#20837;&#21475;&#29305;&#23450;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Entry-Specific Bounds for Low-Rank Matrix Completion under Highly Non-Uniform Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00184
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#39640;&#24230;&#38750;&#22343;&#21248;&#37319;&#26679;&#26465;&#20214;&#19979;&#20302;&#31209;&#30697;&#38453;&#23436;&#25104;&#38382;&#39064;&#30340;&#20837;&#21475;&#29305;&#23450;&#30028;&#38480;&#65292;&#36890;&#36807;&#23450;&#21046;&#27599;&#20010;&#26465;&#30446;&#30340;&#35823;&#24046;&#19978;&#30028;&#26469;&#21305;&#37197;&#19968;&#23450;&#26465;&#20214;&#19979;&#30340;&#26497;&#23567;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#30697;&#38453;&#23436;&#25104;&#28041;&#21450;&#20351;&#29992;&#31232;&#30095;&#19968;&#32452;&#35266;&#27979;&#26465;&#30446;&#26469;&#20272;&#35745;&#30697;&#38453;&#20013;&#26410;&#35266;&#23519;&#21040;&#30340;&#26465;&#30446;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#35266;&#27979;&#21040;&#30340;&#26465;&#30446;&#26159;&#29992;&#39640;&#24230;&#21464;&#21270;&#30340;&#27010;&#29575;&#36827;&#34892;&#37319;&#26679;&#30340;&#38750;&#22343;&#21248;&#35774;&#32622;&#65292;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#28176;&#36817;&#26631;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#32467;&#26500;&#21270;&#37319;&#26679;&#27010;&#29575;&#19979;&#65292;&#36890;&#24120;&#24773;&#20917;&#19979;&#20197;&#21450;&#26377;&#26102;&#22312;&#36739;&#23567;&#30340;&#23376;&#30697;&#38453;&#19978;&#36816;&#34892;&#20272;&#35745;&#31639;&#27861;&#27604;&#22312;&#25972;&#20010;&#30697;&#38453;&#19978;&#26356;&#22909;&#65292;&#29978;&#33267;&#26159;&#26368;&#20339;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23450;&#21046;&#21040;&#27599;&#20010;&#26465;&#30446;&#30340;&#35823;&#24046;&#19978;&#30028;&#65292;&#36825;&#20123;&#19978;&#30028;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#19982;&#26497;&#23567;&#19979;&#30028;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#20197;&#23616;&#37096;&#37319;&#26679;&#27010;&#29575;&#30340;&#20989;&#25968;&#30340;&#24418;&#24335;&#21051;&#30011;&#20102;&#20272;&#35745;&#27599;&#20010;&#26465;&#30446;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00184v1 Announce Type: cross  Abstract: Low-rank matrix completion concerns the problem of estimating unobserved entries in a matrix using a sparse set of observed entries. We consider the non-uniform setting where the observed entries are sampled with highly varying probabilities, potentially with different asymptotic scalings. We show that under structured sampling probabilities, it is often better and sometimes optimal to run estimation algorithms on a smaller submatrix rather than the entire matrix. In particular, we prove error upper bounds customized to each entry, which match the minimax lower bounds under certain conditions. Our bounds characterize the hardness of estimating each entry as a function of the localized sampling probabilities. We provide numerical experiments that confirm our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#23553;&#38381;&#24418;&#24335;&#35299;&#25110;&#25968;&#23398;&#25512;&#23548;&#65292;&#20063;&#19981;&#38656;&#35201;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#20165;&#38656;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#36827;&#34892;&#19968;&#27425;&#25512;&#26029;&#21363;&#21487;&#20272;&#35745;&#28508;&#22312;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;</title><link>https://arxiv.org/abs/2403.00019</link><description>&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#32479;&#35745;&#23398;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Transformer-based Parameter Estimation in Statistics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00019
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Transformer&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#23553;&#38381;&#24418;&#24335;&#35299;&#25110;&#25968;&#23398;&#25512;&#23548;&#65292;&#20063;&#19981;&#38656;&#35201;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#20165;&#38656;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#36827;&#34892;&#19968;&#27425;&#25512;&#26029;&#21363;&#21487;&#20272;&#35745;&#28508;&#22312;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#25968;&#20272;&#35745;&#26159;&#32479;&#35745;&#23398;&#20013;&#26368;&#37325;&#35201;&#30340;&#20219;&#21153;&#20043;&#19968;&#65292;&#26377;&#21161;&#20110;&#24110;&#21161;&#20154;&#20204;&#29702;&#35299;&#35266;&#27979;&#26679;&#26412;&#32972;&#21518;&#30340;&#20998;&#24067;&#12290;&#20256;&#32479;&#19978;&#65292;&#21442;&#25968;&#20272;&#35745;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#35299;&#65288;&#20363;&#22914;&#65292;&#39640;&#26031;&#20998;&#24067;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65289;&#25110;&#36890;&#36807;&#36845;&#20195;&#25968;&#20540;&#26041;&#27861;&#65288;&#20363;&#22914;&#65292;Beta&#20998;&#24067;&#26102;&#23553;&#38381;&#24418;&#24335;&#35299;&#19981;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;Newton-Raphson&#26041;&#27861;&#65289;&#26469;&#23436;&#25104;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Transformer&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;&#19982;&#29616;&#26377;&#35299;&#20915;&#26041;&#26696;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#23553;&#38381;&#24418;&#24335;&#35299;&#25110;&#20219;&#20309;&#25968;&#23398;&#25512;&#23548;&#12290;&#23427;&#29978;&#33267;&#19981;&#38656;&#35201;&#30693;&#36947;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#36825;&#26159;&#25968;&#20540;&#26041;&#27861;&#25152;&#38656;&#30340;&#12290;&#35757;&#32451;&#20102;Transformer&#27169;&#22411;&#21518;&#65292;&#20165;&#38656;&#35201;&#36827;&#34892;&#19968;&#27425;&#25512;&#26029;&#65292;&#21363;&#21487;&#22522;&#20110;&#35266;&#27979;&#26679;&#26412;&#20272;&#35745;&#28508;&#22312;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00019v1 Announce Type: new  Abstract: Parameter estimation is one of the most important tasks in statistics, and is key to helping people understand the distribution behind a sample of observations. Traditionally parameter estimation is done either by closed-form solutions (e.g., maximum likelihood estimation for Gaussian distribution), or by iterative numerical methods such as Newton-Raphson method when closed-form solution does not exist (e.g., for Beta distribution).   In this paper we propose a transformer-based approach to parameter estimation. Compared with existing solutions, our approach does not require a closed-form solution or any mathematical derivations. It does not even require knowing the probability density function, which is needed by numerical methods. After the transformer model is trained, only a single inference is needed to estimate the parameters of the underlying distribution based on a sample of observations. In the empirical study we compared our ap
&lt;/p&gt;</description></item><item><title>PIP-Net&#26159;&#19968;&#20010;&#26032;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#21160;&#24577;&#23398;&#25968;&#25454;&#21644;&#22330;&#26223;&#31354;&#38388;&#29305;&#24449;&#65292;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#25104;&#21151;&#39044;&#27979;&#34892;&#20154;&#36890;&#36807;&#39532;&#36335;&#30340;&#24847;&#22270;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>https://arxiv.org/abs/2402.12810</link><description>&lt;p&gt;
PIP-Net&#65306;&#22478;&#24066;&#20013;&#34892;&#20154;&#24847;&#22270;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
PIP-Net: Pedestrian Intention Prediction in the Wild
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12810
&lt;/p&gt;
&lt;p&gt;
PIP-Net&#26159;&#19968;&#20010;&#26032;&#22411;&#26694;&#26550;&#65292;&#36890;&#36807;&#32508;&#21512;&#21033;&#29992;&#21160;&#24577;&#23398;&#25968;&#25454;&#21644;&#22330;&#26223;&#31354;&#38388;&#29305;&#24449;&#65292;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#35299;&#20915;&#26041;&#26696;&#65292;&#25104;&#21151;&#39044;&#27979;&#34892;&#20154;&#36890;&#36807;&#39532;&#36335;&#30340;&#24847;&#22270;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#20934;&#30340;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#65288;AVs&#65289;&#23545;&#34892;&#20154;&#24847;&#22270;&#30340;&#39044;&#27979;&#26159;&#24403;&#21069;&#35813;&#39046;&#22495;&#30340;&#19968;&#39033;&#30740;&#31350;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;PIP-Net&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#39044;&#27979;AVs&#22312;&#29616;&#23454;&#19990;&#30028;&#22478;&#24066;&#22330;&#26223;&#20013;&#30340;&#34892;&#20154;&#36807;&#39532;&#36335;&#24847;&#22270;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#38024;&#23545;&#19981;&#21516;&#25668;&#20687;&#22836;&#23433;&#35013;&#21644;&#35774;&#32622;&#35774;&#35745;&#30340;PIP-Net&#21464;&#31181;&#12290;&#21033;&#29992;&#26469;&#33258;&#34892;&#39542;&#22330;&#26223;&#30340;&#21160;&#21147;&#23398;&#25968;&#25454;&#21644;&#31354;&#38388;&#29305;&#24449;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#37319;&#29992;&#24490;&#29615;&#21644;&#26102;&#38388;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;&#20026;&#20102;&#22686;&#24378;&#36947;&#36335;&#29992;&#25143;&#30340;&#35270;&#35273;&#34920;&#31034;&#21450;&#20854;&#19982;&#33258;&#36710;&#30340;&#30456;&#20851;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20998;&#31867;&#28145;&#24230;&#29305;&#24449;&#22270;&#65292;&#32467;&#21512;&#23616;&#37096;&#36816;&#21160;&#27969;&#29305;&#24449;&#65292;&#20026;&#22330;&#26223;&#21160;&#24577;&#25552;&#20379;&#20016;&#23500;&#30340;&#27934;&#23519;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#23558;&#25668;&#20687;&#22836;&#30340;&#35270;&#37326;&#20174;&#19968;&#20010;&#25193;&#23637;&#21040;&#22260;&#32469;&#33258;&#36710;&#30340;&#19977;&#20010;&#25668;&#20687;&#22836;&#30340;&#24433;&#21709;&#65292;&#20197;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12810v1 Announce Type: cross  Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10043</link><description>&lt;p&gt;
&#22914;&#20309;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How to validate average calibration for machine learning regression tasks ?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#24179;&#22343;&#26657;&#20934;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#26657;&#20934;&#35823;&#24046;&#19982;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#20540;&#21644;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#21069;&#32773;&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#25935;&#24863;&#65292;&#32780;&#21518;&#32773;&#22312;&#35813;&#26041;&#38754;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#24179;&#22343;&#26657;&#20934;&#24615;&#21487;&#20197;&#36890;&#36807;&#20004;&#31181;&#26041;&#24335;&#36827;&#34892;&#27979;&#35797;&#12290;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#26657;&#20934;&#35823;&#24046;&#65288;CE&#65289;&#20272;&#35745;&#20026;&#24179;&#22343;&#32477;&#23545;&#35823;&#24046;&#65288;MSE&#65289;&#19982;&#24179;&#22343;&#26041;&#24046;&#65288;MV&#65289;&#25110;&#24179;&#22343;&#24179;&#26041;&#19981;&#30830;&#23450;&#24615;&#20043;&#38388;&#30340;&#24046;&#20540;&#12290;&#21478;&#19968;&#31181;&#26041;&#24335;&#26159;&#23558;&#24179;&#22343;&#24179;&#26041;z-&#20998;&#25968;&#25110;&#32553;&#25918;&#35823;&#24046;&#65288;ZMS&#65289;&#19982;1&#36827;&#34892;&#27604;&#36739;&#12290;&#20004;&#31181;&#26041;&#27861;&#21487;&#33021;&#24471;&#20986;&#19981;&#21516;&#30340;&#32467;&#35770;&#65292;&#27491;&#22914;&#26469;&#33258;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25991;&#29486;&#20013;&#30340;&#25968;&#25454;&#38598;&#38598;&#21512;&#25152;&#31034;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;CE&#23545;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#38750;&#24120;&#25935;&#24863;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#31163;&#32676;&#19981;&#30830;&#23450;&#24615;&#30340;&#23384;&#22312;&#65292;&#22240;&#27492;&#26080;&#27861;&#21487;&#38752;&#22320;&#29992;&#20110;&#26657;&#20934;&#27979;&#35797;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;ZMS&#32479;&#35745;&#37327;&#19981;&#20855;&#26377;&#36825;&#31181;&#25935;&#24863;&#24615;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#26368;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;&#25991;&#31456;&#36824;&#35752;&#35770;&#20102;&#23545;&#26465;&#20214;&#26657;&#20934;&#39564;&#35777;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10043v1 Announce Type: cross  Abstract: Average calibration of the uncertainties of machine learning regression tasks can be tested in two ways. One way is to estimate the calibration error (CE) as the difference between the mean absolute error (MSE) and the mean variance (MV) or mean squared uncertainty. The alternative is to compare the mean squared z-scores or scaled errors (ZMS) to 1. Both approaches might lead to different conclusion, as illustrated on an ensemble of datasets from the recent machine learning uncertainty quantification literature. It is shown here that the CE is very sensitive to the distribution of uncertainties, and notably to the presence of outlying uncertainties, and that it cannot be used reliably for calibration testing. By contrast, the ZMS statistic does not present this sensitivity issue and offers the most reliable approach in this context. Implications for the validation of conditional calibration are discussed.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#20998;&#21306;&#20998;&#31867;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20986;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#26032;&#29305;&#24615;&#65292;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;</title><link>https://arxiv.org/abs/2312.14889</link><description>&lt;p&gt;
&#35770;&#20174;&#21487;&#35266;&#27979;&#21644;&#31169;&#23494;&#25968;&#25454;&#20013;&#23454;&#29616;&#36895;&#29575;&#26368;&#20248;&#20998;&#21306;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
On Rate-Optimal Partitioning Classification from Observable and from Privatised Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.14889
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#20998;&#21306;&#20998;&#31867;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20986;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#26032;&#29305;&#24615;&#65292;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#20998;&#21306;&#20998;&#31867;&#30340;&#32463;&#20856;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#22312;&#25918;&#23485;&#26465;&#20214;&#19979;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#21253;&#25324;&#21487;&#35266;&#27979;&#65288;&#38750;&#31169;&#23494;&#65289;&#21644;&#31169;&#23494;&#25968;&#25454;&#12290;&#25105;&#20204;&#20551;&#35774;&#29305;&#24449;&#21521;&#37327;$X$&#21462;&#20540;&#20110;$\mathbb{R}^d$&#65292;&#20854;&#26631;&#31614;&#20026;$Y$&#12290;&#20043;&#21069;&#20851;&#20110;&#20998;&#21306;&#20998;&#31867;&#22120;&#30340;&#32467;&#26524;&#22522;&#20110;&#24378;&#23494;&#24230;&#20551;&#35774;&#65292;&#36825;&#31181;&#20551;&#35774;&#38480;&#21046;&#36739;&#22823;&#65292;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#30340;&#20363;&#23376;&#21152;&#20197;&#35777;&#26126;&#12290;&#25105;&#20204;&#20551;&#35774;$X$&#30340;&#20998;&#24067;&#26159;&#32477;&#23545;&#36830;&#32493;&#20998;&#24067;&#21644;&#31163;&#25955;&#20998;&#24067;&#30340;&#28151;&#21512;&#20307;&#65292;&#20854;&#20013;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#38598;&#20013;&#20110;&#19968;&#20010;$d_a$&#32500;&#23376;&#31354;&#38388;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#22312;&#26356;&#23485;&#26494;&#30340;&#26465;&#20214;&#19979;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65306;&#38500;&#20102;&#26631;&#20934;&#30340;Lipschitz&#21644;&#36793;&#38469;&#26465;&#20214;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#32477;&#23545;&#36830;&#32493;&#20998;&#37327;&#30340;&#19968;&#20010;&#26032;&#29305;&#24615;&#65292;&#36890;&#36807;&#35813;&#29305;&#24615;&#35745;&#31639;&#20102;&#20998;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#31934;&#30830;&#25910;&#25947;&#29575;&#65292;&#23545;&#20110;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.14889v2 Announce Type: replace-cross  Abstract: In this paper we revisit the classical method of partitioning classification and study its convergence rate under relaxed conditions, both for observable (non-privatised) and for privatised data. Let the feature vector $X$ take values in $\mathbb{R}^d$ and denote its label by $Y$. Previous results on the partitioning classifier worked with the strong density assumption, which is restrictive, as we demonstrate through simple examples. We assume that the distribution of $X$ is a mixture of an absolutely continuous and a discrete distribution, such that the absolutely continuous component is concentrated to a $d_a$ dimensional subspace. Here, we study the problem under much milder assumptions: in addition to the standard Lipschitz and margin conditions, a novel characteristic of the absolutely continuous component is introduced, by which the exact convergence rate of the classification error probability is calculated, both for the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#22238;&#25253;&#20998;&#24067;&#30340;&#26377;&#38480;&#32500;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#26032;&#31639;&#27861;&#24182;&#23637;&#31034;&#21487;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#65292;&#25552;&#39640;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2312.07358</link><description>&lt;p&gt;
&#22522;&#20110;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#36125;&#23572;&#26364;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Distributional Bellman Operators over Mean Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.07358
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#22238;&#25253;&#20998;&#24067;&#30340;&#26377;&#38480;&#32500;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#26032;&#31639;&#27861;&#24182;&#23637;&#31034;&#21487;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#32467;&#21512;&#65292;&#25552;&#39640;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#22238;&#25253;&#20998;&#24067;&#30340;&#26377;&#38480;&#32500;&#22343;&#20540;&#23884;&#20837;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26694;&#26550;&#12290; &#25105;&#20204;&#22522;&#20110;&#36825;&#19968;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#20960;&#31181;&#26032;&#30340;&#21160;&#24577;&#35268;&#21010;&#21644;&#26102;&#24207;&#24046;&#20998;&#23398;&#20064;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#28176;&#36817;&#25910;&#25947;&#29702;&#35770;&#65292;&#24182;&#23545;&#36825;&#20123;&#31639;&#27861;&#22312;&#19968;&#31995;&#21015;&#34920;&#26684;&#20219;&#21153;&#19978;&#30340;&#23454;&#35777;&#34920;&#29616;&#36827;&#34892;&#20102;&#26816;&#39564;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#19982;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30452;&#25509;&#32467;&#21512;&#65292;&#24471;&#21040;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#35813;&#20195;&#29702;&#22312; Arcade Learning Environment &#19978;&#20248;&#20110;&#22522;&#32447;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.07358v2 Announce Type: replace-cross  Abstract: We propose a novel algorithmic framework for distributional reinforcement learning, based on learning finite-dimensional mean embeddings of return distributions. We derive several new algorithms for dynamic programming and temporal-difference learning based on this framework, provide asymptotic convergence theory, and examine the empirical performance of the algorithms on a suite of tabular tasks. Further, we show that this approach can be straightforwardly combined with deep reinforcement learning, and obtain a new deep RL agent that improves over baseline distributional approaches on the Arcade Learning Environment.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#20855;&#26377;&#20301;&#32622;&#23610;&#24230;&#21644;&#24418;&#29366;&#30340;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;(NAMLSS)&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#32463;&#20856;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#20998;&#24067;&#22238;&#24402;&#30340;&#20248;&#21183;</title><link>https://arxiv.org/abs/2301.11862</link><description>&lt;p&gt;
&#20855;&#26377;&#20301;&#32622;&#23610;&#24230;&#21644;&#24418;&#29366;&#30340;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65306;&#36229;&#36234;&#24179;&#22343;&#20540;&#30340;&#21487;&#35299;&#37322;&#31070;&#32463;&#22238;&#24402;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Neural Additive Models for Location Scale and Shape: A Framework for Interpretable Neural Regression Beyond the Mean
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.11862
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#20855;&#26377;&#20301;&#32622;&#23610;&#24230;&#21644;&#24418;&#29366;&#30340;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;(NAMLSS)&#26694;&#26550;&#65292;&#32467;&#21512;&#20102;&#32463;&#20856;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#20998;&#24067;&#22238;&#24402;&#30340;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#24050;&#34987;&#35777;&#26126;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#38750;&#24120;&#26377;&#25928;&#65292;&#20351;&#20854;&#25104;&#20026;&#38656;&#35201;&#39640;&#32423;&#39044;&#27979;&#33021;&#21147;&#30340;&#38382;&#39064;&#30340;&#39318;&#36873;&#26041;&#27861;&#12290;&#23613;&#31649;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;DNNs&#30340;&#20869;&#37096;&#36816;&#20316;&#36890;&#24120;&#19981;&#36879;&#26126;&#65292;&#20351;&#20854;&#38590;&#20197;&#35299;&#37322;&#25110;&#29702;&#35299;&#12290;&#36825;&#31181;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#23548;&#33268;&#36817;&#24180;&#26469;&#23545;&#22266;&#26377;&#21487;&#35299;&#37322;&#24615;&#31070;&#32463;&#32593;&#32476;&#30340;&#30740;&#31350;&#19981;&#26029;&#22686;&#21152;&#12290;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;NAMs&#65289;&#31561;&#27169;&#22411;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#26041;&#27861;&#19982;DNNs&#30456;&#32467;&#21512;&#23454;&#29616;&#20102;&#35270;&#35273;&#21487;&#35299;&#37322;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20165;&#38598;&#20013;&#20110;&#24179;&#22343;&#21709;&#24212;&#39044;&#27979;&#65292;&#24573;&#30053;&#20102;&#24213;&#23618;&#25968;&#25454;&#21709;&#24212;&#20998;&#24067;&#30340;&#20854;&#20182;&#29305;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#20301;&#32622;&#23610;&#24230;&#21644;&#24418;&#29366;&#30340;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;(NAMLSS)&#65292;&#36825;&#26159;&#19968;&#20010;&#24314;&#27169;&#26694;&#26550;&#65292;&#23558;&#32463;&#20856;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#19982;&#20998;&#24067;&#22238;&#24402;&#30340;&#22266;&#26377;&#20248;&#21183;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.11862v2 Announce Type: replace-cross  Abstract: Deep neural networks (DNNs) have proven to be highly effective in a variety of tasks, making them the go-to method for problems requiring high-level predictive power. Despite this success, the inner workings of DNNs are often not transparent, making them difficult to interpret or understand. This lack of interpretability has led to increased research on inherently interpretable neural networks in recent years. Models such as Neural Additive Models (NAMs) achieve visual interpretability through the combination of classical statistical methods with DNNs. However, these approaches only concentrate on mean response predictions, leaving out other properties of the response distribution of the underlying data. We propose Neural Additive Models for Location Scale and Shape (NAMLSS), a modelling framework that combines the predictive power of classical deep learning models with the inherent advantages of distributional regression while
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#20272;&#35745;&#31639;&#27861;&#65292;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#20445;&#35777;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#32467;&#26500;&#20272;&#35745;&#38382;&#39064;&#65292;&#32780;&#19981;&#20250;&#25439;&#23475;&#22870;&#21169;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>https://arxiv.org/abs/2210.01282</link><description>&lt;p&gt;
&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#20013;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#32467;&#26500;&#20272;&#35745;&#19982;&#26377;&#38480;&#26102;&#38388;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Structural Estimation of Markov Decision Processes in High-Dimensional State Space with Finite-Time Guarantees
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.01282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#20272;&#35745;&#31639;&#27861;&#65292;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#20445;&#35777;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#32467;&#26500;&#20272;&#35745;&#38382;&#39064;&#65292;&#32780;&#19981;&#20250;&#25439;&#23475;&#22870;&#21169;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22522;&#20110;&#21487;&#35266;&#27979;&#30340;&#34892;&#20026;&#21382;&#21490;&#21644;&#35775;&#38382;&#29366;&#24577;&#26469;&#20272;&#35745;&#20154;&#31867;&#20195;&#29702;&#21160;&#24577;&#20915;&#31574;&#30340;&#32467;&#26500;&#27169;&#22411;&#30340;&#20219;&#21153;&#12290;&#38382;&#39064;&#20855;&#26377;&#22266;&#26377;&#30340;&#23884;&#22871;&#32467;&#26500;&#65306;&#22312;&#20869;&#37096;&#38382;&#39064;&#20013;&#65292;&#30830;&#23450;&#32473;&#23450;&#22870;&#21169;&#20989;&#25968;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#22312;&#22806;&#37096;&#38382;&#39064;&#20013;&#65292;&#26368;&#22823;&#21270;&#36866;&#21512;&#24230;&#24230;&#37327;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#26041;&#27861;&#26469;&#20943;&#36731;&#36825;&#31181;&#23884;&#22871;&#24490;&#29615;&#32467;&#26500;&#30340;&#35745;&#31639;&#36127;&#25285;&#65292;&#20294;&#24403;&#29366;&#24577;&#31354;&#38388;&#35201;&#20040;&#26159;&#20855;&#26377;&#22823;&#22522;&#25968;&#30340;&#31163;&#25955;&#31354;&#38388;&#65292;&#35201;&#20040;&#26159;&#39640;&#32500;&#36830;&#32493;&#31354;&#38388;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38754;&#20020;&#39640;&#22797;&#26434;&#24230;&#30340;&#38382;&#39064;&#12290;&#36870;&#24378;&#21270;&#23398;&#20064;(IRL)&#25991;&#29486;&#20013;&#30340;&#20854;&#20182;&#26041;&#27861;&#24378;&#35843;&#31574;&#30053;&#20272;&#35745;&#65292;&#20294;&#21364;&#20197;&#38477;&#20302;&#22870;&#21169;&#20272;&#35745;&#31934;&#24230;&#20026;&#20195;&#20215;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#26377;&#38480;&#26102;&#38388;&#20445;&#35777;&#30340;&#21333;&#24490;&#29615;&#20272;&#35745;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#29366;&#24577;&#31354;&#38388;&#32780;&#19981;&#20250;&#25439;&#23475;&#22870;&#21169;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.01282v3 Announce Type: replace-cross  Abstract: We consider the task of estimating a structural model of dynamic decisions by a human agent based upon the observable history of implemented actions and visited states. This problem has an inherent nested structure: in the inner problem, an optimal policy for a given reward function is identified while in the outer problem, a measure of fit is maximized. Several approaches have been proposed to alleviate the computational burden of this nested-loop structure, but these methods still suffer from high complexity when the state space is either discrete with large cardinality or continuous in high dimensions. Other approaches in the inverse reinforcement learning (IRL) literature emphasize policy estimation at the expense of reduced reward estimation accuracy. In this paper we propose a single-loop estimation algorithm with finite time guarantees that is equipped to deal with high-dimensional state spaces without compromising rewar
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#22312;&#29366;&#24577;&#19981;&#30830;&#23450;&#24615;&#19979;&#21516;&#26102;&#32771;&#34385;&#28608;&#36827;&#21644;&#20445;&#23432;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;</title><link>https://arxiv.org/abs/2007.12315</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Robust Optimization for Imitation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2007.12315
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#22312;&#29366;&#24577;&#19981;&#30830;&#23450;&#24615;&#19979;&#21516;&#26102;&#32771;&#34385;&#28608;&#36827;&#21644;&#20445;&#23432;&#30340;&#31574;&#30053;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#20223;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#30830;&#23450;&#22312;&#28436;&#31034;&#30340;&#29366;&#24577;&#20998;&#24067;&#20043;&#22806;&#26102;&#20195;&#29702;&#24212;&#37319;&#21462;&#20160;&#20040;&#34892;&#21160;&#12290;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;IRL&#65289;&#21487;&#20197;&#36890;&#36807;&#23398;&#20064;&#21442;&#25968;&#21270;&#22870;&#21169;&#20989;&#25968;&#23454;&#29616;&#23545;&#26032;&#29366;&#24577;&#30340;&#27867;&#21270;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38754;&#20020;&#23545;&#30495;&#23454;&#22870;&#21169;&#20989;&#25968;&#21644;&#30456;&#24212;&#26368;&#20248;&#31574;&#30053;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#29616;&#26377;&#22522;&#20110;IRL&#30340;&#23433;&#20840;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#20351;&#29992;maxmin&#26694;&#26550;&#22788;&#29702;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#35813;&#26694;&#26550;&#22312;&#20551;&#35774;&#26377;&#19968;&#20010;&#23545;&#25239;&#24615;&#22870;&#21169;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#31574;&#30053;&#65292;&#32780;&#39118;&#38505;&#20013;&#31435;&#30340;IRL&#26041;&#27861;&#21017;&#20248;&#21270;&#22343;&#20540;&#25110;MAP&#22870;&#21169;&#20989;&#25968;&#30340;&#31574;&#30053;&#12290;&#23436;&#20840;&#24573;&#35270;&#39118;&#38505;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#20110;&#28608;&#36827;&#21644;&#19981;&#23433;&#20840;&#30340;&#31574;&#30053;&#65292;&#32780;&#23436;&#20840;&#20197;&#23545;&#25239;&#24615;&#26041;&#24335;&#20248;&#21270;&#20063;&#26159;&#26377;&#38382;&#39064;&#30340;&#65292;&#22240;&#20026;&#23427;&#21487;&#33021;&#23548;&#33268;&#34920;&#29616;&#19981;&#20339;&#30340;&#36807;&#24230;&#20445;&#23432;&#31574;&#30053;&#12290;&#20026;&#20102;&#22312;&#36825;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#24314;&#31435;&#26725;&#26753;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#40065;&#26834;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#29366;&#24577;&#30340;&#32622;&#20449;&#21306;&#38388;&#20869;&#23545;&#31574;&#30053;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2007.12315v4 Announce Type: replace  Abstract: One of the main challenges in imitation learning is determining what action an agent should take when outside the state distribution of the demonstrations. Inverse reinforcement learning (IRL) can enable generalization to new states by learning a parameterized reward function, but these approaches still face uncertainty over the true reward function and corresponding optimal policy. Existing safe imitation learning approaches based on IRL deal with this uncertainty using a maxmin framework that optimizes a policy under the assumption of an adversarial reward function, whereas risk-neutral IRL approaches either optimize a policy for the mean or MAP reward function. While completely ignoring risk can lead to overly aggressive and unsafe policies, optimizing in a fully adversarial sense is also problematic as it can lead to overly conservative policies that perform poorly in practice. To provide a bridge between these two extremes, we p
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35774;&#35745;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#19982;&#25511;&#21046;&#65292;Symplectic ODE-Net (SymODEN)&#21487;&#20197;&#36879;&#26126;&#22320;&#23398;&#20064;&#28508;&#22312;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#25581;&#31034;&#31995;&#32479;&#30340;&#30456;&#20851;&#29289;&#29702;&#26041;&#38754;&#12290;</title><link>https://arxiv.org/abs/1909.12077</link><description>&lt;p&gt;
Symplectic ODE-Net: &#20351;&#29992;&#25511;&#21046;&#23398;&#20064;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Symplectic ODE-Net: Learning Hamiltonian Dynamics with Control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1909.12077
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35774;&#35745;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#19982;&#25511;&#21046;&#65292;Symplectic ODE-Net (SymODEN)&#21487;&#20197;&#36879;&#26126;&#22320;&#23398;&#20064;&#28508;&#22312;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#25581;&#31034;&#31995;&#32479;&#30340;&#30456;&#20851;&#29289;&#29702;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Symplectic ODE-Net&#65288;SymODEN&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#35266;&#27979;&#21040;&#30340;&#29366;&#24577;&#36712;&#36857;&#20013;&#25512;&#26029;&#20986;&#30001;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#32473;&#23450;&#30340;&#29289;&#29702;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#12290;&#20026;&#20102;&#22312;&#26356;&#23569;&#30340;&#35757;&#32451;&#26679;&#26412;&#19978;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#65292;SymODEN&#36890;&#36807;&#20197;&#29289;&#29702;&#20026;&#22522;&#30784;&#30340;&#26041;&#24335;&#35774;&#35745;&#30456;&#20851;&#30340;&#35745;&#31639;&#22270;&#65292;&#24341;&#20837;&#36866;&#24403;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#19982;&#25511;&#21046;&#20197;&#36879;&#26126;&#30340;&#26041;&#24335;&#23398;&#20064;&#28508;&#22312;&#21160;&#21147;&#23398;&#65292;&#20174;&#32780;&#21487;&#20197;&#21033;&#29992;&#36825;&#31181;&#21160;&#21147;&#23398;&#26469;&#25581;&#31034;&#31995;&#32479;&#30340;&#30456;&#20851;&#29289;&#29702;&#26041;&#38754;&#65292;&#22914;&#36136;&#37327;&#21644;&#21183;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#24191;&#20041;&#22352;&#26631;&#25968;&#25454;&#23884;&#20837;&#21040;&#39640;&#32500;&#31354;&#38388;&#25110;&#32773;&#21482;&#33021;&#35775;&#38382;&#36895;&#24230;&#25968;&#25454;&#32780;&#19981;&#26159;&#24191;&#20041;&#21160;&#37327;&#26102;&#65292;&#20063;&#33021;&#24378;&#21046;&#25191;&#34892;&#36825;&#31181;&#21704;&#23494;&#39039;&#24418;&#24335;&#12290;&#36825;&#19968;&#26694;&#26550;&#36890;&#36807;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#12289;&#19982;&#29289;&#29702;&#19968;&#33268;&#30340;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
arXiv:1909.12077v5 Announce Type: replace  Abstract: In this paper, we introduce Symplectic ODE-Net (SymODEN), a deep learning framework which can infer the dynamics of a physical system, given by an ordinary differential equation (ODE), from observed state trajectories. To achieve better generalization with fewer training samples, SymODEN incorporates appropriate inductive bias by designing the associated computation graph in a physics-informed manner. In particular, we enforce Hamiltonian dynamics with control to learn the underlying dynamics in a transparent way, which can then be leveraged to draw insight about relevant physical aspects of the system, such as mass and potential energy. In addition, we propose a parametrization which can enforce this Hamiltonian formalism even when the generalized coordinate data is embedded in a high-dimensional space or we can only access velocity data instead of generalized momentum. This framework, by offering interpretable, physically-consisten
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26641;&#24230;&#37327;&#26377;&#22122;&#22768;&#30340;&#20248;&#21270;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#24212;&#29992;&#20013;&#26641;&#32467;&#26500;&#25200;&#21160;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.13653</link><description>&lt;p&gt;
&#37319;&#29992;&#26377;&#22122;&#22768;&#26641;&#24230;&#37327;&#30340;&#20248;&#21270;&#20256;&#36755;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Transport for Measures with Noisy Tree Metric. (arXiv:2310.13653v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13653
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26641;&#24230;&#37327;&#26377;&#22122;&#22768;&#30340;&#20248;&#21270;&#20256;&#36755;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#24212;&#29992;&#20013;&#26641;&#32467;&#26500;&#25200;&#21160;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#26641;&#24230;&#37327;&#31354;&#38388;&#19978;&#25903;&#25345;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#20248;&#21270;&#20256;&#36755;&#65288;OT&#65289;&#38382;&#39064;&#12290;&#24050;&#30693;&#36825;&#31181;OT&#38382;&#39064;&#65288;&#21363;&#26641;-&#29926;&#29926;&#26031;&#22374;&#65288;TW&#65289;&#65289;&#20855;&#26377;&#38381;&#21512;&#24418;&#24335;&#34920;&#36798;&#24335;&#65292;&#20294;&#22522;&#26412;&#19978;&#21462;&#20915;&#20110;&#36755;&#20837;&#27979;&#24230;&#25903;&#25345;&#19978;&#30340;&#24213;&#23618;&#26641;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#25805;&#20316;&#20013;&#65292;&#30001;&#20110;&#22122;&#22768;&#25110;&#23545;&#25239;&#24615;&#27979;&#37327;&#65292;&#32473;&#23450;&#30340;&#26641;&#32467;&#26500;&#21487;&#33021;&#20250;&#34987;&#25200;&#21160;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#26368;&#22823;-&#26368;&#23567;&#40065;&#26834;OT&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32771;&#34385;&#20102;&#22312;&#19968;&#20010;&#26641;&#24230;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#19978;&#20004;&#20010;&#36755;&#20837;&#27979;&#24230;&#20043;&#38388;&#30340;&#26368;&#22823;&#21487;&#33021;&#36317;&#31163;&#12290;&#24635;&#20307;&#19978;&#35828;&#65292;&#30001;&#20110;&#20854;&#38750;&#20984;&#24615;&#21644;&#38750;&#20809;&#28369;&#24615;&#65292;&#36825;&#31181;&#26041;&#27861;&#24456;&#38590;&#35745;&#31639;&#65292;&#21363;&#20415;&#26159;&#22312;&#25903;&#25345;&#20026;1&#32500;&#31354;&#38388;&#30340;&#27979;&#24230;&#24773;&#20917;&#19979;&#65292;&#36825;&#22952;&#30861;&#20102;&#23427;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#22312;&#22823;&#35268;&#27169;&#24773;&#26223;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36793;&#32536;&#21024;&#38500;/&#28155;&#21152;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26641;&#24230;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#65292;&#36825;&#20010;&#38598;&#21512;&#22312;&#19968;&#20010;&#20248;&#38597;&#30340;&#26694;&#26550;&#19979;&#28085;&#30422;&#20102;&#22810;&#26679;&#30340;&#26641;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study optimal transport (OT) problem for probability measures supported on a tree metric space. It is known that such OT problem (i.e., tree-Wasserstein (TW)) admits a closed-form expression, but depends fundamentally on the underlying tree structure over supports of input measures. In practice, the given tree structure may be, however, perturbed due to noisy or adversarial measurements. In order to mitigate this issue, we follow the max-min robust OT approach which considers the maximal possible distances between two input measures over an uncertainty set of tree metrics. In general, this approach is hard to compute, even for measures supported in $1$-dimensional space, due to its non-convexity and non-smoothness which hinders its practical applications, especially for large-scale settings. In this work, we propose \emph{novel uncertainty sets of tree metrics} from the lens of edge deletion/addition which covers a diversity of tree structures in an elegant framework. Consequently, 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.11143</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#30340;&#24503;&#22269;&#39640;&#20998;&#36776;&#29575;&#23460;&#20869;&#27681;&#27668;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model. (arXiv:2310.11143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23460;&#20869;&#27681;&#27668;&#26159;&#19968;&#31181;&#33268;&#30284;&#30340;&#25918;&#23556;&#24615;&#27668;&#20307;&#65292;&#21487;&#20197;&#22312;&#23460;&#20869;&#31215;&#32047;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#23460;&#20869;&#27681;&#26292;&#38706;&#26159;&#22522;&#20110;&#24191;&#27867;&#30340;&#27979;&#37327;&#27963;&#21160;&#20272;&#35745;&#24471;&#26469;&#30340;&#12290;&#28982;&#32780;&#65292;&#26679;&#26412;&#30340;&#29305;&#24449;&#24448;&#24448;&#19982;&#20154;&#21475;&#29305;&#24449;&#19981;&#21516;&#65292;&#36825;&#26159;&#30001;&#20110;&#35768;&#22810;&#30456;&#20851;&#22240;&#32032;&#65292;&#22914;&#22320;&#36136;&#28304;&#27681;&#27668;&#30340;&#21487;&#29992;&#24615;&#25110;&#27004;&#23618;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#22823;&#23567;&#36890;&#24120;&#19981;&#20801;&#35768;&#20197;&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#36827;&#34892;&#26292;&#38706;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#27604;&#32431;&#25968;&#25454;&#26041;&#27861;&#26356;&#21152;&#29616;&#23454;&#22320;&#20272;&#35745;&#23460;&#20869;&#27681;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#38454;&#27573;&#24314;&#27169;&#26041;&#27861;&#65306;1&#65289;&#24212;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65292;&#20351;&#29992;&#29615;&#22659;&#21644;&#24314;&#31569;&#25968;&#25454;&#20316;&#20026;&#39044;&#27979;&#22240;&#23376;&#65292;&#20272;&#35745;&#20102;&#24503;&#22269;&#27599;&#20010;&#20303;&#23429;&#27004;&#30340;&#27599;&#20010;&#27004;&#23618;&#30340;&#23460;&#20869;&#27681;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#65307;2&#65289;&#20351;&#29992;&#27010;&#29575;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#25216;&#26415;&#20351;&#23427;&#20204;&#32452;&#21512;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65292;&#36890;&#36807;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;&#65292;&#20351;&#29992;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#65292;&#20174;&#32780;&#29983;&#25104;&#24615;&#33021;&#26356;&#22909;&#30340;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2310.02304</link><description>&lt;p&gt;
&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65306;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#23398;&#20248;&#21270;&#22120;&#65288;STOP&#65289;&#65292;&#36890;&#36807;&#36882;&#24402;&#33258;&#25105;&#25913;&#36827;&#30340;&#20195;&#30721;&#29983;&#25104;&#65292;&#20351;&#29992;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#65292;&#20174;&#32780;&#29983;&#25104;&#24615;&#33021;&#26356;&#22909;&#30340;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65288;&#20363;&#22914;&#24605;&#32500;&#26641;&#21644;&#31243;&#24207;&#36741;&#21161;&#35821;&#35328;&#27169;&#22411;&#65289;&#21462;&#24471;&#20102;&#19968;&#20123;&#37325;&#35201;&#36827;&#23637;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#8220;&#33050;&#25163;&#26550;&#8221;&#31243;&#24207;&#26469;&#35299;&#20915;&#38382;&#39064;&#65292;&#35813;&#31243;&#24207;&#26500;&#24314;&#20102;&#22810;&#27425;&#35843;&#29992;&#35821;&#35328;&#27169;&#22411;&#20197;&#29983;&#25104;&#26356;&#22909;&#30340;&#36755;&#20986;&#12290;&#33050;&#25163;&#26550;&#31243;&#24207;&#36890;&#24120;&#20351;&#29992;Python&#31561;&#32534;&#31243;&#35821;&#35328;&#32534;&#20889;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#34701;&#21512;&#20102;&#35821;&#35328;&#27169;&#22411;&#30340;&#33050;&#25163;&#26550;&#31243;&#24207;&#26469;&#25913;&#36827;&#33258;&#36523;&#12290;&#25105;&#20204;&#20174;&#19968;&#20010;&#31181;&#23376;&#8220;&#25913;&#36827;&#22120;&#8221;&#24320;&#22987;&#65292;&#36890;&#36807;&#22810;&#27425;&#26597;&#35810;&#35821;&#35328;&#27169;&#22411;&#24182;&#36820;&#22238;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#65292;&#26681;&#25454;&#32473;&#23450;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#25913;&#36827;&#36755;&#20837;&#31243;&#24207;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36816;&#34892;&#36825;&#20010;&#31181;&#23376;&#25913;&#36827;&#22120;&#26469;&#25913;&#36827;&#33258;&#36523;&#12290;&#22312;&#19968;&#31995;&#21015;&#32454;&#20998;&#20219;&#21153;&#20013;&#65292;&#24471;&#21040;&#30340;&#25913;&#36827;&#25913;&#36827;&#22120;&#29983;&#25104;&#30340;&#31243;&#24207;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#31181;&#23376;&#25913;&#36827;&#22120;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#23545;&#35821;&#35328;&#27169;&#22411;&#25552;&#20986;&#30340;&#21508;&#31181;&#33258;&#25105;&#25913;&#36827;&#31574;&#30053;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21253;&#25324;&#27874;&#26463;&#25628;&#32034;&#12289;&#36951;&#20256;&#31639;&#27861;&#21644;&#27169;&#25311;&#36864;&#28779;&#12290;&#30001;&#20110;&#35821;&#35328;&#27169;&#22411;&#26412;&#36523;&#27809;&#26377;&#25913;&#21464;&#65292;&#36825;&#24182;&#19981;&#26159;&#19968;&#31181;&#22686;&#38271;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a "scaffolding" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not fu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#32593;&#32476;&#20197;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#24418;&#24335;&#21021;&#22987;&#21270;&#21518;&#65292;&#36825;&#31181;&#31163;&#25955;&#21270;&#23558;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2309.01213</link><description>&lt;p&gt;
&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#19982;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Implicit regularization of deep residual networks towards neural ODEs. (arXiv:2309.01213v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#32593;&#32476;&#20197;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#24418;&#24335;&#21021;&#22987;&#21270;&#21518;&#65292;&#36825;&#31181;&#31163;&#25955;&#21270;&#23558;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#26159;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#23427;&#20204;&#30340;&#36830;&#32493;&#28145;&#24230;&#27169;&#25311;&#31216;&#20026;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#65292;&#20063;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#23613;&#31649;&#23427;&#20204;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#31163;&#25955;&#27169;&#22411;&#19982;&#36830;&#32493;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#20173;&#32570;&#20047;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#38024;&#23545;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#38750;&#32447;&#24615;&#32593;&#32476;&#30340;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#21521;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#26469;&#26397;&#30528;&#36825;&#20010;&#26041;&#21521;&#36808;&#20986;&#20102;&#19968;&#27493;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#32593;&#32476;&#30340;&#21021;&#22987;&#21270;&#26159;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#31163;&#25955;&#21270;&#65292;&#21017;&#36825;&#31181;&#31163;&#25955;&#21270;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20445;&#25345;&#19981;&#21464;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#20110;&#26377;&#38480;&#30340;&#35757;&#32451;&#26102;&#38388;&#21644;&#35757;&#32451;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#37117;&#25104;&#31435;&#65292;&#21482;&#35201;&#32593;&#32476;&#28385;&#36275;Polyak-Lojasiewicz&#26465;&#20214;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20010;&#26465;&#20214;&#36866;&#29992;&#20110;&#19968;&#20010;&#27531;&#24046;&#32593;&#32476;&#23478;&#26063;&#65292;&#20854;&#20013;&#27531;&#24046;&#26159;&#20004;&#23618;&#24863;&#30693;&#26426;&#65292;&#22312;&#23485;&#24230;&#19978;&#21482;&#26159;&#32447;&#24615;&#36229;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#26263;&#31034;&#20102;&#26799;&#24230;&#27969;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Residual neural networks are state-of-the-art deep learning models. Their continuous-depth analog, neural ordinary differential equations (ODEs), are also widely used. Despite their success, the link between the discrete and continuous models still lacks a solid mathematical foundation. In this article, we take a step in this direction by establishing an implicit regularization of deep residual networks towards neural ODEs, for nonlinear networks trained with gradient flow. We prove that if the network is initialized as a discretization of a neural ODE, then such a discretization holds throughout training. Our results are valid for a finite training time, and also as the training time tends to infinity provided that the network satisfies a Polyak-Lojasiewicz condition. Importantly, this condition holds for a family of residual networks where the residuals are two-layer perceptrons with an overparameterization in width that is only linear, and implies the convergence of gradient flow to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#22312;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#30340;&#24615;&#33021;&#65292;&#24182;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2308.02918</link><description>&lt;p&gt;
&#22522;&#20110;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#30340;&#20809;&#35889;&#25490;&#21517;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Spectral Ranking Inferences based on General Multiway Comparisons. (arXiv:2308.02918v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#22312;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#30340;&#24615;&#33021;&#65292;&#24182;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#38750;&#24120;&#26222;&#36941;&#21644;&#26356;&#21152;&#30495;&#23454;&#30340;&#24773;&#26223;&#20013;&#65292;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#23545;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#36827;&#34892;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27604;&#36739;&#22270;&#30001;&#21487;&#33021;&#20855;&#26377;&#24322;&#26500;&#22823;&#23567;&#30340;&#36229;&#36793;&#32452;&#25104;&#65292;&#23545;&#20110;&#32473;&#23450;&#30340;&#36229;&#36793;&#65292;&#27604;&#36739;&#25968;&#37327;&#21487;&#33021;&#20165;&#20026;1&#12290;&#36825;&#31181;&#35774;&#32622;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#25351;&#23450;&#22270;&#30340;&#38543;&#26426;&#24615;&#20197;&#21450;&#22312;&#24120;&#29992;&#30340;Bradley-Terry-Luce (BTL)&#25110;Plackett-Luce (PL)&#27169;&#22411;&#20013;&#26045;&#21152;&#30340;&#38480;&#21046;&#24615;&#22343;&#21248;&#37319;&#26679;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#22312;&#36866;&#29992;BTL&#25110;PL&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65288;MLE&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#24212;&#29992;&#20174;&#31561;&#26435;&#37325;&#20256;&#32479;&#20809;&#35889;&#26041;&#27861;&#20272;&#35745;&#24471;&#21040;&#30340;&#26368;&#20339;&#21152;&#26435;&#65292;&#21487;&#20197;&#23454;&#29616;&#19982;MLE&#30456;&#21516;&#30340;&#28176;&#36817;&#25928;&#29575;&#30340;&#21452;&#27493;&#20809;&#35889;&#26041;&#27861;&#12290;&#32771;&#34385;&#21040;&#28176;&#36817;&#24773;&#20917;&#65292;
&lt;/p&gt;
&lt;p&gt;
This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a very general and more realistic setup in which the comparison graph consists of hyper-edges of possible heterogeneous sizes and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in the scenarios when the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptot
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35889;&#27969;&#24418;&#23545;&#40784;&#21644;&#25512;&#26029;&#65288;SMAI&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#26469;&#30830;&#23450;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#36991;&#20813;&#35823;&#23548;&#24615;&#25512;&#26029;&#65292;&#24182;&#20445;&#25345;&#25968;&#25454;&#25972;&#21512;&#30340;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.01839</link><description>&lt;p&gt;
&#24744;&#30340;&#25968;&#25454;&#21487;&#23545;&#40784;&#21527;&#65311;&#22522;&#20110;&#21407;&#21017;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#21333;&#32454;&#32990;&#25968;&#25454;&#23545;&#40784;&#24615;&#27979;&#35797;&#21644;&#25972;&#21512;
&lt;/p&gt;
&lt;p&gt;
Is your data alignable? Principled and interpretable alignability testing and integration of single-cell data. (arXiv:2308.01839v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35889;&#27969;&#24418;&#23545;&#40784;&#21644;&#25512;&#26029;&#65288;SMAI&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#26469;&#30830;&#23450;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#36991;&#20813;&#35823;&#23548;&#24615;&#25512;&#26029;&#65292;&#24182;&#20445;&#25345;&#25968;&#25454;&#25972;&#21512;&#30340;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#32454;&#32990;&#25968;&#25454;&#25972;&#21512;&#21487;&#20197;&#25552;&#20379;&#32454;&#32990;&#30340;&#20840;&#38754;&#20998;&#23376;&#35270;&#22270;&#65292;&#24182;&#19988;&#24050;&#32463;&#24320;&#21457;&#20986;&#35768;&#22810;&#31639;&#27861;&#26469;&#28040;&#38500;&#19981;&#38656;&#35201;&#30340;&#25216;&#26415;&#25110;&#29983;&#29289;&#21464;&#24322;&#65292;&#24182;&#25972;&#21512;&#24322;&#36136;&#30340;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#22522;&#26412;&#38480;&#21046;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#32570;&#20047;&#19968;&#31181;&#20005;&#35880;&#30340;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#21028;&#26029;&#20004;&#20010;&#39640;&#32500;&#21333;&#32454;&#32990;&#25968;&#25454;&#38598;&#26159;&#21542;&#21487;&#20197;&#23545;&#40784;&#65288;&#22240;&#27492;&#26159;&#21542;&#24212;&#35813;&#36827;&#34892;&#23545;&#40784;&#65289;&#12290;&#27492;&#22806;&#65292;&#27969;&#34892;&#30340;&#26041;&#27861;&#22312;&#23545;&#40784;&#36807;&#31243;&#20013;&#21487;&#33021;&#20250;&#26126;&#26174;&#30072;&#21464;&#25968;&#25454;&#65292;&#20351;&#24471;&#23545;&#40784;&#21518;&#30340;&#25968;&#25454;&#21644;&#19979;&#28216;&#20998;&#26512;&#38590;&#20197;&#35299;&#37322;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#27969;&#24418;&#23545;&#40784;&#21644;&#25512;&#26029;&#65288;SMAI&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#23454;&#29616;&#22522;&#20110;&#21407;&#21017;&#21644;&#21487;&#35299;&#37322;&#30340;&#21333;&#32454;&#32990;&#25968;&#25454;&#23545;&#40784;&#24615;&#27979;&#35797;&#21644;&#20445;&#25345;&#32467;&#26500;&#30340;&#25972;&#21512;&#12290;SMAI&#25552;&#20379;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#33021;&#22815;&#31283;&#20581;&#22320;&#30830;&#23450;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#20197;&#36991;&#20813;&#35823;&#23548;&#24615;&#25512;&#26029;&#65292;&#21516;&#26102;&#20854;&#26041;&#27861;&#20063;&#32463;&#36807;&#20102;&#39640;&#32500;&#25968;&#25454;&#30340;&#27491;&#24403;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Single-cell data integration can provide a comprehensive molecular view of cells, and many algorithms have been developed to remove unwanted technical or biological variations and integrate heterogeneous single-cell datasets. Despite their wide usage, existing methods suffer from several fundamental limitations. In particular, we lack a rigorous statistical test for whether two high-dimensional single-cell datasets are alignable (and therefore should even be aligned). Moreover, popular methods can substantially distort the data during alignment, making the aligned data and downstream analysis difficult to interpret. To overcome these limitations, we present a spectral manifold alignment and inference (SMAI) framework, which enables principled and interpretable alignability testing and structure-preserving integration of single-cell data. SMAI provides a statistical test to robustly determine the alignability between datasets to avoid misleading inference, and is justified by high-dimen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;CLIP&#27169;&#22411;&#65288;Dp-CLIP&#65289;&#65292;&#26088;&#22312;&#20445;&#25252;&#22810;&#27169;&#24577;AI&#20219;&#21153;&#20013;&#30340;&#25968;&#25454;&#38544;&#31169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#34920;&#26126;&#20854;&#19982;&#26631;&#20934;&#38750;&#31169;&#26377;CLIP&#27169;&#22411;&#30456;&#27604;&#20855;&#26377;&#21516;&#31561;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.08173</link><description>&lt;p&gt;
&#22312;&#22810;&#27169;&#24577;&#20154;&#24037;&#26234;&#33021;&#20013;&#20445;&#25252;&#25968;&#25454;&#65306;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#29992;&#20110;CLIP&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training. (arXiv:2306.08173v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;CLIP&#27169;&#22411;&#65288;Dp-CLIP&#65289;&#65292;&#26088;&#22312;&#20445;&#25252;&#22810;&#27169;&#24577;AI&#20219;&#21153;&#20013;&#30340;&#25968;&#25454;&#38544;&#31169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#34920;&#26126;&#20854;&#19982;&#26631;&#20934;&#38750;&#31169;&#26377;CLIP&#27169;&#22411;&#30456;&#27604;&#20855;&#26377;&#21516;&#31561;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#20154;&#24037;&#26234;&#33021;&#30340;&#25104;&#21151;&#24341;&#21457;&#20102;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#20013;&#25968;&#25454;&#38544;&#31169;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;CLIP&#36890;&#36807;&#23545;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#32852;&#21512;&#35757;&#32451;&#24443;&#24213;&#25913;&#21464;&#20102;&#22810;&#27169;&#24577;&#23398;&#20064;&#65292;&#20294;&#20854;&#21487;&#33021;&#26080;&#24847;&#20013;&#25259;&#38706;&#25935;&#24863;&#20449;&#24687;&#30340;&#28508;&#21147;&#38656;&#35201;&#38598;&#25104;&#20445;&#25252;&#38544;&#31169;&#30340;&#26426;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#65288;CLIP&#65289;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#25913;&#36827;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#38544;&#31169;&#38382;&#39064;&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;Dp-CLIP&#22312;&#21253;&#25324;&#22270;&#20687;&#20998;&#31867;&#21644;&#35270;&#35273;&#38382;&#31572;&#31561;&#22810;&#26679;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#35780;&#20272;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#25345;&#20102;&#19982;&#26631;&#20934;&#30340;&#38750;&#31169;&#26377;CLIP&#27169;&#22411;&#21516;&#31561;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#32447;&#24615;&#34920;&#31034;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#26799;&#24230;&#34987;&#21098;&#36753;&#26102;&#23454;&#29992;&#24615;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
The surge in multimodal AI's success has sparked concerns over data privacy in vision-and-language tasks. While CLIP has revolutionized multimodal learning through joint training on images and text, its potential to unintentionally disclose sensitive information necessitates the integration of privacy-preserving mechanisms. We introduce a differentially private adaptation of the Contrastive Language-Image Pretraining (CLIP) model that effectively addresses privacy concerns while retaining accuracy. Our proposed method, Dp-CLIP, is rigorously evaluated on benchmark datasets encompassing diverse vision-and-language tasks such as image classification and visual question answering. We demonstrate that our approach retains performance on par with the standard non-private CLIP model. Furthermore, we analyze our proposed algorithm under linear representation settings. We derive the convergence rate of our algorithm and show a trade-off between utility and privacy when gradients are clipped pe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;</title><link>http://arxiv.org/abs/2306.03303</link><description>&lt;p&gt;
&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#21151;&#33021;&#24615;&#36755;&#20837;&#26144;&#23556;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#25152;&#35859;&#30340;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#23450;&#20041;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#65292;&#20854;&#20540;&#20063;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21152;&#24615;&#26063;&#20316;&#20026;&#38544;&#34255;&#23618;&#26144;&#23556;&#65292;&#20197;&#21450;&#19968;&#20010;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#24212;&#29992;&#20110;&#27599;&#20010;&#38544;&#34255;&#23618;&#12290;&#20381;&#38752;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#30340;Stone-Weierstrass&#23450;&#29702;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#65292;&#36229;&#36234;&#20102;&#24120;&#35268;&#32039;&#38598;&#36924;&#36817;&#12290;&#36825;&#29305;&#21035;&#36866;&#29992;&#20110;&#36890;&#36807;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65288;&#38750;&#20808;&#35265;&#20043;&#26126;&#30340;&#65289;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#12290;&#20316;&#20026;&#24102;&#26435;Stone-Weierstrass&#23450;&#29702;&#30340;&#36827;&#19968;&#27493;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#24341;&#20837;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#31614;&#21517;&#20869;&#26680;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26159;&#26576;&#20123;&#39640;&#26031;&#36807;&#31243;&#30340;Cameron-Martin&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20108;&#20998;&#20998;&#31867;&#20013;&#25552;&#20379;&#36861;&#32034;&#26435;&#20250;&#22686;&#21152;&#38169;&#35823;&#29575;&#65292;&#23548;&#33268;&#26356;&#22810;&#38169;&#35823;&#30340;&#21457;&#29983;&#12290;&#25552;&#20379;&#31639;&#27861;&#36861;&#32034;&#26435;&#21487;&#33021;&#20063;&#20250;&#22312;&#31995;&#32479;&#32423;&#21035;&#19978;&#32473;&#20104;&#19981;&#21033;&#12290;</title><link>http://arxiv.org/abs/2306.00497</link><description>&lt;p&gt;
&#20108;&#20998;&#20998;&#31867;&#20013;&#36861;&#32034;&#26435;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The Risks of Recourse in Binary Classification. (arXiv:2306.00497v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00497
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20108;&#20998;&#20998;&#31867;&#20013;&#25552;&#20379;&#36861;&#32034;&#26435;&#20250;&#22686;&#21152;&#38169;&#35823;&#29575;&#65292;&#23548;&#33268;&#26356;&#22810;&#38169;&#35823;&#30340;&#21457;&#29983;&#12290;&#25552;&#20379;&#31639;&#27861;&#36861;&#32034;&#26435;&#21487;&#33021;&#20063;&#20250;&#22312;&#31995;&#32479;&#32423;&#21035;&#19978;&#32473;&#20104;&#19981;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#36861;&#32034;&#26435;&#25552;&#20379;&#35299;&#37322;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25512;&#32763;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#19981;&#21033;&#20915;&#31574;&#12290;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#24456;&#23569;&#26377;&#20154;&#20851;&#27880;&#25552;&#20379;&#36861;&#32034;&#26435;&#26159;&#21542;&#26377;&#30410;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#25277;&#35937;&#30340;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#65292;&#27604;&#36739;&#20102;&#20855;&#26377;&#21644;&#27809;&#26377;&#31639;&#27861;&#36861;&#32034;&#26435;&#30340;&#20998;&#31867;&#30340;&#39118;&#38505;&#65288;&#21363;&#26399;&#26395;&#25439;&#22833;&#65289;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22238;&#31572;&#22312;&#25972;&#20010;&#20154;&#32676;&#27700;&#24179;&#19978;&#25552;&#20379;&#36861;&#32034;&#26435;&#20309;&#26102;&#26377;&#30410;&#25110;&#26377;&#23475;&#30340;&#38382;&#39064;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#35768;&#22810;&#21487;&#20449;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#36861;&#32034;&#26435;&#21453;&#32780;&#20250;&#26377;&#23475;&#65292;&#22240;&#20026;&#23427;&#23558;&#29992;&#25143;&#25512;&#21521;&#26356;&#39640;&#31867;&#21035;&#19981;&#30830;&#23450;&#24615;&#30340;&#21306;&#22495;&#65292;&#22240;&#27492;&#20250;&#23548;&#33268;&#26356;&#22810;&#30340;&#38169;&#35823;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#37096;&#32626;&#20998;&#31867;&#22120;&#30340;&#19968;&#26041;&#26159;&#21542;&#26377;&#21160;&#26426;&#38024;&#23545;&#25552;&#20379;&#36861;&#32034;&#26435;&#30340;&#24773;&#20917;&#36827;&#34892;&#31574;&#30053;&#35268;&#21010;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#26102;&#20505;&#30830;&#23454;&#23384;&#22312;&#36825;&#31181;&#29616;&#35937;&#65292;&#36825;&#23545;&#20182;&#20204;&#30340;&#29992;&#25143;&#19981;&#21033;&#12290;&#22240;&#27492;&#65292;&#25552;&#20379;&#31639;&#27861;&#36861;&#32034;&#26435;&#22312;&#31995;&#32479;&#32423;&#21035;&#19978;&#21487;&#33021;&#20063;&#26159;&#26377;&#23475;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e. expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#24179;&#28369;&#22270;&#20449;&#21495;&#20998;&#24067;&#31354;&#38388;&#20013;&#23884;&#20837;&#22270;&#26469;&#23450;&#20041;&#22270;&#30340;&#24179;&#22343;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;Wasserstein&#24230;&#37327;&#34913;&#37327;&#22270;&#30456;&#20284;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.19738</link><description>&lt;p&gt;
&#22270;&#30340;Bures-Wasserstein&#24179;&#22343;&#20540;
&lt;/p&gt;
&lt;p&gt;
Bures-Wasserstein Means of Graphs. (arXiv:2305.19738v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19738
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#24179;&#28369;&#22270;&#20449;&#21495;&#20998;&#24067;&#31354;&#38388;&#20013;&#23884;&#20837;&#22270;&#26469;&#23450;&#20041;&#22270;&#30340;&#24179;&#22343;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;Wasserstein&#24230;&#37327;&#34913;&#37327;&#22270;&#30456;&#20284;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#65292;&#25214;&#21040;&#37319;&#26679;&#25968;&#25454;&#30340;&#24179;&#22343;&#20540;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22312;&#25968;&#25454;&#26679;&#26412;&#20026;&#22270;&#23545;&#35937;&#30340;&#24773;&#20917;&#19979;&#65292;&#23450;&#20041;&#24179;&#22343;&#20540;&#26159;&#19968;&#39033;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#24179;&#28369;&#22270;&#20449;&#21495;&#20998;&#24067;&#31354;&#38388;&#20013;&#23884;&#20837;&#22270;&#26469;&#23450;&#20041;&#22270;&#30340;&#24179;&#22343;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;Wasserstein&#24230;&#37327;&#34913;&#37327;&#22270;&#30456;&#20284;&#24615;&#12290;&#36890;&#36807;&#22312;&#27492;&#23884;&#20837;&#31354;&#38388;&#20013;&#25214;&#21040;&#24179;&#22343;&#20540;&#65292;&#25105;&#20204;&#21487;&#20197;&#24674;&#22797;&#20445;&#30041;&#32467;&#26500;&#20449;&#24687;&#30340;&#24179;&#22343;&#22270;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26032;&#30340;&#22270;&#24179;&#22343;&#20540;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36845;&#20195;&#31639;&#27861;&#26469;&#35745;&#31639;&#23427;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26694;&#26550;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#32467;&#26500;&#21270;&#22270;&#30340;k-means&#32858;&#31867;&#12289;&#21151;&#33021;&#24615;&#33041;&#32593;&#32476;&#30340;&#20998;&#31867;&#20197;&#21450;&#22810;&#23618;&#22270;&#30340;&#21322;&#30417;&#30563;&#33410;&#28857;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#19968;&#33268;&#30340;p&#12290;
&lt;/p&gt;
&lt;p&gt;
Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent p
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25506;&#35752;&#22312; SGD &#19979;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21333;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#21482;&#20250;&#22686;&#21152;&#19968;&#23450;&#22240;&#23376;&#30340;&#25910;&#25947;&#24615;&#65292;&#19981;&#21516;&#32500;&#24230;&#21644;&#23485;&#24230;&#30340;&#21069;&#32622;&#22240;&#23376;&#31934;&#30830;&#32467;&#26524;&#25581;&#31034;&#12290;</title><link>http://arxiv.org/abs/2305.18502</link><description>&lt;p&gt;
&#36867;&#31163;&#24179;&#24248;&#65306;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#22312; SGD &#19979;&#23398;&#20064;&#22256;&#38590;&#30340;&#21333;&#25351;&#26631;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Escaping mediocrity: how two-layer networks learn hard single-index models with SGD. (arXiv:2305.18502v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18502
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25506;&#35752;&#22312; SGD &#19979;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21333;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#21457;&#29616;&#36807;&#21442;&#25968;&#21270;&#21482;&#20250;&#22686;&#21152;&#19968;&#23450;&#22240;&#23376;&#30340;&#25910;&#25947;&#24615;&#65292;&#19981;&#21516;&#32500;&#24230;&#21644;&#23485;&#24230;&#30340;&#21069;&#32622;&#22240;&#23376;&#31934;&#30830;&#32467;&#26524;&#25581;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#19979;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21333;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#22312;&#21021;&#22987;&#21270;&#26102;&#23384;&#22312;&#35768;&#22810;&#24179;&#22374;&#26041;&#21521;&#30340;&#25361;&#25112;&#24615;&#24773;&#20917;&#12290;&#24050;&#32463;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#24773;&#20917;&#19979;&#36890;&#24120;&#38656;&#35201; $n=O(d\log{d})$ &#20010;&#26679;&#26412;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#24230;&#21644;&#19981;&#21516;&#23485;&#24230;&#24773;&#20917;&#19979;&#30340;&#21069;&#32622;&#22240;&#23376;&#30340;&#31934;&#30830;&#32467;&#26524;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#31867;&#20013;&#65292;&#36807;&#21442;&#25968;&#21270;&#21482;&#20250;&#22686;&#21152;&#19968;&#23450;&#22240;&#23376;&#30340;&#25910;&#25947;&#24615;&#12290;&#36825;&#20123;&#35265;&#35299;&#22522;&#20110; SGD &#21160;&#24577;&#30340;&#20302;&#32500;&#24230;&#38543;&#26426;&#36807;&#31243;&#27169;&#22411;&#65292;&#20854;&#20013;&#36867;&#31163;&#24179;&#24248;&#31561;&#21516;&#20110;&#35745;&#31639;&#20986;&#31449;&#20986;&#26102;&#38388;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#36807;&#31243;&#30340;&#30830;&#23450;&#24615;&#36817;&#20284;&#36275;&#20197;&#20195;&#34920;&#36867;&#36920;&#26102;&#38388;&#65292;&#36825;&#24847;&#21619;&#30528;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38543;&#26426;&#24615;&#30340;&#20316;&#29992;&#21487;&#33021;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study explores the sample complexity for two-layer neural networks to learn a single-index target function under Stochastic Gradient Descent (SGD), focusing on the challenging regime where many flat directions are present at initialization. It is well-established that in this scenario $n=O(d\log{d})$ samples are typically needed. However, we provide precise results concerning the pre-factors in high-dimensional contexts and for varying widths. Notably, our findings suggest that overparameterization can only enhance convergence by a constant factor within this problem class. These insights are grounded in the reduction of SGD dynamics to a stochastic process in lower dimensions, where escaping mediocrity equates to calculating an exit time. Yet, we demonstrate that a deterministic approximation of this process adequately represents the escape time, implying that the role of stochasticity may be minimal in this scenario.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#19968;&#31181;&#22522;&#20110;&#28857;&#31215;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#24179;&#22343;&#28857;&#31215;&#21512;&#24182;&#32858;&#31867;&#65292;&#24182;&#19988;&#36755;&#20986;&#30340;&#26641;&#32467;&#26500;&#21487;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#29983;&#25104;&#23618;&#27425;&#32467;&#26500;&#65292;&#26641;&#24418;&#24674;&#22797;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15022</link><description>&lt;p&gt;
&#22522;&#20110;&#28857;&#31215;&#30340;&#23618;&#27425;&#32858;&#31867;&#21487;&#20197;&#24674;&#22797;&#38544;&#34255;&#30340;&#26641;&#24418;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering with dot products recovers hidden tree structure. (arXiv:2305.15022v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15022
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#19968;&#31181;&#22522;&#20110;&#28857;&#31215;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#24179;&#22343;&#28857;&#31215;&#21512;&#24182;&#32858;&#31867;&#65292;&#24182;&#19988;&#36755;&#20986;&#30340;&#26641;&#32467;&#26500;&#21487;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#29983;&#25104;&#23618;&#27425;&#32467;&#26500;&#65292;&#26641;&#24418;&#24674;&#22797;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#20110;&#24050;&#26377;&#20957;&#32858;&#32858;&#31867;&#31639;&#27861;&#30340;&#26032;&#35270;&#35282;&#65292;&#19987;&#27880;&#20110;&#23618;&#27425;&#32467;&#26500;&#30340;&#24674;&#22797;&#12290;&#25105;&#20204;&#24314;&#35758;&#19968;&#31181;&#31616;&#21333;&#30340;&#26631;&#20934;&#31639;&#27861;&#21464;&#20307;&#65292;&#20854;&#20013;&#32858;&#31867;&#26159;&#36890;&#36807;&#26368;&#22823;&#24179;&#22343;&#28857;&#31215;&#32780;&#19981;&#26159;&#26368;&#23567;&#36317;&#31163;&#25110;&#31751;&#20869;&#26041;&#24046;&#26469;&#21512;&#24182;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#27492;&#31639;&#27861;&#36755;&#20986;&#30340;&#26641;&#21487;&#20197;&#20316;&#20026;&#25968;&#25454;&#29983;&#25104;&#23618;&#27425;&#32467;&#26500;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#20851;&#38190;&#25216;&#26415;&#21019;&#26032;&#22312;&#20110;&#29702;&#35299;&#27169;&#22411;&#20013;&#30340;&#23618;&#27425;&#20449;&#24687;&#22914;&#20309;&#36716;&#21270;&#20026;&#21487;&#20174;&#25968;&#25454;&#20013;&#24674;&#22797;&#30340;&#26641;&#24418;&#20960;&#20309;&#20449;&#24687;&#65292;&#24182;&#21516;&#26102;&#22686;&#38271;&#26679;&#26412;&#22823;&#23567;&#21644;&#25968;&#25454;&#32500;&#25968;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;UPGMA&#12289;Ward's&#26041;&#27861;&#21644;HDBSCAN&#65289;&#30340;&#26641;&#24418;&#24674;&#22797;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we offer a new perspective on the well established agglomerative clustering algorithm, focusing on recovery of hierarchical structure. We recommend a simple variant of the standard algorithm, in which clusters are merged by maximum average dot product and not, for example, by minimum distance or within-cluster variance. We demonstrate that the tree output by this algorithm provides a bona fide estimate of generative hierarchical structure in data, under a generic probabilistic graphical model. The key technical innovations are to understand how hierarchical information in this model translates into tree geometry which can be recovered from data, and to characterise the benefits of simultaneously growing sample size and data dimension. We demonstrate superior tree recovery performance with real data over existing approaches such as UPGMA, Ward's method, and HDBSCAN.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#38656;&#35843;&#21442;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20854;&#20013;&#19968;&#31181;&#26159;&#36890;&#36807;&#32771;&#34385;&#36793;&#32536;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20026;&#33258;&#30001;&#33021;&#27867;&#20989;&#26368;&#23567;&#21270;&#24471;&#21040;&#30340;&#65292;&#21478;&#19968;&#31181;&#26159;&#29992;&#20110;&#20248;&#21270;&#35813;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#12290;</title><link>http://arxiv.org/abs/2305.14916</link><description>&lt;p&gt;
CoinEM&#65306;&#26080;&#38656;&#35843;&#21442;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
CoinEM: Tuning-Free Particle-Based Variational Inference for Latent Variable Models. (arXiv:2305.14916v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#38656;&#35843;&#21442;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20854;&#20013;&#19968;&#31181;&#26159;&#36890;&#36807;&#32771;&#34385;&#36793;&#32536;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20026;&#33258;&#30001;&#33021;&#27867;&#20989;&#26368;&#23567;&#21270;&#24471;&#21040;&#30340;&#65292;&#21478;&#19968;&#31181;&#26159;&#29992;&#20110;&#20248;&#21270;&#35813;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#22522;&#20110;&#31890;&#23376;&#30340;&#26032;&#22411;&#31639;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#36793;&#38469;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#23398;&#20064;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#31181;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#23558;&#36793;&#38469;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35270;&#20026;&#20248;&#21270;&#38382;&#39064;&#30340;&#35282;&#24230;&#65306;&#21363;&#23558;&#20854;&#35270;&#20026;&#33258;&#30001;&#33021;&#27867;&#20989;&#30340;&#26368;&#23567;&#21270;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#32771;&#34385;&#33258;&#30001;&#33021;&#20851;&#32852;&#30340;&#26799;&#24230;&#27969;&#30340;&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#27969;&#34892;&#30340; Stein &#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20026;&#27492;&#31639;&#27861;&#24314;&#31435;&#20102;&#19979;&#38477;&#24341;&#29702;&#65292;&#20445;&#35777;&#20102;&#33258;&#30001;&#33021;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#19979;&#38477;&#12290;&#20294;&#27492;&#26041;&#27861;&#21644;&#20854;&#20182;&#30001;&#26799;&#24230;&#27969;&#30340;&#31163;&#25955;&#21270;&#24471;&#21040;&#30340;&#26041;&#27861;&#37117;&#24517;&#39035;&#20381;&#36182;&#20110;&#23398;&#20064;&#29575;&#65292;&#35813;&#23398;&#20064;&#29575;&#24517;&#39035;&#30001;&#20174;&#19994;&#32773;&#20180;&#32454;&#35843;&#25972;&#65292;&#20197;&#30830;&#20445;&#20197;&#21512;&#36866;&#30340;&#36895;&#29575;&#25910;&#25947;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21478;&#19968;&#31181;&#31639;&#27861;&#29992;&#20110;&#20248;&#21270;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#26159;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is to consider the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of the popular Stein variational gradient descent algorithm. In particular, we establish a descent lemma for this algorithm, which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, will necessarily depend on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#20197;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#24182;&#35299;&#20915;&#20102;&#38480;&#21046;&#24179;&#34913;&#28857;Gram&#30697;&#38453;&#26368;&#23567;&#29305;&#24449;&#20540;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2302.05797</link><description>&lt;p&gt;
&#20855;&#26377;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Global Convergence Rate of Deep Equilibrium Models with General Activations. (arXiv:2302.05797v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05797
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#19968;&#33324;&#28608;&#27963;&#20989;&#25968;&#30340;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#30340;&#20840;&#23616;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#20197;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#24182;&#35299;&#20915;&#20102;&#38480;&#21046;&#24179;&#34913;&#28857;Gram&#30697;&#38453;&#26368;&#23567;&#29305;&#24449;&#20540;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#19968;&#31687;&#35770;&#25991;&#20013;&#65292;Ling&#31561;&#20154;&#30740;&#31350;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#36807;&#21442;&#25968;&#21270;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQ&#65289;&#12290;&#20182;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#20197;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#19968;&#38454;&#21644;&#20108;&#38454;&#23548;&#25968;&#30340;&#28608;&#27963;&#20989;&#25968;&#30340;DEQ&#65292;&#35813;&#20107;&#23454;&#20173;&#28982;&#25104;&#31435;&#12290;&#30001;&#20110;&#26032;&#30340;&#28608;&#27963;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#38480;&#21046;&#24179;&#34913;&#28857;&#30340;Gram&#30697;&#38453;&#30340;&#26368;&#23567;&#29305;&#24449;&#20540;&#23588;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#23436;&#25104;&#36825;&#20010;&#20219;&#21153;&#65292;&#25105;&#20204;&#38656;&#35201;&#21019;&#24314;&#19968;&#20010;&#26032;&#30340;&#24635;&#20307;Gram&#30697;&#38453;&#65292;&#24182;&#24320;&#21457;&#19968;&#31181;&#20855;&#26377;Hermite&#22810;&#39033;&#24335;&#23637;&#24320;&#30340;&#26032;&#24418;&#24335;&#30340;&#21452;&#37325;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a recent paper, Ling et al. investigated the over-parametrized Deep Equilibrium Model (DEQ) with ReLU activation. They proved that the gradient descent converges to a globally optimal solution at a linear convergence rate for the quadratic loss function. This paper shows that this fact still holds for DEQs with any general activation that has bounded first and second derivatives. Since the new activation function is generally non-linear, bounding the least eigenvalue of the Gram matrix of the equilibrium point is particularly challenging. To accomplish this task, we need to create a novel population Gram matrix and develop a new form of dual activation with Hermite polynomial expansion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#38024;&#23545;&#21253;&#21547;&#24322;&#26041;&#24046;&#22870;&#21169;&#22122;&#22768;&#30340;&#31574;&#30053;&#35780;&#20272;&#65292;&#20351;&#29992;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#26032;&#31639;&#27861; SPEED&#65292;&#35813;&#31639;&#27861;&#21487;&#23454;&#29616;&#24102;&#26377;&#22343;&#26041;&#35823;&#24046;&#27604;&#36739;&#23567;&#30340;&#31574;&#30053;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2301.12357</link><description>&lt;p&gt;
SPEED: &#32447;&#24615;&#24322;&#26041;&#24046; Bandit &#31574;&#30053;&#35780;&#20272;&#30340;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits. (arXiv:2301.12357v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#38024;&#23545;&#21253;&#21547;&#24322;&#26041;&#24046;&#22870;&#21169;&#22122;&#22768;&#30340;&#31574;&#30053;&#35780;&#20272;&#65292;&#20351;&#29992;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#26032;&#31639;&#27861; SPEED&#65292;&#35813;&#31639;&#27861;&#21487;&#23454;&#29616;&#24102;&#26377;&#22343;&#26041;&#35823;&#24046;&#27604;&#36739;&#23567;&#30340;&#31574;&#30053;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615; Bandit &#19979;&#31574;&#30053;&#35780;&#20272;&#30340;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#38382;&#39064;&#12290;&#22312;&#31574;&#30053;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#20272;&#35745;&#22810;&#33218;&#36172;&#21338;&#26426;&#29615;&#22659;&#20013;&#25191;&#34892;&#30446;&#26631;&#31574;&#30053;&#23558;&#33719;&#24471;&#30340;&#26399;&#26395;&#25910;&#30410;&#12290;&#26412;&#25991;&#26159;&#39318;&#20010;&#19987;&#27880;&#20110;&#35299;&#20915;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#21253;&#21547;&#24322;&#26041;&#24046;&#22870;&#21169;&#22122;&#22768;&#30340;&#31574;&#30053;&#35780;&#20272;&#30340;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#32447;&#24615; Bandit &#29615;&#22659;&#19979;&#21046;&#23450;&#20102;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#26368;&#20248;&#35774;&#35745;&#65292;&#20197;&#20943;&#23569;&#30446;&#26631;&#31574;&#30053;&#20215;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#20351;&#29992;&#35813;&#35774;&#35745;&#26469;&#25512;&#23548;&#20986;&#25968;&#25454;&#25910;&#38598;&#26399;&#38388;&#27599;&#20010;&#21160;&#20316;&#30340;&#26368;&#20248;&#26679;&#26412;&#20998;&#37197;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026; SPEED&#65288;Structured Policy Evaluation Experimental Design&#65289;&#30340;&#26032;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36319;&#36394;&#26368;&#20248;&#35774;&#35745;&#65292;&#24182;&#35745;&#31639;&#20854;&#19982;&#26368;&#20248;&#35774;&#35745;&#30340;&#36951;&#25022;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126; SPEED &#21487;&#20197;&#23454;&#29616;&#24102;&#26377;&#22343;&#26041;&#35823;&#24046;&#27604;&#36739;&#23567;&#30340;&#31574;&#30053;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of optimal data collection for policy evaluation in linear bandits. In policy evaluation, we are given a target policy and asked to estimate the expected reward it will obtain when executed in a multi-armed bandit environment. Our work is the first work that focuses on such optimal data collection strategy for policy evaluation involving heteroscedastic reward noise in the linear bandit setting. We first formulate an optimal design for weighted least squares estimates in the heteroscedastic linear bandit setting that reduces the MSE of the value of the target policy. We then use this formulation to derive the optimal allocation of samples per action during data collection. We then introduce a novel algorithm SPEED (Structured Policy Evaluation Experimental Design) that tracks the optimal design and derive its regret with respect to the optimal design. Finally, we empirically validate that SPEED leads to policy evaluation with mean squared error compa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36866;&#24212;&#26410;&#30693;&#26799;&#24230;&#33539;&#25968;&#12289;&#24179;&#28369;&#24615;&#21644;&#24378;&#20984;&#24615;&#65292;&#24182;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2205.02160</link><description>&lt;p&gt;
&#20351;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#26080;&#21442;&#25968;&#21270;
&lt;/p&gt;
&lt;p&gt;
Making SGD Parameter-Free. (arXiv:2205.02160v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02160
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#65292;&#33021;&#22815;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#36866;&#24212;&#26410;&#30693;&#26799;&#24230;&#33539;&#25968;&#12289;&#24179;&#28369;&#24615;&#21644;&#24378;&#20984;&#24615;&#65292;&#24182;&#22312;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#20855;&#26377;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#31639;&#27861;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#20165;&#27604;&#23545;&#24212;&#30340;&#24050;&#30693;&#21442;&#25968;&#35774;&#32622;&#30340;&#26368;&#20248;&#36895;&#24230;&#22810;&#19968;&#20010;&#21452;&#23545;&#25968;&#22240;&#23376;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20808;&#21069;&#24050;&#30693;&#30340;&#26080;&#21442;&#25968;SCO&#30340;&#26368;&#20339;&#36895;&#24230;&#26159;&#22522;&#20110;&#22312;&#32447;&#26080;&#21442;&#25968;&#21518;&#24724;&#30028;&#30340;&#65292;&#19982;&#24050;&#30693;&#21442;&#25968;&#30340;&#23545;&#24212;&#26041;&#27861;&#30456;&#27604;&#21253;&#21547;&#19981;&#21487;&#36991;&#20813;&#30340;&#39069;&#22806;&#23545;&#25968;&#39033;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#27010;&#24565;&#19978;&#30340;&#31616;&#21333;&#24615;&#65292;&#20855;&#26377;&#39640;&#27010;&#29575;&#20445;&#35777;&#65292;&#24182;&#19988;&#37096;&#20998;&#36866;&#24212;&#26410;&#30693;&#26799;&#24230;&#33539;&#25968;&#12289;&#24179;&#28369;&#24615;&#21644;&#24378;&#20984;&#24615;&#12290;&#25105;&#20204;&#30340;&#25104;&#26524;&#30340;&#26680;&#24515;&#26159;SGD&#27493;&#38271;&#36873;&#25321;&#30340;&#26032;&#22411;&#26080;&#21442;&#25968;&#35777;&#20070;&#65292;&#20197;&#21450;&#20551;&#35774;&#22312;SGD&#36845;&#20195;&#19978;&#27809;&#26377;&#20808;&#39564;&#30028;&#38480;&#30340;&#26102;&#38388;&#19968;&#33268;&#38598;&#20013;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop an algorithm for parameter-free stochastic convex optimization (SCO) whose rate of convergence is only a double-logarithmic factor larger than the optimal rate for the corresponding known-parameter setting. In contrast, the best previously known rates for parameter-free SCO are based on online parameter-free regret bounds, which contain unavoidable excess logarithmic terms compared to their known-parameter counterparts. Our algorithm is conceptually simple, has high-probability guarantees, and is also partially adaptive to unknown gradient norms, smoothness, and strong convexity. At the heart of our results is a novel parameter-free certificate for SGD step size choice, and a time-uniform concentration result that assumes no a-priori bounds on SGD iterates.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#65288;MBDA&#65289;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25512;&#23548;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#32467;&#21512;&#21487;&#35299;&#37322;&#24615;&#21644;&#20132;&#20114;&#24335;&#27169;&#22411;&#30340;&#20248;&#21183;&#20197;&#21450;&#24182;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;&#65292;&#24212;&#29992;&#20110;&#32593;&#32476;&#30417;&#27979;&#21644;&#35786;&#26029;&#65292;&#26368;&#32456;&#22312;UGR'16&#21644;Dartmouth'18&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/1907.02677</link><description>&lt;p&gt;
&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#21487;&#35299;&#37322;&#24615;&#23398;&#20064;&#29992;&#20110;&#32593;&#32476;&#30417;&#27979;
&lt;/p&gt;
&lt;p&gt;
Interpretable Learning in Multivariate Big Data Analysis for Network Monitoring. (arXiv:1907.02677v2 [cs.NI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1907.02677
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#65288;MBDA&#65289;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#25512;&#23548;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#32467;&#21512;&#21487;&#35299;&#37322;&#24615;&#21644;&#20132;&#20114;&#24335;&#27169;&#22411;&#30340;&#20248;&#21183;&#20197;&#21450;&#24182;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;&#65292;&#24212;&#29992;&#20110;&#32593;&#32476;&#30417;&#27979;&#21644;&#35786;&#26029;&#65292;&#26368;&#32456;&#22312;UGR'16&#21644;Dartmouth'18&#20004;&#20010;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#20197;&#35780;&#20272;&#36890;&#20449;&#32593;&#32476;&#24615;&#33021;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#65292;&#27604;&#22914;&#32593;&#32476;&#30417;&#27979;&#21644;&#25925;&#38556;&#25490;&#38500;&#65292;&#22914;&#26524;&#19981;&#33021;&#34987;&#20154;&#31867;&#25805;&#20316;&#21592;&#35299;&#37322;&#65292;&#25968;&#25454;&#27169;&#22411;&#23601;&#27809;&#22810;&#22823;&#29992;&#22788;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22810;&#21464;&#37327;&#22823;&#25968;&#25454;&#20998;&#26512;&#65288;MBDA&#65289;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36825;&#26159;&#19968;&#31181;&#36817;&#26399;&#25552;&#20986;&#30340;&#21487;&#35299;&#37322;&#24615;&#25968;&#25454;&#20998;&#26512;&#24037;&#20855;&#12290;&#22312;&#36825;&#20010;&#25193;&#23637;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33258;&#21160;&#25512;&#23548;&#29305;&#24449;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36825;&#26159;&#24403;&#25968;&#25454;&#37327;&#24222;&#22823;&#26102;&#24212;&#29992;MBDA&#30340;&#37325;&#35201;&#27493;&#39588;&#12290;&#25152;&#24471;&#21040;&#30340;&#32593;&#32476;&#30417;&#27979;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#26816;&#27979;&#21644;&#35786;&#26029;&#19981;&#21516;&#30340;&#32593;&#32476;&#24322;&#24120;&#65292;&#37319;&#29992;&#19968;&#31181;&#23558;&#21487;&#35299;&#37322;&#24615;&#21644;&#20132;&#20114;&#24335;&#27169;&#22411;&#30340;&#20248;&#21183;&#19982;&#24182;&#34892;&#22788;&#29702;&#30340;&#33021;&#21147;&#30456;&#32467;&#21512;&#30340;&#25968;&#25454;&#20998;&#26512;&#24037;&#20316;&#27969;&#12290;&#25105;&#20204;&#23558;&#25193;&#23637;&#30340;MBDA&#24212;&#29992;&#20110;&#20004;&#20010;&#26696;&#20363;&#30740;&#31350;&#65306;UGR'16&#65292;&#29992;&#20110;&#24322;&#24120;&#26816;&#27979;&#30340;&#22522;&#20934;&#27969;&#37327;&#23454;&#38469;&#25968;&#25454;&#38598;&#65292;&#20197;&#21450;Dartmouth'18&#65292;&#26368;&#38271;&#21644;&#26368;&#20855;&#25361;&#25112;&#24615;&#30340;&#25968;&#25454;&#38598;&#20043;&#19968;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is an increasing interest in the development of new data-driven models useful to assess the performance of communication networks. For many applications, like network monitoring and troubleshooting, a data model is of little use if it cannot be interpreted by a human operator. In this paper, we present an extension of the Multivariate Big Data Analysis (MBDA) methodology, a recently proposed interpretable data analysis tool. In this extension, we propose a solution to the automatic derivation of features, a cornerstone step for the application of MBDA when the amount of data is massive. The resulting network monitoring approach allows us to detect and diagnose disparate network anomalies, with a data-analysis workflow that combines the advantages of interpretable and interactive models with the power of parallel processing. We apply the extended MBDA to two case studies: UGR'16, a benchmark flow-based real-traffic dataset for anomaly detection, and Dartmouth'18, the longest and l
&lt;/p&gt;</description></item></channel></rss>