<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.09924</link><description>&lt;p&gt;
&#22522;&#20110;&#28909;&#21644;&#27874;&#21160;&#21160;&#21147;&#23398;&#29305;&#24449;&#30340;&#22270;&#25299;&#25169;&#23646;&#24615;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Graph topological property recovery with heat and wave dynamics-based features on graphsD. (arXiv:2309.09924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#19978;&#30340;PDE&#35299;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20026;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#33719;&#24471;&#36830;&#32493;&#30340;&#33410;&#28857;&#21644;&#22270;&#32423;&#34920;&#31034;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#19982;&#22270;&#30340;&#35889;&#29305;&#24615;&#20197;&#21450;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#28216;&#36208;&#22312;&#22270;&#19978;&#34892;&#20026;&#20043;&#38388;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#24674;&#22797;&#38543;&#26426;&#22270;&#29983;&#25104;&#21442;&#25968;&#12289;Ricci&#26354;&#29575;&#21644;&#25345;&#20037;&#21516;&#35843;&#31561;&#26041;&#24335;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#21160;&#21147;&#23398;&#33021;&#22815;&#25429;&#25417;&#21040;&#22270;&#24418;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#26174;&#33879;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;GDeNet&#22312;&#21253;&#25324;&#24341;&#29992;&#22270;&#12289;&#33647;&#29289;&#20998;&#23376;&#21644;&#34507;&#30333;&#36136;&#22312;&#20869;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35752;&#35770;&#20102;&#36890;&#36807;&#23558;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#28508;&#22312;&#31354;&#38388;&#24314;&#27169;&#20026;&#19968;&#20010;&#21487;&#20197;&#33719;&#21462;&#26679;&#26412;&#30340;&#20998;&#24067;&#65292;&#20174;&#32780;&#23558;&#20219;&#20309;&#33258;&#21160;&#32534;&#30721;&#22120;&#36716;&#21270;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#25216;&#26415;&#12290;&#20854;&#20013;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Copula&#30340;&#26041;&#27861;&#65306;&#32463;&#39564;Beta Copula&#33258;&#21160;&#32534;&#30721;&#22120;&#12290;&#36825;&#20123;&#32467;&#26524;&#23545;&#20110;&#25429;&#25417;&#39640;&#32500;&#25968;&#25454;&#30340;&#29305;&#24449;&#34920;&#31034;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2309.09916</link><description>&lt;p&gt;
&#23398;&#20064;&#38750;&#21442;&#25968;&#39640;&#32500;&#29983;&#25104;&#27169;&#22411;&#65306;&#32463;&#39564;Beta Copula&#33258;&#21160;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Learning Nonparametric High-Dimensional Generative Models: The Empirical-Beta-Copula Autoencoder. (arXiv:2309.09916v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09916
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35752;&#35770;&#20102;&#36890;&#36807;&#23558;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#28508;&#22312;&#31354;&#38388;&#24314;&#27169;&#20026;&#19968;&#20010;&#21487;&#20197;&#33719;&#21462;&#26679;&#26412;&#30340;&#20998;&#24067;&#65292;&#20174;&#32780;&#23558;&#20219;&#20309;&#33258;&#21160;&#32534;&#30721;&#22120;&#36716;&#21270;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#25216;&#26415;&#12290;&#20854;&#20013;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Copula&#30340;&#26041;&#27861;&#65306;&#32463;&#39564;Beta Copula&#33258;&#21160;&#32534;&#30721;&#22120;&#12290;&#36825;&#20123;&#32467;&#26524;&#23545;&#20110;&#25429;&#25417;&#39640;&#32500;&#25968;&#25454;&#30340;&#29305;&#24449;&#34920;&#31034;&#20855;&#26377;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20174;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#28508;&#22312;&#31354;&#38388;&#20013;&#37319;&#26679;&#65292;&#24182;&#35299;&#30721;&#28508;&#22312;&#31354;&#38388;&#26679;&#26412;&#21040;&#21407;&#22987;&#25968;&#25454;&#31354;&#38388;&#65292;&#20219;&#20309;&#33258;&#21160;&#32534;&#30721;&#22120;&#37117;&#21487;&#20197;&#31616;&#21333;&#22320;&#36716;&#21270;&#20026;&#29983;&#25104;&#27169;&#22411;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#38656;&#35201;&#29992;&#19968;&#20010;&#21487;&#20197;&#33719;&#24471;&#26679;&#26412;&#30340;&#20998;&#24067;&#26469;&#24314;&#27169;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#28508;&#22312;&#31354;&#38388;&#12290;&#21487;&#20197;&#32771;&#34385;&#20960;&#31181;&#31616;&#21333;&#30340;&#21487;&#33021;&#24615;&#65288;&#26680;&#23494;&#24230;&#20272;&#35745;&#12289;&#39640;&#26031;&#20998;&#24067;&#65289;&#21644;&#26356;&#22797;&#26434;&#30340;&#26041;&#27861;&#65288;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12289;Copula&#27169;&#22411;&#12289;&#35268;&#33539;&#21270;&#27969;&#65289;&#65292;&#24182;&#19988;&#36817;&#26399;&#24050;&#32463;&#23581;&#35797;&#36807;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#35752;&#35770;&#12289;&#35780;&#20272;&#21644;&#27604;&#36739;&#21487;&#20197;&#29992;&#20110;&#25429;&#25417;&#28508;&#22312;&#31354;&#38388;&#30340;&#21508;&#31181;&#25216;&#26415;&#65292;&#20197;&#20415;&#20351;&#33258;&#21160;&#32534;&#30721;&#22120;&#25104;&#20026;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#36861;&#27714;&#31616;&#21333;&#24615;&#12290;&#20854;&#20013;&#65292;&#32771;&#34385;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Copula&#30340;&#26041;&#27861;&#65292;&#21363;&#32463;&#39564;Beta Copula&#33258;&#21160;&#32534;&#30721;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#20123;&#26041;&#27861;&#30340;&#20854;&#20182;&#26041;&#38754;&#30340;&#28145;&#20837;&#35265;&#35299;&#65292;&#22914;&#26377;&#38024;&#23545;&#24615;&#30340;&#37319;&#26679;&#25110;&#21512;&#25104;&#20855;&#26377;&#29305;&#23450;&#29305;&#24449;&#30340;&#26032;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
By sampling from the latent space of an autoencoder and decoding the latent space samples to the original data space, any autoencoder can simply be turned into a generative model. For this to work, it is necessary to model the autoencoder's latent space with a distribution from which samples can be obtained. Several simple possibilities (kernel density estimates, Gaussian distribution) and more sophisticated ones (Gaussian mixture models, copula models, normalization flows) can be thought of and have been tried recently. This study aims to discuss, assess, and compare various techniques that can be used to capture the latent space so that an autoencoder can become a generative model while striving for simplicity. Among them, a new copula-based method, the Empirical Beta Copula Autoencoder, is considered. Furthermore, we provide insights into further aspects of these methods, such as targeted sampling or synthesizing new data with specific features.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#27493;&#24577;&#21152;&#36895;&#24230;&#25968;&#25454;&#36827;&#34892;&#20010;&#20307;&#36523;&#20221;&#39044;&#27979;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#36991;&#20813;&#20102;&#23558;&#39044;&#27979;&#22120;&#31354;&#38388;&#20998;&#25104;&#21333;&#20803;&#26684;&#65292;&#24182;&#36827;&#34892;&#20102;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#39044;&#27979;&#26041;&#27861;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2309.09897</link><description>&lt;p&gt;
&#27493;&#34892;&#25351;&#32441;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Walking fingerprinting. (arXiv:2309.09897v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09897
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#27493;&#24577;&#21152;&#36895;&#24230;&#25968;&#25454;&#36827;&#34892;&#20010;&#20307;&#36523;&#20221;&#39044;&#27979;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#36991;&#20813;&#20102;&#23558;&#39044;&#27979;&#22120;&#31354;&#38388;&#20998;&#25104;&#21333;&#20803;&#26684;&#65292;&#24182;&#36827;&#34892;&#20102;&#20004;&#20010;&#25968;&#25454;&#38598;&#30340;&#39044;&#27979;&#26041;&#27861;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#27493;&#24577;&#21152;&#36895;&#24230;&#25968;&#25454;&#26469;&#39044;&#27979;&#20010;&#20307;&#30340;&#36523;&#20221;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#23558;&#21152;&#36895;&#24230;&#26102;&#38388;&#24207;&#21015;&#36716;&#21270;&#20026;&#22270;&#20687;&#65292;&#36890;&#36807;&#26500;&#24314;&#23436;&#25972;&#30340;&#32463;&#39564;&#33258;&#30456;&#20851;&#20998;&#24067;&#26469;&#23454;&#29616;&#12290;&#36890;&#36807;&#23558;&#35813;&#22270;&#20687;&#20998;&#25104;&#32593;&#26684;&#21333;&#20803;&#65292;&#24182;&#20351;&#29992;&#36923;&#36753;&#22238;&#24402;&#20135;&#29983;&#30340;&#39044;&#27979;&#22120;&#65292;&#21487;&#20197;&#36827;&#34892;&#20010;&#20307;&#36523;&#20221;&#30340;&#39044;&#27979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#65306;(1) &#23454;&#26045;&#20102;&#20351;&#29992;&#22522;&#20110;&#32593;&#26684;&#21333;&#20803;&#30340;&#39044;&#27979;&#22120;&#36827;&#34892;&#39044;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65307;(2) &#25512;&#23548;&#20102;&#19968;&#31181;&#25512;&#26029;&#26041;&#27861;&#65292;&#20197;&#31579;&#36873;&#20986;&#26368;&#20855;&#39044;&#27979;&#24615;&#30340;&#32593;&#26684;&#21333;&#20803;&#65307;(3) &#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20803;&#20989;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#36991;&#20813;&#20102;&#23558;&#39044;&#27979;&#22120;&#31354;&#38388;&#20998;&#25104;&#21333;&#20803;&#26684;&#12290;&#38024;&#23545;&#20004;&#20010;&#24320;&#28304;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#39044;&#27979;&#26041;&#27861;&#27604;&#36739;&#65306;(1)&#26469;&#33258;32&#20010;&#20010;&#20307;&#22312;1.06&#21315;&#31859;&#36335;&#24452;&#19978;&#34892;&#36208;&#30340;&#21152;&#36895;&#24230;&#25968;&#25454;&#65307;(2)&#22312;&#20004;&#20010;&#19981;&#21516;&#22330;&#21512;&#36827;&#34892;&#20102;&#20845;&#27425;&#37325;&#22797;&#34892;&#36208;&#30340;20&#31859;&#36335;&#24452;&#19978;&#25910;&#38598;&#30340;&#21152;&#36895;&#24230;&#25968;&#25454;&#65292;&#26102;&#38388;&#38388;&#38548;&#33267;&#23569;&#20026;&#19968;&#21608;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of predicting an individual's identity from accelerometry data collected during walking. In a previous paper we introduced an approach that transforms the accelerometry time series into an image by constructing its complete empirical autocorrelation distribution. Predictors derived by partitioning this image into grid cells were used in logistic regression to predict individuals. Here we: (1) implement machine learning methods for prediction using the grid cell-derived predictors; (2) derive inferential methods to screen for the most predictive grid cells; and (3) develop a novel multivariate functional regression model that avoids partitioning of the predictor space into cells. Prediction methods are compared on two open source data sets: (1) accelerometry data collected from $32$ individuals walking on a $1.06$ kilometer path; and (2) accelerometry data collected from six repetitions of walking on a $20$ meter path on two separate occasions at least one week a
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#20316;&#32773;&#36890;&#36807;&#29702;&#35770;&#19982;&#23454;&#39564;&#35777;&#26126;&#20102;&#23558;&#27880;&#24847;&#21147;&#25918;&#22312;&#19978;&#19979;&#25991;-&#26410;&#26631;&#35760;&#26679;&#26412;&#19978;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#39046;&#22495;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.09888</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#8776;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
Context $\approx$ Environment. (arXiv:2309.09888v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09888
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#20316;&#32773;&#36890;&#36807;&#29702;&#35770;&#19982;&#23454;&#39564;&#35777;&#26126;&#20102;&#23558;&#27880;&#24847;&#21147;&#25918;&#22312;&#19978;&#19979;&#25991;-&#26410;&#26631;&#35760;&#26679;&#26412;&#19978;&#65292;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#39046;&#22495;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
AI&#30740;&#31350;&#30340;&#20013;&#24515;&#22312;&#20110;&#20004;&#20010;&#26041;&#38754;&#12290;&#19968;&#26041;&#38754;&#65292;&#31038;&#21306;&#27491;&#22312;&#21162;&#21147;&#26500;&#24314;&#33021;&#22815;&#20002;&#24323;&#34394;&#20551;&#30456;&#20851;&#24615;&#24182;&#22312;&#26032;&#39062;&#30340;&#27979;&#35797;&#29615;&#22659;&#20013;&#26356;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#30340;&#27169;&#22411;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#27809;&#26377;&#20219;&#20309;&#25552;&#26696;&#33021;&#22815;&#20196;&#20154;&#20449;&#26381;&#22320;&#36229;&#36234;&#31616;&#21333;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22522;&#32447;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#24050;&#32463;&#25104;&#20026;&#33021;&#22815;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#12289;&#26681;&#25454;&#29992;&#25143;&#36890;&#36807;&#25552;&#31034;&#26045;&#21152;&#30340;&#22810;&#31181;&#19978;&#19979;&#25991;&#32972;&#26223;&#28789;&#27963;&#27867;&#21270;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#35748;&#20026;&#19978;&#19979;&#25991;&#8776;&#29615;&#22659;&#65292;&#24182;&#20551;&#35774;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#38544;&#34255;&#30528;&#26356;&#22909;&#30340;&#39046;&#22495;&#27867;&#21270;&#20043;&#38053;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#29702;&#35770;&#19982;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27880;&#24847;&#19978;&#19979;&#25991;-&#26410;&#26631;&#35760;&#30340;&#26679;&#26412;&#30340;&#37325;&#35201;&#24615;&#65292;&#36825;&#31181;&#27880;&#24847;&#21487;&#20197;&#20351;&#25105;&#20204;&#25552;&#20986;&#30340;In-Context Risk Minimization (ICRM)&#31639;&#27861;&#32858;&#28966;&#20110;&#27979;&#35797;&#29615;&#22659;&#39118;&#38505;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two lines of work are taking the central stage in AI research. On the one hand, the community is making increasing efforts to build models that discard spurious correlations and generalize better in novel test environments. Unfortunately, the bitter lesson so far is that no proposal convincingly outperforms a simple empirical risk minimization baseline. On the other hand, large language models (LLMs) have erupted as algorithms able to learn in-context, generalizing on-the-fly to the eclectic contextual circumstances that users enforce by means of prompting. In this paper, we argue that context $\approx$ environment, and posit that in-context learning holds the key to better domain generalization. Via extensive theory and experiments, we show that paying attention to context$\unicode{x2013}\unicode{x2013}$unlabeled examples as they arrive$\unicode{x2013}\unicode{x2013}$allows our proposed In-Context Risk Minimization (ICRM) algorithm to zoom-in on the test environment risk minimizer, le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22534;&#21472;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#24182;&#21463;&#38750;&#36127;&#24615;&#32422;&#26463;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;&#35823;&#24046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22534;&#21472;&#20272;&#35745;&#22120;&#30456;&#27604;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#23567;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2309.09880</link><description>&lt;p&gt;
&#30001;&#22534;&#21472;&#22238;&#24402;&#20943;&#23569;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Error Reduction from Stacked Regressions. (arXiv:2309.09880v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09880
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22534;&#21472;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#24182;&#21463;&#38750;&#36127;&#24615;&#32422;&#26463;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;&#35823;&#24046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22534;&#21472;&#20272;&#35745;&#22120;&#30456;&#27604;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#23567;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22534;&#21472;&#22238;&#24402;&#26159;&#19968;&#31181;&#38598;&#25104;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#24418;&#25104;&#19981;&#21516;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#20132;&#21449;&#39564;&#35777;&#25968;&#25454;&#26469;&#29983;&#25104;&#30001;&#26500;&#25104;&#20272;&#35745;&#22120;&#39044;&#27979;&#65292;&#24182;&#20351;&#29992;&#24102;&#38750;&#36127;&#24615;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#27861;&#23398;&#20064;&#32452;&#21512;&#26435;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31867;&#20284;&#22320;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#31181;&#20272;&#35745;&#30340;&#24635;&#20307;&#39118;&#38505;&#26469;&#23398;&#20064;&#36825;&#20123;&#26435;&#37325;&#65292;&#24182;&#21463;&#21040;&#38750;&#36127;&#24615;&#32422;&#26463;&#12290;&#24403;&#26500;&#25104;&#30340;&#20272;&#35745;&#22120;&#26159;&#36890;&#36807;&#33267;&#23569;&#19977;&#20010;&#32500;&#24230;&#20998;&#38548;&#30340;&#23884;&#22871;&#23376;&#31354;&#38388;&#30340;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#30001;&#20110;&#25910;&#32553;&#25928;&#24212;&#65292;&#25152;&#24471;&#21040;&#30340;&#22534;&#21472;&#20272;&#35745;&#22120;&#30340;&#24635;&#20307;&#39118;&#38505;&#20005;&#26684;&#23567;&#20110;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#12290;&#36825;&#37324;&#30340;&#8220;&#26368;&#20339;&#8221;&#26159;&#25351;&#26368;&#23567;&#21270;&#36873;&#25321;&#20934;&#21017;&#22914;AIC&#25110;BIC&#30340;&#27169;&#22411;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#26159;&#19981;&#21487;&#25509;&#21463;&#30340;&#12290;&#22240;&#20026;&#20248;&#21270;&#38382;&#39064;&#21487;&#20197;&#37325;&#26500;&#20026;&#21516;&#20449;&#24687;&#22238;&#24402;&#65292;&#25152;&#20197;...
&lt;/p&gt;
&lt;p&gt;
Stacking regressions is an ensemble technique that forms linear combinations of different regression estimators to enhance predictive accuracy. The conventional approach uses cross-validation data to generate predictions from the constituent estimators, and least-squares with nonnegativity constraints to learn the combination weights. In this paper, we learn these weights analogously by minimizing an estimate of the population risk subject to a nonnegativity constraint. When the constituent estimators are linear least-squares projections onto nested subspaces separated by at least three dimensions, we show that thanks to a shrinkage effect, the resulting stacked estimator has strictly smaller population risk than best single estimator among them. Here ``best'' refers to a model that minimizes a selection criterion such as AIC or BIC. In other words, in this setting, the best single estimator is inadmissible. Because the optimization problem can be reformulated as isotonic regression, t
&lt;/p&gt;</description></item><item><title>PANDA&#26159;&#19968;&#31181;&#39640;&#32500;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#23545;&#35843;&#21442;&#25968;&#38656;&#27714;&#23567;&#19988;&#36798;&#21040;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#20854;&#24615;&#33021;&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#21442;&#25968;&#35843;&#25972;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2309.09831</link><description>&lt;p&gt;
&#39640;&#32500;&#26465;&#20214;&#19979;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#30340;&#20851;&#38190;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Pivotal Estimation of Linear Discriminant Analysis in High Dimensions. (arXiv:2309.09831v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09831
&lt;/p&gt;
&lt;p&gt;
PANDA&#26159;&#19968;&#31181;&#39640;&#32500;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#23545;&#35843;&#21442;&#25968;&#38656;&#27714;&#23567;&#19988;&#36798;&#21040;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#20854;&#24615;&#33021;&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#21442;&#25968;&#35843;&#25972;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#39640;&#32500;&#32972;&#26223;&#19979;&#30340;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PANDA&#65288;PivotAl liNear Discriminant Analysis&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23545;&#35843;&#21442;&#25968;&#38656;&#27714;&#38750;&#24120;&#23567;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PANDA&#22312;&#20272;&#35745;&#35823;&#24046;&#21644;&#38169;&#35823;&#20998;&#31867;&#29575;&#26041;&#38754;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#20840;&#38754;&#25968;&#20540;&#30740;&#31350;&#30340;&#25903;&#25345;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25105;&#20204;&#25552;&#20986;&#30340;PANDA&#22312;&#24615;&#33021;&#19978;&#30456;&#31561;&#25110;&#26356;&#22909;&#65292;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#21442;&#25968;&#35843;&#25972;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the linear discriminant analysis problem in the high-dimensional settings. In this work, we propose PANDA(PivotAl liNear Discriminant Analysis), a tuning-insensitive method in the sense that it requires very little effort to tune the parameters. Moreover, we prove that PANDA achieves the optimal convergence rate in terms of both the estimation error and misclassification rate. Our theoretical results are backed up by thorough numerical studies using both simulated and real datasets. In comparison with the existing methods, we observe that our proposed PANDA yields equal or better performance, and requires substantially less effort in parameter tuning.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#21367;&#31215;&#28145;&#24230;&#26680;&#26426;&#22120;&#30340;&#26032;&#22411;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32431;&#31929;&#20351;&#29992;&#26680;&#32780;&#19981;&#20351;&#29992;&#29305;&#24449;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#36328;&#22495;&#35825;&#23548;&#28857;&#36817;&#20284;&#26041;&#26696;&#21644;&#22810;&#31181;&#27169;&#22411;&#21464;&#20307;&#30340;&#35774;&#35745;&#65292;&#36798;&#21040;&#20102;&#22312;MNIST&#12289;CIFAR-10&#21644;CIFAR-100&#19978;&#25509;&#36817;&#29978;&#33267;&#36229;&#36807;&#20854;&#20182;&#26041;&#27861;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.09814</link><description>&lt;p&gt;
&#21367;&#31215;&#28145;&#24230;&#26680;&#26426;&#22120;
&lt;/p&gt;
&lt;p&gt;
Convolutional Deep Kernel Machines. (arXiv:2309.09814v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09814
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#21367;&#31215;&#28145;&#24230;&#26680;&#26426;&#22120;&#30340;&#26032;&#22411;&#26680;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#32431;&#31929;&#20351;&#29992;&#26680;&#32780;&#19981;&#20351;&#29992;&#29305;&#24449;&#65292;&#36890;&#36807;&#39640;&#25928;&#30340;&#36328;&#22495;&#35825;&#23548;&#28857;&#36817;&#20284;&#26041;&#26696;&#21644;&#22810;&#31181;&#27169;&#22411;&#21464;&#20307;&#30340;&#35774;&#35745;&#65292;&#36798;&#21040;&#20102;&#22312;MNIST&#12289;CIFAR-10&#21644;CIFAR-100&#19978;&#25509;&#36817;&#29978;&#33267;&#36229;&#36807;&#20854;&#20182;&#26041;&#27861;&#30340;&#27979;&#35797;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#26680;&#26426;&#22120;(DKMs)&#26159;&#19968;&#31181;&#26368;&#36817;&#24341;&#20837;&#30340;&#20855;&#26377;&#20854;&#20182;&#28145;&#24230;&#27169;&#22411;&#28789;&#27963;&#24615;&#30340;&#26680;&#26041;&#27861;&#65292;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#12290;DKMs&#32431;&#31929;&#20351;&#29992;&#26680;&#65292;&#32780;&#19981;&#20351;&#29992;&#29305;&#24449;&#65292;&#22240;&#27492;&#19982;&#20854;&#20182;&#26041;&#27861;&#65288;&#20174;&#31070;&#32463;&#32593;&#32476;&#21040;&#28145;&#24230;&#26680;&#23398;&#20064;&#29978;&#33267;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65289;&#19981;&#21516;&#65292;&#21518;&#32773;&#37117;&#20351;&#29992;&#29305;&#24449;&#20316;&#20026;&#22522;&#26412;&#32452;&#25104;&#37096;&#20998;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21367;&#31215;DKMs&#65292;&#24182;&#37197;&#20197;&#19968;&#31181;&#39640;&#25928;&#30340;&#36328;&#22495;&#35825;&#23548;&#28857;&#36817;&#20284;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#24182;&#23454;&#39564;&#35780;&#20272;&#20102;&#35768;&#22810;&#27169;&#22411;&#21464;&#20307;&#65292;&#21253;&#25324;9&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#20026;&#21367;&#31215;DKMs&#35774;&#35745;&#30340;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#20004;&#31181;&#20284;&#28982;&#20989;&#25968;&#21644;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#39030;&#23618;&#12290;&#23613;&#31649;&#21482;&#22312;&#32422;28&#20010;GPU&#23567;&#26102;&#20869;&#35757;&#32451;&#65288;&#27604;&#23436;&#20840;&#30340;NNGP / NTK / Myrtle kernel&#24555;1-2&#20010;&#25968;&#37327;&#32423;&#65289;&#65292;&#20294;&#24471;&#21040;&#30340;&#27169;&#22411;&#22312;MNIST&#19978;&#23454;&#29616;&#20102;&#32422;99&#65285;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#22312;CIFAR-10&#19978;&#20026;92&#65285;&#65292;&#22312;CIFAR-100&#19978;&#20026;71&#65285;&#65292;&#21516;&#26102;&#36798;&#21040;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep kernel machines (DKMs) are a recently introduced kernel method with the flexibility of other deep models including deep NNs and deep Gaussian processes. DKMs work purely with kernels, never with features, and are therefore different from other methods ranging from NNs to deep kernel learning and even deep Gaussian processes, which all use features as a fundamental component. Here, we introduce convolutional DKMs, along with an efficient inter-domain inducing point approximation scheme. Further, we develop and experimentally assess a number of model variants, including 9 different types of normalisation designed for the convolutional DKMs, two likelihoods, and two different types of top-layer. The resulting models achieve around 99% test accuracy on MNIST, 92% on CIFAR-10 and 71% on CIFAR-100, despite training in only around 28 GPU hours, 1-2 orders of magnitude faster than full NNGP / NTK / Myrtle kernels, whilst achieving comparable performance.
&lt;/p&gt;</description></item><item><title>&#22312;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#19979;&#19981;&#22343;&#34913;&#25968;&#25454;&#30340;&#31070;&#32463;&#22604;&#32553;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2309.09725</link><description>&lt;p&gt;
&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#20013;&#30340;&#20132;&#21449;&#29109;&#25439;&#22833;&#19979;&#19981;&#21463;&#38480;&#30340;&#31070;&#32463;&#22604;&#32553;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss with Imbalanced Data. (arXiv:2309.09725v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09725
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#19979;&#19981;&#22343;&#34913;&#25968;&#25454;&#30340;&#31070;&#32463;&#22604;&#32553;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#25991;&#26412;&#22788;&#29702;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#20123;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;DNNs&#22312;&#35757;&#32451;&#30340;&#26411;&#26399;&#38454;&#27573;&#65288;TPT&#65289;&#30340;&#29305;&#24449;&#34920;&#31034;&#21644;&#26411;&#23618;&#20998;&#31867;&#22120;&#20855;&#26377;&#30456;&#20284;&#30340;&#32467;&#26500;&#29305;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22914;&#26524;&#35757;&#32451;&#25968;&#25454;&#26159;&#24179;&#34913;&#30340;&#65288;&#27599;&#20010;&#31867;&#21035;&#20855;&#26377;&#30456;&#21516;&#25968;&#37327;&#30340;&#26679;&#26412;&#65289;&#65292;&#35266;&#23519;&#21040;&#26469;&#33258;&#21516;&#19968;&#31867;&#21035;&#30340;&#26679;&#26412;&#30340;&#29305;&#24449;&#21521;&#37327;&#25910;&#25947;&#21040;&#30456;&#24212;&#30340;&#31867;&#20869;&#22343;&#20540;&#29305;&#24449;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#25104;&#23545;&#35282;&#24230;&#30456;&#21516;&#12290;&#36825;&#19968;&#36855;&#20154;&#30340;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#22604;&#32553;&#65288;NC&#65289;&#65292;&#30001;Papyan&#65292;Han&#21644;Donoho&#22312;2019&#24180;&#39318;&#27425;&#25552;&#20986;&#12290;&#26368;&#36817;&#30340;&#35768;&#22810;&#24037;&#20316;&#36890;&#36807;&#37319;&#29992;&#25152;&#35859;&#30340;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#65288;UFM&#65289;&#22312;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#24357;&#34917;&#20102;NC&#29616;&#35937;&#23545;&#19981;&#22343;&#34913;&#25968;&#25454;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#20989;&#25968;&#19979;&#30340;&#25299;&#23637;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed the huge success of deep neural networks (DNNs) in various tasks of computer vision and text processing. Interestingly, these DNNs with massive number of parameters share similar structural properties on their feature representation and last-layer classifier at terminal phase of training (TPT). Specifically, if the training data are balanced (each class shares the same number of samples), it is observed that the feature vectors of samples from the same class converge to their corresponding in-class mean features and their pairwise angles are the same. This fascinating phenomenon is known as Neural Collapse (N C), first termed by Papyan, Han, and Donoho in 2019. Many recent works manage to theoretically explain this phenomenon by adopting so-called unconstrained feature model (UFM). In this paper, we study the extension of N C phenomenon to the imbalanced data under cross-entropy loss function in the context of unconstrained feature model. Our contribution is
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#25968;&#25237;&#31080;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#26032;&#30340;&#20934;&#30830;&#24615;&#19978;&#30028;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#30528;&#29420;&#31435;&#25237;&#31080;&#20154;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#30340;&#38169;&#35823;&#29575;&#23558;&#20197;&#25351;&#25968;&#26041;&#24335;&#36235;&#21521;&#20110;&#38646;&#65292;&#21542;&#21017;&#23558;&#20197;&#25351;&#25968;&#26041;&#24335;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2309.09564</link><description>&lt;p&gt;
&#22810;&#31867;&#21035;&#20998;&#31867;&#30340;&#22810;&#25968;&#25237;&#31080;&#20934;&#30830;&#24615;&#30340;&#26032;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
New Bounds on the Accuracy of Majority Voting for Multi-Class Classification. (arXiv:2309.09564v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#25968;&#25237;&#31080;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#26032;&#30340;&#20934;&#30830;&#24615;&#19978;&#30028;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#30528;&#29420;&#31435;&#25237;&#31080;&#20154;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#30340;&#38169;&#35823;&#29575;&#23558;&#20197;&#25351;&#25968;&#26041;&#24335;&#36235;&#21521;&#20110;&#38646;&#65292;&#21542;&#21017;&#23558;&#20197;&#25351;&#25968;&#26041;&#24335;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#25968;&#25237;&#31080;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#25968;&#23398;&#20989;&#25968;&#65292;&#36820;&#22238;&#38598;&#21512;&#20013;&#20986;&#29616;&#26368;&#22810;&#30340;&#20540;&#12290;&#20316;&#20026;&#19968;&#31181;&#27969;&#34892;&#30340;&#20915;&#31574;&#34701;&#21512;&#25216;&#26415;&#65292;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#65288;MVF&#65289;&#22312;&#35299;&#20915;&#20914;&#31361;&#12289;&#29420;&#31435;&#25237;&#31080;&#20154;&#23601;&#20998;&#31867;&#38382;&#39064;&#25253;&#21578;&#20182;&#20204;&#30340;&#35266;&#28857;&#26041;&#38754;&#26377;&#30528;&#21508;&#31181;&#24212;&#29992;&#12290;&#23613;&#31649;&#23427;&#22312;&#38598;&#25104;&#23398;&#20064;&#12289;&#25968;&#25454;&#20247;&#21253;&#12289;&#36965;&#24863;&#21644;&#21306;&#22359;&#38142;&#25968;&#25454;&#31070;&#35861;&#31561;&#39046;&#22495;&#26377;&#37325;&#35201;&#24212;&#29992;&#65292;&#20294;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#22312;&#19968;&#33324;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#20934;&#30830;&#24615;&#19968;&#30452;&#26410;&#30693;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#22312;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#26032;&#30340;&#20934;&#30830;&#24615;&#19978;&#30028;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#30340;&#38169;&#35823;&#29575;&#22312;&#29420;&#31435;&#25237;&#31080;&#20154;&#25968;&#37327;&#22686;&#21152;&#26102;&#20197;&#25351;&#25968;&#26041;&#24335;&#36235;&#21521;&#20110;&#38646;&#12290;&#30456;&#21453;&#65292;&#22914;&#26524;&#19981;&#28385;&#36275;&#36825;&#20123;&#26465;&#20214;&#65292;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#30340;&#38169;&#35823;&#29575;&#23558;&#20197;&#25351;&#25968;&#26041;&#24335;&#22686;&#38271;&#12290;&#25105;&#20204;&#39318;&#20808;&#25506;&#35752;&#20102;&#27169;&#22411;&#26080;&#20559;&#24615;&#21644;&#29420;&#31435;&#25237;&#31080;&#20154;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#22810;&#25968;&#25237;&#31080;&#20989;&#25968;&#22312;&#20855;&#20307;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Majority voting is a simple mathematical function that returns the value that appears most often in a set. As a popular decision fusion technique, the majority voting function (MVF) finds applications in resolving conflicts, where a number of independent voters report their opinions on a classification problem. Despite its importance and its various applications in ensemble learning, data crowd-sourcing, remote sensing, and data oracles for blockchains, the accuracy of the MVF for the general multi-class classification problem has remained unknown. In this paper, we derive a new upper bound on the accuracy of the MVF for the multi-class classification problem. More specifically, we show that under certain conditions, the error rate of the MVF exponentially decays toward zero as the number of independent voters increases. Conversely, the error rate of the MVF exponentially grows with the number of independent voters if these conditions are not met.  We first explore the problem for inde
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#22312;&#20581;&#24247;&#30456;&#20851;&#30740;&#31350;&#20013;&#23569;&#25968;&#26063;&#32676;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#34987;&#24573;&#35270;&#32780;&#23548;&#33268;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#27169;&#22411;&#21442;&#25968;&#32452;&#32455;&#25104;&#24352;&#37327;&#65292;&#24182;&#30740;&#31350;&#32467;&#26500;&#21270;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26377;&#38480;&#25110;&#26080;&#21487;&#29992;&#25968;&#25454;&#30340;&#20122;&#32676;&#20307;&#30340;&#40065;&#26834;&#39046;&#22495;&#27867;&#21270;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#32452;&#26631;&#31614;&#30340;&#32467;&#26500;&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#27867;&#21270;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.09555</link><description>&lt;p&gt;
&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#30340;&#22810;&#32500;&#24230;&#39046;&#22495;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-dimensional domain generalization with low-rank structures. (arXiv:2309.09555v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09555
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#22312;&#20581;&#24247;&#30456;&#20851;&#30740;&#31350;&#20013;&#23569;&#25968;&#26063;&#32676;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#34987;&#24573;&#35270;&#32780;&#23548;&#33268;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#27169;&#22411;&#21442;&#25968;&#32452;&#32455;&#25104;&#24352;&#37327;&#65292;&#24182;&#30740;&#31350;&#32467;&#26500;&#21270;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26377;&#38480;&#25110;&#26080;&#21487;&#29992;&#25968;&#25454;&#30340;&#20122;&#32676;&#20307;&#30340;&#40065;&#26834;&#39046;&#22495;&#27867;&#21270;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#32452;&#26631;&#31614;&#30340;&#32467;&#26500;&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#27867;&#21270;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20256;&#32479;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#27979;&#35797;&#25968;&#25454;&#19982;&#35757;&#32451;&#25968;&#25454;&#26159;&#21516;&#20998;&#24067;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#19968;&#20123;&#24212;&#29992;&#20013;&#65292;&#29305;&#23450;&#30340;&#26063;&#32676;&#21487;&#33021;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#34987;&#36739;&#23569;&#22320;&#34920;&#31034;&#65292;&#36825;&#20010;&#20551;&#35774;&#24182;&#19981;&#24635;&#26159;&#25104;&#31435;&#12290;&#36825;&#22312;&#20581;&#24247;&#30456;&#20851;&#30740;&#31350;&#20013;&#26159;&#19968;&#20010;&#20540;&#24471;&#27880;&#24847;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23569;&#25968;&#26063;&#32676;&#21487;&#33021;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#34987;&#24573;&#35270;&#65292;&#36825;&#32473;&#30740;&#31350;&#20154;&#21592;&#22312;&#23545;&#36825;&#20123;&#23569;&#25968;&#26063;&#32676;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#26102;&#24102;&#26469;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#24212;&#23545;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#25152;&#26377;&#20122;&#32676;&#20307;&#30340;&#27169;&#22411;&#21442;&#25968;&#32452;&#32455;&#25104;&#19968;&#20010;&#24352;&#37327;&#12290;&#36890;&#36807;&#30740;&#31350;&#32467;&#26500;&#21270;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#40065;&#26834;&#30340;&#39046;&#22495;&#27867;&#21270;&#65292;&#21363;&#23398;&#20064;&#23545;&#20855;&#26377;&#26377;&#38480;&#25110;&#26080;&#21487;&#29992;&#25968;&#25454;&#30340;&#20122;&#32676;&#20307;&#30340;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26032;&#39062;&#22320;&#21033;&#29992;&#20102;&#32452;&#26631;&#31614;&#30340;&#32467;&#26500;&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#27867;&#21270;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In conventional statistical and machine learning methods, it is typically assumed that the test data are identically distributed with the training data. However, this assumption does not always hold, especially in applications where the target population are not well-represented in the training data. This is a notable issue in health-related studies, where specific ethnic populations may be underrepresented, posing a significant challenge for researchers aiming to make statistical inferences about these minority groups. In this work, we present a novel approach to addressing this challenge in linear regression models. We organize the model parameters for all the sub-populations into a tensor. By studying a structured tensor completion problem, we can achieve robust domain generalization, i.e., learning about sub-populations with limited or no available data. Our method novelly leverages the structure of group labels and it can produce more reliable and interpretable generalization resu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31232;&#30095;&#32447;&#24615;MDP&#20013;&#25506;&#32034;&#21644;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#29305;&#24449;&#36873;&#25321;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#20197;&#22312;&#19982;&#29615;&#22659;&#30340;&#20132;&#20114;&#20013;&#23398;&#20064;&#20986;&#36817;&#20284;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.09457</link><description>&lt;p&gt;
&#19981;&#38656;&#35201;&#35745;&#31639;&#22797;&#26434;&#24615;&#26080;&#27861;&#35299;&#20915;&#30340;&#39044;&#35328;&#26426;&#65292;&#22312;&#31232;&#30095;&#32447;&#24615;MDP&#20013;&#25506;&#32034;&#21644;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exploring and Learning in Sparse Linear MDPs without Computationally Intractable Oracles. (arXiv:2309.09457v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#31232;&#30095;&#32447;&#24615;MDP&#20013;&#25506;&#32034;&#21644;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#29305;&#24449;&#36873;&#25321;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#20197;&#22312;&#19982;&#29615;&#22659;&#30340;&#20132;&#20114;&#20013;&#23398;&#20064;&#20986;&#36817;&#20284;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#22522;&#26412;&#20551;&#35774;&#26159;&#23398;&#20064;&#32773;&#21487;&#20197;&#35775;&#38382;&#24050;&#30693;&#30340;&#29305;&#24449;&#26144;&#23556;$ \phi&#65288;x&#65292;a&#65289;$&#65292;&#35813;&#26144;&#23556;&#23558;&#29366;&#24577;-&#21160;&#20316;&#23545;&#26144;&#23556;&#21040;$d$&#32500;&#21521;&#37327;&#65292;&#24182;&#19988;&#22870;&#21169;&#21644;&#36716;&#25442;&#26159;&#27492;&#34920;&#31034;&#20013;&#30340;&#32447;&#24615;&#20989;&#25968;&#12290;&#20294;&#26159;&#36825;&#20123;&#29305;&#24449;&#20174;&#21738;&#37324;&#26469;&#65311;&#22312;&#27809;&#26377;&#19987;&#23478;&#39046;&#22495;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#31181;&#35825;&#20154;&#30340;&#31574;&#30053;&#26159;&#20351;&#29992;&#8220;&#21416;&#25151;&#27700;&#27133;&#8221;&#26041;&#27861;&#65292;&#24182;&#24076;&#26395;&#30495;&#23454;&#29305;&#24449;&#21253;&#21547;&#22312;&#19968;&#20010;&#26356;&#22823;&#30340;&#28508;&#22312;&#29305;&#24449;&#38598;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#29305;&#24449;&#36873;&#25321;&#30340;&#35282;&#24230;&#37325;&#26032;&#23457;&#35270;&#32447;&#24615;MDP&#12290;&#22312;$k$-&#31232;&#30095;&#32447;&#24615;MDP&#20013;&#65292;&#23384;&#22312;&#19968;&#20010;&#26410;&#30693;&#30340;&#22823;&#23567;&#20026;$k$&#30340;&#23376;&#38598;$S \subset [d]$&#65292;&#20854;&#20013;&#21253;&#21547;&#25152;&#26377;&#30456;&#20851;&#29305;&#24449;&#65292;&#30446;&#26631;&#26159;&#22312;&#19982;&#29615;&#22659;&#30340;&#20132;&#20114;&#20013;&#20165;&#32463;&#36807;poly$(k,\log d)$&#27425;&#23398;&#20064;&#65292;&#23398;&#20064;&#20986;&#36817;&#20284;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#19982;&#27492;&#30456;&#21453;&#65292;&#26089;&#26399;&#30340;&#30740;&#31350;&#35201;&#20040;&#20570;&#20986;&#20102;&#26126;&#26174;&#30340;&#20551;&#35774;&#65292;&#20351;&#24471;&#25506;&#32034;&#26080;&#20851;&#32039;&#35201;&#65292;&#35201;&#20040;&#25552;&#20379;&#20102;&#25351;&#25968;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The key assumption underlying linear Markov Decision Processes (MDPs) is that the learner has access to a known feature map $\phi(x, a)$ that maps state-action pairs to $d$-dimensional vectors, and that the rewards and transitions are linear functions in this representation. But where do these features come from? In the absence of expert domain knowledge, a tempting strategy is to use the ``kitchen sink" approach and hope that the true features are included in a much larger set of potential features. In this paper we revisit linear MDPs from the perspective of feature selection. In a $k$-sparse linear MDP, there is an unknown subset $S \subset [d]$ of size $k$ containing all the relevant features, and the goal is to learn a near-optimal policy in only poly$(k,\log d)$ interactions with the environment. Our main result is the first polynomial-time algorithm for this problem. In contrast, earlier works either made prohibitively strong assumptions that obviated the need for exploration, o
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#20351;&#29992;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#26469;&#26500;&#24314;&#26679;&#26412;&#22797;&#26434;&#24615;&#25551;&#36848;&#23376;&#65292;&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#33021;&#22815;&#24471;&#20986;&#23384;&#22312;&#19968;&#20010;1-&#31435;&#20999;&#20998;&#31867;&#22120;&#30340;&#32467;&#35770;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#36317;&#31163;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.09442</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#36827;&#34892;&#38477;&#32500;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Use of the Kantorovich-Rubinstein Distance for Dimensionality Reduction. (arXiv:2309.09442v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09442
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#20351;&#29992;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#26469;&#26500;&#24314;&#26679;&#26412;&#22797;&#26434;&#24615;&#25551;&#36848;&#23376;&#65292;&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#33021;&#22815;&#24471;&#20986;&#23384;&#22312;&#19968;&#20010;1-&#31435;&#20999;&#20998;&#31867;&#22120;&#30340;&#32467;&#35770;&#65292;&#24182;&#35752;&#35770;&#20102;&#35813;&#36317;&#31163;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30340;&#30446;&#26631;&#26159;&#30740;&#31350;&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#20351;&#29992;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#26469;&#26500;&#24314;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#25551;&#36848;&#23376;&#12290;&#25105;&#20204;&#30340;&#24605;&#24819;&#26159;&#21033;&#29992;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#20316;&#20026;&#24230;&#37327;&#31354;&#38388;&#20013;&#24230;&#37327;&#21644;&#25299;&#25169;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#25105;&#20204;&#20026;&#27599;&#20010;&#31867;&#21035;&#30340;&#28857;&#20851;&#32852;&#19968;&#20010;&#24230;&#37327;&#65292;&#24182;&#30740;&#31350;&#21487;&#20197;&#20174;&#36825;&#20123;&#24230;&#37327;&#20043;&#38388;&#30340;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#20013;&#33719;&#21462;&#30340;&#20960;&#20309;&#20449;&#24687;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36825;&#20123;&#24230;&#37327;&#20043;&#38388;&#23384;&#22312;&#22823;&#30340;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#23601;&#21487;&#20197;&#24471;&#20986;&#23384;&#22312;&#19968;&#20010;&#33021;&#22815;&#33391;&#22909;&#20998;&#31867;&#28857;&#31867;&#21035;&#30340;1-&#31435;&#20999;&#20998;&#31867;&#22120;&#30340;&#32467;&#35770;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#24247;&#25176;&#32599;&#32500;&#22855;-&#40065;&#23486;&#26031;&#22374;&#36317;&#31163;&#20316;&#20026;&#25551;&#36848;&#23376;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of this thesis is to study the use of the Kantorovich-Rubinstein distance as to build a descriptor of sample complexity in classification problems. The idea is to use the fact that the Kantorovich-Rubinstein distance is a metric in the space of measures that also takes into account the geometry and topology of the underlying metric space. We associate to each class of points a measure and thus study the geometrical information that we can obtain from the Kantorovich-Rubinstein distance between those measures. We show that a large Kantorovich-Rubinstein distance between those measures allows to conclude that there exists a 1-Lipschitz classifier that classifies well the classes of points. We also discuss the limitation of the Kantorovich-Rubinstein distance as a descriptor.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Forman-Ricci&#26354;&#29575;&#25193;&#23637;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#31163;&#25955;&#26354;&#29575;&#65292;&#21487;&#20197;&#28155;&#21152;&#25110;&#21024;&#38500;&#36793;&#20197;&#20943;&#36731;&#36825;&#20004;&#31181;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2309.09384</link><description>&lt;p&gt;
&#20351;&#29992;Forman-Ricci&#26354;&#29575;&#30340;&#25193;&#23637;&#26469;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Mitigating Over-Smoothing and Over-Squashing using Augmentations of Forman-Ricci Curvature. (arXiv:2309.09384v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09384
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Forman-Ricci&#26354;&#29575;&#25193;&#23637;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#36890;&#36807;&#35266;&#23519;&#31163;&#25955;&#26354;&#29575;&#65292;&#21487;&#20197;&#28155;&#21152;&#25110;&#21024;&#38500;&#36793;&#20197;&#20943;&#36731;&#36825;&#20004;&#31181;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#22270;&#32467;&#26500;&#25968;&#25454;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#26368;&#36817;&#25551;&#36848;&#20102;&#20960;&#20010;&#28508;&#22312;&#30340;&#38519;&#38449;&#12290;&#36825;&#20123;&#21253;&#25324;&#26080;&#27861;&#20934;&#30830;&#21033;&#29992;&#32534;&#30721;&#22312;&#38271;&#36317;&#31163;&#36830;&#25509;&#20013;&#30340;&#20449;&#24687;&#65288;&#36807;&#24230;&#21387;&#32553;&#65289;&#65292;&#20197;&#21450;&#22312;&#32593;&#32476;&#28145;&#24230;&#22686;&#21152;&#26102;&#38590;&#20197;&#21306;&#20998;&#38468;&#36817;&#33410;&#28857;&#30340;&#23398;&#20064;&#34920;&#31034;&#65288;&#36807;&#24230;&#24179;&#28369;&#65289;&#12290;&#19968;&#31181;&#26377;&#25928;&#30340;&#34920;&#24449;&#36825;&#20004;&#31181;&#25928;&#24212;&#30340;&#26041;&#27861;&#26159;&#31163;&#25955;&#26354;&#29575;&#65306;&#23548;&#33268;&#36807;&#24230;&#21387;&#32553;&#25928;&#24212;&#30340;&#38271;&#36317;&#31163;&#36830;&#25509;&#20855;&#26377;&#20302;&#26354;&#29575;&#65292;&#32780;&#23548;&#33268;&#36807;&#24230;&#24179;&#28369;&#30340;&#36793;&#20855;&#26377;&#39640;&#26354;&#29575;&#12290;&#36825;&#20010;&#35266;&#23519;&#24341;&#21457;&#20102;&#19968;&#20123;&#37325;&#36830;&#25216;&#26415;&#65292;&#36890;&#36807;&#22686;&#21152;&#25110;&#21024;&#38500;&#36793;&#26469;&#20943;&#36731;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#21033;&#29992;&#22270;&#29305;&#24449;&#65288;&#22914;&#26354;&#29575;&#25110;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#35889;&#65289;&#30340;&#37325;&#36830;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22522;&#20110;&#26354;&#29575;&#30340;&#26041;&#27861;&#65292;&#36890;&#24120;&#38656;&#35201;&#26114;&#36149;&#30340;&#23376;&#22270;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
While Graph Neural Networks (GNNs) have been successfully leveraged for learning on graph-structured data across domains, several potential pitfalls have been described recently. Those include the inability to accurately leverage information encoded in long-range connections (over-squashing), as well as difficulties distinguishing the learned representations of nearby nodes with growing network depth (over-smoothing). An effective way to characterize both effects is discrete curvature: Long-range connections that underlie over-squashing effects have low curvature, whereas edges that contribute to over-smoothing have high curvature. This observation has given rise to rewiring techniques, which add or remove edges to mitigate over-smoothing and over-squashing. Several rewiring approaches utilizing graph characteristics, such as curvature or the spectrum of the graph Laplacian, have been proposed. However, existing methods, especially those based on curvature, often require expensive subr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#65292;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#33021;&#22815;&#25910;&#25947;&#21040;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#36825;&#36866;&#29992;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20855;&#26377;&#20805;&#20998;&#24179;&#28369;&#19988;&#26377;&#30028;&#28608;&#27963;&#20989;&#25968;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36830;&#32493;&#26102;&#38388;SGD&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#20809;&#28369;&#26080;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.09258</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets. (arXiv:2309.09258v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#65292;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#33021;&#22815;&#25910;&#25947;&#21040;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#36825;&#36866;&#29992;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20855;&#26377;&#20805;&#20998;&#24179;&#28369;&#19988;&#26377;&#30028;&#28608;&#27963;&#20989;&#25968;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36830;&#32493;&#26102;&#38388;SGD&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#20809;&#28369;&#26080;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23545;&#20110;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#33021;&#22815;&#25910;&#25947;&#21040;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20855;&#26377;&#20805;&#20998;&#24179;&#28369;&#19988;&#26377;&#30028;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;sigmoid&#21644;tanh&#65289;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36830;&#32493;&#26102;&#38388;SGD&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#20809;&#28369;&#26080;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;SoftPlus&#65289;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#35777;&#26126;&#20102;&#22312;&#24658;&#23450;&#22823;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#23384;&#22312;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#65292;&#36825;&#20123;&#20989;&#25968;&#26159;"Villani&#20989;&#25968;"&#65292;&#20174;&#32780;&#33021;&#22815;&#26500;&#24314;&#22312;&#26368;&#36817;&#23545;&#20110;&#27492;&#31867;&#30446;&#26631;&#20989;&#25968;&#19978;&#20998;&#26512;SGD&#30340;&#30740;&#31350;&#36827;&#23637;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates with adequately smooth and bounded activations like sigmoid and tanh. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized logistic loss functions on constant-sized neural nets which are "Villani functions" and thus be able to build on recent progress with analyzing SGD on such objectives.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20855;&#26377;$\ell_0$&#32422;&#26463;&#30340;&#22810;&#32447;&#24615;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#30340;&#20840;&#23616;&#25910;&#25947;&#21152;&#36895;&#31639;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#30340;&#32467;&#26500;&#20449;&#24687;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#26512;&#22810;&#32500;&#25968;&#25454;&#12290;&#35813;&#31639;&#27861;&#20351;&#29992;&#21152;&#36895;&#27425;&#26799;&#24230;&#20132;&#26367;&#32447;&#24615;&#21270;&#26368;&#23567;&#21270;&#19982;&#33258;&#36866;&#24212;&#21160;&#37327;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.09239</link><description>&lt;p&gt;
&#20855;&#26377;$\ell_0$&#32422;&#26463;&#30340;&#22810;&#32447;&#24615;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#30340;&#20840;&#23616;&#25910;&#25947;&#21152;&#36895;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Globally Convergent Accelerated Algorithms for Multilinear Sparse Logistic Regression with $\ell_0$-constraints. (arXiv:2309.09239v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20855;&#26377;$\ell_0$&#32422;&#26463;&#30340;&#22810;&#32447;&#24615;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#30340;&#20840;&#23616;&#25910;&#25947;&#21152;&#36895;&#31639;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#30340;&#32467;&#26500;&#20449;&#24687;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#26512;&#22810;&#32500;&#25968;&#25454;&#12290;&#35813;&#31639;&#27861;&#20351;&#29992;&#21152;&#36895;&#27425;&#26799;&#24230;&#20132;&#26367;&#32447;&#24615;&#21270;&#26368;&#23567;&#21270;&#19982;&#33258;&#36866;&#24212;&#21160;&#37327;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#25968;&#25454;&#34920;&#31034;&#22810;&#32500;&#25968;&#32452;&#12290;&#22522;&#20110;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#30340;&#22238;&#24402;&#26041;&#27861;&#21033;&#29992;&#32467;&#26500;&#20449;&#24687;&#20943;&#23569;&#21442;&#25968;&#25968;&#37327;&#12290;&#22810;&#32447;&#24615;&#36923;&#36753;&#22238;&#24402;&#26159;&#20998;&#26512;&#22810;&#32500;&#25968;&#25454;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#20026;&#20102;&#25552;&#39640;&#20854;&#25928;&#26524;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;$\ell_0$&#32422;&#26463;&#30340;&#22810;&#32447;&#24615;&#31232;&#30095;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;($\ell_0$-MLSR)&#12290;&#19982;$\ell_1$&#33539;&#25968;&#21644;$\ell_2$&#33539;&#25968;&#30456;&#27604;&#65292;$\ell_0$&#33539;&#25968;&#32422;&#26463;&#26356;&#36866;&#21512;&#29305;&#24449;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#29305;&#24615;&#65292;&#27714;&#35299;&#23427;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32570;&#20047;&#25910;&#25947;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;$\ell_0$-MLSR&#20013;&#30340;&#22810;&#32447;&#24615;&#36816;&#31639;&#20063;&#24102;&#26469;&#20102;&#38750;&#20984;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#36895;&#27425;&#26799;&#24230;&#20132;&#26367;&#32447;&#24615;&#21270;&#26368;&#23567;&#21270;&#19982;&#33258;&#36866;&#24212;&#21160;&#37327;(APALM$^+$)&#26041;&#27861;&#26469;&#27714;&#35299;$\ell_0$-MLSR&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;APALM$^+$&#33021;&#22815;&#30830;&#20445;&#30446;&#26631;&#20989;&#25968;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor data represents a multidimensional array. Regression methods based on low-rank tensor decomposition leverage structural information to reduce the parameter count. Multilinear logistic regression serves as a powerful tool for the analysis of multidimensional data. To improve its efficacy and interpretability, we present a Multilinear Sparse Logistic Regression model with $\ell_0$-constraints ($\ell_0$-MLSR). In contrast to the $\ell_1$-norm and $\ell_2$-norm, the $\ell_0$-norm constraint is better suited for feature selection. However, due to its nonconvex and nonsmooth properties, solving it is challenging and convergence guarantees are lacking. Additionally, the multilinear operation in $\ell_0$-MLSR also brings non-convexity. To tackle these challenges, we propose an Accelerated Proximal Alternating Linearized Minimization with Adaptive Momentum (APALM$^+$) method to solve the $\ell_0$-MLSR model. We provide a proof that APALM$^+$ can ensure the convergence of the objective fu
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#26631;&#20934;&#21270;&#27969;&#24341;&#20837;&#39640;&#26031;&#36807;&#31243;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#27169;&#22411;&#65292;&#20351;&#20854;&#20855;&#22791;&#26356;&#28789;&#27963;&#21644;&#34920;&#36798;&#24615;&#24378;&#30340;&#20808;&#39564;&#20998;&#24067;&#21644;&#38750;&#39640;&#26031;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#36125;&#21494;&#26031;&#39640;&#26031;&#36807;&#31243;ODE&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2309.09222</link><description>&lt;p&gt;
&#21452;&#37325;&#26631;&#20934;&#21270;&#27969;&#65306;&#28789;&#27963;&#30340;&#36125;&#21494;&#26031;&#39640;&#26031;&#36807;&#31243;ODE&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Double Normalizing Flows: Flexible Bayesian Gaussian Process ODEs Learning. (arXiv:2309.09222v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09222
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#26631;&#20934;&#21270;&#27969;&#24341;&#20837;&#39640;&#26031;&#36807;&#31243;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#27169;&#22411;&#65292;&#20351;&#20854;&#20855;&#22791;&#26356;&#28789;&#27963;&#21644;&#34920;&#36798;&#24615;&#24378;&#30340;&#20808;&#39564;&#20998;&#24067;&#21644;&#38750;&#39640;&#26031;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#36125;&#21494;&#26031;&#39640;&#26031;&#36807;&#31243;ODE&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#39640;&#26031;&#36807;&#31243;&#34987;&#29992;&#26469;&#24314;&#27169;&#36830;&#32493;&#21160;&#21147;&#31995;&#32479;&#30340;&#21521;&#37327;&#22330;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#27169;&#22411;&#65292;&#36125;&#21494;&#26031;&#25512;&#26029;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#24182;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#31561;&#20219;&#21153;&#65292;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#30340;&#39640;&#26031;&#36807;&#31243;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#27169;&#22411;&#22312;&#20855;&#26377;&#38750;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#30340;&#25968;&#25454;&#38598;&#19978;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#32422;&#26463;&#20808;&#39564;&#21644;&#22343;&#20540;&#22330;&#21518;&#39564;&#21487;&#33021;&#32570;&#20047;&#28789;&#27963;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26631;&#20934;&#21270;&#27969;&#26469;&#37325;&#26032;&#21442;&#25968;&#21270;ODE&#30340;&#21521;&#37327;&#22330;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#26356;&#28789;&#27963;&#12289;&#26356;&#34920;&#36798;&#24615;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#26631;&#20934;&#21270;&#27969;&#30340;&#35299;&#26512;&#21487;&#35745;&#31639;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;GP ODE&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#29983;&#25104;&#19968;&#20010;&#38750;&#39640;&#26031;&#30340;&#21518;&#39564;&#12290;&#36890;&#36807;&#36825;&#20123;&#26631;&#20934;&#21270;&#27969;&#30340;&#21452;&#37325;&#24212;&#29992;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#36125;&#21494;&#26031;&#39640;&#26031;&#36807;&#31243;ODE&#20013;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, Gaussian processes have been utilized to model the vector field of continuous dynamical systems. Bayesian inference for such models \cite{hegde2022variational} has been extensively studied and has been applied in tasks such as time series prediction, providing uncertain estimates. However, previous Gaussian Process Ordinary Differential Equation (ODE) models may underperform on datasets with non-Gaussian process priors, as their constrained priors and mean-field posteriors may lack flexibility. To address this limitation, we incorporate normalizing flows to reparameterize the vector field of ODEs, resulting in a more flexible and expressive prior distribution. Additionally, due to the analytically tractable probability density functions of normalizing flows, we apply them to the posterior inference of GP ODEs, generating a non-Gaussian posterior. Through these dual applications of normalizing flows, our model improves accuracy and uncertainty estimates for Bayesian Gaussian P
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#65288;MFRL&#65289;&#26041;&#27861;&#26469;&#36827;&#34892;&#23454;&#26102;&#25968;&#25454;&#39537;&#21160;&#30340;&#21046;&#36896;&#36807;&#31243;&#25511;&#21046;&#20248;&#21270;&#65292;&#36890;&#36807;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#29702;&#26469;&#20943;&#23569;&#21046;&#36896;&#36807;&#31243;&#20013;&#25200;&#21160;&#30340;&#22823;&#24133;&#24230;&#21464;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#26410;&#30693;&#36807;&#31243;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#30340;MFRL&#25511;&#21046;&#22120;&#22312;&#38750;&#32447;&#24615;&#21270;&#23398;&#26426;&#26800;&#25243;&#20809;&#65288;CMP&#65289;&#36807;&#31243;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2309.09205</link><description>&lt;p&gt;
MFRL-BI: &#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#29702;&#35774;&#35745;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#36807;&#31243;&#25511;&#21046;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
MFRL-BI: Design of a Model-free Reinforcement Learning Process Control Scheme by Using Bayesian Inference. (arXiv:2309.09205v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09205
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#65288;MFRL&#65289;&#26041;&#27861;&#26469;&#36827;&#34892;&#23454;&#26102;&#25968;&#25454;&#39537;&#21160;&#30340;&#21046;&#36896;&#36807;&#31243;&#25511;&#21046;&#20248;&#21270;&#65292;&#36890;&#36807;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#29702;&#26469;&#20943;&#23569;&#21046;&#36896;&#36807;&#31243;&#20013;&#25200;&#21160;&#30340;&#22823;&#24133;&#24230;&#21464;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#26410;&#30693;&#36807;&#31243;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20986;&#30340;MFRL&#25511;&#21046;&#22120;&#22312;&#38750;&#32447;&#24615;&#21270;&#23398;&#26426;&#26800;&#25243;&#20809;&#65288;CMP&#65289;&#36807;&#31243;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#31243;&#25511;&#21046;&#26041;&#26696;&#30340;&#35774;&#35745;&#23545;&#20110;&#20943;&#23569;&#21046;&#36896;&#31995;&#32479;&#20013;&#30340;&#21464;&#24322;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#30830;&#20445;&#20135;&#21697;&#36136;&#37327;&#12290;&#20197;&#21322;&#23548;&#20307;&#21046;&#36896;&#20026;&#20363;&#65292;&#22823;&#37327;&#25991;&#29486;&#20851;&#27880;&#22522;&#20110;&#26576;&#20123;&#32463;&#36807;&#23454;&#39564;&#33719;&#24471;&#30340;&#36807;&#31243;&#27169;&#22411;&#65288;&#36890;&#24120;&#26159;&#32447;&#24615;&#27169;&#22411;&#65289;&#30340;&#25511;&#21046;&#20248;&#21270;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#39044;&#23450;&#20041;&#30340;&#27169;&#22411;&#21487;&#33021;&#19981;&#20934;&#30830;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#22797;&#26434;&#30340;&#21046;&#36896;&#31995;&#32479;&#12290;&#20026;&#20102;&#35299;&#20915;&#27169;&#22411;&#19981;&#20934;&#30830;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#65288;MFRL&#65289;&#26041;&#27861;&#65292;&#26681;&#25454;&#23454;&#26102;&#25968;&#25454;&#21516;&#26102;&#36827;&#34892;&#23454;&#39564;&#21644;&#20248;&#21270;&#25511;&#21046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MFRL&#25511;&#21046;&#26041;&#26696;&#65292;&#36890;&#36807;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#29702;&#26469;&#26356;&#26032;&#25200;&#21160;&#30340;&#20998;&#24067;&#65292;&#20197;&#20943;&#23569;&#21046;&#36896;&#36807;&#31243;&#20013;&#30340;&#22823;&#24133;&#24230;&#21464;&#21270;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;&#24403;&#36807;&#31243;&#27169;&#22411;&#26410;&#30693;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;MFRL&#25511;&#21046;&#22120;&#22312;&#38750;&#32447;&#24615;&#21270;&#23398;&#26426;&#26800;&#25243;&#20809;&#65288;CMP&#65289;&#36807;&#31243;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Design of process control scheme is critical for quality assurance to reduce variations in manufacturing systems. Taking semiconductor manufacturing as an example, extensive literature focuses on control optimization based on certain process models (usually linear models), which are obtained by experiments before a manufacturing process starts. However, in real applications, pre-defined models may not be accurate, especially for a complex manufacturing system. To tackle model inaccuracy, we propose a model-free reinforcement learning (MFRL) approach to conduct experiments and optimize control simultaneously according to real-time data. Specifically, we design a novel MFRL control scheme by updating the distribution of disturbances using Bayesian inference to reduce their large variations during manufacturing processes. As a result, the proposed MFRL controller is demonstrated to perform well in a nonlinear chemical mechanical planarization (CMP) process when the process model is unknow
&lt;/p&gt;</description></item><item><title>&#40654;&#26364;&#29468;&#24819;&#26159;&#25968;&#23398;&#39046;&#22495;&#20013;&#19968;&#20010;&#21382;&#21490;&#24736;&#20037;&#30340;&#26410;&#35299;&#38382;&#39064;&#65292;&#23427;&#20551;&#35774;&#40654;&#26364;&#20989;&#25968;&#30340;&#38750;&#24179;&#20961;&#38646;&#28857;&#30340;&#23454;&#37096;&#22343;&#31561;&#20110;1/2&#12290;&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#21644;&#25193;&#23637;&#20102;&#19968;&#31181;&#26087;&#20998;&#26512;&#20934;&#21017;&#65292;&#23558;&#40654;&#26364;&#29468;&#24819;&#19982;&#28041;&#21450;&#29305;&#27530;&#31867;&#21035;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#12290;</title><link>http://arxiv.org/abs/2309.09171</link><description>&lt;p&gt;
&#20851;&#20110;&#40654;&#26364;&#29468;&#24819;&#21644;&#19968;&#31867;&#29305;&#27530;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#30340;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
On the Connection Between Riemann Hypothesis and a Special Class of Neural Networks. (arXiv:2309.09171v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09171
&lt;/p&gt;
&lt;p&gt;
&#40654;&#26364;&#29468;&#24819;&#26159;&#25968;&#23398;&#39046;&#22495;&#20013;&#19968;&#20010;&#21382;&#21490;&#24736;&#20037;&#30340;&#26410;&#35299;&#38382;&#39064;&#65292;&#23427;&#20551;&#35774;&#40654;&#26364;&#20989;&#25968;&#30340;&#38750;&#24179;&#20961;&#38646;&#28857;&#30340;&#23454;&#37096;&#22343;&#31561;&#20110;1/2&#12290;&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#21644;&#25193;&#23637;&#20102;&#19968;&#31181;&#26087;&#20998;&#26512;&#20934;&#21017;&#65292;&#23558;&#40654;&#26364;&#29468;&#24819;&#19982;&#28041;&#21450;&#29305;&#27530;&#31867;&#21035;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40654;&#26364;&#29468;&#24819;&#65288;RH&#65289;&#26159;&#25968;&#23398;&#20013;&#19968;&#20010;&#21382;&#21490;&#24736;&#20037;&#30340;&#26410;&#35299;&#38382;&#39064;&#65292;&#23427;&#20551;&#35774;&#40654;&#26364;&#20989;&#25968;&#30340;&#38750;&#24179;&#20961;&#38646;&#28857;&#30340;&#23454;&#37096;&#22343;&#31561;&#20110;1/2&#12290;RH&#30340;&#21518;&#26524;&#24433;&#21709;&#24191;&#27867;&#65292;&#28041;&#21450;&#21040;&#35832;&#22914;&#32032;&#25968;&#20998;&#24067;&#12289;&#31639;&#26415;&#20989;&#25968;&#22686;&#38271;&#12289;&#27431;&#25289;&#20989;&#25968;&#22686;&#38271;&#31561;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#21644;&#25193;&#23637;&#20102;&#19968;&#31181;&#31216;&#20026;Nyman-Beurling&#20934;&#21017;&#30340;RH&#26087;&#20998;&#26512;&#20934;&#21017;&#65292;&#35813;&#20934;&#21017;&#23558;RH&#19982;&#28041;&#21450;&#29305;&#27530;&#31867;&#21035;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#12290;&#26412;&#25991;&#26088;&#22312;&#38754;&#21521;&#37027;&#20123;&#23545;RH&#19981;&#29087;&#24713;&#30340;&#35835;&#32773;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#28201;&#21644;&#30340;RH&#20171;&#32461;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Riemann hypothesis (RH) is a long-standing open problem in mathematics. It conjectures that non-trivial zeros of the zeta function all have real part equal to 1/2. The extent of the consequences of RH is far-reaching and touches a wide spectrum of topics including the distribution of prime numbers, the growth of arithmetic functions, the growth of Euler totient, etc. In this note, we revisit and extend an old analytic criterion of the RH known as the Nyman-Beurling criterion which connects the RH to a minimization problem that involves a special class of neural networks. This note is intended for an audience unfamiliar with RH. A gentle introduction to RH is provided.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.09129</link><description>&lt;p&gt;
$L^1$&#20272;&#35745;&#65306;&#32447;&#24615;&#20272;&#35745;&#22120;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
$L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09129
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#32771;&#34385;&#20174;&#22122;&#22768;&#35266;&#27979;$Y=X+Z$&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$Z$&#26159;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#26159;&#26465;&#20214;&#20013;&#20301;&#25968;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#26465;&#20214;&#20013;&#20301;&#25968;&#20013;&#24341;&#20837;&#32447;&#24615;&#30340;&#21807;&#19968;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#20854;&#20182;&#20960;&#20010;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#35777;&#26126;&#20102;&#22914;&#26524;&#23545;&#20110;&#25152;&#26377;$y$&#65292;&#26465;&#20214;&#20998;&#24067;$P_{X|Y=y}$&#37117;&#26159;&#23545;&#31216;&#30340;&#65292;&#21017;$X$&#24517;&#39035;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20854;&#20182;&#30340;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#20197;&#19979;&#29616;&#35937;&#65306;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#23545;&#20110;$p \in (2,\infty)$&#65292;&#26377;&#26080;&#31351;&#22810;&#20010;&#20808;&#39564;&#20998;&#24067;&#21487;&#20197;&#24341;&#20837;&#32447;&#24615;&#24615;&#12290;&#26368;&#21518;&#65292;&#36824;&#25552;&#20379;&#20102;&#25193;&#23637;&#65292;&#20197;&#28085;&#30422;&#23548;&#33268;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the problem of estimating a random variable $X$ from noisy observations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity criterion. It is well known that the optimal Bayesian estimator in this setting is the conditional median. This work shows that the only prior distribution on $X$ that induces linearity in the conditional median is Gaussian.  Along the way, several other results are presented. In particular, it is demonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for all $y$, then $X$ must follow a Gaussian distribution. Additionally, we consider other $L^p$ losses and observe the following phenomenon: for $p \in [1,2]$, Gaussian is the only prior distribution that induces a linear optimal Bayesian estimator, and for $p \in (2,\infty)$, infinitely many prior distributions on $X$ can induce linearity. Finally, extensions are provided to encompass noise models leading to conditional distributions from certain exponential families.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#23558;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#31616;&#21270;&#20026;&#39034;&#24207;&#20272;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#32622;&#20449;&#24207;&#21015;&#26469;&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#21464;&#21270;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.09111</link><description>&lt;p&gt;
&#23558;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#31616;&#21270;&#20026;&#39034;&#24207;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Reducing sequential change detection to sequential estimation. (arXiv:2309.09111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09111
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#23558;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#31616;&#21270;&#20026;&#39034;&#24207;&#20272;&#35745;&#65292;&#36890;&#36807;&#20351;&#29992;&#32622;&#20449;&#24207;&#21015;&#26469;&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#21464;&#21270;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#33021;&#22815;&#26816;&#27979;&#25968;&#25454;&#27969;&#20998;&#24067;&#20013;&#21442;&#25968;&#25110;&#20989;&#25968;&#120579;&#30340;&#20219;&#20309;&#21464;&#21270;&#30340;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20855;&#26377;&#36739;&#23567;&#30340;&#26816;&#27979;&#24310;&#36831;&#65292;&#20294;&#22312;&#27809;&#26377;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#20445;&#35777;&#20551;&#35686;&#25253;&#30340;&#39057;&#29575;&#21463;&#25511;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#32622;&#20449;&#24207;&#21015;&#25551;&#36848;&#20102;&#19968;&#31181;&#20174;&#39034;&#24207;&#21464;&#21270;&#26816;&#27979;&#21040;&#39034;&#24207;&#20272;&#35745;&#30340;&#31616;&#21333;&#32422;&#21270;&#26041;&#27861;&#65306;&#25105;&#20204;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#24320;&#22987;&#19968;&#20010;&#26032;&#30340;$(1-\alpha)$&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#22312;&#25152;&#26377;&#27963;&#21160;&#32622;&#20449;&#24207;&#21015;&#30340;&#20132;&#38598;&#20026;&#31354;&#26102;&#23459;&#24067;&#21464;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24179;&#22343;&#25345;&#32493;&#26102;&#38388;&#33267;&#23569;&#20026;$1/\alpha$&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#20855;&#26377;&#26368;&#23567;&#32467;&#26500;&#20551;&#35774;&#30340;&#21464;&#21270;&#26816;&#27979;&#26041;&#26696;&#65288;&#22240;&#27492;&#20801;&#35768;&#21487;&#33021;&#30456;&#20851;&#30340;&#35266;&#27979;&#21644;&#38750;&#21442;&#25968;&#20998;&#24067;&#31867;&#65289;&#65292;&#20294;&#21364;&#20855;&#26377;&#24378;&#22823;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;Lorden&#65288;1971&#65289;&#30340;&#21464;&#21270;&#26816;&#27979;&#21040;&#39034;&#24207;&#27979;&#35797;&#30340;&#31616;&#21270;&#21644;Shin&#31561;&#20154;&#30340;e-detector&#26377;&#30528;&#26377;&#36259;&#30340;&#30456;&#20284;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sequential change detection, where the goal is to design a scheme for detecting any changes in a parameter or functional $\theta$ of the data stream distribution that has small detection delay, but guarantees control on the frequency of false alarms in the absence of changes. In this paper, we describe a simple reduction from sequential change detection to sequential estimation using confidence sequences: we begin a new $(1-\alpha)$-confidence sequence at each time step, and proclaim a change when the intersection of all active confidence sequences becomes empty. We prove that the average run length is at least $1/\alpha$, resulting in a change detection scheme with minimal structural assumptions~(thus allowing for possibly dependent observations, and nonparametric distribution classes), but strong guarantees. Our approach bears an interesting parallel with the reduction from change detection to sequential testing of Lorden (1971) and the e-detector of Shin e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#31232;&#30095;&#25110;&#29983;&#25104;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#35299;&#20915;&#20102;&#20174;&#20840;&#31209;&#30697;&#38453;&#30340;&#20108;&#27425;&#31995;&#32479;&#20013;&#24674;&#22797;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#38408;&#20540;Wirtinger&#27969;&#31639;&#27861;&#65288;TWF&#65289;&#26469;&#22788;&#29702;&#31232;&#30095;&#20449;&#21495;&#65292;&#24182;&#20351;&#29992;&#35889;&#21021;&#22987;&#21270;&#21644;&#38408;&#20540;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36739;&#23567;&#30340;&#27979;&#37327;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2309.09032</link><description>&lt;p&gt;
&#20351;&#29992;&#31232;&#30095;&#25110;&#29983;&#25104;&#30340;&#20808;&#39564;&#35299;&#20915;&#20840;&#31209;&#30697;&#38453;&#30340;&#20108;&#27425;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Solving Quadratic Systems with Full-Rank Matrices Using Sparse or Generative Priors. (arXiv:2309.09032v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#31232;&#30095;&#25110;&#29983;&#25104;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#35299;&#20915;&#20102;&#20174;&#20840;&#31209;&#30697;&#38453;&#30340;&#20108;&#27425;&#31995;&#32479;&#20013;&#24674;&#22797;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#36890;&#36807;&#24341;&#20837;&#38408;&#20540;Wirtinger&#27969;&#31639;&#27861;&#65288;TWF&#65289;&#26469;&#22788;&#29702;&#31232;&#30095;&#20449;&#21495;&#65292;&#24182;&#20351;&#29992;&#35889;&#21021;&#22987;&#21270;&#21644;&#38408;&#20540;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36739;&#23567;&#30340;&#27979;&#37327;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20855;&#26377;&#20840;&#31209;&#30697;&#38453;&#30340;&#20108;&#27425;&#31995;&#32479;&#20013;&#24674;&#22797;&#20449;&#21495;x&#22312;&#24212;&#29992;&#20013;&#32463;&#24120;&#20986;&#29616;&#65292;&#27604;&#22914;&#26410;&#20998;&#37197;&#30340;&#36317;&#31163;&#20960;&#20309;&#21644;&#20122;&#27874;&#38271;&#25104;&#20687;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#23545;x&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#38024;&#23545;&#39640;&#32500;&#24773;&#20917;&#65288;m &lt;&lt; n&#65289;&#65292;&#20351;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26631;&#20934;&#39640;&#26031;&#30697;&#38453;&#35299;&#20915;&#20102;&#35813;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#32771;&#34385;k-&#31232;&#30095;&#30340;x&#65292;&#24341;&#20837;&#20102;TWF&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#19981;&#38656;&#35201;&#31232;&#30095;&#27700;&#24179;k&#12290;TWF&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#35889;&#21021;&#22987;&#21270;&#65292;&#24403;m = O(k^2log n)&#26102;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#36317;&#31163;x&#36275;&#22815;&#36817;&#30340;&#28857;&#65288;&#21487;&#33021;&#20250;&#26377;&#31526;&#21495;&#32763;&#36716;&#65289;&#65292;&#20197;&#21450;&#20855;&#26377;&#24456;&#22909;&#21021;&#22987;&#21270;&#30340;&#38408;&#20540;&#26799;&#24230;&#19979;&#38477;&#65292;&#35813;&#19979;&#38477;&#20135;&#29983;&#20102;&#19968;&#20010;&#32447;&#24615;&#25910;&#25947;&#21040;x&#30340;&#24207;&#21015;&#65292;&#29992;m = O(klog n)&#20010;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of recovering a signal $\boldsymbol{x} \in \mathbb{R}^n$ from a quadratic system $\{y_i=\boldsymbol{x}^\top\boldsymbol{A}_i\boldsymbol{x},\ i=1,\ldots,m\}$ with full-rank matrices $\boldsymbol{A}_i$ frequently arises in applications such as unassigned distance geometry and sub-wavelength imaging. With i.i.d. standard Gaussian matrices $\boldsymbol{A}_i$, this paper addresses the high-dimensional case where $m\ll n$ by incorporating prior knowledge of $\boldsymbol{x}$. First, we consider a $k$-sparse $\boldsymbol{x}$ and introduce the thresholded Wirtinger flow (TWF) algorithm that does not require the sparsity level $k$. TWF comprises two steps: the spectral initialization that identifies a point sufficiently close to $\boldsymbol{x}$ (up to a sign flip) when $m=O(k^2\log n)$, and the thresholded gradient descent (with a good initialization) that produces a sequence linearly converging to $\boldsymbol{x}$ with $m=O(k\log n)$ measurements. Second, we explore the generative p
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20811;&#37324;&#26031;&#25176;&#36153;&#23572;&#20989;&#25968;&#21644;&#20849;&#24418;&#39044;&#27979;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#30340;&#21487;&#36798;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20272;&#35745;&#22797;&#26434;&#31995;&#32479;&#30340;&#21487;&#36798;&#38598;&#21512;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#24050;&#30693;&#30340;&#25968;&#23398;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.08976</link><description>&lt;p&gt;
&#22522;&#20110;&#20811;&#37324;&#26031;&#25176;&#36153;&#23572;&#20989;&#25968;&#21644;&#20849;&#24418;&#39044;&#27979;&#30340;&#25968;&#25454;&#39537;&#21160;&#21487;&#36798;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Data-driven Reachability using Christoffel Functions and Conformal Prediction. (arXiv:2309.08976v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08976
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#20811;&#37324;&#26031;&#25176;&#36153;&#23572;&#20989;&#25968;&#21644;&#20849;&#24418;&#39044;&#27979;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#30340;&#21487;&#36798;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#20272;&#35745;&#22797;&#26434;&#31995;&#32479;&#30340;&#21487;&#36798;&#38598;&#21512;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#24050;&#30693;&#30340;&#25968;&#23398;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21160;&#21147;&#31995;&#32479;&#20998;&#26512;&#20013;&#65292;&#19968;&#31181;&#37325;&#35201;&#30340;&#25968;&#23398;&#24037;&#20855;&#26159;&#36817;&#20284;&#21487;&#36798;&#38598;&#21512;&#65292;&#21363;&#20174;&#32473;&#23450;&#21021;&#22987;&#29366;&#24577;&#32463;&#36807;&#19968;&#23450;&#26102;&#38388;&#21487;&#20197;&#21040;&#36798;&#30340;&#29366;&#24577;&#38598;&#21512;&#12290;&#21363;&#20351;&#31995;&#32479;&#21160;&#21147;&#23398;&#24050;&#30693;&#19988;&#30001;&#24050;&#30693;&#31995;&#25968;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#32452;&#32473;&#20986;&#65292;&#23545;&#22797;&#26434;&#31995;&#32479;&#26469;&#35828;&#65292;&#35813;&#38598;&#21512;&#24456;&#38590;&#35745;&#31639;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#21442;&#25968;&#24120;&#24120;&#26159;&#26410;&#30693;&#30340;&#65292;&#25968;&#23398;&#27169;&#22411;&#38590;&#20197;&#33719;&#24471;&#12290;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#36890;&#36807;&#22522;&#20110;&#29366;&#24577;&#26679;&#26412;&#20272;&#31639;&#21487;&#36798;&#38598;&#21512;&#26469;&#36991;&#20813;&#36825;&#20123;&#22256;&#38590;&#12290;&#22914;&#26524;&#26377;&#27169;&#22411;&#21487;&#29992;&#65292;&#21487;&#20197;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#33719;&#24471;&#35757;&#32451;&#38598;&#12290;&#22312;&#27809;&#26377;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#20351;&#29992;&#23454;&#38469;&#35266;&#27979;&#32467;&#26524;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#21487;&#36798;&#38598;&#21512;&#36817;&#20284;&#26041;&#27861;&#20351;&#29992;&#20811;&#37324;&#26031;&#25176;&#36153;&#23572;&#20989;&#25968;&#26469;&#36817;&#20284;&#21487;&#36798;&#38598;&#21512;&#12290;&#22312;&#19968;&#23450;&#30340;&#20551;&#35774;&#19979;&#65292;&#36825;&#31181;&#36817;&#20284;&#26041;&#27861;&#21487;&#20197;&#25910;&#25947;&#21040;&#30495;&#23454;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#23588;&#20854;&#26159;&#21487;&#36798;&#38598;&#21512;&#36817;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An important mathematical tool in the analysis of dynamical systems is the approximation of the reach set, i.e., the set of states reachable after a given time from a given initial state. This set is difficult to compute for complex systems even if the system dynamics are known and given by a system of ordinary differential equations with known coefficients. In practice, parameters are often unknown and mathematical models difficult to obtain. Data-based approaches are promised to avoid these difficulties by estimating the reach set based on a sample of states. If a model is available, this training set can be obtained through numerical simulation. In the absence of a model, real-life observations can be used instead. A recently proposed approach for data-based reach set approximation uses Christoffel functions to approximate the reach set. Under certain assumptions, the approximation is guaranteed to converge to the true solution. In this paper, we improve upon these results by notabl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#27861;&#39034;&#24207;&#23454;&#39564;&#35774;&#35745;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;Shapley&#20540;&#12290;&#36825;&#35299;&#20915;&#20102;&#22312;&#35745;&#31639;Shapley&#20540;&#26102;&#30340;&#39640;&#35745;&#31639;&#36127;&#25285;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.08923</link><description>&lt;p&gt;
&#22522;&#20110;&#21152;&#27861;&#39034;&#24207;&#23454;&#39564;&#35774;&#35745;&#30340;Shapley&#20540;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast Approximation of the Shapley Values Based on Order-of-Addition Experimental Designs. (arXiv:2309.08923v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08923
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#27861;&#39034;&#24207;&#23454;&#39564;&#35774;&#35745;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;Shapley&#20540;&#12290;&#36825;&#35299;&#20915;&#20102;&#22312;&#35745;&#31639;Shapley&#20540;&#26102;&#30340;&#39640;&#35745;&#31639;&#36127;&#25285;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#26368;&#21021;&#26159;&#32463;&#27982;&#35745;&#37327;&#23398;&#20013;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#29992;&#20110;&#20844;&#24179;&#22320;&#20998;&#37197;&#32852;&#30431;&#21338;&#24328;&#20013;&#30340;&#25910;&#30410;&#21644;&#25104;&#26412;&#32473;&#29609;&#23478;&#12290;&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#23427;&#30340;&#24212;&#29992;&#24050;&#32463;&#25193;&#23637;&#21040;&#33829;&#38144;&#12289;&#24037;&#31243;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#20854;&#20182;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#20854;&#35745;&#31639;&#36127;&#25285;&#36739;&#37325;&#19968;&#30452;&#34987;&#35748;&#35782;&#21040;&#20294;&#24456;&#23569;&#26377;&#30740;&#31350;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#19968;&#20010;$d$-player&#32852;&#30431;&#21338;&#24328;&#20013;&#65292;&#35745;&#31639;Shapley&#20540;&#38656;&#35201;&#35780;&#20272;$d!$&#25110;$2^d$&#20010;&#36793;&#38469;&#36129;&#29486;&#20540;&#65292;&#36825;&#21462;&#20915;&#20110;&#25105;&#20204;&#37319;&#29992;&#25490;&#21015;&#36824;&#26159;&#32452;&#21512;&#24418;&#24335;&#30340;Shapley&#20540;&#12290;&#22240;&#27492;&#65292;&#24403;$d$&#30456;&#23545;&#36739;&#22823;&#26102;&#65292;&#35745;&#31639;Shapley&#20540;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#36890;&#24120;&#30340;&#35299;&#20915;&#26041;&#27861;&#26159;&#23545;&#25490;&#21015;&#30340;&#38543;&#26426;&#37319;&#26679;&#26469;&#36817;&#20284;&#23436;&#25972;&#30340;&#25490;&#21015;&#21015;&#34920;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley value is originally a concept in econometrics to fairly distribute both gains and costs to players in a coalition game. In the recent decades, its application has been extended to other areas such as marketing, engineering and machine learning. For example, it produces reasonable solutions for problems in sensitivity analysis, local model explanation towards the interpretable machine learning, node importance in social network, attribution models, etc. However, its heavy computational burden has been long recognized but rarely investigated. Specifically, in a $d$-player coalition game, calculating a Shapley value requires the evaluation of $d!$ or $2^d$ marginal contribution values, depending on whether we are taking the permutation or combination formulation of the Shapley value. Hence it becomes infeasible to calculate the Shapley value when $d$ is reasonably large. A common remedy is to take a random sample of the permutations to surrogate for the complete list of permutatio
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08911</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Methods for Non-stationary Online Learning. (arXiv:2309.08911v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08911
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#36890;&#36807;&#38477;&#20302;&#27599;&#36718;&#25237;&#24433;&#30340;&#25968;&#37327;&#26469;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#24179;&#31283;&#22312;&#32447;&#23398;&#20064;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#29305;&#21035;&#26159;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#65292;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#34987;&#25552;&#20986;&#20316;&#20026;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#20004;&#20010;&#21407;&#21017;&#24615;&#24615;&#33021;&#24230;&#37327;&#12290;&#20026;&#20102;&#20248;&#21270;&#23427;&#20204;&#65292;&#36890;&#24120;&#37319;&#29992;&#20004;&#23618;&#22312;&#32447;&#38598;&#25104;&#65292;&#30001;&#20110;&#38750;&#24179;&#31283;&#24615;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#65292;&#20854;&#20013;&#32500;&#25252;&#19968;&#32452;&#22522;&#23398;&#20064;&#22120;&#65292;&#24182;&#37319;&#29992;&#20803;&#31639;&#27861;&#22312;&#36816;&#34892;&#36807;&#31243;&#20013;&#36319;&#36394;&#26368;&#20339;&#23398;&#20064;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#20004;&#23618;&#32467;&#26500;&#24341;&#21457;&#20102;&#20851;&#20110;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#25285;&#24551; -&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21516;&#26102;&#32500;&#25252;$\mathcal{O}(\log T)$&#20010;&#22522;&#23398;&#20064;&#22120;&#65292;&#23545;&#20110;&#19968;&#20010;$T$&#36718;&#22312;&#32447;&#28216;&#25103;&#65292;&#22240;&#27492;&#27599;&#36718;&#25191;&#34892;&#22810;&#27425;&#25237;&#24433;&#21040;&#21487;&#34892;&#22495;&#19978;&#65292;&#24403;&#22495;&#24456;&#22797;&#26434;&#26102;&#65292;&#36825;&#25104;&#20026;&#35745;&#31639;&#29942;&#39048;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20248;&#21270;&#21160;&#24577;&#36951;&#25022;&#21644;&#33258;&#36866;&#24212;&#36951;&#25022;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#23558;&#27599;&#36718;&#30340;&#25237;&#24433;&#27425;&#25968;&#20174;$\mathcal{O}(\log T)$&#38477;&#20302;&#21040;...
&lt;/p&gt;
&lt;p&gt;
Non-stationary online learning has drawn much attention in recent years. In particular, dynamic regret and adaptive regret are proposed as two principled performance measures for online convex optimization in non-stationary environments. To optimize them, a two-layer online ensemble is usually deployed due to the inherent uncertainty of the non-stationarity, in which a group of base-learners are maintained and a meta-algorithm is employed to track the best one on the fly. However, the two-layer structure raises the concern about the computational complexity -- those methods typically maintain $\mathcal{O}(\log T)$ base-learners simultaneously for a $T$-round online game and thus perform multiple projections onto the feasible domain per round, which becomes the computational bottleneck when the domain is complicated. In this paper, we present efficient methods for optimizing dynamic regret and adaptive regret, which reduce the number of projections per round from $\mathcal{O}(\log T)$ t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26377;&#38480;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#23398;&#20064;&#32447;&#24615;&#21270;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#35823;&#24046;&#30028;&#23637;&#31034;&#20102;&#38750;&#32447;&#24615;&#35823;&#24046;&#21644;&#22122;&#22768;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#34920;&#26126;&#22312;&#26377;&#36275;&#22815;&#22810;&#30340;&#26679;&#26412;&#26102;&#65292;&#21487;&#20197;&#23398;&#20064;&#21040;&#20855;&#26377;&#20219;&#24847;&#23567;&#35823;&#24046;&#30340;&#32447;&#24615;&#21270;&#21160;&#21147;&#23398;&#12290;</title><link>http://arxiv.org/abs/2309.08805</link><description>&lt;p&gt;
&#20174;&#26377;&#38480;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#23398;&#20064;&#32447;&#24615;&#21270;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Linearized Models from Nonlinear Systems with Finite Data. (arXiv:2309.08805v1 [eess.SY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08805
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26377;&#38480;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#23398;&#20064;&#32447;&#24615;&#21270;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#35823;&#24046;&#30028;&#23637;&#31034;&#20102;&#38750;&#32447;&#24615;&#35823;&#24046;&#21644;&#22122;&#22768;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#34920;&#26126;&#22312;&#26377;&#36275;&#22815;&#22810;&#30340;&#26679;&#26412;&#26102;&#65292;&#21487;&#20197;&#23398;&#20064;&#21040;&#20855;&#26377;&#20219;&#24847;&#23567;&#35823;&#24046;&#30340;&#32447;&#24615;&#21270;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25511;&#21046;&#29702;&#35770;&#20013;&#65292;&#20174;&#25968;&#25454;&#20013;&#35782;&#21035;&#20986;&#32447;&#24615;&#31995;&#32479;&#27169;&#22411;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#29616;&#26377;&#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#26469;&#33258;&#21333;&#20010;&#31995;&#32479;&#36712;&#36857;&#30340;&#25968;&#25454;&#65292;&#24182;&#20551;&#35774;&#28508;&#22312;&#30340;&#21160;&#21147;&#23398;&#26159;&#30495;&#27491;&#30340;&#32447;&#24615;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24403;&#30495;&#23454;&#30340;&#28508;&#22312;&#21160;&#21147;&#23398;&#26159;&#38750;&#32447;&#24615;&#26102;&#65292;&#35782;&#21035;&#32447;&#24615;&#21270;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#20010;&#36712;&#36857;&#30340;&#30830;&#23450;&#24615;&#25968;&#25454;&#37319;&#38598;&#31639;&#27861;&#65292;&#28982;&#21518;&#20351;&#29992;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#31639;&#27861;&#65292;&#24471;&#21040;&#20102;&#23398;&#20064;&#24471;&#21040;&#30340;&#32447;&#24615;&#21270;&#21160;&#21147;&#23398;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#12290;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#23637;&#31034;&#20102;&#38750;&#32447;&#24615;&#35823;&#24046;&#21644;&#22122;&#22768;&#35823;&#24046;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#34920;&#26126;&#22312;&#26377;&#36275;&#22815;&#22810;&#30340;&#26679;&#26412;&#26102;&#65292;&#21487;&#20197;&#23398;&#20064;&#21040;&#20855;&#26377;&#20219;&#24847;&#23567;&#35823;&#24046;&#30340;&#32447;&#24615;&#21270;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;&#20351;&#29992;&#21333;&#20010;&#36712;&#36857;&#36827;&#34892;&#32447;&#24615;&#31995;&#32479;&#35782;&#21035;&#30340;&#28508;&#22312;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying a linear system model from data has wide applications in control theory. The existing work on finite sample analysis for linear system identification typically uses data from a single system trajectory under i.i.d random inputs, and assumes that the underlying dynamics is truly linear. In contrast, we consider the problem of identifying a linearized model when the true underlying dynamics is nonlinear. We provide a multiple trajectories-based deterministic data acquisition algorithm followed by a regularized least squares algorithm, and provide a finite sample error bound on the learned linearized dynamics. Our error bound demonstrates a trade-off between the error due to nonlinearity and the error due to noise, and shows that one can learn the linearized dynamics with arbitrarily small error given sufficiently many samples. We validate our results through experiments, where we also show the potential insufficiency of linear system identification using a single trajectory w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.08783</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#24322;&#26041;&#24046;&#38382;&#39064;&#21450;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Heteroscedastic sparse high-dimensional linear regression with a partitioned empirical Bayes ECM algorithm. (arXiv:2309.08783v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#24322;&#26041;&#24046;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;ECM&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;&#36825;&#20010;&#27169;&#22411;&#21487;&#20197;&#22788;&#29702;&#27531;&#24046;&#26041;&#24046;&#19981;&#24658;&#23450;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#26469;&#28789;&#27963;&#22320;&#35843;&#25972;&#26041;&#24046;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#25968;&#25454;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#27531;&#24046;&#20855;&#26377;&#24120;&#25968;&#26041;&#24046;&#12290;&#24403;&#36825;&#19968;&#20551;&#35774;&#34987;&#36829;&#32972;&#26102;&#65292;&#20250;&#23548;&#33268;&#20272;&#35745;&#31995;&#25968;&#30340;&#20559;&#24046;&#65292;&#39044;&#27979;&#21306;&#38388;&#38271;&#24230;&#19981;&#21512;&#36866;&#20197;&#21450;&#22686;&#21152;I&#22411;&#38169;&#35823;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20998;&#21306;&#32463;&#39564;&#36125;&#21494;&#26031;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(H-PROBE)&#31639;&#27861;&#30340;&#24322;&#26041;&#24046;&#39640;&#32500;&#24230;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;H-PROBE&#26159;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#26041;&#27861;&#65292;&#22522;&#20110;&#21442;&#25968;&#25193;&#23637;&#30340;&#26399;&#26395;&#26465;&#20214;&#26368;&#22823;&#21270;(PX-ECM)&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#25554;&#20540;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#36229;&#21442;&#25968;&#65292;&#22312;&#22238;&#24402;&#21442;&#25968;&#19978;&#20551;&#35774;&#26368;&#23567;&#12290;&#26041;&#24046;&#27169;&#22411;&#20351;&#29992;&#20102;&#22810;&#20803;&#23545;&#25968;&#20285;&#39532;&#20998;&#24067;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#21487;&#20197;&#21253;&#21547;&#20551;&#35774;&#20250;&#24433;&#21709;&#24322;&#36136;&#24615;&#30340;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#21160;&#26426;&#26159;&#36890;&#36807;T2&#39640;&#20998;&#36776;&#29575;&#31070;&#32463;&#24433;&#20687;&#30740;&#31350;&#19982;&#22833;&#35821;&#25351;&#25968;(AQ)&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear regression methods for high-dimensional data often assume that residuals have constant variance. When this assumption is violated, it can lead to bias in estimated coefficients, prediction intervals with improper length, and increased type I errors. This paper proposes a heteroscedastic (H) high-dimensional linear regression model through a partitioned empirical Bayes Expectation Conditional Maximization (H-PROBE) algorithm. H-PROBE is a computationally efficient maximum a posteriori (MAP) estimation approach based on a Parameter-Expanded Expectation-Conditional-Maximization (PX-ECM) algorithm. It requires minimal prior assumptions on the regression parameters through plug-in empirical Bayes estimates of hyperparameters. The variance model uses recent advances in multivariate log-Gamma distribution theory and can include covariates hypothesized to impact heterogeneity. The motivation of our approach is a study relating Aphasia Quotient (AQ) to high-resolution T2 neuroimag
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#26469;&#21152;&#36895;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36951;&#25022;&#26368;&#23567;&#21270;&#21644;&#32858;&#31867;&#36136;&#37327;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08710</link><description>&lt;p&gt;
&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Clustered Multi-Agent Linear Bandits. (arXiv:2309.08710v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#26469;&#21152;&#36895;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36951;&#25022;&#26368;&#23567;&#21270;&#21644;&#32858;&#31867;&#36136;&#37327;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#38382;&#39064;&#30340;&#19968;&#20010;&#29305;&#23450;&#23454;&#20363;&#65292;&#21363;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#26377;&#25928;&#21327;&#20316;&#26469;&#21152;&#36895;&#25972;&#20307;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#36825;&#19968;&#36129;&#29486;&#20013;&#65292;&#32593;&#32476;&#25511;&#21046;&#22120;&#36127;&#36131;&#20272;&#35745;&#32593;&#32476;&#30340;&#22522;&#26412;&#38598;&#32676;&#32467;&#26500;&#24182;&#20248;&#21270;&#21516;&#19968;&#32452;&#20013;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#32463;&#39564;&#20998;&#20139;&#12290;&#25105;&#20204;&#23545;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#21644;&#32858;&#31867;&#36136;&#37327;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#19982;&#26368;&#20808;&#36827;&#31639;&#27861;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#25105;&#20204;&#30340;&#31639;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#24182;&#25104;&#21151;&#24674;&#22797;&#20102;&#30495;&#23454;&#30340;&#22522;&#26412;&#38598;&#32676;&#21010;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address in this paper a particular instance of the multi-agent linear stochastic bandit problem, called clustered multi-agent linear bandits. In this setting, we propose a novel algorithm leveraging an efficient collaboration between the agents in order to accelerate the overall optimization problem. In this contribution, a network controller is responsible for estimating the underlying cluster structure of the network and optimizing the experiences sharing among agents within the same groups. We provide a theoretical analysis for both the regret minimization problem and the clustering quality. Through empirical evaluation against state-of-the-art algorithms on both synthetic and real data, we demonstrate the effectiveness of our approach: our algorithm significantly improves regret minimization while managing to recover the true underlying cluster partitioning.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#32447;&#24615;&#21453;&#39304;&#30340;&#23433;&#20840;&#26368;&#20248;&#33218;&#35782;&#21035;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#21033;&#29992;&#32447;&#24615;&#32467;&#26500;&#26469;&#20445;&#35777;&#22312;&#27599;&#19968;&#36718;&#20013;&#19981;&#36829;&#21453;&#38454;&#27573;&#24615;&#23433;&#20840;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38388;&#38553;&#30340;&#31639;&#27861;&#26469;&#23454;&#29616;&#26377;&#24847;&#20041;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08709</link><description>&lt;p&gt;
&#32447;&#24615;&#26368;&#20248;&#33218;&#35782;&#21035;&#20013;&#30340;&#23433;&#20840;&#20195;&#20215;
&lt;/p&gt;
&lt;p&gt;
Price of Safety in Linear Best Arm Identification. (arXiv:2309.08709v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08709
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#32447;&#24615;&#21453;&#39304;&#30340;&#23433;&#20840;&#26368;&#20248;&#33218;&#35782;&#21035;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#21033;&#29992;&#32447;&#24615;&#32467;&#26500;&#26469;&#20445;&#35777;&#22312;&#27599;&#19968;&#36718;&#20013;&#19981;&#36829;&#21453;&#38454;&#27573;&#24615;&#23433;&#20840;&#32422;&#26463;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38388;&#38553;&#30340;&#31639;&#27861;&#26469;&#23454;&#29616;&#26377;&#24847;&#20041;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#20855;&#26377;&#32447;&#24615;&#21453;&#39304;&#30340;&#23433;&#20840;&#26368;&#20248;&#33218;&#35782;&#21035;&#26694;&#26550;&#65292;&#20854;&#20013;&#20195;&#29702;&#21463;&#21040;&#19968;&#20123;&#38454;&#27573;&#24615;&#23433;&#20840;&#32422;&#26463;&#30340;&#38480;&#21046;&#65292;&#35813;&#38480;&#21046;&#32447;&#24615;&#22320;&#20381;&#36182;&#20110;&#26410;&#30693;&#30340;&#21442;&#25968;&#21521;&#37327;&#12290;&#20195;&#29702;&#24517;&#39035;&#20197;&#20445;&#23432;&#30340;&#26041;&#24335;&#37319;&#21462;&#34892;&#21160;&#65292;&#20197;&#30830;&#20445;&#22312;&#27599;&#19968;&#36718;&#20013;&#19981;&#20250;&#39640;&#27010;&#29575;&#36829;&#21453;&#23433;&#20840;&#32422;&#26463;&#12290;&#24050;&#32463;&#30740;&#31350;&#20102;&#21033;&#29992;&#32447;&#24615;&#32467;&#26500;&#26469;&#30830;&#20445;&#23433;&#20840;&#24615;&#30340;&#26041;&#27861;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36824;&#27809;&#26377;&#30740;&#31350;&#22312;&#26368;&#20248;&#33218;&#35782;&#21035;&#20013;&#24212;&#29992;&#35813;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38388;&#38553;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#30830;&#20445;&#38454;&#27573;&#24615;&#23433;&#20840;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#26377;&#24847;&#20041;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#30001;&#20110;&#39069;&#22806;&#30340;&#23433;&#20840;&#32422;&#26463;&#23548;&#33268;&#30340;&#24378;&#21046;&#25506;&#32034;&#38454;&#27573;&#65292;&#25105;&#20204;&#22312;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#20184;&#20986;&#20102;&#39069;&#22806;&#30340;&#20195;&#20215;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#39564;&#35828;&#26126;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the safe best-arm identification framework with linear feedback, where the agent is subject to some stage-wise safety constraint that linearly depends on an unknown parameter vector. The agent must take actions in a conservative way so as to ensure that the safety constraint is not violated with high probability at each round. Ways of leveraging the linear structure for ensuring safety has been studied for regret minimization, but not for best-arm identification to the best our knowledge. We propose a gap-based algorithm that achieves meaningful sample complexity while ensuring the stage-wise safety. We show that we pay an extra term in the sample complexity due to the forced exploration phase incurred by the additional safety constraint. Experimental illustrations are provided to justify the design of our algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#39640;&#32500;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32852;&#21512;&#32452;&#21512;-&#23450;&#20215;&#38382;&#39064;&#65292;&#36890;&#36807;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#27169;&#22411;&#25429;&#25417;&#21327;&#21464;&#37327;&#21644;&#34892;&#20026;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;&#35813;&#26041;&#27861;&#20860;&#23481;&#22810;&#31181;&#32467;&#26500;&#21270;&#30340;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#21644;&#23450;&#20215;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#30340;&#27969;&#31243;&#12290;</title><link>http://arxiv.org/abs/2309.08634</link><description>&lt;p&gt;
&#21452;&#39640;&#32500;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65306;&#29992;&#20110;&#32852;&#21512;&#32452;&#21512;-&#23450;&#20215;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Doubly High-Dimensional Contextual Bandits: An Interpretable Model for Joint Assortment-Pricing. (arXiv:2309.08634v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08634
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#39640;&#32500;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32852;&#21512;&#32452;&#21512;-&#23450;&#20215;&#38382;&#39064;&#65292;&#36890;&#36807;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#27169;&#22411;&#25429;&#25417;&#21327;&#21464;&#37327;&#21644;&#34892;&#20026;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;&#35813;&#26041;&#27861;&#20860;&#23481;&#22810;&#31181;&#32467;&#26500;&#21270;&#30340;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#21644;&#23450;&#20215;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#30340;&#27969;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38646;&#21806;&#19994;&#21153;&#30340;&#20851;&#38190;&#25361;&#25112;&#20043;&#19968;&#26159;&#22914;&#20309;&#36873;&#25321;&#35201;&#21521;&#28040;&#36153;&#32773;&#23637;&#31034;&#30340;&#20135;&#21697;&#65288;&#32452;&#21512;&#38382;&#39064;&#65289;&#65292;&#20197;&#21450;&#22914;&#20309;&#23450;&#20215;&#20135;&#21697;&#65288;&#23450;&#20215;&#38382;&#39064;&#65289;&#20197;&#26368;&#22823;&#21270;&#25910;&#20837;&#25110;&#21033;&#28070;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#32852;&#21512;&#32452;&#21512;-&#23450;&#20215;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21516;&#26102;&#32771;&#34385;&#20102;&#32452;&#21512;&#21644;&#23450;&#20215;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#26159;&#21452;&#39640;&#32500;&#30340;&#65292;&#21363;&#19978;&#19979;&#25991;&#21521;&#37327;&#21644;&#34892;&#20026;&#37117;&#20801;&#35768;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#21462;&#20540;&#12290;&#20026;&#20102;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#28789;&#27963;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#65288;&#36817;&#20284;&#65289;&#20302;&#31209;&#34920;&#31034;&#30697;&#38453;&#26469;&#25429;&#25417;&#21327;&#21464;&#37327;&#21644;&#34892;&#20026;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#24471;&#21040;&#30340;&#27169;&#22411;&#31867;&#26159;&#30456;&#24403;&#34920;&#36798;&#21147;&#30340;&#65292;&#21516;&#26102;&#36890;&#36807;&#28508;&#22312;&#22240;&#32032;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#21253;&#25324;&#19981;&#21516;&#32467;&#26500;&#21270;&#30340;&#32447;&#24615;&#24378;&#21270;&#23398;&#20064;&#21644;&#23450;&#20215;&#27169;&#22411;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#34892;&#30340;&#27969;&#31243;&#65292;&#23558;&#25506;&#32034;/&#21033;&#29992;&#21327;&#35758;&#19982;&#39640;&#25928;&#30340;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Key challenges in running a retail business include how to select products to present to consumers (the assortment problem), and how to price products (the pricing problem) to maximize revenue or profit. Instead of considering these problems in isolation, we propose a joint approach to assortment-pricing based on contextual bandits. Our model is doubly high-dimensional, in that both context vectors and actions are allowed to take values in high-dimensional spaces. In order to circumvent the curse of dimensionality, we propose a simple yet flexible model that captures the interactions between covariates and actions via a (near) low-rank representation matrix. The resulting class of models is reasonably expressive while remaining interpretable through latent factors, and includes various structured linear bandit and pricing models as particular cases. We propose a computationally tractable procedure that combines an exploration/exploitation protocol with an efficient low-rank matrix esti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;&#22312;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20559;&#24046;&#19968;&#33324;&#38750;&#38646;&#12290;&#27492;&#22806;&#65292;&#24403;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#24179;&#22343;&#27861;&#26102;&#65292;&#20272;&#35745;&#20540;&#25910;&#25947;&#21040;&#28176;&#36817;&#26080;&#20559;&#65292;&#19988;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.02944</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#65306;&#25193;&#23637;&#29256;&#26412;
&lt;/p&gt;
&lt;p&gt;
The Curse of Memory in Stochastic Approximation: Extended Version. (arXiv:2309.02944v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;&#22312;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20559;&#24046;&#19968;&#33324;&#38750;&#38646;&#12290;&#27492;&#22806;&#65292;&#24403;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#24179;&#22343;&#27861;&#26102;&#65292;&#20272;&#35745;&#20540;&#25910;&#25947;&#21040;&#28176;&#36817;&#26080;&#20559;&#65292;&#19988;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#25511;&#21046;&#30340;&#26368;&#26089;&#30340;&#26085;&#23376;&#20197;&#26469;&#65292;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#22312;&#25511;&#21046;&#31995;&#32479;&#30340;&#31038;&#21306;&#20013;&#24471;&#21040;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#26412;&#25991;&#20197;&#26032;&#30340;&#35270;&#35282;&#37325;&#26032;&#23457;&#35270;&#20102;&#36825;&#20010;&#20027;&#39064;&#65292;&#21463;&#21040;&#26368;&#36817;&#30340;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#35813;&#32467;&#26524;&#35777;&#26126;&#20351;&#29992;&#65288;&#36275;&#22815;&#23567;&#30340;&#65289;&#24658;&#23450;&#27493;&#38271;&#945;&gt;0&#30340;SA&#20855;&#26377;&#38750;&#20961;&#30340;&#24615;&#33021;&#12290;&#22914;&#26524;&#37319;&#29992;&#24179;&#22343;&#27861;&#33719;&#21462;&#26368;&#32456;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#21017;&#20272;&#35745;&#20540;&#22312;&#28176;&#36817;&#26080;&#20559;&#21644;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#19979;&#25910;&#25947;&#12290;&#36825;&#20123;&#32467;&#26524;&#26159;&#38024;&#23545;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#31995;&#25968;&#30340;&#38543;&#26426;&#32447;&#24615;SA&#36882;&#24402;&#33719;&#24471;&#30340;&#12290;&#26412;&#25991;&#22312;&#26356;&#24120;&#35265;&#30340;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#20102;&#38750;&#24120;&#19981;&#21516;&#30340;&#32467;&#35770;&#65306;&#65288;i&#65289;&#22312;&#38750;&#32447;&#24615;SA&#30340;&#24773;&#20917;&#19979;&#65292;&#35782;&#21035;&#20986;&#20102;&#8220;&#30446;&#26631;&#20559;&#24046;&#8221;&#65292;&#24182;&#19988;&#19968;&#33324;&#19978;&#19981;&#20026;&#38646;&#12290;&#20854;&#20313;&#30340;&#32467;&#26524;&#26159;&#38024;&#23545;&#32447;&#24615;SA&#36882;&#24402;&#24314;&#31435;&#30340;&#65306;&#65288;ii&#65289;&#21452;&#21464;&#37327;&#21442;&#25968;&#25200;&#21160;&#36807;&#31243;&#22312;&#25299;&#25169;&#24847;&#20041;&#19978;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#24615;&#65307;&#65288;iii&#65289;&#20559;&#24046;&#30340;&#34920;&#31034;&#20855;&#26377;&#31616;&#21333;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theory and application of stochastic approximation (SA) has grown within the control systems community since the earliest days of adaptive control. This paper takes a new look at the topic, motivated by recent results establishing remarkable performance of SA with (sufficiently small) constant step-size $\alpha&gt;0$. If averaging is implemented to obtain the final parameter estimate, then the estimates are asymptotically unbiased with nearly optimal asymptotic covariance. These results have been obtained for random linear SA recursions with i.i.d.\ coefficients. This paper obtains very different conclusions in the more common case of geometrically ergodic Markovian disturbance: (i) The \textit{target bias} is identified, even in the case of non-linear SA, and is in general non-zero. The remaining results are established for linear SA recursions: (ii) the bivariate parameter-disturbance process is geometrically ergodic in a topological sense; (iii) the representation for bias has a simple
&lt;/p&gt;</description></item><item><title>TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.01082</link><description>&lt;p&gt;
&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#28909;&#24102;&#20960;&#20309;&#24037;&#20855;&#65306;TML&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
Tropical Geometric Tools for Machine Learning: the TML package. (arXiv:2309.01082v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01082
&lt;/p&gt;
&lt;p&gt;
TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#28909;&#24102;&#20960;&#20309;&#23398;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#35768;&#22810;&#30452;&#25509;&#24212;&#29992;&#20110;&#32479;&#35745;&#23398;&#20064;&#38382;&#39064;&#30340;&#24037;&#20855;&#12290;TML&#36719;&#20214;&#21253;&#26159;&#31532;&#19968;&#20010;&#21253;&#21547;&#19968;&#22871;&#20840;&#38754;&#30340;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;R&#36719;&#20214;&#21253;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#28909;&#24102;&#20984;&#24615;&#30456;&#20851;&#30340;&#22522;&#26412;&#35745;&#31639;&#12289;&#28909;&#24102;&#20984;&#38598;&#30340;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#20351;&#29992;&#28909;&#24102;&#24230;&#37327;&#21644;&#28909;&#24102;&#25237;&#24433;&#29615;&#19978;&#30340;max-plus&#20195;&#25968;&#36827;&#34892;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#12290;&#20027;&#35201;&#30340;&#65292;TML&#36719;&#20214;&#21253;&#20351;&#29992;Hit and Run Markov chain Monte Carlo&#37319;&#26679;&#22120;&#19982;&#28909;&#24102;&#24230;&#37327;&#20316;&#20026;&#32479;&#35745;&#25512;&#26029;&#30340;&#20027;&#35201;&#24037;&#20855;&#12290;&#38500;&#20102;&#22522;&#26412;&#35745;&#31639;&#21644;&#28909;&#24102;HAR&#37319;&#26679;&#22120;&#30340;&#21508;&#31181;&#24212;&#29992;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#20851;&#27880;TML&#36719;&#20214;&#21253;&#20013;&#21253;&#21547;&#30340;&#20960;&#31181;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#26041;&#27861;&#65292;&#21253;&#25324;&#28909;&#24102;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#28909;&#24102;&#36923;&#36753;&#22238;&#24402;&#21644;&#28909;&#24102;&#26680;&#23494;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the last decade, developments in tropical geometry have provided a number of uses directly applicable to problems in statistical learning. The TML package is the first R package which contains a comprehensive set of tools and methods used for basic computations related to tropical convexity, visualization of tropically convex sets, as well as supervised and unsupervised learning models using the tropical metric under the max-plus algebra over the tropical projective torus. Primarily, the TML package employs a Hit and Run Markov chain Monte Carlo sampler in conjunction with the tropical metric as its main tool for statistical inference. In addition to basic computation and various applications of the tropical HAR sampler, we also focus on several supervised and unsupervised methods incorporated in the TML package including tropical principal component analysis, tropical logistic regression and tropical kernel density estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#31243;&#26469;&#25506;&#32034;&#21644;&#20998;&#26512;&#21307;&#30103;&#25968;&#25454;&#20013;&#30340;&#25289;&#33298;&#33945;&#38598;&#21512;&#27169;&#22411;&#65292;&#20174;&#32780;&#36229;&#36234;&#20256;&#32479;&#21333;&#19968;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;"&#25289;&#33298;&#33945;&#26816;&#27979;"&#31639;&#27861;&#35782;&#21035;&#20986;&#38598;&#21512;&#20013;&#26368;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.11446</link><description>&lt;p&gt;
&#25506;&#32034;&#25289;&#33298;&#33945;&#38598;&#21512;&#26377;&#21161;&#20110;&#21307;&#30103;&#25968;&#25454;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Exploration of Rashomon Set Assists Explanations for Medical Data. (arXiv:2308.11446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.11446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#31243;&#26469;&#25506;&#32034;&#21644;&#20998;&#26512;&#21307;&#30103;&#25968;&#25454;&#20013;&#30340;&#25289;&#33298;&#33945;&#38598;&#21512;&#27169;&#22411;&#65292;&#20174;&#32780;&#36229;&#36234;&#20256;&#32479;&#21333;&#19968;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;"&#25289;&#33298;&#33945;&#26816;&#27979;"&#31639;&#27861;&#35782;&#21035;&#20986;&#38598;&#21512;&#20013;&#26368;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#24314;&#27169;&#36807;&#31243;&#36890;&#24120;&#20197;&#36873;&#25321;&#26368;&#22823;&#21270;&#26576;&#20010;&#24615;&#33021;&#25351;&#26631;&#30340;&#21333;&#19968;&#27169;&#22411;&#20316;&#20026;&#26368;&#32456;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#23545;&#31245;&#24494;&#24046;&#19968;&#20123;&#30340;&#27169;&#22411;&#36827;&#34892;&#26356;&#28145;&#20837;&#30340;&#20998;&#26512;&#34987;&#24573;&#35270;&#12290;&#23588;&#20854;&#22312;&#21307;&#30103;&#21644;&#20581;&#24247;&#30740;&#31350;&#20013;&#65292;&#30446;&#26631;&#19981;&#20165;&#20165;&#26159;&#39044;&#27979;&#65292;&#36824;&#21253;&#25324;&#20135;&#29983;&#26377;&#20215;&#20540;&#30340;&#27934;&#23519;&#65292;&#20165;&#20165;&#20381;&#36182;&#24615;&#33021;&#25351;&#26631;&#21487;&#33021;&#20250;&#23548;&#33268;&#35823;&#23548;&#25110;&#19981;&#23436;&#25972;&#30340;&#32467;&#35770;&#12290;&#24403;&#22788;&#29702;&#19968;&#32452;&#24615;&#33021;&#25509;&#36817;&#26368;&#20248;&#30340;&#27169;&#22411;&#38598;&#21512;&#26102;&#65292;&#21363;&#25152;&#35859;&#30340;"&#25289;&#33298;&#33945;&#38598;&#21512;"&#65292;&#36825;&#20010;&#38382;&#39064;&#23588;&#20026;&#31361;&#20986;&#12290;&#36825;&#26679;&#30340;&#38598;&#21512;&#21487;&#33021;&#21253;&#21547;&#25551;&#36848;&#25968;&#25454;&#30340;&#19981;&#21516;&#26041;&#24335;&#30340;&#27169;&#22411;&#65292;&#38656;&#35201;&#36827;&#34892;&#20840;&#38754;&#30340;&#20998;&#26512;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#31243;&#26469;&#25506;&#32034;&#25289;&#33298;&#33945;&#38598;&#21512;&#27169;&#22411;&#65292;&#25193;&#23637;&#20102;&#20256;&#32479;&#24314;&#27169;&#26041;&#27861;&#12290;&#26680;&#24515;&#26159;&#36890;&#36807;&#24341;&#20837;&#30340;"&#25289;&#33298;&#33945;&#26816;&#27979;"&#31639;&#27861;&#26469;&#35782;&#21035;&#25289;&#33298;&#33945;&#38598;&#21512;&#20013;&#26368;&#19981;&#21516;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The machine learning modeling process conventionally culminates in selecting a single model that maximizes a selected performance metric. However, this approach leads to abandoning a more profound analysis of slightly inferior models. Particularly in medical and healthcare studies, where the objective extends beyond predictions to valuable insight generation, relying solely on performance metrics can result in misleading or incomplete conclusions. This problem is particularly pertinent when dealing with a set of models with performance close to maximum one, known as $\textit{Rashomon set}$. Such a set can be numerous and may contain models describing the data in a different way, which calls for comprehensive analysis. This paper introduces a novel process to explore Rashomon set models, extending the conventional modeling approach. The cornerstone is the identification of the most different models within the Rashomon set, facilitated by the introduced $\texttt{Rashomon_DETECT}$ algorit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.07843</link><description>&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) &#35813;&#35770;&#25991;&#26631;&#39064;&#24050;&#32763;&#35793;&#65306;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07843
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#21307;&#30103;&#26088;&#22312;&#36890;&#36807;&#22312;&#20010;&#20154;&#26085;&#24120;&#29983;&#27963;&#20013;&#25552;&#20379;&#24178;&#39044;&#26469;&#25552;&#39640;&#20581;&#24247;&#32467;&#26524;&#12290;&#29031;&#39038;&#20276;&#20387;&#21644;&#31038;&#20250;&#25903;&#25345;&#32593;&#32476;&#30340;&#21442;&#19982;&#32463;&#24120;&#22312;&#24110;&#21161;&#20010;&#20154;&#31649;&#29702;&#32321;&#37325;&#30340;&#21307;&#30103;&#26465;&#20214;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#20026;&#31227;&#21160;&#21307;&#30103;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#35774;&#35745;&#38024;&#23545;&#20108;&#20803;&#20851;&#31995;&#8212;&#8212;&#30446;&#26631;&#20154;&#21644;&#20854;&#29031;&#39038;&#20276;&#20387;&#20043;&#38388;&#20851;&#31995;&#8212;&#8212;&#20197;&#25552;&#39640;&#31038;&#20250;&#25903;&#25345;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#65288;Dyadic RL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#29615;&#22659;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#21450;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#20010;&#24615;&#21270;&#24178;&#39044;&#25514;&#26045;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#22810;&#32452;&#24178;&#39044;&#25514;&#26045;&#24433;&#21709;&#30528;&#20108;&#20803;&#20851;&#31995;&#22312;&#22810;&#20010;&#26102;&#38388;&#38388;&#38548;&#20869;&#12290;&#24320;&#21457;&#30340;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#38382;&#39064;&#35774;&#23450;&#65292;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#24182;&#30830;&#23450;&#20102;&#36951;&#25022;&#36793;&#30028;&#12290;&#36890;&#36807;&#27169;&#25311;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#20013;&#20351;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#32622;&#25442;&#26469;&#24230;&#37327;&#21151;&#33021;&#36830;&#25509;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#27599;&#20010;&#32622;&#25442;&#30340;&#26041;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;&#22312;&#19982;&#20854;&#20182;&#25216;&#26415;&#30340;&#27604;&#36739;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.06220</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#32622;&#25442;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Permuted Granger Causality. (arXiv:2308.06220v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06220
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#38750;&#32447;&#24615;&#25968;&#25454;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#20013;&#20351;&#29992;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#32622;&#25442;&#26469;&#24230;&#37327;&#21151;&#33021;&#36830;&#25509;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#27599;&#20010;&#32622;&#25442;&#30340;&#26041;&#24046;&#30340;&#19968;&#33268;&#20272;&#35745;&#12290;&#22312;&#19982;&#20854;&#20182;&#25216;&#26415;&#30340;&#27604;&#36739;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26684;&#20848;&#26480;&#22240;&#26524;&#25512;&#26029;&#26159;&#20174;&#32463;&#27982;&#23398;&#21040;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#24191;&#27867;&#20351;&#29992;&#30340;&#19968;&#31181;&#26377;&#20105;&#35758;&#30340;&#26041;&#27861;&#12290;&#21407;&#22987;&#23450;&#20041;&#22522;&#20110;&#25351;&#23450;&#27169;&#22411;&#26465;&#20214;&#19979;&#24314;&#31435;&#22240;&#26524;&#20851;&#31995;&#30340;&#26102;&#38388;&#24207;&#21015;&#27010;&#24565;&#12290;&#23558;&#26684;&#20848;&#26480;&#22240;&#26524;&#24615;&#24212;&#29992;&#20110;&#38750;&#32447;&#24615;&#25968;&#25454;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#35768;&#22810;&#26041;&#27861;&#20351;&#29992;&#26679;&#26412;&#20869;&#27979;&#35797;&#65292;&#19981;&#33021;&#32435;&#20837;&#26679;&#26412;&#22806;&#30340;&#21487;&#39044;&#27979;&#24615;&#65292;&#23548;&#33268;&#27169;&#22411;&#36807;&#25311;&#21512;&#30340;&#25285;&#24551;&#12290;&#20026;&#20102;&#36827;&#34892;&#26679;&#26412;&#22806;&#27604;&#36739;&#65292;&#25105;&#20204;&#26126;&#30830;&#22320;&#23450;&#20041;&#20102;&#20351;&#29992;&#21327;&#21464;&#37327;&#38598;&#30340;&#32622;&#25442;&#26469;&#34920;&#31034;&#21151;&#33021;&#36830;&#25509;&#24615;&#30340;&#24230;&#37327;&#12290;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25968;&#25454;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#29992;&#20110;&#36817;&#20284;&#20219;&#20309;&#20219;&#24847;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#24182;&#22312;&#29305;&#24449;&#25552;&#21462;&#36807;&#31243;&#21644;&#27169;&#22411;&#27531;&#24046;&#30340;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#35777;&#26126;&#23545;&#27599;&#20010;&#32622;&#25442;&#30340;&#26041;&#24046;&#36827;&#34892;&#20102;&#19968;&#33268;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#27169;&#25311;&#27604;&#36739;&#20102;&#32622;&#25442;&#26041;&#27861;&#19982;&#24809;&#32602;&#30446;&#26631;&#12289;&#22825;&#30495;&#26367;&#20195;&#21644;&#36951;&#28431;&#25216;&#26415;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Granger causal inference is a contentious but widespread method used in fields ranging from economics to neuroscience. The original definition addresses the notion of causality in time series by establishing functional dependence conditional on a specified model. Adaptation of Granger causality to nonlinear data remains challenging, and many methods apply in-sample tests that do not incorporate out-of-sample predictability leading to concerns of model overfitting. To allow for out-of-sample comparison, we explicitly define a measure of functional connectivity using permutations of the covariate set. Artificial neural networks serve as featurizers of the data to approximate any arbitrary, nonlinear relationship, and under certain conditions on the featurization process and the model residuals, we prove consistent estimation of the variance for each permutation. Performance of the permutation method is compared to penalized objective, naive replacement, and omission techniques via simula
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27010;&#24565;&#22120;&#30697;&#38453;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#29305;&#24449;&#21160;&#24577;&#65292;&#24182;&#21033;&#29992;&#21333;&#21464;&#37327;&#37327;&#21270;&#26469;&#35782;&#21035;&#21464;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;&#26465;&#20214;&#21644;&#26080;&#26465;&#20214;&#30340;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#21487;&#20197;&#25552;&#20379;&#28508;&#22312;&#30340;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24863;&#20852;&#36259;&#20301;&#32622;&#12290;</title><link>http://arxiv.org/abs/2308.06213</link><description>&lt;p&gt;
&#20351;&#29992;&#27010;&#24565;&#22120;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Change Point Detection With Conceptors. (arXiv:2308.06213v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06213
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27010;&#24565;&#22120;&#30697;&#38453;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#29305;&#24449;&#21160;&#24577;&#65292;&#24182;&#21033;&#29992;&#21333;&#21464;&#37327;&#37327;&#21270;&#26469;&#35782;&#21035;&#21464;&#28857;&#12290;&#35813;&#26041;&#27861;&#22312;&#26465;&#20214;&#21644;&#26080;&#26465;&#20214;&#30340;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#21487;&#20197;&#25552;&#20379;&#28508;&#22312;&#30340;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24863;&#20852;&#36259;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#21464;&#28857;&#26816;&#27979;&#26088;&#22312;&#35782;&#21035;&#26102;&#38388;&#24207;&#21015;&#20013;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#21457;&#29983;&#21464;&#21270;&#30340;&#28857;&#12290;&#23545;&#20110;&#21333;&#21464;&#37327;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#65292;&#36825;&#20010;&#38382;&#39064;&#24050;&#32463;&#24471;&#21040;&#20102;&#36739;&#22909;&#30340;&#30740;&#31350;&#65292;&#20294;&#26159;&#38543;&#30528;&#32500;&#24230;&#21644;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#22686;&#21152;&#65292;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#38024;&#23545;&#33267;&#22810;&#19968;&#20010;&#21464;&#28857;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#27010;&#24565;&#22120;&#30697;&#38453;&#26469;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#20013;&#25351;&#23450;&#35757;&#32451;&#31383;&#21475;&#30340;&#29305;&#24449;&#21160;&#24577;&#12290;&#30456;&#20851;&#30340;&#38543;&#26426;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#25968;&#25454;&#30340;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#24182;&#19988;&#36890;&#36807;&#35745;&#31639;&#29305;&#24449;&#21270;&#19982;&#20195;&#34920;&#24615;&#27010;&#24565;&#22120;&#30697;&#38453;&#25152;&#24352;&#25104;&#31354;&#38388;&#20043;&#38388;&#30340;&#36317;&#31163;&#30340;&#21333;&#21464;&#37327;&#37327;&#21270;&#26469;&#35782;&#21035;&#21464;&#28857;&#12290;&#36825;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#21487;&#20197;&#25552;&#31034;&#21487;&#33021;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#24863;&#20852;&#36259;&#30340;&#20301;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#30495;&#23454;&#21464;&#28857;&#30340;&#19968;&#33268;&#20272;&#35745;&#65292;&#24182;&#36890;&#36807;&#23545;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#31227;&#21160;&#22359;&#33258;&#21161;&#27861;&#20135;&#29983;&#32479;&#35745;&#37327;&#30340;&#20998;&#20301;&#25968;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#26465;&#20214;&#21644;&#26080;&#26465;&#20214;&#30340;&#21464;&#28857;&#26816;&#27979;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline change point detection seeks to identify points in a time series where the data generating process changes. This problem is well studied for univariate i.i.d. data, but becomes challenging with increasing dimension and temporal dependence. For the at most one change point problem, we propose the use of a conceptor matrix to learn the characteristic dynamics of a specified training window in a time series. The associated random recurrent neural network acts as a featurizer of the data, and change points are identified from a univariate quantification of the distance between the featurization and the space spanned by a representative conceptor matrix. This model agnostic method can suggest potential locations of interest that warrant further study. We prove that, under mild assumptions, the method provides a consistent estimate of the true change point, and quantile estimates for statistics are produced via a moving block bootstrap of the original data. The method is tested on si
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;RED CoMETS&#30340;&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#31526;&#21495;&#21270;&#34920;&#31034;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#23427;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#23637;&#29616;&#20986;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;'HandMovementDirection'&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#25253;&#21578;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.13679</link><description>&lt;p&gt;
RED CoMETS: &#19968;&#31181;&#29992;&#20110;&#31526;&#21495;&#21270;&#34920;&#31034;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#30340;&#38598;&#25104;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
RED CoMETS: An ensemble classifier for symbolically represented multivariate time series. (arXiv:2307.13679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;RED CoMETS&#30340;&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#31526;&#21495;&#21270;&#34920;&#31034;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#23427;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#23637;&#29616;&#20986;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;'HandMovementDirection'&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#25253;&#21578;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#21487;&#22312;&#37329;&#34701;&#12289;&#21307;&#30103;&#12289;&#24037;&#31243;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#20351;&#29992;&#12290;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20998;&#31867;&#22797;&#26434;&#24615;&#26469;&#33258;&#20110;&#20854;&#39640;&#32500;&#24230;&#12289;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#38271;&#24230;&#19981;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;RED CoMETS&#65288;Random Enhanced Co-eye for Multivariate Time Series&#65289;&#30340;&#26032;&#22411;&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#23427;&#35299;&#20915;&#20102;&#36825;&#20123;&#25361;&#25112;&#12290;RED CoMETS&#22522;&#20110;Co-eye&#30340;&#25104;&#21151;&#65292;&#24182;&#23558;&#20854;&#33021;&#21147;&#25193;&#23637;&#21040;&#22788;&#29702;&#22810;&#21464;&#37327;&#25968;&#25454;&#12290;&#20351;&#29992;UCR&#26723;&#26696;&#20013;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#23545;RED CoMETS&#30340;&#24615;&#33021;&#36827;&#34892;&#35780;&#20272;&#65292;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#30456;&#27604;&#65292;&#23427;&#26174;&#31034;&#20986;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#22312;&#25991;&#29486;&#20013;&#23545;&#20110;'HandMovementDirection'&#25968;&#25454;&#38598;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#25253;&#21578;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#22320;&#25913;&#36827;&#20102;&#20256;&#32479;&#30340;Co-eye&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more. The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths. This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges. RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data. The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings. Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset. Moreover, the proposed method signific
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#20307;&#31995;&#65292;&#20026;&#39046;&#22495;&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#36981;&#24490;&#25152;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.14094</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#33539;&#30068;&#22522;&#30784;&#65306;&#19968;&#31181;&#32479;&#19968;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#24418;&#24335;&#20307;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#20307;&#31995;&#65292;&#20026;&#39046;&#22495;&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#36981;&#24490;&#25152;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26088;&#22312;&#22238;&#31572;&#19982;AI&#27169;&#22411;&#37096;&#32626;&#30456;&#20851;&#30340;&#20262;&#29702;&#21644;&#27861;&#24459;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30456;&#24403;&#25968;&#37327;&#30340;&#39046;&#22495;&#29305;&#23450;&#35780;&#35770;&#24378;&#35843;&#38656;&#35201;&#19968;&#20010;&#25968;&#23398;&#22522;&#30784;&#26469;&#23450;&#20041;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#27010;&#24565;&#65292;&#21363;&#20351;&#8220;&#35299;&#37322;&#8221;&#36825;&#20010;&#26415;&#35821;&#36824;&#32570;&#20047;&#31934;&#30830;&#23450;&#20041;&#12290;&#36825;&#20123;&#35780;&#35770;&#36824;&#20027;&#24352;&#24314;&#31435;&#19968;&#20010;&#20581;&#20840;&#32780;&#32479;&#19968;&#30340;&#21487;&#35299;&#37322;AI&#24418;&#24335;&#20307;&#31995;&#65292;&#20197;&#36991;&#20813;&#20986;&#29616;&#19981;&#33391;&#25552;&#20986;&#38382;&#39064;&#65292;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#27983;&#35272;&#19968;&#20010;&#24555;&#36895;&#22686;&#38271;&#30340;&#30693;&#35782;&#20307;&#31995;&#12290;&#25454;&#20316;&#32773;&#25152;&#30693;&#65292;&#35813;&#35770;&#25991;&#26159;&#22635;&#34917;&#35813;&#31354;&#30333;&#30340;&#39318;&#27425;&#23581;&#35797;&#65292;&#36890;&#36807;&#24418;&#24335;&#21270;&#19968;&#20010;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#12290;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#21453;&#39304;&#21333;&#35843;&#33539;&#30068;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;AI&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#30340;&#24418;&#24335;&#23450;&#20041;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36981;&#24490;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#24341;&#20837;&#30340;&#29702;&#35770;&#26469;&#23545;&#24403;&#21069;&#30740;&#31350;&#30340;&#25152;&#26377;&#20027;&#35201;XAI&#31995;&#32479;&#31867;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#19988;&#27169;&#22359;&#21270;&#30340; R6 &#25509;&#21475;&#65292;&#29992;&#20110;&#20855;&#20307;&#23454;&#29616;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#29616;&#19977;&#31181;&#26041;&#27861;&#24182;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#24773;&#22659;&#20013;&#65292;&#32467;&#21512;&#30495;&#23454;&#29992;&#20363;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#20934;&#30830;&#22320;&#24471;&#20986;&#26377;&#20851;&#22914;&#20309;&#26356;&#25913;&#21333;&#20010;&#35266;&#27979;&#20540;&#30340;&#29305;&#24449;&#20540;&#20197;&#33719;&#24471;&#25152;&#38656;&#39044;&#27979;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2304.06569</link><description>&lt;p&gt;
counterfactuals: &#29992;&#20110;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#30340; R &#21253;
&lt;/p&gt;
&lt;p&gt;
counterfactuals: An R Package for Counterfactual Explanation Methods. (arXiv:2304.06569v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06569
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#19988;&#27169;&#22359;&#21270;&#30340; R6 &#25509;&#21475;&#65292;&#29992;&#20110;&#20855;&#20307;&#23454;&#29616;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#12290;&#36890;&#36807;&#23454;&#29616;&#19977;&#31181;&#26041;&#27861;&#24182;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#24773;&#22659;&#20013;&#65292;&#32467;&#21512;&#30495;&#23454;&#29992;&#20363;&#65292;&#27492;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#20934;&#30830;&#22320;&#24471;&#20986;&#26377;&#20851;&#22914;&#20309;&#26356;&#25913;&#21333;&#20010;&#35266;&#27979;&#20540;&#30340;&#29305;&#24449;&#20540;&#20197;&#33719;&#24471;&#25152;&#38656;&#39044;&#27979;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#25552;&#20379;&#26377;&#20851;&#22914;&#20309;&#26356;&#25913;&#21333;&#20010;&#35266;&#27979;&#20540;&#30340;&#29305;&#24449;&#20540;&#20197;&#33719;&#24471;&#25152;&#38656;&#39044;&#27979;&#30340;&#20449;&#24687;&#12290;&#23613;&#31649;&#30740;&#31350;&#20013;&#25552;&#20986;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#26041;&#27861;&#65292;&#20294;&#21482;&#26377;&#23569;&#25968;&#20855;&#26377;&#24191;&#27867;&#21464;&#21270;&#30340;&#25509;&#21475;&#21644;&#35201;&#27714;&#30340;&#23454;&#29616;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461; counterfactuals R &#21253;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110; R6 &#30340;&#27169;&#22359;&#21270;&#21644;&#32479;&#19968;&#30340;&#25509;&#21475;&#65292;&#29992;&#20110;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#12290;&#25105;&#20204;&#24050;&#32463;&#23454;&#29616;&#20102;&#19977;&#31181;&#29616;&#26377;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20123;&#21487;&#36873;&#30340;&#26041;&#27861;&#23398;&#25193;&#23637;&#65292;&#20197;&#23558;&#36825;&#20123;&#26041;&#27861;&#25512;&#24191;&#21040;&#19981;&#21516;&#30340;&#22330;&#26223;&#24182;&#20351;&#20854;&#26356;&#20855;&#21487;&#27604;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#29992;&#20363;&#35299;&#37322;&#20102;&#21253;&#30340;&#32467;&#26500;&#21644;&#24037;&#20316;&#27969;&#31243;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#20182;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#38598;&#25104;&#21040;&#21253;&#20013;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38024;&#23545;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#27604;&#36739;&#20102;&#23454;&#26045;&#30340;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#20854;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#36136;&#37327;&#21644;&#36816;&#34892;&#26102;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual explanation methods provide information on how feature values of individual observations must be changed to obtain a desired prediction. Despite the increasing amount of proposed methods in research, only a few implementations exist whose interfaces and requirements vary widely. In this work, we introduce the counterfactuals R package, which provides a modular and unified R6-based interface for counterfactual explanation methods. We implemented three existing counterfactual explanation methods and propose some optional methodological extensions to generalize these methods to different scenarios and to make them more comparable. We explain the structure and workflow of the package using real use cases and show how to integrate additional counterfactual explanation methods into the package. In addition, we compared the implemented methods for a variety of models and datasets with regard to the quality of their counterfactual explanations and their runtime behavior.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#22312;BGLMs&#19978;&#23454;&#29616;&#30340;&#26080;&#38656;&#22270;&#39592;&#26550;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#30340;&#28176;&#36827;&#36951;&#25022;&#29575;$O(\sqrt{T}\ln T)$&#12290;</title><link>http://arxiv.org/abs/2301.13392</link><description>&lt;p&gt;
&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Causal Bandits without Graph Skeleton. (arXiv:2301.13392v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13392
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21487;&#22312;BGLMs&#19978;&#23454;&#29616;&#30340;&#26080;&#38656;&#22270;&#39592;&#26550;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36798;&#21040;&#20102;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#30340;&#28176;&#36827;&#36951;&#25022;&#29575;$O(\sqrt{T}\ln T)$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#20195;&#29702;&#22312;&#27599;&#19968;&#36718;&#36873;&#25321;&#19968;&#32452;&#21464;&#37327;&#36827;&#34892;&#24178;&#39044;&#65292;&#25910;&#38598;&#35266;&#27979;&#21464;&#37327;&#30340;&#21453;&#39304;&#20197;&#26368;&#23567;&#21270;&#26399;&#26395;&#36951;&#25022;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#30740;&#31350;&#20102;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;&#20108;&#20540;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;BGLMs&#65289;&#20013;&#30340;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#37117;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#26469;&#26500;&#24314;&#22240;&#26524;&#20851;&#31995;&#22270;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20108;&#20540;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#21644;BGLMs&#19978;&#19981;&#32771;&#34385;&#22270;&#39592;&#26550;&#30340;&#32452;&#21512;&#22240;&#26524;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#33324;&#22240;&#26524;&#27169;&#22411;&#19978;&#25552;&#20379;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#25351;&#25968;&#19979;&#38480;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26080;&#38656;&#22270;&#39592;&#26550;&#26469;&#23454;&#29616;BGLMs&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#34920;&#26126;&#23427;&#20173;&#28982;&#36798;&#21040;$O(\sqrt{T}\ln T)$&#30340;&#26399;&#26395;&#36951;&#25022;&#12290;&#36825;&#20010;&#28176;&#36827;&#30340;&#36951;&#25022;&#29575;&#19982;&#20381;&#36182;&#20110;&#22270;&#32467;&#26500;&#30340;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
In combinatorial causal bandits (CCB), the learning agent chooses a subset of variables in each round to intervene and collects feedback from the observed variables to minimize expected regret or sample complexity. Previous works study this problem in both general causal models and binary generalized linear models (BGLMs). However, all of them require prior knowledge of causal graph structure. This paper studies the CCB problem without the graph structure on binary general causal models and BGLMs. We first provide an exponential lower bound of cumulative regrets for the CCB problem on general causal models. To overcome the exponentially large space of parameters, we then consider the CCB problem on BGLMs. We design a regret minimization algorithm for BGLMs even without the graph skeleton and show that it still achieves $O(\sqrt{T}\ln T)$ expected regret. This asymptotic regret is the same as the state-of-art algorithms relying on the graph structure. Moreover, we sacrifice the regret t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21033;&#29992;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2211.02039</link><description>&lt;p&gt;
&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#30340;&#25237;&#24433;&#21327;&#26041;&#24046;&#27979;&#37327;
&lt;/p&gt;
&lt;p&gt;
The Projected Covariance Measure for assumption-lean variable significance testing. (arXiv:2211.02039v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20551;&#35774;&#31616;&#32422;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#21033;&#29992;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20013;&#65292;&#23545;&#20110;&#32473;&#23450;&#38468;&#21152;&#21327;&#21464;&#37327;Z&#65292;&#27979;&#35797;&#21464;&#37327;&#25110;&#21464;&#37327;&#32452;X&#23545;&#20110;&#39044;&#27979;&#21709;&#24212;Y&#30340;&#37325;&#35201;&#24615;&#26159;&#19968;&#39033;&#26222;&#36941;&#20219;&#21153;&#12290;&#19968;&#31181;&#31616;&#21333;&#20294;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#25351;&#23450;&#19968;&#20010;&#32447;&#24615;&#27169;&#22411;&#65292;&#28982;&#21518;&#27979;&#35797;X&#30340;&#22238;&#24402;&#31995;&#25968;&#26159;&#21542;&#20026;&#38750;&#38646;&#12290;&#28982;&#32780;&#65292;&#24403;&#27169;&#22411;&#38169;&#35823;&#25351;&#23450;&#26102;&#65292;&#27979;&#35797;&#30340;&#21151;&#25928;&#21487;&#33021;&#24456;&#24046;&#65292;&#20363;&#22914;&#24403;X&#21442;&#19982;&#22797;&#26434;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#25110;&#32773;&#23548;&#33268;&#35768;&#22810;&#38169;&#35823;&#25298;&#32477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27979;&#35797;&#26465;&#20214;&#22343;&#20540;&#29420;&#31435;&#30340;&#26080;&#27169;&#22411;&#20551;&#35774;&#65292;&#21363;&#32473;&#23450;X&#21644;Z&#65292;Y&#30340;&#26465;&#20214;&#22343;&#20540;&#19981;&#20381;&#36182;&#20110;X&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#21033;&#29992;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#25110;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#21152;&#27861;&#27169;&#22411;&#25110;&#38543;&#26426;&#26862;&#26519;&#65292;&#23454;&#29616;&#31283;&#20581;&#30340;&#35823;&#24046;&#25511;&#21046;&#21644;&#39640;&#21151;&#25928;&#12290;&#35813;&#36807;&#31243;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#22238;&#24402;&#65292;&#39318;&#20808;&#20351;&#29992;&#19968;&#21322;&#30340;&#25968;&#25454;&#20272;&#35745;&#20197;X&#21644;Z&#20026;&#22522;&#30784;&#30340;Y&#30340;&#19968;&#31181;&#25237;&#24433;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Testing the significance of a variable or group of variables $X$ for predicting a response $Y$, given additional covariates $Z$, is a ubiquitous task in statistics. A simple but common approach is to specify a linear model, and then test whether the regression coefficient for $X$ is non-zero. However, when the model is misspecified, the test may have poor power, for example when $X$ is involved in complex interactions, or lead to many false rejections. In this work we study the problem of testing the model-free null of conditional mean independence, i.e. that the conditional mean of $Y$ given $X$ and $Z$ does not depend on $X$. We propose a simple and general framework that can leverage flexible nonparametric or machine learning methods, such as additive models or random forests, to yield both robust error control and high power. The procedure involves using these methods to perform regressions, first to estimate a form of projection of $Y$ on $X$ and $Z$ using one half of the data, an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#23545;&#20998;&#31867;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#12290;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#27169;&#22411;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#27969;&#34892;&#30340;&#32676;&#20307;&#20844;&#24179;&#24230;&#37327;&#26159;&#20851;&#20110;&#27169;&#22411;&#21442;&#25968;&#28857;&#20540;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#30340;&#12290;&#38750;&#28176;&#36817;&#30028;&#38480;&#34920;&#26126;&#65292;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#31169;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#36234;&#26469;&#36234;&#25509;&#36817;&#20110;&#38750;&#31169;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#65292;&#20063;&#31361;&#26174;&#20102;&#27169;&#22411;&#30340;&#32622;&#20449;&#36793;&#30028;&#23545;&#24046;&#20998;&#38544;&#31169;&#30340;&#19981;&#23545;&#31561;&#24433;&#21709;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.16242</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#23545;&#20998;&#31867;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#26377;&#38480;
&lt;/p&gt;
&lt;p&gt;
Differential Privacy has Bounded Impact on Fairness in Classification. (arXiv:2210.16242v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#23545;&#20998;&#31867;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#12290;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#27169;&#22411;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#27969;&#34892;&#30340;&#32676;&#20307;&#20844;&#24179;&#24230;&#37327;&#26159;&#20851;&#20110;&#27169;&#22411;&#21442;&#25968;&#28857;&#20540;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#30340;&#12290;&#38750;&#28176;&#36817;&#30028;&#38480;&#34920;&#26126;&#65292;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#31169;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#36234;&#26469;&#36234;&#25509;&#36817;&#20110;&#38750;&#31169;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#65292;&#20063;&#31361;&#26174;&#20102;&#27169;&#22411;&#30340;&#32622;&#20449;&#36793;&#30028;&#23545;&#24046;&#20998;&#38544;&#31169;&#30340;&#19981;&#23545;&#31561;&#24433;&#21709;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#24046;&#20998;&#38544;&#31169;&#23545;&#20998;&#31867;&#20844;&#24179;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#32473;&#23450;&#27169;&#22411;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#27969;&#34892;&#30340;&#32676;&#20307;&#20844;&#24179;&#24230;&#37327;&#26159;&#20851;&#20110;&#27169;&#22411;&#21442;&#25968;&#28857;&#20540;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#30340;&#12290;&#36825;&#20010;&#32467;&#26524;&#26159;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#20851;&#20110;&#22312;&#20219;&#24847;&#20107;&#20214;&#26465;&#20214;&#19979;&#65288;&#27604;&#22914;&#23646;&#20110;&#25935;&#24863;&#32676;&#20307;&#65289;&#20934;&#30830;&#24615;&#30340;&#22768;&#26126;&#30340;&#32467;&#26524;&#65292;&#21487;&#33021;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#21033;&#26222;&#24076;&#33576;&#24615;&#36136;&#35777;&#26126;&#20102;&#19968;&#20010;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#23427;&#34920;&#26126;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;&#31169;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#36234;&#26469;&#36234;&#25509;&#36817;&#20110;&#38750;&#31169;&#26377;&#27169;&#22411;&#30340;&#20844;&#24179;&#24230;&#12290;&#36825;&#20010;&#30028;&#38480;&#36824;&#31361;&#26174;&#20102;&#27169;&#22411;&#30340;&#32622;&#20449;&#36793;&#30028;&#23545;&#24046;&#20998;&#38544;&#31169;&#30340;&#19981;&#23545;&#31561;&#24433;&#21709;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We theoretically study the impact of differential privacy on fairness in classification. We prove that, given a class of models, popular group fairness measures are pointwise Lipschitz-continuous with respect to the parameters of the model. This result is a consequence of a more general statement on accuracy conditioned on an arbitrary event (such as membership to a sensitive group), which may be of independent interest. We use this Lipschitz property to prove a non-asymptotic bound showing that, as the number of samples increases, the fairness level of private models gets closer to the one of their non-private counterparts. This bound also highlights the importance of the confidence margin of a model on the disparate impact of differential privacy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#12290;&#25552;&#20986;&#20102;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#20381;&#36182;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#26102;&#38388;&#30456;&#20851;&#30340;&#22343;&#22330;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.15179</link><description>&lt;p&gt;
&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#65306;&#23398;&#20064;Wasserstein&#31354;&#38388;&#19978;&#30340;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Mean-field neural networks: learning mappings on Wasserstein space. (arXiv:2210.15179v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#22312;&#23398;&#20064;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#12290;&#25552;&#20986;&#20102;&#20004;&#31867;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#29702;&#35770;&#25903;&#25345;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#20381;&#36182;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#26102;&#38388;&#30456;&#20851;&#30340;&#22343;&#22330;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#36827;&#34892;&#26144;&#23556;&#30340;&#27169;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#20363;&#22914;&#22312;&#22343;&#22330;&#21338;&#24328;/&#25511;&#21046;&#38382;&#39064;&#20013;&#12290;&#25552;&#20986;&#20102;&#20004;&#31867;&#22522;&#20110;&#20108;&#36827;&#21046;&#23494;&#24230;&#21644;&#22278;&#26609;&#36924;&#36817;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#29992;&#20110;&#23398;&#20064;&#36825;&#20123;&#25152;&#35859;&#30340;&#22343;&#22330;&#20989;&#25968;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#33719;&#24471;&#20102;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#30340;&#25903;&#25345;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#26469;&#35757;&#32451;&#36825;&#20004;&#20010;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#21508;&#31181;&#27979;&#35797;&#20998;&#24067;&#20013;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20197;&#21450;&#27867;&#21270;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20381;&#36182;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;&#19981;&#21516;&#31639;&#27861;&#26469;&#35299;&#20915;&#26102;&#38388;&#30456;&#20851;&#30340;&#22343;&#22330;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#27979;&#35797;&#22312;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#31354;&#38388;&#20013;&#30340;&#21322;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#20363;&#23376;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the machine learning task for models with operators mapping between the Wasserstein space of probability measures and a space of functions, like e.g. in mean-field games/control problems. Two classes of neural networks, based on bin density and on cylindrical approximation, are proposed to learn these so-called mean-field functions, and are theoretically supported by universal approximation theorems. We perform several numerical experiments for training these two mean-field neural networks, and show their accuracy and efficiency in the generalization error with various test distributions. Finally, we present different algorithms relying on mean-field neural networks for solving time-dependent mean-field problems, and illustrate our results with numerical tests for the example of a semi-linear partial differential equation in the Wasserstein space of probability measures.
&lt;/p&gt;</description></item><item><title>TabPFN&#26159;&#19968;&#31181;&#21487;&#20197;&#22312;&#19981;&#21040;&#19968;&#31186;&#38047;&#20869;&#23436;&#25104;&#23567;&#22411;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20998;&#31867;&#30340;Transformer&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#23427;&#20351;&#29992;&#20808;&#39564;&#36866;&#24212;&#32593;&#32476;&#65288;PFN&#65289;&#36924;&#36817;&#22522;&#20110;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20808;&#39564;&#34701;&#21512;&#20102;&#22240;&#26524;&#25512;&#29702;&#30340;&#24605;&#24819;&#12290;</title><link>http://arxiv.org/abs/2207.01848</link><description>&lt;p&gt;
TabPFN&#65306;&#22312;&#19968;&#31186;&#20869;&#35299;&#20915;&#23567;&#22411;&#34920;&#26684;&#20998;&#31867;&#38382;&#39064;&#30340;Transformer
&lt;/p&gt;
&lt;p&gt;
TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second. (arXiv:2207.01848v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.01848
&lt;/p&gt;
&lt;p&gt;
TabPFN&#26159;&#19968;&#31181;&#21487;&#20197;&#22312;&#19981;&#21040;&#19968;&#31186;&#38047;&#20869;&#23436;&#25104;&#23567;&#22411;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20998;&#31867;&#30340;Transformer&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;&#23427;&#20351;&#29992;&#20808;&#39564;&#36866;&#24212;&#32593;&#32476;&#65288;PFN&#65289;&#36924;&#36817;&#22522;&#20110;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#20808;&#39564;&#34701;&#21512;&#20102;&#22240;&#26524;&#25512;&#29702;&#30340;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;TabPFN&#65292;&#19968;&#31181;&#32463;&#36807;&#35757;&#32451;&#30340;Transformer&#65292;&#21487;&#20197;&#22312;&#19981;&#21040;&#19968;&#31186;&#38047;&#30340;&#26102;&#38388;&#20869;&#23436;&#25104;&#23567;&#22411;&#34920;&#26684;&#25968;&#25454;&#38598;&#30340;&#30417;&#30563;&#20998;&#31867;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#22312;&#20998;&#31867;&#26041;&#27861;&#30340;&#26368;&#26032;&#29366;&#24577;&#19979;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;TabPFN&#23436;&#20840;&#21253;&#21547;&#22312;&#25105;&#20204;&#32593;&#32476;&#30340;&#26435;&#37325;&#20013;&#65292;&#25509;&#21463;&#35757;&#32451;&#21644;&#27979;&#35797;&#26679;&#26412;&#20316;&#20026;&#35774;&#32622;&#20540;&#36755;&#20837;&#65292;&#24182;&#22312;&#21333;&#20010;&#21069;&#21521;&#20256;&#36882;&#20013;&#20026;&#25972;&#20010;&#27979;&#35797;&#38598;&#25552;&#20379;&#39044;&#27979;&#12290;TabPFN&#26159;&#19968;&#31181;&#20808;&#39564;&#36866;&#24212;&#32593;&#32476;&#65288;PFN&#65289;&#65292;&#21482;&#38656;&#35201;&#32447;&#19979;&#35757;&#32451;&#19968;&#27425;&#65292;&#21363;&#21487;&#36924;&#36817;&#22522;&#20110;&#25105;&#20204;&#30340;&#20808;&#39564;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#36825;&#20010;&#20808;&#39564;&#34701;&#21512;&#20102;&#22240;&#26524;&#25512;&#29702;&#30340;&#24605;&#24819;&#65306;&#23427;&#21253;&#25324;&#19968;&#20010;&#22823;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#31354;&#38388;&#65292;&#20559;&#22909;&#20110;&#31616;&#21333;&#32467;&#26500;&#12290;&#22312;OpenML-CC18&#22871;&#20214;&#30340;18&#20010;&#21253;&#21547;&#26368;&#22810;1000&#20010;&#35757;&#32451;&#25968;&#25454;&#28857;&#12289;&#26368;&#22810;100&#20010;&#32431;&#25968;&#20540;&#29305;&#24449;&#19988;&#26080;&#32570;&#22833;&#20540;&#12289;&#26368;&#22810;10&#20010;&#31867;&#21035;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#25552;&#21319;&#26641;&#65292;&#19982;&#22797;&#26434;&#30340;&#26368;&#26032;AutoM&#26041;&#27861;&#34920;&#29616;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoM
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#24179;&#26041;&#21644;&#26494;&#24347;&#26041;&#27861;&#22312;&#20449;&#24687;&#35770;&#21644;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35745;&#31639;$f$-divergences&#30340;&#20984;&#26494;&#24347;&#31639;&#27861;&#65292;&#20854;&#20013;&#28041;&#21450;&#21040;&#20174;&#38750;&#23616;&#37096;&#21327;&#26041;&#24046;&#30697;&#38453;&#35745;&#31639;&#36825;&#20123;divergences&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#32467;&#26524;&#23545;&#20110;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#22810;&#20010;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2206.13285</link><description>&lt;p&gt;
&#20449;&#24687;&#35770;&#21644;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#22522;&#20110;&#24179;&#26041;&#21644;&#26494;&#24347;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sum-of-Squares Relaxations for Information Theory and Variational Inference. (arXiv:2206.13285v3 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#24179;&#26041;&#21644;&#26494;&#24347;&#26041;&#27861;&#22312;&#20449;&#24687;&#35770;&#21644;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35745;&#31639;$f$-divergences&#30340;&#20984;&#26494;&#24347;&#31639;&#27861;&#65292;&#20854;&#20013;&#28041;&#21450;&#21040;&#20174;&#38750;&#23616;&#37096;&#21327;&#26041;&#24046;&#30697;&#38453;&#35745;&#31639;&#36825;&#20123;divergences&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#32467;&#26524;&#23545;&#20110;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#22810;&#20010;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#39321;&#20892;&#30456;&#23545;&#29109;&#30340;&#25193;&#23637;&#65292;&#31216;&#20026;$f$-divergences&#12290;&#36825;&#20123;divergences&#36890;&#24120;&#19982;&#19977;&#20010;&#32463;&#20856;&#30340;&#30456;&#20851;&#35745;&#31639;&#38382;&#39064;&#30456;&#20851;&#32852;&#65306;&#65288;a&#65289;&#20174;&#30697;&#20272;&#35745;&#65292;&#65288;b&#65289;&#35745;&#31639;&#24402;&#19968;&#21270;&#31215;&#20998;&#65292;&#20197;&#21450;&#65288;c&#65289;&#27010;&#29575;&#27169;&#22411;&#30340;&#21464;&#20998;&#25512;&#26029;&#12290;&#36825;&#20123;&#38382;&#39064;&#36890;&#36807;&#20984;&#23545;&#20598;&#24615;&#30456;&#20114;&#20851;&#32852;&#65292;&#23545;&#20110;&#25152;&#26377;&#36825;&#20123;&#38382;&#39064;&#65292;&#37117;&#26377;&#35768;&#22810;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#19988;&#25105;&#20204;&#26088;&#22312;&#25552;&#20986;&#33021;&#22815;&#20445;&#25345;&#21407;&#22987;&#38382;&#39064;&#29305;&#24615;&#65288;&#22914;&#28508;&#22312;&#20984;&#24615;&#25110;&#21333;&#35843;&#24615;&#65289;&#30340;&#35745;&#31639;&#19978;&#21487;&#34892;&#30340;&#36817;&#20284;&#31639;&#27861;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#20174;&#19982;&#32473;&#23450;&#29305;&#24449;&#21521;&#37327;&#30456;&#20851;&#30340;&#38750;&#23616;&#37096;&#21327;&#26041;&#24046;&#30697;&#38453;&#35745;&#31639;&#36825;&#20123;divergences&#30340;&#19968;&#31995;&#21015;&#20984;&#26494;&#24347;&#24320;&#22987;&#65306;&#20174;&#36890;&#24120;&#19981;&#26131;&#22788;&#29702;&#30340;&#26368;&#20248;&#19979;&#30028;&#24320;&#22987;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#22522;&#20110;&#8220;&#24179;&#26041;&#21644;&#8221;&#30340;&#26494;&#24347;&#65292;&#23427;&#29616;&#22312;&#20316;&#20026;&#21322;&#23450;&#35268;&#21010;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider extensions of the Shannon relative entropy, referred to as $f$-divergences.Three classical related computational problems are typically associated with these divergences: (a) estimation from moments, (b) computing normalizing integrals, and (c) variational inference in probabilistic models. These problems are related to one another through convex duality, and for all them, there are many applications throughout data science, and we aim for computationally tractable approximation algorithms that preserve properties of the original problem such as potential convexity or monotonicity. In order to achieve this, we derive a sequence of convex relaxations for computing these divergences from non-centered covariance matrices associated with a given feature vector: starting from the typically non-tractable optimal lower-bound, we consider an additional relaxation based on ``sums-of-squares'', which is is now computable in polynomial time as a semidefinite program. We also provide c
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#29992;&#20110;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#20102;&#23450;&#20041;OOD&#27010;&#24565;&#21644;&#25552;&#20379;&#24378;&#26377;&#21147;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#19982;&#20043;&#21069;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#27979;&#35797;&#30456;&#27604;&#65292;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;OOD&#23454;&#20363;&#20013;&#34920;&#29616;&#26356;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2206.09522</link><description>&lt;p&gt;
&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#29992;&#20110;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#29992;&#20110;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#20102;&#23450;&#20041;OOD&#27010;&#24565;&#21644;&#25552;&#20379;&#24378;&#26377;&#21147;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#19982;&#20043;&#21069;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#27979;&#35797;&#30456;&#27604;&#65292;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;OOD&#23454;&#20363;&#20013;&#34920;&#29616;&#26356;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#31163;&#32676;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#21363;&#22312;&#25512;&#29702;&#26102;&#26816;&#27979;&#23398;&#20064;&#31639;&#27861;&#30340;&#36755;&#20986;&#26159;&#21542;&#21487;&#20449;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#25552;&#20986;&#20102;&#19968;&#20123;OOD&#26816;&#27979;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#24418;&#24335;&#21270;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;OOD&#27010;&#24565;&#30340;&#23450;&#20041;&#65292;&#21253;&#25324;&#36755;&#20837;&#20998;&#24067;&#21644;&#23398;&#20064;&#31639;&#27861;&#65292;&#36825;&#20026;&#26500;&#24314;&#24378;&#22823;&#30340;OOD&#26816;&#27979;&#27979;&#35797;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#21551;&#21457;&#30340;&#36807;&#31243;&#65292;&#20351;&#29992;&#31526;&#21512;&#24615;p&#20540;&#31995;&#32479;&#22320;&#32467;&#21512;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#20219;&#24847;&#25968;&#37327;&#30340;&#19981;&#21516;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23545;&#23558;&#20837;&#32676;&#26679;&#26412;&#38169;&#35823;&#20998;&#31867;&#20026;OOD&#30340;&#27010;&#29575;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20043;&#21069;&#24037;&#20316;&#20013;&#25552;&#20986;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#27979;&#35797;&#22312;&#29305;&#23450;&#22330;&#26223;&#19979;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;OOD&#23454;&#20363;&#20013;&#30340;&#34920;&#29616;&#24182;&#19981;&#19968;&#33268;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;m&#20010;&#19981;&#21516;&#32479;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Out-of-Distribution (OOD) detection, that is, detecting whether a learning algorithm's output can be trusted at inference time. While a number of tests for OOD detection have been proposed in prior work, a formal framework for studying this problem is lacking. We propose a definition for the notion of OOD that includes both the input distribution and the learning algorithm, which provides insights for the construction of powerful tests for OOD detection. We propose a multiple hypothesis testing inspired procedure to systematically combine any number of different statistics from the learning algorithm using conformal p-values. We further provide strong guarantees on the probability of incorrectly classifying an in-distribution sample as OOD. In our experiments, we find that threshold-based tests proposed in prior work perform well in specific settings, but not uniformly well across different types of OOD instances. In contrast, our proposed method that combines m
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20844;&#24179;&#20998;&#31867;&#20013;&#23384;&#22312;&#30340;&#25112;&#30053;&#25805;&#32437;&#24046;&#24322;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#32422;&#26463;&#30340;&#20248;&#21270;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.10842</link><description>&lt;p&gt;
&#35299;&#20915;&#20844;&#24179;&#20998;&#31867;&#20013;&#25112;&#30053;&#25805;&#32437;&#30340;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
Addressing Strategic Manipulation Disparities in Fair Classification. (arXiv:2205.10842v2 [cs.CY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10842
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20844;&#24179;&#20998;&#31867;&#20013;&#23384;&#22312;&#30340;&#25112;&#30053;&#25805;&#32437;&#24046;&#24322;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#32422;&#26463;&#30340;&#20248;&#21270;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#20998;&#31867;&#29615;&#22659;&#20013;&#65292;&#22914;&#36151;&#27454;&#30003;&#35831;&#35780;&#20272;&#25110;&#22312;&#32447;&#24179;&#21488;&#19978;&#30340;&#20869;&#23481;&#23457;&#26597;&#65292;&#20010;&#20307;&#36890;&#36807;&#25112;&#30053;&#24615;&#22320;&#26356;&#26032;&#20854;&#29305;&#24449;&#26469;&#22686;&#21152;&#20854;&#33719;&#24471;&#29305;&#23450;&#65288;&#31215;&#26497;&#65289;&#20915;&#31574;&#30340;&#21487;&#33021;&#24615;&#65288;&#20197;&#19968;&#23450;&#30340;&#25104;&#26412;&#65289;&#12290;&#28982;&#32780;&#65292;&#24403;&#19981;&#21516;&#20154;&#21475;&#32676;&#20307;&#20855;&#26377;&#19981;&#21516;&#30340;&#29305;&#24449;&#20998;&#24067;&#25110;&#25903;&#20184;&#19981;&#21516;&#30340;&#26356;&#26032;&#25104;&#26412;&#26102;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#26469;&#33258;&#23569;&#25968;&#32676;&#20307;&#30340;&#20010;&#20307;&#20184;&#20986;&#26356;&#39640;&#30340;&#25104;&#26412;&#26469;&#26356;&#26032;&#20854;&#29305;&#24449;&#12290;&#20844;&#24179;&#20998;&#31867;&#26088;&#22312;&#36890;&#36807;&#38480;&#21046;&#20998;&#31867;&#22120;&#28385;&#36275;&#32479;&#35745;&#20844;&#24179;&#24615;&#23646;&#24615;&#26469;&#35299;&#20915;&#27492;&#31867;&#20998;&#31867;&#22120;&#24615;&#33021;&#24046;&#24322;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#24182;&#19981;&#33021;&#30830;&#20445;&#21463;&#32422;&#26463;&#30340;&#20998;&#31867;&#22120;&#20943;&#23569;&#25112;&#30053;&#25805;&#32437;&#25104;&#26412;&#30340;&#24046;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#25112;&#30053;&#29615;&#22659;&#20013;&#30340;&#36825;&#31181;&#20559;&#24046;&#24182;&#20026;&#25112;&#30053;&#25805;&#32437;&#25552;&#20379;&#24179;&#31561;&#26426;&#20250;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#32422;&#26463;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#26500;&#24314;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world classification settings, such as loan application evaluation or content moderation on online platforms, individuals respond to classifier predictions by strategically updating their features to increase their likelihood of receiving a particular (positive) decision (at a certain cost). Yet, when different demographic groups have different feature distributions or pay different update costs, prior work has shown that individuals from minority groups often pay a higher cost to update their features. Fair classification aims to address such classifier performance disparities by constraining the classifiers to satisfy statistical fairness properties. However, we show that standard fairness constraints do not guarantee that the constrained classifier reduces the disparity in strategic manipulation cost. To address such biases in strategic settings and provide equal opportunities for strategic manipulation, we propose a constrained optimization framework that constructs classif
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20613;&#31435;&#21494;&#23481;&#37327;&#26465;&#20214;&#30340;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#30340;&#26368;&#20248;&#23398;&#20064;&#29575;&#65292;&#36890;&#36807;&#25554;&#20540;&#29702;&#35770;&#21644;&#26032;&#30340;&#20613;&#31435;&#21494;&#31561;&#23481;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#24191;&#27867;&#31867;&#21035;&#30340;Tikhonov&#27491;&#21017;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#26368;&#23567;&#21270;&#33258;&#36866;&#24212;&#29575;&#65292;&#19981;&#38656;&#35201;&#22238;&#24402;&#20989;&#25968;&#21253;&#21547;&#22312;&#20551;&#35774;&#38598;&#20013;&#12290;</title><link>http://arxiv.org/abs/2204.07856</link><description>&lt;p&gt;
&#24102;&#26377;&#20613;&#31435;&#21494;&#23481;&#37327;&#26465;&#20214;&#30340;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#30340;&#26368;&#20248;&#23398;&#20064;&#29575;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning Rates for Regularized Least-Squares with a Fourier Capacity Condition. (arXiv:2204.07856v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.07856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20613;&#31435;&#21494;&#23481;&#37327;&#26465;&#20214;&#30340;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#30340;&#26368;&#20248;&#23398;&#20064;&#29575;&#65292;&#36890;&#36807;&#25554;&#20540;&#29702;&#35770;&#21644;&#26032;&#30340;&#20613;&#31435;&#21494;&#31561;&#23481;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#24191;&#27867;&#31867;&#21035;&#30340;Tikhonov&#27491;&#21017;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#26368;&#23567;&#21270;&#33258;&#36866;&#24212;&#29575;&#65292;&#19981;&#38656;&#35201;&#22238;&#24402;&#20989;&#25968;&#21253;&#21547;&#22312;&#20551;&#35774;&#38598;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;Hilbert&#31354;&#38388;&#20013;&#30340;&#24191;&#27867;&#31867;&#21035;&#30340;Tikhonov&#27491;&#21017;&#21270;&#23398;&#20064;&#38382;&#39064;&#20013;&#25512;&#23548;&#20986;&#26368;&#23567;&#21270;&#33258;&#36866;&#24212;&#29575;&#65292;&#19981;&#38656;&#35201;&#22238;&#24402;&#20989;&#25968;&#21253;&#21547;&#22312;&#20551;&#35774;&#38598;&#20013;&#65292;&#24182;&#19988;&#26368;&#37325;&#35201;&#30340;&#26159;&#19981;&#20351;&#29992;&#20256;&#32479;&#30340;&#20869;&#26680;&#29305;&#24449;&#34928;&#20943;&#30340;&#20808;&#39564;&#20551;&#35774;&#12290;&#36890;&#36807;&#25554;&#20540;&#29702;&#35770;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#30340;Hilbert&#31354;&#38388;&#30340;&#8220;&#32039;&#8221;$L^{\infty}(\mathcal{X})$&#23884;&#20837;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#25512;&#26029;&#20986;Mercer&#31639;&#23376;&#30340;&#39057;&#35889;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21033;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#20613;&#31435;&#21494;&#31561;&#23481;&#24615;&#26465;&#20214;&#65292;&#36890;&#36807;&#26368;&#20248;Hilbert&#23610;&#24230;&#20989;&#25968;&#25429;&#25417;&#20102;&#20869;&#26680;Dirichlet&#23481;&#37327;&#21644;&#23567;&#29699;&#27010;&#29575;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive minimax adaptive rates for a new, broad class of Tikhonov-regularized learning problems in Hilbert scales under general source conditions. Our analysis does not require the regression function to be contained in the hypothesis class, and most notably does not employ the conventional \textit{a priori} assumptions on kernel eigendecay. Using the theory of interpolation, we demonstrate that the spectrum of the Mercer operator can be inferred in the presence of ``tight'' $L^{\infty}(\mathcal{X})$ embeddings of suitable Hilbert scales. Our analysis utilizes a new Fourier isocapacitary condition, which captures the interplay of the kernel Dirichlet capacities and small ball probabilities via the optimal Hilbert scale function.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26469;&#26368;&#22823;&#21270;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#23616;&#37096;AUC&#65288;pAUC&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#20934;&#30830;&#21644;&#24179;&#28369;&#30340;pAUC&#20272;&#35745;&#37327;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.00176</link><description>&lt;p&gt;
&#24403;AUC&#36935;&#19978;DRO&#65306;&#22522;&#20110;&#38750;&#20984;&#25910;&#25947;&#20445;&#35777;&#30340;&#28145;&#24230;&#23398;&#20064;&#23616;&#37096;AUC&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
When AUC meets DRO: Optimizing Partial AUC for Deep Learning with Non-Convex Convergence Guarantee. (arXiv:2203.00176v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00176
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26469;&#26368;&#22823;&#21270;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#23616;&#37096;AUC&#65288;pAUC&#65289;&#65292;&#24182;&#25552;&#20986;&#20102;&#20934;&#30830;&#21644;&#24179;&#28369;&#30340;pAUC&#20272;&#35745;&#37327;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#19968;&#31181;&#31995;&#32479;&#19988;&#39640;&#25928;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#19968;&#27425;&#24615;&#21644;&#20108;&#27425;&#24615;&#23616;&#37096;AUC&#65288;pAUC&#65289;&#26368;&#22823;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26469;&#20026;&#27599;&#20010;&#21333;&#29420;&#30340;&#27491;&#25968;&#25454;&#23450;&#20041;&#25439;&#22833;&#65292;&#25552;&#20986;&#20102;pAUC&#26367;&#20195;&#30446;&#26631;&#30340;&#26032;&#20844;&#24335;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;DRO&#30340;&#24418;&#24335;&#65292;&#19968;&#31181;&#22522;&#20110;&#26465;&#20214;&#39118;&#38505;&#20540;&#65288;CVaR&#65289;&#65292;&#20135;&#29983;&#38750;&#24179;&#28369;&#20294;&#20934;&#30830;&#30340;pAUC&#20272;&#35745;&#37327;&#65307;&#21478;&#19968;&#31181;&#22522;&#20110;KL&#25955;&#24230;&#27491;&#21017;&#21270;&#30340;DRO&#65292;&#20135;&#29983;&#19981;&#20934;&#30830;&#20294;&#24179;&#28369;&#65288;&#36719;&#65289;&#30340;pAUC&#20272;&#35745;&#37327;&#12290;&#23545;&#20110;&#19968;&#27425;&#24615;&#21644;&#20108;&#27425;&#24615;pAUC&#26368;&#22823;&#21270;&#65292;&#25105;&#20204;&#20998;&#21035;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#23545;&#20110;&#20248;&#21270;&#21508;&#33258;&#30340;&#20004;&#31181;&#24418;&#24335;&#30340;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;pAUC&#26368;&#22823;&#21270;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose systematic and efficient gradient-based methods for both one-way and two-way partial AUC (pAUC) maximization that are applicable to deep learning. We propose new formulations of pAUC surrogate objectives by using the distributionally robust optimization (DRO) to define the loss for each individual positive data. We consider two formulations of DRO, one of which is based on conditional-value-at-risk (CVaR) that yields a non-smooth but exact estimator for pAUC, and another one is based on a KL divergence regularized DRO that yields an inexact but smooth (soft) estimator for pAUC. For both one-way and two-way pAUC maximization, we propose two algorithms and prove their convergence for optimizing their two formulations, respectively. Experiments demonstrate the effectiveness of the proposed algorithms for pAUC maximization for deep learning on various datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31995;&#21015;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#30456;&#20284;&#24615;&#21644;&#24046;&#24322;&#24615;&#65292;&#24182;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.05250</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#40065;&#26834;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive and Robust Multi-Task Learning. (arXiv:2202.05250v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31995;&#21015;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#30456;&#20284;&#24615;&#21644;&#24046;&#24322;&#24615;&#65292;&#24182;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#35299;&#20915;&#20174;&#19981;&#21516;&#26469;&#28304;&#25910;&#38598;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#24182;&#23545;&#27599;&#20010;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#20010;&#27169;&#22411;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#33258;&#21160;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#21516;&#26102;&#22788;&#29702;&#23427;&#20204;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#23545;&#24322;&#24120;&#20219;&#21153;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the multi-task learning problem that aims to simultaneously analyze multiple datasets collected from different sources and learn one model for each of them. We propose a family of adaptive methods that automatically utilize possible similarities among those tasks while carefully handling their differences. We derive sharp statistical guarantees for the methods and prove their robustness against outlier tasks. Numerical experiments on synthetic and real datasets demonstrate the efficacy of our new methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#26080;&#32500;&#24230;&#24230;&#37327;&#65292;&#29992;&#20110;&#39640;&#32500;&#24773;&#20917;&#19979;&#32463;&#39564;&#27979;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#32500;&#24230;&#28798;&#38590;&#38382;&#39064;&#65292;&#20855;&#26377;&#37325;&#35201;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2104.12036</link><description>&lt;p&gt;
&#19968;&#31867;&#26080;&#32500;&#24230;&#24230;&#37327;&#29992;&#20110;&#32463;&#39564;&#27979;&#24230;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
A Class of Dimension-free Metrics for the Convergence of Empirical Measures. (arXiv:2104.12036v4 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.12036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#26080;&#32500;&#24230;&#24230;&#37327;&#65292;&#29992;&#20110;&#39640;&#32500;&#24773;&#20917;&#19979;&#32463;&#39564;&#27979;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#35299;&#20915;&#20102;&#32500;&#24230;&#28798;&#38590;&#38382;&#39064;&#65292;&#20855;&#26377;&#37325;&#35201;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#39640;&#32500;&#24773;&#20917;&#19979;&#32463;&#39564;&#27979;&#24230;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#24230;&#37327;&#31867;&#65292;&#35777;&#26126;&#22312;&#36825;&#31181;&#24230;&#37327;&#19979;&#65292;&#25910;&#25947;&#24615;&#19981;&#21463;&#32500;&#24230;&#28798;&#38590;&#30340;&#24433;&#21709;&#12290;&#36825;&#31181;&#29305;&#24615;&#23545;&#20110;&#39640;&#32500;&#20998;&#26512;&#33267;&#20851;&#37325;&#35201;&#65292;&#19982;&#32463;&#20856;&#24230;&#37327;&#65288;&#22914;Wasserstein&#24230;&#37327;&#65289;&#24418;&#25104;&#23545;&#27604;&#12290;&#25152;&#25552;&#20986;&#30340;&#24230;&#37327;&#23646;&#20110;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;&#30340;&#33539;&#30068;&#65292;&#25105;&#20204;&#25351;&#23450;&#20102;&#27979;&#35797;&#20989;&#25968;&#31354;&#38388;&#30340;&#20934;&#21017;&#65292;&#20197;&#30830;&#20445;&#19981;&#21463;&#32500;&#24230;&#28798;&#38590;&#24433;&#21709;&#12290;&#25152;&#36873;&#27979;&#35797;&#20989;&#25968;&#31354;&#38388;&#30340;&#20363;&#23376;&#21253;&#25324;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#12289;Barron&#31354;&#38388;&#21644;&#27969;&#35825;&#23548;&#20989;&#25968;&#31354;&#38388;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25152;&#25552;&#20986;&#24230;&#37327;&#30340;&#19977;&#20010;&#24212;&#29992;&#65306;1. &#22312;&#38543;&#26426;&#21464;&#37327;&#24773;&#20917;&#19979;&#30340;&#32463;&#39564;&#27979;&#24230;&#25910;&#25947;&#24615;&#65307;2. n&#31890;&#23376;&#31995;&#32479;&#25910;&#25947;&#20110;McKean-Vlasov&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#65307;3. &#26500;&#36896;&#40784;&#27425;n-player&#30340;&#949;-Nash&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper concerns the convergence of empirical measures in high dimensions. We propose a new class of probability metrics and show that under such metrics, the convergence is free of the curse of dimensionality (CoD). Such a feature is critical for high-dimensional analysis and stands in contrast to classical metrics ({\it e.g.}, the Wasserstein metric). The proposed metrics fall into the category of integral probability metrics, for which we specify criteria of test function spaces to guarantee the property of being free of CoD. Examples of the selected test function spaces include the reproducing kernel Hilbert spaces, Barron space, and flow-induced function spaces. Three applications of the proposed metrics are presented: 1. The convergence of empirical measure in the case of random variables; 2. The convergence of $n$-particle system to the solution to McKean-Vlasov stochastic differential equation; 3. The construction of an $\varepsilon$-Nash equilibrium for a homogeneous $n$-pl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#25552;&#20379;&#35299;&#31163;&#30028;&#65292;&#30456;&#27604;&#29616;&#26377;&#26694;&#26550;&#22312;&#31070;&#32463;&#32593;&#32476;&#19978;&#26377;&#26174;&#33879;&#30340;&#23454;&#29992;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2102.08649</link><description>&lt;p&gt;
&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#29992;&#20110;PAC-Bayesian&#30028;&#30340;&#23454;&#29992;&#35299;&#35835;
&lt;/p&gt;
&lt;p&gt;
A General Framework for the Practical Disintegration of PAC-Bayesian Bounds. (arXiv:2102.08649v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.08649
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#25552;&#20379;&#35299;&#31163;&#30028;&#65292;&#30456;&#27604;&#29616;&#26377;&#26694;&#26550;&#22312;&#31070;&#32463;&#32593;&#32476;&#19978;&#26377;&#26174;&#33879;&#30340;&#23454;&#29992;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian&#30028;&#22312;&#30740;&#31350;&#38543;&#26426;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#33021;&#21147;&#26102;&#24050;&#34987;&#35777;&#26126;&#32039;&#20945;&#32780;&#19988;&#26377;&#20449;&#24687;&#37327;&#12290;&#28982;&#32780;&#65292;&#24403;&#24212;&#29992;&#20110;&#19968;&#20123;&#30830;&#23450;&#24615;&#27169;&#22411;&#23478;&#26063;&#65288;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#26102;&#65292;&#23427;&#20204;&#38656;&#35201;&#26494;&#24347;&#19988;&#26114;&#36149;&#30340;&#21435;&#38543;&#26426;&#21270;&#27493;&#39588;&#12290;&#20316;&#20026;&#26367;&#20195;&#27493;&#39588;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;PAC-Bayesian&#27867;&#21270;&#30028;&#65292;&#36825;&#20123;&#30028;&#29420;&#20855;&#21019;&#26032;&#24615;&#65292;&#33021;&#22815;&#25552;&#20379;&#35299;&#31163;&#30028;&#65292;&#21363;&#23427;&#20204;&#33021;&#22815;&#23545;&#19968;&#20010;&#21333;&#19968;&#20551;&#35774;&#25552;&#20379;&#20445;&#35777;&#65292;&#32780;&#19981;&#26159;&#36890;&#24120;&#30340;&#24179;&#22343;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#30028;&#26131;&#20110;&#20248;&#21270;&#65292;&#24182;&#21487;&#29992;&#20110;&#35774;&#35745;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#22312;&#31070;&#32463;&#32593;&#32476;&#19978;&#23637;&#31034;&#20102;&#36825;&#31181;&#34892;&#20026;&#65292;&#24182;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#26694;&#26550;&#30456;&#27604;&#30340;&#26174;&#33879;&#23454;&#29992;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
PAC-Bayesian bounds are known to be tight and informative when studying the generalization ability of randomized classifiers. However, they require a loose and costly derandomization step when applied to some families of deterministic models such as neural networks. As an alternative to this step, we introduce new PAC-Bayesian generalization bounds that have the originality to provide disintegrated bounds, i.e., they give guarantees over one single hypothesis instead of the usual averaged analysis. Our bounds are easily optimizable and can be used to design learning algorithms. We illustrate this behavior on neural networks, and we show a significant practical improvement over the state-of-the-art framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25042;&#24816;&#22411;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#20854;&#22312;&#20999;&#25442;&#27425;&#25968;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#19988;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#21576;&#29616;&#20986;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2102.03803</link><description>&lt;p&gt;
&#25042;&#24816;&#22411;&#22312;&#32447;&#20984;&#20248;&#21270;: &#20999;&#25442;&#39044;&#31639;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.03803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25042;&#24816;&#22411;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#20854;&#22312;&#20999;&#25442;&#27425;&#25968;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#19988;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#21576;&#29616;&#20986;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#29609;&#23478;&#22312;T&#36718;&#20013;&#30340;&#26399;&#26395;&#20999;&#25442;&#20915;&#31574;&#19981;&#36229;&#36807;S&#27425;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35299;&#20915;&#20102;&#31163;&#25955;&#20915;&#31574;&#35774;&#32622;&#20013;&#30340;&#31867;&#20284;&#38382;&#39064;&#65292;&#26368;&#36817;&#20063;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#20351;&#29992;&#33258;&#36866;&#24212;&#23545;&#25163;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#24182;&#22312;&#26222;&#36941;&#23384;&#22312;&#30340;&#26080;&#30693;&#35774;&#32622;&#20013;&#25552;&#20986;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#19968;&#33324;&#20984;&#25439;&#22833;&#24314;&#31435;&#20102;O(T/S)&#30340;&#36951;&#25022;&#19978;&#30028;&#20197;&#21450;&#24378;&#20984;&#25439;&#22833;&#30340;&#36817;&#20284;O(T/S^2)&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#38543;&#26426;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#22312;&#19968;&#33324;&#21644;&#24378;&#20984;&#35774;&#32622;&#20013;&#36951;&#25022;&#20165;&#26377;&#23545;&#25968;&#22240;&#23376;&#30340;&#20056;&#27861;log T&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;log T&#27425;&#20999;&#25442;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34917;&#20805;&#20102;&#19982;&#25105;&#20204;&#32771;&#34385;&#30340;&#19968;&#20123;&#24773;&#20917;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#26469;&#34917;&#20805;&#25105;&#20204;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a variant of online convex optimization where the player is permitted to switch decisions at most $S$ times in expectation throughout $T$ rounds. Similar problems have been addressed in prior work for the discrete decision set setting, and more recently in the continuous setting but only with an adaptive adversary. In this work, we aim to fill the gap and present computationally efficient algorithms in the more prevalent oblivious setting, establishing a regret bound of $O(T/S)$ for general convex losses and $\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches with only a multiplicative $\log T$ factor overhead in its regret in both the general and strongly convex settings. Finally, we complement our algorithms with lower bounds that match our upper bounds in some of the cases we consider.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#23581;&#35797;&#22312;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#26041;&#24046;&#39118;&#38505;&#20934;&#21017;&#30740;&#31350;&#39118;&#38505;&#25935;&#24863;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26041;&#24046;&#32422;&#26463;&#30340;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2012.14098</link><description>&lt;p&gt;
&#39118;&#38505;&#25935;&#24863;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65306;&#26041;&#24046;&#32422;&#26463;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#33021;&#22815;&#25214;&#21040;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Risk-Sensitive Deep RL: Variance-Constrained Actor-Critic Provably Finds Globally Optimal Policy. (arXiv:2012.14098v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.14098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#23581;&#35797;&#22312;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#26041;&#24046;&#39118;&#38505;&#20934;&#21017;&#30740;&#31350;&#39118;&#38505;&#25935;&#24863;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26041;&#24046;&#32422;&#26463;&#30340;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#20165;&#20851;&#27880;&#26368;&#22823;&#21270;&#24635;&#22238;&#25253;&#30340;&#26399;&#26395;&#20540;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#20854;&#22266;&#26377;&#30340;&#38543;&#26426;&#24615;&#12290;&#36825;&#31181;&#38543;&#26426;&#24615;&#20063;&#34987;&#31216;&#20026;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19982;&#39118;&#38505;&#30340;&#27010;&#24565;&#23494;&#20999;&#30456;&#20851;&#12290;&#26412;&#25991;&#39318;&#27425;&#23581;&#35797;&#22312;&#24179;&#22343;&#22870;&#21169;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#26041;&#24046;&#39118;&#38505;&#20934;&#21017;&#30740;&#31350;&#39118;&#38505;&#25935;&#24863;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#19968;&#20010;&#26041;&#24046;&#32422;&#26463;&#30340;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#20010;&#31574;&#30053;&#65292;&#26368;&#22823;&#21270;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#30340;&#26399;&#26395;&#20540;&#65292;&#24182;&#19988;&#20351;&#24471;&#38271;&#26399;&#24179;&#22343;&#22870;&#21169;&#30340;&#26041;&#24046;&#19978;&#30028;&#19981;&#36229;&#36807;&#26576;&#20010;&#38408;&#20540;&#12290;&#21033;&#29992;Lagrange&#21644;Fenchel&#23545;&#20598;&#24615;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#20010;&#26080;&#32422;&#26463;&#30340;&#38797;&#28857;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36845;&#20195;&#21644;&#39640;&#25928;&#26356;&#26032;&#31574;&#30053;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
While deep reinforcement learning has achieved tremendous successes in various applications, most existing works only focus on maximizing the expected value of total return and thus ignore its inherent stochasticity. Such stochasticity is also known as the aleatoric uncertainty and is closely related to the notion of risk. In this work, we make the first attempt to study risk-sensitive deep reinforcement learning under the average reward setting with the variance risk criteria. In particular, we focus on a variance-constrained policy optimization problem where the goal is to find a policy that maximizes the expected value of the long-run average reward, subject to a constraint that the long-run variance of the average reward is upper bounded by a threshold. Utilizing Lagrangian and Fenchel dualities, we transform the original problem into an unconstrained saddle-point policy optimization problem, and propose an actor-critic algorithm that iteratively and efficiently updates the policy,
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22686;&#21152;&#27744;&#21270;&#23618;&#21644;&#37325;&#24314;&#23618;&#26469;&#25913;&#36827;&#33014;&#22218;&#32593;&#32476;&#65288;CN&#65289;&#30340;&#35774;&#35745;&#65292;&#20197;&#36866;&#24212;&#20855;&#26377;&#19981;&#21516;&#19978;&#19979;&#25991;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#24182;&#19982;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#36827;&#34892;&#20102;&#24615;&#33021;&#23545;&#27604;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;CN&#22312;&#22823;&#22823;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#30340;&#21516;&#26102;&#34920;&#29616;&#20986;&#20102;&#19982;DL&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/1903.07497</link><description>&lt;p&gt;
&#22522;&#20110;&#19978;&#19979;&#25991;&#24863;&#30693;&#30340;&#20808;&#36827;&#33014;&#22218;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Advanced Capsule Networks via Context Awareness. (arXiv:1903.07497v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.07497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22686;&#21152;&#27744;&#21270;&#23618;&#21644;&#37325;&#24314;&#23618;&#26469;&#25913;&#36827;&#33014;&#22218;&#32593;&#32476;&#65288;CN&#65289;&#30340;&#35774;&#35745;&#65292;&#20197;&#36866;&#24212;&#20855;&#26377;&#19981;&#21516;&#19978;&#19979;&#25991;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#24182;&#19982;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#36827;&#34892;&#20102;&#24615;&#33021;&#23545;&#27604;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;CN&#22312;&#22823;&#22823;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#30340;&#21516;&#26102;&#34920;&#29616;&#20986;&#20102;&#19982;DL&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33014;&#22218;&#32593;&#32476;&#65288;CN&#65289;&#20026;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#31038;&#21306;&#25552;&#20379;&#20102;&#26032;&#30340;&#26550;&#26500;&#12290;&#23613;&#31649;&#23427;&#30340;&#26377;&#25928;&#24615;&#24050;&#32463;&#22312;MNIST&#21644;smallNORB&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#20294;&#26159;&#23545;&#20110;&#20855;&#26377;&#19981;&#21516;&#19978;&#19979;&#25991;&#30340;&#22270;&#20687;&#30340;&#25968;&#25454;&#38598;&#65292;&#35813;&#32593;&#32476;&#20173;&#28982;&#38754;&#20020;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;CN&#65288;&#21521;&#37327;&#29256;&#26412;&#65289;&#30340;&#35774;&#35745;&#65292;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#22686;&#21152;&#20102;&#26356;&#22810;&#30340;&#27744;&#21270;&#23618;&#26469;&#36807;&#28388;&#22270;&#20687;&#32972;&#26223;&#65292;&#24182;&#22686;&#21152;&#20102;&#26356;&#22810;&#30340;&#37325;&#24314;&#23618;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#22270;&#20687;&#24674;&#22797;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#27604;&#36739;&#20102;CN&#21644;DL&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;&#22312;DL&#27169;&#22411;&#20013;&#65292;&#38500;&#20102;&#22312;&#24378;&#22823;&#30340;&#35745;&#31639;&#26426;&#19978;&#20351;&#29992;Inception V3&#21644;DenseNet V201&#22806;&#65292;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;NASNet&#12289;MobileNet V1&#21644;MobileNet V2&#26469;&#36866;&#29992;&#20110;&#23567;&#22411;&#21644;&#23884;&#20837;&#24335;&#35774;&#22791;&#12290;&#25105;&#20204;&#22312;&#32654;&#22269;&#25163;&#35821;&#65288;ASL&#65289;&#30340;&#25163;&#25351;&#25340;&#20889;&#23383;&#27597;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;CN&#19982;DL&#27169;&#22411;&#30456;&#27604;&#65292;&#22312;&#22823;&#22823;&#20943;&#23569;&#35757;&#32451;&#26102;&#38388;&#30340;&#21516;&#26102;&#34920;&#29616;&#20986;&#20102;&#21487;&#27604;&#36739;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#38142;&#25509;&#20197;&#36827;&#34892;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Capsule Networks (CN) offer new architectures for Deep Learning (DL) community. Though its effectiveness has been demonstrated in MNIST and smallNORB datasets, the networks still face challenges in other datasets for images with distinct contexts. In this research, we improve the design of CN (Vector version) namely we expand more Pooling layers to filter image backgrounds and increase Reconstruction layers to make better image restoration. Additionally, we perform experiments to compare accuracy and speed of CN versus DL models. In DL models, we utilize Inception V3 and DenseNet V201 for powerful computers besides NASNet, MobileNet V1 and MobileNet V2 for small and embedded devices. We evaluate our models on a fingerspelling alphabet dataset from American Sign Language (ASL). The results show that CNs perform comparably to DL models while dramatically reducing training time. We also make a demonstration and give a link for the purpose of illustration.
&lt;/p&gt;</description></item></channel></rss>