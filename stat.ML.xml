<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#23398;&#20064;&#25193;&#25955;&#30340;&#26041;&#27861;&#25913;&#36827;&#20102;&#37319;&#26679;&#36807;&#31243;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#21464;&#20998;&#24418;&#24335;&#30340;&#36335;&#24452;&#31354;&#38388;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#23545;&#25968;&#26041;&#24046;&#25439;&#22833;&#65292;&#20248;&#21270;&#20102;&#37319;&#26679;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.01198</link><description>&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#25193;&#25955;&#25913;&#36827;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Improved sampling via learned diffusions. (arXiv:2307.01198v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01198
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23398;&#20064;&#25193;&#25955;&#30340;&#26041;&#27861;&#25913;&#36827;&#20102;&#37319;&#26679;&#36807;&#31243;&#65292;&#24341;&#20837;&#20102;&#22522;&#20110;&#21464;&#20998;&#24418;&#24335;&#30340;&#36335;&#24452;&#31354;&#38388;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#23545;&#25968;&#26041;&#24046;&#25439;&#22833;&#65292;&#20248;&#21270;&#20102;&#37319;&#26679;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#19968;&#31995;&#21015;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#25511;&#21046;&#25193;&#25955;&#36807;&#31243;&#20174;&#38750;&#26631;&#20934;&#21270;&#30446;&#26631;&#23494;&#24230;&#20013;&#37319;&#26679;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#35270;&#20026;Schr&#246;dinger&#26725;&#38382;&#39064;&#30340;&#29305;&#20363;&#65292;&#23547;&#27714;&#32473;&#23450;&#20808;&#39564;&#20998;&#24067;&#21644;&#25351;&#23450;&#30446;&#26631;&#20043;&#38388;&#26368;&#21487;&#33021;&#30340;&#38543;&#26426;&#28436;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#24341;&#20837;&#22522;&#20110;&#26102;&#38388;&#21453;&#28436;&#25193;&#25955;&#36807;&#31243;&#30340;&#36335;&#24452;&#31354;&#38388;&#24230;&#37327;&#20043;&#38388;&#30340;&#24046;&#24322;&#30340;&#21464;&#20998;&#24418;&#24335;&#26469;&#25512;&#24191;&#36825;&#20010;&#26694;&#26550;&#12290;&#36825;&#20010;&#25277;&#35937;&#30340;&#35270;&#35282;&#23548;&#33268;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#20248;&#21270;&#30340;&#23454;&#38469;&#25439;&#22833;&#65292;&#24182;&#23558;&#20808;&#21069;&#30340;&#30446;&#26631;&#20316;&#20026;&#29305;&#20363;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#23427;&#20801;&#35768;&#25105;&#20204;&#32771;&#34385;&#38500;&#20102;&#24050;&#30693;&#23384;&#22312;&#27169;&#24335;&#22349;&#32553;&#38382;&#39064;&#30340;&#21453;&#21521;Kullback-Leibler&#24046;&#21035;&#20043;&#22806;&#30340;&#20854;&#20182;&#24046;&#21035;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25152;&#35859;&#30340;&#23545;&#25968;&#26041;&#24046;&#25439;&#22833;&#65292;&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#25968;&#20540;&#29305;&#24615;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#22312;&#25152;&#26377;&#32771;&#34385;&#30340;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, a series of papers proposed deep learning-based approaches to sample from unnormalized target densities using controlled diffusion processes. In this work, we identify these approaches as special cases of the Schr\"odinger bridge problem, seeking the most likely stochastic evolution between a given prior distribution and the specified target. We further generalize this framework by introducing a variational formulation based on divergences between path space measures of time-reversed diffusion processes. This abstract perspective leads to practical losses that can be optimized by gradient-based algorithms and includes previous objectives as special cases. At the same time, it allows us to consider divergences other than the reverse Kullback-Leibler divergence that is known to suffer from mode collapse. In particular, we propose the so-called log-variance loss, which exhibits favorable numerical properties and leads to significantly improved performance across all considered a
&lt;/p&gt;</description></item><item><title>&#23558;$n$&#20010;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#25311;&#21512;&#21040;&#20197;&#21407;&#28857;&#20026;&#20013;&#24515;&#30340;&#26925;&#29699;&#20307;&#36793;&#30028;&#30340;&#38382;&#39064;$(\mathrm{P})$&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38543;&#26426;&#21521;&#37327;Gram&#30697;&#38453;&#38598;&#20013;&#24615;&#30340;&#25913;&#36827;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#24403;$n \leq d^2 / C$&#26102;&#65292;&#38382;&#39064;$(\mathrm{P})$&#20855;&#26377;&#24456;&#39640;&#30340;&#21487;&#34892;&#24615;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.01181</link><description>&lt;p&gt;
&#23558;&#22823;&#37327;&#38543;&#26426;&#28857;&#25311;&#21512;&#25104;&#26925;&#29699;&#20307;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fitting an ellipsoid to a quadratic number of random points. (arXiv:2307.01181v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01181
&lt;/p&gt;
&lt;p&gt;
&#23558;$n$&#20010;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#25311;&#21512;&#21040;&#20197;&#21407;&#28857;&#20026;&#20013;&#24515;&#30340;&#26925;&#29699;&#20307;&#36793;&#30028;&#30340;&#38382;&#39064;$(\mathrm{P})$&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38543;&#26426;&#21521;&#37327;Gram&#30697;&#38453;&#38598;&#20013;&#24615;&#30340;&#25913;&#36827;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#24403;$n \leq d^2 / C$&#26102;&#65292;&#38382;&#39064;$(\mathrm{P})$&#20855;&#26377;&#24456;&#39640;&#30340;&#21487;&#34892;&#24615;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24403;$n, d \to \infty $&#26102;&#65292;&#23558;$n$&#20010;&#26631;&#20934;&#39640;&#26031;&#38543;&#26426;&#21521;&#37327;&#25311;&#21512;&#21040;&#20197;&#21407;&#28857;&#20026;&#20013;&#24515;&#30340;&#26925;&#29699;&#20307;&#30340;&#36793;&#30028;&#30340;&#38382;&#39064;$(\mathrm{P})$&#12290;&#36825;&#20010;&#38382;&#39064;&#34987;&#29468;&#27979;&#20855;&#26377;&#23574;&#38160;&#30340;&#21487;&#34892;&#24615;&#36716;&#21464;&#65306;&#23545;&#20110;&#20219;&#24847;$\varepsilon &gt; 0$&#65292;&#22914;&#26524;$n \leq (1 - \varepsilon) d^2 / 4$&#65292;&#37027;&#20040;$(\mathrm{P})$&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#26377;&#35299;&#65307;&#32780;&#22914;&#26524;$n \geq (1 + \varepsilon) d^2 /4$&#65292;&#37027;&#20040;$(\mathrm{P})$&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#26080;&#35299;&#12290;&#30446;&#21069;&#65292;&#23545;&#20110;&#36127;&#38754;&#24773;&#20917;&#65292;&#21482;&#30693;&#36947;$n \geq d^2 / 2$&#26159;&#24179;&#20961;&#30340;&#19968;&#20010;&#19978;&#30028;&#65292;&#32780;&#23545;&#20110;&#27491;&#38754;&#24773;&#20917;&#65292;&#24050;&#30693;&#30340;&#26368;&#22909;&#32467;&#26524;&#26159;&#20551;&#35774;$n \leq d^2 / \mathrm{polylog}(d)$&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;Bartl&#21644;Mendelson&#20851;&#20110;&#38543;&#26426;&#21521;&#37327;&#30340;Gram&#30697;&#38453;&#38598;&#20013;&#24615;&#30340;&#19968;&#20010;&#20851;&#38190;&#32467;&#26524;&#25913;&#36827;&#20102;&#20197;&#21069;&#30340;&#26041;&#27861;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#32473;&#20986;&#19968;&#20010;&#31616;&#21333;&#30340;&#35777;&#26126;&#65292;&#24403;$n \leq d^2 / C$&#26102;&#65292;&#38382;&#39064;$(\mathrm{P})$&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#26159;&#21487;&#34892;&#30340;&#65292;&#20854;&#20013;$C&gt; 0$&#26159;&#19968;&#20010;&#65288;&#21487;&#33021;&#24456;&#22823;&#30340;&#65289;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem $(\mathrm{P})$ of fitting $n$ standard Gaussian random vectors in $\mathbb{R}^d$ to the boundary of a centered ellipsoid, as $n, d \to \infty$. This problem is conjectured to have a sharp feasibility transition: for any $\varepsilon &gt; 0$, if $n \leq (1 - \varepsilon) d^2 / 4$ then $(\mathrm{P})$ has a solution with high probability, while $(\mathrm{P})$ has no solutions with high probability if $n \geq (1 + \varepsilon) d^2 /4$. So far, only a trivial bound $n \geq d^2 / 2$ is known on the negative side, while the best results on the positive side assume $n \leq d^2 / \mathrm{polylog}(d)$. In this work, we improve over previous approaches using a key result of Bartl &amp; Mendelson on the concentration of Gram matrices of random vectors under mild assumptions on their tail behavior. This allows us to give a simple proof that $(\mathrm{P})$ is feasible with high probability when $n \leq d^2 / C$, for a (possibly large) constant $C &gt; 0$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36825;&#19968;&#22522;&#30784;&#20998;&#24067;&#26063;&#25552;&#20379;&#20102;&#39318;&#20010;&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23545;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30446;&#26631;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28151;&#21512;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.01178</link><description>&lt;p&gt;
&#20351;&#29992;DDPM&#30446;&#26631;&#20989;&#25968;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Mixtures of Gaussians Using the DDPM Objective. (arXiv:2307.01178v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01178
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36825;&#19968;&#22522;&#30784;&#20998;&#24067;&#26063;&#25552;&#20379;&#20102;&#39318;&#20010;&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23545;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30446;&#26631;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#28151;&#21512;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#23398;&#20064;&#20960;&#20046;&#20219;&#20309;&#20998;&#24067;&#65292;&#21069;&#25552;&#26159;&#25105;&#20204;&#33021;&#22815;&#36827;&#34892;&#35780;&#20998;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22312;&#20160;&#20040;&#35774;&#32622;&#19979;&#21487;&#20197;&#36827;&#34892;&#35780;&#20998;&#20272;&#35745;&#65292;&#20197;&#21450;&#20309;&#26102;&#21487;&#20197;&#23454;&#38469;&#19978;&#35777;&#26126;&#22522;&#20110;&#26799;&#24230;&#30340;&#31639;&#27861;&#33021;&#22815;&#25104;&#21151;&#65292;&#36825;&#20173;&#28982;&#19981;&#21313;&#20998;&#28165;&#26970;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#22312;&#36825;&#20123;&#26041;&#38754;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#26377;&#25928;&#30340;&#32467;&#26524;&#65292;&#30740;&#31350;&#30340;&#26159;&#26368;&#22522;&#26412;&#30340;&#20998;&#24067;&#26063;&#20043;&#19968;&#65292;&#21363;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20197;&#19979;&#20004;&#31181;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23545;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30446;&#26631;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#39640;&#25928;&#22320;&#24674;&#22797;&#28151;&#21512;&#27169;&#22411;&#30340;&#30495;&#23454;&#21442;&#25968;&#65306;1&#65289;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#23398;&#20064;&#20855;&#26377;$d$&#32500;&#24230;&#21644;$1/\text{poly}(d)$-&#20998;&#38548;&#20013;&#24515;&#30340;&#20004;&#20010;&#29699;&#38754;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12290;2&#65289;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#24102;&#26377;&#28909;&#21551;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#21487;&#20197;&#23398;&#20064;&#20855;&#26377;$\Omega(\sqrt{\log(\min(K,d))})$-&#20998;&#38548;&#20013;&#24515;&#30340;$K$&#20010;&#29699;&#38754;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#30340;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#26159;&#19968;&#20010;&#26032;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Recent works have shown that diffusion models can learn essentially any distribution provided one can perform score estimation. Yet it remains poorly understood under what settings score estimation is possible, let alone when practical gradient-based algorithms for this task can provably succeed.  In this work, we give the first provably efficient results along these lines for one of the most fundamental distribution families, Gaussian mixture models. We prove that gradient descent on the denoising diffusion probabilistic model (DDPM) objective can efficiently recover the ground truth parameters of the mixture model in the following two settings: 1) We show gradient descent with random initialization learns mixtures of two spherical Gaussians in $d$ dimensions with $1/\text{poly}(d)$-separated centers. 2) We show gradient descent with a warm start learns mixtures of $K$ spherical Gaussians with $\Omega(\sqrt{\log(\min(K,d))})$-separated centers. A key ingredient in our proofs is a new 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;(NHL)&#30340;&#27010;&#24565;&#65292;&#23427;&#23558;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#19968;&#31995;&#21015;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#20989;&#25968;&#31354;&#38388;&#20869;&#30340;&#24615;&#36136;&#21644;&#24212;&#29992;&#12290;&#36890;&#36807;&#35777;&#26126;&#19981;&#21516;&#23618;&#27425;&#30340;NHL&#19982;&#22810;&#23618;NNs&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;NHL&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;NHL&#30340;&#29305;&#24449;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#22312;ReLU&#21644;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#19979;&#23637;&#31034;&#20102;NHLs&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2307.01177</link><description>&lt;p&gt;
&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;&#65306;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space. (arXiv:2307.01177v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;(NHL)&#30340;&#27010;&#24565;&#65292;&#23427;&#23558;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#25551;&#36848;&#20026;&#19968;&#31995;&#21015;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65292;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#30740;&#31350;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#22312;&#20989;&#25968;&#31354;&#38388;&#20869;&#30340;&#24615;&#36136;&#21644;&#24212;&#29992;&#12290;&#36890;&#36807;&#35777;&#26126;&#19981;&#21516;&#23618;&#27425;&#30340;NHL&#19982;&#22810;&#23618;NNs&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;NHL&#30340;&#27867;&#21270;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;NHL&#30340;&#29305;&#24449;&#21160;&#21147;&#23398;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#22312;ReLU&#21644;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#19979;&#23637;&#31034;&#20102;NHLs&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;(NNs)&#25152;&#25506;&#32034;&#30340;&#20989;&#25968;&#31354;&#38388;&#30340;&#29305;&#24449;&#21270;&#26159;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#30340;&#37325;&#35201;&#26041;&#38754;&#12290;&#26412;&#25991;&#23558;&#20855;&#26377;&#20219;&#24847;&#23485;&#24230;&#30340;&#22810;&#23618;NN&#35270;&#20026;&#23450;&#20041;&#29305;&#23450;&#23618;&#27425;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#30340;&#31070;&#32463;&#24076;&#23572;&#20271;&#29305;&#38454;&#26799;(NHL)&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23450;&#20041;&#19968;&#20010;&#20989;&#25968;&#31354;&#38388;&#21644;&#19968;&#20010;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#35813;&#24230;&#37327;&#25512;&#24191;&#20102;&#27973;&#23618;NNs&#30340;&#20808;&#21069;&#32467;&#26524;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#22312;&#20960;&#20010;&#26041;&#38754;&#30340;&#29702;&#35770;&#29305;&#24615;&#21644;&#24433;&#21709;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;L&#23618;NNs&#34920;&#31034;&#30340;&#20989;&#25968;&#19982;&#23646;&#20110;L&#23618;NHLs&#30340;&#20989;&#25968;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23398;&#20064;&#20855;&#26377;&#21463;&#25511;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;NHL&#30340;&#27867;&#21270;&#20445;&#35777;&#12290;&#31532;&#19977;&#65292;&#23545;&#24212;&#20110;&#22312;&#26080;&#31351;&#23485;&#22343;&#22330;&#26497;&#38480;&#19979;&#35757;&#32451;&#22810;&#23618;NNs&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;NHL&#30340;&#29305;&#24449;&#21160;&#21147;&#23398;&#65292;&#35813;&#21160;&#21147;&#23398;&#34987;&#25551;&#36848;&#20026;&#22810;&#20010;&#38543;&#26426;&#22330;&#30340;&#28436;&#21270;&#12290;&#31532;&#22235;&#65292;&#22312;ReLU&#21644;&#20108;&#27425;&#28608;&#27963;&#20989;&#25968;&#19979;&#23637;&#31034;&#20102;NHLs&#20013;&#30340;&#28145;&#24230;&#20998;&#31163;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
The characterization of the functions spaces explored by neural networks (NNs) is an important aspect of deep learning theory. In this work, we view a multi-layer NN with arbitrary width as defining a particular hierarchy of reproducing kernel Hilbert spaces (RKHSs), named a Neural Hilbert Ladder (NHL). This allows us to define a function space and a complexity measure that generalize prior results for shallow NNs, and we then examine their theoretical properties and implications in several aspects. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning an NHL with the complexity measure controlled. Third, corresponding to the training of multi-layer NNs in the infinite-width mean-field limit, we derive an evolution of the NHL characterized as the dynamics of multiple random fields. Fourth, we show examples of depth separation in NHLs under ReLU and quadratic activation fun
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26368;&#36895;&#19979;&#38477;&#27861;&#65292;&#25105;&#20204;&#22312;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#20013;&#25506;&#32034;&#24182;&#25913;&#36827;&#20102;&#36138;&#23146;&#30340;&#20108;&#32500;&#22352;&#26631;&#26356;&#26032;&#26041;&#27861;&#65292;&#22312;&#28385;&#36275;&#29305;&#23450;&#26465;&#20214;&#19979;&#21462;&#24471;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#35813;&#26041;&#27861;&#25512;&#24191;&#21040;&#21516;&#26102;&#20855;&#26377;&#27714;&#21644;&#32422;&#26463;&#21644;&#36793;&#30028;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;L1-&#33539;&#25968;&#19979;&#30340;&#26368;&#36895;&#19979;&#38477;&#27861;&#21487;&#20197;&#22312;&#26356;&#30701;&#30340;&#35745;&#31639;&#26102;&#38388;&#20869;&#21462;&#24471;&#26356;&#22810;&#30340;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2307.01169</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#36895;&#19979;&#38477;&#27861;&#20998;&#26512;&#21644;&#25913;&#36827;&#22522;&#20110;&#36138;&#23146;&#30340;&#20108;&#32500;&#22352;&#26631;&#26356;&#26032;&#22312;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Analyzing and Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization via Steepest Descent in the 1-Norm. (arXiv:2307.01169v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01169
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26368;&#36895;&#19979;&#38477;&#27861;&#65292;&#25105;&#20204;&#22312;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#20013;&#25506;&#32034;&#24182;&#25913;&#36827;&#20102;&#36138;&#23146;&#30340;&#20108;&#32500;&#22352;&#26631;&#26356;&#26032;&#26041;&#27861;&#65292;&#22312;&#28385;&#36275;&#29305;&#23450;&#26465;&#20214;&#19979;&#21462;&#24471;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#35813;&#26041;&#27861;&#25512;&#24191;&#21040;&#21516;&#26102;&#20855;&#26377;&#27714;&#21644;&#32422;&#26463;&#21644;&#36793;&#30028;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;L1-&#33539;&#25968;&#19979;&#30340;&#26368;&#36895;&#19979;&#38477;&#27861;&#21487;&#20197;&#22312;&#26356;&#30701;&#30340;&#35745;&#31639;&#26102;&#38388;&#20869;&#21462;&#24471;&#26356;&#22810;&#30340;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#21464;&#37327;&#30340;&#27714;&#21644;&#32422;&#26463;&#19979;&#26368;&#23567;&#21270;&#19968;&#20010;&#24179;&#28369;&#20989;&#25968;&#12290;&#36890;&#36807;&#21033;&#29992;&#36138;&#23146;&#30340;2&#32500;&#22352;&#26631;&#26356;&#26032;&#19982;&#31561;&#24335;&#32422;&#26463;&#30340;&#26368;&#36895;&#19979;&#38477;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#36895;&#24230;&#22312;&#28385;&#36275;&#36817;&#31471;Polyak-Lojasiewicz&#26465;&#20214;&#19979;&#27604;&#38543;&#26426;&#36873;&#25321;&#26356;&#24555;&#65292;&#24182;&#19988;&#19982;&#38382;&#39064;&#32500;&#24230;n&#26080;&#20851;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#21516;&#26102;&#20855;&#26377;&#27714;&#21644;&#32422;&#26463;&#21644;&#36793;&#30028;&#32422;&#26463;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#36825;&#22312;&#25903;&#25345;&#21521;&#37327;&#26426;&#23545;&#20598;&#38382;&#39064;&#20013;&#20986;&#29616;&#12290;&#29616;&#26377;&#30340;&#36138;&#23146;&#35268;&#21017;&#35201;&#20040;&#21482;&#33021;&#20445;&#35777;&#24494;&#23567;&#30340;&#36827;&#23637;&#65292;&#35201;&#20040;&#38656;&#35201;O(n^2)&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36793;&#30028;&#21644;&#27714;&#21644;&#32422;&#26463;&#30340;L1-&#33539;&#25968;&#26368;&#36895;&#19979;&#38477;&#27861;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#21487;&#20197;&#27604;&#20197;&#21069;&#30340;&#35268;&#21017;&#21462;&#24471;&#26356;&#22810;&#30340;&#36827;&#23637;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;O(n log n)&#30340;&#26102;&#38388;&#20869;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider minimizing a smooth function subject to a summation constraint over its variables. By exploiting a connection between the greedy 2-coordinate update for this problem and equality-constrained steepest descent in the 1-norm, we give a convergence rate for greedy selection under a proximal Polyak-Lojasiewicz assumption that is faster than random selection and independent of the problem dimension $n$. We then consider minimizing with both a summation constraint and bound constraints, as arises in the support vector machine dual problem. Existing greedy rules for this setting either guarantee trivial progress only or require $O(n^2)$ time to compute. We show that boundand summation-constrained steepest descent in the L1-norm guarantees more progress per iteration than previous rules and can be computed in only $O(n \log n)$ time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#39318;&#27425;&#23545;&#20998;&#24067;&#36716;&#31227;&#21644;&#38271;&#23614;&#31867;&#21035;&#20998;&#24067;&#19979;&#30340;&#21512;&#35268;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#38271;&#23614;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#22823;&#22823;&#19979;&#38477;&#65292;&#23545;&#20110;&#22312;&#29616;&#23454;&#19990;&#30028;&#21644;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#20855;&#26377;&#37325;&#35201;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01088</link><description>&lt;p&gt;
&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#38271;&#23614;&#25968;&#25454;&#19979;&#65292;&#23545;&#29616;&#20195;&#35270;&#35273;&#26550;&#26500;&#36827;&#34892;&#21512;&#35268;&#39044;&#27979;&#30340;&#32463;&#39564;&#35777;&#23454;
&lt;/p&gt;
&lt;p&gt;
Empirically Validating Conformal Prediction on Modern Vision Architectures Under Distribution Shift and Long-tailed Data. (arXiv:2307.01088v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#39318;&#27425;&#23545;&#20998;&#24067;&#36716;&#31227;&#21644;&#38271;&#23614;&#31867;&#21035;&#20998;&#24067;&#19979;&#30340;&#21512;&#35268;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#38271;&#23614;&#35774;&#32622;&#19979;&#30340;&#24615;&#33021;&#22823;&#22823;&#19979;&#38477;&#65292;&#23545;&#20110;&#22312;&#29616;&#23454;&#19990;&#30028;&#21644;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#20855;&#26377;&#37325;&#35201;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#35268;&#39044;&#27979;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#21487;&#38752;&#22320;&#20026;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#23433;&#20840;&#20445;&#35777;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#24615;&#33021;&#24050;&#30693;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#38271;&#23614;&#31867;&#21035;&#20998;&#24067;&#19979;&#20250;&#19979;&#38477;&#65292;&#32780;&#36825;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#32463;&#24120;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#24773;&#20917;&#19979;&#30340;&#20960;&#31181;&#20107;&#21518;&#21644;&#22522;&#20110;&#35757;&#32451;&#30340;&#21512;&#35268;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#20102;&#24615;&#33021;&#34920;&#24449;&#65292;&#24182;&#39318;&#27425;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#35768;&#22810;&#21512;&#35268;&#26041;&#27861;&#21644;&#31070;&#32463;&#32593;&#32476;&#23478;&#26063;&#20013;&#65292;&#24615;&#33021;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#36829;&#21453;&#23433;&#20840;&#20445;&#35777;&#26102;&#22823;&#22823;&#19979;&#38477;&#12290;&#21516;&#26679;&#65292;&#22312;&#38271;&#23614;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#31867;&#21035;&#30340;&#20445;&#35777;&#32463;&#24120;&#34987;&#36829;&#21453;&#12290;&#20102;&#35299;&#36825;&#20123;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#23545;&#20110;&#22312;&#29616;&#23454;&#19990;&#30028;&#21644;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#37096;&#32626;&#26159;&#24517;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction has emerged as a rigorous means of providing deep learning models with reliable uncertainty estimates and safety guarantees. Yet, its performance is known to degrade under distribution shift and long-tailed class distributions, which are often present in real world applications. Here, we characterize the performance of several post-hoc and training-based conformal prediction methods under these settings, providing the first empirical evaluation on large-scale datasets and models. We show that across numerous conformal methods and neural network families, performance greatly degrades under distribution shifts violating safety guarantees. Similarly, we show that in long-tailed settings the guarantees are frequently violated on many classes. Understanding the limitations of these methods is necessary for deployment in real world and safety-critical applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#26657;&#20934;&#21487;&#24494;&#20998;&#30340;&#22522;&#20110;Agent&#30340;&#27169;&#22411;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.01085</link><description>&lt;p&gt;
&#26657;&#20934;&#21487;&#24494;&#20998;&#30340;&#22522;&#20110;Agent&#30340;&#27169;&#22411;&#30340;&#19968;&#20123;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Some challenges of calibrating differentiable agent-based models. (arXiv:2307.01085v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#26657;&#20934;&#21487;&#24494;&#20998;&#30340;&#22522;&#20110;Agent&#30340;&#27169;&#22411;&#38754;&#20020;&#30340;&#25361;&#25112;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Agent&#30340;&#27169;&#22411;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#27169;&#25311;&#21644;&#25512;&#29702;&#22797;&#26434;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#20294;&#26159;&#23427;&#20204;&#30340;&#24212;&#29992;&#21463;&#21040;&#20102;&#22797;&#26434;&#24615;&#12289;&#31163;&#25955;&#24615;&#21644;&#21442;&#25968;&#25512;&#23548;&#21644;&#20248;&#21270;&#20219;&#21153;&#30340;&#22256;&#38590;&#30340;&#38480;&#21046;&#12290;&#36825;&#24341;&#36215;&#20102;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#22522;&#20110;Agent&#30340;&#27169;&#22411;&#20316;&#20026;&#20811;&#26381;&#36825;&#20123;&#22256;&#38590;&#30340;&#31574;&#30053;&#30340;&#20852;&#36259;&#65292;&#28982;&#32780;&#36824;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#24182;&#23637;&#31034;&#20102;&#19968;&#20123;&#23454;&#39564;&#65292;&#31361;&#20986;&#20102;&#36825;&#20123;&#25361;&#25112;&#20197;&#21450;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Agent-based models (ABMs) are a promising approach to modelling and reasoning about complex systems, yet their application in practice is impeded by their complexity, discrete nature, and the difficulty of performing parameter inference and optimisation tasks. This in turn has sparked interest in the construction of differentiable ABMs as a strategy for combatting these difficulties, yet a number of challenges remain. In this paper, we discuss and present experiments that highlight some of these challenges, along with potential solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#36817;&#20284;&#30340;&#20960;&#20309;&#20445;&#25345;&#29305;&#24615;&#20316;&#20026;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#23637;&#31034;&#20102;&#31867;&#26465;&#20214;&#27969;&#24418;&#23398;&#20064;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#36873;&#25321;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#22312;&#20960;&#20046;&#25152;&#26377;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#20013;&#20445;&#25345;&#23616;&#37096;&#32467;&#26500;&#65292;&#24182;&#27491;&#30830;&#22320;&#32500;&#25252;&#20840;&#23616;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2307.01077</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#26862;&#26519;&#20445;&#25345;&#20960;&#20309;&#29305;&#24615;&#30340;&#36817;&#20284;&#26469;&#36827;&#34892;&#30417;&#30563;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Supervised Manifold Learning via Random Forest Geometry-Preserving Proximities. (arXiv:2307.01077v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#36817;&#20284;&#30340;&#20960;&#20309;&#20445;&#25345;&#29305;&#24615;&#20316;&#20026;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#23637;&#31034;&#20102;&#31867;&#26465;&#20214;&#27969;&#24418;&#23398;&#20064;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#36873;&#25321;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#22312;&#20960;&#20046;&#25152;&#26377;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#20013;&#20445;&#25345;&#23616;&#37096;&#32467;&#26500;&#65292;&#24182;&#27491;&#30830;&#22320;&#32500;&#25252;&#20840;&#23616;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#26088;&#22312;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#23547;&#25214;&#20869;&#22312;&#30340;&#20302;&#32500;&#25968;&#25454;&#32467;&#26500;&#12290;&#20027;&#27969;&#30340;&#27969;&#24418;&#23398;&#20064;&#31639;&#27861;&#65292;&#20363;&#22914;Isomap&#65292;UMAP&#65292;t-SNE&#65292;Diffusion Map&#21644;Laplacian Eigenmaps&#65292;&#19981;&#20351;&#29992;&#25968;&#25454;&#26631;&#31614;&#65292;&#22240;&#27492;&#34987;&#35748;&#20026;&#26159;&#26080;&#30417;&#30563;&#30340;&#12290;&#29616;&#26377;&#30340;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#30417;&#30563;&#25193;&#23637;&#20165;&#36866;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#19988;&#30001;&#20110;&#20351;&#29992;&#20102;&#19981;&#20445;&#25345;&#39034;&#24207;&#30340;&#31867;&#26465;&#20214;&#36317;&#31163;&#32780;&#26410;&#33021;&#25581;&#31034;&#26377;&#24847;&#20041;&#30340;&#23884;&#20837;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23450;&#37327;&#21644;&#21487;&#35270;&#21270;&#22320;&#23637;&#31034;&#20102;&#31867;&#26465;&#20214;&#27969;&#24418;&#23398;&#20064;&#30340;&#24369;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#36873;&#25321;&#65292;&#22312;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#20013;&#20351;&#29992;&#25968;&#25454;&#20960;&#20309;&#20445;&#25345;&#30340;&#38543;&#26426;&#26862;&#26519;&#36817;&#20284;&#20316;&#20026;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#36825;&#20123;&#36817;&#20284;&#26041;&#27861;&#36827;&#34892;&#23616;&#37096;&#32467;&#26500;&#20445;&#25345;&#22312;&#20960;&#20046;&#25152;&#26377;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#20013;&#37117;&#26159;&#26222;&#36941;&#30340;&#65292;&#24182;&#19988;&#20351;&#29992;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#33021;&#22815;&#27491;&#30830;&#22320;&#32500;&#25252;&#20840;&#23616;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifold learning approaches seek the intrinsic, low-dimensional data structure within a high-dimensional space. Mainstream manifold learning algorithms, such as Isomap, UMAP, $t$-SNE, Diffusion Map, and Laplacian Eigenmaps do not use data labels and are thus considered unsupervised. Existing supervised extensions of these methods are limited to classification problems and fall short of uncovering meaningful embeddings due to their construction using order non-preserving, class-conditional distances. In this paper, we show the weaknesses of class-conditional manifold learning quantitatively and visually and propose an alternate choice of kernel for supervised dimensionality reduction using a data-geometry-preserving variant of random forest proximities as an initialization for manifold learning methods. We show that local structure preservation using these proximities is near universal across manifold learning approaches and global structure is properly maintained using diffusion-based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.01050</link><description>&lt;p&gt;
&#36816;&#36755;&#12289;&#21464;&#20998;&#25512;&#26029;&#21644;&#25193;&#25955;&#65306;&#24212;&#29992;&#20110;&#22238;&#28779;&#27969;&#21644;&#34203;&#23450;&#35860;&#26725;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges. (arXiv:2307.01050v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26368;&#20248;&#36816;&#36755;&#19982;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#37325;&#28857;&#30740;&#31350;&#20102;&#27491;&#21521;&#21644;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#21450;Girsanov&#21464;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#30340;&#21407;&#21017;&#24615;&#21644;&#31995;&#32479;&#24615;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26368;&#32456;&#21457;&#23637;&#20986;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#65288;&#19982;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;Jarzynski&#21644;Crooks&#24658;&#31561;&#24335;&#26377;&#20851;&#65289;&#21644;&#19968;&#20010;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#65288;IPF&#65289;&#22411;&#30446;&#26631;&#65292;&#19981;&#21516;&#20110;&#26631;&#20934;IPF&#30340;&#39034;&#24207;&#24615;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#29983;&#25104;&#24314;&#27169;&#31034;&#20363;&#21644;&#22522;&#20110;&#21452;&#20117;&#30340;&#31232;&#26377;&#20107;&#20214;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between optimal transport and variational inference, with a focus on forward and reverse time stochastic differential equations and Girsanov transformations.We present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of a novel score-based annealed flow technique (with connections to Jarzynski and Crooks identities from statistical physics) and a regularised iterative proportional fitting (IPF)-type objective, departing from the sequential nature of standard IPF. Through a series of generative modelling examples and a double-well-based rare event task, we showcase the potential of the proposed methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#26426;&#22120;&#23398;&#20064;&#19979;&#30340;&#30452;&#25509;&#21644;&#38388;&#25509;&#20998;&#20301;&#27835;&#30103;&#25928;&#24212;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#21644;&#20132;&#21449;&#25311;&#21512;&#26469;&#22788;&#29702;&#21487;&#35266;&#27979;&#36873;&#25321;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20056;&#27861;&#33258;&#21161;&#27861;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2307.01049</link><description>&lt;p&gt;
&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#26426;&#22120;&#23398;&#20064;&#19979;&#30340;&#30452;&#25509;&#21644;&#38388;&#25509;&#20998;&#20301;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Estimation of Direct and Indirect Quantile Treatment Effects with Machine Learning. (arXiv:2307.01049v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01049
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#26426;&#22120;&#23398;&#20064;&#19979;&#30340;&#30452;&#25509;&#21644;&#38388;&#25509;&#20998;&#20301;&#27835;&#30103;&#25928;&#24212;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#21644;&#20132;&#21449;&#25311;&#21512;&#26469;&#22788;&#29702;&#21487;&#35266;&#27979;&#36873;&#25321;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20056;&#27861;&#33258;&#21161;&#27861;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;/&#26080;&#20559;&#30340;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#21487;&#35266;&#27979;&#36873;&#25321;&#20559;&#24046;&#30340;&#24773;&#20917;&#19979;&#30340;&#30452;&#25509;&#21644;&#38388;&#25509;&#20998;&#20301;&#27835;&#30103;&#25928;&#24212;&#12290;&#36825;&#20351;&#24471;&#33021;&#22815;&#23558;&#20108;&#36827;&#21046;&#27835;&#30103;&#30340;&#22240;&#26524;&#25928;&#24212;&#22312;&#29305;&#23450;&#32467;&#26524;&#25490;&#21517;&#19978;&#20998;&#35299;&#20026;&#36890;&#36807;&#20013;&#20171;&#21464;&#37327;&#65288;&#31216;&#20026;&#20013;&#20171;&#22240;&#23376;&#65289;&#38388;&#25509;&#24433;&#21709;&#21644;&#65288;&#26410;&#32463;&#20013;&#20171;&#30340;&#65289;&#30452;&#25509;&#24433;&#21709;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#25152;&#25552;&#26041;&#27861;&#22522;&#20110;&#28508;&#22312;&#32467;&#26524;&#30340;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#30340;&#26377;&#25928;&#24471;&#20998;&#20989;&#25968;&#65292;&#23545;&#20110;&#26576;&#20123;&#22266;&#23450;&#21442;&#25968;&#30340;&#20559;&#24046;&#65292;&#22914;&#32467;&#26524;&#12289;&#22788;&#29702;&#21644;&#20013;&#20171;&#27169;&#22411;&#65292;&#26159;&#31283;&#20581;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#26469;&#20272;&#35745;&#36825;&#20123;&#22266;&#23450;&#21442;&#25968;&#65292;&#24182;&#20351;&#29992;&#20132;&#21449;&#25311;&#21512;&#26469;&#20943;&#23567;&#23545;&#30452;&#25509;&#21644;&#38388;&#25509;&#20998;&#20301;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#30340;&#36807;&#25311;&#21512;&#20559;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25928;&#26524;&#20272;&#35745;&#37327;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#20056;&#27861;&#33258;&#21161;&#27861;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#65292;&#24182;&#23637;&#31034;&#20102;&#20056;&#27861;&#33258;&#21161;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We suggest double/debiased machine learning estimators of direct and indirect quantile treatment effects under a selection-on-observables assumption. This permits disentangling the causal effect of a binary treatment at a specific outcome rank into an indirect component that operates through an intermediate variable called mediator and an (unmediated) direct impact. The proposed method is based on the efficient score functions of the cumulative distribution functions of potential outcomes, which are robust to certain misspecifications of the nuisance parameters, i.e., the outcome, treatment, and mediator models. We estimate these nuisance parameters by machine learning and use cross-fitting to reduce overfitting bias in the estimation of direct and indirect quantile treatment effects. We establish uniform consistency and asymptotic normality of our effect estimators. We also propose a multiplier bootstrap for statistical inference and show the validity of the multiplier bootstrap. Fina
&lt;/p&gt;</description></item><item><title>&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25506;&#31350;&#20102;&#24403;&#21069;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;QML&#23454;&#29616;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#12290;&#19982;&#32463;&#20856;&#23545;&#24212;&#29289;&#30456;&#27604;&#36739;&#65292;&#36825;&#20123;QML&#23454;&#29616;&#30340;&#24615;&#33021;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2307.00908</link><description>&lt;p&gt;
&#36817;&#26399;&#37327;&#23376;&#35013;&#32622;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;: &#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#25216;&#26415;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#30340;&#29616;&#29366;
&lt;/p&gt;
&lt;p&gt;
Quantum Machine Learning on Near-Term Quantum Devices: Current State of Supervised and Unsupervised Techniques for Real-World Applications. (arXiv:2307.00908v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00908
&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25506;&#31350;&#20102;&#24403;&#21069;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;QML&#23454;&#29616;&#30340;&#38480;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#12290;&#19982;&#32463;&#20856;&#23545;&#24212;&#29289;&#30456;&#27604;&#36739;&#65292;&#36825;&#20123;QML&#23454;&#29616;&#30340;&#24615;&#33021;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#37327;&#23376;&#30828;&#20214;&#22312;&#36895;&#24230;&#12289;&#37327;&#23376;&#27604;&#29305;&#25968;&#37327;&#21644;&#37327;&#23376;&#20307;&#31215;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#36827;&#23637;&#65292;&#37327;&#23376;&#20307;&#31215;&#34987;&#23450;&#20041;&#20026;&#22312;&#36817;&#26399;&#37327;&#23376;&#35774;&#22791;&#19978;&#21487;&#20197;&#26377;&#25928;&#23454;&#29616;&#30340;&#37327;&#23376;&#30005;&#36335;&#30340;&#26368;&#22823;&#35268;&#27169;&#12290;&#22240;&#27492;&#65292;&#22312;&#23454;&#38469;&#30828;&#20214;&#19978;&#24212;&#29992;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;(QML)&#20197;&#23454;&#29616;&#37327;&#23376;&#20248;&#21183;&#24050;&#32463;&#26377;&#20102;&#24456;&#22823;&#30340;&#22686;&#38271;&#12290;&#22312;&#36825;&#31687;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#23454;&#29616;&#30340;&#36873;&#23450;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#24212;&#29992;&#65292;&#29305;&#21035;&#38024;&#23545;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#12290;&#25105;&#20204;&#25506;&#35752;&#24182;&#24378;&#35843;&#20102;QML&#22312;&#37327;&#23376;&#30828;&#20214;&#19978;&#30340;&#24403;&#21069;&#38480;&#21046;&#12290;&#25105;&#20204;&#28145;&#20837;&#35752;&#35770;&#20102;&#21508;&#31181;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#30340;&#25216;&#26415;&#65292;&#22914;&#32534;&#30721;&#25216;&#26415;&#12289;&#22522;&#24577;&#32467;&#26500;&#12289;&#35823;&#24046;&#34917;&#20607;&#21644;&#26799;&#24230;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#36825;&#20123;QML&#23454;&#29616;&#19982;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#20043;&#38388;&#30340;&#24615;&#33021;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The past decade has seen considerable progress in quantum hardware in terms of the speed, number of qubits and quantum volume which is defined as the maximum size of a quantum circuit that can be effectively implemented on a near-term quantum device. Consequently, there has also been a rise in the number of works based on the applications of Quantum Machine Learning (QML) on real hardware to attain quantum advantage over their classical counterparts. In this survey, our primary focus is on selected supervised and unsupervised learning applications implemented on quantum hardware, specifically targeting real-world scenarios. Our survey explores and highlights the current limitations of QML implementations on quantum hardware. We delve into various techniques to overcome these limitations, such as encoding techniques, ansatz structure, error mitigation, and gradient methods. Additionally, we assess the performance of these QML implementations in comparison to their classical counterparts
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#35299;&#30721;&#26694;&#26550;MADS&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#65292;&#21033;&#29992;SIREN&#30340;&#33021;&#21147;&#36827;&#34892;&#39640;&#20445;&#30495;&#37325;&#24314;&#65292;&#24182;&#37319;&#29992;&#36229;&#32593;&#32476;&#26550;&#26500;&#36827;&#34892;&#27867;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#27169;&#22411;&#22312;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.00868</link><description>&lt;p&gt;
MADS&#65306;&#35843;&#25511;&#24335;&#33258;&#35299;&#30721;SIREN&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;
&lt;/p&gt;
&lt;p&gt;
MADS: Modulated Auto-Decoding SIREN for time series imputation. (arXiv:2307.00868v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#35299;&#30721;&#26694;&#26550;MADS&#65292;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#65292;&#21033;&#29992;SIREN&#30340;&#33021;&#21147;&#36827;&#34892;&#39640;&#20445;&#30495;&#37325;&#24314;&#65292;&#24182;&#37319;&#29992;&#36229;&#32593;&#32476;&#26550;&#26500;&#36827;&#34892;&#27867;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#27169;&#22411;&#22312;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#25152;&#24314;&#27169;&#25968;&#25454;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#26174;&#33879;&#21464;&#24322;&#24615;&#65292;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#22312;&#35768;&#22810;&#39046;&#22495;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#20256;&#32479;&#30340;&#25554;&#34917;&#26041;&#27861;&#36890;&#24120;&#23545;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#26045;&#21152;&#24378;&#20551;&#35774;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#65292;&#32780;&#30740;&#31350;&#20154;&#21592;&#26368;&#36817;&#24320;&#22987;&#25506;&#32034;&#28145;&#24230;&#23398;&#20064;&#22312;&#27492;&#20219;&#21153;&#20013;&#30340;&#28508;&#21147;&#65292;&#21463;&#21040;&#36825;&#20123;&#27169;&#22411;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#24378;&#22823;&#24615;&#33021;&#30340;&#21551;&#21457;&#65292;&#24212;&#29992;&#33539;&#22260;&#24191;&#27867;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;&#33258;&#35299;&#30721;&#26694;&#26550;MADS&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;SIREN&#23545;&#20449;&#21495;&#21644;&#19981;&#35268;&#21017;&#25968;&#25454;&#36827;&#34892;&#39640;&#20445;&#30495;&#37325;&#24314;&#30340;&#33021;&#21147;&#65292;&#24182;&#23558;&#20854;&#19982;&#36229;&#32593;&#32476;&#26550;&#26500;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#31354;&#38388;&#30340;&#20808;&#39564;&#30693;&#35782;&#26469;&#23454;&#29616;&#27867;&#21270;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#23427;&#36229;&#36234;&#20102;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series imputation remains a significant challenge across many fields due to the potentially significant variability in the type of data being modelled. Whilst traditional imputation methods often impose strong assumptions on the underlying data generation process, limiting their applicability, researchers have recently begun to investigate the potential of deep learning for this task, inspired by the strong performance shown by these models in both classification and regression problems across a range of applications. In this work we propose MADS, a novel auto-decoding framework for time series imputation, built upon implicit neural representations. Our method leverages the capabilities of SIRENs for high fidelity reconstruction of signals and irregular data, and combines it with a hypernetwork architecture which allows us to generalise by learning a prior over the space of time series. We evaluate our model on two real-world datasets, and show that it outperforms state-of-the-art
&lt;/p&gt;</description></item><item><title>CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2307.00859</link><description>&lt;p&gt;
CardiGraphormer: &#25581;&#31034;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery. (arXiv:2307.00859v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00859
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#38420;&#30340;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#20013;&#65292;&#24050;&#30693;&#33647;&#29289;&#32422;&#26377;15,000&#31181;&#65292;&#20294;&#21482;&#26377;&#22823;&#32422;4,200&#31181;&#24471;&#21040;&#20102;&#25209;&#20934;&#65292;&#21270;&#23398;&#31354;&#38388;&#30340;&#32452;&#21512;&#24615;&#36136;&#25552;&#20379;&#20102;&#19968;&#39033;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#20154;&#24037;&#26234;&#33021;&#25104;&#20026;&#20102;&#26377;&#21147;&#30340;&#20249;&#20276;&#65292;&#20256;&#32479;&#30340;&#20154;&#24037;&#26234;&#33021;&#26694;&#26550;&#20173;&#38754;&#20020;&#37325;&#22823;&#38556;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CardiGraphormer&#65292;&#36825;&#26159;&#19968;&#31181;&#21010;&#26102;&#20195;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#20174;&#32780;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#12290;CardiGraphormer&#26159;Graphormer&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#30340;&#26032;&#39062;&#32452;&#21512;&#65292;&#21033;&#29992;SSL&#23398;&#20064;&#26377;&#25928;&#30340;&#20998;&#23376;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;GNN&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#12290;&#23427;&#22312;&#22788;&#29702;&#20998;&#23376;&#32467;&#26500;&#31561;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#33021;&#25191;&#34892;&#19982;&#33410;&#28857;&#12289;&#33410;&#28857;&#23545;&#12289;&#23376;&#22270;&#25110;&#25972;&#20010;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential a
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#32447;&#20998;&#31867;&#20013;&#20351;&#29992;&#20184;&#36153;&#38543;&#26426;&#19987;&#23478;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#34913;&#25903;&#20184;&#37329;&#39069;&#21644;&#20934;&#30830;&#24615;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#24635;&#25104;&#26412;&#19981;&#36229;&#36807;&#39044;&#20808;&#30693;&#36947;&#25152;&#26377;&#19987;&#23478;&#29983;&#20135;&#21147;&#30340;&#39044;&#27979;&#31639;&#27861;&#25104;&#26412;&#30340;&#20989;&#25968;&#65292;&#36890;&#36807;&#32467;&#21512;Lipschitz Bandits&#21644;&#22522;&#20110;&#26367;&#20195;&#25439;&#22833;&#30340;&#22312;&#32447;&#20998;&#31867;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2307.00836</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#20998;&#31867;&#20013;&#26435;&#34913;&#25903;&#20184;&#21644;&#20934;&#30830;&#24615;&#65306;&#22522;&#20110;&#20184;&#36153;&#38543;&#26426;&#19987;&#23478;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Trading-Off Payments and Accuracy in Online Classification with Paid Stochastic Experts. (arXiv:2307.00836v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00836
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#32034;&#20102;&#22312;&#32447;&#20998;&#31867;&#20013;&#20351;&#29992;&#20184;&#36153;&#38543;&#26426;&#19987;&#23478;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26435;&#34913;&#25903;&#20184;&#37329;&#39069;&#21644;&#20934;&#30830;&#24615;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#24635;&#25104;&#26412;&#19981;&#36229;&#36807;&#39044;&#20808;&#30693;&#36947;&#25152;&#26377;&#19987;&#23478;&#29983;&#20135;&#21147;&#30340;&#39044;&#27979;&#31639;&#27861;&#25104;&#26412;&#30340;&#20989;&#25968;&#65292;&#36890;&#36807;&#32467;&#21512;Lipschitz Bandits&#21644;&#22522;&#20110;&#26367;&#20195;&#25439;&#22833;&#30340;&#22312;&#32447;&#20998;&#31867;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#20998;&#31867;&#20013;&#30340;&#20184;&#36153;&#38543;&#26426;&#19987;&#23478;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#19987;&#23478;&#22312;&#36827;&#34892;&#39044;&#27979;&#20043;&#21069;&#24517;&#39035;&#20184;&#36153;&#12290;&#25105;&#20204;&#25903;&#20184;&#32473;&#27599;&#20010;&#19987;&#23478;&#30340;&#37329;&#39069;&#36890;&#36807;&#26576;&#20010;&#26410;&#30693;&#30340;Lipschitz&#8220;&#29983;&#20135;&#21147;&#8221;&#20989;&#25968;&#30452;&#25509;&#24433;&#21709;&#20182;&#20204;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#23398;&#20064;&#32773;&#24517;&#39035;&#20915;&#23450;&#20026;&#27599;&#20010;&#19987;&#23478;&#25903;&#20184;&#22810;&#23569;&#37329;&#39069;&#65292;&#28982;&#21518;&#36827;&#34892;&#39044;&#27979;&#12290;&#20182;&#20204;&#25152;&#25215;&#25285;&#30340;&#25104;&#26412;&#26159;&#39044;&#27979;&#35823;&#24046;&#21644;&#25152;&#26377;&#19987;&#23478;&#30340;&#39044;&#20184;&#27454;&#30340;&#21152;&#26435;&#24635;&#21644;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#22312;T&#36718;&#21518;&#30340;&#24635;&#25104;&#26412;&#26368;&#22810;&#36229;&#36807;&#20107;&#20808;&#30693;&#36947;&#25152;&#26377;&#19987;&#23478;&#29983;&#20135;&#21147;&#30340;&#39044;&#27979;&#31639;&#27861;&#30340;&#25104;&#26412;$\mathcal{O}(K^2(\log T)\sqrt{T})$&#65292;&#20854;&#20013;K&#26159;&#19987;&#23478;&#30340;&#25968;&#37327;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#32467;&#21512;&#20102;Lipschitz Bandits&#21644;&#22522;&#20110;&#26367;&#20195;&#25439;&#22833;&#30340;&#22312;&#32447;&#20998;&#31867;&#12290;&#36825;&#20123;&#24037;&#20855;&#20351;&#25105;&#20204;&#33021;&#22815;&#25913;&#36827;&#26631;&#20934;Lipschitz Bandit&#35774;&#32622;&#20013;&#30340;$T^{2/3}$&#38454;&#27573;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#36824;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#31639;&#27861;&#30340;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate online classification with paid stochastic experts. Here, before making their prediction, each expert must be paid. The amount that we pay each expert directly influences the accuracy of their prediction through some unknown Lipschitz "productivity" function. In each round, the learner must decide how much to pay each expert and then make a prediction. They incur a cost equal to a weighted sum of the prediction error and upfront payments for all experts. We introduce an online learning algorithm whose total cost after $T$ rounds exceeds that of a predictor which knows the productivity of all experts in advance by at most $\mathcal{O}(K^2(\log T)\sqrt{T})$ where $K$ is the number of experts. In order to achieve this result, we combine Lipschitz bandits and online classification with surrogate losses. These tools allow us to improve upon the bound of order $T^{2/3}$ one would obtain in the standard Lipschitz bandit setting. Our algorithm is empirically evaluated on synthet
&lt;/p&gt;</description></item><item><title>Engression&#26159;&#19968;&#31181;&#38750;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20998;&#24067;&#22238;&#24402;&#25216;&#26415;&#21644;&#39044;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65292;&#22312;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#36793;&#30028;&#22806;&#20063;&#33021;&#21487;&#38752;&#22320;&#36827;&#34892;&#22806;&#25512;&#12290;</title><link>http://arxiv.org/abs/2307.00835</link><description>&lt;p&gt;
Engression: &#38750;&#32447;&#24615;&#22238;&#24402;&#30340;&#22806;&#25512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Engression: Extrapolation for Nonlinear Regression?. (arXiv:2307.00835v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00835
&lt;/p&gt;
&lt;p&gt;
Engression&#26159;&#19968;&#31181;&#38750;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20998;&#24067;&#22238;&#24402;&#25216;&#26415;&#21644;&#39044;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65292;&#22312;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#36793;&#30028;&#22806;&#20063;&#33021;&#21487;&#38752;&#22320;&#36827;&#34892;&#22806;&#25512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22806;&#25512;&#23545;&#20110;&#35768;&#22810;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#24120;&#24120;&#20250;&#36935;&#21040;&#36229;&#20986;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#30340;&#27979;&#35797;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#27169;&#22411;&#26469;&#35828;&#65292;&#22806;&#25512;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#20256;&#32479;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#36890;&#24120;&#36935;&#21040;&#22256;&#38590;&#65306;&#26641;&#38598;&#25104;&#27169;&#22411;&#22312;&#25903;&#25345;&#33539;&#22260;&#22806;&#25552;&#20379;&#36830;&#32493;&#30340;&#39044;&#27979;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24448;&#24448;&#21464;&#24471;&#19981;&#21487;&#25511;&#12290;&#36825;&#39033;&#24037;&#20316;&#26088;&#22312;&#25552;&#20379;&#19968;&#31181;&#38750;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#20854;&#21487;&#38752;&#24615;&#22312;&#35757;&#32451;&#26679;&#26412;&#33539;&#22260;&#36793;&#30028;&#19981;&#20250;&#31435;&#21363;&#23849;&#28291;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#19968;&#31181;&#21517;&#20026;&#8220;engression&#8221;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#26159;&#19968;&#31181;&#39044;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#20998;&#24067;&#22238;&#24402;&#25216;&#26415;&#65292;&#20854;&#20013;&#22122;&#22768;&#28155;&#21152;&#21040;&#21327;&#21464;&#37327;&#19978;&#24182;&#24212;&#29992;&#38750;&#32447;&#24615;&#36716;&#25442;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#36890;&#24120;&#36866;&#29992;&#20110;&#35768;&#22810;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#23637;&#31034;engression&#21487;&#20197;&#22312;&#19968;&#20123;&#20551;&#35774;&#19979;&#25104;&#21151;&#36827;&#34892;&#22806;&#25512;&#65292;&#20363;&#22914;&#20005;&#26684;&#38480;&#21046;&#22122;&#22768;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extrapolation is crucial in many statistical and machine learning applications, as it is common to encounter test data outside the training support. However, extrapolation is a considerable challenge for nonlinear models. Conventional models typically struggle in this regard: while tree ensembles provide a constant prediction beyond the support, neural network predictions tend to become uncontrollable. This work aims at providing a nonlinear regression methodology whose reliability does not break down immediately at the boundary of the training support. Our primary contribution is a new method called `engression' which, at its core, is a distributional regression technique for pre-additive noise models, where the noise is added to the covariates before applying a nonlinear transformation. Our experimental results indicate that this model is typically suitable for many real data sets. We show that engression can successfully perform extrapolation under some assumptions such as a strictl
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;-&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#36890;&#36807;&#23450;&#37327;&#23454;&#39564;&#35780;&#20272;&#20102;&#25968;&#25454;&#37327;&#21644;&#20272;&#35745;&#33539;&#22260;&#23545;&#30693;&#35782;&#30340;&#20215;&#20540;&#30340;&#24433;&#21709;&#65292;&#38416;&#26126;&#20102;&#25968;&#25454;&#21644;&#30693;&#35782;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#19981;&#21516;&#32593;&#32476;&#26550;&#26500;&#65292;&#25552;&#20379;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#20808;&#21069;&#30693;&#35782;&#20316;&#29992;&#30340;&#20840;&#38754;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.00712</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30693;&#35782;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
Worth of knowledge in deep learning. (arXiv:2307.00712v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00712
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;-&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#36890;&#36807;&#23450;&#37327;&#23454;&#39564;&#35780;&#20272;&#20102;&#25968;&#25454;&#37327;&#21644;&#20272;&#35745;&#33539;&#22260;&#23545;&#30693;&#35782;&#30340;&#20215;&#20540;&#30340;&#24433;&#21709;&#65292;&#38416;&#26126;&#20102;&#25968;&#25454;&#21644;&#30693;&#35782;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#24182;&#21487;&#24212;&#29992;&#20110;&#19981;&#21516;&#32593;&#32476;&#26550;&#26500;&#65292;&#25552;&#20379;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#20808;&#21069;&#30693;&#35782;&#20316;&#29992;&#30340;&#20840;&#38754;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#26159;&#20154;&#31867;&#29992;&#26469;&#27934;&#23519;&#19990;&#30028;&#30340;&#32047;&#31215;&#29702;&#35299;&#21644;&#32463;&#39564;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#20808;&#21069;&#30340;&#30693;&#35782;&#23545;&#20110;&#24357;&#34917;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#30340;&#32570;&#28857;&#38750;&#24120;&#37325;&#35201;&#65292;&#20363;&#22914;&#25968;&#25454;&#20381;&#36182;&#24615;&#12289;&#27867;&#21270;&#33021;&#21147;&#21644;&#36981;&#23432;&#32422;&#26463;&#12290;&#20026;&#20102;&#33021;&#22815;&#26377;&#25928;&#35780;&#20272;&#30693;&#35782;&#30340;&#20215;&#20540;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21463;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#21551;&#21457;&#30340;&#26694;&#26550;&#12290;&#36890;&#36807;&#23450;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25968;&#25454;&#37327;&#21644;&#20272;&#35745;&#33539;&#22260;&#23545;&#30693;&#35782;&#30340;&#20215;&#20540;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#38416;&#26126;&#20102;&#25968;&#25454;&#21644;&#30693;&#35782;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#65292;&#21253;&#25324;&#20381;&#36182;&#12289;&#21327;&#21516;&#21644;&#26367;&#20195;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#21487;&#20197;&#24212;&#29992;&#20110;&#21508;&#31181;&#24120;&#35265;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#25552;&#20379;&#23545;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#20808;&#21069;&#30693;&#35782;&#20316;&#29992;&#30340;&#20840;&#38754;&#29702;&#35299;&#12290;&#23427;&#36824;&#21487;&#20197;&#29992;&#20110;&#25913;&#36827;&#30693;&#24773;&#26426;&#22120;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#20197;&#21450;&#21306;&#20998;&#19981;&#36866;&#24403;&#30340;&#20808;&#21069;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge constitutes the accumulated understanding and experience that humans use to gain insight into the world. In deep learning, prior knowledge is essential for mitigating shortcomings of data-driven models, such as data dependence, generalization ability, and compliance with constraints. To enable efficient evaluation of the worth of knowledge, we present a framework inspired by interpretable machine learning. Through quantitative experiments, we assess the influence of data volume and estimation range on the worth of knowledge. Our findings elucidate the complex relationship between data and knowledge, including dependence, synergistic, and substitution effects. Our model-agnostic framework can be applied to a variety of common network architectures, providing a comprehensive understanding of the role of prior knowledge in deep learning models. It can also be used to improve the performance of informed machine learning, as well as distinguish improper prior knowledge.
&lt;/p&gt;</description></item><item><title>Morse&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#25311;&#21512;KL&#25955;&#24230;&#25439;&#22833;&#65292;&#21487;&#20197;&#24471;&#21040;&#29983;&#25104;&#23494;&#24230;&#12289;OOD&#26816;&#27979;&#22120;&#12289;&#26657;&#20934;&#28201;&#24230;&#12289;&#29983;&#25104;&#37319;&#26679;&#22120;&#21644;&#36317;&#31163;&#24863;&#30693;&#20998;&#31867;&#22120;&#12290;&#23427;&#32479;&#19968;&#20102;&#22810;&#31181;&#25216;&#26415;&#24212;&#29992;&#65292;&#22914;OOD&#26816;&#27979;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#36830;&#32493;&#23398;&#20064;&#31561;&#12290;</title><link>http://arxiv.org/abs/2307.00667</link><description>&lt;p&gt;
Morse&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Morse Neural Networks for Uncertainty Quantification. (arXiv:2307.00667v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00667
&lt;/p&gt;
&lt;p&gt;
Morse&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#25311;&#21512;KL&#25955;&#24230;&#25439;&#22833;&#65292;&#21487;&#20197;&#24471;&#21040;&#29983;&#25104;&#23494;&#24230;&#12289;OOD&#26816;&#27979;&#22120;&#12289;&#26657;&#20934;&#28201;&#24230;&#12289;&#29983;&#25104;&#37319;&#26679;&#22120;&#21644;&#36317;&#31163;&#24863;&#30693;&#20998;&#31867;&#22120;&#12290;&#23427;&#32479;&#19968;&#20102;&#22810;&#31181;&#25216;&#26415;&#24212;&#29992;&#65292;&#22914;OOD&#26816;&#27979;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#36830;&#32493;&#23398;&#20064;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65306;Morse&#31070;&#32463;&#32593;&#32476;&#65292;&#23427;&#23558;&#38750;&#26631;&#20934;&#21270;&#30340;&#39640;&#26031;&#23494;&#24230;&#25512;&#24191;&#20026;&#20855;&#26377;&#39640;&#32500;&#23376;&#27969;&#24418;&#30340;&#27169;&#24335;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#31163;&#25955;&#28857;&#12290;&#36890;&#36807;KL&#25955;&#24230;&#25439;&#22833;&#25311;&#21512;Morse&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#24471;&#21040;1&#65289;&#65288;&#38750;&#26631;&#20934;&#21270;&#30340;&#65289;&#29983;&#25104;&#23494;&#24230;&#65292;2&#65289;&#19968;&#31181;OOD&#26816;&#27979;&#22120;&#65292;3&#65289;&#19968;&#31181;&#26657;&#20934;&#28201;&#24230;&#65292;4&#65289;&#19968;&#31181;&#29983;&#25104;&#37319;&#26679;&#22120;&#65292;&#20197;&#21450;&#22312;&#26377;&#30417;&#30563;&#24773;&#20917;&#19979;5&#65289;&#19968;&#31181;&#36317;&#31163;&#24863;&#30693;&#20998;&#31867;&#22120;&#12290;Morse&#32593;&#32476;&#21487;&#20197;&#22312;&#39044;&#35757;&#32451;&#32593;&#32476;&#20043;&#19978;&#20351;&#29992;&#65292;&#20197;&#23454;&#29616;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#36317;&#31163;&#24863;&#30693;&#26657;&#20934;&#12290;&#30001;&#20110;&#20854;&#22810;&#21151;&#33021;&#24615;&#65292;Morse&#31070;&#32463;&#32593;&#32476;&#32479;&#19968;&#20102;&#35768;&#22810;&#25216;&#26415;&#65306;&#20363;&#22914;&#65292;&#65288;Mac&#234;do&#31561;&#65292;2021&#24180;&#65289;&#30340;&#29109;&#20540;&#26816;&#27979;&#22120;&#22312;OOD&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#65288;Ruff&#31561;&#65292;2018&#24180;&#65289;&#30340;&#21333;&#31867;&#28145;&#24230;&#25903;&#25345;&#21521;&#37327;&#25551;&#36848;&#26041;&#27861;&#22312;&#24322;&#24120;&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#25110;&#32773;&#65288;Sun&#31561;&#65292;2021&#24180;&#65289;&#30340;&#23545;&#27604;&#21333;&#31867;&#20998;&#31867;&#22120;&#22312;&#36830;&#32493;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new deep generative model useful for uncertainty quantification: the Morse neural network, which generalizes the unnormalized Gaussian densities to have modes of high-dimensional submanifolds instead of just discrete points. Fitting the Morse neural network via a KL-divergence loss yields 1) a (unnormalized) generative density, 2) an OOD detector, 3) a calibration temperature, 4) a generative sampler, along with in the supervised case 5) a distance aware-classifier. The Morse network can be used on top of a pre-trained network to bring distance-aware calibration w.r.t the training data. Because of its versatility, the Morse neural networks unifies many techniques: e.g., the Entropic Out-of-Distribution Detector of (Mac\^edo et al., 2021) in OOD detection, the one class Deep Support Vector Description method of (Ruff et al., 2018) in anomaly detection, or the Contrastive One Class classifier in continuous learning (Sun et al., 2021). The Morse neural network has connectio
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23376;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#20998;&#23618;&#32467;&#26500;&#34701;&#20837;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20013;&#65292;&#24182;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#26469;&#35774;&#35745;&#26377;&#25928;&#30340;&#20998;&#23376;&#28508;&#22312;&#21521;&#37327;&#65292;&#29992;&#20110;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2307.00623</link><description>&lt;p&gt;
&#20351;&#29992;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#23545;&#20998;&#23376;&#22270;&#36827;&#34892;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Variational Autoencoding Molecular Graphs with Denoising Diffusion Probabilistic Model. (arXiv:2307.00623v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00623
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23376;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#20998;&#23618;&#32467;&#26500;&#34701;&#20837;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20013;&#65292;&#24182;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#26469;&#35774;&#35745;&#26377;&#25928;&#30340;&#20998;&#23376;&#28508;&#22312;&#21521;&#37327;&#65292;&#29992;&#20110;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#33647;&#29289;&#21457;&#29616;&#20013;&#65292;&#35774;&#35745;&#20998;&#23376;&#25551;&#36848;&#31526;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;(VAEs)&#31561;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#36890;&#36807;&#35774;&#35745;&#30001;&#20998;&#23376;&#32467;&#26500;&#23548;&#20986;&#30340;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20316;&#20026;&#25551;&#36848;&#31526;&#65292;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#22312;&#21482;&#26377;&#20998;&#23376;&#32467;&#26500;&#30340;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#24212;&#29992;&#20110;&#36801;&#31227;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#36890;&#24120;VAE&#30340;&#28508;&#22312;&#21521;&#37327;&#30340;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#20551;&#35774;&#20026;&#31616;&#21333;&#30340;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#65292;&#32780;&#19988;&#21327;&#26041;&#24046;&#20026;&#38646;&#65292;&#36825;&#21487;&#33021;&#38480;&#21046;&#20102;&#34920;&#31034;&#28508;&#22312;&#29305;&#24449;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23376;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#20998;&#23618;&#32467;&#26500;&#34701;&#20837;&#27010;&#29575;&#28508;&#22312;&#21521;&#37327;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;(DDPM)&#23454;&#29616;&#20102;&#36825;&#19968;&#30446;&#26631;&#12290;&#36890;&#36807;&#19968;&#20123;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#27169;&#22411;&#21487;&#20197;&#20026;&#20998;&#23376;&#24615;&#36136;&#39044;&#27979;&#35774;&#35745;&#20986;&#26377;&#25928;&#30340;&#20998;&#23376;&#28508;&#22312;&#21521;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven drug discovery, designing molecular descriptors is a very important task. Deep generative models such as variational autoencoders (VAEs) offer a potential solution by designing descriptors as probabilistic latent vectors derived from molecular structures. These models can be trained on large datasets, which have only molecular structures, and applied to transfer learning. Nevertheless, the approximate posterior distribution of the latent vectors of the usual VAE assumes a simple multivariate Gaussian distribution with zero covariance, which may limit the performance of representing the latent features. To overcome this limitation, we propose a novel molecular deep generative model that incorporates a hierarchical structure into the probabilistic latent vectors. We achieve this by a denoising diffusion probabilistic model (DDPM). We demonstrate that our model can design effective molecular latent vectors for molecular property prediction from some experiments by small dat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#26469;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#19988;&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.00619</link><description>&lt;p&gt;
&#36890;&#36807;&#21518;&#39564;&#37319;&#26679;&#21644;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#21487;&#35777;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models. (arXiv:2307.00619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00619
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#26469;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;&#12290;&#29702;&#35770;&#20998;&#26512;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#19988;&#22312;&#22810;&#31181;&#38382;&#39064;&#19978;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#35299;&#20915;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#20808;&#21069;&#25552;&#20986;&#30340;&#31639;&#27861;&#65288;&#22914;DPS&#21644;DDRM&#65289;&#20165;&#36866;&#29992;&#20110;&#20687;&#32032;&#31354;&#38388;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#32447;&#24615;&#27169;&#22411;&#35774;&#32622;&#20013;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#26679;&#26412;&#24674;&#22797;&#30340;&#21487;&#38752;&#24615;&#12290;&#20174;&#25105;&#20204;&#30340;&#20998;&#26512;&#20013;&#33719;&#24471;&#30340;&#31639;&#27861;&#27934;&#23519;&#21147;&#24310;&#20280;&#21040;&#20102;&#23454;&#36341;&#20013;&#24120;&#32771;&#34385;&#30340;&#26356;&#19968;&#33324;&#30340;&#35774;&#32622;&#12290;&#23454;&#39564;&#19978;&#65292;&#22312;&#21253;&#25324;&#38543;&#26426;&#20462;&#22797;&#12289;&#22359;&#20462;&#22797;&#12289;&#38477;&#22122;&#12289;&#21435;&#27169;&#31946;&#12289;&#21435;&#26465;&#32441;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#21508;&#31181;&#38382;&#39064;&#19978;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#20808;&#21069;&#25552;&#20986;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#20013;&#34920;&#29616;&#21331;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the first framework to solve linear inverse problems leveraging pre-trained latent diffusion models. Previously proposed algorithms (such as DPS and DDRM) only apply to pixel-space diffusion models. We theoretically analyze our algorithm showing provable sample recovery in a linear model setting. The algorithmic insight obtained from our analysis extends to more general settings often considered in practice. Experimentally, we outperform previously proposed posterior sampling algorithms in a wide variety of problems including random inpainting, block inpainting, denoising, deblurring, destriping, and super-resolution.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#26041;&#27861;&#65288;GGS&#65289;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#65292;&#28040;&#38500;&#20102;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25628;&#32034;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#21457;&#29616;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2307.00494</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimizing protein fitness using Gibbs sampling with Graph-based Smoothing. (arXiv:2307.00494v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00494
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#26041;&#27861;&#65288;GGS&#65289;&#20248;&#21270;&#34507;&#30333;&#36136;&#36866;&#24212;&#24615;&#65292;&#28040;&#38500;&#20102;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#39640;&#20102;&#25628;&#32034;&#25928;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#21457;&#29616;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#26041;&#38754;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#35774;&#35745;&#20986;&#22312;&#32473;&#23450;&#20219;&#21153;&#19978;&#20855;&#26377;&#26356;&#39640;&#36866;&#24212;&#24615;&#30340;&#26032;&#22411;&#34507;&#30333;&#36136;&#23545;&#35768;&#22810;&#21307;&#23398;&#39046;&#22495;&#26469;&#35828;&#37117;&#26159;&#38761;&#21629;&#24615;&#30340;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#31351;&#20030;&#25628;&#32034;&#28023;&#37327;&#24207;&#21015;&#31354;&#38388;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20197;&#21069;&#30340;&#26041;&#27861;&#23558;&#25628;&#32034;&#38480;&#21046;&#22312;&#20174;&#21442;&#32771;&#24207;&#21015;&#30340;&#23567;&#31361;&#21464;&#21322;&#24452;&#33539;&#22260;&#20869;&#65292;&#20294;&#36825;&#26679;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#35774;&#35745;&#31354;&#38388;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#28040;&#38500;&#31361;&#21464;&#36317;&#31163;&#30340;&#38480;&#21046;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#25928;&#30340;&#25506;&#32034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;Gibbs&#37319;&#26679;&#65288;GGS&#65289;&#65292;&#23427;&#36890;&#36807;&#36845;&#20195;&#24212;&#29992;&#24102;&#26377;&#26799;&#24230;&#30340;Gibbs&#26469;&#25552;&#20986;&#26377;&#21033;&#30340;&#31361;&#21464;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#22270;&#24418;&#24179;&#28369;&#30340;&#26041;&#27861;&#21435;&#38500;&#23548;&#33268;&#20551;&#38451;&#24615;&#30340;&#22122;&#22768;&#26799;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#38598;&#20013;&#21457;&#29616;&#20102;&#39640;&#36866;&#24212;&#24615;&#34507;&#30333;&#36136;&#65292;&#26368;&#22810;&#20855;&#26377;8&#20010;&#31361;&#21464;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;GFP&#21644;AAV&#35774;&#35745;&#38382;&#39064;&#12289;&#28040;&#34701;&#35797;&#39564;&#21644;&#22522;&#20934;&#27169;&#22411;&#26469;&#38416;&#26126;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to design novel proteins with higher fitness on a given task would be revolutionary for many fields of medicine. However, brute-force search through the combinatorially large space of sequences is infeasible. Prior methods constrain search to a small mutational radius from a reference sequence, but such heuristics drastically limit the design space. Our work seeks to remove the restriction on mutational distance while enabling efficient exploration. We propose Gibbs sampling with Graph-based Smoothing (GGS) which iteratively applies Gibbs with gradients to propose advantageous mutations using graph-based smoothing to remove noisy gradients that lead to false positives. Our method is state-of-the-art in discovering high-fitness proteins with up to 8 mutations from the training set. We study the GFP and AAV design problems, ablations, and baselines to elucidate the results. Code: https://github.com/kirjner/GGS
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25193;&#25955;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#24102;&#32570;&#22833;&#20540;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#35757;&#32451;&#30446;&#26631;&#30340;&#19968;&#33268;&#24615;&#21644;&#19978;&#30028;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.00467</link><description>&lt;p&gt;
&#20351;&#29992;&#32570;&#22833;&#20540;&#30340;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#35757;&#32451;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MissDiff: Training Diffusion Models on Tabular Data with Missing Values. (arXiv:2307.00467v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25193;&#25955;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#24102;&#32570;&#22833;&#20540;&#30340;&#34920;&#26684;&#25968;&#25454;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#35757;&#32451;&#30446;&#26631;&#30340;&#19968;&#33268;&#24615;&#21644;&#19978;&#30028;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#24314;&#27169;&#25968;&#25454;&#20998;&#24067;&#21644;&#21512;&#25104;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#25193;&#25955;&#27169;&#22411;&#38656;&#35201;&#23436;&#25972;&#25110;&#23436;&#20840;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#21508;&#31181;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#21253;&#25324;&#21307;&#30103;&#21644;&#37329;&#34701;&#65292;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#38598;&#26102;&#24120;&#24120;&#36935;&#21040;&#25968;&#25454;&#19981;&#23436;&#25972;&#30340;&#38382;&#39064;&#12290;&#26412;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#21644;&#26377;&#21407;&#21017;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21508;&#31181;&#32570;&#22833;&#26426;&#21046;&#19979;&#20174;&#24102;&#32570;&#22833;&#20540;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#12290;&#25105;&#20204;&#39318;&#20808;&#35266;&#23519;&#21040;&#24191;&#27867;&#37319;&#29992;&#30340;&#8220;&#34917;&#20840;&#20877;&#29983;&#25104;&#8221;&#27969;&#31243;&#21487;&#33021;&#20250;&#23548;&#33268;&#26377;&#20559;&#30340;&#23398;&#20064;&#30446;&#26631;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#35758;&#22312;&#35757;&#32451;&#38454;&#27573;&#23631;&#34109;&#21435;&#22122;&#35780;&#20998;&#21305;&#37197;&#30340;&#22238;&#24402;&#25439;&#22833;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#23398;&#20064;&#25968;&#25454;&#20998;&#24067;&#24471;&#20998;&#26041;&#38754;&#26159;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#25152;&#25552;&#20986;&#30340;&#35757;&#32451;&#30446;&#26631;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#20316;&#20026;&#36127;&#23545;&#25968;&#20284;&#28982;&#30340;&#19978;&#30028;&#12290;&#21033;&#29992;&#36924;&#30495;&#21644;&#39640;&#25928;&#30340;&#22810;&#20010;&#34920;&#26684;&#25968;&#25454;&#38598;&#23545;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The diffusion model has shown remarkable performance in modeling data distributions and synthesizing data. However, the vanilla diffusion model requires complete or fully observed data for training. Incomplete data is a common issue in various real-world applications, including healthcare and finance, particularly when dealing with tabular datasets. This work presents a unified and principled diffusion-based framework for learning from data with missing values under various missing mechanisms. We first observe that the widely adopted "impute-then-generate" pipeline may lead to a biased learning objective. Then we propose to mask the regression loss of Denoising Score Matching in the training phase. We prove the proposed method is consistent in learning the score of data distributions, and the proposed training objective serves as an upper bound for the negative likelihood in certain cases. The proposed framework is evaluated on multiple tabular datasets using realistic and efficacious 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#23485;&#26494;Pareto&#38598;&#30340;&#35782;&#21035;&#65292;&#36890;&#36807;&#25918;&#26494;&#31574;&#30053;&#26469;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.00424</link><description>&lt;p&gt;
&#23485;&#26494;Pareto&#38598;&#35782;&#21035;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Algorithms for Relaxed Pareto Set Identification. (arXiv:2307.00424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#23485;&#26494;Pareto&#38598;&#30340;&#35782;&#21035;&#65292;&#36890;&#36807;&#25918;&#26494;&#31574;&#30053;&#26469;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#20013;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;Pareto&#26368;&#20248;&#38598;&#21512;&#30340;&#35782;&#21035;&#38382;&#39064;&#12290;&#30001;&#20110;&#20934;&#30830;&#35782;&#21035;Pareto&#38598;&#21512;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#33021;&#38750;&#24120;&#22823;&#65292;&#22240;&#27492;&#30740;&#31350;&#20102;&#20801;&#35768;&#36755;&#20986;&#19968;&#20123;&#39069;&#22806;&#36817;&#20284;&#26368;&#20248;&#33218;&#30340;&#25918;&#26494;&#31574;&#30053;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#20854;&#20182;&#20801;&#35768;&#35782;&#21035;Pareto&#38598;&#21512;&#30340;&#30456;&#20851;&#23376;&#38598;&#30340;&#25918;&#26494;&#31574;&#30053;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33258;&#36866;&#24212;Pareto&#25506;&#32034;&#30340;&#21333;&#19968;&#25277;&#26679;&#31574;&#30053;&#65292;&#21487;&#20197;&#19982;&#19981;&#21516;&#30340;&#20572;&#27490;&#35268;&#21017;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#32771;&#34385;Pareto&#38598;&#21512;&#35782;&#21035;&#38382;&#39064;&#30340;&#19981;&#21516;&#25918;&#26494;&#31574;&#30053;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20123;&#19981;&#21516;&#32452;&#21512;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#29305;&#21035;&#37327;&#21270;&#20102;&#22312;&#23547;&#25214;&#35782;&#21035;&#26368;&#22810;$k$&#20010;Pareto&#26368;&#20248;&#33218;&#26102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20943;&#23569;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#33258;&#36866;&#24212;Pareto&#25506;&#32034;&#22312;&#19968;&#20010;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#33391;&#22909;&#23454;&#38469;&#24615;&#33021;&#65292;&#20854;&#20013;&#25105;&#20204;&#33258;&#36866;&#24212;&#22320;&#25506;&#32034;&#20102;&#20960;&#31181;&#30123;&#33495;&#25509;&#31181;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we revisit the fixed-confidence identification of the Pareto optimal set in a multi-objective multi-armed bandit model. As the sample complexity to identify the exact Pareto set can be very large, a relaxation allowing to output some additional near-optimal arms has been studied. In this work we also tackle alternative relaxations that allow instead to identify a relevant subset of the Pareto set. Notably, we propose a single sampling strategy, called Adaptive Pareto Exploration, that can be used in conjunction with different stopping rules to take into account different relaxations of the Pareto Set Identification problem. We analyze the sample complexity of these different combinations, quantifying in particular the reduction in sample complexity that occurs when one seeks to identify at most $k$ Pareto optimal arms. We showcase the good practical performance of Adaptive Pareto Exploration on a real-world scenario, in which we adaptively explore several vaccination stra
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t</title><link>http://arxiv.org/abs/2307.00405</link><description>&lt;p&gt;
&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;UCB&#31867;&#22411;&#31639;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient UCB-type Algorithms For Learning Predictive State Representations. (arXiv:2307.00405v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00405
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33324;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#26088;&#22312;&#36890;&#36807;&#22522;&#20110;&#36807;&#21435;&#35266;&#23519;&#21644;&#34892;&#21160;&#30340;&#21382;&#21490;&#26469;&#26368;&#22823;&#21270;&#32047;&#31215;&#22870;&#21169;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#21487;&#20197;&#29992;&#39044;&#27979;&#29366;&#24577;&#34920;&#31034;&#65288;PSRs&#65289;&#24314;&#27169;&#20302;&#31209;&#32467;&#26500;&#65292;&#37027;&#20040;&#23427;&#26159;&#21487;&#32479;&#35745;&#23398;&#20064;&#30340;&#12290;&#23613;&#31649;&#26377;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#20351;&#29992;&#39044;&#20808;&#35774;&#35745;&#22909;&#30340;&#27493;&#39588;&#25110;&#32773;&#26159;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#30340;&#25110;&#32773;&#26159;&#19981;&#21487;&#35745;&#31639;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#26041;&#27861;&#22312;&#36172;&#21338;&#26426;&#21644;MDPs&#20013;&#34987;&#25104;&#21151;&#22320;&#20316;&#20026;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#20294;&#23545;PSR&#36825;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#36824;&#27809;&#26377;&#36827;&#34892;&#30740;&#31350;&#65292;&#36825;&#26159;&#30001;&#20110;&#22312;&#36825;&#31181;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#20048;&#35266;&#22411;&#22870;&#21169;&#30340;&#35774;&#35745;&#21313;&#20998;&#22256;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;PSRs&#30340;&#31532;&#19968;&#31181;&#24050;&#30693;&#30340;UCB&#31867;&#22411;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#26032;&#30340;&#22870;&#21169;&#39033;&#26469;&#19978;&#30028;t
&lt;/p&gt;
&lt;p&gt;
The general sequential decision-making problem, which includes Markov decision processes (MDPs) and partially observable MDPs (POMDPs) as special cases, aims at maximizing a cumulative reward by making a sequence of decisions based on a history of observations and actions over time. Recent studies have shown that the sequential decision-making problem is statistically learnable if it admits a low-rank structure modeled by predictive state representations (PSRs). Despite these advancements, existing approaches typically involve oracles or steps that are not computationally efficient. On the other hand, the upper confidence bound (UCB) based approaches, which have served successfully as computationally efficient methods in bandits and MDPs, have not been investigated for more general PSRs, due to the difficulty of optimistic bonus design in these more challenging settings. This paper proposes the first known UCB-type approach for PSRs, featuring a novel bonus term that upper bounds the t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32452;&#20985;&#27491;&#21017;&#21270;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#31232;&#30095;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#29305;&#24449;&#24182;&#20445;&#25345;&#31283;&#23450;&#30340;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.00344</link><description>&lt;p&gt;
&#20351;&#29992;&#32452;&#20985;&#27491;&#21017;&#21270;&#30340;&#31232;&#30095;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Sparse-Input Neural Network using Group Concave Regularization. (arXiv:2307.00344v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00344
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32452;&#20985;&#27491;&#21017;&#21270;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#30340;&#31232;&#30095;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#36873;&#25321;&#37325;&#35201;&#30340;&#29305;&#24449;&#24182;&#20445;&#25345;&#31283;&#23450;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21516;&#26102;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#38750;&#32447;&#24615;&#20989;&#25968;&#20272;&#35745;&#22312;&#39640;&#32500;&#29615;&#22659;&#20013;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#20854;&#20013;&#21464;&#37327;&#30340;&#25968;&#37327;&#36229;&#36807;&#20102;&#24314;&#27169;&#20013;&#21487;&#29992;&#30340;&#26679;&#26412;&#22823;&#23567;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#12290;&#34429;&#28982;&#32452;LASSO&#24050;&#32463;&#34987;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#20013;&#36873;&#25321;&#21464;&#37327;&#65292;&#20294;&#23427;&#20542;&#21521;&#20110;&#36873;&#25321;&#26080;&#20851;&#32039;&#35201;&#30340;&#21464;&#37327;&#26469;&#24357;&#34917;&#36807;&#24230;&#32553;&#20943;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31232;&#30095;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#20351;&#29992;&#32452;&#20985;&#27491;&#21017;&#21270;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#65292;&#36866;&#29992;&#20110;&#20302;&#32500;&#21644;&#39640;&#32500;&#35774;&#32622;&#12290;&#20027;&#35201;&#24605;&#24819;&#26159;&#23545;&#27599;&#20010;&#36755;&#20837;&#33410;&#28857;&#30340;&#25152;&#26377;&#20986;&#31449;&#36830;&#25509;&#30340;&#26435;&#37325;&#30340;l2&#33539;&#25968;&#24212;&#29992;&#36866;&#24403;&#30340;&#20985;&#24809;&#32602;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#21482;&#20351;&#29992;&#21407;&#22987;&#21464;&#37327;&#30340;&#19968;&#20010;&#23567;&#23376;&#38598;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#21521;&#21518;&#36335;&#24452;&#20248;&#21270;&#24320;&#21457;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#33719;&#24471;&#31283;&#23450;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simultaneous feature selection and non-linear function estimation are challenging, especially in high-dimensional settings where the number of variables exceeds the available sample size in modeling. In this article, we investigate the problem of feature selection in neural networks. Although the group LASSO has been utilized to select variables for learning with neural networks, it tends to select unimportant variables into the model to compensate for its over-shrinkage. To overcome this limitation, we propose a framework of sparse-input neural networks using group concave regularization for feature selection in both low-dimensional and high-dimensional settings. The main idea is to apply a proper concave penalty to the $l_2$ norm of weights from all outgoing connections of each input node, and thus obtain a neural net that only uses a small subset of the original variables. In addition, we develop an effective algorithm based on backward path-wise optimization to yield stable solutio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2307.00310</link><description>&lt;p&gt;
&#26799;&#24230;&#30456;&#20284;&#65306;&#25935;&#24863;&#24230;&#32463;&#24120;&#34987;&#36807;&#39640;&#20272;&#35745;&#22312;DP-SGD&#20013;
&lt;/p&gt;
&lt;p&gt;
Gradients Look Alike: Sensitivity is Often Overestimated in DP-SGD. (arXiv:2307.00310v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;DP-SGD&#20998;&#26512;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#36827;&#34892;&#26356;&#20934;&#30830;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#26159;&#31169;&#26377;&#28145;&#24230;&#23398;&#20064;&#30340;&#26631;&#20934;&#31639;&#27861;&#12290;&#34429;&#28982;&#24050;&#30693;&#20854;&#38544;&#31169;&#20998;&#26512;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#26159;&#32039;&#23494;&#30340;&#65292;&#20294;&#26159;&#19968;&#20123;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#24120;&#35265;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#26174;&#33879;&#20943;&#23569;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;DP-SGD&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#25429;&#25417;&#21040;&#22312;&#25968;&#25454;&#38598;&#20013;&#20855;&#26377;&#30456;&#20284;&#37051;&#23621;&#30340;&#28857;&#20139;&#21463;&#26356;&#22909;&#38544;&#31169;&#24615;&#30340;&#30452;&#35273;&#12290;&#24418;&#24335;&#19978;&#26469;&#35828;&#65292;&#36825;&#26159;&#36890;&#36807;&#20462;&#25913;&#20174;&#35757;&#32451;&#25968;&#25454;&#38598;&#35745;&#31639;&#24471;&#21040;&#30340;&#27169;&#22411;&#26356;&#26032;&#30340;&#27599;&#27493;&#38544;&#31169;&#24615;&#20998;&#26512;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#32452;&#21512;&#23450;&#29702;&#65292;&#20197;&#26377;&#25928;&#22320;&#21033;&#29992;&#36825;&#20010;&#26032;&#30340;&#27599;&#27493;&#20998;&#26512;&#26469;&#25512;&#29702;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#12290;&#24635;&#32780;&#35328;&#20043;&#65292;&#25105;&#20204;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;DP-SGD&#20998;&#26512;&#20351;&#25105;&#20204;&#33021;&#22815;&#27491;&#24335;&#22320;&#26174;&#31034;DP-SGD&#23545;&#35768;&#22810;&#25968;&#25454;&#28857;&#30340;&#38544;&#31169;&#27844;&#28431;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private stochastic gradient descent (DP-SGD) is the canonical algorithm for private deep learning. While it is known that its privacy analysis is tight in the worst-case, several empirical results suggest that when training on common benchmark datasets, the models obtained leak significantly less privacy for many datapoints. In this paper, we develop a new analysis for DP-SGD that captures the intuition that points with similar neighbors in the dataset enjoy better privacy than outliers. Formally, this is done by modifying the per-step privacy analysis of DP-SGD to introduce a dependence on the distribution of model updates computed from a training dataset. We further develop a new composition theorem to effectively use this new per-step analysis to reason about an entire training run. Put all together, our evaluation shows that this novel DP-SGD analysis allows us to now formally show that DP-SGD leaks significantly less privacy for many datapoints. In particular, we ob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;&#36125;&#21494;&#26031;&#25216;&#26415;&#24212;&#29992;&#20110;&#27979;&#26012;&#20202;&#25968;&#25454;&#30340;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#37327;&#21270;&#21644;&#35780;&#20272;&#19981;&#30830;&#23450;&#24615;&#26469;&#26368;&#23567;&#21270;&#25104;&#26412;&#21644;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.00305</link><description>&lt;p&gt;
&#24212;&#29992;&#36125;&#21494;&#26031;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#65306;&#27979;&#26012;&#20202;&#25968;&#25454;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Applied Bayesian Structural Health Monitoring: inclinometer data anomaly detection and forecasting. (arXiv:2307.00305v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00305
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;&#36125;&#21494;&#26031;&#25216;&#26415;&#24212;&#29992;&#20110;&#27979;&#26012;&#20202;&#25968;&#25454;&#30340;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#37327;&#21270;&#21644;&#35780;&#20272;&#19981;&#30830;&#23450;&#24615;&#26469;&#26368;&#23567;&#21270;&#25104;&#26412;&#21644;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#26012;&#20202;&#25506;&#22836;&#26159;&#19968;&#31181;&#21487;&#20197;&#29992;&#26469;&#27979;&#37327;&#22303;&#26041;&#22369;&#20307;&#21464;&#24418;&#30340;&#35774;&#22791;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#23558;&#36125;&#21494;&#26031;&#25216;&#26415;&#24212;&#29992;&#20110;&#23454;&#38469;&#27979;&#26012;&#20202;&#25968;&#25454;&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;&#21151;&#33021;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#26412;&#25991;&#35814;&#32454;&#20171;&#32461;&#20102;&#23545;&#25972;&#20010;&#33521;&#22269;&#38081;&#36335;&#32593;&#32476;&#20013;&#25910;&#38598;&#30340;&#27979;&#26012;&#20202;&#25968;&#25454;&#36827;&#34892;&#20998;&#26512;&#30340;&#24773;&#20917;&#12290;&#30417;&#27979;&#25968;&#25454;&#22788;&#29702;&#36807;&#31243;&#20013;&#65292;&#20174;&#19994;&#20154;&#21592;&#36890;&#24120;&#26377;&#20004;&#20010;&#30446;&#26631;&#65292;&#19968;&#26159;&#35782;&#21035;&#20219;&#20309;&#24322;&#24120;&#25110;&#21361;&#38505;&#30340;&#36816;&#21160;&#65292;&#20108;&#26159;&#36890;&#36807;&#39044;&#27979;&#26469;&#39044;&#27979;&#28508;&#22312;&#26410;&#26469;&#30340;&#19981;&#33391;&#24773;&#20917;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#25216;&#26415;&#65292;&#36890;&#36807;&#23454;&#26045;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#23545;&#27979;&#26012;&#20202;&#25968;&#25454;&#36827;&#34892;&#24322;&#24120;&#26816;&#27979;&#21644;&#39044;&#27979;&#12290;&#36890;&#36807;&#37327;&#21270;&#21644;&#35780;&#20272;&#36866;&#24403;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#26368;&#23567;&#21270;&#25104;&#26412;&#21644;&#39118;&#38505;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#20419;&#36827;&#22686;&#24378;&#30340;&#20915;&#31574;&#21644;&#39118;&#38505;&#20998;&#26512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27979;&#26012;&#20202;&#25968;&#25454;&#21487;&#20197;&#34987;&#25551;&#36848;&#20026;
&lt;/p&gt;
&lt;p&gt;
Inclinometer probes are devices that can be used to measure deformations within earthwork slopes. This paper demonstrates a novel application of Bayesian techniques to real-world inclinometer data, providing both anomaly detection and forecasting. Specifically, this paper details an analysis of data collected from inclinometer data across the entire UK rail network.  Practitioners have effectively two goals when processing monitoring data. The first is to identify any anomalous or dangerous movements, and the second is to predict potential future adverse scenarios by forecasting. In this paper we apply Uncertainty Quantification (UQ) techniques by implementing a Bayesian approach to anomaly detection and forecasting for inclinometer data. Subsequently, both costs and risks may be minimised by quantifying and evaluating the appropriate uncertainties. This framework may then act as an enabler for enhanced decision making and risk analysis.  We show that inclinometer data can be described
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#33258;&#21161;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#20272;&#35745;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#30340;&#26631;&#20934;&#35823;&#24046;&#65292;&#24182;&#20026;&#34913;&#37327;&#24179;&#22343;&#27169;&#22411;&#24615;&#33021;&#30340;&#24635;&#20307;&#21442;&#25968;&#20135;&#29983;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2307.00260</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#21161;&#27861;&#30340;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Bootstrapping the Cross-Validation Estimate. (arXiv:2307.00260v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#33258;&#21161;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#20272;&#35745;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#30340;&#26631;&#20934;&#35823;&#24046;&#65292;&#24182;&#20026;&#34913;&#37327;&#24179;&#22343;&#27169;&#22411;&#24615;&#33021;&#30340;&#24635;&#20307;&#21442;&#25968;&#20135;&#29983;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#35780;&#20272;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#30340;&#25216;&#26415;&#12290;&#23427;&#21487;&#20197;&#36991;&#20813;&#23545;&#38169;&#35823;&#20272;&#35745;&#20013;&#30340;&#20048;&#35266;&#20559;&#24046;&#65292;&#23588;&#20854;&#23545;&#20110;&#20351;&#29992;&#22797;&#26434;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#26500;&#24314;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#26159;&#20381;&#36182;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#38543;&#26426;&#20540;&#65292;&#22240;&#27492;&#20934;&#30830;&#37327;&#21270;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#38750;&#24120;&#37325;&#35201;&#12290;&#29305;&#21035;&#26159;&#24403;&#20351;&#29992;&#20132;&#21449;&#39564;&#35777;&#27604;&#36739;&#20004;&#20010;&#27169;&#22411;&#30340;&#24615;&#33021;&#26102;&#65292;&#24517;&#39035;&#30830;&#23450;&#38169;&#35823;&#20272;&#35745;&#30340;&#24046;&#24322;&#26159;&#21542;&#26159;&#30001;&#20110;&#20598;&#28982;&#27874;&#21160;&#12290;&#23613;&#31649;&#24050;&#32463;&#21457;&#23637;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#23545;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#36827;&#34892;&#25512;&#26029;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#26377;&#35768;&#22810;&#38480;&#21046;&#65292;&#22914;&#20005;&#26684;&#30340;&#27169;&#22411;&#20551;&#35774;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#33258;&#21161;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#20272;&#35745;&#20132;&#21449;&#39564;&#35777;&#20272;&#35745;&#30340;&#26631;&#20934;&#35823;&#24046;&#65292;&#24182;&#20026;&#34913;&#37327;&#24179;&#22343;&#27169;&#22411;&#24615;&#33021;&#30340;&#24635;&#20307;&#21442;&#25968;&#20135;&#29983;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-validation is a widely used technique for evaluating the performance of prediction models. It helps avoid the optimism bias in error estimates, which can be significant for models built using complex statistical learning algorithms. However, since the cross-validation estimate is a random value dependent on observed data, it is essential to accurately quantify the uncertainty associated with the estimate. This is especially important when comparing the performance of two models using cross-validation, as one must determine whether differences in error estimates are a result of chance fluctuations. Although various methods have been developed for making inferences on cross-validation estimates, they often have many limitations, such as stringent model assumptions This paper proposes a fast bootstrap method that quickly estimates the standard error of the cross-validation estimate and produces valid confidence intervals for a population parameter measuring average model performance
&lt;/p&gt;</description></item><item><title>UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00238</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00238
&lt;/p&gt;
&lt;p&gt;
UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#24403;&#30446;&#26631;&#25968;&#25454;&#31232;&#32570;&#32780;&#28304;&#25968;&#25454;&#20805;&#36275;&#65292;&#25110;&#32773;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#36716;&#31227;&#23398;&#20064;&#22312;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;UTrans&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#30340;&#30028;&#38480;&#20302;&#20110;&#20165;&#26377;&#30446;&#26631;&#25968;&#25454;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#20551;&#35774;&#26816;&#39564;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#25968;&#25454;&#26816;&#27979;&#31639;&#27861;&#65292;&#29992;&#20110;&#25490;&#38500;&#19981;&#21487;&#36716;&#31227;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#35780;&#20272;&#21644;&#27604;&#36739;&#20102;UTrans&#19982;&#29616;&#26377;&#31639;&#27861;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;UTrans&#22312;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#32654;&#22269;&#20195;&#38469;&#27969;&#21160;&#25968;&#25454;&#65292;&#24182;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#19982;&#32463;&#20856;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#27631;&#20132;&#38598;&#65292;&#24182;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;EEMBI-PC&#65292;&#23427;&#26159;EEMBI&#30340;&#25193;&#23637;&#29256;&#26412;&#65292;&#23558;PC&#31639;&#27861;&#30340;&#26368;&#21518;&#19968;&#27493;&#38598;&#25104;&#21040;EEMBI&#20013;&#12290;</title><link>http://arxiv.org/abs/2307.00227</link><description>&lt;p&gt;
&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#27631;&#20132;&#38598;&#36827;&#34892;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Structure Learning by Using Intersection of Markov Blankets. (arXiv:2307.00227v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00227
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#27631;&#20132;&#38598;&#65292;&#24182;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#30340;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;EEMBI-PC&#65292;&#23427;&#26159;EEMBI&#30340;&#25193;&#23637;&#29256;&#26412;&#65292;&#23558;PC&#31639;&#27861;&#30340;&#26368;&#21518;&#19968;&#27493;&#38598;&#25104;&#21040;EEMBI&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;&#20869;&#28304;&#21644;&#22806;&#28304;&#39532;&#23572;&#21487;&#22827;&#27631;&#20132;&#38598;&#65288;EEMBI&#65289;&#65292;&#23427;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCM&#65289;&#30340;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EEMBI&#30340;&#25193;&#23637;&#29256;&#26412;&#65292;&#21363;EEMBI-PC&#65292;&#23427;&#23558;PC&#31639;&#27861;&#30340;&#26368;&#21518;&#19968;&#27493;&#38598;&#25104;&#21040;EEMBI&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel causal structure learning algorithm called Endogenous and Exogenous Markov Blankets Intersection (EEMBI), which combines the properties of Bayesian networks and Structural Causal Models (SCM). Furthermore, we propose an extended version of EEMBI, namely EEMBI-PC, which integrates the last step of the PC algorithm into EEMBI.
&lt;/p&gt;</description></item><item><title>&#24179;&#34913;&#26041;&#27861;&#23545;&#19981;&#24179;&#34913;&#20998;&#31867;&#38382;&#39064;&#20013;&#27169;&#22411;&#34892;&#20026;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#24179;&#34913;&#20998;&#26512;&#22312;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00157</link><description>&lt;p&gt;
&#24179;&#34913;&#26041;&#27861;&#23545;&#19981;&#24179;&#34913;&#20998;&#31867;&#38382;&#39064;&#20013;&#27169;&#22411;&#34892;&#20026;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Effect of Balancing Methods on Model Behavior in Imbalanced Classification Problems. (arXiv:2307.00157v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00157
&lt;/p&gt;
&lt;p&gt;
&#24179;&#34913;&#26041;&#27861;&#23545;&#19981;&#24179;&#34913;&#20998;&#31867;&#38382;&#39064;&#20013;&#27169;&#22411;&#34892;&#20026;&#20135;&#29983;&#26174;&#33879;&#24433;&#21709;&#12290;&#36825;&#20123;&#21457;&#29616;&#24378;&#35843;&#20102;&#24179;&#34913;&#20998;&#26512;&#22312;&#27169;&#22411;&#35757;&#32451;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#24179;&#34913;&#25968;&#25454;&#23545;&#20998;&#31867;&#38382;&#39064;&#26500;&#25104;&#20102;&#37325;&#35201;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#27169;&#22411;&#24615;&#33021;&#21463;&#21040;&#23545;&#23569;&#25968;&#31867;&#21035;&#23398;&#20064;&#19981;&#36275;&#30340;&#24433;&#21709;&#12290;&#24179;&#34913;&#26041;&#27861;&#36890;&#24120;&#34987;&#29992;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#25311;&#21512;&#25110;&#32773;&#20449;&#24687;&#20002;&#22833;&#31561;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#24179;&#34913;&#26041;&#27861;&#26356;&#20855;&#25361;&#25112;&#24615;&#30340;&#26041;&#38754;&#8212;&#8212;&#23427;&#20204;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#25429;&#25417;&#36825;&#20123;&#21464;&#21270;&#65292;&#26412;&#30740;&#31350;&#20351;&#29992;&#20102;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#26469;&#27604;&#36739;&#22312;&#24179;&#34913;&#21069;&#21518;&#35757;&#32451;&#30340;&#27169;&#22411;&#12290;&#38500;&#20102;&#21464;&#37327;&#37325;&#35201;&#24615;&#26041;&#27861;&#22806;&#65292;&#26412;&#30740;&#31350;&#36824;&#20351;&#29992;&#20102;&#37096;&#20998;&#20381;&#36182;&#36718;&#24275;&#21644;&#32047;&#31215;&#23616;&#37096;&#24433;&#21709;&#25216;&#26415;&#12290;&#36827;&#34892;&#20102;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#38598;&#30340;&#27979;&#35797;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#24320;&#28304;Python&#21253;edgaro&#26469;&#26041;&#20415;&#36827;&#34892;&#36825;&#31181;&#20998;&#26512;&#12290;&#25152;&#24471;&#21040;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#30001;&#20110;&#24179;&#34913;&#26041;&#27861;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#34892;&#20026;&#21457;&#29983;&#20102;&#26174;&#33879;&#21464;&#21270;&#65292;&#21487;&#33021;&#20250;&#20351;&#27169;&#22411;&#23545;&#24179;&#34913;&#20998;&#24067;&#20135;&#29983;&#20559;&#35265;&#12290;&#36825;&#20123;&#21457;&#29616;&#35777;&#23454;&#20102;&#24179;&#34913;&#20998;&#26512;&#23545;&#27169;&#22411;&#34892;&#20026;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imbalanced data poses a significant challenge in classification as model performance is affected by insufficient learning from minority classes. Balancing methods are often used to address this problem. However, such techniques can lead to problems such as overfitting or loss of information. This study addresses a more challenging aspect of balancing methods - their impact on model behavior. To capture these changes, Explainable Artificial Intelligence tools are used to compare models trained on datasets before and after balancing. In addition to the variable importance method, this study uses the partial dependence profile and accumulated local effects techniques. Real and simulated datasets are tested, and an open-source Python package edgaro is developed to facilitate this analysis. The results obtained show significant changes in model behavior due to balancing methods, which can lead to biased models toward a balanced distribution. These findings confirm that balancing analysis sh
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.00127</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional Bayesian Structure Learning in Gaussian Graphical Models using Marginal Pseudo-Likelihood. (arXiv:2307.00127v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00127
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#20351;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#35299;&#20915;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#30701;&#26102;&#38388;&#20869;&#29983;&#25104;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;R&#36719;&#20214;&#21253;BDgraph&#30340;&#20195;&#30721;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#22270;&#27169;&#22411;&#20197;&#22270;&#24418;&#24418;&#24335;&#25551;&#32472;&#20102;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#12290;&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#21033;&#29992;&#36793;&#38469;&#20266;&#20284;&#28982;&#20989;&#25968;&#26469;&#24212;&#23545;&#39640;&#32500;&#22270;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#26631;&#20934;&#35745;&#31639;&#26426;&#19978;&#22312;&#20960;&#20998;&#38047;&#20869;&#24555;&#36895;&#29983;&#25104;&#23545;&#21253;&#21547;1000&#20010;&#21464;&#37327;&#30340;&#38382;&#39064;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#23545;&#20110;&#23545;&#23454;&#38469;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#20154;&#65292;&#25903;&#25345;&#36825;&#31181;&#26032;&#26041;&#27861;&#30340;&#20195;&#30721;&#36890;&#36807;R&#36719;&#20214;&#21253;BDgraph&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian graphical models depict the conditional dependencies between variables within a multivariate normal distribution in a graphical format. The identification of these graph structures is an area known as structure learning. However, when utilizing Bayesian methodologies in structure learning, computational complexities can arise, especially with high-dimensional graphs surpassing 250 nodes. This paper introduces two innovative search algorithms that employ marginal pseudo-likelihood to address this computational challenge. These methods can swiftly generate reliable estimations for problems encompassing 1000 variables in just a few minutes on standard computers. For those interested in practical applications, the code supporting this new approach is made available through the R package BDgraph.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21152;&#36895;&#38750;&#31934;&#30830;&#36229;&#26799;&#24230;&#19979;&#38477;&#30340;&#26041;&#27861;&#29992;&#20110;&#21452;&#23618;&#20248;&#21270;&#65292;&#21487;&#20197;&#22312;&#36739;&#20302;&#30340;&#22797;&#26434;&#24230;&#19979;&#25214;&#21040;&#19968;&#38454;&#21644;&#20108;&#38454;&#31283;&#23450;&#28857;&#65292;&#25104;&#20026;&#21452;&#23618;&#20248;&#21270;&#21644;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#26368;&#26032;&#26368;&#20339;&#29366;&#24577;&#12290;</title><link>http://arxiv.org/abs/2307.00126</link><description>&lt;p&gt;
&#21152;&#36895;&#38750;&#31934;&#30830;&#36229;&#26799;&#24230;&#19979;&#38477;&#29992;&#20110;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Accelerating Inexact HyperGradient Descent for Bilevel Optimization. (arXiv:2307.00126v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00126
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21152;&#36895;&#38750;&#31934;&#30830;&#36229;&#26799;&#24230;&#19979;&#38477;&#30340;&#26041;&#27861;&#29992;&#20110;&#21452;&#23618;&#20248;&#21270;&#65292;&#21487;&#20197;&#22312;&#36739;&#20302;&#30340;&#22797;&#26434;&#24230;&#19979;&#25214;&#21040;&#19968;&#38454;&#21644;&#20108;&#38454;&#31283;&#23450;&#28857;&#65292;&#25104;&#20026;&#21452;&#23618;&#20248;&#21270;&#21644;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#26368;&#26032;&#26368;&#20339;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#19968;&#33324;&#38750;&#20984;-&#20984;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#8212;&#8212;"&#37325;&#26032;&#21551;&#21160;&#30340;&#21152;&#36895;&#36229;&#26799;&#24230;&#19979;&#38477;" (RAHGD) &#26041;&#27861;&#8212;&#8212;&#21487;&#20197;&#25214;&#21040;&#19968;&#20010; $\epsilon$-&#19968;&#38454;&#31283;&#23450;&#28857;&#65292;&#20854; oracle &#22797;&#26434;&#24230;&#20026; $\tilde{\mathcal{O}}(\kappa^{3.25}\epsilon^{-1.75})$&#65292;&#20854;&#20013; $\kappa$ &#26159;&#19979;&#23618;&#30446;&#26631;&#30340;&#26465;&#20214;&#25968;&#65292;$\epsilon$ &#26159;&#26399;&#26395;&#31934;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102; RAHGD &#30340;&#25200;&#21160;&#21464;&#20307;&#65292;&#29992;&#20110;&#22312;&#30456;&#21516;&#30340; oracle &#22797;&#26434;&#24230;&#19979;&#25214;&#21040;&#19968;&#20010; $\big(\epsilon,\mathcal{O}(\kappa^{2.5}\sqrt{\epsilon}\,)\big)$-&#20108;&#38454;&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#21452;&#23618;&#20248;&#21270;&#20013;&#23454;&#29616;&#20102;&#24050;&#30693;&#26368;&#22909;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#25913;&#36827;&#20102;&#29616;&#26377;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#20013;&#25214;&#21040;&#20108;&#38454;&#31283;&#23450;&#28857;&#30340;&#19978;&#30028;&#22797;&#26434;&#24230;&#65292;&#20026;&#26368;&#26032;&#30340;&#22522;&#20934;&#35774;&#32622;&#20102;&#19968;&#20010;&#26032;&#30340;&#26368;&#20339;&#29366;&#24577;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a method for solving general nonconvex-strongly-convex bilevel optimization problems. Our method -- the \emph{Restarted Accelerated HyperGradient Descent} (\texttt{RAHGD}) method -- finds an $\epsilon$-first-order stationary point of the objective with $\tilde{\mathcal{O}}(\kappa^{3.25}\epsilon^{-1.75})$ oracle complexity, where $\kappa$ is the condition number of the lower-level objective and $\epsilon$ is the desired accuracy. We also propose a perturbed variant of \texttt{RAHGD} for finding an $\big(\epsilon,\mathcal{O}(\kappa^{2.5}\sqrt{\epsilon}\,)\big)$-second-order stationary point within the same order of oracle complexity. Our results achieve the best-known theoretical guarantees for finding stationary points in bilevel optimization and also improve upon the existing upper complexity bound for finding second-order stationary points in nonconvex-strongly-concave minimax optimization problems, setting a new state-of-the-art benchmark. Empirical studies are conducted t
&lt;/p&gt;</description></item><item><title>&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#20801;&#35768;&#29289;&#29702;&#31185;&#23398;&#23478;&#24212;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20110;&#39640;&#32500;&#38382;&#39064;&#20013;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#20808;&#39564;&#30340;&#25903;&#25345;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.00056</link><description>&lt;p&gt;
&#29992;&#20110;&#29289;&#29702;&#31185;&#23398;&#23478;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#20808;&#39564;&#30340;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Proximal nested sampling with data-driven priors for physical scientists. (arXiv:2307.00056v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00056
&lt;/p&gt;
&lt;p&gt;
&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#20801;&#35768;&#29289;&#29702;&#31185;&#23398;&#23478;&#24212;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20110;&#39640;&#32500;&#38382;&#39064;&#20013;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#20808;&#39564;&#30340;&#25903;&#25345;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#24341;&#20837;&#20102;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#65292;&#20197;&#24320;&#36767;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#35745;&#31639;&#25104;&#20687;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#25968;&#20984;&#20284;&#28982;&#20989;&#25968;&#30340;&#27169;&#22411;&#65292;&#36825;&#22312;&#25104;&#20687;&#31185;&#23398;&#20013;&#38750;&#24120;&#26222;&#36941;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#30446;&#30340;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20197;&#25945;&#23398;&#30340;&#26041;&#24335;&#23545;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#36827;&#34892;&#32508;&#36848;&#65292;&#20197;&#21162;&#21147;&#20026;&#29289;&#29702;&#31185;&#23398;&#23478;&#35299;&#37322;&#35813;&#26694;&#26550;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#22914;&#20309;&#22312;&#32463;&#39564;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#25193;&#23637;&#65292;&#20197;&#25903;&#25345;&#25968;&#25454;&#39537;&#21160;&#30340;&#20808;&#39564;&#65292;&#22914;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proximal nested sampling was introduced recently to open up Bayesian model selection for high-dimensional problems such as computational imaging. The framework is suitable for models with a log-convex likelihood, which are ubiquitous in the imaging sciences. The purpose of this article is two-fold. First, we review proximal nested sampling in a pedagogical manner in an attempt to elucidate the framework for physical scientists. Second, we show how proximal nested sampling can be extended in an empirical Bayes setting to support data-driven priors, such as deep neural networks learned from training data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#65292;&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#35299;&#20915;&#20102;&#21407;&#22987;&#26041;&#27861;&#20013;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.00048</link><description>&lt;p&gt;
&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Learned harmonic mean estimation of the marginal likelihood with normalizing flows. (arXiv:2307.00048v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#23398;&#20064;&#36793;&#32536;&#20284;&#28982;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#65292;&#22312;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#35299;&#20915;&#20102;&#21407;&#22987;&#26041;&#27861;&#20013;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#36793;&#32536;&#20284;&#28982;&#65288;&#20063;&#31216;&#20026;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#65289;&#26159;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#23427;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21407;&#21017;&#30340;&#23450;&#37327;&#27604;&#36739;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#23398;&#20064;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#22120;&#35299;&#20915;&#20102;&#21407;&#22987;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#36793;&#32536;&#20284;&#28982;&#30340;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;&#23398;&#20064;&#30340;&#35843;&#21644;&#24179;&#22343;&#20272;&#35745;&#22120;&#23398;&#20064;&#20102;&#19968;&#20010;&#37325;&#35201;&#24615;&#37319;&#26679;&#30446;&#26631;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#36817;&#20284;&#20110;&#26368;&#20248;&#20998;&#24067;&#12290;&#34429;&#28982;&#36817;&#20284;&#19981;&#24517;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#30830;&#20445;&#23398;&#20064;&#20998;&#24067;&#30340;&#27010;&#29575;&#36136;&#37327;&#21253;&#21547;&#22312;&#21518;&#39564;&#20998;&#24067;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20197;&#36991;&#20813;&#26041;&#24046;&#29190;&#28856;&#38382;&#39064;&#12290;&#22312;&#20808;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#30830;&#20445;&#28385;&#36275;&#36825;&#20010;&#24615;&#36136;&#65292;&#22312;&#35757;&#32451;&#27169;&#22411;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#19987;&#38376;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#34920;&#31034;&#37325;&#35201;&#24615;&#37319;&#26679;&#30446;&#26631;&#20998;&#24067;&#12290;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#20174;&#21518;&#39564;&#26679;&#26412;&#20013;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the marginal likelihood (also called the Bayesian model evidence) is an important task in Bayesian model selection, providing a principled quantitative way to compare models. The learned harmonic mean estimator solves the exploding variance problem of the original harmonic mean estimation of the marginal likelihood. The learned harmonic mean estimator learns an importance sampling target distribution that approximates the optimal distribution. While the approximation need not be highly accurate, it is critical that the probability mass of the learned distribution is contained within the posterior in order to avoid the exploding variance problem. In previous work a bespoke optimization problem is introduced when training models in order to ensure this property is satisfied. In the current article we introduce the use of normalizing flows to represent the importance sampling target distribution. A flow-based model is trained on samples from the posterior by maximum likelihood e
&lt;/p&gt;</description></item><item><title>TemperatureGAN&#26159;&#19968;&#20010;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20351;&#29992;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#25968;&#25454;&#65292;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.17248</link><description>&lt;p&gt;
TemperatureGAN: &#21306;&#22495;&#22823;&#27668;&#28201;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
TemperatureGAN: Generative Modeling of Regional Atmospheric Temperatures. (arXiv:2306.17248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.17248
&lt;/p&gt;
&lt;p&gt;
TemperatureGAN&#26159;&#19968;&#20010;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20351;&#29992;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#25968;&#25454;&#65292;&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#29983;&#25104;&#22120;&#23545;&#20110;&#20272;&#35745;&#27668;&#20505;&#23545;&#21508;&#20010;&#39046;&#22495;&#30340;&#24433;&#21709;&#38750;&#24120;&#26377;&#29992;&#12290;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#36827;&#34892;&#27668;&#20505;&#39118;&#38505;&#30340;&#39044;&#27979;&#65292;&#20363;&#22914;&#33021;&#28304;&#31995;&#32479;&#65292;&#38656;&#35201;&#20934;&#30830;&#65288;&#19982;&#22522;&#20934;&#30495;&#23454;&#25968;&#25454;&#26377;&#32479;&#35745;&#30456;&#20284;&#24615;&#65289;&#12289;&#21487;&#38752;&#65288;&#19981;&#20135;&#29983;&#38169;&#35823;&#26679;&#26412;&#65289;&#21644;&#39640;&#25928;&#30340;&#29983;&#25104;&#22120;&#12290;&#25105;&#20204;&#21033;&#29992;&#26469;&#33258;&#21271;&#32654;&#38470;&#22320;&#25968;&#25454;&#21516;&#21270;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#24341;&#20837;&#20102;TemperatureGAN&#65292;&#36825;&#26159;&#19968;&#20010;&#20197;&#26376;&#20221;&#12289;&#20301;&#32622;&#21644;&#26102;&#38388;&#27573;&#20026;&#26465;&#20214;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#20197;&#27599;&#23567;&#26102;&#20998;&#36776;&#29575;&#29983;&#25104;&#22320;&#38754;&#20197;&#19978;2m&#30340;&#22823;&#27668;&#28201;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#35780;&#20272;&#26041;&#27861;&#21644;&#25351;&#26631;&#26469;&#34913;&#37327;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;TemperatureGAN&#33021;&#22815;&#29983;&#25104;&#20855;&#26377;&#33391;&#22909;&#31354;&#38388;&#34920;&#31034;&#21644;&#19982;&#24050;&#30693;&#26172;&#22812;&#21608;&#26399;&#19968;&#33268;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#39640;&#20445;&#30495;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic generators are useful for estimating climate impacts on various sectors. Projecting climate risk in various sectors, e.g. energy systems, requires generators that are accurate (statistical resemblance to ground-truth), reliable (do not produce erroneous examples), and efficient. Leveraging data from the North American Land Data Assimilation System, we introduce TemperatureGAN, a Generative Adversarial Network conditioned on months, locations, and time periods, to generate 2m above ground atmospheric temperatures at an hourly resolution. We propose evaluation methods and metrics to measure the quality of generated samples. We show that TemperatureGAN produces high-fidelity examples with good spatial representation and temporal dynamics consistent with known diurnal cycles.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#29983;&#23398;&#20064;&#30340;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#32479;&#35745;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#12289;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#20197;&#21450;&#22312;&#19981;&#21516;&#26469;&#28304;&#25968;&#25454;&#36136;&#37327;&#19981;&#19968;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.14288</link><description>&lt;p&gt;
&#22522;&#20110;&#20849;&#29983;&#23398;&#20064;&#30340;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Near Optimal Heteroscedastic Regression with Symbiotic Learning. (arXiv:2306.14288v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#29983;&#23398;&#20064;&#30340;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#32479;&#35745;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#12289;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#20197;&#21450;&#22312;&#19981;&#21516;&#26469;&#28304;&#25968;&#25454;&#36136;&#37327;&#19981;&#19968;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#32463;&#20856;&#30340;&#24322;&#26041;&#24046;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#23637;&#24320;&#35752;&#35770;&#12290;&#20551;&#35774;&#25105;&#20204;&#26377;n&#20010;&#26679;&#26412; $(\mathbf{x}_i, y_i) \in \mathbb{R}^d \times \mathbb{R}$&#65292;&#20854;&#20013; $y_i = \langle \mathbf{w}^{*}, \mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i \rangle$&#65292; $\mathbf{x}_i \sim N(0,\mathbf{I})$&#65292;$\epsilon_i \sim N(0,1)$&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745; $\mathbf{w}^{*}$&#12290;&#22312;&#32479;&#35745;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#12289;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#24322;&#26041;&#24046;&#27169;&#22411;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21516;&#26102;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#22914;&#26524;&#25968;&#25454;&#26469;&#28304;&#19981;&#21516;&#65292;&#32780;&#19981;&#21516;&#26469;&#28304;&#30340;&#25968;&#25454;&#36136;&#37327;&#20063;&#19981;&#19968;&#65292;&#21017;&#24322;&#26041;&#24046;&#27169;&#22411;&#20063;&#26174;&#24471;&#29305;&#21035;&#30456;&#20851;&#12290;&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#21487;&#20197;&#20272;&#35745;&#20986;$\mathbf{w}^{*}$&#30340;&#24179;&#26041;&#33539;&#25968;&#65292;&#35823;&#24046;&#20026;$\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} + \left(\frac{d}{n}\right)^2\right)\right)$&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#38480;&#65288;&#19978;&#30028;&#23384;&#22312;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#26412;&#30740;&#31350;&#30340;&#32467;&#26524;&#26174;&#33879;&#25913;&#36827;&#20102;&#24322;&#26041;&#24046;&#22238;&#24402;&#38382;&#39064;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the classical problem of heteroscedastic linear regression, where we are given $n$ samples $(\mathbf{x}_i, y_i) \in \mathbb{R}^d \times \mathbb{R}$ obtained from $y_i = \langle \mathbf{w}^{*}, \mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i \rangle$, where $\mathbf{x}_i \sim N(0,\mathbf{I})$, $\epsilon_i \sim N(0,1)$, and our task is to estimate $\mathbf{w}^{*}$. In addition to the classical applications of heteroscedastic models in fields such as statistics, econometrics, time series analysis etc., it is also particularly relevant in machine learning when data is collected from multiple sources of varying but apriori unknown quality, e.g., large model training. Our work shows that we can estimate $\mathbf{w}^{*}$ in squared norm up to an error of $\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} + \left(\frac{d}{n}\right)^2\right)\right)$ and prove a matching lower bound (up to logarithmic factors). Our result substantially improves 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#32479;&#35745;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#36981;&#24490;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#21407;&#21017;&#65292;&#25512;&#23548;&#20986;&#20102;&#20854;&#32479;&#35745;&#30028;&#38480;&#21450;&#21442;&#25968;&#21270;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.13580</link><description>&lt;p&gt;
&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Lower Complexity Adaptation for Empirical Entropic Optimal Transport. (arXiv:2306.13580v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#32479;&#35745;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#36981;&#24490;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#21407;&#21017;&#65292;&#25512;&#23548;&#20986;&#20102;&#20854;&#32479;&#35745;&#30028;&#38480;&#21450;&#21442;&#25968;&#21270;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#39564;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816; (EOT) &#26159;&#20248;&#21270;&#36755;&#36816; (OT) &#30340;&#19968;&#31181;&#26377;&#25928;&#19988;&#35745;&#31639;&#21487;&#34892;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#20998;&#26512;&#26377;&#30528;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#25512;&#23548;&#20986;&#20102; EOT &#25104;&#26412;&#30340;&#26032;&#30340;&#32479;&#35745;&#30028;&#38480;&#65292;&#24182;&#26174;&#31034;&#23427;&#20204;&#22312;&#29109;&#27491;&#21017;&#21270;&#21442;&#25968; $\epsilon$ &#21644;&#26679;&#26412;&#22823;&#23567; $n$ &#30340;&#32479;&#35745;&#24615;&#33021;&#20165;&#21462;&#20915;&#20110;&#20004;&#20010;&#27010;&#29575;&#27979;&#24230;&#20043;&#20013;&#36739;&#31616;&#21333;&#30340;&#37027;&#20010;&#12290;&#20363;&#22914;&#65292;&#22312;&#20805;&#20998;&#24179;&#28369;&#30340;&#25104;&#26412;&#19979;&#65292;&#36825;&#20250;&#20135;&#29983;&#20855;&#26377;$\epsilon^{-d/2}$&#22240;&#23376;&#30340;&#21442;&#25968;&#21270;&#36895;&#29575;$n^{-1/2}$&#65292;&#20854;&#20013;$d$&#26159;&#20004;&#20010;&#24635;&#20307;&#27979;&#24230;&#30340;&#26368;&#23567;&#32500;&#24230;&#12290;&#36825;&#30830;&#35748;&#20102;&#32463;&#39564;EOT&#20063;&#36981;&#24490;&#20102;&#26368;&#36817;&#25165;&#20026;&#26410;&#35268;&#21017;&#21270;OT&#30830;&#35748;&#30340;&#20302;&#22797;&#26434;&#24230;&#36866;&#24212;&#21407;&#21017;&#30340;&#26631;&#24535;&#24615;&#29305;&#24449;&#12290;&#26681;&#25454;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#30340;&#32463;&#39564;&#29109;Gromov-Wasserstein&#36317;&#31163;&#21450;&#20854;&#26410;&#35268;&#21017;&#21270;&#29256;&#26412;&#20063;&#36981;&#24490;&#27492;&#21407;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entropic optimal transport (EOT) presents an effective and computationally viable alternative to unregularized optimal transport (OT), offering diverse applications for large-scale data analysis. In this work, we derive novel statistical bounds for empirical plug-in estimators of the EOT cost and show that their statistical performance in the entropy regularization parameter $\epsilon$ and the sample size $n$ only depends on the simpler of the two probability measures. For instance, under sufficiently smooth costs this yields the parametric rate $n^{-1/2}$ with factor $\epsilon^{-d/2}$, where $d$ is the minimum dimension of the two population measures. This confirms that empirical EOT also adheres to the lower complexity adaptation principle, a hallmark feature only recently identified for unregularized OT. As a consequence of our theory, we show that the empirical entropic Gromov-Wasserstein distance and its unregularized version for measures on Euclidean spaces also obey this princip
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#21487;&#20197;&#24212;&#23545;&#37325;&#23614;&#20998;&#24067;&#19988;&#20445;&#35777;&#26377;&#38480;&#30340;&#20551;&#38451;&#24615;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.09548</link><description>&lt;p&gt;
&#22312;&#32447;&#37325;&#23614;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Online Heavy-tailed Change-point detection. (arXiv:2306.09548v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09548
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#21487;&#20197;&#24212;&#23545;&#37325;&#23614;&#20998;&#24067;&#19988;&#20445;&#35777;&#26377;&#38480;&#30340;&#20551;&#38451;&#24615;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979; (OCPD) &#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#26679;&#26412;&#21487;&#33021;&#26159;&#37325;&#23614;&#20998;&#24067;&#65292;&#19968;&#20010;&#25509;&#19968;&#20010;&#22320;&#21576;&#29616;&#65292;&#24182;&#19988;&#24517;&#39035;&#23613;&#26089;&#26816;&#27979;&#21040;&#24213;&#23618;&#22343;&#20540;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35009;&#21098;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477; (SGD) &#30340;&#31639;&#27861;&#65292;&#21363;&#20351;&#25105;&#20204;&#20165;&#20551;&#23450;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#31532;&#20108;&#38454;&#30697;&#26377;&#30028;&#65292;&#35813;&#31639;&#27861;&#20063;&#33021;&#27491;&#24120;&#24037;&#20316;&#12290;&#25105;&#20204;&#27966;&#29983;&#20102;&#22312;&#25152;&#26377;&#20855;&#26377;&#26377;&#30028;&#31532;&#20108;&#30697;&#30340;&#20998;&#24067;&#26063;&#20013;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26377;&#38480;&#26679;&#26412;&#20551;&#38451;&#24615;&#29575; (FPR) &#30340;&#20445;&#35777;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#31532;&#19968;&#20010;&#20445;&#35777;&#26377;&#38480;&#26679;&#26412; FPR &#30340; OCPD &#31639;&#27861;&#65292;&#21363;&#20351;&#25968;&#25454;&#26159;&#39640;&#32500;&#30340;&#65292;&#24213;&#23618;&#20998;&#24067;&#26159;&#37325;&#23614;&#30340;&#12290;&#25105;&#20204;&#35770;&#25991;&#30340;&#25216;&#26415;&#36129;&#29486;&#26159;&#23637;&#31034;&#20102;&#35009;&#21098; SGD &#21487;&#20197;&#20272;&#35745;&#38543;&#26426;&#21521;&#37327;&#30340;&#22343;&#20540;&#24182;&#21516;&#26102;&#22312;&#25152;&#26377;&#32622;&#20449;&#24230;&#20540;&#19978;&#25552;&#20379;&#32622;&#20449;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#31283;&#20581;&#30340;&#20272;&#35745;&#19982;&#24182;&#38598;&#36793;&#30028;&#35770;&#35777;&#30456;&#32467;&#21512;&#65292;&#26500;&#24314;&#19968;&#20010;&#26377;&#38480;&#30340;&#39034;&#24207;&#21464;&#28857;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study algorithms for online change-point detection (OCPD), where samples that are potentially heavy-tailed, are presented one at a time and a change in the underlying mean must be detected as early as possible. We present an algorithm based on clipped Stochastic Gradient Descent (SGD), that works even if we only assume that the second moment of the data generating process is bounded. We derive guarantees on worst-case, finite-sample false-positive rate (FPR) over the family of all distributions with bounded second moment. Thus, our method is the first OCPD algorithm that guarantees finite-sample FPR, even if the data is high dimensional and the underlying distributions are heavy-tailed. The technical contribution of our paper is to show that clipped-SGD can estimate the mean of a random vector and simultaneously provide confidence bounds at all confidence values. We combine this robust estimate with a union bound argument and construct a sequential change-point algorithm with finite
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22522;&#20110;&#20114;&#32852;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#19981;&#20559;&#24494;&#20998;&#65292;&#24320;&#21457;&#20986;&#19968;&#31181;&#26080;&#20559;&#12289;&#20302;&#26041;&#24046;&#21644;&#33258;&#21160;&#30340;&#26041;&#27861;&#23545;&#22797;&#26434;&#23494;&#24230;&#36827;&#34892;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545; MH &#37319;&#26679;&#22120;&#30340;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.07961</link><description>&lt;p&gt;
&#36890;&#36807;&#19981;&#20559;&#24494;&#20998;&#23545;&#25239;&#22797;&#26434;&#23494;&#24230;&#29983;&#25104;&#65292;&#22522;&#20110;&#20114;&#32852;&#39532;&#23572;&#31185;&#22827;&#38142;&#19981;&#20559;&#24494;&#20998;&#20248;&#21270; MH &#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentiating Metropolis-Hastings to Optimize Intractable Densities. (arXiv:2306.07961v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22522;&#20110;&#20114;&#32852;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#19981;&#20559;&#24494;&#20998;&#65292;&#24320;&#21457;&#20986;&#19968;&#31181;&#26080;&#20559;&#12289;&#20302;&#26041;&#24046;&#21644;&#33258;&#21160;&#30340;&#26041;&#27861;&#23545;&#22797;&#26434;&#23494;&#24230;&#36827;&#34892;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545; MH &#37319;&#26679;&#22120;&#30340;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27010;&#29575;&#27169;&#22411;&#25512;&#29702;&#20013;&#65292;&#30446;&#26631;&#23494;&#24230;&#20989;&#25968;&#36890;&#24120;&#21464;&#24471;&#38590;&#20197;&#35745;&#31639;&#65292;&#38656;&#35201;&#20351;&#29992; Monte Carlo &#35745;&#31639;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#19981;&#20559;&#24494;&#20998; Metropolis-Hastings &#37319;&#26679;&#22120;&#30340;&#26041;&#27861;&#65292;&#20351;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#27010;&#29575;&#25512;&#29702;&#26469;&#36827;&#34892;&#24494;&#20998;&#12290;&#36890;&#36807;&#23558;&#38543;&#26426;&#24494;&#20998;&#30340;&#26368;&#26032;&#36827;&#23637;&#19982; Markov &#38142;&#32806;&#21512;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#23454;&#29616;&#26080;&#20559;&#65292;&#20302;&#26041;&#24046;&#21644;&#33258;&#21160;&#30340;&#31243;&#24207;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#24212;&#29992;&#20110;&#30001;&#20110;&#32321;&#29712;&#30340;&#30446;&#26631;&#23494;&#24230;&#23548;&#33268;&#26399;&#26395;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#25214;&#21040;&#19968;&#20010;&#27169;&#26865;&#20004;&#21487;&#30340;&#35266;&#23519;&#21644;&#22312; Ising &#27169;&#22411;&#20013;&#26368;&#22823;&#21270;&#27604;&#28909;&#26469;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
When performing inference on probabilistic models, target densities often become intractable, necessitating the use of Monte Carlo samplers. We develop a methodology for unbiased differentiation of the Metropolis-Hastings sampler, allowing us to differentiate through probabilistic inference. By fusing recent advances in stochastic differentiation with Markov chain coupling schemes, the procedure can be made unbiased, low-variance, and automatic. This allows us to apply gradient-based optimization to objectives expressed as expectations over intractable target densities. We demonstrate our approach by finding an ambiguous observation in a Gaussian mixture model and by maximizing the specific heat in an Ising model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;DFM&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#26631;&#31614;&#20559;&#31227;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#19978;&#38480;&#21644;&#40065;&#26834;&#24615;&#12290;&#20351;&#29992;&#22522;&#20110;&#26680;&#30340;DFM&#29256;&#26412;&#21487;&#20197;&#25552;&#39640;&#25928;&#29575;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.04376</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#29305;&#24449;&#21305;&#37197;&#30340;&#26631;&#31614;&#20559;&#31227;&#37327;&#37327;&#21270;&#21450;&#20854;&#40065;&#26834;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Label Shift Quantification with Robustness Guarantees via Distribution Feature Matching. (arXiv:2306.04376v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;DFM&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#26631;&#31614;&#20559;&#31227;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#19978;&#38480;&#21644;&#40065;&#26834;&#24615;&#12290;&#20351;&#29992;&#22522;&#20110;&#26680;&#30340;DFM&#29256;&#26412;&#21487;&#20197;&#25552;&#39640;&#25928;&#29575;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#23398;&#20064;&#22788;&#29702;&#22312;&#26631;&#31614;&#20559;&#31227;&#19979;&#20272;&#35745;&#30446;&#26631;&#26631;&#31614;&#20998;&#24067;&#30340;&#20219;&#21153;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#20998;&#24067;&#29305;&#24449;&#21305;&#37197;&#65288;DFM&#65289;&#65292;&#23558;&#20808;&#21069;&#25991;&#29486;&#20013;&#24341;&#20837;&#30340;&#21508;&#31181;&#20272;&#35745;&#22120;&#24674;&#22797;&#20026;&#29305;&#23450;&#23454;&#20363;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;DFM&#31243;&#24207;&#30340;&#19968;&#33324;&#24615;&#33021;&#30028;&#65292;&#25913;&#36827;&#20102;&#20808;&#21069;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#25512;&#23548;&#30340;&#30028;&#38480;&#30340;&#33509;&#24178;&#20851;&#38190;&#26041;&#38754;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#20998;&#26512;&#25193;&#23637;&#21040;&#30740;&#31350;DFM&#31243;&#24207;&#22312;&#26410;&#31934;&#30830;&#20551;&#35774;&#26631;&#31614;&#20559;&#31227;&#37327;&#30340;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#30446;&#26631;&#21463;&#21040;&#26410;&#30693;&#20998;&#24067;&#27745;&#26579;&#30340;&#24773;&#20917;&#19979;&#12290;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#35814;&#32454;&#30340;&#25968;&#23383;&#30740;&#31350;&#30830;&#35748;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#21407;&#29702;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#65292;&#21487;&#25193;&#23637;&#19988;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#22522;&#20110;&#26680;&#30340;DFM&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantification learning deals with the task of estimating the target label distribution under label shift. In this paper, we first present a unifying framework, distribution feature matching (DFM), that recovers as particular instances various estimators introduced in previous literature. We derive a general performance bound for DFM procedures, improving in several key aspects upon previous bounds derived in particular cases. We then extend this analysis to study robustness of DFM procedures in the misspecified setting under departure from the exact label shift hypothesis, in particular in the case of contamination of the target by an unknown distribution. These theoretical findings are confirmed by a detailed numerical study on simulated and real-world datasets. We also introduce an efficient, scalable and robust version of kernel-based DFM using the Random Fourier Feature principle.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#32447;&#24615;&#32422;&#26463;&#21327;&#26041;&#24046;&#30697;&#38453;&#21464;&#25442;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#20801;&#35768;&#30456;&#23545;&#31616;&#21333;&#30340;&#28176;&#36817;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#12290;&#30740;&#31350;&#30340;&#37325;&#28857;&#26159;&#20851;&#20110;&#24314;&#27169;&#30456;&#20851;&#30697;&#38453;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.03590</link><description>&lt;p&gt;
&#29109;&#21327;&#26041;&#24046;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Entropic covariance models. (arXiv:2306.03590v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#32447;&#24615;&#32422;&#26463;&#21327;&#26041;&#24046;&#30697;&#38453;&#21464;&#25442;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#20801;&#35768;&#30456;&#23545;&#31616;&#21333;&#30340;&#28176;&#36817;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#12290;&#30740;&#31350;&#30340;&#37325;&#28857;&#26159;&#20851;&#20110;&#24314;&#27169;&#30456;&#20851;&#30697;&#38453;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20013;&#65292;&#25214;&#21040;&#21512;&#36866;&#30340;&#27169;&#22411;&#21644;&#26377;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#39033;&#25361;&#25112;&#12290;&#25991;&#29486;&#20013;&#36890;&#24120;&#37319;&#29992;&#20004;&#31181;&#26041;&#27861;&#65292;&#19968;&#31181;&#26159;&#23545;&#21327;&#26041;&#24046;&#30697;&#38453;&#25110;&#20854;&#36870;&#26045;&#21152;&#32447;&#24615;&#32422;&#26463;&#65292;&#21478;&#19968;&#31181;&#26159;&#32771;&#34385;&#26045;&#21152;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#30697;&#38453;&#23545;&#25968;&#19978;&#30340;&#32447;&#24615;&#32422;&#26463;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#32447;&#24615;&#32422;&#26463;&#21327;&#26041;&#24046;&#30697;&#38453;&#21464;&#25442;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19978;&#36848;&#20363;&#23376;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#26041;&#27861;&#35299;&#20915;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#24182;&#20135;&#29983;&#20102;&#19968;&#20010;M&#20272;&#35745;&#37327;&#65292;&#20801;&#35768;&#30456;&#23545;&#31616;&#21333;&#30340;&#28176;&#36817;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#12290;&#22312;&#24320;&#21457;&#20102;&#19968;&#33324;&#29702;&#35770;&#20043;&#21518;&#65292;&#25105;&#20204;&#38598;&#20013;&#22312;&#24314;&#27169;&#30456;&#20851;&#30697;&#38453;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#12290;&#25105;&#20204;&#30340;&#20960;&#20309;&#27934;&#23519;&#21147;&#20801;&#35768;&#25105;&#20204;&#25193;&#23637;&#21327;&#26041;&#24046;&#30697;&#38453;&#24314;&#27169;&#20013;&#30340;&#19968;&#20123;&#26368;&#26032;&#32467;&#26524;&#12290;&#36825;&#21253;&#25324;&#25552;&#20379;&#30456;&#20851;&#30697;&#38453;&#31354;&#38388;&#30340;&#26080;&#38480;&#21046;&#21442;&#25968;&#21270;&#65292;&#36825;&#26159;&#19968;&#31181;&#26367;&#20195;&#21033;&#29992;&#21464;&#25442;&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23545;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;Cholesky&#22240;&#23376;&#26045;&#21152;&#31232;&#30095;&#24615;&#38480;&#21046;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
In covariance matrix estimation, one of the challenges lies in finding a suitable model and an efficient estimation method. Two commonly used approaches in the literature involve imposing linear restrictions on the covariance matrix or its inverse. Another approach considers linear restrictions on the matrix logarithm of the covariance matrix. In this paper, we present a general framework for linear restrictions on different transformations of the covariance matrix, including the mentioned examples. Our proposed estimation method solves a convex problem and yields an M-estimator, allowing for relatively straightforward asymptotic and finite sample analysis. After developing the general theory, we focus on modelling correlation matrices and on sparsity. Our geometric insights allow to extend various recent results in covariance matrix modelling. This includes providing unrestricted parametrizations of the space of correlation matrices, which is alternative to a recent result utilizing t
&lt;/p&gt;</description></item><item><title>MACE&#30340;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#26550;&#26500;&#22312;&#20869;&#22495;&#12289;&#22806;&#25512;&#21644;&#20302;&#25968;&#25454;&#33539;&#22260;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#22312;&#22788;&#29702;&#38750;&#26230;&#30899;&#12289;&#23567;&#20998;&#23376;&#26377;&#26426;&#21270;&#23398;&#12289;&#22823;&#20998;&#23376;&#21644;&#28082;&#24577;&#27700;&#31561;&#39046;&#22495;&#26102;&#24120;&#24120;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#12290;&#21363;&#20351;&#21482;&#26377;50&#20010;&#38543;&#26426;&#36873;&#23450;&#30340;&#21442;&#32771;&#37197;&#32622;&#65292;&#35813;&#27169;&#22411;&#20063;&#33021;&#38750;&#24120;&#39640;&#25928;&#22320;&#22797;&#29616;&#23454;&#39564;&#20998;&#23376;&#25391;&#21160;&#20809;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.14247</link><description>&lt;p&gt;
MACE&#21147;&#22330;&#26550;&#26500;&#30340;&#35780;&#20272;&#65306;&#20174;&#33647;&#29289;&#21270;&#23398;&#21040;&#26448;&#26009;&#31185;&#23398;
&lt;/p&gt;
&lt;p&gt;
Evaluation of the MACE Force Field Architecture: from Medicinal Chemistry to Materials Science. (arXiv:2305.14247v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14247
&lt;/p&gt;
&lt;p&gt;
MACE&#30340;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#26550;&#26500;&#22312;&#20869;&#22495;&#12289;&#22806;&#25512;&#21644;&#20302;&#25968;&#25454;&#33539;&#22260;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#31168;&#65292;&#22312;&#22788;&#29702;&#38750;&#26230;&#30899;&#12289;&#23567;&#20998;&#23376;&#26377;&#26426;&#21270;&#23398;&#12289;&#22823;&#20998;&#23376;&#21644;&#28082;&#24577;&#27700;&#31561;&#39046;&#22495;&#26102;&#24120;&#24120;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#12290;&#21363;&#20351;&#21482;&#26377;50&#20010;&#38543;&#26426;&#36873;&#23450;&#30340;&#21442;&#32771;&#37197;&#32622;&#65292;&#35813;&#27169;&#22411;&#20063;&#33021;&#38750;&#24120;&#39640;&#25928;&#22320;&#22797;&#29616;&#23454;&#39564;&#20998;&#23376;&#25391;&#21160;&#20809;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
MACE&#26550;&#26500;&#20195;&#34920;&#20102;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#30340;&#26368;&#26032;&#25216;&#26415;&#65292;&#33021;&#22815;&#22788;&#29702;&#20869;&#22495;&#12289;&#22806;&#25512;&#21644;&#20302;&#25968;&#25454;&#33539;&#22260;&#20219;&#21153;&#12290;&#26412;&#25991;&#23545;MACE&#36827;&#34892;&#20102;&#36827;&#19968;&#27493;&#35780;&#20272;&#65292;&#36890;&#36807;&#25311;&#21512;&#24050;&#21457;&#34920;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#27169;&#22411;&#26469;&#34920;&#26126;MACE&#22312;&#21508;&#31181;&#20307;&#31995;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#20854;&#20182;&#26367;&#20195;&#26041;&#26696;&#65292;&#21253;&#25324;&#38750;&#26230;&#30899;&#12289;&#19968;&#33324;&#30340;&#23567;&#20998;&#23376;&#26377;&#26426;&#21270;&#23398;&#12289;&#22823;&#20998;&#23376;&#21644;&#28082;&#24577;&#27700;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#33021;&#21147;&#65292;&#20174;&#32422;&#26463;&#20960;&#20309;&#20248;&#21270;&#21040;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#65292;&#21457;&#29616;&#20854;&#22312;&#25152;&#26377;&#27979;&#35797;&#39046;&#22495;&#37117;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#22312;&#20165;50&#20010;&#38543;&#26426;&#36873;&#23450;&#30340;&#21442;&#32771;&#37197;&#32622;&#19978;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;MACE&#21363;&#21487;&#38750;&#24120;&#39640;&#25928;&#22320;&#22797;&#29616;&#23454;&#39564;&#20998;&#23376;&#25391;&#21160;&#20809;&#35889;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#21363;&#20351;&#22312;&#22823;&#20998;&#23376;&#21644;&#24369;&#30456;&#20114;&#20316;&#29992;&#30340;&#20998;&#23376;&#32452;&#35013;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#22522;&#20110;&#20005;&#26684;&#23616;&#37096;&#30340;&#21407;&#23376;&#20013;&#24515;&#27169;&#22411;&#20063;&#26159;&#36275;&#22815;&#36866;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The MACE architecture represents the state of the art in the field of machine learning force fields for a variety of in-domain, extrapolation and low-data regime tasks. In this paper, we further evaluate MACE by fitting models for published benchmark datasets. We show that MACE generally outperforms alternatives for a wide range of systems from amorphous carbon and general small molecule organic chemistry to large molecules and liquid water. We demonstrate the capabilities of the model on tasks ranging from constrained geometry optimisation to molecular dynamics simulations and find excellent performance across all tested domains. We show that MACE is very data efficient, and can reproduce experimental molecular vibrational spectra when trained on as few as 50 randomly selected reference configurations. We further demonstrate that the strictly local atom-centered model is sufficient for such tasks even in the case of large molecules and weakly interacting molecular assemblies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#35686;&#31034;&#25925;&#20107;&#38416;&#37322;&#20102;&#20998;&#26512;&#25968;&#25454;&#26102;&#65292;&#27979;&#37327;&#20960;&#20309;&#21644;&#24213;&#23618;&#29616;&#35937;&#20960;&#20309;&#24046;&#24322;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#36825;&#31181;&#24046;&#24322;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22914;&#20309;&#23548;&#33268;&#23545;&#19968;&#20010;&#20462;&#27491;&#36807;&#30340;&#38382;&#39064;&#32473;&#20986;&#38169;&#35823;&#31572;&#26696;&#12290;&#36825;&#20123;&#38382;&#39064;&#36866;&#29992;&#20110;&#38477;&#32500;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2304.14248</link><description>&lt;p&gt;
&#20851;&#20110;&#27931;&#20811;&#26031;&#27934;&#31348;&#30340;&#27969;&#24418;&#23398;&#20064;&#65306;&#20851;&#20110;&#27969;&#24418;&#23398;&#20064;&#21644;&#29289;&#29702;&#29616;&#35937;&#30340;&#35780;&#35770;&#65288;arXiv:2304.14248v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
On Manifold Learning in Plato's Cave: Remarks on Manifold Learning and Physical Phenomena. (arXiv:2304.14248v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#35686;&#31034;&#25925;&#20107;&#38416;&#37322;&#20102;&#20998;&#26512;&#25968;&#25454;&#26102;&#65292;&#27979;&#37327;&#20960;&#20309;&#21644;&#24213;&#23618;&#29616;&#35937;&#20960;&#20309;&#24046;&#24322;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#36825;&#31181;&#24046;&#24322;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22914;&#20309;&#23548;&#33268;&#23545;&#19968;&#20010;&#20462;&#27491;&#36807;&#30340;&#38382;&#39064;&#32473;&#20986;&#38169;&#35823;&#31572;&#26696;&#12290;&#36825;&#20123;&#38382;&#39064;&#36866;&#29992;&#20110;&#38477;&#32500;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23581;&#35797;&#36890;&#36807;&#27979;&#37327;&#19981;&#38656;&#35201;&#23545;&#29289;&#29702;&#29616;&#35937;&#25110;&#27979;&#37327;&#35774;&#22791;&#36827;&#34892;&#26174;&#24335;&#24314;&#27169;&#30340;&#20302;&#32500;&#27969;&#24418;&#32467;&#26500;&#26469;&#25512;&#26029;&#28508;&#22312;&#29289;&#29702;&#29616;&#35937;&#30340;&#20302;&#32500;&#27969;&#24418;&#32467;&#26500;&#65292;&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#27979;&#37327;&#20960;&#20309;&#21644;&#24213;&#23618;&#29616;&#35937;&#20960;&#20309;&#20043;&#38388;&#24046;&#24322;&#30340;&#35686;&#31034;&#25925;&#20107;&#12290;&#22312;&#26222;&#36890;&#24773;&#20917;&#19979;&#65292;&#36825;&#31687;&#35770;&#25991;&#25152;&#23637;&#31034;&#30340;&#24230;&#37327;&#24418;&#21464;&#22312;&#25968;&#23398;&#19978;&#26159;&#30452;&#25509;&#32780;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#23427;&#21482;&#26159;&#25968;&#20010;&#31867;&#20284;&#25928;&#24212;&#20013;&#30340;&#19968;&#20010;&#12290;&#34429;&#28982;&#36825;&#24182;&#19981;&#24635;&#26159;&#20986;&#29616;&#38382;&#39064;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26631;&#20934;&#19988;&#26080;&#23475;&#25968;&#25454;&#22788;&#29702;&#36807;&#31243;&#30340;&#20363;&#23376;&#65292;&#20854;&#20013;&#36825;&#31181;&#24433;&#21709;&#23548;&#33268;&#23545;&#19968;&#20010;&#30475;&#20284;&#31616;&#21333;&#30340;&#38382;&#39064;&#32473;&#20986;&#20102;&#38169;&#35823;&#30340;&#31572;&#26696;&#12290;&#23613;&#31649;&#25105;&#20204;&#20851;&#27880;&#27969;&#24418;&#23398;&#20064;&#65292;&#20294;&#36825;&#20123;&#38382;&#39064;&#24191;&#27867;&#36866;&#29992;&#20110;&#38477;&#32500;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many techniques in machine learning attempt explicitly or implicitly to infer a low-dimensional manifold structure of an underlying physical phenomenon from measurements without an explicit model of the phenomenon or the measurement apparatus. This paper presents a cautionary tale regarding the discrepancy between the geometry of measurements and the geometry of the underlying phenomenon in a benign setting. The deformation in the metric illustrated in this paper is mathematically straightforward and unavoidable in the general case, and it is only one of several similar effects. While this is not always problematic, we provide an example of an arguably standard and harmless data processing procedure where this effect leads to an incorrect answer to a seemingly simple question. Although we focus on manifold learning, these issues apply broadly to dimensionality reduction and unsupervised learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#30340; uniform conformal inference &#31639;&#27861;&#65292;&#23454;&#29616;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2304.06158</link><description>&lt;p&gt;
&#20026;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#21518;&#36873;&#25512;&#29702;&#65306;&#26435;&#34913;&#31934;&#24230;&#21644;&#35206;&#30422;&#33539;&#22260;
&lt;/p&gt;
&lt;p&gt;
Post-selection Inference for Conformal Prediction: Trading off Coverage for Precision. (arXiv:2304.06158v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#30340; uniform conformal inference &#31639;&#27861;&#65292;&#23454;&#29616;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33268;&#24615;&#25512;&#29702;&#22312;&#20026;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#30340;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#31639;&#27861;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19978;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;&#20256;&#32479;&#19978;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#25512;&#29702;&#38656;&#35201;&#29420;&#31435;&#20110;&#25968;&#25454;&#30340;&#38169;&#35823;&#35206;&#30422;&#27700;&#24179;&#35268;&#33539;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#22312;&#35745;&#31639;&#20986;&#39044;&#27979;&#38598;&#20043;&#21518;&#26356;&#26032;&#38169;&#35823;&#35206;&#30422;&#27700;&#24179;&#12290;&#20363;&#22914;&#65292;&#22312;&#20108;&#20803;&#20998;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#20250;&#20174;&#19968;&#20010;95&#65285;&#30340;&#39044;&#27979;&#38598;&#24320;&#22987;&#65292;&#24182;&#21457;&#29616;&#22823;&#22810;&#25968;&#39044;&#27979;&#38598;&#21253;&#21547;&#25152;&#26377;&#36755;&#20986;&#31867;&#21035;&#12290;&#22914;&#26524;&#20004;&#20010;&#31867;&#21035;&#37117;&#19981;&#21487;&#21462;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#20250;&#32771;&#34385;80&#65285;&#30340;&#39044;&#27979;&#38598;&#12290;&#20855;&#26377;&#25968;&#25454;&#30456;&#20851;&#30340;&#35823;&#35206;&#30422;&#27700;&#24179;&#21644;&#20445;&#35777;&#35206;&#30422;&#33539;&#22260;&#30340;&#39044;&#27979;&#38598;&#30340;&#26500;&#24314;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#21518;&#36873;&#25512;&#29702;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26080;&#20998;&#24067;&#20449;&#36182;&#24102;&#65292;&#24320;&#21457;&#20102;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#35823;&#35206;&#30422;&#27700;&#24179;&#30340;&#26377;&#38480;&#26679;&#26412;&#39044;&#27979;&#20445;&#35777;&#30340;&#32479;&#19968;&#19968;&#33268;&#24615;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal inference has played a pivotal role in providing uncertainty quantification for black-box ML prediction algorithms with finite sample guarantees. Traditionally, conformal prediction inference requires a data-independent specification of miscoverage level. In practical applications, one might want to update the miscoverage level after computing the prediction set. For example, in the context of binary classification, the analyst might start with a $95\%$ prediction sets and see that most prediction sets contain all outcome classes. Prediction sets with both classes being undesirable, the analyst might desire to consider, say $80\%$ prediction set. Construction of prediction sets that guarantee coverage with data-dependent miscoverage level can be considered as a post-selection inference problem. In this work, we develop uniform conformal inference with finite sample prediction guarantee with arbitrary data-dependent miscoverage levels using distribution-free confidence bands f
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#22240;&#23376;&#21270;&#26041;&#27861;&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#21487;&#20197;&#25910;&#25947;&#65292;&#24182;&#19988;&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.14244</link><description>&lt;p&gt;
&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#65306;&#36807;&#21442;&#25968;&#21270;&#38750;&#23545;&#31216;&#30697;&#38453;&#24863;&#30693;&#20013;&#30340;&#27867;&#21270;&#21644;&#25910;&#25947;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing. (arXiv:2303.14244v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36807;&#21442;&#25968;&#21270;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#36890;&#36807;&#22240;&#23376;&#21270;&#26041;&#27861;&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#21487;&#20197;&#25910;&#25947;&#65292;&#24182;&#19988;&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#20110;&#35757;&#32451;&#36807;&#21442;&#25968;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#30340;&#25910;&#25947;&#21644;&#27867;&#21270;&#23646;&#24615;&#26377;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#20854;&#20013;&#35768;&#22810;&#26041;&#38754;&#65292;&#21253;&#25324;&#23567;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#35282;&#33394;&#20197;&#21450;&#27169;&#22411;&#30340;&#21508;&#31181;&#21442;&#25968;&#22312;&#26799;&#24230;&#26356;&#26032;&#20013;&#22914;&#20309;&#32806;&#21512;&#20197;&#20419;&#36827;&#33391;&#22909;&#30340;&#27867;&#21270;&#65292;&#20173;&#28982;&#26159;&#24456;&#31070;&#31192;&#30340;&#12290;&#26368;&#36817;&#19968;&#31995;&#21015;&#30340;&#35770;&#25991;&#24050;&#32463;&#24320;&#22987;&#30740;&#31350;&#38750;&#20984;&#23545;&#31216;&#21322;&#27491;&#23450;&#65288;PSD&#65289;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#30340;&#24418;&#24335;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#38656;&#35201;&#20174;&#20960;&#20010;&#32447;&#24615;&#27979;&#37327;&#20013;&#37325;&#24314;&#19968;&#20010;&#20302;&#31209;PSD&#30697;&#38453;&#12290;&#36825;&#31181;&#24213;&#23618;&#30340;&#23545;&#31216;&#24615;/PSD&#24615;&#23545;&#20110;&#29616;&#26377;&#30340;&#36825;&#20010;&#38382;&#39064;&#30340;&#25910;&#25947;&#21644;&#27867;&#21270;&#20445;&#35777;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#19968;&#33324;&#30340;&#36807;&#21442;&#25968;&#21270;&#30340;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#65292;&#20854;&#20013;&#24076;&#26395;&#20174;&#23569;&#37327;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#37325;&#24314;&#19968;&#20010;&#38750;&#23545;&#31216;&#30697;&#24418;&#20302;&#31209;&#30697;&#38453;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#22240;&#23376;&#21270;&#26469;&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#22312;&#36825;&#20010;&#38382;&#39064;&#19978;&#21487;&#20197;&#25910;&#25947;&#65292;&#32780;&#38544;&#24335;&#24179;&#34913;&#21644;&#27491;&#21017;&#21270;&#21487;&#20197;&#20419;&#36827;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been significant progress in understanding the convergence and generalization properties of gradient-based methods for training overparameterized learning models. However, many aspects including the role of small random initialization and how the various parameters of the model are coupled during gradient-based updates to facilitate good generalization remain largely mysterious. A series of recent papers have begun to study this role for non-convex formulations of symmetric Positive Semi-Definite (PSD) matrix sensing problems which involve reconstructing a low-rank PSD matrix from a few linear measurements. The underlying symmetry/PSDness is crucial to existing convergence and generalization guarantees for this problem. In this paper, we study a general overparameterized low-rank matrix sensing problem where one wishes to reconstruct an asymmetric rectangular low-rank matrix from a few linear measurements. We prove that an overparameterized model trained via factori
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#26680;&#24515;&#27979;&#35797;&#30340;&#39640;&#32500;U&#32479;&#35745;&#30340;&#25910;&#25947;&#23450;&#29702;&#65292;&#24182;&#21457;&#29616;U&#32479;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#20250;&#32463;&#21382;&#20174;&#38750;&#36864;&#21270;&#39640;&#26031;&#26497;&#38480;&#21040;&#36864;&#21270;&#26497;&#38480;&#30340;&#30456;&#21464;&#12290;&#36825;&#19968;&#29616;&#35937;&#23545;&#20110;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#38750;&#36864;&#21270;U&#32479;&#35745;&#20855;&#26377;&#36739;&#22823;&#26041;&#24046;&#21644;&#19981;&#23545;&#31216;&#20998;&#24067;&#30340;&#38750;&#39640;&#26031;&#26497;&#38480;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#30028;&#38480;&#36866;&#29992;&#20110;&#20219;&#20309;&#26377;&#38480;&#25968;&#37327;&#21644;&#32500;&#24230;&#30340;&#26679;&#26412;&#65292;&#19982;&#24213;&#23618;&#20989;&#25968;&#30340;&#29305;&#24449;&#20540;&#26080;&#20851;&#65292;&#24182;&#19988;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#19982;&#32500;&#24230;&#26080;&#20851;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#29702;&#35770;&#24212;&#29992;&#21040;&#20004;&#20010;&#24120;&#29992;&#30340;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#20998;&#24067;&#27979;&#35797;&#26041;&#27861;&#65292;MMD&#21644;KSD&#65292;&#26469;&#30740;&#31350;&#23427;&#20204;&#30340;&#39640;&#32500;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#27979;&#35797;&#21151;&#29575;&#22914;&#20309;&#19982;&#32500;&#24230;&#21644;&#24102;&#23485;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.05686</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#26680;&#24515;&#27979;&#35797;&#30340;U&#32479;&#35745;&#30340;&#39640;&#32500;&#25910;&#25947;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
A High-dimensional Convergence Theorem for U-statistics with Applications to Kernel-based Testing. (arXiv:2302.05686v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#26680;&#24515;&#27979;&#35797;&#30340;&#39640;&#32500;U&#32479;&#35745;&#30340;&#25910;&#25947;&#23450;&#29702;&#65292;&#24182;&#21457;&#29616;U&#32479;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#20250;&#32463;&#21382;&#20174;&#38750;&#36864;&#21270;&#39640;&#26031;&#26497;&#38480;&#21040;&#36864;&#21270;&#26497;&#38480;&#30340;&#30456;&#21464;&#12290;&#36825;&#19968;&#29616;&#35937;&#23545;&#20110;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#38750;&#36864;&#21270;U&#32479;&#35745;&#20855;&#26377;&#36739;&#22823;&#26041;&#24046;&#21644;&#19981;&#23545;&#31216;&#20998;&#24067;&#30340;&#38750;&#39640;&#26031;&#26497;&#38480;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#30028;&#38480;&#36866;&#29992;&#20110;&#20219;&#20309;&#26377;&#38480;&#25968;&#37327;&#21644;&#32500;&#24230;&#30340;&#26679;&#26412;&#65292;&#19982;&#24213;&#23618;&#20989;&#25968;&#30340;&#29305;&#24449;&#20540;&#26080;&#20851;&#65292;&#24182;&#19988;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#19982;&#32500;&#24230;&#26080;&#20851;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#29702;&#35770;&#24212;&#29992;&#21040;&#20004;&#20010;&#24120;&#29992;&#30340;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#20998;&#24067;&#27979;&#35797;&#26041;&#27861;&#65292;MMD&#21644;KSD&#65292;&#26469;&#30740;&#31350;&#23427;&#20204;&#30340;&#39640;&#32500;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#27979;&#35797;&#21151;&#29575;&#22914;&#20309;&#19982;&#32500;&#24230;&#21644;&#24102;&#23485;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;U&#32479;&#35745;&#30340;&#20108;&#27425;&#25910;&#25947;&#23450;&#29702;&#65292;&#20854;&#20013;&#25968;&#25454;&#32500;&#24230;$d$&#21487;&#20197;&#38543;&#26679;&#26412;&#22823;&#23567;$n$&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#19968;&#20010;U&#32479;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#20250;&#32463;&#21382;&#20174;&#38750;&#36864;&#21270;&#39640;&#26031;&#26497;&#38480;&#21040;&#36864;&#21270;&#26497;&#38480;&#30340;&#30456;&#21464;&#65292;&#19981;&#35770;&#20854;&#36864;&#21270;&#24615;&#22914;&#20309;&#65292;&#21482;&#21462;&#20915;&#20110;&#19968;&#20010;&#30697;&#27604;&#29575;&#12290;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#26159;&#65292;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#38750;&#36864;&#21270;&#30340;U&#32479;&#35745;&#21487;&#33021;&#20855;&#26377;&#19968;&#20010;&#20855;&#26377;&#36739;&#22823;&#26041;&#24046;&#21644;&#19981;&#23545;&#31216;&#20998;&#24067;&#30340;&#38750;&#39640;&#26031;&#26497;&#38480;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#23545;&#20219;&#20309;&#26377;&#38480;&#30340;$n$&#21644;$d$&#37117;&#26159;&#26377;&#25928;&#30340;&#65292;&#19982;&#24213;&#23618;&#20989;&#25968;&#30340;&#20010;&#21035;&#29305;&#24449;&#20540;&#26080;&#20851;&#65292;&#24182;&#19988;&#22312;&#19968;&#20010;&#36866;&#24230;&#30340;&#20551;&#35774;&#19979;&#19982;&#32500;&#24230;&#26080;&#20851;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#29702;&#35770;&#24212;&#29992;&#21040;&#20004;&#20010;&#27969;&#34892;&#30340;&#22522;&#20110;&#26680;&#24515;&#30340;&#20998;&#24067;&#27979;&#35797;&#65292;MMD&#21644;KSD&#19978;&#65292;&#36825;&#20123;&#27979;&#35797;&#22312;&#39640;&#32500;&#24615;&#33021;&#30340;&#30740;&#31350;&#19968;&#30452;&#26159;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#19968;&#20010;&#31616;&#21333;&#30340;&#32463;&#39564;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#27491;&#30830;&#22320;&#39044;&#27979;&#20102;&#22312;&#22266;&#23450;&#38408;&#20540;&#19979;&#27979;&#35797;&#21151;&#29575;&#22914;&#20309;&#38543;&#30528;$d$&#21644;&#24102;&#23485;&#30340;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a convergence theorem for U-statistics of degree two, where the data dimension $d$ is allowed to scale with sample size $n$. We find that the limiting distribution of a U-statistic undergoes a phase transition from the non-degenerate Gaussian limit to the degenerate limit, regardless of its degeneracy and depending only on a moment ratio. A surprising consequence is that a non-degenerate U-statistic in high dimensions can have a non-Gaussian limit with a larger variance and asymmetric distribution. Our bounds are valid for any finite $n$ and $d$, independent of individual eigenvalues of the underlying function, and dimension-independent under a mild assumption. As an application, we apply our theory to two popular kernel-based distribution tests, MMD and KSD, whose high-dimensional performance has been challenging to study. In a simple empirical setting, our results correctly predict how the test power at a fixed threshold scales with $d$ and the bandwidth.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#25945;&#24072;&#35757;&#32451;&#30340;&#23494;&#38598;Hebbian&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#33021;&#21147;&#65292;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#21644;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#24471;&#21040;&#20102;&#19968;&#20010;&#30456;&#22270;&#65292;&#25351;&#20986;&#36825;&#20123;&#32593;&#32476;&#22312;&#22823;&#35268;&#27169;&#21644;&#32467;&#26500;&#31616;&#21333;&#30340;&#25968;&#25454;&#38598;&#19979;&#21487;&#20197;&#22312;&#36229;&#22823;&#23384;&#20648;&#25110;&#36229;&#39640;&#26816;&#27979;&#21306;&#22495;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2212.00606</link><description>&lt;p&gt;
&#23494;&#38598;&#24335;Hebbian&#31070;&#32463;&#32593;&#32476;&#65306;&#30417;&#30563;&#23398;&#20064;&#30340;&#23545;&#31216;&#22270;&#29255;
&lt;/p&gt;
&lt;p&gt;
Dense Hebbian neural networks: a replica symmetric picture of supervised learning. (arXiv:2212.00606v2 [cond-mat.dis-nn] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00606
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#25945;&#24072;&#35757;&#32451;&#30340;&#23494;&#38598;Hebbian&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#33021;&#21147;&#65292;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#21644;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#24471;&#21040;&#20102;&#19968;&#20010;&#30456;&#22270;&#65292;&#25351;&#20986;&#36825;&#20123;&#32593;&#32476;&#22312;&#22823;&#35268;&#27169;&#21644;&#32467;&#26500;&#31616;&#21333;&#30340;&#25968;&#25454;&#38598;&#19979;&#21487;&#20197;&#22312;&#36229;&#22823;&#23384;&#20648;&#25110;&#36229;&#39640;&#26816;&#27979;&#21306;&#22495;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#30001;&#25945;&#24072;&#65288;&#21363;&#30417;&#30563;&#23398;&#20064;&#65289;&#35757;&#32451;&#30340;&#23494;&#38598;&#30340;&#20851;&#32852;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#36890;&#36807;&#33258;&#26059;&#29627;&#29827;&#30340;&#32479;&#35745;&#21147;&#23398;&#20998;&#26512;&#21644;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#26469;&#30740;&#31350;&#23427;&#20204;&#30340;&#35745;&#31639;&#33021;&#21147;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#30456;&#22270;&#65292;&#24635;&#32467;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#22914;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#36136;&#37327;&#21644;&#25968;&#37327;&#12289;&#32593;&#32476;&#23384;&#20648;&#21644;&#22122;&#22768;&#31561;&#25511;&#21046;&#21442;&#25968;&#30340;&#20989;&#25968;&#65292;&#36825;&#22312;&#32593;&#32476;&#23610;&#23544;&#22823;&#12289;&#25968;&#25454;&#38598;&#32467;&#26500;&#31616;&#21333;&#30340;&#26497;&#38480;&#19979;&#26159;&#26377;&#25928;&#30340;&#65306;&#36825;&#20123;&#32593;&#32476;&#21487;&#20197;&#22312;&#36229;&#22823;&#23384;&#20648;&#21306;&#22495;&#24037;&#20316;&#65288;&#19982;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30456;&#27604;&#65292;&#23427;&#20204;&#21487;&#20197;&#22788;&#29702;&#22823;&#37327;&#30340;&#27169;&#24335;&#65289;&#65292;&#25110;&#32773;&#22312;&#36229;&#39640;&#26816;&#27979;&#21306;&#22495;&#24037;&#20316;&#65288;&#19982;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30456;&#27604;&#65292;&#23427;&#20204;&#21487;&#20197;&#22312;&#26497;&#20302;&#30340;&#20449;&#22122;&#27604;&#19979;&#36827;&#34892;&#27169;&#24335;&#35782;&#21035;&#65289;&#12290;&#22312;&#20197;&#38543;&#26426;&#29702;&#35770;&#20316;&#20026;&#21442;&#32771;&#26694;&#26550;&#30340;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#36824;&#23545;&#36825;&#20123;&#32593;&#32476;&#22312;&#32467;&#26500;&#21270;&#25968;&#25454;&#38598;&#65288;&#22914;MNist&#65289;&#19978;&#23637;&#31034;&#30340;&#23398;&#20064;&#12289;&#23384;&#20648;&#21644;&#26816;&#32034;&#33021;&#21147;&#36827;&#34892;&#20102;&#25968;&#20540;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider dense, associative neural-networks trained by a teacher (i.e., with supervision) and we investigate their computational capabilities analytically, via statistical-mechanics of spin glasses, and numerically, via Monte Carlo simulations. In particular, we obtain a phase diagram summarizing their performance as a function of the control parameters such as quality and quantity of the training dataset, network storage and noise, that is valid in the limit of large network size and structureless datasets: these networks may work in a ultra-storage regime (where they can handle a huge amount of patterns, if compared with shallow neural networks) or in a ultra-detection regime (where they can perform pattern recognition at prohibitive signal-to-noise ratios, if compared with shallow neural networks). Guided by the random theory as a reference framework, we also test numerically learning, storing and retrieval capabilities shown by these networks on structured datasets as MNist and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#30417;&#30563;&#35757;&#32451;&#30340;&#23494;&#38598;&#36154;&#32500;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#26041;&#27861;&#21644;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#20998;&#26512;&#20102;&#20854;&#35745;&#31639;&#33021;&#21147;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#30456;&#22270;&#65292;&#24635;&#32467;&#20102;&#32593;&#32476;&#24615;&#33021;&#19982;&#35757;&#32451;&#25968;&#25454;&#38598;&#36136;&#37327;&#12289;&#25968;&#37327;&#21644;&#32593;&#32476;&#23384;&#20648;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#35745;&#21147;&#23398;&#20013;&#30340;&#23439;&#35266;&#21487;&#35266;&#27979;&#37327;&#19982;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2211.14067</link><description>&lt;p&gt;
&#23494;&#38598;&#30340;&#36154;&#32500;&#27169;&#22411;&#31070;&#32463;&#32593;&#32476;&#65306;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23545;&#31216;&#21103;&#26412;&#25551;&#36848;
&lt;/p&gt;
&lt;p&gt;
Dense Hebbian neural networks: a replica symmetric picture of unsupervised learning. (arXiv:2211.14067v2 [cond-mat.dis-nn] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#30417;&#30563;&#35757;&#32451;&#30340;&#23494;&#38598;&#36154;&#32500;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#26041;&#27861;&#21644;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#20998;&#26512;&#20102;&#20854;&#35745;&#31639;&#33021;&#21147;&#12290;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#30456;&#22270;&#65292;&#24635;&#32467;&#20102;&#32593;&#32476;&#24615;&#33021;&#19982;&#35757;&#32451;&#25968;&#25454;&#38598;&#36136;&#37327;&#12289;&#25968;&#37327;&#21644;&#32593;&#32476;&#23384;&#20648;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#35745;&#21147;&#23398;&#20013;&#30340;&#23439;&#35266;&#21487;&#35266;&#27979;&#37327;&#19982;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#30417;&#30563;&#35757;&#32451;&#30340;&#23494;&#38598;&#20851;&#32852;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#21147;&#23398;&#26041;&#27861;&#21644;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#36827;&#34892;&#20102;&#35745;&#31639;&#33021;&#21147;&#30340;&#20998;&#26512;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;&#22823;&#32593;&#32476;&#35268;&#27169;&#21644;&#26080;&#32467;&#26500;&#25968;&#25454;&#38598;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#33719;&#24471;&#20102;&#19968;&#20010;&#30456;&#22270;&#65292;&#24635;&#32467;&#20102;&#32593;&#32476;&#24615;&#33021;&#19982;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#36136;&#37327;&#12289;&#25968;&#37327;&#20197;&#21450;&#32593;&#32476;&#23384;&#20648;&#31561;&#25511;&#21046;&#21442;&#25968;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#32479;&#35745;&#21147;&#23398;&#20013;&#24120;&#29992;&#30340;&#23439;&#35266;&#21487;&#35266;&#27979;&#37327;&#19982;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#22312;&#25216;&#26415;&#19978;&#65292;&#20174;&#35299;&#26512;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#36816;&#29992;Guerra&#30340;&#25554;&#20540;&#23454;&#29616;&#20102;&#22823;&#20559;&#24046;&#21644;&#31283;&#23450;&#24615;&#20998;&#26512;&#65292;&#29992;&#20110;&#22788;&#29702;&#19982;&#31361;&#35302;&#21518;&#30005;&#20301;&#30456;&#20851;&#30340;&#38750;&#39640;&#26031;&#20998;&#24067;&#65307;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#23558;Plefka&#36817;&#20284;&#25554;&#20837;&#21040;&#33945;&#29305;&#21345;&#27931;&#26041;&#26696;&#20013;&#65292;&#20197;&#21152;&#36895;&#31361;&#35302;&#24378;&#24230;&#30340;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider dense, associative neural-networks trained with no supervision and we investigate their computational capabilities analytically, via a statistical-mechanics approach, and numerically, via Monte Carlo simulations. In particular, we obtain a phase diagram summarizing their performance as a function of the control parameters such as the quality and quantity of the training dataset and the network storage, valid in the limit of large network size and structureless datasets. Moreover, we establish a bridge between macroscopic observables standardly used in statistical mechanics and loss functions typically used in the machine learning. As technical remarks, from the analytic side, we implement large deviations and stability analysis within Guerra's interpolation to tackle the not-Gaussian distributions involved in the post-synaptic potentials while, from the computational counterpart, we insert Plefka approximation in the Monte Carlo scheme, to speed up the evaluation of the syn
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;&#24179;&#28369;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#30340;&#29420;&#31435;&#21644;&#20381;&#36182;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#26500;&#24314;&#20102;&#32622;&#20449;&#21306;&#38388;&#24182;&#36827;&#34892;&#20102;&#25512;&#26029;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#28176;&#36817;&#32467;&#26524;&#12290;&#24212;&#29992;&#20013;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#36710;&#36742;&#20215;&#26684;&#12290;</title><link>http://arxiv.org/abs/2211.13289</link><description>&lt;p&gt;
Shapley&#26354;&#32447;&#65306;&#19968;&#31181;&#24179;&#28369;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Shapley Curves: A Smoothing Perspective. (arXiv:2211.13289v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13289
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#24179;&#28369;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#30340;&#29420;&#31435;&#21644;&#20381;&#36182;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#26500;&#24314;&#20102;&#32622;&#20449;&#21306;&#38388;&#24182;&#36827;&#34892;&#20102;&#25512;&#26029;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#28176;&#36817;&#32467;&#26524;&#12290;&#24212;&#29992;&#20013;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#36710;&#36742;&#20215;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28304;&#33258;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#65292;Shapley&#20540;&#24050;&#25104;&#20026;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#24230;&#37327;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23545;Shapley&#20540;&#30340;&#32479;&#35745;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#20197;&#38750;&#21442;&#25968;(&#25110;&#24179;&#28369;)&#30340;&#35282;&#24230;&#65292;&#24341;&#20837;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#29420;&#31435;&#21644;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#37117;&#24471;&#20986;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#24182;&#23545;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#36827;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#37326;&#34542;&#24341;&#23548;&#31243;&#24207;&#29256;&#26412;&#65292;&#19987;&#38376;&#35843;&#25972;&#20197;&#33719;&#24471;Shapley&#26354;&#32447;&#30340;&#33391;&#22909;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#12290;&#28176;&#36817;&#32467;&#26524;&#22312;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;&#12290;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#20102;&#36710;&#36742;&#30340;&#20215;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;
Originating from cooperative game theory, Shapley values have become one of the most widely used measures for variable importance in applied Machine Learning. However, the statistical understanding of Shapley values is still limited. In this paper, we take a nonparametric (or smoothing) perspective by introducing Shapley curves as a local measure of variable importance. We propose two estimation strategies and derive the consistency and asymptotic normality both under independence and dependence among the features. This allows us to construct confidence intervals and conduct inference on the estimated Shapley curves. We propose a novel version of the wild bootstrap procedure, specifically adjusted to give good finite sample coverage of the Shapley curves. The asymptotic results are validated in extensive experiments. In an empirical application, we analyze which attributes drive the prices of vehicles.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20915;&#31574;&#20219;&#21153;&#65292;&#20027;&#21160;&#33719;&#21462;&#22810;&#27169;&#24577;&#26102;&#38388;&#25968;&#25454;&#12290;&#36890;&#36807;&#26435;&#34913;&#33719;&#21462;&#25104;&#26412;&#21644;&#39044;&#27979;&#24615;&#33021;&#65292;&#23398;&#20064;&#20195;&#29702;&#31243;&#24207;&#26469;&#20027;&#21160;&#36873;&#25321;&#33719;&#21462;&#30340;&#36755;&#20837;&#27169;&#24577;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#35299;&#20915;&#20855;&#26377;&#23454;&#38469;&#30456;&#20851;&#25512;&#29702;&#25216;&#33021;&#30340;&#21512;&#25104;&#24773;&#26223;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#23398;&#20064;&#21040;&#25104;&#26412;&#21453;&#24212;&#24335;&#30340;&#33719;&#21462;&#34892;&#20026;&#65292;&#20294;&#26080;&#27861;&#23398;&#20064;&#21040;&#33258;&#36866;&#24212;&#30340;&#33719;&#21462;&#31574;&#30053;&#65292;&#31361;&#26174;&#20102;&#20219;&#21153;&#30340;&#22256;&#38590;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.05039</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#26102;&#38388;&#25968;&#25454;&#30340;&#20027;&#21160;&#33719;&#21462;&#65306;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20915;&#31574;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Active Acquisition for Multimodal Temporal Data: A Challenging Decision-Making Task. (arXiv:2211.05039v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05039
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20915;&#31574;&#20219;&#21153;&#65292;&#20027;&#21160;&#33719;&#21462;&#22810;&#27169;&#24577;&#26102;&#38388;&#25968;&#25454;&#12290;&#36890;&#36807;&#26435;&#34913;&#33719;&#21462;&#25104;&#26412;&#21644;&#39044;&#27979;&#24615;&#33021;&#65292;&#23398;&#20064;&#20195;&#29702;&#31243;&#24207;&#26469;&#20027;&#21160;&#36873;&#25321;&#33719;&#21462;&#30340;&#36755;&#20837;&#27169;&#24577;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#35299;&#20915;&#20855;&#26377;&#23454;&#38469;&#30456;&#20851;&#25512;&#29702;&#25216;&#33021;&#30340;&#21512;&#25104;&#24773;&#26223;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#25104;&#21151;&#23398;&#20064;&#21040;&#25104;&#26412;&#21453;&#24212;&#24335;&#30340;&#33719;&#21462;&#34892;&#20026;&#65292;&#20294;&#26080;&#27861;&#23398;&#20064;&#21040;&#33258;&#36866;&#24212;&#30340;&#33719;&#21462;&#31574;&#30053;&#65292;&#31361;&#26174;&#20102;&#20219;&#21153;&#30340;&#22256;&#38590;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20915;&#31574;&#20219;&#21153;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22810;&#27169;&#24577;&#26102;&#38388;&#25968;&#25454;&#30340;&#20027;&#21160;&#33719;&#21462;&#65288;A2MT&#65289;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#36755;&#20837;&#29305;&#24449;&#22312;&#27979;&#35797;&#26102;&#19981;&#23481;&#26131;&#33719;&#24471;&#65292;&#24517;&#39035;&#20197;&#36739;&#22823;&#20195;&#20215;&#33719;&#21462;&#12290;&#36890;&#36807;A2MT&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#20195;&#29702;&#31243;&#24207;&#65292;&#20351;&#20854;&#33021;&#22815;&#20027;&#21160;&#36873;&#25321;&#35201;&#33719;&#21462;&#30340;&#36755;&#20837;&#27169;&#24577;&#65292;&#26435;&#34913;&#33719;&#21462;&#25104;&#26412;&#19982;&#39044;&#27979;&#24615;&#33021;&#12290;A2MT&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#20219;&#21153;&#65292;&#31216;&#20026;&#20027;&#21160;&#29305;&#24449;&#33719;&#21462;&#65292;&#20197;&#20415;&#36827;&#34892;&#20851;&#20110;&#39640;&#32500;&#36755;&#20837;&#30340;&#26102;&#38388;&#20915;&#31574;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Perceiver IO&#26550;&#26500;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;A2MT&#12290;&#25105;&#20204;&#30340;&#20195;&#29702;&#31243;&#24207;&#33021;&#22815;&#35299;&#20915;&#19968;&#20010;&#38656;&#35201;&#23454;&#38469;&#30456;&#20851;&#30340;&#36328;&#27169;&#24577;&#25512;&#29702;&#25216;&#33021;&#30340;&#26032;&#39062;&#21512;&#25104;&#24773;&#26223;&#12290;&#22312;&#20004;&#20010;&#22823;&#35268;&#27169;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;Kinetics-700&#21644;AudioSet&#19978;&#65292;&#25105;&#20204;&#30340;&#20195;&#29702;&#31243;&#24207;&#25104;&#21151;&#22320;&#23398;&#20064;&#20102;&#25104;&#26412;&#21453;&#24212;&#24335;&#30340;&#33719;&#21462;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#28040;&#34701;&#23454;&#39564;&#34920;&#26126;&#23427;&#20204;&#26080;&#27861;&#23398;&#20064;&#21040;&#33258;&#36866;&#24212;&#30340;&#33719;&#21462;&#31574;&#30053;&#65292;&#31361;&#26174;&#20102;&#35813;&#20219;&#21153;&#30340;&#22256;&#38590;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a challenging decision-making task that we call active acquisition for multimodal temporal data (A2MT). In many real-world scenarios, input features are not readily available at test time and must instead be acquired at significant cost. With A2MT, we aim to learn agents that actively select which modalities of an input to acquire, trading off acquisition cost and predictive performance. A2MT extends a previous task called active feature acquisition to temporal decision making about high-dimensional inputs. We propose a method based on the Perceiver IO architecture to address A2MT in practice. Our agents are able to solve a novel synthetic scenario requiring practically relevant cross-modal reasoning skills. On two large-scale, real-world datasets, Kinetics-700 and AudioSet, our agents successfully learn cost-reactive acquisition behavior. However, an ablation reveals they are unable to learn adaptive acquisition strategies, emphasizing the difficulty of the task even for 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#31070;&#32463;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;Neural EKF&#65289;&#30340;&#21487;&#23398;&#20064;&#21345;&#23572;&#26364;&#28388;&#27874;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#22797;&#26434;&#29289;&#29702;&#31995;&#32479;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#21147;&#23398;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#26469;&#23398;&#20064;&#36807;&#31243;&#21160;&#21147;&#23398;&#21644;&#20256;&#24863;&#35266;&#27979;&#30340;&#24314;&#27169;&#65292;&#25552;&#39640;&#32467;&#26500;&#21709;&#24212;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.04165</link><description>&lt;p&gt;
&#31070;&#32463;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#29992;&#20110;&#23398;&#20064;&#21644;&#39044;&#27979;&#32467;&#26500;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Neural Extended Kalman Filters for Learning and Predicting Dynamics of Structural Systems. (arXiv:2210.04165v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#31070;&#32463;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;Neural EKF&#65289;&#30340;&#21487;&#23398;&#20064;&#21345;&#23572;&#26364;&#28388;&#27874;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#22797;&#26434;&#29289;&#29702;&#31995;&#32479;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#21147;&#23398;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#26469;&#23398;&#20064;&#36807;&#31243;&#21160;&#21147;&#23398;&#21644;&#20256;&#24863;&#35266;&#27979;&#30340;&#24314;&#27169;&#65292;&#25552;&#39640;&#32467;&#26500;&#21709;&#24212;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#32467;&#26500;&#21709;&#24212;&#39044;&#27979;&#26159;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#21644;&#25511;&#21046;&#24212;&#29992;&#30340;&#20027;&#35201;&#39537;&#21160;&#21147;&#12290;&#36825;&#24448;&#24448;&#38656;&#35201;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#20805;&#20998;&#25429;&#25417;&#22797;&#26434;&#32467;&#26500;&#31995;&#32479;&#30340;&#22522;&#26412;&#21160;&#21147;&#23398;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#21487;&#23398;&#20064;&#30340;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;&#31216;&#20026;&#31070;&#32463;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65289;&#26469;&#23398;&#20064;&#22797;&#26434;&#29289;&#29702;&#31995;&#32479;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#21147;&#23398;&#12290;&#31070;&#32463;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#26159;&#20256;&#32479;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#20854;&#20013;&#36807;&#31243;&#21160;&#21147;&#23398;&#21644;&#20256;&#24863;&#35266;&#27979;&#30340;&#24314;&#27169;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#65292;&#22240;&#27492;&#21487;&#20197;&#36890;&#36807;&#31471;&#21040;&#31471;&#35757;&#32451;&#26469;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#22312;&#21464;&#20998;&#25512;&#29702;&#26694;&#26550;&#19979;&#23454;&#29616;&#65292;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#36890;&#36807;&#24863;&#30693;&#27979;&#37327;&#36827;&#34892;&#25512;&#29702;&#12290;&#36890;&#24120;&#65292;&#20256;&#32479;&#30340;&#21464;&#20998;&#25512;&#29702;&#27169;&#22411;&#30340;&#21442;&#25968;&#26159;&#29420;&#31435;&#20110;&#28508;&#22312;&#21160;&#21147;&#23398;&#27169;&#22411;&#30340;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#12290;&#36825;&#31181;&#29305;&#28857;&#20351;&#24471;&#25512;&#29702;&#21644;&#37325;&#26500;&#30340;&#20934;&#30830;&#24615;&#30456;&#23545;&#36739;&#24369;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate structural response prediction forms a main driver for structural health monitoring and control applications. This often requires the proposed model to adequately capture the underlying dynamics of complex structural systems. In this work, we utilize a learnable Extended Kalman Filter (EKF), named the Neural Extended Kalman Filter (Neural EKF) throughout this paper, for learning the latent evolution dynamics of complex physical systems. The Neural EKF is a generalized version of the conventional EKF, where the modeling of process dynamics and sensory observations can be parameterized by neural networks, therefore learned by end-to-end training. The method is implemented under the variational inference framework with the EKF conducting inference from sensing measurements. Typically, conventional variational inference models are parameterized by neural networks independent of the latent dynamics models. This characteristic makes the inference and reconstruction accuracy weakly b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;Vendi&#20998;&#25968;&#65292;&#23427;&#33021;&#22815;&#28789;&#27963;&#22320;&#34913;&#37327;&#19981;&#21516;&#24418;&#24335;&#30340;&#22810;&#26679;&#24615;&#65292;&#32780;&#19988;&#19981;&#38656;&#35201;&#21442;&#32771;&#25968;&#25454;&#38598;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#29983;&#25104;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2210.02410</link><description>&lt;p&gt;
The Vendi&#20998;&#25968;: &#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
The Vendi Score: A Diversity Evaluation Metric for Machine Learning. (arXiv:2210.02410v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.02410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#22810;&#26679;&#24615;&#35780;&#20272;&#25351;&#26631;Vendi&#20998;&#25968;&#65292;&#23427;&#33021;&#22815;&#28789;&#27963;&#22320;&#34913;&#37327;&#19981;&#21516;&#24418;&#24335;&#30340;&#22810;&#26679;&#24615;&#65292;&#32780;&#19988;&#19981;&#38656;&#35201;&#21442;&#32771;&#25968;&#25454;&#38598;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#29983;&#25104;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26679;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#20013;&#35768;&#22810;&#39046;&#22495;&#30340;&#37325;&#35201;&#26631;&#20934;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#25968;&#25454;&#38598;&#31574;&#21010;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#34913;&#37327;&#22810;&#26679;&#24615;&#30340;&#25351;&#26631;&#24448;&#24448;&#26159;&#38024;&#23545;&#29305;&#23450;&#39046;&#22495;&#30340;&#65292;&#24182;&#19988;&#28789;&#27963;&#24615;&#26377;&#38480;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;Vendi&#20998;&#25968;&#26469;&#35299;&#20915;&#22810;&#26679;&#24615;&#35780;&#20272;&#38382;&#39064;&#65292;&#35813;&#25351;&#26631;&#23558;&#29983;&#24577;&#23398;&#21644;&#37327;&#23376;&#32479;&#35745;&#21147;&#23398;&#30340;&#24605;&#24819;&#19982;ML&#30456;&#32467;&#21512;&#24182;&#36827;&#34892;&#25193;&#23637;&#12290;Vendi&#20998;&#25968;&#23450;&#20041;&#20026;&#30456;&#20284;&#24615;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#30340;&#39321;&#20892;&#29109;&#30340;&#25351;&#25968;&#20989;&#25968;&#12290;&#36825;&#20010;&#30697;&#38453;&#26159;&#30001;&#29992;&#25143;&#23450;&#20041;&#30340;&#30456;&#20284;&#24615;&#20989;&#25968;&#24212;&#29992;&#20110;&#35201;&#35780;&#20272;&#22810;&#26679;&#24615;&#30340;&#26679;&#26412;&#32780;&#35825;&#23548;&#20986;&#30340;&#12290;&#36890;&#36807;&#20351;&#29992;&#30456;&#20284;&#24615;&#20989;&#25968;&#20316;&#20026;&#36755;&#20837;&#65292;Vendi&#20998;&#25968;&#20351;&#29992;&#25143;&#33021;&#22815;&#25351;&#23450;&#20219;&#20309;&#25152;&#38656;&#30340;&#22810;&#26679;&#24615;&#24418;&#24335;&#12290;&#19982;ML&#20013;&#30340;&#35768;&#22810;&#29616;&#26377;&#25351;&#26631;&#19981;&#21516;&#65292;Vendi&#20998;&#25968;&#19981;&#38656;&#35201;&#21442;&#32771;&#25968;&#25454;&#38598;&#25110;&#26679;&#26412;&#25110;&#26631;&#31614;&#30340;&#20998;&#24067;&#65292;&#22240;&#27492;&#23427;&#36890;&#29992;&#19988;&#36866;&#29992;&#20110;&#20219;&#20309;&#29983;&#25104;&#27169;&#22411;&#12289;&#35299;&#30721;&#31639;&#27861;&#21644;&#26469;&#33258;&#20219;&#20309;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper, we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ML. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#65292;&#20351;&#24471;&#21363;&#20351;&#24178;&#25200;&#20989;&#25968;&#26159;&#24369;&#26631;&#35782;&#30340;&#65292;&#20063;&#21487;&#20197;&#23545;&#21151;&#33021;&#36827;&#34892;&#24378;&#26631;&#35782;&#24182;&#36827;&#34892;&#25512;&#29702;&#12290;</title><link>http://arxiv.org/abs/2208.08291</link><description>&lt;p&gt;
&#20851;&#20110;&#24369;&#26631;&#35782;&#20989;&#25968;&#30340;&#24378;&#26631;&#35782;&#21151;&#33021;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Inference on Strongly Identified Functionals of Weakly Identified Functions. (arXiv:2208.08291v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08291
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#65292;&#20351;&#24471;&#21363;&#20351;&#24178;&#25200;&#20989;&#25968;&#26159;&#24369;&#26631;&#35782;&#30340;&#65292;&#20063;&#21487;&#20197;&#23545;&#21151;&#33021;&#36827;&#34892;&#24378;&#26631;&#35782;&#24182;&#36827;&#34892;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#65292;&#21253;&#25324;&#38750;&#21442;&#25968;&#24037;&#20855;&#21464;&#37327;(NPIV)&#20998;&#26512;&#12289;&#26410;&#27979;&#21040;&#28151;&#28102;&#19979;&#30340;&#36817;&#22240;&#26524;&#25512;&#29702;&#21644;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#19982;&#38544;&#34255;&#21464;&#37327;&#65292;&#25105;&#20204;&#23545;&#26465;&#20214;&#30697;&#38480;&#21046;&#23450;&#20041;&#30340;&#24178;&#25200;&#20989;&#25968;(&#20363;&#22914;&#24179;&#22343;&#22240;&#26524;&#25928;&#24212;)&#36827;&#34892;&#25512;&#29702;&#12290;&#36825;&#20123;&#24178;&#25200;&#20989;&#25968;&#36890;&#24120;&#26159;&#24369;&#26631;&#35782;&#30340;&#65292;&#21363;&#26465;&#20214;&#30697;&#38480;&#21046;&#21487;&#20197;&#20005;&#37325;&#19981;&#33391;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#26377;&#22810;&#20010;&#35299;&#12290;&#26377;&#26102;&#65292;&#36890;&#36807;&#26045;&#21152;&#33021;&#22815;&#20351;&#20989;&#25968;&#20197;&#20351;&#20851;&#20110;&#21151;&#33021;&#30340;&#25512;&#29702;&#25104;&#20026;&#21487;&#33021;&#30340;&#36895;&#29575;&#26469;&#20272;&#35745;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#65292;&#29992;&#20110;&#21151;&#33021;&#30340;&#24378;&#26631;&#35782;&#65292;&#21363;&#20351;&#24178;&#25200;&#20989;&#25968;&#19981;&#26159;&#65307;&#20063;&#23601;&#26159;&#35828;&#65292;&#21151;&#33021;&#21487;&#20197;&#20197;$\sqrt{n}$&#30340;&#36895;&#29575;&#36827;&#34892;&#28176;&#36817;&#27491;&#24577;&#20272;&#35745;&#12290;&#36825;&#20010;&#26465;&#20214;&#24847;&#21619;&#30528;&#20462;&#27491;&#24178;&#25200;&#20989;&#25968;&#30340;&#23384;&#22312;&#65292;
&lt;/p&gt;
&lt;p&gt;
In a variety of applications, including nonparametric instrumental variable (NPIV) analysis, proximal causal inference under unmeasured confounding, and missing-not-at-random data with shadow variables, we are interested in inference on a continuous linear functional (e.g., average causal effects) of nuisance function (e.g., NPIV regression) defined by conditional moment restrictions. These nuisance functions are generally weakly identified, in that the conditional moment restrictions can be severely ill-posed as well as admit multiple solutions. This is sometimes resolved by imposing strong conditions that imply the function can be estimated at rates that make inference on the functional possible. In this paper, we study a novel condition for the functional to be strongly identified even when the nuisance function is not; that is, the functional is amenable to asymptotically-normal estimation at $\sqrt{n}$-rates. The condition implies the existence of debiasing nuisance functions, and
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22312;R&#20013;&#20351;&#29992;theft&#21253;&#36827;&#34892;&#22522;&#20110;&#29305;&#24449;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#20102;&#24403;&#21069;&#23384;&#22312;&#30340;&#38382;&#39064;&#21253;&#25324;&#32570;&#20047;&#32479;&#19968;&#30340;&#35775;&#38382;&#28857;&#20197;&#21450;&#29992;&#25143;&#38656;&#35201;&#25484;&#25569;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;&#26469;&#33719;&#24471;&#25152;&#26377;&#29305;&#24449;&#38598;&#12290;</title><link>http://arxiv.org/abs/2208.06146</link><description>&lt;p&gt;
&#22312;R&#20013;&#20351;&#29992;theft&#21253;&#36827;&#34892;&#22522;&#20110;&#29305;&#24449;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Feature-Based Time-Series Analysis in R using the theft Package. (arXiv:2208.06146v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06146
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22312;R&#20013;&#20351;&#29992;theft&#21253;&#36827;&#34892;&#22522;&#20110;&#29305;&#24449;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#25351;&#20986;&#20102;&#24403;&#21069;&#23384;&#22312;&#30340;&#38382;&#39064;&#21253;&#25324;&#32570;&#20047;&#32479;&#19968;&#30340;&#35775;&#38382;&#28857;&#20197;&#21450;&#29992;&#25143;&#38656;&#35201;&#25484;&#25569;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;&#26469;&#33719;&#24471;&#25152;&#26377;&#29305;&#24449;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#22312;&#21508;&#20010;&#31185;&#23398;&#39046;&#22495;&#20013;&#34987;&#27979;&#37327;&#21644;&#20998;&#26512;&#12290;&#19968;&#31181;&#37327;&#21270;&#26102;&#38388;&#24207;&#21015;&#32467;&#26500;&#30340;&#26041;&#27861;&#26159;&#36890;&#36807;&#35745;&#31639;&#19968;&#32452;&#25688;&#35201;&#32479;&#35745;&#37327;&#25110;"&#29305;&#24449;"&#65292;&#28982;&#21518;&#29992;&#29305;&#24449;&#21521;&#37327;&#30340;&#23646;&#24615;&#26469;&#34920;&#31034;&#26102;&#38388;&#24207;&#21015;&#12290;&#32467;&#26524;&#24471;&#21040;&#30340;&#29305;&#24449;&#31354;&#38388;&#26159;&#21487;&#35299;&#37322;&#21644;&#20449;&#24687;&#20016;&#23500;&#30340;&#65292;&#20351;&#24471;&#20256;&#32479;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#21253;&#25324;&#32858;&#31867;&#12289;&#22238;&#24402;&#21644;&#20998;&#31867;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;&#23384;&#22312;&#35768;&#22810;&#24320;&#28304;&#36719;&#20214;&#21253;&#22312;&#22810;&#31181;&#32534;&#31243;&#35821;&#35328;&#20013;&#35745;&#31639;&#26102;&#38388;&#24207;&#21015;&#29305;&#24449;&#38598;&#65292;&#21253;&#25324;catch22&#65288;22&#20010;&#29305;&#24449;&#65306;Matlab&#12289;R&#12289;Python&#12289;Julia&#65289;&#12289;feasts&#65288;42&#20010;&#29305;&#24449;&#65306;R&#65289;&#12289;tsfeatures&#65288;63&#20010;&#29305;&#24449;&#65306;R&#65289;&#12289;Kats&#65288;40&#20010;&#29305;&#24449;&#65306;Python&#65289;&#12289;tsfresh&#65288;779&#20010;&#29305;&#24449;&#65306;Python&#65289;&#21644;TSFEL&#65288;390&#20010;&#29305;&#24449;&#65306;Python&#65289;&#12290;&#28982;&#32780;&#65292;&#23384;&#22312;&#20960;&#20010;&#38382;&#39064;&#65306;&#65288;i&#65289;&#30446;&#21069;&#23578;&#26080;&#36825;&#20123;&#36719;&#20214;&#21253;&#30340;&#21333;&#19968;&#35775;&#38382;&#28857;&#65307;&#65288;ii&#65289;&#35201;&#35775;&#38382;&#25152;&#26377;&#29305;&#24449;&#38598;&#65292;&#29992;&#25143;&#24517;&#39035;&#31934;&#36890;&#22810;&#31181;&#35821;&#35328;&#65307;&#65288;iii&#65289;th
&lt;/p&gt;
&lt;p&gt;
Time series are measured and analyzed across the sciences. One method of quantifying the structure of time series is by calculating a set of summary statistics or `features', and then representing a time series in terms of its properties as a feature vector. The resulting feature space is interpretable and informative, and enables conventional statistical learning approaches, including clustering, regression, and classification, to be applied to time-series datasets. Many open-source software packages for computing sets of time-series features exist across multiple programming languages, including catch22 (22 features: Matlab, R, Python, Julia), feasts (42 features: R), tsfeatures (63 features: R), Kats (40 features: Python), tsfresh (779 features: Python), and TSFEL (390 features: Python). However, there are several issues: (i) a singular access point to these packages is not currently available; (ii) to access all feature sets, users must be fluent in multiple languages; and (iii) th
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#28145;&#24230;&#30452;&#25509;&#21028;&#21035;&#35299;&#30721;&#22120;&#65288;D4&#65289;&#12290;D4&#36890;&#36807;&#24341;&#20837;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#26377;&#25928;&#22320;&#20272;&#35745;&#20102;&#39640;&#32500;&#35266;&#27979;&#20449;&#21495;&#19979;&#30340;&#28508;&#22312;&#29366;&#24577;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.10947</link><description>&lt;p&gt;
&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#30340;&#28145;&#24230;&#30452;&#25509;&#21028;&#21035;&#35299;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Deep Direct Discriminative Decoders for High-dimensional Time-series Data Analysis. (arXiv:2205.10947v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10947
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#65292;&#21363;&#28145;&#24230;&#30452;&#25509;&#21028;&#21035;&#35299;&#30721;&#22120;&#65288;D4&#65289;&#12290;D4&#36890;&#36807;&#24341;&#20837;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#25193;&#23637;&#24615;&#65292;&#26377;&#25928;&#22320;&#20272;&#35745;&#20102;&#39640;&#32500;&#35266;&#27979;&#20449;&#21495;&#19979;&#30340;&#28508;&#22312;&#29366;&#24577;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;SSMs&#65289;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#20013;&#12290;SSMs&#20381;&#36182;&#20110;&#23545;&#29366;&#24577;&#21644;&#35266;&#27979;&#36807;&#31243;&#30340;&#26126;&#30830;&#23450;&#20041;&#12290;&#24403;&#35266;&#27979;&#25968;&#25454;&#30340;&#32500;&#24230;&#22686;&#21152;&#25110;&#35266;&#27979;&#25968;&#25454;&#20998;&#24067;&#20559;&#31163;&#27491;&#24577;&#20998;&#24067;&#26102;&#65292;&#25551;&#36848;&#36825;&#20123;&#36807;&#31243;&#24182;&#19981;&#24635;&#26159;&#23481;&#26131;&#30340;&#65292;&#36825;&#25104;&#20026;&#24314;&#27169;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#35266;&#27979;&#36807;&#31243;&#30340;&#26032;&#30340;SSM&#34920;&#36798;&#24418;&#24335;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#35299;&#20915;&#26041;&#26696;&#31216;&#20026;&#28145;&#24230;&#30452;&#25509;&#21028;&#21035;&#35299;&#30721;&#22120;&#65288;D4&#65289;&#12290;D4&#23558;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#25193;&#23637;&#24615;&#24341;&#20837;&#21040;SSM&#34920;&#36798;&#24418;&#24335;&#20013;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#26500;&#24314;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#39640;&#32500;&#35266;&#27979;&#20449;&#21495;&#39640;&#25928;&#22320;&#20272;&#35745;&#28508;&#22312;&#30340;&#29366;&#24577;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#65288;&#22914;Lorenz&#21560;&#24341;&#23376;&#12289;Langevin&#21160;&#21147;&#23398;&#12289;&#38543;&#26426;&#34892;&#36208;&#21160;&#21147;&#23398;&#21644;&#22823;&#40736;&#28023;&#39532;&#38829;&#29366;&#31070;&#32463;&#25968;&#25454;&#65289;&#19978;&#28436;&#31034;&#20102;D4&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#27604;&#20256;&#32479;&#30340;SSMs&#21644;RNNs&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;D4&#21487;&#20197;&#24212;&#29992;&#20110;
&lt;/p&gt;
&lt;p&gt;
The state-space models (SSMs) are widely utilized in the analysis of time-series data. SSMs rely on an explicit definition of the state and observation processes. Characterizing these processes is not always easy and becomes a modeling challenge when the dimension of observed data grows or the observed data distribution deviates from the normal distribution. Here, we propose a new formulation of SSM for high-dimensional observation processes. We call this solution the deep direct discriminative decoder (D4). The D4 brings deep neural networks' expressiveness and scalability to the SSM formulation letting us build a novel solution that efficiently estimates the underlying state processes through high-dimensional observation signal. We demonstrate the D4 solutions in simulated and real data such as Lorenz attractors, Langevin dynamics, random walk dynamics, and rat hippocampus spiking neural data and show that the D4 performs better than traditional SSMs and RNNs. The D4 can be applied t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22806;&#37096;&#26377;&#25928;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#27835;&#30103;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#23545;&#31574;&#30053;&#26222;&#36866;&#24615;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2205.05561</link><description>&lt;p&gt;
&#22806;&#37096;&#26377;&#25928;&#30340;&#31574;&#30053;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Externally Valid Policy Choice. (arXiv:2205.05561v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22806;&#37096;&#26377;&#25928;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#27835;&#30103;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#30340;&#26041;&#27861;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#24378;&#35843;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#23545;&#31574;&#30053;&#26222;&#36866;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#31574;&#30053;&#26159;&#22806;&#37096;&#26377;&#25928;&#25110;&#24191;&#20041;&#21270;&#30340;&#65306;&#23427;&#20204;&#22312;&#38500;&#20102;&#23454;&#39564;&#65288;&#25110;&#35757;&#32451;&#65289;&#20154;&#32676;&#22806;&#30340;&#20854;&#20182;&#30446;&#26631;&#20154;&#32676;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#23545;&#20110;&#23454;&#39564;&#20154;&#32676;&#32780;&#35328;&#65292;&#26368;&#22823;&#21270;&#31119;&#21033;&#30340;&#31574;&#30053;&#23545;&#20110;&#23454;&#39564;&#21644;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#32467;&#26524;&#65288;&#20294;&#19981;&#26159;&#29305;&#24449;&#65289;&#20998;&#24067;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#23545;&#32467;&#26524;&#21644;&#29305;&#24449;&#21464;&#21270;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#26679;&#20570;&#26102;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#23454;&#39564;&#20154;&#32676;&#20869;&#30340;&#27835;&#30103;&#25928;&#26524;&#24322;&#36136;&#24615;&#22914;&#20309;&#24433;&#21709;&#31574;&#30053;&#30340;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#23454;&#39564;&#25110;&#35266;&#23519;&#25968;&#25454;&#65288;&#20854;&#20013;&#27835;&#30103;&#26159;&#20869;&#29983;&#30340;&#65289;&#12290;&#25105;&#20204;&#30340;&#35768;&#22810;&#26041;&#27861;&#21487;&#20197;&#20351;&#29992;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning personalized treatment policies that are externally valid or generalizable: they perform well in other target populations besides the experimental (or training) population from which data are sampled. We first show that welfare-maximizing policies for the experimental population are robust to shifts in the distribution of outcomes (but not characteristics) between the experimental and target populations. We then develop new methods for learning policies that are robust to shifts in outcomes and characteristics. In doing so, we highlight how treatment effect heterogeneity within the experimental population affects the generalizability of policies. Our methods may be used with experimental or observational data (where treatment is endogenous). Many of our methods can be implemented with linear programming.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34276;&#34067;&#39034;&#24207;&#30456;&#20851;&#30340;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#21452;&#21464;&#37327;&#20998;&#20301;&#25968;&#65292;&#24182;&#20351;&#29992;&#34276;&#34067;&#30456;&#20851;&#30340;&#27700;&#24179;&#26354;&#32447;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#36991;&#20813;&#20256;&#32479;&#22238;&#24402;&#27169;&#22411;&#30340;&#19968;&#20123;&#38382;&#39064;&#65292;&#22914;&#21464;&#37327;&#36716;&#25442;&#12289;&#20849;&#32447;&#24615;&#21644;&#20998;&#20301;&#25968;&#20132;&#21449;&#12290;</title><link>http://arxiv.org/abs/2205.02557</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#21464;&#37327;&#34276;&#34067;&#39034;&#24207;&#30456;&#20851;&#30340;&#22238;&#24402;&#12289;&#21452;&#21464;&#37327;&#27700;&#24179;&#26354;&#32447;&#21644;&#20998;&#20301;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Bivariate vine copula based regression, bivariate level and quantile curves. (arXiv:2205.02557v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02557
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34276;&#34067;&#39034;&#24207;&#30456;&#20851;&#30340;&#22238;&#24402;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#21452;&#21464;&#37327;&#20998;&#20301;&#25968;&#65292;&#24182;&#20351;&#29992;&#34276;&#34067;&#30456;&#20851;&#30340;&#27700;&#24179;&#26354;&#32447;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#36991;&#20813;&#20256;&#32479;&#22238;&#24402;&#27169;&#22411;&#30340;&#19968;&#20123;&#38382;&#39064;&#65292;&#22914;&#21464;&#37327;&#36716;&#25442;&#12289;&#20849;&#32447;&#24615;&#21644;&#20998;&#20301;&#25968;&#20132;&#21449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#21464;&#37327;&#20998;&#20301;&#25968;&#30340;&#32479;&#35745;&#20998;&#26512;&#24050;&#32463;&#24456;&#25104;&#29087;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#21464;&#37327;&#20998;&#20301;&#25968;&#30340;&#30740;&#31350;&#20173;&#28982;&#26377;&#24453;&#28145;&#20837;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#34276;&#34067;&#39034;&#24207;&#30456;&#20851;&#30340;&#21452;&#21464;&#37327;&#65288;&#26465;&#20214;&#65289;&#20998;&#20301;&#25968;&#65292;&#20351;&#29992;&#34276;&#34067;&#30456;&#20851;&#22238;&#24402;&#27169;&#22411;&#30340;&#27700;&#24179;&#26354;&#32447;&#12290;&#34276;&#34067;&#30456;&#20851;&#26159;&#19968;&#31181;&#30001;&#36830;&#32493;&#26641;&#24418;&#27169;&#22411;&#30830;&#23450;&#30340;&#22270;&#24418;&#27169;&#22411;&#65292;&#20801;&#35768;&#23545;&#36793;&#38469;&#20998;&#24067;&#21644;&#30456;&#20851;&#32467;&#26500;&#36827;&#34892;&#20998;&#24320;&#24314;&#27169;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#27169;&#22411;&#65288;&#30001;&#26641;&#24207;&#21015;&#32473;&#20986;&#65289;&#65292;&#19987;&#20026;&#39044;&#27979;&#22238;&#24402;&#35774;&#32622;&#20013;&#20004;&#20010;&#21709;&#24212;&#30340;&#23545;&#31216;&#22788;&#29702;&#32780;&#35774;&#35745;&#12290;&#25105;&#20204;&#30830;&#31435;&#20102;&#27169;&#22411;&#30340;&#35745;&#31639;&#21487;&#34892;&#24615;&#21644;&#33719;&#24471;&#19981;&#21516;&#26465;&#20214;&#20998;&#24067;&#30340;&#31616;&#21333;&#26041;&#27861;&#12290;&#20351;&#29992;&#34276;&#34067;&#30456;&#20851;&#65292;&#22238;&#24402;&#30340;&#20856;&#22411;&#19981;&#36275;&#65292;&#22914;&#38656;&#23545;&#39044;&#27979;&#21464;&#37327;&#36827;&#34892;&#36716;&#25442;&#25110;&#20132;&#20114;&#12289;&#20849;&#32447;&#24615;&#25110;&#20998;&#20301;&#25968;&#20132;&#21449;&#65292;&#37117;&#21487;&#20197;&#36991;&#20813;&#12290;&#25105;&#20204;&#36890;&#36807;&#19981;&#21516;&#34276;&#34067;&#30456;&#20851;&#20998;&#24067;&#26469;&#35828;&#26126;&#22522;&#20110;&#34276;&#34067;&#30456;&#20851;&#30340;&#21452;&#21464;&#37327;&#27700;&#24179;&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
The statistical analysis of univariate quantiles is a well developed research topic. However, there is a need for research in multivariate quantiles. We construct bivariate (conditional) quantiles using the level curves of vine copula based bivariate regression model. Vine copulas are graph theoretical models identified by a sequence of linked trees, which allow for separate modelling of marginal distributions and the dependence structure. We introduce a novel graph structure model (given by a tree sequence) specifically designed for a symmetric treatment of two responses in a predictive regression setting. We establish computational tractability of the model and a straight forward way of obtaining different conditional distributions. Using vine copulas the typical shortfalls of regression, as the need for transformations or interactions of predictors, collinearity or quantile crossings are avoided. We illustrate the copula based bivariate level curves for different copula distribution
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#31616;&#21333;&#30340;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#36275;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#23545;&#34394;&#20551;&#30456;&#20851;&#24615;&#30340;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#22312;&#34394;&#20551;&#30456;&#20851;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#23218;&#32654;&#25110;&#32988;&#36807;&#65292;&#20294;&#20854;&#22797;&#26434;&#24230;&#21644;&#35745;&#31639;&#24320;&#38144;&#36739;&#20302;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22312;ImageNet&#35757;&#32451;&#30340;&#22823;&#22411;&#27169;&#22411;&#36827;&#34892;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#65292;&#20165;&#20960;&#20998;&#38047;&#30340;&#35757;&#32451;&#26102;&#38388;&#23601;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#23545;&#32972;&#26223;&#21644;&#32441;&#29702;&#20449;&#24687;&#30340;&#20381;&#36182;&#65292;&#25552;&#39640;&#23545;&#21327;&#21464;&#37327;&#36716;&#21464;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.02937</link><description>&lt;p&gt;
&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#36275;&#20197;&#25552;&#39640;&#23545;&#34394;&#20551;&#30456;&#20851;&#24615;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations. (arXiv:2204.02937v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.02937
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#34920;&#26126;&#65292;&#31616;&#21333;&#30340;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#36275;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#23545;&#34394;&#20551;&#30456;&#20851;&#24615;&#30340;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#22312;&#34394;&#20551;&#30456;&#20851;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#23218;&#32654;&#25110;&#32988;&#36807;&#65292;&#20294;&#20854;&#22797;&#26434;&#24230;&#21644;&#35745;&#31639;&#24320;&#38144;&#36739;&#20302;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22312;ImageNet&#35757;&#32451;&#30340;&#22823;&#22411;&#27169;&#22411;&#36827;&#34892;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#65292;&#20165;&#20960;&#20998;&#38047;&#30340;&#35757;&#32451;&#26102;&#38388;&#23601;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#23545;&#32972;&#26223;&#21644;&#32441;&#29702;&#20449;&#24687;&#30340;&#20381;&#36182;&#65292;&#25552;&#39640;&#23545;&#21327;&#21464;&#37327;&#36716;&#21464;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21487;&#20197;&#20027;&#35201;&#20381;&#38752;&#31616;&#21333;&#30340;&#34394;&#20551;&#29305;&#24449;&#65288;&#22914;&#32972;&#26223;&#65289;&#36827;&#34892;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20204;&#20173;&#28982;&#32463;&#24120;&#23398;&#20064;&#19982;&#25968;&#25454;&#25152;&#38656;&#23646;&#24615;&#30456;&#20851;&#30340;&#26680;&#24515;&#29305;&#24449;&#65292;&#19982;&#26368;&#36817;&#30340;&#30740;&#31350;&#32467;&#26524;&#30456;&#21453;&#12290;&#21463;&#21040;&#36825;&#19968;&#21551;&#31034;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#31616;&#21333;&#30340;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#21487;&#20197;&#22312;&#34394;&#20551;&#30456;&#20851;&#24615;&#22522;&#20934;&#27979;&#35797;&#20013;&#19982;&#29978;&#33267;&#32988;&#36807;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#65292;&#20294;&#20854;&#22797;&#26434;&#24230;&#21644;&#35745;&#31639;&#24320;&#38144;&#26174;&#33879;&#36739;&#20302;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#23545;&#20110;&#22312;ImageNet&#35757;&#32451;&#30340;&#22823;&#22411;&#27169;&#22411;&#19978;&#36827;&#34892;&#26368;&#21518;&#19968;&#23618;&#37325;&#26032;&#35757;&#32451;&#65292;&#20165;&#32463;&#36807;&#20960;&#20998;&#38047;&#30340;&#21333;GPU&#35757;&#32451;&#65292;&#20063;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#23545;&#32972;&#26223;&#21644;&#32441;&#29702;&#20449;&#24687;&#30340;&#20381;&#36182;&#65292;&#25552;&#39640;&#23545;&#21327;&#21464;&#37327;&#36716;&#21464;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network classifiers can largely rely on simple spurious features, such as backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent findings. Inspired by this insight, we demonstrate that simple last layer retraining can match or outperform state-of-the-art approaches on spurious correlation benchmarks, but with profoundly lower complexity and computational expenses. Moreover, we show that last layer retraining on large ImageNet-trained models can also significantly reduce reliance on background and texture information, improving robustness to covariate shift, after only minutes of training on a single GPU.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#32570;&#22833;&#35266;&#27979;&#30340;&#20301;&#32622;&#26410;&#30693;&#26102;&#23398;&#20064;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19981;&#38656;&#35201;&#20808;&#39564;&#20449;&#24687;&#30340;&#37325;&#24314;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.06527</link><description>&lt;p&gt;
&#24403;&#32570;&#22833;&#35266;&#27979;&#30340;&#20301;&#32622;&#26410;&#30693;&#26102;&#23398;&#20064;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Hidden Markov Models When the Locations of Missing Observations are Unknown. (arXiv:2203.06527v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.06527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#32570;&#22833;&#35266;&#27979;&#30340;&#20301;&#32622;&#26410;&#30693;&#26102;&#23398;&#20064;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19981;&#38656;&#35201;&#20808;&#39564;&#20449;&#24687;&#30340;&#37325;&#24314;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#26159;&#29992;&#20110;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;&#30340;&#26368;&#24120;&#29992;&#30340;&#32479;&#35745;&#27169;&#22411;&#20043;&#19968;&#12290;HMM&#20855;&#26377;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#36825;&#20063;&#26159;&#23427;&#20855;&#26377;&#36890;&#29992;&#24615;&#30340;&#20851;&#38190;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#26631;&#20934;&#30340;HMM&#23398;&#20064;&#31639;&#27861;&#22522;&#20110;&#32570;&#22833;&#35266;&#27979;&#22312;&#35266;&#27979;&#24207;&#21015;&#20013;&#30340;&#20301;&#32622;&#24050;&#30693;&#30340;&#20551;&#35774;&#12290;&#22312;&#33258;&#28982;&#31185;&#23398;&#20013;&#65292;&#36825;&#31181;&#20551;&#35774;&#24120;&#24120;&#19981;&#25104;&#31435;&#65292;&#22240;&#27492;&#36890;&#24120;&#20351;&#29992;&#29305;&#27530;&#21464;&#20307;&#30340;HMM&#65292;&#31216;&#20026;Silent-state HMMs&#65288;SHMMs&#65289;&#12290;&#23613;&#31649;&#36825;&#20123;&#31639;&#27861;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#23427;&#20204;&#20005;&#37325;&#20381;&#36182;&#20110;&#28508;&#22312;&#38142;&#30340;&#29305;&#23450;&#32467;&#26500;&#20551;&#35774;&#65292;&#27604;&#22914;&#38750;&#24490;&#29615;&#24615;&#65292;&#36825;&#38480;&#21046;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;&#22312;&#38750;&#24490;&#29615;&#24773;&#20917;&#19979;&#65292;&#24050;&#32463;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#37325;&#24314;&#25928;&#26524;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#20855;&#26377;&#26410;&#30693;&#32570;&#22833;&#35266;&#27979;&#20301;&#32622;&#25968;&#25454;&#20013;&#23398;&#20064;HMM&#30340;&#19968;&#33324;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19981;&#38656;&#35201;&#20219;&#20309;&#20808;&#39564;&#20449;&#24687;&#30340;&#37325;&#24314;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Hidden Markov Model (HMM) is one of the most widely used statistical models for sequential data analysis. One of the key reasons for this versatility is the ability of HMM to deal with missing data. However, standard HMM learning algorithms rely crucially on the assumption that the positions of the missing observations \emph{within the observation sequence} are known. In the natural sciences, where this assumption is often violated, special variants of HMM, commonly known as Silent-state HMMs (SHMMs), are used. Despite their widespread use, these algorithms strongly rely on specific structural assumptions of the underlying chain, such as acyclicity, thus limiting the applicability of these methods. Moreover, even in the acyclic case, it has been shown that these methods can lead to poor reconstruction. In this paper we consider the general problem of learning an HMM from data with unknown missing observation locations. We provide reconstruction algorithms that do not require any as
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#32570;&#20047;&#24179;&#28369;&#24615;&#30340;&#21183;&#33021;&#30340;&#37319;&#26679;&#38382;&#39064;&#30340;&#36817;&#31471;&#31639;&#27861;&#65292;&#22312;&#20984;&#21644;&#38750;&#20984;&#24773;&#20917;&#19979;&#22343;&#21487;&#36866;&#29992;&#12290;&#35813;&#31639;&#27861;&#30340;&#20851;&#38190;&#21019;&#26032;&#28857;&#22312;&#20110;&#22522;&#20110;&#25298;&#32477;&#37319;&#26679;&#30340;&#20132;&#26367;&#37319;&#26679;&#26694;&#26550;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;</title><link>http://arxiv.org/abs/2202.13975</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#37319;&#26679;&#30340;&#36817;&#31471;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Proximal Algorithm for Sampling. (arXiv:2202.13975v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#32570;&#20047;&#24179;&#28369;&#24615;&#30340;&#21183;&#33021;&#30340;&#37319;&#26679;&#38382;&#39064;&#30340;&#36817;&#31471;&#31639;&#27861;&#65292;&#22312;&#20984;&#21644;&#38750;&#20984;&#24773;&#20917;&#19979;&#22343;&#21487;&#36866;&#29992;&#12290;&#35813;&#31639;&#27861;&#30340;&#20851;&#38190;&#21019;&#26032;&#28857;&#22312;&#20110;&#22522;&#20110;&#25298;&#32477;&#37319;&#26679;&#30340;&#20132;&#26367;&#37319;&#26679;&#26694;&#26550;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19982;&#32570;&#20047;&#24179;&#28369;&#24615;&#30340;&#21183;&#33021;&#30456;&#20851;&#30340;&#37319;&#26679;&#38382;&#39064;&#12290;&#36825;&#20123;&#21183;&#33021;&#21487;&#20197;&#26159;&#20984;&#30340;&#25110;&#38750;&#20984;&#30340;&#12290;&#19981;&#21516;&#20110;&#26631;&#20934;&#30340;&#24179;&#28369;&#35774;&#32622;&#65292;&#36825;&#20123;&#21183;&#33021;&#21482;&#34987;&#35748;&#20026;&#26159;&#24369;&#24179;&#28369;&#25110;&#38750;&#24179;&#28369;&#30340;&#65292;&#25110;&#32773;&#26159;&#22810;&#20010;&#36825;&#26679;&#30340;&#20989;&#25968;&#30340;&#27714;&#21644;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#37319;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31867;&#20284;&#20110;&#29992;&#20110;&#36825;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#37319;&#26679;&#20219;&#21153;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#36817;&#31471;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#19968;&#31181;&#31216;&#20026;&#20132;&#26367;&#37319;&#26679;&#26694;&#26550;&#65288;ASF&#65289;&#30340;Gibbs&#37319;&#26679;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#20851;&#38190;&#36129;&#29486;&#26159;&#22522;&#20110;&#25298;&#32477;&#37319;&#26679;&#30340;ASF&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#36866;&#29992;&#20110;&#38750;&#20984;&#21644;&#19981;&#19968;&#23450;&#24179;&#28369;&#30340;&#20984;&#21183;&#33021;&#12290;&#22312;&#26412;&#24037;&#20316;&#32771;&#34385;&#30340;&#20960;&#20046;&#25152;&#26377;&#37319;&#26679;&#26696;&#20363;&#20013;&#65292;&#25105;&#20204;&#30340;&#36817;&#31471;&#37319;&#26679;&#31639;&#27861;&#30340;&#22797;&#26434;&#24615;&#37117;&#20248;&#20110;&#25152;&#26377;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study sampling problems associated with potentials that lack smoothness. The potentials can be either convex or non-convex. Departing from the standard smooth setting, the potentials are only assumed to be weakly smooth or non-smooth, or the summation of multiple such functions. We develop a sampling algorithm that resembles proximal algorithms in optimization for this challenging sampling task. Our algorithm is based on a special case of Gibbs sampling known as the alternating sampling framework (ASF). The key contribution of this work is a practical realization of the ASF based on rejection sampling for both non-convex and convex potentials that are not necessarily smooth. In almost all the cases of sampling considered in this work, our proximal sampling algorithm achieves better complexity than all existing methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20559;&#24046;&#25968;&#25454;&#25439;&#22833;&#30340;&#36890;&#29992;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#24212;&#29992;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#29702;&#35770;&#25552;&#20379;&#20102;&#25903;&#25345;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#28789;&#27963;&#30340;&#31639;&#27861;&#21644;&#22788;&#29702;&#32467;&#26500;&#24615;&#38646;&#20803;&#32032;&#30340;&#33021;&#21147;&#12290;&#20316;&#32773;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#26696;&#20363;&#30740;&#31350;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#24212;&#29992;&#24191;&#27867;&#24615;&#12290;</title><link>http://arxiv.org/abs/2110.05674</link><description>&lt;p&gt;
&#20559;&#24046;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Deviance Matrix Factorization. (arXiv:2110.05674v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.05674
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20559;&#24046;&#25968;&#25454;&#25439;&#22833;&#30340;&#36890;&#29992;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#24212;&#29992;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#29702;&#35770;&#25552;&#20379;&#20102;&#25903;&#25345;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#28789;&#27963;&#30340;&#31639;&#27861;&#21644;&#22788;&#29702;&#32467;&#26500;&#24615;&#38646;&#20803;&#32032;&#30340;&#33021;&#21147;&#12290;&#20316;&#32773;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#26696;&#20363;&#30740;&#31350;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#24212;&#29992;&#24191;&#27867;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#29992;&#20110;&#20559;&#24046;&#25968;&#25454;&#25439;&#22833;&#30340;&#36890;&#29992;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#23558;&#26222;&#36941;&#23384;&#22312;&#30340;&#22855;&#24322;&#20540;&#20998;&#35299;&#25193;&#23637;&#21040;&#24179;&#26041;&#35823;&#24046;&#25439;&#22833;&#20043;&#22806;&#12290;&#34429;&#28982;&#20043;&#21069;&#24050;&#32463;&#26377;&#31867;&#20284;&#30340;&#26041;&#27861;&#65292;&#20294;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#30340;&#32463;&#20856;&#32479;&#35745;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26465;&#30446;&#26435;&#37325;&#26469;&#22788;&#29702;&#32467;&#26500;&#24615;&#38646;&#20803;&#32032;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#35843;&#25972;GLM&#29702;&#35770;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#20197;&#19979;&#26041;&#24335;&#25903;&#25345;&#36825;&#20123;&#20998;&#35299;&#65306;&#65288;i&#65289;&#22312;GLM&#35774;&#32622;&#19979;&#26174;&#31034;&#24378;&#19968;&#33268;&#24615;&#65292;&#65288;ii&#65289;&#36890;&#36807;&#24191;&#20041;Hosmer-Lemeshow&#26816;&#39564;&#26816;&#39564;&#25152;&#36873;&#25321;&#25351;&#25968;&#26063;&#20998;&#24067;&#30340;&#36866;&#24212;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#36890;&#36807;&#26368;&#22823;&#29305;&#24449;&#20540;&#38388;&#38548;&#27861;&#30830;&#23450;&#20998;&#35299;&#30340;&#31209;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25903;&#25345;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#27169;&#25311;&#30740;&#31350;&#65292;&#35780;&#20272;&#23545;&#20998;&#35299;&#20551;&#35774;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#20351;&#29992;&#22270;&#20687;&#20154;&#33080;&#35782;&#21035;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12289;&#32593;&#32476;&#20998;&#26512;&#21644;&#29983;&#29289;&#21307;&#23398;&#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#26696;&#20363;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate a general matrix factorization for deviance-based data losses, extending the ubiquitous singular value decomposition beyond squared error loss. While similar approaches have been explored before, our method leverages classical statistical methodology from generalized linear models (GLMs) and provides an efficient algorithm that is flexible enough to allow for structural zeros via entry weights. Moreover, by adapting results from GLM theory, we provide support for these decompositions by (i) showing strong consistency under the GLM setup, (ii) checking the adequacy of a chosen exponential family via a generalized Hosmer-Lemeshow test, and (iii) determining the rank of the decomposition via a maximum eigenvalue gap method. To further support our findings, we conduct simulation studies to assess robustness to decomposition assumptions and extensive case studies using benchmark datasets from image face recognition, natural language processing, network analysis, and biomedica
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#20855;&#26377;&#21453;&#39304;&#20449;&#24687;&#30340;&#31163;&#32447;&#21644;&#22312;&#32447;&#24773;&#22659;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#35266;&#23519;&#26368;&#20339;&#21160;&#20316;&#24182;&#26368;&#23567;&#21270;&#21518;&#24724;&#26469;&#20248;&#21270;&#20915;&#31574;&#21046;&#23450;&#12290;</title><link>http://arxiv.org/abs/2106.14015</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#36870;&#20248;&#21270;&#65306;&#31163;&#32447;&#21644;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Inverse Optimization: Offline and Online Learning. (arXiv:2106.14015v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.14015
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#30740;&#31350;&#20102;&#20855;&#26377;&#21453;&#39304;&#20449;&#24687;&#30340;&#31163;&#32447;&#21644;&#22312;&#32447;&#24773;&#22659;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#35266;&#23519;&#26368;&#20339;&#21160;&#20316;&#24182;&#26368;&#23567;&#21270;&#21518;&#24724;&#26469;&#20248;&#21270;&#20915;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#21453;&#39304;&#20449;&#24687;&#30340;&#31163;&#32447;&#21644;&#22312;&#32447;&#24773;&#22659;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#23519;&#21040;&#30340;&#19981;&#26159;&#25439;&#22833;&#65292;&#32780;&#26159;&#19968;&#20010;&#20855;&#26377;&#23436;&#20840;&#20102;&#35299;&#30446;&#26631;&#20989;&#25968;&#30340;&#39044;&#27979;&#31070;&#32463;&#32593;&#32476;&#23558;&#20250;&#37319;&#21462;&#30340;&#26368;&#20339;&#21160;&#20316;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#21518;&#24724;&#65292;&#21518;&#24724;&#23450;&#20041;&#20026;&#25105;&#20204;&#30340;&#25439;&#22833;&#19982;&#20840;&#30693;&#39044;&#27979;&#31070;&#32463;&#32593;&#32476;&#20135;&#29983;&#30340;&#25439;&#22833;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#22312;&#31163;&#32447;&#24773;&#22659;&#20013;&#65292;&#20915;&#31574;&#32773;&#21487;&#20197;&#33719;&#24471;&#36807;&#21435;&#26102;&#26399;&#30340;&#20449;&#24687;&#24182;&#38656;&#35201;&#20570;&#20986;&#19968;&#20010;&#20915;&#31574;&#65292;&#32780;&#22312;&#22312;&#32447;&#24773;&#22659;&#20013;&#65292;&#20915;&#31574;&#32773;&#26681;&#25454;&#27599;&#20010;&#26102;&#26399;&#30340;&#26032;&#19968;&#32452;&#21487;&#34892;&#21160;&#20316;&#21644;&#24773;&#22659;&#20989;&#25968;&#26469;&#21160;&#24577;&#20248;&#21270;&#20915;&#31574;&#12290;&#23545;&#20110;&#31163;&#32447;&#24773;&#22659;&#65292;&#25105;&#20204;&#23558;&#26368;&#20248;&#26497;&#23567;&#26497;&#22823;&#31574;&#30053;&#29305;&#24449;&#21270;&#65292;&#30830;&#23450;&#20102;&#21487;&#20197;&#20316;&#20026;&#25968;&#25454;&#20135;&#29983;&#30340;&#20449;&#24687;&#30340;&#22522;&#30784;&#20960;&#20309;&#24418;&#29366;&#30340;&#20989;&#25968;&#34920;&#29616;&#12290;&#22312;&#22312;&#32447;&#24773;&#22659;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#20960;&#20309;&#29305;&#24449;&#26469;&#20248;&#21270;&#32047;&#31215;&#21518;&#24724;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#31639;&#27861;&#26469;&#25214;&#21040;&#32047;&#31215;&#21518;&#24724;&#30340;&#26368;&#23567;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problems of offline and online contextual optimization with feedback information, where instead of observing the loss, we observe, after-the-fact, the optimal action an oracle with full knowledge of the objective function would have taken. We aim to minimize regret, which is defined as the difference between our losses and the ones incurred by an all-knowing oracle. In the offline setting, the decision-maker has information available from past periods and needs to make one decision, while in the online setting, the decision-maker optimizes decisions dynamically over time based a new set of feasible actions and contextual functions in each period. For the offline setting, we characterize the optimal minimax policy, establishing the performance that can be achieved as a function of the underlying geometry of the information induced by the data. In the online setting, we leverage this geometric characterization to optimize the cumulative regret. We develop an algorithm that y
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#26500;&#24314;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35813;&#27169;&#22411;&#22312;&#32473;&#23450;&#20195;&#29702;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;PCL&#21487;&#20197;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#21644;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;DFPV&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.03907</link><description>&lt;p&gt;
&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#21450;&#20854;&#22312;&#28151;&#28102;&#36172;&#21338;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03907
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#36890;&#36807;&#26500;&#24314;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#35813;&#27169;&#22411;&#22312;&#32473;&#23450;&#20195;&#29702;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;PCL&#21487;&#20197;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#39640;&#32500;&#21644;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;DFPV&#22312;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#30340;&#24615;&#33021;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20195;&#29702;&#22240;&#26524;&#23398;&#20064;&#65288;PCL&#65289;&#26159;&#19968;&#31181;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#26102;&#65292;&#21033;&#29992;&#20195;&#29702;&#65288;&#32467;&#26500;&#21270;&#20391;&#38754;&#20449;&#24687;&#65289;&#20272;&#35745;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#26041;&#27861;&#12290;&#36825;&#26159;&#36890;&#36807;&#20004;&#38454;&#27573;&#22238;&#24402;&#23454;&#29616;&#30340;&#65306;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#24314;&#27169;&#27835;&#30103;&#21644;&#20195;&#29702;&#20043;&#38388;&#30340;&#20851;&#31995;&#65307;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#27169;&#22411;&#26469;&#23398;&#20064;&#22312;&#32473;&#23450;&#20195;&#29702;&#25552;&#20379;&#30340;&#19978;&#19979;&#25991;&#19979;&#65292;&#27835;&#30103;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;PCL&#22312;&#21487;&#35782;&#21035;&#26465;&#20214;&#19979;&#20445;&#35777;&#24674;&#22797;&#30495;&#23454;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCL&#26041;&#27861;&#65292;&#28145;&#24230;&#29305;&#24449;&#20195;&#29702;&#21464;&#37327;&#26041;&#27861;&#65288;DFPV&#65289;&#65292;&#20197;&#35299;&#20915;&#20195;&#29702;&#12289;&#27835;&#30103;&#21644;&#32467;&#26524;&#20026;&#39640;&#32500;&#19988;&#20855;&#26377;&#38750;&#32447;&#24615;&#22797;&#26434;&#20851;&#31995;&#30340;&#24773;&#20917;&#65292;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#34920;&#31034;&#12290;&#25105;&#20204;&#34920;&#26126;DFPV&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21512;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#26368;&#36817;&#30340;&#26368;&#20808;&#36827;&#30340;PCL&#26041;&#27861;&#65292;&#21253;&#25324;&#28041;&#21450;&#39640;&#32500;&#22270;&#20687;&#25968;&#25454;&#30340;&#35774;&#32622;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;PCL&#30340;&#24212;&#29992;...
&lt;/p&gt;
&lt;p&gt;
Proxy causal learning (PCL) is a method for estimating the causal effect of treatments on outcomes in the presence of unobserved confounding, using proxies (structured side information) for the confounder. This is achieved via two-stage regression: in the first stage, we model relations among the treatment and proxies; in the second stage, we use this model to learn the effect of treatment on the outcome, given the context provided by the proxies. PCL guarantees recovery of the true causal effect, subject to identifiability conditions. We propose a novel method for PCL, the deep feature proxy variable method (DFPV), to address the case where the proxies, treatments, and outcomes are high-dimensional and have nonlinear complex relationships, as represented by deep neural network features. We show that DFPV outperforms recent state-of-the-art PCL methods on challenging synthetic benchmarks, including settings involving high dimensional image data. Furthermore, we show that PCL can be app
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24179;&#28369;&#25554;&#20540;&#30340;&#26041;&#24335;&#23558;&#27169;&#20223;&#23398;&#20064;&#21644;&#32431;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#32479;&#19968;&#36215;&#26469;&#12290;&#26694;&#26550;&#22260;&#32469;&#30528;&#19968;&#31181;&#34913;&#37327;&#34892;&#20026;&#31574;&#30053;&#19982;&#19987;&#23478;&#31574;&#30053;&#20559;&#31163;&#31243;&#24230;&#30340;&#24369;&#29256;&#26412;&#38598;&#20013;&#31995;&#25968;&#23637;&#24320;&#12290;&#36890;&#36807;&#35813;&#26694;&#26550;&#65292;&#30740;&#31350;&#32773;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#31639;&#27861;&#35774;&#35745;&#30340;&#38382;&#39064;&#65306;&#33021;&#21542;&#24320;&#21457;&#20986;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#26368;&#20248;&#24615;&#30340;&#31639;&#27861;&#65311;</title><link>http://arxiv.org/abs/2103.12021</link><description>&lt;p&gt;
&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#19982;&#27169;&#20223;&#23398;&#20064;&#30340;&#26725;&#26753;&#65306;&#19968;&#20010;&#24754;&#35266;&#30340;&#25925;&#20107;
&lt;/p&gt;
&lt;p&gt;
Bridging Offline Reinforcement Learning and Imitation Learning: A Tale of Pessimism. (arXiv:2103.12021v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.12021
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#24179;&#28369;&#25554;&#20540;&#30340;&#26041;&#24335;&#23558;&#27169;&#20223;&#23398;&#20064;&#21644;&#32431;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#32479;&#19968;&#36215;&#26469;&#12290;&#26694;&#26550;&#22260;&#32469;&#30528;&#19968;&#31181;&#34913;&#37327;&#34892;&#20026;&#31574;&#30053;&#19982;&#19987;&#23478;&#31574;&#30053;&#20559;&#31163;&#31243;&#24230;&#30340;&#24369;&#29256;&#26412;&#38598;&#20013;&#31995;&#25968;&#23637;&#24320;&#12290;&#36890;&#36807;&#35813;&#26694;&#26550;&#65292;&#30740;&#31350;&#32773;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#31639;&#27861;&#35774;&#35745;&#30340;&#38382;&#39064;&#65306;&#33021;&#21542;&#24320;&#21457;&#20986;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#26368;&#20248;&#24615;&#30340;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#26426;&#65288;&#25110;&#25209;&#27425;&#65289;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26088;&#22312;&#20174;&#22266;&#23450;&#30340;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#26080;&#38656;&#20027;&#21160;&#25910;&#38598;&#25968;&#25454;&#12290;&#26681;&#25454;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#32452;&#25104;&#65292;&#20027;&#35201;&#20351;&#29992;&#20004;&#31181;&#26041;&#27861;&#65306;&#36866;&#29992;&#20110;&#19987;&#23478;&#25968;&#25454;&#38598;&#30340;&#27169;&#20223;&#23398;&#20064;&#21644;&#36890;&#24120;&#38656;&#35201;&#22343;&#21248;&#35206;&#30422;&#25968;&#25454;&#38598;&#30340;&#32431;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#12290;&#20174;&#23454;&#36341;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25968;&#25454;&#38598;&#36890;&#24120;&#20559;&#31163;&#36825;&#20004;&#20010;&#26497;&#31471;&#65292;&#24182;&#19988;&#36890;&#24120;&#20107;&#20808;&#19981;&#30693;&#36947;&#30830;&#20999;&#30340;&#25968;&#25454;&#32452;&#25104;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#23427;&#22312;&#25968;&#25454;&#32452;&#25104;&#30340;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#24179;&#28369;&#25554;&#20540;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#27169;&#20223;&#23398;&#20064;&#21644;&#32431;&#32852;&#26426;&#24378;&#21270;&#23398;&#20064;&#12290;&#26032;&#30340;&#26694;&#26550;&#22260;&#32469;&#19968;&#20010;&#24369;&#29256;&#26412;&#30340;&#38598;&#20013;&#31995;&#25968;&#23637;&#24320;&#65292;&#35813;&#31995;&#25968;&#34913;&#37327;&#20102;&#34892;&#20026;&#31574;&#30053;&#19982;&#19987;&#23478;&#31574;&#30053;&#20043;&#38388;&#30340;&#20559;&#31163;&#31243;&#24230;&#12290;&#22312;&#36825;&#20010;&#26032;&#30340;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#31639;&#27861;&#35774;&#35745;&#30340;&#38382;&#39064;&#65306;&#33021;&#21542;&#24320;&#21457;&#20986;&#19968;&#31181;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#26368;&#20248;&#24615;&#30340;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main categories of methods are used: imitation learning which is suitable for expert datasets and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown a priori. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation from the behavior policy to the expert policy alone.  Under this new framework, we further investigate the question on algorithm design: can one develop an algorithm that achieves a minimax optimal r
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26694;&#26550;&#12290;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#30446;&#26631;&#12289;&#26041;&#27861;&#23398;&#12289;&#20860;&#23481;&#30340;&#24378;&#21270;&#23398;&#20064;&#32972;&#26223;&#20197;&#21450;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#19982;&#20854;&#20182;&#30456;&#20851;&#20027;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2009.07888</link><description>&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.07888
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26694;&#26550;&#12290;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#30446;&#26631;&#12289;&#26041;&#27861;&#23398;&#12289;&#20860;&#23481;&#30340;&#24378;&#21270;&#23398;&#20064;&#32972;&#26223;&#20197;&#21450;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#19982;&#20854;&#20182;&#30456;&#20851;&#20027;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#26159;&#35299;&#20915;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#30340;&#23398;&#20064;&#33539;&#24335;&#12290;&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#24378;&#21270;&#23398;&#20064;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#38500;&#20102;&#22312;&#26426;&#22120;&#20154;&#21644;&#28216;&#25103;&#31561;&#35832;&#22810;&#39046;&#22495;&#20013;&#20855;&#26377;&#33391;&#22909;&#21069;&#26223;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#36801;&#31227;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38754;&#20020;&#30340;&#21508;&#31181;&#25361;&#25112;&#30340;&#26041;&#27861;&#24050;&#32463;&#20986;&#29616;&#65292;&#36890;&#36807;&#20174;&#22806;&#37096;&#19987;&#19994;&#30693;&#35782;&#20013;&#36716;&#31227;&#30693;&#35782;&#65292;&#20197;&#25552;&#39640;&#23398;&#20064;&#36807;&#31243;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#26368;&#20808;&#36827;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26694;&#26550;&#65292;&#22312;&#27492;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#30446;&#26631;&#12289;&#26041;&#27861;&#23398;&#12289;&#20860;&#23481;&#30340;&#24378;&#21270;&#23398;&#20064;&#32972;&#26223;&#20197;&#21450;&#23454;&#38469;&#24212;&#29992;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#19982;&#20854;&#20182;&#30456;&#20851;&#20027;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning is a learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in reinforcement learning upon the fast development of deep neural networks. Along with the promising prospects of reinforcement learning in numerous domains such as robotics and game-playing, transfer learning has arisen to tackle various challenges faced by reinforcement learning, by transferring knowledge from external expertise to facilitate the efficiency and effectiveness of the learning process. In this survey, we systematically investigate the recent progress of transfer learning approaches in the context of deep reinforcement learning. Specifically, we provide a framework for categorizing the state-of-the-art transfer learning approaches, under which we analyze their goals, methodologies, compatible reinforcement learning backbones, and practical applications. We also draw connections between transfer learning and other relevant topics 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22242;&#38431;&#20013;&#23398;&#20064;&#20999;&#25442;&#20195;&#29702;&#25511;&#21046;&#30340;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20195;&#29702;&#30340;&#31574;&#30053;&#21644;&#29615;&#22659;&#30340;&#36716;&#31227;&#27010;&#29575;&#65292;&#22312;&#19981;&#21516;&#33258;&#21160;&#21270;&#27700;&#24179;&#19979;&#20351;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#33021;&#22815;&#24037;&#20316;&#12290;&#35813;&#31639;&#27861;&#30340;&#24635;&#36951;&#25022;&#19982;&#26368;&#20339;&#20999;&#25442;&#31574;&#30053;&#30456;&#27604;&#26159;&#27425;&#32447;&#24615;&#30340;&#65292;&#24403;&#22810;&#20010;&#20195;&#29702;&#22242;&#38431;&#22312;&#30456;&#20284;&#29615;&#22659;&#20013;&#36816;&#34892;&#26102;&#65292;&#35813;&#31639;&#27861;&#20174;&#32500;&#25252;&#29615;&#22659;&#30340;&#20849;&#20139;&#32622;&#20449;&#30028;&#20013;&#33719;&#30410;&#21290;&#27973;&#12290;</title><link>http://arxiv.org/abs/2002.04258</link><description>&lt;p&gt;
&#36890;&#36807;2&#23618;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#23398;&#20064;&#22312;&#22242;&#38431;&#20013;&#20999;&#25442;&#20195;&#29702;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning to Switch Among Agents in a Team via 2-Layer Markov Decision Processes. (arXiv:2002.04258v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.04258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22242;&#38431;&#20013;&#23398;&#20064;&#20999;&#25442;&#20195;&#29702;&#25511;&#21046;&#30340;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#20195;&#29702;&#30340;&#31574;&#30053;&#21644;&#29615;&#22659;&#30340;&#36716;&#31227;&#27010;&#29575;&#65292;&#22312;&#19981;&#21516;&#33258;&#21160;&#21270;&#27700;&#24179;&#19979;&#20351;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#33021;&#22815;&#24037;&#20316;&#12290;&#35813;&#31639;&#27861;&#30340;&#24635;&#36951;&#25022;&#19982;&#26368;&#20339;&#20999;&#25442;&#31574;&#30053;&#30456;&#27604;&#26159;&#27425;&#32447;&#24615;&#30340;&#65292;&#24403;&#22810;&#20010;&#20195;&#29702;&#22242;&#38431;&#22312;&#30456;&#20284;&#29615;&#22659;&#20013;&#36816;&#34892;&#26102;&#65292;&#35813;&#31639;&#27861;&#20174;&#32500;&#25252;&#29615;&#22659;&#30340;&#20849;&#20139;&#32622;&#20449;&#30028;&#20013;&#33719;&#30410;&#21290;&#27973;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#22312;&#36890;&#24120;&#20197;&#23436;&#20840;&#33258;&#20027;&#30340;&#26041;&#24335;&#24037;&#20316;&#30340;&#20551;&#35774;&#19979;&#24320;&#21457;&#21644;&#35780;&#20272; - &#23427;&#20204;&#23558;&#37319;&#21462;&#25152;&#26377;&#34892;&#21160;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#24320;&#21457;&#31639;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22312;&#20195;&#29702;&#20043;&#38388;&#20999;&#25442;&#25511;&#21046;&#65292;&#20351;&#29616;&#26377;&#30340;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#33258;&#21160;&#21270;&#27700;&#24179;&#19979;&#24037;&#20316;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#27491;&#24335;&#23450;&#20041;&#20102;&#36890;&#36807;2&#23618;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#22312;&#22242;&#38431;&#20013;&#23398;&#20064;&#20999;&#25442;&#25511;&#21046;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#20195;&#29702;&#30340;&#31574;&#30053;&#21644;&#29615;&#22659;&#30340;&#36716;&#31227;&#27010;&#29575;&#30340;&#19978;&#32622;&#20449;&#30028;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#25214;&#21040;&#19968;&#31995;&#21015;&#20999;&#25442;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#26368;&#20339;&#20999;&#25442;&#31574;&#30053;&#30340;&#24635;&#36951;&#25022;&#22312;&#23398;&#20064;&#27493;&#39588;&#30340;&#25968;&#37327;&#19978;&#26159;&#27425;&#32447;&#24615;&#30340;&#65292;&#24182;&#19988;&#27599;&#24403;&#22810;&#20010;&#20195;&#29702;&#22242;&#38431;&#22312;&#30456;&#20284;&#30340;&#29615;&#22659;&#20013;&#36816;&#34892;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20174;&#32500;&#25252;&#29615;&#22659;&#30340;&#20849;&#20139;&#32622;&#20449;&#30028;&#20013;&#33719;&#24471;&#24456;&#22823;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning agents have been mostly developed and evaluated under the assumption that they will operate in a fully autonomous manner -- they will take all actions. In this work, our goal is to develop algorithms that, by learning to switch control between agents, allow existing reinforcement learning agents to operate under different automation levels. To this end, we first formally define the problem of learning to switch control among agents in a team via a 2-layer Markov decision process. Then, we develop an online learning algorithm that uses upper confidence bounds on the agents' policies and the environment's transition probabilities to find a sequence of switching policies. The total regret of our algorithm with respect to the optimal switching policy is sublinear in the number of learning steps and, whenever multiple teams of agents operate in a similar environment, our algorithm greatly benefits from maintaining shared confidence bounds for the environments' transit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#35201;&#26435;&#37325;&#31034;&#33539;&#30340;&#20803;&#36866;&#24212;&#24615;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#29305;&#23450;&#20219;&#21153;&#30340;&#20808;&#21069;&#30693;&#35782;&#36827;&#34892;&#20998;&#37197;&#37325;&#35201;&#26435;&#37325;&#65292;&#23454;&#29616;&#20102;&#22312;&#20219;&#20309;&#30456;&#20851;&#20219;&#21153;&#19978;&#30340;&#27867;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20351;&#26426;&#22120;&#20154;&#22312;&#22810;&#26679;&#21270;&#29615;&#22659;&#20219;&#21153;&#20013;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#36890;&#36807;&#23569;&#37327;&#31034;&#33539;&#36866;&#24212;&#26410;&#30693;&#29615;&#22659;&#12290;</title><link>http://arxiv.org/abs/1911.10322</link><description>&lt;p&gt;
&#20351;&#29992;&#37325;&#35201;&#26435;&#37325;&#31034;&#33539;&#30340;&#20803;&#36866;&#24212;&#24615;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Meta Adaptation using Importance Weighted Demonstrations. (arXiv:1911.10322v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.10322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#35201;&#26435;&#37325;&#31034;&#33539;&#30340;&#20803;&#36866;&#24212;&#24615;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#29305;&#23450;&#20219;&#21153;&#30340;&#20808;&#21069;&#30693;&#35782;&#36827;&#34892;&#20998;&#37197;&#37325;&#35201;&#26435;&#37325;&#65292;&#23454;&#29616;&#20102;&#22312;&#20219;&#20309;&#30456;&#20851;&#20219;&#21153;&#19978;&#30340;&#27867;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20351;&#26426;&#22120;&#20154;&#22312;&#22810;&#26679;&#21270;&#29615;&#22659;&#20219;&#21153;&#20013;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#36890;&#36807;&#23569;&#37327;&#31034;&#33539;&#36866;&#24212;&#26410;&#30693;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#27169;&#20223;&#23398;&#20064;&#21464;&#24471;&#26497;&#20026;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#20013;&#65292;&#30001;&#20110;&#22823;&#22810;&#25968;&#20219;&#21153;&#30340;&#36712;&#36857;&#20998;&#24067;&#19981;&#26029;&#21464;&#21270;&#65292;&#20165;&#20165;&#22522;&#20110;&#36830;&#32493;&#32858;&#21512;&#30340;&#25968;&#25454;&#26469;&#36827;&#34892;&#27169;&#22411;&#25311;&#21512;&#26159;&#24466;&#21171;&#30340;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#20998;&#24067;&#21457;&#29983;&#22914;&#27492;&#22823;&#30340;&#21464;&#21270;&#65292;&#20197;&#33267;&#20110;&#26234;&#33021;&#20307;&#24456;&#38590;&#25512;&#26029;&#20986;&#26032;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#19968;&#32452;&#29305;&#23450;&#20219;&#21153;&#30340;&#20808;&#21069;&#30693;&#35782;&#36827;&#34892;&#20998;&#37197;&#37325;&#35201;&#26435;&#37325;&#65292;&#20174;&#32780;&#22312;&#20219;&#20309;&#30456;&#20851;&#20219;&#21153;&#19978;&#36827;&#34892;&#27867;&#21270;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20123;&#23454;&#39564;&#65292;&#22312;&#36825;&#20123;&#23454;&#39564;&#20013;&#65292;&#26426;&#22120;&#20154;&#20174;&#22810;&#26679;&#21270;&#30340;&#29615;&#22659;&#20219;&#21153;&#20013;&#35757;&#32451;&#65292;&#24182;&#33021;&#22815;&#36890;&#36807;&#23569;&#37327;&#31034;&#33539;&#36827;&#34892;&#23398;&#20064;&#65292;&#20174;&#32780;&#36866;&#24212;&#26410;&#30693;&#29615;&#22659;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#21407;&#22411;&#26426;&#22120;&#20154;&#31995;&#32479;&#65292;&#22312;&#35270;&#35273;&#23548;&#33322;&#20219;&#21153;&#19978;&#27979;&#35797;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#33021;&#22815;&#39564;&#35777;&#36825;&#20123;&#20551;&#35774;&#30340;&#23454;&#39564;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imitation learning has gained immense popularity because of its high sample-efficiency. However, in real-world scenarios, where the trajectory distribution of most of the tasks dynamically shifts, model fitting on continuously aggregated data alone would be futile. In some cases, the distribution shifts, so much, that it is difficult for an agent to infer the new task. We propose a novel algorithm to generalize on any related task by leveraging prior knowledge on a set of specific tasks, which involves assigning importance weights to each past demonstration. We show experiments where the robot is trained from a diversity of environmental tasks and is also able to adapt to an unseen environment, using few-shot learning. We also developed a prototype robot system to test our approach on the task of visual navigation, and experimental results obtained were able to confirm these suppositions.
&lt;/p&gt;</description></item></channel></rss>