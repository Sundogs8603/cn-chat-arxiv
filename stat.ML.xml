<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>MAGDiff&#26159;&#19968;&#31181;&#26032;&#30340;&#34920;&#31034;&#27861;&#65292;&#21487;&#20197;&#20174;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20013;&#25552;&#21462;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;&#65292;&#32780;&#19981;&#38656;&#35201;&#35757;&#32451;&#26032;&#27169;&#22411;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#23545;&#27604;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26469;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#26679;&#26412; Kolmogorov-Smirnov &#27979;&#35797;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.13271</link><description>&lt;p&gt;
MAGDiff: &#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks. (arXiv:2305.13271v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13271
&lt;/p&gt;
&lt;p&gt;
MAGDiff&#26159;&#19968;&#31181;&#26032;&#30340;&#34920;&#31034;&#27861;&#65292;&#21487;&#20197;&#20174;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20013;&#25552;&#21462;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;&#65292;&#32780;&#19981;&#38656;&#35201;&#35757;&#32451;&#26032;&#27169;&#22411;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#23545;&#27604;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26469;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#26679;&#26412; Kolmogorov-Smirnov &#27979;&#35797;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#65292;&#20294;&#20687;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#19968;&#26679;&#65292;&#23427;&#20204;&#21463;&#21040;&#25968;&#25454;&#36716;&#31227;&#30340;&#24433;&#21709;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#19982;&#23454;&#38469;&#24212;&#29992;&#25968;&#25454;&#20043;&#38388;&#20998;&#24067;&#23384;&#22312;&#24046;&#24322;&#26102;&#65292;&#20854;&#24615;&#33021;&#20250;&#21463;&#21040;&#20005;&#37325;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026; MAGDiff &#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20219;&#20309;&#32473;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20013;&#25552;&#21462;&#20986;&#26469;&#65292;&#24182;&#19988;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;&#65292;&#32780;&#19981;&#38656;&#35201;&#35757;&#32451;&#19987;&#38376;&#29992;&#20110;&#27492;&#20219;&#21153;&#30340;&#26032;&#27169;&#22411;&#12290;&#36825;&#20123;&#34920;&#31034;&#24418;&#24335;&#26159;&#36890;&#36807;&#27604;&#36739;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26469;&#35745;&#31639;&#30340;&#65292;&#23545;&#20110;&#23646;&#20110;&#35757;&#32451;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#25968;&#25454;&#21644;&#20219;&#21153;&#33258;&#36866;&#24212;&#32479;&#35745;&#37327;&#65292;&#29992;&#20110;&#26816;&#27979;&#24120;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#30340;&#20004;&#20010;&#26679;&#26412;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#20004;&#20010;&#26679;&#26412; Kolmogorov-Smirnov&#65288;KS&#65289;&#27979;&#35797;&#30340;&#32479;&#35745;&#21151;&#29575;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on sev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36125;&#21494;&#26031;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031; Stein &#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#21487;&#39640;&#25928;&#22320;&#32534;&#30721;&#31215;&#20998;&#20808;&#39564;&#20449;&#24687;&#24182;&#35745;&#31639;&#31215;&#20998;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#35813;&#26041;&#27861;&#23637;&#29616;&#20986;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.13248</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Numerical Integration with Neural Networks. (arXiv:2305.13248v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36125;&#21494;&#26031;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031; Stein &#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#21487;&#39640;&#25928;&#22320;&#32534;&#30721;&#31215;&#20998;&#20808;&#39564;&#20449;&#24687;&#24182;&#35745;&#31639;&#31215;&#20998;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#35813;&#26041;&#27861;&#23637;&#29616;&#20986;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#27010;&#29575;&#25968;&#20540;&#26041;&#27861;&#23545;&#20110;&#25968;&#20540;&#31215;&#20998;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#65306;&#21487;&#20197;&#32534;&#30721;&#31215;&#20998;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#21487;&#20197;&#37327;&#21270;&#31215;&#20998;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20294;&#26159;&#65292;&#36825;&#31867;&#26041;&#27861;&#20013;&#26368;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#31215;&#20998;&#31639;&#27861;&#65288;Bayesian Quadrature&#65289;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#22240;&#27492;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031; Stein &#31070;&#32463;&#32593;&#32476;&#12290;&#20851;&#38190;&#25104;&#20998;&#26159;&#22522;&#20110; Stein &#31639;&#23376;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#20197;&#21450;&#22522;&#20110; Laplace &#36817;&#20284;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#36817;&#20284;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#23548;&#33268;&#20102;&#22312;&#27969;&#34892;&#30340; Genz &#20989;&#25968;&#22522;&#20934;&#27979;&#35797;&#21644;&#22312;&#36125;&#21494;&#26031;&#21160;&#21147;&#31995;&#32479;&#20998;&#26512;&#20197;&#21450;&#22823;&#35268;&#27169;&#39118;&#21147;&#21457;&#30005;&#39044;&#27979;&#20013;&#35268;&#27169;&#30340;&#25968;&#37327;&#32423;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm.
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21033;&#29992;&#31561;&#21387;&#31561;&#28201;&#27969;&#24471;&#21040;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#65292;&#24182;&#22312;&#21333;&#21407;&#23376;&#27700;&#30340;&#32467;&#26230;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.13233</link><description>&lt;p&gt;
&#36890;&#36807;&#31561;&#21387;&#31561;&#28201;&#27969;&#33719;&#24471;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;
&lt;/p&gt;
&lt;p&gt;
Gibbs free energies via isobaric-isothermal flows. (arXiv:2305.13233v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13233
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21033;&#29992;&#31561;&#21387;&#31561;&#28201;&#27969;&#24471;&#21040;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#65292;&#24182;&#22312;&#21333;&#21407;&#23376;&#27700;&#30340;&#32467;&#26230;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32463;&#36807;&#35757;&#32451;&#21487;&#20174;&#31561;&#21387;&#31561;&#28201;&#65288;NPT&#65289;&#38598;&#21512;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#36817;&#20284;&#26041;&#27861;&#26469;&#24471;&#21040;&#23436;&#20840;&#28789;&#27963;&#30340;&#19977;&#26012;&#26230;&#31995;&#32479;&#30340;&#32852;&#21512;&#20998;&#24067;&#21644;&#31890;&#23376;&#22352;&#26631;&#20197;&#36798;&#21040;&#25152;&#38656;&#30340;&#20869;&#37096;&#21387;&#21147;&#12290;&#25105;&#20204;&#23545;&#21333;&#21407;&#23376;&#27700;&#22312;&#31435;&#26041;&#21644;&#20845;&#35282;&#20912;&#30456;&#20013;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#21457;&#29616;&#19982;&#24050;&#24314;&#31435;&#30340;&#22522;&#32447;&#30456;&#27604;&#65292;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#21644;&#20854;&#20182;&#21487;&#35266;&#27979;&#37327;&#30340;&#32467;&#26524;&#23436;&#20840;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a machine-learning model based on normalizing flows that is trained to sample from the isobaric-isothermal (NPT) ensemble. In our approach, we approximate the joint distribution of a fully-flexible triclinic simulation box and particle coordinates to achieve a desired internal pressure. We test our model on monatomic water in the cubic and hexagonal ice phases and find excellent agreement of Gibbs free energies and other observables compared with established baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#20108;&#38454;&#20449;&#24687;&#21152;&#36895;&#24046;&#20998;&#38544;&#31169;&#20984;&#20248;&#21270;&#65292;&#22312;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#31867;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20108;&#27425;&#25910;&#25947;&#36895;&#24230;&#21644;&#26368;&#20248;&#36229;&#39069;&#25439;&#22833;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.13209</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#38454;&#26041;&#27861;&#23454;&#29616;&#26356;&#24555;&#30340;&#24046;&#20998;&#38544;&#31169;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Faster Differentially Private Convex Optimization via Second-Order Methods. (arXiv:2305.13209v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#20108;&#38454;&#20449;&#24687;&#21152;&#36895;&#24046;&#20998;&#38544;&#31169;&#20984;&#20248;&#21270;&#65292;&#22312;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#31867;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20108;&#27425;&#25910;&#25947;&#36895;&#24230;&#21644;&#26368;&#20248;&#36229;&#39069;&#25439;&#22833;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26159;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#22312;&#20984;&#21644;&#38750;&#20984;&#30340;&#24773;&#20917;&#19979;&#22343;&#21487;&#20351;&#29992;&#12290;&#22914;&#26524;&#27809;&#26377;&#38544;&#31169;&#32422;&#26463;&#65292;&#20687;&#29275;&#39039;&#27861;&#36825;&#26679;&#30340;&#20108;&#38454;&#26041;&#27861;&#27604;&#26799;&#24230;&#19979;&#38477;&#36825;&#26679;&#30340;&#19968;&#38454;&#26041;&#27861;&#26356;&#24555;&#22320;&#25910;&#25947;&#12290;&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#25439;&#22833;&#20989;&#25968;&#30340;&#20108;&#38454;&#20449;&#24687;&#21152;&#36895;&#24046;&#20998;&#38544;&#31169;&#20984;&#20248;&#21270;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#20351;&#29992;Nesterov&#21644;Polyak&#30340;&#27491;&#21017;&#21270;&#19977;&#27425;&#29275;&#39039;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#31169;&#26377;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#23545;&#20110;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#31867;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#20108;&#27425;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#36229;&#39069;&#25439;&#22833;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#26080;&#32422;&#26463;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#35774;&#35745;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#20108;&#38454;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#20004;&#26041;&#38754;&#30740;&#31350;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#65292;&#19982;&#20854;&#20182;&#22522;&#32447;&#27604;&#36739;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22987;&#32456;&#23454;&#29616;&#20102;&#26368;&#20339;&#36229;&#39069;&#25439;&#22833;&#65292;&#27604;DP-GD/DP-SGD&#24555;10-40&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private (stochastic) gradient descent is the workhorse of DP private machine learning in both the convex and non-convex settings. Without privacy constraints, second-order methods, like Newton's method, converge faster than first-order methods like gradient descent. In this work, we investigate the prospect of using the second-order information from the loss function to accelerate DP convex optimization. We first develop a private variant of the regularized cubic Newton method of Nesterov and Polyak, and show that for the class of strongly convex loss functions, our algorithm has quadratic convergence and achieves the optimal excess loss. We then design a practical second-order DP algorithm for the unconstrained logistic regression problem. We theoretically and empirically study the performance of our algorithm. Empirical results show our algorithm consistently achieves the best excess loss compared to other baselines and is 10-40x faster than DP-GD/DP-SGD.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#23558;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#32435;&#20837;&#21040;SignSGD&#20013;&#65292;&#24182;&#20445;&#35777;&#20102;&#31867;&#20284;&#23436;&#25972;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.13187</link><description>&lt;p&gt;
SignSVRG: &#36890;&#36807;&#26041;&#24046;&#32553;&#20943;&#20462;&#27491;SignSGD
&lt;/p&gt;
&lt;p&gt;
SignSVRG: fixing SignSGD via variance reduction. (arXiv:2305.13187v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#23558;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#32435;&#20837;&#21040;SignSGD&#20013;&#65292;&#24182;&#20445;&#35777;&#20102;&#31867;&#20284;&#23436;&#25972;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#26080;&#32422;&#26463;&#20989;&#25968;&#30340;&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#23558;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#32435;&#20837;&#21040;SignSGD&#20013;&#65292;&#24182;&#20445;&#35777;&#20102;&#31867;&#20284;&#23436;&#25972;&#31526;&#21495;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;&#35813;&#26680;&#24515;&#24605;&#24819;&#39318;&#20808;&#24212;&#29992;&#20110;&#20984;&#21644;Lipschitz&#20989;&#25968;&#21644;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#28982;&#21518;&#36890;&#36807;&#26041;&#24046;&#32553;&#20943;&#25193;&#23637;&#21040;&#24179;&#28369;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24456;&#22522;&#30784;&#65292;&#27604;&#20856;&#22411;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#30340;&#35777;&#26126;&#31616;&#21333;&#24471;&#22810;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23545;&#20110;&#24179;&#28369;&#20989;&#25968;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#32473;&#20986;&#20102;&#26399;&#26395;&#26799;&#24230;&#33539;&#25968;&#30340;$ \mathcal {O}&#65288;1 / \ sqrt {T}&#65289;$&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#19988;&#23545;&#20110;&#24179;&#28369;&#20984;&#20989;&#25968;&#30340;&#24773;&#20917;&#65292;&#25910;&#25947;&#36895;&#24230;&#20026;$ \mathcal {O}&#65288;1 / T&#65289;$&#65292;&#24674;&#22797;&#20102;&#30830;&#23450;&#24615;&#26041;&#27861;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;SignSGD&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of unconstrained minimization of finite sums of functions. We propose a simple, yet, practical way to incorporate variance reduction techniques into SignSGD, guaranteeing convergence that is similar to the full sign gradient descent. The core idea is first instantiated on the problem of minimizing sums of convex and Lipschitz functions and is then extended to the smooth case via variance reduction. Our analysis is elementary and much simpler than the typical proof for variance reduction methods. We show that for smooth functions our method gives $\mathcal{O}(1 / \sqrt{T})$ rate for expected norm of the gradient and $\mathcal{O}(1/T)$ rate in the case of smooth convex functions, recovering convergence results of deterministic methods, while preserving computational advantages of SignSGD.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#29616;&#35937;&#65288;Deep Neural Collapse&#65289;&#65292;&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#20013;&#65292;&#21807;&#19968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#34920;&#29616;&#20986;&#20102;DNC&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#36890;&#36807;&#36873;&#25321;&#21512;&#36866;&#30340;&#36229;&#21442;&#25968;&#65292;&#20165;&#23545;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#22312;&#19981;&#25439;&#22833;&#31934;&#24230;&#30340;&#24773;&#20917;&#19979;&#21152;&#24555;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2305.13165</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#21487;&#35777;&#20026;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained Features Model. (arXiv:2305.13165v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#29616;&#35937;&#65288;Deep Neural Collapse&#65289;&#65292;&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#20013;&#65292;&#21807;&#19968;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#34920;&#29616;&#20986;&#20102;DNC&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#36890;&#36807;&#36873;&#25321;&#21512;&#36866;&#30340;&#36229;&#21442;&#25968;&#65292;&#20165;&#23545;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#22312;&#19981;&#25439;&#22833;&#31934;&#24230;&#30340;&#24773;&#20917;&#19979;&#21152;&#24555;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#22349;&#22604;(NC)&#25351;&#30340;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#26411;&#26399;&#26368;&#21518;&#19968;&#23618;&#30340;&#24778;&#22855;&#32467;&#26500;&#12290;&#26368;&#36817;&#26377;&#36234;&#26469;&#36234;&#22810;&#30340;&#23454;&#39564;&#35777;&#25454;&#34920;&#26126;NC&#21521;&#31070;&#32463;&#32593;&#32476;&#30340;&#36739;&#26089;&#23618;&#20256;&#25773;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#21518;&#19968;&#23618;&#20013;&#30340;NC&#22312;&#29702;&#35770;&#19978;&#24050;&#32463;&#30740;&#31350;&#24471;&#24456;&#22909;&#65292;&#20294;&#23545;&#20110;&#20854;&#22810;&#23618;&#32423;&#30340;&#23545;&#24212;&#29289;-&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;(DNC)&#21364;&#30693;&#20043;&#29978;&#23569;&#12290;&#29305;&#21035;&#22320;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#22522;&#20110;&#32447;&#24615;&#23618;&#25110;&#20165;&#28041;&#21450;&#26368;&#21518;&#20004;&#23618;&#65292;&#20294;&#20195;&#20215;&#21364;&#26159;&#19968;&#20010;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22522;&#20110;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#30340;&#24050;&#24314;&#31435;&#20998;&#26512;&#26694;&#26550;&#25512;&#24191;&#21040;&#22810;&#20010;&#38750;&#32447;&#24615;&#23618;&#32423;&#65292;&#24357;&#34917;&#20102;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#36129;&#29486;&#22312;&#20110;&#35777;&#26126;&#65292;&#22312;&#28145;&#24230;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#20013;&#65292;&#29992;&#20110;&#20108;&#20803;&#20998;&#31867;&#30340;&#21807;&#19968;&#20840;&#23616;&#26368;&#20248;&#35299;&#34920;&#29616;&#20986;&#20102;DNC&#30340;&#25152;&#26377;&#20856;&#22411;&#29305;&#24449;&#12290;&#36825;&#35299;&#37322;&#20102;&#29616;&#26377;&#20851;&#20110;DNC&#30340;&#23454;&#39564;&#35777;&#25454;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#20063;&#35777;&#26126;&#65292;&#36890;&#36807;&#36873;&#25321;&#21512;&#36866;&#30340;&#36229;&#21442;&#25968;&#65292;&#20165;&#23545;&#27169;&#22411;&#30340;&#26368;&#21518;&#19968;&#23618;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#22312;&#19981;&#25439;&#22833;&#31934;&#24230;&#30340;&#24773;&#20917;&#19979;&#21152;&#24555;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural collapse (NC) refers to the surprising structure of the last layer of deep neural networks in the terminal phase of gradient descent training. Recently, an increasing amount of experimental evidence has pointed to the propagation of NC to earlier layers of neural networks. However, while the NC in the last layer is well studied theoretically, much less is known about its multi-layered counterpart - deep neural collapse (DNC). In particular, existing work focuses either on linear layers or only on the last two layers at the price of an extra assumption. Our paper fills this gap by generalizing the established analytical framework for NC - the unconstrained features model - to multiple non-linear layers. Our key technical contribution is to show that, in a deep unconstrained features model, the unique global optimum for binary classification exhibits all the properties typical of DNC. This explains the existing experimental evidence of DNC. We also empirically show that (i) by opt
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#26631;&#37327;&#32593;&#32476;&#21644;&#20854;&#20182;&#27169;&#22411;&#65292;&#30740;&#31350;&#34920;&#26126;&#26799;&#24230;&#19979;&#38477;&#20250;&#21333;&#35843;&#36882;&#20943;&#26799;&#24230;&#27969;&#35299;&#30340;&#23574;&#38160;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.13064</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#21333;&#35843;&#36882;&#20943;&#20102;&#26631;&#37327;&#32593;&#32476;&#21644;&#20854;&#20182;&#27169;&#22411;&#20013;&#30340;&#26799;&#24230;&#27969;&#35299;&#30340;&#23574;&#38160;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow Solutions in Scalar Networks and Beyond. (arXiv:2305.13064v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13064
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#26631;&#37327;&#32593;&#32476;&#21644;&#20854;&#20182;&#27169;&#22411;&#65292;&#30740;&#31350;&#34920;&#26126;&#26799;&#24230;&#19979;&#38477;&#20250;&#21333;&#35843;&#36882;&#20943;&#26799;&#24230;&#27969;&#35299;&#30340;&#23574;&#38160;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#23558;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#24212;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25439;&#22833;&#20960;&#20046;&#19981;&#20250;&#21333;&#35843;&#36882;&#20943;&#12290;&#30456;&#21453;&#65292;&#25439;&#22833;&#20250;&#22312;&#26799;&#24230;&#19979;&#38477;&#25910;&#25947;&#21040;&#20854;&#8220;&#31283;&#23450;&#36793;&#32536;&#8221;&#65288;EoS&#65289;&#26102;&#25391;&#33633;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#31181;&#22312;GD&#35757;&#32451;&#36807;&#31243;&#20013;&#21333;&#35843;&#36882;&#20943;&#30340;&#37327;&#65306;&#26799;&#24230;&#27969;&#35299;&#65288;GFS&#65289;&#25152;&#36798;&#21040;&#30340;&#23574;&#38160;&#24230; - &#22914;&#26524;&#20174;&#29616;&#22312;&#24320;&#22987;&#21040;&#25910;&#25947;&#65292;&#25105;&#20204;&#20351;&#29992;&#26080;&#31351;&#23567;&#30340;&#27493;&#38271;&#36827;&#34892;&#35757;&#32451;&#25152;&#33719;&#24471;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#20351;&#29992;&#24179;&#26041;&#25439;&#22833;&#20998;&#26512;&#26631;&#37327;&#31070;&#32463;&#32593;&#32476;&#65292;&#36825;&#21487;&#33021;&#26159;EoS&#29616;&#35937;&#20173;&#28982;&#21457;&#29983;&#30340;&#26368;&#31616;&#21333;&#30340;&#24773;&#20917;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;GFS&#23574;&#38160;&#24230;&#21333;&#35843;&#36882;&#20943;&#12290;&#20351;&#29992;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;GD&#22312;&#26631;&#37327;&#32593;&#32476;&#20013;&#21487;&#20197;&#34987;&#35777;&#26126;&#25910;&#25947;&#21040;EoS&#30340;&#35774;&#32622;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;GD&#22312;&#24179;&#26041;&#22238;&#24402;&#27169;&#22411;&#20197;&#21450;&#23454;&#38469;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#21333;&#35843;&#36882;&#20943;&#20102;GFS&#30340;&#23574;&#38160;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research shows that when Gradient Descent (GD) is applied to neural networks, the loss almost never decreases monotonically. Instead, the loss oscillates as gradient descent converges to its ''Edge of Stability'' (EoS). Here, we find a quantity that does decrease monotonically throughout GD training: the sharpness attained by the gradient flow solution (GFS)-the solution that would be obtained if, from now until convergence, we train with an infinitesimal step size. Theoretically, we analyze scalar neural networks with the squared loss, perhaps the simplest setting where the EoS phenomena still occur. In this model, we prove that the GFS sharpness decreases monotonically. Using this result, we characterize settings where GD provably converges to the EoS in scalar networks. Empirically, we show that GD monotonically decreases the GFS sharpness in a squared regression model as well as practical neural network architectures.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#23618;&#25968;&#25454;&#21644;&#33410;&#28857;&#23646;&#24615;&#25972;&#21512;&#30340;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#23558;&#32593;&#32476;&#25968;&#25454;&#34920;&#31034;&#20026;&#25968;&#25454;&#30697;&#38453;&#30340;&#31616;&#21333;&#26041;&#24335;&#12290;&#35813;&#26041;&#27861;&#21487;&#26681;&#25454;&#20998;&#26512;&#30446;&#26631;&#36873;&#25321;&#25968;&#25454;&#30697;&#38453;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#21387;&#32553;&#25968;&#25454;&#30697;&#38453;&#30340;&#26041;&#27861;&#23558;&#20854;&#34892;&#20998;&#25104;&#31038;&#21306;&#65292;&#20174;&#32780;&#36827;&#34892;&#24378;&#22823;&#30340;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2305.13012</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#22810;&#23618;&#25968;&#25454;&#21644;&#33410;&#28857;&#23646;&#24615;&#25972;&#21512;&#30340;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A network community detection method with integration of data from multiple layers and node attributes. (arXiv:2305.13012v1 [physics.soc-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13012
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#22810;&#23618;&#25968;&#25454;&#21644;&#33410;&#28857;&#23646;&#24615;&#25972;&#21512;&#30340;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#23558;&#32593;&#32476;&#25968;&#25454;&#34920;&#31034;&#20026;&#25968;&#25454;&#30697;&#38453;&#30340;&#31616;&#21333;&#26041;&#24335;&#12290;&#35813;&#26041;&#27861;&#21487;&#26681;&#25454;&#20998;&#26512;&#30446;&#26631;&#36873;&#25321;&#25968;&#25454;&#30697;&#38453;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#21387;&#32553;&#25968;&#25454;&#30697;&#38453;&#30340;&#26041;&#27861;&#23558;&#20854;&#34892;&#20998;&#25104;&#31038;&#21306;&#65292;&#20174;&#32780;&#36827;&#34892;&#24378;&#22823;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#32593;&#32476;&#26159;&#24403;&#21069;&#22797;&#26434;&#32593;&#32476;&#30740;&#31350;&#30340;&#28909;&#28857;&#12290;&#22312;&#36825;&#26679;&#30340;&#32593;&#32476;&#20013;&#65292;&#21487;&#33021;&#23384;&#22312;&#22810;&#31181;&#31867;&#22411;&#30340;&#38142;&#25509;&#20197;&#21450;&#35768;&#22810;&#33410;&#28857;&#23646;&#24615;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;&#22810;&#23618;&#21644;&#20854;&#20182;&#31867;&#22411;&#30340;&#22797;&#26434;&#32593;&#32476;&#24212;&#29992;&#65292;&#23558;&#21508;&#31181;&#25968;&#25454;&#19982;&#25299;&#25169;&#20449;&#24687;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#36827;&#34892;&#24378;&#22823;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#24335;&#65292;&#23558;&#32593;&#32476;&#25968;&#25454;&#34920;&#31034;&#20026;&#25968;&#25454;&#30697;&#38453;&#65292;&#20854;&#20013;&#34892;&#23545;&#24212;&#33410;&#28857;&#65292;&#21015;&#23545;&#24212;&#25968;&#25454;&#39033;&#12290;&#21015;&#25968;&#21487;&#20197;&#20219;&#24847;&#36873;&#25321;&#65292;&#22240;&#27492;&#21487;&#20197;&#36890;&#36807;&#28155;&#21152;&#21015;&#36731;&#26494;&#25193;&#23637;&#25968;&#25454;&#30697;&#38453;&#12290;&#25968;&#25454;&#30697;&#38453;&#21487;&#20197;&#26681;&#25454;&#20998;&#26512;&#30446;&#26631;&#36873;&#25321;&#65292;&#24182;&#19988;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#26377;&#24456;&#22823;&#19981;&#21516;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#20801;&#35768;&#25968;&#25454;&#30697;&#38453;&#26368;&#22823;&#21387;&#32553;&#30340;&#26041;&#27861;&#23558;&#25968;&#25454;&#30697;&#38453;&#30340;&#34892;&#20998;&#25104;&#31038;&#21306;&#12290;&#20026;&#20102;&#21387;&#32553;&#25968;&#25454;&#30697;&#38453;&#65292;&#25105;&#20204;&#24314;&#35758;&#25193;&#23637;&#25152;&#35859;&#30340;&#38750;&#26041;&#38453;&#30340;&#24120;&#35268;&#20998;&#35299;&#26041;&#27861;&#12290;&#25105;&#20204;&#20026;&#20960;&#31181;&#20855;&#20307;&#24773;&#20917;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multilayer networks are in the focus of the current complex network study. In such networks multiple types of links may exist as well as many attributes for nodes. To fully use multilayer -- and other types of complex networks in applications, the merging of various data with topological information renders a powerful analysis. First, we suggest a simple way of representing network data in a data matrix where rows correspond to the nodes, and columns correspond to the data items. The number of columns is allowed to be arbitrary, so that the data matrix can be easily expanded by adding columns. The data matrix can be chosen according to targets of the analysis, and may vary a lot from case to case. Next, we partition the rows of the data matrix into communities using a method which allows maximal compression of the data matrix. For compressing a data matrix, we suggest to extend so called regular decomposition method for non-square matrices. We illustrate our method for several types of
&lt;/p&gt;</description></item><item><title>funLOCI&#26159;&#19968;&#31181;&#19977;&#27493;&#20998;&#35010;&#24335;&#20998;&#23618;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#38024;&#23545;&#21151;&#33021;&#25968;&#25454;&#25214;&#20986;&#26412;&#22320;&#32858;&#31867;&#65292;&#36890;&#36807;&#20511;&#37492;&#22810;&#20803;&#21644;&#21151;&#33021;&#32858;&#31867;&#30340;&#24605;&#24819;&#65292;&#37319;&#29992;&#21152;&#27861;&#27169;&#22411;&#32771;&#34385;&#26354;&#32447;&#30340;&#24418;&#29366;&#65292;&#21487;&#20351;&#29992;&#26641;&#29366;&#22270;&#21487;&#35270;&#21270;&#21644;&#25351;&#23548;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#39069;&#22806;&#30340;&#27493;&#39588;&#23558;&#32467;&#26524;&#25968;&#37327;&#38477;&#33267;&#26368;&#23567;&#12290;</title><link>http://arxiv.org/abs/2305.12991</link><description>&lt;p&gt;
funLOCI: &#19968;&#31181;&#38024;&#23545;&#21151;&#33021;&#25968;&#25454;&#30340;&#26412;&#22320;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
funLOCI: a local clustering algorithm for functional data. (arXiv:2305.12991v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12991
&lt;/p&gt;
&lt;p&gt;
funLOCI&#26159;&#19968;&#31181;&#19977;&#27493;&#20998;&#35010;&#24335;&#20998;&#23618;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#38024;&#23545;&#21151;&#33021;&#25968;&#25454;&#25214;&#20986;&#26412;&#22320;&#32858;&#31867;&#65292;&#36890;&#36807;&#20511;&#37492;&#22810;&#20803;&#21644;&#21151;&#33021;&#32858;&#31867;&#30340;&#24605;&#24819;&#65292;&#37319;&#29992;&#21152;&#27861;&#27169;&#22411;&#32771;&#34385;&#26354;&#32447;&#30340;&#24418;&#29366;&#65292;&#21487;&#20351;&#29992;&#26641;&#29366;&#22270;&#21487;&#35270;&#21270;&#21644;&#25351;&#23548;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#39069;&#22806;&#30340;&#27493;&#39588;&#23558;&#32467;&#26524;&#25968;&#37327;&#38477;&#33267;&#26368;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#38382;&#39064;&#28041;&#21450;&#21040;&#20855;&#26377;&#19968;&#20010;&#26080;&#38480;&#36830;&#32493;&#32500;&#24230;&#30340;&#25968;&#25454;&#65306;&#21151;&#33021;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102; funLOCI &#31639;&#27861;&#65292;&#23427;&#20801;&#35768;&#35782;&#21035;&#21151;&#33021;&#26412;&#22320;&#32858;&#31867;&#25110;&#21151;&#33021;&#22522;&#22240;&#24231;&#65292;&#21363;&#34920;&#29616;&#20986;&#30456;&#20284;&#34892;&#20026;&#30340;&#20989;&#25968;&#23376;&#38598;/&#32452;&#22312;&#30456;&#21516;&#21306;&#38388;&#20869;&#30340;&#36830;&#32493;&#23376;&#38598;&#20013;&#12290;&#21151;&#33021;&#26412;&#22320;&#32858;&#31867;&#30340;&#23450;&#20041;&#20511;&#37492;&#20102;&#22810;&#20803;&#21644;&#21151;&#33021;&#32858;&#31867;&#20197;&#21450;&#21452;&#32858;&#31867;&#30340;&#24605;&#24819;&#65292;&#24182;&#22522;&#20110;&#19968;&#20010;&#21152;&#27861;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#26354;&#32447;&#30340;&#24418;&#29366;&#12290;funLOCI &#26159;&#19968;&#20010;&#22522;&#20110;&#20998;&#35010;&#24335;&#20998;&#23618;&#32858;&#31867;&#30340;&#19977;&#27493;&#31639;&#27861;&#12290;&#20351;&#29992;&#26641;&#29366;&#22270;&#21487;&#20197;&#21487;&#35270;&#21270;&#21644;&#25351;&#23548;&#25628;&#32034;&#36807;&#31243;&#20197;&#21450;&#20999;&#21106;&#38408;&#20540;&#30340;&#36873;&#25321;&#12290;&#20026;&#20102;&#22788;&#29702;&#22823;&#37327;&#30340;&#26412;&#22320;&#32858;&#31867;&#65292;&#23454;&#29616;&#20102;&#39069;&#22806;&#30340;&#27493;&#39588;&#20197;&#23558;&#32467;&#26524;&#25968;&#37327;&#38477;&#33267;&#26368;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, more and more problems are dealing with data with one infinite continuous dimension: functional data. In this paper, we introduce the funLOCI algorithm which allows to identify functional local clusters or functional loci, i.e., subsets/groups of functions exhibiting similar behaviour across the same continuous subset of the domain. The definition of functional local clusters leverages ideas from multivariate and functional clustering and biclustering and it is based on an additive model which takes into account the shape of the curves. funLOCI is a three-step algorithm based on divisive hierarchical clustering. The use of dendrograms allows to visualize and to guide the searching procedure and the cutting thresholds selection. To deal with the large quantity of local clusters, an extra step is implemented to reduce the number of results to the minimum.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#30340;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#21457;&#29616;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.12883</link><description>&lt;p&gt;
&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#26469;&#30740;&#31350;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors. (arXiv:2305.12883v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12883
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#30340;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#21457;&#29616;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26368;&#23567;$\ell_2$&#33539;&#25968;&#65288;&#26080;&#23725;&#65289;&#25554;&#20540;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#30740;&#31350;&#26041;&#20852;&#26410;&#33406;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20998;&#26512;&#37117;&#23616;&#38480;&#20110;&#31616;&#21333;&#30340;&#22238;&#24402;&#35823;&#24046;&#32467;&#26500;&#65292;&#20551;&#35774;&#35823;&#24046;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20855;&#26377;&#38646;&#22343;&#20540;&#21644;&#30456;&#21516;&#30340;&#26041;&#24046;&#65292;&#19982;&#29305;&#24449;&#21521;&#37327;&#26080;&#20851;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#29702;&#35770;&#20998;&#26512;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#26816;&#26597;&#26080;&#23725;&#25554;&#20540;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#20801;&#35768;&#26356;&#19968;&#33324;&#30340;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#65292;&#25171;&#30772;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28508;&#22312;&#22909;&#22788;&#65292;&#36890;&#36807;&#25551;&#32472;&#26377;&#38480;&#26679;&#26412;&#20013;&#30340;&#22343;&#26041;&#35823;&#24046;&#26469;&#34920;&#24449;&#22343;&#26041;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#23545;&#20110;&#26679;&#26412;&#37327;&#65292;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a significant growth in research focusing on minimum $\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to a simple regression error structure, assuming independent and identically distributed errors with zero mean and common variance, independent of the feature vectors. Additionally, the main focus of these theoretical analyses has been on the out-of-sample prediction risk. This paper breaks away from the existing literature by examining the mean squared error of the ridgeless interpolation least squares estimator, allowing for more general assumptions about the regression errors. Specifically, we investigate the potential benefits of overparameterization by characterizing the mean squared error in a finite sample. Our findings reveal that including a large number of unimportant parameters relative to the sample size can effectively reduce the mean squared error of the estimator. N
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.12809</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#26469;&#32763;&#36716;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yang&#31561;&#20154;&#21457;&#29616;&#65292;&#20165;&#21024;&#38500;1%&#30340;&#35757;&#32451;&#25968;&#25454;&#23601;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#32467;&#26524;&#32763;&#36716;&#12290;&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#30340;&#26222;&#36941;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#19968;&#20010;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#21487;&#21542;&#23548;&#33268;&#27979;&#35797;&#32467;&#26524;&#32763;&#36716;&#65311;&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#36825;&#31181;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22987;&#32456;&#33021;&#22815;&#20135;&#29983;&#25104;&#21151;&#30340;&#32467;&#26524;&#12290;&#36825;&#31181;&#26426;&#21046;&#26377;&#22810;&#37325;&#20316;&#29992;&#65306;&#65288;1&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#34917;&#20805;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24674;&#22797;&#21487;&#33021;&#38169;&#35823;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#65307;&#65288;2&#65289;&#35780;&#20272;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#26412;&#25991;&#21457;&#29616;&#23376;&#38598;&#30340;&#22823;&#23567;&#19982;&#35757;&#32451;&#38598;&#20013;&#22122;&#22768;&#25968;&#25454;&#30340;&#27604;&#20363;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#20851;&#31995;&#65307;&#65288;3&#65289;&#25552;&#20379;&#20102;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#30340;&#35265;&#35299;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#20195;&#34920;&#20102;&#23545;&#35782;&#21035;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#38382;&#39064;&#30340;&#31532;&#19968;&#27425;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#24773;&#20917;&#19979;&#32570;&#22833;&#26631;&#31614;&#19988;&#23384;&#22312;&#36873;&#25321;&#20559;&#24046;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.12789</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#22240;&#26524;&#25512;&#26029;&#65306;&#38754;&#21521;&#34928;&#20943;&#37325;&#21472;&#30340;&#36873;&#25321;&#20559;&#24046;&#19979;&#21487;&#27867;&#21270;&#30340;&#21452;&#31283;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Causal Inference: Generalizable and Double Robust Inference for Average Treatment Effects under Selection Bias with Decaying Overlap. (arXiv:2305.12789v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#24773;&#20917;&#19979;&#32570;&#22833;&#26631;&#31614;&#19988;&#23384;&#22312;&#36873;&#25321;&#20559;&#24046;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#28151;&#28102;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#21463;&#21040;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23384;&#22312;&#21487;&#33021;&#32570;&#22833;&#30340;&#26631;&#31614;&#24773;&#20917;&#19979;&#30340;ATE&#20272;&#35745;&#38382;&#39064;&#12290;&#26631;&#35760;&#25351;&#31034;&#31526;&#30340;&#26465;&#20214;&#20542;&#21521;&#24471;&#20998;&#20801;&#35768;&#20381;&#36182;&#20110;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#34928;&#20943;&#32780;&#34928;&#20943;&#8212;&#8212;&#20174;&#32780;&#20801;&#35768;&#26410;&#26631;&#35760;&#25968;&#25454;&#22823;&#23567;&#27604;&#26631;&#35760;&#25968;&#25454;&#22823;&#23567;&#22686;&#38271;&#24471;&#26356;&#24555;&#12290;&#36825;&#31181;&#24773;&#20917;&#22635;&#34917;&#20102;&#21322;&#30417;&#30563;&#65288;SS&#65289;&#21644;&#32570;&#22833;&#25968;&#25454;&#25991;&#29486;&#20013;&#30340;&#37325;&#35201;&#31354;&#30333;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20801;&#35768;&#36873;&#25321;&#20559;&#24046;&#30340;&#38543;&#26426;&#32570;&#22833;&#65288;MAR&#65289;&#26426;&#21046;&#8212;&#8212;&#36825;&#36890;&#24120;&#22312;&#26631;&#20934;&#30340;SS&#25991;&#29486;&#20013;&#26159;&#31105;&#27490;&#30340;&#65292;&#24182;&#19988;&#22312;&#32570;&#22833;&#25968;&#25454;&#25991;&#29486;&#20013;&#36890;&#24120;&#38656;&#35201;&#19968;&#20010;&#27491;&#24615;&#26465;&#20214;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;ATE&#30340;&#19968;&#33324;&#21452;&#31283;DR-DMAR&#65288;decaying&#65289;SS&#20272;&#35745;&#22120;&#65292;&#36825;&#31181;&#20272;&#35745;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Average treatment effect (ATE) estimation is an essential problem in the causal inference literature, which has received significant recent attention, especially with the presence of high-dimensional confounders. We consider the ATE estimation problem in high dimensions when the observed outcome (or label) itself is possibly missing. The labeling indicator's conditional propensity score is allowed to depend on the covariates, and also decay uniformly with sample size - thus allowing for the unlabeled data size to grow faster than the labeled data size. Such a setting fills in an important gap in both the semi-supervised (SS) and missing data literatures. We consider a missing at random (MAR) mechanism that allows selection bias - this is typically forbidden in the standard SS literature, and without a positivity condition - this is typically required in the missing data literature. We first propose a general doubly robust 'decaying' MAR (DR-DMAR) SS estimator for the ATE, which is cons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#20998;&#24067;&#39044;&#27979;&#21306;&#22495;&#30340;&#26500;&#36896;&#65292;&#20197;&#25551;&#36848;&#19981;&#21516;&#29615;&#22659;&#19979;&#25968;&#25454;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#19968;&#31181;&#36866;&#24212;&#29305;&#23450;&#29615;&#22659;&#30340;&#21152;&#26435;&#19968;&#33268;&#24615;&#20998;&#25968;&#26500;&#24314;&#33258;&#36866;&#24212;&#30340;&#19968;&#33268;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20854;&#26465;&#20214;&#24179;&#22343;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.12686</link><description>&lt;p&gt;
&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#19968;&#33268;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Conformal Inference for Invariant Risk Minimization. (arXiv:2305.12686v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12686
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#20998;&#24067;&#39044;&#27979;&#21306;&#22495;&#30340;&#26500;&#36896;&#65292;&#20197;&#25551;&#36848;&#19981;&#21516;&#29615;&#22659;&#19979;&#25968;&#25454;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#19968;&#31181;&#36866;&#24212;&#29305;&#23450;&#29615;&#22659;&#30340;&#21152;&#26435;&#19968;&#33268;&#24615;&#20998;&#25968;&#26500;&#24314;&#33258;&#36866;&#24212;&#30340;&#19968;&#33268;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20854;&#26465;&#20214;&#24179;&#22343;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24212;&#29992;&#21487;&#33021;&#20250;&#21463;&#21040;&#20998;&#24067;&#20559;&#31227;&#30340;&#20005;&#37325;&#24433;&#21709;&#65292;&#22240;&#20026;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#20013;&#23545;&#35757;&#32451;&#21644;&#27979;&#35797;&#26679;&#26412;&#32676;&#20307;&#21516;&#36136;&#24615;&#30340;&#20551;&#35774;&#21487;&#33021;&#22312;&#23454;&#38469;&#24773;&#20917;&#20013;&#24182;&#19981;&#21487;&#34892;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#24335;&#26159;&#20351;&#29992;&#19981;&#21464;&#23398;&#20064;&#65292;&#20363;&#22914;&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;IRM&#65289;&#65292;&#20197;&#33719;&#24471;&#19968;&#31181;&#19981;&#21464;&#34920;&#31034;&#65292;&#26377;&#21161;&#20110;&#22312;&#20998;&#24067;&#20559;&#31227;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#24471;&#26080;&#20998;&#24067;&#39044;&#27979;&#21306;&#22495;&#65292;&#20197;&#25551;&#36848;&#25968;&#25454;&#26469;&#33258;&#19981;&#21516;&#29615;&#22659;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#19981;&#21464;&#34920;&#31034;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#19968;&#31181;&#36866;&#24212;&#29305;&#23450;&#29615;&#22659;&#30340;&#21152;&#26435;&#19968;&#33268;&#24615;&#20998;&#25968;&#65292;&#21033;&#29992;&#21152;&#26435;&#19968;&#33268;&#24615;&#20998;&#25968;&#26500;&#24314;&#33258;&#36866;&#24212;&#19968;&#33268;&#21306;&#38388;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#35777;&#26126;&#20854;&#26465;&#20214;&#24179;&#22343;&#20540;&#12290;&#20026;&#20102;&#23637;&#31034;&#26412;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
The application of machine learning models can be significantly impeded by the occurrence of distributional shifts, as the assumption of homogeneity between the population of training and testing samples in machine learning and statistics may not be feasible in practical situations. One way to tackle this problem is to use invariant learning, such as invariant risk minimization (IRM), to acquire an invariant representation that aids in generalization with distributional shifts. This paper develops methods for obtaining distribution-free prediction regions to describe uncertainty estimates for invariant representations, accounting for the distribution shifts of data from different environments. Our approach involves a weighted conformity score that adapts to the specific environment in which the test sample is situated. We construct an adaptive conformal interval using the weighted conformity score and prove its conditional average under certain conditions. To demonstrate the effectiven
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22312;&#21482;&#26377;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#38598;&#21644;&#24369;&#21487;&#23454;&#29616;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#35206;&#30422;&#20998;&#24067;&#30340;&#38468;&#21152;&#20391;&#20449;&#24687;&#23454;&#29616;&#20102;&#26679;&#26412;&#26377;&#25928;&#31163;&#32447;RL&#65292;&#24182;&#23637;&#31034;&#20102;&#35206;&#30422;&#20998;&#24067;&#22312;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#38656;&#38468;&#21152;&#25968;&#25454;&#37327;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.12679</link><description>&lt;p&gt;
&#24102;&#26377;&#38468;&#21152;&#35206;&#30422;&#20998;&#24067;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Offline Reinforcement Learning with Additional Covering Distributions. (arXiv:2305.12679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22312;&#21482;&#26377;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#38598;&#21644;&#24369;&#21487;&#23454;&#29616;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#35206;&#30422;&#20998;&#24067;&#30340;&#38468;&#21152;&#20391;&#20449;&#24687;&#23454;&#29616;&#20102;&#26679;&#26412;&#26377;&#25928;&#31163;&#32447;RL&#65292;&#24182;&#23637;&#31034;&#20102;&#35206;&#30422;&#20998;&#24067;&#22312;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#38656;&#38468;&#21152;&#25968;&#25454;&#37327;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#20174;&#26085;&#24535;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#21363;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#23613;&#31649;&#24050;&#32463;&#20184;&#20986;&#20102;&#24456;&#22810;&#21162;&#21147;&#65292;&#22312;&#20855;&#26377;&#29702;&#35770;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#30340;&#29616;&#26377;&#31639;&#27861;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#20855;&#26377;&#25506;&#32034;&#24615;&#25968;&#25454;&#35206;&#30422;&#25110;&#24378;&#21487;&#23454;&#29616;&#30340;&#20989;&#25968;&#31867;&#65292;&#36825;&#22312;&#29616;&#23454;&#20013;&#24456;&#38590;&#28385;&#36275;&#12290;&#34429;&#28982;&#26368;&#36817;&#26377;&#19968;&#20123;&#25104;&#21151;&#35299;&#20915;&#36825;&#20123;&#24378;&#20551;&#35774;&#30340;&#20316;&#21697;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#38656;&#35201;&#21482;&#33021;&#30001;&#19968;&#37096;&#20998;MDP&#28385;&#36275;&#30340;&#38388;&#38553;&#20551;&#35774;&#65292;&#35201;&#20040;&#20351;&#29992;&#34892;&#20026;&#27491;&#21017;&#21270;&#65292;&#20351;&#24471;&#23398;&#20064;&#31574;&#30053;&#30340;&#26368;&#20248;&#24615;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#36793;&#38469;&#37325;&#35201;&#24615;&#25277;&#26679;(MIS)&#30340;&#31616;&#21333;&#31639;&#27861;&#30340;&#26679;&#26412;&#26377;&#38480;&#20445;&#35777;&#65292;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#35206;&#30422;&#20998;&#24067;&#30340;&#38468;&#21152;&#20391;&#20449;&#24687;&#19979;&#20165;&#20855;&#26377;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#38598;&#21644;&#24369;&#21487;&#23454;&#29616;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#29992;MDP&#30340;&#26679;&#26412;&#26377;&#25928;&#31163;&#32447;RL&#26159;&#21487;&#33021;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35206;&#30422;&#20998;&#24067;&#22312;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#38656;&#38468;&#21152;&#25968;&#25454;&#37327;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23427;&#33021;&#22815;&#26377;&#30410;&#20110;&#23398;&#20064;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study learning optimal policies from a logged dataset, i.e., offline RL, with function approximation. Despite the efforts devoted, existing algorithms with theoretic finite-sample guarantees typically assume exploratory data coverage or strong realizable function classes, which is hard to be satisfied in reality. While there are recent works that successfully tackle these strong assumptions, they either require the gap assumptions that only could be satisfied by part of MDPs or use the behavior regularization that makes the optimality of learned policy even intractable. To solve this challenge, we provide finite-sample guarantees for a simple algorithm based on marginalized importance sampling (MIS), showing that sample-efficient offline RL for general MDPs is possible with only a partial coverage dataset and weak realizable function classes given additional side information of a covering distribution. Furthermore, we demonstrate that the covering distribution trades off prior knowl
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;TSAB&#65292;&#36890;&#36807;&#24314;&#27169;&#21442;&#19982;&#32773;&#30340;&#36712;&#36857;&#20026;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#32467;&#21512;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#26410;&#26469;&#29366;&#24577;&#65292;&#20197;&#36866;&#24212;&#38750;Markovian&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#22312;&#25552;&#39640;&#25968;&#25454;&#20381;&#20174;&#24615;&#21644;/&#25110;&#21442;&#19982;&#24230;&#30340;&#36164;&#28304;&#20998;&#37197;&#26041;&#38754;&#20248;&#20110;&#36807;&#21435;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.12640</link><description>&lt;p&gt;
&#38750;Markovian&#19990;&#30028;&#20013;&#30340;&#26377;&#38480;&#36164;&#28304;&#20998;&#37197;&#65306;&#27597;&#23156;&#20445;&#20581;&#30340;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Limited Resource Allocation in a Non-Markovian World: The Case of Maternal and Child Healthcare. (arXiv:2305.12640v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12640
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;TSAB&#65292;&#36890;&#36807;&#24314;&#27169;&#21442;&#19982;&#32773;&#30340;&#36712;&#36857;&#20026;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#32467;&#21512;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#26410;&#26469;&#29366;&#24577;&#65292;&#20197;&#36866;&#24212;&#38750;Markovian&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#22312;&#25552;&#39640;&#25968;&#25454;&#20381;&#20174;&#24615;&#21644;/&#25110;&#21442;&#19982;&#24230;&#30340;&#36164;&#28304;&#20998;&#37197;&#26041;&#38754;&#20248;&#20110;&#36807;&#21435;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#21307;&#30103;&#20445;&#20581;&#35745;&#21010;&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#21442;&#19982;&#32773;&#30340;&#20381;&#20174;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65288;&#20363;&#22914;&#65292;&#20174;&#21355;&#29983;&#24037;&#20316;&#32773;&#22788;&#21450;&#26102;&#33719;&#24471;&#25903;&#25345;&#30005;&#35805;&#65289;&#65292;&#23433;&#25490;&#24178;&#39044;&#25514;&#26045;&#20197;&#22686;&#21152;&#20381;&#20174;&#24615;&#21644;/&#25110;&#21442;&#19982;&#24230;&#30340;&#38382;&#39064;&#12290;&#36807;&#21435;&#30340;&#30740;&#31350;&#24050;&#32463;&#25104;&#21151;&#22320;&#20026;&#36825;&#20010;&#38382;&#39064;&#24320;&#21457;&#20102;&#20960;&#31867;&#22522;&#20110;&#19981;&#23433;&#23450;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;RMAB&#65289;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#36807;&#21435;&#30340;RMAB&#26041;&#27861;&#37117;&#20551;&#35774;&#21442;&#19982;&#32773;&#30340;&#34892;&#20026;&#36981;&#24490;Markov&#23646;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26469;&#33258;&#25105;&#20204;&#21512;&#20316;NGO ARMMAN&#30340;&#23381;&#22919;&#20581;&#24247;&#24847;&#35782;&#35745;&#21010;&#30340;&#30495;&#23454;&#25968;&#25454;&#23545;Markov&#20551;&#35774;&#23384;&#22312;&#26174;&#30528;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;RMAB&#25193;&#23637;&#21040;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#65292;&#36825;&#26159;&#20197;&#21069;&#19981;&#21463;&#37325;&#35270;&#30340;&#39046;&#22495;&#12290;&#20026;&#20102;&#35299;&#20915;&#24191;&#20041;&#30340;&#38750;Markovian RMAB&#35774;&#32622;&#65292;&#25105;&#20204;&#65288;i&#65289;&#23558;&#27599;&#20010;&#21442;&#19982;&#32773;&#36712;&#36857;&#24314;&#27169;&#20026;&#26102;&#38388;&#24207;&#21015;&#65292;&#65288;ii&#65289;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#23398;&#20064;&#22797;&#26434;&#30340;&#27169;&#24335;&#21644;&#21160;&#24577;&#26469;&#39044;&#27979;&#26410;&#26469;&#29366;&#24577;&#65292;&#65288;iii&#65289;&#25552;&#20986;Time-series Arm Bandit&#65288;TSAB&#65289;&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#33719;&#36807;&#21435;&#21644;&#26410;&#26469;&#29366;&#24577;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#26469;&#36866;&#24212;&#38750;Markovian&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;TSAB&#20248;&#20110;&#20197;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#23454;&#29616;&#26356;&#22909;&#30340;&#36164;&#28304;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of many healthcare programs depends on participants' adherence. We consider the problem of scheduling interventions in low resource settings (e.g., placing timely support calls from health workers) to increase adherence and/or engagement. Past works have successfully developed several classes of Restless Multi-armed Bandit (RMAB) based solutions for this problem. Nevertheless, all past RMAB approaches assume that the participants' behaviour follows the Markov property. We demonstrate significant deviations from the Markov assumption on real-world data on a maternal health awareness program from our partner NGO, ARMMAN. Moreover, we extend RMABs to continuous state spaces, a previously understudied area. To tackle the generalised non-Markovian RMAB setting we (i) model each participant's trajectory as a time-series, (ii) leverage the power of time-series forecasting models to learn complex patterns and dynamics to predict future states, and (iii) propose the Time-series Arm 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24050;&#30693;&#30340;&#21442;&#25968;&#20998;&#24067;&#29992;&#20110;&#25968;&#25454;&#20999;&#29255;&#30340;&#30830;&#20999;&#21518;&#36873;&#25321;&#25512;&#26029;&#26041;&#27861;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.12581</link><description>&lt;p&gt;
&#24102;&#21442;&#25968;&#20998;&#24067;&#30340;&#25968;&#25454;&#20999;&#29255;&#30830;&#20999;&#21518;&#36873;&#25321;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
A parametric distribution for exact post-selection inference with data carving. (arXiv:2305.12581v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24050;&#30693;&#30340;&#21442;&#25968;&#20998;&#24067;&#29992;&#20110;&#25968;&#25454;&#20999;&#29255;&#30340;&#30830;&#20999;&#21518;&#36873;&#25321;&#25512;&#26029;&#26041;&#27861;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#36873;&#25321;&#25512;&#26029;&#65288;PoSI&#65289;&#26159;&#19968;&#31181;&#32479;&#35745;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#20551;&#35774;&#29983;&#25104;&#21644;&#27979;&#35797;&#20351;&#29992;&#30456;&#21516;&#30340;&#25968;&#25454;&#26469;&#28304;&#26102;&#33719;&#21462;&#26377;&#25928;&#30340;&#32622;&#20449;&#21306;&#38388;&#21644;p&#20540;&#12290; PoSI&#21487;&#29992;&#20110;&#19968;&#31995;&#21015;&#27969;&#34892;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;Lasso&#12290; &#25968;&#25454;&#20999;&#29255;&#26159;PoSI&#30340;&#21464;&#20307;&#65292;&#22312;&#25512;&#26029;&#26102;&#38388;&#23558;&#37096;&#20998;&#20445;&#30041;&#25968;&#25454;&#19982;&#20551;&#35774;&#29983;&#25104;&#25968;&#25454;&#32467;&#21512;&#20351;&#29992;&#12290;&#34429;&#28982;&#25968;&#25454;&#20999;&#29255;&#20855;&#26377;&#26377;&#21560;&#24341;&#21147;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#24615;&#36136;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#35745;&#31639;&#26114;&#36149;&#30340;MCMC&#26041;&#27861;&#26469;&#25191;&#34892;&#25512;&#26029;&#12290;&#26412;&#25991;&#30340;&#20851;&#38190;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#21487;&#22522;&#20110;&#24050;&#30693;&#30340;&#21442;&#25968;&#20998;&#24067;&#26500;&#24314;&#25968;&#25454;&#20999;&#29255;&#36807;&#31243;&#30340;&#26530;&#36724;&#37327;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#39640;&#26031;&#21709;&#24212;&#30340;&#19968;&#32452;&#22810;&#38754;&#20307;&#32422;&#26463;&#19979;&#65292;&#25968;&#25454;&#20999;&#29255;&#23558;&#36981;&#24490;&#27491;&#24120;&#20540;&#21644;&#25130;&#26029;&#27491;&#24120;&#20540;&#20043;&#21644;&#65288;SNTN&#65289;&#65292;&#36825;&#26159;&#25130;&#26029;&#21452;&#21464;&#37327;&#27491;&#24577;&#20998;&#24067;&#30340;&#19968;&#20010;&#21464;&#20307;&#12290;&#36825;&#31181;&#27934;&#23519;&#21147;&#30340;&#20027;&#35201;&#24433;&#21709;&#26159;&#20351;&#25968;&#25454;&#20999;&#29255;&#30340;&#26377;&#25928;&#21644;&#30830;&#20999;&#30340;&#21518;&#36873;&#25321;&#25512;&#26029;&#25104;&#20026;&#21487;&#33021;&#65292;&#32780;&#26080;&#38656;&#37319;&#29992;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;MCMC&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Post-selection inference (PoSI) is a statistical technique for obtaining valid confidence intervals and p-values when hypothesis generation and testing use the same source of data. PoSI can be used on a range of popular algorithms including the Lasso. Data carving is a variant of PoSI in which a portion of held out data is combined with the hypothesis generating data at inference time. While data carving has attractive theoretical and empirical properties, existing approaches rely on computationally expensive MCMC methods to carry out inference. This paper's key contribution is to show that pivotal quantities can be constructed for the data carving procedure based on a known parametric distribution. Specifically, when the selection event is characterized by a set of polyhedral constraints on a Gaussian response, data carving will follow the sum of a normal and a truncated normal (SNTN), which is a variant of the truncated bivariate normal distribution. The main impact of this insight i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.12569</link><description>&lt;p&gt;
&#26377;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#26159;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#24517;&#22791;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Generative Modeling is All You Need for Marked Temporal Point Processes. (arXiv:2305.12569v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#26465;&#20214;&#29983;&#25104;&#22120;&#20197;&#21382;&#21490;&#35266;&#23519;&#20316;&#20026;&#36755;&#20837;&#65292;&#29983;&#25104;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#35813;&#27169;&#22411;&#20855;&#26377;&#39640;&#25928;&#12289;&#28789;&#27963;&#21644;&#34920;&#31034;&#33021;&#21147;&#31561;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29983;&#25104;&#24314;&#27169;&#30340;&#36827;&#27493;&#20351;&#24471;&#20174;&#19978;&#19979;&#25991;&#20449;&#24687;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#20869;&#23481;&#25104;&#20026;&#21487;&#33021;&#65292;&#20294;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#22914;&#20309;&#25945;&#27169;&#22411;&#30693;&#36947;&#20309;&#26102;&#29983;&#25104;&#20869;&#23481;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20107;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#20174;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#20013;&#25552;&#21462;&#20854;&#32479;&#35745;&#30452;&#35273;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#24178;&#20928;&#12289;&#28789;&#27963;&#21644;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36866;&#29992;&#20110;&#28041;&#21450;&#22810;&#32500;&#26631;&#35760;&#30340;&#21508;&#31181;&#24212;&#29992;&#12290;&#25105;&#20204;&#26088;&#22312;&#25429;&#25417;&#28857;&#36807;&#31243;&#30340;&#20998;&#24067;&#32780;&#19981;&#38656;&#26126;&#30830;&#25351;&#23450;&#26465;&#20214;&#24378;&#24230;&#25110;&#27010;&#29575;&#23494;&#24230;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#26465;&#20214;&#29983;&#25104;&#22120;&#65292;&#20197;&#20107;&#20214;&#21382;&#21490;&#20026;&#36755;&#20837;&#24182;&#29983;&#25104;&#22312;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#20107;&#20214;&#19979;&#65292;&#21487;&#33021;&#21457;&#29983;&#30340;&#39640;&#36136;&#37327;&#38543;&#21518;&#20107;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#31995;&#21015;&#21033;&#30410;&#65292;&#21253;&#25324;&#22312;&#23398;&#20064;&#27169;&#22411;&#21644;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#30340;&#24322;&#24120;&#25928;&#29575;&#20197;&#21450;&#30456;&#24403;&#22823;&#30340;&#34920;&#31034;&#33021;&#21147;&#26469;&#25429;&#25417;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advancements in generative modeling have made it possible to generate high-quality content from context information, but a key question remains: how to teach models to know when to generate content? To answer this question, this study proposes a novel event generative model that draws its statistical intuition from marked temporal point processes, and offers a clean, flexible, and computationally efficient solution for a wide range of applications involving multi-dimensional marks. We aim to capture the distribution of the point process without explicitly specifying the conditional intensity or probability density. Instead, we use a conditional generator that takes the history of events as input and generates the high-quality subsequent event that is likely to occur given the prior observations. The proposed framework offers a host of benefits, including exceptional efficiency in learning the model and generating samples, as well as considerable representational power to capture
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#21333;&#35843;&#23398;&#20064;&#29575; SGD &#30340;&#31639;&#27861;&#20381;&#28982;&#21487;&#20197;&#36798;&#21040;&#28176;&#36817;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#65292;&#20294;&#26159;&#36825;&#26159;&#20197;&#20809;&#28369;&#24230;&#24120;&#25968;&#20986;&#29616;&#28798;&#38590;&#24615;&#25351;&#25968;&#32423;&#20381;&#36182;&#20026;&#20195;&#20215;&#30340;&#65292;&#22240;&#27492;&#30740;&#31350;&#20102;&#19977;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#26469;&#38450;&#27490;&#36825;&#31181;&#25351;&#25968;&#20381;&#36182;&#65292;&#23454;&#29616;&#20102;&#20102;&#20934;&#30830;&#24615;&#21644;&#33258;&#36866;&#24212;&#24615;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.12475</link><description>&lt;p&gt;
&#21333;&#35843;&#23398;&#20064;&#29575; SGD &#30340;&#38480;&#21046;&#21644;&#33258;&#36866;&#24212;&#26041;&#27861;&#30340;&#23041;&#21147;
&lt;/p&gt;
&lt;p&gt;
Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods. (arXiv:2305.12475v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#21333;&#35843;&#23398;&#20064;&#29575; SGD &#30340;&#31639;&#27861;&#20381;&#28982;&#21487;&#20197;&#36798;&#21040;&#28176;&#36817;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#65292;&#20294;&#26159;&#36825;&#26159;&#20197;&#20809;&#28369;&#24230;&#24120;&#25968;&#20986;&#29616;&#28798;&#38590;&#24615;&#25351;&#25968;&#32423;&#20381;&#36182;&#20026;&#20195;&#20215;&#30340;&#65292;&#22240;&#27492;&#30740;&#31350;&#20102;&#19977;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#26469;&#38450;&#27490;&#36825;&#31181;&#25351;&#25968;&#20381;&#36182;&#65292;&#23454;&#29616;&#20102;&#20102;&#20934;&#30830;&#24615;&#21644;&#33258;&#36866;&#24212;&#24615;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#30340;&#32463;&#20856;&#20998;&#26512;&#20381;&#36182;&#20110;&#32463;&#36807;&#32454;&#35843;&#30340;&#22810;&#39033;&#24335;&#34928;&#20943;&#27493;&#38271;&#65292;&#32780;&#36825;&#38656;&#35201;&#20381;&#36182;&#20110;&#38382;&#39064;&#21442;&#25968;&#65292;&#20363;&#22914;&#26446;&#26222;&#24076;&#33576;&#24179;&#28369;&#24120;&#25968;&#65292;&#32780;&#22312;&#23454;&#36341;&#20013;&#36825;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#30340; $\eta &gt; 0$ &#30340;&#21333;&#35843;&#23398;&#20064;&#29575; SGD&#65288;untuned SGD&#65289;&#65292;&#20854;&#20381;&#28982;&#33021;&#22815;&#36798;&#21040;&#28176;&#36817;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230; $ \tilde{O}(T^{-1/4}) $&#12290;&#28982;&#32780;&#65292;&#36825;&#26159;&#20197;&#20809;&#28369;&#24230;&#24120;&#25968;&#20986;&#29616;&#28798;&#38590;&#24615;&#25351;&#25968;&#32423;&#20381;&#36182;&#20026;&#20195;&#20215;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26080;&#22122;&#22768;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#26041;&#26696;&#20063;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#12290;&#25509;&#30528;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#8212;&#8212;&#24402;&#19968;&#21270;&#30340; SGD&#65288;NSGD&#65289;&#65292;AMSGrad &#21644; AdaGrad&#8212;&#8212;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#38450;&#27490;&#22914;&#27492;&#25351;&#25968;&#20381;&#36182;&#23384;&#22312;&#26102;&#30340;&#23041;&#21147;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35777;&#26126;&#65292;&#25903;&#25345;&#20102;&#23454;&#36341;&#20013;&#20351;&#29992;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#26080;&#38656;&#26356;&#22810;&#20449;&#24687;&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The classical analysis of Stochastic Gradient Descent (SGD) with polynomially decaying stepsize $\eta_t = \eta/\sqrt{t}$ relies on well-tuned $\eta$ depending on problem parameters such as Lipschitz smoothness constant, which is often unknown in practice. In this work, we prove that SGD with arbitrary $\eta &gt; 0$, referred to as untuned SGD, still attains an order-optimal convergence rate $\widetilde{O}(T^{-1/4})$ in terms of gradient norm for minimizing smooth objectives. Unfortunately, it comes at the expense of a catastrophic exponential dependence on the smoothness constant, which we show is unavoidable for this scheme even in the noiseless setting. We then examine three families of adaptive methods $\unicode{x2013}$ Normalized SGD (NSGD), AMSGrad, and AdaGrad $\unicode{x2013}$ unveiling their power in preventing such exponential dependency in the absence of information about the smoothness parameter and boundedness of stochastic gradients. Our results provide theoretical justificat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;q-GRFs&#65288;&#25311;&#38543;&#26426;&#25968;&#33945;&#29305;&#21345;&#32599;&#22270;&#38543;&#26426;&#29305;&#24449;&#65289;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#26045;&#21152;&#25239;&#29983;&#32456;&#27490;&#30340;&#26041;&#27861;&#35825;&#23548;&#31639;&#27861;&#38543;&#26426;&#28459;&#27493;&#38271;&#24230;&#20043;&#38388;&#30340;&#36127;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#22270;&#38543;&#26426;&#29305;&#24449;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#33021;&#22815;&#36866;&#29992;&#20110;&#20219;&#20309;&#22270;&#24418;&#25299;&#25169;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.12470</link><description>&lt;p&gt;
&#25311;&#38543;&#26426;&#25968;&#33945;&#29305;&#21345;&#32599;&#22270;&#38543;&#26426;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Quasi-Monte Carlo Graph Random Features. (arXiv:2305.12470v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12470
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;q-GRFs&#65288;&#25311;&#38543;&#26426;&#25968;&#33945;&#29305;&#21345;&#32599;&#22270;&#38543;&#26426;&#29305;&#24449;&#65289;&#30340;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#26045;&#21152;&#25239;&#29983;&#32456;&#27490;&#30340;&#26041;&#27861;&#35825;&#23548;&#31639;&#27861;&#38543;&#26426;&#28459;&#27493;&#38271;&#24230;&#20043;&#38388;&#30340;&#36127;&#30456;&#20851;&#24615;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#22270;&#38543;&#26426;&#29305;&#24449;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#33021;&#22815;&#36866;&#29992;&#20110;&#20219;&#20309;&#22270;&#24418;&#25299;&#25169;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#21046;&#26469;&#25913;&#21892;&#26368;&#36817;&#24341;&#20837;&#30340;&#22270;&#38543;&#26426;&#29305;&#24449;&#65288;GRFs&#65289;&#31867;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#26045;&#21152;&#25239;&#29983;&#32456;&#27490; - &#19968;&#31181;&#37319;&#26679;&#26356;&#22810;&#26679;&#21270;&#30340;&#38543;&#26426;&#28459;&#27493;&#30340;&#36807;&#31243;&#26469;&#35825;&#23548;&#31639;&#27861;&#38543;&#26426;&#28459;&#27493;&#38271;&#24230;&#20043;&#38388;&#30340;&#36127;&#30456;&#20851;&#24615;&#12290;&#23427;&#20855;&#26377;&#38750;&#24120;&#31616;&#21333;&#30340;&#23454;&#29616;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#25311;&#38543;&#26426;&#25968;&#33945;&#29305;&#21345;&#32599;&#22270;&#38543;&#26426;&#29305;&#24449;&#65288;q-GRFs&#65289;&#30340;&#24615;&#36136;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#35777;&#26126;&#23427;&#20204;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#20135;&#29983;&#26356;&#20302;&#26041;&#24046;&#30340;2-&#27491;&#21017;&#21270;&#25289;&#26222;&#25289;&#26031;&#26680;&#20272;&#35745;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#20219;&#20309;&#22270;&#24418;&#25299;&#25169;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21508;&#31181;&#20219;&#21153;&#30340;&#32463;&#39564;&#20934;&#30830;&#24230;&#25913;&#36827;&#65292;&#21253;&#25324;&#26032;&#30340;&#23454;&#29992;&#24212;&#29992;&#31243;&#24207;&#65306;&#22270;&#25193;&#25955;&#36807;&#31243;&#30340;&#26102;&#38388;&#26377;&#25928;&#36924;&#36817;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;q-GRFs&#26159;&#31532;&#19968;&#20010;&#23545;&#32452;&#21512;&#23545;&#35937;&#19978;&#23450;&#20041;&#30340;&#26680;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#30340;&#25311;&#38543;&#26426;&#25968;&#33945;&#29305;&#21345;&#32599;&#26041;&#26696;&#65292;&#20174;&#32780;&#24341;&#21457;&#20102;&#20851;&#20110;&#22270;&#24418;&#30340;&#30456;&#20851;&#24615;&#30340;&#26032;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel mechanism to improve the accuracy of the recently-introduced class of graph random features (GRFs). Our method induces negative correlations between the lengths of the algorithm's random walks by imposing antithetic termination: a procedure to sample more diverse random walks which may be of independent interest. It has a trivial drop-in implementation. We derive strong theoretical guarantees on the properties of these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance estimators of the 2-regularised Laplacian kernel under mild conditions. Remarkably, our results hold for any graph topology. We demonstrate empirical accuracy improvements on a variety of tasks including a new practical application: time-efficient approximation of the graph diffusion process. To our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo scheme for kernels defined on combinatorial objects, inviting new research on correlations between graph rand
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#32852;&#37030;&#25919;&#31574;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#26412;&#22320;&#31574;&#30053;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#32447;&#19979;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#65292;&#21487;&#20197;&#22312;&#19981;&#20132;&#25442;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25919;&#31574;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20840;&#23616;&#21644;&#23616;&#37096;&#21518;&#24724;&#19978;&#38480;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#29992;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.12407</link><description>&lt;p&gt;
&#24322;&#26500;&#35266;&#27979;&#25968;&#25454;&#19979;&#30340;&#32852;&#37030;&#24369;&#21270;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Offline Policy Learning with Heterogeneous Observational Data. (arXiv:2305.12407v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#32852;&#37030;&#25919;&#31574;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22522;&#20110;&#26412;&#22320;&#31574;&#30053;&#32858;&#21512;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#32447;&#19979;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#31574;&#30053;&#36827;&#34892;&#35757;&#32451;&#65292;&#21487;&#20197;&#22312;&#19981;&#20132;&#25442;&#21407;&#22987;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25919;&#31574;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#20840;&#23616;&#21644;&#23616;&#37096;&#21518;&#24724;&#19978;&#38480;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#29992;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22522;&#20110;&#24322;&#26500;&#25968;&#25454;&#28304;&#30340;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#20010;&#24615;&#21270;&#20915;&#31574;&#25919;&#31574;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#32852;&#37030;&#35774;&#32622;&#20013;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#20013;&#22830;&#26381;&#21153;&#22120;&#26088;&#22312;&#22312;&#20998;&#24067;&#22312;&#24322;&#26500;&#28304;&#19978;&#30340;&#25968;&#25454;&#19978;&#23398;&#20064;&#19968;&#20010;&#25919;&#31574;&#65292;&#32780;&#19981;&#20132;&#25442;&#23427;&#20204;&#30340;&#21407;&#22987;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32852;&#37030;&#25919;&#31574;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#20351;&#29992;&#21452;&#37325;&#31283;&#20581;&#32447;&#19979;&#31574;&#30053;&#35780;&#20272;&#21644;&#23398;&#20064;&#31574;&#30053;&#35757;&#32451;&#30340;&#26412;&#22320;&#31574;&#30053;&#32858;&#21512;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#24724;&#20998;&#26512;&#26041;&#27861;&#26469;&#30830;&#31435;&#23545;&#20840;&#23616;&#21518;&#24724;&#27010;&#24565;&#30340;&#26377;&#38480;&#26679;&#26412;&#19978;&#30028;&#65292;&#36825;&#20010;&#20840;&#23616;&#21518;&#24724;&#27010;&#24565;&#36328;&#36234;&#20102;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38024;&#23545;&#27599;&#20010;&#21333;&#29420;&#30340;&#23458;&#25143;&#31471;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#23616;&#37096;&#21518;&#24724;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#30001;&#30456;&#23545;&#20110;&#25152;&#26377;&#20854;&#20182;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#21464;&#21270;&#29305;&#24449;&#24615;&#22320;&#25551;&#36848;&#12290;&#25105;&#20204;&#29992;&#23454;&#39564;&#32467;&#26524;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#25552;&#20379;&#20102;&#24322;&#26500;&#23458;&#25143;&#31471;&#21442;&#19982;&#32852;&#37030;&#23398;&#20064;&#30340;&#20215;&#20540;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning personalized decision policies on observational data from heterogeneous data sources. Moreover, we examine this problem in the federated setting where a central server aims to learn a policy on the data distributed across the heterogeneous sources without exchanging their raw data. We present a federated policy learning algorithm based on aggregation of local policies trained with doubly robust offline policy evaluation and learning strategies. We provide a novel regret analysis for our approach that establishes a finite-sample upper bound on a notion of global regret across a distribution of clients. In addition, for any individual client, we establish a corresponding local regret upper bound characterized by the presence of distribution shift relative to all other clients. We support our theoretical findings with experimental results. Our analysis and experiments provide insights into the value of heterogeneous client participation in federation fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#24403;&#38598;&#25104;&#27169;&#22411;&#30340;&#38169;&#35823;&#29575;&#36739;&#21333;&#20010;&#27169;&#22411;&#26356;&#20302;&#65292;&#19988;&#27169;&#22411;&#38388;&#19981;&#21516;&#24847;&#30340;&#38169;&#35823;&#29575;&#36229;&#36807;&#24179;&#22343;&#38169;&#35823;&#29575;&#65292;&#21017;&#38598;&#25104;&#23398;&#20064;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.12313</link><description>&lt;p&gt;
&#38598;&#25104;&#23398;&#20064;&#20309;&#26102;&#26377;&#25928;&#65311;
&lt;/p&gt;
&lt;p&gt;
When are ensembles really effective?. (arXiv:2305.12313v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#24403;&#38598;&#25104;&#27169;&#22411;&#30340;&#38169;&#35823;&#29575;&#36739;&#21333;&#20010;&#27169;&#22411;&#26356;&#20302;&#65292;&#19988;&#27169;&#22411;&#38388;&#19981;&#21516;&#24847;&#30340;&#38169;&#35823;&#29575;&#36229;&#36807;&#24179;&#22343;&#38169;&#35823;&#29575;&#65292;&#21017;&#38598;&#25104;&#23398;&#20064;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#23398;&#20064;&#22312;&#32479;&#35745;&#25968;&#25454;&#20998;&#26512;&#20013;&#20855;&#26377;&#24736;&#20037;&#30340;&#21382;&#21490;&#65292;&#24182;&#26377;&#35768;&#22810;&#20855;&#26377;&#24433;&#21709;&#21147;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#38598;&#25104;&#23398;&#20064;&#30340;&#22909;&#22788;&#19981;&#26159;&#26222;&#36941;&#19988;&#19981;&#26126;&#26174;&#12290;&#26412;&#25991;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#20004;&#26041;&#38754;&#30740;&#31350;&#20102;&#38598;&#25104;&#23398;&#20064;&#20309;&#26102;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembling has a long history in statistical data analysis, with many impactful applications. However, in many modern machine learning settings, the benefits of ensembling are less ubiquitous and less obvious. We study, both theoretically and empirically, the fundamental question of when ensembling yields significant performance improvements in classification tasks. Theoretically, we prove new results relating the \emph{ensemble improvement rate} (a measure of how much ensembling decreases the error rate versus a single model, on a relative scale) to the \emph{disagreement-error ratio}. We show that ensembling improves performance significantly whenever the disagreement rate is large relative to the average error rate; and that, conversely, one classifier is often enough whenever the disagreement rate is low relative to the average error rate. On the way to proving these results, we derive, under a mild condition called \emph{competence}, improved upper and lower bounds on the average 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#36317;&#31163;&#23545;&#19977;&#32500;&#29289;&#20307;&#36827;&#34892;&#23545;&#40784;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20248;&#21270;&#23454;&#29616;&#35745;&#31639;&#12290;&#22312;&#23545;&#40784;&#30495;&#23454;&#34507;&#30333;&#36136;&#20998;&#23376;&#26041;&#38754;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#24182;&#38416;&#26126;&#20102;&#23545;&#26032;&#36317;&#31163;&#20989;&#25968;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2305.12310</link><description>&lt;p&gt;
&#20351;&#29992;Wasserstein&#36317;&#31163;&#23545;&#23494;&#24230;&#22320;&#22270;&#36827;&#34892;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Alignment of Density Maps in Wasserstein Distance. (arXiv:2305.12310v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#36317;&#31163;&#23545;&#19977;&#32500;&#29289;&#20307;&#36827;&#34892;&#23545;&#40784;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20248;&#21270;&#23454;&#29616;&#35745;&#31639;&#12290;&#22312;&#23545;&#40784;&#30495;&#23454;&#34507;&#30333;&#36136;&#20998;&#23376;&#26041;&#38754;&#65292;&#35813;&#31639;&#27861;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#65292;&#24182;&#38416;&#26126;&#20102;&#23545;&#26032;&#36317;&#31163;&#20989;&#25968;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#23558;&#19977;&#32500;&#29289;&#20307;&#34920;&#31034;&#20026;&#23494;&#24230;&#22320;&#22270;&#24182;&#36827;&#34892;&#23545;&#40784;&#65292;&#35813;&#31639;&#27861;&#30340;&#21160;&#26426;&#26159;&#22312;&#20919;&#20923;&#30005;&#23376;&#26174;&#24494;&#38236;&#20013;&#30340;&#24212;&#29992;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#22312;&#21018;&#24615;&#21464;&#25442;&#21518;&#23494;&#24230;&#22320;&#22270;&#20043;&#38388;&#26368;&#23567;&#21270;1-Wasserstein&#36317;&#31163;&#12290;&#24341;&#20837;&#30340;&#25439;&#22833;&#20989;&#25968;&#27604;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#22330;&#20855;&#26377;&#26356;&#22909;&#30340;&#29305;&#24615;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#35745;&#31639;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#30495;&#23454;&#34507;&#30333;&#36136;&#20998;&#23376;&#30340;&#23545;&#40784;&#26041;&#38754;&#65292;&#35813;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#22312;&#23545;&#40784;&#24322;&#36136;&#23545;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#26032;&#36317;&#31163;&#20989;&#25968;&#30340;&#28508;&#22312;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose an algorithm for aligning three-dimensional objects when represented as density maps, motivated by applications in cryogenic electron microscopy. The algorithm is based on minimizing the 1-Wasserstein distance between the density maps after a rigid transformation. The induced loss function enjoys a more benign landscape than its Euclidean counterpart and Bayesian optimization is employed for computation. Numerical experiments show improved accuracy and efficiency over existing algorithms on the alignment of real protein molecules. In the context of aligning heterogeneous pairs, we illustrate a potential need for new distance functions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#38382;&#39064;&#20026;&#25237;&#24433;&#30697;&#38453;&#30340;&#38750;&#20984;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#33021;&#22815;&#30830;&#23450;&#26368;&#20248;&#35299;&#30340;&#20998;&#31163;&#20998;&#25903;&#23450;&#30028;&#26041;&#26696;&#65292;&#24182;&#19988;&#36890;&#36807;&#26032;&#39062;&#21644;&#32039;&#23494;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;&#65292;&#20351;&#24471;&#26368;&#20248;&#24615;&#24046;&#36317;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20943;&#23569;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2305.12292</link><description>&lt;p&gt;
&#26368;&#20248;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#65306;&#21322;&#23450;&#26494;&#24347;&#21644;&#29305;&#24449;&#21521;&#37327;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Optimal Low-Rank Matrix Completion: Semidefinite Relaxations and Eigenvector Disjunctions. (arXiv:2305.12292v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12292
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#37325;&#26032;&#34920;&#36848;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#38382;&#39064;&#20026;&#25237;&#24433;&#30697;&#38453;&#30340;&#38750;&#20984;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#33021;&#22815;&#30830;&#23450;&#26368;&#20248;&#35299;&#30340;&#20998;&#31163;&#20998;&#25903;&#23450;&#30028;&#26041;&#26696;&#65292;&#24182;&#19988;&#36890;&#36807;&#26032;&#39062;&#21644;&#32039;&#23494;&#30340;&#20984;&#26494;&#24347;&#26041;&#27861;&#65292;&#20351;&#24471;&#26368;&#20248;&#24615;&#24046;&#36317;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#20943;&#23569;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#30340;&#30446;&#30340;&#26159;&#35745;&#31639;&#19968;&#20010;&#22797;&#26434;&#24230;&#26368;&#23567;&#30340;&#30697;&#38453;&#65292;&#20197;&#23613;&#21487;&#33021;&#20934;&#30830;&#22320;&#24674;&#22797;&#32473;&#23450;&#30340;&#19968;&#32452;&#35266;&#27979;&#25968;&#25454;&#65292;&#24182;&#19988;&#20855;&#26377;&#20247;&#22810;&#24212;&#29992;&#65292;&#22914;&#20135;&#21697;&#25512;&#33616;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#35299;&#20915;&#20302;&#31209;&#30697;&#38453;&#22635;&#34917;&#30340;&#26041;&#27861;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#34429;&#28982;&#39640;&#24230;&#21487;&#25193;&#23637;&#24182;&#19988;&#36890;&#24120;&#33021;&#22815;&#30830;&#23450;&#39640;&#36136;&#37327;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#19981;&#20855;&#22791;&#20219;&#20309;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20302;&#31209;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#25237;&#24433;&#30697;&#38453;&#30340;&#38750;&#20984;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#19968;&#31181;&#20998;&#31163;&#20998;&#25903;&#23450;&#30028;&#26041;&#26696;&#26469;&#37325;&#26032;&#23457;&#35270;&#30697;&#38453;&#22635;&#34917;&#38382;&#39064;&#65292;&#20197;&#23454;&#29616;&#26368;&#20248;&#24615;&#23548;&#21521;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#20026;&#19968;&#32452;&#31209;&#19968;&#30697;&#38453;&#30340;&#21644;&#65292;&#24182;&#36890;&#36807; Shor &#26494;&#24347;&#26469;&#28608;&#21169;&#27599;&#20010;&#31209;&#19968;&#30697;&#38453;&#20013;&#30340;&#27599;&#20010; 2*2 &#23567;&#30697;&#38453;&#30340;&#34892;&#21015;&#24335;&#20026;&#38646;&#65292;&#20174;&#32780;&#25512;&#23548;&#20986;&#19968;&#31181;&#26032;&#39062;&#19988;&#36890;&#24120;&#24456;&#32039;&#30340;&#20984;&#26494;&#24347;&#31867;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26032;&#20984;&#26494;&#24347;&#26041;&#27861;&#23558;&#26368;&#20248;&#24615;&#24046;&#36317;&#20943;&#23569;&#20102;&#20004;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-rank matrix completion consists of computing a matrix of minimal complexity that recovers a given set of observations as accurately as possible, and has numerous applications such as product recommendation. Unfortunately, existing methods for solving low-rank matrix completion are heuristics that, while highly scalable and often identifying high-quality solutions, do not possess any optimality guarantees. We reexamine matrix completion with an optimality-oriented eye, by reformulating low-rank problems as convex problems over the non-convex set of projection matrices and implementing a disjunctive branch-and-bound scheme that solves them to certifiable optimality. Further, we derive a novel and often tight class of convex relaxations by decomposing a low-rank matrix as a sum of rank-one matrices and incentivizing, via a Shor relaxation, that each two-by-two minor in each rank-one matrix has determinant zero. In numerical experiments, our new convex relaxations decrease the optimali
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30149;&#20363;&#23545;&#29031;&#30740;&#31350;&#25968;&#25454;&#38598;&#30340;&#26377;&#30417;&#30563;&#24335;&#38477;&#32500;&#26041;&#27861;CIR&#65292;&#24182;&#22312;&#20445;&#30041;&#21709;&#24212;&#21464;&#37327;&#30340;&#20989;&#25968;&#20851;&#31995;&#30340;&#21516;&#26102;&#65292;&#30452;&#25509;&#40723;&#21169;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#23558;&#21069;&#26223;&#32452;&#19982;&#32972;&#26223;&#32452;&#20998;&#31163;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.12287</link><description>&lt;p&gt;
&#23545;&#27604;&#21453;&#21521;&#22238;&#24402;&#30340;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contrastive inverse regression for dimension reduction. (arXiv:2305.12287v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30149;&#20363;&#23545;&#29031;&#30740;&#31350;&#25968;&#25454;&#38598;&#30340;&#26377;&#30417;&#30563;&#24335;&#38477;&#32500;&#26041;&#27861;CIR&#65292;&#24182;&#22312;&#20445;&#30041;&#21709;&#24212;&#21464;&#37327;&#30340;&#20989;&#25968;&#20851;&#31995;&#30340;&#21516;&#26102;&#65292;&#30452;&#25509;&#40723;&#21169;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#23558;&#21069;&#26223;&#32452;&#19982;&#32972;&#26223;&#32452;&#20998;&#31163;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#24335;&#38477;&#32500;&#65288;SDR&#65289;&#22240;&#33021;&#22312;&#20445;&#30041;&#19982;&#25351;&#23450;&#21709;&#24212;&#21464;&#37327;&#30340;&#20989;&#25968;&#20851;&#31995;&#30340;&#21516;&#26102;&#20943;&#23569;&#39640;&#32500;&#21327;&#21464;&#37327;&#65292;&#27491;&#25104;&#20026;&#25968;&#25454;&#31185;&#23398;&#26085;&#30410;&#20851;&#27880;&#30340;&#35805;&#39064;&#12290;&#28982;&#32780;&#29616;&#26377;&#30340;SDR&#26041;&#27861;&#24182;&#38750;&#36866;&#29992;&#20110;&#20998;&#26512;&#30149;&#20363;&#23545;&#29031;&#30740;&#31350;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#21644;&#21033;&#29992;&#20165;&#23384;&#22312;&#20110;&#30149;&#20363;&#32452;&#25110;&#30149;&#20363;&#32452;&#20013;&#23500;&#21547;&#30340;&#20302;&#32500;&#32467;&#26500;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#23545;&#27604;&#21453;&#21521;&#22238;&#24402;&#65288;CIR&#65289;&#30340;&#26377;&#30417;&#30563;&#24335;&#38477;&#32500;&#26041;&#27861;&#65292;&#19987;&#20026;&#23545;&#27604;&#24773;&#22659;&#32780;&#35774;&#35745;&#12290;CIR&#22312;Stiefel&#27969;&#24418;&#19978;&#24341;&#20837;&#20102;&#20248;&#21270;&#38382;&#39064;&#21644;&#38750;&#31283;&#23450;&#30446;&#26631;&#65292;&#30452;&#25509;&#40723;&#21169;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#23558;&#21069;&#26223;&#32452;&#19982;&#32972;&#26223;&#32452;&#20998;&#31163;&#65292;&#24182;&#22312;&#20445;&#30041;&#21709;&#24212;&#21464;&#37327;&#30340;&#20989;&#25968;&#20851;&#31995;&#30340;&#21516;&#26102;&#36827;&#34892;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;CIR&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised dimension reduction (SDR) has been a topic of growing interest in data science, as it enables the reduction of high-dimensional covariates while preserving the functional relation with certain response variables of interest. However, existing SDR methods are not suitable for analyzing datasets collected from case-control studies. In this setting, the goal is to learn and exploit the low-dimensional structure unique to or enriched by the case group, also known as the foreground group. While some unsupervised techniques such as the contrastive latent variable model and its variants have been developed for this purpose, they fail to preserve the functional relationship between the dimension-reduced covariates and the response variable. In this paper, we propose a supervised dimension reduction method called contrastive inverse regression (CIR) specifically designed for the contrastive setting. CIR introduces an optimization problem defined on the Stiefel manifold with a non-sta
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#26080;&#20998;&#24067;&#27169;&#22411;&#26080;&#20559;&#22238;&#24402;&#26657;&#20934;&#26041;&#27861;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#30340;&#32479;&#35745;&#20445;&#35777;&#21644;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.12283</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#26041;&#27861;&#19979;&#30340;&#26080;&#20998;&#24067;&#27169;&#22411;&#26080;&#20559;&#22238;&#24402;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods. (arXiv:2305.12283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#26080;&#20998;&#24067;&#27169;&#22411;&#26080;&#20559;&#22238;&#24402;&#26657;&#20934;&#26041;&#27861;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#30340;&#32479;&#35745;&#20445;&#35777;&#21644;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22238;&#24402;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#26657;&#20934;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#24213;&#23618;&#39044;&#27979;&#27169;&#22411;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#21644;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the uncertainty quantification problem for regression models. Specifically, we consider an individual calibration objective for characterizing the quantiles of the prediction model. While such an objective is well-motivated from downstream tasks such as newsvendor cost, the existing methods have been largely heuristic and lack of statistical guarantee in terms of individual calibration. We show via simple examples that the existing methods focusing on population-level calibration guarantees such as average calibration or sharpness can lead to harmful and unexpected results. We propose simple nonparametric calibration methods that are agnostic of the underlying prediction model and enjoy both computational efficiency and statistical consistency. Our approach enables a better understanding of the possibility of individual calibration, and we establish matching upper and lower bounds for the calibration error of our proposed methods. Technically, our analysis co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30417;&#30563;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#31867;&#20869;&#22810;&#26679;&#24615;&#21644;&#31867;&#38388;&#22810;&#26679;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#23545;&#19979;&#28216;&#20219;&#21153;&#34920;&#29616;&#30340;&#24433;&#21709;&#65292;&#24182;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#19979;&#28216;&#24615;&#33021;&#21333;&#35843;&#22320;&#21462;&#20915;&#20110;&#36825;&#20004;&#31181;&#22810;&#26679;&#24615;&#12290;&#26368;&#20339;&#30340;&#31867;&#21035;&#26679;&#26412;&#27604;&#65288;#&#31867;&#21035; / #&#27599;&#31867;&#26679;&#26412;&#25968;&#65289;&#19982;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39044;&#27979;&#26368;&#20339;&#30340;&#39044;&#35757;&#32451;&#31867;&#21035;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.12224</link><description>&lt;p&gt;
&#30417;&#30563;&#39044;&#35757;&#32451;&#20013;&#31867;&#20869;/&#31867;&#38388;&#22810;&#26679;&#24615;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training. (arXiv:2305.12224v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30417;&#30563;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#31867;&#20869;&#22810;&#26679;&#24615;&#21644;&#31867;&#38388;&#22810;&#26679;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#23545;&#19979;&#28216;&#20219;&#21153;&#34920;&#29616;&#30340;&#24433;&#21709;&#65292;&#24182;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#19979;&#28216;&#24615;&#33021;&#21333;&#35843;&#22320;&#21462;&#20915;&#20110;&#36825;&#20004;&#31181;&#22810;&#26679;&#24615;&#12290;&#26368;&#20339;&#30340;&#31867;&#21035;&#26679;&#26412;&#27604;&#65288;#&#31867;&#21035; / #&#27599;&#31867;&#26679;&#26412;&#25968;&#65289;&#19982;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#26080;&#20851;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#39044;&#27979;&#26368;&#20339;&#30340;&#39044;&#35757;&#32451;&#31867;&#21035;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#23545;&#20110;&#26500;&#24314;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#27492;&#38656;&#35201;&#23545;&#23427;&#20204;&#23545;&#19979;&#28216;&#20219;&#21153;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#30417;&#30563;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#31867;&#20869;&#22810;&#26679;&#24615;&#65288;&#27599;&#20010;&#31867;&#21035;&#30340;&#26679;&#26412;&#25968;&#65289;&#21644;&#31867;&#38388;&#22810;&#26679;&#24615;&#65288;&#31867;&#21035;&#25968;&#65289;&#20043;&#38388;&#30340;&#26435;&#34913;&#23545;&#19979;&#28216;&#34920;&#29616;&#30340;&#24433;&#21709;&#12290;&#23454;&#35777;&#34920;&#26126;&#65292;&#24403;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#22266;&#23450;&#26102;&#65292;&#26368;&#20339;&#30340;&#19979;&#28216;&#34920;&#29616;&#21462;&#20915;&#20110;&#31867;&#20869;/&#31867;&#38388;&#22810;&#26679;&#24615;&#30340;&#24179;&#34913;&#12290;&#20026;&#20102;&#20102;&#35299;&#20854;&#22522;&#26412;&#26426;&#21046;&#65292;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#19979;&#28216;&#34920;&#29616;&#21333;&#35843;&#22320;&#21462;&#20915;&#20110;&#20004;&#31181;&#22810;&#26679;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#25581;&#31034;&#20102;&#26368;&#20339;&#30340;&#31867;&#21035;&#26679;&#26412;&#27604;&#65288;#&#31867;&#21035; / #&#27599;&#31867;&#26679;&#26412;&#25968;&#65289;&#19981;&#21463;&#39044;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#24433;&#21709;&#65292;&#36825;&#21551;&#21457;&#25105;&#20204;&#24212;&#29992;&#39044;&#27979;&#26368;&#20339;&#30340;&#39044;&#35757;&#32451;&#31867;&#21035;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#24212;&#29992;&#30340;&#26377;&#25928;&#24615;&#65292;&#24615;&#33021;&#25552;&#21319;&#32422;&#20026;2&#20010;&#30334;&#20998;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-training datasets are critical for building state-of-the-art machine learning models, motivating rigorous study on their impact on downstream tasks. In this work, we study the impact of the trade-off between the intra-class diversity (the number of samples per class) and the inter-class diversity (the number of classes) of a supervised pre-training dataset. Empirically, we found that with the size of the pre-training dataset fixed, the best downstream performance comes with a balance on the intra-/inter-class diversity. To understand the underlying mechanism, we show theoretically that the downstream performance depends monotonically on both types of diversity. Notably, our theory reveals that the optimal class-to-sample ratio (#classes / #samples per class) is invariant to the size of the pre-training dataset, which motivates an application of predicting the optimal number of pre-training classes. We demonstrate the effectiveness of this application by an improvement of around 2 p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#20351;&#29992; Langevin &#21160;&#21147;&#23398;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#20811;&#26381;&#24402;&#19968;&#21270;&#27969;&#21487;&#33021;&#38754;&#20020;&#30340;&#22797;&#26434;&#20998;&#24067;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#36731;&#26494;&#22320;&#34701;&#20837;&#20219;&#20309; NF &#32467;&#26500;&#20013;&#12290;</title><link>http://arxiv.org/abs/2305.12149</link><description>&lt;p&gt;
&#22312;&#28508;&#31354;&#38388;&#20013;&#20351;&#29992; Langevin &#21160;&#21147;&#23398;&#30340;&#24402;&#19968;&#21270;&#27969;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Normalizing flow sampling with Langevin dynamics in the latent space. (arXiv:2305.12149v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#20351;&#29992; Langevin &#21160;&#21147;&#23398;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#20197;&#20811;&#26381;&#24402;&#19968;&#21270;&#27969;&#21487;&#33021;&#38754;&#20020;&#30340;&#22797;&#26434;&#20998;&#24067;&#38382;&#39064;&#65292;&#24182;&#33021;&#22815;&#36731;&#26494;&#22320;&#34701;&#20837;&#20219;&#20309; NF &#32467;&#26500;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#65288;NF&#65289;&#20351;&#29992;&#36830;&#32493;&#29983;&#25104;&#22120;&#23558;&#31616;&#21333;&#30340;&#28508;&#22312;&#20998;&#24067;&#65288;&#20363;&#22914;&#39640;&#26031;&#20998;&#24067;&#65289;&#26144;&#23556;&#21040;&#19982;&#35757;&#32451;&#25968;&#25454;&#38598;&#30456;&#20851;&#32852;&#30340;&#32463;&#39564;&#30446;&#26631;&#20998;&#24067;&#12290;&#36890;&#36807;&#26368;&#23567;&#21270;&#21464;&#20998;&#30446;&#26631;&#26469;&#35757;&#32451;&#21518;&#65292;&#23398;&#20064;&#21040;&#30340;&#26144;&#23556;&#25552;&#20379;&#20102;&#30446;&#26631;&#20998;&#24067;&#30340;&#36817;&#20284;&#29983;&#25104;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#23558;&#30446;&#26631;&#20998;&#24067;&#22312;&#28508;&#22495;&#20013;&#37319;&#26679;&#65292;&#28982;&#21518;&#23558;&#20854;&#20256;&#36755;&#22238;&#30446;&#26631;&#22495;&#65292;&#20197;&#20811;&#26381;&#24403;&#24212;&#23545;&#22797;&#26434;&#20998;&#24067;&#26102;&#21487;&#33021;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#28508;&#31354;&#38388;&#20013;&#30340; Metropolis &#35843;&#25972; Langevin &#21160;&#21147;&#23398;&#65292;&#24182;&#19988;&#21487;&#20197;&#36731;&#26494;&#22320;&#34701;&#20837;&#20219;&#20309; NF &#32467;&#26500;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29609;&#20855;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows (NF) use a continuous generator to map a simple latent (e.g. Gaussian) distribution, towards an empirical target distribution associated with a training data set. Once trained by minimizing a variational objective, the learnt map provides an approximate generative model of the target distribution. Since standard NF implement differentiable maps, they may suffer from pathological behaviors when targeting complex distributions. For instance, such problems may appear for distributions on multi-component topologies or characterized by multiple modes with high probability regions separated by very unlikely areas. A typical symptom is the explosion of the Jacobian norm of the transformation in very low probability areas. This paper proposes to overcome this issue thanks to a new Markov chain Monte Carlo algorithm to sample from the target distribution in the latent domain before transporting it back to the target domain. The approach relies on a Metropolis adjusted Langevin
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;ERM&#35757;&#32451;&#27169;&#22411;&#23545;&#25239;&#24378;&#22823;&#40657;&#30418;&#25915;&#20987;&#30340;&#23433;&#20840;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#25351;&#26631;&#37327;&#21270;&#27169;&#22411;&#23433;&#20840;&#24615;&#65306;&#21333;&#20010;&#26679;&#26412;&#30340;&#31283;&#23450;&#24615;&#21644;&#26597;&#35810;&#19982;&#21407;&#22987;&#25968;&#25454;&#29305;&#24449;&#30340;&#23545;&#40784;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#30740;&#31350;RF&#21644;NTK&#22238;&#24402;&#65292;&#35777;&#26126;&#38543;&#30528;&#27867;&#21270;&#33021;&#21147;&#30340;&#25552;&#39640;&#65292;&#38544;&#31169;&#20445;&#25252;&#21487;&#20197;&#24471;&#21040;&#21152;&#24378;&#12290;</title><link>http://arxiv.org/abs/2305.12100</link><description>&lt;p&gt;
&#31283;&#23450;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#65306;&#23545;&#20110;&#38543;&#26426;&#29305;&#24449;&#21644;NTK&#29305;&#24449;&#30340;&#31934;&#30830;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Stability, Generalization and Privacy: Precise Analysis for Random and NTK Features. (arXiv:2305.12100v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12100
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;ERM&#35757;&#32451;&#27169;&#22411;&#23545;&#25239;&#24378;&#22823;&#40657;&#30418;&#25915;&#20987;&#30340;&#23433;&#20840;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#25351;&#26631;&#37327;&#21270;&#27169;&#22411;&#23433;&#20840;&#24615;&#65306;&#21333;&#20010;&#26679;&#26412;&#30340;&#31283;&#23450;&#24615;&#21644;&#26597;&#35810;&#19982;&#21407;&#22987;&#25968;&#25454;&#29305;&#24449;&#30340;&#23545;&#40784;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#36890;&#36807;&#30740;&#31350;RF&#21644;NTK&#22238;&#24402;&#65292;&#35777;&#26126;&#38543;&#30528;&#27867;&#21270;&#33021;&#21147;&#30340;&#25552;&#39640;&#65292;&#38544;&#31169;&#20445;&#25252;&#21487;&#20197;&#24471;&#21040;&#21152;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#23481;&#26131;&#21463;&#21040;&#24674;&#22797;&#25915;&#20987;&#65292;&#24341;&#36215;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#30340;&#25285;&#24551;&#12290;&#38024;&#23545;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#31561;&#24120;&#35265;&#31639;&#27861;&#36890;&#24120;&#19981;&#33021;&#30452;&#25509;&#23454;&#26045;&#23433;&#20840;&#20445;&#38556;&#30340;&#38382;&#39064;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;ERM&#35757;&#32451;&#27169;&#22411;&#23545;&#25239;&#29305;&#23450;&#24378;&#22823;&#40657;&#30418;&#23376;&#25915;&#20987;&#30340;&#23433;&#20840;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36890;&#36807;&#20004;&#20010;&#30475;&#20284;&#19981;&#21516;&#20294;&#26377;&#32852;&#31995;&#30340;&#25351;&#26631;&#26469;&#37327;&#21270;&#27169;&#22411;&#23433;&#20840;&#24615;&#65306;&#19968;&#26159;&#30456;&#23545;&#20110;&#21333;&#20010;&#35757;&#32451;&#26679;&#26412;&#30340;&#27169;&#22411;&#31283;&#23450;&#24615;&#65292;&#21478;&#19968;&#20010;&#26159;&#25915;&#20987;&#26597;&#35810;&#21644;&#21407;&#22987;&#25968;&#25454;&#29305;&#24449;&#30340;&#29305;&#24449;&#23545;&#40784;&#12290;&#34429;&#28982;&#21069;&#32773;&#22312;&#23398;&#20064;&#29702;&#35770;&#20013;&#24050;&#32463;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#38416;&#36848;&#65292;&#24182;&#19982;&#32463;&#20856;&#24037;&#20316;&#20013;&#30340;&#27867;&#21270;&#35823;&#24046;&#30456;&#20851;&#65292;&#20294;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#31532;&#20108;&#31181;&#29305;&#24615;&#26159;&#26032;&#39062;&#30340;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#32467;&#26524;&#20026;&#20004;&#31181;&#21407;&#22411;&#35774;&#32622;&#25552;&#20379;&#20102;&#29305;&#24449;&#23545;&#40784;&#30340;&#31934;&#30830;&#21051;&#30011;&#65306;&#38543;&#26426;&#29305;&#24449;&#65288;RF&#65289;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#22238;&#24402;&#12290;&#36825;&#35777;&#26126;&#65292;&#38543;&#30528;&#27867;&#21270;&#33021;&#21147;&#30340;&#25552;&#39640;&#65292;&#38544;&#31169;&#20445;&#25252;&#33021;&#22815;&#24471;&#21040;&#21152;&#24378;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#20854;&#20182;&#26377;&#36259;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models can be vulnerable to recovery attacks, raising privacy concerns to users, and widespread algorithms such as empirical risk minimization (ERM) often do not directly enforce safety guarantees. In this paper, we study the safety of ERM-trained models against a family of powerful black-box attacks. Our analysis quantifies this safety via two separate terms: (i) the model stability with respect to individual training samples, and (ii) the feature alignment between the attacker query and the original data. While the first term is well established in learning theory and it is connected to the generalization error in classical work, the second one is, to the best of our knowledge, novel. Our key technical result provides a precise characterization of the feature alignment for the two prototypical settings of random features (RF) and neural tangent kernel (NTK) regression. This proves that privacy strengthens with an increase in the generalization capability, unveiling also
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#23398;&#20064;&#29702;&#35770;&#21644;&#24212;&#29992;&#27010;&#29575;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35777;&#26126;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#32479;&#19968;&#25351;&#21335;&#65292;&#24182;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#24378;&#20984;&#25439;&#22833;&#21644;&#24102;&#28155;&#21152;&#22122;&#22768;&#30340;&#38750;&#20984;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2305.12056</link><description>&lt;p&gt;
&#65288;&#24102;&#22122;&#22768;&#30340;&#65289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#26102;&#38388;&#22343;&#21248;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent. (arXiv:2305.12056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#23398;&#20064;&#29702;&#35770;&#21644;&#24212;&#29992;&#27010;&#29575;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35777;&#26126;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#32479;&#19968;&#25351;&#21335;&#65292;&#24182;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#24378;&#20984;&#25439;&#22833;&#21644;&#24102;&#28155;&#21152;&#22122;&#22768;&#30340;&#38750;&#20984;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#31283;&#23450;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#27010;&#24565;&#65292;&#23545;&#20110;&#25512;&#23548;&#23454;&#36341;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#29992;&#30340;&#12290;&#36807;&#21435;&#21313;&#24180;&#24050;&#32463;&#35265;&#35777;&#20102;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#25152;&#24212;&#29992;&#30340;&#19981;&#21516;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#22686;&#21152;&#12290;&#34429;&#28982;&#36825;&#20123;&#30028;&#38480;&#29031;&#20142;&#20102;&#20248;&#21270;&#31639;&#27861;&#30340;&#21508;&#31181;&#23646;&#24615;&#65292;&#20294;&#27599;&#20010;&#26696;&#20363;&#30340;&#20998;&#26512;&#36890;&#24120;&#38656;&#35201;&#19981;&#21516;&#30340;&#35777;&#26126;&#25216;&#26415;&#21644;&#26174;&#33879;&#19981;&#21516;&#30340;&#25968;&#23398;&#24037;&#20855;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#22312;&#23398;&#20064;&#29702;&#35770;&#21644;&#24212;&#29992;&#27010;&#29575;&#20043;&#38388;&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#35777;&#26126;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#32479;&#19968;&#25351;&#21335;&#12290;&#25105;&#20204;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#19978;&#38416;&#36848;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#24378;&#20984;&#25439;&#22833;&#21644;&#24102;&#28155;&#21152;&#22122;&#22768;&#30340;&#38750;&#20984;&#25439;&#22833;&#30340;&#26102;&#38388;&#22343;&#21248;&#31283;&#23450;&#24615;&#30028;&#38480;&#65288;&#21363;&#65292;&#30028;&#38480;&#19981;&#38543;&#36845;&#20195;&#27425;&#25968;&#22686;&#21152;&#32780;&#22686;&#21152;&#65289;&#65292;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#19982;&#20808;&#21069;&#25991;&#29486;&#30456;&#20284;&#30340;&#32467;&#26524;&#25110;&#23558;&#23427;&#20204;&#25193;&#23637;&#21040;&#26356;&#24191;&#27867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic stability is an important notion that has proven powerful for deriving generalization bounds for practical algorithms. The last decade has witnessed an increasing number of stability bounds for different algorithms applied on different classes of loss functions. While these bounds have illuminated various properties of optimization algorithms, the analysis of each case typically required a different proof technique with significantly different mathematical tools. In this study, we make a novel connection between learning theory and applied probability and introduce a unified guideline for proving Wasserstein stability bounds for stochastic optimization algorithms. We illustrate our approach on stochastic gradient descent (SGD) and we obtain time-uniform stability bounds (i.e., the bound does not increase with the number of iterations) for strongly convex losses and non-convex losses with additive noise, where we recover similar results to the prior art or extend them to mor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#31070;&#32463;&#32593;&#32476;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38024;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#25552;&#20379;&#39640;&#27010;&#29575;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11997</link><description>&lt;p&gt;
&#20855;&#26377;&#27010;&#29575;&#20445;&#35777;&#30340;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#31070;&#32463;&#32593;&#32476;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38024;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#25552;&#20379;&#39640;&#27010;&#29575;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#21457;&#29616;&#20559;&#31227;&#65292;&#36890;&#36807;&#20351;&#29992;&#31283;&#23450;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#21453;&#20107;&#23454;&#35299;&#37322;&#23545;&#21487;&#33021;&#30340;&#27169;&#22411;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#21453;&#20107;&#23454;&#35299;&#37322;&#20248;&#21270;&#20013;&#24341;&#20837;&#27491;&#21017;&#21270;&#39033;&#26469;&#23558;&#29983;&#25104;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#38752;&#36817;&#25968;&#25454;&#27969;&#24418;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#30340;&#39640;&#27010;&#29575;&#40065;&#26834;&#24615;&#12290;&#26032;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{&lt;}\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed \emph{naturally-occurring} model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure -- that we call \emph{Stability} -- to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counter
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PC&#30340;&#26032;&#22411;&#26102;&#24207;&#35760;&#24518;&#27169;&#22411;&#65292;&#31216;&#20026;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#65288;tPC&#65289;&#65292;&#21487;&#20197;&#36890;&#36807;&#29983;&#29289;&#21487;&#34892;&#30340;&#31070;&#32463;&#23454;&#29616;&#20934;&#30830;&#22320;&#35760;&#24518;&#21644;&#26816;&#32034;&#36830;&#32493;&#36755;&#20837;&#12290;&#20854;&#20013;tPC&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#31181;&#32463;&#20856;&#24322;&#21521;&#24615;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#65288;AHN&#65289;&#65292;&#20855;&#26377;&#26356;&#31283;&#23450;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#32534;&#30721;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#65292;&#21306;&#20998;&#22312;&#24207;&#21015;&#20013;&#20986;&#29616;&#30340;&#37325;&#22797;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2305.11982</link><description>&lt;p&gt;
&#24102;&#26377;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#30340;&#26102;&#24207;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
Sequential Memory with Temporal Predictive Coding. (arXiv:2305.11982v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11982
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PC&#30340;&#26032;&#22411;&#26102;&#24207;&#35760;&#24518;&#27169;&#22411;&#65292;&#31216;&#20026;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#65288;tPC&#65289;&#65292;&#21487;&#20197;&#36890;&#36807;&#29983;&#29289;&#21487;&#34892;&#30340;&#31070;&#32463;&#23454;&#29616;&#20934;&#30830;&#22320;&#35760;&#24518;&#21644;&#26816;&#32034;&#36830;&#32493;&#36755;&#20837;&#12290;&#20854;&#20013;tPC&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#31181;&#32463;&#20856;&#24322;&#21521;&#24615;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#65288;AHN&#65289;&#65292;&#20855;&#26377;&#26356;&#31283;&#23450;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#32534;&#30721;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#65292;&#21306;&#20998;&#22312;&#24207;&#21015;&#20013;&#20986;&#29616;&#30340;&#37325;&#22797;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29983;&#29289;&#20307;&#23384;&#20648;&#20107;&#20214;&#24207;&#21015;&#30340;&#26102;&#38388;&#39034;&#24207;&#33267;&#20851;&#37325;&#35201;&#65292;&#28982;&#32780;&#22823;&#33041;&#20013;&#25903;&#37197;&#26102;&#24207;&#35760;&#24518;&#30340;&#35745;&#31639;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#21463;&#21040;&#31070;&#32463;&#31185;&#23398;&#29702;&#35770;&#21644;&#39044;&#27979;&#32534;&#30721;&#65288;PC&#65289;&#22312;&#38745;&#24577;&#23384;&#20648;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#21551;&#31034;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PC&#30340;&#26032;&#22411;&#26102;&#24207;&#35760;&#24518;&#27169;&#22411;&#65292;&#31216;&#20026;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#65288;tPC&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;tPC&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#29983;&#29289;&#21487;&#34892;&#30340;&#31070;&#32463;&#23454;&#29616;&#20934;&#30830;&#22320;&#35760;&#24518;&#21644;&#26816;&#32034;&#36830;&#32493;&#36755;&#20837;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#30740;&#31350;&#34920;&#26126;&#65292;tPC&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#31181;&#20855;&#26377;&#38544;&#24335;&#32479;&#35745;&#30333;&#21270;&#36807;&#31243;&#30340;&#32463;&#20856;&#24322;&#21521;&#24615;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#65288;AHN&#65289;&#65292;&#36825;&#20250;&#22312;&#32467;&#26500;&#21270;&#36755;&#20837;&#30340;&#26102;&#24207;&#35760;&#24518;&#20219;&#21153;&#20013;&#23548;&#33268;&#26356;&#31283;&#23450;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20855;&#26377;&#22810;&#23618;&#32467;&#26500;&#30340;tPC&#21487;&#20197;&#32534;&#30721;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#65292;&#22240;&#27492;&#21487;&#20197;&#21306;&#20998;&#22312;&#24207;&#21015;&#20013;&#20986;&#29616;&#30340;&#37325;&#22797;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Memorizing the temporal order of event sequences is critical for the survival of biological agents. However, the computational mechanism underlying sequential memory in the brain remains unclear. Inspired by neuroscience theories and recent successes in applying predictive coding (PC) to static memory tasks, in this work we propose a novel PC-based model for sequential memory, called temporal predictive coding (tPC). We show that our tPC models can memorize and retrieve sequential inputs accurately with a biologically plausible neural implementation. Importantly, our analytical study reveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN) with an implicit statistical whitening process, which leads to more stable performance in sequential memory tasks of structured inputs. Moreover, we find that tPC with a multi-layer structure can encode context-dependent information, thus distinguishing between repeating elements appearing in a sequence, a computation attribute
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20010;&#24615;&#21270;&#28201;&#24230;&#30340;&#23545;&#27604;&#25439;&#22833;&#29992;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#26681;&#25454;&#25968;&#25454;&#20998;&#24067;&#33258;&#21160;&#35843;&#25972;&#28201;&#24230;&#20197;&#20351;&#24471;&#35757;&#32451;&#26356;&#21152;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2305.11965</link><description>&lt;p&gt;
&#19981;&#26159;&#25152;&#26377;&#30340;&#35821;&#20041;&#37117;&#26159;&#24179;&#31561;&#30340;&#65306;&#20855;&#26377;&#33258;&#23450;&#20041;&#28201;&#24230;&#30340;&#23545;&#27604;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization. (arXiv:2305.11965v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20010;&#24615;&#21270;&#28201;&#24230;&#30340;&#23545;&#27604;&#25439;&#22833;&#29992;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#26681;&#25454;&#25968;&#25454;&#20998;&#24067;&#33258;&#21160;&#35843;&#25972;&#28201;&#24230;&#20197;&#20351;&#24471;&#35757;&#32451;&#26356;&#21152;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#21407;&#21017;&#24615;&#21644;&#31995;&#32479;&#24615;&#30340;&#26041;&#24335;&#65292;&#20248;&#21270;&#20855;&#26377;&#20010;&#24615;&#21270;&#28201;&#24230;&#30340;&#23545;&#27604;&#25439;&#22833;&#65292;&#29992;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#12290;&#26222;&#36941;&#20570;&#27861;&#26159;&#23558;&#20840;&#23616;&#28201;&#24230;&#21442;&#25968;&#964;&#29992;&#20110;&#25152;&#26377;&#25968;&#25454;&#65292;&#24573;&#30053;&#20102;&#8220;&#19981;&#26159;&#25152;&#26377;&#30340;&#35821;&#20041;&#37117;&#26159;&#24179;&#31561;&#30340;&#8221;&#36825;&#20010;&#20107;&#23454;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#23637;&#31034;&#38271;&#23614;&#20998;&#24067;&#26102;&#65292;&#19981;&#21516;&#30340;&#38170;&#28857;&#25968;&#25454;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#25968;&#37327;&#30340;&#31867;&#20284;&#35821;&#20041;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#40065;&#26834;&#24615;&#20248;&#21270;&#65288;DRO&#65289;&#30340;&#26032;&#22411;&#40065;&#26834;&#23545;&#27604;&#25439;&#22833;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#20851;&#964;&#30340;&#24433;&#21709;&#30340;&#30452;&#35273;&#21644;&#33258;&#21160;&#28201;&#24230;&#20010;&#24615;&#21270;&#30340;&#26426;&#21046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#38543;&#26426;&#31639;&#27861;&#26469;&#20248;&#21270;&#40065;&#26834;&#24615;&#23545;&#27604;&#25439;&#22833;&#65292;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#22823;&#22411;&#23567;&#25209;&#37327;&#22823;&#23567;&#12290;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33258;&#21160;&#23398;&#20064;&#27599;&#20010;&#26679;&#26412;&#30340;&#21512;&#36866;&#964;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20855;&#26377;&#39057;&#32321;&#35821;&#20041;&#30340;&#26679;&#26412;&#20351;&#29992;&#36739;&#22823;&#28201;&#24230;&#20197;&#20445;&#25345;&#38590;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we aim to optimize a contrastive loss with individualized temperatures in a principled and systematic manner for self-supervised learning. The common practice of using a global temperature parameter $\tau$ ignores the fact that ``not all semantics are created equal", meaning that different anchor data may have different numbers of samples with similar semantics, especially when data exhibits long-tails. First, we propose a new robust contrastive loss inspired by distributionally robust optimization (DRO), providing us an intuition about the effect of $\tau$ and a mechanism for automatic temperature individualization. Then, we propose an efficient stochastic algorithm for optimizing the robust contrastive loss with a provable convergence guarantee without using large mini-batch sizes. Theoretical and experimental results show that our algorithm automatically learns a suitable $\tau$ for each sample. Specifically, samples with frequent semantics use large temperatures to k
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24207;&#21015;&#26368;&#20248;&#33218;&#35782;&#21035;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#33041;-&#26426;&#25509;&#21475;&#20013;&#30340;&#25340;&#20889;&#31995;&#32479;&#12290;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#24555;&#22320;&#36827;&#34892;&#23398;&#20064;&#24182;&#25552;&#39640;&#20449;&#24687;&#20256;&#36755;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.11908</link><description>&lt;p&gt;
&#24207;&#21015;&#26368;&#20248;&#33218;&#35782;&#21035;&#21450;&#20854;&#22312;&#33041;-&#26426;&#25509;&#21475;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequential Best-Arm Identification with Application to Brain-Computer Interface. (arXiv:2305.11908v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24207;&#21015;&#26368;&#20248;&#33218;&#35782;&#21035;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#33041;-&#26426;&#25509;&#21475;&#20013;&#30340;&#25340;&#20889;&#31995;&#32479;&#12290;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#24555;&#22320;&#36827;&#34892;&#23398;&#20064;&#24182;&#25552;&#39640;&#20449;&#24687;&#20256;&#36755;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33041;-&#26426;&#25509;&#21475;&#26159;&#19968;&#31181;&#20351;&#22823;&#33041;&#19982;&#22806;&#37096;&#35774;&#22791;&#25110;&#35745;&#31639;&#26426;&#31995;&#32479;&#30452;&#25509;&#36890;&#20449;&#30340;&#25216;&#26415;&#65292;&#23427;&#20801;&#35768;&#20010;&#20307;&#21482;&#20351;&#29992;&#24605;&#32500;&#19982;&#35774;&#22791;&#36827;&#34892;&#20132;&#20114;&#65292;&#24182;&#20855;&#26377;&#22312;&#21307;&#23398;&#12289;&#24247;&#22797;&#21644;&#20154;&#20307;&#22686;&#24378;&#31561;&#39046;&#22495;&#20013;&#24191;&#27867;&#24212;&#29992;&#30340;&#28508;&#21147;&#12290; &#22522;&#20110;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#21644;&#20107;&#20214;&#30456;&#20851;&#30005;&#20301;&#65288;ERP&#65289;&#30340;&#25340;&#20889;&#22120;&#31995;&#32479;&#26159;&#19968;&#31181;&#31867;&#22411;&#30340;&#33041;-&#26426;&#25509;&#21475;&#65292;&#23427;&#20801;&#35768;&#29992;&#25143;&#22312;&#19981;&#20351;&#29992;&#29289;&#29702;&#38190;&#30424;&#30340;&#24773;&#20917;&#19979;&#25340;&#20889;&#21333;&#35789;&#65292;&#32780;&#26159;&#36890;&#36807;&#35760;&#24405;&#21644;&#35299;&#37322;&#22312;&#19981;&#21516;&#30340;&#21050;&#28608;&#21576;&#29616;&#33539;&#20363;&#19979;&#30340;&#33041;&#20449;&#21495;&#12290;&#20256;&#32479;&#30340;&#38750;&#33258;&#36866;&#24212;&#33539;&#20363;&#23558;&#27599;&#20010;&#21333;&#35789;&#36873;&#25321;&#35270;&#20026;&#29420;&#31435;&#30340;&#65292;&#23548;&#33268;&#20102;&#28459;&#38271;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#20026;&#20102;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#19968;&#31995;&#21015;&#26368;&#20248;&#33218;&#35782;&#21035;&#20219;&#21153;&#12290;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#25105;&#20204;&#21033;&#29992;&#20174;&#20808;&#21069;&#20219;&#21153;&#20013;&#23398;&#20064;&#21040;&#30340;&#20808;&#39564;&#30693;&#35782;&#26469;&#36890;&#30693;&#21644;&#20419;&#36827;&#21518;&#32493;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26356;&#24555;&#30340;&#23398;&#20064;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#20449;&#24687;&#20256;&#36755;&#36895;&#29575;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;ERP&#25340;&#20889;&#23454;&#39564;&#21644;&#30495;&#23454;&#30340;EEG&#25171;&#23383;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A brain-computer interface (BCI) is a technology that enables direct communication between the brain and an external device or computer system. It allows individuals to interact with the device using only their thoughts, and holds immense potential for a wide range of applications in medicine, rehabilitation, and human augmentation. An electroencephalogram (EEG) and event-related potential (ERP)-based speller system is a type of BCI that allows users to spell words without using a physical keyboard, but instead by recording and interpreting brain signals under different stimulus presentation paradigms. Conventional non-adaptive paradigms treat each word selection independently, leading to a lengthy learning process. To improve the sampling efficiency, we cast the problem as a sequence of best-arm identification tasks in multi-armed bandits. Leveraging pre-trained large language models (LLMs), we utilize the prior knowledge learned from previous tasks to inform and facilitate subsequent
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#65288;DS-TS&#65289;&#65292;&#21487;&#20197;&#35299;&#20915;&#31361;&#28982;&#24615;&#21464;&#21270;&#21644;&#24179;&#28369;&#24615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.10718</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Discounted Thompson Sampling for Non-Stationary Bandit Problems. (arXiv:2305.10718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10718
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#65288;DS-TS&#65289;&#65292;&#21487;&#20197;&#35299;&#20915;&#31361;&#28982;&#24615;&#21464;&#21270;&#21644;&#24179;&#28369;&#24615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#21463;&#21040;&#20102;&#26174;&#33879;&#20851;&#27880;&#12290;NS-MAB&#36890;&#24120;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#36827;&#34892;&#24314;&#27169;&#65306;&#31361;&#28982;&#24615;&#21464;&#21270;&#21644;&#24179;&#28369;&#24615;&#21464;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24102;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#37319;&#26679;&#31639;&#27861;&#65288;DS-TS&#65289;&#20197;&#35299;&#20915;&#36825;&#20004;&#20010;&#38750;&#31283;&#24577;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#23558;&#25240;&#25187;&#22240;&#23376;&#32435;&#20837;&#27748;&#26222;&#26862;&#37319;&#26679;&#26469;&#34987;&#21160;&#36866;&#24212;&#21464;&#21270;&#12290;DS-TS&#26041;&#27861;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#20294;&#32570;&#20047;&#23545;&#36951;&#25022;&#19978;&#38480;&#30340;&#20998;&#26512;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;DS-TS&#21487;&#20197;&#22312;&#31361;&#28982;&#24615;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36817;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#65288;$\tilde{O} (\sqrt {TB_T})$&#65289;&#65292;&#22312;&#24179;&#28369;&#24615;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616; $\tilde{O}(T^{\beta})$ &#30340;&#36817;&#20046;&#26368;&#20248;&#36951;&#25022;&#19978;&#38480;&#65292;&#20854;&#20013; $T$ &#26159;&#26102;&#38388;&#27493;&#25968;&#65292;$B_T$ &#26159;&#26029;&#28857;&#25968;&#65292;$\beta$ &#19982;&#25910;&#30410;&#20998;&#24067;&#30340;&#24179;&#28369;&#24615;&#26377;&#20851;&#65292;$\tilde{O}$ &#26159;&#23545;&#25968;&#36951;&#25022;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-stationary multi-armed bandit (NS-MAB) problems have recently received significant attention. NS-MAB are typically modelled in two scenarios: abruptly changing, where reward distributions remain constant for a certain period and change at unknown time steps, and smoothly changing, where reward distributions evolve smoothly based on unknown dynamics. In this paper, we propose Discounted Thompson Sampling (DS-TS) with Gaussian priors to address both non-stationary settings. Our algorithm passively adapts to changes by incorporating a discounted factor into Thompson Sampling. DS-TS method has been experimentally validated, but analysis of the regret upper bound is currently lacking. Under mild assumptions, we show that DS-TS with Gaussian priors can achieve nearly optimal regret bound on the order of $\tilde{O}(\sqrt{TB_T})$ for abruptly changing and $\tilde{O}(T^{\beta})$ for smoothly changing, where $T$ is the number of time steps, $B_T$ is the number of breakpoints, $\beta$ is asso
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#24352;&#37327;&#31215;&#22312;&#36229;&#32500;&#35745;&#31639;&#20013;&#30340;&#25968;&#23398;&#20851;&#31995;&#65292;&#23558;&#20854;&#30830;&#23450;&#20026;&#20013;&#24515;&#34920;&#31034;&#65292;&#24182;&#21457;&#29616;&#23427;&#26159;&#26368;&#36890;&#29992;&#12289;&#26368;&#20855;&#34920;&#29616;&#21147;&#21644;&#26368;&#21387;&#32553;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#35823;&#24046;&#35299;&#32465;&#21644;&#26816;&#27979;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.10572</link><description>&lt;p&gt;
&#24352;&#37327;&#31215;&#19982;&#36229;&#32500;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Tensor Products and Hyperdimensional Computing. (arXiv:2305.10572v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#24352;&#37327;&#31215;&#22312;&#36229;&#32500;&#35745;&#31639;&#20013;&#30340;&#25968;&#23398;&#20851;&#31995;&#65292;&#23558;&#20854;&#30830;&#23450;&#20026;&#20013;&#24515;&#34920;&#31034;&#65292;&#24182;&#21457;&#29616;&#23427;&#26159;&#26368;&#36890;&#29992;&#12289;&#26368;&#20855;&#34920;&#29616;&#21147;&#21644;&#26368;&#21387;&#32553;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#35823;&#24046;&#35299;&#32465;&#21644;&#26816;&#27979;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20043;&#21069;&#23545;&#22270;&#23884;&#20837;&#30340;&#20998;&#26512;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23558;&#19968;&#20123;&#32467;&#26524;&#25512;&#24191;&#21644;&#25299;&#23637;&#21040;&#21521;&#37327;&#31526;&#21495;&#32467;&#26500; (VSA) &#21644;&#36229;&#32500;&#35745;&#31639; (HDC) &#30340;&#19968;&#33324;&#35774;&#32622;&#20013;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25506;&#32034;&#36229;&#21472;&#21152;&#12289;&#27491;&#20132;&#21644;&#24352;&#37327;&#31215;&#20043;&#38388;&#30340;&#25968;&#23398;&#20851;&#31995;&#12290;&#25105;&#20204;&#23558;&#24352;&#37327;&#31215;&#34920;&#31034;&#30830;&#23450;&#20026;&#20013;&#24515;&#34920;&#31034;&#65292;&#24182;&#20855;&#26377;&#19968;&#22871;&#29420;&#29305;&#30340;&#23646;&#24615;&#12290;&#36825;&#21253;&#25324;&#23427;&#26159;&#26368;&#36890;&#29992;&#21644;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#34920;&#31034;&#65292;&#20063;&#26159;&#26368;&#21387;&#32553;&#30340;&#34920;&#31034;&#65292;&#20855;&#26377;&#26080;&#35823;&#24046;&#35299;&#32465;&#21644;&#26816;&#27979;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Following up on a previous analysis of graph embeddings, we generalize and expand some results to the general setting of vector symbolic architectures (VSA) and hyperdimensional computing (HDC). Importantly, we explore the mathematical relationship between superposition, orthogonality, and tensor product. We establish the tensor product representation as the central representation, with a suite of unique properties. These include it being the most general and expressive representation, as well as being the most compressed representation that has errorrless unbinding and detection.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20851;&#27880;&#19968;&#31181;&#38750;&#32447;&#24615;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65306;&#25193;&#25955;&#26144;&#23556;&#12290;&#26412;&#25991;&#38416;&#36848;&#22914;&#20309;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#19982;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2304.14378</link><description>&lt;p&gt;
&#21151;&#33021;&#25193;&#25955;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Functional Diffusion Maps. (arXiv:2304.14378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20851;&#27880;&#19968;&#31181;&#38750;&#32447;&#24615;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65306;&#25193;&#25955;&#26144;&#23556;&#12290;&#26412;&#25991;&#38416;&#36848;&#22914;&#20309;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#19982;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#21487;&#20197;&#34987;&#35270;&#20026;&#26159;&#21151;&#33021;&#24615;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#29983;&#25104;&#23427;&#20204;&#30340;&#36807;&#31243;&#26159;&#36830;&#32493;&#30340;&#12290;&#36825;&#31181;&#31867;&#22411;&#25968;&#25454;&#30340;&#19968;&#20010;&#22522;&#26412;&#29305;&#24615;&#26159;&#65292;&#29702;&#35770;&#19978;&#23427;&#20204;&#23646;&#20110;&#26080;&#38480;&#32500;&#31354;&#38388;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#36890;&#24120;&#21482;&#33021;&#24471;&#21040;&#26377;&#38480;&#25968;&#37327;&#30340;&#35266;&#23519;&#32467;&#26524;&#65292;&#23427;&#20204;&#20173;&#28982;&#26159;&#39640;&#32500;&#30340;&#65292;&#22240;&#27492;&#38477;&#32500;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#29616;&#26377;&#26041;&#27861;&#26159;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#36825;&#31181;&#32463;&#20856;&#25216;&#26415;&#20551;&#35774;&#25968;&#25454;&#20301;&#20110;&#19968;&#20010;&#32447;&#24615;&#27969;&#24418;&#20013;&#65292;&#22240;&#27492;&#24403;&#36825;&#20010;&#20551;&#35774;&#19981;&#25104;&#31435;&#26102;&#21487;&#33021;&#20250;&#20986;&#29616;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#32858;&#28966;&#20110;&#19968;&#31181;&#38750;&#32447;&#24615;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65306;&#25193;&#25955;&#26144;&#23556;&#12290;&#26412;&#25991;&#35299;&#37322;&#20102;&#22914;&#20309;&#23558;&#36825;&#31181;&#22810;&#21464;&#37327;&#26041;&#27861;&#25193;&#23637;&#21040;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#34892;&#20026;&#19982;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#22312;&#19981;&#21516;&#30340;&#27169;&#25311;&#21644;&#23454;&#38469;&#20363;&#23376;&#20013;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays many real-world datasets can be considered as functional, in the sense that the processes which generate them are continuous. A fundamental property of this type of data is that in theory they belong to an infinite-dimensional space. Although in practice we usually receive finite observations, they are still high-dimensional and hence dimensionality reduction methods are crucial. In this vein, the main state-of-the-art method for functional data analysis is Functional PCA. Nevertheless, this classic technique assumes that the data lie in a linear manifold, and hence it could have problems when this hypothesis is not fulfilled. In this research, attention has been placed on a non-linear manifold learning method: Diffusion Maps. The article explains how to extend this multivariate method to functional data and compares its behavior against Functional PCA over different simulated and real examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22522;&#20110;&#27010;&#24565;&#23884;&#20837;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;DCR&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#25552;&#39640;&#20102;&#39640;&#36798;+25&#65285;&#65292;&#24182;&#20135;&#29983;&#33021;&#22815;&#35299;&#37322;&#20854;&#39044;&#27979;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#21644;&#30495;&#20540;&#24230;&#65292;&#36866;&#24212;&#24615;&#24378;&#12290;</title><link>http://arxiv.org/abs/2304.14068</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31070;&#32463;&#31526;&#21495;&#27010;&#24565;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Interpretable Neural-Symbolic Concept Reasoning. (arXiv:2304.14068v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22522;&#20110;&#27010;&#24565;&#23884;&#20837;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;DCR&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#25552;&#39640;&#20102;&#39640;&#36798;+25&#65285;&#65292;&#24182;&#20135;&#29983;&#33021;&#22815;&#35299;&#37322;&#20854;&#39044;&#27979;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#21644;&#30495;&#20540;&#24230;&#65292;&#36866;&#24212;&#24615;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#39640;&#24230;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#23427;&#20204;&#19981;&#36879;&#26126;&#30340;&#20915;&#31574;&#36807;&#31243;&#38459;&#27490;&#20102;&#23427;&#20204;&#33719;&#24471;&#23436;&#20840;&#30340;&#20154;&#31867;&#20449;&#20219;&#12290;&#27010;&#24565;&#27169;&#22411;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#19968;&#32452;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#26368;&#20808;&#36827;&#30340;&#27010;&#24565;&#27169;&#22411;&#20381;&#36182;&#20110;&#39640;&#32500;&#27010;&#24565;&#23884;&#20837;&#34920;&#31034;&#65292;&#32570;&#20047;&#26126;&#30830;&#30340;&#35821;&#20041;&#21547;&#20041;&#65292;&#22240;&#27492;&#36136;&#30097;&#20854;&#20915;&#31574;&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Deep Concept Reasoner(DCR)&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#27010;&#24565;&#23884;&#20837;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#12290;&#22312;DCR&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#19981;&#30452;&#25509;&#36827;&#34892;&#20219;&#21153;&#39044;&#27979;&#65292;&#32780;&#26159;&#20351;&#29992;&#27010;&#24565;&#23884;&#20837;&#24314;&#31435;&#35821;&#27861;&#35268;&#21017;&#32467;&#26500;&#12290;&#28982;&#21518;DCR&#22312;&#26377;&#24847;&#20041;&#30340;&#27010;&#24565;&#30495;&#20540;&#24230;&#19978;&#25191;&#34892;&#36825;&#20123;&#35268;&#21017;&#65292;&#20197;&#19981;&#21487;&#24494;&#20998;&#30340;&#26041;&#24335;&#25552;&#20379;&#26368;&#32456;&#30340;&#21487;&#35299;&#37322;&#21644;&#35821;&#20041;&#19968;&#33268;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;DCR&#65306;(i)&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#25552;&#39640;&#20102;&#39640;&#36798;+25&#65285;;(ii)&#20135;&#29983;&#33021;&#22815;&#35299;&#37322;&#20854;&#39044;&#27979;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#21644;&#30495;&#20540;&#24230;;(iii)&#24456;&#23481;&#26131;&#36866;&#24212;&#26032;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), the first interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner. Our experiments show that DCR: (i) improves up to +25% w.r.t. state-of-the-art interpretable concept-based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.10025</link><description>&lt;p&gt;
&#29992;&#20110;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#35782;&#21035;&#21644;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#39564;&#21644;&#35266;&#23519;&#30740;&#31350;&#20013;&#65292;&#20154;&#20204;&#36890;&#24120;&#23545;&#20102;&#35299;&#24178;&#39044;&#26041;&#26696;&#22914;&#20309;&#25913;&#21892;&#26368;&#32456;&#32467;&#26524;&#30340;&#28508;&#22312;&#26426;&#21046;&#24863;&#20852;&#36259;&#12290;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26088;&#22312;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20294;&#20027;&#35201;&#38480;&#20110;&#27835;&#30103;&#23436;&#20840;&#26381;&#20174;&#30340;&#24773;&#20917;&#65292;&#21482;&#26377;&#23569;&#25968;&#24773;&#20917;&#38656;&#35201;&#25490;&#38500;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21322;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26080;&#38656;&#25490;&#38500;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#25972;&#20010;&#30740;&#31350;&#20154;&#32676;&#30340;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#65292;&#24182;&#36827;&#19968;&#27493;&#38024;&#23545;&#30001;&#28508;&#22312;&#26381;&#20174;&#34892;&#20026;&#29305;&#24449;&#21270;&#30340;&#20122;&#20154;&#32676;&#20013;&#30340;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#36827;&#34892;&#35782;&#21035;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#20272;&#35745;&#37327;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#28608;&#21169;&#20102;&#19968;&#32452;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;&#22120;&#36827;&#34892;&#25512;&#35770;&#12290;&#36825;&#20123;&#34987;&#35782;&#21035;&#20272;&#35745;&#37327;&#30340;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#20998;&#24067;&#24335;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#25552;&#20986;&#20102;&#31283;&#20581;&#20998;&#38454;&#27573;&#20215;&#20540;&#23398;&#20064;&#65288;RPVL&#65289;&#31639;&#27861;&#26469;&#35299;&#20915;&#34920;&#26684;&#21095;&#24773;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.02783</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#30340;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improved Sample Complexity Bounds for Distributionally Robust Reinforcement Learning. (arXiv:2303.02783v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02783
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#20998;&#24067;&#24335;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#25552;&#20986;&#20102;&#31283;&#20581;&#20998;&#38454;&#27573;&#20215;&#20540;&#23398;&#20064;&#65288;RPVL&#65289;&#31639;&#27861;&#26469;&#35299;&#20915;&#34920;&#26684;&#21095;&#24773;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#35757;&#32451;&#29615;&#22659;&#19982;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#21442;&#25968;&#19981;&#21305;&#37197;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#20854;&#21046;&#23450;&#20026;&#19968;&#20010;&#20998;&#24067;&#24335;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;(DR-RL)&#38382;&#39064;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#23398;&#20064;&#22312;&#19981;&#30830;&#23450;&#38598;&#20013;&#38024;&#23545;&#29615;&#22659;&#26368;&#22351;&#30340;&#38543;&#26426;&#27169;&#22411;&#19979;&#26368;&#22823;&#21270;&#20215;&#20540;&#20989;&#25968;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#34920;&#26684;&#21095;&#24773;&#23398;&#20064;&#29615;&#22659;&#65292;&#22312;&#19981;&#30830;&#23450;&#38598;&#34987;&#23450;&#20041;&#22312;&#21517;&#20041;&#65288;&#35757;&#32451;&#65289;&#29615;&#22659;&#30340;&#29983;&#25104;&#27169;&#22411;&#21608;&#22260;&#30340;&#24773;&#20917;&#19979;&#65292;&#31639;&#27861;&#21487;&#20197;&#35775;&#38382;&#35813;&#29615;&#22659;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31283;&#20581;&#20998;&#38454;&#27573;&#20215;&#20540;&#23398;&#20064;(RPVL)&#31639;&#27861;&#26469;&#35299;&#20915;&#29992;&#22235;&#31181;&#19981;&#21516;&#21457;&#25955;&#24230;&#25351;&#23450;&#30340;&#19981;&#30830;&#23450;&#38598;&#30340;&#38382;&#39064;: &#20840;&#21464;&#20998;&#12289;&#21345;&#26041;&#12289;Kullback-Leibler&#21644;Wasserstein&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102; $\tilde{\mathcal{O}}(|\mathcal{S}||\mathcal{A}| H^{5})$ &#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#36825;&#27604;&#29616;&#26377;&#32467;&#26524;&#24179;&#22343;&#22909;&#20102;&#19968;&#20493;&#30340; $|\mathcal{S}|$
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a control policy that is robust against the parameter mismatches between the training environment and testing environment. We formulate this as a distributionally robust reinforcement learning (DR-RL) problem where the objective is to learn the policy which maximizes the value function against the worst possible stochastic model of the environment in an uncertainty set. We focus on the tabular episodic learning setting where the algorithm has access to a generative model of the nominal (training) environment around which the uncertainty set is defined. We propose the Robust Phased Value Learning (RPVL) algorithm to solve this problem for the uncertainty sets specified by four different divergences: total variation, chi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm achieves $\tilde{\mathcal{O}}(|\mathcal{S}||\mathcal{A}| H^{5})$ sample complexity, which is uniformly better than the existing results by a factor of $|\mathcal{S}|
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Gibbs&#31639;&#27861;&#30340;&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26356;&#26032;&#26041;&#21521;&#21644;&#21322;&#24452;&#20998;&#37327;&#23454;&#29616;&#37319;&#26679;&#36807;&#31243;&#65292;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#36234;&#12290;</title><link>http://arxiv.org/abs/2302.03945</link><description>&lt;p&gt;
Gibbsian&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Gibbsian polar slice sampling. (arXiv:2302.03945v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Gibbs&#31639;&#27861;&#30340;&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26356;&#26032;&#26041;&#21521;&#21644;&#21322;&#24452;&#20998;&#37327;&#23454;&#29616;&#37319;&#26679;&#36807;&#31243;&#65292;&#19988;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#26159;&#19968;&#31181;&#36817;&#20284;&#37319;&#26679;&#20998;&#24067;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#19982;&#32500;&#24230;&#30456;&#20851;&#24615;&#24456;&#22909;&#65292;&#20294;&#23454;&#29616;&#38590;&#24230;&#24456;&#22823;&#65292;&#29978;&#33267;&#19981;&#21487;&#33021;&#23454;&#29616;&#12290;&#25105;&#20204;&#22312;&#26356;&#26032;&#38142;&#36845;&#20195;&#30340;&#26041;&#21521;&#21644;&#21322;&#24452;&#20998;&#37327;&#26102;&#65292;&#33719;&#24471;&#20102;&#19968;&#31995;&#21015;&#27169;&#25311;&#26497;&#22352;&#26631;&#20999;&#29255;&#37319;&#26679;&#30340;&#37319;&#26679;&#22120;&#65292;&#21516;&#26102;&#21487;&#20197;&#26377;&#25928;&#22320;&#23454;&#26045;&#12290;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#20248;&#20110;&#26368;&#30456;&#20851;&#30340;&#20004;&#31181;&#26041;&#27861;&#65292;&#21363;&#26925;&#22278;&#20999;&#29255;&#37319;&#26679;&#21644; hit-and-run &#22343;&#21248;&#20999;&#29255;&#37319;&#26679;&#12290;&#22312;&#30446;&#26631;&#20998;&#24067;&#20855;&#26377;&#36866;&#24403;&#20551;&#35774;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26126;&#30830;&#24615;&#21644;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Polar slice sampling (Roberts &amp; Rosenthal, 2002) is a Markov chain approach for approximate sampling of distributions that is difficult, if not impossible, to implement efficiently, but behaves provably well with respect to the dimension. By updating the directional and radial components of chain iterates separately, we obtain a family of samplers that mimic polar slice sampling, and yet can be implemented efficiently. Numerical experiments in a variety of settings indicate that our proposed algorithm outperforms the two most closely related approaches, elliptical slice sampling (Murray et al., 2010) and hit-and-run uniform slice sampling (MacKay, 2003). We prove the well-definedness and convergence of our methods under suitable assumptions on the target distribution.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#24212;&#29992;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#29615;&#22659;&#35268;&#33539;&#26469;&#34920;&#24449;&#29615;&#22659;&#30340;&#26041;&#24046;&#23646;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22522;&#20110;&#27169;&#22411;&#21644;&#26080;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#23545;&#20110;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;&#29615;&#22659;&#21516;&#26102;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#30028;&#38480;&#26159;&#31532;&#19968;&#27425;&#34987;&#35777;&#26126;&#20986;&#26469;&#30340;&#12290;</title><link>http://arxiv.org/abs/2301.13446</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23574;&#38160;&#26041;&#24046;&#30456;&#20851;&#30028;&#38480;&#65306;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;&#29615;&#22659;&#30340;&#26368;&#20339;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments. (arXiv:2301.13446v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#24212;&#29992;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#29615;&#22659;&#35268;&#33539;&#26469;&#34920;&#24449;&#29615;&#22659;&#30340;&#26041;&#24046;&#23646;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22522;&#20110;&#27169;&#22411;&#21644;&#26080;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#23545;&#20110;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;&#29615;&#22659;&#21516;&#26102;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#30028;&#38480;&#26159;&#31532;&#19968;&#27425;&#34987;&#35777;&#26126;&#20986;&#26469;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#12290;&#20855;&#26377;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#20445;&#35777;&#30340;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#21033;&#29992;&#20855;&#26377;&#20302;&#26041;&#24046;&#65288;&#20363;&#22914;&#65292;&#22312;&#30830;&#23450;&#24615;MDP&#19978;&#20139;&#26377;&#24120;&#37327;&#36951;&#25022;&#65289;&#30340;&#29615;&#22659;&#12290;&#29616;&#26377;&#31639;&#27861;&#35201;&#20040;&#29420;&#31435;&#20110;&#26041;&#24046;&#35201;&#20040;&#27425;&#20248;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20004;&#20010;&#26032;&#30340;&#29615;&#22659;&#35268;&#33539;&#26469;&#34920;&#24449;&#29615;&#22659;&#30340;&#32454;&#31890;&#24230;&#26041;&#24046;&#23646;&#24615;&#12290;&#23545;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;MVP&#31639;&#27861;(Zhang&#31561;&#65292;2021a)&#30340;&#21464;&#31181;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#30456;&#23545;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#35268;&#33539;&#20139;&#26377;&#26041;&#24046;&#30456;&#20851;&#30340;&#30028;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#36825;&#19968;&#30028;&#38480;&#23545;&#20110;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;MDP&#21516;&#26102;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#65292;&#36825;&#26159;&#20854;&#31181;&#31867;&#20013;&#30340;&#31532;&#19968;&#20010;&#32467;&#26524;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#21442;&#32771;&#20989;&#25968;&#30340;&#31639;&#27861;&#20197;&#21450;&#19968;&#20010;&#26032;&#30340;&#24102;&#26377;&#19978;&#38480;&#21152;&#20493;&#21442;&#32771;&#26356;&#26032;&#36827;&#24230;&#34920;&#30340;&#31574;&#30053;&#21551;&#21160;&#20102;&#20851;&#20110;&#20855;&#26377;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#30340;&#30740;&#31350;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20123;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study variance-dependent regret bounds for Markov decision processes (MDPs). Algorithms with variance-dependent regret guarantees can automatically exploit environments with low variance (e.g., enjoying constant regret on deterministic MDPs). The existing algorithms are either variance-independent or suboptimal. We first propose two new environment norms to characterize the fine-grained variance properties of the environment. For model-based methods, we design a variant of the MVP algorithm (Zhang et al., 2021a) and use new analysis techniques show to this algorithm enjoys variance-dependent bounds with respect to our proposed norms. In particular, this bound is simultaneously minimax optimal for both stochastic and deterministic MDPs, the first result of its kind. We further initiate the study on model-free algorithms with variance-dependent regret bounds by designing a reference-function-based algorithm with a novel capped-doubling reference update schedule. Lastly, we also provid
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25277;&#26679;&#30340;Nystr&#246;m&#36924;&#36817;&#26041;&#27861;&#29992;&#20110;&#26680;&#31215;&#20998;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#38750;i.i.d.&#22320;&#26631;&#28857;&#30340;&#29702;&#35770;&#20445;&#35777;&#26041;&#27861;&#65292;&#20351;&#24471;&#25552;&#39640;&#20102;&#36924;&#36817;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2301.09517</link><description>&lt;p&gt;
&#22522;&#20110;&#25277;&#26679;&#30340;Nystr&#246;m&#36924;&#36817;&#21644;&#26680;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling-based Nystr\"om Approximation and Kernel Quadrature. (arXiv:2301.09517v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09517
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25277;&#26679;&#30340;Nystr&#246;m&#36924;&#36817;&#26041;&#27861;&#29992;&#20110;&#26680;&#31215;&#20998;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#38750;i.i.d.&#22320;&#26631;&#28857;&#30340;&#29702;&#35770;&#20445;&#35777;&#26041;&#27861;&#65292;&#20351;&#24471;&#25552;&#39640;&#20102;&#36924;&#36817;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#19982;&#27010;&#29575;&#27979;&#37327;&#30456;&#20851;&#30340;&#27491;&#23450;&#26680;&#30340;Nystr&#246;m&#36924;&#36817;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#20256;&#32479;Nystr&#246;m&#36924;&#36817;&#22312;&#36830;&#32493;&#21306;&#38388;&#20013;&#20351;&#29992;i.i.d.&#25277;&#26679;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#30340;&#25913;&#36827;&#35823;&#24046;&#30028;&#65292;&#35777;&#26126;&#25216;&#24039;&#20511;&#37492;&#20102;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24341;&#20837;&#20102;Nystr&#246;m&#36924;&#36817;&#20013;&#30340;&#23376;&#31354;&#38388;&#31934;&#32454;&#36873;&#25321;&#65292;&#36825;&#26159;&#36866;&#29992;&#20110;&#38750;i.i.d.&#22320;&#26631;&#28857;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#22312;&#20984;&#26680;&#31215;&#20998;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#32473;&#20986;&#20102;&#26032;&#30340;&#29702;&#35770;&#20445;&#35777;&#20197;&#21450;&#25968;&#20540;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the Nystr\"om approximation of a positive definite kernel associated with a probability measure. We first prove an improved error bound for the conventional Nystr\"om approximation with i.i.d. sampling and singular-value decomposition in the continuous regime; the proof techniques are borrowed from statistical learning theory. We further introduce a refined selection of subspaces in Nystr\"om approximation with theoretical guarantees that is applicable to non-i.i.d. landmark points. Finally, we discuss their application to convex kernel quadrature and give novel theoretical guarantees as well as numerical observations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VRDS&#30340;&#20998;&#23618;&#25277;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#65292;&#20197;&#32553;&#23567;&#25490;&#21015;&#25277;&#26679;&#26041;&#27861;&#30340;&#20272;&#35745;&#26041;&#24046;&#65292;&#24182;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#21024;&#38500;&#24212;&#29992;&#31243;&#24207;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2210.16835</link><description>&lt;p&gt;
&#21487;&#20449;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#30340;&#26041;&#24046;&#32553;&#23567;Shapley&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Variance reduced Shapley value estimation for trustworthy data valuation. (arXiv:2210.16835v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;VRDS&#30340;&#20998;&#23618;&#25277;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#25968;&#25454;&#20215;&#20540;&#65292;&#20197;&#32553;&#23567;&#25490;&#21015;&#25277;&#26679;&#26041;&#27861;&#30340;&#20272;&#35745;&#26041;&#24046;&#65292;&#24182;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#21024;&#38500;&#24212;&#29992;&#31243;&#24207;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#65292;&#29305;&#21035;&#26159;&#22312;&#31639;&#27861;&#39044;&#27979;&#21644;&#20915;&#31574;&#20013;&#37327;&#21270;&#25968;&#25454;&#20215;&#20540;&#65292;&#26159;&#25968;&#25454;&#20132;&#26131;&#22330;&#26223;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#30446;&#21069;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;&#26159;&#23450;&#20041;&#25968;&#25454;Shapley&#20540;&#65292;&#28982;&#21518;&#36890;&#36807;&#25490;&#24207;&#25277;&#26679;&#31639;&#27861;&#36827;&#34892;&#36817;&#20284;&#35745;&#31639;&#12290;&#20026;&#20102;&#24357;&#34917;&#25490;&#21015;&#25277;&#26679;&#31639;&#27861;&#30340;&#22823;&#20272;&#35745;&#26041;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#31283;&#20581;&#30340;&#25968;&#25454;&#20272;&#20215;&#26041;&#27861;&#65292;&#20351;&#29992;&#20998;&#23618;&#25277;&#26679;&#65292;&#24182;&#21629;&#21517;&#20026;&#26041;&#24046;&#32553;&#23567;&#25968;&#25454;Shapley&#20540;&#65288;VRDS&#65289;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;&#20998;&#23618;&#25277;&#26679;&#65292;&#27599;&#20010;&#23618;&#25277;&#22810;&#23569;&#26679;&#26412;&#65292;&#20197;&#21450;VRDS&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#21644;&#25968;&#25454;&#21024;&#38500;&#24212;&#29992;&#31243;&#24207;&#20013;&#35828;&#26126;&#20102;VRDS&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation, especially quantifying data value in algorithmic prediction and decision-making, is a fundamental problem in data trading scenarios. The most widely used method is to define the data Shapley and approximate it by means of the permutation sampling algorithm. To make up for the large estimation variance of the permutation sampling that hinders the development of the data marketplace, we propose a more robust data valuation method using stratified sampling, named variance reduced data Shapley (VRDS for short). We theoretically show how to stratify, how many samples are taken at each stratum, and the sample complexity analysis of VRDS. Finally, the effectiveness of VRDS is illustrated in different types of datasets and data removal applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20855;&#26377;&#26377;&#38480;&#25903;&#25345;&#30340;&#19968;&#33324;&#21442;&#25968;&#26680;&#36827;&#34892;TPP&#25512;&#29702;&#30340;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22810;&#39033;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.04635</link><description>&lt;p&gt;
FaDIn: &#38024;&#23545;&#20855;&#26377;&#19968;&#33324;&#21442;&#25968;&#26680;&#30340;Hawkes&#36807;&#31243;&#30340;&#24555;&#36895;&#31163;&#25955;&#21270;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels. (arXiv:2210.04635v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20855;&#26377;&#26377;&#38480;&#25903;&#25345;&#30340;&#19968;&#33324;&#21442;&#25968;&#26680;&#36827;&#34892;TPP&#25512;&#29702;&#30340;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22810;&#39033;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#28857;&#36807;&#31243;&#26159;&#24314;&#27169;&#20107;&#20214;&#25968;&#25454;&#30340;&#33258;&#28982;&#24037;&#20855;&#12290;&#22312;&#25152;&#26377;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#27169;&#22411;&#20013;&#65292;Hawkes&#36807;&#31243;&#34987;&#35777;&#26126;&#26159;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#23427;&#20204;&#23545;&#20110;&#21508;&#31181;&#24212;&#29992;&#30340;&#36866;&#24403;&#24314;&#27169;&#65292;&#29305;&#21035;&#26159;&#22312;&#32771;&#34385;&#25351;&#25968;&#25110;&#38750;&#21442;&#25968;&#26680;&#26102;&#12290;&#23613;&#31649;&#38750;&#21442;&#25968;&#26680;&#26159;&#19968;&#31181;&#36873;&#25321;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#38656;&#35201;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#32780;&#25351;&#25968;&#26680;&#26356;&#20855;&#25968;&#25454;&#25928;&#29575;&#65292;&#23545;&#20110;&#31435;&#21363;&#35302;&#21457;&#26356;&#22810;&#20107;&#20214;&#30340;&#29305;&#23450;&#24212;&#29992;&#26356;&#26377;&#25928;&#65292;&#20294;&#23545;&#20110;&#38656;&#35201;&#20272;&#35745;&#24310;&#36831;&#30340;&#24212;&#29992;&#65288;&#22914;&#31070;&#32463;&#31185;&#23398;&#65289;&#65292;&#23427;&#20204;&#19981;&#22826;&#36866;&#29992;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#20379;&#19968;&#31181;&#20351;&#29992;&#20855;&#26377;&#26377;&#38480;&#25903;&#25345;&#30340;&#19968;&#33324;&#21442;&#25968;&#26680;&#36827;&#34892;TPP&#25512;&#29702;&#30340;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#25152;&#24320;&#21457;&#30340;&#35299;&#20915;&#26041;&#26696;&#21253;&#25324;&#21033;&#29992;&#20107;&#20214;&#30340;&#31163;&#25955;&#21270;&#30340;&#24555;&#36895;$\ell_2$&#26799;&#24230;&#27714;&#35299;&#22120;&#12290;&#22312;&#29702;&#35770;&#19978;&#25903;&#25345;&#31163;&#25955;&#21270;&#30340;&#20351;&#29992;&#21518;&#65292;&#36890;&#36807;&#22810;&#31181;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#26032;&#26041;&#27861;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their adequate modeling for various applications, particularly when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for specific applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast $\ell_2$ gradient-based solver leveraging a discretized version of the events. After theoretically supporting the use of discretization, the statistical and computational efficiency of the novel approach is demonstrated through va
&lt;/p&gt;</description></item><item><title>&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#23637;&#24320;&#27714;&#23548;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#26412;&#25991;&#23545;&#20854;&#22312;&#26799;&#24230;&#19979;&#38477;&#21644; Chebyshev &#26041;&#27861;&#20013;&#30340;&#20108;&#27425;&#30446;&#26631;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#65292;&#21457;&#29616;&#25105;&#20204;&#35201;&#30830;&#20445;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#25910;&#25947;&#65292;&#23601;&#24517;&#39035;&#38754;&#20020;&#23637;&#24320;&#27714;&#23548;&#30340;&#35781;&#21650;&#65292;&#21363;&#35201;&#20040;&#36873;&#25321;&#22823;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#24555;&#36895;&#28176;&#36827;&#25910;&#25947;&#20294;&#31639;&#27861;&#26377;&#36739;&#38271;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#35201;&#20040;&#36873;&#25321;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#21363;&#26102;&#20294;&#36739;&#24930;&#30340;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2209.13271</link><description>&lt;p&gt;
&#23637;&#24320;&#30340;&#35781;&#21650;&#65306;&#31995;&#32479;&#20248;&#21270;&#30340;&#19981;&#21516;&#21270;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
The Curse of Unrolling: Rate of Differentiating Through Optimization. (arXiv:2209.13271v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.13271
&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#23637;&#24320;&#27714;&#23548;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#26412;&#25991;&#23545;&#20854;&#22312;&#26799;&#24230;&#19979;&#38477;&#21644; Chebyshev &#26041;&#27861;&#20013;&#30340;&#20108;&#27425;&#30446;&#26631;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#65292;&#21457;&#29616;&#25105;&#20204;&#35201;&#30830;&#20445;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#25910;&#25947;&#65292;&#23601;&#24517;&#39035;&#38754;&#20020;&#23637;&#24320;&#27714;&#23548;&#30340;&#35781;&#21650;&#65292;&#21363;&#35201;&#20040;&#36873;&#25321;&#22823;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#24555;&#36895;&#28176;&#36827;&#25910;&#25947;&#20294;&#31639;&#27861;&#26377;&#36739;&#38271;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#35201;&#20040;&#36873;&#25321;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#21363;&#26102;&#20294;&#36739;&#24930;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#20248;&#21270;&#38382;&#39064;&#35299;&#30340;&#38597;&#21487;&#27604;&#30697;&#38453;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20013;&#24515;&#38382;&#39064;&#65292;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#12289;&#20248;&#21270;&#20316;&#20026;&#19968;&#31181;&#23618;&#20197;&#21450;&#25968;&#25454;&#38598;&#33976;&#39311;&#31561;&#26041;&#38754;&#26377;&#30528;&#24191;&#27867;&#24212;&#29992;&#12290;&#23637;&#24320;&#27714;&#23548;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#36845;&#20195;&#27714;&#35299;&#22120;&#36817;&#20284;&#27714;&#35299;&#35299;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#36335;&#24452;&#36827;&#34892;&#19981;&#21516;&#21270;&#12290;&#26412;&#25991;&#38024;&#23545;&#26799;&#24230;&#19979;&#38477;&#21644;Chebyshev&#26041;&#27861;&#20013;&#20108;&#27425;&#30446;&#26631;&#25552;&#20379;&#20102;&#35813;&#26041;&#27861;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20026;&#20102;&#30830;&#20445;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#25910;&#25947;&#65292;&#25105;&#20204;&#21487;&#20197;&#36873;&#25321;1&#65289;&#36873;&#25321;&#22823;&#30340;&#23398;&#20064;&#29575;&#65292;&#23548;&#33268;&#24555;&#36895;&#30340;&#28176;&#36827;&#25910;&#25947;&#65292;&#20294;&#21487;&#33021;&#20250;&#25509;&#21463;&#31639;&#27861;&#20855;&#26377;&#20219;&#24847;&#38271;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#25110;&#32773;2&#65289;&#36873;&#25321;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#65292;&#23548;&#33268;&#21363;&#26102;&#20294;&#36739;&#24930;&#30340;&#25910;&#25947;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#23637;&#24320;&#30340;&#35781;&#21650;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#27492;&#26041;&#27861;&#30456;&#20851;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#20363;&#22914;&#23548;&#20986;&#23454;&#29992;&#30340;&#26356;&#26032;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the Jacobian of the solution of an optimization problem is a central problem in machine learning, with applications in hyperparameter optimization, meta-learning, optimization as a layer, and dataset distillation, to name a few. Unrolled differentiation is a popular heuristic that approximates the solution using an iterative solver and differentiates it through the computational path. This work provides a non-asymptotic convergence-rate analysis of this approach on quadratic objectives for gradient descent and the Chebyshev method. We show that to ensure convergence of the Jacobian, we can either 1) choose a large learning rate leading to a fast asymptotic convergence but accept that the algorithm may have an arbitrarily long burn-in phase or 2) choose a smaller learning rate leading to an immediate but slower convergence. We refer to this phenomenon as the curse of unrolling. Finally, we discuss open problems relative to this approach, such as deriving a practical update rul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#27169;&#22411;&#29305;&#23450;&#20132;&#20114;&#26816;&#27979;&#26041;&#27861;&#26469;&#33258;&#21160;&#21270;&#23547;&#25214;GLMs&#20013;&#24212;&#28155;&#21152;&#30340;&#20132;&#20114;&#20316;&#29992;&#20197;&#25552;&#39640;&#20854;&#39044;&#27979;&#33021;&#21147;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.08030</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#26816;&#27979;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#20132;&#20114;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
Detection of Interacting Variables for Generalized Linear Models via Neural Networks. (arXiv:2209.08030v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.08030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#27169;&#22411;&#29305;&#23450;&#20132;&#20114;&#26816;&#27979;&#26041;&#27861;&#26469;&#33258;&#21160;&#21270;&#23547;&#25214;GLMs&#20013;&#24212;&#28155;&#21152;&#30340;&#20132;&#20114;&#20316;&#29992;&#20197;&#25552;&#39640;&#20854;&#39044;&#27979;&#33021;&#21147;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#26159;&#20445;&#38505;&#20844;&#21496;&#32463;&#24120;&#20351;&#29992;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#20854;&#36136;&#37327;&#21462;&#20915;&#20110;&#20132;&#20114;&#21464;&#37327;&#30340;&#36873;&#25321;&#12290;&#23547;&#25214;&#20132;&#20114;&#20316;&#29992;&#23545;&#20110;&#20855;&#26377;&#35768;&#22810;&#21464;&#37327;&#30340;&#25968;&#25454;&#38598;&#26469;&#35828;&#38750;&#24120;&#32791;&#26102;&#65292;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#31934;&#31639;&#24072;&#30340;&#19987;&#19994;&#21028;&#26029;&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#35270;&#35273;&#24615;&#33021;&#25351;&#26631;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#23547;&#25214;GLMs&#20013;&#24212;&#28155;&#21152;&#30340;&#20132;&#20114;&#20316;&#29992;&#20197;&#25552;&#39640;&#20854;&#39044;&#27979;&#33021;&#21147;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#31070;&#32463;&#32593;&#32476;&#21644;&#27169;&#22411;&#29305;&#23450;&#30340;&#20132;&#20114;&#26816;&#27979;&#26041;&#27861;&#65292;&#36825;&#27604;&#20256;&#32479;&#26041;&#27861;&#65288;&#22914;Friedman H&#32479;&#35745;&#37327;&#25110;SHAP&#20540;&#65289;&#35201;&#24555;&#12290;&#22312;&#25968;&#23383;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#24037;&#29983;&#25104;&#25968;&#25454;&#20197;&#21450;&#24320;&#28304;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The quality of generalized linear models (GLMs), frequently used by insurance companies, depends on the choice of interacting variables. The search for interactions is time-consuming, especially for data sets with a large number of variables, depends much on expert judgement of actuaries, and often relies on visual performance indicators. Therefore, we present an approach to automating the process of finding interactions that should be added to GLMs to improve their predictive power. Our approach relies on neural networks and a model-specific interaction detection method, which is computationally faster than the traditionally used methods like Friedman H-Statistic or SHAP values. In numerical studies, we provide the results of our approach on artificially generated data as well as open-source data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#33707;&#37324;-&#33576;&#26106;&#40784;&#26684;&#24418;&#24335;&#20027;&#20041;&#30340;&#28145;&#24230;&#23398;&#20064;&#26032;&#34920;&#36848;&#65292;&#24341;&#20837;&#20102;&#31070;&#32463;&#32593;&#32476;&#35760;&#24518;&#30340;&#26032;&#27010;&#24565;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#31639;&#23376;&#26041;&#31243;&#30452;&#25509;&#21521;&#21069;&#21644;&#21521;&#21518;&#20256;&#25773;&#24863;&#20852;&#36259;&#30340;&#37327;&#12290;&#25910;&#32553;&#26144;&#23556;&#29702;&#35770;&#34987;&#29992;&#26469;&#24320;&#21457;&#35760;&#24518;&#34928;&#20943;&#38543;&#32593;&#32476;&#23618;&#25968;&#22686;&#21152;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2209.05544</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#33707;&#37324;-&#33576;&#26106;&#40784;&#26684;&#34920;&#36848;
&lt;/p&gt;
&lt;p&gt;
The Mori-Zwanzig formulation of deep learning. (arXiv:2209.05544v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.05544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#33707;&#37324;-&#33576;&#26106;&#40784;&#26684;&#24418;&#24335;&#20027;&#20041;&#30340;&#28145;&#24230;&#23398;&#20064;&#26032;&#34920;&#36848;&#65292;&#24341;&#20837;&#20102;&#31070;&#32463;&#32593;&#32476;&#35760;&#24518;&#30340;&#26032;&#27010;&#24565;&#65292;&#24182;&#36890;&#36807;&#32447;&#24615;&#31639;&#23376;&#26041;&#31243;&#30452;&#25509;&#21521;&#21069;&#21644;&#21521;&#21518;&#20256;&#25773;&#24863;&#20852;&#36259;&#30340;&#37327;&#12290;&#25910;&#32553;&#26144;&#23556;&#29702;&#35770;&#34987;&#29992;&#26469;&#24320;&#21457;&#35760;&#24518;&#34928;&#20943;&#38543;&#32593;&#32476;&#23618;&#25968;&#22686;&#21152;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#19981;&#21487;&#36870;&#32479;&#35745;&#21147;&#23398;&#30340;&#33707;&#37324;-&#33576;&#26106;&#40784;&#26684;&#65288;MZ&#65289;&#24418;&#24335;&#20027;&#20041;&#65292;&#25552;&#20986;&#20102;&#28145;&#24230;&#23398;&#20064;&#30340;&#26032;&#34920;&#36848;&#12290;&#36825;&#31181;&#26032;&#30340;&#34920;&#36848;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#31163;&#25955;&#21160;&#21147;&#31995;&#32479;&#20043;&#38388;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#36890;&#36807;&#32447;&#24615;&#31639;&#23376;&#26041;&#31243;&#30452;&#25509;&#21521;&#21069;&#21644;&#21521;&#21518;&#20256;&#25773;&#24863;&#20852;&#36259;&#30340;&#37327;&#65288;&#26465;&#20214;&#26399;&#26395;&#21644;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65289;&#12290;&#36825;&#20123;&#26032;&#26041;&#31243;&#21487;&#20197;&#20316;&#20026;&#24320;&#21457;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26032;&#30340;&#26377;&#25928;&#21442;&#25968;&#21270;&#30340;&#36215;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#36807;&#31639;&#23376;&#29702;&#35770;&#26041;&#27861;&#30740;&#31350;&#28145;&#24230;&#23398;&#20064;&#30340;&#26694;&#26550;&#12290;&#25152;&#25552;&#20986;&#30340;MZ&#24418;&#24335;&#20027;&#20041;&#33258;&#28982;&#24341;&#20837;&#20102;&#31070;&#32463;&#32593;&#32476;&#35760;&#24518;&#30340;&#26032;&#27010;&#24565;&#65292;&#22312;&#20302;&#32500;&#24314;&#27169;&#21644;&#21442;&#25968;&#21270;&#20013;&#36215;&#30528; fundamental &#30340;&#20316;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#25910;&#32553;&#26144;&#23556;&#29702;&#35770;&#65292;&#25105;&#20204;&#24320;&#21457;&#20986;&#20102;&#35760;&#24518;&#34928;&#20943;&#38543;&#32593;&#32476;&#23618;&#25968;&#22686;&#21152;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new formulation of deep learning based on the Mori-Zwanzig (MZ) formalism of irreversible statistical mechanics. The new formulation is built upon the well-known duality between deep neural networks and discrete dynamical systems, and it allows us to directly propagate quantities of interest (conditional expectations and probability density functions) forward and backward through the network by means of exact linear operator equations. Such new equations can be used as a starting point to develop new effective parameterizations of deep neural networks, and provide a new framework to study deep-learning via operator theoretic methods. The proposed MZ formulation of deep learning naturally introduces a new concept, i.e., the memory of the neural network, which plays a fundamental role in low-dimensional modeling and parameterization. By using the theory of contraction mappings, we develop sufficient conditions for the memory of the neural network to decay with the number of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#32452;&#21512;&#22797;&#21512;&#20307;&#36825;&#19968;&#26032;&#22411;&#25299;&#25169;&#22495;&#12290;&#32452;&#21512;&#22797;&#21512;&#20307;&#32467;&#21512;&#20102;&#36229;&#22270;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#30340;&#20248;&#28857;&#65292;&#20801;&#35768;&#26500;&#24314;&#20998;&#23618;&#39640;&#38454;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2206.00606</link><description>&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#65306;&#36229;&#36234;&#22270;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Topological Deep Learning: Going Beyond Graph Data. (arXiv:2206.00606v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#32452;&#21512;&#22797;&#21512;&#20307;&#36825;&#19968;&#26032;&#22411;&#25299;&#25169;&#22495;&#12290;&#32452;&#21512;&#22797;&#21512;&#20307;&#32467;&#21512;&#20102;&#36229;&#22270;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#30340;&#20248;&#28857;&#65292;&#20801;&#35768;&#26500;&#24314;&#20998;&#23618;&#39640;&#38454;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#19982;&#24320;&#21457;&#25903;&#25345;&#20110;&#25299;&#25169;&#22495;&#19978;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26377;&#20851;&#65292;&#20363;&#22914;&#21333;&#32431;&#22797;&#21512;&#20307;&#12289;&#32990;&#33108;&#22797;&#21512;&#20307;&#21644;&#36229;&#22270;&#12290;&#36825;&#20123;&#25299;&#25169;&#22495;&#22312;&#31185;&#23398;&#35745;&#31639;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24314;&#31435;&#22312;&#26356;&#20016;&#23500;&#25968;&#25454;&#32467;&#26500;&#20043;&#19978;&#30340;&#32479;&#19968;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21253;&#25324;&#25299;&#25169;&#22495;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#32452;&#21512;&#22797;&#21512;&#20307;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#25299;&#25169;&#22495;&#12290;&#32452;&#21512;&#22797;&#21512;&#20307;&#21487;&#20197;&#30475;&#20316;&#26159;&#20445;&#25345;&#26576;&#20123;&#29702;&#24819;&#24615;&#36136;&#30340;&#22270;&#30340;&#25512;&#24191;&#12290;&#31867;&#20284;&#20110;&#36229;&#22270;&#65292;&#32452;&#21512;&#22797;&#21512;&#20307;&#23545;&#20851;&#31995;&#38598;&#21512;&#19981;&#26045;&#21152;&#20219;&#20309;&#32422;&#26463;&#12290;&#27492;&#22806;&#65292;&#32452;&#21512;&#22797;&#21512;&#20307;&#20801;&#35768;&#26500;&#24314;&#20998;&#23618;&#39640;&#38454;&#20851;&#31995;&#65292;&#31867;&#20284;&#20110;&#21333;&#32431;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#20013;&#30340;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#32452;&#21512;&#22797;&#21512;&#20307;&#25512;&#24191;&#24182;&#32467;&#21512;&#20102;&#36229;&#22270;&#21644;&#32990;&#33108;&#22797;&#21512;&#20307;&#30340;&#26377;&#29992;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topological deep learning is a rapidly growing field that pertains to the development of deep learning models for data supported on topological domains such as simplicial complexes, cell complexes, and hypergraphs, which generalize many domains encountered in scientific computations. In this paper, we present a unifying deep learning framework built upon a richer data structure that includes widely adopted topological domains.  Specifically, we first introduce combinatorial complexes, a novel type of topological domain. Combinatorial complexes can be seen as generalizations of graphs that maintain certain desirable properties. Similar to hypergraphs, combinatorial complexes impose no constraints on the set of relations. In addition, combinatorial complexes permit the construction of hierarchical higher-order relations, analogous to those found in simplicial and cell complexes. Thus, combinatorial complexes generalize and combine useful traits of both hypergraphs and cell complexes, whi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25509;&#36817;&#21333;&#36890;&#36947;&#35821;&#38899;&#20998;&#31163;&#30028;&#38480;&#30340;&#26041;&#27861;SepIt&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;5&#20010;&#21644;10&#20010;&#35828;&#35805;&#20154;&#30340;&#24773;&#20917;&#19979;&#20173;&#26377;&#25552;&#39640;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2205.11801</link><description>&lt;p&gt;
SepIt: &#25509;&#36817;&#21333;&#36890;&#36947;&#35821;&#38899;&#20998;&#31163;&#30028;&#38480;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SepIt: Approaching a Single Channel Speech Separation Bound. (arXiv:2205.11801v4 [eess.AS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11801
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25509;&#36817;&#21333;&#36890;&#36947;&#35821;&#38899;&#20998;&#31163;&#30028;&#38480;&#30340;&#26041;&#27861;SepIt&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;5&#20010;&#21644;10&#20010;&#35828;&#35805;&#20154;&#30340;&#24773;&#20917;&#19979;&#20173;&#26377;&#25552;&#39640;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#36890;&#36947;&#35821;&#38899;&#20998;&#31163;&#20219;&#21153;&#30340;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#22522;&#20110;&#23545;&#35821;&#38899;&#30701;&#26102;&#27573;&#24615;&#36136;&#30340;&#20551;&#35774;&#12290;&#20351;&#29992;&#35813;&#19978;&#30028;&#65292;&#25105;&#20204;&#33021;&#22815;&#23637;&#31034;&#65292;&#34429;&#28982;&#26368;&#36817;&#30340;&#26041;&#27861;&#24050;&#32463;&#21462;&#24471;&#20102;&#22312;&#23569;&#25968;&#20960;&#20010;&#35828;&#35805;&#20154;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;&#20294;&#22312;5&#20010;&#21644;10&#20010;&#35828;&#35805;&#20154;&#30340;&#24773;&#20917;&#19979;&#36824;&#26377;&#25552;&#39640;&#30340;&#31354;&#38388;&#12290;&#25509;&#30528;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;SepIt&#26469;&#36845;&#20195;&#22320;&#25913;&#36827;&#19981;&#21516;&#35828;&#35805;&#20154;&#30340;&#20272;&#35745;&#12290;&#22312;&#27979;&#35797;&#26102;&#65292;SepIt&#23545;&#20110;&#27599;&#20010;&#27979;&#35797;&#26679;&#26412;&#30340;&#36845;&#20195;&#27425;&#25968;&#26159;&#21487;&#21464;&#30340;&#65292;&#22522;&#20110;&#25105;&#20204;&#20998;&#26512;&#20013;&#20986;&#29616;&#30340;&#20114;&#20449;&#24687;&#26631;&#20934;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;SepIt&#22312;2&#12289;3&#12289;5&#21644;10&#20010;&#35828;&#35805;&#20154;&#30340;&#24773;&#20917;&#19979;&#32988;&#36807;&#20102;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an upper bound for the Single Channel Speech Separation task, which is based on an assumption regarding the nature of short segments of speech. Using the bound, we are able to show that while the recent methods have made significant progress for a few speakers, there is room for improvement for five and ten speakers. We then introduce a Deep neural network, SepIt, that iteratively improves the different speakers' estimation. At test time, SpeIt has a varying number of iterations per test sample, based on a mutual information criterion that arises from our analysis. In an extensive set of experiments, SepIt outperforms the state-of-the-art neural networks for 2, 3, 5, and 10 speakers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#23567;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#23567;&#30340;NTK&#29305;&#24449;&#20540;&#30340;&#19979;&#30028;&#65292;&#20855;&#26377;&#27425;&#32447;&#24615;&#23618;&#23485;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#26159;&#24378;&#22823;&#30340;&#35760;&#24518;&#22120;&#21644;&#20248;&#21270;&#22120;&#65292;&#21482;&#35201;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#26679;&#26412;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2205.10217</link><description>&lt;p&gt;
&#24102;&#26377;&#26368;&#23567;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#35760;&#24518;&#21270;&#19982;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization. (arXiv:2205.10217v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10217
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#23567;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#23567;&#30340;NTK&#29305;&#24449;&#20540;&#30340;&#19979;&#30028;&#65292;&#20855;&#26377;&#27425;&#32447;&#24615;&#23618;&#23485;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#26159;&#24378;&#22823;&#30340;&#35760;&#24518;&#22120;&#21644;&#20248;&#21270;&#22120;&#65292;&#21482;&#35201;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#26679;&#26412;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#24050;&#25104;&#20026;&#25552;&#20379;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35760;&#24518;&#21270;&#12289;&#20248;&#21270;&#21644;&#27867;&#21270;&#20445;&#35777;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#37096;&#20998;&#23398;&#32773;&#24050;&#30740;&#31350;&#20102;&#33267;&#23569;&#19968;&#23618;&#20855;&#26377;$\Omega(N)$&#20010;&#31070;&#32463;&#20803;&#30340;&#20004;&#23618;&#21644;&#28145;&#23618;&#32593;&#32476;&#30340;NTK&#35889;&#65292;&#20854;&#20013;$N$&#26159;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#35777;&#25454;&#34920;&#26126;&#65292;&#20855;&#26377;&#27425;&#32447;&#24615;&#23618;&#23485;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#26159;&#24378;&#22823;&#30340;&#35760;&#24518;&#22120;&#21644;&#20248;&#21270;&#22120;&#65292;&#21482;&#35201;&#21442;&#25968;&#25968;&#37327;&#36229;&#36807;&#26679;&#26412;&#25968;&#37327;&#21363;&#21487;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#33258;&#28982;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#26159;&#22312;&#36825;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#27425;&#32447;&#24615;&#35774;&#32622;&#19979;&#65292;NTK&#26159;&#21542;&#23384;&#22312;&#33391;&#22909;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32943;&#23450;&#22320;&#22238;&#31572;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#25216;&#26415;&#36129;&#29486;&#26159;&#25552;&#20379;&#20102;&#19968;&#20010;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#26368;&#23567;&#30340;NTK&#29305;&#24449;&#20540;&#30340;&#19979;&#30028;&#65292;&#21363;&#21442;&#25968;&#25968;&#37327;&#22823;&#32422;&#20026;$\Omega(N)$&#65292;&#22240;&#27492;&#31070;&#32463;&#20803;&#25968;&#37327;&#33267;&#23569;&#20026;$\Omega(\sqrt{N})$&#12290;&#20026;&#23637;&#31034;&#25105;&#20204;&#31639;&#27861;&#30340;&#36866;&#29992;&#24615;&#65292;&#25105;&#20204;&#22312;&#22810;&#39033;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Neural Tangent Kernel (NTK) has emerged as a powerful tool to provide memorization, optimization and generalization guarantees in deep neural networks. A line of work has studied the NTK spectrum for two-layer and deep networks with at least a layer with $\Omega(N)$ neurons, $N$ being the number of training samples. Furthermore, there is increasing evidence suggesting that deep networks with sub-linear layer widths are powerful memorizers and optimizers, as long as the number of parameters exceeds the number of samples. Thus, a natural open question is whether the NTK is well conditioned in such a challenging sub-linear setup. In this paper, we answer this question in the affirmative. Our key technical contribution is a lower bound on the smallest NTK eigenvalue for deep networks with the minimum possible over-parameterization: the number of parameters is roughly $\Omega(N)$ and, hence, the number of neurons is as little as $\Omega(\sqrt{N})$. To showcase the applicability of our N
&lt;/p&gt;</description></item><item><title>&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#26159;&#19968;&#31181;&#33021;&#22815;&#20174;&#37051;&#23621;&#33410;&#28857;&#30340;&#29305;&#24449;&#20013;&#32858;&#21512;&#20449;&#24687;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#19978;&#19979;&#25991;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#8220;&#26131;&#8221;&#21306;&#38388;&#20869;&#65292;&#23427;&#33021;&#22815;&#21306;&#20998;&#36328;&#31867;&#21644;&#20869;&#31867;&#36793;&#32536;&#24182;&#32500;&#25252;&#37325;&#35201;&#36793;&#32536;&#30340;&#26435;&#37325;&#12290;</title><link>http://arxiv.org/abs/2202.13060</link><description>&lt;p&gt;
&#22270;&#27880;&#24847;&#21147;&#22238;&#39038;
&lt;/p&gt;
&lt;p&gt;
Graph Attention Retrospective. (arXiv:2202.13060v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.13060
&lt;/p&gt;
&lt;p&gt;
&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#26159;&#19968;&#31181;&#33021;&#22815;&#20174;&#37051;&#23621;&#33410;&#28857;&#30340;&#29305;&#24449;&#20013;&#32858;&#21512;&#20449;&#24687;&#30340;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#19978;&#19979;&#25991;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#8220;&#26131;&#8221;&#21306;&#38388;&#20869;&#65292;&#23427;&#33021;&#22815;&#21306;&#20998;&#36328;&#31867;&#21644;&#20869;&#31867;&#36793;&#32536;&#24182;&#32500;&#25252;&#37325;&#35201;&#36793;&#32536;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22270;&#30340;&#23398;&#20064;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24555;&#36895;&#21457;&#23637;&#30340;&#19968;&#20010;&#23376;&#39046;&#22495;&#65292;&#24212;&#29992;&#20110;&#31038;&#20132;&#32593;&#32476;&#12289;&#24341;&#25991;&#32593;&#32476;&#21644;&#29983;&#29289;&#20449;&#24687;&#23398;&#12290;&#20854;&#20013;&#26368;&#27969;&#34892;&#30340;&#27169;&#22411;&#20043;&#19968;&#26159;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#12290;&#23427;&#20204;&#34987;&#24341;&#20837;&#20351;&#33410;&#28857;&#33021;&#22815;&#20197;&#38750;&#32479;&#19968;&#30340;&#26041;&#24335;&#20174;&#37051;&#23621;&#33410;&#28857;&#30340;&#29305;&#24449;&#20013;&#32858;&#21512;&#20449;&#24687;&#65292;&#19982;&#31616;&#21333;&#30340;&#22270;&#21367;&#31215;&#19981;&#21516;&#65292;&#21518;&#32773;&#19981;&#33021;&#21306;&#20998;&#33410;&#28857;&#30340;&#37051;&#23621;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22270;&#27880;&#24847;&#32593;&#32476;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#23545;&#19978;&#19979;&#25991;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#33410;&#28857;&#20998;&#31867;&#38382;&#39064;&#35777;&#26126;&#20102;&#22270;&#27880;&#24847;&#26426;&#21046;&#30340;&#22810;&#20010;&#24615;&#33021;&#32467;&#26524;&#12290;&#22312;&#35813;&#27169;&#22411;&#20013;&#65292;&#33410;&#28857;&#29305;&#24449;&#26469;&#33258;&#20110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#36793;&#32536;&#26469;&#33258;&#20110;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#8220;&#26131;&#8221;&#21306;&#38388;&#20869;&#65292;&#39640;&#26031;&#20998;&#24067;&#22343;&#20540;&#20043;&#38388;&#30340;&#36317;&#31163;&#36275;&#22815;&#22823;&#26102;&#65292;&#22270;&#27880;&#24847;&#21147;&#21487;&#20197;&#21306;&#20998;&#36328;&#31867;&#21644;&#20869;&#31867;&#36793;&#32536;&#12290;&#22240;&#27492;&#65292;&#23427;&#32500;&#25252;&#20102;&#37325;&#35201;&#36793;&#32536;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph-based learning is a rapidly growing sub-field of machine learning with applications in social networks, citation networks, and bioinformatics. One of the most popular models is graph attention networks. They were introduced to allow a node to aggregate information from features of neighbor nodes in a non-uniform way, in contrast to simple graph convolution which does not distinguish the neighbors of a node. In this paper, we theoretically study the behaviour of graph attention networks. We prove multiple results on the performance of the graph attention mechanism for the problem of node classification for a contextual stochastic block model. Here, the node features are obtained from a mixture of Gaussians and the edges from a stochastic block model. We show that in an "easy" regime, where the distance between the means of the Gaussians is large enough, graph attention is able to distinguish inter-class from intra-class edges. Thus it maintains the weights of important edges and s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31995;&#21015;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#30456;&#20284;&#24615;&#21644;&#24046;&#24322;&#24615;&#65292;&#24182;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.05250</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#40065;&#26834;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive and Robust Multi-Task Learning. (arXiv:2202.05250v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31995;&#21015;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#22788;&#29702;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#30456;&#20284;&#24615;&#21644;&#24046;&#24322;&#24615;&#65292;&#24182;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#35299;&#20915;&#20174;&#19981;&#21516;&#26469;&#28304;&#25910;&#38598;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#24182;&#23545;&#27599;&#20010;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#20010;&#27169;&#22411;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#33258;&#21160;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#65292;&#21516;&#26102;&#22788;&#29702;&#23427;&#20204;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#23545;&#24322;&#24120;&#20219;&#21153;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the multi-task learning problem that aims to simultaneously analyze multiple datasets collected from different sources and learn one model for each of them. We propose a family of adaptive methods that automatically utilize possible similarities among those tasks while carefully handling their differences. We derive sharp statistical guarantees for the methods and prove their robustness against outlier tasks. Numerical experiments on synthetic and real datasets demonstrate the efficacy of our new methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23558;&#21028;&#21035;&#32593;&#32476;&#36716;&#25442;&#20026;&#29983;&#25104;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#29992;&#39640;&#26031;&#26680;&#26367;&#25442;&#22810;&#38754;&#20307;&#20013;&#30340;&#20223;&#23556;&#20989;&#25968;&#26469;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20869;&#37096;&#21644;&#22806;&#37096;&#25968;&#25454;&#26657;&#20934;&#38382;&#39064;&#65292;&#24182;&#22312; CIFAR-10&#65292;CIFAR-100 &#21644; SVHN &#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.13001</link><description>&lt;p&gt;
&#28145;&#24230;&#21028;&#21035;&#21040;&#26680;&#29983;&#25104;&#32593;&#32476;&#30340;&#23450;&#26631;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deep Discriminative to Kernel Generative Networks for Calibrated Inference. (arXiv:2201.13001v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.13001
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23558;&#21028;&#21035;&#32593;&#32476;&#36716;&#25442;&#20026;&#29983;&#25104;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#29992;&#39640;&#26031;&#26680;&#26367;&#25442;&#22810;&#38754;&#20307;&#20013;&#30340;&#20223;&#23556;&#20989;&#25968;&#26469;&#29983;&#25104;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#20869;&#37096;&#21644;&#22806;&#37096;&#25968;&#25454;&#26657;&#20934;&#38382;&#39064;&#65292;&#24182;&#22312; CIFAR-10&#65292;CIFAR-100 &#21644; SVHN &#31561;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21028;&#21035;&#19982;&#29983;&#25104;&#32593;&#32476;&#22312;&#20154;&#24037;&#26234;&#33021;&#21644;&#33258;&#28982;&#26234;&#33021;&#30340;&#30740;&#31350;&#20013;&#37117;&#26377;&#20854;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#20108;&#32773;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#23558;&#28145;&#24230;&#21028;&#21035;&#32593;&#32476;&#36716;&#25442;&#20026;&#26680;&#29983;&#25104;&#32593;&#32476;&#12290;&#25105;&#20204;&#23558;&#28145;&#24230;&#27169;&#22411;&#35270;&#20026;&#24191;&#20041;&#30340;&#21010;&#20998;&#35268;&#21017;&#65292;&#24182;&#20351;&#29992;&#39640;&#26031;&#26680;&#26367;&#25442;&#30001;&#35757;&#32451;&#25968;&#25454;&#26500;&#25104;&#30340;&#22810;&#38754;&#20307;&#20013;&#30340;&#20223;&#23556;&#20989;&#25968;&#65292;&#26469;&#33719;&#24471;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fight between discriminative versus generative goes deep, in both the study of artificial and natural intelligence. In our view, both camps have complementary values. So, we sought to synergistically combine them. Here, we propose a methodology to convert deep discriminative networks to kernel generative networks. We leveraged the fact that deep models, including both random forests and deep networks, learn internal representations which are unions of polytopes with affine activation functions to conceptualize them both as generalized partitioning rules. We replace the affine function in each polytope populated by the training data with Gaussian kernel that results in a generative model. Theoretically, we derive the conditions under which our generative models are a consistent estimator of the corresponding class conditional density. Moreover, our proposed models obtain well calibrated posteriors for in-distribution, and extrapolate beyond the training data to handle out-of-distrib
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#19988;&#28789;&#27963;&#30340;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#28151;&#21512;&#26925;&#22278;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#38750;&#39640;&#26031;&#25968;&#25454;&#25554;&#34917;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2201.12020</link><description>&lt;p&gt;
&#19968;&#31181;&#40065;&#26834;&#32780;&#28789;&#27963;&#30340;&#26925;&#22278;&#20998;&#24067;&#28151;&#21512;&#32570;&#22833;&#25968;&#25454;EM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Robust and Flexible EM Algorithm for Mixtures of Elliptical Distributions with Missing Data. (arXiv:2201.12020v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.12020
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#40065;&#26834;&#19988;&#28789;&#27963;&#30340;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#28151;&#21512;&#26925;&#22278;&#20998;&#24067;&#65292;&#35299;&#20915;&#20102;&#38750;&#39640;&#26031;&#25968;&#25454;&#25554;&#34917;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22122;&#22768;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#32570;&#22833;&#25968;&#25454;&#25554;&#34917;&#30340;&#38382;&#39064;&#12290;Gaussian&#28151;&#21512;&#27169;&#22411;&#30340;&#26399;&#26395;&#26497;&#22823;&#31639;&#27861;&#24050;&#32463;&#34987;&#35777;&#26126;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#27604;&#22522;&#20110;k&#36817;&#37051;&#25110;&#22522;&#20110;&#22810;&#37325;&#26041;&#31243;&#38142;&#30340;&#25554;&#34917;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#20294;&#26159;&#65292;Gaussian&#28151;&#21512;&#27169;&#22411;&#23545;&#20110;&#24322;&#26500;&#25968;&#25454;&#26159;&#38750;&#40065;&#26834;&#30340;&#65292;&#24403;&#25968;&#25454;&#21463;&#21040;&#31163;&#32676;&#28857;&#25110;&#36981;&#24490;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#24433;&#21709;&#26102;&#20250;&#23548;&#33268;&#24615;&#33021;&#20272;&#35745;&#36739;&#24046;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#26925;&#22278;&#20998;&#24067;&#30340;&#28151;&#21512;&#29289;&#65292;&#20855;&#26377;&#22788;&#29702;&#28508;&#22312;&#32570;&#22833;&#25968;&#25454;&#30340;&#29305;&#24615;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#36825;&#20010;&#38382;&#39064;&#21487;&#20197;&#24402;&#32467;&#20026;&#22312;&#36890;&#29992;&#26465;&#20214;&#19979;&#65288;&#21363;&#27599;&#20010;&#26679;&#26412;&#37117;&#26159;&#20174;&#19968;&#20010;&#21487;&#33021;&#19981;&#21516;&#30340;&#26925;&#22278;&#20998;&#24067;&#28151;&#21512;&#29289;&#20013;&#25277;&#21462;&#30340;&#65289;&#65292;&#20272;&#35745;angular Gaussian&#20998;&#24067;&#30340;&#28151;&#21512;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper tackles the problem of missing data imputation for noisy and non-Gaussian data. A classical imputation method, the Expectation Maximization (EM) algorithm for Gaussian mixture models, has shown interesting properties when compared to other popular approaches such as those based on k-nearest neighbors or on multiple imputations by chained equations. However, Gaussian mixture models are known to be non-robust to heterogeneous data, which can lead to poor estimation performance when the data is contaminated by outliers or follows non-Gaussian distributions. To overcome this issue, a new EM algorithm is investigated for mixtures of elliptical distributions with the property of handling potential missing data. This paper shows that this problem reduces to the estimation of a mixture of Angular Gaussian distributions under generic assumptions (i.e., each sample is drawn from a mixture of elliptical distributions, which is possibly different for one sample to another). In that case
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#19978;&#30028;&#65292;&#23427;&#19981;&#21253;&#21547;&#21452;&#37325;&#20381;&#36182;&#24615;&#30340;&#26415;&#35821;&#65292;&#22312;&#39046;&#22495;&#24402;&#32435;&#20013;&#20248;&#21270;&#20102;&#26410;&#35265;&#22495;&#30340;&#39118;&#38505;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2109.01902</link><description>&lt;p&gt;
&#22810;&#20010;&#39046;&#22495;&#19979;&#36890;&#29992;&#30340;&#36136;&#24515;&#23545;&#40784;&#21644;&#37325;&#26500;&#25439;&#22833;&#26368;&#23567;&#21270;&#39046;&#22495;&#24402;&#32435;&#35770;&#25991;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Barycentric-alignment and reconstruction loss minimization for domain generalization. (arXiv:2109.01902v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.01902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#19978;&#30028;&#65292;&#23427;&#19981;&#21253;&#21547;&#21452;&#37325;&#20381;&#36182;&#24615;&#30340;&#26415;&#35821;&#65292;&#22312;&#39046;&#22495;&#24402;&#32435;&#20013;&#20248;&#21270;&#20102;&#26410;&#35265;&#22495;&#30340;&#39118;&#38505;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#36827;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#39046;&#22495;&#24402;&#32435;&#65288;DG&#65289;&#29702;&#35770;&#21644;&#23454;&#36341;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20856;&#22411;&#30340;DG&#35774;&#32622;&#65292;&#20854;&#20013;&#20551;&#35774;&#30001;&#34920;&#31034;&#26144;&#23556;&#21644;&#26631;&#35760;&#20989;&#25968;&#32452;&#25104;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;DG&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#26410;&#35265;&#22495;&#20013;&#30340;&#20998;&#31867;&#39118;&#38505;&#30340;&#24050;&#30693;&#19978;&#30028;&#20849;&#21516;&#23398;&#20064;&#34920;&#31034;&#21644;&#26631;&#35760;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#22522;&#20110;&#36825;&#20010;&#29702;&#35770;&#19978;&#30028;&#30340;&#26041;&#27861;&#24573;&#30053;&#20102;&#19968;&#20010;&#30001;&#20110;&#20854;&#23545;&#34920;&#31034;&#26144;&#23556;&#21644;&#26410;&#30693;&#26368;&#20248;&#26631;&#35760;&#20989;&#25968;&#30340;&#21452;&#37325;&#20381;&#36182;&#20851;&#31995;&#32780;&#26080;&#27861;&#30452;&#25509;&#20248;&#21270;&#30340;&#26415;&#35821;&#12290;&#20026;&#20102;&#24357;&#21512;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#65292;&#23427;&#19981;&#21253;&#21547;&#36825;&#31181;&#21452;&#37325;&#20381;&#36182;&#24615;&#30340;&#26415;&#35821;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#19968;&#20010;&#21487;&#20197;&#23436;&#20840;&#20248;&#21270;&#30340;&#26410;&#35265;&#22495;&#39118;&#38505;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#25512;&#23548;&#21033;&#29992;&#20102;&#23558;&#26368;&#20248;&#20256;&#36755;&#24230;&#37327;&#19982;&#20449;&#24687;&#30456;&#36830;&#30340;&#32463;&#20856;&#21644;&#26368;&#36817;&#30340;&#20256;&#36755;&#19981;&#31561;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper advances the theory and practice of Domain Generalization (DG) in machine learning. We consider the typical DG setting where the hypothesis is composed of a representation mapping followed by a labeling function. Within this setting, the majority of popular DG methods aim to jointly learn the representation and the labeling functions by minimizing a well-known upper bound for the classification risk in the unseen domain. In practice, however, methods based on this theoretical upper bound ignore a term that cannot be directly optimized due to its dual dependence on both the representation mapping and the unknown optimal labeling function in the unseen domain. To bridge this gap between theory and practice, we introduce a new upper bound that is free of terms having such dual dependence, resulting in a fully optimizable risk upper bound for the unseen domain. Our derivation leverages classical and recent transport inequalities that link optimal transport metrics with informati
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#30456;&#20114;&#20316;&#29992;&#24494;&#31890;&#24179;&#22343;&#22330;&#26041;&#31243;&#20013;&#30456;&#20114;&#20316;&#29992;&#26680;&#30340;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#20165;&#22312;&#29305;&#23450;&#30340;&#20989;&#25968;&#31354;&#38388;&#20013;&#25165;&#20855;&#26377;&#21807;&#19968;&#30340;&#26368;&#23567;&#21270;&#22120;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#35745;&#31639;&#23454;&#36341;&#65292;&#30740;&#31350;&#35777;&#26126;&#20102;&#21453;&#38382;&#39064;&#30340;&#30149;&#24577;&#24615;&#36136;&#65292;&#38656;&#35201;&#36827;&#34892;&#27491;&#21017;&#21270;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2106.05565</link><description>&lt;p&gt;
&#30456;&#20114;&#20316;&#29992;&#24494;&#31890;&#24179;&#22343;&#22330;&#26041;&#31243;&#20013;&#30340;&#30456;&#20114;&#20316;&#29992;&#26680;&#21487;&#36776;&#35782;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Identifiability of interaction kernels in mean-field equations of interacting particles. (arXiv:2106.05565v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.05565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#30456;&#20114;&#20316;&#29992;&#24494;&#31890;&#24179;&#22343;&#22330;&#26041;&#31243;&#20013;&#30456;&#20114;&#20316;&#29992;&#26680;&#30340;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#20165;&#22312;&#29305;&#23450;&#30340;&#20989;&#25968;&#31354;&#38388;&#20013;&#25165;&#20855;&#26377;&#21807;&#19968;&#30340;&#26368;&#23567;&#21270;&#22120;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#35745;&#31639;&#23454;&#36341;&#65292;&#30740;&#31350;&#35777;&#26126;&#20102;&#21453;&#38382;&#39064;&#30340;&#30149;&#24577;&#24615;&#36136;&#65292;&#38656;&#35201;&#36827;&#34892;&#27491;&#21017;&#21270;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#30456;&#20114;&#20316;&#29992;&#24494;&#31890;&#25110;&#20195;&#29702;&#20154;&#30340;&#24179;&#22343;&#22330;&#26041;&#31243;&#20013;&#30456;&#20114;&#20316;&#29992;&#26680;&#30340;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#65292;&#36825;&#26159;&#21508;&#31181;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#26085;&#30410;&#20851;&#27880;&#30340;&#39046;&#22495;&#12290;&#20027;&#35201;&#20851;&#27880;&#28857;&#22312;&#20110;&#30830;&#23450;&#25968;&#25454;&#30456;&#20851;&#20989;&#25968;&#31354;&#38388;&#65292;&#20854;&#20013;&#20108;&#27425;&#25439;&#22833;&#20989;&#25968;&#25317;&#26377;&#21807;&#19968;&#30340;&#26368;&#23567;&#21270;&#22120;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#20010;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;$L^2$&#31354;&#38388;&#65306;&#19968;&#20010;&#26159;&#30001;&#25968;&#25454;&#33258;&#36866;&#24212;&#26435;&#37325;&#34913;&#37327;&#30340;&#65292;&#21478;&#19968;&#20010;&#20351;&#29992;&#21202;&#36125;&#26684;&#27979;&#24230;&#12290;&#22312;&#27599;&#20010;$L^2$&#31354;&#38388;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#36776;&#35782;&#24615;&#30340;&#20989;&#25968;&#31354;&#38388;&#26159;&#19982;&#27714;&#31215;&#20998;&#31639;&#23376;&#30456;&#20851;&#30340;RKHS&#38381;&#21253;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#30456;&#36741;&#30456;&#25104;&#65292;&#26412;&#30740;&#31350;&#23436;&#25104;&#20102;&#20855;&#26377;&#26377;&#38480;&#25110;&#26080;&#38480;&#24494;&#31890;&#30340;&#30456;&#20114;&#20316;&#29992;&#24494;&#31890;&#31995;&#32479;&#30340;&#21487;&#36776;&#35782;&#24615;&#30340;&#20840;&#38754;&#25551;&#36848;&#65292;&#31361;&#26174;&#20102;&#36825;&#20004;&#31181;&#24773;&#20917;&#20043;&#38388;&#30340;&#20851;&#38190;&#24046;&#24322;&#12290;&#27492;&#22806;&#65292;&#21487;&#36776;&#35782;&#24615;&#20998;&#26512;&#23545;&#20110;&#35745;&#31639;&#23454;&#36341;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#23427;&#34920;&#26126;&#21453;&#38382;&#39064;&#26159;&#30149;&#24577;&#30340;&#65292;&#38656;&#35201;&#27491;&#21017;&#21270;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study examines the identifiability of interaction kernels in mean-field equations of interacting particles or agents, an area of growing interest across various scientific and engineering fields. The main focus is identifying data-dependent function spaces where a quadratic loss functional possesses a unique minimizer. We consider two data-adaptive $L^2$ spaces: one weighted by a data-adaptive measure and the other using the Lebesgue measure. In each $L^2$ space, we show that the function space of identifiability is the closure of the RKHS associated with the integral operator of inversion.  Alongside prior research, our study completes a full characterization of identifiability in interacting particle systems with either finite or infinite particles, highlighting critical differences between these two settings. Moreover, the identifiability analysis has important implications for computational practice. It shows that the inverse problem is ill-posed, necessitating regularization.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36807;&#25311;&#21512;&#12289;&#20132;&#21449;&#39564;&#35777;&#12289;&#27491;&#21017;&#21270;&#12289;&#35013;&#34955;&#27861;&#21644;&#25552;&#21319;&#27861;&#30340;&#30456;&#20851;&#29702;&#35770;&#65292;&#21253;&#25324;&#23450;&#20041;&#21644;&#20855;&#20307;&#23454;&#29616;&#65292;&#24182;&#32473;&#20986;&#20102;AdaBoost&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#30340;&#20855;&#20307;&#35745;&#31639;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/1905.12787</link><description>&lt;p&gt;
&#36807;&#25311;&#21512;&#12289;&#20132;&#21449;&#39564;&#35777;&#12289;&#27491;&#21017;&#21270;&#12289;&#35013;&#34955;&#27861;&#21644;&#25552;&#21319;&#27861;&#32972;&#21518;&#30340;&#29702;&#35770;&#65306;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
The Theory Behind Overfitting, Cross Validation, Regularization, Bagging, and Boosting: Tutorial. (arXiv:1905.12787v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.12787
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36807;&#25311;&#21512;&#12289;&#20132;&#21449;&#39564;&#35777;&#12289;&#27491;&#21017;&#21270;&#12289;&#35013;&#34955;&#27861;&#21644;&#25552;&#21319;&#27861;&#30340;&#30456;&#20851;&#29702;&#35770;&#65292;&#21253;&#25324;&#23450;&#20041;&#21644;&#20855;&#20307;&#23454;&#29616;&#65292;&#24182;&#32473;&#20986;&#20102;AdaBoost&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#30340;&#20855;&#20307;&#35745;&#31639;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#25945;&#31243;&#24615;&#30340;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#20102;&#38543;&#26426;&#21464;&#37327;&#21644;&#20998;&#31867;/&#39044;&#27979;&#27169;&#22411;&#30340;&#22343;&#26041;&#35823;&#24046;&#12289;&#26041;&#24046;&#12289;&#21327;&#26041;&#24046;&#21644;&#20559;&#24046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;Stein&#30340;&#26080;&#20559;&#39118;&#38505;&#20272;&#35745;&#22120;&#65288;SURE&#65289;&#21046;&#23450;&#20102;&#27169;&#22411;&#30340;&#30495;&#23454;&#21644;&#27867;&#21270;&#35823;&#24046;&#65292;&#21253;&#25324;&#35757;&#32451;&#21644;&#39564;&#35777;/&#27979;&#35797;&#23454;&#20363;&#12290;&#21033;&#29992;&#24471;&#21040;&#30340;&#30495;&#23454;&#21644;&#27867;&#21270;&#35823;&#24046;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#36807;&#25311;&#21512;&#12289;&#27424;&#25311;&#21512;&#21644;&#27867;&#21270;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#20132;&#21449;&#39564;&#35777;&#21644;&#20004;&#20010;&#33879;&#21517;&#30340;&#20363;&#23376;&#65292;&#21363;K&#20493;&#20132;&#21449;&#39564;&#35777;&#21644;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#12290;&#25105;&#20204;&#31616;&#35201;&#20171;&#32461;&#20102;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65292;&#28982;&#21518;&#36716;&#21521;&#27491;&#21017;&#21270;&#65292;&#22312;&#36825;&#37324;&#25105;&#20204;&#20877;&#27425;&#20351;&#29992;SURE&#12290;&#25105;&#20204;&#23545;$\ell_2$&#21644;$\ell_1$&#33539;&#25968;&#27491;&#21017;&#21270;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#33258;&#20030;&#32858;&#21512;&#65288;bagging&#65289;&#22914;&#20309;&#38477;&#20302;&#20272;&#35745;&#26041;&#24046;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#25552;&#21319;&#27861;&#65292;&#29305;&#21035;&#26159;AdaBoost&#65292;&#24182;&#35299;&#37322;&#20102;&#23427;&#20316;&#20026;&#19968;&#20010;&#21152;&#24615;&#27169;&#22411;&#21644;&#26368;&#22823;&#38388;&#38548;&#27169;&#22411;&#65288;&#21363;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#65289;&#30340;&#21407;&#29702;&#12290;&#32473;&#20986;&#20102;AdaBoost&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#65292;&#21253;&#25324;&#25351;&#25968;&#25439;&#22833;&#21644;0-1&#25439;&#22833;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24635;&#32467;&#20102;&#25945;&#31243;&#30340;&#20027;&#35201;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this tutorial paper, we first define mean squared error, variance, covariance, and bias of both random variables and classification/predictor models. Then, we formulate the true and generalization errors of the model for both training and validation/test instances where we make use of the Stein's Unbiased Risk Estimator (SURE). We define overfitting, underfitting, and generalization using the obtained true and generalization errors. We introduce cross validation and two well-known examples which are $K$-fold and leave-one-out cross validations. We briefly introduce generalized cross validation and then move on to regularization where we use the SURE again. We work on both $\ell_2$ and $\ell_1$ norm regularizations. Then, we show that bootstrap aggregating (bagging) reduces the variance of estimation. Boosting, specifically AdaBoost, is introduced and it is explained as both an additive model and a maximum margin model, i.e., Support Vector Machine (SVM). The upper bound on the gener
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#19968;&#31687;&#38416;&#36848;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#25945;&#31243;&#12290;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#21487;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;Fisher&#21028;&#21035;&#20998;&#26512;&#31561;&#12290;</title><link>http://arxiv.org/abs/1903.11240</link><description>&lt;p&gt;
&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#65306;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Eigenvalue and Generalized Eigenvalue Problems: Tutorial. (arXiv:1903.11240v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.11240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#19968;&#31687;&#38416;&#36848;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#25945;&#31243;&#12290;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#21487;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;Fisher&#21028;&#21035;&#20998;&#26512;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#25945;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#29305;&#24449;&#20540;&#38382;&#39064;&#12289;&#29305;&#24449;&#20540;&#20998;&#35299;&#65288;&#35889;&#20998;&#35299;&#65289;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#21040;&#20102;&#23548;&#33268;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#26680;&#30417;&#30563;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;Fisher&#21028;&#21035;&#20998;&#26512;&#65292;&#36825;&#20123;&#26041;&#27861;&#37117;&#20250;&#23548;&#33268;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#35299;&#20915;&#29305;&#24449;&#20540;&#21644;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is a tutorial for eigenvalue and generalized eigenvalue problems. We first introduce eigenvalue problem, eigen-decomposition (spectral decomposition), and generalized eigenvalue problem. Then, we mention the optimization problems which yield to the eigenvalue and generalized eigenvalue problems. We also provide examples from machine learning, including principal component analysis, kernel supervised principal component analysis, and Fisher discriminant analysis, which result in eigenvalue and generalized eigenvalue problems. Finally, we introduce the solutions to both eigenvalue and generalized eigenvalue problems.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#33539;&#25968;&#27714;&#21644;&#27491;&#21017;&#21270;&#39033;&#30340;&#20984;&#24615;&#26368;&#20248;&#20256;&#36755;&#31243;&#24207;&#65292;&#22312;&#20960;&#20309;&#20551;&#35774;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#24674;&#22797;&#22522;&#30784;&#31867;&#32467;&#26500;&#12290;&#35813;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#21152;&#36895;&#30340;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21807;&#19968;&#24615;&#20248;&#21270;&#26041;&#24335;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#26032;&#30340;&#27491;&#21017;&#21270;&#31243;&#24207;&#19981;&#20165;&#21487;&#20197;&#26356;&#22909;&#22320;&#20445;&#30041;&#25968;&#25454;&#20013;&#30340;&#31867;&#32467;&#26500;&#65292;&#36824;&#21487;&#20197;&#22312;&#25968;&#25454;&#20960;&#20309;&#24418;&#29366;&#26041;&#38754;&#25552;&#20379;&#39069;&#22806;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/1903.03850</link><description>&lt;p&gt;
&#22522;&#20110;&#31867;&#32467;&#26500;&#30340;&#26368;&#20248;&#20256;&#36755;&#24674;&#22797;&#30028;&#38480;: &#19968;&#31181;&#33539;&#25968;&#27714;&#21644;&#27491;&#21017;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Recovery Bounds on Class-Based Optimal Transport: A Sum-of-Norms Regularization Framework. (arXiv:1903.03850v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.03850
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#33539;&#25968;&#27714;&#21644;&#27491;&#21017;&#21270;&#39033;&#30340;&#20984;&#24615;&#26368;&#20248;&#20256;&#36755;&#31243;&#24207;&#65292;&#22312;&#20960;&#20309;&#20551;&#35774;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#24674;&#22797;&#22522;&#30784;&#31867;&#32467;&#26500;&#12290;&#35813;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#21152;&#36895;&#30340;&#36817;&#31471;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21807;&#19968;&#24615;&#20248;&#21270;&#26041;&#24335;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#26032;&#30340;&#27491;&#21017;&#21270;&#31243;&#24207;&#19981;&#20165;&#21487;&#20197;&#26356;&#22909;&#22320;&#20445;&#30041;&#25968;&#25454;&#20013;&#30340;&#31867;&#32467;&#26500;&#65292;&#36824;&#21487;&#20197;&#22312;&#25968;&#25454;&#20960;&#20309;&#24418;&#29366;&#26041;&#38754;&#25552;&#20379;&#39069;&#22806;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#23637;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#29702;&#35299;&#23562;&#37325;&#31867;&#32467;&#26500;&#30340;&#26368;&#20248;&#20256;&#36755;&#26041;&#26696;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#24102;&#26377;&#33539;&#25968;&#27714;&#21644;&#27491;&#21017;&#21270;&#39033;&#30340;&#20984;&#24615;&#26368;&#20248;&#20256;&#36755;&#31243;&#24207;&#65292;&#35813;&#31243;&#24207;&#22312;&#20960;&#20309;&#20551;&#35774;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#24674;&#22797;&#22522;&#30784;&#31867;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#31181;&#21152;&#36895;&#30340;&#36817;&#31471;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#38381;&#24335;&#25237;&#24433;&#21644;&#36817;&#31471;&#25805;&#20316;&#31526;&#26041;&#26696;&#65292;&#20174;&#32780;&#20026;&#35745;&#31639;&#26368;&#20248;&#20256;&#36755;&#35745;&#21010;&#25552;&#20379;&#20102;&#26356;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#21807;&#19968;&#24615;&#20248;&#21270;&#26041;&#24335;&#65292;&#21363;&#20351;&#22312;&#32570;&#20047;&#24378;&#20984;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#24471;&#21040;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#20197;&#21069;&#30340;&#27491;&#21017;&#21270;&#31243;&#24207;&#30456;&#27604;&#65292;&#26032;&#30340;&#27491;&#21017;&#21270;&#31243;&#24207;&#19981;&#20165;&#21487;&#20197;&#26356;&#22909;&#22320;&#20445;&#30041;&#25968;&#25454;&#20013;&#30340;&#31867;&#32467;&#26500;&#65292;&#36824;&#21487;&#20197;&#22312;&#25968;&#25454;&#20960;&#20309;&#24418;&#29366;&#26041;&#38754;&#25552;&#20379;&#39069;&#22806;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel theoretical framework for understating OT schemes respecting a class structure. For this purpose, we propose a convex OT program with a sum-of-norms regularization term, which provably recovers the underlying class structure under geometric assumptions. Furthermore, we derive an accelerated proximal algorithm with a closed-form projection and proximal operator scheme, thereby affording a more scalable algorithm for computing optimal transport plans. We provide a novel argument for the uniqueness of the optimum even in the absence of strong convexity. Our experiments show that the new regularizer not only results in a better preservation of the class structure in the data but also yields additional robustness to the data geometry, compared to previous regularizers.
&lt;/p&gt;</description></item></channel></rss>