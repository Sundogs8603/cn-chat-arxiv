<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.13646</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#29992;&#20110;&#24102;&#21327;&#21464;&#20449;&#24687;&#30340;&#38543;&#26426;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Data-driven Piecewise Affine Decision Rules for Stochastic Programming with Covariate Information. (arXiv:2304.13646v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#25968;&#20540;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#21327;&#21464;&#20449;&#24687;&#30340;&#38543;&#26426;&#35268;&#21010;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#20837;&#38750;&#20984;&#20998;&#27573;&#20223;&#23556;&#20915;&#31574;&#35268;&#21017;(PADR)&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#26041;&#27861;&#65292;&#26088;&#22312;&#23398;&#20064;&#29305;&#24449;&#19982;&#26368;&#20248;&#20915;&#31574;&#20043;&#38388;&#30340;&#30452;&#25509;&#26144;&#23556;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;PADR&#30340;ERM&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#21487;&#29992;&#20110;&#26080;&#32422;&#26463;&#38382;&#39064;&#65292;&#20197;&#21450;&#32422;&#26463;&#38382;&#39064;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#38750;&#20984;&#21644;&#38750;&#21487;&#24494;&#30340;ERM&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22686;&#24378;&#30340;&#38543;&#26426;&#20027;&#23548;&#19979;&#38477;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#27839;&#65288;&#22797;&#21512;&#24378;&#65289;&#26041;&#21521;&#31283;&#23450;&#24615;&#30340;&#28176;&#36817;&#25910;&#25947;&#20197;&#21450;&#22797;&#26434;&#24615;&#20998;&#26512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;PADR-based ERM&#26041;&#27861;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#20984;&#22411;SP&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#19968;&#33268;&#24615;&#20445;&#35777;&#21644;&#35745;&#31639;&#21487;&#22788;&#29702;&#24615;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#65292;PADR-based ERM&#26041;&#27861;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Focusing on stochastic programming (SP) with covariate information, this paper proposes an empirical risk minimization (ERM) method embedded within a nonconvex piecewise affine decision rule (PADR), which aims to learn the direct mapping from features to optimal decisions. We establish the nonasymptotic consistency result of our PADR-based ERM model for unconstrained problems and asymptotic consistency result for constrained ones. To solve the nonconvex and nondifferentiable ERM problem, we develop an enhanced stochastic majorization-minimization algorithm and establish the asymptotic convergence to (composite strong) directional stationarity along with complexity analysis. We show that the proposed PADR-based ERM method applies to a broad class of nonconvex SP problems with theoretical consistency guarantees and computational tractability. Our numerical study demonstrates the superior performance of PADR-based ERM methods compared to state-of-the-art approaches under various settings,
&lt;/p&gt;</description></item><item><title>&#20026;&#20102;&#22788;&#29702;&#24102;&#26377;&#23457;&#26680;&#20219;&#21153;&#30340;&#29983;&#23384;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Diffsurv&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#21487;&#33021;&#32452;&#21512;&#30697;&#38453;&#65292;&#32771;&#34385;&#21040;&#24341;&#20837;&#30340;&#26631;&#31614;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#29616;&#21487;&#21306;&#20998;&#30340;&#25490;&#24207;&#12290;</title><link>http://arxiv.org/abs/2304.13594</link><description>&lt;p&gt;
Diffsurv: &#21487;&#21306;&#20998;&#30340;&#25490;&#24207;&#29992;&#20110;&#26377;&#23457;&#26597;&#26102;&#38388;&#30340;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Diffsurv: Differentiable sorting for censored time-to-event data. (arXiv:2304.13594v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13594
&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22788;&#29702;&#24102;&#26377;&#23457;&#26680;&#20219;&#21153;&#30340;&#29983;&#23384;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Diffsurv&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#39044;&#27979;&#21487;&#33021;&#32452;&#21512;&#30697;&#38453;&#65292;&#32771;&#34385;&#21040;&#24341;&#20837;&#30340;&#26631;&#31614;&#19981;&#30830;&#23450;&#24615;&#65292;&#23454;&#29616;&#21487;&#21306;&#20998;&#30340;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#21322;&#30417;&#30563;&#20219;&#21153;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24456;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#22312;&#21307;&#30103;&#39046;&#22495;&#12290;&#30446;&#21069;&#65292;&#29983;&#23384;&#20998;&#26512;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;Cox&#30340;&#37096;&#20998;&#20284;&#28982;&#65292;&#21487;&#35299;&#37322;&#20026;&#22312;&#19968;&#33268;&#24615;&#25351;&#25968;&#30340;&#19979;&#38480;&#19978;&#20248;&#21270;&#30340;&#25490;&#24207;&#27169;&#22411;&#12290;&#36825;&#31181;&#25490;&#24207;&#27169;&#22411;&#21644;Cox&#30340;&#37096;&#20998;&#20284;&#28982;&#20043;&#38388;&#30340;&#20851;&#31995;&#20165;&#32771;&#34385;&#20102;&#25104;&#23545;&#27604;&#36739;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#21457;&#23637;&#20102;&#21487;&#21306;&#20998;&#25490;&#24207;&#30340;&#26041;&#27861;&#65292;&#25918;&#26494;&#20102;&#36825;&#31181;&#25104;&#23545;&#29420;&#31435;&#20551;&#35774;&#65292;&#20351;&#24471;&#33021;&#22815;&#23545;&#26679;&#26412;&#38598;&#36827;&#34892;&#25490;&#24207;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#21487;&#21306;&#20998;&#25490;&#24207;&#26041;&#27861;&#19981;&#33021;&#32771;&#34385;&#21040;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#20851;&#38190;&#22240;&#32032;&#8212;&#8212;&#23457;&#26597;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;Diffsurv&#12290;&#25105;&#20204;&#36890;&#36807;&#39044;&#27979;&#21487;&#33021;&#25490;&#21015;&#30697;&#38453;&#26469;&#25193;&#23637;&#19981;&#21516;iable&#25490;&#24207;&#26041;&#27861;&#20197;&#22788;&#29702;&#23457;&#26597;&#20219;&#21153;&#65292;&#36825;&#20123;&#30697;&#38453;&#32771;&#34385;&#21040;&#23457;&#26597;&#26679;&#26412;&#24341;&#20837;&#30340;&#26631;&#31614;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#19982;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;...
&lt;/p&gt;
&lt;p&gt;
Survival analysis is a crucial semi-supervised task in machine learning with numerous real-world applications, particularly in healthcare. Currently, the most common approach to survival analysis is based on Cox's partial likelihood, which can be interpreted as a ranking model optimized on a lower bound of the concordance index. This relation between ranking models and Cox's partial likelihood considers only pairwise comparisons. Recent work has developed differentiable sorting methods which relax this pairwise independence assumption, enabling the ranking of sets of samples. However, current differentiable sorting methods cannot account for censoring, a key factor in many real-world datasets. To address this limitation, we propose a novel method called Diffsurv. We extend differentiable sorting methods to handle censored tasks by predicting matrices of possible permutations that take into account the label uncertainty introduced by censored samples. We contrast this approach with meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23376;&#39640;&#26031;&#22870;&#21169;&#24773;&#22659;&#19979;&#30340; Thompson &#25277;&#26679;&#31639;&#27861;&#22312;&#24773;&#22659; Bandit &#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#24341;&#20837;&#20102;&#25552;&#39640;&#20449;&#24687;&#27604;&#29575;&#30340;&#26032;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2304.13593</link><description>&lt;p&gt;
&#22522;&#20110;&#20114;&#20449;&#24687;&#27604;&#20363;&#30340; Thompson &#25277;&#26679;&#31639;&#27861;&#22312;&#23376;&#39640;&#26031;&#22870;&#21169;&#24773;&#22659;&#19979;&#30340;&#36951;&#25022;&#30028;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Thompson Sampling Regret Bounds for Contextual Bandits with sub-Gaussian rewards. (arXiv:2304.13593v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23376;&#39640;&#26031;&#22870;&#21169;&#24773;&#22659;&#19979;&#30340; Thompson &#25277;&#26679;&#31639;&#27861;&#22312;&#24773;&#22659; Bandit &#38382;&#39064;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#24341;&#20837;&#20102;&#25552;&#39640;&#20449;&#24687;&#27604;&#29575;&#30340;&#26032;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110; Neu et al. &#30340;&#26694;&#26550;&#21644;&#20854;&#25552;&#20986;&#30340;&#20114;&#20449;&#24687;&#27604;&#20363;&#27010;&#24565;&#30340;&#24773;&#22659; Bandit &#38382;&#39064;&#20013;&#30340; Thompson &#25277;&#26679;&#31639;&#27861;&#34920;&#29616;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102; Thompson &#25277;&#26679;&#26399;&#26395;&#32047;&#35745;&#36951;&#25022;&#30340;&#20840;&#38754;&#36793;&#30028;&#21462;&#20915;&#20110;&#29615;&#22659;&#21442;&#25968;&#21644;&#21382;&#21490;&#30340;&#20114;&#20449;&#24687;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#23376;&#39640;&#26031;&#22870;&#21169;&#25104;&#31435;&#30340;&#25552;&#39640;&#20449;&#24687;&#27604;&#29575;&#30340;&#26032;&#36793;&#30028;&#65292;&#20174;&#32780;&#25512;&#24191;&#20102; Neu &#31561;&#20154;&#30340;&#32467;&#26524;&#65292;&#20854;&#20998;&#26512;&#35201;&#27714;&#20108;&#36827;&#21046;&#22870;&#21169;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20026;&#38750;&#32467;&#26500;&#21270;&#26377;&#30028;&#24773;&#22659; Bandit&#12289;&#32467;&#26500;&#21270;&#26377;&#30028;&#24773;&#22659; Bandit&#65288;&#25289;&#26222;&#25289;&#26031;&#20284;&#28982;&#20989;&#25968;&#65289;&#12289;&#32467;&#26500;&#21270; Bernoulli Bandit &#21644;&#26377;&#30028;&#32447;&#24615;&#24773;&#22659; Bandit &#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study the performance of the Thompson Sampling algorithm for Contextual Bandit problems based on the framework introduced by Neu et al. and their concept of lifted information ratio. First, we prove a comprehensive bound on the Thompson Sampling expected cumulative regret that depends on the mutual information of the environment parameters and the history. Then, we introduce new bounds on the lifted information ratio that hold for sub-Gaussian rewards, thus generalizing the results from Neu et al. which analysis requires binary rewards. Finally, we provide explicit regret bounds for the special cases of unstructured bounded contextual bandits, structured bounded contextual bandits with Laplace likelihood, structured Bernoulli bandits, and bounded linear contextual bandits.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22266;&#23450;&#20808;&#39564;&#20998;&#24067;&#32570;&#20047;&#20449;&#24687;&#21644;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#26114;&#36149;&#19981;&#31283;&#23450;&#30340;&#23616;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.13586</link><description>&lt;p&gt;
&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22266;&#23450;&#20808;&#39564;&#20998;&#24067;&#32570;&#20047;&#20449;&#24687;&#21644;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#26114;&#36149;&#19981;&#31283;&#23450;&#30340;&#23616;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#20004;&#20010;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#19968;&#31181;&#32479;&#35745;&#26377;&#25928;&#19988;&#35745;&#31639;&#39640;&#25928;&#30340;&#24230;&#37327;&#12290;SW&#36317;&#31163;&#30340;&#19968;&#20010;&#20851;&#38190;&#37096;&#20998;&#26159;&#20999;&#29255;&#20998;&#24067;&#12290;&#30446;&#21069;&#26377;&#20004;&#31181;&#26041;&#27861;&#26469;&#36873;&#25321;&#36825;&#20010;&#20998;&#24067;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#31532;&#20108;&#31181;&#26159;&#20248;&#21270;&#24402;&#23646;&#20110;&#21442;&#25968;&#20998;&#24067;&#26063;&#30340;&#26368;&#20339;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#26368;&#22823;&#21270;&#26399;&#26395;&#30340;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#26377;&#23616;&#38480;&#24615;&#12290;&#22266;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#22312;&#31361;&#20986;&#33021;&#22815;&#21306;&#20998;&#20004;&#20010;&#24120;&#35268;&#27010;&#29575;&#27979;&#24230;&#30340;&#25237;&#24433;&#26041;&#21521;&#26041;&#38754;&#32570;&#20047;&#20449;&#24687;&#12290;&#32780;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#36890;&#24120;&#26159;&#26114;&#36149;&#21644;&#19981;&#31283;&#23450;&#30340;&#12290;&#27492;&#22806;&#65292;&#35774;&#35745;&#20505;&#36873;&#20998;&#24067;&#30340;&#21442;&#25968;&#20998;&#24067;&#26063;&#21487;&#33021;&#20250;&#24456;&#23481;&#26131;&#34987;&#38169;&#35823;&#25351;&#23450;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#20999;&#29255;&#20998;&#24067;&#35774;&#35745;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20174;&#32780;&#20351;&#20854;&#26356;&#21152;&#36890;&#29992;&#32780;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;&#25968;&#23398;&#21407;&#29702;&#30740;&#31350;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#30340;&#23454;&#29616;&#21644;&#25913;&#36827;&#26041;&#27861;&#65292;&#37325;&#35201;&#30340;&#27010;&#29575;&#31639;&#27861;&#26159;&#25552;&#39640;&#31639;&#27861;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#30340;&#20851;&#38190;&#65292;&#21516;&#26102;&#20171;&#32461;&#20004;&#31181;&#19981;&#21516;&#25968;&#23398;&#36317;&#31163;&#30340;&#20248;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.13579</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#23398;&#21407;&#29702;&#30340;&#25512;&#33616;&#31995;&#32479;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improvements on Recommender System based on Mathematical Principles. (arXiv:2304.13579v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#25968;&#23398;&#21407;&#29702;&#30740;&#31350;&#25512;&#33616;&#31995;&#32479;&#31639;&#27861;&#30340;&#23454;&#29616;&#21644;&#25913;&#36827;&#26041;&#27861;&#65292;&#37325;&#35201;&#30340;&#27010;&#29575;&#31639;&#27861;&#26159;&#25552;&#39640;&#31639;&#27861;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#30340;&#20851;&#38190;&#65292;&#21516;&#26102;&#20171;&#32461;&#20004;&#31181;&#19981;&#21516;&#25968;&#23398;&#36317;&#31163;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#30740;&#31350;&#25512;&#33616;&#31995;&#32479;&#30340;&#23454;&#29616;&#21407;&#29702;&#21644;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#22522;&#20110;&#25968;&#23398;&#21407;&#29702;&#35299;&#37322;&#25512;&#33616;&#31639;&#27861;&#65292;&#24182;&#23547;&#25214;&#21487;&#34892;&#30340;&#25913;&#36827;&#26041;&#27861;&#12290;&#27010;&#29575;&#31639;&#27861;&#22312;&#25512;&#33616;&#31995;&#32479;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#25105;&#20204;&#23558;&#25551;&#36848;&#23427;&#20204;&#22914;&#20309;&#24110;&#21161;&#25552;&#39640;&#31639;&#27861;&#30340;&#20934;&#30830;&#24615;&#21644;&#36895;&#24230;&#12290;&#26412;&#25991;&#36824;&#23558;&#35814;&#32454;&#38416;&#36848;&#20004;&#31181;&#19981;&#21516;&#25968;&#23398;&#36317;&#31163;&#25551;&#36848;&#30456;&#20284;&#24230;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, we will research the Recommender System's implementation about how it works and the algorithms used. We will explain the Recommender System's algorithms based on mathematical principles, and find feasible methods for improvements. The algorithms based on probability have its significance in Recommender System, we will describe how they help to increase the accuracy and speed of the algorithms. Both the weakness and the strength of two different mathematical distance used to describe the similarity will be detailed illustrated in this article.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13534</link><description>&lt;p&gt;
&#29992;&#22343;&#22330;&#21338;&#24328;&#20026;&#29983;&#25104;&#27169;&#22411;&#25645;&#24314;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22343;&#22330;&#21338;&#24328; (MFGs) &#20316;&#20026;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#12289;&#22686;&#24378;&#21644;&#35774;&#35745;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102; MFGs &#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#20851;&#32852;&#65292;&#24182;&#36890;&#36807;&#19981;&#21516;&#30340;&#31890;&#23376;&#21160;&#21147;&#23398;&#21644;&#20195;&#20215;&#20989;&#25968;&#25512;&#23548;&#20102;&#36825;&#19977;&#20010;&#31867;&#21035;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#8212;&#8212;&#19968;&#32452;&#32806;&#21512;&#30340;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#21644;&#29305;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#21512;&#25104;&#26679;&#26412;&#65292;&#21478;&#19968;&#20010;&#20195;&#29702;&#23545;&#26679;&#26412;&#36827;&#34892;&#35782;&#21035;&#65292;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#22810;&#26679;&#19988;&#36924;&#30495;&#65292;&#21516;&#26102;&#19982;&#22522;&#20934;&#27169;&#22411;&#30456;&#27604;&#65292;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;&#24635;&#20043;&#65292;&#26412;&#25991;&#31361;&#26174;&#20102; MFGs &#20316;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#29983;&#25104;&#27169;&#22411;&#30340;&#23454;&#39564;&#23460;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
&lt;/p&gt;</description></item><item><title>FLEX&#26159;&#19968;&#31181;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#33258;&#36866;&#24212;&#25506;&#32034;&#31639;&#27861;&#65292;&#20351;&#29992;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#38656;&#35201;&#26368;&#23569;&#30340;&#36164;&#28304;&#65292;&#24182;&#29992;&#20110;&#19979;&#28216;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#20013;&#12290;</title><link>http://arxiv.org/abs/2304.13426</link><description>&lt;p&gt;
FLEX&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#33258;&#36866;&#24212;&#25506;&#32034;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
FLEX: an Adaptive Exploration Algorithm for Nonlinear Systems. (arXiv:2304.13426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13426
&lt;/p&gt;
&lt;p&gt;
FLEX&#26159;&#19968;&#31181;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#33258;&#36866;&#24212;&#25506;&#32034;&#31639;&#27861;&#65292;&#20351;&#29992;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#38656;&#35201;&#26368;&#23569;&#30340;&#36164;&#28304;&#65292;&#24182;&#29992;&#20110;&#19979;&#28216;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#21152;&#24378;&#23398;&#20064;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#20294;&#25910;&#38598;&#36866;&#21512;&#31995;&#32479;&#30340;&#31934;&#30830;&#27169;&#22411;&#30340;&#25968;&#25454;&#21487;&#33021;&#24456;&#26114;&#36149;&#12290;&#22240;&#27492;&#20197;&#26679;&#26412;&#26377;&#25928;&#30340;&#26041;&#24335;&#25506;&#32034;&#26410;&#30693;&#29615;&#22659;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#21160;&#21147;&#23398;&#30340;&#22797;&#26434;&#24615;&#20197;&#21450;&#23454;&#38469;&#31995;&#32479;&#30340;&#35745;&#31639;&#38480;&#21046;&#20351;&#24471;&#36825;&#19968;&#20219;&#21153;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;FLEX&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#23454;&#39564;&#35774;&#35745;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#25506;&#32034;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#26368;&#22823;&#21270;&#19979;&#19968;&#27493;&#20449;&#24687;&#65292;&#20174;&#32780;&#24471;&#21040;&#33258;&#36866;&#24212;&#25506;&#32034;&#31639;&#27861;&#65292;&#19982;&#36890;&#29992;&#21442;&#25968;&#21270;&#23398;&#20064;&#27169;&#22411;&#20860;&#23481;&#65292;&#24182;&#19988;&#38656;&#35201;&#26368;&#23569;&#30340;&#36164;&#28304;&#12290;&#25105;&#20204;&#22312;&#28085;&#30422;&#19981;&#21516;&#35774;&#32622;&#30340;&#33509;&#24178;&#38750;&#32447;&#24615;&#29615;&#22659;&#20013;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#26102;&#21464;&#21160;&#21147;&#23398;&#12290;&#29282;&#35760;&#25506;&#32034;&#26159;&#20026;&#20102;&#26381;&#21153;&#20110;&#24320;&#21457;&#24615;&#30446;&#26631;&#65292;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#24212;&#29992;&#20110;&#19979;&#28216;&#22522;&#20110;&#27169;&#22411;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#65292;&#24182;&#23558;&#20854;&#19982;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#27169;&#22411;&#21644;&#27169;&#22411;&#33258;&#30001;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based reinforcement learning is a powerful tool, but collecting data to fit an accurate model of the system can be costly. Exploring an unknown environment in a sample-efficient manner is hence of great importance. However, the complexity of dynamics and the computational limitations of real systems make this task challenging. In this work, we introduce FLEX, an exploration algorithm for nonlinear dynamics based on optimal experimental design. Our policy maximizes the information of the next step and results in an adaptive exploration algorithm, compatible with generic parametric learning models and requiring minimal resources. We test our method on a number of nonlinear environments covering different settings, including time-varying dynamics. Keeping in mind that exploration is intended to serve an exploitation objective, we also test our algorithm on downstream model-based classical control tasks and compare it to other state-of-the-art model-based and model-free approaches. T
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#21644;Monte Carlo&#37319;&#26679;&#30340;&#30452;&#25509;&#26041;&#27861;&#26469;&#20272;&#31639;&#33258;&#26059;&#31995;&#32479;&#30340;&#21452;&#37096;&#20998;&#20114;&#20449;&#24687;&#65292;&#21487;&#20197;&#30740;&#31350;&#20219;&#24847;&#23376;&#31995;&#32479;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#24182;&#19988;&#22312;Ising&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.13412</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#26059;&#31995;&#32479;&#20114;&#20449;&#24687;&#30340;&#20272;&#31639;
&lt;/p&gt;
&lt;p&gt;
Mutual information of spin systems from autoregressive neural networks. (arXiv:2304.13412v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#21644;Monte Carlo&#37319;&#26679;&#30340;&#30452;&#25509;&#26041;&#27861;&#26469;&#20272;&#31639;&#33258;&#26059;&#31995;&#32479;&#30340;&#21452;&#37096;&#20998;&#20114;&#20449;&#24687;&#65292;&#21487;&#20197;&#30740;&#31350;&#20219;&#24847;&#23376;&#31995;&#32479;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#24182;&#19988;&#22312;Ising&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#22522;&#20110;Monte Carlo&#37319;&#26679;&#21644;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#30452;&#25509;&#26041;&#27861;&#26469;&#20272;&#31639;&#32463;&#20856;&#33258;&#26059;&#31995;&#32479;&#30340;&#21452;&#37096;&#20998;&#20114;&#20449;&#24687;&#12290;&#23427;&#20801;&#35768;&#30740;&#31350;&#20219;&#24847;&#23376;&#31995;&#32479;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#24182;&#19988;&#21487;&#25512;&#24191;&#21040;&#32463;&#20856;&#22330;&#29702;&#35770;&#12290;&#25105;&#20204;&#29992;Ising&#27169;&#22411;&#30340;&#22235;&#20010;&#20998;&#21306;&#28436;&#31034;&#20102;&#23427;&#30340;&#25928;&#26524;&#65292;&#21253;&#25324;&#22810;&#37325;&#36830;&#25509;&#30340;&#20598;&#22855;&#20998;&#21106;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#36828;&#31163;&#20020;&#30028;&#28201;&#24230;&#26102;&#65292;&#38754;&#31215;&#35268;&#24459;&#24471;&#21040;&#20102;&#28385;&#36275;&#65306;&#24120;&#25968;&#39033;&#26159;&#36890;&#29992;&#30340;&#65292;&#32780;&#27604;&#20363;&#31995;&#25968;&#23545;&#20110;&#20598;&#22855;&#20998;&#21106;&#26159;&#19981;&#21516;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe a direct approach to estimate bipartite mutual information of a classical spin system based on Monte Carlo sampling enhanced by autoregressive neural networks. It allows studying arbitrary geometries of subsystems and can be generalized to classical field theories. We demonstrate it on the Ising model for four partitionings, including a multiply-connected even-odd division. We show that the area law is satisfied for temperatures away from the critical temperature: the constant term is universal, whereas the proportionality coefficient is different for the even-odd partitioning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20984;&#32858;&#31867;&#30340;&#22810;&#20219;&#21153;&#22238;&#24402;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#32676;&#32452;&#34701;&#21512;&#27491;&#21017;&#21270;&#26041;&#27861;&#23545;&#20219;&#21153;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20351;&#29992;&#32858;&#31867;&#20013;&#24515;&#28857;&#21442;&#25968;&#20195;&#34920;&#20219;&#21153;&#32858;&#31867;&#20013;&#24515;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#19981;&#21516;&#32858;&#31867;&#20043;&#38388;&#20449;&#24687;&#30340;&#24178;&#25200;&#12290;</title><link>http://arxiv.org/abs/2304.13342</link><description>&lt;p&gt;
&#22522;&#20110;&#20984;&#32858;&#31867;&#30340;&#22810;&#20219;&#21153;&#22238;&#24402;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning Regression via Convex Clustering. (arXiv:2304.13342v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20984;&#32858;&#31867;&#30340;&#22810;&#20219;&#21153;&#22238;&#24402;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#32676;&#32452;&#34701;&#21512;&#27491;&#21017;&#21270;&#26041;&#27861;&#23545;&#20219;&#21153;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#20351;&#29992;&#32858;&#31867;&#20013;&#24515;&#28857;&#21442;&#25968;&#20195;&#34920;&#20219;&#21153;&#32858;&#31867;&#20013;&#24515;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#19981;&#21516;&#32858;&#31867;&#20043;&#38388;&#20449;&#24687;&#30340;&#24178;&#25200;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;(MTL)&#26159;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#20849;&#20139;&#30456;&#20851;&#20219;&#21153;&#30340;&#20844;&#20849;&#20449;&#24687;&#26469;&#25552;&#39640;&#20272;&#35745;&#21644;&#39044;&#27979;&#30340;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;&#22312;MTL&#20013;&#65292;&#26377;&#20960;&#20010;&#20851;&#20110;&#20851;&#31995;&#21644;&#26041;&#27861;&#30340;&#20551;&#35774;&#29992;&#20110;&#32467;&#21512;&#20219;&#21153;&#12290;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#20854;&#20013;&#19968;&#20010;&#33258;&#28982;&#20551;&#35774;&#26159;&#23558;&#20219;&#21153;&#20998;&#31867;&#20026;&#20855;&#26377;&#29305;&#24449;&#30340;&#19968;&#20123;&#32858;&#31867;&#12290;&#38024;&#23545;&#36825;&#31181;&#20551;&#35774;&#65292;&#32676;&#32452;&#34701;&#21512;&#27491;&#21017;&#21270;&#26041;&#27861;&#36890;&#36807;&#32553;&#23567;&#20219;&#21153;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#25191;&#34892;&#20219;&#21153;&#32858;&#31867;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36716;&#31227;&#21516;&#19968;&#32858;&#31867;&#20013;&#30340;&#20844;&#20849;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#20063;&#20250;&#22312;&#19981;&#21516;&#32858;&#31867;&#20043;&#38388;&#36716;&#31227;&#20449;&#24687;&#65292;&#20174;&#32780;&#21152;&#21095;&#20272;&#35745;&#21644;&#39044;&#27979;&#30340;&#38169;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;MTL&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#20195;&#34920;&#20219;&#21153;&#32858;&#31867;&#20013;&#24515;&#30340;&#20013;&#24515;&#28857;&#21442;&#25968;&#12290;&#30001;&#20110;&#35813;&#27169;&#22411;&#23558;&#21442;&#25968;&#20998;&#20026;&#22238;&#24402;&#21442;&#25968;&#21644;&#32858;&#31867;&#21442;&#25968;&#65292;&#22240;&#27492;&#25105;&#20204;&#21487;&#20197;&#25913;&#21892;&#20272;&#35745;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning (MTL) is a methodology that aims to improve the general performance of estimation and prediction by sharing common information among related tasks. In the MTL, there are several assumptions for the relationships and methods to incorporate them. One of the natural assumptions in the practical situation is that tasks are classified into some clusters with their characteristics. For this assumption, the group fused regularization approach performs clustering of the tasks by shrinking the difference among tasks. This enables us to transfer common information within the same cluster. However, this approach also transfers the information between different clusters, which worsens the estimation and prediction. To overcome this problem, we propose an MTL method with a centroid parameter representing a cluster center of the task. Because this model separates parameters into the parameters for regression and the parameters for clustering, we can improve estimation and predict
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#22312;HAR&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#25552;&#39640;&#20102;&#27169;&#22411;&#23398;&#20064;&#26032;&#31867;&#21035;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#27169;&#22411;&#22312;&#20808;&#21069;&#23398;&#20064;&#30340;&#31867;&#21035;&#19978;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13327</link><description>&lt;p&gt;
&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#30340;&#35780;&#20272;&#65306;&#24212;&#29992;&#20110;HAR
&lt;/p&gt;
&lt;p&gt;
Evaluation of Regularization-based Continual Learning Approaches: Application to HAR. (arXiv:2304.13327v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#22312;HAR&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#25552;&#39640;&#20102;&#27169;&#22411;&#23398;&#20064;&#26032;&#31867;&#21035;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#27169;&#22411;&#22312;&#20808;&#21069;&#23398;&#20064;&#30340;&#31867;&#21035;&#19978;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26222;&#36866;&#35745;&#31639;&#22312;&#35768;&#22810;&#37325;&#35201;&#30340;&#39046;&#22495;&#20013;&#25552;&#20379;&#26381;&#21153;&#65292;&#21253;&#25324;&#20581;&#24247;&#21644;&#31119;&#21033;&#36825;&#20010;&#30456;&#20851;&#19988;&#21160;&#24577;&#30340;&#39046;&#22495;&#12290;&#22312;&#36825;&#20010;&#39046;&#22495;&#20013;&#65292;&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;&#65288;HAR&#65289;&#22312;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#30446;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#20381;&#36182;&#20110;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#28436;&#36827;&#20173;&#28982;&#24456;&#22256;&#38590;&#65292;&#38500;&#38750;&#36827;&#34892;&#23436;&#25972;&#30340;&#37325;&#26032;&#35757;&#32451;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36830;&#32493;&#23398;&#20064;&#30340;&#27010;&#24565;&#22312;&#20170;&#22825;&#38750;&#24120;&#26377;&#21069;&#36884;&#65292;&#23588;&#20854;&#26159;&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#25216;&#26415;&#12290;&#36825;&#20123;&#25216;&#26415;&#38750;&#24120;&#26377;&#36259;&#65292;&#22240;&#20026;&#23427;&#20204;&#24456;&#31616;&#21333;&#24182;&#19988;&#25104;&#26412;&#20302;&#12290;&#24050;&#32463;&#36827;&#34892;&#20102;&#21021;&#27493;&#30340;&#30740;&#31350;&#65292;&#24182;&#23637;&#31034;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#20173;&#28982;&#38750;&#24120;&#19987;&#19994;&#21270;&#24182;&#19988;&#38590;&#20197;&#27604;&#36739;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19977;&#31181;&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#22312;HAR&#39046;&#22495;&#30340;&#20840;&#38754;&#27604;&#36739;&#65292;&#24182;&#31361;&#20986;&#23427;&#20204;&#30340;&#20248;&#28857;&#21644;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#22522;&#20110;&#20844;&#24320;&#21487;&#29992;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#20123;&#26041;&#27861;&#25552;&#39640;&#20102;&#27169;&#22411;&#23398;&#20064;&#26032;&#31867;&#21035;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#27169;&#22411;&#22312;&#20808;&#21069;&#23398;&#20064;&#30340;&#31867;&#21035;&#19978;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pervasive computing allows the provision of services in many important areas, including the relevant and dynamic field of health and well-being. In this domain, Human Activity Recognition (HAR) has gained a lot of attention in recent years. Current solutions rely on Machine Learning (ML) models and achieve impressive results. However, the evolution of these models remains difficult, as long as a complete retraining is not performed. To overcome this problem, the concept of Continual Learning is very promising today and, more particularly, the techniques based on regularization. These techniques are particularly interesting for their simplicity and their low cost. Initial studies have been conducted and have shown promising outcomes. However, they remain very specific and difficult to compare. In this paper, we provide a comprehensive comparison of three regularization-based methods that we adapted to the HAR domain, highlighting their strengths and limitations. Our experiments were con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#26368;&#23567;&#21270;&#31243;&#24207;&#35745;&#31639;&#31354;&#38388;&#35889;&#24179;&#28369;&#30340;Andrews&#22270;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35299;&#38598;&#26159;&#19968;&#20010;&#27969;&#24418;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#24555;&#36895;&#21487;&#35270;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.13239</link><description>&lt;p&gt;
&#29992;&#26368;&#20248;&#31354;&#38388;&#35889;&#24179;&#28369;&#26041;&#27861;&#25968;&#20540;&#36924;&#36817;Andrews&#22270;
&lt;/p&gt;
&lt;p&gt;
Numerical Approximation of Andrews Plots with Optimal Spatial-Spectral Smoothing. (arXiv:2304.13239v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#26368;&#23567;&#21270;&#31243;&#24207;&#35745;&#31639;&#31354;&#38388;&#35889;&#24179;&#28369;&#30340;Andrews&#22270;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35299;&#38598;&#26159;&#19968;&#20010;&#27969;&#24418;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#24555;&#36895;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Andrews&#22270;&#25552;&#20379;&#20102;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#32654;&#35266;&#21487;&#35270;&#21270;&#12290;&#26412;&#24037;&#20316;&#35777;&#26126;&#20102;Andrews&#22270;&#65288;&#22312;&#20351;&#29992;&#25968;&#25454;&#38598;&#30340;&#20027;&#25104;&#20998;&#20998;&#20540;&#23450;&#20041;&#26102;&#65289;&#24179;&#22343;&#19978;&#26159;&#26368;&#20248;&#8220;&#24179;&#28369;&#8221;&#30340;&#65292;&#24182;&#19988;&#22312;&#20174;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#31354;&#38388;&#21040;$L^2([0,1])$&#30340;&#32447;&#24615;&#31561;&#36317;&#26144;&#23556;&#38598;&#21512;&#19978;&#35299;&#20915;&#20102;&#19968;&#20010;&#26080;&#38480;&#32500;&#24230;&#20108;&#27425;&#26368;&#23567;&#21270;&#31243;&#24207;&#12290;&#36890;&#36807;&#24314;&#31435;&#25216;&#26415;&#24615;&#26426;&#22120;&#23545;&#32447;&#24615;&#31561;&#36317;&#26144;&#23556;&#19978;&#30340;&#19968;&#33324;&#26080;&#38480;&#32500;&#20108;&#27425;&#26368;&#23567;&#21270;&#31243;&#24207;&#30340;&#35299;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#35299;&#38598;&#65288;&#22312;&#36890;&#24120;&#24773;&#20917;&#19979;&#65289;&#26159;&#19968;&#20010;&#27969;&#24418;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#20010;&#35299;&#38598;&#21512;&#20013;&#20986;&#29616;&#30340;&#27169;&#26865;&#20004;&#21487;&#65292;&#25105;&#20204;&#22312;&#26080;&#38480;&#32500;&#20248;&#21270;&#31243;&#24207;&#20013;&#28155;&#21152;&#8220;&#35889;&#24179;&#28369;&#8221;&#39033;&#65292;&#20197;&#24341;&#23548;&#20855;&#26377;&#26368;&#20248;&#31354;&#38388;&#35889;&#24179;&#28369;&#25928;&#26524;&#30340;Andrews&#22270;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#35813;&#31243;&#24207;&#30340;&#65288;&#36890;&#24120;&#65289;&#35299;&#38598;&#65292;&#35777;&#26126;&#20102;&#32467;&#26524;&#22270;&#33021;&#22815;&#36827;&#34892;&#39640;&#25928;&#30340;&#25968;&#20540;&#36924;&#36817;&#12290;&#36825;&#20123;&#31354;&#38388;&#35889;&#24179;&#28369;&#30340;Andrews&#22270;&#21487;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#26377;&#25928;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Andrews plots provide aesthetically pleasant visualizations of high-dimensional datasets. This work proves that Andrews plots (when defined in terms of the principal component scores of a dataset) are optimally ``smooth'' on average, and solve an infinite-dimensional quadratic minimization program over the set of linear isometries from the Euclidean data space to $L^2([0,1])$. By building technical machinery that characterizes the solutions to general infinite-dimensional quadratic minimization programs over linear isometries, we further show that the solution set is (in the generic case) a manifold. To avoid the ambiguities presented by this manifold of solutions, we add ``spectral smoothing'' terms to the infinite-dimensional optimization program to induce Andrews plots with optimal spatial-spectral smoothing. We characterize the (generic) set of solutions to this program and prove that the resulting plots admit efficient numerical approximations. These spatial-spectral smooth Andrew
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#37325;&#31283;&#20581;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#39564;&#27835;&#30103;&#30340;&#20998;&#24067;&#25928;&#24212;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#38169;&#35823;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13237</link><description>&lt;p&gt;
&#19968;&#31181;&#26377;&#25928;&#30340;&#21452;&#37325;&#31283;&#20581;&#26680;&#22788;&#29702;&#25928;&#24212;&#26816;&#39564;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient Doubly-Robust Test for the Kernel Treatment Effect. (arXiv:2304.13237v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#26680;&#30340;&#21452;&#37325;&#31283;&#20581;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#26816;&#39564;&#27835;&#30103;&#30340;&#20998;&#24067;&#25928;&#24212;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#38169;&#35823;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20998;&#27835;&#30103;&#19979;&#30340;&#39044;&#26399;&#21453;&#20107;&#23454;&#24046;&#24322;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#30446;&#26631;&#25928;&#24212;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#27835;&#30103;&#21487;&#33021;&#20855;&#26377;&#36229;&#20986;&#24179;&#22343;&#20540;&#30340;&#25928;&#24212;&#65292;&#20363;&#22914;&#38477;&#20302;&#25110;&#25552;&#39640;&#26041;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26680;&#30340;&#27835;&#30103;&#25928;&#24212;&#20998;&#24067;&#26816;&#39564;&#26041;&#27861;&#12290;&#26412;&#25991;&#30340;&#26041;&#27861;&#26159;&#22522;&#20110;&#26680;&#30340;&#12289;&#31283;&#20581;&#30340;&#65292;&#20445;&#35777;&#20102;&#19968;&#31867;&#38169;&#35823;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#39640;&#25928;&#30340;&#65292;&#36991;&#20813;&#20102;&#32622;&#25442;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The average treatment effect, which is the difference in expectation of the counterfactuals, is probably the most popular target effect in causal inference with binary treatments. However, treatments may have effects beyond the mean, for instance decreasing or increasing the variance. We propose a new kernel-based test for distributional effects of the treatment. It is, to the best of our knowledge, the first kernel-based, doubly-robust test with provably valid type-I error. Furthermore, our proposed algorithm is efficient, avoiding the use of permutations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26680;&#26041;&#27861;&#31639;&#23376;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#23545;&#22810;&#32452;&#25968;&#25454;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#21518;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#37117;&#26159;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#31639;&#23376;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.13202</link><description>&lt;p&gt;
&#26680;&#26041;&#27861;&#22312;&#31639;&#23376;&#23398;&#20064;&#20013;&#34920;&#29616;&#31454;&#20105;&#21147;
&lt;/p&gt;
&lt;p&gt;
Kernel Methods are Competitive for Operator Learning. (arXiv:2304.13202v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13202
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26680;&#26041;&#27861;&#31639;&#23376;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#23545;&#22810;&#32452;&#25968;&#25454;&#36827;&#34892;&#20840;&#38754;&#27604;&#36739;&#21518;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#37117;&#26159;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#31639;&#23376;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#26680;&#30340;&#31639;&#23376;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#25552;&#20379;&#20102;&#20808;&#39564;&#35823;&#24046;&#20998;&#26512;&#21644;&#19982;&#27969;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65288;&#22914;Deep Operator Net&#65288;DeepONet&#65289;[Lu et al.]&#21644;Fourier&#31070;&#32463;&#31639;&#23376;&#65288;FNO&#65289;[Li et al.]&#65289;&#30340;&#20840;&#38754;&#25968;&#23383;&#27604;&#36739;&#12290;&#25105;&#20204;&#32771;&#34385;&#30446;&#26631;&#31639;&#23376;$\mathcal{G}^\dagger:\mathcal{U}\to\mathcal{V}$&#30340;&#36755;&#20837;/&#36755;&#20986;&#31354;&#38388;&#26159;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#30340;&#24773;&#20917;&#65292;&#25968;&#25454;&#20197;&#36755;&#20837;/&#36755;&#20986;&#20989;&#25968;&#30340;&#37096;&#20998;&#35266;&#27979;$\varphi(v_i),\phi(u_i)$&#30340;&#24418;&#24335;&#20986;&#29616;&#65292;&#20854;&#20013;$v_i=\mathcal{G}^\dagger(u_i)$&#65288;$i=1,\ldots,N$&#65289;&#65292;&#27979;&#37327;&#31639;&#23376;$\varphi:\mathcal{V}\to\mathbb{R}^m$&#21644;$\phi:\mathcal{U}\to\mathbb{R}^n$&#26159;&#32447;&#24615;&#30340;&#12290;&#22312;&#20889;$\psi:\mathbb{R}^n\to\mathcal{U}$&#21644;$\chi:\mathbb{R}^m\to\mathcal{V}$&#20316;&#20026;&#19982;$\phi$&#21644;$\varphi$&#30456;&#20851;&#30340;&#26368;&#20339;&#24674;&#22797;&#26144;&#23556;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;$\bar{f}$ &#26680;&#26144;&#23556; $L^2(\mathcal{U},\mathbb{R}^n)$ &#23450;&#20041;&#19968;&#20010;$k$ &#31867;&#22411;&#30340;&#26368;&#23567;&#20108;&#20056;&#27169;&#22411;&#65292; &#28982;&#21518;&#29992; $\bar{\mathcal{G}}=\chi\circ\bar{f}\circ\psi$ &#26469;&#36817;&#20284;$\mathcal{G}^\dagger$&#12290; &#25105;&#20204;&#30340;&#20998;&#26512;&#28041;&#21450;&#22810;&#20010;&#20363;&#23376;&#65292;&#21253;&#25324;&#24120;&#35265;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#31639;&#23376;&#36817;&#20284;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#26680;&#26041;&#27861;&#37117;&#26159;&#19968;&#31181;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#31639;&#23376;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a general kernel-based framework for learning operators between Banach spaces along with a priori error analysis and comprehensive numerical comparisons with popular neural net (NN) approaches such as Deep Operator Net (DeepONet) [Lu et al.] and Fourier Neural Operator (FNO) [Li et al.]. We consider the setting where the input/output spaces of target operator $\mathcal{G}^\dagger\,:\, \mathcal{U}\to \mathcal{V}$ are reproducing kernel Hilbert spaces (RKHS), the data comes in the form of partial observations $\phi(u_i), \varphi(v_i)$ of input/output functions $v_i=\mathcal{G}^\dagger(u_i)$ ($i=1,\ldots,N$), and the measurement operators $\phi\,:\, \mathcal{U}\to \mathbb{R}^n$ and $\varphi\,:\, \mathcal{V} \to \mathbb{R}^m$ are linear. Writing $\psi\,:\, \mathbb{R}^n \to \mathcal{U}$ and $\chi\,:\, \mathbb{R}^m \to \mathcal{V}$ for the optimal recovery maps associated with $\phi$ and $\varphi$, we approximate $\mathcal{G}^\dagger$ with $\bar{\mathcal{G}}=\chi \circ \bar{f} \ci
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#24314;&#31435;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#19979;&#30340;&#31934;&#30830;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#20381;&#36182;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#38598;&#20013;&#21644;&#27491;&#21017;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2304.13139</link><description>&lt;p&gt;
&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#31934;&#30830;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Exact recovery for the non-uniform Hypergraph Stochastic Block Model. (arXiv:2304.13139v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#24314;&#31435;&#20102;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#19979;&#30340;&#31934;&#30830;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#20381;&#36182;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#38598;&#20013;&#21644;&#27491;&#21017;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#22312;&#38750;&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#19979;&#30340;&#38543;&#26426;&#36229;&#22270;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#38382;&#39064;&#65292;&#20854;&#20013;&#27599;&#20010;&#36229;&#36793;&#29420;&#31435;&#22320;&#20197;&#26576;&#20123;&#32473;&#23450;&#27010;&#29575;&#20986;&#29616;&#65292;&#35813;&#27010;&#29575;&#20165;&#21462;&#20915;&#20110;&#20854;&#39030;&#28857;&#30340;&#26631;&#31614;&#12290;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#39318;&#27425;&#24314;&#31435;&#20102;&#22312;&#36825;&#31181;&#38750;&#22343;&#21248;&#24773;&#20917;&#19979;&#23454;&#29616;&#31934;&#30830;&#24674;&#22797;&#30340;&#23574;&#38160;&#38408;&#20540;&#65292;&#21463;&#21040;&#27425;&#35201;&#32422;&#26463;&#65307;&#23588;&#20854;&#26159;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;K&#31867;&#21035;&#30340;&#27169;&#22411;&#21644;&#23545;&#31216;&#20108;&#36827;&#21046;&#27169;&#22411;&#65288;K=2&#65289;&#12290;&#20851;&#38190;&#28857;&#26159;&#36890;&#36807;&#32858;&#21512;&#25152;&#26377;&#22343;&#21248;&#23618;&#30340;&#20449;&#24687;&#65292;&#21363;&#20351;&#22312;&#32771;&#34385;&#27599;&#20010;&#23618;&#26102;&#20284;&#20046;&#19981;&#21487;&#33021;&#23454;&#29616;&#31934;&#30830;&#24674;&#22797;&#65292;&#25105;&#20204;&#20063;&#21487;&#20197;&#33719;&#24471;&#31934;&#30830;&#24674;&#22797;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#25104;&#21151;&#22320;&#22312;&#38408;&#20540;&#20197;&#19978;&#23454;&#29616;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;&#25105;&#20204;&#31639;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;&#20381;&#36182;&#20110;&#38750;&#22343;&#21248;&#38543;&#26426;&#36229;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#38598;&#20013;&#21644;&#27491;&#21017;&#21270;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Consider the community detection problem in random hypergraphs under the non-uniform hypergraph stochastic block model (HSBM), where each hyperedge appears independently with some given probability depending only on the labels of its vertices. We establish, for the first time in the literature, a sharp threshold for exact recovery under this non-uniform case, subject to minor constraints; in particular, we consider the model with $K$ classes as well as the symmetric binary model ($K=2$). One crucial point here is that by aggregating information from all the uniform layers, we may obtain exact recovery even in cases when this may appear impossible if each layer were considered alone. Two efficient algorithms that successfully achieve exact recovery above the threshold are provided. The theoretical analysis of our algorithms relies on the concentration and regularization of the adjacency matrix for non-uniform random hypergraphs, which could be of independent interest. We also address so
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#23545;&#27969;&#20256;&#28909;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#33258;&#30001;&#27969;&#30456;&#20132;&#30340;&#20845;&#20010;&#38388;&#38553;&#21943;&#27668;&#23380;&#36827;&#34892;&#25511;&#21046;&#65292;&#20248;&#21270;&#20102;&#25104;&#26412;&#20989;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#23545;&#23545;&#27969;&#20256;&#28909;&#36895;&#29575;&#30340;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2304.12618</link><description>&lt;p&gt;
&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#23545;&#27969;&#20256;&#28909;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Genetically-inspired convective heat transfer enhancement. (arXiv:2304.12618v1 [physics.flu-dyn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12618
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#23545;&#27969;&#20256;&#28909;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#33258;&#30001;&#27969;&#30456;&#20132;&#30340;&#20845;&#20010;&#38388;&#38553;&#21943;&#27668;&#23380;&#36827;&#34892;&#25511;&#21046;&#65292;&#20248;&#21270;&#20102;&#25104;&#26412;&#20989;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#23545;&#23545;&#27969;&#20256;&#28909;&#36895;&#29575;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#24179;&#26495;&#19978;&#30340;&#32010;&#27969;&#36793;&#30028;&#23618;(TBL)&#19978;&#65292;&#37319;&#29992;&#22522;&#20110;&#32447;&#24615;&#36951;&#20256;&#31639;&#27861;&#25511;&#21046;(LGAC)&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#23454;&#29616;&#23545;&#27969;&#20256;&#28909;&#30340;&#22686;&#24378;&#12290;&#35813;&#25511;&#21046;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#32452;&#19982;&#33258;&#30001;&#27969;&#30456;&#20132;&#30340;&#20845;&#20010;&#38388;&#38553;&#21943;&#27668;&#23380;&#12290;&#36890;&#36807;&#23545;&#36733;&#27874;&#39057;&#29575;&#65292;&#21344;&#31354;&#27604;&#21644;&#25191;&#34892;&#22120;&#20043;&#38388;&#30340;&#30456;&#20301;&#24046;&#30340;&#25511;&#21046;&#21442;&#25968;&#23450;&#20041;&#24320;&#29615;&#26368;&#20248;&#21608;&#26399;&#24615;&#28608;&#21169;&#12290;&#26681;&#25454;&#26080;&#25200;&#21160;TBL&#21644;&#31283;&#24577;&#21943;&#27969;&#30340;&#25511;&#21046;&#65292;&#23545;&#25511;&#21046;&#23450;&#24459;&#36827;&#34892;&#20102;&#20248;&#21270;&#12290;&#25104;&#26412;&#20989;&#25968;&#21253;&#25324;&#22721;&#38754;&#23545;&#27969;&#20256;&#28909;&#36895;&#29575;&#21644;&#25191;&#34892;&#25104;&#26412;&#12290;&#37319;&#29992;&#32418;&#22806;&#28909;&#25104;&#20687;&#21644;&#31890;&#23376;&#22270;&#20687;&#27979;&#36895;&#25216;&#26415;&#35780;&#20272;&#20102;&#25511;&#21046;&#22120;&#30340;&#24615;&#33021;&#12290;&#26368;&#20248;&#25511;&#21046;&#22120;&#20135;&#29983;&#20102;&#30053;&#24494;&#19981;&#23545;&#31216;&#30340;&#27969;&#22330;&#12290;LGAC&#31639;&#27861;&#25910;&#25947;&#20110;&#25152;&#26377;&#25191;&#34892;&#22120;&#30340;&#30456;&#21516;&#39057;&#29575;&#21644;&#21344;&#31354;&#27604;&#12290;&#22914;&#27492;&#39057;&#29575;&#38750;&#24120;&#25509;&#36817;&#20110;&#29305;&#24449;&#39057;&#29575;&#30340;&#20498;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convective heat transfer in a turbulent boundary layer (TBL) on a flat plate is enhanced using an artificial intelligence approach based on linear genetic algorithms control (LGAC). The actuator is a set of six slot jets in crossflow aligned with the freestream. An open-loop optimal periodic forcing is defined by the carrier frequency, the duty cycle and the phase difference between actuators as control parameters. The control laws are optimised with respect to the unperturbed TBL and to the actuation with a steady jet. The cost function includes the wall convective heat transfer rate and the cost of the actuation. The performance of the controller is assessed by infrared thermography and characterised also with particle image velocimetry measurements. The optimal controller yields a slightly asymmetric flow field. The LGAC algorithm converges to the same frequency and duty cycle for all the actuators. It is noted that such frequency is strikingly equal to the inverse of the charac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.12407</link><description>&lt;p&gt;
Langevin&#22411;Monte Carlo&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic analysis of Langevin-type Monte Carlo algorithms. (arXiv:2303.12407v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Langevin&#22411;&#31639;&#27861;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21183;&#20989;&#25968;&#26159;&#32791;&#25955;&#30340;&#65292;&#19988;&#20854;&#24369;&#26799;&#24230;&#20855;&#26377;&#26377;&#38480;&#30340;&#36830;&#32493;&#24615;&#27169;&#37327;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#30340;&#38750;&#28176;&#36827;&#24615;&#65292;&#23427;&#34913;&#37327;&#20102;&#21513;&#24067;&#26031;&#20998;&#24067;&#19982;&#22522;&#20110;Liptser-Shiryaev&#29702;&#35770;&#21644;&#20989;&#25968;&#19981;&#31561;&#24335;&#30340;Langevin&#22411;&#31639;&#27861;&#30340;&#19968;&#33324;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#20010;&#19978;&#38480;&#26469;&#23637;&#31034;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#26159;&#20805;&#20998;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25511;&#21046;&#21442;&#25968;&#26469;&#33719;&#24471;Langevin Monte Carlo&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#25552;&#20986;&#20102;&#29699;&#24418;&#24179;&#28369;&#25216;&#26415;&#30340;Langevin&#22411;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Langevin-type algorithms for Gibbs distributions such that the potentials are dissipative and their weak gradients have the finite moduli of continuity. Our main result is a non-asymptotic upper bound of the 2-Wasserstein distance between the Gibbs distribution and the law of general Langevin-type algorithms based on the Liptser--Shiryaev theory and functional inequalities. We apply this bound to show that the dissipativity of the potential and the $\alpha$-H\"{o}lder continuity of the gradient with $\alpha&gt;1/3$ are sufficient for the convergence of the Langevin Monte Carlo algorithm with appropriate control of the parameters. We also propose Langevin-type algorithms with spherical smoothing for potentials without convexity or continuous differentiability.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22240;&#26524;&#20851;&#31995;&#26469;&#23454;&#29616;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;&#30693;&#35782;&#36801;&#31227;&#65292;&#20027;&#35201;&#24212;&#29992;&#20110;&#38754;&#21521;&#22810;&#26679;&#24615;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.08635</link><description>&lt;p&gt;
&#38754;&#21521;&#22810;&#26679;&#24615;&#39044;&#27979;&#30340;&#29983;&#25104;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Causal Representation Learning for Out-of-Distribution Motion Forecasting. (arXiv:2302.08635v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08635
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#25104;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#22240;&#26524;&#20851;&#31995;&#26469;&#23454;&#29616;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;&#30693;&#35782;&#36801;&#31227;&#65292;&#20027;&#35201;&#24212;&#29992;&#20110;&#38754;&#21521;&#22810;&#26679;&#24615;&#39044;&#27979;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#26377;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#20551;&#23450;&#26679;&#26412;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20294;&#23545;&#20110;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#24456;&#25935;&#24863;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21033;&#29992;&#22240;&#26524;&#20851;&#31995;&#23454;&#29616;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;&#30693;&#35782;&#36801;&#31227;&#30340;&#29983;&#25104;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#22312;&#20154;&#20307;&#36712;&#36857;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#19988;&#35813;&#26041;&#27861;&#20063;&#21487;&#20197;&#24212;&#29992;&#20110;&#20854;&#20182;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional supervised learning methods typically assume i.i.d samples and are found to be sensitive to out-of-distribution (OOD) data. We propose Generative Causal Representation Learning (GCRL) which leverages causality to facilitate knowledge transfer under distribution shifts. While we evaluate the effectiveness of our proposed method in human trajectory prediction models, GCRL can be applied to other domains as well. First, we propose a novel causal model that explains the generative factors in motion forecasting datasets using features that are common across all environments and with features that are specific to each environment. Selection variables are used to determine which parts of the model can be directly transferred to a new environment without fine-tuning. Second, we propose an end-to-end variational learning paradigm to learn the causal mechanisms that generate observations from features. GCRL is supported by strong theoretical results that imply identifiability of the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SOVR&#30340;&#23545;&#25239;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#20197;&#32858;&#28966;&#37325;&#35201;&#26679;&#26412;&#65292;&#22686;&#21152;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#23545;&#25968;&#20960;&#29575;&#38388;&#38548;&#65292;&#20174;&#32780;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#23545;&#25239;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.10283</link><description>&lt;p&gt;
&#19968;&#23545;&#20854;&#20313;&#25439;&#22833;&#20989;&#25968;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#32858;&#28966;&#37325;&#35201;&#26679;&#26412;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
One-vs-the-Rest Loss to Focus on Important Samples in Adversarial Training. (arXiv:2207.10283v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.10283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SOVR&#30340;&#23545;&#25239;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#65292;&#21487;&#20197;&#32858;&#28966;&#37325;&#35201;&#26679;&#26412;&#65292;&#22686;&#21152;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;&#23545;&#25968;&#20960;&#29575;&#38388;&#38548;&#65292;&#20174;&#32780;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#23545;&#25239;&#25915;&#20987;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#25439;&#22833;&#20989;&#25968;&#12290;&#30001;&#20110;&#23545;&#25239;&#35757;&#32451;&#23384;&#22312;&#22256;&#38590;&#65292;&#22914;&#38656;&#35201;&#39640;&#27169;&#22411;&#23481;&#37327;&#65292;&#36890;&#36807;&#21152;&#26435;&#20132;&#21449;&#29109;&#25439;&#22833;&#20851;&#27880;&#37325;&#35201;&#25968;&#25454;&#28857;&#24050;&#24341;&#36215;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#23481;&#26131;&#21463;&#21040;&#22797;&#26434;&#25915;&#20987;&#30340;&#24433;&#21709;&#65292;&#22914;Auto-Attack&#12290;&#26412;&#25991;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#20204;&#30340;&#26131;&#21463;&#25915;&#20987;&#30340;&#21407;&#22240;&#26159;&#30495;&#23454;&#26631;&#31614;&#21644;&#20854;&#20182;&#26631;&#31614;&#20043;&#38388;&#30340;&#23545;&#25968;&#20960;&#29575;&#20043;&#38388;&#30340;&#36739;&#23567;&#38388;&#38548;&#12290;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#26159;&#26681;&#25454;&#23545;&#25968;&#20960;&#29575;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#20998;&#31867;&#30340;&#65292;&#25152;&#20197;&#23545;&#25968;&#20960;&#29575;&#30340;&#38388;&#38548;&#24212;&#35813;&#36275;&#22815;&#22823;&#65292;&#20197;&#36991;&#20813;&#25915;&#20987;&#32763;&#36716;&#26368;&#22823;&#30340;&#23545;&#25968;&#20960;&#29575;&#12290;&#37325;&#35201;&#24615;&#24863;&#30693;&#26041;&#27861;&#19981;&#20250;&#22686;&#21152;&#37325;&#35201;&#26679;&#26412;&#30340;&#23545;&#25968;&#20960;&#29575;&#38388;&#38548;&#65292;&#20294;&#19982;&#20132;&#21449;&#29109;&#25439;&#22833;&#30456;&#27604;&#20250;&#20943;&#23569;&#36739;&#19981;&#37325;&#35201;&#26679;&#26412;&#30340;&#23545;&#25968;&#20960;&#29575;&#38388;&#38548;&#12290;&#20026;&#20102;&#22686;&#21152;&#37325;&#35201;&#26679;&#26412;&#30340;&#23545;&#25968;&#20960;&#29575;&#38388;&#38548;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20999;&#25442;&#19968;&#23545;&#20854;&#20313;&#65288;SOVR&#65289;&#25439;&#22833;&#20989;&#25968;&#65292;&#35813;&#25439;&#22833;&#20989;&#25968;&#22312;&#20855;&#26377;&#36739;&#23567;&#23545;&#25968;&#20960;&#29575;&#38388;&#38548;&#30340;&#37325;&#35201;&#26679;&#26412;&#20013;&#20174;&#20132;&#21449;&#29109;&#20999;&#25442;&#21040;&#19968;&#23545;&#20854;&#20313;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20379;&#29702;&#35770;&#20998;&#26512;&#12289;&#28040;&#34701;&#30740;&#31350;&#21644;&#23454;&#39564;&#65292;&#35777;&#26126;SOVR&#23545;&#25239;&#25239;&#20987;&#21644;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new loss function for adversarial training. Since adversarial training has difficulties, e.g., necessity of high model capacity, focusing on important data points by weighting cross-entropy loss has attracted much attention. However, they are vulnerable to sophisticated attacks, e.g., Auto-Attack. This paper experimentally reveals that the cause of their vulnerability is their small margins between logits for the true label and the other labels. Since neural networks classify the data points based on the logits, logit margins should be large enough to avoid flipping the largest logit by the attacks. Importance-aware methods do not increase logit margins of important samples but decrease those of less-important samples compared with cross-entropy loss. To increase logit margins of important samples, we propose switching one-vs-the-rest loss (SOVR), which switches from cross-entropy to one-vs-the-rest loss for important samples that have small logit margins. We prov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#35843;&#21644;&#26041;&#27861;&#65292;&#20135;&#29983;&#21327;&#35843;&#30340;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#65292;&#30456;&#27604;&#20110;&#27010;&#29575;&#39640;&#26031;&#35843;&#21644;&#65292;&#33021;&#22815;&#24102;&#26469;&#26174;&#33879;&#30340;&#39044;&#27979;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2207.09322</link><description>&lt;p&gt;
&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#35843;&#21644;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Reconciliation of Count Time Series. (arXiv:2207.09322v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#35843;&#21644;&#26041;&#27861;&#65292;&#20135;&#29983;&#21327;&#35843;&#30340;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#65292;&#30456;&#27604;&#20110;&#27010;&#29575;&#39640;&#26031;&#35843;&#21644;&#65292;&#33021;&#22815;&#24102;&#26469;&#26174;&#33879;&#30340;&#39044;&#27979;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#35843;&#21644;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#20294;&#30446;&#21069;&#26082;&#27809;&#26377;&#24418;&#24335;&#21270;&#30340;&#26694;&#26550;&#65292;&#20063;&#27809;&#26377;&#38024;&#23545;&#27010;&#29575;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#35843;&#21644;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#23454;&#20540;&#21644;&#35745;&#25968;&#21464;&#37327;&#30340;&#36830;&#36143;&#24615;&#21644;&#21327;&#35843;&#30340;&#27010;&#29575;&#39044;&#27979;&#23450;&#20041;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#21327;&#35843;&#26041;&#27861;&#12290;&#23427;&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#35268;&#21017;&#30340;&#27010;&#25324;&#65292;&#24182;&#19988;&#21487;&#20197;&#21327;&#35843;&#23454;&#25968;&#21644;&#35745;&#25968;&#21464;&#37327;&#12290;&#24403;&#29992;&#20110;&#35745;&#25968;&#21464;&#37327;&#26102;&#65292;&#23427;&#20250;&#20135;&#29983;&#21327;&#35843;&#30340;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#35745;&#25968;&#21464;&#37327;&#30340;&#26102;&#38388;&#21327;&#35843;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#27010;&#29575;&#39640;&#26031;&#35843;&#21644;&#30456;&#27604;&#65292;&#23427;&#23545;&#39044;&#27979;&#30340;&#25913;&#36827;&#38750;&#24120;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecast reconciliation is an important research topic. Yet, there is currently neither formal framework nor practical method for the probabilistic reconciliation of count time series. In this paper we propose a definition of coherency and reconciled probabilistic forecast which applies to both real-valued and count variables and a novel method for probabilistic reconciliation. It is based on a generalization of Bayes' rule and it can reconcile both real-value and count variables. When applied to count variables, it yields a reconciled probability mass function. Our experiments with the temporal reconciliation of count variables show a major forecast improvement compared to the probabilistic Gaussian reconciliation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.11740</link><description>&lt;p&gt;
&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#23545;&#20851;&#38190;&#26399;&#30340;&#31070;&#32463;&#21487;&#22609;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#23454;&#29616;&#31361;&#35302;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#12290;&#65288;arXiv: 2203.11740v12 [cs.NE] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#31361;&#35302;&#20849;&#20139;&#36830;&#25509;&#26435;&#37325;&#20043;&#22806;&#65292;PNN&#36824;&#21253;&#25324;&#31361;&#35302;&#26377;&#25928;&#33539;&#22260;&#30340;&#26435;&#37325;[14-25]&#12290;PNN&#32771;&#34385;&#31361;&#35302;&#24378;&#24230;&#24179;&#34913;&#22312;&#31361;&#35302;&#21534;&#22124;&#30340;&#21160;&#24577;&#21644;&#38271;&#24230;&#24120;&#25968;&#20043;&#21644;&#30340;&#38745;&#24577;&#20013;[14]&#65292;&#24182;&#21253;&#21547;&#20102;&#40060;&#32676;&#34892;&#20026;&#30340;&#20808;&#23548;&#34892;&#20026;&#12290;&#31361;&#35302;&#24418;&#25104;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#20250;&#25233;&#21046;&#26641;&#31361;&#29983;&#25104;[15]&#12290;&#31867;&#20284;&#20110;Spring Boot&#20013;&#30340;&#24378;&#21046;&#38887;&#24615;&#65292;&#21453;&#21521;&#22238;&#36335;&#30340;&#35760;&#24518;&#25345;&#20037;&#24230;&#26799;&#24230;&#20063;&#23384;&#22312;&#12290;&#30456;&#23545;&#36739;&#22909;&#21644;&#36739;&#24046;&#30340;&#26799;&#24230;&#20449;&#24687;&#23384;&#20648;&#22312;&#31867;&#20284;&#20110;&#33041;&#35126;&#30340;&#35760;&#24518;&#30165;&#36857;&#32454;&#32990;&#20013;&#65292;&#22312;&#21453;&#21521;&#22238;&#36335;&#30340;&#31361;&#35302;&#24418;&#25104;&#20013;&#12290;&#20105;&#35758;&#35748;&#20026;&#20154;&#31867;&#28023;&#39532;&#31070;&#32463;&#20803;&#30340;&#20877;&#29983;&#33021;&#21147;&#26159;&#21542;&#25345;&#32493;&#21040;&#32769;&#24180;&#65292;&#24182;&#21487;&#33021;&#22312;&#21518;&#26399;&#36845;&#20195;&#20013;&#24418;&#25104;&#26032;&#30340;&#26356;&#38271;&#30340;&#22238;&#36335;[17,18]&#12290;&#20851;&#38381;&#20851;&#38190;&#26399;&#20250;&#23548;&#33268;&#31070;&#32463;&#32010;&#20081;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;[19]&#12290;&#32771;&#34385;&#21040;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#28608;&#27963;&#31361;&#35302;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#27604;&#36739;&#20102;&#21333;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#65288;TSC&#65289;&#19982;&#22810;&#20803;TSC(MTSC)&#38382;&#39064;&#30340;&#31639;&#27861;&#12290;&#20316;&#32773;&#27979;&#35797;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#12289;&#24418;&#29366;&#21644;&#21333;&#35789;&#34955;&#26041;&#27861;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#32500;&#24230;&#26080;&#20851;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2007.13156</link><description>&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Multivariate Time Series Classification Algorithms. (arXiv:2007.13156v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.13156
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#27604;&#36739;&#20102;&#21333;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#65288;TSC&#65289;&#19982;&#22810;&#20803;TSC(MTSC)&#38382;&#39064;&#30340;&#31639;&#27861;&#12290;&#20316;&#32773;&#27979;&#35797;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#12289;&#24418;&#29366;&#21644;&#21333;&#35789;&#34955;&#26041;&#27861;&#30340;&#31639;&#27861;&#65292;&#24182;&#23558;&#20854;&#19982;&#32500;&#24230;&#26080;&#20851;&#30340;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#65288;TSC&#65289;&#28041;&#21450;&#20174;&#26377;&#24207;&#30340;&#23454;&#20540;&#23646;&#24615;&#20013;&#26500;&#24314;&#29992;&#20110;&#31163;&#25955;&#30446;&#26631;&#21464;&#37327;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#26368;&#36817;&#20960;&#24180;&#65292;&#19968;&#32452;&#26032;&#30340;TSC&#31639;&#27861;&#24050;&#32463;&#24320;&#21457;&#20986;&#26469;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#20043;&#21069;&#30340;&#25216;&#26415;&#27700;&#24179;&#19978;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;&#20027;&#35201;&#20851;&#27880;&#30340;&#26159;&#21333;&#21464;&#37327;TSC&#65292;&#21363;&#27599;&#20010;&#26696;&#20363;&#37117;&#26377;&#19968;&#20010;&#21333;&#19968;&#24207;&#21015;&#21644;&#19968;&#20010;&#31867;&#26631;&#31614;&#30340;&#38382;&#39064;&#12290;&#20294;&#23454;&#38469;&#19978;&#65292;&#26356;&#24120;&#35265;&#30340;&#26159;&#36935;&#21040;&#22810;&#20803;TSC(MTSC)&#38382;&#39064;&#65292;&#20854;&#20013;&#22810;&#20010;&#24207;&#21015;&#19982;&#21333;&#19968;&#26631;&#31614;&#20851;&#32852;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;MTSC&#30340;&#32771;&#34385;&#36828;&#19981;&#22914;&#21333;&#21464;&#37327;&#24773;&#20917;&#37027;&#20040;&#22810;&#12290;2018&#24180;&#25512;&#20986;&#20102;30&#20010;MTSC&#38382;&#39064;&#30340;UEA&#23384;&#26723;&#24211;&#65292;&#20351;&#31639;&#27861;&#20043;&#38388;&#30340;&#27604;&#36739;&#26356;&#23481;&#26131;&#12290;&#25105;&#20204;&#22238;&#39038;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#12289;&#24418;&#29366;&#21644;&#21333;&#35789;&#34955;&#26041;&#27861;&#25552;&#20986;&#30340;&#23450;&#21046;MTSC&#31639;&#27861;&#12290; MTSC&#30340;&#26368;&#31616;&#21333;&#26041;&#27861;&#26159;&#36890;&#36807;&#22810;&#20803;&#32500;&#24230;&#19978;&#30340;&#38598;&#25104;&#21333;&#21464;&#37327;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#23450;&#21046;&#31639;&#27861;&#19982;&#36825;&#20123;&#32500;&#24230;&#26080;&#20851;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time Series Classification (TSC) involved building predictive models for a discrete target variable from ordered, real valued, attributes. Over recent years, a new set of TSC algorithms have been developed which have made significant improvement over the previous state of the art. The main focus has been on univariate TSC, i.e. the problem where each case has a single series and a class label. In reality, it is more common to encounter multivariate TSC (MTSC) problems where multiple series are associated with a single label. Despite this, much less consideration has been given to MTSC than the univariate case. The UEA archive of 30 MTSC problems released in 2018 has made comparison of algorithms easier. We review recently proposed bespoke MTSC algorithms based on deep learning, shapelets and bag of words approaches. The simplest approach to MTSC is to ensemble univariate classifiers over the multivariate dimensions. We compare the bespoke algorithms to these dimension independent appro
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#30340;&#24322;&#26500;&#20803;&#38598;&#25104;&#31639;&#27861; HIVE-COTE &#30340;&#26368;&#26032;&#31283;&#23450;&#29256;&#26412; 1.0&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#25351;&#21335;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#21644;&#36164;&#28304;&#20351;&#29992;&#24773;&#20917;&#65292;&#24182;&#19982;&#19977;&#31181;&#36817;&#26399;&#25552;&#20986;&#30340;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2004.06069</link><description>&lt;p&gt;
&#20004;&#20010;&#24037;&#20855;&#31665;&#30340;&#25925;&#20107;&#8212;&#8212;&#31532;&#19977;&#27425;&#25253;&#21578;&#65306;&#20851;&#20110;HIVE-COTE v1.0&#30340;&#20351;&#29992;&#21644;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
A tale of two toolkits, report the third: on the usage and performance of HIVE-COTE v1.0. (arXiv:2004.06069v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.06069
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#30340;&#24322;&#26500;&#20803;&#38598;&#25104;&#31639;&#27861; HIVE-COTE &#30340;&#26368;&#26032;&#31283;&#23450;&#29256;&#26412; 1.0&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#25351;&#21335;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35780;&#20272;&#20102;&#20854;&#24615;&#33021;&#21644;&#36164;&#28304;&#20351;&#29992;&#24773;&#20917;&#65292;&#24182;&#19982;&#19977;&#31181;&#36817;&#26399;&#25552;&#20986;&#30340;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#27425;&#21270;&#36716;&#25442;&#38598;&#21512;&#27861;&#65288;HIVE-COTE&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#30340;&#24322;&#26500;&#20803;&#38598;&#25104;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#26368;&#21021;&#20110;2016&#24180;&#25552;&#20986;&#65292;&#32463;&#21382;&#20102;&#19968;&#20123;&#23567;&#30340;&#25913;&#21464;&#65292;&#24182;&#22312;&#20004;&#20010;&#24320;&#28304;&#20195;&#30721;&#24211;&#20013;&#25512;&#20986;&#20102;&#21487;&#37197;&#32622;&#12289;&#21487;&#25193;&#23637;&#21644;&#26131;&#20110;&#20351;&#29992;&#30340;&#29256;&#26412;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#26368;&#26032;&#31283;&#23450;&#30340; HIVE-COTE &#29256;&#26412; 1.0 &#30340;&#27010;&#36848;&#65292;&#24182;&#38416;&#36848;&#20102;&#23427;&#19982;&#26368;&#21021;&#29256;&#26412;&#30340;&#21306;&#21035;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#35813;&#20998;&#31867;&#22120;&#30340;&#25351;&#21335;&#65292;&#24182;&#23545;&#20854;&#39044;&#27979;&#24615;&#33021;&#21644;&#36164;&#28304;&#20351;&#29992;&#24773;&#20917;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#35780;&#20272;&#12290;&#25105;&#20204;&#20351;&#29992; aeon &#24037;&#20855;&#21253;&#27604;&#36739;&#20102; HIVE-COTE &#19982;&#19977;&#31181;&#36817;&#26399;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Hierarchical Vote Collective of Transformation-based Ensembles (HIVE-COTE) is a heterogeneous meta ensemble for time series classification. Since it was first proposed in 2016, the algorithm has undergone some minor changes and there is now a configurable, scalable and easy to use version available in two open source repositories. We present an overview of the latest stable HIVE-COTE, version 1.0, and describe how it differs to the original. We provide a walkthrough guide of how to use the classifier, and conduct extensive experimental evaluation of its predictive performance and resource usage. We compare the performance of HIVE-COTE to three recently proposed algorithms using the aeon toolkit.
&lt;/p&gt;</description></item></channel></rss>