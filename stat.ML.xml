<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#36755;&#20986;&#23618;&#27979;&#35797;&#35823;&#24046;&#30340;&#20005;&#26684;&#28176;&#36817;&#29305;&#24615;&#65292;&#24182;&#23545;&#20351;&#29992;&#39640;&#26031;&#24425;&#34425;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;</title><link>https://arxiv.org/abs/2402.13999</link><description>&lt;p&gt;
&#28145;&#24230;&#32467;&#26500;&#21270;&#65288;&#38543;&#26426;&#65289;&#29305;&#24449;&#23398;&#20064;&#30340;&#28176;&#36817;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of Learning with Deep Structured (Random) Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13999
&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#36755;&#20986;&#23618;&#27979;&#35797;&#35823;&#24046;&#30340;&#20005;&#26684;&#28176;&#36817;&#29305;&#24615;&#65292;&#24182;&#23545;&#20351;&#29992;&#39640;&#26031;&#24425;&#34425;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#19968;&#22823;&#31867;&#29305;&#24449;&#26144;&#23556;&#65292;&#25105;&#20204;&#22312;&#36755;&#20837;&#32500;&#24230;&#12289;&#38544;&#34255;&#23618;&#23485;&#24230;&#21644;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#25104;&#27604;&#20363;&#22686;&#38271;&#30340;&#39640;&#32500;&#26497;&#38480;&#19979;&#65292;&#25552;&#20379;&#20102;&#19982;&#23398;&#20064;&#36755;&#20986;&#23618;&#30456;&#20851;&#30340;&#27979;&#35797;&#35823;&#24046;&#30340;&#20005;&#26684;&#28176;&#36817;&#29305;&#24615;&#21051;&#30011;&#12290;&#36825;&#19968;&#29305;&#24449;&#20197;&#29305;&#24449;&#30340;&#24635;&#20307;&#21327;&#26041;&#24046;&#20026;&#22522;&#30784;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#37096;&#20998;&#21463;&#21040;&#20351;&#29992;&#39640;&#26031;&#24425;&#34425;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#21363;&#20855;&#26377;&#38543;&#26426;&#20294;&#32467;&#26500;&#21270;&#26435;&#37325;&#30340;&#28145;&#23618;&#38750;&#32447;&#24615;&#20840;&#36830;&#25509;&#32593;&#32476;&#65292;&#20854;&#25353;&#34892;&#30340;&#21327;&#26041;&#24046;&#36827;&#19968;&#27493;&#20801;&#35768;&#20381;&#36182;&#20110;&#20043;&#21069;&#23618;&#30340;&#26435;&#37325;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#20197;&#26435;&#37325;&#30697;&#38453;&#20026;&#22522;&#30784;&#30340;&#29305;&#24449;&#21327;&#26041;&#24046;&#30340;&#38381;&#21512;&#24418;&#24335;&#20844;&#24335;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#33021;&#22815;&#25429;&#25417;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#20855;&#26377;&#26377;&#38480;&#23485;&#24230;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13999v1 Announce Type: cross  Abstract: For a large class of feature maps we provide a tight asymptotic characterisation of the test error associated with learning the readout layer, in the high-dimensional limit where the input dimension, hidden layer widths, and number of training samples are proportionally large. This characterization is formulated in terms of the population covariance of the features. Our work is partially motivated by the problem of learning with Gaussian rainbow neural networks, namely deep non-linear fully-connected networks with random but structured weights, whose row-wise covariances are further allowed to depend on the weights of previous layers. For such networks we also derive a closed-form formula for the feature covariance in terms of the weight matrices. We further find that in some cases our results can capture feature maps learned by deep, finite-width neural networks trained under gradient descent.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65288;PNNs&#65289;&#26469;&#24314;&#27169;Aleatoric&#19981;&#30830;&#23450;&#24615;&#65292;&#36890;&#36807;&#24320;&#21457;&#27010;&#29575;&#36317;&#31163;&#24230;&#37327;&#26469;&#20248;&#21270;PNN&#26550;&#26500;&#65292;&#35777;&#23454;&#20102;PNNs&#22312;&#27169;&#25311;Aleatoric&#19981;&#30830;&#23450;&#24615;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.13945</link><description>&lt;p&gt;
&#29992;&#20110;&#24314;&#27169;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#20013;Aleatoric&#19981;&#30830;&#23450;&#24615;&#30340;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65288;PNNs&#65289;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65288;PNNs&#65289;&#26469;&#24314;&#27169;Aleatoric&#19981;&#30830;&#23450;&#24615;&#65292;&#36890;&#36807;&#24320;&#21457;&#27010;&#29575;&#36317;&#31163;&#24230;&#37327;&#26469;&#20248;&#21270;PNN&#26550;&#26500;&#65292;&#35777;&#23454;&#20102;PNNs&#22312;&#27169;&#25311;Aleatoric&#19981;&#30830;&#23450;&#24615;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65288;PNNs&#65289;&#26469;&#24314;&#27169;Aleatoric&#19981;&#30830;&#23450;&#24615;&#65292;&#35813;&#19981;&#30830;&#23450;&#24615;&#26159;&#25351;&#31995;&#32479;&#36755;&#20837;&#36755;&#20986;&#20851;&#31995;&#20013;&#22266;&#26377;&#30340;&#21464;&#24322;&#24615;&#65292;&#36890;&#24120;&#34920;&#29616;&#20026;&#19981;&#22343;&#31561;&#30340;&#26041;&#24046;&#25110;&#24322;&#26041;&#24046;&#24615;&#12290;&#19981;&#21516;&#20110;&#20135;&#29983;&#30830;&#23450;&#24615;&#36755;&#20986;&#30340;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#65292;PNNs&#20026;&#30446;&#26631;&#21464;&#37327;&#29983;&#25104;&#27010;&#29575;&#20998;&#24067;&#65292;&#20801;&#35768;&#22312;&#22238;&#24402;&#22330;&#26223;&#20013;&#30830;&#23450;&#39044;&#27979;&#22343;&#20540;&#21644;&#21306;&#38388;&#12290;&#26412;&#25991;&#30340;&#36129;&#29486;&#21253;&#25324;&#24320;&#21457;&#27010;&#29575;&#36317;&#31163;&#24230;&#37327;&#26469;&#20248;&#21270;PNN&#26550;&#26500;&#65292;&#20197;&#21450;&#22312;&#21463;&#25511;&#25968;&#25454;&#38598;&#21644;&#28041;&#21450;&#32420;&#32500;&#22686;&#24378;&#22797;&#21512;&#26448;&#26009;&#30340;&#23454;&#38469;&#26448;&#26009;&#31185;&#23398;&#26696;&#20363;&#20013;&#37096;&#32626;PNNs&#12290;&#30740;&#31350;&#32467;&#26524;&#35777;&#23454;&#65292;PNNs&#26377;&#25928;&#22320;&#27169;&#25311;&#20102;Aleatoric&#19981;&#30830;&#23450;&#24615;&#65292;&#35777;&#26126;&#22312;&#36825;&#19968;&#30446;&#30340;&#19978;&#65292;&#23427;&#27604;&#36890;&#24120;&#37319;&#29992;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26356;&#20026;&#21512;&#36866;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22312;&#19968;&#20010;&#30495;&#23454;&#30340;&#31185;&#23398;&#29615;&#22659;&#20013;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13945v1 Announce Type: cross  Abstract: This paper investigates the use of probabilistic neural networks (PNNs) to model aleatoric uncertainty, which refers to the inherent variability in the input-output relationships of a system, often characterized by unequal variance or heteroscedasticity. Unlike traditional neural networks that produce deterministic outputs, PNNs generate probability distributions for the target variable, allowing the determination of both predicted means and intervals in regression scenarios. Contributions of this paper include the development of a probabilistic distance metric to optimize PNN architecture, and the deployment of PNNs in controlled data sets as well as a practical material science case involving fiber-reinforced composites. The findings confirm that PNNs effectively model aleatoric uncertainty, proving to be more appropriate than the commonly employed Gaussian process regression for this purpose. Specifically, in a real-world scientific
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#29702;&#35299;&#39640;&#25928;Transformer&#65288;&#20363;&#22914;&#31232;&#30095;Transformer&#21644;&#32447;&#24615;Transformer&#65289;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#65292;&#21457;&#29616;&#23427;&#20204;&#36866;&#21512;&#35299;&#20915;&#19968;&#33324;DP&#20219;&#21153;&#65292;&#20294;&#19981;&#21516;&#20110;&#26631;&#20934;Transformer&#12290;</title><link>https://arxiv.org/abs/2402.13934</link><description>&lt;p&gt;
&#30830;&#23454;&#39640;&#25928;&#30340;Transformer&#33021;&#22815;&#33410;&#32422;&#35745;&#31639;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do Efficient Transformers Really Save Computation?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#29702;&#35299;&#39640;&#25928;Transformer&#65288;&#20363;&#22914;&#31232;&#30095;Transformer&#21644;&#32447;&#24615;Transformer&#65289;&#30340;&#33021;&#21147;&#21644;&#38480;&#21046;&#65292;&#21457;&#29616;&#23427;&#20204;&#36866;&#21512;&#35299;&#20915;&#19968;&#33324;DP&#20219;&#21153;&#65292;&#20294;&#19981;&#21516;&#20110;&#26631;&#20934;Transformer&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22522;&#20110;Transformer&#30340;&#35821;&#35328;&#27169;&#22411;&#22312;&#36234;&#26469;&#36234;&#22823;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#65292;&#24182;&#25317;&#26377;&#22823;&#37327;&#21442;&#25968;&#65292;&#25214;&#21040;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26631;&#20934;Transformer&#21464;&#24471;&#38750;&#24120;&#26377;&#20215;&#20540;&#12290;&#34429;&#28982;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#39640;&#25928;&#30340;Transformer&#21644;Transformer&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20294;&#27809;&#26377;&#19968;&#20010;&#33021;&#22815;&#25552;&#20379;&#23427;&#20204;&#36866;&#21512;&#26367;&#20195;&#26631;&#20934;Transformer&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36825;&#20351;&#24471;&#24456;&#38590;&#30830;&#23450;&#20309;&#26102;&#20351;&#29992;&#29305;&#23450;&#27169;&#22411;&#20197;&#21450;&#36827;&#19968;&#27493;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#29702;&#35299;&#39640;&#25928;Transformer&#30340;&#33021;&#21147;&#21644;&#23616;&#38480;&#24615;&#65292;&#29305;&#21035;&#26159;&#31232;&#30095;Transformer&#21644;&#32447;&#24615;Transformer&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#23427;&#20204;&#22312;Chain-of-Thought (CoT)&#25552;&#31034;&#20013;&#23637;&#31034;&#30340;&#25512;&#29702;&#33021;&#21147;&#65292;&#24182;&#36981;&#24490;&#20808;&#21069;&#30340;&#30740;&#31350;&#23558;&#23427;&#20204;&#24314;&#27169;&#20026;&#21160;&#24577;&#35268;&#21010;&#65288;DP&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#36275;&#22815;&#34920;&#36798;&#35299;&#20915;&#19968;&#33324;DP&#20219;&#21153;&#30340;&#33021;&#21147;&#65292;&#20294;&#19982;&#26631;&#20934;Transformer&#19981;&#21516;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13934v1 Announce Type: cross  Abstract: As transformer-based language models are trained on increasingly large datasets and with vast numbers of parameters, finding more efficient alternatives to the standard Transformer has become very valuable. While many efficient Transformers and Transformer alternatives have been proposed, none provide theoretical guarantees that they are a suitable replacement for the standard Transformer. This makes it challenging to identify when to use a specific model and what directions to prioritize for further investigation. In this paper, we aim to understand the capabilities and limitations of efficient Transformers, specifically the Sparse Transformer and the Linear Transformer. We focus on their reasoning capability as exhibited by Chain-of-Thought (CoT) prompts and follow previous works to model them as Dynamic Programming (DP) problems. Our results show that while these models are expressive enough to solve general DP tasks, contrary to ex
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31283;&#23450;&#20102;&#38543;&#26426;&#38797;&#28857;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#26799;&#24230;&#19981;&#26029;&#22686;&#38271;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#20445;&#35777;</title><link>https://arxiv.org/abs/2402.13903</link><description>&lt;p&gt;
&#22788;&#29702;&#38543;&#26426;&#38797;&#28857;&#20248;&#21270;&#20013;&#30340;&#26080;&#30028;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Dealing with unbounded gradients in stochastic saddle-point optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13903
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31283;&#23450;&#20102;&#38543;&#26426;&#38797;&#28857;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#26799;&#24230;&#19981;&#26029;&#22686;&#38271;&#30340;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#23547;&#25214;&#20984;&#20985;&#20989;&#25968;&#38797;&#28857;&#30340;&#38543;&#26426;&#19968;&#38454;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#36825;&#31867;&#26041;&#27861;&#38754;&#20020;&#30340;&#19968;&#20010;&#20030;&#19990;&#38395;&#21517;&#30340;&#25361;&#25112;&#26159;&#65292;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#26799;&#24230;&#21487;&#33021;&#20250;&#20219;&#24847;&#22686;&#38271;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#31283;&#23450;&#24615;&#21644;&#21457;&#25955;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31283;&#23450;&#20102;&#36845;&#20195;&#24182;&#20135;&#29983;&#20102;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#21363;&#20351;&#23450;&#20041;&#22495;&#21644;&#26799;&#24230;&#22122;&#22768;&#38543;&#36845;&#20195;&#30340;&#35268;&#27169;&#32447;&#24615;&#21464;&#21270;&#65288;&#22240;&#27492;&#21487;&#33021;&#26159;&#26080;&#30028;&#30340;&#65289;&#12290;&#38500;&#20102;&#25552;&#20379;&#19968;&#31995;&#21015;&#19968;&#33324;&#24615;&#32467;&#26524;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#24212;&#29992;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20855;&#20307;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#23548;&#33268;&#22312;&#19981;&#38656;&#35201;&#26377;&#20851;&#20559;&#32622;&#36328;&#24230;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#25214;&#21040;&#24179;&#22343;&#22870;&#21169;MDP&#20013;&#25509;&#36817;&#26368;&#20248;&#31574;&#30053;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13903v1 Announce Type: new  Abstract: We study the performance of stochastic first-order methods for finding saddle points of convex-concave functions. A notorious challenge faced by such methods is that the gradients can grow arbitrarily large during optimization, which may result in instability and divergence. In this paper, we propose a simple and effective regularization technique that stabilizes the iterates and yields meaningful performance guarantees even if the domain and the gradient noise scales linearly with the size of the iterates (and is thus potentially unbounded). Besides providing a set of general results, we also apply our algorithm to a specific problem in reinforcement learning, where it leads to performance guarantees for finding near-optimal policies in an average-reward MDP without prior knowledge of the bias span.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#23545;&#26356;&#22823;&#31867;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25552;&#39640;&#20102;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.13901</link><description>&lt;p&gt;
&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#65306;&#26032;&#26041;&#27861;&#21644;&#25913;&#36827;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic Convergence of Discrete-time Diffusion Models: New Approach and Improved Rate
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13901
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#65292;&#25913;&#36827;&#20102;&#23545;&#26356;&#22823;&#31867;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25552;&#39640;&#20102;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#29983;&#25104;&#25216;&#26415;&#20986;&#29616;&#65292;&#23558;&#22122;&#22768;&#36716;&#21270;&#20026;&#25968;&#25454;&#12290;&#29702;&#35770;&#19978;&#20027;&#35201;&#30740;&#31350;&#20102;&#36830;&#32493;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#19988;&#20165;&#22312;&#25991;&#29486;&#20013;&#23545;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#20102;&#33719;&#24471;&#12290;&#26412;&#25991;&#20026;&#26356;&#22823;&#31867;&#30340;&#20998;&#24067;&#24314;&#31435;&#20102;&#31163;&#25955;&#26102;&#38388;&#25193;&#25955;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#23545;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#39318;&#20808;&#20026;&#20855;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#24179;&#28369;&#21644;&#19968;&#33324;&#65288;&#21487;&#33021;&#38750;&#20809;&#28369;&#65289;&#20998;&#24067;&#24314;&#31435;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#28982;&#21518;&#23558;&#32467;&#26524;&#19987;&#38376;&#24212;&#29992;&#20110;&#19968;&#20123;&#26377;&#26126;&#30830;&#21442;&#25968;&#20381;&#36182;&#20851;&#31995;&#30340;&#26377;&#36259;&#20998;&#24067;&#31867;&#21035;&#65292;&#21253;&#25324;&#20855;&#26377;Lipschitz&#20998;&#25968;&#12289;&#39640;&#26031;&#28151;&#21512;&#20998;&#24067;&#21644;&#20855;&#26377;&#26377;&#30028;&#25903;&#25745;&#30340;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13901v1 Announce Type: new  Abstract: The denoising diffusion model emerges recently as a powerful generative technique that converts noise into data. Theoretical convergence guarantee has been mainly studied for continuous-time diffusion models, and has been obtained for discrete-time diffusion models only for distributions with bounded support in the literature. In this paper, we establish the convergence guarantee for substantially larger classes of distributions under discrete-time diffusion models and further improve the convergence rate for distributions with bounded support. In particular, we first establish the convergence rates for both smooth and general (possibly non-smooth) distributions having finite second moment. We then specialize our results to a number of interesting classes of distributions with explicit parameter dependencies, including distributions with Lipschitz scores, Gaussian mixture distributions, and distributions with bounded support. We further 
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#35299;&#20915;&#20102;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#30340;&#39281;&#21644;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#21644;&#22823;&#35268;&#27169;&#28145;&#24230;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#38598;&#25104;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>https://arxiv.org/abs/2402.13891</link><description>&lt;p&gt;
&#20811;&#26381;&#36845;&#20195;&#27491;&#21017;&#21270;&#20013;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#39281;&#21644;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Overcoming Saturation in Density Ratio Estimation by Iterated Regularization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13891
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#35299;&#20915;&#20102;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#30340;&#39281;&#21644;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#65292;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#21644;&#22823;&#35268;&#27169;&#28145;&#24230;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#38598;&#25104;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26377;&#38480;&#26679;&#26412;&#20013;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#30340;&#27604;&#29575;&#65292;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#22823;&#31867;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#26680;&#26041;&#27861;&#23384;&#22312;&#38169;&#35823;&#39281;&#21644;&#38382;&#39064;&#65292;&#36825;&#38459;&#30861;&#20102;&#31639;&#27861;&#22312;&#39640;&#24230;&#35268;&#21017;&#23398;&#20064;&#38382;&#39064;&#19978;&#23454;&#29616;&#24555;&#36895;&#38169;&#35823;&#25910;&#25947;&#29575;&#12290;&#20026;&#20102;&#35299;&#20915;&#39281;&#21644;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#20013;&#20197;&#23454;&#29616;&#24555;&#36895;&#38169;&#35823;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23494;&#24230;&#27604;&#20272;&#35745;&#22522;&#20934;&#27979;&#35797;&#20197;&#21450;&#22823;&#35268;&#27169;&#35780;&#20272;&#28145;&#24230;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#38598;&#25104;&#26041;&#38754;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13891v1 Announce Type: new  Abstract: Estimating the ratio of two probability densities from finitely many samples, is a central task in machine learning and statistics. In this work, we show that a large class of kernel methods for density ratio estimation suffers from error saturation, which prevents algorithms from achieving fast error convergence rates on highly regular learning problems. To resolve saturation, we introduce iterated regularization in density ratio estimation to achieve fast error rates. Our methods outperform its non-iteratively regularized versions on benchmarks for density ratio estimation as well as on large-scale evaluations for importance-weighted ensembling of deep unsupervised domain adaptation models.
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#21306;&#38388;&#38646;&#20551;&#35774;&#26694;&#26550;&#21644;&#22522;&#20110;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#27979;&#35797;&#65292;&#21487;&#20197;&#35268;&#36991;&#20256;&#32479;P&#20540;&#23384;&#22312;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#21516;&#26102;&#36890;&#36807;&#35843;&#25972;&#36125;&#21494;&#26031;&#22240;&#23376;&#26469;&#35299;&#20915;&#20808;&#39564;&#23494;&#24230;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.13890</link><description>&lt;p&gt;
&#19968;&#31181;&#32479;&#19968;&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#20013;&#30340;&#21306;&#38388;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
A unified Bayesian framework for interval hypothesis testing in clinical trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13890
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#21306;&#38388;&#38646;&#20551;&#35774;&#26694;&#26550;&#21644;&#22522;&#20110;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#27979;&#35797;&#65292;&#21487;&#20197;&#35268;&#36991;&#20256;&#32479;P&#20540;&#23384;&#22312;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#21516;&#26102;&#36890;&#36807;&#35843;&#25972;&#36125;&#21494;&#26031;&#22240;&#23376;&#26469;&#35299;&#20915;&#20808;&#39564;&#23494;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32654;&#22269;&#32479;&#35745;&#21327;&#20250;&#65288;ASA&#65289;&#20851;&#20110;&#32479;&#35745;&#26174;&#33879;&#24615;&#21644;P&#20540;&#30340;&#22768;&#26126;&#35686;&#21578;&#32479;&#35745;&#23398;&#23478;&#19981;&#35201;&#20165;&#20165;&#22522;&#20110;&#20256;&#32479;P&#20540;&#20570;&#20986;&#31185;&#23398;&#20915;&#31574;&#12290;&#22768;&#26126;&#38416;&#26126;&#20102;P&#20540;&#23384;&#22312;&#30340;&#20851;&#38190;&#38382;&#39064;&#65292;&#21253;&#25324;&#32570;&#20047;&#36879;&#26126;&#24230;&#65292;&#19981;&#33021;&#37327;&#21270;&#25903;&#25345;&#38646;&#20551;&#35774;&#30340;&#35777;&#25454;&#65292;&#26080;&#27861;&#34913;&#37327;&#25928;&#24212;&#30340;&#22823;&#23567;&#25110;&#32467;&#26524;&#30340;&#37325;&#35201;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#19982;&#22522;&#20110;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#27979;&#35797;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;&#21306;&#38388;&#38646;&#20551;&#35774;&#26694;&#26550;&#65288;&#32780;&#19981;&#26159;&#28857;&#38646;&#20551;&#35774;&#26694;&#26550;&#65289;&#26377;&#21161;&#20110;&#35268;&#36991;P&#20540;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#27880;&#24847;&#21040;&#20026;&#36125;&#21494;&#26031;&#22240;&#23376;&#25351;&#23450;&#20808;&#39564;&#23494;&#24230;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#24182;&#19988;&#19968;&#30452;&#26159;&#29616;&#26377;&#25991;&#29486;&#20013;&#25209;&#35780;&#36125;&#21494;&#26031;&#20551;&#35774;&#26816;&#39564;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#36890;&#36807;&#30452;&#25509;&#22522;&#20110;&#24120;&#35265;&#27979;&#35797;&#32479;&#35745;&#37327;&#35843;&#25972;&#36125;&#21494;&#26031;&#22240;&#23376;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13890v1 Announce Type: cross  Abstract: The American Statistical Association (ASA) statement on statistical significance and P-values \cite{wasserstein2016asa} cautioned statisticians against making scientific decisions solely on the basis of traditional P-values. The statement delineated key issues with P-values, including a lack of transparency, an inability to quantify evidence in support of the null hypothesis, and an inability to measure the size of an effect or the importance of a result. In this article, we demonstrate that the interval null hypothesis framework (instead of the point null hypothesis framework), when used in tandem with Bayes factor-based tests, is instrumental in circumnavigating the key issues of P-values. Further, we note that specifying prior densities for Bayes factors is challenging and has been a reason for criticism of Bayesian hypothesis testing in existing literature. We address this by adapting Bayes factors directly based on common test sta
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#65292;&#26368;&#22823;&#21270;&#25928;&#29575;&#24182;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#12290;</title><link>https://arxiv.org/abs/2402.13852</link><description>&lt;p&gt;
&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Neural Control System for Continuous Glucose Monitoring and Maintenance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13852
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#65292;&#26368;&#22823;&#21270;&#25928;&#29575;&#24182;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31934;&#30830;&#30340;&#33889;&#33796;&#31958;&#27700;&#24179;&#31649;&#29702;&#23545;&#20110;&#31958;&#23615;&#30149;&#24739;&#32773;&#33267;&#20851;&#37325;&#35201;&#65292;&#21487;&#20197;&#36991;&#20813;&#20005;&#37325;&#24182;&#21457;&#30151;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#25511;&#21046;&#31995;&#32479;&#65292;&#29992;&#20110;&#36830;&#32493;&#33889;&#33796;&#31958;&#30417;&#27979;&#21644;&#32500;&#25252;&#65292;&#21033;&#29992;&#24494;&#20998;&#39044;&#27979;&#25511;&#21046;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#21463;&#21040;&#22797;&#26434;&#31070;&#32463;&#31574;&#30053;&#21644;&#21487;&#21306;&#20998;&#24314;&#27169;&#30340;&#25351;&#23548;&#65292;&#23454;&#26102;&#21160;&#24577;&#35843;&#25972;&#33008;&#23707;&#32032;&#36755;&#36865;&#65292;&#22686;&#24378;&#33889;&#33796;&#31958;&#20248;&#21270;&#12290;&#36825;&#31181;&#31471;&#21040;&#31471;&#26041;&#27861;&#26368;&#22823;&#21270;&#25928;&#29575;&#65292;&#30830;&#20445;&#20010;&#24615;&#21270;&#25252;&#29702;&#21644;&#25913;&#21892;&#20581;&#24247;&#32467;&#26524;&#65292;&#22914;&#32463;&#39564;&#21457;&#29616;&#25152;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13852v1 Announce Type: cross  Abstract: Precise glucose level management is pivotal for individuals with diabetes, averting severe complications. In this work, we introduce a novel neural control system for continuous glucose monitoring and maintenance, utilizing differential predictive control. Our system, guided by a sophisticated neural policy and differentiable modeling, dynamically adjusts insulin delivery in real-time, enhancing glucose optimization. This end-to-end approach maximizes efficiency, ensuring personalized care and improved health outcomes, as affirmed by empirical findings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;Concrete&#20998;&#24067;&#20316;&#20026;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#20855;&#26377;&#26368;&#20248;&#24615;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26679;&#26412;&#29983;&#25104;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.13765</link><description>&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#32479;&#35745;&#24314;&#27169;&#23454;&#29616;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13765
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#20351;&#29992;Concrete&#20998;&#24067;&#20316;&#20026;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#20855;&#26377;&#26368;&#20248;&#24615;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26679;&#26412;&#29983;&#25104;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#20998;&#31867;&#27169;&#22411;&#24517;&#39035;&#36827;&#34892;&#26657;&#20934;&#65292;&#20197;&#35780;&#20272;&#39044;&#27979;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#12290;&#19968;&#20123;&#26368;&#36817;&#30340;&#26657;&#20934;&#26041;&#27861;&#37319;&#29992;&#20102;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26657;&#20934;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#36825;&#20123;&#27169;&#22411;&#20855;&#26377;&#24456;&#39640;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Concrete&#20998;&#24067;&#20316;&#20026;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#27010;&#29575;&#27169;&#22411;&#30340;&#20445;&#25345;&#31934;&#24230;&#30340;&#26657;&#20934;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19978;&#35757;&#32451;&#30340;DNN&#27169;&#22411;&#20855;&#26377;Concrete&#20998;&#24067;&#21442;&#25968;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21512;&#25104;&#29983;&#25104;&#26679;&#26412;&#65292;&#29992;&#20110;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#31934;&#24230;&#20445;&#25345;&#26657;&#20934;&#20219;&#21153;&#19978;&#21487;&#20197;&#20248;&#20110;&#20197;&#24448;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20934;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13765v1 Announce Type: new  Abstract: Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;</title><link>https://arxiv.org/abs/2402.13728</link><description>&lt;p&gt;
&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#20316;&#20026;&#28145;&#24230;&#31070;&#32463;&#22349;&#22604;&#26426;&#21046;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Average gradient outer product as a mechanism for deep neural collapse
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#31070;&#32463;&#22349;&#22604;&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#30340;&#65292;&#26435;&#37325;&#30340;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#39640;&#24230;&#30456;&#20851;&#65292;&#23548;&#33268;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Deep Neural Collapse (DNC)&#25351;&#30340;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#26368;&#21518;&#20960;&#23618;&#25968;&#25454;&#34920;&#31034;&#30340;&#24778;&#20154;&#21018;&#24615;&#32467;&#26500;&#12290;&#23613;&#31649;&#36825;&#31181;&#29616;&#35937;&#22312;&#21508;&#31181;&#24773;&#22659;&#20013;&#37117;&#24471;&#21040;&#20102;&#27979;&#37327;&#65292;&#20294;&#20854;&#20986;&#29616;&#21482;&#26377;&#37096;&#20998;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#20805;&#20998;&#35777;&#25454;&#65292;&#34920;&#26126;DNC&#20027;&#35201;&#26159;&#36890;&#36807;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;(AGOP)&#36827;&#34892;&#28145;&#24230;&#29305;&#24449;&#23398;&#20064;&#32780;&#21457;&#29983;&#30340;&#12290;&#30456;&#27604;&#20110;&#35299;&#37322;&#31070;&#32463;&#22349;&#22604;&#30340;&#29305;&#24449;&#19981;&#21487;&#30693;&#26041;&#27861;&#65292;&#22914;&#26080;&#32422;&#26463;&#29305;&#24449;&#27169;&#22411;&#65292;&#36825;&#19968;&#36827;&#23637;&#26356;&#36827;&#19968;&#27493;&#12290;&#25105;&#20204;&#32487;&#32493;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;&#26435;&#37325;&#30340;&#21491;&#22855;&#24322;&#21521;&#37327;&#21644;&#22855;&#24322;&#20540;&#26159;DNN&#20013;&#31867;&#20869;&#21464;&#24322;&#22349;&#22604;&#30340;&#20027;&#35201;&#22240;&#32032;&#12290;&#27491;&#22914;&#26368;&#36817;&#30340;&#30740;&#31350;&#25152;&#31034;&#65292;&#36825;&#31181;&#22855;&#24322;&#32467;&#26500;&#19982;AGOP&#30340;&#39640;&#24230;&#30456;&#20851;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#23454;&#39564;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;AGOP&#22312;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#24341;&#21457;&#31070;&#32463;&#22349;&#22604;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13728v1 Announce Type: new  Abstract: Deep Neural Collapse (DNC) refers to the surprisingly rigid structure of the data representations in the final layers of Deep Neural Networks (DNNs). Though the phenomenon has been measured in a wide variety of settings, its emergence is only partially understood. In this work, we provide substantial evidence that DNC formation occurs primarily through deep feature learning with the average gradient outer product (AGOP). This takes a step further compared to efforts that explain neural collapse via feature-agnostic approaches, such as the unconstrained features model. We proceed by providing evidence that the right singular vectors and values of the weights are responsible for the majority of within-class variability collapse in DNNs. As shown in recent work, this singular structure is highly correlated with that of the AGOP. We then establish experimentally and theoretically that AGOP induces neural collapse in a randomly initialized ne
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#19978;&#19979;&#30028;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#32622;&#29305;&#23450;&#30340;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#38480;&#65292;&#24182;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;</title><link>https://arxiv.org/abs/2402.13662</link><description>&lt;p&gt;
&#19968;&#31181;&#30028;&#23450;&#23614;&#37096;&#27010;&#29575;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Method For Bounding Tail Probabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13662
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#19978;&#19979;&#30028;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35774;&#32622;&#29305;&#23450;&#30340;&#20989;&#25968;&#65292;&#24471;&#21040;&#20102;&#26032;&#30340;&#19978;&#19979;&#30028;&#38480;&#65292;&#24182;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#19978;&#19979;&#30028;&#23450;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#65288;RVs&#65289;&#30340;&#21491;&#23614;&#21644;&#24038;&#23614;&#27010;&#29575;&#12290;&#23545;&#20110;&#20855;&#26377;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;$f_X(x)$&#30340;RV $X$&#30340;&#21491;&#23614;&#27010;&#29575;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#35201;&#27714;&#35774;&#32622;&#19968;&#20010;&#36830;&#32493;&#30340;&#12289;&#27491;&#30340;&#12289;&#20005;&#26684;&#36882;&#20943;&#30340;&#20989;&#25968;$g_X(x)$&#65292;&#20351;&#24471;$-f_X(x)/g'_X(x)$&#26159;&#19968;&#20010;&#36882;&#20943;&#19988;&#36882;&#22686;&#30340;&#20989;&#25968;&#65292;$\forall x&gt;x_0$&#65292;&#20998;&#21035;&#32473;&#20986;&#24418;&#24335;&#20026;$-f_X(x) g_X(x)/g'_X(x)$&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;$\forall x&gt;x_0$&#65292;&#20854;&#20013;$x_0$&#26159;&#26576;&#20010;&#28857;&#12290;&#31867;&#20284;&#22320;&#65292;&#23545;&#20110;$X$&#30340;&#24038;&#23614;&#27010;&#29575;&#30340;&#19978;&#19979;&#30028;&#65292;&#35813;&#26041;&#27861;&#39318;&#20808;&#35201;&#27714;&#35774;&#32622;&#19968;&#20010;&#36830;&#32493;&#30340;&#12289;&#27491;&#30340;&#12289;&#20005;&#26684;&#36882;&#22686;&#30340;&#20989;&#25968;$g_X(x)$&#65292;&#20351;&#24471;$f_X(x)/g'_X(x)$&#26159;&#19968;&#20010;&#22686;&#21152;&#19988;&#36882;&#20943;&#30340;&#20989;&#25968;&#65292;$\forall x&lt;x_0$&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#20989;&#25968;$g_X(x)$&#30340;&#33391;&#22909;&#20505;&#36873;&#31034;&#20363;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#26032;&#30028;&#38480;&#19982;&#39532;&#23572;&#21487;&#22827;&#19981;&#31561;&#24335;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13662v1 Announce Type: cross  Abstract: We present a method for upper and lower bounding the right and the left tail probabilities of continuous random variables (RVs). For the right tail probability of RV $X$ with probability density function $f_X(x)$, this method requires first setting a continuous, positive, and strictly decreasing function $g_X(x)$ such that $-f_X(x)/g'_X(x)$ is a decreasing and increasing function, $\forall x&gt;x_0$, which results in upper and lower bounds, respectively, given in the form $-f_X(x) g_X(x)/g'_X(x)$, $\forall x&gt;x_0$, where $x_0$ is some point. Similarly, for the upper and lower bounds on the left tail probability of $X$, this method requires first setting a continuous, positive, and strictly increasing function $g_X(x)$ such that $f_X(x)/g'_X(x)$ is an increasing and decreasing function, $\forall x&lt;x_0$. We provide some examples of good candidates for the function $g_X(x)$. We also establish connections between the new bounds and Markov's in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36827;&#34892;&#20102;&#38024;&#23545;&#19968;&#20010;&#31616;&#21333;&#32780;&#38750;&#24120;&#36890;&#29992;&#30340;&#20998;&#31867;&#27169;&#22411;&#30340;&#22823;&#32500;&#20998;&#26512;&#30740;&#31350;&#65292;&#35813;&#27169;&#22411;&#21516;&#26102;&#28085;&#30422;&#20102;&#22810;&#20219;&#21153;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#65292;&#24182;&#32771;&#34385;&#20102;&#19981;&#30830;&#23450;&#30340;&#26631;&#31614;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#34920;&#24449;&#20102;&#20851;&#38190;&#21151;&#33021;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#20851;&#20110;&#26377;&#25928;&#20351;&#29992;&#35813;&#27169;&#22411;&#30340;&#21453;&#30452;&#35273;&#25351;&#23548;&#12290;</title><link>https://arxiv.org/abs/2402.13646</link><description>&lt;p&gt;
&#23545;&#22810;&#20219;&#21153;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#22823;&#32500;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Large Dimensional Analysis of Multi-task Semi-Supervised Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36827;&#34892;&#20102;&#38024;&#23545;&#19968;&#20010;&#31616;&#21333;&#32780;&#38750;&#24120;&#36890;&#29992;&#30340;&#20998;&#31867;&#27169;&#22411;&#30340;&#22823;&#32500;&#20998;&#26512;&#30740;&#31350;&#65292;&#35813;&#27169;&#22411;&#21516;&#26102;&#28085;&#30422;&#20102;&#22810;&#20219;&#21153;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#65292;&#24182;&#32771;&#34385;&#20102;&#19981;&#30830;&#23450;&#30340;&#26631;&#31614;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#34920;&#24449;&#20102;&#20851;&#38190;&#21151;&#33021;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#20851;&#20110;&#26377;&#25928;&#20351;&#29992;&#35813;&#27169;&#22411;&#30340;&#21453;&#30452;&#35273;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#19968;&#20010;&#31616;&#21333;&#20294;&#38750;&#24120;&#36890;&#29992;&#30340;&#20998;&#31867;&#27169;&#22411;&#36827;&#34892;&#20102;&#22823;&#32500;&#30740;&#31350;&#65292;&#21516;&#26102;&#28085;&#30422;&#20102;&#22810;&#20219;&#21153;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#65292;&#24182;&#32771;&#34385;&#20102;&#19981;&#30830;&#23450;&#30340;&#26631;&#31614;&#12290;&#21033;&#29992;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#19968;&#20123;&#20851;&#38190;&#21151;&#33021;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#20174;&#32780;&#19968;&#26041;&#38754;&#21487;&#20197;&#39044;&#27979;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21478;&#19968;&#26041;&#38754;&#21487;&#20197;&#25581;&#31034;&#19968;&#20123;&#20851;&#20110;&#22914;&#20309;&#39640;&#25928;&#20351;&#29992;&#23427;&#30340;&#21453;&#30452;&#35273;&#25351;&#23548;&#12290;&#35813;&#27169;&#22411;&#24378;&#22823;&#21040;&#36275;&#20197;&#25552;&#20379;&#33391;&#22909;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#19988;&#31616;&#21333;&#30452;&#35266;&#21040;&#36275;&#20197;&#28145;&#20837;&#20102;&#35299;&#20854;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13646v1 Announce Type: cross  Abstract: This article conducts a large dimensional study of a simple yet quite versatile classification model, encompassing at once multi-task and semi-supervised learning, and taking into account uncertain labeling. Using tools from random matrix theory, we characterize the asymptotics of some key functionals, which allows us on the one hand to predict the performances of the algorithm, and on the other hand to reveal some counter-intuitive guidance on how to use it efficiently. The model, powerful enough to provide good performance guarantees, is also straightforward enough to provide strong insights into its behavior.
&lt;/p&gt;</description></item><item><title>&#37325;&#35201;&#21457;&#29616;&#21253;&#25324;&#39640;&#32500;&#24773;&#20917;&#19979;&#37325;&#25277;&#26679;&#26041;&#27861;&#30340;&#38382;&#39064;&#65292;&#20165;&#24403;$\alpha$&#36275;&#22815;&#22823;&#26102;&#25552;&#20379;&#19968;&#33268;&#21487;&#38752;&#30340;&#35823;&#24046;&#20272;&#35745;&#65292;&#20197;&#21450;&#22312;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;$\alpha\!&lt;\!1$&#30340;&#24773;&#20917;&#19979;&#23427;&#20204;&#30340;&#39044;&#27979;&#34920;&#29616;</title><link>https://arxiv.org/abs/2402.13622</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#27491;&#21017;&#21270;&#22238;&#24402;&#20013;&#23545;&#33258;&#20030;&#21644;&#23376;&#25277;&#26679;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of Bootstrap and Subsampling in High-dimensional Regularized Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13622
&lt;/p&gt;
&lt;p&gt;
&#37325;&#35201;&#21457;&#29616;&#21253;&#25324;&#39640;&#32500;&#24773;&#20917;&#19979;&#37325;&#25277;&#26679;&#26041;&#27861;&#30340;&#38382;&#39064;&#65292;&#20165;&#24403;$\alpha$&#36275;&#22815;&#22823;&#26102;&#25552;&#20379;&#19968;&#33268;&#21487;&#38752;&#30340;&#35823;&#24046;&#20272;&#35745;&#65292;&#20197;&#21450;&#22312;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;$\alpha\!&lt;\!1$&#30340;&#24773;&#20917;&#19979;&#23427;&#20204;&#30340;&#39044;&#27979;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#20272;&#35745;&#32479;&#35745;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#27969;&#34892;&#37325;&#25277;&#26679;&#26041;&#27861;&#65292;&#22914;&#23376;&#25277;&#26679;&#12289;&#33258;&#20030;&#21644;jackknife&#65292;&#20197;&#21450;&#23427;&#20204;&#22312;&#39640;&#32500;&#30417;&#30563;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#24773;&#22659;&#19979;&#65292;&#20363;&#22914;&#23725;&#22238;&#24402;&#21644;&#36923;&#36753;&#22238;&#24402;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#26041;&#27861;&#20272;&#35745;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#25552;&#20379;&#20102;&#32039;&#33268;&#30340;&#28176;&#36817;&#25551;&#36848;&#65292;&#32771;&#34385;&#21040;&#26679;&#26412;&#25968;&#37327;$n$&#21644;&#21327;&#21464;&#37327;&#32500;&#24230;$d$&#20197;&#21487;&#27604;&#22266;&#23450;&#36895;&#29575;$\alpha\!=\! n/d$&#22686;&#38271;&#30340;&#26497;&#38480;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26377;&#19977;&#20010;&#26041;&#38754;&#65306;i&#65289;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#37325;&#25277;&#26679;&#26041;&#27861;&#23384;&#22312;&#38382;&#39064;&#65292;&#24182;&#34920;&#29616;&#20986;&#36825;&#20123;&#24773;&#20917;&#20856;&#22411;&#30340;&#21452;&#23792;&#34892;&#20026;&#65307;ii&#65289;&#21482;&#26377;&#22312;$\alpha$&#36275;&#22815;&#22823;&#26102;&#65292;&#23427;&#20204;&#25165;&#25552;&#20379;&#19968;&#33268;&#21487;&#38752;&#30340;&#35823;&#24046;&#20272;&#35745;&#65288;&#25105;&#20204;&#32473;&#20986;&#25910;&#25947;&#29575;&#65289;&#65307;iii&#65289;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#30456;&#20851;&#30340;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;$\alpha\!&lt;\!1$&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#26159;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13622v1 Announce Type: cross  Abstract: We investigate popular resampling methods for estimating the uncertainty of statistical models, such as subsampling, bootstrap and the jackknife, and their performance in high-dimensional supervised regression tasks. We provide a tight asymptotic description of the biases and variances estimated by these methods in the context of generalized linear models, such as ridge and logistic regression, taking the limit where the number of samples $n$ and dimension $d$ of the covariates grow at a comparable fixed rate $\alpha\!=\! n/d$. Our findings are three-fold: i) resampling methods are fraught with problems in high dimensions and exhibit the double-descent-like behavior typical of these situations; ii) only when $\alpha$ is large enough do they provide consistent and reliable error estimations (we give convergence rates); iii) in the over-parametrized regime $\alpha\!&lt;\!1$ relevant to modern machine learning practice, their predictions are
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;MCMC&#21644;&#26799;&#24230;&#19979;&#38477;&#30340;Ohzeki&#26041;&#27861;&#30340;&#21487;&#35757;&#32451;&#37319;&#26679;&#27714;&#35299;&#22120;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#27493;&#38271;&#65292;&#37319;&#29992;&#22522;&#20110;&#37319;&#26679;&#30340;&#26799;&#24230;&#20272;&#35745;&#26367;&#20195;&#33258;&#21160;&#24494;&#20998;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#26174;&#31034;&#30456;&#23545;&#20110;&#21407;&#22987;&#26041;&#27861;&#26174;&#33879;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;</title><link>https://arxiv.org/abs/2402.13608</link><description>&lt;p&gt;
Markov Chain Monte Carlo&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#21152;&#36895;&#36890;&#36807;&#28145;&#24230;&#23637;&#24320;
&lt;/p&gt;
&lt;p&gt;
Convergence Acceleration of Markov Chain Monte Carlo-based Gradient Descent by Deep Unfolding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13608
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#20102;MCMC&#21644;&#26799;&#24230;&#19979;&#38477;&#30340;Ohzeki&#26041;&#27861;&#30340;&#21487;&#35757;&#32451;&#37319;&#26679;&#27714;&#35299;&#22120;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#27493;&#38271;&#65292;&#37319;&#29992;&#22522;&#20110;&#37319;&#26679;&#30340;&#26799;&#24230;&#20272;&#35745;&#26367;&#20195;&#33258;&#21160;&#24494;&#20998;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#26174;&#31034;&#30456;&#23545;&#20110;&#21407;&#22987;&#26041;&#27861;&#26174;&#33879;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35757;&#32451;&#30340;&#22522;&#20110;&#28145;&#24230;&#23637;&#24320;&#30340;&#37319;&#26679;&#27714;&#35299;&#22120;&#65292;&#29992;&#20110;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65288;COPs&#65289;&#65292;&#35813;&#27714;&#35299;&#22120;&#22522;&#20110;&#32467;&#21512;&#20102;&#39532;&#23572;&#21487;&#22827;&#38142;&#8212;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#21644;&#26799;&#24230;&#19979;&#38477;&#30340;Ohzeki&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#26469;&#35757;&#32451;&#20854;&#27493;&#38271;&#12290;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37319;&#26679;&#30340;&#26799;&#24230;&#20272;&#35745;&#65292;&#29992;&#26041;&#24046;&#20272;&#35745;&#20195;&#26367;&#33258;&#21160;&#24494;&#20998;&#65292;&#20174;&#32780;&#35268;&#36991;&#20102;&#30001;&#20110;MCMC&#30340;&#19981;&#21487;&#24494;&#20998;&#24615;&#32780;&#23548;&#33268;&#21453;&#21521;&#20256;&#25773;&#22833;&#36133;&#30340;&#38382;&#39064;&#12290;&#23569;&#25968;COPs&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#21407;&#22987;&#30340;Ohzeki&#26041;&#27861;&#30456;&#27604;&#65292;&#25552;&#20986;&#30340;&#27714;&#35299;&#22120;&#26174;&#33879;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13608v1 Announce Type: cross  Abstract: This study proposes a trainable sampling-based solver for combinatorial optimization problems (COPs) using a deep-learning technique called deep unfolding. The proposed solver is based on the Ohzeki method that combines Markov-chain Monte-Carlo (MCMC) and gradient descent, and its step sizes are trained by minimizing a loss function. In the training process, we propose a sampling-based gradient estimation that substitutes auto-differentiation with a variance estimation, thereby circumventing the failure of back propagation due to the non-differentiability of MCMC. The numerical results for a few COPs demonstrated that the proposed solver significantly accelerated the convergence speed compared with the original Ohzeki method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20999;&#24179;&#38754;&#31639;&#27861;&#65292;&#38024;&#23545;&#20302;&#32500;&#25968;&#25454;&#30340;k-means&#32858;&#31867;&#38382;&#39064;&#36827;&#34892;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#21033;&#29992;&#32467;&#26500;&#21270;&#20985;&#24418;&#20998;&#37197;&#38382;&#39064;&#21644;&#20840;&#23616;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#22312;&#21512;&#29702;&#26102;&#38388;&#20869;&#35299;&#20915;&#22823;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#25910;&#25947;&#20110;&#38646;&#26368;&#20248;&#24615;&#24046;&#20540;&#30340;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.13595</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20840;&#23616;&#35299;&#20915;&#20302;&#32500;k-means&#32858;&#31867;&#38382;&#39064;&#30340;&#20999;&#24179;&#38754;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A cutting plane algorithm for globally solving low dimensional k-means clustering problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#20999;&#24179;&#38754;&#31639;&#27861;&#65292;&#38024;&#23545;&#20302;&#32500;&#25968;&#25454;&#30340;k-means&#32858;&#31867;&#38382;&#39064;&#36827;&#34892;&#20840;&#23616;&#26368;&#20248;&#35299;&#65292;&#21033;&#29992;&#32467;&#26500;&#21270;&#20985;&#24418;&#20998;&#37197;&#38382;&#39064;&#21644;&#20840;&#23616;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#65292;&#22312;&#21512;&#29702;&#26102;&#38388;&#20869;&#35299;&#20915;&#22823;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#25910;&#25947;&#20110;&#38646;&#26368;&#20248;&#24615;&#24046;&#20540;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#26159;&#25968;&#25454;&#31185;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22522;&#26412;&#30340;&#24037;&#20855;&#20043;&#19968;&#65292;k-means&#32858;&#31867;&#26159;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#38024;&#23545;&#20302;&#32500;&#25968;&#25454;&#30340;k-means&#38382;&#39064;&#65292;&#26412;&#25991;&#23558;&#20854;&#21046;&#23450;&#20026;&#32467;&#26500;&#21270;&#20985;&#24418;&#20998;&#37197;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#20302;&#32500;&#32467;&#26500;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#21512;&#29702;&#30340;&#26102;&#38388;&#20869;&#20026;&#20855;&#26377;&#22810;&#20010;&#31751;&#30340;&#22823;&#25968;&#25454;&#38598;&#25214;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#36845;&#20195;&#27714;&#35299;&#19968;&#20010;&#23567;&#20985;&#38382;&#39064;&#21644;&#19968;&#20010;&#22823;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31995;&#21015;&#21487;&#34892;&#35299;&#20197;&#21450;&#25910;&#25947;&#20110;&#38646;&#26368;&#20248;&#24615;&#24046;&#20540;&#30340;&#36793;&#30028;&#12290;&#26412;&#25991;&#32467;&#21512;&#20102;&#20840;&#23616;&#20248;&#21270;&#29702;&#35770;&#26041;&#27861;&#26469;&#21152;&#36895;&#31243;&#24207;&#65292;&#24182;&#25552;&#20379;&#20102;&#23427;&#20204;&#22312;&#24615;&#33021;&#26041;&#38754;&#30340;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13595v1 Announce Type: cross  Abstract: Clustering is one of the most fundamental tools in data science and machine learning, and k-means clustering is one of the most common such methods. There is a variety of approximate algorithms for the k-means problem, but computing the globally optimal solution is in general NP-hard. In this paper we consider the k-means problem for instances with low dimensional data and formulate it as a structured concave assignment problem. This allows us to exploit the low dimensional structure and solve the problem to global optimality within reasonable time for large data sets with several clusters. The method builds on iteratively solving a small concave problem and a large linear programming problem. This gives a sequence of feasible solutions along with bounds which we show converges to zero optimality gap. The paper combines methods from global optimization theory to accelerate the procedure, and we provide numerical results on their perfor
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#25972;&#20010;&#20998;&#24067;&#22312;&#22238;&#24402;&#20013;&#30340;&#24615;&#33021;&#25552;&#21319;&#20027;&#35201;&#26469;&#33258;&#20110;&#20248;&#21270;&#30340;&#25913;&#36827;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#26356;&#22909;&#30340;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2402.13425</link><description>&lt;p&gt;
&#22312;&#22238;&#24402;&#20013;&#25506;&#35752;&#30452;&#26041;&#22270;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Investigating the Histogram Loss in Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13425
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#25972;&#20010;&#20998;&#24067;&#22312;&#22238;&#24402;&#20013;&#30340;&#24615;&#33021;&#25552;&#21319;&#20027;&#35201;&#26469;&#33258;&#20110;&#20248;&#21270;&#30340;&#25913;&#36827;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#26356;&#22909;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#24120;&#35265;&#30340;&#26159;&#65292;&#22312;&#22238;&#24402;&#20013;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#24314;&#27169;&#25972;&#20010;&#20998;&#24067;&#65292;&#21363;&#20351;&#21482;&#38656;&#35201;&#22343;&#20540;&#26469;&#36827;&#34892;&#39044;&#27979;&#12290; &#36825;&#31181;&#39069;&#22806;&#30340;&#24314;&#27169;&#36890;&#24120;&#20250;&#24102;&#26469;&#24615;&#33021;&#22686;&#30410;&#65292;&#20294;&#32972;&#21518;&#30340;&#21407;&#22240;&#23578;&#19981;&#23436;&#20840;&#28165;&#26970;&#12290; &#26412;&#25991;&#30740;&#31350;&#20102;&#22238;&#24402;&#20013;&#30340;&#19968;&#31181;&#26368;&#26032;&#26041;&#27861;&#65292;&#21363;&#30452;&#26041;&#22270;&#25439;&#22833;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#30446;&#26631;&#20998;&#24067;&#21644;&#28789;&#27963;&#30452;&#26041;&#22270;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#21449;&#29109;&#26469;&#23398;&#20064;&#30446;&#26631;&#21464;&#37327;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290; &#25105;&#20204;&#35774;&#35745;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20026;&#20160;&#20040;&#20197;&#21450;&#20309;&#26102;&#20250;&#20986;&#29616;&#24615;&#33021;&#22686;&#30410;&#65292;&#20197;&#21450;&#25439;&#22833;&#30340;&#19981;&#21516;&#32452;&#20214;&#22914;&#20309;&#20026;&#27492;&#20570;&#20986;&#36129;&#29486;&#12290; &#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#23398;&#20064;&#20998;&#24067;&#30340;&#22909;&#22788;&#26469;&#33258;&#20110;&#20248;&#21270;&#30340;&#25913;&#36827;&#65292;&#32780;&#19981;&#26159;&#23398;&#20064;&#26356;&#22909;&#30340;&#34920;&#31034;&#12290; &#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30452;&#26041;&#22270;&#25439;&#22833;&#22312;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13425v1 Announce Type: cross  Abstract: It is becoming increasingly common in regression to train neural networks that model the entire distribution even if only the mean is required for prediction. This additional modeling often comes with performance gain and the reasons behind the improvement are not fully known. This paper investigates a recent approach to regression, the Histogram Loss, which involves learning the conditional distribution of the target variable by minimizing the cross-entropy between a target distribution and a flexible histogram prediction. We design theoretical and empirical analyses to determine why and when this performance gain appears, and how different components of the loss contribute to it. Our results suggest that the benefits of learning distributions in this setup come from improvements in optimization rather than learning a better representation. We then demonstrate the viability of the Histogram Loss in common deep learning applications wi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#23558;&#21508;&#31181;&#24418;&#24335;&#30340;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#20808;&#39564;&#20013;&#65292;&#20197;&#23454;&#29616;&#26356;&#22909;&#31526;&#21512;&#39046;&#22495;&#30693;&#35782;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#21518;&#39564;&#26679;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.13410</link><description>&lt;p&gt;
&#20855;&#26377;&#39046;&#22495;&#30693;&#35782;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Bayesian Neural Networks with Domain Knowledge Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13410
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#23558;&#21508;&#31181;&#24418;&#24335;&#30340;&#39046;&#22495;&#30693;&#35782;&#25972;&#21512;&#21040;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#20808;&#39564;&#20013;&#65292;&#20197;&#23454;&#29616;&#26356;&#22909;&#31526;&#21512;&#39046;&#22495;&#30693;&#35782;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#20855;&#34920;&#29616;&#21147;&#30340;&#21518;&#39564;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#20854;&#33021;&#22815;&#37327;&#21270;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#65292;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#21464;&#24471;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#20026;BNNs&#25351;&#23450;&#33021;&#22815;&#25429;&#25417;&#30456;&#20851;&#39046;&#22495;&#30693;&#35782;&#30340;&#20808;&#39564;&#24448;&#24448;&#26497;&#20855;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#21464;&#20998;&#25512;&#26029;&#23558;&#21508;&#31181;&#24418;&#24335;&#30340;&#39046;&#22495;&#30693;&#35782;&#65288;&#21363;&#21487;&#20197;&#29992;&#25439;&#22833;&#20989;&#25968;&#34920;&#31034;&#30340;&#20219;&#20309;&#30693;&#35782;&#65289;&#25972;&#21512;&#21040;BNN&#20808;&#39564;&#20013;&#65292;&#21516;&#26102;&#23454;&#29616;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#21644;&#25277;&#26679;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23548;&#33268;&#23545;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#30340;&#20808;&#39564;&#20998;&#37197;&#39640;&#27010;&#29575;&#36136;&#37327;&#32473;&#26356;&#31526;&#21512;&#25105;&#20204;&#39046;&#22495;&#30693;&#35782;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#23548;&#33268;&#21518;&#39564;&#26679;&#26412;&#20063;&#34920;&#29616;&#20986;&#36825;&#31181;&#34892;&#20026;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#20351;&#29992;&#25105;&#20204;&#25552;&#20986;&#30340;&#39046;&#22495;&#30693;&#35782;&#20808;&#39564;&#30340;BNNs&#20248;&#20110;&#20855;&#26377;&#26631;&#20934;&#20808;&#39564;&#65288;&#20363;&#22914;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#12289;&#39640;&#26031;&#36807;&#31243;&#65289;&#30340;&#27169;&#22411;&#65292;&#22312;&#25104;&#21151;&#25972;&#21512;&#22810;&#31181;&#31867;&#22411;&#30340;&#20808;&#39564;&#20449;&#24687;&#65288;&#20363;&#22914;&#20844;&#24179;&#24615;&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13410v1 Announce Type: new  Abstract: Bayesian neural networks (BNNs) have recently gained popularity due to their ability to quantify model uncertainty. However, specifying a prior for BNNs that captures relevant domain knowledge is often extremely challenging. In this work, we propose a framework for integrating general forms of domain knowledge (i.e., any knowledge that can be represented by a loss function) into a BNN prior through variational inference, while enabling computationally efficient posterior inference and sampling. Specifically, our approach results in a prior over neural network weights that assigns high probability mass to models that better align with our domain knowledge, leading to posterior samples that also exhibit this behavior. We show that BNNs using our proposed domain knowledge priors outperform those with standard priors (e.g., isotropic Gaussian, Gaussian process), successfully incorporating diverse types of prior information such as fairness, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#20803;&#21644;&#22810;&#31867;&#21035;&#35774;&#32622;&#19979;&#30340;&#33258;&#20027;&#23398;&#20064;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32500;&#24230;$SDdim$&#26469;&#31934;&#30830;&#21051;&#30011;&#20219;&#20309;&#27010;&#24565;&#31867;&#21035;&#30340;&#33258;&#20027;&#23398;&#20064;&#38169;&#35823;&#19978;&#30028;&#65292;&#24182;&#21033;&#29992;&#8220;&#26631;&#35760;&#28216;&#25103;&#8221;&#36827;&#34892;&#35299;&#37322;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#31181;&#20363;&#23376;&#20013;&#30340;&#35745;&#31639;&#32467;&#26524;&#21644;&#23545;&#33258;&#20027;&#23398;&#20064;&#30340;&#23398;&#20064;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/2402.13400</link><description>&lt;p&gt;
&#33258;&#20027;&#23398;&#20064;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
The Dimension of Self-Directed Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#20803;&#21644;&#22810;&#31867;&#21035;&#35774;&#32622;&#19979;&#30340;&#33258;&#20027;&#23398;&#20064;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32500;&#24230;$SDdim$&#26469;&#31934;&#30830;&#21051;&#30011;&#20219;&#20309;&#27010;&#24565;&#31867;&#21035;&#30340;&#33258;&#20027;&#23398;&#20064;&#38169;&#35823;&#19978;&#30028;&#65292;&#24182;&#21033;&#29992;&#8220;&#26631;&#35760;&#28216;&#25103;&#8221;&#36827;&#34892;&#35299;&#37322;&#65292;&#23637;&#31034;&#20102;&#22312;&#21508;&#31181;&#20363;&#23376;&#20013;&#30340;&#35745;&#31639;&#32467;&#26524;&#21644;&#23545;&#33258;&#20027;&#23398;&#20064;&#30340;&#23398;&#20064;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#33258;&#20027;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#26159;&#33258;1990&#24180;&#20195;&#21021;&#20197;&#26469;&#21560;&#24341;&#22312;&#32447;&#23398;&#20064;&#29702;&#35770;&#31038;&#21306;&#20851;&#27880;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#23398;&#20064;&#32773;&#34987;&#20801;&#35768;&#33258;&#36866;&#24212;&#22320;&#36873;&#25321;&#19979;&#19968;&#20010;&#25968;&#25454;&#28857;&#26469;&#36827;&#34892;&#39044;&#27979;&#65292;&#19982;&#23545;&#25239;&#24615;&#22312;&#32447;&#23398;&#20064;&#35774;&#32622;&#19981;&#21516;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20108;&#20803;&#21644;&#22810;&#31867;&#21035;&#35774;&#32622;&#19979;&#30340;&#33258;&#20027;&#23398;&#20064;&#22797;&#26434;&#24615;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#32500;&#24230;&#65292;&#21363;$SDdim$&#65292;&#31934;&#30830;&#22320;&#21051;&#30011;&#20102;&#20219;&#20309;&#27010;&#24565;&#31867;&#21035;&#30340;&#33258;&#20027;&#23398;&#20064;&#38169;&#35823;&#19978;&#30028;&#12290;$SDdim$&#32972;&#21518;&#30340;&#30452;&#35273;&#21487;&#20197;&#29702;&#35299;&#20026;&#19968;&#20010;&#31216;&#20026;&#8220;&#26631;&#35760;&#28216;&#25103;&#8221;&#30340;&#21452;&#20154;&#28216;&#25103;&#12290;&#21033;&#29992;&#36825;&#20010;&#21452;&#20154;&#28216;&#25103;&#65292;&#25105;&#20204;&#23545;&#35768;&#22810;&#20363;&#23376;&#36827;&#34892;&#20102;$SDdim$&#30340;&#35745;&#31639;&#65292;&#29305;&#21035;&#26159;&#22312;&#36724;&#23545;&#40784;&#30697;&#24418;&#12289;VC&#32500;&#25968;&#20026;$1$&#30340;&#31867;&#21035;&#21644;&#32447;&#24615;&#20998;&#38548;&#22120;&#31561;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#30528;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#20851;&#20110;&#33258;&#20027;&#23398;&#20064;&#30340;&#23398;&#20064;&#24046;&#36317;&#65292;&#37325;&#28857;&#20851;&#27880;&#33258;&#20027;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13400v1 Announce Type: cross  Abstract: Understanding the self-directed learning complexity has been an important problem that has captured the attention of the online learning theory community since the early 1990s. Within this framework, the learner is allowed to adaptively choose its next data point in making predictions unlike the setting in adversarial online learning.   In this paper, we study the self-directed learning complexity in both the binary and multi-class settings, and we develop a dimension, namely $SDdim$, that exactly characterizes the self-directed learning mistake-bound for any concept class. The intuition behind $SDdim$ can be understood as a two-player game called the "labelling game". Armed with this two-player game, we calculate $SDdim$ on a whole host of examples with notable results on axis-aligned rectangles, VC dimension $1$ classes, and linear separators. We demonstrate several learnability gaps with a central focus on self-directed learning and
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#65292;&#39318;&#27425;&#37319;&#29992;&#21464;&#21387;&#22120;&#39044;&#27979;&#20108;&#36827;&#21046;&#21464;&#37327;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36234;&#20102;&#20256;&#32479;CPLEX&#21644;LSTM&#12290;</title><link>https://arxiv.org/abs/2402.13380</link><description>&lt;p&gt;
&#36808;&#21521;&#21464;&#21387;&#22120;&#65306;&#29992;&#21464;&#21387;&#22120;&#24443;&#24213;&#25913;&#21464;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#30340;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Toward TransfORmers: Revolutionizing the Solution of Mixed Integer Programs with Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13380
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#65292;&#39318;&#27425;&#37319;&#29992;&#21464;&#21387;&#22120;&#39044;&#27979;&#20108;&#36827;&#21046;&#21464;&#37327;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36234;&#20102;&#20256;&#32479;CPLEX&#21644;LSTM&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#21464;&#21387;&#22120;&#27169;&#22411;&#26469;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#19987;&#27880;&#20110;&#23481;&#37327;&#38480;&#21046;&#25209;&#37327;&#29983;&#20135;&#38382;&#39064;&#65288;CLSP&#65289;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#39318;&#20010;&#21033;&#29992;&#21464;&#21387;&#22120;&#26469;&#39044;&#27979;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#38382;&#39064;&#20013;&#30340;&#20108;&#36827;&#21046;&#21464;&#37327;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#21464;&#21387;&#22120;&#22788;&#29702;&#39034;&#24207;&#25968;&#25454;&#30340;&#33021;&#21147;&#65292;&#38750;&#24120;&#36866;&#21512;&#39044;&#27979;&#27599;&#20010;CLSP&#21608;&#26399;&#20013;&#34920;&#31034;&#29983;&#20135;&#35774;&#32622;&#20915;&#31574;&#30340;&#20108;&#36827;&#21046;&#21464;&#37327;&#12290;&#36825;&#20010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#21160;&#24577;&#30340;&#65292;&#25105;&#20204;&#38656;&#35201;&#22312;&#32422;&#26463;&#26465;&#20214;&#19979;&#22788;&#29702;&#39034;&#24207;&#20915;&#31574;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#21464;&#21387;&#22120;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;CLSP&#35299;&#20915;&#26041;&#26696;&#12290;&#25152;&#25552;&#20986;&#30340;&#21518;&#22788;&#29702;&#21464;&#21387;&#22120;&#31639;&#27861;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36234;&#20102;&#26368;&#20808;&#36827;&#30340;&#27714;&#35299;&#22120;CPLEX&#21644;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13380v1 Announce Type: new  Abstract: In this study, we introduce an innovative deep learning framework that employs a transformer model to address the challenges of mixed-integer programs, specifically focusing on the Capacitated Lot Sizing Problem (CLSP). Our approach, to our knowledge, is the first to utilize transformers to predict the binary variables of a mixed-integer programming (MIP) problem. Specifically, our approach harnesses the encoder decoder transformer's ability to process sequential data, making it well-suited for predicting binary variables indicating production setup decisions in each period of the CLSP. This problem is inherently dynamic, and we need to handle sequential decision making under constraints. We present an efficient algorithm in which CLSP solutions are learned through a transformer neural network. The proposed post-processed transformer algorithm surpasses the state-of-the-art solver, CPLEX and Long Short-Term Memory (LSTM) in solution time
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28120;&#27760;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#39118;&#38505;&#19982;&#24378;Oracle&#23398;&#20064;&#32773;&#30456;&#21305;&#37197;&#65292;&#24182;&#23558;&#24369;Oracle&#23398;&#20064;&#32773;&#30340;&#39118;&#38505;&#20316;&#20026;&#33258;&#36866;&#24212;&#23398;&#20064;&#32773;&#39118;&#38505;&#30340;&#19968;&#20010;&#23454;&#38469;&#22522;&#20934;&#12290;</title><link>https://arxiv.org/abs/2402.13366</link><description>&lt;p&gt;
&#32479;&#35745;&#35838;&#31243;&#23398;&#20064;&#65306;&#23454;&#29616;Oracle&#39118;&#38505;&#30340;&#28120;&#27760;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Statistical curriculum learning: An elimination algorithm achieving an oracle risk
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13366
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28120;&#27760;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#39118;&#38505;&#19982;&#24378;Oracle&#23398;&#20064;&#32773;&#30456;&#21305;&#37197;&#65292;&#24182;&#23558;&#24369;Oracle&#23398;&#20064;&#32773;&#30340;&#39118;&#38505;&#20316;&#20026;&#33258;&#36866;&#24212;&#23398;&#20064;&#32773;&#39118;&#38505;&#30340;&#19968;&#20010;&#23454;&#38469;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21442;&#25968;&#39044;&#27979;&#35774;&#32622;&#19979;&#30340;&#32479;&#35745;&#29256;&#26412;&#35838;&#31243;&#23398;&#20064;&#65288;CL&#65289;&#12290;&#23398;&#20064;&#32773;&#38656;&#35201;&#20272;&#35745;&#30446;&#26631;&#21442;&#25968;&#21521;&#37327;&#65292;&#24182;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#20174;&#30446;&#26631;&#27169;&#22411;&#25110;&#20854;&#20182;&#31867;&#20284;&#20110;&#30446;&#26631;&#27169;&#22411;&#20294;&#22122;&#22768;&#36739;&#23567;&#30340;&#28304;&#27169;&#22411;&#20013;&#25910;&#38598;&#26679;&#26412;&#12290;&#26681;&#25454;&#20182;&#20204;&#25509;&#25910;&#30340;&#36741;&#21161;&#20449;&#24687;&#27700;&#24179;&#65292;&#25105;&#20204;&#32771;&#34385;&#19977;&#31181;&#31867;&#22411;&#30340;&#23398;&#20064;&#32773;&#12290;&#22312;&#21333;&#19968;&#26469;&#28304;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28120;&#27760;&#23398;&#20064;&#26041;&#27861;&#65292;&#20854;&#39118;&#38505;&#19982;&#24378;-Oracle&#23398;&#20064;&#32773;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#12290;&#22312;&#22810;&#28304;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20027;&#24352;&#24369;-Oracle&#23398;&#20064;&#32773;&#30340;&#39118;&#38505;&#26159;&#33258;&#36866;&#24212;&#23398;&#20064;&#32773;&#39118;&#38505;&#30340;&#19968;&#20010;&#29616;&#23454;&#22522;&#20934;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#22810;&#37325;&#28120;&#27760;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13366v1 Announce Type: new  Abstract: We consider a statistical version of curriculum learning (CL) in a parametric prediction setting. The learner is required to estimate a target parameter vector, and can adaptively collect samples from either the target model, or other source models that are similar to the target model, but less noisy. We consider three types of learners, depending on the level of side-information they receive. The first two, referred to as strong/weak-oracle learners, receive high/low degrees of information about the models, and use these to learn. The third, a fully adaptive learner, estimates the target parameter vector without any prior information. In the single source case, we propose an elimination learning method, whose risk matches that of a strong-oracle learner. In the multiple source case, we advocate that the risk of the weak-oracle learner is a realistic benchmark for the risk of adaptive learners. We develop an adaptive multiple elimination
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992; PAC-Bayes &#29702;&#35770;&#21644; Gibbs &#20998;&#24067;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#26694;&#26550;&#65292;&#21487;&#36866;&#29992;&#20110;&#20219;&#24847;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#20801;&#35768;&#23545;&#27867;&#21270;&#24046;&#36317;&#36827;&#34892;&#23450;&#21046;&#21270;&#35843;&#25972;&#12290;</title><link>https://arxiv.org/abs/2402.13285</link><description>&lt;p&gt;
&#21033;&#29992; PAC-Bayes &#29702;&#35770;&#21644; Gibbs &#20998;&#24067;&#25512;&#23548;&#24102;&#26377;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Leveraging PAC-Bayes Theory and Gibbs Distributions for Generalization Bounds with Complexity Measures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992; PAC-Bayes &#29702;&#35770;&#21644; Gibbs &#20998;&#24067;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#27867;&#21270;&#30028;&#38480;&#26694;&#26550;&#65292;&#21487;&#36866;&#29992;&#20110;&#20219;&#24847;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#20801;&#35768;&#23545;&#27867;&#21270;&#24046;&#36317;&#36827;&#34892;&#23450;&#21046;&#21270;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#27867;&#21270;&#30028;&#38480;&#36890;&#24120;&#28041;&#21450;&#30001;&#32771;&#34385;&#30340;&#29702;&#35770;&#26694;&#26550;&#26045;&#21152;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#12290;&#26412;&#25991;&#21033;&#29992;&#20102;&#20998;&#35299;&#30340; PAC-Bayes &#30028;&#38480;&#26694;&#26550;&#65292;&#25512;&#23548;&#20986;&#19968;&#20010;&#21487;&#23454;&#20363;&#21270;&#20026;&#20219;&#24847;&#22797;&#26434;&#24230;&#24230;&#37327;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#20197;&#27010;&#29575;&#21516;&#26102;&#28085;&#30422;&#20551;&#35774;&#21644;&#23398;&#20064;&#26679;&#26412;&#65292;&#21487;&#20197;&#26681;&#25454;&#27867;&#21270;&#24046;&#36317;&#35843;&#25972;&#22797;&#26434;&#24230;&#65292;&#22240;&#20026;&#23427;&#21487;&#23450;&#21046;&#20197;&#36866;&#24212;&#20551;&#35774;&#31867;&#21644;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13285v1 Announce Type: cross  Abstract: In statistical learning theory, a generalization bound usually involves a complexity measure imposed by the considered theoretical framework. This limits the scope of such bounds, as other forms of capacity measures or regularizations are used in algorithms. In this paper, we leverage the framework of disintegrated PAC-Bayes bounds to derive a general generalization bound instantiable with arbitrary complexity measures. One trick to prove such a result involves considering a commonly used family of distributions: the Gibbs distributions. Our bound stands in probability jointly over the hypothesis and the learning sample, which allows the complexity to be adapted to the generalization gap as it can be customized to fit both the hypothesis class and the task.
&lt;/p&gt;</description></item><item><title>&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30446;&#21069;&#20027;&#35201;&#38598;&#20013;&#22312;&#39044;&#27979;&#20998;&#23376;&#21644;&#26448;&#26009;&#30340;&#30446;&#26631;&#29305;&#24615;&#65292;&#32780;&#23578;&#26410;&#36798;&#21040;&#29983;&#25104;&#33021;&#21147;&#19982;&#20854;&#20182;&#39046;&#22495;&#30340;&#27700;&#24179;&#12290;</title><link>https://arxiv.org/abs/2402.13221</link><description>&lt;p&gt;
CHILI: &#29992;&#20110;&#25512;&#36827;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#21270;&#23398;&#20449;&#24687;&#30340;&#22823;&#22411;&#26080;&#26426;&#32435;&#31859;&#26448;&#26009;&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.13221
&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30446;&#21069;&#20027;&#35201;&#38598;&#20013;&#22312;&#39044;&#27979;&#20998;&#23376;&#21644;&#26448;&#26009;&#30340;&#30446;&#26631;&#29305;&#24615;&#65292;&#32780;&#23578;&#26410;&#36798;&#21040;&#29983;&#25104;&#33021;&#21147;&#19982;&#20854;&#20182;&#39046;&#22495;&#30340;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#36827;&#23637;&#20027;&#35201;&#21463;&#21270;&#23398;&#24212;&#29992;&#30340;&#39537;&#21160;&#65292;&#22240;&#20026;&#22270;&#19968;&#30452;&#26159;&#20998;&#23376;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#34920;&#31034;&#24418;&#24335;&#12290;&#34429;&#28982;&#26089;&#26399;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#23567;&#26377;&#26426;&#20998;&#23376;&#19978;&#65292;&#20294;&#26368;&#36817;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#33539;&#22260;&#24050;&#32463;&#25193;&#23637;&#21040;&#21253;&#25324;&#26080;&#26426;&#26448;&#26009;&#12290;&#24314;&#27169;&#26080;&#26426;&#26230;&#20307;&#26448;&#26009;&#30340;&#21608;&#26399;&#24615;&#21644;&#23545;&#31216;&#24615;&#24102;&#26469;&#29420;&#29305;&#25361;&#25112;&#65292;&#29616;&#26377;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#35299;&#20915;&#12290;&#36716;&#21521;&#26080;&#26426;&#32435;&#31859;&#26448;&#26009;&#20250;&#22686;&#21152;&#22797;&#26434;&#24615;&#65292;&#22240;&#20026;&#27599;&#20010;&#22270;&#20013;&#33410;&#28857;&#25968;&#37327;&#30340;&#33539;&#22260;&#21487;&#33021;&#24456;&#24191;&#65288;$10$&#21040;$10^5$&#65289;&#12290;&#29616;&#26377;&#22270;&#26426;&#22120;&#23398;&#20064;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#36890;&#36807;&#22270;&#20316;&#20026;&#36755;&#20837;&#26469;&#39044;&#27979;&#30446;&#26631;&#29305;&#24615;&#65292;&#26469;&#34920;&#24449;&#20998;&#23376;&#21644;&#26448;&#26009;&#12290;&#20294;&#26159;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#26368;&#28608;&#21160;&#20154;&#24515;&#30340;&#24212;&#29992;&#23558;&#22312;&#20854;&#29983;&#25104;&#33021;&#21147;&#26041;&#38754;&#65292;&#30446;&#21069;&#19982;&#22270;&#20687;&#25110;&#25991;&#26412;&#31561;&#20854;&#20182;&#39046;&#22495;&#36824;&#19981;&#22312;&#21516;&#19968;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.13221v1 Announce Type: new  Abstract: Advances in graph machine learning (ML) have been driven by applications in chemistry as graphs have remained the most expressive representations of molecules. While early graph ML methods focused primarily on small organic molecules, recently, the scope of graph ML has expanded to include inorganic materials. Modelling the periodicity and symmetry of inorganic crystalline materials poses unique challenges, which existing graph ML methods are unable to address. Moving to inorganic nanomaterials increases complexity as the scale of number of nodes within each graph can be broad ($10$ to $10^5$). The bulk of existing graph ML focuses on characterising molecules and materials by predicting target properties with graphs as input. However, the most exciting applications of graph ML will be in their generative capabilities, which is currently not at par with other domains such as images or text.   We invite the graph ML community to address th
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20102;&#21508;&#31181;&#26500;&#36896;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#21019;&#26032;&#24615;&#22320;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#26631;&#24535;&#30528;&#23545;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#20445;&#25345;&#21462;&#24471;&#37325;&#22823;&#36827;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.10232</link><description>&lt;p&gt;
Johnson-Lindenstrauss&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Simple, unified analysis of Johnson-Lindenstrauss with applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10232
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#31616;&#21270;&#21644;&#32479;&#19968;&#20102;&#21508;&#31181;&#26500;&#36896;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#65292;&#36890;&#36807;&#21019;&#26032;&#24615;&#22320;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#26631;&#24535;&#30528;&#23545;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#20445;&#25345;&#21462;&#24471;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#31616;&#21333;&#32479;&#19968;&#20998;&#26512;&#65292;&#36825;&#26159;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#33267;&#20851;&#37325;&#35201;&#30340;&#38477;&#32500;&#39046;&#22495;&#20013;&#30340;&#22522;&#30707;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#31616;&#21270;&#20102;&#29702;&#35299;&#65292;&#36824;&#23558;&#21508;&#31181;&#26500;&#36896;&#32479;&#19968;&#21040;JL&#26694;&#26550;&#19979;&#65292;&#21253;&#25324;&#29699;&#24418;&#12289;&#39640;&#26031;&#12289;&#20108;&#36827;&#21046;&#30828;&#24065;&#21644;&#27425;&#39640;&#26031;&#27169;&#22411;&#12290;&#36825;&#31181;&#31616;&#21270;&#21644;&#32479;&#19968;&#22312;&#20445;&#25345;&#25968;&#25454;&#22266;&#26377;&#20960;&#20309;&#30340;&#37325;&#35201;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#23545;&#20174;&#27969;&#31639;&#27861;&#21040;&#24378;&#21270;&#23398;&#20064;&#31561;&#21508;&#31181;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#36825;&#20010;&#31616;&#21270;&#26694;&#26550;&#20869;&#25552;&#20986;&#20102;&#29699;&#24418;&#26500;&#36896;&#26377;&#25928;&#24615;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#35777;&#26126;&#12290;&#25105;&#20204;&#36129;&#29486;&#30340;&#26680;&#24515;&#26159;&#23558;Hanson-Wright&#19981;&#31561;&#24335;&#25299;&#23637;&#21040;&#39640;&#32500;&#24230;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#24120;&#25968;&#65292;&#36825;&#26631;&#24535;&#30528;&#25991;&#29486;&#20013;&#36136;&#30340;&#39134;&#36291;&#12290;&#36890;&#36807;&#36816;&#29992;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#27010;&#29575;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10232v1 Announce Type: new  Abstract: In this work, we present a simple and unified analysis of the Johnson-Lindenstrauss (JL) lemma, a cornerstone in the field of dimensionality reduction critical for managing high-dimensional data. Our approach not only simplifies the understanding but also unifies various constructions under the JL framework, including spherical, Gaussian, binary coin, and sub-Gaussian models. This simplification and unification make significant strides in preserving the intrinsic geometry of data, essential across diverse applications from streaming algorithms to reinforcement learning. Notably, we deliver the first rigorous proof of the spherical construction's effectiveness within this simplified framework. At the heart of our contribution is an innovative extension of the Hanson-Wright inequality to high dimensions, complete with explicit constants, marking a substantial leap in the literature. By employing simple yet powerful probabilistic tools and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.07588</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;
&lt;/p&gt;
&lt;p&gt;
Rethinking Scaling Laws for Learning in Strategic Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#24605;&#32771;&#20102;&#22312;&#25112;&#30053;&#29615;&#22659;&#20013;&#23398;&#20064;&#30340;&#27604;&#20363;&#23450;&#24459;&#65292;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#35266;&#28857;&#65292;&#21363;&#27169;&#22411;&#36234;&#22823;&#25110;&#34920;&#36798;&#33021;&#21147;&#36234;&#24378;&#24182;&#19981;&#19968;&#23450;&#20250;&#38543;&#20043;&#25552;&#39640;&#24615;&#33021;&#12290;&#36890;&#36807;&#20960;&#20010;&#25112;&#30053;&#29615;&#22659;&#30340;&#20363;&#23376;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36234;&#26469;&#36234;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#37096;&#32626;&#21453;&#26144;&#20986;&#19968;&#20010;&#20849;&#35782;&#65306;&#27169;&#22411;&#36234;&#26377;&#34920;&#36798;&#33021;&#21147;&#65292;&#36234;&#25317;&#26377;&#22823;&#37327;&#25968;&#25454;&#65292;&#23601;&#33021;&#25913;&#21892;&#24615;&#33021;&#12290;&#38543;&#30528;&#27169;&#22411;&#22312;&#21508;&#31181;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#37096;&#32626;&#65292;&#23427;&#20204;&#19981;&#21487;&#36991;&#20813;&#22320;&#38754;&#20020;&#30528;&#25112;&#30053;&#29615;&#22659;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#27169;&#22411;&#19982;&#25112;&#30053;&#20114;&#21160;&#23545;&#27604;&#20363;&#23450;&#24459;&#30340;&#30456;&#20114;&#20316;&#29992;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36825;&#20010;&#33258;&#28982;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#25112;&#30053;&#20114;&#21160;&#21487;&#20197;&#25171;&#30772;&#20256;&#32479;&#30340;&#27604;&#20363;&#23450;&#24459;&#35266;&#28857;&#65292;&#21363;&#24615;&#33021;&#24182;&#19981;&#19968;&#23450;&#38543;&#30528;&#27169;&#22411;&#30340;&#25193;&#22823;&#21644;/&#25110;&#34920;&#36798;&#33021;&#21147;&#30340;&#22686;&#24378;&#65288;&#21363;&#20351;&#26377;&#26080;&#38480;&#25968;&#25454;&#65289;&#32780;&#21333;&#35843;&#25552;&#39640;&#12290;&#25105;&#20204;&#36890;&#36807;&#25112;&#30053;&#22238;&#24402;&#12289;&#25112;&#30053;&#20998;&#31867;&#21644;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#20363;&#23376;&#23637;&#31034;&#20102;&#36825;&#19968;&#29616;&#35937;&#30340;&#24433;&#21709;&#65292;&#36825;&#20123;&#20363;&#23376;&#23637;&#31034;&#20102;&#25112;&#30053;&#29615;&#22659;&#20013;&#30340;&#38480;&#21046;&#27169;&#22411;&#25110;&#31574;&#30053;&#31867;&#30340;&#34920;&#36798;&#33021;&#21147;&#21363;&#21487;&#12290;
&lt;/p&gt;
&lt;p&gt;
The deployment of ever-larger machine learning models reflects a growing consensus that the more expressive the model$\unicode{x2013}$and the more data one has access to$\unicode{x2013}$the more one can improve performance. As models get deployed in a variety of real world scenarios, they inevitably face strategic environments. In this work, we consider the natural question of how the interplay of models and strategic interactions affects scaling laws. We find that strategic interactions can break the conventional view of scaling laws$\unicode{x2013}$meaning that performance does not necessarily monotonically improve as models get larger and/ or more expressive (even with infinite data). We show the implications of this phenomenon in several contexts including strategic regression, strategic classification, and multi-agent reinforcement learning through examples of strategic environments in which$\unicode{x2013}$by simply restricting the expressivity of one's model or policy class$\uni
&lt;/p&gt;</description></item><item><title>&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#21487;&#33719;&#24471;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#65292;&#19982;&#26410;&#32463;&#38408;&#20540;&#22788;&#29702;&#30340;Oja&#21521;&#37327;&#30456;&#27604;&#65292;&#36825;&#22823;&#22823;&#20943;&#23567;&#20102;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2402.07240</link><description>&lt;p&gt;
&#38408;&#20540;Oja&#26159;&#21542;&#36866;&#29992;&#20110;&#31232;&#30095;PCA&#65311;
&lt;/p&gt;
&lt;p&gt;
Thresholded Oja does Sparse PCA?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07240
&lt;/p&gt;
&lt;p&gt;
&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#21487;&#33719;&#24471;&#19968;&#20010;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#65292;&#19982;&#26410;&#32463;&#38408;&#20540;&#22788;&#29702;&#30340;Oja&#21521;&#37327;&#30456;&#27604;&#65292;&#36825;&#22823;&#22823;&#20943;&#23567;&#20102;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#24403;&#27604;&#20540;$d/n \rightarrow c &gt; 0$&#26102;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#38382;&#39064;&#12290;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#65292;&#20851;&#20110;&#31232;&#30095;PCA&#30340;&#26368;&#20248;&#29575;&#24050;&#32463;&#26377;&#24456;&#22810;&#30740;&#31350;&#65292;&#20854;&#20013;&#25152;&#26377;&#25968;&#25454;&#37117;&#21487;&#20197;&#29992;&#20110;&#22810;&#27425;&#20256;&#36882;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#24403;&#20154;&#21475;&#29305;&#24449;&#21521;&#37327;&#26159;$s$-&#31232;&#30095;&#26102;&#65292;&#20855;&#26377;$O(d)$&#23384;&#20648;&#21644;$O(nd)$&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#27969;&#31639;&#27861;&#36890;&#24120;&#35201;&#27714;&#24378;&#21021;&#22987;&#21270;&#26465;&#20214;&#65292;&#21542;&#21017;&#20250;&#26377;&#27425;&#20248;&#38169;&#35823;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#23545;Oja&#31639;&#27861;&#30340;&#36755;&#20986;&#65288;Oja&#21521;&#37327;&#65289;&#36827;&#34892;&#38408;&#20540;&#21644;&#37325;&#26032;&#24402;&#19968;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#25509;&#36817;&#26368;&#20248;&#30340;&#38169;&#35823;&#29575;&#12290;&#36825;&#38750;&#24120;&#20196;&#20154;&#24778;&#35766;&#65292;&#22240;&#20026;&#27809;&#26377;&#38408;&#20540;&#65292;Oja&#21521;&#37327;&#30340;&#35823;&#24046;&#24456;&#22823;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#38598;&#20013;&#22312;&#38480;&#21046;&#26410;&#24402;&#19968;&#21270;&#30340;Oja&#21521;&#37327;&#30340;&#39033;&#19978;&#65292;&#36825;&#28041;&#21450;&#23558;&#19968;&#32452;&#29420;&#31435;&#38543;&#26426;&#30697;&#38453;&#30340;&#20056;&#31215;&#22312;&#38543;&#26426;&#21021;&#22987;&#21521;&#37327;&#19978;&#30340;&#25237;&#24433;&#12290; &#36825;&#26159;&#38750;&#24179;&#20961;&#19988;&#26032;&#39062;&#30340;&#65292;&#22240;&#20026;&#20197;&#21069;&#30340;Oja&#31639;&#27861;&#20998;&#26512;&#27809;&#26377;&#32771;&#34385;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.07240v2 Announce Type: cross  Abstract: We consider the problem of Sparse Principal Component Analysis (PCA) when the ratio $d/n \rightarrow c &gt; 0$. There has been a lot of work on optimal rates on sparse PCA in the offline setting, where all the data is available for multiple passes. In contrast, when the population eigenvector is $s$-sparse, streaming algorithms that have $O(d)$ storage and $O(nd)$ time complexity either typically require strong initialization conditions or have a suboptimal error. We show that a simple algorithm that thresholds and renormalizes the output of Oja's algorithm (the Oja vector) obtains a near-optimal error rate. This is very surprising because, without thresholding, the Oja vector has a large error. Our analysis centers around bounding the entries of the unnormalized Oja vector, which involves the projection of a product of independent random matrices on a random initial vector. This is nontrivial and novel since previous analyses of Oja's al
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26368;&#36817;&#27169;&#20223;&#23398;&#20064;&#21644;&#20445;&#23432;RL&#31639;&#27861;&#36827;&#23637;&#21551;&#21457;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#36716;&#31227;&#36807;&#31243;&#20013;&#24341;&#20837;&#24809;&#32602;&#26469;&#35843;&#33410;&#28304;&#35757;&#32451;&#31574;&#30053;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;</title><link>https://arxiv.org/abs/2312.15474</link><description>&lt;p&gt;
&#22312;&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#36716;&#31227;&#30340;&#20445;&#23432;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Conservative Approach for Few-Shot Transfer in Off-Dynamics Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.15474
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26368;&#36817;&#27169;&#20223;&#23398;&#20064;&#21644;&#20445;&#23432;RL&#31639;&#27861;&#36827;&#23637;&#21551;&#21457;&#30340;&#21019;&#26032;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#36716;&#31227;&#36807;&#31243;&#20013;&#24341;&#20837;&#24809;&#32602;&#26469;&#35843;&#33410;&#28304;&#35757;&#32451;&#31574;&#30053;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#21160;&#21147;&#23398;&#24378;&#21270;&#23398;&#20064;&#65288;ODRL&#65289;&#26088;&#22312;&#23558;&#31574;&#30053;&#20174;&#28304;&#29615;&#22659;&#36716;&#31227;&#21040;&#20855;&#26377;&#19981;&#21516;&#20294;&#30456;&#20284;&#21160;&#21147;&#23398;&#29305;&#24449;&#30340;&#30446;&#26631;&#29615;&#22659;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20256;&#32479;RL&#20195;&#29702;&#36807;&#24230;&#20381;&#36182;&#28304;&#29615;&#22659;&#30340;&#21160;&#21147;&#23398;&#65292;&#23548;&#33268;&#21457;&#29616;&#22312;&#35813;&#29615;&#22659;&#20013;&#34920;&#29616;&#21331;&#36234;&#30340;&#31574;&#30053;&#65292;&#20294;&#22312;&#30446;&#26631;&#29615;&#22659;&#20013;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#23569;&#26679;&#26412;&#26694;&#26550;&#20013;&#65292;&#24341;&#20837;&#20102;&#26469;&#33258;&#30446;&#26631;&#29615;&#22659;&#30340;&#26377;&#38480;&#25968;&#37327;&#36716;&#25442;&#20197;&#20419;&#36827;&#26356;&#26377;&#25928;&#30340;&#36716;&#31227;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21463;&#26368;&#36817;&#27169;&#20223;&#23398;&#20064;&#21644;&#20445;&#23432;RL&#31639;&#27861;&#36827;&#23637;&#21551;&#21457;&#30340;&#21019;&#26032;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#24809;&#32602;&#26469;&#35843;&#33410;&#28304;&#35757;&#32451;&#31574;&#30053;&#29983;&#25104;&#30340;&#36712;&#36857;&#12290;&#25105;&#20204;&#22312;&#20195;&#34920;&#19981;&#21516;&#31163;&#32447;&#21160;&#21147;&#23398;&#26465;&#20214;&#30340;&#21508;&#31181;&#29615;&#22659;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#22312;&#36825;&#20123;&#29615;&#22659;&#20013;&#35775;&#38382;&#30446;&#26631;&#29615;&#22659;&#26159;&#26497;&#31471;&#22256;&#38590;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.15474v2 Announce Type: replace  Abstract: Off-dynamics Reinforcement Learning (ODRL) seeks to transfer a policy from a source environment to a target environment characterized by distinct yet similar dynamics. In this context, traditional RL agents depend excessively on the dynamics of the source environment, resulting in the discovery of policies that excel in this environment but fail to provide reasonable performance in the target one. In the few-shot framework, a limited number of transitions from the target environment are introduced to facilitate a more effective transfer. Addressing this challenge, we propose an innovative approach inspired by recent advancements in Imitation Learning and conservative RL algorithms. The proposed method introduces a penalty to regulate the trajectories generated by the source-trained policy. We evaluate our method across various environments representing diverse off-dynamics conditions, where access to the target environment is extreme
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25551;&#36848;&#24615;&#20998;&#26512;&#20559;&#24207;&#38598;&#21512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25913;&#36827;&#30340;&#26080;&#20132;&#24182;&#27867;&#28145;&#24230; (ufg) &#27604;&#36739;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#22312;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#25552;&#20379;&#20102;&#31034;&#20363;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#22522;&#20110;ufg&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#26377;&#24456;&#22823;&#21306;&#21035;&#12290;</title><link>https://arxiv.org/abs/2312.12839</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#20132;&#24182;&#30340;&#27867;&#28145;&#24230;&#27604;&#36739;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Comparing Machine Learning Algorithms by Union-Free Generic Depth
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25551;&#36848;&#24615;&#20998;&#26512;&#20559;&#24207;&#38598;&#21512;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#25913;&#36827;&#30340;&#26080;&#20132;&#24182;&#27867;&#28145;&#24230; (ufg) &#27604;&#36739;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#22312;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#25552;&#20379;&#20102;&#31034;&#20363;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#22522;&#20110;ufg&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#26377;&#24456;&#22823;&#21306;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#20989;&#25968;&#27010;&#24565;&#30340;&#25551;&#36848;&#24615;&#20998;&#26512;&#20559;&#24207;&#38598;&#21512;&#30340;&#26694;&#26550;&#12290;&#23613;&#31649;&#32447;&#24615;&#31354;&#38388;&#21644;&#24230;&#37327;&#31354;&#38388;&#30340;&#30740;&#31350;&#38750;&#24120;&#28145;&#20837;&#65292;&#20294;&#20851;&#20110;&#20559;&#24207;&#38598;&#21512;&#31561;&#38750;&#26631;&#20934;&#25968;&#25454;&#31867;&#22411;&#30340;&#28145;&#24230;&#20989;&#25968;&#30340;&#35752;&#35770;&#20960;&#20046;&#27809;&#26377;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25152;&#26377;&#20559;&#24207;&#38598;&#21512;&#30340;&#33879;&#21517;&#31616;&#21333;&#28145;&#24230;&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#26080;&#20132;&#24182;&#27867;&#28145;&#24230; (ufg)&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;ufg&#28145;&#24230;&#26469;&#27604;&#36739;&#22522;&#20110;&#22810;&#32500;&#24615;&#33021;&#25351;&#26631;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#31034;&#20363;&#65292;&#23545;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#30340;&#20998;&#31867;&#22120;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26377;&#24076;&#26395;&#22320;&#23637;&#31034;&#20102;&#22522;&#20110;ufg&#26041;&#27861;&#30340;&#19981;&#21516;&#20998;&#26512;&#26041;&#27861;&#30340;&#24191;&#27867;&#22810;&#26679;&#24615;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#31034;&#20363;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#27979;&#35797;&#26041;&#27861;&#26377;&#24456;&#22823;&#21306;&#21035;&#65292;&#22240;&#27492;&#20026;&#20998;&#31867;&#22120;&#27604;&#36739;&#30340;&#28909;&#28872;&#35752;&#35770;&#22686;&#28155;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a framework for descriptively analyzing sets of partial orders based on the concept of depth functions. Despite intensive studies in linear and metric spaces, there is very little discussion on depth functions for non-standard data types such as partial orders. We introduce an adaptation of the well-known simplicial depth to the set of all partial orders, the union-free generic (ufg) depth. Moreover, we utilize our ufg depth for a comparison of machine learning algorithms based on multidimensional performance measures. Concretely, we provide two examples of classifier comparisons on samples of standard benchmark data sets. Our results demonstrate promisingly the wide variety of different analysis approaches based on ufg methods. Furthermore, the examples outline that our approach differs substantially from existing benchmarking approaches, and thus adds a new perspective to the vivid debate on classifier comparison.
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#38543;&#26426;&#35797;&#39564;&#35774;&#35745;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#65292;&#33021;&#22815;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24378;&#24230;&#65292;&#24182;&#20272;&#35745;&#20854;&#19979;&#30028;&#65292;&#26377;&#25928;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#35782;&#21035;&#28151;&#28102;&#12290;</title><link>https://arxiv.org/abs/2312.03871</link><description>&lt;p&gt;
&#38544;&#34109;&#32780;&#21487;&#37327;&#21270;&#65306;&#20351;&#29992;&#38543;&#26426;&#35797;&#39564;&#30340;&#28151;&#28102;&#24378;&#24230;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Hidden yet quantifiable: A lower bound for confounding strength using randomized trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03871
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#38543;&#26426;&#35797;&#39564;&#35774;&#35745;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#65292;&#33021;&#22815;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24378;&#24230;&#65292;&#24182;&#20272;&#35745;&#20854;&#19979;&#30028;&#65292;&#26377;&#25928;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#35782;&#21035;&#28151;&#28102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24555;&#33410;&#22863;&#31934;&#20934;&#21307;&#23398;&#26102;&#20195;&#65292;&#35266;&#23519;&#24615;&#30740;&#31350;&#22312;&#27491;&#30830;&#35780;&#20272;&#20020;&#24202;&#23454;&#36341;&#20013;&#26032;&#30103;&#27861;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21487;&#33021;&#20005;&#37325;&#25439;&#23475;&#20174;&#38750;&#38543;&#26426;&#25968;&#25454;&#20013;&#24471;&#20986;&#30340;&#22240;&#26524;&#32467;&#35770;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#35797;&#39564;&#26469;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#26032;&#31574;&#30053;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#26816;&#27979;&#24378;&#24230;&#36229;&#36807;&#32473;&#23450;&#38408;&#20540;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#35813;&#26816;&#39564;&#26469;&#20272;&#35745;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24378;&#24230;&#30340;&#28176;&#36817;&#26377;&#25928;&#19979;&#30028;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#21151;&#25928;&#21644;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#19979;&#30028;&#22914;&#20309;&#33021;&#22815;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#27491;&#30830;&#35782;&#21035;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#23384;&#22312;&#21644;&#19981;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03871v2 Announce Type: replace-cross  Abstract: In the era of fast-paced precision medicine, observational studies play a major role in properly evaluating new treatments in clinical practice. Yet, unobserved confounding can significantly compromise causal conclusions drawn from non-randomized data. We propose a novel strategy that leverages randomized trials to quantify unobserved confounding. First, we design a statistical test to detect unobserved confounding with strength above a given threshold. Then, we use the test to estimate an asymptotically valid lower bound on the unobserved confounding strength. We evaluate the power and validity of our statistical test on several synthetic and semi-synthetic datasets. Further, we show how our lower bound can correctly identify the absence and presence of unobserved confounding in a real-world setting.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Tree of Attacks with Pruning (TAP)&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21482;&#38656;&#35201;&#23545;&#30446;&#26631;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#40657;&#30418;&#35775;&#38382;&#30340;&#36234;&#29425;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24605;&#32500;&#26641;&#25512;&#29702;&#21644;&#20462;&#21098;&#29983;&#25104;&#20934;&#30830;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;</title><link>https://arxiv.org/abs/2312.02119</link><description>&lt;p&gt;
&#25915;&#20987;&#26641;&#65306;&#33258;&#21160;&#30772;&#35299;&#40657;&#30418;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tree of Attacks: Jailbreaking Black-Box LLMs Automatically
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02119
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Tree of Attacks with Pruning (TAP)&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21482;&#38656;&#35201;&#23545;&#30446;&#26631;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#40657;&#30418;&#35775;&#38382;&#30340;&#36234;&#29425;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24605;&#32500;&#26641;&#25512;&#29702;&#21644;&#20462;&#21098;&#29983;&#25104;&#20934;&#30830;&#30340;&#36234;&#29425;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#23637;&#31034;&#20102;&#22810;&#21151;&#33021;&#24615;&#65292;&#20294;&#20173;&#22312;&#29983;&#25104;&#26377;&#23475;&#12289;&#24102;&#20559;&#35265;&#21644;&#26377;&#27602;&#20869;&#23481;&#65292;&#36825;&#19968;&#28857;&#30001;&#20154;&#20026;&#35774;&#35745;&#30340;&#36234;&#29425;&#34892;&#20026;&#30340;&#26222;&#36941;&#23384;&#22312;&#24471;&#20197;&#35777;&#26126;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Tree of Attacks with Pruning (TAP)&#30340;&#33258;&#21160;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#36234;&#29425;&#65292;&#20165;&#38656;&#35201;&#23545;&#30446;&#26631;LLM&#36827;&#34892;&#40657;&#30418;&#35775;&#38382;&#12290;TAP&#21033;&#29992;LLM&#26469;&#36890;&#36807;&#24605;&#32500;&#26641;&#25512;&#29702;&#36845;&#20195;&#22320;&#20248;&#21270;&#20505;&#36873;&#65288;&#25915;&#20987;&#65289;&#25552;&#31034;&#65292;&#30452;&#21040;&#29983;&#25104;&#30340;&#25552;&#31034;&#20043;&#19968;&#36234;&#29425;&#30446;&#26631;&#12290;&#20851;&#38190;&#22312;&#20110;&#65292;&#22312;&#23558;&#25552;&#31034;&#21457;&#36865;&#32473;&#30446;&#26631;&#20043;&#21069;&#65292;TAP&#23545;&#20854;&#36827;&#34892;&#35780;&#20272;&#24182;&#31227;&#38500;&#21487;&#33021;&#19981;&#20250;&#23548;&#33268;&#36234;&#29425;&#30340;&#25552;&#31034;&#12290;&#20351;&#29992;&#24605;&#32500;&#26641;&#25512;&#29702;&#20351;TAP&#33021;&#22815;&#22312;&#22823;&#37327;&#25552;&#31034;&#30340;&#25628;&#32034;&#31354;&#38388;&#20013;&#23548;&#33322;&#65292;&#32780;&#20462;&#21098;&#21017;&#20943;&#23569;&#20102;&#21457;&#36865;&#32473;&#30446;&#26631;&#30340;&#24635;&#26597;&#35810;&#25968;&#37327;&#12290;&#22312;&#23454;&#35777;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;TAP&#29983;&#25104;&#30340;&#25552;&#31034;&#36234;&#29425;&#20102;&#36229;&#36807;80%&#30340;&#26368;&#20808;&#36827;LLMs&#65288;&#21253;&#25324;GPT4&#21644;GPT4-Turbo&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02119v2 Announce Type: replace-cross  Abstract: While Large Language Models (LLMs) display versatile functionality, they continue to generate harmful, biased, and toxic content, as demonstrated by the prevalence of human-designed jailbreaks. In this work, we present Tree of Attacks with Pruning (TAP), an automated method for generating jailbreaks that only requires black-box access to the target LLM. TAP utilizes an LLM to iteratively refine candidate (attack) prompts using tree-of-thought reasoning until one of the generated prompts jailbreaks the target. Crucially, before sending prompts to the target, TAP assesses them and prunes the ones unlikely to result in jailbreaks. Using tree-of-thought reasoning allows TAP to navigate a large search space of prompts and pruning reduces the total number of queries sent to the target. In empirical evaluations, we observe that TAP generates prompts that jailbreak state-of-the-art LLMs (including GPT4 and GPT4-Turbo) for more than 80%
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#37325;&#21472;&#20998;&#32452; lasso &#30340;&#38750;&#37325;&#21472;&#32479;&#35745;&#36924;&#36817;&#26041;&#27861;&#65292;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#20026;&#29616;&#20195;&#38382;&#39064;&#30340;&#24212;&#29992;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>https://arxiv.org/abs/2211.09221</link><description>&lt;p&gt;
&#38024;&#23545;&#37325;&#21472;&#20998;&#32452; lasso &#30340;&#38750;&#37325;&#21472;&#32479;&#35745;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
The non-overlapping statistical approximation to overlapping group lasso
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.09221
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#37325;&#21472;&#20998;&#32452; lasso &#30340;&#38750;&#37325;&#21472;&#32479;&#35745;&#36924;&#36817;&#26041;&#27861;&#65292;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#20013;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#20026;&#29616;&#20195;&#38382;&#39064;&#30340;&#24212;&#29992;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452; lasso &#26159;&#32479;&#35745;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#26681;&#25454;&#39044;&#23450;&#20041;&#30340;&#32452;&#20174;&#27169;&#22411;&#20013;&#28040;&#38500;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#24403;&#36825;&#20123;&#32452;&#37325;&#21472;&#26102;&#65292;&#30001;&#20110;&#37325;&#21472;&#32452;&#24341;&#36215;&#30340;&#19981;&#21487;&#20998;&#24615;&#65292;&#20248;&#21270;&#32452; lasso &#24809;&#32602;&#30446;&#26631;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#19978;&#21487;&#33021;&#20250;&#21464;&#24471;&#32791;&#26102;&#65292;&#36825;&#19968;&#29942;&#39048;&#20005;&#37325;&#38480;&#21046;&#20102;&#37325;&#21472;&#20998;&#32452; lasso &#27491;&#21017;&#21270;&#22312;&#35768;&#22810;&#29616;&#20195;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#27604;&#22914;&#22522;&#22240;&#36890;&#36335;&#36873;&#25321;&#21644;&#22270;&#27169;&#22411;&#20272;&#35745;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20998;&#30340;&#24809;&#32602;&#20316;&#20026;&#37325;&#21472;&#20998;&#32452; lasso &#24809;&#32602;&#30340;&#36924;&#36817;&#12290;&#30001;&#20110;&#21487;&#20998;&#24615;&#65292;&#22522;&#20110;&#25105;&#20204;&#30340;&#24809;&#32602;&#30340;&#27491;&#21017;&#21270;&#35745;&#31639;&#30456;&#23545;&#20110;&#37325;&#21472;&#20998;&#32452; lasso &#35201;&#24555;&#24471;&#22810;&#65292;&#23588;&#20854;&#23545;&#20110;&#22823;&#35268;&#27169;&#21644;&#39640;&#32500;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#24809;&#32602;&#26159;&#37325;&#21472;&#32452; lasso &#30340;&#26368;&#20005;&#26684;&#30340;&#21487;&#20998;&#26494;&#24347;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.09221v3 Announce Type: replace-cross  Abstract: Group lasso is a commonly used regularization method in statistical learning in which parameters are eliminated from the model according to predefined groups. However, when the groups overlap, optimizing the group lasso penalized objective can be time-consuming on large-scale problems because of the non-separability induced by the overlapping groups. This bottleneck has seriously limited the application of overlapping group lasso regularization in many modern problems, such as gene pathway selection and graphical model estimation. In this paper, we propose a separable penalty as an approximation of the overlapping group lasso penalty. Thanks to the separability, the computation of regularization based on our penalty is substantially faster than that of the overlapping group lasso, especially for large-scale and high-dimensional problems. We show that the penalty is the tightest separable relaxation of the overlapping group lass
&lt;/p&gt;</description></item><item><title>&#35780;&#20272;&#30456;&#20284;&#24230;&#35780;&#20998;&#20989;&#25968;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#36136;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;ROC&#26354;&#32447;&#65292;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#30830;&#35780;&#20272;&#19982;ROC&#26354;&#32447;&#30456;&#20851;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#38754;&#37096;&#35782;&#21035;&#31561;&#20855;&#26377;&#31038;&#20250;&#24433;&#21709;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2211.07245</link><description>&lt;p&gt;
&#35780;&#20272;&#30456;&#20284;&#24230;&#35780;&#20998;&#30340;&#19981;&#30830;&#23450;&#24615;&#65306;&#38754;&#37096;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#19982;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Assessing Uncertainty in Similarity Scoring: Performance &amp; Fairness in Face Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.07245
&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#30456;&#20284;&#24230;&#35780;&#20998;&#20989;&#25968;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#36136;&#30340;&#20851;&#38190;&#24037;&#20855;&#26159;ROC&#26354;&#32447;&#65292;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#30830;&#35780;&#20272;&#19982;ROC&#26354;&#32447;&#30456;&#20851;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#38754;&#37096;&#35782;&#21035;&#31561;&#20855;&#26377;&#31038;&#20250;&#24433;&#21709;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ROC&#26354;&#32447;&#26159;&#35780;&#20272;&#30456;&#20284;&#24230;&#35780;&#20998;&#20989;&#25968;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#36136;&#30340;&#20027;&#35201;&#24037;&#20855;&#12290;&#20026;&#20102;&#22522;&#20110;&#32463;&#39564;ROC&#20998;&#26512;&#24471;&#20986;&#21487;&#38752;&#32467;&#35770;&#65292;&#20934;&#30830;&#35780;&#20272;&#19982;&#24863;&#20852;&#36259;&#30340;ROC&#26354;&#32447;&#30340;&#32479;&#35745;&#29256;&#26412;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#26159;&#32477;&#23545;&#24517;&#35201;&#30340;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#20855;&#26377;&#37325;&#35201;&#31038;&#20250;&#24433;&#21709;&#30340;&#24212;&#29992;&#65292;&#22914;&#38754;&#37096;&#35782;&#21035;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30456;&#20284;&#24615;&#20989;&#25968;&#30340;&#32463;&#39564;ROC&#26354;&#32447;&#20197;&#21450;&#29992;&#20110;&#35780;&#20272;&#20844;&#24179;&#24615;&#30340;&#21103;&#20135;&#21697;&#25351;&#26631;&#30340;&#28176;&#36817;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#35299;&#37322;&#65292;&#30001;&#20110;&#22312;&#30456;&#20284;&#24230;&#35780;&#20998;&#24773;&#20917;&#19979;&#65292;&#35823;&#25509;&#21463;/&#25298;&#32477;&#29575;&#30340;&#24418;&#24335;&#20026;U-&#32479;&#35745;&#37327;&#65292;&#25152;&#20197;&#22825;&#30495;&#30340;&#33258;&#21161;&#27861;&#21487;&#33021;&#20250;&#21361;&#21450;&#35780;&#20272;&#36807;&#31243;&#12290;&#24517;&#39035;&#20351;&#29992;&#19987;&#38376;&#30340;&#37325;&#26032;&#23621;&#20013;&#25216;&#26415;&#12290;&#38500;&#36827;&#34892;&#30340;&#29702;&#35770;&#20998;&#26512;&#22806;&#65292;&#36824;&#20351;&#29992;&#30495;&#23454;&#20154;&#33080;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#21508;&#31181;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.07245v2 Announce Type: replace-cross  Abstract: The ROC curve is the major tool for assessing not only the performance but also the fairness properties of a similarity scoring function. In order to draw reliable conclusions based on empirical ROC analysis, accurately evaluating the uncertainty level related to statistical versions of the ROC curves of interest is absolutely necessary, especially for applications with considerable societal impact such as Face Recognition. In this article, we prove asymptotic guarantees for empirical ROC curves of similarity functions as well as for by-product metrics useful to assess fairness. We also explain that, because the false acceptance/rejection rates are of the form of U-statistics in the case of similarity scoring, the naive bootstrap approach may jeopardize the assessment procedure. A dedicated recentering technique must be used instead. Beyond the theoretical analysis carried out, various experiments using real face image datasets
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#39640;&#32500;&#38382;&#39064;&#26144;&#23556;&#21040;&#29699;&#38754;&#19978;&#30340;&#31435;&#20307;&#25237;&#24433;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#32500;&#20998;&#24067;&#20013;&#30340;&#28151;&#21512;&#38382;&#39064;&#65292;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;</title><link>https://arxiv.org/abs/2205.12112</link><description>&lt;p&gt;
&#31435;&#20307;&#25237;&#24433;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Stereographic Markov Chain Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.12112
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#39640;&#32500;&#38382;&#39064;&#26144;&#23556;&#21040;&#29699;&#38754;&#19978;&#30340;&#31435;&#20307;&#25237;&#24433;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#39640;&#32500;&#20998;&#24067;&#20013;&#30340;&#28151;&#21512;&#38382;&#39064;&#65292;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#20998;&#24067;&#65292;&#23588;&#20854;&#26159;&#37027;&#20123;&#20855;&#26377;&#37325;&#23614;&#20998;&#24067;&#30340;&#38382;&#39064;&#65292;&#23545;&#20110;&#29616;&#25104;&#30340;MCMC&#25277;&#26679;&#22120;&#26469;&#35828;&#26497;&#20855;&#25361;&#25112;&#24615;&#65306;&#26080;&#30028;&#29366;&#24577;&#31354;&#38388;&#12289;&#36880;&#28176;&#20943;&#24369;&#30340;&#26799;&#24230;&#20449;&#24687;&#21644;&#23616;&#37096;&#31227;&#21160;&#23548;&#33268;&#20102;&#8220;&#31896;&#28382;&#8221;&#29616;&#35937;&#21644;&#24046;&#21170;&#30340;&#29702;&#35770;&#28151;&#21512;&#29305;&#24615;&#8212;&#8212;&#20960;&#20309;&#36941;&#21382;&#19981;&#25910;&#25947;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#26032;&#30340;MCMC&#25277;&#26679;&#22120;&#65292;&#23558;&#21407;&#39640;&#32500;&#38382;&#39064;&#26144;&#23556;&#21040;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#30340;&#29699;&#38754;&#19978;&#65292;&#24182;&#32416;&#27491;&#20102;&#36825;&#20123;&#19981;&#26131;&#28151;&#21512;&#30340;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#38543;&#26426;&#34892;&#36208;Metropolis&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#20197;&#21450;Bouncy Particle&#21462;&#26679;&#22120;&#30340;&#29256;&#26412;&#65292;&#23545;&#19968;&#31867;&#36731;&#23614;&#21644;&#37325;&#23614;&#20998;&#24067;&#20855;&#26377;&#19968;&#33268;&#36941;&#21382;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#24230;&#20013;&#34920;&#29616;&#20986;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;&#22312;&#26368;&#20339;&#24773;&#20917;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#21462;&#26679;&#22120;&#21487;&#20197;&#22312;&#26356;&#39640;&#32500;&#24230;&#20013;&#33719;&#24471;&#8220;&#32500;&#24230;&#31069;&#31119;&#8221;&#65292;&#21363;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2205.12112v2 Announce Type: replace-cross  Abstract: High-dimensional distributions, especially those with heavy tails, are notoriously difficult for off-the-shelf MCMC samplers: the combination of unbounded state spaces, diminishing gradient information, and local moves results in empirically observed ``stickiness'' and poor theoretical mixing properties -- lack of geometric ergodicity. In this paper, we introduce a new class of MCMC samplers that map the original high-dimensional problem in Euclidean space onto a sphere and remedy these notorious mixing problems. In particular, we develop random-walk Metropolis type algorithms as well as versions of the Bouncy Particle Sampler that are uniformly ergodic for a large class of light and heavy-tailed distributions and also empirically exhibit rapid convergence in high dimensions. In the best scenario, the proposed samplers can enjoy the ``blessings of dimensionality'' that the convergence is faster in higher dimensions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#20123;&#19981;&#31561;&#24335;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#25104;&#31435;&#65292;&#22312;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15567</link><description>&lt;p&gt;
&#30697;&#38453;&#36229;&#38789;&#21644;&#38543;&#26426;&#30697;&#38453;&#38598;&#20013;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Matrix Supermartingales and Randomized Matrix Concentration Inequalities. (arXiv:2401.15567v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#20123;&#19981;&#31561;&#24335;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#25104;&#31435;&#65292;&#22312;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;&#20999;&#23572;&#35834;&#22827;&#19978;&#30028;&#21644;&#33258;&#24402;&#19968;&#21270;&#37325;&#23614;&#35774;&#32622;&#12290;&#36825;&#20123;&#19981;&#31561;&#24335;&#36890;&#24120;&#20197;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#25104;&#31435;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#30697;&#38453;&#36229;&#38789;&#21644;&#26497;&#20540;&#19981;&#31561;&#24335;&#30340;&#29702;&#35770;&#65292;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present new concentration inequalities for either martingale dependent or exchangeable random symmetric matrices under a variety of tail conditions, encompassing standard Chernoff bounds to self-normalized heavy-tailed settings. These inequalities are often randomized in a way that renders them strictly tighter than existing deterministic results in the literature, are typically expressed in the Loewner order, and are sometimes valid at arbitrary data-dependent stopping times.  Along the way, we explore the theory of matrix supermartingales and maximal inequalities, potentially of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.14593</link><description>&lt;p&gt;
&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#31283;&#20581;&#20272;&#35745;Pareto&#30340;&#23610;&#24230;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Robust Estimation of Pareto's Scale Parameter from Grouped Data. (arXiv:2401.14593v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65288;MTuM&#65289;&#65292;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20013;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;&#20854;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21487;&#33719;&#21462;&#30340;&#23436;&#20840;&#35266;&#27979;&#21040;&#30340;&#20174;&#22836;&#33267;&#23614;&#30340;&#25439;&#22833;&#20005;&#37325;&#24615;&#26679;&#26412;&#25968;&#25454;&#38598;&#23384;&#22312;&#26102;&#65292;&#23384;&#22312;&#35768;&#22810;&#31283;&#20581;&#20272;&#35745;&#22120;&#20316;&#20026;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65288;MLE&#65289;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#20998;&#32452;&#25439;&#22833;&#20005;&#37325;&#24615;&#25968;&#25454;&#26102;&#65292;&#31283;&#20581;&#30340;MLE&#26367;&#20195;&#26041;&#26696;&#30340;&#36873;&#25321;&#21464;&#24471;&#38750;&#24120;&#26377;&#38480;&#65292;&#21482;&#26377;&#23569;&#25968;&#26041;&#27861;&#21487;&#29992;&#65292;&#20363;&#22914;&#26368;&#23567;&#20108;&#20056;&#27861;&#12289;&#26368;&#23567;Hellinger&#36317;&#31163;&#21644;&#26368;&#20248;&#26377;&#30028;&#24433;&#21709;&#20989;&#25968;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#25130;&#26029;&#30697;&#27861;&#30340;&#26032;&#22411;&#31283;&#20581;&#20272;&#35745;&#25216;&#26415;&#65292;&#35813;&#26041;&#27861;&#19987;&#38376;&#29992;&#20110;&#20174;&#20998;&#32452;&#25968;&#25454;&#20272;&#35745;Pareto&#20998;&#24067;&#30340;&#23614;&#25351;&#25968;&#12290;&#36890;&#36807;&#24212;&#29992;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#39564;&#35777;&#20102;MTuM&#30340;&#25512;&#29702;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous robust estimators exist as alternatives to the maximum likelihood estimator (MLE) when a completely observed ground-up loss severity sample dataset is available. However, the options for robust alternatives to MLE become significantly limited when dealing with grouped loss severity data, with only a handful of methods like least squares, minimum Hellinger distance, and optimal bounded influence function available. This paper introduces a novel robust estimation technique, the Method of Truncated Moments (MTuM), specifically designed to estimate the tail index of a Pareto distribution from grouped data. Inferential justification of MTuM is established by employing the central limit theorem and validating them through a comprehensive simulation study.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#35757;&#32451;&#38598;&#32500;&#24230;&#26377;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35748;&#20026;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;&#21487;&#33021;&#26159;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#26174;&#33879;&#24046;&#24322;&#30340;&#37096;&#20998;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2401.08865</link><description>&lt;p&gt;
Intrinsic Dataset Properties&#23545;&#27867;&#21270;&#33021;&#21147;&#30340;&#24433;&#21709;&#65306;&#25581;&#31034;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#20043;&#38388;&#30340;&#23398;&#20064;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images. (arXiv:2401.08865v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#35757;&#32451;&#38598;&#32500;&#24230;&#26377;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35748;&#20026;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;&#21487;&#33021;&#26159;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#26174;&#33879;&#24046;&#24322;&#30340;&#37096;&#20998;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#21516;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#36825;&#22312;&#20174;&#33258;&#28982;&#22270;&#20687;&#21040;&#20854;&#20182;&#19987;&#38376;&#39046;&#22495;&#65288;&#22914;&#21307;&#23398;&#22270;&#20687;&#65289;&#37319;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#25216;&#26415;&#26102;&#36890;&#24120;&#34987;&#24573;&#35270;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#35757;&#32451;&#38598;&#30340;&#22266;&#26377;&#32500;&#24230;($d_{data}$)&#19982;&#32593;&#32476;&#30340;&#27867;&#21270;&#38169;&#35823;&#19968;&#33324;&#20250;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#21307;&#23398;&#65288;&#25918;&#23556;&#23398;&#65289;&#21644;&#33258;&#28982;&#22270;&#20687;&#39046;&#22495;&#20043;&#38388;&#30340;&#36825;&#31181;&#20851;&#31995;&#30340;&#38497;&#23789;&#31243;&#24230;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#19988;&#26080;&#29616;&#26377;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#24182;&#32463;&#39564;&#35777;&#19968;&#20010;&#19982;$d_{data}$&#30456;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#26469;&#35299;&#20915;&#36825;&#20010;&#30693;&#35782;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#32771;&#34385;&#21040;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;($K_F$)&#36825;&#19968;&#24230;&#37327;&#25351;&#26631;&#21487;&#20197;&#37096;&#20998;&#35299;&#37322;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#30340;&#26174;&#33879;&#32553;&#25918;&#24046;&#24322;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21033;&#29992;&#27979;&#37327;&#36825;&#19968;&#25351;&#26631;&#21487;&#20197;&#25552;&#20379;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension ($d_{data}$) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to $d_{data}$, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic "label sharpness" ($K_F$) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.16834</link><description>&lt;p&gt;
&#36890;&#36807;&#20272;&#35745;&#25968;&#25454;&#20998;&#24067;&#27604;&#20363;&#30340;&#31163;&#25955;&#25193;&#25955;&#35821;&#35328;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution. (arXiv:2310.16834v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16834
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#29109;&#36825;&#19968;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24357;&#34917;&#20102;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#29616;&#26377;&#26041;&#27861;&#30340;&#19981;&#36275;&#65292;&#25552;&#20986;&#20102;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;(SEDD)&#24182;&#22312;GPT-2&#23454;&#39564;&#20013;&#21462;&#24471;&#20102;&#26377;&#31454;&#20105;&#21147;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#35768;&#22810;&#29983;&#25104;&#24314;&#27169;&#20219;&#21153;&#20013;&#20855;&#26377;&#31361;&#30772;&#24615;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#33258;&#28982;&#35821;&#35328;&#31561;&#31163;&#25955;&#25968;&#25454;&#39046;&#22495;&#20013;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#20851;&#38190;&#26159;&#65292;&#26631;&#20934;&#30340;&#25193;&#25955;&#27169;&#22411;&#20381;&#36182;&#20110;&#25104;&#29087;&#30340;&#24471;&#20998;&#21305;&#37197;&#29702;&#35770;&#65292;&#20294;&#26159;&#23558;&#20854;&#25512;&#24191;&#21040;&#31163;&#25955;&#32467;&#26500;&#24182;&#27809;&#26377;&#21462;&#24471;&#30456;&#21516;&#30340;&#32463;&#39564;&#25910;&#30410;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#24471;&#20998;&#29109;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#25955;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#26469;&#24357;&#34917;&#36825;&#20010;&#24046;&#36317;&#65292;&#23427;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#31283;&#23450;&#65292;&#21487;&#20197;&#24418;&#25104;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;ELBO&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21435;&#22122;&#21464;&#20307;&#39640;&#25928;&#20248;&#21270;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#24471;&#20998;&#29109;&#31163;&#25955;&#25193;&#25955;&#27169;&#22411;&#65288;SEDD&#65289;&#25193;&#23637;&#21040;GPT-2&#30340;&#23454;&#39564;&#35774;&#32622;&#20013;&#65292;&#23454;&#29616;&#20102;&#26497;&#20855;&#31454;&#20105;&#21147;&#30340;&#20284;&#28982;&#24230;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#31639;&#27861;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#22312;&#27604;&#36739;&#22823;&#23567;&#30456;&#20284;&#30340;SEDD&#21644;GPT-2&#27169;&#22411;&#26102;&#65292;SEDD&#36798;&#21040;&#20102;&#21487;&#27604;&#36739;&#30340;&#22256;&#24785;&#24230;&#65288;&#36890;&#24120;&#22312;&#22522;&#32447;&#30340;+$10\%$&#20869;&#65292;&#24182;&#19988;&#26377;&#26102;&#36229;&#36807;&#22522;&#32447;&#65289;&#12290;&#27492;&#22806;&#65292;SEDD&#27169;&#22411;&#23398;&#21040;&#20102;...
&lt;/p&gt;
&lt;p&gt;
Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel discrete score matching loss that is more stable than existing methods, forms an ELBO for maximum likelihood training, and can be efficiently optimized with a denoising variant. We scale our Score Entropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2, achieving highly competitive likelihoods while also introducing distinct algorithmic advantages. In particular, when comparing similarly sized SEDD and GPT-2 models, SEDD attains comparable perplexities (normally within $+10\%$ of and sometimes outperforming the baseline). Furthermore, SEDD models lear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25512;&#23548;&#20102;&#28041;&#21450;&#20219;&#24847;&#20984;&#27604;&#36739;&#20989;&#25968;&#30340;&#36890;&#29992;&#20449;&#24687;&#29702;&#35770;&#21644;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#26368;&#32039;&#30028;&#38480;&#26159;&#30001;&#20984;&#20849;&#36717;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;(CGF)&#26500;&#25104;&#30340;&#65292;&#20351;&#24471;&#36825;&#20123;&#30028;&#38480;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#32467;&#26500;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.10534</link><description>&lt;p&gt;
&#23545;&#27604;&#20998;&#31867;&#22120;&#22312;&#27867;&#21270;&#30028;&#38480;&#20013;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Comparing Comparators in Generalization Bounds. (arXiv:2310.10534v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#23548;&#20102;&#28041;&#21450;&#20219;&#24847;&#20984;&#27604;&#36739;&#20989;&#25968;&#30340;&#36890;&#29992;&#20449;&#24687;&#29702;&#35770;&#21644;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#26368;&#32039;&#30028;&#38480;&#26159;&#30001;&#20984;&#20849;&#36717;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;(CGF)&#26500;&#25104;&#30340;&#65292;&#20351;&#24471;&#36825;&#20123;&#30028;&#38480;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#32467;&#26500;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#28041;&#21450;&#20219;&#24847;&#20984;&#27604;&#36739;&#20989;&#25968;&#30340;&#36890;&#29992;&#20449;&#24687;&#29702;&#35770;&#21644;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#35813;&#20989;&#25968;&#27979;&#37327;&#35757;&#32451;&#35823;&#24046;&#21644;&#26679;&#26412;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#35813;&#30028;&#38480;&#22312;&#27604;&#36739;&#20989;&#25968;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;(CG), &#34987;&#30028;&#23450;&#22312;&#19968;&#26063;&#38480;&#21046;&#20998;&#24067;&#20989;&#25968;&#30340;CGF&#19978;&#38480;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#27604;&#36739;&#20989;&#25968;&#26159;CGF&#30340;&#20984;&#20849;&#36717;&#65292;&#20063;&#34987;&#31216;&#20026;Cram\'er&#20989;&#25968;&#26102;&#65292;&#24471;&#21040;&#30340;&#30028;&#38480;&#26159;&#26368;&#32039;&#30340;&#12290;&#36825;&#20010;&#32467;&#35770;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#20855;&#26377;&#31867;&#20284;&#32467;&#26500;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36825;&#35777;&#23454;&#20102;&#24050;&#30693;&#30028;&#38480;&#22312;&#26377;&#30028;&#21644;&#27425;&#39640;&#26031;&#25439;&#22833;&#24773;&#20917;&#19979;&#30340;&#36817;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#22312;&#20854;&#20182;&#38480;&#21046;&#20998;&#24067;&#19979;&#24471;&#21040;&#20102;&#26032;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training and population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\'er function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36890;&#36807;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#36817;&#20284;&#32852;&#21512;&#20998;&#24067;&#65292;&#35777;&#26126;&#20102;&#31890;&#23376;&#27969;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#22312;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#36870;&#38382;&#39064;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03054</link><description>&lt;p&gt;
&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#26799;&#24230;&#27969;&#30340;&#21518;&#39564;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36890;&#36807;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#36817;&#20284;&#32852;&#21512;&#20998;&#24067;&#65292;&#35777;&#26126;&#20102;&#31890;&#23376;&#27969;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#22312;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#36870;&#38382;&#39064;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36825;&#20010;MMD&#65292;&#20063;&#34987;&#31216;&#20026;&#33021;&#37327;&#36317;&#31163;&#65292;&#20855;&#26377;&#20687;&#36890;&#36807;&#20999;&#29255;&#21644;&#25490;&#24207;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#30340;&#20960;&#20010;&#26377;&#30410;&#23646;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26469;&#36817;&#20284;&#30495;&#23454;&#24773;&#20917;&#21644;&#35266;&#23519;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#24182;&#20026;&#21518;&#39564;&#20998;&#24067;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31890;&#23376;&#27969;&#30830;&#23454;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#33021;&#21147;&#36890;&#36807;&#25968;&#23383;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#21253;&#25324;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#35832;&#22914;&#36229;&#20998;&#36776;&#29575;&#12289;&#20462;&#22797;&#21644;&#20302;&#21058;&#37327;&#21644;&#26377;&#38480;&#35282;&#24230;&#35774;&#32622;&#19979;&#30340;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#31561;&#36870;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modeling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#32852;&#24819;&#35760;&#24518;&#20013;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#36890;&#36807;&#39640;&#32500;&#30697;&#38453;&#21644;&#23884;&#20837;&#30340;&#22806;&#31215;&#26469;&#27169;&#25311;&#20869;&#23618;Transformer&#35821;&#35328;&#27169;&#22411;&#12290;&#20316;&#32773;&#25512;&#23548;&#20986;&#20102;&#19982;&#26679;&#26412;&#25968;&#37327;&#21644;&#21442;&#25968;&#22823;&#23567;&#30456;&#20851;&#30340;&#31934;&#30830;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#23637;&#31034;&#20102;&#23384;&#20648;&#35760;&#24518;&#20851;&#32852;&#30340;&#32454;&#31890;&#24230;&#21487;&#35270;&#21270;&#12290;</title><link>http://arxiv.org/abs/2310.02984</link><description>&lt;p&gt;
&#32553;&#25918;&#23450;&#24459;&#22312;&#32852;&#24819;&#35760;&#24518;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Scaling Laws for Associative Memories. (arXiv:2310.02984v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24212;&#29992;&#20110;&#32852;&#24819;&#35760;&#24518;&#20013;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#36890;&#36807;&#39640;&#32500;&#30697;&#38453;&#21644;&#23884;&#20837;&#30340;&#22806;&#31215;&#26469;&#27169;&#25311;&#20869;&#23618;Transformer&#35821;&#35328;&#27169;&#22411;&#12290;&#20316;&#32773;&#25512;&#23548;&#20986;&#20102;&#19982;&#26679;&#26412;&#25968;&#37327;&#21644;&#21442;&#25968;&#22823;&#23567;&#30456;&#20851;&#30340;&#31934;&#30830;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#23637;&#31034;&#20102;&#23384;&#20648;&#35760;&#24518;&#20851;&#32852;&#30340;&#32454;&#31890;&#24230;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#24456;&#21487;&#33021;&#28041;&#21450;&#21040;&#25277;&#35937;&#35268;&#21017;&#30340;&#21457;&#29616;&#21644;&#35760;&#24518;&#12290;&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#32852;&#24819;&#35760;&#24518;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22522;&#20110;&#39640;&#32500;&#30697;&#38453;&#65292;&#30001;&#23884;&#20837;&#30340;&#22806;&#31215;&#32452;&#25104;&#65292;&#19982;Transformer&#35821;&#35328;&#27169;&#22411;&#30340;&#20869;&#23618;&#30456;&#20851;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20851;&#20110;&#26679;&#26412;&#25968;&#37327;&#21644;&#21442;&#25968;&#35268;&#27169;&#30340;&#31934;&#30830;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35752;&#35770;&#20102;&#19981;&#21516;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21253;&#25324;&#22522;&#20110;&#20248;&#21270;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#39564;&#35777;&#21644;&#35299;&#37322;&#29702;&#35770;&#32467;&#26524;&#65292;&#21253;&#25324;&#23545;&#23384;&#20648;&#35760;&#24518;&#20851;&#32852;&#30340;&#32454;&#31890;&#24230;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning arguably involves the discovery and memorization of abstract rules. The aim of this paper is to study associative memory mechanisms. Our model is based on high-dimensional matrices consisting of outer products of embeddings, which relates to the inner layers of transformer language models. We derive precise scaling laws with respect to sample size and parameter size, and discuss the statistical efficiency of different estimators, including optimization-based algorithms. We provide extensive numerical experiments to validate and interpret theoretical results, including fine-grained visualizations of the stored memory associations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#31639;&#27861;&#65292;&#20445;&#35777;&#38646;&#38598;&#20013;&#24230;&#24046;&#20998;&#38544;&#31169;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#26356;&#24378;&#30340;&#20445;&#35777;&#65292;&#24182;&#19988;&#22788;&#29702;&#38750;&#24179;&#28369;&#21644;&#38750;&#24517;&#39035;&#24378;&#20984;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14012</link><description>&lt;p&gt;
&#29992;&#20110;&#38750;&#24179;&#28369;&#30446;&#26631;&#20989;&#25968;&#30340;&#38646;&#38598;&#20013;&#24230;&#31169;&#26377;&#20998;&#24067;&#24335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Zero-Concentrated Private Distributed Learning for Nonsmooth Objective Functions. (arXiv:2306.14012v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#31639;&#27861;&#65292;&#20445;&#35777;&#38646;&#38598;&#20013;&#24230;&#24046;&#20998;&#38544;&#31169;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#26356;&#24378;&#30340;&#20445;&#35777;&#65292;&#24182;&#19988;&#22788;&#29702;&#38750;&#24179;&#28369;&#21644;&#38750;&#24517;&#39035;&#24378;&#20984;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#38750;&#24179;&#28369;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#65288;ADMM&#65289;&#20998;&#24067;&#21040;&#20998;&#24067;&#24335;&#35774;&#32622;&#20013;&#65292;&#24182;&#37319;&#29992;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#36817;&#20284;&#26469;&#22788;&#29702;&#38750;&#24179;&#28369;&#30446;&#26631;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#27599;&#20010;&#20195;&#29702;&#22788;&#29992;&#26041;&#24046;&#36882;&#20943;&#30340;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#35745;&#31639;&#32467;&#26524;&#26469;&#30830;&#20445;&#38646;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#65288;zCDP&#65289;&#12290;&#36825;&#31181;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#20801;&#35768;&#27604;&#20256;&#32479;&#30340;$(\epsilon&#65292;\delta)$-DP&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#65292;&#27604;&#26368;&#36817;&#30340;R&#233;nyi-DP&#25552;&#20379;&#26356;&#24378;&#30340;&#20445;&#35777;&#12290;&#24320;&#21457;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#31639;&#27861;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#38544;&#31169;&#20934;&#30830;&#24615;&#24179;&#34913;&#65292;&#24182;&#22788;&#29702;&#38750;&#24179;&#28369;&#21644;&#38750;&#24517;&#39035;&#24378;&#20984;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#38544;&#31169;&#20445;&#35777;&#21644;&#31639;&#27861;&#25910;&#25947;&#21040;&#31934;&#30830;&#35299;&#30340;&#23436;&#25972;&#29702;&#35770;&#35777;&#26126;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#20854;&#20182;&#20551;&#35774;&#19979;&#65292;&#35813;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#27604;&#38598;&#20013;&#24335;&#38750;&#31169;&#26377;&#31639;&#27861;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops a fully distributed differentially-private learning algorithm to solve nonsmooth optimization problems. We distribute the Alternating Direction Method of Multipliers (ADMM) to comply with the distributed setting and employ an approximation of the augmented Lagrangian to handle nonsmooth objective functions. Furthermore, we ensure zero-concentrated differential privacy (zCDP) by perturbing the outcome of the computation at each agent with a variance-decreasing Gaussian noise. This privacy-preserving method allows for better accuracy than the conventional $(\epsilon, \delta)$-DP and stronger guarantees than the more recent R\'enyi-DP. The developed fully distributed algorithm has a competitive privacy accuracy trade-off and handles nonsmooth and non-necessarily strongly convex problems. We provide complete theoretical proof for the privacy guarantees and the convergence of the algorithm to the exact solution. We also prove under additional assumptions that the algorit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#32423;&#31070;&#32463;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#35745;&#31639;&#20294;&#21487;&#20197;&#36890;&#36807;&#21069;&#21521;&#27169;&#25311;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#26368;&#20248;&#27010;&#29575;&#25512;&#26029;&#65292;&#30528;&#37325;&#32771;&#34385;&#20102;&#27169;&#22411;&#30340;&#23618;&#32423;&#32467;&#26500;&#65292;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#20945;&#30340;&#21442;&#25968;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2306.12584</link><description>&lt;p&gt;
&#22522;&#20110;&#23618;&#32423;&#31070;&#32463;&#27169;&#25311;&#30340;&#20107;&#20214;&#38598;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Neural Simulation-Based Inference Over Event Ensembles. (arXiv:2306.12584v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12584
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#32423;&#31070;&#32463;&#27169;&#25311;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#35745;&#31639;&#20294;&#21487;&#20197;&#36890;&#36807;&#21069;&#21521;&#27169;&#25311;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#26368;&#20248;&#27010;&#29575;&#25512;&#26029;&#65292;&#30528;&#37325;&#32771;&#34385;&#20102;&#27169;&#22411;&#30340;&#23618;&#32423;&#32467;&#26500;&#65292;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#20945;&#30340;&#21442;&#25968;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#20107;&#20214;&#38598;&#26159;&#24120;&#35265;&#30340;&#35266;&#27979;&#20540;&#38598;&#21512;&#65292;&#23427;&#20204;&#20849;&#21516;&#32422;&#26463;&#20102;&#24863;&#20852;&#36259;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20855;&#26377;&#23618;&#32423;&#32467;&#26500;&#65292;&#20854;&#20013;&#8220;&#23616;&#37096;&#8221;&#21442;&#25968;&#24433;&#21709;&#21333;&#20010;&#20107;&#20214;&#65292;&#8220;&#20840;&#23616;&#8221;&#21442;&#25968;&#24433;&#21709;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23454;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#35745;&#31639;&#20294;&#21487;&#20197;&#36890;&#36807;&#21069;&#21521;&#27169;&#25311;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#25972;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#26368;&#20248;&#27010;&#29575;&#25512;&#26029;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#20284;&#28982;&#20989;&#25968;&#65288;&#27604;&#65289;&#25110;&#21518;&#39564;&#27010;&#29575;&#30340;&#31070;&#32463;&#20272;&#35745;&#22120;&#65292;&#24182;&#23637;&#31034;&#20102;&#26126;&#30830;&#32771;&#34385;&#27169;&#22411;&#23618;&#32423;&#32467;&#26500;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#20945;&#30340;&#21442;&#25968;&#32422;&#26463;&#12290;&#25105;&#20204;&#20197;&#29289;&#29702;&#31185;&#23398;&#20026;&#20363;&#30740;&#31350;&#20102;&#26412;&#25991;&#35752;&#35770;&#30340;&#20869;&#23481;&#65292;&#30528;&#37325;&#20110;&#31890;&#23376;&#29289;&#29702;&#23398;&#65288;&#31890;&#23376;&#23545;&#25758;&#26426;&#25968;&#25454;&#65289;&#21644;&#22825;&#20307;&#29289;&#29702;&#23398;&#65288;&#24378;&#24341;&#21147;&#36879;&#38236;&#35266;&#27979;&#65289;&#30340;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
When analyzing real-world data it is common to work with event ensembles, which comprise sets of observations that collectively constrain the parameters of an underlying model of interest. Such models often have a hierarchical structure, where "local" parameters impact individual events and "global" parameters influence the entire dataset. We introduce practical approaches for optimal dataset-wide probabilistic inference in cases where the likelihood is intractable, but simulations can be realized via forward modeling. We construct neural estimators for the likelihood(-ratio) or posterior and show that explicitly accounting for the model's hierarchical structure can lead to tighter parameter constraints. We ground our discussion using case studies from the physical sciences, focusing on examples from particle physics (particle collider data) and astrophysics (strong gravitational lensing observations).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.05857</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#21487;&#20197;&#34987;&#21098;&#26525;&#21040;&#22810;&#20040;&#31232;&#30095;&#65306;&#20960;&#20309;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Sparse Can We Prune A Deep Network: A Geometric Viewpoint. (arXiv:2306.05857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#12290;&#34429;&#28982;&#23427;&#21487;&#20197;&#25552;&#20379;&#20986;&#33394;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24378;&#21152;&#20102;&#37325;&#22823;&#30340;&#23384;&#20648;&#36127;&#25285;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#30740;&#31350;&#32593;&#32476;&#21098;&#26525;&#12290;&#19968;&#20010;&#33258;&#28982;&#32780;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#65306;&#25105;&#20204;&#33021;&#21098;&#26525;&#19968;&#20010;&#28145;&#24230;&#32593;&#32476;&#21040;&#22810;&#20040;&#31232;&#30095;&#65288;&#20960;&#20046;&#19981;&#24433;&#21709;&#24615;&#33021;&#65289;&#65311;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#31532;&#19968;&#21407;&#29702;&#26041;&#27861;&#65292;&#20855;&#20307;&#22320;&#65292;&#21482;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25105;&#20204;&#33021;&#22815;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#25551;&#36848;&#21098;&#26525;&#27604;&#29575;&#30340;&#23574;&#38160;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#23545;&#24212;&#20110;&#21487;&#34892;&#21644;&#19981;&#21487;&#34892;&#20043;&#38388;&#30340;&#36793;&#30028;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#65292;&#36825;&#20123;&#20984;&#20307;&#26159;&#30001;$l_1$-&#35268;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#24471;&#20986;&#30340;&#65292;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21098;&#26525;&#36807;&#31243;&#20013;&#21442;&#25968;&#30340;&#20998;&#24067;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterization constitutes one of the most significant hallmarks of deep neural networks. Though it can offer the advantage of outstanding generalization performance, it meanwhile imposes substantial storage burden, thus necessitating the study of network pruning. A natural and fundamental question is: How sparse can we prune a deep network (with almost no hurt on the performance)? To address this problem, in this work we take a first principles approach, specifically, by merely enforcing the sparsity constraint on the original loss function, we're able to characterize the sharp phase transition point of pruning ratio, which corresponds to the boundary between the feasible and the infeasible, from the perspective of high-dimensional geometry. It turns out that the phase transition point of pruning ratio equals the squared Gaussian width of some convex body resulting from the $l_1$-regularized loss function, normalized by the original dimension of parameters. As a byproduct, we pr
&lt;/p&gt;</description></item><item><title>dotears&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;DAG&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26469;&#25512;&#26029;&#21333;&#20010;&#22240;&#26524;&#32467;&#26500;&#12290;&#23427;&#30452;&#25509;&#20272;&#35745;&#22806;&#29983;&#35823;&#24046;&#32467;&#26500;&#65292;&#36991;&#20813;&#20102;&#24490;&#29615;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.19215</link><description>&lt;p&gt;
dotears: &#20351;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#19968;&#33268;&#30340;DAG&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
dotears: Scalable, consistent DAG estimation using observational and interventional data. (arXiv:2305.19215v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19215
&lt;/p&gt;
&lt;p&gt;
dotears&#26159;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;DAG&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26469;&#25512;&#26029;&#21333;&#20010;&#22240;&#26524;&#32467;&#26500;&#12290;&#23427;&#30452;&#25509;&#20272;&#35745;&#22806;&#29983;&#35823;&#24046;&#32467;&#26500;&#65292;&#36991;&#20813;&#20102;&#24490;&#29615;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#26377;&#21521;&#26080;&#29615;&#22270; (DAG)&#38754;&#20020;&#30528;&#21487;&#36776;&#35782;&#24615;&#32570;&#22833;&#21644;&#35299;&#20915;&#26041;&#26696;&#32452;&#21512;&#31354;&#38388;&#30340;&#22797;&#26434;&#24615;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#39640;&#20102;&#35266;&#27979;&#25968;&#25454;&#20013;&#22522;&#20110;&#24471;&#20998;&#30340;DAG&#32467;&#26500;&#23398;&#20064;&#30340;&#21487;&#25805;&#20316;&#24615;&#65292;&#20294;&#23545;&#22806;&#29983;&#35823;&#24046;&#26041;&#24046;&#30340;&#32467;&#26500;&#25935;&#24863;&#12290;&#21516;&#26102;&#65292;&#20174;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#22806;&#29983;&#26041;&#24046;&#32467;&#26500;&#38656;&#35201;&#32467;&#26500;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#38024;&#23545;&#26032;&#30340;&#29983;&#29289;&#25216;&#26415;&#65292;&#23558;&#39640;&#24230;&#24182;&#34892;&#30340;&#22522;&#22240;&#24178;&#39044;&#19982;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#32852;&#31995;&#36215;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#25193;&#23637;&#30340;&#32467;&#26500;&#23398;&#20064;&#26694;&#26550;dotears&#65292;&#36890;&#36807;&#36830;&#32493;&#20248;&#21270;&#21033;&#29992;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26469;&#25512;&#26029;&#21333;&#20010;&#22240;&#26524;&#32467;&#26500;&#12290;dotears&#21033;&#29992;&#24178;&#39044;&#30340;&#21487;&#39044;&#27979;&#30340;&#32467;&#26500;&#21518;&#26524;&#30452;&#25509;&#20272;&#35745;&#22806;&#29983;&#35823;&#24046;&#32467;&#26500;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#24490;&#29615;&#20272;&#35745;&#38382;&#39064;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#20808;&#21069;&#30340;&#24037;&#20316;&#65292;&#20174;&#32463;&#39564;&#21644;&#20998;&#26512;&#26041;&#38754;&#36827;&#34892;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning causal directed acyclic graphs (DAGs) from data is complicated by a lack of identifiability and the combinatorial space of solutions. Recent work has improved tractability of score-based structure learning of DAGs in observational data, but is sensitive to the structure of the exogenous error variances. On the other hand, learning exogenous variance structure from observational data requires prior knowledge of structure. Motivated by new biological technologies that link highly parallel gene interventions to a high-dimensional observation, we present $\texttt{dotears}$ [doo-tairs], a scalable structure learning framework which leverages observational and interventional data to infer a single causal structure through continuous optimization. $\texttt{dotears}$ exploits predictable structural consequences of interventions to directly estimate the exogenous error structure, bypassing the circular estimation problem. We extend previous work to show, both empirically and analytical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#20559;&#24046;&#26657;&#27491;&#24182;&#24418;&#25104;&#20102;&#21487;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2211.16298</link><description>&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Double Robust Bayesian Inference on Average Treatment Effects. (arXiv:2211.16298v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#20559;&#24046;&#26657;&#27491;&#24182;&#24418;&#25104;&#20102;&#21487;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#20559;&#24615;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#12290;&#25105;&#20204;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#35843;&#25972;&#27493;&#39588;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#26657;&#27491;&#65307;&#20854;&#27425;&#65292;&#25105;&#20204;&#22312;&#20135;&#29983;&#30340;ATE&#30340;&#21518;&#39564;&#20998;&#24067;&#19978;&#24341;&#20837;&#19968;&#20010;&#37325;&#26032;&#23621;&#20013;&#26415;&#35821;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#21452;&#37325;&#40065;&#26834;&#24615;&#19979;&#30340;&#21322;&#21442;&#25968;Bernstein-von Mises&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#37327;&#21644;&#21452;&#37325;&#40065;&#26834;&#39057;&#29575;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#31561;&#20215;&#24615;&#65307;&#21363;&#65292;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#30340;&#32570;&#20047;&#24179;&#28369;&#24615;&#21487;&#20197;&#36890;&#36807;&#27010;&#29575;&#24471;&#20998;&#30340;&#39640;&#35268;&#21017;&#24615;&#36827;&#34892;&#34917;&#20607;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#22240;&#27492;&#65292;&#20135;&#29983;&#30340;&#36125;&#21494;&#26031;&#28857;&#20272;&#35745;&#20869;&#22312;&#21270;&#20102;&#39057;&#29575;&#22411;&#21452;&#37325;&#40065;&#26834;&#20272;&#35745;&#37327;&#30340;&#20559;&#24046;&#26657;&#27491;&#65292;&#32780;&#36125;&#21494;&#26031;&#21487;&#20449;&#38598;&#24418;&#25104;&#30340;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#28176;&#36817;&#31934;&#30830;&#30340;&#35206;&#30422;&#27010;&#29575;&#12290;&#22312;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#40065;&#26834;&#30340;&#36125;&#21494;&#26031;&#31243;&#24207;&#23548;&#33268;&#20102;&#26174;&#30528;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We study a double robust Bayesian inference procedure on the average treatment effect (ATE) under unconfoundedness. Our robust Bayesian approach involves two adjustment steps: first, we make a correction for prior distributions of the conditional mean function; second, we introduce a recentering term on the posterior distribution of the resulting ATE. We prove asymptotic equivalence of our Bayesian estimator and double robust frequentist estimators by establishing a new semiparametric Bernstein-von Mises theorem under double robustness; i.e., the lack of smoothness of conditional mean functions can be compensated by high regularity of the propensity score and vice versa. Consequently, the resulting Bayesian point estimator internalizes the bias correction as the frequentist-type doubly robust estimator, and the Bayesian credible sets form confidence intervals with asymptotically exact coverage probability. In simulations, we find that this robust Bayesian procedure leads to significant
&lt;/p&gt;</description></item></channel></rss>