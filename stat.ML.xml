<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24102;&#26377;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#21608;&#26399;&#24615;&#23545;&#25239;&#24615;&#32447;&#24615;MDP&#65292;&#22312;&#38543;&#26426;&#32447;&#24615;MDP&#21644;&#24102;&#26377;&#20840;&#20449;&#24687;&#30340;&#25932;&#23545;&#32447;&#24615;MDP&#20013;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#65292;&#24182;&#20855;&#26377;&#26032;&#39062;&#30340;&#22810;&#25209;&#27425;&#26356;&#26032;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.08841</link><description>&lt;p&gt;
&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#22312;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of Optimistic Proximal Policy Optimization in Linear Markov Decision Processes. (arXiv:2305.08841v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24102;&#26377;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#21608;&#26399;&#24615;&#23545;&#25239;&#24615;&#32447;&#24615;MDP&#65292;&#22312;&#38543;&#26426;&#32447;&#24615;MDP&#21644;&#24102;&#26377;&#20840;&#20449;&#24687;&#30340;&#25932;&#23545;&#32447;&#24615;MDP&#20013;&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#65292;&#24182;&#20855;&#26377;&#26032;&#39062;&#30340;&#22810;&#25209;&#27425;&#26356;&#26032;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65288;PPO&#65289;&#31639;&#27861;&#26159;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#26368;&#25104;&#21151;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#23613;&#31649;PPO&#24456;&#25104;&#21151;&#65292;&#20294;&#26159;&#23545;&#20110;PPO&#21450;&#20854;&#20048;&#35266;&#21464;&#31181;&#26159;&#21542;&#33021;&#26377;&#25928;&#35299;&#20915;&#32447;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDPs)&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#19981;&#36275;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#24102;&#26377;&#20840;&#20449;&#24687;&#21453;&#39304;&#30340;&#21608;&#26399;&#25932;&#23545;&#32447;&#24615;MDP&#65292;&#24182;&#20026;&#20854;&#24314;&#31435;&#20102;&#19968;&#20010;$\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$&#30340;&#21518;&#24724;&#20540;&#12290;&#20854;&#20013;$d$&#26159;&#32447;&#24615;MDPs&#30340;&#29615;&#22659;&#32500;&#25968;&#65292;$H$&#26159;&#27599;&#20010;&#21608;&#26399;&#30340;&#38271;&#24230;&#65292;$K$&#26159;&#21608;&#26399;&#25968;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#31574;&#30053;&#30340;&#31639;&#27861;&#30456;&#27604;&#65292;&#22312;&#38543;&#26426;&#32447;&#24615;MDP&#21644;&#24102;&#26377;&#20840;&#20449;&#24687;&#30340;&#25932;&#23545;&#32447;&#24615;MDP&#20013;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#24403;&#20170;&#26368;&#20808;&#36827;&#30340;&#21518;&#24724;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#35774;&#35745;&#20855;&#26377;&#26032;&#39062;&#30340;&#22810;&#25209;&#27425;&#26356;&#26032;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proximal policy optimization (PPO) algorithm stands as one of the most prosperous methods in the field of reinforcement learning (RL). Despite its success, the theoretical understanding of PPO remains deficient. Specifically, it is unclear whether PPO or its optimistic variants can effectively solve linear Markov decision processes (MDPs), which are arguably the simplest models in RL with function approximation. To bridge this gap, we propose an optimistic variant of PPO for episodic adversarial linear MDPs with full-information feedback, and establish a $\tilde{\mathcal{O}}(d^{3/4}H^2K^{3/4})$ regret for it. Here $d$ is the ambient dimension of linear MDPs, $H$ is the length of each episode, and $K$ is the number of episodes. Compared with existing policy-based algorithms, we achieve the state-of-the-art regret bound in both stochastic linear MDPs and adversarial linear MDPs with full information. Additionally, our algorithm design features a novel multi-batched updating mechanism
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#32771;&#34385;&#31038;&#21306;&#32467;&#26500;&#30340;&#24433;&#21709;&#21147;&#26368;&#22823;&#21270;&#31639;&#27861;&#65292;&#22312;&#20449;&#24687;&#20256;&#25773;&#36807;&#31243;&#20013;&#65292;&#33021;&#22815;&#20445;&#35777;&#19981;&#21516;&#31038;&#21306;&#38388;&#30340;&#20449;&#24687;&#35206;&#30422;&#24046;&#24322;&#19981;&#20250;&#36807;&#22823;&#12290;</title><link>http://arxiv.org/abs/2305.08791</link><description>&lt;p&gt;
&#31038;&#20132;&#32593;&#32476;&#19978;&#24102;&#26377;&#31038;&#21306;&#32467;&#26500;&#30340;&#20844;&#24179;&#20449;&#24687;&#20256;&#25773;
&lt;/p&gt;
&lt;p&gt;
Fair Information Spread on Social Networks with Community Structure. (arXiv:2305.08791v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08791
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#32771;&#34385;&#31038;&#21306;&#32467;&#26500;&#30340;&#24433;&#21709;&#21147;&#26368;&#22823;&#21270;&#31639;&#27861;&#65292;&#22312;&#20449;&#24687;&#20256;&#25773;&#36807;&#31243;&#20013;&#65292;&#33021;&#22815;&#20445;&#35777;&#19981;&#21516;&#31038;&#21306;&#38388;&#30340;&#20449;&#24687;&#35206;&#30422;&#24046;&#24322;&#19981;&#20250;&#36807;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#32593;&#32476;&#19978;&#30340;&#20449;&#24687;&#20256;&#25773;&#24050;&#32463;&#21313;&#20998;&#26222;&#36941;&#12290;&#24433;&#21709;&#21147;&#26368;&#22823;&#21270; (IM) &#31639;&#27861;&#30340;&#30446;&#30340;&#26159;&#35782;&#21035;&#37027;&#20123;&#22312;&#33719;&#24471;&#20449;&#24687;&#21518;&#23558;&#22312;&#31038;&#20132;&#32593;&#32476;&#19978;&#20135;&#29983;&#26368;&#22823;&#20256;&#25773;&#30340;&#20010;&#20307;&#65292;&#24182;&#19988;&#36825;&#20123;&#31639;&#27861;&#20027;&#35201;&#26159;&#38024;&#23545;&#33829;&#38144;&#32780;&#24320;&#21457;&#30340;&#12290;&#22312;&#20855;&#26377;&#31038;&#21306;&#32467;&#26500;&#30340;&#31038;&#20132;&#32593;&#32476;&#20013;&#65292;IM &#31639;&#27861;&#20165;&#30528;&#30524;&#20110;&#26368;&#22823;&#21270;&#20256;&#25773;&#65292;&#21487;&#33021;&#23548;&#33268;&#19981;&#21516;&#31038;&#21306;&#38388;&#20449;&#24687;&#35206;&#30422;&#24046;&#24322;&#26174;&#33879;&#65292;&#36825;&#22312;&#20844;&#20849;&#21355;&#29983;&#20256;&#25773;&#31561;&#24773;&#22659;&#19979;&#26159;&#19981;&#21033;&#30340;&#12290;&#34429;&#28982;&#26377;&#20123; IM &#31639;&#27861;&#26088;&#22312;&#36890;&#36807;&#33410;&#28857;&#23646;&#24615;&#26469;&#35299;&#20915;&#20449;&#24687;&#35206;&#30422;&#30340;&#19981;&#24179;&#34913;&#29616;&#35937;&#65292;&#20294;&#26159;&#27809;&#26377;&#20351;&#29992;&#32593;&#32476;&#26412;&#36523;&#30340;&#23454;&#39564;&#31038;&#21306;&#32467;&#26500;&#65292;&#32780;&#36825;&#21487;&#33021;&#26159;&#26377;&#30410;&#30340;&#65292;&#22240;&#20026;&#31038;&#21306;&#30452;&#25509;&#24433;&#21709;&#20449;&#24687;&#30340;&#20256;&#25773;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#23454;&#39564;&#32593;&#32476;&#32467;&#26500;&#21487;&#20197;&#21033;&#29992;&#31038;&#21306;&#26816;&#27979;&#25216;&#26415;&#65292;&#22312;&#27809;&#26377;&#30456;&#20851;&#33410;&#28857;&#23646;&#24615;&#21487;&#29992;&#26102;&#36816;&#34892;&#20844;&#24179;&#24863;&#30693;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information spread through social networks is ubiquitous. Influence maximization (IM) algorithms aim to identify individuals who will generate the greatest spread through the social network if provided with information, and have been largely devel- oped with marketing in mind. In social networks with community structure, which are very common, IM algorithms focused solely on maximizing spread may yield signifi- cant disparities in information coverage between communities, which is problematic in settings such as public health messaging. While some IM algorithms aim to remedy disparity in information coverage using node attributes, none use the empirical com- munity structure within the network itself, which may be beneficial since communities directly affect the spread of information. Further, the use of empirical network struc- ture allows us to leverage community detection techniques, making it possible to run fair-aware algorithms when there are no relevant node attributes availab
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#25512;&#24191;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#30740;&#31350;&#20102;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#24182;&#34920;&#24449;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#35777;&#26126;&#20102;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;Nesterov&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30830;&#23450;&#20986;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2305.08658</link><description>&lt;p&gt;
&#20851;&#20110;&#20248;&#21270;&#31639;&#27861;&#12289;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#21644;&#24494;&#20998;&#26041;&#31243;&#30340;&#32852;&#31995;&#65306;&#29702;&#35770;&#19982;&#27934;&#35265;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights. (arXiv:2305.08658v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#25512;&#24191;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#30740;&#31350;&#20102;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#24182;&#34920;&#24449;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#35777;&#26126;&#20102;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;Nesterov&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30830;&#23450;&#20986;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#24191;Fazylab&#31561;&#20154;&#22312;2018&#24180;&#21457;&#23637;&#30340;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#29992;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#30740;&#31350;$m$-&#24378;&#20984;&#21644;$L$-&#20809;&#28369;&#20989;&#25968;&#30340;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#20351;&#29992;&#26032;&#26694;&#26550;&#65292;&#25105;&#20204;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#30340;&#26032;&#22411;&#65288;&#31163;&#25955;&#65289;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#36827;&#34892;&#20102;&#35299;&#26512;&#25512;&#23548;&#65292;&#24182;&#34920;&#24449;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#23545;&#20110;&#26631;&#20934;&#31995;&#25968;&#30340;Nesterov&#26041;&#27861;&#30340;&#20808;&#21069;&#35777;&#26126;&#36895;&#24230;&#26377;&#20102;&#26126;&#26174;&#25913;&#36827;&#65292;&#24182;&#19988;&#34920;&#24449;&#20102;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;&#25105;&#20204;&#20026;Polyak ODE&#33719;&#24471;&#20102;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#65292;&#24182;&#37325;&#26032;&#23457;&#35270;&#20102;&#27492;ODE&#19982;Nesterov&#31639;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23558;Nesterov&#26041;&#27861;&#35299;&#37322;&#20026;&#21152;&#24615;Runge-Kutta&#31163;&#25955;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#35299;&#37322;&#20102;&#31163;&#25955;&#21270;Polyak&#26041;&#31243;&#30340;&#32467;&#26500;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study connections between differential equations and optimization algorithms for $m$-strongly and $L$-smooth convex functions through the use of Lyapunov functions by generalizing the Linear Matrix Inequality framework developed by Fazylab et al. in 2018. Using the new framework we derive analytically a new (discrete) Lyapunov function for a two-parameter family of Nesterov optimization methods and characterize their convergence rate. This allows us to prove a convergence rate that improves substantially on the previously proven rate of Nesterov's method for the standard choice of coefficients, as well as to characterize the choice of coefficients that yields the optimal rate. We obtain a new Lyapunov function for the Polyak ODE and revisit the connection between this ODE and the Nesterov's algorithms. In addition discuss a new interpretation of Nesterov method as an additive Runge-Kutta discretization and explain the structural conditions that discretizations of the Polyak equation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#22810;&#32423;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#32676;&#20307;&#25968;&#25454;&#35270;&#20026;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#24182;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23454;&#29616;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;</title><link>http://arxiv.org/abs/2305.08657</link><description>&lt;p&gt;
&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#32534;&#30721;&#21040;&#22810;&#32423;&#27169;&#22411;&#20013;&#29992;&#20110;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;
Encoding Domain Expertise into Multilevel Models for Source Location. (arXiv:2305.08657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#22810;&#32423;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#32676;&#20307;&#25968;&#25454;&#35270;&#20026;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#24182;&#23558;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#29289;&#29702;&#30693;&#35782;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#65292;&#20197;&#23454;&#29616;&#28304;&#20301;&#32622;&#30340;&#23450;&#20301;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#32676;&#20307;&#25968;&#25454;&#26159;&#26222;&#36941;&#23384;&#22312;&#30340;&#12290;&#26426;&#22120;&#21644;&#22522;&#30784;&#35774;&#26045;&#36234;&#26469;&#36234;&#22810;&#22320;&#37197;&#22791;&#20102;&#20256;&#24863;&#31995;&#32479;&#65292;&#21457;&#20986;&#20855;&#26377;&#22797;&#26434;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#30340;&#36965;&#27979;&#25968;&#25454;&#27969;&#12290;&#23454;&#38469;&#19978;&#65292;&#25968;&#25454;&#20013;&#24515;&#30340;&#30417;&#27979;&#31243;&#24207;&#20542;&#21521;&#20110;&#23558;&#36825;&#20123;&#36164;&#20135;&#65288;&#20197;&#21450;&#21508;&#33258;&#30340;&#27169;&#22411;&#65289;&#35270;&#20026;&#19981;&#21516;&#30340;&#23454;&#20307; - &#29420;&#31435;&#36816;&#34892;&#24182;&#19982;&#29420;&#31435;&#25968;&#25454;&#30456;&#20851;&#32852;&#12290;&#30456;&#21453;&#65292;&#36825;&#39033;&#24037;&#20316;&#25429;&#25417;&#20102;&#19968;&#32452;&#31995;&#32479;&#27169;&#22411;&#20043;&#38388;&#30340;&#32479;&#35745;&#30456;&#20851;&#24615;&#21644;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#12290;&#21033;&#29992;&#36125;&#21494;&#26031;&#22810;&#32423;&#26041;&#27861;&#65292;&#25968;&#25454;&#30340;&#20215;&#20540;&#21487;&#20197;&#24471;&#21040;&#25193;&#23637;&#65292;&#22240;&#20026;&#21487;&#20197;&#23558;&#20154;&#32676;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#26469;&#32771;&#34385;&#65292;&#32780;&#19981;&#26159;&#20316;&#20026;&#32452;&#25104;&#37096;&#20998;&#12290;&#26368;&#26377;&#36259;&#30340;&#26159;&#65292;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#21644;&#22522;&#30784;&#29289;&#29702;&#30693;&#35782;&#21487;&#20197;&#22312;&#31995;&#32479;&#12289;&#23376;&#32452;&#25110;&#20154;&#32676;&#27700;&#24179;&#19978;&#32534;&#30721;&#21040;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22768;&#21457;&#23556;&#65288;&#21040;&#36798;&#26102;&#38388;&#65289;&#26144;&#23556;&#28304;&#20301;&#32622;&#30340;&#31034;&#20363;&#65292;&#20197;&#35828;&#26126;&#22810;&#32423;&#27169;&#22411;&#22914;&#20309;&#33258;&#28982;&#22320;&#36866;&#29992;&#20110;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data from populations of systems are prevalent in many industrial applications. Machines and infrastructure are increasingly instrumented with sensing systems, emitting streams of telemetry data with complex interdependencies. In practice, data-centric monitoring procedures tend to consider these assets (and respective models) as distinct -- operating in isolation and associated with independent data. In contrast, this work captures the statistical correlations and interdependencies between models of a group of systems. Utilising a Bayesian multilevel approach, the value of data can be extended, since the population can be considered as a whole, rather than constituent parts. Most interestingly, domain expertise and knowledge of the underlying physics can be encoded in the model at the system, subgroup, or population level. We present an example of acoustic emission (time-of-arrival) mapping for source location, to illustrate how multilevel models naturally lend themselves to represent
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20020;&#24202;&#21644;&#38750;&#20020;&#24202;&#25991;&#26412;&#19978;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#20013;&#20351;&#29992;&#25299;&#25169;&#21644;&#20960;&#20309;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#25512;&#26029;&#20027;&#35201;&#29305;&#24449;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.08642</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25299;&#25169;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Topological Interpretability for Deep-Learning. (arXiv:2305.08642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20020;&#24202;&#21644;&#38750;&#20020;&#24202;&#25991;&#26412;&#19978;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#20013;&#20351;&#29992;&#25299;&#25169;&#21644;&#20960;&#20309;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#25512;&#26029;&#20027;&#35201;&#29305;&#24449;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#31995;&#32479;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#29702;&#35299;&#23427;&#20204;&#30340;&#20915;&#31574;&#26426;&#21046;&#30340;&#38656;&#27714;&#20063;&#30456;&#24212;&#21152;&#36895;&#12290;&#25105;&#20204;&#33021;&#22815;&#20449;&#20219;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#20915;&#31574;&#31995;&#32479;&#25152;&#20570;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#31243;&#24230;&#36234;&#26469;&#36234;&#25104;&#20026;&#19968;&#20010;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#30340;&#31995;&#32479;&#65292;&#20363;&#22914;&#21009;&#20107;&#21496;&#27861;&#25110;&#21307;&#23398;&#35786;&#26029;&#31995;&#32479;&#20013;&#65292;&#38169;&#35823;&#30340;&#25512;&#26029;&#21487;&#33021;&#20250;&#20135;&#29983;&#24754;&#21095;&#24615;&#30340;&#21518;&#26524;&#12290;&#23613;&#31649;&#22312;&#35299;&#20915;&#28041;&#21450;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#26080;&#27861;&#37327;&#21270;&#20854;&#39044;&#27979;&#30340;&#30830;&#23450;&#24615;&#12290;&#32780;&#19988;&#24403;&#20854;&#35299;&#20915;&#26041;&#26696;&#19981;&#27491;&#30830;&#26102;&#65292;&#36890;&#24120;&#20173;&#28982;&#38750;&#24120;&#33258;&#20449;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20020;&#24202;&#21644;&#38750;&#20020;&#24202;&#25991;&#26412;&#19978;&#35757;&#32451;&#30340;&#20004;&#20010;DL&#20998;&#31867;&#27169;&#22411;&#20013;&#25512;&#26029;&#26480;&#20986;&#29305;&#24449;&#65292;&#37319;&#29992;&#20102;&#25299;&#25169;&#21644;&#20960;&#20309;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#27169;&#22411;&#39044;&#27979;&#31354;&#38388;&#30340;&#22270;&#24418;&#65292;&#24182;&#36890;&#36807;&#29305;&#24449;&#21644;&#39044;&#27979;&#30340;&#30456;&#20284;&#24615;&#23558;&#36755;&#20837;&#32858;&#31867;&#21040;&#22270;&#24418;&#30340;&#39030;&#28857;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasing adoption of AI-based systems across everyday life, the need to understand their decision-making mechanisms is correspondingly accelerating. The level at which we can trust the statistical inferences made from AI-based decision systems is an increasing concern, especially in high-risk systems such as criminal justice or medical diagnosis, where incorrect inferences may have tragic consequences. Despite their successes in providing solutions to problems involving real-world data, deep learning (DL) models cannot quantify the certainty of their predictions. And are frequently quite confident, even when their solutions are incorrect.  This work presents a method to infer prominent features in two DL classification models trained on clinical and non-clinical text by employing techniques from topological and geometric data analysis. We create a graph of a model's prediction space and cluster the inputs into the graph's vertices by the similarity of features and prediction
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#21152;&#26435;&#30340;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#36991;&#20813;&#21327;&#21464;&#37327;&#28418;&#31227;&#23545;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.08637</link><description>&lt;p&gt;
&#20026;&#21327;&#21464;&#37327;&#28418;&#31227;&#33258;&#36866;&#24212;&#24341;&#20837;&#21452;&#37325;&#21152;&#26435;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Double-Weighting for Covariate Shift Adaptation. (arXiv:2305.08637v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08637
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#21152;&#26435;&#30340;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#36991;&#20813;&#21327;&#21464;&#37327;&#28418;&#31227;&#23545;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#20013;&#24120;&#24120;&#21463;&#21040;&#21327;&#21464;&#37327;&#28418;&#31227;&#24433;&#21709;&#65292;&#21363;&#35757;&#32451;&#26679;&#26412;&#21644;&#27979;&#35797;&#26679;&#26412;&#30340;&#23454;&#20363;&#36793;&#32536;&#20998;&#24067;&#19981;&#21516;&#20294;&#26631;&#31614;&#26465;&#20214;&#30456;&#21516;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#27604;&#29575;p_te&#65288;x&#65289;/p_tr&#65288;x&#65289;&#23545;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65288;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65289;&#65292;&#25110;&#32773;&#20351;&#29992;&#27604;&#29575;p_tr&#65288;x&#65289;/p_te&#65288;x&#65289;&#23545;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65288;&#40065;&#26834;&#26041;&#27861;&#65289;&#26469;&#35299;&#20915;&#36825;&#31181;&#21327;&#21464;&#37327;&#28418;&#31227;&#12290;&#28982;&#32780;&#65292;&#22312;&#25903;&#25345;&#19981;&#21305;&#37197;&#25110;&#19978;&#36848;&#27604;&#29575;&#21462;&#22823;&#20540;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21487;&#33021;&#24456;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;(MRC)&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35757;&#32451;&#26679;&#26412;&#21644;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#26469;&#36991;&#20813;&#36825;&#31181;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#26377;&#25928;&#30340;&#25216;&#26415;&#26469;&#33719;&#24471;&#20004;&#32452;&#21152;&#26435;&#65292;&#24182;&#25512;&#24191;&#20102;&#20256;&#32479;&#30340;&#26680;&#22343;&#20540;&#21305;&#37197;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $\mathrm{p}_\text{tr}(x)$ and $\mathrm{p}_\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $\mathrm{p}_\text{te}(x)/\mathrm{p}_\text{tr}(x)$ to weight training samples (reweighting methods) or using the ratio $\mathrm{p}_\text{tr}(x)/\mathrm{p}_\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel genera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#36890;&#36807;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#21487;&#20197;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.08529</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#32852;&#21512;&#29420;&#31435;&#24615;&#26816;&#39564;&#29992;&#20110;&#22810;&#20803;&#12289;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series. (arXiv:2305.08529v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#36890;&#36807;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#21487;&#20197;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25429;&#25417;&#30456;&#20114;&#36830;&#25509;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#20102;&#35299;&#20849;&#21516;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#21644;&#28508;&#22312;&#20381;&#36182;&#20851;&#31995;&#26159;&#20934;&#30830;&#32479;&#35745;&#24314;&#27169;&#21644;&#20998;&#26512;&#27492;&#31867;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558; d &#21464;&#37327; Hilbert-Schmidt &#29420;&#31435;&#24615;&#20934;&#21017;&#65288;dHSIC&#65289;&#25193;&#23637;&#21040;&#21253;&#21547;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#24191;&#27867;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#12290;&#36890;&#36807;&#21033;&#29992;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#37327;&#36523;&#23450;&#21046;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22914;&#20309;&#22312;&#21512;&#25104;&#31034;&#20363;&#65288;&#21253;&#25324;&#39057;&#29575;&#28151;&#21512;&#25968;&#25454;&#65289;&#20197;&#21450;&#23454;&#38469;&#27668;&#20505;&#21644;&#31038;&#20250;&#32463;&#27982;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#20998;&#26512;&#22797;&#26434;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#22686;&#21152;&#20102;&#25968;&#23398;&#24037;&#20855;&#31665;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate time-series data that capture the temporal evolution of interconnected systems are ubiquitous in diverse areas. Understanding the complex relationships and potential dependencies among co-observed variables is crucial for the accurate statistical modelling and analysis of such systems. Here, we introduce kernel-based statistical tests of joint independence in multivariate time-series by extending the d-variable Hilbert-Schmidt independence criterion (dHSIC) to encompass both stationary and nonstationary random processes, thus allowing broader real-world applications. By leveraging resampling techniques tailored for both single- and multiple-realization time series, we show how the method robustly uncovers significant higher-order dependencies in synthetic examples, including frequency mixing data, as well as real-world climate and socioeconomic data. Our method adds to the mathematical toolbox for the analysis of complex high-dimensional time-series datasets.
&lt;/p&gt;</description></item><item><title>&#26631;&#31614;&#24179;&#28369;&#26159;&#29992;&#20110;&#20462;&#25913;&#25439;&#22833;&#20989;&#25968;&#21644;&#19968;&#33268;&#30340;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#25552;&#39640;&#27491;&#30830;&#35268;&#23450;&#27169;&#22411;&#30340;&#25928;&#29575;&#65292;&#20943;&#23567;&#27169;&#22411;&#35268;&#33539;&#21270;&#19981;&#27491;&#30830;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.08501</link><description>&lt;p&gt;
&#26631;&#31614;&#24179;&#28369;&#26159;&#23545;&#27169;&#22411;&#35268;&#33539;&#21270;&#30340;&#24378;&#21270;&#38450;&#24481;
&lt;/p&gt;
&lt;p&gt;
Label Smoothing is Robustification against Model Misspecification. (arXiv:2305.08501v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08501
&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#24179;&#28369;&#26159;&#29992;&#20110;&#20462;&#25913;&#25439;&#22833;&#20989;&#25968;&#21644;&#19968;&#33268;&#30340;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#25552;&#39640;&#27491;&#30830;&#35268;&#23450;&#27169;&#22411;&#30340;&#25928;&#29575;&#65292;&#20943;&#23567;&#27169;&#22411;&#35268;&#33539;&#21270;&#19981;&#27491;&#30830;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#24179;&#28369;&#65288;LS&#65289;&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#37319;&#29992;&#24179;&#28369;&#30446;&#26631;&#12290;&#20363;&#22914;&#65292;&#22312;&#20108;&#20803;&#20998;&#31867;&#20013;&#65292;&#20256;&#32479;&#30340;&#36923;&#36753;&#22238;&#24402;&#65288;LR&#65289;&#20351;&#29992;&#29420;&#28909;&#30446;&#26631;$(1,0)^\top$&#65292;&#32780;&#20351;&#29992;&#26631;&#31614;&#24179;&#28369;&#30340;LR&#65288;LSLR&#65289;&#20351;&#29992;&#24179;&#28369;&#21518;&#30340;&#30446;&#26631;$(1-\frac{\alpha}{2},\frac{\alpha}{2})^\top$&#65292;&#20854;&#20013;$\alpha\in(0,1)$&#26159;&#24179;&#28369;&#31561;&#32423;&#65292;&#23427;&#20250;&#23548;&#33268;logit&#20540;&#25380;&#21387;&#12290;&#38500;&#20102;&#26631;&#31614;&#24179;&#28369;&#30340;&#24120;&#35265;&#35268;&#33539;&#21270;&#35299;&#37322;&#23548;&#33268;&#19981;&#19968;&#33268;&#30340;&#27010;&#29575;&#20272;&#35745;&#22120;&#20043;&#22806;&#65292;&#25105;&#20204;&#23558;LSLR&#35270;&#20026;&#20462;&#25913;&#25439;&#22833;&#20989;&#25968;&#21644;&#19968;&#33268;&#30340;&#27010;&#29575;&#20272;&#35745;&#22120;&#12290;&#20026;&#20102;&#30740;&#31350;LSLR&#23545;&#36825;&#20004;&#31181;&#20462;&#25913;&#30340;&#37325;&#35201;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20462;&#25913;&#29256;&#30340;LSLR&#65292;&#21363;MLSLR&#65292;&#23427;&#20351;&#29992;&#19982;LSLR&#30456;&#21516;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#19982;LR&#30456;&#21516;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#65292;&#20294;&#19981;&#20250;&#25380;&#21387;logit&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Label smoothing (LS) adopts smoothed targets in classification tasks. For example, in binary classification, instead of the one-hot target $(1,0)^\top$ used in conventional logistic regression (LR), LR with LS (LSLR) uses the smoothed target $(1-\frac{\alpha}{2},\frac{\alpha}{2})^\top$ with a smoothing level $\alpha\in(0,1)$, which causes squeezing of values of the logit. Apart from the common regularization-based interpretation of LS that leads to an inconsistent probability estimator, we regard LSLR as modifying the loss function and consistent estimator for probability estimation. In order to study the significance of each of these two modifications by LSLR, we introduce a modified LSLR (MLSLR) that uses the same loss function as LSLR and the same consistent estimator as LR, while not squeezing the logits. For the loss function modification, we theoretically show that MLSLR with a larger smoothing level has lower efficiency with correctly-specified models, while it exhibits higher r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;</title><link>http://arxiv.org/abs/2305.08463</link><description>&lt;p&gt;
&#22343;&#20540;&#28418;&#31227;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Mean Shift. (arXiv:2305.08463v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22343;&#20540;&#28418;&#31227;&#65288;MS&#65289;&#31639;&#27861;&#23547;&#25214;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#30340;&#27169;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#30001;MS&#31639;&#27861;&#20135;&#29983;&#30340;&#27169;&#20272;&#35745;&#24207;&#21015;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#22312;&#30456;&#24403;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#20511;&#21161;&#20110;&#20851;&#20110;{\L}ojasiewicz&#19981;&#31561;&#24335;&#30340;&#35770;&#35777;&#65292;&#35780;&#20272;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#28085;&#30422;&#35299;&#26512;&#26680;&#21644;Epanechnikov&#26680;&#30340;&#21457;&#29616;&#65292;&#24847;&#20041;&#22312;&#20110;&#28085;&#30422;&#20102;&#22312;&#22522;&#20110;KDE&#30340;&#27169;&#20272;&#35745;&#30340;&#28176;&#36817;&#32479;&#35745;&#25928;&#29575;&#26041;&#38754;&#26368;&#20248;&#30340;&#38750;&#36127;&#26680;&#8212;&#8212;&#21452;&#37325;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mean shift (MS) algorithm seeks a mode of the kernel density estimate (KDE). This study presents a convergence guarantee of the mode estimate sequence generated by the MS algorithm and an evaluation of the convergence rate, under fairly mild conditions, with the help of the argument concerning the {\L}ojasiewicz inequality. Our findings, which extend existing ones covering analytic kernels and the Epanechnikov kernel, are significant in that they cover the biweight kernel that is optimal among non-negative kernels in terms of the asymptotic statistical efficiency for the KDE-based mode estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#28145;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#20013;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#35777;&#26126;&#20102;$\mathcal{O}(\log d)$&#30340;&#28145;&#24230;&#23601;&#36275;&#20197;&#23454;&#29616;&#26222;&#36866;&#24615;&#65292;&#29992;CNN&#23398;&#20064;&#31232;&#30095;&#20989;&#25968;&#21482;&#38656;&#35201;$\tilde{\mathcal{O}}(\log^2d)$&#20010;&#26679;&#26412;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23616;&#37096;&#36830;&#25509;&#32593;&#32476;&#65288;LCN&#65289;&#20998;&#26512;&#20102;&#26435;&#37325;&#20849;&#20139;&#21644;&#23616;&#37096;&#24615;&#30340;&#24402;&#32435;&#20559;&#32622;&#30340;&#21306;&#21035;&#65292;&#24471;&#20986;&#20102;&#23427;&#20204;&#22312;&#34920;&#31034;&#38656;&#35201;&#26377;&#38480;&#24179;&#31227;&#31561;&#21464;&#21644;&#39640;&#26041;&#21521;&#36873;&#25321;&#24615;&#30340;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.08404</link><description>&lt;p&gt;
&#28145;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#24402;&#32435;&#20559;&#32622;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis of Inductive Biases in Deep Convolutional Networks. (arXiv:2305.08404v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#28145;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#20013;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#35777;&#26126;&#20102;$\mathcal{O}(\log d)$&#30340;&#28145;&#24230;&#23601;&#36275;&#20197;&#23454;&#29616;&#26222;&#36866;&#24615;&#65292;&#29992;CNN&#23398;&#20064;&#31232;&#30095;&#20989;&#25968;&#21482;&#38656;&#35201;$\tilde{\mathcal{O}}(\log^2d)$&#20010;&#26679;&#26412;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23616;&#37096;&#36830;&#25509;&#32593;&#32476;&#65288;LCN&#65289;&#20998;&#26512;&#20102;&#26435;&#37325;&#20849;&#20139;&#21644;&#23616;&#37096;&#24615;&#30340;&#24402;&#32435;&#20559;&#32622;&#30340;&#21306;&#21035;&#65292;&#24471;&#20986;&#20102;&#23427;&#20204;&#22312;&#34920;&#31034;&#38656;&#35201;&#26377;&#38480;&#24179;&#31227;&#31561;&#21464;&#21644;&#39640;&#26041;&#21521;&#36873;&#25321;&#24615;&#30340;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#20013;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#36825;&#34987;&#35748;&#20026;&#26159;CNN&#22312;&#35270;&#35273;&#20219;&#21153;&#19978;&#34920;&#29616;&#24322;&#24120;&#20986;&#33394;&#30340;&#37325;&#35201;&#39537;&#21160;&#22240;&#32032;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;CNN&#30340;&#26222;&#36866;&#24615;&#65292;&#21363;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\mathcal{O}(\log d)$&#30340;&#28145;&#24230;&#23601;&#36275;&#20197;&#23454;&#29616;&#26222;&#36866;&#24615;&#65292;&#20854;&#20013;$d$&#26159;&#36755;&#20837;&#32500;&#24230;&#12290;&#36825;&#30456;&#27604;&#20110;&#29616;&#26377;&#32467;&#26524;&#38656;&#35201;$\Omega(d)$&#30340;&#28145;&#24230;&#26159;&#19968;&#39033;&#37325;&#22823;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#29992;CNN&#23398;&#20064;&#31232;&#30095;&#20989;&#25968;&#21482;&#38656;&#35201;$\tilde{\mathcal{O}}(\log^2d)$&#20010;&#26679;&#26412;&#65292;&#34920;&#26126;&#28145;&#24230;CNN&#21487;&#20197;&#26377;&#25928;&#22320;&#25429;&#25417;&#38271;&#31243;&#31232;&#30095;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#20998;&#26512;&#20102;&#20849;&#20139;&#26435;&#37325;&#21644;&#23616;&#37096;&#24615;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#36890;&#36807;&#23545;&#31216;&#24615;&#24471;&#20986;&#32467;&#35770;&#12290;&#20026;&#20102;&#21306;&#20998;&#36825;&#20004;&#31181;&#20559;&#35265;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23616;&#37096;&#36830;&#25509;&#32593;&#32476;&#65288;LCN&#65289;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#34920;&#31034;&#38656;&#35201;&#26377;&#38480;&#24179;&#31227;&#31561;&#21464;&#21644;&#39640;&#26041;&#21521;&#36873;&#25321;&#24615;&#30340;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#28145;CNN&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#29702;&#35770;&#27934;&#23519;&#21147;&#65292;&#21516;&#26102;&#26356;&#22909;&#22320;&#29702;&#35299;&#20102;&#23427;&#20204;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the inductive biases in convolutional neural networks (CNNs), which are believed to be vital drivers behind CNNs' exceptional performance on vision-like tasks. We first analyze the universality of CNNs, i.e., the ability to approximate continuous functions. We prove that a depth of $\mathcal{O}(\log d)$ is sufficient for achieving universality, where $d$ is the input dimension. This is a significant improvement over existing results that required a depth of $\Omega(d)$. We also prove that learning sparse functions with CNNs needs only $\tilde{\mathcal{O}}(\log^2d)$ samples, indicating that deep CNNs can efficiently capture long-range sparse correlations. Note that all these are achieved through a novel combination of increased network depth and the utilization of multichanneling and downsampling.  Lastly, we study the inductive biases of weight sharing and locality through the lens of symmetry. To separate two biases, we introduce locally-connected networks (LCN
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22312;&#23545;&#25239;&#24615;RL&#20013;&#23454;&#29616;&#26080;&#22320;&#24179;&#32447;&#31574;&#30053;&#25628;&#32034;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#37319;&#29992;&#26041;&#24046;-&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#21644;&#22522;&#20110;&#21344;&#29992;&#27979;&#37327;&#30340;&#25216;&#26415;&#35299;&#20915;&#20102;&#25506;&#32034;&#21644;&#23545;&#25239;&#24615;&#22870;&#21169;&#30340;&#25361;&#25112;&#12290;&#31639;&#27861;&#36798;&#21040;&#20102;&#19968;&#20010; $\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$ &#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.08359</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#32447;&#24615;&#28151;&#21512;MDP&#20013;&#30340;&#26080;&#22320;&#24179;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs. (arXiv:2305.08359v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08359
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#22312;&#23545;&#25239;&#24615;RL&#20013;&#23454;&#29616;&#26080;&#22320;&#24179;&#32447;&#31574;&#30053;&#25628;&#32034;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#37319;&#29992;&#26041;&#24046;-&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#21644;&#22522;&#20110;&#21344;&#29992;&#27979;&#37327;&#30340;&#25216;&#26415;&#35299;&#20915;&#20102;&#25506;&#32034;&#21644;&#23545;&#25239;&#24615;&#22870;&#21169;&#30340;&#25361;&#25112;&#12290;&#31639;&#27861;&#36798;&#21040;&#20102;&#19968;&#20010; $\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$ &#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#24635;&#22870;&#21169;&#21463;&#21040;1&#30340;&#38480;&#21046;&#26102;&#65292;&#20998;&#38598;&#24335;&#24378;&#21270;&#23398;&#20064;(RL)&#24182;&#19981;&#27604;&#21333;&#33218;&#21290;&#24466;&#38382;&#39064;&#26356;&#38590;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#24773;&#20917;&#19979;&#22312;&#35268;&#21010;&#22320;&#24179;&#32447;H&#19978;&#30340;&#36951;&#25022;&#30028;&#20855;&#26377;&#23545;&#25968;&#22810;&#39033;&#24335;&#20381;&#36182;&#24615;&#12290;&#28982;&#32780;&#65292;&#26159;&#21542;&#21487;&#20197;&#23558;&#36825;&#31181;&#32467;&#26524;&#25512;&#24191;&#21040;&#23545;&#25239;&#24615;RL&#20013;&#30340;&#22870;&#21169;&#34987;&#27599;&#38598;&#21512;&#25511;&#21046;&#30340;&#24773;&#20917;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#31532;&#19968;&#31181;&#26080;&#22320;&#24179;&#32447;&#31574;&#30053;&#25628;&#32034;&#31639;&#27861;&#65292;&#32943;&#23450;&#22238;&#31572;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#25506;&#32034;&#21644;&#23545;&#25239;&#24615;&#22870;&#21169;&#24102;&#26469;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#37319;&#29992;&#20102;(1)&#26041;&#24046;-&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#21152;&#26435;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#29992;&#20110;&#36716;&#31227;&#26680;&#24515;&#30340;&#20272;&#35745;&#65307;&#21644;(2)&#19968;&#31181;&#22522;&#20110;&#21344;&#29992;&#27979;&#37327;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#32447;&#25628;&#32034;&#19968;&#20010;&#38543;&#26426;&#31574;&#30053;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#23436;&#20840;&#20449;&#24687;&#21453;&#39304;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;&#19968;&#20010;$\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$&#30340;&#36951;&#25022;&#30028;&#12290;&#20854;&#20013;$d$&#26159;&#24050;&#30693;&#29305;&#24449;&#26144;&#23556;&#30340;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have shown that episodic reinforcement learning (RL) is no harder than bandits when the total reward is bounded by $1$, and proved regret bounds that have a polylogarithmic dependence on the planning horizon $H$. However, it remains an open question that if such results can be carried over to adversarial RL, where the reward is adversarially chosen at each episode. In this paper, we answer this question affirmatively by proposing the first horizon-free policy search algorithm. To tackle the challenges caused by exploration and adversarially chosen reward, our algorithm employs (1) a variance-uncertainty-aware weighted least square estimator for the transition kernel; and (2) an occupancy measure-based technique for the online search of a \emph{stochastic} policy. We show that our algorithm achieves an $\tilde{O}\big((d+\log (|\mathcal{S}|^2 |\mathcal{A}|))\sqrt{K}\big)$ regret with full-information feedback, where $d$ is the dimension of a known feature mapping linearly 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#26088;&#22312;&#38024;&#23545;&#20855;&#26377;&#26377;&#30028;Eluder&#32500;&#24230;&#30340;&#19968;&#33324;&#20989;&#25968;&#31867;&#65292;&#25552;&#20379;&#38750;&#32447;&#24615;bandits&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#33410;&#30446;&#24335;RL&#30340;&#32479;&#19968;PAC&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.08350</link><description>&lt;p&gt;
&#26377;&#30028;Eluder&#32500;&#24230;&#19979;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#19968;PAC&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Uniform-PAC Guarantees for Model-Based RL with Bounded Eluder Dimension. (arXiv:2305.08350v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08350
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#26088;&#22312;&#38024;&#23545;&#20855;&#26377;&#26377;&#30028;Eluder&#32500;&#24230;&#30340;&#19968;&#33324;&#20989;&#25968;&#31867;&#65292;&#25552;&#20379;&#38750;&#32447;&#24615;bandits&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#33410;&#30446;&#24335;RL&#30340;&#32479;&#19968;PAC&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#21462;&#24471;&#20102;&#26174;&#30528;&#36827;&#23637;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#36825;&#20123;&#24037;&#20316;&#37117;&#20165;&#25552;&#20379;&#36951;&#25022;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;&#19968;&#20010;&#26356;&#24378;&#30340;&#24615;&#33021;&#20445;&#35777;&#8212;&#8212;&#32479;&#19968;&#27010;&#29575;&#36817;&#20284;&#27491;&#30830;&#24615;&#65288;Uniform-PAC&#65289;&#20445;&#35777;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#26263;&#31034;&#20219;&#20309;&#30446;&#26631;&#23398;&#20064;&#20934;&#30830;&#24230;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#30028;&#21644;&#22810;&#39033;&#24335;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#20351;&#29992;&#20855;&#26377;&#26377;&#30028;Eluder&#32500;&#24230;&#30340;&#19968;&#33324;&#20989;&#25968;&#31867;&#30340;&#38750;&#32447;&#24615;bandits&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#33410;&#30446;&#24335;RL&#30340;&#31639;&#27861;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#27599;&#20010;&#25805;&#20316;&#26681;&#25454;&#20854;&#30456;&#23545;&#20110;&#32622;&#20449;&#38598;&#30340;&#23485;&#24230;&#20998;&#37197;&#21040;&#19981;&#21516;&#30340;&#32423;&#21035;&#20013;&#12290;&#23454;&#29616;&#30340;&#32479;&#19968;PAC&#26679;&#26412;&#22797;&#26434;&#24230;&#26159;&#32039;&#23494;&#21305;&#37197;&#26368;&#20808;&#36827;&#30340;&#20943;&#23567;&#21040;&#32447;&#24615;&#24773;&#20917;&#19979;&#30340;&#36951;&#25022;&#30028;&#25110;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#20855;&#26377;&#26377;&#30028;Eluder&#32500;&#24230;&#30340;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#25552;&#20379;&#38750;&#32447;&#24615;bandits&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#33410;&#30446;&#24335;RL&#30340;&#32479;&#19968;PAC&#20445;&#35777;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been remarkable progress in reinforcement learning (RL) with general function approximation. However, all these works only provide regret or sample complexity guarantees. It is still an open question if one can achieve stronger performance guarantees, i.e., the uniform probably approximate correctness (Uniform-PAC) guarantee that can imply both a sub-linear regret bound and a polynomial sample complexity for any target learning accuracy. We study this problem by proposing algorithms for both nonlinear bandits and model-based episodic RL using the general function class with a bounded eluder dimension. The key idea of the proposed algorithms is to assign each action to different levels according to its width with respect to the confidence set. The achieved uniform-PAC sample complexity is tight in the sense that it matches the state-of-the-art regret bounds or sample complexity guarantees when reduced to the linear case. To the best of our knowledge, this is the firs
&lt;/p&gt;</description></item><item><title>&#21457;&#24067;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#8212;&#8212;&#31070;&#32463;&#29627;&#23572;&#20857;&#26364;&#26426;(NBM)&#65292;&#20854;&#21487;&#36890;&#36807;&#23558;CRBM&#21442;&#25968;&#36716;&#25442;&#20026;&#31070;&#32463;&#32593;&#32476;&#23558;CRBM&#25512;&#24191;&#65292;&#24182;&#25104;&#21151;&#22320;&#35299;&#20915;&#20102;&#39640;&#26031;-&#20271;&#21162;&#21033;CRBM&#22312;&#27169;&#25311;&#27491;&#24120;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.08337</link><description>&lt;p&gt;
&#31070;&#32463;&#29627;&#23572;&#20857;&#26364;&#26426;
&lt;/p&gt;
&lt;p&gt;
Neural Boltzmann Machines. (arXiv:2305.08337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08337
&lt;/p&gt;
&lt;p&gt;
&#21457;&#24067;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#8212;&#8212;&#31070;&#32463;&#29627;&#23572;&#20857;&#26364;&#26426;(NBM)&#65292;&#20854;&#21487;&#36890;&#36807;&#23558;CRBM&#21442;&#25968;&#36716;&#25442;&#20026;&#31070;&#32463;&#32593;&#32476;&#23558;CRBM&#25512;&#24191;&#65292;&#24182;&#25104;&#21151;&#22320;&#35299;&#20915;&#20102;&#39640;&#26031;-&#20271;&#21162;&#21033;CRBM&#22312;&#27169;&#25311;&#27491;&#24120;&#20998;&#24067;&#25968;&#25454;&#19978;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#20351;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#20316;&#20026;&#36755;&#20837;&#26469;&#29983;&#25104;&#26032;&#30340;&#21019;&#36896;&#24615;&#36755;&#20986;&#12290;&#26465;&#20214;&#21463;&#38480;&#27874;&#23572;&#20857;&#26364;&#26426;(CRBM)&#26159;&#19968;&#31867;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#24050;&#32463;&#34987;&#35777;&#26126;&#22312;&#24314;&#27169;&#22024;&#26434;&#30340;&#31163;&#25955;&#25110;&#36830;&#32493;&#25968;&#25454;&#26041;&#38754;&#29305;&#21035;&#25797;&#38271;&#65292;&#20294;CRBM&#30340;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#21046;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#37319;&#29992;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31070;&#32463;&#29627;&#23572;&#20857;&#26364;&#26426;(NBM)&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;CRBM&#21442;&#25968;&#36716;&#25442;&#20026;&#33258;&#24049;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#23558;CRBM&#25512;&#24191;&#65292;&#36825;&#20123;&#32593;&#32476;&#20801;&#35768;&#26159;&#26465;&#20214;&#36755;&#20837;&#30340;&#20989;&#25968;&#12290;NBM&#26159;&#39640;&#24230;&#28789;&#27963;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#36817;&#20284;&#22320;&#26368;&#22823;&#21270;&#25968;&#25454;&#30340;&#23545;&#25968;&#20284;&#28982;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;NBM&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#36890;&#24120;&#36896;&#25104;&#39640;&#26031;-&#20271;&#21162;&#21033;CRBM&#38382;&#39064;&#30340;&#27491;&#24120;&#20998;&#24067;&#25968;&#25454;&#26041;&#38754;&#12290;&#21487;&#20197;&#22312;https://github.com/unlearnai/neural-boltzmann-machines&#25214;&#21040;&#29992;&#20110;&#37325;&#29616;&#25105;&#20204;&#32467;&#26524;&#30340;&#20195;&#30721;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional generative models are capable of using contextual information as input to create new imaginative outputs. Conditional Restricted Boltzmann Machines (CRBMs) are one class of conditional generative models that have proven to be especially adept at modeling noisy discrete or continuous data, but the lack of expressivity in CRBMs have limited their widespread adoption. Here we introduce Neural Boltzmann Machines (NBMs) which generalize CRBMs by converting each of the CRBM parameters to their own neural networks that are allowed to be functions of the conditional inputs. NBMs are highly flexible conditional generative models that can be trained via stochastic gradient descent to approximately maximize the log-likelihood of the data. We demonstrate the utility of NBMs especially with normally distributed data which has historically caused problems for Gaussian-Bernoulli CRBMs. Code to reproduce our results can be found at https://github.com/unlearnai/neural-boltzmann-machines.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#37492;&#21035;&#22120;&#35757;&#32451;GAN&#30340;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#31639;&#27861;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#65292;&#25581;&#31034;&#20102;&#23398;&#20064;&#29575;&#12289;&#27491;&#21017;&#21270;&#21644;&#24102;&#23485;&#23545;&#20854;&#24433;&#21709;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#25910;&#25947;&#12289;&#25391;&#33633;&#25110;&#21457;&#25955;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2305.08277</link><description>&lt;p&gt;
&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#31639;&#27861;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Local Convergence of Gradient Descent-Ascent for Training Generative Adversarial Networks. (arXiv:2305.08277v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#37492;&#21035;&#22120;&#35757;&#32451;GAN&#30340;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#31639;&#27861;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#65292;&#25581;&#31034;&#20102;&#23398;&#20064;&#29575;&#12289;&#27491;&#21017;&#21270;&#21644;&#24102;&#23485;&#23545;&#20854;&#24433;&#21709;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#25910;&#25947;&#12289;&#25391;&#33633;&#25110;&#21457;&#25955;&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22797;&#26434;&#39640;&#32500;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#35757;&#32451;&#26041;&#27861;&#12290;&#35757;&#32451;GAN&#30340;&#26631;&#20934;&#26041;&#27861;&#28041;&#21450;&#23545;&#26497;&#23567;-&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#36827;&#34892;&#26799;&#24230;&#19979;&#38477;-&#19978;&#21319;&#65288;GDA&#65289;&#36807;&#31243;&#12290;&#30001;&#20110;&#21160;&#24577;&#30340;&#38750;&#32447;&#24615;&#24615;&#36136;&#65292;&#35813;&#36807;&#31243;&#36890;&#24120;&#24456;&#38590;&#20998;&#26512;&#12290;&#26412;&#30740;&#31350;&#37325;&#28857;&#30740;&#31350;&#20102;&#20351;&#29992;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#37492;&#21035;&#22120;&#35757;&#32451;GAN&#26102;&#30340;GDA&#23616;&#37096;&#21160;&#24577;&#12290;&#35813;&#25910;&#25947;&#24615;&#20998;&#26512;&#26159;&#22312;[Becker et al. 2022]&#30340;&#8220;&#23396;&#31435;&#28857;&#27169;&#22411;&#8221;&#20551;&#35774;&#19979;&#65292;&#23545;&#25551;&#36848;GDA&#36845;&#20195;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#31995;&#32479;&#36827;&#34892;&#32447;&#24615;&#21270;&#24471;&#21040;&#30340;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#23398;&#20064;&#29575;&#12289;&#27491;&#21017;&#21270;&#21644;&#26680;&#21028;&#21035;&#22120;&#30340;&#24102;&#23485;&#23545;GDA&#23616;&#37096;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30456;&#21464;&#29616;&#35937;&#65292;&#34920;&#26126;&#31995;&#32479;&#20309;&#26102;&#25910;&#25947;&#12289;&#25391;&#33633;&#25110;&#21457;&#25955;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#39564;&#35777;&#25105;&#20204;&#32467;&#35770;&#30340;&#25968;&#20540;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs) are a popular formulation to train generative models for complex high dimensional data. The standard method for training GANs involves a gradient descent-ascent (GDA) procedure on a minimax optimization problem. This procedure is hard to analyze in general due to the nonlinear nature of the dynamics. We study the local dynamics of GDA for training a GAN with a kernel-based discriminator. This convergence analysis is based on a linearization of a non-linear dynamical system that describes the GDA iterations, under an \textit{isolated points model} assumption from [Becker et al. 2022]. Our analysis brings out the effect of the learning rates, regularization, and the bandwidth of the kernel discriminator, on the local convergence rate of GDA. Importantly, we show phase transitions that indicate when the system converges, oscillates, or diverges. We also provide numerical simulations that verify our claims.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.08074</link><description>&lt;p&gt;
&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#21644;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#22312;&#28151;&#27788;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#26159;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21160;&#24577;&#30340;&#39044;&#27979;&#21644;&#27169;&#22411;&#31616;&#21270;&#65292;&#22312;&#29289;&#29702;&#31185;&#23398;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65292;&#20294;&#22312;&#30830;&#23450;&#24615;&#28151;&#27788;&#20013;&#65292;&#23427;&#30340;&#24615;&#36136;&#25110;&#32773;&#23427;&#30340;&#25910;&#25947;&#24615;&#36824;&#19981;&#28165;&#26970;&#12290;&#29305;&#21035;&#26159;&#65292;EDMD&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#22914;&#20309;&#22788;&#29702;&#38656;&#35201;&#25551;&#32472;&#28151;&#27788;&#21160;&#21147;&#23398;&#21547;&#20041;&#30340;&#27491;&#21017;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#20063;&#26159;&#19981;&#28165;&#26970;&#30340;&#12290;&#26412;&#25991;&#22312;&#20998;&#26512;&#19978;&#31616;&#21333;&#30340;&#19968;&#20010;&#22278;&#29615;&#23637;&#24320;&#26144;&#23556;&#30340;&#26368;&#31616;&#21333;&#20363;&#23376;&#19978;&#65292;&#21457;&#23637;&#20102;&#20851;&#20110;EDMD&#30340;&#19968;&#33324;&#30340;&#12289;&#20005;&#26684;&#30340;&#29702;&#35770;&#12290;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#20851;&#20110;&#22312;&#21333;&#20301;&#22278;&#19978;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#65288;OPUC&#65289;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#26102;&#65292;&#38024;&#23545;&#22810;&#39033;&#24335;&#30340;&#21487;&#35266;&#27979;&#23383;&#20856;&#30340;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#20855;&#26377;&#25351;&#25968;&#25928;&#29575;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#21040;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#30340;&#25351;&#25968;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;OffCEM&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#23545;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#19978;&#19979;&#25991;&#21305;&#37197;&#31574;&#30053;&#36827;&#34892;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#12290;&#35813;&#20272;&#35745;&#22120;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#22870;&#21169;&#20272;&#35745;&#26469;&#22788;&#29702;&#27531;&#20313;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#26032;&#30340;&#26412;&#22320;&#27491;&#30830;&#24615;&#26465;&#20214;&#19979;&#20445;&#25345;&#26080;&#20559;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;OffCEM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22823;&#21160;&#20316;&#31354;&#38388;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.08062</link><description>&lt;p&gt;
&#22522;&#20110;&#36830;&#35789;&#25928;&#24212;&#24314;&#27169;&#30340;&#22823;&#21160;&#20316;&#31354;&#38388;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Off-Policy Evaluation for Large Action Spaces via Conjunct Effect Modeling. (arXiv:2305.08062v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08062
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;OffCEM&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#23545;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#19978;&#19979;&#25991;&#21305;&#37197;&#31574;&#30053;&#36827;&#34892;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#12290;&#35813;&#20272;&#35745;&#22120;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#22870;&#21169;&#20272;&#35745;&#26469;&#22788;&#29702;&#27531;&#20313;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#22312;&#26032;&#30340;&#26412;&#22320;&#27491;&#30830;&#24615;&#26465;&#20214;&#19979;&#20445;&#25345;&#26080;&#20559;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;OffCEM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22823;&#21160;&#20316;&#31354;&#38388;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#23545;&#20110;&#20256;&#32479;&#37325;&#35201;&#24615;&#21152;&#26435;&#26041;&#27861;&#26041;&#24040;&#30340;&#22823;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#30340;&#19978;&#19979;&#25991;&#21305;&#37197;&#31574;&#30053;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#26041;&#24040;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20272;&#35745;&#22120;OffCEM&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#36830;&#35789;&#25928;&#24212;&#27169;&#22411;&#65288;CEM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25928;&#24212;&#20998;&#35299;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;&#25928;&#24212;&#20998;&#20026;&#32676;&#38598;&#25928;&#24212;&#21644;&#27531;&#24046;&#25928;&#24212;&#12290;OffCEM&#20165;&#23545;&#34892;&#21160;&#32676;&#38598;&#24212;&#29992;&#37325;&#35201;&#24615;&#21152;&#26435;&#65292;&#36890;&#36807;&#22522;&#20110;&#27169;&#22411;&#30340;&#22870;&#21169;&#20272;&#35745;&#26469;&#22788;&#29702;&#27531;&#20313;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26032;&#30340;&#26412;&#22320;&#27491;&#30830;&#24615;&#26465;&#20214;&#19979;&#65292;&#35813;&#20272;&#35745;&#22120;&#26159;&#26080;&#20559;&#30340;&#65292;&#35813;&#26465;&#20214;&#20165;&#35201;&#27714;&#27531;&#24046;&#25928;&#24212;&#27169;&#22411;&#20445;&#30041;&#27599;&#20010;&#32676;&#38598;&#20013;&#34892;&#21160;&#30340;&#30456;&#23545;&#26399;&#26395;&#22870;&#21169;&#24046;&#24322;&#12290;&#20026;&#20102;&#20805;&#20998;&#21033;&#29992;CEM&#21644;&#26412;&#22320;&#27491;&#30830;&#24615;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20004;&#27493;&#36807;&#31243;&#65292;&#29992;&#20110;&#25191;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#20272;&#35745;&#65292;&#31532;&#19968;&#27493;&#26368;&#23567;&#21270;&#20559;&#24046;&#65292;&#31532;&#20108;&#27493;&#26368;&#23567;&#21270;&#26041;&#24046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25152;&#24471;&#21040;&#30340;OPE&#20272;&#35745;&#22120;OffCEM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22823;&#21160;&#20316;&#31354;&#38388;&#25968;&#25454;&#38598;&#19978;&#37117;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study off-policy evaluation (OPE) of contextual bandit policies for large discrete action spaces where conventional importance-weighting approaches suffer from excessive variance. To circumvent this variance issue, we propose a new estimator, called OffCEM, that is based on the conjunct effect model (CEM), a novel decomposition of the causal effect into a cluster effect and a residual effect. OffCEM applies importance weighting only to action clusters and addresses the residual causal effect through model-based reward estimation. We show that the proposed estimator is unbiased under a new condition, called local correctness, which only requires that the residual-effect model preserves the relative expected reward differences of the actions within each cluster. To best leverage the CEM and local correctness, we also propose a new two-step procedure for performing model-based estimation that minimizes bias in the first step and variance in the second step. We find that the resulting O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#24212;&#29992;&#20110;&#20219;&#20309;MPNN&#32467;&#26500;&#30340;&#26694;&#26550;&#65292;&#25191;&#34892;&#22522;&#20110;&#23618;&#30340;&#21160;&#24577;&#37325;&#36830;&#26469;&#30830;&#20445;&#36880;&#28176;&#23494;&#38598;&#21270;&#30340;&#22270;&#24418;&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#24310;&#36831;&#26426;&#21046;&#65292;&#20801;&#35768;&#36328;&#23618;&#33410;&#28857;&#20043;&#38388;&#30340;&#36339;&#36291;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2305.08018</link><description>&lt;p&gt;
DRew&#65306;&#24102;&#24310;&#36831;&#30340;&#21160;&#24577;&#37325;&#36830;&#28040;&#24687;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
DRew: Dynamically Rewired Message Passing with Delay. (arXiv:2305.08018v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#24212;&#29992;&#20110;&#20219;&#20309;MPNN&#32467;&#26500;&#30340;&#26694;&#26550;&#65292;&#25191;&#34892;&#22522;&#20110;&#23618;&#30340;&#21160;&#24577;&#37325;&#36830;&#26469;&#30830;&#20445;&#36880;&#28176;&#23494;&#38598;&#21270;&#30340;&#22270;&#24418;&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#24310;&#36831;&#26426;&#21046;&#65292;&#20801;&#35768;&#36328;&#23618;&#33410;&#28857;&#20043;&#38388;&#30340;&#36339;&#36291;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#35777;&#26126;&#65292;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#23384;&#22312;&#36807;&#24230;&#21387;&#32553;&#29616;&#35937;&#65292;&#23548;&#33268;&#38271;&#31243;&#30456;&#20114;&#20316;&#29992;&#20219;&#21153;&#34920;&#29616;&#19981;&#20339;&#12290;&#36825;&#20027;&#35201;&#24402;&#22240;&#20110;&#21482;&#22312;&#33410;&#28857;&#30340;&#30456;&#37051;&#23621;&#20043;&#38388;&#36827;&#34892;&#23616;&#37096;&#28040;&#24687;&#20256;&#36882;&#12290;&#35797;&#22270;&#20351;&#22270;&#24418;&#8220;&#26356;&#36830;&#36890;&#8221;&#24182;&#19988;&#26356;&#36866;&#21512;&#38271;&#31243;&#20219;&#21153;&#30340;&#37325;&#36830;&#26041;&#27861;&#36890;&#24120;&#20250;&#22833;&#21435;&#22522;&#20110;&#22270;&#24418;&#36317;&#31163;&#25552;&#20379;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#22240;&#20026;&#23427;&#20204;&#20250;&#20351;&#36828;&#31243;&#33410;&#28857;&#22312;&#27599;&#19968;&#23618;&#20013;&#31435;&#21363;&#36890;&#20449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;MPNN&#26550;&#26500;&#65292;&#20197;&#25191;&#34892;&#22522;&#20110;&#23618;&#30340;&#37325;&#36830;&#65292;&#20197;&#30830;&#20445;&#36880;&#28176;&#21152;&#23494;&#22270;&#24418;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#24310;&#36831;&#26426;&#21046;&#65292;&#23427;&#20801;&#35768;&#26681;&#25454;&#23618;&#21644;&#23427;&#20204;&#30340;&#30456;&#20114;&#36317;&#31163;&#22312;&#33410;&#28857;&#20043;&#38388;&#36827;&#34892;&#36339;&#36291;&#36830;&#25509;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#38271;&#31243;&#20219;&#21153;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;&#20854;&#20248;&#20110;&#22270;&#24418;&#21464;&#25442;&#22120;&#21644;&#22810;&#36339;MPNN&#12290;
&lt;/p&gt;
&lt;p&gt;
Message passing neural networks (MPNNs) have been shown to suffer from the phenomenon of over-squashing that causes poor performance for tasks relying on long-range interactions. This can be largely attributed to message passing only occurring locally, over a node's immediate neighbours. Rewiring approaches attempting to make graphs `more connected', and supposedly better suited to long-range tasks, often lose the inductive bias provided by distance on the graph since they make distant nodes communicate instantly at every layer. In this paper we propose a framework, applicable to any MPNN architecture, that performs a layer-dependent rewiring to ensure gradual densification of the graph. We also propose a delay mechanism that permits skip connections between nodes depending on the layer and their mutual distance. We validate our approach on several long-range tasks and show that it outperforms graph Transformers and multi-hop MPNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#32039;&#33268;&#24555;&#36895;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#65292;&#21487;&#20197;&#20445;&#35777;&#38750;&#27431;&#20960;&#37324;&#24471;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#22270;&#23884;&#20837;&#22312;&#23454;&#38469;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#19979;&#30340;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/2305.07971</link><description>&lt;p&gt;
&#24230;&#37327;&#31354;&#38388;&#20013;&#22270;&#23884;&#20837;&#30340;&#32039;&#33268;&#24555;&#36895;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Tight and fast generalization error bound of graph embedding in metric space. (arXiv:2305.07971v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07971
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#32039;&#33268;&#24555;&#36895;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#65292;&#21487;&#20197;&#20445;&#35777;&#38750;&#27431;&#20960;&#37324;&#24471;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#22270;&#23884;&#20837;&#22312;&#23454;&#38469;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#19979;&#30340;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#24230;&#37327;&#31354;&#38388;&#20013;&#23454;&#29616;&#26377;&#25928;&#19988;&#39640;&#25928;&#30340;&#22270;&#23884;&#20837;&#65292;&#26088;&#22312;&#33719;&#24471;&#22312;&#24230;&#37327;&#31354;&#38388;&#20013;&#21453;&#26144;&#22270;&#32467;&#26500;&#30340;&#39030;&#28857;&#34920;&#31034;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#21452;&#26354;&#31354;&#38388;&#20013;&#30340;&#22270;&#23884;&#20837;&#22312;&#23884;&#20837;&#20855;&#26377;&#20998;&#23618;&#26641;&#32467;&#26500;&#30340;&#22270;&#19978;&#65292;&#20363;&#22914;&#33258;&#28982;&#35821;&#35328;&#12289;&#31038;&#20132;&#32593;&#32476;&#21644;&#30693;&#35782;&#24211;&#20013;&#30340;&#25968;&#25454;&#65292;&#24050;&#32463;&#33719;&#24471;&#20102;&#23454;&#39564;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#29702;&#35770;&#20998;&#26512;&#26174;&#31034;&#65292;&#38750;&#27431;&#20960;&#37324;&#24471;&#22270;&#23884;&#20837;&#30340;&#27867;&#21270;&#35823;&#24046;&#27604;&#27431;&#20960;&#37324;&#24471;&#22270;&#23884;&#20837;&#30340;&#35823;&#24046;&#19978;&#38480;&#35201;&#39640;&#24471;&#22810;&#65292;&#39640;&#27867;&#21270;&#35823;&#24046;&#34920;&#26126;&#25968;&#25454;&#20013;&#30340;&#19981;&#23436;&#25972;&#24615;&#21644;&#22122;&#22768;&#21487;&#33021;&#20250;&#26174;&#33879;&#25439;&#22351;&#23398;&#20064;&#24615;&#33021;&#12290;&#36825;&#24847;&#21619;&#30528;&#29616;&#26377;&#30340;&#30028;&#38480;&#19981;&#33021;&#20445;&#35777;&#23454;&#38469;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#19979;&#22312;&#38750;&#27431;&#20960;&#37324;&#24471;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#22270;&#23884;&#20837;&#25104;&#21151;&#65292;&#36825;&#21487;&#33021;&#20250;&#38459;&#27490;&#38750;&#27431;&#20960;&#37324;&#24471;&#22270;&#23884;&#20837;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#38750;&#27431;&#20960;&#37324;&#24471;&#24230;&#37327;&#31354;&#38388;&#20013;&#22270;&#23884;&#20837;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#65292;&#35813;&#19978;&#38480;&#32039;&#20945;&#19988;&#24555;&#36895;&#65292;&#21487;&#20197;&#20445;&#35777;&#22312;&#23454;&#38469;&#35757;&#32451;&#25968;&#25454;&#35268;&#27169;&#19979;&#38750;&#27431;&#20960;&#37324;&#24471;&#22270;&#23884;&#20837;&#30340;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have experimentally shown that we can achieve in non-Euclidean metric space effective and efficient graph embedding, which aims to obtain the vertices' representations reflecting the graph's structure in the metric space. Specifically, graph embedding in hyperbolic space has experimentally succeeded in embedding graphs with hierarchical-tree structure, e.g., data in natural languages, social networks, and knowledge bases. However, recent theoretical analyses have shown a much higher upper bound on non-Euclidean graph embedding's generalization error than Euclidean one's, where a high generalization error indicates that the incompleteness and noise in the data can significantly damage learning performance. It implies that the existing bound cannot guarantee the success of graph embedding in non-Euclidean metric space in a practical training data size, which can prevent non-Euclidean graph embedding's application in real problems. This paper provides a novel upper bound of
&lt;/p&gt;</description></item><item><title>&#32473;&#20986;&#20102;&#22312;&#38543;&#26426;&#27700;&#24211;&#27169;&#22411;&#19978;&#20351;&#29992;&#22352;&#26631;&#19979;&#38477;&#27861;&#36827;&#34892;&#20248;&#21270;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#21644;&#23610;&#24230;&#23450;&#24459;&#65292;&#20026;&#30828;&#20214;&#32593;&#32476;&#20248;&#21270;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2305.07908</link><description>&lt;p&gt;
&#24067;&#23572;&#26435;&#37325;&#20248;&#21270;&#30340;&#25910;&#25947;&#24615;&#21644;&#23610;&#24230;&#22312;&#30828;&#20214;&#27700;&#24211;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convergence and scaling of Boolean-weight optimization for hardware reservoirs. (arXiv:2305.07908v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07908
&lt;/p&gt;
&lt;p&gt;
&#32473;&#20986;&#20102;&#22312;&#38543;&#26426;&#27700;&#24211;&#27169;&#22411;&#19978;&#20351;&#29992;&#22352;&#26631;&#19979;&#38477;&#27861;&#36827;&#34892;&#20248;&#21270;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#21644;&#23610;&#24230;&#23450;&#24459;&#65292;&#20026;&#30828;&#20214;&#32593;&#32476;&#20248;&#21270;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#30828;&#20214;&#21270;&#26159;&#23454;&#29616;&#19979;&#19968;&#20195;&#39640;&#25928;&#21644;&#24378;&#22823;&#20154;&#24037;&#26234;&#33021;&#35299;&#20915;&#26041;&#26696;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#38500;&#20102;&#23454;&#29616;&#24182;&#34892;&#12289;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#30828;&#20214;&#26550;&#26500;&#22806;&#65292;&#29992;&#25277;&#26679;&#26377;&#25928;&#30340;&#26041;&#27861;&#20248;&#21270;&#31995;&#32479;&#26497;&#22823;&#30340;&#21442;&#25968;&#31354;&#38388;&#20063;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#20998;&#26512;&#22320;&#23548;&#20986;&#20102;&#39640;&#25928;&#22352;&#26631;&#19979;&#38477;&#27861;&#22312;&#20248;&#21270;&#38543;&#26426;&#22797;&#26434;&#31070;&#32463;&#32593;&#32476;--&#27700;&#24211;&#30340;&#35835;&#20986;&#23618;&#25152;&#38656;&#30340;&#23610;&#24230;&#23450;&#24459;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25910;&#25947;&#26159;&#25351;&#25968;&#32423;&#30340;&#65292;&#24182;&#19988;&#38543;&#30528;&#32593;&#32476;&#31070;&#32463;&#20803;&#25968;&#37327;&#30340;&#32447;&#24615;&#32553;&#25918;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#23436;&#20840;&#22797;&#29616;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#30340;&#20809;&#23376;&#27700;&#24211;&#23454;&#39564;&#20013;&#30340;&#25910;&#25947;&#24615;&#21644;&#23610;&#24230;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#30828;&#20214;&#32593;&#32476;&#20248;&#21270;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#22522;&#30784;&#65292;&#24182;&#30830;&#23450;&#20102;&#26377;&#21069;&#36884;&#30340;&#20248;&#21270;&#25910;&#26463;&#36895;&#24230;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hardware implementation of neural network are an essential step to implement next generation efficient and powerful artificial intelligence solutions.  Besides the realization of a parallel, efficient and scalable hardware architecture, the optimization of the system's extremely large parameter space with sampling-efficient approaches is essential.  Here, we analytically derive the scaling laws for highly efficient Coordinate Descent applied to optimizing the readout layer of a random recurrently connection neural network, a reservoir.  We demonstrate that the convergence is exponential and scales linear with the network's number of neurons.  Our results perfectly reproduce the convergence and scaling of a large-scale photonic reservoir implemented in a proof-of-concept experiment.  Our work therefore provides a solid foundation for such optimization in hardware networks, and identifies future directions that are promising for optimizing convergence speed during learning leveraging mea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30452;&#25509;&#27169;&#25311;&#32597;&#35265;&#20107;&#20214;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#32467;&#21512;&#37325;&#35201;&#24615;&#37319;&#26679;&#33719;&#24471;&#39640;&#31934;&#24230;&#30340;&#22797;&#26434;&#31215;&#20998;&#21644;&#26399;&#26395;&#20272;&#35745;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#24182;&#20026;&#32597;&#35265;&#20107;&#20214;&#20998;&#24067;&#25552;&#20379;&#33268;&#21629;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.07863</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#32597;&#35265;&#20107;&#20214;&#27169;&#25311;&#30340;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Flow-Based Generative Model for Rare-Event Simulation. (arXiv:2305.07863v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07863
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30452;&#25509;&#27169;&#25311;&#32597;&#35265;&#20107;&#20214;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#32467;&#21512;&#37325;&#35201;&#24615;&#37319;&#26679;&#33719;&#24471;&#39640;&#31934;&#24230;&#30340;&#22797;&#26434;&#31215;&#20998;&#21644;&#26399;&#26395;&#20272;&#35745;&#65292;&#26377;&#25928;&#22320;&#25552;&#39640;&#37319;&#26679;&#25928;&#29575;&#24182;&#20026;&#32597;&#35265;&#20107;&#20214;&#20998;&#24067;&#25552;&#20379;&#33268;&#21629;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#35299;&#20915;&#20915;&#31574;&#38382;&#39064;&#36890;&#24120;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#20272;&#35745;&#20915;&#31574;&#30340;&#26399;&#26395;&#32467;&#26524;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#37319;&#26679;&#21487;&#33021;&#20250;&#24573;&#30053;&#32597;&#35265;&#20294;&#37325;&#35201;&#30340;&#20107;&#20214;&#65292;&#36825;&#21487;&#33021;&#20250;&#20005;&#37325;&#24433;&#21709;&#20915;&#31574;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#20854;&#20013;&#35757;&#32451;&#20102;&#19968;&#20010;&#24402;&#19968;&#21270;&#27969;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#30452;&#25509;&#20174;&#26465;&#20214;&#20998;&#24067;&#20013;&#27169;&#25311;&#26679;&#26412;&#65292;&#21069;&#25552;&#26159;&#21457;&#29983;&#32597;&#35265;&#20107;&#20214;&#12290;&#36890;&#36807;&#21033;&#29992;&#32806;&#21512;&#27969;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#21407;&#21017;&#19978;&#20219;&#24847;&#22909;&#22320;&#36924;&#36817;&#20219;&#20309;&#37319;&#26679;&#20998;&#24067;&#12290;&#36890;&#36807;&#23558;&#36924;&#36817;&#26041;&#27861;&#19982;&#37325;&#35201;&#24615;&#37319;&#26679;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#39640;&#31934;&#24230;&#30340;&#22797;&#26434;&#31215;&#20998;&#21644;&#26399;&#26395;&#20272;&#35745;&#12290;&#25105;&#20204;&#21253;&#25324;&#20102;&#20960;&#20010;&#31034;&#20363;&#26469;&#28436;&#31034;&#22914;&#20309;&#22312;&#39640;&#32500;&#21644;&#32597;&#35265;&#20107;&#20214;&#35774;&#32622;&#20013;&#20351;&#29992;&#35813;&#26041;&#27861;&#36827;&#34892;&#26377;&#25928;&#37319;&#26679;&#21644;&#20272;&#35745;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#30452;&#25509;&#20174;&#32597;&#35265;&#20107;&#20214;&#20998;&#24067;&#20013;&#27169;&#25311;&#21487;&#20197;&#33719;&#24471;&#20851;&#20110;&#32597;&#35265;&#20107;&#20214;&#21457;&#29983;&#26041;&#24335;&#30340;&#37325;&#35201;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving decision problems in complex, stochastic environments is often achieved by estimating the expected outcome of decisions via Monte Carlo sampling. However, sampling may overlook rare, but important events, which can severely impact the decision making process. We present a method in which a Normalizing Flow generative model is trained to simulate samples directly from a conditional distribution given that a rare event occurs. By utilizing Coupling Flows, our model can, in principle, approximate any sampling distribution arbitrarily well. By combining the approximation method with Importance Sampling, highly accurate estimates of complicated integrals and expectations can be obtained. We include several examples to demonstrate how the method can be used for efficient sampling and estimation, even in high-dimensional and rare-event settings. We illustrate that by simulating directly from a rare-event distribution significant insight can be gained into the way rare events happen.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23485;&#24230;&#20026; $n$&#65292;&#28145;&#24230;&#20026; $L$ &#30340;&#38543;&#26426;&#20840;&#36830;&#25509; ReLU &#32593;&#32476;&#20013; $\mu$P &#23398;&#20064;&#29575;&#23545; $n$ &#21644; $L$ &#30340;&#20381;&#36182;&#24615;&#65292;&#21457;&#29616;&#38500;&#31532;&#19968;&#23618;&#21644;&#26368;&#21518;&#19968;&#23618;&#20197;&#22806;&#65292;&#26368;&#22823;&#23398;&#20064;&#29575;&#19982; $n$ &#26080;&#20851;&#65292;&#20294;&#19982; $L$ &#25353; $L^{-3/2}$ &#32553;&#25918;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.07810</link><description>&lt;p&gt;
ReLU MLPs &#20013; $\mu$P &#23398;&#20064;&#36895;&#29575;&#30340;&#28145;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Depth Dependence of $\mu$P Learning Rates in ReLU MLPs. (arXiv:2305.07810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23485;&#24230;&#20026; $n$&#65292;&#28145;&#24230;&#20026; $L$ &#30340;&#38543;&#26426;&#20840;&#36830;&#25509; ReLU &#32593;&#32476;&#20013; $\mu$P &#23398;&#20064;&#29575;&#23545; $n$ &#21644; $L$ &#30340;&#20381;&#36182;&#24615;&#65292;&#21457;&#29616;&#38500;&#31532;&#19968;&#23618;&#21644;&#26368;&#21518;&#19968;&#23618;&#20197;&#22806;&#65292;&#26368;&#22823;&#23398;&#20064;&#29575;&#19982; $n$ &#26080;&#20851;&#65292;&#20294;&#19982; $L$ &#25353; $L^{-3/2}$ &#32553;&#25918;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#31616;&#30701;&#30340;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#23485;&#24230;&#20026; $n$&#65292;&#28145;&#24230;&#20026; $L$ &#30340;&#38543;&#26426;&#20840;&#36830;&#25509; ReLU &#32593;&#32476;&#65292;&#24182;&#37197;&#22791;&#20102;&#24179;&#22343;&#22330;&#26435;&#37325;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#30340;&#30446;&#30340;&#26159;&#30740;&#31350; $\mu$P &#23398;&#20064;&#29575;&#23545; $n$ &#21644; $L$ &#30340;&#20381;&#36182;&#24615;&#8212;&#8212;&#22312; $n,L$ &#24456;&#22823;&#26102; &#65292;&#32463;&#36807;&#26799;&#24230;&#19979;&#38477;&#19968;&#27493;&#21518;&#30340;&#39044;&#28608;&#27963;&#22343;&#26041;&#24046;&#21464;&#21270;&#20173;&#20445;&#25345;&#22343;&#21248;&#26377;&#30028;&#30340;&#26368;&#22823;&#23398;&#20064;&#29575;&#12290;&#19982; Yang &#31561;&#20154;&#20851;&#20110; $\mu$P &#30340;&#20808;&#21069;&#24037;&#20316;&#19968;&#26679;&#65292;&#25105;&#20204;&#21457;&#29616;&#38500;&#31532;&#19968;&#23618;&#21644;&#26368;&#21518;&#19968;&#23618;&#30340;&#26435;&#37325;&#22806;&#65292;&#36825;&#20010;&#26368;&#22823;&#26356;&#26032;&#23398;&#20064;&#29575;&#19982; $n$ &#26080;&#20851;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#23545; $L$ &#26377;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#20381;&#36182;&#24615;&#65292;&#25353; $L^{-3/2}$ &#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this short note we consider random fully connected ReLU networks of width $n$ and depth $L$ equipped with a mean-field weight initialization. Our purpose is to study the dependence on $n$ and $L$ of the maximal update ($\mu$P) learning rate, the largest learning rate for which the mean squared change in pre-activations after one step of gradient descent remains uniformly bounded at large $n,L$. As in prior work on $\mu$P of Yang et. al., we find that this maximal update learning rate is independent of $n$ for all but the first and last layer weights. However, we find that it has a non-trivial dependence of $L$, scaling like $L^{-3/2}.$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20026;ResNets&#23548;&#20986;&#31995;&#32479;&#30340;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#65292;&#25351;&#20986;&#23545;&#20110;&#28145;&#23618;&#32593;&#32476;&#26550;&#26500;&#65292;&#32553;&#25918;&#21442;&#25968;&#26159;&#20248;&#21270;&#20449;&#21495;&#20256;&#25773;&#21644;&#30830;&#20445;&#26377;&#25928;&#21033;&#29992;&#32593;&#32476;&#28145;&#24230;&#26041;&#38754;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2305.07715</link><description>&lt;p&gt;
&#36890;&#36807;&#27531;&#24046;&#32553;&#25918;&#23454;&#29616;ResNets&#30340;&#20449;&#21495;&#26368;&#20248;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
Optimal signal propagation in ResNets through residual scaling. (arXiv:2305.07715v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20026;ResNets&#23548;&#20986;&#31995;&#32479;&#30340;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#65292;&#25351;&#20986;&#23545;&#20110;&#28145;&#23618;&#32593;&#32476;&#26550;&#26500;&#65292;&#32553;&#25918;&#21442;&#25968;&#26159;&#20248;&#21270;&#20449;&#21495;&#20256;&#25773;&#21644;&#30830;&#20445;&#26377;&#25928;&#21033;&#29992;&#32593;&#32476;&#28145;&#24230;&#26041;&#38754;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Residual&#32593;&#32476;&#65288;ResNets&#65289;&#22312;&#22823;&#28145;&#24230;&#19978;&#27604;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#26356;&#22909;&#30340;&#35757;&#32451;&#33021;&#21147;&#21644;&#24615;&#33021;&#12290;&#24341;&#20837;&#36339;&#36807;&#36830;&#25509;&#21487;&#20197;&#20419;&#36827;&#20449;&#21495;&#21521;&#26356;&#28145;&#23618;&#30340;&#20256;&#36882;&#12290;&#27492;&#22806;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#21457;&#29616;&#20026;&#27531;&#24046;&#20998;&#25903;&#28155;&#21152;&#32553;&#25918;&#21442;&#25968;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#23613;&#31649;&#20182;&#20204;&#32463;&#39564;&#24615;&#22320;&#30830;&#23450;&#20102;&#36825;&#31181;&#32553;&#25918;&#21442;&#25968;&#29305;&#21035;&#26377;&#21033;&#30340;&#21462;&#20540;&#33539;&#22260;&#65292;&#20294;&#20854;&#30456;&#20851;&#30340;&#24615;&#33021;&#25552;&#21319;&#21450;&#20854;&#22312;&#32593;&#32476;&#36229;&#21442;&#25968;&#19978;&#30340;&#26222;&#36866;&#24615;&#20173;&#38656;&#35201;&#36827;&#19968;&#27493;&#29702;&#35299;&#12290;&#23545;&#20110;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFNets&#65289;&#65292;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#22312;&#20449;&#21495;&#20256;&#25773;&#21644;&#36229;&#21442;&#25968;&#35843;&#33410;&#26041;&#38754;&#33719;&#24471;&#20102;&#37325;&#35201;&#27934;&#35265;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#20026;ResNets&#23548;&#20986;&#20102;&#19968;&#20010;&#31995;&#32479;&#30340;&#26377;&#38480;&#23610;&#23544;&#29702;&#35770;&#65292;&#20197;&#30740;&#31350;&#20449;&#21495;&#20256;&#25773;&#21450;&#20854;&#23545;&#27531;&#24046;&#20998;&#25903;&#32553;&#25918;&#30340;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#23548;&#20986;&#21709;&#24212;&#20989;&#25968;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#65292;&#36825;&#26159;&#34913;&#37327;&#32593;&#32476;&#23545;&#36755;&#20837;&#25935;&#24863;&#24615;&#30340;&#19968;&#31181;&#25351;&#26631;&#65292;&#24182;&#34920;&#26126;&#23545;&#20110;&#28145;&#23618;&#32593;&#32476;&#26550;&#26500;&#65292;&#32553;&#25918;&#21442;&#25968;&#22312;&#20248;&#21270;&#20449;&#21495;&#20256;&#25773;&#21644;&#30830;&#20445;&#26377;&#25928;&#21033;&#29992;&#32593;&#32476;&#28145;&#24230;&#26041;&#38754;&#21457;&#25381;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Residual networks (ResNets) have significantly better trainability and thus performance than feed-forward networks at large depth. Introducing skip connections facilitates signal propagation to deeper layers. In addition, previous works found that adding a scaling parameter for the residual branch further improves generalization performance. While they empirically identified a particularly beneficial range of values for this scaling parameter, the associated performance improvement and its universality across network hyperparameters yet need to be understood. For feed-forward networks (FFNets), finite-size theories have led to important insights with regard to signal propagation and hyperparameter tuning. We here derive a systematic finite-size theory for ResNets to study signal propagation and its dependence on the scaling for the residual branch. We derive analytical expressions for the response function, a measure for the network's sensitivity to inputs, and show that for deep netwo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#21516;&#26102;&#24314;&#31435;&#20102;&#19979;&#38480;&#35823;&#24046;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#27492;&#22806;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.00608</link><description>&lt;p&gt;
&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65306;&#22312;&#24471;&#20998;&#20272;&#35745;&#21644;&#20445;&#24207;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentiable Neural Networks with RePU Activation: with Applications to Score Estimation and Isotonic Regression. (arXiv:2305.00608v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00608
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;RePU&#28608;&#27963;&#20989;&#25968;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#21516;&#26102;&#24314;&#31435;&#20102;&#19979;&#38480;&#35823;&#24046;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#27492;&#22806;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#30001;&#20462;&#27491;&#21518;&#30340;&#24130;&#21333;&#20803;&#65288;RePU&#65289;&#20989;&#25968;&#28608;&#27963;&#30340;&#21487;&#24494;&#20998;&#31070;&#32463;&#32593;&#32476;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;RePU&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#23548;&#25968;&#21487;&#20197;&#30001;&#28151;&#21512;&#28608;&#27963;RePU&#32593;&#32476;&#26469;&#34920;&#31034;&#65292;&#24182;&#25512;&#23548;&#20102;&#23548;&#25968;RePU&#32593;&#32476;&#20989;&#25968;&#31867;&#30340;&#22797;&#26434;&#24230;&#30340;&#19978;&#30028;&#12290;&#22312;&#20351;&#29992;RePU&#28608;&#27963;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#21516;&#26102;&#36817;&#20284;$C^s$&#24179;&#28369;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#35823;&#24046;&#30028;&#12290;&#27492;&#22806;&#65292;&#24403;&#25968;&#25454;&#20855;&#26377;&#36817;&#20284;&#20302;&#32500;&#25903;&#25345;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#25913;&#36827;&#30340;&#36924;&#36817;&#35823;&#24046;&#30028;&#65292;&#35777;&#26126;&#20102;RePU&#32593;&#32476;&#20943;&#32531;&#32500;&#24230;&#28798;&#38590;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#28145;&#24230;&#24471;&#20998;&#21305;&#37197;&#20272;&#35745;&#22120;(DSME)&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;RePU&#32593;&#32476;&#30340;&#24809;&#32602;&#20445;&#24207;&#22238;&#24402;(PDIR)&#12290;&#25105;&#20204;&#22312;&#20551;&#23450;&#30446;&#26631;&#20989;&#25968;&#23646;&#20110;$C^s$&#24179;&#28369;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#20026;DSME&#21644;PDIR&#24314;&#31435;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of differentiable neural networks activated by rectified power unit (RePU) functions. We show that the partial derivatives of RePU neural networks can be represented by RePUs mixed-activated networks and derive upper bounds for the complexity of the function class of derivatives of RePUs networks. We establish error bounds for simultaneously approximating $C^s$ smooth functions and their derivatives using RePU-activated deep neural networks. Furthermore, we derive improved approximation error bounds when data has an approximate low-dimensional support, demonstrating the ability of RePU networks to mitigate the curse of dimensionality. To illustrate the usefulness of our results, we consider a deep score matching estimator (DSME) and propose a penalized deep isotonic regression (PDIR) using RePU networks. We establish non-asymptotic excess risk bounds for DSME and PDIR under the assumption that the target functions belong to a class of $C^s$ smooth functions. We 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#32858;&#31867;&#36895;&#24230;&#32780;&#19981;&#29306;&#29298;&#32858;&#31867;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.09868</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#32858;&#31867;&#36895;&#24230;&#32780;&#19981;&#29306;&#29298;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#20294;&#26159;&#30001;&#20110;&#20854;&#35745;&#31639;&#26114;&#36149;&#30340;&#31751;&#20998;&#37197;&#27493;&#39588;&#65292;&#23427;&#38754;&#20020;&#30528;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#25968;&#25454;&#38598;&#21387;&#32553;&#25104;&#23569;&#37327;&#35889;&#34920;&#31034;&#30340;&#32858;&#21512;&#25968;&#25454;&#28857;&#65292;&#28982;&#21518;&#22312;&#21387;&#32553;&#21518;&#30340;&#25968;&#25454;&#38598;&#19978;&#25191;&#34892;&#26631;&#20934;&#30340;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#65292;&#26368;&#21518;&#23558;&#21387;&#32553;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#32467;&#26524;&#26144;&#23556;&#22238;&#21407;&#22987;&#25968;&#25454;&#38598;&#20197;&#21457;&#29616;&#31751;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#36739;&#20110;&#26631;&#20934;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#36895;&#24230;&#65292;&#32780;&#19981;&#20250;&#25439;&#22833;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Deep Metric Learning&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;&#65292;&#33021;&#22815;&#26377;&#25928;&#30340;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.07689</link><description>&lt;p&gt;
&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#29992;&#20110;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Deep Metric Learning&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#36317;&#31163;&#34920;&#31034;&#65292;&#33021;&#22815;&#26377;&#25928;&#30340;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#25552;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25216;&#26415;&#24050;&#24212;&#29992;&#20110;&#21508;&#31181;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#65292;&#36890;&#36807;&#28145;&#24230;&#32593;&#32476;&#23398;&#20064;&#26679;&#26412;&#23884;&#20837;&#26469;&#36827;&#34892;&#35270;&#35273;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#26041;&#27861;&#37319;&#29992;&#22266;&#23450;&#36317;&#31163;&#24230;&#37327;&#20316;&#20026;&#20004;&#20010;&#23884;&#20837;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#20989;&#25968;&#65292;&#21487;&#33021;&#23548;&#33268;&#25429;&#25417;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#30340;&#20122;&#26368;&#20248;&#24615;&#33021;&#12290;Bregman&#25955;&#24230;&#27010;&#25324;&#20102;&#21508;&#31181;&#36317;&#31163;&#24230;&#37327;&#30340;&#24230;&#37327;&#65292;&#24182;&#22312;&#35768;&#22810;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#39046;&#22495;&#20013;&#20135;&#29983;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#22914;&#20309;&#20174;Bregman&#25955;&#24230;&#33719;&#24471;&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#25439;&#22833;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#32463;&#39564;Bregman&#25955;&#24230;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#35774;&#32622;&#23545;Bregman&#25955;&#24230;&#19979;&#30340;&#20984;&#20989;&#25968;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#20854;&#20182;SOTA&#28145;&#24230;&#24230;&#37327;&#23398;&#20064;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20116;&#20010;&#27969;&#34892;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#29305;&#21035;&#26159;&#22312;&#27169;&#24335;&#35782;&#21035;&#21644;&#32858;&#31867;&#20219;&#21153;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
&lt;/p&gt;</description></item><item><title>&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#20250;&#20135;&#29983;&#39044;&#27979;&#22810;&#26679;&#24615;&#65292;&#21363;&#20351;&#23545;&#20110;&#30456;&#21516;&#36755;&#20837;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#38543;&#26426;&#24615;&#20063;&#20250;&#24471;&#21040;&#19981;&#21516;&#30340;&#36755;&#20986;&#65292;&#36825;&#19968;&#25104;&#26412;&#19981;&#20165;&#26410;&#34987;&#30740;&#31350;&#36824;&#26410;&#34987;&#23457;&#26680;&#25110;&#20256;&#36798;&#32473;&#27169;&#22411;&#35774;&#35745;&#32773;&#21644;&#21033;&#30410;&#30456;&#20851;&#32773;&#12290;</title><link>http://arxiv.org/abs/2302.14517</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#20219;&#24847;&#20915;&#31574;&#26159;&#19968;&#20010;&#38544;&#34255;&#25104;&#26412;
&lt;/p&gt;
&lt;p&gt;
Arbitrary Decisions are a Hidden Cost of Differentially Private Training. (arXiv:2302.14517v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14517
&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#20250;&#20135;&#29983;&#39044;&#27979;&#22810;&#26679;&#24615;&#65292;&#21363;&#20351;&#23545;&#20110;&#30456;&#21516;&#36755;&#20837;&#65292;&#20351;&#29992;&#19981;&#21516;&#30340;&#38543;&#26426;&#24615;&#20063;&#20250;&#24471;&#21040;&#19981;&#21516;&#30340;&#36755;&#20986;&#65292;&#36825;&#19968;&#25104;&#26412;&#19981;&#20165;&#26410;&#34987;&#30740;&#31350;&#36824;&#26410;&#34987;&#23457;&#26680;&#25110;&#20256;&#36798;&#32473;&#27169;&#22411;&#35774;&#35745;&#32773;&#21644;&#21033;&#30410;&#30456;&#20851;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#31169;&#20445;&#25252;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;&#30340;&#26426;&#21046;&#36890;&#24120;&#26088;&#22312;&#22312;&#27169;&#22411;&#35757;&#32451;&#26399;&#38388;&#20445;&#35777;&#24046;&#20998;&#38544;&#31169;(DP)&#12290;&#22312;&#23558;&#27169;&#22411;&#21442;&#25968;&#25311;&#21512;&#21040;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#26102;&#65292;&#23454;&#36341;&#20013;&#20351;&#29992;&#38543;&#26426;&#21270;&#26041;&#27861;(&#20363;&#22914;&#65292;&#22312;&#25130;&#26029;&#30340;&#26799;&#24230;&#19978;&#28155;&#21152;&#39640;&#26031;&#22122;&#22768;)&#20197;&#30830;&#20445;DP&#35757;&#32451;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#38543;&#26426;&#21270;&#20250;&#20135;&#29983;&#39044;&#27979;&#22810;&#26679;&#24615;&#65306;&#23545;&#20110;&#32473;&#23450;&#30340;&#36755;&#20837;&#31034;&#20363;&#65292;&#30001;&#21516;&#26679;DP-&#20445;&#35777;&#30340;&#27169;&#22411;&#39044;&#27979;&#30340;&#36755;&#20986;&#21462;&#20915;&#20110;&#35757;&#32451;&#20013;&#20351;&#29992;&#30340;&#38543;&#26426;&#24615;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#32473;&#23450;&#30340;&#36755;&#20837;&#65292;&#21363;&#20351;&#20351;&#29992;&#30456;&#21516;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#65292;&#39044;&#27979;&#36755;&#20986;&#20063;&#21487;&#33021;&#21457;&#29983;&#24040;&#22823;&#21464;&#21270;&#12290;&#23578;&#26410;&#30740;&#31350;&#30001;DP&#35757;&#32451;&#24341;&#36215;&#30340;&#22810;&#26679;&#24615;&#25104;&#26412;&#65292;&#24182;&#19988;&#30446;&#21069;&#36824;&#26410;&#32463;&#36807;&#23457;&#26680;&#25110;&#21521;&#27169;&#22411;&#35774;&#35745;&#32773;&#21644;&#21033;&#30410;&#30456;&#20851;&#32773;&#20256;&#36798;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#31181;&#22312;&#21487;&#38752;&#22320;&#20272;&#35745;&#39044;&#27979;&#22810;&#26679;&#24615;&#25152;&#38656;&#30340;&#37325;&#26032;&#35757;&#32451;&#27425;&#25968;&#30340;&#19978;&#38480;&#65292;&#24182;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#39564;&#20998;&#26512;&#20102;&#19977;&#31181;DP-&#30830;&#20445;&#35757;&#32451;&#26041;&#27861;&#30340;&#39044;&#27979;&#22810;&#26679;&#24615;&#25104;&#26412;&#65292;&#21253;&#25324;&#29702;&#35770;&#21644;&#23454;&#39564;&#20004;&#20010;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mechanisms used in privacy-preserving machine learning often aim to guarantee differential privacy (DP) during model training. Practical DP-ensuring training methods use randomization when fitting model parameters to privacy-sensitive data (e.g., adding Gaussian noise to clipped gradients). We demonstrate that such randomization incurs predictive multiplicity: for a given input example, the output predicted by equally-private models depends on the randomness used in training. Thus, for a given input, the predicted output can vary drastically if a model is re-trained, even if the same training dataset is used. The predictive-multiplicity cost of DP training has not been studied, and is currently neither audited for nor communicated to model designers and stakeholders. We derive a bound on the number of re-trainings required to estimate predictive multiplicity reliably. We analyze--both theoretically and through extensive experiments--the predictive-multiplicity cost of three DP-ensuring
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24341;&#23548;&#28145;&#24230;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#28145;&#24230;&#26680;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#22312;&#20248;&#21270;&#20013;&#25351;&#23548;&#28145;&#24230;&#26680;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#36935;&#21040;&#26032;&#25968;&#25454;&#28857;&#26102;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#32622;&#20449;&#24230;&#65292;&#26082;&#21033;&#29992;&#20102;&#36125;&#21494;&#26031;&#34892;&#20026;&#65292;&#21448;&#20445;&#25345;&#20102;&#28145;&#24230;&#26680;&#30340;&#27867;&#21270;&#33021;&#21147;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09574</link><description>&lt;p&gt;
&#24341;&#23548;&#28145;&#24230;&#26680;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Guided Deep Kernel Learning. (arXiv:2302.09574v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24341;&#23548;&#28145;&#24230;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#28145;&#24230;&#26680;&#65292;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#22312;&#20248;&#21270;&#20013;&#25351;&#23548;&#28145;&#24230;&#26680;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#36935;&#21040;&#26032;&#25968;&#25454;&#28857;&#26102;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#32622;&#20449;&#24230;&#65292;&#26082;&#21033;&#29992;&#20102;&#36125;&#21494;&#26031;&#34892;&#20026;&#65292;&#21448;&#20445;&#25345;&#20102;&#28145;&#24230;&#26680;&#30340;&#27867;&#21270;&#33021;&#21147;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#22312;&#36890;&#24120;&#36890;&#36807;&#28145;&#24230;&#26680;&#23398;&#20064; (DKL) &#23558;&#39640;&#26031;&#36807;&#31243;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#32467;&#21512;&#36215;&#26469;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30001;&#20110;&#26680;&#20248;&#21270;&#36807;&#31243;&#65292;&#36825;&#31181;&#26041;&#27861;&#24120;&#24120;&#20250;&#22833;&#21435;&#23427;&#20204;&#30340;&#36125;&#21494;&#26031;&#20248;&#21183;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#28145;&#24230;&#26680;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#39640;&#26031;&#36807;&#31243; (NNGP) &#27169;&#22411;&#20316;&#20026; DKl &#27169;&#22411;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#25351;&#23548;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992; NNGP &#30340;&#21487;&#38752;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20197;&#20351; DKL &#22312;&#36935;&#21040;&#26032;&#25968;&#25454;&#28857;&#26102;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#32622;&#20449;&#24230;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26082;&#21033;&#29992;&#20102; NNGP &#30340;&#36125;&#21494;&#26031;&#34892;&#20026; (&#21363;&#20854;&#25239;&#36807;&#25311;&#21512;&#24615;&#21644;&#20934;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;)&#65292;&#21448;&#20445;&#25345;&#20102;&#28145;&#24230;&#26680;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21487;&#25193;&#23637;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19981;&#21516;&#22823;&#23567;&#21644;&#32500;&#24230;&#30340;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26657;&#20934;&#35780;&#20272;&#26694;&#26550;&#65292;&#25506;&#32034;&#20102;&#26657;&#20934;&#20998;&#25968;&#35774;&#35745;&#20013;&#30340;&#19981;&#21516;&#36873;&#25321;&#65292;&#24182;&#30740;&#31350;&#20102;&#26681;&#25454;&#36755;&#20837;&#29305;&#24449;&#32780;&#19981;&#26159;&#39044;&#27979;&#32467;&#26524;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#20998;&#32452;&#30340;&#20248;&#21183;&#65292;&#20174;&#32780;&#24110;&#21161;&#21046;&#23450;&#20855;&#26377;&#29702;&#24819;&#25968;&#23398;&#29305;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.04118</link><description>&lt;p&gt;
&#35770;&#26657;&#20934;&#30340;&#31934;&#32454;&#24230;
&lt;/p&gt;
&lt;p&gt;
On the Richness of Calibration. (arXiv:2302.04118v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04118
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26657;&#20934;&#35780;&#20272;&#26694;&#26550;&#65292;&#25506;&#32034;&#20102;&#26657;&#20934;&#20998;&#25968;&#35774;&#35745;&#20013;&#30340;&#19981;&#21516;&#36873;&#25321;&#65292;&#24182;&#30740;&#31350;&#20102;&#26681;&#25454;&#36755;&#20837;&#29305;&#24449;&#32780;&#19981;&#26159;&#39044;&#27979;&#32467;&#26524;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#20998;&#32452;&#30340;&#20248;&#21183;&#65292;&#20174;&#32780;&#24110;&#21161;&#21046;&#23450;&#20855;&#26377;&#29702;&#24819;&#25968;&#23398;&#29305;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19982;&#35266;&#27979;&#26631;&#31614;&#39057;&#29575;&#30340;&#27604;&#36739;&#65292;&#21363;&#36890;&#36807;&#26657;&#20934;&#30340;&#26041;&#27861;&#21487;&#20197;&#35780;&#20272;&#27010;&#29575;&#39044;&#27979;&#65292;&#26368;&#36817;&#65292;&#31639;&#27861;&#20844;&#24179;&#24615;&#26041;&#38754;&#30340;&#23398;&#32773;&#24320;&#22987;&#30740;&#31350;&#19968;&#20010;&#21517;&#20026;&#22810;&#26657;&#20934;&#30340;&#26657;&#20934;&#22522;&#20934;&#30340;&#19981;&#26029;&#22686;&#38271;&#30340;&#22810;&#26679;&#24615;&#65292;&#20294;&#36824;&#26159;&#27604;&#36739;&#23616;&#38480;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26126;&#30830;&#35774;&#35745;&#26657;&#20934;&#24230;&#37327;&#26102;&#28041;&#21450;&#30340;&#36873;&#25321;&#65292;&#25506;&#32034;&#21644;&#20998;&#26512;&#20102;&#26657;&#20934;&#35780;&#20272;&#30340;&#21508;&#31181;&#24418;&#24335;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#36873;&#25321;&#20998;&#20026;&#19977;&#20010;&#20998;&#32452;&#36873;&#25321;&#21644;&#19968;&#20010;&#20851;&#20110;&#32452;&#38169;&#35823;&#21512;&#24182;&#30340;&#36873;&#25321;&#12290;&#36825;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20197;&#27604;&#36739;&#20197;&#21069;&#25552;&#20986;&#30340;&#26657;&#20934;&#20998;&#25968;&#65292;&#24182;&#26377;&#21161;&#20110;&#21046;&#23450;&#20855;&#26377;&#29702;&#24819;&#25968;&#23398;&#29305;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#26681;&#25454;&#36755;&#20837;&#29305;&#24449;&#32780;&#19981;&#26159;&#39044;&#27979;&#23545;&#25968;&#25454;&#28857;&#36827;&#34892;&#20998;&#32452;&#30340;&#21487;&#33021;&#24615;&#65292;&#24182;&#27491;&#24335;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#36824;&#23545;&#36866;&#21512;&#30340;&#32452;&#38169;&#35823;&#21512;&#24182;&#20989;&#25968;&#30340;&#31354;&#38388;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic predictions can be evaluated through comparisons with observed label frequencies, that is, through the lens of calibration. Recent scholarship on algorithmic fairness has started to look at a growing variety of calibration-based objectives under the name of multi-calibration but has still remained fairly restricted. In this paper, we explore and analyse forms of evaluation through calibration by making explicit the choices involved in designing calibration scores. We organise these into three grouping choices and a choice concerning the agglomeration of group errors. This provides a framework for comparing previously proposed calibration scores and helps to formulate novel ones with desirable mathematical properties. In particular, we explore the possibility of grouping datapoints based on their input features rather than on predictions and formally demonstrate advantages of such approaches. We also characterise the space of suitable agglomeration functions for group erro
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#65292;&#25552;&#20986;&#22235;&#20010;&#35823;&#24046;&#37096;&#20998;&#35780;&#20272;&#33258;&#30417;&#30563;&#23398;&#20064;&#23545;169&#20010;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20026;SSL&#30340;&#35774;&#35745;&#21644;&#20351;&#29992;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2302.03068</link><description>&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#35780;&#20272;&#33258;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Evaluating Self-Supervised Learning via Risk Decomposition. (arXiv:2302.03068v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03068
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#39118;&#38505;&#20998;&#35299;&#65292;&#25552;&#20986;&#22235;&#20010;&#35823;&#24046;&#37096;&#20998;&#35780;&#20272;&#33258;&#30417;&#30563;&#23398;&#20064;&#23545;169&#20010;&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20026;SSL&#30340;&#35774;&#35745;&#21644;&#20351;&#29992;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#30340;&#27969;&#31243;&#35774;&#35745;&#28041;&#21450;&#26550;&#26500;&#12289;&#22686;&#24378;&#21644;&#39044;&#35757;&#32451;&#25968;&#25454;&#31561;&#35832;&#22810;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;SSL&#36890;&#24120;&#20351;&#29992;&#21333;&#19968;&#24230;&#37327;&#26469;&#35780;&#20272;&#65292;&#36825;&#24182;&#19981;&#33021;&#25552;&#20379;&#28145;&#20837;&#30340;&#27934;&#23519;&#21644;&#25913;&#36827;&#26041;&#26696;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;SSL&#39118;&#38505;&#20998;&#35299;&#65292;&#20174;&#36924;&#36817;&#12289;&#34920;&#31034;&#21487;&#29992;&#24615;&#12289;&#25506;&#38024;&#27867;&#21270;&#21644;&#32534;&#30721;&#22120;&#27867;&#21270;&#31561;&#35282;&#24230;&#23545;&#38169;&#35823;&#36827;&#34892;&#20998;&#35299;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;30&#20010;&#35774;&#35745;&#36873;&#25321;&#23545;169&#20010;&#22312;ImageNet&#19978;&#35780;&#20272;&#30340;SSL&#35270;&#35273;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#20026;&#27599;&#20010;&#32452;&#20214;&#25552;&#20379;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#22120;&#65292;&#20026;SSL&#27169;&#22411;&#30340;&#35774;&#35745;&#21644;&#20351;&#29992;&#25552;&#20379;&#23453;&#36149;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) pipelines differ in many design choices such as the architecture, augmentations, or pretraining data. Yet SSL is typically evaluated using a single metric: linear probing on ImageNet. This does not provide much insight into why or when a model is better, now how to improve it. To address this, we propose an SSL risk decomposition, which generalizes the classical supervised approximation-estimation decomposition by considering errors arising from the representation learning step. Our decomposition consists of four error components: approximation, representation usability, probe generalization, and encoder generalization. We provide efficient estimators for each component and use them to analyze the effect of 30 design choices on 169 SSL vision models evaluated on ImageNet. Our analysis gives valuable insights for designing and using SSL models. For example, it highlights the main sources of error and shows how to improve SSL in specific settings (full- vs 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#21644;&#23454;&#29992;&#30340;&#26041;&#27861;{\sc LegendreTron}&#65292;&#29992;&#20110;&#32852;&#21512;&#23398;&#20064;&#22810;&#31867;&#21035;&#38382;&#39064;&#30340;&#27491;&#30830;&#26631;&#20934;&#25439;&#22833;&#21644;&#27010;&#29575;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#32463;&#24120;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.11695</link><description>&lt;p&gt;
LegendreTron&#65306;&#21319;&#32423;&#29256;&#22810;&#31867;&#21035;&#27491;&#30830;&#22810;&#39033;&#25439;&#22833;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
LegendreTron: Uprising Proper Multiclass Loss Learning. (arXiv:2301.11695v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#21644;&#23454;&#29992;&#30340;&#26041;&#27861;{\sc LegendreTron}&#65292;&#29992;&#20110;&#32852;&#21512;&#23398;&#20064;&#22810;&#31867;&#21035;&#38382;&#39064;&#30340;&#27491;&#30830;&#26631;&#20934;&#25439;&#22833;&#21644;&#27010;&#29575;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#32463;&#24120;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25439;&#22833;&#20989;&#25968;&#26159;&#30417;&#30563;&#23398;&#20064;&#30340;&#22522;&#30784;&#65292;&#36890;&#24120;&#22312;&#27169;&#22411;&#24320;&#21457;&#20043;&#21069;&#36873;&#25321;&#12290;&#20026;&#36991;&#20813;&#36873;&#25321;&#25439;&#22833;&#20989;&#25968;&#21487;&#33021;&#20986;&#29616;&#30340;&#29305;&#23450;&#36873;&#25321;&#65292;&#32479;&#35745;&#20915;&#31574;&#29702;&#35770;&#25551;&#36848;&#20102;&#25439;&#22833;&#30340;&#19968;&#31181;&#29702;&#24819;&#23646;&#24615;&#65292;&#31216;&#20026;&#8220;&#27491;&#30830;&#24615;&#8221;&#65292;&#23427;&#26029;&#35328;&#36125;&#21494;&#26031;&#35268;&#21017;&#26159;&#26368;&#20248;&#30340;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#23581;&#35797;&#32852;&#21512;&#23398;&#20064;&#25439;&#22833;&#21644;&#27169;&#22411;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#25311;&#21512;&#19968;&#20010;&#23558;$\mathbb{R}$&#21333;&#35843;&#26144;&#23556;&#21040;$[0,1]$&#30340;&#21453;&#35299;&#26631;&#20934;&#38142;&#25509;&#20989;&#25968;&#26469;&#20272;&#35745;&#20108;&#20803;&#38382;&#39064;&#30340;&#27010;&#29575;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#20984;&#20989;&#25968;&#26799;&#24230;&#30340;&#21333;&#35843;&#24615;&#23558;&#21333;&#35843;&#24615;&#25193;&#23637;&#21040;$\mathbb{R}^{C-1}$&#21040;&#27010;&#29575;&#30340;&#27491;&#25237;&#24433;$\tilde{\Delta}^{C-1}$&#30340;&#26144;&#23556;&#19978;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#32780;&#23454;&#29992;&#30340;&#26041;&#27861;{\sc LegendreTron}&#65292;&#29992;&#20110;&#32852;&#21512;&#23398;&#20064;&#22810;&#31867;&#21035;&#38382;&#39064;&#30340;&#27491;&#30830;&#26631;&#20934;&#25439;&#22833;&#21644;&#27010;&#29575;&#12290;&#22312;&#26368;&#22810;1,000&#31181;&#31867;&#21035;&#30340;&#39046;&#22495;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#20854;&#20182;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Loss functions serve as the foundation of supervised learning and are often chosen prior to model development. To avoid potentially ad hoc choices of losses, statistical decision theory describes a desirable property for losses known as \emph{properness}, which asserts that Bayes' rule is optimal. Recent works have sought to \emph{learn losses} and models jointly. Existing methods do this by fitting an inverse canonical link function which monotonically maps $\mathbb{R}$ to $[0,1]$ to estimate probabilities for binary problems. In this paper, we extend monotonicity to maps between $\mathbb{R}^{C-1}$ and the projected probability simplex $\tilde{\Delta}^{C-1}$ by using monotonicity of gradients of convex functions. We present {\sc LegendreTron} as a novel and practical method that jointly learns \emph{proper canonical losses} and probabilities for multiclass problems. Tested on a benchmark of domains with up to 1,000 classes, our experimental results show that our method consistently ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#25429;&#33719;&#26680;&#20381;&#36182;&#20851;&#31995;&#30340;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#21644;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#27169;&#22411;&#30456;&#27604;&#65292;&#35813;&#27169;&#22411;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#19978;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.09870</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Context-specific kernel-based hidden Markov model for time series analysis. (arXiv:2301.09870v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#25429;&#33719;&#26680;&#20381;&#36182;&#20851;&#31995;&#30340;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#12290;&#19982;&#20256;&#32479;&#27169;&#22411;&#21644;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#27169;&#22411;&#30456;&#27604;&#65292;&#35813;&#27169;&#22411;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#30340;&#25968;&#25454;&#19978;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#26159;&#29702;&#35299;&#21644;&#24314;&#27169;&#38543;&#26426;&#21160;&#24577;&#25968;&#25454;&#30340;&#26377;&#29992;&#24037;&#20855;&#65307;&#22312;&#38750;&#39640;&#26031;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#20351;&#29992;&#31867;&#20284;&#39640;&#26031;&#28151;&#21512;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#27169;&#22411;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#27169;&#22411;&#21463;&#21040;&#31934;&#24230;&#30697;&#38453;&#30340;&#35745;&#31639;&#20197;&#21450;&#20855;&#26377;&#24456;&#22810;&#19981;&#24517;&#35201;&#30340;&#21442;&#25968;&#30340;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#36825;&#26679;&#30340;&#27169;&#22411;&#22312;&#20551;&#23450;&#25152;&#26377;&#21464;&#37327;&#29420;&#31435;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#22909;&#65292;&#36825;&#21487;&#33021;&#26159;&#19981;&#29616;&#23454;&#30340;&#20551;&#35774;&#12290;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#20063;&#33021;&#22815;&#24314;&#27169;&#38750;&#39640;&#26031;&#25968;&#25454;&#65292;&#20294;&#23427;&#20204;&#20551;&#23450;&#21464;&#37327;&#20043;&#38388;&#26159;&#29420;&#31435;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#26032;&#22411;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#33021;&#22815;&#21033;&#29992;&#19978;&#19979;&#25991;&#30456;&#20851;&#36125;&#21494;&#26031;&#32593;&#32476;&#25429;&#33719;&#26680;&#20381;&#36182;&#20851;&#31995;&#12290;&#20171;&#32461;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#21450;&#20854;&#22522;&#20110;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#36824;&#23558;&#35813;&#27169;&#22411;&#19982;&#30456;&#20851;&#30340;HMM&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional hidden Markov models have been a useful tool to understand and model stochastic dynamic data; in the case of non-Gaussian data, models such as mixture of Gaussian hidden Markov models can be used. However, these suffer from the computation of precision matrices and have a lot of unnecessary parameters. As a consequence, such models often perform better when it is assumed that all variables are independent, a hypothesis that may be unrealistic. Hidden Markov models based on kernel density estimation are also capable of modeling non-Gaussian data, but they assume independence between variables. In this article, we introduce a new hidden Markov model based on kernel density estimation, which is capable of capturing kernel dependencies using context-specific Bayesian networks. The proposed model is described, together with a learning algorithm based on the expectation-maximization algorithm. Additionally, the model is compared to related HMMs on synthetic and real data. From th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#32447;&#24615;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#29702;&#25214;&#21040;&#20102;&#39044;&#27979;&#21518;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#30340;&#38750;&#28176;&#36817;&#34920;&#36798;&#65292;&#24182;&#36890;&#36807;&#36825;&#20123;&#34920;&#36798;&#24335;&#24471;&#21040;&#28145;&#24230;&#12289;&#23485;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#32852;&#21512;&#20316;&#29992;&#30340;&#26032;&#22270;&#20687;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#32447;&#24615;&#32593;&#32476;&#22312;&#26080;&#38480;&#28145;&#24230;&#26102;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#39044;&#27979;&#65292;&#24182;&#25512;&#23548;&#20102;&#26377;&#38480;&#32593;&#32476;&#30340;&#23574;&#38160;&#22823;&#20559;&#24046;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2212.14457</link><description>&lt;p&gt;
&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Bayesian Interpolation with Deep Linear Networks. (arXiv:2212.14457v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14457
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#32447;&#24615;&#32593;&#32476;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#29702;&#25214;&#21040;&#20102;&#39044;&#27979;&#21518;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#30340;&#38750;&#28176;&#36817;&#34920;&#36798;&#65292;&#24182;&#36890;&#36807;&#36825;&#20123;&#34920;&#36798;&#24335;&#24471;&#21040;&#28145;&#24230;&#12289;&#23485;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#32852;&#21512;&#20316;&#29992;&#30340;&#26032;&#22270;&#20687;&#65292;&#21516;&#26102;&#35777;&#26126;&#20102;&#32447;&#24615;&#32593;&#32476;&#22312;&#26080;&#38480;&#28145;&#24230;&#26102;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#39044;&#27979;&#65292;&#24182;&#25512;&#23548;&#20102;&#26377;&#38480;&#32593;&#32476;&#30340;&#23574;&#38160;&#22823;&#20559;&#24046;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#34920;&#24449;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#12289;&#23485;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#22914;&#20309;&#20849;&#21516;&#24433;&#21709;&#27169;&#22411;&#36136;&#37327;&#26159;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#32447;&#24615;&#32593;&#32476;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#20855;&#26377;&#39640;&#26031;&#26435;&#37325;&#20808;&#39564;&#21644;&#24179;&#22343;&#24179;&#26041;&#35823;&#24046;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#23545;&#21333;&#36755;&#20986;&#32500;&#24230;&#36827;&#34892;&#20102;&#23436;&#25972;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#20219;&#20309;&#35757;&#32451;&#25968;&#25454;&#38598;&#12289;&#32593;&#32476;&#28145;&#24230;&#21644;&#38544;&#34255;&#23618;&#23485;&#24230;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#39044;&#27979;&#21518;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#30340;&#38750;&#28176;&#36817;&#34920;&#36798;&#65292;&#36825;&#20123;&#34920;&#36798;&#24335;&#26159;&#19968;&#31867;&#20851;&#20110;Meijer-G&#20989;&#25968;&#30340;&#20122;&#32431;&#29305;&#27530;&#20989;&#25968;&#12290;&#36890;&#36807;&#36825;&#20123;Meijer-G&#20989;&#25968;&#30340;&#26032;&#22411;&#28176;&#36817;&#23637;&#24320;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#28145;&#24230;&#12289;&#23485;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#32852;&#21512;&#20316;&#29992;&#30340;&#20016;&#23500;&#26032;&#22270;&#20687;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#32447;&#24615;&#32593;&#32476;&#22312;&#26080;&#38480;&#28145;&#24230;&#26102;&#21487;&#20197;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#39044;&#27979;&#65306;&#20855;&#26377;&#25968;&#25454;&#19981;&#21487;&#30693;&#20808;&#39564;&#30340;&#26080;&#38480;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#21518;&#39564;&#27010;&#29575;&#19982;&#20855;&#26377;&#26368;&#22823;&#21270;&#25968;&#25454;&#20381;&#36182;&#20808;&#39564;&#20449;&#24687;&#30340;&#27973;&#32593;&#32476;&#30340;&#21518;&#39564;&#27010;&#29575;&#30456;&#21516;&#65292;&#19988;&#21518;&#39564;&#27010;&#29575;&#38598;&#20013;&#20110;&#32447;&#24615;&#20989;&#25968;&#12290;&#24403;&#32593;&#32476;&#26159;&#26377;&#38480;&#30340;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#21518;&#39564;&#36317;&#31163;&#32447;&#24615;&#20989;&#25968;&#30340;&#23574;&#38160;&#22823;&#20559;&#24046;&#36793;&#30028;&#65292;&#24182;&#34920;&#26126;&#36825;&#20123;&#36793;&#30028;&#20197;&#39640;&#24230;&#38169;&#32508;&#22797;&#26434;&#30340;&#26041;&#24335;&#21462;&#20915;&#20110;&#32593;&#32476;&#28145;&#24230;&#12289;&#23485;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#12290;&#26368;&#21518;&#65292;&#22312;&#22823;&#25968;&#25454;&#38598;&#26497;&#38480;&#19979;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#35777;&#25454;&#30340;&#28176;&#36817;&#23637;&#24320;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#22266;&#23450;&#23485;&#24230;&#65292;&#35777;&#25454;&#26159;&#28145;&#24230;&#21644;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#22810;&#39033;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Characterizing how neural network depth, width, and dataset size jointly impact model quality is a central problem in deep learning theory. We give here a complete solution in the special case of linear networks with output dimension one trained using zero noise Bayesian inference with Gaussian weight priors and mean squared error as a negative log-likelihood. For any training dataset, network depth, and hidden layer widths, we find non-asymptotic expressions for the predictive posterior and Bayesian model evidence in terms of Meijer-G functions, a class of meromorphic special functions of a single complex variable. Through novel asymptotic expansions of these Meijer-G functions, a rich new picture of the joint role of depth, width, and dataset size emerges. We show that linear networks make provably optimal predictions at infinite depth: the posterior of infinitely deep linear networks with data-agnostic priors is the same as that of shallow networks with evidence-maximizing data-depe
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#29992;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#35299;&#37322;&#19982;&#39044;&#27979;&#30340;&#20851;&#31995;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#20851;&#31995;&#36828;&#19981;&#22914;&#29702;&#24819;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2212.06925</link><description>&lt;p&gt;
&#35770;&#35299;&#37322;&#19982;&#39044;&#27979;&#30340;&#20851;&#31995;&#65306;&#19968;&#31181;&#22240;&#26524;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
On the Relationship Between Explanation and Prediction: A Causal View. (arXiv:2212.06925v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.06925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#29992;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#35299;&#37322;&#19982;&#39044;&#27979;&#30340;&#20851;&#31995;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#20851;&#31995;&#36828;&#19981;&#22914;&#29702;&#24819;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#27169;&#22411;&#20915;&#31574;&#35299;&#37322;&#30340;&#33021;&#21147;&#25104;&#20026;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24320;&#21457;&#12289;&#37096;&#32626;&#21644;&#24212;&#29992;&#30340;&#26680;&#24515;&#35201;&#27714;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23578;&#26410;&#29702;&#35299;&#35299;&#37322;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;&#25968;&#25454;&#12289;&#27169;&#22411;&#39044;&#27979;&#12289;&#36229;&#21442;&#25968;&#21644;&#38543;&#26426;&#21021;&#22987;&#21270;&#31561;&#19978;&#28216;&#22240;&#32032;&#22914;&#20309;&#24433;&#21709;&#19979;&#28216;&#30340;&#35299;&#37322;&#65311;&#34429;&#28982;&#20808;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#35299;&#37322;&#19982;&#39044;&#27979;&#20043;&#38388;&#20851;&#31995;&#36739;&#23567;&#30340;&#25285;&#24551;&#65292;&#20294;&#32570;&#20047;&#30830;&#23450;&#24615;&#30340;&#30740;&#31350;&#26469;&#37327;&#21270;&#36825;&#31181;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20511;&#37492;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#35780;&#20272;&#20102;&#36825;&#31181;&#20851;&#31995;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#24178;&#39044;&#35299;&#37322;&#21644;&#39044;&#27979;&#30340;&#22240;&#26524;&#31062;&#20808;&#65292;&#22312;&#20351;&#29992;&#20197;&#26174;&#30524;&#24230;&#20026;&#22522;&#30784;&#30340;&#35299;&#37322;&#25110;&#39044;&#27979;&#26102;&#23545;&#36229;&#21442;&#25968;&#21644;&#36755;&#20837;&#36827;&#34892;&#27979;&#37327;&#65292;&#26469;&#30740;&#31350;&#35299;&#37322;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#35299;&#37322;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20851;&#31995;&#36828;&#38750;&#29702;&#24819;&#12290;&#20107;&#23454;&#19978;&#65292;&#8220;&#29702;&#24819;&#8221;&#24773;&#20917;&#19979;&#30340;&#24046;&#36317;&#21482;&#20250;&#22312;&#26356;&#39640;&#30340;&#24773;&#20917;&#19979;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
Being able to provide explanations for a model's decision has become a central requirement for the development, deployment, and adoption of machine learning models. However, we are yet to understand what explanation methods can and cannot do. How do upstream factors such as data, model prediction, hyperparameters, and random initialization influence downstream explanations? While previous work raised concerns that explanations (E) may have little relationship with the prediction (Y), there is a lack of conclusive study to quantify this relationship. Our work borrows tools from causal inference to systematically assay this relationship. More specifically, we study the relationship between E and Y by measuring the treatment effect when intervening on their causal ancestors, i.e., on hyperparameters and inputs used to generate saliency-based Es or Ys. Our results suggest that the relationships between E and Y is far from ideal. In fact, the gap between 'ideal' case only increase in higher
&lt;/p&gt;</description></item><item><title>&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#65292;&#23545;&#39044;&#27979;&#36712;&#36857;&#30340;&#21518;&#32493;&#29366;&#24577;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#20551;&#35774;&#26159;&#38169;&#35823;&#30340;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#20998;&#27573;&#32447;&#24615;&#36817;&#20284;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.11103</link><description>&lt;p&gt;
&#36807;&#21435;&#30340;&#20107;&#24773;&#24456;&#37325;&#35201;&#65306;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#36712;&#36857;&#39044;&#27979;&#20013;&#21518;&#32493;&#29366;&#24577;&#30340;&#30456;&#20851;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Past Does Matter: Correlation of Subsequent States in Trajectory Predictions of Gaussian Process Models. (arXiv:2211.11103v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11103
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#65292;&#23545;&#39044;&#27979;&#36712;&#36857;&#30340;&#21518;&#32493;&#29366;&#24577;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#20551;&#35774;&#26159;&#38169;&#35823;&#30340;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#20998;&#27573;&#32447;&#24615;&#36817;&#20284;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#21160;&#24577;&#31995;&#32479;&#30340;&#36712;&#36857;&#20998;&#24067;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#22312;&#32771;&#34385;&#21040;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#30340;&#35745;&#31639;&#25104;&#26412;&#20043;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#27169;&#22411;&#36755;&#20986;&#21644;&#36712;&#36857;&#20998;&#24067;&#30340;&#36817;&#20284;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#20043;&#21069;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#30340;&#24037;&#20316;&#65292;&#37325;&#28857;&#25918;&#22312;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#19978;&#65292;&#38169;&#35823;&#22320;&#21253;&#21547;&#20102;&#23545;&#39044;&#27979;&#36712;&#36857;&#30340;&#21518;&#32493;&#29366;&#24577;&#20043;&#38388;&#29420;&#31435;&#24615;&#30340;&#20551;&#35774;&#12290;&#23558;&#36825;&#20123;&#24605;&#24819;&#25193;&#23637;&#21040;&#36830;&#32493;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#20551;&#35774;&#30340;&#21547;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#20998;&#27573;&#32447;&#24615;&#36817;&#20284;&#26041;&#27861;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the distribution of trajectories from a Gaussian Process model of a dynamical system is an important challenge in utilizing such models. Motivated by the computational cost of sampling-based approaches, we consider approximations of the model's output and trajectory distribution. We show that previous work on uncertainty propagation, focussed on discrete state-space models, incorrectly included an independence assumption between subsequent states of the predicted trajectories. Expanding these ideas to continuous ordinary differential equation models, we illustrate the implications of this assumption and propose a novel piecewise linear approximation of Gaussian Processes to mitigate them.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#8212;&#8212;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#29615;&#22659;&#20256;&#24863;&#22120;&#30340;&#25918;&#32622;&#25928;&#29575;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#36890;&#36807;&#23398;&#20064;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38750;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.10381</link><description>&lt;p&gt;
&#24102;&#26377;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#30340;&#29615;&#22659;&#20256;&#24863;&#22120;&#25918;&#32622;
&lt;/p&gt;
&lt;p&gt;
Environmental Sensor Placement with Convolutional Gaussian Neural Processes. (arXiv:2211.10381v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#8212;&#8212;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#29615;&#22659;&#20256;&#24863;&#22120;&#30340;&#25918;&#32622;&#25928;&#29575;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#36890;&#36807;&#23398;&#20064;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38750;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29615;&#22659;&#20256;&#24863;&#22120;&#23545;&#20110;&#30417;&#27979;&#22825;&#27668;&#21644;&#27668;&#20505;&#21464;&#21270;&#30340;&#24433;&#21709;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#20687;&#21335;&#26497;&#36825;&#26679;&#30340;&#20559;&#36828;&#22320;&#21306;&#65292;&#26368;&#22823;&#21270;&#27979;&#37327;&#20449;&#24687;&#21644;&#26377;&#25928;&#25918;&#32622;&#20256;&#24863;&#22120;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#39044;&#27979;&#26032;&#20256;&#24863;&#22120;&#25552;&#20379;&#30340;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#26469;&#35780;&#20272;&#25918;&#32622;&#20449;&#24687;&#12290;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#27492;&#30446;&#30340;&#65292;&#20294;&#38590;&#20197;&#25429;&#25417;&#22797;&#26434;&#30340;&#38750;&#24179;&#31283;&#34892;&#20026;&#24182;&#32553;&#25918;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#20219;&#24847;&#30446;&#26631;&#20301;&#32622;&#30340;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#20351;&#29992;&#27169;&#25311;&#30340;&#21335;&#26497;&#22320;&#21306;&#22320;&#38754;&#28201;&#24230;&#24322;&#24120;&#20316;&#20026;&#30495;&#23454;&#25968;&#25454;&#65292;ConvGNP&#23398;&#20064;&#20102;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#24182;&#20248;&#20110;&#38750;&#24179;&#31283;GP&#22522;&#32447;&#12290;&#22312;&#27169;&#25311;&#30340;s&#20013;&#65292;
&lt;/p&gt;
&lt;p&gt;
Environmental sensors are crucial for monitoring weather conditions and the impacts of climate change. However, it is challenging to maximise measurement informativeness and place sensors efficiently, particularly in remote regions like Antarctica. Probabilistic machine learning models can evaluate placement informativeness by predicting the uncertainty reduction provided by a new sensor. Gaussian process (GP) models are widely used for this purpose, but they struggle with capturing complex non-stationary behaviour and scaling to large datasets. This paper proposes using a convolutional Gaussian neural process (ConvGNP) to address these issues. A ConvGNP uses neural networks to parameterise a joint Gaussian distribution at arbitrary target locations, enabling flexibility and scalability. Using simulated surface air temperature anomaly over Antarctica as ground truth, the ConvGNP learns spatial and seasonal non-stationarities, outperforming a non-stationary GP baseline. In a simulated s
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#33258;&#36866;&#24212;&#20559;&#24046;&#26657;&#27491;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#27431;&#27954;&#20013;&#26399;&#22825;&#27668;&#39044;&#25253;&#20013;&#24515;&#30340;&#20122;&#23395;&#33410;&#27169;&#22411;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#28201;&#24230;&#21644;&#38477;&#27700;&#39044;&#27979;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2209.10666</link><description>&lt;p&gt;
&#25913;&#36827;&#20122;&#23395;&#33410;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20559;&#24046;&#26657;&#27491;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Bias Correction for Improved Subseasonal Forecasting. (arXiv:2209.10666v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10666
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#33258;&#36866;&#24212;&#20559;&#24046;&#26657;&#27491;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#27431;&#27954;&#20013;&#26399;&#22825;&#27668;&#39044;&#25253;&#20013;&#24515;&#30340;&#20122;&#23395;&#33410;&#27169;&#22411;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#28201;&#24230;&#21644;&#38477;&#27700;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20122;&#23395;&#33410;&#39044;&#27979;&#26159;&#39044;&#27979;&#26410;&#26469;2&#21040;6&#21608;&#28201;&#24230;&#21644;&#38477;&#27700;&#30340;&#37325;&#35201;&#25163;&#27573;&#65292;&#23545;&#20110;&#26377;&#25928;&#30340;&#27700;&#36164;&#28304;&#20998;&#37197;&#12289;&#37326;&#28779;&#31649;&#29702;&#20197;&#21450;&#24178;&#26097;&#21644;&#27946;&#28061;&#28798;&#23475;&#30340;&#32531;&#35299;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20559;&#24046;&#26657;&#27491;&#65288;ABC&#65289;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#23558;&#26368;&#20808;&#36827;&#30340;&#25968;&#20540;&#27169;&#22411;&#19982;&#26426;&#22120;&#23398;&#20064;&#32467;&#21512;&#65292;&#26088;&#22312;&#23545;&#27668;&#35937;&#21160;&#21147;&#23398;&#21644;&#29289;&#29702;&#23398;&#27169;&#22411;&#20013;&#30340;&#22266;&#26377;&#35823;&#24046;&#36827;&#34892;&#20462;&#27491;&#12290;&#22312;&#32654;&#22269;&#36830;&#32493;&#21306;&#22495;&#65292;&#24403;&#25105;&#20204;&#23558;ABC&#26041;&#27861;&#24212;&#29992;&#20110;&#27431;&#27954;&#20013;&#26399;&#22825;&#27668;&#39044;&#25253;&#20013;&#24515;&#65288;ECMWF&#65289;&#30340;&#39046;&#20808;&#20122;&#23395;&#33410;&#27169;&#22411;&#26102;&#65292;&#21457;&#29616;&#28201;&#24230;&#39044;&#27979;&#25216;&#24039;&#25552;&#39640;&#20102;60-90&#65285;&#65288;&#22522;&#32447;&#25216;&#24039;&#22312;0.18-0.25&#20043;&#38388;&#65289;&#65292;&#38477;&#27700;&#39044;&#27979;&#25216;&#24039;&#25552;&#39640;&#20102;40-69&#65285;&#65288;&#22522;&#32447;&#25216;&#24039;&#22312;0.11-0.15&#20043;&#38388;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Subseasonal forecasting -- predicting temperature and precipitation 2 to 6 weeks ahead -- is critical for effective water allocation, wildfire management, and drought and flood mitigation. Recent international research efforts have advanced the subseasonal capabilities of operational dynamical models, yet temperature and precipitation prediction skills remain poor, partly due to stubborn errors in representing atmospheric dynamics and physics inside dynamical models. Here, to counter these errors, we introduce an adaptive bias correction (ABC) method that combines state-of-the-art dynamical forecasts with observations using machine learning. We show that, when applied to the leading subseasonal model from the European Centre for Medium-Range Weather Forecasts (ECMWF), ABC improves temperature forecasting skill by 60-90% (over baseline skills of 0.18-0.25) and precipitation forecasting skill by 40-69% (over baseline skills of 0.11-0.15) in the contiguous U.S. We couple these performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23884;&#20837;&#22270;&#24418;&#21040;&#21521;&#37327;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24352;&#37327;&#31215;&#20197;&#21450;&#29699;&#24418;&#30721;&#23454;&#29616;&#39640;&#25928;&#21387;&#32553;&#21644;&#34920;&#24449;&#65292;&#22312;&#31232;&#30095;&#22270;&#34920;&#31034;&#21644;&#20854;&#20182;&#24212;&#29992;&#20013;&#20855;&#26377;&#28508;&#22312;&#25216;&#26415;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2208.10917</link><description>&lt;p&gt;
&#24352;&#37327;&#31215;&#19982;&#36817;&#20284;&#27491;&#20132;&#30721;&#30340;&#22270;&#23884;&#20837;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Graph Embeddings via Tensor Products and Approximately Orthonormal Codes. (arXiv:2208.10917v4 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.10917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23884;&#20837;&#22270;&#24418;&#21040;&#21521;&#37327;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#24352;&#37327;&#31215;&#20197;&#21450;&#29699;&#24418;&#30721;&#23454;&#29616;&#39640;&#25928;&#21387;&#32553;&#21644;&#34920;&#24449;&#65292;&#22312;&#31232;&#30095;&#22270;&#34920;&#31034;&#21644;&#20854;&#20182;&#24212;&#29992;&#20013;&#20855;&#26377;&#28508;&#22312;&#25216;&#26415;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#20197;&#20445;&#25345;&#32467;&#26500;&#26041;&#24335;&#26469;&#23884;&#20837;&#22270;&#24418;&#30340;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#20016;&#23500;&#30340;&#34920;&#24449;&#33021;&#21147;&#24182;&#24314;&#31435;&#20102;&#19968;&#20123;&#29702;&#35770;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#36807;&#31243;&#23646;&#20110;&#32465;&#23450;&#21644;&#27714;&#21644;&#26041;&#27861;&#65292;&#24182;&#19988;&#25105;&#20204;&#26174;&#31034;&#20102;&#24352;&#37327;&#31215;&#26159;&#23562;&#37325;&#21472;&#21152;&#21407;&#29702;&#30340;&#26368;&#19968;&#33324;&#30340;&#32465;&#23450;&#25805;&#20316;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20123;&#31934;&#30830;&#30340;&#32467;&#26524;&#23545;&#25105;&#20204;&#26041;&#27861;&#30340;&#34892;&#20026;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#20351;&#29992;&#30340;&#29699;&#24418;&#30721;&#23454;&#29616;&#20102;&#19968;&#20010;&#35013;&#31665;&#19978;&#38480;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#37051;&#25509;&#30697;&#38453;&#30340;&#32852;&#31995;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26159;&#19968;&#31181;&#37051;&#25509;&#30697;&#38453;&#30340;&#21387;&#32553;&#65292;&#20855;&#26377;&#31232;&#30095;&#22270;&#34920;&#31034;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze a method for embedding graphs as vectors in a structure-preserving manner, showcasing its rich representational capacity and establishing some of its theoretical properties. Our procedure falls under the bind-and-sum approach, and we show that the tensor product is the most general binding operation that respects the superposition principle. We also establish some precise results characterizing the behavior of our method, and we show that our use of spherical codes achieves a packing upper bound. We establish a link to adjacency matrices, showing that our method is, in some sense, a compression of adjacency matrices with applications towards sparse graph representations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24050;&#22833;&#25928;&#65292;&#30456;&#20851;&#20869;&#23481;&#24050;&#34987;&#21512;&#24182;&#21040;&#21478;&#19968;&#31687;&#35770;&#25991;&#20013;&#12290;</title><link>http://arxiv.org/abs/2208.08769</link><description>&lt;p&gt;
&#22270;&#23884;&#20837;&#26041;&#27861;&#30340;&#35760;&#24518;&#19982;&#23481;&#37327;
&lt;/p&gt;
&lt;p&gt;
Memory and Capacity of Graph Embedding Methods. (arXiv:2208.08769v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24050;&#22833;&#25928;&#65292;&#30456;&#20851;&#20869;&#23481;&#24050;&#34987;&#21512;&#24182;&#21040;&#21478;&#19968;&#31687;&#35770;&#25991;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24050;&#22833;&#25928;&#65306;&#35831;&#26597;&#30475;&#8220;&#36890;&#36807;&#24352;&#37327;&#31215;&#21644;&#36817;&#20284;&#27491;&#20132;&#30721;&#23454;&#29616;&#22270;&#23884;&#20837;&#8221;&#30340;&#35770;&#25991;&#65292;&#20854;&#20013;&#24050;&#23558;&#26412;&#25991;&#21512;&#24182;&#20026;&#19968;&#31687;&#35770;&#25991;&#12290;
&lt;/p&gt;
&lt;p&gt;
THIS PAPER IS NOW DEFUNCT: Check out "Graph Embeddings via Tensor Products and Approximately Orthonormal Codes", where it has been combined into one paper.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#36873;&#25321;&#38598;&#21512;&#20013;&#20250;&#25226;&#36873;&#25321;&#27010;&#29575;&#30340;&#38598;&#21512;&#19968;&#33268;&#22320;&#25551;&#36848;&#20986;&#26469;&#12290;</title><link>http://arxiv.org/abs/2208.06115</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Nonparametric Approach with Marginals for Modeling Consumer Choice. (arXiv:2208.06115v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#20998;&#24067;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#28040;&#36153;&#32773;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#20219;&#20309;&#36873;&#25321;&#38598;&#21512;&#20013;&#20250;&#25226;&#36873;&#25321;&#27010;&#29575;&#30340;&#38598;&#21512;&#19968;&#33268;&#22320;&#25551;&#36848;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#28040;&#36153;&#32773;&#22312;&#19981;&#21516;&#36873;&#25321;&#38598;&#21512;&#20013;&#20316;&#20986;&#36873;&#25321;&#30340;&#25968;&#25454;&#65292;&#24320;&#21457;&#25551;&#36848;&#21644;&#39044;&#27979;&#28040;&#36153;&#32773;&#36873;&#25321;&#34892;&#20026;&#30340;&#31616;&#27905;&#27169;&#22411;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#20854;&#20013;&#19968;&#31181;&#36873;&#25321;&#27169;&#22411;&#26159;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20165;&#38656;&#35201;&#35268;&#23450;&#38543;&#26426;&#25928;&#29992;&#30340;&#36793;&#32536;&#20998;&#24067;&#21363;&#21487;&#35299;&#37322;&#36873;&#39033;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31934;&#30830;&#30340;&#36873;&#25321;&#27010;&#29575;&#38598;&#21512;&#30340;&#29305;&#24449;&#21270;&#26041;&#27861;&#65292;&#35813;&#38598;&#21512;&#21487;&#20197;&#22312;&#20219;&#20309;&#38598;&#21512;&#20013;&#19968;&#33268;&#22320;&#36890;&#36807;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#26469;&#25551;&#36848;&#12290;&#20801;&#35768;&#26681;&#25454;&#20854;&#25928;&#29992;&#30340;&#36793;&#32536;&#20998;&#24067;&#23558;&#36873;&#25321;&#38598;&#21512;&#36827;&#34892;&#20998;&#32452;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;(a)&#39564;&#35777;&#36825;&#20010;&#27169;&#22411;&#19982;&#36873;&#25321;&#27010;&#29575;&#25968;&#25454;&#30340;&#19968;&#33268;&#24615;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#26159;&#21487;&#33021;&#30340;&#65292;(b)&#26368;&#25509;&#36817;&#25311;&#21512;&#30340;&#26041;&#27861;&#21487;&#20197;&#31616;&#21270;&#20026;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#20984;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22810;&#39033;&#24335;Logit&#27169;&#22411;&#21644;m&#30456;&#27604;&#65292;&#36793;&#32536;&#20998;&#24067;&#27169;&#22411;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#34920;&#29616;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given data on choices made by consumers for different assortments, a key challenge is to develop parsimonious models that describe and predict consumer choice behavior. One such choice model is the marginal distribution model which requires only the specification of the marginal distributions of the random utilities of the alternatives to explain choice data. In this paper, we develop an exact characterisation of the set of choice probabilities which are representable by the marginal distribution model consistently across any collection of assortments. Allowing for the possibility of alternatives to be grouped based on the marginal distribution of their utilities, we show (a) verifying consistency of choice probability data with this model is possible in polynomial time and (b) finding the closest fit reduces to solving a mixed integer convex program. Our results show that the marginal distribution model provides much better representational power as compared to multinomial logit and m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#21450;&#20854;&#19982;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20511;&#21161;&#20960;&#20309;&#27979;&#37327;&#29702;&#35770;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#20248;&#21270;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24378;&#21046;&#23454;&#34892;&#19968;&#20010;&#31616;&#21333;&#30340;&#31751;&#32467;&#26500;&#65292;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2207.10541</link><description>&lt;p&gt;
&#25581;&#31034;&#25512;&#36827;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#20960;&#20309;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Unveiling the Latent Space Geometry of Push-Forward Generative Models. (arXiv:2207.10541v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.10541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#21450;&#20854;&#19982;&#27169;&#22411;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20511;&#21161;&#20960;&#20309;&#27979;&#37327;&#29702;&#35770;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#20248;&#21270;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24378;&#21046;&#23454;&#34892;&#19968;&#20010;&#31616;&#21333;&#30340;&#31751;&#32467;&#26500;&#65292;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#37117;&#26159;&#36890;&#36807;&#36830;&#32493;&#29983;&#25104;&#22120;&#25512;&#36827;&#39640;&#26031;&#27979;&#37327;&#32780;&#23450;&#20041;&#30340;&#65292;&#20363;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#25110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#12290;&#26412;&#25991;&#25506;&#31350;&#20102;&#36825;&#20123;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#65292;&#22312;&#23398;&#20064;&#19981;&#36830;&#36890;&#20998;&#24067;&#26102;&#65292;&#23427;&#20204;&#24448;&#24448;&#36755;&#20986;&#36229;&#20986;&#30446;&#26631;&#20998;&#24067;&#25903;&#25345;&#33539;&#22260;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#19982;&#23427;&#20204;&#30340;&#28508;&#22312;&#31354;&#38388;&#20960;&#20309;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20511;&#21161;&#20960;&#20309;&#27979;&#37327;&#29702;&#35770;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#25105;&#20204;&#22312;&#28508;&#22312;&#31354;&#38388;&#30340;&#32500;&#24230;&#22823;&#20110;&#27169;&#30340;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#20248;&#21270;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#36890;&#36807;&#23545;GAN&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#29702;&#35770;&#32467;&#26524;&#30340;&#21487;&#38752;&#24615;&#65292;&#24182;&#23545;&#36825;&#20123;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#20960;&#20309;&#32467;&#26500;&#33719;&#24471;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25130;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#24378;&#21046;&#23454;&#34892;&#19968;&#20010;&#31616;&#21333;&#30340;&#31751;&#32467;&#26500;&#65292;&#24182;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many deep generative models are defined as a push-forward of a Gaussian measure by a continuous generator, such as Generative Adversarial Networks (GANs) or Variational Auto-Encoders (VAEs). This work explores the latent space of such deep generative models. A key issue with these models is their tendency to output samples outside of the support of the target distribution when learning disconnected distributions. We investigate the relationship between the performance of these models and the geometry of their latent space. Building on recent developments in geometric measure theory, we prove a sufficient condition for optimality in the case where the dimension of the latent space is larger than the number of modes. Through experiments on GANs, we demonstrate the validity of our theoretical results and gain new insights into the latent space geometry of these models. Additionally, we propose a truncation method that enforces a simplicial cluster structure in the latent space and improve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20840;&#23616;&#30446;&#26631;&#30340;&#25299;&#25169;&#32467;&#26500;&#20197;&#21450;&#23618;&#27425;&#20998;&#21106;&#21644;&#24369;&#24179;&#28369;&#29305;&#24615;&#65292;&#23454;&#29616;&#20102;&#19982;&#23458;&#25143;&#31471;&#25968;&#37327;&#21644;&#35780;&#20272;&#39044;&#31639;&#30456;&#20851;&#30340;&#27425;&#32447;&#24615;&#32047;&#35745;&#36951;&#25022;&#24230;&#65292;&#23545;&#25968;&#36890;&#20449;&#21482;&#22312;&#20013;&#22830;&#26381;&#21153;&#22120;&#21644;&#23458;&#25143;&#31471;&#20043;&#38388;&#36827;&#34892;&#65292;&#20445;&#25252;&#20102;&#23458;&#25143;&#31471;&#30340;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2205.15268</link><description>&lt;p&gt;
&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Federated X-Armed Bandit. (arXiv:2205.15268v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15268
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#32852;&#37030;&#22810;&#33218;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#20840;&#23616;&#30446;&#26631;&#30340;&#25299;&#25169;&#32467;&#26500;&#20197;&#21450;&#23618;&#27425;&#20998;&#21106;&#21644;&#24369;&#24179;&#28369;&#29305;&#24615;&#65292;&#23454;&#29616;&#20102;&#19982;&#23458;&#25143;&#31471;&#25968;&#37327;&#21644;&#35780;&#20272;&#39044;&#31639;&#30456;&#20851;&#30340;&#27425;&#32447;&#24615;&#32047;&#35745;&#36951;&#25022;&#24230;&#65292;&#23545;&#25968;&#36890;&#20449;&#21482;&#22312;&#20013;&#22830;&#26381;&#21153;&#22120;&#21644;&#23458;&#25143;&#31471;&#20043;&#38388;&#36827;&#34892;&#65292;&#20445;&#25252;&#20102;&#23458;&#25143;&#31471;&#30340;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#32852;&#37030; $\mathcal{X}$-armed bandit &#26694;&#26550;&#65292;&#19981;&#21516;&#23458;&#25143;&#31471;&#38754;&#20020;&#22312;&#30456;&#21516;&#22495;&#19978;&#23450;&#20041;&#30340;&#24322;&#26500;&#23616;&#37096;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#38656;&#35201;&#21327;&#20316;&#22320;&#25214;&#20986;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#27492;&#31867;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#32852;&#37030;&#31639;&#27861;&#65292;&#31216;&#20026; \texttt{Fed-PNE}&#12290;&#36890;&#36807;&#21033;&#29992;&#20840;&#23616;&#30446;&#26631;&#30340;&#25299;&#25169;&#32467;&#26500;&#20197;&#21450;&#23618;&#27425;&#20998;&#21106;&#21644;&#24369;&#24179;&#28369;&#29305;&#24615;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#19982;&#23458;&#25143;&#31471;&#25968;&#37327;&#21644;&#35780;&#20272;&#39044;&#31639;&#30456;&#20851;&#30340;&#27425;&#32447;&#24615;&#32047;&#35745;&#36951;&#25022;&#24230;&#12290;&#21516;&#26102;&#65292;&#23427;&#21482;&#38656;&#35201;&#20013;&#22830;&#26381;&#21153;&#22120;&#21644;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#23545;&#25968;&#36890;&#20449;&#65292;&#20445;&#25252;&#20102;&#23458;&#25143;&#31471;&#30340;&#38544;&#31169;&#12290;&#21512;&#25104;&#20989;&#25968;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102; \texttt{Fed-PNE} &#30456;&#23545;&#20110;&#21508;&#31181;&#38598;&#20013;&#24335;&#21644;&#32852;&#37030;&#22522;&#32447;&#31639;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work establishes the first framework of federated $\mathcal{X}$-armed bandit, where different clients face heterogeneous local objective functions defined on the same domain and are required to collaboratively figure out the global optimum. We propose the first federated algorithm for such problems, named \texttt{Fed-PNE}. By utilizing the topological structure of the global objective inside the hierarchical partitioning and the weak smoothness property, our algorithm achieves sublinear cumulative regret with respect to both the number of clients and the evaluation budget. Meanwhile, it only requires logarithmic communications between the central server and clients, protecting the client privacy. Experimental results on synthetic functions and real datasets validate the advantages of \texttt{Fed-PNE} over various centralized and federated baseline algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#27010;&#24565;&#30340;&#8220;&#38750;&#22238;&#28335;&#8221;&#30697;&#38453;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#30340;Ihara-Bass&#22411;&#20844;&#24335;&#65292;&#21033;&#29992;&#35813;&#29702;&#35770;&#35777;&#26126;&#20102;&#38543;&#26426;k-CSP&#23454;&#20363;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#24378;&#35777;&#26126;&#30340;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2204.10881</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#24067;&#23572;&#30697;&#38453;&#30340;Ihara-Bass&#20844;&#24335;&#21450;&#38543;&#26426;CSPs&#30340;&#24378;&#35777;&#26126;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
A Ihara-Bass Formula for Non-Boolean Matrices and Strong Refutations of Random CSPs. (arXiv:2204.10881v2 [cs.CC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#27010;&#24565;&#30340;&#8220;&#38750;&#22238;&#28335;&#8221;&#30697;&#38453;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#30340;Ihara-Bass&#22411;&#20844;&#24335;&#65292;&#21033;&#29992;&#35813;&#29702;&#35770;&#35777;&#26126;&#20102;&#38543;&#26426;k-CSP&#23454;&#20363;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#24378;&#35777;&#26126;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#8220;&#38750;&#22238;&#28335;&#8221;&#30697;&#38453;&#27010;&#24565;&#65292;&#21487;&#19982;&#20219;&#20309;&#23545;&#31216;&#30697;&#38453;&#30456;&#20851;&#65292;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#30340;Ihara-Bass&#22411;&#20844;&#24335;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#29702;&#35770;&#35777;&#26126;&#20102;&#20851;&#20110;$k$&#20010;&#21464;&#37327;&#27599;&#32422;&#26463;&#30340;&#38543;&#26426;&#32422;&#26463;&#28385;&#36275;&#38382;&#39064;&#65288;k-CSPs&#65289;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#24378;&#35777;&#26126;&#30340;&#26032;&#32467;&#26524;&#12290;&#23545;&#20110;&#30001;&#19968;&#20010;&#30001;$p$&#20998;&#25968;&#30340;&#20998;&#37197;&#28385;&#36275;&#30340;&#32422;&#26463;&#26500;&#24314;&#30340;&#38543;&#26426;k-CSP&#23454;&#20363;&#65292;&#22914;&#26524;&#23454;&#20363;&#21253;&#21547;$n$&#20010;&#21464;&#37327;&#21644;$n^{k/2} / \epsilon^2$&#20010;&#32422;&#26463;&#65292;&#21017;&#25105;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#35745;&#31639;&#20986;&#26368;&#20248;&#35299;&#20165;&#28385;&#36275;$p+O_k(\epsilon)$&#20010;&#32422;&#26463;&#30340;&#35777;&#20070;&#12290;&#20197;&#21069;&#65292;&#36825;&#20165;&#23545;&#20110;&#20598;&#25968;$k$&#26159;&#24050;&#30693;&#30340;&#65292;&#20294;&#23545;&#20110;&#22855;&#25968;$k$&#65292;&#38656;&#35201;$n^{k/2} (\log n)^{O(1)} / \epsilon^2$&#20010;&#38543;&#26426;&#32422;&#26463;&#25165;&#33021;&#24471;&#20986;&#30456;&#21516;&#30340;&#32467;&#35770;&#12290;&#34429;&#28982;&#25913;&#36827;&#20165;&#26159;&#23545;&#25968;&#32423;&#21035;&#30340;&#65292;&#20294;&#23427;&#20811;&#26381;&#20102;&#36825;&#31867;&#32467;&#26524;&#30340;&#19968;&#20010;&#37325;&#35201;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define a novel notion of ``non-backtracking'' matrix associated to any symmetric matrix, and we prove a ``Ihara-Bass'' type formula for it.  We use this theory to prove new results on polynomial-time strong refutations of random constraint satisfaction problems with $k$ variables per constraints (k-CSPs). For a random k-CSP instance constructed out of a constraint that is satisfied by a $p$ fraction of assignments, if the instance contains $n$ variables and $n^{k/2} / \epsilon^2$ constraints, we can efficiently compute a certificate that the optimum satisfies at most a $p+O_k(\epsilon)$ fraction of constraints.  Previously, this was known for even $k$, but for odd $k$ one needed $n^{k/2} (\log n)^{O(1)} / \epsilon^2$ random constraints to achieve the same conclusion.  Although the improvement is only polylogarithmic, it overcomes a significant barrier to these types of results. Strong refutation results based on current approaches construct a certificate that a certain matrix associ
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#33324;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#21487;&#20197;&#20026;&#30740;&#31350;&#23545;&#25239;&#24615;&#20195;&#29702;&#25439;&#22833;&#21644;&#20854;&#19968;&#33268;&#24615;&#23646;&#24615;&#25552;&#20379;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2112.01694</link><description>&lt;p&gt;
&#20851;&#20110;&#23545;&#25239;&#24615;Bayes&#20998;&#31867;&#22120;&#23384;&#22312;&#24615;&#30340;&#30740;&#31350;&#65288;&#25193;&#23637;&#29256;&#65289;
&lt;/p&gt;
&lt;p&gt;
On the Existence of the Adversarial Bayes Classifier (Extended Version). (arXiv:2112.01694v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.01694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#30340;&#23384;&#22312;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#33324;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#21487;&#20197;&#20026;&#30740;&#31350;&#23545;&#25239;&#24615;&#20195;&#29702;&#25439;&#22833;&#21644;&#20854;&#19968;&#33268;&#24615;&#23646;&#24615;&#25552;&#20379;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#26368;&#36817;&#24050;&#32463;&#26377;&#22810;&#39033;&#29702;&#35770;&#30740;&#31350;&#65292;&#20294;&#19982;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#30456;&#20851;&#30340;&#35768;&#22810;&#37325;&#35201;&#38382;&#39064;&#20173;&#28982;&#26410;&#34987;&#35299;&#20915;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20851;&#20110;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#23384;&#22312;&#24615;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#33324;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#20445;&#35777;&#23384;&#22312;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;&#30340;Bayes&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#20197;&#20026;&#23545;&#21518;&#32493;&#23545;&#25239;&#35757;&#32451;&#20581;&#22766;&#24615;&#19979;&#20195;&#29702;&#25439;&#22833;&#21644;&#23427;&#20204;&#30340;&#19968;&#33268;&#24615;&#23646;&#24615;&#30340;&#30740;&#31350;&#25552;&#20379;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#26412;&#25991;&#26159;&#8220;&#20851;&#20110;&#23545;&#25239;&#24615;Bayes&#20998;&#31867;&#22120;&#23384;&#22312;&#24615;&#8221;&#30340;&#30699;&#27491;&#21644;&#25193;&#23637;&#29256;&#26412;&#65292;&#35813;&#31295;&#20214;&#24050;&#21457;&#34920;&#22312;NeurIPS 2021&#19978;&#12290;&#21407;&#22987;&#35770;&#25991;&#20013;&#26377;&#20004;&#22788;&#23450;&#29702;&#38169;&#35823;&#65292;&#19968;&#22788;&#26159;&#23545;&#20266;&#21487;&#35777;&#20581;&#22766;&#24615;&#30340;&#23450;&#20041;&#65292;&#21478;&#19968;&#22788;&#26159;&#38024;&#23545;&#20219;&#24847;&#24230;&#37327;&#31354;&#38388;&#30340;$A^\e$&#21487;&#27979;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open. In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties. This manuscript is the extended and corrected version of the paper \emph{On the Existence of the Adversarial Bayes Classifier} published in NeurIPS 2021. There were two errors in theorem statements in the original paper -- one in the definition of pseudo-certifiable robustness and the other in the measurability of $A^\e$ for arbitrary metric spaces. In this version we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#22238;&#24402;&#38750;&#23545;&#31216;&#32447;&#24615;&#39640;&#26031;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#21487;&#20197;&#20026;&#27599;&#20010;&#36807;&#31243;&#29366;&#24577;&#25317;&#26377;&#19981;&#21516;&#30340;&#25512;&#29702;&#27169;&#22411;&#65292;&#21516;&#26102;&#36890;&#36807;&#20462;&#25913;&#22522;&#30784;&#27169;&#22411;&#65292;&#20351;&#20854;&#20855;&#26377;&#38750;&#23545;&#31216;&#33258;&#22238;&#24402;&#20998;&#37327;&#65292;&#33021;&#22815;&#33258;&#21160;&#36873;&#25321;&#26368;&#22823;&#21270;&#32473;&#23450;&#35757;&#32451;&#38598;&#30340;&#24809;&#32602;&#20284;&#28982;&#30340;&#33258;&#22238;&#24402;&#38454;&#25968;&#12290;</title><link>http://arxiv.org/abs/2010.15604</link><description>&lt;p&gt;
&#33258;&#22238;&#24402;&#38750;&#23545;&#31216;&#32447;&#24615;&#39640;&#26031;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Autoregressive Asymmetric Linear Gaussian Hidden Markov Models. (arXiv:2010.15604v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.15604
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#22238;&#24402;&#38750;&#23545;&#31216;&#32447;&#24615;&#39640;&#26031;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#21487;&#20197;&#20026;&#27599;&#20010;&#36807;&#31243;&#29366;&#24577;&#25317;&#26377;&#19981;&#21516;&#30340;&#25512;&#29702;&#27169;&#22411;&#65292;&#21516;&#26102;&#36890;&#36807;&#20462;&#25913;&#22522;&#30784;&#27169;&#22411;&#65292;&#20351;&#20854;&#20855;&#26377;&#38750;&#23545;&#31216;&#33258;&#22238;&#24402;&#20998;&#37327;&#65292;&#33021;&#22815;&#33258;&#21160;&#36873;&#25321;&#26368;&#22823;&#21270;&#32473;&#23450;&#35757;&#32451;&#38598;&#30340;&#24809;&#32602;&#20284;&#28982;&#30340;&#33258;&#22238;&#24402;&#38454;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#38543;&#26102;&#38388;&#28436;&#21464;&#30340;&#30495;&#23454;&#36807;&#31243;&#20013;&#65292;&#30456;&#20851;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#21487;&#33021;&#20250;&#25913;&#21464;&#12290;&#22240;&#27492;&#65292;&#20026;&#27599;&#20010;&#36807;&#31243;&#29366;&#24577;&#25317;&#26377;&#19981;&#21516;&#30340;&#25512;&#29702;&#27169;&#22411;&#26159;&#26377;&#20248;&#21183;&#30340;&#12290;&#38750;&#23545;&#31216;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#28385;&#36275;&#36825;&#31181;&#21160;&#24577;&#35201;&#27714;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#26694;&#26550;&#65292;&#20854;&#20013;&#36807;&#31243;&#30340;&#36235;&#21183;&#21487;&#20197;&#34987;&#34920;&#31034;&#20026;&#19968;&#20010;&#28508;&#21464;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#36825;&#20123;&#26368;&#36817;&#30340;&#38750;&#23545;&#31216;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65292;&#20351;&#20854;&#20855;&#26377;&#38750;&#23545;&#31216;&#33258;&#22238;&#24402;&#20998;&#37327;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#36873;&#25321;&#26368;&#22823;&#21270;&#32473;&#23450;&#35757;&#32451;&#38598;&#30340;&#24809;&#32602;&#20284;&#28982;&#30340;&#33258;&#22238;&#24402;&#38454;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24517;&#39035;&#22914;&#20309;&#35843;&#25972;&#25512;&#29702;&#12289;&#38544;&#34255;&#29366;&#24577;&#35299;&#30721;&#21644;&#21442;&#25968;&#23398;&#20064;&#26469;&#36866;&#24212;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#23637;&#31034;&#36825;&#20010;&#26032;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a real life process evolving over time, the relationship between its relevant variables may change. Therefore, it is advantageous to have different inference models for each state of the process. Asymmetric hidden Markov models fulfil this dynamical requirement and provide a framework where the trend of the process can be expressed as a latent variable. In this paper, we modify these recent asymmetric hidden Markov models to have an asymmetric autoregressive component, allowing the model to choose the order of autoregression that maximizes its penalized likelihood for a given training set. Additionally, we show how inference, hidden states decoding and parameter learning must be adapted to fit the proposed model. Finally, we run experiments with synthetic and real data to show the capabilities of this new model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;DAG&#22240;&#26524;&#27169;&#22411;&#30340;&#20302;&#31209;&#20551;&#35774;&#26469;&#35299;&#20915;&#39640;&#32500;&#24773;&#20917;&#19979;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#38590;&#39064;&#65292;&#24182;&#25104;&#21151;&#22320;&#23558;&#29616;&#26377;&#30340;&#20302;&#31209;&#25216;&#26415;&#24212;&#29992;&#21040;&#20102;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#65292;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#31264;&#23494;&#22270;&#30340;&#25968;&#25454;&#27169;&#22411;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2006.05691</link><description>&lt;p&gt;
&#20302;&#31209;&#26377;&#21521;&#26080;&#29615;&#22270;&#19982;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
On Low Rank Directed Acyclic Graphs and Causal Structure Learning. (arXiv:2006.05691v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.05691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;DAG&#22240;&#26524;&#27169;&#22411;&#30340;&#20302;&#31209;&#20551;&#35774;&#26469;&#35299;&#20915;&#39640;&#32500;&#24773;&#20917;&#19979;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#38590;&#39064;&#65292;&#24182;&#25104;&#21151;&#22320;&#23558;&#29616;&#26377;&#30340;&#20302;&#31209;&#25216;&#26415;&#24212;&#29992;&#21040;&#20102;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#65292;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#23545;&#20110;&#31264;&#23494;&#22270;&#30340;&#25968;&#25454;&#27169;&#22411;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36817;&#24180;&#26469;&#26377;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23398;&#20064;&#30001;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#34920;&#31034;&#30340;&#22240;&#26524;&#32467;&#26500;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#24403;&#35201;&#23398;&#20064;&#30340;&#22270;&#19981;&#26159;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#21033;&#29992;&#20851;&#20110;DAG&#22240;&#26524;&#27169;&#22411;&#30340;&#65288;&#21152;&#26435;&#65289;&#37051;&#25509;&#30697;&#38453;&#30340;&#20302;&#31209;&#20551;&#35774;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#21033;&#29992;&#29616;&#26377;&#30340;&#20302;&#31209;&#25216;&#26415;&#26469;&#35843;&#25972;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#20805;&#20998;&#21033;&#29992;&#36825;&#20010;&#20551;&#35774;&#65292;&#24182;&#24314;&#31435;&#19968;&#20123;&#26377;&#29992;&#30340;&#32467;&#26524;&#65292;&#23558;&#21487;&#35299;&#37322;&#30340;&#22270;&#24418;&#26465;&#20214;&#19982;&#20302;&#31209;&#20551;&#35774;&#30456;&#20851;&#32852;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#34920;&#26126;&#26368;&#22823;&#31209;&#19982;&#20013;&#24515;&#33410;&#28857;&#39640;&#24230;&#30456;&#20851;&#65292;&#36825;&#34920;&#26126;&#22312;&#23454;&#36341;&#20013;&#32463;&#24120;&#36935;&#21040;&#30340;&#26080;&#26631;&#24230;&#32593;&#32476;&#24448;&#24448;&#26159;&#20302;&#31209;&#30340;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#20302;&#31209;&#36866;&#24212;&#23545;&#20110;&#21508;&#31181;&#25968;&#25454;&#27169;&#22411;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#30456;&#23545;&#22823;&#19988;&#23494;&#38598;&#30340;&#22270;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#39564;&#35777;&#36807;&#31243;&#65292;&#36866;&#24212;&#24615;&#26041;&#27861;&#22987;&#32456;&#20445;&#25345;&#21331;&#36234;&#25110;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite several advances in recent years, learning causal structures represented by directed acyclic graphs (DAGs) remains a challenging task in high dimensional settings when the graphs to be learned are not sparse. In this paper, we propose to exploit a low rank assumption regarding the (weighted) adjacency matrix of a DAG causal model to help address this problem. We utilize existing low rank techniques to adapt causal structure learning methods to take advantage of this assumption and establish several useful results relating interpretable graphical conditions to the low rank assumption. Specifically, we show that the maximum rank is highly related to hubs, suggesting that scale-free networks, which are frequently encountered in practice, tend to be low rank. Our experiments demonstrate the utility of the low rank adaptations for a variety of data models, especially with relatively large and dense graphs. Moreover, with a validation procedure, the adaptations maintain a superior or
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AdaUSM&#30340;AdaGrad&#21464;&#20307;&#65292;&#23427;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#26435;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#32479;&#19968;AdaGrad&#12289;AccAdaGrad&#12289;Adam&#21644;RMSProp&#30340;&#23398;&#20064;&#29575;&#65292;&#21516;&#26102;&#36890;&#36807;&#20351;&#29992;&#32479;&#19968;&#21160;&#37327;&#26041;&#26696;&#65292;&#35206;&#30422;&#20102;&#37325;&#29699;&#21160;&#37327;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#21160;&#37327;&#65307;&#22312;&#38750;&#20984;&#38543;&#26426;&#35774;&#32622;&#20013;&#30340;&#25910;&#25947;&#29575;&#20026;$\mathcal{O}(\log(T)/\sqrt{T})$&#12290;</title><link>http://arxiv.org/abs/1808.03408</link><description>&lt;p&gt;
&#19968;&#31181;&#24102;&#26377;&#26435;&#37325;&#32858;&#38598;&#21644;&#21160;&#37327;&#21152;&#36895;&#30340;AdaGrad&#30340;&#32479;&#19968;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Unified Analysis of AdaGrad with Weighted Aggregation and Momentum Acceleration. (arXiv:1808.03408v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1808.03408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;AdaUSM&#30340;AdaGrad&#21464;&#20307;&#65292;&#23427;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#26435;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#32479;&#19968;AdaGrad&#12289;AccAdaGrad&#12289;Adam&#21644;RMSProp&#30340;&#23398;&#20064;&#29575;&#65292;&#21516;&#26102;&#36890;&#36807;&#20351;&#29992;&#32479;&#19968;&#21160;&#37327;&#26041;&#26696;&#65292;&#35206;&#30422;&#20102;&#37325;&#29699;&#21160;&#37327;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#21160;&#37327;&#65307;&#22312;&#38750;&#20984;&#38543;&#26426;&#35774;&#32622;&#20013;&#30340;&#25910;&#25947;&#29575;&#20026;$\mathcal{O}(\log(T)/\sqrt{T})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#21644;&#21160;&#37327;&#25216;&#26415;&#38598;&#25104;&#21040;SGD&#20013;&#20250;&#23548;&#33268;&#19968;&#31867;&#39640;&#25928;&#21152;&#36895;&#33258;&#36866;&#24212;&#38543;&#26426;&#31639;&#27861;&#65292;&#22914;AdaGrad&#65292;RMSProp&#65292;Adam&#65292;AccAdaGrad&#31561;&#12290;&#23613;&#31649;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#26377;&#25928;&#65292;&#20294;&#23427;&#20204;&#30340;&#25910;&#25947;&#29702;&#35770;&#20173;&#23384;&#22312;&#24456;&#22823;&#24046;&#36317;&#65292;&#29305;&#21035;&#26159;&#22312;&#38750;&#20984;&#38543;&#26426;&#35774;&#32622;&#20013;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#8220;&#24102;&#26377;&#32479;&#19968;&#21160;&#37327;&#30340;&#21152;&#26435;AdaGrad&#8221;&#65292;&#31216;&#20026;AdaUSM&#65292;&#23427;&#20855;&#26377;&#20197;&#19979;&#20027;&#35201;&#29305;&#24449;&#65306;(1) &#23427;&#34701;&#21512;&#20102;&#32479;&#19968;&#30340;&#21160;&#37327;&#26041;&#26696;&#65292;&#28085;&#30422;&#20102;&#37325;&#29699;&#21160;&#37327;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#21160;&#37327;&#65307;(2) &#23427;&#37319;&#29992;&#20102;&#19968;&#31181;&#26032;&#30340;&#21152;&#26435;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#32479;&#19968;AdaGrad&#65292;AccAdaGrad&#65292;Adam&#21644;RMSProp&#30340;&#23398;&#20064;&#29575;&#12290;&#27492;&#22806;&#65292;&#24403;&#25105;&#20204;&#22312;AdaUSM&#20013;&#37319;&#29992;&#22810;&#39033;&#24335;&#22686;&#38271;&#30340;&#26435;&#37325;&#26102;&#65292;&#22312;&#38750;&#20984;&#38543;&#26426;&#35774;&#32622;&#20013;&#21487;&#20197;&#24471;&#21040;&#20854;&#25910;&#25947;&#29575;&#20026;$\mathcal{O}(\log(T)/\sqrt{T})$ &#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;Adam&#21644;RMSProp&#30340;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#22312;&#37325;&#21152;&#26435;&#30340;&#24773;&#20917;&#19979;&#26159;&#19968;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Integrating adaptive learning rate and momentum techniques into SGD leads to a large class of efficiently accelerated adaptive stochastic algorithms, such as AdaGrad, RMSProp, Adam, AccAdaGrad, \textit{etc}. In spite of their effectiveness in practice, there is still a large gap in their theories of convergences, especially in the difficult non-convex stochastic setting. To fill this gap, we propose \emph{weighted AdaGrad with unified momentum}, dubbed AdaUSM, which has the main characteristics that (1) it incorporates a unified momentum scheme which covers both the heavy ball momentum and the Nesterov accelerated gradient momentum; (2) it adopts a novel weighted adaptive learning rate that can unify the learning rates of AdaGrad, AccAdaGrad, Adam, and RMSProp. Moreover, when we take polynomially growing weights in AdaUSM, we obtain its $\mathcal{O}(\log(T)/\sqrt{T})$ convergence rate in the non-convex stochastic setting. We also show that the adaptive learning rates of Adam and RMSPro
&lt;/p&gt;</description></item></channel></rss>