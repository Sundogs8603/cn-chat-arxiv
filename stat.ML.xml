<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27169;&#22411;HomoODE&#65292;&#23427;&#32487;&#25215;&#20102;DEQs&#30340;&#39640;&#31934;&#24230;&#24615;&#33021;&#21644;Neural ODEs&#30340;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.09583</link><description>&lt;p&gt;
&#20004;&#26522;&#30828;&#24065;&#30340;&#20004;&#38754;&#65306;&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#36830;&#25509;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation. (arXiv:2310.09583v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09583
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27169;&#22411;HomoODE&#65292;&#23427;&#32487;&#25215;&#20102;DEQs&#30340;&#39640;&#31934;&#24230;&#24615;&#33021;&#21644;Neural ODEs&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#26159;&#20004;&#31181;&#38544;&#24335;&#27169;&#22411;&#30340;&#20998;&#25903;&#65292;&#20197;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#20302;&#20869;&#23384;&#28040;&#32791;&#25104;&#23601;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#34429;&#28982;&#20004;&#32773;&#37117;&#26159;&#38544;&#24335;&#27169;&#22411;&#65292;&#20294;DEQs&#21644;Neural ODEs&#26159;&#20174;&#19981;&#21516;&#30340;&#25968;&#23398;&#24418;&#24335;&#23548;&#20986;&#30340;&#12290;&#21463;&#21516;&#20262;&#24310;&#32493;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20004;&#31181;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#23454;&#38469;&#19978;&#26159;&#21516;&#19968;&#20010;&#30828;&#24065;&#30340;&#20004;&#38754;&#12290;&#21516;&#20262;&#24310;&#32493;&#26159;&#19968;&#31181;&#22522;&#20110;&#23545;&#24212;ODE&#30340;&#35299;&#38750;&#32447;&#24615;&#26041;&#31243;&#32452;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#32473;&#23450;&#36825;&#31181;&#32852;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27169;&#22411;&#31216;&#20026;HomoODE&#65292;&#23427;&#32487;&#25215;&#20102;DEQs&#30340;&#39640;&#31934;&#24230;&#24615;&#36136;&#21644;Neural ODEs&#30340;&#31283;&#23450;&#24615;&#12290;&#19982;DEQs&#19981;&#21516;&#65292;HomoODE&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#20351;&#29992;&#20462;&#25913;&#21518;&#30340;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#38544;&#24335;&#22320;&#35299;&#20915;&#24179;&#34913;&#28857;&#25214;&#23547;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations (Neural ODEs) are two branches of implicit models that have achieved remarkable success owing to their superior performance and low memory consumption. While both are implicit models, DEQs and Neural ODEs are derived from different mathematical formulations. Inspired by homotopy continuation, we establish a connection between these two models and illustrate that they are actually two sides of the same coin. Homotopy continuation is a classical method of solving nonlinear equations based on a corresponding ODE. Given this connection, we proposed a new implicit model called HomoODE that inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs, which explicitly solve an equilibrium-point-finding problem via Newton's methods in the forward pass, HomoODE solves the equilibrium-point-finding problem implicitly using a modified Neural ODE via homotopy continuation. Fur
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;gamma&#20998;&#24067;&#21644;log-Gaussian&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#38598;&#20197;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#35266;&#27979;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;Raman&#21644;CARS&#20809;&#35889;&#65292;&#21516;&#26102;&#35757;&#32451;&#20004;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#21487;&#20197;&#20272;&#35745;&#22522;&#30784;&#30340;&#20809;&#35889;&#24182;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08055</link><description>&lt;p&gt;
&#29992;&#20110;Raman&#21644;CARS&#20809;&#35889;&#23398;&#20013;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#23545;&#25968;-&#39640;&#26031;&#947;&#36807;&#31243;&#30340;&#35757;&#32451;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Log-Gaussian Gamma Processes for Training Bayesian Neural Networks in Raman and CARS Spectroscopies. (arXiv:2310.08055v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;gamma&#20998;&#24067;&#21644;log-Gaussian&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#38598;&#20197;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#65292;&#35299;&#20915;&#20102;&#23454;&#38469;&#35266;&#27979;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#36890;&#36807;&#24212;&#29992;&#20110;Raman&#21644;CARS&#20809;&#35889;&#65292;&#21516;&#26102;&#35757;&#32451;&#20004;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#21487;&#20197;&#20272;&#35745;&#22522;&#30784;&#30340;&#20809;&#35889;&#24182;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;gamma&#20998;&#24067;&#30340;&#38543;&#26426;&#21464;&#37327;&#21644;log-Gaussian&#24314;&#27169;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#36866;&#21512;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#21508;&#31181;&#24212;&#29992;&#20013;&#23454;&#38469;&#35266;&#27979;&#25968;&#25454;&#26377;&#38480;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;Raman&#21644;&#30456;&#24178;&#38450;-&#26031;&#25176;&#20811;&#26031;&#25289;&#26364;&#25955;&#23556;(CARS)&#20809;&#35889;&#20013;&#65292;&#20351;&#29992;&#23454;&#39564;&#20809;&#35889;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#12290;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#36827;&#34892;&#65292;&#20174;&#32780;&#20026;&#27169;&#22411;&#25552;&#20379;&#23436;&#25972;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#65292;&#21487;&#29992;&#20110;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#23545;Raman&#21644;CARS&#30340;&#21152;&#24615;&#21644;&#20056;&#24615;&#32972;&#26223;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;&#20004;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;gamma&#36807;&#31243;&#30340;&#21442;&#25968;&#65292;&#28982;&#21518;&#21487;&#20197;&#29992;&#36825;&#20123;&#21442;&#25968;&#26469;&#20272;&#35745;&#22522;&#30784;&#30340;Raman&#20809;&#35889;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#20998;&#24067;&#21442;&#25968;&#30340;&#20272;&#35745;&#21516;&#26102;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an approach utilizing gamma-distributed random variables, coupled with log-Gaussian modeling, to generate synthetic datasets suitable for training neural networks. This addresses the challenge of limited real observations in various applications. We apply this methodology to both Raman and coherent anti-Stokes Raman scattering (CARS) spectra, using experimental spectra to estimate gamma process parameters. Parameter estimation is performed using Markov chain Monte Carlo methods, yielding a full Bayesian posterior distribution for the model which can be sampled for synthetic data generation. Additionally, we model the additive and multiplicative background functions for Raman and CARS with Gaussian processes. We train two Bayesian neural networks to estimate parameters of the gamma process which can then be used to estimate the underlying Raman spectrum and simultaneously provide uncertainty through the estimation of parameters of a probability distribution. We apply the trai
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02679</link><description>&lt;p&gt;
&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65306;&#36890;&#36807;&#37096;&#20998;&#36712;&#36857;&#20248;&#21270;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
Diffusion Generative Flow Samplers: Improving learning signals through partial trajectory optimization. (arXiv:2310.02679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02679
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#30340;&#37319;&#26679;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#23398;&#20064;&#36807;&#31243;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#23454;&#29616;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#21644;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#26469;&#25913;&#21892;&#23398;&#20064;&#20449;&#21495;&#30340;&#20998;&#37197;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#38590;&#20197;&#22788;&#29702;&#30340;&#39640;&#32500;&#23494;&#24230;&#20989;&#25968;&#20013;&#36827;&#34892;&#37319;&#26679;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#20013;&#32463;&#24120;&#20986;&#29616;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;&#26368;&#36817;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#25511;&#21046;&#30340;&#38543;&#26426;&#36807;&#31243;&#26469;&#27169;&#25311;&#36825;&#20123;&#30446;&#26631;&#23494;&#24230;&#30340;&#36817;&#20284;&#26679;&#26412;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#20027;&#35201;&#32570;&#28857;&#26159;&#35757;&#32451;&#30446;&#26631;&#38656;&#35201;&#35745;&#31639;&#23436;&#25972;&#30340;&#36712;&#36857;&#65292;&#23548;&#33268;&#30001;&#20110;&#20351;&#29992;&#23436;&#25972;&#36712;&#36857;&#21644;&#21482;&#22312;&#32456;&#31471;&#26102;&#38388;&#23384;&#22312;&#30340;&#23398;&#20064;&#20449;&#21495;&#30340;&#20351;&#29992;&#32780;&#20135;&#29983;&#32531;&#24930;&#30340;&#20449;&#29992;&#20998;&#37197;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25193;&#25955;&#29983;&#25104;&#27969;&#37319;&#26679;&#22120;&#65288;DGFS&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#37319;&#26679;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#23398;&#20064;&#36807;&#31243;&#21487;&#34892;&#22320;&#20998;&#35299;&#20026;&#30701;&#30340;&#37096;&#20998;&#36712;&#36857;&#27573;&#65292;&#36890;&#36807;&#21442;&#25968;&#21270;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#27969;&#20989;&#25968;&#8221;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#29983;&#25104;&#27969;&#32593;&#32476;&#65288;GFlowNets&#65289;&#30340;&#29702;&#35770;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#20013;&#38388;&#30340;&#23398;&#20064;&#20449;&#21495;&#65292;&#24182;&#20174;&#38750;&#31574;&#30053;&#25506;&#32034;&#33021;&#21147;&#20013;&#21463;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We tackle the problem of sampling from intractable high-dimensional density functions, a fundamental task that often appears in machine learning and statistics. We extend recent sampling-based approaches that leverage controlled stochastic processes to model approximate samples from these target densities. The main drawback of these approaches is that the training objective requires full trajectories to compute, resulting in sluggish credit assignment issues due to use of entire trajectories and a learning signal present only at the terminal time. In this work, we present Diffusion Generative Flow Samplers (DGFS), a sampling-based framework where the learning process can be tractably broken down into short partial trajectory segments, via parameterizing an additional "flow function". Our method takes inspiration from the theory developed for generative flow networks (GFlowNets), allowing us to make use of intermediate learning signals and benefit from off-policy exploration capabilitie
&lt;/p&gt;</description></item><item><title>SimFBO&#21644;&#20854;ShroFBO&#21464;&#20307;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;FBO&#26694;&#26550;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20803;&#23398;&#20064;&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.19442</link><description>&lt;p&gt;
SimFBO&#65306;&#31616;&#21333;&#12289;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;&#32852;&#37030;&#21452;&#23618;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning. (arXiv:2305.19442v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19442
&lt;/p&gt;
&lt;p&gt;
SimFBO&#21644;&#20854;ShroFBO&#21464;&#20307;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#12289;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;FBO&#26694;&#26550;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#20803;&#23398;&#20064;&#21644;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26469;&#65292;&#30001;&#20110;&#20803;&#23398;&#20064;&#12289;&#24494;&#35843;&#12289;&#36229;&#21442;&#25968;&#35843;&#25972;&#31561;&#39046;&#22495;&#20013;&#23884;&#22871;&#20248;&#21270;&#32467;&#26500;&#30340;&#20986;&#29616;&#65292;&#32852;&#37030;&#21452;&#23618;&#20248;&#21270;&#65288;FBO&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#36793;&#32536;&#35745;&#31639;&#20013;&#26174;&#31034;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;FBO&#31639;&#27861;&#24448;&#24448;&#28041;&#21450;&#22797;&#26434;&#30340;&#35745;&#31639;&#65292;&#24182;&#38656;&#35201;&#27599;&#27425;&#36845;&#20195;&#22810;&#20010;&#23376;&#24490;&#29615;&#65292;&#27599;&#20010;&#23376;&#24490;&#29615;&#21253;&#21547;&#22810;&#20010;&#36890;&#20449;&#36718;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;SimFBO&#30340;&#31616;&#21333;&#28789;&#27963;&#30340;FBO&#26694;&#26550;&#65292;&#23427;&#26131;&#20110;&#23454;&#29616;&#65292;&#19981;&#38656;&#35201;&#23376;&#24490;&#29615;&#65292;&#24182;&#21253;&#25324;&#19968;&#31181;&#24191;&#20041;&#30340;&#26381;&#21153;&#22120;&#31471;&#32858;&#21512;&#21644;&#26356;&#26032;&#20197;&#25552;&#39640;&#36890;&#20449;&#25928;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#31995;&#32479;&#32423;&#24322;&#26500;&#40065;&#26834;FBO&#65288;ShroFBO&#65289;&#20316;&#20026;SimFBO&#30340;&#21464;&#20307;&#65292;&#20854;&#23545;&#26412;&#22320;&#35745;&#31639;&#30340;&#24322;&#26500;&#26377;&#26356;&#24378;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#37096;&#20998;&#23458;&#25143;&#31471;&#21442;&#19982;&#21644;&#26080;&#26367;&#25442;&#30340;&#23458;&#25143;&#31471;&#37319;&#26679;&#19979;&#65292;SimFBO&#21644;ShroFBO&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#25910;&#25947;&#21152;&#36895;&#65292;&#21516;&#26102;&#25913;&#36827;&#20102;&#26679;&#26412;&#21644;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#20803;&#23398;&#20064;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated bilevel optimization (FBO) has shown great potential recently in machine learning and edge computing due to the emerging nested optimization structure in meta-learning, fine-tuning, hyperparameter tuning, etc. However, existing FBO algorithms often involve complicated computations and require multiple sub-loops per iteration, each of which contains a number of communication rounds. In this paper, we propose a simple and flexible FBO framework named SimFBO, which is easy to implement without sub-loops, and includes a generalized server-side aggregation and update for improving communication efficiency. We further propose System-level heterogeneity robust FBO (ShroFBO) as a variant of SimFBO with stronger resilience to heterogeneous local computation. We show that SimFBO and ShroFBO provably achieve a linear convergence speedup with partial client participation and client sampling without replacement, as well as improved sample and communication complexities. Experiments demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#12290;</title><link>http://arxiv.org/abs/2305.16150</link><description>&lt;p&gt;
&#32479;&#19968;GAN&#21644;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#30340;&#31890;&#23376;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20363;&#22914;&#26799;&#24230;&#27969;&#21644;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#24778;&#20154;&#30340;&#24615;&#33021;&#32780;&#26368;&#36817;&#21463;&#21040;&#20851;&#27880;&#12290;&#20256;&#32479;&#19978;&#65292;&#36890;&#36807;&#24494;&#20998;&#26041;&#31243;&#26469;&#31227;&#21160;&#31890;&#23376;&#20998;&#24067;&#30340;&#26041;&#27861;&#34987;&#26222;&#36941;&#35748;&#20026;&#26159;&#19982;&#20197;&#21069;&#24191;&#27867;&#20351;&#29992;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30456;&#23545;&#31435;&#30340;&#65292;&#21518;&#32773;&#28041;&#21450;&#21040;&#35757;&#32451;&#19968;&#20010;&#21521;&#21069;&#30340;&#29983;&#25104;&#22120;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#36825;&#31181;&#35299;&#37322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#25512;&#24191;&#12290;&#36825;&#34920;&#26126;&#65292;&#29983;&#25104;&#22120;&#26159;&#20219;&#20309;&#36825;&#26679;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#36873;&#38468;&#20214;&#12290;&#22240;&#27492;&#65292;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#33258;&#28982;&#22320;&#20986;&#29616;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#27979;&#35797;&#36825;&#20123;&#21407;&#22987;&#27169;&#22411;&#30340;&#21487;&#34892;&#24615;&#65292;&#36825;&#20123;&#27169;&#22411;&#26159;&#25105;&#20204;&#26694;&#26550;&#21487;&#33021;&#24212;&#29992;&#30340;&#27010;&#24565;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Particle-based deep generative models, such as gradient flows and score-based diffusion models, have recently gained traction thanks to their striking performance. Their principle of displacing particle distributions by differential equations is conventionally seen as opposed to the previously widespread generative adversarial networks (GANs), which involve training a pushforward generator network. In this paper, we challenge this interpretation and propose a novel framework that unifies particle and adversarial generative models by framing generator training as a generalization of particle models. This suggests that a generator is an optional addition to any such generative model. Consequently, integrating a generator into a score-based diffusion model and training a GAN without a generator naturally emerge from our framework. We empirically test the viability of these original models as proofs of concepts of potential applications of our framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2305.11650</link><description>&lt;p&gt;
&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411;&#65288;EBMs&#65289;&#20026;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;EBMs &#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20173;&#28982;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#29992;&#20110;&#21487;&#25193;&#23637; EBM &#35757;&#32451;&#30340;&#24191;&#27867;&#20351;&#29992;&#30340;&#21435;&#22122;&#20998;&#25968;&#21305;&#37197;&#65288;DSM&#65289;&#26041;&#27861;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#23548;&#33268;&#33021;&#37327;&#27169;&#22411;&#23398;&#20064;&#21040;&#8220;&#22024;&#26434;&#8221;&#30340;&#25968;&#25454;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26694;&#26550;&#65306;&#65288;&#20266;&#65289;Gibbs&#37319;&#26679;&#19982;&#21160;&#37327;&#21305;&#37197;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#32463;&#36807;DSM&#35757;&#32451;&#33391;&#22909;&#30340;&#8220;&#22024;&#26434;&#8221;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#22522;&#30784;&#8220;&#24178;&#20928;&#8221;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#30456;&#20851;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) offer a versatile framework for modeling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a `noisy' data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a `noisy' model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.14496</link><description>&lt;p&gt;
&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning with Explanation Constraints. (arXiv:2303.14496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#37322;&#32422;&#26463;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;EPAC&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#20351;&#29992;&#36825;&#20123;&#35299;&#37322;&#26102;&#27169;&#22411;&#30340;&#30410;&#22788;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#36817;&#20284;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#30417;&#30563;&#23398;&#20064;&#20551;&#35774;&#23384;&#22312;&#26631;&#27880;&#25968;&#25454;&#65292;&#20294;&#25105;&#20204;&#21487;&#33021;&#26377;&#20851;&#20110;&#27169;&#22411;&#24212;&#22914;&#20309;&#36816;&#34892;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#26412;&#25991;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20174;&#35299;&#37322;&#32422;&#26463;&#20013;&#23398;&#20064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#65292;&#20998;&#26512;&#20102;&#36825;&#20123;&#35299;&#37322;&#22914;&#20309;&#25552;&#39640;&#27169;&#22411;&#30340;&#23398;&#20064;&#33021;&#21147;&#12290;&#26412;&#25991;&#30340;&#31532;&#19968;&#39033;&#20851;&#38190;&#36129;&#29486;&#26159;&#36890;&#36807;&#23450;&#20041;&#25105;&#20204;&#31216;&#20043;&#20026;EPAC&#27169;&#22411;&#65288;&#22312;&#26032;&#25968;&#25454;&#26399;&#26395;&#20013;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#30340;&#27169;&#22411;&#65289;&#26469;&#22238;&#31572;&#21738;&#20123;&#27169;&#22411;&#20250;&#21463;&#30410;&#20110;&#35299;&#37322;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#26631;&#20934;&#30340;&#23398;&#20064;&#29702;&#35770;&#24037;&#20855;&#20998;&#26512;&#20102;&#36825;&#31867;&#27169;&#22411;&#12290;&#31532;&#20108;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#23545;&#20110;&#30001;&#32447;&#24615;&#27169;&#22411;&#21644;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#20449;&#24687;&#32473;&#20986;&#30340;&#35268;&#33539;&#35299;&#37322;&#30340;&#38480;&#21046;&#65288;&#20197;&#20854;Rademacher&#22797;&#26434;&#24230;&#20026;&#34913;&#37327;&#26631;&#20934;&#65289;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#21464;&#20998;&#36817;&#20284;&#25552;&#20379;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#24182;&#28385;&#36275;&#36825;&#20123;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
While supervised learning assumes the presence of labeled data, we may have prior information about how models should behave. In this paper, we formalize this notion as learning from explanation constraints and provide a learning theoretic framework to analyze how such explanations can improve the learning of our models. For what models would explanations be helpful? Our first key contribution addresses this question via the definition of what we call EPAC models (models that satisfy these constraints in expectation over new data), and we analyze this class of models using standard learning theoretic tools. Our second key contribution is to characterize these restrictions (in terms of their Rademacher complexities) for a canonical class of explanations given by gradient information for linear models and two layer neural networks. Finally, we provide an algorithmic solution for our framework, via a variational approximation that achieves better performance and satisfies these constraint
&lt;/p&gt;</description></item></channel></rss>