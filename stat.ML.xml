<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#26159;&#21033;&#29992;&#21487;&#36716;&#31227;&#24615;&#23398;&#20064;&#31639;&#27861;&#25913;&#36827;&#36719;&#27979;&#37327;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#26469;&#22686;&#24378;&#36719;&#27979;&#37327;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#22810;&#20010;&#23454;&#29616;&#30340;&#36827;&#31243;&#12290;</title><link>http://arxiv.org/abs/2309.15828</link><description>&lt;p&gt;
&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#20801;&#35768;&#23569;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-unit soft sensing permits few-shot learning. (arXiv:2309.15828v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15828
&lt;/p&gt;
&lt;p&gt;
&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#26159;&#21033;&#29992;&#21487;&#36716;&#31227;&#24615;&#23398;&#20064;&#31639;&#27861;&#25913;&#36827;&#36719;&#27979;&#37327;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#26469;&#22686;&#24378;&#36719;&#27979;&#37327;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#22810;&#20010;&#23454;&#29616;&#30340;&#36827;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#21033;&#29992;&#20855;&#26377;&#21487;&#36716;&#31227;&#24615;&#30340;&#23398;&#20064;&#31639;&#27861;&#26469;&#25913;&#36827;&#36719;&#27979;&#37327;&#30340;&#21508;&#31181;&#26041;&#27861;&#12290;&#24635;&#20307;&#26469;&#35828;&#65292;&#24403;&#19968;&#20010;&#36719;&#27979;&#37327;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#26469;&#23398;&#20064;&#26102;&#65292;&#20854;&#24615;&#33021;&#21487;&#20197;&#24471;&#21040;&#21152;&#24378;&#12290;&#21487;&#36716;&#31227;&#24615;&#30340;&#26377;&#29992;&#24615;&#21462;&#20915;&#20110;&#25152;&#35774;&#35745;&#30340;&#23398;&#20064;&#20219;&#21153;&#30340;&#30456;&#20851;&#24615;&#12290;&#22312;&#36719;&#27979;&#37327;&#35201;&#24212;&#29992;&#20110;&#26377;&#22810;&#20010;&#23454;&#29616;&#30340;&#36827;&#31243;&#65288;&#20363;&#22914;&#65292;&#26377;&#22810;&#20010;&#21487;&#29992;&#25968;&#25454;&#30340;&#31995;&#32479;&#25110;&#35774;&#22791;&#65289;&#26102;&#65292;&#23588;&#20854;&#30456;&#20851;&#12290;&#28982;&#21518;&#65292;&#27599;&#20010;&#23454;&#29616;&#37117;&#25552;&#20379;&#19968;&#20010;&#36719;&#27979;&#37327;&#23398;&#20064;&#20219;&#21153;&#65292;&#24182;&#19988;&#21512;&#29702;&#22320;&#26399;&#26395;&#36825;&#20123;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#20855;&#26377;&#24378;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#24212;&#29992;&#21487;&#36716;&#31227;&#24615;&#23548;&#33268;&#20102;&#25105;&#20204;&#25152;&#31216;&#30340;&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#65292;&#20854;&#20013;&#36719;&#27979;&#37327;&#36890;&#36807;&#20174;&#25152;&#26377;&#23454;&#29616;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#26469;&#24314;&#27169;&#19968;&#20010;&#36827;&#31243;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#30340;&#23398;&#20064;&#33021;&#21147;&#65292;&#23427;&#34987;&#26500;&#24314;&#20026;&#19968;&#20010;&#20998;&#23618;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;...
&lt;/p&gt;
&lt;p&gt;
Recent literature has explored various ways to improve soft sensors using learning algorithms with transferability. Broadly put, the performance of a soft sensor may be strengthened when it is learned by solving multiple tasks. The usefulness of transferability depends on how strongly related the devised learning tasks are. A particularly relevant case for transferability, is when a soft sensor is to be developed for a process of which there are many realizations, e.g. system or device with many implementations from which data is available. Then, each realization presents a soft sensor learning task, and it is reasonable to expect that the different tasks are strongly related. Applying transferability in this setting leads to what we call multi-unit soft sensing, where a soft sensor models a process by learning from data from all of its realizations.  This paper explores the learning abilities of a multi-unit soft sensor, which is formulated as a hierarchical model and implemented usin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#20013;&#30340;&#20844;&#24179;&#24615;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#21270;&#30456;&#20851;&#24615;&#24046;&#24322;&#35823;&#24046;&#26469;&#20943;&#36731;&#19981;&#20844;&#24179;&#29616;&#35937;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;CCA&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#20943;&#23569;&#20102;&#30456;&#20851;&#24615;&#24046;&#24322;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.15809</link><description>&lt;p&gt;
&#20844;&#24179;&#30340;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Fair Canonical Correlation Analysis. (arXiv:2309.15809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#20013;&#30340;&#20844;&#24179;&#24615;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#21270;&#30456;&#20851;&#24615;&#24046;&#24322;&#35823;&#24046;&#26469;&#20943;&#36731;&#19981;&#20844;&#24179;&#29616;&#35937;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;CCA&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#20943;&#23569;&#20102;&#30456;&#20851;&#24615;&#24046;&#24322;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20856;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#20013;&#30340;&#20844;&#24179;&#24615;&#21644;&#20559;&#35265;&#38382;&#39064;&#65292;CCA&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#32479;&#35745;&#25216;&#26415;&#65292;&#29992;&#20110;&#30740;&#31350;&#20004;&#32452;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#19982;&#21463;&#20445;&#25252;&#23646;&#24615;&#30456;&#20851;&#30340;&#30456;&#20851;&#24615;&#24046;&#24322;&#35823;&#24046;&#65292;&#26469;&#20943;&#36731;&#19981;&#20844;&#24179;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;CCA&#33021;&#22815;&#20174;&#25152;&#26377;&#25968;&#25454;&#28857;&#20013;&#23398;&#20064;&#21040;&#20840;&#23616;&#25237;&#24433;&#30697;&#38453;&#65292;&#21516;&#26102;&#30830;&#20445;&#36825;&#20123;&#30697;&#38453;&#20135;&#29983;&#19982;&#32452;&#29305;&#23450;&#25237;&#24433;&#30697;&#38453;&#30456;&#24403;&#30340;&#30456;&#20851;&#24615;&#27700;&#24179;&#12290;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20943;&#23569;&#30456;&#20851;&#24615;&#24046;&#24322;&#35823;&#24046;&#30340;&#21516;&#26102;&#19981;&#20250;&#24433;&#21709;CCA&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates fairness and bias in Canonical Correlation Analysis (CCA), a widely used statistical technique for examining the relationship between two sets of variables. We present a framework that alleviates unfairness by minimizing the correlation disparity error associated with protected attributes. Our approach enables CCA to learn global projection matrices from all data points while ensuring that these matrices yield comparable correlation levels to group-specific projection matrices. Experimental evaluation on both synthetic and real-world datasets demonstrates the efficacy of our method in reducing correlation disparity error without compromising CCA accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20462;&#25913;&#22240;&#26524;&#26862;&#26519;&#26041;&#27861;&#65292;&#20197;&#30456;&#23545;&#39118;&#38505;&#20026;&#30446;&#26631;&#65292;&#20174;&#32780;&#25429;&#25417;&#21040;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#28508;&#22312;&#26469;&#28304;&#12290;</title><link>http://arxiv.org/abs/2309.15793</link><description>&lt;p&gt;
&#29992;&#22240;&#26524;&#26862;&#26519;&#38024;&#23545;&#30456;&#23545;&#39118;&#38505;&#24322;&#36136;&#24615;&#36827;&#34892;&#30446;&#26631;&#21270;
&lt;/p&gt;
&lt;p&gt;
Targeting Relative Risk Heterogeneity with Causal Forests. (arXiv:2309.15793v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20462;&#25913;&#22240;&#26524;&#26862;&#26519;&#26041;&#27861;&#65292;&#20197;&#30456;&#23545;&#39118;&#38505;&#20026;&#30446;&#26631;&#65292;&#20174;&#32780;&#25429;&#25417;&#21040;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#28508;&#22312;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20020;&#24202;&#35797;&#39564;&#20998;&#26512;&#20013;&#65292;&#27835;&#30103;&#25928;&#24212;&#24322;&#36136;&#24615;&#65288;TEH&#65289;&#21363;&#31181;&#32676;&#20013;&#19981;&#21516;&#20122;&#32676;&#30340;&#27835;&#30103;&#25928;&#24212;&#30340;&#21464;&#24322;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#22240;&#26524;&#26862;&#26519;&#65288;Wager&#21644;Athey&#65292;2018&#65289;&#26159;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#38750;&#24120;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#20294;&#20687;&#35768;&#22810;&#20854;&#20182;&#21457;&#29616;TEH&#30340;&#26041;&#27861;&#19968;&#26679;&#65292;&#23427;&#29992;&#20110;&#20998;&#31163;&#20122;&#32676;&#30340;&#26631;&#20934;&#20391;&#37325;&#20110;&#32477;&#23545;&#39118;&#38505;&#30340;&#24046;&#24322;&#12290;&#36825;&#21487;&#33021;&#20250;&#21066;&#24369;&#32479;&#35745;&#21151;&#25928;&#65292;&#25513;&#30422;&#20102;&#30456;&#23545;&#39118;&#38505;&#20013;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#32780;&#30456;&#23545;&#39118;&#38505;&#36890;&#24120;&#26159;&#20020;&#24202;&#20851;&#27880;&#30340;&#26356;&#21512;&#36866;&#30340;&#25968;&#37327;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#23454;&#29616;&#20102;&#19968;&#31181;&#20462;&#25913;&#22240;&#26524;&#26862;&#26519;&#20197;&#38024;&#23545;&#30456;&#23545;&#39118;&#38505;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#22522;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#27604;&#36739;&#30340;&#26032;&#39062;&#33410;&#28857;&#20998;&#21106;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#32467;&#26524;&#65292;&#34920;&#26126;&#30456;&#23545;&#39118;&#38505;&#30340;&#22240;&#26524;&#26862;&#26519;&#21487;&#20197;&#25429;&#25417;&#21040;&#20854;&#20182;&#26410;&#35266;&#23519;&#21040;&#30340;&#24322;&#36136;&#24615;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Treatment effect heterogeneity (TEH), or variability in treatment effect for different subgroups within a population, is of significant interest in clinical trial analysis. Causal forests (Wager and Athey, 2018) is a highly popular method for this problem, but like many other methods for detecting TEH, its criterion for separating subgroups focuses on differences in absolute risk. This can dilute statistical power by masking nuance in the relative risk, which is often a more appropriate quantity of clinical interest. In this work, we propose and implement a methodology for modifying causal forests to target relative risk using a novel node-splitting procedure based on generalized linear model (GLM) comparison. We present results on simulated and real-world data that suggest relative risk causal forests can capture otherwise unobserved sources of heterogeneity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#8220;&#38544;&#24335;&#25506;&#32034;&#8221;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#31574;&#30053;&#20215;&#20540;&#30340;&#26435;&#37325;&#37325;&#35201;&#20272;&#35745;&#12290;&#19982;&#20043;&#21069;&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#22312;&#20960;&#20046;&#25152;&#26377;&#24773;&#20917;&#19979;&#37117;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;&#20043;&#21069;&#25152;&#20570;&#30340;&#38750;&#24120;&#33499;&#21051;&#30340;&#8220;&#22343;&#21248;&#35206;&#30422;&#8221;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2309.15771</link><description>&lt;p&gt;
&#26435;&#37325;&#37325;&#35201;&#30340;&#31163;&#32447;&#23398;&#20064;&#27491;&#30830;&#22320;&#23436;&#25104;
&lt;/p&gt;
&lt;p&gt;
Importance-Weighted Offline Learning Done Right. (arXiv:2309.15771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#8220;&#38544;&#24335;&#25506;&#32034;&#8221;&#20272;&#35745;&#22120;&#26469;&#35745;&#31639;&#31574;&#30053;&#20215;&#20540;&#30340;&#26435;&#37325;&#37325;&#35201;&#20272;&#35745;&#12290;&#19982;&#20043;&#21069;&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#22312;&#20960;&#20046;&#25152;&#26377;&#24773;&#20917;&#19979;&#37117;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#21516;&#26102;&#28040;&#38500;&#20102;&#20043;&#21069;&#25152;&#20570;&#30340;&#38750;&#24120;&#33499;&#21051;&#30340;&#8220;&#22343;&#21248;&#35206;&#30422;&#8221;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#22522;&#20110;&#30001;&#27425;&#20248;&#34892;&#20026;&#31574;&#30053;&#25910;&#38598;&#30340;&#20915;&#31574;&#25968;&#25454;&#38598;&#23398;&#20064;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#19981;&#23545;&#22870;&#21169;&#20989;&#25968;&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#65292;&#32780;&#26159;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#32473;&#23450;&#30340;&#31574;&#30053;&#31867;&#65292;&#24182;&#19988;&#26088;&#22312;&#19982;&#35813;&#31867;&#20013;&#30340;&#26368;&#20339;&#27604;&#36739;&#22120;&#31574;&#30053;&#31454;&#20105;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#26041;&#27861;&#26159;&#35745;&#31639;&#27599;&#20010;&#31574;&#30053;&#20215;&#20540;&#30340;&#26435;&#37325;&#37325;&#35201;&#20272;&#35745;&#65292;&#24182;&#36873;&#25321;&#19968;&#20010;&#26368;&#23567;&#21270;&#20272;&#35745;&#20540;&#30340;&#31574;&#30053;&#65292;&#20943;&#21435;&#20272;&#35745;&#20540;&#20013;&#30340;&#8220;&#24754;&#35266;&#8221;&#35843;&#25972;&#20197;&#20943;&#23569;&#20854;&#38543;&#26426;&#27874;&#21160;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#22522;&#20110; \citet{Neu2015} &#30340;&#8220;&#38544;&#24335;&#25506;&#32034;&#8221;&#20272;&#35745;&#22120;&#30340;&#31616;&#21333;&#26367;&#20195;&#26041;&#27861;&#65292;&#20854;&#24615;&#33021;&#20445;&#35777;&#22312;&#20960;&#20046;&#25152;&#26377;&#21487;&#33021;&#30340;&#24773;&#20917;&#19979;&#37117;&#20248;&#20110;&#20043;&#21069;&#30340;&#32467;&#26524;&#12290;&#23588;&#20854;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#28040;&#38500;&#20102;&#20043;&#21069;&#25152;&#26377;&#24037;&#20316;&#20013;&#38750;&#24120;&#33499;&#21051;&#30340;&#8220;&#22343;&#21248;&#35206;&#30422;&#8221;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of offline policy optimization in stochastic contextual bandit problems, where the goal is to learn a near-optimal policy based on a dataset of decision data collected by a suboptimal behavior policy. Rather than making any structural assumptions on the reward function, we assume access to a given policy class and aim to compete with the best comparator policy within this class. In this setting, a standard approach is to compute importance-weighted estimators of the value of each policy, and select a policy that minimizes the estimated value up to a "pessimistic" adjustment subtracted from the estimates to reduce their random fluctuations. In this paper, we show that a simple alternative approach based on the "implicit exploration" estimator of \citet{Neu2015} yields performance guarantees that are superior in nearly all possible terms to all previous results. Most notably, we remove an extremely restrictive "uniform coverage" assumption made in all previous works.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#29109;&#21305;&#37197;&#26694;&#26550;&#30340;&#26032;&#30340;&#21487;&#22788;&#29702;&#30340;&#25512;&#26029;&#26041;&#26696;&#65292;&#21487;&#20197;&#23884;&#20837;&#21040;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#20013;&#65292;&#23545;&#20110;&#25551;&#36848;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#36807;&#31243;&#30340;Markov&#36339;&#36291;&#36807;&#31243;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#31867;&#36817;&#20284;&#20998;&#24067;&#30340;&#38381;&#24335;&#32467;&#26524;&#20197;&#21450;&#24212;&#29992;&#20110;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#30340;&#19968;&#33324;&#31867;&#21035;&#26469;&#21152;&#20197;&#35770;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#36817;&#20284;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31243;&#24207;&#23548;&#20986;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#28857;&#20272;&#35745;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#22312;&#21508;&#31181;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#31034;&#20363;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.15604</link><description>&lt;p&gt;
Entropic Matching&#29992;&#20110;Markov&#36339;&#36291;&#36807;&#31243;&#30340;&#26399;&#26395;&#20256;&#25773;&#30340;&#29109;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Entropic Matching for Expectation Propagation of Markov Jump Processes. (arXiv:2309.15604v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15604
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#29109;&#21305;&#37197;&#26694;&#26550;&#30340;&#26032;&#30340;&#21487;&#22788;&#29702;&#30340;&#25512;&#26029;&#26041;&#26696;&#65292;&#21487;&#20197;&#23884;&#20837;&#21040;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#20013;&#65292;&#23545;&#20110;&#25551;&#36848;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#36807;&#31243;&#30340;Markov&#36339;&#36291;&#36807;&#31243;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#31867;&#36817;&#20284;&#20998;&#24067;&#30340;&#38381;&#24335;&#32467;&#26524;&#20197;&#21450;&#24212;&#29992;&#20110;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#30340;&#19968;&#33324;&#31867;&#21035;&#26469;&#21152;&#20197;&#35770;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#36817;&#20284;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31243;&#24207;&#23548;&#20986;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#28857;&#20272;&#35745;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#22312;&#21508;&#31181;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#31034;&#20363;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#35813;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#28508;&#22312;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#36807;&#31243;&#30340;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#36890;&#24120;&#38590;&#20197;&#22788;&#29702;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#30001;Markov&#36339;&#36291;&#36807;&#31243;&#25551;&#36848;&#30340;&#31163;&#25955;&#29366;&#24577;&#31354;&#38388;&#36807;&#31243;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#22788;&#29702;&#30340;&#25512;&#26029;&#26041;&#26696;&#65292;&#22522;&#20110;&#29109;&#21305;&#37197;&#26694;&#26550;&#65292;&#21487;&#20197;&#23884;&#20837;&#21040;&#20247;&#25152;&#21608;&#30693;&#30340;&#26399;&#26395;&#20256;&#25773;&#31639;&#27861;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#19968;&#31867;&#31616;&#21333;&#30340;&#36817;&#20284;&#20998;&#24067;&#25552;&#20379;&#38381;&#24335;&#32467;&#26524;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#30340;&#19968;&#33324;&#31867;&#21035;&#65292;&#35813;&#31867;&#21035;&#26159;&#31995;&#32479;&#29983;&#29289;&#23398;&#24314;&#27169;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#36817;&#20284;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31243;&#24207;&#23548;&#20986;&#20102;&#28508;&#22312;&#21442;&#25968;&#30340;&#28857;&#20272;&#35745;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#21508;&#31181;&#21270;&#23398;&#21453;&#24212;&#32593;&#32476;&#31034;&#20363;&#20013;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#38543;&#26426;&#30340;Lotka-Voltera&#31034;&#20363;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#30340;&#23616;&#38480;&#24615;&#21644;&#26410;&#26469;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the problem of statistical inference for latent continuous-time stochastic processes, which is often intractable, particularly for discrete state space processes described by Markov jump processes. To overcome this issue, we propose a new tractable inference scheme based on an entropic matching framework that can be embedded into the well-known expectation propagation algorithm. We demonstrate the effectiveness of our method by providing closed-form results for a simple family of approximate distributions and apply it to the general class of chemical reaction networks, which are a crucial tool for modeling in systems biology. Moreover, we derive closed form expressions for point estimation of the underlying parameters using an approximate expectation maximization procedure. We evaluate the performance of our method on various chemical reaction network instantiations, including a stochastic Lotka-Voltera example, and discuss its limitations and potential for future 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#39044;&#27979;&#20219;&#24847;&#36755;&#20837;&#22270;&#20687;&#21518;&#39564;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2309.15533</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#21518;&#39564;&#20027;&#25104;&#20998;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification via Neural Posterior Principal Components. (arXiv:2309.15533v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15533
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#22312;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#39044;&#27979;&#20219;&#24847;&#36755;&#20837;&#22270;&#20687;&#21518;&#39564;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#23545;&#20110;&#22312;&#33258;&#21160;&#39550;&#39542;&#21644;&#29983;&#29289;&#25104;&#20687;&#31561;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#20013;&#37096;&#32626;&#22270;&#20687;&#24674;&#22797;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#20851;&#20110;&#19981;&#30830;&#23450;&#24615;&#21487;&#35270;&#21270;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#27599;&#20687;&#32032;&#20272;&#35745;&#19978;&#12290;&#28982;&#32780;&#65292;&#27599;&#20687;&#32032;&#26041;&#24046;&#30340;&#28909;&#22270;&#36890;&#24120;&#22312;&#23454;&#38469;&#20013;&#29992;&#36884;&#26377;&#38480;&#65292;&#22240;&#20026;&#23427;&#26080;&#27861;&#25429;&#25417;&#20687;&#32032;&#20043;&#38388;&#30340;&#24378;&#30456;&#20851;&#24615;&#12290;&#26356;&#33258;&#28982;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#23545;&#24212;&#20110;&#21518;&#39564;&#20998;&#24067;&#30340;&#20027;&#25104;&#20998;&#65288;PCs&#65289;&#19978;&#30340;&#26041;&#24046;&#12290;&#29702;&#35770;&#19978;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#36755;&#20837;&#22270;&#20687;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#24212;&#29992;PCA&#26469;&#35745;&#31639;PCs&#12290;&#28982;&#32780;&#65292;&#36825;&#38656;&#35201;&#22312;&#27979;&#35797;&#26102;&#29983;&#25104;&#22823;&#37327;&#30340;&#26679;&#26412;&#65292;&#32780;&#22312;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#65288;&#25193;&#25955;&#65289;&#27169;&#22411;&#19979;&#38750;&#24120;&#32531;&#24930;&#12290;&#22312;&#35813;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#21333;&#27425;&#21069;&#21521;&#20256;&#36882;&#20013;&#39044;&#27979;&#21518;&#39564;&#20998;&#24067;&#30340;PCs&#65292;&#36866;&#29992;&#20110;&#20219;&#24847;&#36755;&#20837;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification is crucial for the deployment of image restoration models in safety-critical domains, like autonomous driving and biological imaging. To date, methods for uncertainty visualization have mainly focused on per-pixel estimates. However, a heatmap of per-pixel variances is typically of little practical use, as it does not capture the strong correlations between pixels. A more natural measure of uncertainty corresponds to the variances along the principal components (PCs) of the posterior distribution. Theoretically, the PCs can be computed by applying PCA on samples generated from a conditional generative model for the input image. However, this requires generating a very large number of samples at test time, which is painfully slow with the current state-of-the-art (diffusion) models. In this work, we present a method for predicting the PCs of the posterior distribution for any input image, in a single forward pass of a neural network. Our method can either wrap
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#30417;&#27979;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22312;&#32447;&#26816;&#27979;&#26041;&#26696;&#65292;&#36890;&#36807;&#32771;&#34385;&#27169;&#22411;&#36136;&#37327;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#65292;&#21487;&#20197;&#20943;&#23569;&#19981;&#24517;&#35201;&#30340;&#35686;&#25253;&#24182;&#20248;&#21270;&#23545;&#30456;&#20851;&#21464;&#21270;&#30340;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2309.15187</link><description>&lt;p&gt;
&#30417;&#27979;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65306;&#22312;&#32447;&#26816;&#27979;&#30456;&#20851;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Monitoring Machine Learning Models: Online Detection of Relevant Deviations. (arXiv:2309.15187v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#30417;&#27979;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22312;&#32447;&#26816;&#27979;&#26041;&#26696;&#65292;&#36890;&#36807;&#32771;&#34385;&#27169;&#22411;&#36136;&#37327;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#65292;&#21487;&#20197;&#20943;&#23569;&#19981;&#24517;&#35201;&#30340;&#35686;&#25253;&#24182;&#20248;&#21270;&#23545;&#30456;&#20851;&#21464;&#21270;&#30340;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#21508;&#20010;&#39046;&#22495;&#20013;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#20294;&#20854;&#24615;&#33021;&#21487;&#33021;&#20250;&#38543;&#26102;&#38388;&#30340;&#25512;&#31227;&#32780;&#38477;&#20302;&#65292;&#21407;&#22240;&#26159;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#25110;&#20854;&#20182;&#22240;&#32032;&#12290;&#19968;&#26041;&#38754;&#65292;&#26816;&#27979;&#21644;&#35299;&#20915;&#36825;&#31181;&#38477;&#32423;&#23545;&#20110;&#20445;&#25345;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#32473;&#23450;&#36275;&#22815;&#30340;&#25968;&#25454;&#65292;&#21487;&#20197;&#26816;&#27979;&#21040;&#20219;&#24847;&#23567;&#30340;&#36136;&#37327;&#21464;&#21270;&#12290;&#30001;&#20110;&#27169;&#22411;&#37325;&#26032;&#35757;&#32451;&#25110;&#26367;&#25442;&#31561;&#24178;&#39044;&#25514;&#26045;&#21487;&#33021;&#20195;&#20215;&#39640;&#26114;&#65292;&#25105;&#20204;&#35748;&#20026;&#20165;&#24403;&#21464;&#21270;&#36229;&#36807;&#32473;&#23450;&#38408;&#20540;&#26102;&#25165;&#24212;&#35813;&#36827;&#34892;&#36825;&#20123;&#24178;&#39044;&#25514;&#26045;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#30417;&#27979;&#26041;&#26696;&#26469;&#26816;&#27979;&#36825;&#20123;&#30456;&#20851;&#21464;&#21270;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#36890;&#36807;&#32771;&#34385;&#25152;&#27979;&#37327;&#27169;&#22411;&#36136;&#37327;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#26469;&#20943;&#23569;&#19981;&#24517;&#35201;&#30340;&#35686;&#25253;&#24182;&#20811;&#26381;&#22810;&#37325;&#27979;&#35797;&#38382;&#39064;&#12290;&#25991;&#20013;&#25552;&#20379;&#20102;&#19968;&#33268;&#24615;&#21644;&#25351;&#23450;&#28176;&#36817;&#27700;&#24179;&#30340;&#26465;&#20214;&#12290;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#30340;&#23454;&#35777;&#39564;&#35777;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#27169;&#22411;&#36136;&#37327;&#30456;&#20851;&#21464;&#21270;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#65292;&#30456;&#27604;&#22522;&#20934;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are essential tools in various domains, but their performance can degrade over time due to changes in data distribution or other factors. On one hand, detecting and addressing such degradations is crucial for maintaining the models' reliability. On the other hand, given enough data, any arbitrary small change of quality can be detected. As interventions, such as model re-training or replacement, can be expensive, we argue that they should only be carried out when changes exceed a given threshold. We propose a sequential monitoring scheme to detect these relevant changes. The proposed method reduces unnecessary alerts and overcomes the multiple testing problem by accounting for temporal dependence of the measured model quality. Conditions for consistency and specified asymptotic levels are provided. Empirical validation using simulated and real data demonstrates the superiority of our approach in detecting relevant changes in model quality compared to benchmark m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#38543;&#26426;&#20248;&#21270;&#30340;&#38646;&#38454;&#40654;&#26364;&#24179;&#22343;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65288;Zo-RASA&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#40654;&#26364;&#31227;&#21160;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#22120;&#21644;&#26032;&#39062;&#30340;&#40654;&#26364;-&#26446;&#38597;&#26222;&#35834;&#22827;&#20998;&#26512;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#29983;&#25104;&#949;-&#36817;&#20284;&#30340;&#19968;&#38454;&#31283;&#23450;&#35299;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#36890;&#36807;&#20351;&#29992;&#22238;&#32553;&#21644;&#21521;&#37327;&#20256;&#36755;&#26367;&#20195;&#25351;&#25968;&#26144;&#23556;&#21644;&#24179;&#34892;&#20256;&#36755;&#38477;&#20302;&#20102;&#31639;&#27861;&#30340;&#27599;&#27425;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.14506</link><description>&lt;p&gt;
&#38646;&#38454;&#40654;&#26364;&#24179;&#22343;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Zeroth-order Riemannian Averaging Stochastic Approximation Algorithms. (arXiv:2309.14506v1 [math.OC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14506
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#38543;&#26426;&#20248;&#21270;&#30340;&#38646;&#38454;&#40654;&#26364;&#24179;&#22343;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65288;Zo-RASA&#65289;&#65292;&#36890;&#36807;&#20351;&#29992;&#40654;&#26364;&#31227;&#21160;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#22120;&#21644;&#26032;&#39062;&#30340;&#40654;&#26364;-&#26446;&#38597;&#26222;&#35834;&#22827;&#20998;&#26512;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#29983;&#25104;&#949;-&#36817;&#20284;&#30340;&#19968;&#38454;&#31283;&#23450;&#35299;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#36890;&#36807;&#20351;&#29992;&#22238;&#32553;&#21644;&#21521;&#37327;&#20256;&#36755;&#26367;&#20195;&#25351;&#25968;&#26144;&#23556;&#21644;&#24179;&#34892;&#20256;&#36755;&#38477;&#20302;&#20102;&#31639;&#27861;&#30340;&#27599;&#27425;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#38543;&#26426;&#20248;&#21270;&#30340;&#38646;&#38454;&#40654;&#26364;&#24179;&#22343;&#38543;&#26426;&#36924;&#36817;&#65288;Zo-RASA&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;Zo-RASA&#20165;&#20351;&#29992;&#27599;&#27425;&#36845;&#20195;&#20013;&#30340;&#19968;&#20010;&#26679;&#26412;&#25110;&#24120;&#25968;&#38454;&#30340;&#25209;&#22788;&#29702;&#23601;&#33021;&#23454;&#29616;&#29983;&#25104;&#949;-&#36817;&#20284;&#30340;&#19968;&#38454;&#31283;&#23450;&#35299;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#37319;&#29992;&#20102;&#40654;&#26364;&#31227;&#21160;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#24182;&#21033;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#40654;&#26364;-&#26446;&#38597;&#26222;&#35834;&#22827;&#20998;&#26512;&#25216;&#26415;&#36827;&#34892;&#25910;&#25947;&#20998;&#26512;&#12290;&#36890;&#36807;&#20351;&#29992;&#22238;&#32553;&#21644;&#21521;&#37327;&#20256;&#36755;&#20195;&#26367;&#25351;&#25968;&#26144;&#23556;&#21644;&#24179;&#34892;&#20256;&#36755;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#31639;&#27861;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#38477;&#20302;&#20102;&#27599;&#27425;&#36845;&#20195;&#30340;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20960;&#20309;&#26465;&#20214;&#65292;&#28385;&#36275;&#26377;&#26377;&#30028;&#31532;&#20108;&#22522;&#26412;&#24418;&#24335;&#30340;&#27969;&#24418;&#65292;&#20174;&#32780;&#20026;&#29992;&#21521;&#37327;&#20256;&#36755;&#36924;&#36817;&#24179;&#34892;&#20256;&#36755;&#25552;&#20379;&#26032;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Zeroth-order Riemannian Averaging Stochastic Approximation (\texttt{Zo-RASA}) algorithms for stochastic optimization on Riemannian manifolds. We show that \texttt{Zo-RASA} achieves optimal sample complexities for generating $\epsilon$-approximation first-order stationary solutions using only one-sample or constant-order batches in each iteration. Our approach employs Riemannian moving-average stochastic gradient estimators, and a novel Riemannian-Lyapunov analysis technique for convergence analysis. We improve the algorithm's practicality by using retractions and vector transport, instead of exponential mappings and parallel transports, thereby reducing per-iteration complexity. Additionally, we introduce a novel geometric condition, satisfied by manifolds with bounded second fundamental form, which enables new error bounds for approximating parallel transport with vector transport.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#38543;&#26426;&#32447;&#24615;Bandit&#31639;&#27861;&#65292;&#21033;&#29992;&#38797;&#28857;&#36793;&#30028;&#30340;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#38543;&#26426;Bandit&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#33021;&#22815;&#20197;&#31454;&#20105;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#20445;&#35777;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.14298</link><description>&lt;p&gt;
&#20351;&#29992;&#38797;&#28857;&#36793;&#30028;&#30340;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#25913;&#36827;&#38543;&#26426;&#32447;&#24615;Bandit&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures. (arXiv:2309.14298v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#38543;&#26426;&#32447;&#24615;Bandit&#31639;&#27861;&#65292;&#21033;&#29992;&#38797;&#28857;&#36793;&#30028;&#30340;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#38543;&#26426;Bandit&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#35813;&#31639;&#27861;&#33021;&#22815;&#20197;&#31454;&#20105;&#24615;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#20445;&#35777;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#38543;&#26426;&#32447;&#24615;Bandit&#38382;&#39064;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#20445;&#35777;&#30340;&#25913;&#36827;&#31639;&#27861;&#12290;&#24191;&#27867;&#20351;&#29992;&#30340;"&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#30340;&#20048;&#35266;&#21407;&#21017;"&#21487;&#20197;&#23558;&#38543;&#26426;Bandit&#38382;&#39064;&#36716;&#21270;&#20026;&#23545;&#26410;&#30693;&#22870;&#21169;&#20989;&#25968;&#26500;&#24314;&#32622;&#20449;&#24207;&#21015;&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#31639;&#27861;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#32622;&#20449;&#24207;&#21015;&#30340;&#22823;&#23567;&#65292;&#32622;&#20449;&#38598;&#36739;&#23567;&#21487;&#25552;&#20379;&#26356;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#21644;&#26356;&#24378;&#30340;&#36951;&#25022;&#20445;&#35777;&#12290;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#23545;&#33258;&#36866;&#24212;&#39532;&#19969;&#26684;&#23572;&#28151;&#21512;&#30340;&#23614;&#37096;&#36793;&#30028;&#26469;&#26500;&#24314;&#36866;&#29992;&#20110;&#38543;&#26426;Bandit&#30340;&#32622;&#20449;&#24207;&#21015;&#12290;&#36825;&#20123;&#32622;&#20449;&#24207;&#21015;&#20801;&#35768;&#36890;&#36807;&#20984;&#35268;&#21010;&#36827;&#34892;&#39640;&#25928;&#30340;&#21160;&#20316;&#36873;&#25321;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#25105;&#20204;&#30340;&#32622;&#20449;&#24207;&#21015;&#30340;&#32447;&#24615;Bandit&#31639;&#27861;&#33021;&#22815;&#20445;&#35777;&#36798;&#21040;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#36951;&#25022;&#12290;&#25105;&#20204;&#23454;&#35777;&#21644;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32622;&#20449;&#24207;&#21015;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#32039;&#33268;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32039;&#33268;&#32622;&#20449;&#24207;&#21015;&#21487;&#20197;&#25552;&#20379;&#21644;&#32622;&#20449;&#38598;&#27604;&#36739;&#23481;&#26131;&#37197;&#32622;&#30340;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present improved algorithms with worst-case regret guarantees for the stochastic linear bandit problem. The widely used "optimism in the face of uncertainty" principle reduces a stochastic bandit problem to the construction of a confidence sequence for the unknown reward function. The performance of the resulting bandit algorithm depends on the size of the confidence sequence, with smaller confidence sets yielding better empirical performance and stronger regret guarantees. In this work, we use a novel tail bound for adaptive martingale mixtures to construct confidence sequences which are suitable for stochastic bandits. These confidence sequences allow for efficient action selection via convex programming. We prove that a linear bandit algorithm based on our confidence sequences is guaranteed to achieve competitive worst-case regret. We show that our confidence sequences are tighter than competitors, both empirically and theoretically. Finally, we demonstrate that our tighter confi
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.13775</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;The Rashomon Importance Distribution: &#25670;&#33073;&#19981;&#31283;&#23450;&#30340;&#22522;&#20110;&#21333;&#19968;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance. (arXiv:2309.13775v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13775
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#23545;&#20110;&#22238;&#31572;&#36951;&#20256;&#23398;&#12289;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#23398;&#31561;&#39046;&#22495;&#30340;&#37325;&#22823;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#35745;&#31639;&#32473;&#23450;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#32473;&#23450;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#38598;&#65292;&#21487;&#33021;&#26377;&#35768;&#22810;&#27169;&#22411;&#21516;&#26679;&#33021;&#35299;&#37322;&#30446;&#26631;&#32467;&#26524;;&#22914;&#26524;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#35299;&#37322;&#65292;&#19981;&#21516;&#30340;&#30740;&#31350;&#32773;&#21487;&#33021;&#20250;&#24471;&#20986;&#35768;&#22810;&#20914;&#31361;&#20294;&#21516;&#26679;&#26377;&#25928;&#30340;&#32467;&#35770;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#32771;&#34385;&#20102;&#32473;&#23450;&#25968;&#25454;&#38598;&#30340;&#25152;&#26377;&#21487;&#33021;&#35299;&#37322;&#65292;&#36825;&#20123;&#27934;&#23519;&#21147;&#21487;&#33021;&#19981;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#22240;&#20026;&#24182;&#38750;&#25152;&#26377;&#22909;&#30340;&#35299;&#37322;&#22312;&#21512;&#29702;&#30340;&#25968;&#25454;&#25200;&#21160;&#19979;&#37117;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#37327;&#21270;&#20102;&#22312;&#25152;&#26377;&#22909;&#30340;&#27169;&#22411;&#38598;&#21512;&#20013;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#38750;&#24120;&#28789;&#27963;&#65292;&#21487;&#20197;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22534;&#21472;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#24182;&#21463;&#38750;&#36127;&#24615;&#32422;&#26463;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;&#35823;&#24046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22534;&#21472;&#20272;&#35745;&#22120;&#30456;&#27604;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#23567;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2309.09880</link><description>&lt;p&gt;
&#30001;&#22534;&#21472;&#22238;&#24402;&#20943;&#23569;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Error Reduction from Stacked Regressions. (arXiv:2309.09880v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09880
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22534;&#21472;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#24635;&#20307;&#39118;&#38505;&#24182;&#21463;&#38750;&#36127;&#24615;&#32422;&#26463;&#65292;&#25104;&#21151;&#38477;&#20302;&#20102;&#35823;&#24046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22534;&#21472;&#20272;&#35745;&#22120;&#30456;&#27604;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#23567;&#30340;&#24635;&#20307;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22534;&#21472;&#22238;&#24402;&#26159;&#19968;&#31181;&#38598;&#25104;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#24418;&#25104;&#19981;&#21516;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#20132;&#21449;&#39564;&#35777;&#25968;&#25454;&#26469;&#29983;&#25104;&#30001;&#26500;&#25104;&#20272;&#35745;&#22120;&#39044;&#27979;&#65292;&#24182;&#20351;&#29992;&#24102;&#38750;&#36127;&#24615;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#27861;&#23398;&#20064;&#32452;&#21512;&#26435;&#37325;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#31867;&#20284;&#22320;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#31181;&#20272;&#35745;&#30340;&#24635;&#20307;&#39118;&#38505;&#26469;&#23398;&#20064;&#36825;&#20123;&#26435;&#37325;&#65292;&#24182;&#21463;&#21040;&#38750;&#36127;&#24615;&#32422;&#26463;&#12290;&#24403;&#26500;&#25104;&#30340;&#20272;&#35745;&#22120;&#26159;&#36890;&#36807;&#33267;&#23569;&#19977;&#20010;&#32500;&#24230;&#20998;&#38548;&#30340;&#23884;&#22871;&#23376;&#31354;&#38388;&#30340;&#32447;&#24615;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#30001;&#20110;&#25910;&#32553;&#25928;&#24212;&#65292;&#25152;&#24471;&#21040;&#30340;&#22534;&#21472;&#20272;&#35745;&#22120;&#30340;&#24635;&#20307;&#39118;&#38505;&#20005;&#26684;&#23567;&#20110;&#20854;&#20013;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#12290;&#36825;&#37324;&#30340;&#8220;&#26368;&#20339;&#8221;&#26159;&#25351;&#26368;&#23567;&#21270;&#36873;&#25321;&#20934;&#21017;&#22914;AIC&#25110;BIC&#30340;&#27169;&#22411;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#30340;&#21333;&#20010;&#20272;&#35745;&#22120;&#26159;&#19981;&#21487;&#25509;&#21463;&#30340;&#12290;&#22240;&#20026;&#20248;&#21270;&#38382;&#39064;&#21487;&#20197;&#37325;&#26500;&#20026;&#21516;&#20449;&#24687;&#22238;&#24402;&#65292;&#25152;&#20197;...
&lt;/p&gt;
&lt;p&gt;
Stacking regressions is an ensemble technique that forms linear combinations of different regression estimators to enhance predictive accuracy. The conventional approach uses cross-validation data to generate predictions from the constituent estimators, and least-squares with nonnegativity constraints to learn the combination weights. In this paper, we learn these weights analogously by minimizing an estimate of the population risk subject to a nonnegativity constraint. When the constituent estimators are linear least-squares projections onto nested subspaces separated by at least three dimensions, we show that thanks to a shrinkage effect, the resulting stacked estimator has strictly smaller population risk than best single estimator among them. Here ``best'' refers to a model that minimizes a selection criterion such as AIC or BIC. In other words, in this setting, the best single estimator is inadmissible. Because the optimization problem can be reformulated as isotonic regression, t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.07261</link><description>&lt;p&gt;
&#20855;&#26377;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#21516;&#26102;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simultaneous inference for generalized linear models with unmeasured confounders. (arXiv:2309.07261v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#21644;&#32447;&#24615;&#25237;&#24433;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#24341;&#36215;&#30340;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#30740;&#31350;&#20013;&#65292;&#24120;&#24120;&#36827;&#34892;&#25104;&#21315;&#19978;&#19975;&#20010;&#21516;&#26102;&#20551;&#35774;&#26816;&#39564;&#65292;&#20197;&#30830;&#23450;&#24046;&#24322;&#34920;&#36798;&#30340;&#22522;&#22240;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23384;&#22312;&#26410;&#27979;&#28151;&#28102;&#22240;&#32032;&#65292;&#35768;&#22810;&#26631;&#20934;&#32479;&#35745;&#26041;&#27861;&#21487;&#33021;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23384;&#22312;&#28151;&#28102;&#25928;&#24212;&#26102;&#30340;&#22810;&#20803;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;&#22823;&#35268;&#27169;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#12290;&#22312;&#20219;&#24847;&#28151;&#28102;&#26426;&#21046;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32479;&#35745;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#27861;&#65292;&#21033;&#29992;&#27491;&#20132;&#32467;&#26500;&#24182;&#23558;&#32447;&#24615;&#25237;&#24433;&#25972;&#21512;&#21040;&#19977;&#20010;&#20851;&#38190;&#38454;&#27573;&#20013;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#22810;&#20803;&#21709;&#24212;&#21464;&#37327;&#20998;&#31163;&#36793;&#38469;&#21644;&#19981;&#30456;&#20851;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#24674;&#22797;&#28151;&#28102;&#31995;&#25968;&#30340;&#21015;&#31354;&#38388;&#12290;&#38543;&#21518;&#65292;&#21033;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#24615;&#20272;&#35745;&#65292;&#24182;&#24378;&#21152;&#27491;&#20132;&#24615;&#38480;&#21046;&#20110;&#28151;&#28102;&#31995;&#25968;&#65292;&#32852;&#21512;&#20272;&#35745;&#28508;&#22312;&#22240;&#23376;&#21644;&#20027;&#35201;&#25928;&#24212;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32467;&#21512;&#25237;&#24433;&#21644;&#21152;&#26435;&#20559;&#24046;&#26657;&#27491;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tens of thousands of simultaneous hypothesis tests are routinely performed in genomic studies to identify differentially expressed genes. However, due to unmeasured confounders, many standard statistical approaches may be substantially biased. This paper investigates the large-scale hypothesis testing problem for multivariate generalized linear models in the presence of confounding effects. Under arbitrary confounding mechanisms, we propose a unified statistical estimation and inference framework that harnesses orthogonal structures and integrates linear projections into three key stages. It first leverages multivariate responses to separate marginal and uncorrelated confounding effects, recovering the confounding coefficients' column space. Subsequently, latent factors and primary effects are jointly estimated, utilizing $\ell_1$-regularization for sparsity while imposing orthogonality onto confounding coefficients. Finally, we incorporate projected and weighted bias-correction steps 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02211</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Machine Learning with Multi-source Data. (arXiv:2309.02211v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02211
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22810;&#28304;&#25968;&#25454;&#30340;&#20998;&#24067;&#40065;&#26834;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#25552;&#39640;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#30446;&#26631;&#20998;&#24067;&#19982;&#28304;&#25968;&#25454;&#38598;&#19981;&#21516;&#26102;&#65292;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#23548;&#33268;&#36739;&#24046;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#21033;&#29992;&#22810;&#20010;&#25968;&#25454;&#28304;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26469;&#20248;&#21270;&#20851;&#20110;&#30446;&#26631;&#20998;&#24067;&#31867;&#30340;&#21487;&#35299;&#37322;&#26041;&#24046;&#30340;&#23545;&#25239;&#24615;&#22870;&#21169;&#12290;&#19982;&#20256;&#32479;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#25913;&#21892;&#20102;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#30446;&#26631;&#20154;&#32676;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32452;&#20998;&#24067;&#40065;&#26834;&#39044;&#27979;&#27169;&#22411;&#26159;&#28304;&#25968;&#25454;&#38598;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340;&#21152;&#26435;&#24179;&#22343;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#20851;&#38190;&#37492;&#21035;&#32467;&#26524;&#26469;&#25552;&#39640;&#20219;&#24847;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#31561;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#22120;&#26469;&#20272;&#35745;&#36890;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;c&#26041;&#38754;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical machine learning methods may lead to poor prediction performance when the target distribution differs from the source populations. This paper utilizes data from multiple sources and introduces a group distributionally robust prediction model defined to optimize an adversarial reward about explained variance with respect to a class of target distributions. Compared to classical empirical risk minimization, the proposed robust prediction model improves the prediction accuracy for target populations with distribution shifts. We show that our group distributionally robust prediction model is a weighted average of the source populations' conditional outcome models. We leverage this key identification result to robustify arbitrary machine learning algorithms, including, for example, random forests and neural networks. We devise a novel bias-corrected estimator to estimate the optimal aggregation weight for general machine-learning algorithms and demonstrate its improvement in the c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#37327;&#23376;&#29305;&#24615;&#20197;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#20027;&#35201;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#35270;&#20026;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#32780;&#38750;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.12013</link><description>&lt;p&gt;
&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Quantum-Noise-driven Generative Diffusion Models. (arXiv:2308.12013v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12013
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#37327;&#23376;&#29305;&#24615;&#20197;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#20027;&#35201;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#35270;&#20026;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#32780;&#38750;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#30340;&#29983;&#25104;&#27169;&#22411;&#26159;&#20174;&#26377;&#38480;&#30340;&#35757;&#32451;&#26679;&#26412;&#20013;&#25512;&#26029;&#20986;&#22797;&#26434;&#21644;&#26410;&#30693;&#25968;&#25454;&#20998;&#24067;&#24182;&#20135;&#29983;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#26694;&#26550;&#65292;&#26368;&#36817;&#22312;&#21019;&#24314;&#21512;&#25104;&#25991;&#26412;&#21644;&#39640;&#36136;&#37327;&#22270;&#20687;&#26041;&#38754;&#24050;&#32463;&#36229;&#36234;&#20102;&#29983;&#25104;&#23545;&#25239;&#24615;&#32593;&#32476;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#37327;&#23376;&#25512;generalization&#65292;&#21363;&#19977;&#31181;&#21487;&#33021;&#22312;&#23454;&#38469;&#37327;&#23376;&#31995;&#32479;&#19978;&#36827;&#34892;&#23454;&#39564;&#30340;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#24819;&#27861;&#26159;&#21033;&#29992;&#29420;&#29305;&#30340;&#37327;&#23376;&#29305;&#24615;&#65292;&#29305;&#21035;&#26159;&#30446;&#21069;&#21487;&#29992;&#30340;&#26377;&#22122;&#22768;&#37327;&#23376;&#22788;&#29702;&#22120;&#19981;&#21487;&#36991;&#20813;&#22320;&#21463;&#21040;&#30340;&#30456;&#24178;&#24615;&#12289;&#32416;&#32544;&#24615;&#21644;&#22122;&#22768;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#30340;&#20027;&#35201;&#35745;&#31639;&#36127;&#25285;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#19981;&#20316;&#20026;&#38656;&#35201;&#26816;&#27979;&#21644;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#32780;&#26159;&#20316;&#20026;&#19968;&#31181;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#65292;&#20351;&#24471;&#25193;&#25955;&#27169;&#22411;&#33021;&#22815;&#26356;&#22909;&#22320;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models realized with machine learning techniques are powerful tools to infer complex and unknown data distributions from a finite number of training samples in order to produce new synthetic data. Diffusion models are an emerging framework that have recently overcome the performance of the generative adversarial networks in creating synthetic text and high-quality images. Here, we propose and discuss the quantum generalization of diffusion models, i.e., three quantum-noise-driven generative diffusion models that could be experimentally tested on real quantum systems. The idea is to harness unique quantum features, in particular the non-trivial interplay among coherence, entanglement and noise that the currently available noisy quantum processors do unavoidably suffer from, in order to overcome the main computational burdens of classical diffusion models during inference. Hence, we suggest to exploit quantum noise not as an issue to be detected and solved but instead as a ver
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.03666</link><description>&lt;p&gt;
&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#30340;&#26725;&#26753;&#65306;&#19968;&#31181;&#25506;&#32034;&#24615;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03666
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30740;&#31350;&#20154;&#21592;&#21162;&#21147;&#32553;&#23567;&#26426;&#22120;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#36890;&#36807;&#21457;&#23637;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25105;&#20204;&#24517;&#39035;&#35748;&#35782;&#21040;&#21487;&#20449;&#24230;&#22312;&#24320;&#25918;&#19990;&#30028;&#20013;&#30340;&#20851;&#38190;&#37325;&#35201;&#24615;&#65292;&#22312;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#23545;&#27599;&#20010;&#20154;&#37117;&#24050;&#32463;&#26080;&#22788;&#19981;&#22312;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#20960;&#20010;&#25361;&#25112;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#20449;&#20219;&#21361;&#26426;&#65306;1&#65289;&#23545;&#39044;&#27979;&#32467;&#26524;&#30340;&#35299;&#37322;&#19981;&#36275;&#65307;2&#65289;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#19981;&#36275;&#65307;3&#65289;&#23545;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#36866;&#24212;&#33021;&#21147;&#24046;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#31243;&#24207;&#65292;&#29992;&#20110;&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#20174;&#21333;&#27169;&#24577;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#22330;&#26223;&#65292;&#20197;&#20379;&#35835;&#32773;&#20351;&#29992;&#12290;1&#65289;&#20026;&#20102;&#22686;&#24378;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#21046;&#20102;&#20855;&#26377;&#29305;&#23450;&#29289;&#29702;&#21547;&#20041;&#30340;&#21487;&#20449;&#32593;&#32476;&#65307;2&#65289;&#28982;&#21518;&#65292;&#36890;&#36807;&#28789;&#27963;&#30340;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#35774;&#35745;&#29615;&#22659;&#31119;&#31049;&#20219;&#21153;&#25509;&#21475;&#65292;&#20197;&#25913;&#21892;&#21487;&#20449;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As researchers strive to narrow the gap between machine intelligence and human through the development of artificial intelligence technologies, it is imperative that we recognize the critical importance of trustworthiness in open-world, which has become ubiquitous in all aspects of daily life for everyone. However, several challenges may create a crisis of trust in current artificial intelligence systems that need to be bridged: 1) Insufficient explanation of predictive results; 2) Inadequate generalization for learning models; 3) Poor adaptability to uncertain environments. Consequently, we explore a neural program to bridge trustworthiness and open-world learning, extending from single-modal to multi-modal scenarios for readers. 1) To enhance design-level interpretability, we first customize trustworthy networks with specific physical meanings; 2) We then design environmental well-being task-interfaces via flexible learning regularizers for improving the generalization of trustworthy
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;Zonoid&#30340;&#26368;&#20248;&#36924;&#36817;&#21644;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#20004;&#20010;&#38382;&#39064;&#12290;&#23545;&#20110;Zonoid&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#22312;$d=2,3$&#26102;&#30340;&#23545;&#25968;&#24046;&#36317;&#65292;&#23454;&#29616;&#20102;&#22312;&#25152;&#26377;&#32500;&#24230;&#19978;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;$k \geq 1$&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#30446;&#21069;&#30340;&#36924;&#36817;&#29575;&#65292;&#24182;&#33021;&#22815;&#22343;&#21248;&#36924;&#36817;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.15285</link><description>&lt;p&gt;
Zonoid&#30340;&#26368;&#20248;&#36924;&#36817;&#21644;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks. (arXiv:2307.15285v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;Zonoid&#30340;&#26368;&#20248;&#36924;&#36817;&#21644;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#20004;&#20010;&#38382;&#39064;&#12290;&#23545;&#20110;Zonoid&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#22312;$d=2,3$&#26102;&#30340;&#23545;&#25968;&#24046;&#36317;&#65292;&#23454;&#29616;&#20102;&#22312;&#25152;&#26377;&#32500;&#24230;&#19978;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;$k \geq 1$&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#30446;&#21069;&#30340;&#36924;&#36817;&#29575;&#65292;&#24182;&#33021;&#22815;&#22343;&#21248;&#36924;&#36817;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#19979;&#20004;&#20010;&#30456;&#20851;&#38382;&#39064;&#12290;&#31532;&#19968;&#20010;&#38382;&#39064;&#26159;&#30830;&#23450;&#19968;&#20010;&#20219;&#24847;&#30340;&#22312;$\mathbb{R}^{d+1}$&#31354;&#38388;&#20013;&#30340;Zonoid&#21487;&#20197;&#36890;&#36807;$n$&#20010;&#32447;&#27573;&#30340;Hausdorff&#36317;&#31163;&#26469;&#36924;&#36817;&#30340;&#35823;&#24046;&#12290;&#31532;&#20108;&#20010;&#38382;&#39064;&#26159;&#30830;&#23450;&#27973;&#23618;ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#22312;&#20854;&#21464;&#20998;&#31354;&#38388;&#20013;&#30340;&#22343;&#21248;&#33539;&#25968;&#30340;&#26368;&#20248;&#36924;&#36817;&#29575;&#12290;&#31532;&#19968;&#20010;&#38382;&#39064;&#24050;&#32463;&#22312;$d \neq 2, 3$&#26102;&#24471;&#21040;&#35299;&#20915;&#65292;&#20294;&#24403;$d = 2, 3$&#26102;&#65292;&#26368;&#20248;&#19978;&#30028;&#21644;&#26368;&#20248;&#19979;&#30028;&#20043;&#38388;&#20173;&#23384;&#22312;&#19968;&#20010;&#23545;&#25968;&#24046;&#36317;&#12290;&#25105;&#20204;&#22635;&#34917;&#20102;&#36825;&#20010;&#24046;&#36317;&#65292;&#23436;&#25104;&#20102;&#25152;&#26377;&#32500;&#24230;&#19978;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31532;&#20108;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;$k \geq 1$&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#29616;&#26377;&#30340;&#36924;&#36817;&#29575;&#65292;&#24182;&#23454;&#29616;&#20102;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#22343;&#21248;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the following two related problems. The first is to determine to what error an arbitrary zonoid in $\mathbb{R}^{d+1}$ can be approximated in the Hausdorff distance by a sum of $n$ line segments. The second is to determine optimal approximation rates in the uniform norm for shallow ReLU$^k$ neural networks on their variation spaces. The first of these problems has been solved for $d\neq 2,3$, but when $d=2,3$ a logarithmic gap between the best upper and lower bounds remains. We close this gap, which completes the solution in all dimensions. For the second problem, our techniques significantly improve upon existing approximation rates when $k\geq 1$, and enable uniform approximation of both the target function and its derivatives.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2306.11112</link><description>&lt;p&gt;
&#32416;&#27491;&#20844;&#24179;&#20998;&#31867;&#20013;&#30340;&#20302;&#20272;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#34987;&#20302;&#20272;&#20559;&#24046;&#25439;&#22351;&#30340;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#27491;&#20363;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#25935;&#24863;&#32452;&#20013;&#20197;&#19981;&#21516;&#30340;&#26410;&#30693;&#36895;&#29575;&#20174;&#25968;&#25454;&#20013;&#36807;&#28388;&#25481;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26377;&#23569;&#37327;&#26080;&#20559;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#27599;&#20010;&#32452;&#30340;&#20943;&#23569;&#21442;&#25968;&#65292;&#21363;&#20351;&#22312;&#20132;&#21449;&#32452;&#25104;&#21592;&#36164;&#26684;&#20351;&#24471;&#23398;&#20064;&#27599;&#20010;&#20132;&#21449;&#29575;&#21464;&#24471;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#24773;&#20917;&#19979;&#12290;&#21033;&#29992;&#36825;&#20010;&#20998;&#32452;&#20002;&#22833;&#29575;&#30340;&#20272;&#35745;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#20351;&#25105;&#20204;&#36817;&#20284;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#65292;&#21363;&#20351;&#25105;&#20204;&#21482;&#33021;&#22312;&#19968;&#20010;&#26377;&#20559;&#26679;&#26412;&#19978;&#35266;&#23519;&#21040;&#32463;&#39564;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23553;&#35013;&#20102;&#36825;&#20010;&#23398;&#20064;&#21644;&#37325;&#26032;&#21152;&#26435;&#36807;&#31243;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;PAC&#39118;&#26684;&#30340;&#20445;&#35777;&#65292;&#21363;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#25105;&#20204;&#23545;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#39118;&#38505;&#30340;&#20272;&#35745;&#23558;&#19982;&#30495;&#23454;&#39118;&#38505;&#20219;&#24847;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out parameters, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using this estimate for the group-wise drop-out rate, we construct a re-weighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. Finally, we present an algorithm encapsulating this learning and re-weighting process, and we provide strong PAC-style guarantees that, with high probability, our estimate of the risk of the hypothesis over the true distribution will be arbitrarily close to the true risk.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21253;&#25324;&#24322;&#24120;&#28857;&#30340;&#39640;&#32500;&#20581;&#22766;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#31934;&#30830;&#28176;&#36817;&#29305;&#24615;&#65292;&#23545;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#31616;&#21333;&#26657;&#20934;&#24182;&#35745;&#31639;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#30001;&#20110;&#33539;&#25968;&#26657;&#20934;&#19981;&#21305;&#37197;&#65292;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#19968;&#33268;&#24615;&#38656;&#35201;&#19968;&#20010;&#36739;&#24378;&#30340;&#25910;&#25947;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2305.18974</link><description>&lt;p&gt;
&#24322;&#24120;&#28857;&#23384;&#22312;&#26102;&#20581;&#22766;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#24615;&#33021;&#30340;&#28176;&#36827;&#29305;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Characterisation of Robust Empirical Risk Minimisation Performance in the Presence of Outliers. (arXiv:2305.18974v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18974
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#21253;&#25324;&#24322;&#24120;&#28857;&#30340;&#39640;&#32500;&#20581;&#22766;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#20351;&#29992;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#30340;&#31934;&#30830;&#28176;&#36817;&#29305;&#24615;&#65292;&#23545;&#27867;&#21270;&#35823;&#24046;&#36827;&#34892;&#20102;&#31616;&#21333;&#26657;&#20934;&#24182;&#35745;&#31639;&#20102;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#30001;&#20110;&#33539;&#25968;&#26657;&#20934;&#19981;&#21305;&#37197;&#65292;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#19968;&#33268;&#24615;&#38656;&#35201;&#19968;&#20010;&#36739;&#24378;&#30340;&#25910;&#25947;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#20581;&#22766;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#24403;&#32500;&#24230;$d$&#21644;&#25968;&#25454;&#28857;&#25968;&#37327;$n$&#20197;&#22266;&#23450;&#27604;&#29575;$\alpha=n/d$&#21457;&#25955;&#65292;&#24182;&#30740;&#31350;&#20102;&#21253;&#25324;&#24322;&#24120;&#28857;&#22312;&#20869;&#30340;&#25968;&#25454;&#27169;&#22411;&#12290;&#25105;&#20204;&#23545;&#20351;&#29992;$\ell_2$ -&#27491;&#21017;&#21270;$\ell_2$&#65292;$\ell_1$&#65292;&#21644; Huber &#25439;&#22833;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#24615;&#33021;&#25552;&#20379;&#20102;&#31934;&#30830;&#30340;&#28176;&#36817;&#29305;&#24615;&#65292;&#36825;&#26159;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#25105;&#20204;&#20851;&#27880;&#24615;&#33021;&#30340;&#20004;&#20010;&#25351;&#26631;&#65306;&#20855;&#26377;&#24322;&#24120;&#28857;&#30340;&#30456;&#20284;&#25968;&#25454;&#38598;&#30340;&#27867;&#21270;&#35823;&#24046;&#21644;&#21407;&#22987;&#26080;&#27745;&#26579;&#20989;&#25968;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;&#25105;&#20204;&#23558;&#32467;&#26524;&#19982;&#20449;&#24687;&#35770;&#36125;&#21494;&#26031;&#26368;&#20248;&#20272;&#35745;&#30028;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23545;&#20110;&#27867;&#21270;&#35823;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22914;&#26524;&#36827;&#34892;&#31616;&#21333;&#30340;&#26657;&#20934;&#24182;&#35745;&#31639;&#25910;&#25947;&#36895;&#29575;&#65292;&#21017;&#26368;&#20248;&#27491;&#21017;&#21270;ERM&#22312;&#22823;&#26679;&#26412;&#22797;&#26434;&#24230;&#38480;&#21046;&#19979;&#26159;&#28176;&#36817;&#19968;&#33268;&#30340;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20272;&#35745;&#35823;&#24046;&#65292;&#30001;&#20110;&#33539;&#25968;&#26657;&#20934;&#19981;&#21305;&#37197;&#65292;&#25105;&#20204;&#34920;&#26126;&#20272;&#35745;&#22120;&#30340;&#19968;&#33268;&#24615;&#38656;&#35201;&#19968;&#20010;&#36739;&#24378;&#30340;&#25910;&#25947;&#20551;&#35774;&#65292;&#36825;&#23545;&#38382;&#39064;&#30340;&#35299;&#20915;&#36824;&#38656;&#35201;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study robust linear regression in high-dimension, when both the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\alpha=n/d$, and study a data model that includes outliers. We provide exact asymptotics for the performances of the empirical risk minimisation (ERM) using $\ell_2$-regularised $\ell_2$, $\ell_1$, and Huber loss, which are the standard approach to such problems. We focus on two metrics for the performance: the generalisation error to similar datasets with outliers, and the estimation error of the original, unpolluted function. Our results are compared with the information theoretic Bayes-optimal estimation bound. For the generalization error, we find that optimally-regularised ERM is asymptotically consistent in the large sample complexity limit if one perform a simple calibration, and compute the rates of convergence. For the estimation error however, we show that due to a norm calibration mismatch, the consistency of the estimator requires an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.14683</link><description>&lt;p&gt;
&#35770;&#36827;&#21270;&#30952;&#38155;&#12289;&#24179;&#22374;&#26497;&#23567;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On progressive sharpening, flat minima and generalisation. (arXiv:2305.14683v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#25439;&#22833;&#26354;&#29575;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#29616;&#26377;&#30340;&#28145;&#24230;&#32593;&#32476;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#39057;&#35889;&#32463;&#39564;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#23558;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31995;&#21015;&#29702;&#35770;&#32467;&#26524;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#20551;&#35774;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#36827;&#21270;&#30952;&#38155;&#29616;&#35937;&#20197;&#21450;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#25551;&#36848;&#12290;&#23454;&#39564;&#35777;&#25454;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20027;&#24352;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new approach to understanding the relationship between loss curvature and generalisation in deep learning. Specifically, we use existing empirical analyses of the spectrum of deep network loss Hessians to ground an ansatz tying together the loss Hessian and the input-output Jacobian of a deep neural network. We then prove a series of theoretical results which quantify the degree to which the input-output Jacobian of a model approximates its Lipschitz norm over a data distribution, and deduce a novel generalisation bound in terms of the empirical Jacobian. We use our ansatz, together with our theoretical results, to give a new account of the recently observed progressive sharpening phenomenon, as well as the generalisation properties of flat minima. Experimental evidence is provided to validate our claims.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.08074</link><description>&lt;p&gt;
&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#21644;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#22312;&#28151;&#27788;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Orthogonal polynomial approximation and Extended Dynamic Mode Decomposition in chaos. (arXiv:2305.08074v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#31616;&#21333;&#30340;&#28151;&#27788;&#26144;&#23556;&#19978;&#35777;&#26126;&#20102;&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#23545;&#20110;&#22810;&#39033;&#24335;&#21487;&#35266;&#27979;&#23383;&#20856;&#26377;&#25351;&#25968;&#25928;&#29575;&#65292;&#20174;&#32780;&#26377;&#25928;&#22788;&#29702;&#20102;&#28151;&#27788;&#21160;&#21147;&#23398;&#20013;&#30340;&#27491;&#21017;&#20989;&#25968;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#33267;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#23637;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;EDMD&#65289;&#26159;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#21160;&#24577;&#30340;&#39044;&#27979;&#21644;&#27169;&#22411;&#31616;&#21270;&#65292;&#22312;&#29289;&#29702;&#31185;&#23398;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#27010;&#24565;&#19978;&#24456;&#31616;&#21333;&#65292;&#20294;&#22312;&#30830;&#23450;&#24615;&#28151;&#27788;&#20013;&#65292;&#23427;&#30340;&#24615;&#36136;&#25110;&#32773;&#23427;&#30340;&#25910;&#25947;&#24615;&#36824;&#19981;&#28165;&#26970;&#12290;&#29305;&#21035;&#26159;&#65292;EDMD&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#22914;&#20309;&#22788;&#29702;&#38656;&#35201;&#25551;&#32472;&#28151;&#27788;&#21160;&#21147;&#23398;&#21547;&#20041;&#30340;&#27491;&#21017;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#20063;&#26159;&#19981;&#28165;&#26970;&#30340;&#12290;&#26412;&#25991;&#22312;&#20998;&#26512;&#19978;&#31616;&#21333;&#30340;&#19968;&#20010;&#22278;&#29615;&#23637;&#24320;&#26144;&#23556;&#30340;&#26368;&#31616;&#21333;&#20363;&#23376;&#19978;&#65292;&#21457;&#23637;&#20102;&#20851;&#20110;EDMD&#30340;&#19968;&#33324;&#30340;&#12289;&#20005;&#26684;&#30340;&#29702;&#35770;&#12290;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#20851;&#20110;&#22312;&#21333;&#20301;&#22278;&#19978;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#65288;OPUC&#65289;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26080;&#38480;&#25968;&#25454;&#26497;&#38480;&#26102;&#65292;&#38024;&#23545;&#22810;&#39033;&#24335;&#30340;&#21487;&#35266;&#27979;&#23383;&#20856;&#30340;&#26368;&#23567;&#20108;&#20056;&#25237;&#24433;&#20855;&#26377;&#25351;&#25968;&#25928;&#29575;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20351;&#29992;EDMD&#20135;&#29983;&#30340;&#39044;&#27979;&#21644;Koopman&#35889;&#25968;&#25454;&#25910;&#25947;&#21040;&#29289;&#29702;&#19978;&#26377;&#24847;&#20041;&#30340;&#26497;&#38480;&#30340;&#25351;&#25968;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Extended Dynamic Mode Decomposition (EDMD) is a data-driven tool for forecasting and model reduction of dynamics, which has been extensively taken up in the physical sciences. While the method is conceptually simple, in deterministic chaos it is unclear what its properties are or even what it converges to. In particular, it is not clear how EDMD's least-squares approximation treats the classes of regular functions needed to make sense of chaotic dynamics.  In this paper we develop a general, rigorous theory of EDMD on the simplest examples of chaotic maps: analytic expanding maps of the circle. Proving a new result in the theory of orthogonal polynomials on the unit circle (OPUC), we show that in the infinite-data limit, the least-squares projection is exponentially efficient for polynomial observable dictionaries. As a result, we show that the forecasts and Koopman spectral data produced using EDMD in this setting converge to the physically meaningful limits, at an exponential rate.  
&lt;/p&gt;</description></item><item><title>&#32858;&#21512;&#21464;&#37327;&#19978;&#30340;&#22240;&#26524;&#24615;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20250;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;</title><link>http://arxiv.org/abs/2304.11625</link><description>&lt;p&gt;
&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#32858;&#21512;&#21644;&#24726;&#35770;&#24615;&#28151;&#28102;
&lt;/p&gt;
&lt;p&gt;
Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11625
&lt;/p&gt;
&lt;p&gt;
&#32858;&#21512;&#21464;&#37327;&#19978;&#30340;&#22240;&#26524;&#24615;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#20250;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#30340;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32858;&#21512;&#21464;&#37327;&#20013;&#65292;&#24178;&#39044;&#30340;&#24433;&#21709;&#36890;&#24120;&#26159;&#19981;&#30830;&#23450;&#30340;&#65292;&#22240;&#20026;&#30456;&#21516;&#30340;&#23439;&#35266;&#24178;&#39044;&#30340;&#19981;&#21516;&#24494;&#35266;&#23454;&#29616;&#21487;&#33021;&#20250;&#23548;&#33268;&#19979;&#28216;&#23439;&#35266;&#21464;&#37327;&#30340;&#19981;&#21516;&#21464;&#21270;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23545;&#20110;&#32858;&#21512;&#21464;&#37327;&#65292;&#22240;&#26524;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20351;&#24471;&#21407;&#26412;&#19981;&#28151;&#28102;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#28151;&#28102;&#65292;&#24182;&#19988;&#21453;&#20043;&#20134;&#28982;&#65292;&#36825;&#19968;&#28857;&#21462;&#20915;&#20110;&#30456;&#24212;&#30340;&#24494;&#35266;&#23454;&#29616;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#21482;&#26377;&#22312;&#32858;&#21512;&#22240;&#26524;&#31995;&#32479;&#27809;&#26377;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25165;&#21487;&#20197;&#23454;&#38469;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#12290;&#21542;&#21017;&#65292;&#25105;&#20204;&#38656;&#35201;&#25509;&#21463;&#19968;&#28857;&#65292;&#23601;&#26159;&#23439;&#35266;&#22240;&#26524;&#20851;&#31995;&#36890;&#24120;&#21482;&#19982;&#24494;&#35266;&#29366;&#24577;&#30456;&#20851;&#12290;&#22312;&#31215;&#26497;&#26041;&#38754;&#65292;&#25105;&#20204;&#34920;&#26126;&#24403;&#23439;&#35266;&#24178;&#39044;&#30340;&#20998;&#24067;&#19982;&#35266;&#27979;&#20998;&#24067;&#20013;&#24494;&#35266;&#29366;&#24577;&#30340;&#20998;&#24067;&#30456;&#21516;&#26102;&#65292;&#22240;&#26524;&#20851;&#31995;&#21487;&#20197;&#36827;&#34892;&#32858;&#21512;&#65292;&#24182;&#35752;&#35770;&#20102;&#27492;&#35266;&#23519;&#30340;&#27010;&#25324;&#12290;
&lt;/p&gt;
&lt;p&gt;
In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Cayley&#21464;&#25442;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23558;&#26925;&#29699;&#25311;&#21512;&#21040;&#22024;&#26434;&#25968;&#25454;&#20013;&#30340;&#26032;&#31639;&#27861;CTEF&#65292;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#30340;&#26925;&#29699;&#65292;&#24182;&#19988;&#33021;&#25552;&#21462;&#20854;&#20182;&#26041;&#27861;&#26080;&#27861;&#35782;&#21035;&#30340;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38477;&#32500;&#12289;&#25968;&#25454;&#21487;&#35270;&#21270;&#21644;&#32858;&#31867;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2304.10630</link><description>&lt;p&gt;
&#29992;Cayley&#21464;&#25442;&#25311;&#21512;&#26925;&#29699;
&lt;/p&gt;
&lt;p&gt;
Ellipsoid fitting with the Cayley transform. (arXiv:2304.10630v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10630
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Cayley&#21464;&#25442;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23558;&#26925;&#29699;&#25311;&#21512;&#21040;&#22024;&#26434;&#25968;&#25454;&#20013;&#30340;&#26032;&#31639;&#27861;CTEF&#65292;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#30340;&#26925;&#29699;&#65292;&#24182;&#19988;&#33021;&#25552;&#21462;&#20854;&#20182;&#26041;&#27861;&#26080;&#27861;&#35782;&#21035;&#30340;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#65292;&#21487;&#29992;&#20110;&#38477;&#32500;&#12289;&#25968;&#25454;&#21487;&#35270;&#21270;&#21644;&#32858;&#31867;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;Cayley&#21464;&#25442;&#26925;&#29699;&#25311;&#21512;(CTEF)&#65292;&#23427;&#20351;&#29992;Cayley&#21464;&#25442;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23558;&#26925;&#29699;&#25311;&#21512;&#21040;&#22024;&#26434;&#30340;&#25968;&#25454;&#20013;&#12290;&#19982;&#35768;&#22810;&#26925;&#29699;&#25311;&#21512;&#26041;&#27861;&#19981;&#21516;&#65292;CTEF&#26159;&#26925;&#29699;&#29305;&#23450;&#30340;&#8212;&#8212;&#24847;&#21619;&#30528;&#23427;&#24635;&#26159;&#36820;&#22238;&#26925;&#22278;&#35299;&#8212;&#8212;&#24182;&#19988;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#30340;&#26925;&#29699;&#12290;&#24403;&#25968;&#25454;&#19981;&#22343;&#21248;&#22320;&#20998;&#24067;&#22312;&#26925;&#29699;&#34920;&#38754;&#19978;&#26102;&#65292;&#23427;&#20063;&#20248;&#20110;&#20854;&#20182;&#25311;&#21512;&#26041;&#27861;&#12290;&#21463;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#35299;&#37322;&#21644;&#21487;&#37325;&#22797;&#26041;&#27861;&#30340;&#21628;&#21505;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;CTEF&#24212;&#29992;&#20110;&#38477;&#32500;&#12289;&#25968;&#25454;&#21487;&#35270;&#21270;&#21644;&#32858;&#31867;&#12290;&#30001;&#20110;CTEF&#25429;&#25417;&#20840;&#23616;&#26354;&#29575;&#65292;&#22240;&#27492;&#23427;&#33021;&#22815;&#25552;&#21462;&#20854;&#20182;&#26041;&#27861;&#26080;&#27861;&#35782;&#21035;&#30340;&#25968;&#25454;&#20013;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#12290;&#36825;&#22312;&#20154;&#31867;&#32454;&#32990;&#21608;&#26399;&#25968;&#25454;&#30340;&#38477;&#32500;&#21644;&#22312;&#32463;&#20856;&#29609;&#20855;&#20363;&#23376;&#30340;&#32858;&#31867;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#20102;&#35828;&#26126;&#12290;&#22312;&#21518;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;CTEF&#20248;&#20110;10&#31181;&#27969;&#34892;&#30340;&#32858;&#31867;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an algorithm, Cayley transform ellipsoid fitting (CTEF), that uses the Cayley transform to fit ellipsoids to noisy data in any dimension. Unlike many ellipsoid fitting methods, CTEF is ellipsoid specific -- meaning it always returns elliptic solutions -- and can fit arbitrary ellipsoids. It also outperforms other fitting methods when data are not uniformly distributed over the surface of an ellipsoid. Inspired by calls for interpretable and reproducible methods in machine learning, we apply CTEF to dimension reduction, data visualization, and clustering. Since CTEF captures global curvature, it is able to extract nonlinear features in data that other methods fail to identify. This is illustrated in the context of dimension reduction on human cell cycle data, and in the context of clustering on classical toy examples. In the latter case, CTEF outperforms 10 popular clustering algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#29992;&#20110;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#20805;&#24403;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#24674;&#22797;&#29992;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#32780;&#26469;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.09123</link><description>&lt;p&gt;
&#20351;&#29992;&#34987;&#21160; Langevin &#21160;&#21147;&#23398;&#30340;&#33258;&#36866;&#24212;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Bounds for Adaptive Inverse Reinforcement Learning using Passive Langevin Dynamics. (arXiv:2304.09123v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#29992;&#20110;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#29992;&#20110;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#35813;&#31639;&#27861;&#20805;&#24403;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#24674;&#22797;&#29992;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#32780;&#26469;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398; (SGLD) &#26159;&#20174;&#27010;&#29575;&#20998;&#24067;&#37319;&#26679;&#30340;&#26377;&#29992;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#34987;&#21160;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398;&#31639;&#27861; (PSGLD) &#30340;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#65292;&#26088;&#22312;&#23454;&#29616;&#36870;&#24378;&#21270;&#23398;&#20064;&#12290;&#27492;&#22788;&#30340;&#8220;&#34987;&#21160;&#8221;&#26159;&#25351; PSGLD &#31639;&#27861;(&#36870;&#23398;&#20064;&#36807;&#31243;)&#21487;&#29992;&#30340;&#22122;&#22768;&#28176;&#21464;&#26159;&#30001;&#22806;&#37096;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;(&#27491;&#21521;&#23398;&#20064;&#22120;)&#22312;&#38543;&#26426;&#36873;&#25321;&#30340;&#28857;&#19978;&#35780;&#20272;&#30340;&#12290;PSGLD &#31639;&#27861;&#22240;&#27492;&#20805;&#24403;&#19968;&#20010;&#38543;&#26426;&#37319;&#26679;&#22120;&#65292;&#21487;&#24674;&#22797;&#27491;&#22312;&#34987;&#27492;&#22806;&#37096;&#36807;&#31243;&#20248;&#21270;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#38543;&#26426;&#36924;&#36817;&#25216;&#26415;&#20998;&#26512;&#20102;&#36825;&#20010;&#34987;&#21160;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#33021;&#65307;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23427;&#30340;&#26377;&#38480;&#26102;&#38388;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#34987;&#21160;&#31639;&#27861;&#21644;&#20854;&#31283;&#23450;&#27979;&#24230;&#20043;&#38388;&#30340; 2-Wasserstein &#36317;&#31163;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#38480;&#65292;&#20174;&#20013;&#21487;&#20197;&#33719;&#24471;&#37325;&#24314;&#30340;&#25104;&#26412;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic gradient Langevin dynamics (SGLD) are a useful methodology for sampling from probability distributions. This paper provides a finite sample analysis of a passive stochastic gradient Langevin dynamics algorithm (PSGLD) designed to achieve inverse reinforcement learning. By "passive", we mean that the noisy gradients available to the PSGLD algorithm (inverse learning process) are evaluated at randomly chosen points by an external stochastic gradient algorithm (forward learner). The PSGLD algorithm thus acts as a randomized sampler which recovers the cost function being optimized by this external process. Previous work has analyzed the asymptotic performance of this passive algorithm using stochastic approximation techniques; in this work we analyze the non-asymptotic performance. Specifically, we provide finite-time bounds on the 2-Wasserstein distance between the passive algorithm and its stationary measure, from which the reconstructed cost function is obtained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;Hilbert-Valued&#21442;&#25968;&#36827;&#34892;&#19968;&#27493;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.16711</link><description>&lt;p&gt;
Hilbert-Valued&#21442;&#25968;&#30340;&#19968;&#27493;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
One-Step Estimation of Differentiable Hilbert-Valued Parameters. (arXiv:2303.16711v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;Hilbert-Valued&#21442;&#25968;&#36827;&#34892;&#19968;&#27493;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20809;&#28369;Hilbert-Valued&#21442;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#20809;&#28369;&#24615;&#30001;&#36880;&#36335;&#24452;&#21487;&#24494;&#26465;&#20214;&#34920;&#24449;&#12290;&#24403;&#21442;&#25968;&#31354;&#38388;&#26159;&#37325;&#29616;&#26680;Hilbert&#31354;&#38388;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#33719;&#21462;&#39640;&#25928;&#21644;&#30456;&#20851;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#23545;&#24212;&#20110;&#22522;&#20110;Hilbert-Valued&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#30340;&#20132;&#21449;&#19968;&#27493;&#20272;&#35745;&#22120;&#30340;&#27010;&#25324;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#21363;&#20351;&#20351;&#29992;&#20219;&#24847;&#30340;&#36741;&#21161;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#21253;&#25324;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21363;&#20351;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#65292;&#21482;&#35201;&#21442;&#25968;&#20855;&#26377;&#39640;&#25928;&#30340;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#20123;&#32467;&#26524;&#33258;&#28982;&#22320;&#21487;&#20197;&#25193;&#23637;&#21040;&#35813;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#25581;&#31034;&#20102;&#19981;&#24184;&#30340;&#20107;&#23454;&#65292;&#24403;&#19981;&#23384;&#22312;&#37325;&#29616;&#26680;&#26102;&#65292;&#35768;&#22810;&#26377;&#36259;&#30340;&#21442;&#25968;&#21363;&#20351;&#23427;&#20204;&#22312;&#36335;&#24452;&#19978;&#26159;&#21487;&#24494;&#30340;&#65292;&#20063;&#32570;&#20047;&#26377;&#25928;&#30340;&#24433;&#21709;&#20989;&#25968;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present estimators for smooth Hilbert-valued parameters, where smoothness is characterized by a pathwise differentiability condition. When the parameter space is a reproducing kernel Hilbert space, we provide a means to obtain efficient, root-n rate estimators and corresponding confidence sets. These estimators correspond to generalizations of cross-fitted one-step estimators based on Hilbert-valued efficient influence functions. We give theoretical guarantees even when arbitrary estimators of nuisance functions are used, including those based on machine learning techniques. We show that these results naturally extend to Hilbert spaces that lack a reproducing kernel, as long as the parameter has an efficient influence function. However, we also uncover the unfortunate fact that, when there is no reproducing kernel, many interesting parameters fail to have an efficient influence function, even though they are pathwise differentiable. To handle these cases, we propose a regularized on
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Thompson-CHM&#30340;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#65292;&#19988;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#32500;&#21644;&#22810;&#32500;&#29615;&#22659;&#20013;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#27169;&#22359;&#21270;&#35774;&#35745;&#65292;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02033</link><description>&lt;p&gt;
&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#30340;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Asymptotically Optimal Algorithm for the Convex Hull Membership Problem. (arXiv:2302.02033v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;Thompson-CHM&#30340;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#65292;&#19988;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#32500;&#21644;&#22810;&#32500;&#29615;&#22659;&#20013;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#27169;&#22359;&#21270;&#35774;&#35745;&#65292;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#30340;&#32431;&#25506;&#32034;&#35774;&#32622;&#19982;&#20984;&#21253;&#22343;&#20540;&#30340;&#26377;&#38480;&#20998;&#24067;&#38598;&#21512;&#20013;&#26377;&#25928;&#20934;&#30830;&#22320;&#30830;&#23450;&#32473;&#23450;&#28857;&#26159;&#21542;&#22312;&#20984;&#21253;&#20013;&#30456;&#20851;&#12290;&#25105;&#20204;&#22312;&#19968;&#32500;&#29615;&#22659;&#20013;&#23436;&#20840;&#21051;&#30011;&#20102;&#20984;&#21253;&#25104;&#21592;&#38382;&#39064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#31639;&#27861;&#65292;&#21517;&#20026;Thompson-CHM&#65292;&#20854;&#27169;&#22359;&#21270;&#35774;&#35745;&#21253;&#25324;&#20572;&#27490;&#35268;&#21017;&#21644;&#37319;&#26679;&#35268;&#21017;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#31639;&#27861;&#25193;&#23637;&#21040;&#20102;&#19968;&#20123;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#25991;&#29486;&#20013;&#24191;&#20041;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;Thompson-CHM&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30340;&#25193;&#23637;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#20197;&#23637;&#31034;&#31639;&#27861;&#30340;&#32463;&#39564;&#34892;&#20026;&#19982;&#25105;&#20204;&#22312;&#23454;&#38469;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;&#29702;&#35770;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the pure-exploration setting for the convex hull membership (CHM) problem where one aims to efficiently and accurately determine if a given point lies in the convex hull of means of a finite set of distributions. We give a complete characterization of the sample complexity of the CHM problem in the one-dimensional setting. We present the first asymptotically optimal algorithm called Thompson-CHM, whose modular design consists of a stopping rule and a sampling rule. In addition, we extend the algorithm to settings that generalize several important problems in the multi-armed bandit literature. Furthermore, we discuss the extension of Thompson-CHM to higher dimensions. Finally, we provide numerical experiments to demonstrate the empirical behavior of the algorithm matches our theoretical results for realistic time horizons.
&lt;/p&gt;</description></item><item><title>GeONet&#26159;&#19968;&#20010;&#19981;&#21463;&#32593;&#26684;&#24433;&#21709;&#30340;&#28145;&#24230;&#31070;&#32463;&#31639;&#23376;&#32593;&#32476;&#65292;&#23398;&#20064;&#20102;&#20174;&#21021;&#22987;&#21644;&#32456;&#31471;&#20998;&#24067;&#21040;&#36830;&#25509;&#20004;&#20010;&#31471;&#28857;&#20998;&#24067;&#30340;Wasserstein&#27979;&#22320;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#12290;&#36890;&#36807;&#23398;&#20064;&#38797;&#28857;&#20248;&#21270;&#26465;&#20214;&#65292;GeONet&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#24182;&#22312;&#20223;&#30495;&#31034;&#20363;&#21644;&#27979;&#35797;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#19982;&#26631;&#20934;OT&#27714;&#35299;&#22120;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.14440</link><description>&lt;p&gt;
GeONet&#65306;&#19968;&#31181;&#23398;&#20064;Wasserstein&#27979;&#22320;&#30340;&#31070;&#32463;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
GeONet: a neural operator for learning the Wasserstein geodesic. (arXiv:2209.14440v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14440
&lt;/p&gt;
&lt;p&gt;
GeONet&#26159;&#19968;&#20010;&#19981;&#21463;&#32593;&#26684;&#24433;&#21709;&#30340;&#28145;&#24230;&#31070;&#32463;&#31639;&#23376;&#32593;&#32476;&#65292;&#23398;&#20064;&#20102;&#20174;&#21021;&#22987;&#21644;&#32456;&#31471;&#20998;&#24067;&#21040;&#36830;&#25509;&#20004;&#20010;&#31471;&#28857;&#20998;&#24067;&#30340;Wasserstein&#27979;&#22320;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#12290;&#36890;&#36807;&#23398;&#20064;&#38797;&#28857;&#20248;&#21270;&#26465;&#20214;&#65292;GeONet&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#24182;&#22312;&#20223;&#30495;&#31034;&#20363;&#21644;&#27979;&#35797;&#25968;&#25454;&#19978;&#21462;&#24471;&#20102;&#19982;&#26631;&#20934;OT&#27714;&#35299;&#22120;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#20256;&#36755;(OT)&#25552;&#20379;&#20102;&#19968;&#31181;&#23558;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#20960;&#20309;&#19978;&#26377;&#24847;&#20041;&#27604;&#36739;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#20256;&#32479;&#30340;&#35745;&#31639;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#21644;&#27979;&#22320;&#30340;&#26041;&#27861;&#38656;&#35201;&#32593;&#26684;&#20381;&#36182;&#30340;&#22495;&#31163;&#25955;&#21270;&#65292;&#21516;&#26102;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GeONet&#65292;&#19968;&#31181;&#19981;&#21463;&#32593;&#26684;&#24433;&#21709;&#30340;&#28145;&#24230;&#31070;&#32463;&#31639;&#23376;&#32593;&#32476;&#65292;&#23427;&#23398;&#20064;&#20102;&#23558;&#36755;&#20837;&#30340;&#21021;&#22987;&#21644;&#32456;&#31471;&#20998;&#24067;&#26144;&#23556;&#21040;&#36830;&#25509;&#20004;&#20010;&#31471;&#28857;&#20998;&#24067;&#30340;Wasserstein&#27979;&#22320;&#30340;&#38750;&#32447;&#24615;&#26144;&#23556;&#12290;&#22312;&#33073;&#26426;&#35757;&#32451;&#38454;&#27573;&#65292;GeONet&#36890;&#36807;&#32806;&#21512;&#30340;PDE&#31995;&#32479;&#34920;&#24449;&#30340;&#21407;&#22987;&#21644;&#23545;&#20598;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#26368;&#20248;&#26465;&#20214;&#23398;&#20064;&#20102;OT&#38382;&#39064;&#30340;&#38797;&#28857;&#20248;&#21270;&#26465;&#20214;&#12290;&#21518;&#32493;&#30340;&#25512;&#29702;&#38454;&#27573;&#26159;&#30636;&#26102;&#23436;&#25104;&#30340;&#65292;&#24182;&#21487;&#20197;&#22312;&#22312;&#32447;&#23398;&#20064;&#35774;&#32622;&#20013;&#29992;&#20110;&#23454;&#26102;&#39044;&#27979;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;GeONet&#22312;&#20223;&#30495;&#31034;&#20363;&#21644;...
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) offers a versatile framework to compare complex data distributions in a geometrically meaningful way. Traditional methods for computing the Wasserstein distance and geodesic between probability measures require mesh-dependent domain discretization and suffer from the curse-of-dimensionality. We present GeONet, a mesh-invariant deep neural operator network that learns the non-linear mapping from the input pair of initial and terminal distributions to the Wasserstein geodesic connecting the two endpoint distributions. In the offline training stage, GeONet learns the saddle point optimality conditions for the dynamic formulation of the OT problem in the primal and dual spaces that are characterized by a coupled PDE system. The subsequent inference stage is instantaneous and can be deployed for real-time predictions in the online learning setting. We demonstrate that GeONet achieves comparable testing accuracy to the standard OT solvers on simulation examples and the
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#36125;&#21494;&#26031;LOO-CV&#20934;&#21017;&#30340;&#26032;&#30340;&#28151;&#21512;&#20272;&#35745;&#37327;&#65292;&#20445;&#25345;&#20102;&#32463;&#20856;&#26041;&#27861;&#30340;&#31616;&#20415;&#24615;&#21644;&#35745;&#31639;&#26041;&#20415;&#24615;&#65292;&#24182;&#30830;&#20445;&#20102;&#32467;&#26524;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#26041;&#24046;&#26377;&#38480;&#12290;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#23588;&#20026;&#26174;&#33879;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#21644;&#20855;&#26377;&#39640;&#24230;&#24433;&#21709;&#30340;&#35266;&#27979;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2209.09190</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#40065;&#26834;&#31163;&#32676;&#20540;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Robust leave-one-out cross-validation for high-dimensional Bayesian models. (arXiv:2209.09190v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.09190
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#35745;&#31639;&#36125;&#21494;&#26031;LOO-CV&#20934;&#21017;&#30340;&#26032;&#30340;&#28151;&#21512;&#20272;&#35745;&#37327;&#65292;&#20445;&#25345;&#20102;&#32463;&#20856;&#26041;&#27861;&#30340;&#31616;&#20415;&#24615;&#21644;&#35745;&#31639;&#26041;&#20415;&#24615;&#65292;&#24182;&#30830;&#20445;&#20102;&#32467;&#26524;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#26041;&#24046;&#26377;&#38480;&#12290;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#23588;&#20026;&#26174;&#33879;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#21644;&#20855;&#26377;&#39640;&#24230;&#24433;&#21709;&#30340;&#35266;&#27979;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32676;&#20540;&#20132;&#21449;&#39564;&#35777;&#65288;LOO-CV&#65289;&#26159;&#20272;&#35745;&#26679;&#26412;&#22806;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#19968;&#31181;&#24120;&#29992;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#38656;&#35201;&#22810;&#27425;&#25311;&#21512;&#27169;&#22411;&#65292;&#35745;&#31639;LOO-CV&#20934;&#21017;&#21487;&#33021;&#38750;&#24120;&#32791;&#26102;&#12290;&#22312;&#36125;&#21494;&#26031;&#32972;&#26223;&#19979;&#65292;&#37325;&#35201;&#24615;&#25277;&#26679;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#33021;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#32463;&#20856;&#26041;&#27861;&#24456;&#23481;&#26131;&#20135;&#29983;&#28176;&#36817;&#26041;&#24046;&#20026;&#26080;&#31351;&#22823;&#30340;&#20272;&#35745;&#37327;&#65292;&#20351;&#20854;&#28508;&#22312;&#22320;&#19981;&#21487;&#38752;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#20272;&#35745;&#37327;&#26469;&#35745;&#31639;&#36125;&#21494;&#26031;LOO-CV&#20934;&#21017;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#25345;&#20102;&#32463;&#20856;&#26041;&#27861;&#30340;&#31616;&#21333;&#24615;&#21644;&#35745;&#31639;&#26041;&#20415;&#24615;&#65292;&#21516;&#26102;&#20445;&#35777;&#20102;&#25152;&#24471;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#26041;&#24046;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#25968;&#20540;&#32467;&#26524;&#26469;&#35828;&#26126;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#21644;&#25928;&#29575;&#12290;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#65292;&#36825;&#31181;&#35745;&#31639;&#20248;&#21183;&#23588;&#20026;&#26174;&#33879;&#65292;&#21487;&#20197;&#22312;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#21644;&#20855;&#26377;&#39640;&#24230;&#24433;&#21709;&#24615;&#30340;&#35266;&#27979;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#36125;&#21494;&#26031;LOO-CV&#12290;
&lt;/p&gt;
&lt;p&gt;
Leave-one-out cross-validation (LOO-CV) is a popular method for estimating out-of-sample predictive accuracy. However, computing LOO-CV criteria can be computationally expensive due to the need to fit the model multiple times. In the Bayesian context, importance sampling provides a possible solution but classical approaches can easily produce estimators whose asymptotic variance is infinite, making them potentially unreliable. Here we propose and analyze a novel mixture estimator to compute Bayesian LOO-CV criteria. Our method retains the simplicity and computational convenience of classical approaches, while guaranteeing finite asymptotic variance of the resulting estimators. Both theoretical and numerical results are provided to illustrate the improved robustness and efficiency. The computational benefits are particularly significant in high-dimensional problems, allowing to perform Bayesian LOO-CV for a broader range of models, and datasets with highly influential observations. The 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;Frank-Wolfe&#31639;&#27861;&#21464;&#20307;&#65292;&#21033;&#29992;&#24191;&#20041;&#33258;&#21327;&#35843;&#20989;&#25968;&#30340;&#29305;&#24615;&#65292;&#22312;&#19981;&#38656;&#35201;&#20351;&#29992;&#20108;&#38454;&#20449;&#24687;&#25110;&#20272;&#35745;&#23616;&#37096;&#24179;&#28369;&#24230;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$\mathcal{O}(1/t)$&#30340;&#25910;&#25947;&#36895;&#24230;&#36798;&#21040;&#20102;&#20248;&#21270;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2105.13913</link><description>&lt;p&gt;
&#21482;&#38656;&#31616;&#21333;&#27493;&#39588;&#65306;Frank-Wolfe&#31639;&#27861;&#21644;&#24191;&#20041;&#33258;&#21327;&#35843;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Simple steps are all you need: Frank-Wolfe and generalized self-concordant functions. (arXiv:2105.13913v6 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.13913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;Frank-Wolfe&#31639;&#27861;&#21464;&#20307;&#65292;&#21033;&#29992;&#24191;&#20041;&#33258;&#21327;&#35843;&#20989;&#25968;&#30340;&#29305;&#24615;&#65292;&#22312;&#19981;&#38656;&#35201;&#20351;&#29992;&#20108;&#38454;&#20449;&#24687;&#25110;&#20272;&#35745;&#23616;&#37096;&#24179;&#28369;&#24230;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$\mathcal{O}(1/t)$&#30340;&#25910;&#25947;&#36895;&#24230;&#36798;&#21040;&#20102;&#20248;&#21270;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#33258;&#21327;&#35843;&#26159;&#35768;&#22810;&#37325;&#35201;&#23398;&#20064;&#38382;&#39064;&#30340;&#30446;&#26631;&#20989;&#25968;&#20013;&#23384;&#22312;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;Frank-Wolfe&#21464;&#20307;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#21464;&#20307;&#20351;&#29992;&#20102;&#24320;&#29615;&#27493;&#38271;&#31574;&#30053;$\gamma_t=2/(t+2)$&#65292;&#23545;&#20110;&#36825;&#31867;&#20989;&#25968;&#22312;&#21407;&#22987;&#38388;&#38553;&#21644;Frank-Wolfe&#38388;&#38553;&#26041;&#38754;&#33719;&#24471;&#20102;$\mathcal{O}(1/t)$&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$t$&#26159;&#36845;&#20195;&#27425;&#25968;&#12290;&#36825;&#36991;&#20813;&#20102;&#20351;&#29992;&#20108;&#38454;&#20449;&#24687;&#25110;&#38656;&#35201;&#20272;&#35745;&#20808;&#21069;&#24037;&#20316;&#30340;&#23616;&#37096;&#24179;&#28369;&#24230;&#21442;&#25968;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19981;&#21516;&#24120;&#35265;&#24773;&#20917;&#19979;&#30340;&#25913;&#36827;&#25910;&#25947;&#36895;&#24230;&#65292;&#20363;&#22914;&#65292;&#24403;&#25152;&#32771;&#34385;&#30340;&#21487;&#34892;&#22495;&#26159;&#22343;&#21248;&#20984;&#30340;&#25110;&#32773;&#26159;&#22810;&#38754;&#20307;&#30340;&#26102;&#20505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized self-concordance is a key property present in the objective function of many important learning problems. We establish the convergence rate of a simple Frank-Wolfe variant that uses the open-loop step size strategy $\gamma_t = 2/(t+2)$, obtaining a $\mathcal{O}(1/t)$ convergence rate for this class of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the iteration count. This avoids the use of second-order information or the need to estimate local smoothness parameters of previous work. We also show improved convergence rates for various common cases, e.g., when the feasible region under consideration is uniformly convex or polyhedral.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#28789;&#27963;&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26426;&#26800;&#24314;&#27169;&#20013;&#30340;&#25968;&#25454;&#19968;&#33268;&#21453;&#28436;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#36125;&#21494;&#26031;&#20998;&#26512;&#20013;&#26080;&#20449;&#24687;&#20808;&#39564;&#24341;&#20837;&#30340;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22312;&#38543;&#26426;&#36870;&#38382;&#39064;&#26694;&#26550;&#19979;&#25512;&#26029;&#21442;&#25968;&#12290;&#20351;&#29992;&#25298;&#32477;&#37319;&#26679;&#12289;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#31561;&#26032;&#26041;&#27861;&#35299;&#20915;&#20102;&#25968;&#25454;&#19968;&#33268;&#21453;&#28436;&#30340;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#32422;&#26463;&#20248;&#21270;&#21644;&#20808;&#39564;&#36870;&#38382;&#39064;&#20998;&#26512;&#36827;&#19968;&#27493;&#20248;&#21270;&#20102;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2009.08267</link><description>&lt;p&gt;
&#26426;&#26800;&#24314;&#27169;&#20013;&#25968;&#25454;&#19968;&#33268;&#21453;&#28436;&#30340;&#26032;&#39062;&#28789;&#27963;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Novel and flexible parameter estimation methods for data-consistent inversion in mechanistic modeling. (arXiv:2009.08267v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.08267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#28789;&#27963;&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#26426;&#26800;&#24314;&#27169;&#20013;&#30340;&#25968;&#25454;&#19968;&#33268;&#21453;&#28436;&#12290;&#35813;&#26041;&#27861;&#35299;&#20915;&#20102;&#36125;&#21494;&#26031;&#20998;&#26512;&#20013;&#26080;&#20449;&#24687;&#20808;&#39564;&#24341;&#20837;&#30340;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#22312;&#38543;&#26426;&#36870;&#38382;&#39064;&#26694;&#26550;&#19979;&#25512;&#26029;&#21442;&#25968;&#12290;&#20351;&#29992;&#25298;&#32477;&#37319;&#26679;&#12289;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#31561;&#26032;&#26041;&#27861;&#35299;&#20915;&#20102;&#25968;&#25454;&#19968;&#33268;&#21453;&#28436;&#30340;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#32422;&#26463;&#20248;&#21270;&#21644;&#20808;&#39564;&#36870;&#38382;&#39064;&#20998;&#26512;&#36827;&#19968;&#27493;&#20248;&#21270;&#20102;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#31995;&#32479;&#30340;&#39044;&#27979;&#36890;&#24120;&#20381;&#36182;&#20110;&#20174;&#27169;&#25311;&#38598;&#21512;&#20013;&#33719;&#24471;&#30340;&#30693;&#35782;&#65292;&#20363;&#22914;&#29983;&#29289;&#31185;&#23398;&#20013;&#30340;&#32454;&#32990;&#38598;&#21512;&#12290;&#20026;&#20102;&#23450;&#24615;&#21644;&#23450;&#37327;&#20998;&#26512;&#65292;&#36825;&#20123;&#38598;&#21512;&#20351;&#29992;&#21442;&#25968;&#21270;&#30340;&#26426;&#26800;&#27169;&#22411;&#65288;MM&#65289;&#36827;&#34892;&#27169;&#25311;&#12290;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#27169;&#22411;&#26063;&#26041;&#27861;&#26159;&#30446;&#21069;&#29289;&#29702;&#31995;&#32479;&#21442;&#25968;&#20272;&#35745;&#30340;&#20004;&#31867;&#20027;&#27969;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#36125;&#21494;&#26031;&#20998;&#26512;&#20013;&#65292;&#23545;MM&#21442;&#25968;&#20351;&#29992;&#26080;&#20449;&#24687;&#20808;&#39564;&#20250;&#24341;&#20837;&#19981;&#21487;&#21462;&#30340;&#20559;&#24046;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22914;&#20309;&#22312;&#38543;&#26426;&#36870;&#38382;&#39064;&#65288;SIP&#65289;&#26694;&#26550;&#20013;&#25512;&#26029;&#21442;&#25968;&#65292;&#35813;&#26694;&#26550;&#20063;&#34987;&#31216;&#20026;&#25968;&#25454;&#19968;&#33268;&#21453;&#28436;&#65292;&#20854;&#20013;&#20808;&#39564;&#21482;&#20851;&#27880;&#30001;&#20110;MM&#19981;&#21487;&#36870;&#36896;&#25104;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#28436;&#31034;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#25298;&#32477;&#37319;&#26679;&#12289;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;SIP&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20811;&#26381;SIP&#30340;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#22522;&#20110;&#32422;&#26463;&#20248;&#21270;&#21644;&#39044;
&lt;/p&gt;
&lt;p&gt;
Predictions for physical systems often rely upon knowledge acquired from ensembles of entities, e.g., ensembles of cells in biological sciences. For qualitative and quantitative analysis, these ensembles are simulated with parametric families of mechanistic models (MM). Two classes of methodologies, based on Bayesian inference and Population of Models, currently prevail in parameter estimation for physical systems. However, in Bayesian analysis, uninformative priors for MM parameters introduce undesirable bias. Here, we propose how to infer parameters within the framework of stochastic inverse problems (SIP), also termed data-consistent inversion, wherein the prior targets only uncertainties that arise due to MM non-invertibility. To demonstrate, we introduce new methods to solve SIP based on rejection sampling, Markov chain Monte Carlo, and generative adversarial networks (GANs). In addition, to overcome limitations of SIP, we reformulate SIP based on constrained optimization and pres
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#21892;SGD&#25910;&#25947;&#24615;&#30340;&#26041;&#27861;&#65292;&#26082;&#20943;&#23569;&#20102;&#39640;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#21448;&#20445;&#25345;&#20102;&#36739;&#39640;&#31934;&#24230;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/1910.08222</link><description>&lt;p&gt;
&#36890;&#36807;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#25913;&#21892;SGD&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving the convergence of SGD through adaptive batch sizes. (arXiv:1910.08222v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.08222
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#33258;&#36866;&#24212;&#25209;&#22823;&#23567;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#21892;SGD&#25910;&#25947;&#24615;&#30340;&#26041;&#27861;&#65292;&#26082;&#20943;&#23569;&#20102;&#39640;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#21448;&#20445;&#25345;&#20102;&#36739;&#39640;&#31934;&#24230;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23567;&#25209;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21450;&#20854;&#21464;&#31181;&#20351;&#29992;&#23569;&#37327;&#35757;&#32451;&#26679;&#26412;&#26469;&#36817;&#20284;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#20063;&#23601;&#26159;&#25209;&#22823;&#23567;&#12290;&#23567;&#25209;&#37327;&#22823;&#23567;&#22312;&#27599;&#20010;&#27169;&#22411;&#26356;&#26032;&#26102;&#38656;&#35201;&#36739;&#23569;&#30340;&#35745;&#31639;&#37327;&#65292;&#20294;&#21487;&#33021;&#23548;&#33268;&#39640;&#26041;&#24046;&#30340;&#26799;&#24230;&#20272;&#35745;&#65292;&#36825;&#23545;&#20248;&#21270;&#26469;&#35828;&#26159;&#19968;&#20123;&#25361;&#25112;&#12290;&#30456;&#21453;&#65292;&#22823;&#25209;&#37327;&#38656;&#35201;&#26356;&#22810;&#35745;&#31639;&#37327;&#65292;&#20294;&#21487;&#33021;&#20135;&#29983;&#26356;&#39640;&#31934;&#24230;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25209;&#22823;&#23567;&#35843;&#25972;&#21040;&#27169;&#22411;&#35757;&#32451;&#25439;&#22833;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#21508;&#31181;&#20989;&#25968;&#31867;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#27169;&#22411;&#26356;&#26032;&#26469;&#35828;&#38656;&#35201;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#21516;&#25968;&#37327;&#30340;&#27425;&#25968;&#65292;&#21516;&#26102;&#23545;&#20110;&#26799;&#24230;&#35745;&#31639;&#26469;&#35828;&#38656;&#35201;&#19982;SGD&#30456;&#21516;&#25968;&#37327;&#30340;&#27425;&#25968;&#12290;&#35813;&#26041;&#27861;&#38656;&#35201;&#22312;&#27599;&#20010;&#27169;&#22411;&#26356;&#26032;&#26102;&#35745;&#31639;&#25972;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#65292;&#20294;&#36890;&#36807;&#36817;&#20284;&#35757;&#32451;&#25439;&#22833;&#21487;&#20197;&#22823;&#22823;&#20943;&#23569;&#25152;&#38656;&#30340;&#35745;&#31639;&#37327;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#38656;&#35201;&#26356;&#23569;&#30340;&#27169;&#22411;&#26356;&#26032;&#32780;&#19981;&#22686;&#21152;&#24635;&#35745;&#31639;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mini-batch stochastic gradient descent (SGD) and variants thereof approximate the objective function's gradient with a small number of training examples, aka the batch size. Small batch sizes require little computation for each model update but can yield high-variance gradient estimates, which poses some challenges for optimization. Conversely, large batches require more computation but can yield higher precision gradient estimates. This work presents a method to adapt the batch size to the model's training loss. For various function classes, we show that our method requires the same order of model updates as gradient descent while requiring the same order of gradient computations as SGD. This method requires evaluating the model's loss on the entire dataset every model update. However, the required computation is greatly reduced by approximating the training loss. We provide experiments that illustrate our methods require fewer model updates without increasing the total amount of comp
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#38024;&#23545;&#20108;&#36827;&#21046;&#21464;&#37327;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#23454;&#29992;&#31639;&#27861;&#65292;&#36890;&#36807;&#20998;&#26512;&#30028;&#38480;&#21644;&#29616;&#20195;&#31995;&#32479;&#25216;&#26415;&#30340;&#32467;&#21512;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#20248;&#21270;&#30340;&#22256;&#38590;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#22312;&#21487;&#25193;&#23637;&#24615;&#12289;&#36895;&#24230;&#21644;&#26368;&#20248;&#24615;&#35777;&#26126;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/1904.12847</link><description>&lt;p&gt;
&#26368;&#20248;&#31232;&#30095;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
Optimal Sparse Decision Trees. (arXiv:1904.12847v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1904.12847
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#38024;&#23545;&#20108;&#36827;&#21046;&#21464;&#37327;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#23454;&#29992;&#31639;&#27861;&#65292;&#36890;&#36807;&#20998;&#26512;&#30028;&#38480;&#21644;&#29616;&#20195;&#31995;&#32479;&#25216;&#26415;&#30340;&#32467;&#21512;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#20248;&#21270;&#30340;&#22256;&#38590;&#65292;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#22312;&#21487;&#25193;&#23637;&#24615;&#12289;&#36895;&#24230;&#21644;&#26368;&#20248;&#24615;&#35777;&#26126;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#31639;&#27861;&#33258;&#20174;1980&#24180;&#20195;&#21021;&#20197;&#26469;&#23601;&#19968;&#30452;&#26159;&#21487;&#35299;&#37322;&#65288;&#36879;&#26126;&#65289;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#31639;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#33258;&#20174;&#23427;&#20204;&#38382;&#19990;&#20197;&#26469;&#65292;&#22256;&#25200;&#20915;&#31574;&#26641;&#31639;&#27861;&#30340;&#38382;&#39064;&#23601;&#26159;&#23427;&#20204;&#30340;&#38750;&#26368;&#20248;&#24615;&#65292;&#25110;&#32773;&#35828;&#32570;&#20047;&#25509;&#36817;&#26368;&#20248;&#30340;&#20445;&#35777;&#65306;&#20915;&#31574;&#26641;&#31639;&#27861;&#24448;&#24448;&#26159;&#36138;&#23146;&#30340;&#25110;&#32773;&#30446;&#20809;&#30701;&#27973;&#30340;&#65292;&#26377;&#26102;&#20250;&#20135;&#29983;&#26126;&#26174;&#38750;&#26368;&#20248;&#30340;&#27169;&#22411;&#12290;&#20915;&#31574;&#26641;&#20248;&#21270;&#30340;&#22256;&#38590;&#26082;&#26159;&#19968;&#20010;&#29702;&#35770;&#19978;&#30340;&#38556;&#30861;&#65292;&#20063;&#26159;&#19968;&#20010;&#23454;&#38469;&#19978;&#30340;&#38556;&#30861;&#65292;&#21363;&#20351;&#26159;&#20180;&#32454;&#30340;&#25968;&#23398;&#35268;&#21010;&#26041;&#27861;&#20063;&#26080;&#27861;&#39640;&#25928;&#22320;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#38024;&#23545;&#20108;&#36827;&#21046;&#21464;&#37327;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#23454;&#29992;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20998;&#26512;&#30028;&#38480;&#20943;&#23567;&#25628;&#32034;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;&#29616;&#20195;&#31995;&#32479;&#25216;&#26415;&#65292;&#21253;&#25324;&#25968;&#25454;&#32467;&#26500;&#21644;&#33258;&#23450;&#20041;&#20301;&#21521;&#37327;&#24211;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#22312;&#21487;&#25193;&#23637;&#24615;&#12289;&#36895;&#24230;&#21644;&#26368;&#20248;&#24615;&#35777;&#26126;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/xi&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision tree algorithms have been among the most popular algorithms for interpretable (transparent) machine learning since the early 1980's. The problem that has plagued decision tree algorithms since their inception is their lack of optimality, or lack of guarantees of closeness to optimality: decision tree algorithms are often greedy or myopic, and sometimes produce unquestionably suboptimal models. Hardness of decision tree optimization is both a theoretical and practical obstacle, and even careful mathematical programming approaches have not been able to solve these problems efficiently. This work introduces the first practical algorithm for optimal decision trees for binary variables. The algorithm is a co-design of analytical bounds that reduce the search space and modern systems techniques, including data structures and a custom bit-vector library. Our experiments highlight advantages in scalability, speed, and proof of optimality. The code is available at https://github.com/xi
&lt;/p&gt;</description></item></channel></rss>