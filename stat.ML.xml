<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36816;&#29992;&#23548;&#25968;&#20449;&#24687;&#30340;&#31070;&#32463;&#31639;&#23376;&#21152;&#36895;&#20102;&#20960;&#20309;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#26174;&#33879;&#21152;&#24555;&#20102;&#35299;&#20915;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#30340;&#36807;&#31243;&#12290;</title><link>https://arxiv.org/abs/2403.08220</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#30340;&#39640;&#25928;&#20960;&#20309;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65306;&#21033;&#29992;&#23548;&#25968;&#20449;&#24687;&#30340;&#31070;&#32463;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Efficient geometric Markov chain Monte Carlo for nonlinear Bayesian inversion enabled by derivative-informed neural operators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08220
&lt;/p&gt;
&lt;p&gt;
&#36816;&#29992;&#23548;&#25968;&#20449;&#24687;&#30340;&#31070;&#32463;&#31639;&#23376;&#21152;&#36895;&#20102;&#20960;&#20309;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#26174;&#33879;&#21152;&#24555;&#20102;&#35299;&#20915;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36816;&#31639;&#23398;&#20064;&#26041;&#27861;&#26469;&#21152;&#36895;&#20960;&#20309;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#20197;&#35299;&#20915;&#26080;&#38480;&#32500;&#38750;&#32447;&#24615;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#12290;&#34429;&#28982;&#20960;&#20309;MCMC&#37319;&#29992;&#36866;&#24212;&#21518;&#39564;&#23616;&#37096;&#20960;&#20309;&#30340;&#39640;&#36136;&#37327;&#25552;&#35758;&#65292;&#20294;&#22312;&#21442;&#25968;&#21040;&#21487;&#35266;&#27979;&#65288;PtO&#65289;&#26144;&#23556;&#36890;&#36807;&#26114;&#36149;&#30340;&#27169;&#22411;&#27169;&#25311;&#23450;&#20041;&#26102;&#65292;&#38656;&#35201;&#35745;&#31639;&#23545;&#25968;&#20284;&#28982;&#30340;&#23616;&#37096;&#26799;&#24230;&#21644;Hessian&#20449;&#24687;&#65292;&#36896;&#25104;&#39640;&#25104;&#26412;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#30001;PtO&#26144;&#23556;&#30340;&#31070;&#32463;&#31639;&#23376;&#26367;&#20195;&#39537;&#21160;&#30340;&#24310;&#36831;&#25509;&#21463;&#20960;&#20309;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#20854;&#20013;&#25552;&#35758;&#34987;&#35774;&#35745;&#20026;&#21033;&#29992;&#23545;&#25968;&#20284;&#28982;&#21644;&#20854;&#26799;&#24230;&#21644;Hessian&#30340;&#24555;&#36895;&#26367;&#20195;&#20272;&#35745;&#12290;&#20026;&#20102;&#23454;&#29616;&#26174;&#33879;&#21152;&#36895;&#65292;&#26367;&#20195;&#21697;&#38656;&#35201;&#20934;&#30830;&#39044;&#27979;&#21487;&#35266;&#27979;&#21450;&#20854;&#21442;&#25968;&#23548;&#25968;&#65288;&#21487;&#35266;&#27979;&#19982;&#21442;&#25968;&#20043;&#38388;&#30340;&#23548;&#25968;&#65289;&#12290;&#36890;&#36807;&#20256;&#32479;&#30340;&#26041;&#27861;&#23545;&#36825;&#26679;&#30340;&#26367;&#20195;&#21697;&#36827;&#34892;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08220v1 Announce Type: cross  Abstract: We propose an operator learning approach to accelerate geometric Markov chain Monte Carlo (MCMC) for solving infinite-dimensional nonlinear Bayesian inverse problems. While geometric MCMC employs high-quality proposals that adapt to posterior local geometry, it requires computing local gradient and Hessian information of the log-likelihood, incurring a high cost when the parameter-to-observable (PtO) map is defined through expensive model simulations. We consider a delayed-acceptance geometric MCMC method driven by a neural operator surrogate of the PtO map, where the proposal is designed to exploit fast surrogate approximations of the log-likelihood and, simultaneously, its gradient and Hessian. To achieve a substantial speedup, the surrogate needs to be accurate in predicting both the observable and its parametric derivative (the derivative of the observable with respect to the parameter). Training such a surrogate via conventional o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#19982;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#20803;&#20998;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#35299;&#32806;&#25216;&#26415;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#24341;&#20837;&#65292;&#23454;&#29616;&#20102;&#22312;&#20445;&#35777;&#20844;&#24179;&#24615;&#30340;&#21516;&#26102;&#25552;&#21319;&#20102;&#38544;&#31169;&#24615;&#33021;&#21644;&#25928;&#29992;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.15603</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20844;&#24179;&#20108;&#20803;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Fair Binary Classifications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15603
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#19982;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#20803;&#20998;&#31867;&#31639;&#27861;&#65292;&#36890;&#36807;&#35299;&#32806;&#25216;&#26415;&#21644;&#24046;&#20998;&#38544;&#31169;&#30340;&#24341;&#20837;&#65292;&#23454;&#29616;&#20102;&#22312;&#20445;&#35777;&#20844;&#24179;&#24615;&#30340;&#21516;&#26102;&#25552;&#21319;&#20102;&#38544;&#31169;&#24615;&#33021;&#21644;&#25928;&#29992;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#21644;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#20108;&#20803;&#20998;&#31867;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35299;&#32806;&#25216;&#26415;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#19968;&#20010;&#20165;&#20855;&#26377;&#20844;&#24179;&#24615;&#20445;&#35777;&#30340;&#20998;&#31867;&#22120;&#12290;&#35813;&#31639;&#27861;&#25509;&#21463;&#38024;&#23545;&#19981;&#21516;&#20154;&#21475;&#32676;&#20307;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#65292;&#24182;&#29983;&#25104;&#19968;&#20010;&#28385;&#36275;&#32479;&#35745;&#24179;&#34913;&#30340;&#21333;&#19968;&#20998;&#31867;&#22120;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#35813;&#31639;&#27861;&#20197;&#32435;&#20837;&#24046;&#20998;&#38544;&#31169;&#12290;&#26368;&#32456;&#31639;&#27861;&#30340;&#24615;&#33021;&#22312;&#38544;&#31169;&#12289;&#20844;&#24179;&#24615;&#21644;&#25928;&#29992;&#20445;&#35777;&#26041;&#38754;&#24471;&#21040;&#20102;&#20005;&#26684;&#26816;&#39564;&#12290;&#23545;Adult&#21644;&#20449;&#29992;&#21345;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#20844;&#24179;&#24615;&#20445;&#35777;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#30456;&#21516;&#27700;&#24179;&#30340;&#38544;&#31169;&#21644;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15603v1 Announce Type: new  Abstract: In this work, we investigate binary classification under the constraints of both differential privacy and fairness. We first propose an algorithm based on the decoupling technique for learning a classifier with only fairness guarantee. This algorithm takes in classifiers trained on different demographic groups and generates a single classifier satisfying statistical parity. We then refine this algorithm to incorporate differential privacy. The performance of the final algorithm is rigorously examined in terms of privacy, fairness, and utility guarantees. Empirical evaluations conducted on the Adult and Credit Card datasets illustrate that our algorithm outperforms the state-of-the-art in terms of fairness guarantees, while maintaining the same level of privacy and utility.
&lt;/p&gt;</description></item><item><title>REMEDI&#26159;&#19968;&#31181;&#29992;&#20110;&#25913;&#36827;&#31070;&#32463;&#29109;&#20272;&#35745;&#30340;&#26657;&#27491;&#36716;&#25442;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#30456;&#23545;&#29109;&#20272;&#35745;&#22522;&#27169;&#22411;&#30340;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2402.05718</link><description>&lt;p&gt;
REMEDI: &#25913;&#36827;&#31070;&#32463;&#29109;&#20272;&#35745;&#30340;&#26657;&#27491;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
REMEDI: Corrective Transformations for Improved Neural Entropy Estimation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05718
&lt;/p&gt;
&lt;p&gt;
REMEDI&#26159;&#19968;&#31181;&#29992;&#20110;&#25913;&#36827;&#31070;&#32463;&#29109;&#20272;&#35745;&#30340;&#26657;&#27491;&#36716;&#25442;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#30456;&#23545;&#29109;&#20272;&#35745;&#22522;&#27169;&#22411;&#30340;&#20559;&#24046;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#20219;&#21153;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#24687;&#35770;&#37327;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#25968;&#25454;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#22686;&#21152;&#20351;&#24471;&#20934;&#30830;&#20272;&#35745;&#36825;&#20123;&#37327;&#30340;&#38656;&#27714;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20272;&#35745;&#23384;&#22312;&#37325;&#22823;&#25361;&#25112;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#30456;&#23545;&#36739;&#20302;&#30340;&#32500;&#24230;&#20013;&#24050;&#32463;&#22256;&#38590;&#37325;&#37325;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;REMEDI&#65292;&#29992;&#20110;&#39640;&#25928;&#20934;&#30830;&#22320;&#20272;&#35745;&#24494;&#20998;&#29109;&#65292;&#19968;&#31181;&#22522;&#26412;&#30340;&#20449;&#24687;&#35770;&#37327;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#31616;&#21333;&#33258;&#36866;&#24212;&#22522;&#27169;&#22411;&#30340;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#20854;&#30456;&#23545;&#29109;&#20174;&#25968;&#25454;&#23494;&#24230;&#20013;&#20272;&#35745;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#20272;&#35745;&#20219;&#21153;&#20013;&#24471;&#21040;&#20102;&#25913;&#36827;&#65292;&#21253;&#25324;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#33258;&#28982;&#25968;&#25454;&#30340;&#29109;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#37325;&#35201;&#30340;&#29702;&#35770;&#19968;&#33268;&#24615;&#32467;&#26524;&#25193;&#23637;&#21040;&#25105;&#20204;&#26041;&#27861;&#25152;&#38656;&#30340;&#26356;&#24191;&#20041;&#30340;&#35774;&#32622;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#25552;&#39640;&#29109;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information theoretic quantities play a central role in machine learning. The recent surge in the complexity of data and models has increased the demand for accurate estimation of these quantities. However, as the dimension grows the estimation presents significant challenges, with existing methods struggling already in relatively low dimensions. To address this issue, in this work, we introduce $\texttt{REMEDI}$ for efficient and accurate estimation of differential entropy, a fundamental information theoretic quantity. The approach combines the minimization of the cross-entropy for simple, adaptive base models and the estimation of their deviation, in terms of the relative entropy, from the data density. Our approach demonstrates improvement across a broad spectrum of estimation tasks, encompassing entropy estimation on both synthetic and natural data. Further, we extend important theoretical consistency results to a more generalized setting required by our approach. We illustrate how
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(WCE-GNN)&#23454;&#29616;&#20102;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;WCE-GNN&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.05569</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Hypergraph Node Classification With Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05569
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21033;&#29992;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(WCE-GNN)&#23454;&#29616;&#20102;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;WCE-GNN&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#21644;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36229;&#22270;&#26159;&#29992;&#26469;&#27169;&#25311;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#20013;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#20851;&#38190;&#12290;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#25104;&#21151;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#20855;&#26377;&#25104;&#23545;&#20132;&#20114;&#30340;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#36825;&#28608;&#21457;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#20855;&#26377;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#25968;&#25454;&#30340;&#24819;&#27861;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#36229;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;HyperGNNs&#65289;&#30340;&#21457;&#23637;&#12290;GNNs&#21644;HyperGNNs&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19981;&#21516;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#34987;&#35774;&#35745;&#29992;&#20110;&#22788;&#29702;&#19981;&#21516;&#20960;&#20309;&#25299;&#25169;&#30340;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#22312;&#33410;&#28857;&#20998;&#31867;&#30340;&#19978;&#19979;&#25991;&#20013;&#65292;&#22823;&#22810;&#25968;HyperGNNs&#21487;&#20197;&#20351;&#29992;&#24102;&#26377;&#36229;&#22270;&#30340;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#30340;GNN&#26469;&#36817;&#20284;&#12290;&#36825;&#23548;&#33268;&#20102;WCE-GNN&#65292;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19968;&#20010;GNN&#21644;&#19968;&#20010;&#21152;&#26435;&#23376;&#22270;&#25193;&#23637;&#65288;WCE&#65289;&#65292;&#29992;&#20110;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#12290;&#23545;&#20110;&#20061;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#36229;&#22270;&#33410;&#28857;&#20998;&#31867;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;WCE-GNN&#19981;&#20165;&#20855;&#26377;&#20248;&#31168;&#30340;&#39044;&#27979;&#25928;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypergraphs, with hyperedges connecting more than two nodes, are key for modelling higher-order interactions in real-world data. The success of graph neural networks (GNNs) reveals the capability of neural networks to process data with pairwise interactions. This inspires the usage of neural networks for data with higher-order interactions, thereby leading to the development of hypergraph neural networks (HyperGNNs). GNNs and HyperGNNs are typically considered distinct since they are designed for data on different geometric topologies. However, in this paper, we theoretically demonstrate that, in the context of node classification, most HyperGNNs can be approximated using a GNN with a weighted clique expansion of the hypergraph. This leads to WCE-GNN, a simple and efficient framework comprising a GNN and a weighted clique expansion (WCE), for hypergraph node classification. Experiments on nine real-world hypergraph node classification benchmarks showcase that WCE-GNN demonstrates not o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#21644;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#27973;&#26174;&#24335;&#32593;&#32476;&#26469;&#23454;&#29616;&#19982;&#32473;&#23450;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#30456;&#21516;&#30340;&#29305;&#24449;&#20809;&#35889;&#34892;&#20026;&#12290;</title><link>https://arxiv.org/abs/2402.02697</link><description>&lt;p&gt;
&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#19982;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#19981;&#22826;&#28145;&#30340;&#26174;&#24335;&#27169;&#22411;&#20960;&#20046;&#31561;&#20215;
&lt;/p&gt;
&lt;p&gt;
Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models for High-dimensional Gaussian Mixtures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#21644;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;&#35774;&#35745;&#27973;&#26174;&#24335;&#32593;&#32476;&#26469;&#23454;&#29616;&#19982;&#32473;&#23450;&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#30456;&#21516;&#30340;&#29305;&#24449;&#20809;&#35889;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#22343;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#20316;&#20026;&#20856;&#22411;&#30340;&#38544;&#24335;&#31070;&#32463;&#32593;&#32476;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#26174;&#30528;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#38544;&#24335;DEQ&#21644;&#26174;&#24335;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20043;&#38388;&#30340;&#36830;&#25509;&#21644;&#24046;&#24322;&#32570;&#20047;&#29702;&#35770;&#19978;&#30340;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20511;&#37492;&#26368;&#36817;&#22312;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#23545;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36755;&#20837;&#25968;&#25454;&#19979;&#65292;&#38544;&#24335;DEQ&#30340;&#20849;&#36717;&#26680;&#65288;CK&#65289;&#21644;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#30697;&#38453;&#30340;&#29305;&#24449;&#20809;&#35889;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#35777;&#26126;&#20102;&#36825;&#20123;&#38544;&#24335;-CKs&#21644;NTKs&#30340;&#20809;&#35889;&#34892;&#20026;&#21462;&#20915;&#20110;DEQ&#28608;&#27963;&#20989;&#25968;&#21644;&#21021;&#22987;&#26435;&#37325;&#26041;&#24046;&#65292;&#20294;&#20165;&#36890;&#36807;&#19968;&#32452;&#22235;&#20010;&#38750;&#32447;&#24615;&#26041;&#31243;&#12290;&#20316;&#20026;&#36825;&#19968;&#29702;&#35770;&#32467;&#26524;&#30340;&#30452;&#25509;&#24433;&#21709;&#65292;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#31934;&#24515;&#35774;&#35745;&#19968;&#20010;&#27973;&#26174;&#24335;&#32593;&#32476;&#26469;&#20135;&#29983;&#19982;&#32473;&#23450;DEQ&#30456;&#21516;&#30340;CK&#25110;NTK&#12290;&#23613;&#31649;&#36825;&#37324;&#26159;&#38024;&#23545;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#25512;&#23548;&#30340;&#65292;&#32463;&#39564;&#32467;&#26524;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
Deep equilibrium models (DEQs), as a typical implicit neural network, have demonstrated remarkable success on various tasks. There is, however, a lack of theoretical understanding of the connections and differences between implicit DEQs and explicit neural network models. In this paper, leveraging recent advances in random matrix theory (RMT), we perform an in-depth analysis on the eigenspectra of the conjugate kernel (CK) and neural tangent kernel (NTK) matrices for implicit DEQs, when the input data are drawn from a high-dimensional Gaussian mixture. We prove, in this setting, that the spectral behavior of these Implicit-CKs and NTKs depend on the DEQ activation function and initial weight variances, but only via a system of four nonlinear equations. As a direct consequence of this theoretical result, we demonstrate that a shallow explicit network can be carefully designed to produce the same CK or NTK as a given DEQ. Despite derived here for Gaussian mixture data, empirical results 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#36716;&#21270;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#27492;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.16655</link><description>&lt;p&gt;
&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#26500;&#24314;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rademacher Complexity of Neural ODEs via Chen-Fliess Series. (arXiv:2401.16655v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#36716;&#21270;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#27492;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#36830;&#32493;&#28145;&#24230;&#31070;&#32463;ODE&#27169;&#22411;&#20351;&#29992;Chen-Fliess&#24207;&#21015;&#23637;&#24320;&#20026;&#21333;&#23618;&#12289;&#26080;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#12290;&#22312;&#36825;&#20010;&#32593;&#32476;&#20013;&#65292;&#36755;&#20986;&#30340;&#8220;&#26435;&#37325;&#8221;&#26469;&#33258;&#25511;&#21046;&#36755;&#20837;&#30340;&#29305;&#24449;&#24207;&#21015;&#65292;&#23427;&#30001;&#25511;&#21046;&#36755;&#20837;&#22312;&#21333;&#32431;&#24418;&#19978;&#30340;&#36845;&#20195;&#31215;&#20998;&#26500;&#25104;&#12290;&#32780;&#8220;&#29305;&#24449;&#8221;&#21017;&#22522;&#20110;&#21463;&#25511;ODE&#27169;&#22411;&#20013;&#36755;&#20986;&#20989;&#25968;&#30456;&#23545;&#20110;&#21521;&#37327;&#22330;&#30340;&#36845;&#20195;&#26446;&#23548;&#25968;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#24212;&#29992;&#36825;&#20010;&#26694;&#26550;&#25512;&#23548;&#20986;&#20102;&#23558;&#21021;&#22987;&#26465;&#20214;&#26144;&#23556;&#21040;&#26576;&#20010;&#32456;&#31471;&#26102;&#38388;&#30340;ODE&#27169;&#22411;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#32039;&#20945;&#34920;&#36798;&#24335;&#12290;&#36825;&#19968;&#32467;&#26524;&#21033;&#29992;&#20102;&#21333;&#23618;&#32467;&#26500;&#25152;&#24102;&#26469;&#30340;&#30452;&#25509;&#20998;&#26512;&#24615;&#36136;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20123;&#20855;&#20307;&#31995;&#32479;&#30340;&#20363;&#23376;&#23454;&#20363;&#21270;&#35813;&#30028;&#65292;&#24182;&#35752;&#35770;&#20102;&#21487;&#33021;&#30340;&#21518;&#32493;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how continuous-depth neural ODE models can be framed as single-layer, infinite-width nets using the Chen--Fliess series expansion for nonlinear ODEs. In this net, the output ''weights'' are taken from the signature of the control input -- a tool used to represent infinite-dimensional paths as a sequence of tensors -- which comprises iterated integrals of the control input over a simplex. The ''features'' are taken to be iterated Lie derivatives of the output function with respect to the vector fields in the controlled ODE model. The main result of this work applies this framework to derive compact expressions for the Rademacher complexity of ODE models that map an initial condition to a scalar output at some terminal time. The result leverages the straightforward analysis afforded by single-layer architectures. We conclude with some examples instantiating the bound for some specific systems and discuss potential follow-up work.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15771</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#25968;&#25454;&#39537;&#21160;&#40065;&#26834;&#20248;&#21270;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#36890;&#24120;&#28041;&#21450;&#20248;&#21270;&#25968;&#25454;&#39537;&#21160;&#30340;&#39118;&#38505;&#20934;&#21017;&#12290;&#39118;&#38505;&#36890;&#24120;&#26159;&#26681;&#25454;&#32463;&#39564;&#25968;&#25454;&#20998;&#24067;&#35745;&#31639;&#30340;&#65292;&#20294;&#30001;&#20110;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#31283;&#23450;&#21644;&#19981;&#22909;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#40065;&#26834;&#20934;&#21017;&#65292;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#65288;&#21363;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65289;&#29702;&#35770;&#21644;&#26368;&#36817;&#30340;&#24179;&#28369;&#27169;&#31946;&#35268;&#36991;&#20559;&#22909;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30340;&#35265;&#35299;&#30456;&#32467;&#21512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#30340;&#26032;&#36830;&#25509;&#65292;&#20854;&#20013;&#21253;&#25324;&#23725;&#22238;&#24402;&#21644;&#22871;&#32034;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#40065;&#26834;&#20248;&#21270;&#36807;&#31243;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#32479;&#35745;&#20445;&#35777;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#23384;&#22312;&#12290;&#23545;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#34920;&#31034;&#30340;&#21487;&#34892;&#36817;&#20284;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
&lt;/p&gt;</description></item><item><title>MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.13459</link><description>&lt;p&gt;
&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#25972;&#21512;&#23616;&#37096;&#21644;&#20840;&#23616;&#20449;&#24687;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Model-Agnostic Graph Neural Network for Integrating Local and Global Information. (arXiv:2309.13459v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13459
&lt;/p&gt;
&lt;p&gt;
MaGNet&#26159;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#21508;&#31181;&#20197;&#22270;&#20026;&#37325;&#28857;&#30340;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;GNN&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#38480;&#21046;&#65306;&#30001;&#20110;&#40657;&#30418;&#29305;&#24615;&#65292;&#32467;&#26524;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#65307;&#26080;&#27861;&#23398;&#20064;&#19981;&#21516;&#39034;&#24207;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#26080;&#20851;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MaGNet&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#39034;&#24207;&#22320;&#25972;&#21512;&#19981;&#21516;&#39034;&#24207;&#30340;&#20449;&#24687;&#65292;&#20174;&#39640;&#38454;&#37051;&#23621;&#20013;&#25552;&#21462;&#30693;&#35782;&#65292;&#24182;&#36890;&#36807;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#32039;&#20945;&#22270;&#32467;&#26500;&#25552;&#20379;&#26377;&#24847;&#20041;&#19988;&#21487;&#35299;&#37322;&#30340;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;MaGNet&#30001;&#20004;&#20010;&#32452;&#20214;&#32452;&#25104;&#65306;&#22270;&#25299;&#25169;&#19979;&#22797;&#26434;&#20851;&#31995;&#30340;&#28508;&#22312;&#34920;&#31034;&#30340;&#20272;&#35745;&#27169;&#22411;&#21644;&#35782;&#21035;&#26377;&#24433;&#21709;&#21147;&#30340;&#33410;&#28857;&#12289;&#36793;&#21644;&#37325;&#35201;&#33410;&#28857;&#29305;&#24449;&#30340;&#35299;&#37322;&#27169;&#22411;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#24314;&#31435;&#20102;MaGNet&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#24378;&#22823;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have achieved promising performance in a variety of graph-focused tasks. Despite their success, existing GNNs suffer from two significant limitations: a lack of interpretability in results due to their black-box nature, and an inability to learn representations of varying orders. To tackle these issues, we propose a novel Model-agnostic Graph Neural Network (MaGNet) framework, which is able to sequentially integrate information of various orders, extract knowledge from high-order neighbors, and provide meaningful and interpretable results by identifying influential compact graph structures. In particular, MaGNet consists of two components: an estimation model for the latent representation of complex relationships under graph topology, and an interpretation model that identifies influential nodes, edges, and important node features. Theoretically, we establish the generalization error bound for MaGNet via empirical Rademacher complexity, and showcase its pow
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#30340;&#21442;&#25968;&#20272;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2307.04191</link><description>&lt;p&gt;
&#20851;&#20110;&#36923;&#36753;&#22238;&#24402;&#20013;&#21442;&#25968;&#20272;&#35745;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the sample complexity of estimation in logistic regression. (arXiv:2307.04191v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#30340;&#21442;&#25968;&#20272;&#35745;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#21457;&#29616;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#26159;&#22122;&#22768;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#20013;&#26368;&#24120;&#35265;&#30340;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#20043;&#19968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26631;&#20934;&#27491;&#24577;&#21327;&#21464;&#37327;&#19979;&#65292;&#20197;$\ell_2$&#35823;&#24046;&#20026;&#38480;&#65292;&#20272;&#35745;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#21442;&#25968;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#32771;&#34385;&#20102;&#32500;&#24230;&#21644;&#36870;&#28201;&#24230;&#30340;&#24433;&#21709;&#12290;&#36870;&#28201;&#24230;&#25511;&#21046;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#20449;&#22122;&#27604;&#12290;&#34429;&#28982;&#36923;&#36753;&#22238;&#24402;&#30340;&#24191;&#20041;&#30028;&#38480;&#21644;&#28176;&#36817;&#24615;&#33021;&#24050;&#32463;&#26377;&#20102;&#28145;&#20837;&#30740;&#31350;&#65292;&#20294;&#20851;&#20110;&#21442;&#25968;&#20272;&#35745;&#30340;&#38750;&#28176;&#36817;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#20043;&#21069;&#30340;&#20998;&#26512;&#20013;&#27809;&#26377;&#35752;&#35770;&#20854;&#19982;&#35823;&#24046;&#21644;&#36870;&#28201;&#24230;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#26354;&#32447;&#22312;&#36870;&#28201;&#24230;&#26041;&#38754;&#20855;&#26377;&#20004;&#20010;&#36716;&#25240;&#28857;&#65288;&#25110;&#20020;&#30028;&#28857;&#65289;&#65292;&#26126;&#30830;&#21010;&#20998;&#20102;&#20302;&#12289;&#20013;&#21644;&#39640;&#28201;&#24230;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
The logistic regression model is one of the most popular data generation model in noisy binary classification problems. In this work, we study the sample complexity of estimating the parameters of the logistic regression model up to a given $\ell_2$ error, in terms of the dimension and the inverse temperature, with standard normal covariates. The inverse temperature controls the signal-to-noise ratio of the data generation process. While both generalization bounds and asymptotic performance of the maximum-likelihood estimator for logistic regression are well-studied, the non-asymptotic sample complexity that shows the dependence on error and the inverse temperature for parameter estimation is absent from previous analyses. We show that the sample complexity curve has two change-points (or critical points) in terms of the inverse temperature, clearly separating the low, moderate, and high temperature regimes.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#24212;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20449;&#24230;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#40657;&#30418;&#27169;&#22411;&#20013;&#32622;&#20449;&#24230;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#36873;&#25321;&#24615;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2305.19187</link><description>&lt;p&gt;
&#29983;&#25104;&#21487;&#20449;&#30340;&#25991;&#26412;&#65306;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generating with Confidence: Uncertainty Quantification for Black-box Large Language Models. (arXiv:2305.19187v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#24212;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20449;&#24230;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#30740;&#31350;&#40657;&#30418;&#27169;&#22411;&#20013;&#32622;&#20449;&#24230;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#36873;&#25321;&#24615;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#65292;&#19987;&#38376;&#29992;&#20110;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#21508;&#20010;&#39046;&#22495;&#34920;&#29616;&#20986;&#20102;&#24456;&#22909;&#30340;&#33021;&#21147;&#65292;&#20294;&#26159;&#35780;&#20272;LLMs&#29983;&#25104;&#30340;&#32467;&#26524;&#30340;&#21487;&#20449;&#24230;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#20851;&#20110;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#30740;&#31350;&#20063;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#25991;&#29486;&#36890;&#24120;&#20551;&#23450;&#23545;&#35821;&#35328;&#27169;&#22411;&#30340;&#30333;&#30418;&#35775;&#38382;&#65292;&#36825;&#35201;&#20040;&#26159;&#30001;&#20110;&#26368;&#26032;&#30340;LLMs&#30340;&#23553;&#38381;&#28304;&#20195;&#30721;&#30340;&#24615;&#36136;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#35745;&#31639;&#38480;&#21046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#40657;&#30418;LLMs&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#21306;&#20998;&#20102;&#20004;&#31181;&#23494;&#20999;&#30456;&#20851;&#30340;&#27010;&#24565;: &#21482;&#19982;&#36755;&#20837;&#26377;&#20851;&#30340;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#21644;&#36824;&#19982;&#29983;&#25104;&#30340;&#22238;&#22797;&#26377;&#20851;&#30340;&#8220;&#32622;&#20449;&#24230;&#8221;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#20960;&#20010;&#32622;&#20449;&#24230;/&#19981;&#30830;&#23450;&#24230;&#25351;&#26631;&#65292;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#8220;&#36873;&#25321;&#24615;&#33258;&#28982;&#35821;&#35328;&#29983;&#25104;&#8221;&#65292;&#20854;&#20013;&#19981;&#21487;&#38752;&#30340;&#32467;&#26524;&#21487;&#20197;&#34987;&#24573;&#30053;&#25110;&#32773;&#31227;&#20132;&#32473;&#36827;&#19968;&#27493;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) specializing in natural language generation (NLG) have recently started exhibiting promising capabilities across a variety of domains. However, gauging the trustworthiness of responses generated by LLMs remains an open challenge, with limited research on uncertainty quantification for NLG. Furthermore, existing literature typically assumes white-box access to language models, which is becoming unrealistic either due to the closed-source nature of the latest LLMs or due to computational constraints. In this work, we investigate uncertainty quantification in NLG for $\textit{black-box}$ LLMs. We first differentiate two closely-related notions: $\textit{uncertainty}$, which depends only on the input, and $\textit{confidence}$, which additionally depends on the generated response. We then propose and compare several confidence/uncertainty metrics, applying them to $\textit{selective NLG}$, where unreliable results could either be ignored or yielded for further 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#25512;&#24191;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#30740;&#31350;&#20102;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#24182;&#34920;&#24449;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#35777;&#26126;&#20102;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;Nesterov&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30830;&#23450;&#20986;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2305.08658</link><description>&lt;p&gt;
&#20851;&#20110;&#20248;&#21270;&#31639;&#27861;&#12289;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#21644;&#24494;&#20998;&#26041;&#31243;&#30340;&#32852;&#31995;&#65306;&#29702;&#35770;&#19982;&#27934;&#35265;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the connections between optimization algorithms, Lyapunov functions, and differential equations: theory and insights. (arXiv:2305.08658v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#25512;&#24191;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#65292;&#30740;&#31350;&#20102;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#24182;&#34920;&#24449;&#20854;&#25910;&#25947;&#36895;&#24230;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#35777;&#26126;&#20102;&#26377;&#26174;&#33879;&#25913;&#36827;&#30340;Nesterov&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#30830;&#23450;&#20986;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25512;&#24191;Fazylab&#31561;&#20154;&#22312;2018&#24180;&#21457;&#23637;&#30340;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#26694;&#26550;&#65292;&#30740;&#31350;&#20102;&#29992;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#30740;&#31350;$m$-&#24378;&#20984;&#21644;$L$-&#20809;&#28369;&#20989;&#25968;&#30340;&#24494;&#20998;&#26041;&#31243;&#21644;&#20248;&#21270;&#31639;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#20351;&#29992;&#26032;&#26694;&#26550;&#65292;&#25105;&#20204;&#38024;&#23545;&#19968;&#20010;&#20004;&#21442;&#25968;Nesterov&#20248;&#21270;&#26041;&#27861;&#23478;&#26063;&#30340;&#26032;&#22411;&#65288;&#31163;&#25955;&#65289;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#36827;&#34892;&#20102;&#35299;&#26512;&#25512;&#23548;&#65292;&#24182;&#34920;&#24449;&#20102;&#20854;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#23545;&#20110;&#26631;&#20934;&#31995;&#25968;&#30340;Nesterov&#26041;&#27861;&#30340;&#20808;&#21069;&#35777;&#26126;&#36895;&#24230;&#26377;&#20102;&#26126;&#26174;&#25913;&#36827;&#65292;&#24182;&#19988;&#34920;&#24449;&#20102;&#20135;&#29983;&#26368;&#20339;&#36895;&#24230;&#30340;&#31995;&#25968;&#36873;&#25321;&#12290;&#25105;&#20204;&#20026;Polyak ODE&#33719;&#24471;&#20102;&#26032;&#30340;&#26446;&#20122;&#26222;&#35834;&#22827;&#20989;&#25968;&#65292;&#24182;&#37325;&#26032;&#23457;&#35270;&#20102;&#27492;ODE&#19982;Nesterov&#31639;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#27492;&#22806;&#65292;&#35752;&#35770;&#20102;&#23558;Nesterov&#26041;&#27861;&#35299;&#37322;&#20026;&#21152;&#24615;Runge-Kutta&#31163;&#25955;&#21270;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#35299;&#37322;&#20102;&#31163;&#25955;&#21270;Polyak&#26041;&#31243;&#30340;&#32467;&#26500;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study connections between differential equations and optimization algorithms for $m$-strongly and $L$-smooth convex functions through the use of Lyapunov functions by generalizing the Linear Matrix Inequality framework developed by Fazylab et al. in 2018. Using the new framework we derive analytically a new (discrete) Lyapunov function for a two-parameter family of Nesterov optimization methods and characterize their convergence rate. This allows us to prove a convergence rate that improves substantially on the previously proven rate of Nesterov's method for the standard choice of coefficients, as well as to characterize the choice of coefficients that yields the optimal rate. We obtain a new Lyapunov function for the Polyak ODE and revisit the connection between this ODE and the Nesterov's algorithms. In addition discuss a new interpretation of Nesterov method as an additive Runge-Kutta discretization and explain the structural conditions that discretizations of the Polyak equation
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#22312;&#19968;&#23450;&#29366;&#24577;&#19979;&#30340;&#25910;&#25947;&#27010;&#29575;&#20026;1&#65292;&#24314;&#31435;&#20102;QTD&#19982;&#38750;&#32447;&#24615;&#24494;&#20998;&#21253;&#21547;&#24335;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2301.04462</link><description>&lt;p&gt;
&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
An Analysis of Quantile Temporal-Difference Learning. (arXiv:2301.04462v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#22312;&#19968;&#23450;&#29366;&#24577;&#19979;&#30340;&#25910;&#25947;&#27010;&#29575;&#20026;1&#65292;&#24314;&#31435;&#20102;QTD&#19982;&#38750;&#32447;&#24615;&#24494;&#20998;&#21253;&#21547;&#24335;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65306;&#37327;&#21270;&#26102;&#38388;&#24046;&#20998;&#23398;&#20064;&#65288;QTD&#65289;&#65292;&#35813;&#31639;&#27861;&#24050;&#25104;&#20026;&#22810;&#20010;&#25104;&#21151;&#30340;&#24378;&#21270;&#23398;&#20064;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#23613;&#31649;&#22312;&#23454;&#35777;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;QTD&#30340;&#29702;&#35770;&#35748;&#35782;&#19968;&#30452;&#38590;&#20197;&#25417;&#25720;&#12290;&#19982;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#38543;&#26426;&#36924;&#36817;&#24037;&#20855;&#26469;&#36827;&#34892;&#20998;&#26512;&#30340;&#32463;&#20856;TD&#23398;&#20064;&#19981;&#21516;&#65292;QTD&#30340;&#26356;&#26032;&#24182;&#19981;&#36817;&#20284;&#20110;&#25910;&#32553;&#31639;&#23376;&#65292;&#39640;&#24230;&#38750;&#32447;&#24615;&#24182;&#19988;&#21487;&#33021;&#20855;&#26377;&#22810;&#20010;&#19981;&#21160;&#28857;&#12290;&#26412;&#25991;&#30340;&#26680;&#24515;&#32467;&#26524;&#26159;&#35777;&#26126;&#22312;&#19982;&#19968;&#31867;&#21160;&#24577;&#35268;&#21010;&#31243;&#24207;&#30340;&#19981;&#21160;&#28857;&#30456;&#24212;&#30340;&#29366;&#24577;&#19979;&#65292;QTD&#30340;&#25910;&#25947;&#27010;&#29575;&#20026;1&#65292;&#20174;&#32780;&#35753;QTD&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#20102;&#30830;&#23450;&#24615;&#30340;&#22522;&#30784;&#12290;&#35777;&#26126;&#36890;&#36807;&#38543;&#26426;&#36924;&#36817;&#29702;&#35770;&#21644;&#38750;&#20809;&#28369;&#20998;&#26512;&#23558;QTD&#19982;&#38750;&#32447;&#24615;&#24494;&#20998;&#21253;&#21547;&#24335;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyse quantile temporal-difference learning (QTD), a distributional reinforcement learning algorithm that has proven to be a key component in several successful large-scale applications of reinforcement learning. Despite these empirical successes, a theoretical understanding of QTD has proven elusive until now. Unlike classical TD learning, which can be analysed with standard stochastic approximation tools, QTD updates do not approximate contraction mappings, are highly non-linear, and may have multiple fixed points. The core result of this paper is a proof of convergence to the fixed points of a related family of dynamic programming procedures with probability 1, putting QTD on firm theoretical footing. The proof establishes connections between QTD and non-linear differential inclusions through stochastic approximation theory and non-smooth analysis.
&lt;/p&gt;</description></item><item><title>&#21327;&#21464;&#37327;&#36716;&#31227;&#21644;&#23545;&#25239;&#25200;&#21160;&#23545;&#32479;&#35745;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23545;&#22806;&#25512;&#21306;&#22495;&#30340;&#24433;&#21709;&#20197;&#21450;&#20854;&#23545;&#21518;&#32493;&#23398;&#20064;&#30340;&#24179;&#34913;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2212.02457</link><description>&lt;p&gt;
&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#31069;&#31119;&#21644;&#35781;&#21650;&#65306;&#23545;&#25239;&#23398;&#20064;&#21160;&#24577;&#12289;&#26041;&#21521;&#25910;&#25947;&#21644;&#24179;&#34913;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Blessings and Curses of Covariate Shifts: Adversarial Learning Dynamics, Directional Convergence, and Equilibria. (arXiv:2212.02457v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02457
&lt;/p&gt;
&lt;p&gt;
&#21327;&#21464;&#37327;&#36716;&#31227;&#21644;&#23545;&#25239;&#25200;&#21160;&#23545;&#32479;&#35745;&#23398;&#20064;&#30340;&#31283;&#20581;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#20102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23545;&#22806;&#25512;&#21306;&#22495;&#30340;&#24433;&#21709;&#20197;&#21450;&#20854;&#23545;&#21518;&#32493;&#23398;&#20064;&#30340;&#24179;&#34913;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21464;&#37327;&#20998;&#24067;&#36716;&#31227;&#21644;&#23545;&#25239;&#25200;&#21160;&#23545;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#30340;&#31283;&#20581;&#24615;&#25552;&#20986;&#20102;&#25361;&#25112;&#65306;&#27979;&#35797;&#21327;&#21464;&#37327;&#20998;&#24067;&#20013;&#30340;&#36731;&#24494;&#36716;&#31227;&#33021;&#26174;&#33879;&#24433;&#21709;&#22522;&#20110;&#35757;&#32451;&#20998;&#24067;&#23398;&#20064;&#30340;&#32479;&#35745;&#27169;&#22411;&#24615;&#33021;&#12290;&#24403;&#22806;&#25512;&#21457;&#29983;&#26102;&#65292;&#21363;&#21327;&#21464;&#37327;&#36716;&#31227;&#21040;&#35757;&#32451;&#20998;&#24067;&#31232;&#32570;&#30340;&#21306;&#22495;&#26102;&#65292;&#27169;&#22411;&#24615;&#33021;&#36890;&#24120;&#20250;&#38477;&#20302;&#65292;&#22240;&#27492;&#65292;&#23398;&#20064;&#27169;&#22411;&#20449;&#24687;&#24456;&#23569;&#12290;&#20026;&#20102;&#31283;&#20581;&#24615;&#21644;&#27491;&#21017;&#21270;&#32771;&#34385;&#65292;&#24314;&#35758;&#37319;&#29992;&#23545;&#25239;&#25200;&#21160;&#25216;&#26415;&#65292;&#28982;&#32780;&#65292;&#38656;&#35201;&#23545;&#32473;&#23450;&#23398;&#20064;&#27169;&#22411;&#26102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#22806;&#25512;&#21306;&#22495;&#36827;&#34892;&#20180;&#32454;&#30740;&#31350;&#12290;&#26412;&#25991;&#22312;&#26080;&#38480;&#32500;&#24230;&#30340;&#35774;&#32622;&#20013;&#31934;&#30830;&#21051;&#30011;&#20102;&#22806;&#25512;&#21306;&#22495;&#65292;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#26041;&#38754;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#30740;&#31350;&#20102;&#23545;&#25239;&#21327;&#21464;&#37327;&#36716;&#31227;&#23545;&#38543;&#21518;&#30340;&#24179;&#34913;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Covariate distribution shifts and adversarial perturbations present robustness challenges to the conventional statistical learning framework: mild shifts in the test covariate distribution can significantly affect the performance of the statistical model learned based on the training distribution. The model performance typically deteriorates when extrapolation happens: namely, covariates shift to a region where the training distribution is scarce, and naturally, the learned model has little information. For robustness and regularization considerations, adversarial perturbation techniques are proposed as a remedy; however, careful study needs to be carried out about what extrapolation region adversarial covariate shift will focus on, given a learned model. This paper precisely characterizes the extrapolation region, examining both regression and classification in an infinite-dimensional setting. We study the implications of adversarial covariate shifts to subsequent learning of the equi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#20445;&#38505;&#34892;&#19994;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#25968;&#25454;&#20013;&#21457;&#29616;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#65292;&#25552;&#20986;&#20102;&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#29616;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#21516;&#26102;&#20445;&#35777;&#25968;&#25454;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2112.09466</link><description>&lt;p&gt;
&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#65306;&#35299;&#20915;&#20445;&#38505;&#34892;&#19994;&#20013;&#30340;&#26631;&#27880;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fair Active Learning: Solving the Labeling Problem in Insurance. (arXiv:2112.09466v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#20445;&#38505;&#34892;&#19994;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#25968;&#25454;&#20013;&#21457;&#29616;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#65292;&#25552;&#20986;&#20102;&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#23454;&#29616;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#30340;&#21516;&#26102;&#20445;&#35777;&#25968;&#25454;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22312;&#20445;&#38505;&#34892;&#19994;&#24191;&#27867;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#25152;&#38754;&#20020;&#30340;&#37325;&#22823;&#38556;&#30861;&#65292;&#29305;&#21035;&#20851;&#27880;&#20419;&#36827;&#20844;&#24179;&#24615;&#12290;&#26368;&#21021;&#30340;&#25361;&#25112;&#22312;&#20110;&#26377;&#25928;&#21033;&#29992;&#26410;&#26631;&#35760;&#30340;&#20445;&#38505;&#25968;&#25454;&#65292;&#36890;&#36807;&#20027;&#21160;&#23398;&#20064;&#25216;&#26415;&#38477;&#20302;&#26631;&#27880;&#30340;&#24037;&#20316;&#37327;&#65292;&#24182;&#24378;&#35843;&#25968;&#25454;&#30456;&#20851;&#24615;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#21508;&#31181;&#20027;&#21160;&#23398;&#20064;&#25277;&#26679;&#26041;&#27861;&#65292;&#24182;&#35780;&#20272;&#23427;&#20204;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#20445;&#38505;&#25968;&#25454;&#38598;&#30340;&#24433;&#21709;&#12290;&#35813;&#20998;&#26512;&#24378;&#35843;&#20102;&#23454;&#29616;&#20844;&#27491;&#27169;&#22411;&#25512;&#26029;&#30340;&#22256;&#38590;&#65292;&#22240;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#33021;&#20250;&#22797;&#21046;&#24213;&#23618;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#27495;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#30456;&#20114;&#20851;&#32852;&#30340;&#25361;&#25112;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#20844;&#24179;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#37319;&#26679;&#20449;&#24687;&#37327;&#20805;&#36275;&#19988;&#20844;&#24179;&#30340;&#23454;&#20363;&#65292;&#22312;&#27169;&#22411;&#39044;&#27979;&#24615;&#33021;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#65292;&#36825;&#19968;&#28857;&#22312;&#20445;&#38505;&#25968;&#25454;&#38598;&#19978;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses significant obstacles that arise from the widespread use of machine learning models in the insurance industry, with a specific focus on promoting fairness. The initial challenge lies in effectively leveraging unlabeled data in insurance while reducing the labeling effort and emphasizing data relevance through active learning techniques. The paper explores various active learning sampling methodologies and evaluates their impact on both synthetic and real insurance datasets. This analysis highlights the difficulty of achieving fair model inferences, as machine learning models may replicate biases and discrimination found in the underlying data. To tackle these interconnected challenges, the paper introduces an innovative fair active learning method. The proposed approach samples informative and fair instances, achieving a good balance between model predictive performance and fairness, as confirmed by numerical experiments on insurance datasets.
&lt;/p&gt;</description></item></channel></rss>