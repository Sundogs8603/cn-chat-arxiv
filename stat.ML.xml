<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01092</link><description>&lt;p&gt;
&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Dynamical Model of Neural Scaling Laws
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01092
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#38543;&#30528;&#35757;&#32451;&#26102;&#38388;&#12289;&#25968;&#25454;&#38598;&#22823;&#23567;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#39044;&#27979;&#24615;&#22320;&#25552;&#39640;&#65292;&#36328;&#22810;&#20010;&#25968;&#37327;&#32423;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#23450;&#24459;&#65292;&#23427;&#25253;&#21578;&#20102;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#22823;&#23567;&#26102;&#24615;&#33021;&#19982;&#35745;&#31639;&#25968;&#37327;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#20316;&#20026;&#32593;&#32476;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#21487;&#35299;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#22797;&#29616;&#20102;&#20851;&#20110;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#35768;&#22810;&#35266;&#23519;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23545;&#20110;&#20026;&#20160;&#20040;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#25552;&#20986;&#20102;&#19968;&#20010;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#29702;&#35770;&#39044;&#27979;&#20102;&#19968;&#31181;&#19981;&#23545;&#31216;&#30340;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#65292;&#20854;&#20013;&#35757;&#32451;&#27493;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#24555;&#20110;&#27169;&#22411;&#21442;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#65292;&#19982;&#26368;&#36817;&#30340;&#23454;&#35777;&#35266;&#23519;&#19968;&#33268;&#12290;&#20854;&#27425;&#65292;&#35266;&#23519;&#21040;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#65292;&#32593;&#32476;&#20250;&#25910;&#25947;&#21040;&#26080;&#38480;&#23485;&#24230;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#37325;&#24314;&#38454;&#27573;&#21644;&#37325;&#24314;&#25439;&#22833;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#21644;&#29305;&#24449;&#34920;&#31034;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#20849;&#21516;&#20449;&#24687;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#35299;&#20915;&#30456;&#20851;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2404.00505</link><description>&lt;p&gt;
&#20855;&#26377;&#37325;&#24314;&#25439;&#22833;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning with Reconstruction Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#37325;&#24314;&#38454;&#27573;&#21644;&#37325;&#24314;&#25439;&#22833;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#21644;&#29305;&#24449;&#34920;&#31034;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#20849;&#21516;&#20449;&#24687;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#35299;&#20915;&#30456;&#20851;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#22810;&#25968;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25968;&#23398;&#20248;&#21270;&#30340;&#24212;&#29992;&#20013;&#65292;&#36890;&#24120;&#20026;&#27599;&#20010;&#29305;&#23450;&#20248;&#21270;&#30446;&#26631;&#35757;&#32451;&#19968;&#20010;&#19987;&#29992;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#22330;&#26223;&#20013;&#65292;&#21516;&#19968;&#32452;&#38382;&#39064;&#36755;&#20837;&#19978;&#32463;&#24120;&#38656;&#35201;&#20248;&#21270;&#20960;&#20010;&#19981;&#21516;&#20294;&#30456;&#20851;&#30340;&#30446;&#26631;&#25110;&#20219;&#21153;&#12290;&#19982;&#20026;&#27599;&#20010;&#38382;&#39064;&#21333;&#29420;&#35757;&#32451;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#30456;&#27604;&#65292;&#26356;&#26377;&#25928;&#30340;&#26041;&#27861;&#26159;&#21033;&#29992;&#36825;&#20123;&#30446;&#26631;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#20351;&#29992;&#20849;&#20139;&#27169;&#22411;&#21442;&#25968;&#21644;&#29305;&#24449;&#34920;&#31034;&#35757;&#32451;&#22810;&#20010;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#26412;&#25991;&#39318;&#20808;&#24314;&#31435;&#20102;&#20849;&#21516;&#20449;&#24687;&#30340;&#27010;&#24565;&#65306;&#35299;&#20915;&#30456;&#20851;&#20219;&#21153;&#25152;&#38656;&#30340;&#20849;&#20139;&#30693;&#35782;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27169;&#22411;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#27169;&#22411;&#20013;&#28155;&#21152;&#19968;&#20010;&#39069;&#22806;&#30340;&#37325;&#24314;&#38454;&#27573;&#20197;&#21450;&#30456;&#20851;&#30340;&#26032;&#37325;&#24314;&#25439;&#22833;&#12290;&#35813;&#25439;&#22833;&#29992;&#20110;&#20174;&#36873;&#25321;&#30340;&#38544;&#34255;&#29366;&#24577;&#24320;&#22987;&#37325;&#26032;&#26500;&#24314;&#20849;&#21516;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00505v1 Announce Type: cross  Abstract: In most applications of utilizing neural networks for mathematical optimization, a dedicated model is trained for each specific optimization objective. However, in many scenarios, several distinct yet correlated objectives or tasks often need to be optimized on the same set of problem inputs. Instead of independently training a different neural network for each problem separately, it would be more efficient to exploit the correlations between these objectives and to train multiple neural network models with shared model parameters and feature representations. To achieve this, this paper first establishes the concept of common information: the shared knowledge required for solving the correlated tasks, then proposes a novel approach for model training by adding into the model an additional reconstruction stage associated with a new reconstruction loss. This loss is for reconstructing the common information starting from a selected hidde
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.06499</link><description>&lt;p&gt;
TaCo&#65306;&#36890;&#36807;&#20449;&#24687;&#35770;&#21644;&#21487;&#35299;&#37322;&#24615;&#22312;NLP&#20013;&#30340;&#36755;&#20986;&#23884;&#20837;&#20013;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#27010;&#24565;&#21435;&#38500;
&lt;/p&gt;
&lt;p&gt;
TaCo: Targeted Concept Removal in Output Embeddings for NLP via Information Theory and Explainability. (arXiv:2312.06499v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.06499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20449;&#24687;&#35770;&#34920;&#26126;&#65292;&#20026;&#20102;&#23454;&#29616;&#20844;&#24179;&#24615;&#65292;&#27169;&#22411;&#19981;&#24212;&#33021;&#22815;&#39044;&#27979;&#25935;&#24863;&#21464;&#37327;&#65292;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#24180;&#40836;&#12290;&#28982;&#32780;&#65292;&#19982;&#36825;&#20123;&#21464;&#37327;&#30456;&#20851;&#30340;&#20449;&#24687;&#36890;&#24120;&#20197;&#38544;&#24335;&#30340;&#26041;&#24335;&#20986;&#29616;&#22312;&#35821;&#35328;&#20013;&#65292;&#36825;&#32473;&#35782;&#21035;&#21644;&#20943;&#23569;&#20559;&#35265;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#22312;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#19978;&#25805;&#20316;&#65292;&#29420;&#31435;&#20110;&#20855;&#20307;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#26368;&#36817;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24182;&#37319;&#29992;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#36873;&#23450;&#21464;&#37327;&#20013;&#30340;&#38544;&#24335;&#20449;&#24687;&#12290;&#36890;&#36807;&#30452;&#25509;&#25805;&#32437;&#26368;&#21518;&#19968;&#23618;&#30340;&#23884;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21040;&#29616;&#26377;&#27169;&#22411;&#20013;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#37325;&#22823;&#20462;&#25913;&#25110;&#37325;&#35757;&#32451;&#12290;&#22312;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#21518;&#22788;&#29702;&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fairness of Natural Language Processing (NLP) models has emerged as a crucial concern. Information theory indicates that to achieve fairness, a model should not be able to predict sensitive variables, such as gender, ethnicity, and age. However, information related to these variables often appears implicitly in language, posing a challenge in identifying and mitigating biases effectively. To tackle this issue, we present a novel approach that operates at the embedding level of an NLP model, independent of the specific architecture. Our method leverages insights from recent advances in XAI techniques and employs an embedding transformation to eliminate implicit information from a selected variable. By directly manipulating the embeddings in the final layer, our approach enables a seamless integration into existing models without requiring significant modifications or retraining. In evaluation, we show that the proposed post-hoc approach significantly reduces gender-related associati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26500;&#24314;&#20102;&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;&#26041;&#27861;&#65292;&#20351;&#29992;&#22240;&#26524;&#21367;&#31215;&#24182;&#34892;&#35780;&#20272;&#25972;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#20284;&#28982;&#65292;&#23454;&#29616;&#20102;&#23545;&#29983;&#24577;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#24182;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.12544</link><description>&lt;p&gt;
&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
Neural Likelihood Approximation for Integer Valued Time Series Data. (arXiv:2310.12544v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26500;&#24314;&#20102;&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;&#26041;&#27861;&#65292;&#20351;&#29992;&#22240;&#26524;&#21367;&#31215;&#24182;&#34892;&#35780;&#20272;&#25972;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#20284;&#28982;&#65292;&#23454;&#29616;&#20102;&#23545;&#29983;&#24577;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#36827;&#34892;&#20934;&#30830;&#25512;&#26029;&#24182;&#26174;&#33879;&#21152;&#24555;&#35745;&#31639;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29289;&#29702;&#21644;&#29983;&#29289;&#31185;&#23398;&#20013;&#65292;&#23450;&#20041;&#22312;&#25972;&#25968;&#20540;&#29366;&#24577;&#31354;&#38388;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#24456;&#24120;&#35265;&#12290;&#36825;&#20123;&#27169;&#22411;&#29992;&#20110;&#25429;&#25417;&#23567;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#20854;&#20013;&#20010;&#20307;&#32676;&#20307;&#30340;&#20010;&#20307;&#23646;&#24615;&#19981;&#33021;&#34987;&#24573;&#35270;&#65292;&#38543;&#26426;&#25928;&#24212;&#24456;&#37325;&#35201;&#12290;&#30001;&#20110;&#20284;&#28982;&#30340;&#22797;&#26434;&#24615;&#65292;&#20174;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#25512;&#26029;&#36825;&#20123;&#27169;&#22411;&#30340;&#21442;&#25968;&#26159;&#22256;&#38590;&#30340;&#65307;&#30446;&#21069;&#30340;&#26041;&#27861;&#22522;&#20110;&#22522;&#30784;&#27169;&#22411;&#30340;&#27169;&#25311;&#65292;&#35745;&#31639;&#25104;&#26412;&#38750;&#24120;&#39640;&#26114;&#65292;&#20197;&#33267;&#20110;&#38590;&#20197;&#23454;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#22240;&#26524;&#21367;&#31215;&#26500;&#24314;&#20102;&#29992;&#20110;&#25972;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#31070;&#32463;&#20284;&#28982;&#36817;&#20284;&#26041;&#27861;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#24182;&#34892;&#35780;&#20272;&#25972;&#20010;&#26102;&#38388;&#24207;&#21015;&#30340;&#20284;&#28982;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19968;&#20123;&#29983;&#24577;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#36827;&#34892;&#25512;&#26029;&#26469;&#28436;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#33021;&#22815;&#20934;&#30830;&#22320;&#36817;&#20284;&#30495;&#23454;&#30340;&#21518;&#39564;&#27010;&#29575;&#65292;&#21516;&#26102;&#22312;&#24403;&#21069;&#26041;&#27861;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#26174;&#33879;&#30340;&#35745;&#31639;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic processes defined on integer valued state spaces are popular within the physical and biological sciences. These models are necessary for capturing the dynamics of small systems where the individual nature of the populations cannot be ignored and stochastic effects are important. The inference of the parameters of such models, from time series data, is difficult due to intractability of the likelihood; current methods, based on simulations of the underlying model, can be so computationally expensive as to be prohibitive. In this paper we construct a neural likelihood approximation for integer valued time series data using causal convolutions, which allows us to evaluate the likelihood of the whole time series in parallel. We demonstrate our method by performing inference on a number of ecological and epidemiological models, showing that we can accurately approximate the true posterior while achieving significant computational speed ups in situations where current methods stru
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25490;&#21517;&#20013;&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#38382;&#39064;&#19982;Top-k&#21453;&#39304;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#30340;&#26497;&#22823;&#21518;&#24724;&#29575;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;Chaudhuri&#21644;Tewari [2017]&#25152;&#25552;&#20986;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.02425</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#25490;&#21517;&#20013;&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#38382;&#39064;&#19982;Top-k&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
On the Minimax Regret in Online Ranking with Top-k Feedback. (arXiv:2309.02425v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25490;&#21517;&#20013;&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#38382;&#39064;&#19982;Top-k&#21453;&#39304;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#20840;&#38754;&#30340;&#26497;&#22823;&#21518;&#24724;&#29575;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;Chaudhuri&#21644;Tewari [2017]&#25152;&#25552;&#20986;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#25490;&#21517;&#20013;&#65292;&#23398;&#20064;&#31639;&#27861;&#25353;&#39034;&#24207;&#23545;&#19968;&#32452;&#39033;&#30446;&#36827;&#34892;&#25490;&#21517;&#65292;&#24182;&#20197;&#30456;&#20851;&#24615;&#24471;&#20998;&#30340;&#24418;&#24335;&#25509;&#25910;&#21453;&#39304;&#12290;&#30001;&#20110;&#33719;&#24471;&#30456;&#20851;&#24615;&#24471;&#20998;&#36890;&#24120;&#28041;&#21450;&#20154;&#24037;&#27880;&#37322;&#65292;&#22240;&#27492;&#32771;&#34385;&#20165;&#23545;&#25490;&#21517;&#20013;&#30340;&#21069;k&#20010;&#39033;&#30446;&#38480;&#21046;&#21453;&#39304;&#30340;&#37096;&#20998;&#21453;&#39304;&#35774;&#32622;&#20855;&#26377;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;Chaudhuri&#21644;Tewari [2017]&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#20998;&#26512;&#24102;&#26377;Top $k$&#21453;&#39304;&#30340;&#22312;&#32447;&#25490;&#21517;&#31639;&#27861;&#12290;&#20182;&#20204;&#24037;&#20316;&#30340;&#20851;&#38190;&#35201;&#32032;&#26159;&#20351;&#29992;&#20102;&#37096;&#20998;&#30417;&#25511;&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20855;&#26377;Top $k$&#21453;&#39304;&#30340;&#22312;&#32447;&#25490;&#21517;&#65292;&#24182;&#35299;&#20915;&#20102;Chaudhuri&#21644;Tewari [2017]&#25552;&#20986;&#30340;&#19968;&#20123;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#25152;&#26377;$k$&#21644;&#20197;&#19979;&#25490;&#21517;&#24615;&#33021;&#24230;&#37327;&#65288;Pairwise Loss&#65292;Discounted Cumulative Gain&#21644;Precision@n&#65289;&#30340;Top $k$&#21453;&#39304;&#27169;&#22411;&#36827;&#34892;&#20102;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#29575;&#30340;&#23436;&#20840;&#21051;&#30011;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23454;&#29616;&#20102;Precision@n&#30340;&#26368;&#23567;&#26497;&#22823;&#21518;&#24724;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online ranking, a learning algorithm sequentially ranks a set of items and receives feedback on its ranking in the form of relevance scores. Since obtaining relevance scores typically involves human annotation, it is of great interest to consider a partial feedback setting where feedback is restricted to the top-$k$ items in the rankings. Chaudhuri and Tewari [2017] developed a framework to analyze online ranking algorithms with top $k$ feedback. A key element in their work was the use of techniques from partial monitoring. In this paper, we further investigate online ranking with top $k$ feedback and solve some open problems posed by Chaudhuri and Tewari [2017]. We provide a full characterization of minimax regret rates with the top $k$ feedback model for all $k$ and for the following ranking performance measures: Pairwise Loss, Discounted Cumulative Gain, and Precision@n. In addition, we give an efficient algorithm that achieves the minimax regret rate for Precision@n.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#21464;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#24191;&#27867;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#36827;&#34892;&#24555;&#36895;&#31354;&#38388;&#24314;&#27169;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#21644;&#21152;&#36895;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.14142</link><description>&lt;p&gt;
&#24555;&#36895;&#31354;&#38388;&#24314;&#27169;&#30340;&#32508;&#21512;&#21464;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Integrated Variational Fourier Features for Fast Spatial Modelling with Gaussian Processes. (arXiv:2308.14142v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14142
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#21464;&#20998;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#24191;&#27867;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#36827;&#34892;&#24555;&#36895;&#31354;&#38388;&#24314;&#27169;&#65292;&#30456;&#27604;&#20854;&#20182;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#21644;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#21464;&#20998;&#36924;&#36817;&#26159;&#25193;&#23637;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#21644;&#23398;&#20064;&#33267;&#26356;&#22823;&#25968;&#25454;&#38598;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#23545;&#20110;$N$&#20010;&#35757;&#32451;&#28857;&#65292;&#31934;&#30830;&#25512;&#29702;&#30340;&#25104;&#26412;&#20026;$O(N^3)$&#65307;&#20351;&#29992;$M \ll N$&#29305;&#24449;&#30340;&#20808;&#36827;&#31232;&#30095;&#21464;&#20998;&#26041;&#27861;&#25104;&#26412;&#20026;$O(NM^2)$&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#26356;&#22797;&#26434;&#29305;&#24449;&#30340;&#26041;&#27861;&#65307;&#36825;&#20123;&#26041;&#27861;&#22312;&#20302;&#32500;&#20219;&#21153;&#65288;&#22914;&#31354;&#38388;&#24314;&#27169;&#65289;&#20013;&#33021;&#22815;&#26377;&#24456;&#22909;&#30340;&#24615;&#33021;&#65292;&#20294;&#21482;&#20351;&#29992;&#20102;&#19968;&#31867;&#38750;&#24120;&#26377;&#38480;&#30340;&#26680;&#20989;&#25968;&#65292;&#25490;&#38500;&#20102;&#19968;&#20123;&#24120;&#29992;&#30340;&#26680;&#20989;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32508;&#21512;&#20613;&#37324;&#21494;&#29305;&#24449;&#65292;&#23558;&#36825;&#20123;&#24615;&#33021;&#20248;&#21183;&#25193;&#23637;&#21040;&#38750;&#24120;&#24191;&#27867;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#12290;&#25105;&#20204;&#20174;&#25910;&#25947;&#20998;&#26512;&#21644;&#32463;&#39564;&#25506;&#32034;&#30340;&#35282;&#24230;&#26469;&#35299;&#37322;&#35813;&#26041;&#27861;&#21644;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#21516;&#26102;&#23637;&#31034;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#31354;&#38388;&#22238;&#24402;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse variational approximations are popular methods for scaling up inference and learning in Gaussian processes to larger datasets. For $N$ training points, exact inference has $O(N^3)$ cost; with $M \ll N$ features, state of the art sparse variational methods have $O(NM^2)$ cost. Recently, methods have been proposed using more sophisticated features; these promise $O(M^3)$ cost, with good performance in low dimensional tasks such as spatial modelling, but they only work with a very limited class of kernels, excluding some of the most commonly used. In this work, we propose integrated Fourier features, which extends these performance benefits to a very broad class of stationary covariance functions. We motivate the method and choice of parameters from a convergence analysis and empirical exploration, and show practical speedup in synthetic and real world spatial regression tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#31454;&#25216;&#20307;&#32946;&#25216;&#33021;&#35780;&#32423;&#20027;&#35201;&#26041;&#27861;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#24182;&#25552;&#20986;&#20102;&#37319;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#30340;&#24314;&#35758;&#12290;&#36890;&#36807;&#20351;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#65292;&#29609;&#23478;&#30340;&#25216;&#33021;&#21487;&#20197;&#34920;&#31034;&#20026;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#21464;&#37327;&#65292;&#32780;&#27604;&#36187;&#32467;&#26524;&#21017;&#26159;&#21807;&#19968;&#30340;&#35266;&#27979;&#37327;&#12290;&#35813;&#35270;&#35282;&#26377;&#21161;&#20110;&#35299;&#32806;&#24314;&#27169;&#21644;&#25512;&#29702;&#65292;&#24182;&#20419;&#36827;&#36890;&#29992;&#25512;&#29702;&#24037;&#20855;&#30340;&#21457;&#23637;&#12290;&#22312;&#26500;&#24314;&#25216;&#33021;&#35780;&#32423;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#26041;&#38754;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#22522;&#26412;&#27493;&#39588;&#65292;&#21516;&#26102;&#36824;&#35752;&#35770;&#20102;&#28388;&#27874;&#12289;&#24179;&#28369;&#21644;&#21442;&#25968;&#20272;&#35745;&#31561;&#25512;&#29702;&#38454;&#27573;&#12290;&#22312;&#38754;&#23545;&#39640;&#32500;&#22330;&#26223;&#20013;&#30340;&#35745;&#31639;&#25361;&#25112;&#26102;&#65292;&#26412;&#25991;&#24378;&#35843;&#20102;&#25152;&#37319;&#29992;&#30340;&#36817;&#20284;&#21644;&#31616;&#21270;&#26041;&#27861;&#12290;&#35813;&#25991;&#25552;&#20379;&#20102;&#23545;&#35760;&#24405;&#30340;&#27969;&#34892;&#26041;&#27861;&#30340;&#31616;&#26126;&#24635;&#32467;&#12290;</title><link>http://arxiv.org/abs/2308.02414</link><description>&lt;p&gt;
&#23545;&#22312;&#32447;&#25216;&#33021;&#35780;&#32423;&#24314;&#27169;&#21644;&#25512;&#29702;&#30340;&#29366;&#24577;&#31354;&#38388;&#35270;&#35282;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A State-Space Perspective on Modelling and Inference for Online Skill Rating. (arXiv:2308.02414v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02414
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#31454;&#25216;&#20307;&#32946;&#25216;&#33021;&#35780;&#32423;&#20027;&#35201;&#26041;&#27861;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#24182;&#25552;&#20986;&#20102;&#37319;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#30340;&#24314;&#35758;&#12290;&#36890;&#36807;&#20351;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#65292;&#29609;&#23478;&#30340;&#25216;&#33021;&#21487;&#20197;&#34920;&#31034;&#20026;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#21464;&#37327;&#65292;&#32780;&#27604;&#36187;&#32467;&#26524;&#21017;&#26159;&#21807;&#19968;&#30340;&#35266;&#27979;&#37327;&#12290;&#35813;&#35270;&#35282;&#26377;&#21161;&#20110;&#35299;&#32806;&#24314;&#27169;&#21644;&#25512;&#29702;&#65292;&#24182;&#20419;&#36827;&#36890;&#29992;&#25512;&#29702;&#24037;&#20855;&#30340;&#21457;&#23637;&#12290;&#22312;&#26500;&#24314;&#25216;&#33021;&#35780;&#32423;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#26041;&#38754;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#22522;&#26412;&#27493;&#39588;&#65292;&#21516;&#26102;&#36824;&#35752;&#35770;&#20102;&#28388;&#27874;&#12289;&#24179;&#28369;&#21644;&#21442;&#25968;&#20272;&#35745;&#31561;&#25512;&#29702;&#38454;&#27573;&#12290;&#22312;&#38754;&#23545;&#39640;&#32500;&#22330;&#26223;&#20013;&#30340;&#35745;&#31639;&#25361;&#25112;&#26102;&#65292;&#26412;&#25991;&#24378;&#35843;&#20102;&#25152;&#37319;&#29992;&#30340;&#36817;&#20284;&#21644;&#31616;&#21270;&#26041;&#27861;&#12290;&#35813;&#25991;&#25552;&#20379;&#20102;&#23545;&#35760;&#24405;&#30340;&#27969;&#34892;&#26041;&#27861;&#30340;&#31616;&#26126;&#24635;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#22238;&#39038;&#20102;&#29992;&#20110;&#31454;&#25216;&#20307;&#32946;&#25216;&#33021;&#35780;&#32423;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20513;&#37319;&#29992;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#65292;&#23558;&#29609;&#23478;&#30340;&#25216;&#33021;&#34920;&#31034;&#20026;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#65292;&#27604;&#36187;&#32467;&#26524;&#20316;&#20026;&#21807;&#19968;&#30340;&#35266;&#27979;&#37327;&#12290;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#35270;&#35282;&#26377;&#21161;&#20110;&#35299;&#32806;&#24314;&#27169;&#21644;&#25512;&#29702;&#65292;&#20174;&#32780;&#20351;&#24471;&#26356;&#21152;&#27880;&#37325;&#27169;&#22411;&#20551;&#35774;&#30340;&#26041;&#27861;&#24471;&#20197;&#31361;&#20986;&#65292;&#24182;&#20419;&#36827;&#20102;&#36890;&#29992;&#25512;&#29702;&#24037;&#20855;&#30340;&#21457;&#23637;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#26500;&#24314;&#25216;&#33021;&#35780;&#32423;&#30340;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#22522;&#26412;&#27493;&#39588;&#65292;&#24182;&#35752;&#35770;&#20102;&#25512;&#29702;&#30340;&#19977;&#20010;&#38454;&#27573;&#65306;&#28388;&#27874;&#12289;&#24179;&#28369;&#21644;&#21442;&#25968;&#20272;&#35745;&#12290;&#22312;&#25972;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#28041;&#21450;&#22823;&#37327;&#29609;&#23478;&#21644;&#27604;&#36187;&#30340;&#39640;&#32500;&#22330;&#26223;&#20013;&#36827;&#34892;&#35268;&#27169;&#25193;&#23637;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#29992;&#20110;&#26377;&#25928;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#30340;&#36817;&#20284;&#21644;&#31616;&#21270;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25991;&#29486;&#20013;&#35760;&#24405;&#30340;&#27969;&#34892;&#26041;&#27861;&#30340;&#31616;&#26126;&#24635;&#32467;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper offers a comprehensive review of the main methodologies used for skill rating in competitive sports. We advocate for a state-space model perspective, wherein players' skills are represented as time-varying, and match results serve as the sole observed quantities. The state-space model perspective facilitates the decoupling of modeling and inference, enabling a more focused approach highlighting model assumptions, while also fostering the development of general-purpose inference tools. We explore the essential steps involved in constructing a state-space model for skill rating before turning to a discussion on the three stages of inference: filtering, smoothing and parameter estimation. Throughout, we examine the computational challenges of scaling up to high-dimensional scenarios involving numerous players and matches, highlighting approximations and reductions used to address these challenges effectively. We provide concise summaries of popular methods documented in the lit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10352</link><description>&lt;p&gt;
&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#21106;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#24050;&#25104;&#20026;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#27861;&#12290;&#24191;&#27867;&#24212;&#29992;&#21253;&#25324;&#22270;&#20687;&#22788;&#29702;&#12289;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#24120;&#24120;&#38656;&#35201;&#20248;&#21270;&#19968;&#20123;&#21442;&#25968;&#20197;&#26368;&#23567;&#21270;SW&#65292;&#35813;&#21442;&#25968;&#20805;&#24403;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#25439;&#22833;&#20989;&#25968;&#65288;&#22240;&#20026;&#20855;&#26377;&#23494;&#24230;&#30340;&#27979;&#24230;&#22312;&#25968;&#20540;&#19978;&#26159;&#26080;&#27861;&#23454;&#29616;&#30340;&#65289;&#12290;&#25152;&#26377;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#37117;&#23384;&#22312;&#30456;&#21516;&#30340;&#23376;&#38382;&#39064;&#65292;&#21363;&#26368;&#23567;&#21270;&#20999;&#21106;Wasserstein&#33021;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$&#30340;&#23646;&#24615;&#65292;&#21363;&#20004;&#20010;&#20855;&#26377;&#19982;&#19968;&#20010;&#27979;&#24230;&#30340;&#25903;&#25745;&#30456;&#21516;&#25968;&#37327;&#30340;&#31163;&#25955;&#22343;&#21248;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#36317;&#31163;&#20316;&#20026;&#25903;&#25745;$Y \in \mathbb{R}^{n \times d}$&#20989;&#25968;&#30340;&#33021;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#33021;&#37327;&#30340;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#65292;&#20197;&#21450;&#20854;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;$\mathcal{E}_p$&#65288;&#20351;&#29992;SW&#20013;&#30340;&#26399;&#26395;&#20272;&#35745;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#27979;&#35797;&#26694;&#26550;&#65292;&#21487;&#20197;&#38750;&#32447;&#24615;&#27604;&#36739;&#22797;&#26434;&#30340;&#32454;&#32990;&#38388;&#20998;&#23376;&#29305;&#24449;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#26680;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#32454;&#32990;&#32676;&#20307;&#20013;&#38544;&#34109;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26680;&#27979;&#35797;&#22914;&#20309;&#20811;&#26381;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24212;&#29992;&#20110;&#30740;&#31350;&#20998;&#21270;&#36870;&#36716;&#30340;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2307.08509</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Kernel-Based Testing for Single-Cell Differential Analysis. (arXiv:2307.08509v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26041;&#27861;&#30340;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#27979;&#35797;&#26694;&#26550;&#65292;&#21487;&#20197;&#38750;&#32447;&#24615;&#27604;&#36739;&#22797;&#26434;&#30340;&#32454;&#32990;&#38388;&#20998;&#23376;&#29305;&#24449;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#26680;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#32454;&#32990;&#32676;&#20307;&#20013;&#38544;&#34109;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26680;&#27979;&#35797;&#22914;&#20309;&#20811;&#26381;&#21333;&#32454;&#32990;&#24046;&#24322;&#20998;&#26512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#24212;&#29992;&#20110;&#30740;&#31350;&#20998;&#21270;&#36870;&#36716;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#32454;&#32990;&#25216;&#26415;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#22522;&#22240;&#34920;&#36798;&#21644;&#34920;&#35266;&#36951;&#20256;&#20462;&#39280;&#31561;&#20998;&#23376;&#29305;&#24449;&#30340;&#23453;&#36149;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20197;&#25511;&#21046;&#21644;&#24378;&#26377;&#21147;&#30340;&#26041;&#24335;&#27604;&#36739;&#36825;&#20123;&#22797;&#26434;&#20998;&#24067;&#38754;&#20020;&#30528;&#26041;&#27861;&#35770;&#19978;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#22522;&#20110;&#26680;&#23884;&#20837;&#30340;&#26680;&#27979;&#35797;&#26694;&#26550;&#26469;&#38750;&#32447;&#24615;&#27604;&#36739;&#32454;&#32990;&#38388;&#22797;&#26434;&#20998;&#23376;&#29305;&#24449;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#19981;&#20165;&#20801;&#35768;&#23545;&#29305;&#24449;&#36827;&#34892;&#20998;&#26512;&#65292;&#36824;&#33021;&#22312;&#32771;&#34385;&#20102;&#23427;&#20204;&#20043;&#38388;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#36716;&#24405;&#32452;&#25110;&#34920;&#35266;&#32452;&#30340;&#20840;&#23616;&#27604;&#36739;&#12290;&#36890;&#36807;&#20351;&#29992;&#20998;&#31867;&#22120;&#22522;&#20110;&#26680;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#26469;&#21306;&#20998;&#32454;&#32990;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#21457;&#29616;&#22312;&#32454;&#32990;&#32676;&#20307;&#20013;&#21407;&#26412;&#26080;&#27861;&#23519;&#35273;&#21040;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26680;&#27979;&#35797;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#19987;&#38376;&#29992;&#20110;&#21333;&#32454;&#32990;&#30340;&#24046;&#24322;&#20998;&#26512;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#36824;&#23558;&#26680;&#27979;&#35797;&#24212;&#29992;&#20110;&#30740;&#31350;&#20998;&#21270;&#36870;&#36716;&#30340;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Single-cell technologies have provided valuable insights into the distribution of molecular features, such as gene expression and epigenomic modifications. However, comparing these complex distributions in a controlled and powerful manner poses methodological challenges. Here we propose to benefit from the kernel-testing framework to compare the complex cell-wise distributions of molecular features in a non-linear manner based on their kernel embedding. Our framework not only allows for feature-wise analyses but also enables global comparisons of transcriptomes or epigenomes, considering their intricate dependencies. By using a classifier to discriminate cells based on the variability of their embedding, our method uncovers heterogeneities in cell populations that would otherwise go undetected. We show that kernel testing overcomes the limitations of differential analysis methods dedicated to single-cell. Kernel testing is applied to investigate the reversion process of differentiating
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#25511;&#21046;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#38750;&#32047;&#31215;&#30446;&#26631;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#25913;&#29616;&#26377;&#31639;&#27861;&#30340;&#26041;&#27861;&#26469;&#20248;&#21270;&#36825;&#20123;&#30446;&#26631;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#26041;&#31243;&#20013;&#20351;&#29992;&#24191;&#20041;&#36816;&#31639;&#21487;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#38750;&#32047;&#31215;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2307.04957</link><description>&lt;p&gt;
&#38750;&#32047;&#31215;&#30446;&#26631;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Non-Cumulative Objective. (arXiv:2307.04957v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#25511;&#21046;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#38750;&#32047;&#31215;&#30446;&#26631;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#25913;&#29616;&#26377;&#31639;&#27861;&#30340;&#26041;&#27861;&#26469;&#20248;&#21270;&#36825;&#20123;&#30446;&#26631;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#26041;&#31243;&#20013;&#20351;&#29992;&#24191;&#20041;&#36816;&#31639;&#21487;&#20197;&#26356;&#22909;&#22320;&#22788;&#29702;&#38750;&#32047;&#31215;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#30446;&#26631;&#20960;&#20046;&#24635;&#26159;&#23450;&#20041;&#20026;&#27839;&#36807;&#31243;&#20013;&#22870;&#21169;&#30340;\emph{&#32047;&#31215;}&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#26368;&#20248;&#25511;&#21046;&#21644;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#23588;&#20854;&#26159;&#22312;&#36890;&#20449;&#21644;&#32593;&#32476;&#39046;&#22495;&#20013;&#65292;&#30446;&#26631;&#24182;&#19981;&#33258;&#28982;&#22320;&#34920;&#36798;&#20026;&#22870;&#21169;&#30340;&#27714;&#21644;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#35782;&#21040;&#21508;&#31181;&#38382;&#39064;&#20013;&#38750;&#32047;&#31215;&#30446;&#26631;&#30340;&#26222;&#36941;&#23384;&#22312;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#25913;&#29616;&#26377;&#31639;&#27861;&#20197;&#20248;&#21270;&#36825;&#20123;&#30446;&#26631;&#30340;&#26041;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;&#35768;&#22810;&#26368;&#20248;&#25511;&#21046;&#21644;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#26500;&#24314;&#27169;&#22359;&#65306;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#26041;&#31243;&#12290;&#20026;&#20102;&#20248;&#21270;&#38750;&#32047;&#31215;&#30446;&#26631;&#65292;&#25105;&#20204;&#29992;&#19982;&#30446;&#26631;&#30456;&#23545;&#24212;&#30340;&#24191;&#20041;&#36816;&#31639;&#26367;&#25442;&#20102;&#36125;&#23572;&#26364;&#26356;&#26032;&#35268;&#21017;&#20013;&#30340;&#21407;&#22987;&#27714;&#21644;&#36816;&#31639;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24191;&#20041;&#36816;&#31639;&#24418;&#24335;&#30340;&#36275;&#22815;&#26465;&#20214;&#20197;&#21450;&#23545;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
In reinforcement learning, the objective is almost always defined as a \emph{cumulative} function over the rewards along the process. However, there are many optimal control and reinforcement learning problems in various application fields, especially in communications and networking, where the objectives are not naturally expressed as summations of the rewards. In this paper, we recognize the prevalence of non-cumulative objectives in various problems, and propose a modification to existing algorithms for optimizing such objectives. Specifically, we dive into the fundamental building block for many optimal control and reinforcement learning algorithms: the Bellman optimality equation. To optimize a non-cumulative objective, we replace the original summation operation in the Bellman update rule with a generalized operation corresponding to the objective. Furthermore, we provide sufficient conditions on the form of the generalized operation as well as assumptions on the Markov decision 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20020;&#24202;&#21644;&#38750;&#20020;&#24202;&#25991;&#26412;&#19978;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#20013;&#20351;&#29992;&#25299;&#25169;&#21644;&#20960;&#20309;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#25512;&#26029;&#20027;&#35201;&#29305;&#24449;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.08642</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#25299;&#25169;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Topological Interpretability for Deep-Learning. (arXiv:2305.08642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20020;&#24202;&#21644;&#38750;&#20020;&#24202;&#25991;&#26412;&#19978;&#35757;&#32451;&#30340;&#28145;&#24230;&#23398;&#20064;&#20998;&#31867;&#27169;&#22411;&#20013;&#20351;&#29992;&#25299;&#25169;&#21644;&#20960;&#20309;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#25512;&#26029;&#20027;&#35201;&#29305;&#24449;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#30340;&#31995;&#32479;&#22312;&#26085;&#24120;&#29983;&#27963;&#20013;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#24191;&#27867;&#65292;&#29702;&#35299;&#23427;&#20204;&#30340;&#20915;&#31574;&#26426;&#21046;&#30340;&#38656;&#27714;&#20063;&#30456;&#24212;&#21152;&#36895;&#12290;&#25105;&#20204;&#33021;&#22815;&#20449;&#20219;&#22522;&#20110;&#20154;&#24037;&#26234;&#33021;&#20915;&#31574;&#31995;&#32479;&#25152;&#20570;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#31243;&#24230;&#36234;&#26469;&#36234;&#25104;&#20026;&#19968;&#20010;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#39118;&#38505;&#30340;&#31995;&#32479;&#65292;&#20363;&#22914;&#21009;&#20107;&#21496;&#27861;&#25110;&#21307;&#23398;&#35786;&#26029;&#31995;&#32479;&#20013;&#65292;&#38169;&#35823;&#30340;&#25512;&#26029;&#21487;&#33021;&#20250;&#20135;&#29983;&#24754;&#21095;&#24615;&#30340;&#21518;&#26524;&#12290;&#23613;&#31649;&#22312;&#35299;&#20915;&#28041;&#21450;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#27169;&#22411;&#26080;&#27861;&#37327;&#21270;&#20854;&#39044;&#27979;&#30340;&#30830;&#23450;&#24615;&#12290;&#32780;&#19988;&#24403;&#20854;&#35299;&#20915;&#26041;&#26696;&#19981;&#27491;&#30830;&#26102;&#65292;&#36890;&#24120;&#20173;&#28982;&#38750;&#24120;&#33258;&#20449;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20020;&#24202;&#21644;&#38750;&#20020;&#24202;&#25991;&#26412;&#19978;&#35757;&#32451;&#30340;&#20004;&#20010;DL&#20998;&#31867;&#27169;&#22411;&#20013;&#25512;&#26029;&#26480;&#20986;&#29305;&#24449;&#65292;&#37319;&#29992;&#20102;&#25299;&#25169;&#21644;&#20960;&#20309;&#25968;&#25454;&#20998;&#26512;&#25216;&#26415;&#12290;&#25105;&#20204;&#21019;&#24314;&#20102;&#27169;&#22411;&#39044;&#27979;&#31354;&#38388;&#30340;&#22270;&#24418;&#65292;&#24182;&#36890;&#36807;&#29305;&#24449;&#21644;&#39044;&#27979;&#30340;&#30456;&#20284;&#24615;&#23558;&#36755;&#20837;&#32858;&#31867;&#21040;&#22270;&#24418;&#30340;&#39030;&#28857;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasing adoption of AI-based systems across everyday life, the need to understand their decision-making mechanisms is correspondingly accelerating. The level at which we can trust the statistical inferences made from AI-based decision systems is an increasing concern, especially in high-risk systems such as criminal justice or medical diagnosis, where incorrect inferences may have tragic consequences. Despite their successes in providing solutions to problems involving real-world data, deep learning (DL) models cannot quantify the certainty of their predictions. And are frequently quite confident, even when their solutions are incorrect.  This work presents a method to infer prominent features in two DL classification models trained on clinical and non-clinical text by employing techniques from topological and geometric data analysis. We create a graph of a model's prediction space and cluster the inputs into the graph's vertices by the similarity of features and prediction
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.14989</link><description>&lt;p&gt;
Kullback-Leibler Maillard&#37319;&#26679;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards. (arXiv:2304.14989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;Kullback-Leibler Maillard Sampling (KL-MS)&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#26377;&#30028;&#22870;&#21169;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#23454;&#29616;KL&#31354;&#38388;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22870;&#21169;&#20998;&#24067;&#38598;&#20013;&#22312;&#21306;&#38388;$[0,1]$&#20869;&#30340;$K$&#33218;&#25968;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Kullback-Leibler Maillard Sampling (KL-MS)&#30340;&#26032;&#31639;&#27861;&#65292;&#23427;&#26159;Maillard&#37319;&#26679;&#22312;KL&#31354;&#38388;&#30340;&#33258;&#28982;&#25193;&#23637;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;KL-MS&#22312;Bernoulli&#22870;&#21169;&#26102;&#20855;&#26377;&#28176;&#36817;&#26368;&#20248;&#24615;&#33021;&#65292;&#20854;&#26368;&#22351;&#24773;&#20917;&#36951;&#25022;&#24230;&#19978;&#30028;&#20026;$O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$&#65292;&#20854;&#20013;$\mu^*$&#26159;&#26368;&#20248;&#33218;&#30340;&#26399;&#26395;&#22870;&#21169;&#65292;$T$&#26159;&#26102;&#27573;&#38271;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study $K$-armed bandit problems where the reward distributions of the arms are all supported on the $[0,1]$ interval. It has been a challenge to design regret-efficient randomized exploration algorithms in this setting. Maillard sampling~\cite{maillard13apprentissage}, an attractive alternative to Thompson sampling, has recently been shown to achieve competitive regret guarantees in the sub-Gaussian reward setting~\cite{bian2022maillard} while maintaining closed-form action probabilities, which is useful for offline policy evaluation. In this work, we propose the Kullback-Leibler Maillard Sampling (KL-MS) algorithm, a natural extension of Maillard sampling for achieving KL-style gap-dependent regret bound. We show that KL-MS enjoys the asymptotic optimality when the rewards are Bernoulli and has a worst-case regret bound of the form $O(\sqrt{\mu^*(1-\mu^*) K T \ln K} + K \ln T)$, where $\mu^*$ is the expected reward of the optimal arm, and $T$ is the time horizon length.
&lt;/p&gt;</description></item></channel></rss>