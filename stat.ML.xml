<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#23548;&#21521;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#24211;&#23384;&#37197;&#36865;&#38382;&#39064;&#65292;&#36890;&#36807;&#30452;&#25509;&#38598;&#25104;&#24211;&#23384;&#39044;&#27979;&#21644;&#36335;&#24452;&#20248;&#21270;&#65292;&#21487;&#33021;&#30830;&#20445;&#19968;&#20010;&#24378;&#22823;&#30340;&#20379;&#24212;&#38142;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2311.00983</link><description>&lt;p&gt;
&#20248;&#21270;&#24211;&#23384;&#37197;&#36865;&#65306;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20915;&#31574;&#23548;&#21521;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimizing Inventory Routing: A Decision-Focused Learning Approach using Neural Networks. (arXiv:2311.00983v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#23548;&#21521;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#24211;&#23384;&#37197;&#36865;&#38382;&#39064;&#65292;&#36890;&#36807;&#30452;&#25509;&#38598;&#25104;&#24211;&#23384;&#39044;&#27979;&#21644;&#36335;&#24452;&#20248;&#21270;&#65292;&#21487;&#33021;&#30830;&#20445;&#19968;&#20010;&#24378;&#22823;&#30340;&#20379;&#24212;&#38142;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24211;&#23384;&#37197;&#36865;&#38382;&#39064;&#65288;IRP&#65289;&#26159;&#20379;&#24212;&#38142;&#31649;&#29702;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#65292;&#23427;&#28041;&#21450;&#22312;&#32771;&#34385;&#24211;&#23384;&#38656;&#27714;&#35268;&#21010;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#24773;&#20917;&#19979;&#20248;&#21270;&#26377;&#25928;&#30340;&#36335;&#24452;&#36873;&#25321;&#12290;&#20026;&#20102;&#35299;&#20915;IRP&#38382;&#39064;&#65292;&#36890;&#24120;&#37319;&#29992;&#20004;&#38454;&#27573;&#30340;&#26041;&#27861;&#65292;&#39318;&#20808;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#39044;&#27979;&#38656;&#27714;&#65292;&#28982;&#21518;&#20351;&#29992;&#20248;&#21270;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#37197;&#36865;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#23454;&#29616;&#23436;&#32654;&#20934;&#30830;&#24230;&#26041;&#38754;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#24211;&#23384;&#27700;&#24179;&#21463;&#21160;&#24577;&#19994;&#21153;&#29615;&#22659;&#30340;&#24433;&#21709;&#65292;&#36827;&#32780;&#24433;&#21709;&#21040;&#19979;&#19968;&#38454;&#27573;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#23548;&#33268;&#27425;&#20248;&#20915;&#31574;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20915;&#31574;&#23548;&#21521;&#23398;&#20064;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#29616;&#23454;&#19990;&#30028;&#30340;IRP&#38382;&#39064;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#31995;&#32479;&#20013;&#30452;&#25509;&#38598;&#25104;&#20102;&#24211;&#23384;&#39044;&#27979;&#21644;&#36335;&#24452;&#20248;&#21270;&#65292;&#21487;&#33021;&#30830;&#20445;&#19968;&#20010;&#24378;&#22823;&#30340;&#20379;&#24212;&#38142;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inventory Routing Problem (IRP) is a crucial challenge in supply chain management as it involves optimizing efficient route selection while considering the uncertainty of inventory demand planning. To solve IRPs, usually a two-stage approach is employed, where demand is predicted using machine learning techniques first, and then an optimization algorithm is used to minimize routing costs. Our experiment shows machine learning models fall short of achieving perfect accuracy because inventory levels are influenced by the dynamic business environment, which, in turn, affects the optimization problem in the next stage, resulting in sub-optimal decisions. In this paper, we formulate and propose a decision-focused learning-based approach to solving real-world IRPs. This approach directly integrates inventory prediction and routing optimization within an end-to-end system potentially ensuring a robust supply chain strategy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12781</link><description>&lt;p&gt;
&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Conditional Density Estimations from Privacy-Protected Data. (arXiv:2310.12781v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12781
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#20013;&#36827;&#34892;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#23548;&#33268;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#32479;&#35745;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#38656;&#35201;&#22312;&#25935;&#24863;&#29992;&#25143;&#25968;&#25454;&#19978;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#12290;&#24046;&#20998;&#38544;&#31169;&#25552;&#20379;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#20445;&#35777;&#65292;&#21363;&#20010;&#20307;&#29992;&#25143;&#20449;&#24687;&#19981;&#20250;&#27844;&#38706;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21521;&#20445;&#23494;&#25968;&#25454;&#27880;&#20837;&#26657;&#20934;&#30340;&#22122;&#22768;&#65292;&#20174;&#32780;&#20135;&#29983;&#38544;&#31169;&#20445;&#25252;&#30340;&#25968;&#25454;&#38598;&#25110;&#26597;&#35810;&#12290;&#28982;&#32780;&#65292;&#22312;&#32479;&#35745;&#20998;&#26512;&#36807;&#31243;&#20013;&#21482;&#33021;&#35775;&#38382;&#31169;&#26377;&#21270;&#25968;&#25454;&#20250;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#24230;&#22686;&#21152;&#65292;&#38590;&#20197;&#23545;&#22522;&#30784;&#26426;&#23494;&#25968;&#25454;&#30340;&#21442;&#25968;&#36827;&#34892;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#38544;&#31169;&#20445;&#25252;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#22120;&#20316;&#20026;&#19968;&#32452;&#28789;&#27963;&#30340;&#20998;&#24067;&#26469;&#36817;&#20284;&#32473;&#23450;&#35266;&#27979;&#21040;&#30340;&#31169;&#26377;&#26597;&#35810;&#32467;&#26524;&#30340;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#20256;&#26579;&#30149;&#27169;&#22411;&#19979;&#30340;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20197;&#21450;&#26222;&#36890;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#19978;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern statistical analysis and machine learning applications require training models on sensitive user data. Differential privacy provides a formal guarantee that individual-level information about users does not leak. In this framework, randomized algorithms inject calibrated noise into the confidential data, resulting in privacy-protected datasets or queries. However, restricting access to only the privatized data during statistical analysis makes it computationally challenging to perform valid inferences on parameters underlying the confidential data. In this work, we propose simulation-based inference methods from privacy-protected datasets. Specifically, we use neural conditional density estimators as a flexible family of distributions to approximate the posterior distribution of model parameters given the observed private query results. We illustrate our methods on discrete time-series data under an infectious disease model and on ordinary linear regression models. Illustra
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23450;&#21521;&#24322;&#24615;&#25193;&#25955;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20302;&#32500;&#27969;&#24418;&#20013;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#24577;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#21462;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#26469;&#26816;&#27979;&#22797;&#26434;&#31995;&#32479;&#25110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#21160;&#21147;&#23398;&#36716;&#21464;&#65292;&#24182;&#22312;&#30495;&#23454;&#30340;&#33041;&#30005;&#22270;&#25968;&#25454;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.03842</link><description>&lt;p&gt;
&#38544;&#24615;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#30340;&#36716;&#21521;&#39044;&#35686;
&lt;/p&gt;
&lt;p&gt;
Early warning via transitions in latent stochastic dynamical systems. (arXiv:2309.03842v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23450;&#21521;&#24322;&#24615;&#25193;&#25955;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#25429;&#25417;&#20302;&#32500;&#27969;&#24418;&#20013;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#24577;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#21462;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#26469;&#26816;&#27979;&#22797;&#26434;&#31995;&#32479;&#25110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#21160;&#21147;&#23398;&#36716;&#21464;&#65292;&#24182;&#22312;&#30495;&#23454;&#30340;&#33041;&#30005;&#22270;&#25968;&#25454;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#22522;&#22240;&#31361;&#21464;&#12289;&#33041;&#30142;&#30149;&#12289;&#33258;&#28982;&#28798;&#23475;&#12289;&#37329;&#34701;&#21361;&#26426;&#21644;&#24037;&#31243;&#21487;&#38752;&#24615;&#65292;&#23545;&#22797;&#26434;&#31995;&#32479;&#25110;&#39640;&#32500;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#21160;&#21147;&#23398;&#36716;&#21464;&#36827;&#34892;&#26089;&#26399;&#35686;&#25253;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#20026;&#20102;&#26377;&#25928;&#25552;&#21462;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65306;&#23450;&#21521;&#24322;&#24615;&#25193;&#25955;&#22270;&#65292;&#23427;&#25429;&#25417;&#20102;&#20302;&#32500;&#27969;&#24418;&#20013;&#30340;&#28508;&#22312;&#28436;&#21270;&#21160;&#24577;&#12290;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#30495;&#23454;&#30340;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#25968;&#25454;&#65292;&#25105;&#20204;&#25104;&#21151;&#25214;&#21040;&#20102;&#36866;&#24403;&#30340;&#26377;&#25928;&#22352;&#26631;&#65292;&#24182;&#25512;&#23548;&#20986;&#33021;&#22815;&#26816;&#27979;&#29366;&#24577;&#36716;&#21464;&#20013;&#20020;&#30028;&#28857;&#30340;&#26089;&#26399;&#35686;&#25253;&#20449;&#21495;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#28508;&#22312;&#21160;&#24577;&#19982;&#21407;&#22987;&#25968;&#25454;&#38598;&#32852;&#31995;&#36215;&#26469;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26694;&#26550;&#22312;&#23494;&#24230;&#21644;&#36716;&#21464;&#27010;&#29575;&#31561;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#31532;&#20108;&#20010;&#22352;&#26631;&#22312;&#21508;&#31181;&#35780;&#20272;&#25351;&#26631;&#20013;&#20445;&#25345;&#26377;&#24847;&#20041;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Early warnings for dynamical transitions in complex systems or high-dimensional observation data are essential in many real world applications, such as gene mutation, brain diseases, natural disasters, financial crises, and engineering reliability. To effectively extract early warning signals, we develop a novel approach: the directed anisotropic diffusion map that captures the latent evolutionary dynamics in low-dimensional manifold. Applying the methodology to authentic electroencephalogram (EEG) data, we successfully find the appropriate effective coordinates, and derive early warning signals capable of detecting the tipping point during the state transition. Our method bridges the latent dynamics with the original dataset. The framework is validated to be accurate and effective through numerical experiments, in terms of density and transition probability. It is shown that the second coordinate holds meaningful information for critical transition in various evaluation metrics.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;Wishart&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#19968;&#31867;&#23376;&#31354;&#38388;&#24182;&#38598;&#27169;&#22411;&#25429;&#25417;&#20449;&#21495;&#32467;&#26500;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#12290;&#36890;&#36807;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#28982;&#30340;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#32479;&#35745;&#36817;&#20284;&#26368;&#20248;&#37051;&#22495;&#20013;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20855;&#20307;&#26696;&#20363;&#30340;&#20998;&#26512;&#23637;&#31034;&#20102;&#35745;&#31639;&#38590;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#22522;&#26412;&#31232;&#30095;PCA&#35266;&#23519;&#21040;&#30340;&#29616;&#35937;&#22312;&#20854;&#32467;&#26500;&#21270;&#23545;&#24212;&#29289;&#20013;&#20063;&#21516;&#26679;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2307.13535</link><description>&lt;p&gt;
&#31639;&#27861;&#21644;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#38556;&#30861;&#26159;&#21542;&#36866;&#29992;&#20110;&#20854;&#20182;&#32467;&#26500;&#35774;&#32622;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do algorithms and barriers for sparse principal component analysis extend to other structured settings?. (arXiv:2307.13535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13535
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;Wishart&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#19968;&#31867;&#23376;&#31354;&#38388;&#24182;&#38598;&#27169;&#22411;&#25429;&#25417;&#20449;&#21495;&#32467;&#26500;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#12290;&#36890;&#36807;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#28982;&#30340;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#32479;&#35745;&#36817;&#20284;&#26368;&#20248;&#37051;&#22495;&#20013;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20855;&#20307;&#26696;&#20363;&#30340;&#20998;&#26512;&#23637;&#31034;&#20102;&#35745;&#31639;&#38590;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#22522;&#26412;&#31232;&#30095;PCA&#35266;&#23519;&#21040;&#30340;&#29616;&#35937;&#22312;&#20854;&#32467;&#26500;&#21270;&#23545;&#24212;&#29289;&#20013;&#20063;&#21516;&#26679;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23574;&#23792;Wishart&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#65292;&#20854;&#20013;&#20449;&#21495;&#20013;&#30340;&#32467;&#26500;&#36890;&#36807;&#19968;&#31867;&#23376;&#31354;&#38388;&#24182;&#38598;&#27169;&#22411;&#26469;&#25429;&#25417;&#12290;&#36825;&#20010;&#36890;&#29992;&#31867;&#21035;&#21253;&#25324;&#22522;&#26412;&#31232;&#30095;PCA&#20197;&#21450;&#24102;&#26377;&#22270;&#31232;&#30095;&#24615;&#30340;&#21464;&#20307;&#12290;&#20026;&#20102;&#22312;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#32479;&#19968;&#35270;&#35282;&#19979;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#38382;&#39064;&#23454;&#20363;&#30340;&#20960;&#20309;&#26377;&#20851;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#28982;&#30340;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#32479;&#35745;&#36817;&#20284;&#26368;&#20248;&#37051;&#22495;&#20013;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#26222;&#36866;&#22522;&#30784;&#20013;&#36335;&#24452;&#31232;&#30095;&#24615;&#21644;&#26641;&#31232;&#30095;&#24615;&#30340;&#20004;&#31181;&#37325;&#35201;&#29305;&#27530;&#24773;&#20917;&#36827;&#34892;&#31471;&#21040;&#31471;&#20998;&#26512;&#65292;&#34917;&#20805;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#21021;&#22987;&#21270;&#26041;&#27861;&#21644;&#30456;&#21305;&#37197;&#30340;&#35745;&#31639;&#38590;&#24230;&#35777;&#25454;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#22522;&#26412;&#31232;&#30095;PCA&#35266;&#23519;&#21040;&#30340;&#20960;&#20010;&#29616;&#35937;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#20854;&#32467;&#26500;&#21270;&#23545;&#24212;&#29289;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a principal component analysis problem under the spiked Wishart model in which the structure in the signal is captured by a class of union-of-subspace models. This general class includes vanilla sparse PCA as well as its variants with graph sparsity. With the goal of studying these problems under a unified statistical and computational lens, we establish fundamental limits that depend on the geometry of the problem instance, and show that a natural projected power method exhibits local convergence to the statistically near-optimal neighborhood of the solution. We complement these results with end-to-end analyses of two important special cases given by path and tree sparsity in a general basis, showing initialization methods and matching evidence of computational hardness. Overall, our results indicate that several of the phenomena observed for vanilla sparse PCA extend in a natural fashion to its structured counterparts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.14872</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24179;&#34913;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#20960;&#20309;&#24863;&#30693;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21463;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#19982;&#24754;&#35266;&#29702;&#35770;&#21518;&#24724;&#30028;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#21551;&#21457;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#21253;&#25324;&#36138;&#24515;&#12289;OFUL&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#22312;&#20869;&#30340;&#24191;&#27867;&#31639;&#27861;&#31867;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#22312;&#20445;&#30041;&#22522;&#26412;&#31639;&#27861;&#22823;&#37096;&#20998;&#20248;&#33391;&#29305;&#24615;&#30340;&#21516;&#26102;&#8220;&#26657;&#27491;&#8221;&#22522;&#26412;&#31639;&#27861;&#22312;&#26576;&#20123;&#23454;&#20363;&#20013;&#34920;&#29616;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#26368;&#20248;&#21518;&#24724;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#22522;&#20110;&#39044;&#27979;&#30340;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#27491;&#27493;&#39588;&#20197;&#23454;&#29616;&#23545;&#26410;&#35266;&#27979;&#21040;&#21709;&#24212;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#30340;&#26041;&#27861;&#25104;&#21151;&#25511;&#21046;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#27491;&#30830;&#21629;&#21517;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#20854;&#23384;&#22312;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.13746</link><description>&lt;p&gt;
&#22312;&#39044;&#27979;&#20043;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Valid inference after prediction. (arXiv:2306.13746v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13746
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#22522;&#20110;&#39044;&#27979;&#30340;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#27491;&#27493;&#39588;&#20197;&#23454;&#29616;&#23545;&#26410;&#35266;&#27979;&#21040;&#21709;&#24212;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#30340;&#26041;&#27861;&#25104;&#21151;&#25511;&#21046;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#27491;&#30830;&#21629;&#21517;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#20854;&#23384;&#22312;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#22522;&#20110;&#39044;&#27979;&#30340;&#25512;&#26029;&#65292;&#21363;&#20351;&#29992;&#39044;&#20808;&#35757;&#32451;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#21709;&#24212;&#21464;&#37327;&#65292;&#28982;&#21518;&#23545;&#35813;&#39044;&#27979;&#21709;&#24212;&#19982;&#26576;&#20123;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#23558;&#26631;&#20934;&#25512;&#26029;&#26041;&#27861;&#24212;&#29992;&#20110;&#35813;&#36807;&#31243;&#24182;&#19981;&#33021;&#20934;&#30830;&#37327;&#21270;&#26410;&#35266;&#27979;&#21040;&#65288;&#32780;&#38750;&#39044;&#27979;&#21040;&#65289;&#21709;&#24212;&#19982;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#26368;&#36817;&#65292;Wang&#31561;&#20154;&#65288;2020&#65289;&#21644;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#20102;&#20462;&#27491;&#65288;ii&#65289;&#27493;&#39588;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26410;&#35266;&#27979;&#21040;&#21709;&#24212;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26377;&#25928;&#25512;&#26029;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#25511;&#21046;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#27491;&#30830;&#21629;&#21517;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#26080;&#35770;&#39044;&#20808;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#21709;&#24212;&#30340;&#36136;&#37327;&#22914;&#20309;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#21457;&#29616;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20302;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has focused on the very common practice of prediction-based inference: that is, (i) using a pre-trained machine learning model to predict an unobserved response variable, and then (ii) conducting inference on the association between that predicted response and some covariates. As pointed out by Wang et al. [2020], applying a standard inferential approach in (ii) does not accurately quantify the association between the unobserved (as opposed to the predicted) response and the covariates. In recent work, Wang et al. [2020] and Angelopoulos et al. [2023] propose corrections to step (ii) in order to enable valid inference on the association between the unobserved response and the covariates. Here, we show that the method proposed by Angelopoulos et al. [2023] successfully controls the type 1 error rate and provides confidence intervals with correct nominal coverage, regardless of the quality of the pre-trained machine learning model used to predict the unobserved response. Howe
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#24773;&#20917;&#19979;&#32570;&#22833;&#26631;&#31614;&#19988;&#23384;&#22312;&#36873;&#25321;&#20559;&#24046;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.12789</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#22240;&#26524;&#25512;&#26029;&#65306;&#38754;&#21521;&#34928;&#20943;&#37325;&#21472;&#30340;&#36873;&#25321;&#20559;&#24046;&#19979;&#21487;&#27867;&#21270;&#30340;&#21452;&#31283;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Causal Inference: Generalizable and Double Robust Inference for Average Treatment Effects under Selection Bias with Decaying Overlap. (arXiv:2305.12789v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#24773;&#20917;&#19979;&#32570;&#22833;&#26631;&#31614;&#19988;&#23384;&#22312;&#36873;&#25321;&#20559;&#24046;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20855;&#26377;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#23588;&#20854;&#26159;&#22312;&#39640;&#32500;&#28151;&#28102;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#21463;&#21040;&#20102;&#26497;&#22823;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23384;&#22312;&#21487;&#33021;&#32570;&#22833;&#30340;&#26631;&#31614;&#24773;&#20917;&#19979;&#30340;ATE&#20272;&#35745;&#38382;&#39064;&#12290;&#26631;&#35760;&#25351;&#31034;&#31526;&#30340;&#26465;&#20214;&#20542;&#21521;&#24471;&#20998;&#20801;&#35768;&#20381;&#36182;&#20110;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#34928;&#20943;&#32780;&#34928;&#20943;&#8212;&#8212;&#20174;&#32780;&#20801;&#35768;&#26410;&#26631;&#35760;&#25968;&#25454;&#22823;&#23567;&#27604;&#26631;&#35760;&#25968;&#25454;&#22823;&#23567;&#22686;&#38271;&#24471;&#26356;&#24555;&#12290;&#36825;&#31181;&#24773;&#20917;&#22635;&#34917;&#20102;&#21322;&#30417;&#30563;&#65288;SS&#65289;&#21644;&#32570;&#22833;&#25968;&#25454;&#25991;&#29486;&#20013;&#30340;&#37325;&#35201;&#31354;&#30333;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20801;&#35768;&#36873;&#25321;&#20559;&#24046;&#30340;&#38543;&#26426;&#32570;&#22833;&#65288;MAR&#65289;&#26426;&#21046;&#8212;&#8212;&#36825;&#36890;&#24120;&#22312;&#26631;&#20934;&#30340;SS&#25991;&#29486;&#20013;&#26159;&#31105;&#27490;&#30340;&#65292;&#24182;&#19988;&#22312;&#32570;&#22833;&#25968;&#25454;&#25991;&#29486;&#20013;&#36890;&#24120;&#38656;&#35201;&#19968;&#20010;&#27491;&#24615;&#26465;&#20214;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;ATE&#30340;&#19968;&#33324;&#21452;&#31283;DR-DMAR&#65288;decaying&#65289;SS&#20272;&#35745;&#22120;&#65292;&#36825;&#31181;&#20272;&#35745;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Average treatment effect (ATE) estimation is an essential problem in the causal inference literature, which has received significant recent attention, especially with the presence of high-dimensional confounders. We consider the ATE estimation problem in high dimensions when the observed outcome (or label) itself is possibly missing. The labeling indicator's conditional propensity score is allowed to depend on the covariates, and also decay uniformly with sample size - thus allowing for the unlabeled data size to grow faster than the labeled data size. Such a setting fills in an important gap in both the semi-supervised (SS) and missing data literatures. We consider a missing at random (MAR) mechanism that allows selection bias - this is typically forbidden in the standard SS literature, and without a positivity condition - this is typically required in the missing data literature. We first propose a general doubly robust 'decaying' MAR (DR-DMAR) SS estimator for the ATE, which is cons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\ell_1$-TCL&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30693;&#35782;&#36801;&#31227;&#21644;Lasso&#22238;&#24402;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.09126</link><description>&lt;p&gt;
&#30693;&#35782;&#36801;&#31227;&#19979;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;: &#36716;&#31227;&#22240;&#26524;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Causal Learning: Causal Effect Estimation with Knowledge Transfer. (arXiv:2305.09126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\ell_1$-TCL&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30693;&#35782;&#36801;&#31227;&#21644;Lasso&#22238;&#24402;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#21363;&#22312;&#30456;&#21516;&#30340;&#21327;&#21464;&#37327;&#65288;&#25110;&#29305;&#24449;&#65289;&#31354;&#38388;&#35774;&#32622;&#19979;&#36890;&#36807;&#30693;&#35782;&#36801;&#31227;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#65292;&#21363;&#21516;&#31867;&#21035;&#36801;&#31227;&#23398;&#20064;&#65288;TL&#65289;&#65292;&#23558;&#20854;&#31216;&#20026;&#36716;&#31227;&#22240;&#26524;&#23398;&#20064;&#65288;TCL&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;$\ell_1$-TCL&#65292;&#20854;&#20013;&#21253;&#21547;$\ell_1$&#27491;&#21017;&#21270;TL&#26469;&#36827;&#34892;&#33510;&#20107;&#21442;&#25968;&#20272;&#35745;&#21644;&#19979;&#28216;&#25554;&#20214;ACE&#20272;&#35745;&#22120;&#65292;&#21253;&#25324;&#32467;&#26524;&#22238;&#24402;&#12289;&#36870;&#27010;&#29575;&#21152;&#26435;&#21644;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#20511;&#21161;&#20110;Lasso&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#24674;&#22797;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
A novel problem of improving causal effect estimation accuracy with the help of knowledge transfer under the same covariate (or feature) space setting, i.e., homogeneous transfer learning (TL), is studied, referred to as the Transfer Causal Learning (TCL) problem. While most recent efforts in adapting TL techniques to estimate average causal effect (ACE) have been focused on the heterogeneous covariate space setting, those methods are inadequate for tackling the TCL problem since their algorithm designs are based on the decomposition into shared and domain-specific covariate spaces. To address this issue, we propose a generic framework called \texttt{$\ell_1$-TCL}, which incorporates $\ell_1$ regularized TL for nuisance parameter estimation and downstream plug-in ACE estimators, including outcome regression, inverse probability weighted, and doubly robust estimators. Most importantly, with the help of Lasso for high-dimensional regression, we establish non-asymptotic recovery guarantee
&lt;/p&gt;</description></item><item><title>PAM&#27169;&#22411;&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20998;&#32452;&#25968;&#25454;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;&#38646;&#22686;&#24378;&#36125;&#22612;&#65288;ZAB&#65289;&#20998;&#24067;&#23454;&#29616;&#20102;&#22810;&#32452;&#38388;&#30340;&#21407;&#23376;&#20849;&#20139;&#21644;&#29420;&#29305;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.14954</link><description>&lt;p&gt;
PAM&#65306;&#22522;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20998;&#32452;&#25968;&#25454;&#20998;&#26512;&#30340;&#26684;&#23376;&#21407;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
PAM: Plaid Atoms Model for Bayesian Nonparametric Analysis of Grouped Data. (arXiv:2304.14954v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14954
&lt;/p&gt;
&lt;p&gt;
PAM&#27169;&#22411;&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#30340;&#20998;&#32452;&#25968;&#25454;&#20998;&#26512;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;&#38646;&#22686;&#24378;&#36125;&#22612;&#65288;ZAB&#65289;&#20998;&#24067;&#23454;&#29616;&#20102;&#22810;&#32452;&#38388;&#30340;&#21407;&#23376;&#20849;&#20139;&#21644;&#29420;&#29305;&#24615;&#65292;&#24182;&#19988;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23545;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#30456;&#20851;&#32858;&#31867;&#30340;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#31216;&#20026;&#26684;&#23376;&#21407;&#23376;&#27169;&#22411;&#65288;PAM&#65289;&#65292;&#23545;&#20110;&#27599;&#20010;&#32452;&#20272;&#35745;&#19968;&#32452;&#32858;&#31867;&#65292;&#24182;&#20801;&#35768;&#19968;&#20123;&#32858;&#31867;&#19982;&#20854;&#20182;&#32452;&#20849;&#20139;&#25110;&#20165;&#20026;&#35813;&#32452;&#25152;&#25317;&#26377;&#12290;PAM&#22522;&#20110;&#23545;&#20247;&#25152;&#21608;&#30693;&#30340;&#31896;&#24615;&#30772;&#35010;&#36807;&#31243;&#30340;&#25193;&#23637;&#65292;&#36890;&#36807;&#23558;&#38646;&#28155;&#21152;&#20026;&#32858;&#31867;&#26435;&#37325;&#30340;&#21487;&#33021;&#20540;&#20043;&#19968;&#65292;&#20174;&#32780;&#22312;&#27169;&#22411;&#20013;&#20135;&#29983;&#38646;&#22686;&#24378;&#36125;&#22612;&#65288;ZAB&#65289;&#20998;&#24067;&#12290;&#22240;&#27492;&#65292;ZAB&#20801;&#35768;&#22312;&#22810;&#20010;&#32452;&#20013;&#19968;&#20123;&#32858;&#31867;&#30340;&#26435;&#37325;&#24688;&#22909;&#20026;&#38646;&#65292;&#20174;&#32780;&#23454;&#29616;&#32452;&#38388;&#20849;&#20139;&#21644;&#29420;&#29305;&#30340;&#21407;&#23376;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;PAM&#30340;&#29702;&#35770;&#23646;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#19982;&#24050;&#30693;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20999;&#29255;&#21462;&#26679;&#22120;&#29992;&#20110;&#21518;&#39564;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#22810;&#20803;&#25110;&#35745;&#25968;&#25968;&#25454;&#25552;&#20986;&#20102;&#25152;&#25552;&#20986;&#27169;&#22411;&#30340;&#36731;&#24494;&#25193;&#23637;&#12290;&#36890;&#36807;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#24212;&#29992;&#35828;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider dependent clustering of observations in groups. The proposed model, called the plaid atoms model (PAM), estimates a set of clusters for each group and allows some clusters to be either shared with other groups or uniquely possessed by the group. PAM is based on an extension to the well-known stick-breaking process by adding zero as a possible value for the cluster weights, resulting in a zero-augmented beta (ZAB) distribution in the model. As a result, ZAB allows some cluster weights to be exactly zero in multiple groups, thereby enabling shared and unique atoms across groups. We explore theoretical properties of PAM and show its connection to known Bayesian nonparametric models. We propose an efficient slice sampler for posterior inference. Minor extensions of the proposed model for multivariate or count data are presented. Simulation studies and applications using real-world datasets illustrate the model's desirable performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22266;&#23450;&#20808;&#39564;&#20998;&#24067;&#32570;&#20047;&#20449;&#24687;&#21644;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#26114;&#36149;&#19981;&#31283;&#23450;&#30340;&#23616;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.13586</link><description>&lt;p&gt;
&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22266;&#23450;&#20808;&#39564;&#20998;&#24067;&#32570;&#20047;&#20449;&#24687;&#21644;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#26114;&#36149;&#19981;&#31283;&#23450;&#30340;&#23616;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#20004;&#20010;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#19968;&#31181;&#32479;&#35745;&#26377;&#25928;&#19988;&#35745;&#31639;&#39640;&#25928;&#30340;&#24230;&#37327;&#12290;SW&#36317;&#31163;&#30340;&#19968;&#20010;&#20851;&#38190;&#37096;&#20998;&#26159;&#20999;&#29255;&#20998;&#24067;&#12290;&#30446;&#21069;&#26377;&#20004;&#31181;&#26041;&#27861;&#26469;&#36873;&#25321;&#36825;&#20010;&#20998;&#24067;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#31532;&#20108;&#31181;&#26159;&#20248;&#21270;&#24402;&#23646;&#20110;&#21442;&#25968;&#20998;&#24067;&#26063;&#30340;&#26368;&#20339;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#26368;&#22823;&#21270;&#26399;&#26395;&#30340;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#26377;&#23616;&#38480;&#24615;&#12290;&#22266;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#22312;&#31361;&#20986;&#33021;&#22815;&#21306;&#20998;&#20004;&#20010;&#24120;&#35268;&#27010;&#29575;&#27979;&#24230;&#30340;&#25237;&#24433;&#26041;&#21521;&#26041;&#38754;&#32570;&#20047;&#20449;&#24687;&#12290;&#32780;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#36890;&#24120;&#26159;&#26114;&#36149;&#21644;&#19981;&#31283;&#23450;&#30340;&#12290;&#27492;&#22806;&#65292;&#35774;&#35745;&#20505;&#36873;&#20998;&#24067;&#30340;&#21442;&#25968;&#20998;&#24067;&#26063;&#21487;&#33021;&#20250;&#24456;&#23481;&#26131;&#34987;&#38169;&#35823;&#25351;&#23450;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#20999;&#29255;&#20998;&#24067;&#35774;&#35745;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20174;&#32780;&#20351;&#20854;&#26356;&#21152;&#36890;&#29992;&#32780;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter
&lt;/p&gt;</description></item><item><title>&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#65288;MSW&#65289;&#36317;&#31163;&#26159;&#19968;&#31181;&#26032;&#30340;SW&#36317;&#31163;&#23478;&#26063;&#65292;&#36890;&#36807;&#22312;&#25237;&#24433;&#26041;&#21521;&#19978;&#26045;&#21152;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#65292;&#35299;&#20915;&#20102;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#20013;&#29420;&#31435;&#25237;&#24433;&#23548;&#33268;&#30340;&#20887;&#20313;&#25237;&#24433;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#65288;found in translation&#65289;</title><link>http://arxiv.org/abs/2301.03749</link><description>&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65306;&#36229;&#36234;&#29420;&#31435;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
Markovian Sliced Wasserstein Distances: Beyond Independent Projections. (arXiv:2301.03749v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.03749
&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#65288;MSW&#65289;&#36317;&#31163;&#26159;&#19968;&#31181;&#26032;&#30340;SW&#36317;&#31163;&#23478;&#26063;&#65292;&#36890;&#36807;&#22312;&#25237;&#24433;&#26041;&#21521;&#19978;&#26045;&#21152;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#65292;&#35299;&#20915;&#20102;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#20013;&#29420;&#31435;&#25237;&#24433;&#23548;&#33268;&#30340;&#20887;&#20313;&#25237;&#24433;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#65288;found in translation&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#30001;&#20110;&#29420;&#31435;&#30340;&#22343;&#21248;&#38543;&#26426;&#25237;&#24433;&#26041;&#21521;&#32780;&#23548;&#33268;&#20887;&#20313;&#25237;&#24433;&#12290;&#20026;&#20102;&#37096;&#20998;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#26368;&#22823;K&#20999;&#29255;Wasserstein&#65288;Max-K-SW&#65289;&#36317;&#31163;&#65288;$K\geq1$&#65289;&#23547;&#27714;&#26368;&#20339;&#30340;&#21306;&#20998;&#27491;&#20132;&#25237;&#24433;&#26041;&#21521;&#12290;&#23613;&#31649;&#33021;&#22815;&#20943;&#23569;&#25237;&#24433;&#25968;&#37327;&#65292;&#20294;Max-K-SW&#30340;&#24230;&#37327;&#24615;&#22312;&#23454;&#36341;&#20013;&#19981;&#33021;&#20445;&#35777;&#65292;&#21407;&#22240;&#26159;&#20248;&#21270;&#30340;&#38750;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#27491;&#20132;&#32422;&#26463;&#20063;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#65292;&#21487;&#33021;&#19981;&#22826;&#26377;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;SW&#36317;&#31163;&#23478;&#26063;&#65292;&#31216;&#20026;&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#65288;MSW&#65289;&#36317;&#31163;&#65292;&#23427;&#22312;&#25237;&#24433;&#26041;&#21521;&#19978;&#26045;&#21152;&#20102;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#25351;&#23450;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#65292;&#21253;&#25324;&#20808;&#39564;&#20998;&#24067;&#12289;&#36716;&#31227;&#20998;&#24067;&#20197;&#21450;&#29123;&#28903;&#21644;&#31232;&#30095;&#21270;&#25216;&#26415;&#65292;&#35752;&#35770;&#20102;MSW&#30340;&#21508;&#31181;&#25104;&#21592;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;MSW&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#21253;&#25324;&#25299;&#25169;&#24615;&#36136;&#65288;found in translation&#65289;
&lt;/p&gt;
&lt;p&gt;
Sliced Wasserstein (SW) distance suffers from redundant projections due to independent uniform random projecting directions. To partially overcome the issue, max K sliced Wasserstein (Max-K-SW) distance ($K\geq 1$), seeks the best discriminative orthogonal projecting directions. Despite being able to reduce the number of projections, the metricity of Max-K-SW cannot be guaranteed in practice due to the non-optimality of the optimization. Moreover, the orthogonality constraint is also computationally expensive and might not be effective. To address the problem, we introduce a new family of SW distances, named Markovian sliced Wasserstein (MSW) distance, which imposes a first-order Markov structure on projecting directions. We discuss various members of MSW by specifying the Markov structure including the prior distribution, the transition distribution, and the burning and thinning technique. Moreover, we investigate the theoretical properties of MSW including topological properties (met
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;(DPDMs)&#65292;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#23454;&#29616;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#65292;&#22312;&#22270;&#20687;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#36234;&#65292;&#33021;&#22815;&#22312;&#26631;&#20934;&#27979;&#35797;&#20013;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;DP-SGD&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30456;&#23218;&#32654;&#12290;</title><link>http://arxiv.org/abs/2210.09929</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Diffusion Models. (arXiv:2210.09929v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;(DPDMs)&#65292;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#23454;&#29616;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#65292;&#22312;&#22270;&#20687;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#36234;&#65292;&#33021;&#22815;&#22312;&#26631;&#20934;&#27979;&#35797;&#20013;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;DP-SGD&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20381;&#36182;&#20110;&#36234;&#26469;&#36234;&#22823;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#28982;&#32780;&#22312;&#28041;&#21450;&#38544;&#31169;&#30340;&#39046;&#22495;&#65292;&#25968;&#25454;&#36890;&#24120;&#26159;&#26377;&#38480;&#30340;&#12290;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#32469;&#36807;&#36825;&#19968;&#25361;&#25112;&#65292;&#25552;&#20379;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#35775;&#38382;&#12290;&#26412;&#25991;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#25104;&#21151;&#22522;&#30784;&#19978;&#65292;&#24341;&#20837;&#20102;&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;(DPDMs)&#65292;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(DP-SGD)&#26469;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;DPDM&#20013;&#30340;&#21442;&#25968;&#21270;&#21644;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#22122;&#22768;&#22810;&#26679;&#24615;&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;DM&#35757;&#32451;&#30340;&#24378;&#22823;&#25913;&#36827;&#12290;&#25105;&#20204;&#22312;&#22270;&#20687;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26032;&#39062;DPDMs&#65292;&#24182;&#22312;&#25152;&#26377;&#23454;&#39564;&#35777;&#26126;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#20351;&#29992;DPDM&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#34920;&#29616;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;DP-SGD&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30456;&#24403;&#65292;&#36825;&#22312;&#20197;&#24448;&#30340;&#30740;&#31350;&#20013;&#27809;&#26377;&#34987;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
While modern machine learning models rely on increasingly large training datasets, data is often limited in privacy-sensitive domains. Generative models trained with differential privacy (DP) on sensitive data can sidestep this challenge, providing access to synthetic data instead. We build on the recent success of diffusion models (DMs) and introduce Differentially Private Diffusion Models (DPDMs), which enforce privacy using differentially private stochastic gradient descent (DP-SGD). We investigate the DM parameterization and the sampling algorithm, which turn out to be crucial ingredients in DPDMs, and propose noise multiplicity, a powerful modification of DP-SGD tailored to the training of DMs. We validate our novel DPDMs on image generation benchmarks and achieve state-of-the-art performance in all experiments. Moreover, on standard benchmarks, classifiers trained on DPDM-generated synthetic data perform on par with task-specific DP-SGD-trained classifiers, which has not been dem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#20869;&#23481;&#28508;&#21464;&#37327;&#20197;&#21450;&#21512;&#25104;&#32441;&#29702;&#21464;&#37327;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#19978;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2209.06950</link><description>&lt;p&gt;
&#22522;&#20110;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v5 [eess.IV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.06950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#20869;&#23481;&#28508;&#21464;&#37327;&#20197;&#21450;&#21512;&#25104;&#32441;&#29702;&#21464;&#37327;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#19978;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#31471;&#21040;&#31471;&#20248;&#21270;&#30340;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#26694;&#26550;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#21464;&#25442;&#32534;&#30721;&#33539;&#24335;&#65292;&#23558;&#22270;&#20687;&#26144;&#23556;&#21040;&#28508;&#22312;&#31354;&#38388;&#36827;&#34892;&#20449;&#24687;&#29109;&#32534;&#30721;&#65292;&#28982;&#21518;&#20877;&#26144;&#23556;&#22238;&#25968;&#25454;&#31354;&#38388;&#36827;&#34892;&#37325;&#26500;&#12290;&#19982;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAE)&#30340;&#31070;&#32463;&#21387;&#32553;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#35299;&#30721;&#22120;&#26159;&#19968;&#20010;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#20869;&#23481;&#8221;&#28508;&#21464;&#37327;&#65292;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#20250;&#23545;&#20854;&#36827;&#34892;&#26465;&#20214;&#21270;&#65292;&#24182;&#21033;&#29992;&#35813;&#21464;&#37327;&#23384;&#20648;&#22270;&#20687;&#20449;&#24687;&#12290;&#20915;&#23450;&#25193;&#25955;&#36807;&#31243;&#30340;&#21097;&#20313;&#8220;&#32441;&#29702;&#8221;&#21464;&#37327;&#20250;&#22312;&#35299;&#30721;&#26102;&#21512;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#21487;&#20197;&#26681;&#25454;&#24863;&#30693;&#24230;&#37327;&#36827;&#34892;&#35843;&#25972;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#28041;&#21450;&#20102;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#36739;&#20110;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#26041;&#27861;&#33021;&#22815;&#24471;&#21040;&#26356;&#22909;&#30340;FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper outlines an end-to-end optimized lossy image compression framework using diffusion generative models. The approach relies on the transform coding paradigm, where an image is mapped into a latent space for entropy coding and, from there, mapped back to the data space for reconstruction. In contrast to VAE-based neural compression, where the (mean) decoder is a deterministic neural network, our decoder is a conditional diffusion model. Our approach thus introduces an additional "content" latent variable on which the reverse diffusion process is conditioned and uses this variable to store information about the image. The remaining "texture" variables characterizing the diffusion process are synthesized at decoding time. We show that the model's performance can be tuned toward perceptual metrics of interest. Our extensive experiments involving multiple datasets and image quality assessment metrics show that our approach yields stronger reported FID scores than the GAN-based mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20013;&#24515;&#21270;&#21098;&#35009;&#22312;&#38754;&#23545;&#19981;&#21516;&#24694;&#24847;&#20195;&#29702;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22810;&#24341;&#29992;&#28857;&#21098;&#35009; (MRPC) &#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;MRPC &#26694;&#26550;&#21033;&#29992;&#22810;&#20010;&#21442;&#32771;&#28857;&#26377;&#25928;&#22320;&#20013;&#21644;&#19987;&#38376;&#35774;&#35745;&#30340; Byzantine attacks&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340; Byzantine attacks &#19979;&#65292;MRPC &#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; FL &#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.09894</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;&#20154;&#20063;&#33021;&#20174;&#21382;&#21490;&#20013;&#23398;&#20064;&#65306;&#32852;&#37030;&#23398;&#20064;&#20013;&#24515;&#21270;&#21098;&#35009;&#30340;&#34928;&#33853;
&lt;/p&gt;
&lt;p&gt;
Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning. (arXiv:2208.09894v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09894
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20013;&#24515;&#21270;&#21098;&#35009;&#22312;&#38754;&#23545;&#19981;&#21516;&#24694;&#24847;&#20195;&#29702;&#26102;&#30340;&#33030;&#24369;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22810;&#24341;&#29992;&#28857;&#21098;&#35009; (MRPC) &#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;MRPC &#26694;&#26550;&#21033;&#29992;&#22810;&#20010;&#21442;&#32771;&#28857;&#26377;&#25928;&#22320;&#20013;&#21644;&#19987;&#38376;&#35774;&#35745;&#30340; Byzantine attacks&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340; Byzantine attacks &#19979;&#65292;MRPC &#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; FL &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064; (FL) &#26694;&#26550;&#30001;&#20110;&#22312;&#24191;&#27867;&#30340;&#21327;&#20316;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#20294;&#20063;&#24341;&#36215;&#20102;&#26576;&#20123;&#23433;&#20840;&#38382;&#39064;&#12290;&#20854;&#20013;&#65292;&#25308;&#21344;&#24237;&#25915;&#20987;&#30340;&#39118;&#38505;&#26159;&#29305;&#21035;&#20851;&#27880;&#30340;&#38382;&#39064;&#65292;&#36825;&#25351;&#30340;&#26159;&#24694;&#24847;&#23458;&#25143;&#21442;&#19982;&#23398;&#20064;&#36807;&#31243;&#30340;&#21487;&#33021;&#24615;&#12290;&#22240;&#27492;&#65292;FL &#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#30446;&#26631;&#26159;&#28040;&#38500; Byzantine attacks &#30340;&#28508;&#22312;&#24433;&#21709;&#65292;&#30830;&#20445;&#26368;&#32456;&#27169;&#22411;&#26159;&#21487;&#20449;&#30340;&#12290;&#24050;&#32463;&#35266;&#23519;&#21040;&#65292;&#23458;&#25143;&#31471;&#30340;&#27169;&#22411;/&#26356;&#26032;&#20043;&#38388;&#30340;&#26041;&#24046;&#36234;&#22823;&#65292;&#38544;&#34255; Byzantine attacks &#30340;&#31354;&#38388;&#23601;&#36234;&#22823;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#20351;&#29992;&#21160;&#37327;&#65292;&#20174;&#32780;&#20943;&#23569;&#26041;&#24046;&#65292;&#21487;&#20197;&#21066;&#24369;&#24050;&#30693; Byzantine attacks &#30340;&#21147;&#37327;&#12290;&#20013;&#24515;&#21270;&#21098;&#35009; (CC) &#26694;&#26550;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#19978;&#19968;&#27425;&#30340;&#21160;&#37327;&#39033;&#38500;&#20102;&#20943;&#23569;&#26041;&#24046;&#22806;&#65292;&#36824;&#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#21442;&#32771;&#28857;&#26356;&#22909;&#22320;&#28040;&#38500; Byzantine attacks&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#30340;&#24694;&#24847;&#20195;&#29702;&#26377;&#19981;&#21516;&#30446;&#26631;&#26102; CC &#30340;&#33030;&#24369;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#21098;&#35009;&#31639;&#27861;&#31216;&#20026;&#22810;&#24341;&#29992;&#28857;&#21098;&#35009; (MRPC)&#65292;&#20197;&#20811;&#26381;&#36825;&#31181;&#33030;&#24369;&#24615;&#12290;MRPC &#26694;&#26550;&#26377;&#25928;&#22320;&#21033;&#29992;&#22810;&#20010;&#21442;&#32771;&#28857;&#26469;&#28040;&#38500;&#19987;&#38376;&#35774;&#35745;&#20197;&#32469;&#36807; CC &#26041;&#27861;&#30340; Byzantine attacks&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#31867;&#22411;&#30340; Byzantine attacks &#19979;&#65292;MRPC &#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340; FL &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks, and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients' models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that, the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this wor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Auto-SDE&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#24930;-&#24555;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#26377;&#25928;&#38477;&#32500;&#21160;&#21147;&#23398;&#65292;&#36890;&#36807;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#31163;&#25955;&#21270;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25429;&#25417;&#20102;&#31995;&#32479;&#30340;&#28436;&#21270;&#29305;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.04151</link><description>&lt;p&gt;
Auto-SDE:&#20174;&#25968;&#25454;&#39537;&#21160;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#20013;&#23398;&#20064;&#26377;&#25928;&#30340;&#38477;&#32500;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Auto-SDE: Learning effective reduced dynamics from data-driven stochastic dynamical systems. (arXiv:2205.04151v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.04151
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Auto-SDE&#30340;&#31639;&#27861;&#26469;&#23398;&#20064;&#24930;-&#24555;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#26377;&#25928;&#38477;&#32500;&#21160;&#21147;&#23398;&#65292;&#36890;&#36807;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#31163;&#25955;&#21270;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65292;&#25429;&#25417;&#20102;&#31995;&#32479;&#30340;&#28436;&#21270;&#29305;&#24615;&#65292;&#24182;&#22312;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#33021;&#22815;&#25551;&#32472;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22797;&#26434;&#29616;&#35937;&#65292;&#22810;&#23610;&#24230;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#31185;&#23398;&#21644;&#24037;&#31243;&#38382;&#39064;&#12290;&#26412;&#25991;&#33268;&#21147;&#20110;&#30740;&#31350;&#24930;-&#24555;&#38543;&#26426;&#21160;&#21147;&#23398;&#31995;&#32479;&#30340;&#26377;&#25928;&#38477;&#32500;&#21160;&#21147;&#23398;&#12290;&#32473;&#23450;&#28385;&#36275;&#26576;&#20123;&#26410;&#30693;&#24930;-&#24555;&#38543;&#26426;&#31995;&#32479;&#30340;&#30701;&#26399;&#35266;&#27979;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21253;&#25324;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;Auto-SDE&#30340;&#26032;&#31639;&#27861;&#26469;&#23398;&#20064;&#19981;&#21464;&#30340;&#24930;&#27969;&#24418;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25429;&#25417;&#20102;&#19968;&#31995;&#21015;&#26102;&#38388;&#30456;&#20851;&#30340;&#33258;&#21160;&#32534;&#30721;&#22120;&#31070;&#32463;&#32593;&#32476;&#30340;&#28436;&#21270;&#29305;&#24615;&#65292;&#25439;&#22833;&#20989;&#25968;&#36890;&#36807;&#31163;&#25955;&#21270;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26500;&#36896;&#12290;&#36890;&#36807;&#22312;&#21508;&#31181;&#35780;&#20272;&#25351;&#26631;&#19979;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#20934;&#30830;&#24615;&#12289;&#31283;&#23450;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiscale stochastic dynamical systems have been widely adopted to scientific and engineering problems due to their capability of depicting complex phenomena in many real world applications. This work is devoted to investigating the effective reduced dynamics for a slow-fast stochastic dynamical system. Given observation data on a short-term period satisfying some unknown slow-fast stochastic system, we propose a novel algorithm including a neural network called Auto-SDE to learn invariant slow manifold. Our approach captures the evolutionary nature of a series of time-dependent autoencoder neural networks with the loss constructed from a discretized stochastic differential equation. Our algorithm is also proved to be accurate, stable and effective through numerical experiments under various evaluation metrics.
&lt;/p&gt;</description></item></channel></rss>