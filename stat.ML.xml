<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Lie&#32676;&#30340;&#21160;&#21147;&#23398;Langevin Monte Carlo&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21644;&#31934;&#32454;&#31163;&#25955;&#21270;&#23454;&#29616;&#20102;Lie&#32676;&#32467;&#26500;&#30340;&#20445;&#25345;&#65292;&#24182;&#22312;W2&#36317;&#31163;&#19979;&#35777;&#26126;&#20102;&#36830;&#32493;&#21160;&#21147;&#23398;&#21644;&#31163;&#25955;&#37319;&#26679;&#22120;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.12012</link><description>&lt;p&gt;
&#22522;&#20110;Lie&#32676;&#30340;&#21160;&#21147;&#23398;Langevin Monte Carlo&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of Kinetic Langevin Monte Carlo on Lie groups
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12012
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Lie&#32676;&#30340;&#21160;&#21147;&#23398;Langevin Monte Carlo&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21644;&#31934;&#32454;&#31163;&#25955;&#21270;&#23454;&#29616;&#20102;Lie&#32676;&#32467;&#26500;&#30340;&#20445;&#25345;&#65292;&#24182;&#22312;W2&#36317;&#31163;&#19979;&#35777;&#26126;&#20102;&#36830;&#32493;&#21160;&#21147;&#23398;&#21644;&#31163;&#25955;&#37319;&#26679;&#22120;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#21464;&#20998;&#20248;&#21270;&#21644;&#24038;&#24179;&#20961;&#21270;&#31561;&#25216;&#26415;&#26500;&#24314;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#12289;&#22522;&#20110;&#21160;&#37327;&#30340;&#21160;&#21147;&#23398;&#31995;&#32479;&#65292;&#29992;&#20110;&#20248;&#21270;&#23450;&#20041;&#22312;Lie&#32676;&#19978;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#36866;&#24403;&#22320;&#20026;&#20248;&#21270;&#21160;&#21147;&#23398;&#28155;&#21152;&#21487;&#22788;&#29702;&#30340;&#22122;&#22768;&#65292;&#23558;&#20854;&#36716;&#21270;&#20026;&#37319;&#26679;&#21160;&#21147;&#23398;&#65292;&#21033;&#29992;&#21160;&#37327;&#21464;&#37327;&#26159;&#27431;&#20960;&#37324;&#24471;&#30340;&#36825;&#19968;&#26377;&#21033;&#29305;&#24615;&#65292;&#23613;&#31649;&#28508;&#22312;&#20989;&#25968;&#23384;&#22312;&#20110;&#27969;&#24418;&#19978;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#31934;&#24515;&#31163;&#25955;&#21270;&#23548;&#33268;&#30340;&#21160;&#21147;&#23398;&#37319;&#26679;&#21160;&#21147;&#23398;&#25552;&#20986;&#20102;&#19968;&#20010;Lie&#32676;MCMC&#37319;&#26679;&#22120;&#12290;&#36825;&#31181;&#31163;&#25955;&#21270;&#23436;&#20840;&#20445;&#25345;&#20102;Lie&#32676;&#32467;&#26500;&#12290;&#22312;W2&#36317;&#31163;&#19979;&#65292;&#20998;&#21035;&#23545;&#36830;&#32493;&#21160;&#21147;&#23398;&#21644;&#31163;&#25955;&#37319;&#26679;&#22120;&#35777;&#26126;&#20102;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#20854;&#20013;&#21482;&#38656;&#35201;Lie&#32676;&#30340;&#32039;&#33268;&#24615;&#21644;&#28508;&#22312;&#20989;&#25968;&#30340;&#27979;&#22320;L-&#20809;&#28369;&#24615;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#23545;&#21160;&#21147;&#23398;Langevin&#31639;&#27861;&#30340;&#31532;&#19968;&#20010;&#25910;&#25947;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12012v1 Announce Type: cross  Abstract: Explicit, momentum-based dynamics for optimizing functions defined on Lie groups was recently constructed, based on techniques such as variational optimization and left trivialization. We appropriately add tractable noise to the optimization dynamics to turn it into a sampling dynamics, leveraging the advantageous feature that the momentum variable is Euclidean despite that the potential function lives on a manifold. We then propose a Lie-group MCMC sampler, by delicately discretizing the resulting kinetic-Langevin-type sampling dynamics. The Lie group structure is exactly preserved by this discretization. Exponential convergence with explicit convergence rate for both the continuous dynamics and the discrete sampler are then proved under W2 distance. Only compactness of the Lie group and geodesically L-smoothness of the potential function are needed. To the best of our knowledge, this is the first convergence result for kinetic Langev
&lt;/p&gt;</description></item><item><title>2023&#24180;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#21487;&#35299;&#37322;&#21644;&#21487;&#20449;&#36182;&#30340;&#26426;&#22120;&#23398;&#20064;&#21487;&#35270;&#21270;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#19988;&#19981;&#26029;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#20026;&#21508;&#31181;&#39046;&#22495;&#25552;&#20379;&#20102;&#36235;&#21183;&#12289;&#35265;&#35299;&#21644;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.12005</link><description>&lt;p&gt;
2023&#24180;&#26426;&#22120;&#23398;&#20064;&#20013;&#20449;&#20219;&#21487;&#35270;&#21270;&#30340;&#26368;&#26032;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Visualization for Trust in Machine Learning Revisited: The State of the Field in 2023
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12005
&lt;/p&gt;
&lt;p&gt;
2023&#24180;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#21487;&#35299;&#37322;&#21644;&#21487;&#20449;&#36182;&#30340;&#26426;&#22120;&#23398;&#20064;&#21487;&#35270;&#21270;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#19988;&#19981;&#26029;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#20026;&#21508;&#31181;&#39046;&#22495;&#25552;&#20379;&#20102;&#36235;&#21183;&#12289;&#35265;&#35299;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#21644;&#21487;&#20449;&#36182;&#30340;&#26426;&#22120;&#23398;&#20064;&#21487;&#35270;&#21270;&#20173;&#28982;&#26159;&#20449;&#24687;&#21487;&#35270;&#21270;&#21644;&#35270;&#35273;&#20998;&#26512;&#39046;&#22495;&#20013;&#26368;&#37325;&#35201;&#21644;&#28145;&#20837;&#30740;&#31350;&#30340;&#39046;&#22495;&#20043;&#19968;&#65292;&#28041;&#21450;&#21307;&#23398;&#12289;&#37329;&#34701;&#21644;&#29983;&#29289;&#20449;&#24687;&#23398;&#31561;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#12290;&#22312;&#25105;&#20204;2020&#24180;&#30340;&#26368;&#26032;&#25253;&#21578;&#20013;&#65292;&#21253;&#25324;&#20102;200&#31181;&#25216;&#26415;&#65292;&#25105;&#20204;&#22362;&#25345;&#25910;&#38598;&#21516;&#34892;&#35780;&#23457;&#30340;&#25991;&#31456;&#65292;&#25551;&#36848;&#21487;&#35270;&#21270;&#25216;&#26415;&#65292;&#26681;&#25454;&#20808;&#21069;&#24314;&#31435;&#30340;&#21253;&#21547;119&#20010;&#31867;&#21035;&#30340;&#20998;&#31867;&#27169;&#24335;&#23545;&#20854;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#22312;&#22312;&#32447;&#35843;&#26597;&#27983;&#35272;&#22120;&#20013;&#25552;&#20379;&#20102;542&#31181;&#25216;&#26415;&#30340;&#32467;&#26524;&#38598;&#12290;&#22312;&#26412;&#35843;&#26597;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25130;&#33267;2023&#24180;&#31179;&#23395;&#20851;&#20110;&#36825;&#19968;&#25968;&#25454;&#38598;&#30340;&#26032;&#20998;&#26512;&#32467;&#26524;&#65292;&#24182;&#35752;&#35770;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;&#21487;&#35270;&#21270;&#30340;&#36235;&#21183;&#12289;&#35265;&#35299;&#21644;&#20843;&#20010;&#24320;&#25918;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#23454;&#20102;&#21487;&#35270;&#21270;&#25216;&#26415;&#22312;&#22686;&#21152;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20449;&#20219;&#26041;&#38754;&#21576;&#24555;&#36895;&#22686;&#38271;&#30340;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12005v1 Announce Type: cross  Abstract: Visualization for explainable and trustworthy machine learning remains one of the most important and heavily researched fields within information visualization and visual analytics with various application domains, such as medicine, finance, and bioinformatics. After our 2020 state-of-the-art report comprising 200 techniques, we have persistently collected peer-reviewed articles describing visualization techniques, categorized them based on the previously established categorization schema consisting of 119 categories, and provided the resulting collection of 542 techniques in an online survey browser. In this survey article, we present the updated findings of new analyses of this dataset as of fall 2023 and discuss trends, insights, and eight open challenges for using visualizations in machine learning. Our results corroborate the rapidly growing trend of visualization techniques for increasing trust in machine learning models in the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;&#26080;&#20998;&#31867;&#22120;&#24341;&#23548;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#23574;&#38160;&#32479;&#35745;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#36866;&#24212;&#25968;&#25454;&#20998;&#24067;&#24179;&#28369;&#24230;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#39062;&#30340;&#25193;&#25955;&#27888;&#21202;&#36924;&#36817;&#25216;&#26415;&#22312;&#29702;&#35770;&#21457;&#23637;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.11968</link><description>&lt;p&gt;
&#25581;&#31034;&#26080;&#20998;&#31867;&#22120;&#24341;&#23548;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65306;&#19968;&#20010;&#23574;&#38160;&#30340;&#32479;&#35745;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Unveil Conditional Diffusion Models with Classifier-free Guidance: A Sharp Statistical Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#26080;&#20998;&#31867;&#22120;&#24341;&#23548;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#23574;&#38160;&#32479;&#35745;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#36866;&#24212;&#25968;&#25454;&#20998;&#24067;&#24179;&#28369;&#24230;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#26032;&#39062;&#30340;&#25193;&#25955;&#27888;&#21202;&#36924;&#36817;&#25216;&#26415;&#22312;&#29702;&#35770;&#21457;&#23637;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11968v1 &#20844;&#21578;&#31867;&#22411;: &#26032; &#20855;&#26377;&#20998;&#31867;&#26465;&#20214;&#30340;&#25193;&#25955;&#27169;&#22411;&#26159;&#29616;&#20195;&#22270;&#20687;&#21512;&#25104;&#30340;&#22522;&#30784;&#65292;&#22312;&#35745;&#31639;&#29983;&#29289;&#23398;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#32467;&#21512;&#21508;&#31181;&#26465;&#20214;&#20449;&#24687;&#65292;&#22914;&#25552;&#31034;&#36755;&#20837;&#65292;&#20197;&#24341;&#23548;&#26679;&#26412;&#29983;&#25104;&#21040;&#25152;&#38656;&#30340;&#23646;&#24615;&#12290;&#23613;&#31649;&#32463;&#39564;&#19978;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#29702;&#35770;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#23578;&#19981;&#23436;&#22791;&#12290;&#26412;&#25991;&#36890;&#36807;&#23637;&#31034;&#20351;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#20998;&#24067;&#20272;&#35745;&#30340;&#23574;&#38160;&#32479;&#35745;&#29702;&#35770;&#26469;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24471;&#20986;&#19968;&#20010;&#36866;&#24212;&#25968;&#25454;&#20998;&#24067;&#24179;&#28369;&#24230;&#24182;&#21305;&#37197;&#26497;&#23567;&#26497;&#20540;&#19979;&#38480;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#25105;&#20204;&#29702;&#35770;&#21457;&#23637;&#30340;&#20851;&#38190;&#22312;&#20110;&#26465;&#20214;&#35780;&#20998;&#20989;&#25968;&#30340;&#36924;&#36817;&#32467;&#26524;&#65292;&#20381;&#36182;&#20110;&#19968;&#31181;&#26032;&#39062;&#30340;&#25193;&#25955;&#27888;&#21202;&#36924;&#36817;&#25216;&#26415;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32479;&#35745;&#29702;&#35770;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11968v1 Announce Type: new  Abstract: Conditional diffusion models serve as the foundation of modern image synthesis and find extensive application in fields like computational biology and reinforcement learning. In these applications, conditional diffusion models incorporate various conditional information, such as prompt input, to guide the sample generation towards desired properties. Despite the empirical success, theory of conditional diffusion models is largely missing. This paper bridges this gap by presenting a sharp statistical theory of distribution estimation using conditional diffusion models. Our analysis yields a sample complexity bound that adapts to the smoothness of the data distribution and matches the minimax lower bound. The key to our theoretical development lies in an approximation result for the conditional score function, which relies on a novel diffused Taylor approximation technique. Moreover, we demonstrate the utility of our statistical theory in 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Quantile Recalibration Training&#30340;&#26032;&#22411;&#31471;&#21040;&#31471;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#65292;&#23558;&#21518;&#22788;&#29702;&#26657;&#20934;&#30452;&#25509;&#25972;&#21512;&#21040;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26080;&#38656;&#39069;&#22806;&#21442;&#25968;&#65292;&#23637;&#31034;&#20986;&#22312;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#20013;&#25552;&#39640;&#26657;&#20934;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.11964</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#35774;&#35745;&#27010;&#29575;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Calibration by Design for Neural Network Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11964
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Quantile Recalibration Training&#30340;&#26032;&#22411;&#31471;&#21040;&#31471;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#65292;&#23558;&#21518;&#22788;&#29702;&#26657;&#20934;&#30452;&#25509;&#25972;&#21512;&#21040;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26080;&#38656;&#39069;&#22806;&#21442;&#25968;&#65292;&#23637;&#31034;&#20986;&#22312;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#20013;&#25552;&#39640;&#26657;&#20934;&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#35768;&#22810;&#30495;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#36827;&#34892;&#26368;&#20339;&#20915;&#31574;&#65292;&#20026;&#22238;&#24402;&#38382;&#39064;&#29983;&#25104;&#32463;&#36807;&#26657;&#20934;&#19988;&#31934;&#30830;&#30340;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20998;&#24067;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#30340;&#35823;&#26657;&#20934;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#21508;&#31181;&#25913;&#21892;&#26657;&#20934;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#35757;&#32451;&#21518;&#35843;&#25972;&#39044;&#27979;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#21644;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36827;&#34892;&#25805;&#20316;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#12290;&#34429;&#28982;&#19982;&#27491;&#21017;&#21270;&#26041;&#27861;&#30456;&#27604;&#65292;&#21518;&#22788;&#29702;&#26041;&#27861;&#22312;&#26657;&#20934;&#26041;&#38754;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#25913;&#36827;&#65292;&#20294;&#21518;&#22788;&#29702;&#27493;&#39588;&#19982;&#27169;&#22411;&#35757;&#32451;&#23436;&#20840;&#29420;&#31435;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Quantile Recalibration Training&#30340;&#26032;&#22411;&#31471;&#21040;&#31471;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#65292;&#23558;&#21518;&#22788;&#29702;&#26657;&#20934;&#30452;&#25509;&#25972;&#21512;&#21040;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#31639;&#27861;&#65292;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#20854;&#20182;&#21518;&#22788;&#29702;&#26041;&#27861;&#20197;&#21450;&#27491;&#21017;&#21270;&#26041;&#27861;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#21253;&#21547;&#22312;&#20869;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#19968;&#20010;&#22823;&#35268;&#27169;&#38382;&#39064;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11964v1 Announce Type: new  Abstract: Generating calibrated and sharp neural network predictive distributions for regression problems is essential for optimal decision-making in many real-world applications. To address the miscalibration issue of neural networks, various methods have been proposed to improve calibration, including post-hoc methods that adjust predictions after training and regularization methods that act during training. While post-hoc methods have shown better improvement in calibration compared to regularization methods, the post-hoc step is completely independent of model training. We introduce a novel end-to-end model training procedure called Quantile Recalibration Training, integrating post-hoc calibration directly into the training process without additional parameters. We also present a unified algorithm that includes our method and other post-hoc and regularization methods, as particular cases. We demonstrate the performance of our method in a large
&lt;/p&gt;</description></item><item><title>&#20302;&#27425;&#22810;&#39033;&#24335;&#20272;&#35745;&#31867;&#19978;&#30340;&#36801;&#31227;&#23398;&#20064;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#23545;&#20110;&#20302;&#27425;&#22810;&#39033;&#24335;&#26469;&#35828;&#38750;&#24179;&#20961;&#30340;&#36801;&#31227;&#23398;&#20064;&#26159;&#21487;&#33021;&#30340;&#65292;&#36229;&#36234;&#20102;$dQ/dP$&#26377;&#30028;&#30340;&#32463;&#20856;&#20551;&#35774;</title><link>https://arxiv.org/abs/2403.11963</link><description>&lt;p&gt;
&#36229;&#36234;&#26377;&#30028;&#23494;&#24230;&#27604;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning Beyond Bounded Density Ratios
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11963
&lt;/p&gt;
&lt;p&gt;
&#20302;&#27425;&#22810;&#39033;&#24335;&#20272;&#35745;&#31867;&#19978;&#30340;&#36801;&#31227;&#23398;&#20064;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#23545;&#20110;&#20302;&#27425;&#22810;&#39033;&#24335;&#26469;&#35828;&#38750;&#24179;&#20961;&#30340;&#36801;&#31227;&#23398;&#20064;&#26159;&#21487;&#33021;&#30340;&#65292;&#36229;&#36234;&#20102;$dQ/dP$&#26377;&#30028;&#30340;&#32463;&#20856;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#36801;&#31227;&#23398;&#20064;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#23398;&#20064;&#31639;&#27861;&#20174;&#26576;&#20010;&#28304;&#20998;&#24067;$P$&#25910;&#38598;&#25968;&#25454;&#65292;&#20294;&#38656;&#35201;&#22312;&#19981;&#21516;&#30340;&#30446;&#26631;&#20998;&#24067;$Q$&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#26631;&#20934;&#30340;&#27979;&#24230;&#21464;&#25442;&#35770;&#35777;&#34920;&#26126;&#65292;&#24403;&#23494;&#24230;&#27604;$dQ/dP$&#26377;&#30028;&#26102;&#21457;&#29983;&#36801;&#31227;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;Kpotufe&#21644;Martinet(2018&#24180;COLT)&#20197;&#21450;Hanneke&#21644;Kpotufe(2019&#24180;NeurIPS)&#20043;&#21069;&#24341;&#20154;&#28145;&#24605;&#30340;&#20316;&#21697;&#23637;&#31034;&#20102;&#19968;&#20123;&#24773;&#20917;&#65292;&#20854;&#20013;&#27604;&#29575;$dQ/dP$&#26159;&#26080;&#30028;&#30340;&#65292;&#20294;&#36801;&#31227;&#23398;&#20064;&#26159;&#21487;&#33021;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#22312;&#20302;&#27425;&#22810;&#39033;&#24335;&#20272;&#35745;&#31867;&#19978;&#36827;&#34892;&#36801;&#31227;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#22312;&#23450;&#20041;&#22495;$\mathbb{R}^n$&#19978;&#30340;&#19968;&#33324;&#36801;&#31227;&#19981;&#31561;&#24335;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#23545;&#20110;&#20302;&#27425;&#22810;&#39033;&#24335;&#26469;&#35828;&#38750;&#24179;&#20961;&#30340;&#36801;&#31227;&#23398;&#20064;&#26159;&#21487;&#33021;&#30340;&#65292;&#36828;&#36828;&#36229;&#20986;&#20102;$dQ/dP$&#34987;&#26377;&#30028;&#30340;&#32463;&#20856;&#20551;&#35774;&#12290;&#20363;&#22914;&#65292;&#22914;&#26524;$Q$&#26159;&#23545;&#25968;&#20985;&#27979;&#24230;&#65292;&#21017;&#22987;&#32456;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11963v1 Announce Type: new  Abstract: We study the fundamental problem of transfer learning where a learning algorithm collects data from some source distribution $P$ but needs to perform well with respect to a different target distribution $Q$. A standard change of measure argument implies that transfer learning happens when the density ratio $dQ/dP$ is bounded. Yet, prior thought-provoking works by Kpotufe and Martinet (COLT, 2018) and Hanneke and Kpotufe (NeurIPS, 2019) demonstrate cases where the ratio $dQ/dP$ is unbounded, but transfer learning is possible.   In this work, we focus on transfer learning over the class of low-degree polynomial estimators. Our main result is a general transfer inequality over the domain $\mathbb{R}^n$, proving that non-trivial transfer learning for low-degree polynomials is possible under very mild assumptions, going well beyond the classical assumption that $dQ/dP$ is bounded. For instance, it always applies if $Q$ is a log-concave measur
&lt;/p&gt;</description></item><item><title>CASPER&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25554;&#34917;&#38382;&#39064;&#65292;&#36991;&#20813;&#36807;&#24230;&#21033;&#29992;&#38750;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#25968;&#25454;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.11960</link><description>&lt;p&gt;
CASPER&#65306;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#26102;&#31354;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25554;&#34917;
&lt;/p&gt;
&lt;p&gt;
CASPER: Causality-Aware Spatiotemporal Graph Neural Networks for Spatiotemporal Time Series Imputation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11960
&lt;/p&gt;
&lt;p&gt;
CASPER&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#20851;&#31995;&#24863;&#30693;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25554;&#34917;&#38382;&#39064;&#65292;&#36991;&#20813;&#36807;&#24230;&#21033;&#29992;&#38750;&#22240;&#26524;&#20851;&#31995;&#65292;&#25552;&#39640;&#25968;&#25454;&#20998;&#26512;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11960v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25552;&#35201;&#65306;&#26102;&#31354;&#26102;&#38388;&#24207;&#21015;&#26159;&#29702;&#35299;&#20154;&#31867;&#27963;&#21160;&#21450;&#20854;&#24433;&#21709;&#30340;&#22522;&#30784;&#65292;&#36890;&#24120;&#36890;&#36807;&#25918;&#32622;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#30417;&#27979;&#20256;&#24863;&#22120;&#25910;&#38598;&#12290;&#25910;&#38598;&#21040;&#30340;&#25968;&#25454;&#36890;&#24120;&#21253;&#21547;&#30001;&#20110;&#21508;&#31181;&#25925;&#38556;&#32780;&#23548;&#33268;&#30340;&#32570;&#22833;&#20540;&#65292;&#36825;&#23545;&#25968;&#25454;&#20998;&#26512;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#20026;&#20102;&#22635;&#34917;&#32570;&#22833;&#20540;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#12290;&#22312;&#24674;&#22797;&#29305;&#23450;&#25968;&#25454;&#28857;&#26102;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#26041;&#27861;&#20542;&#21521;&#20110;&#32771;&#34385;&#19982;&#35813;&#28857;&#30456;&#20851;&#30340;&#25152;&#26377;&#20449;&#24687;&#65292;&#26080;&#35770;&#23427;&#20204;&#26159;&#21542;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#12290;&#22312;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#20013;&#65292;&#21253;&#25324;&#19968;&#20123;&#26410;&#30693;&#28151;&#26434;&#22240;&#32032;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#20363;&#22914;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#32972;&#26223;&#22122;&#22768;&#21644;&#26500;&#24314;&#30340;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#30340;&#38750;&#22240;&#26524;&#24555;&#25463;&#36793;&#12290;&#36825;&#20123;&#28151;&#26434;&#22240;&#32032;&#21487;&#33021;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#24320;&#36767;&#21453;&#21521;&#36335;&#24452;&#65292;&#25442;&#21477;&#35805;&#35828;&#65292;&#23427;&#20204;&#24314;&#31435;&#20102;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#30340;&#38750;&#22240;&#26524;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11960v1 Announce Type: new  Abstract: Spatiotemporal time series is the foundation of understanding human activities and their impacts, which is usually collected via monitoring sensors placed at different locations. The collected data usually contains missing values due to various failures, which have significant impact on data analysis. To impute the missing values, a lot of methods have been introduced. When recovering a specific data point, most existing methods tend to take into consideration all the information relevant to that point regardless of whether they have a cause-and-effect relationship. During data collection, it is inevitable that some unknown confounders are included, e.g., background noise in time series and non-causal shortcut edges in the constructed sensor network. These confounders could open backdoor paths between the input and output, in other words, they establish non-causal correlations between the input and output. Over-exploiting these non-causa
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;PESCAL&#65292;&#21033;&#29992;&#22522;&#20110;&#21069;&#38376;&#26631;&#20934;&#30340;&#20013;&#20171;&#21464;&#37327;&#28040;&#38500;&#28151;&#26434;&#20559;&#24046;&#65292;&#24182;&#37319;&#29992;&#24754;&#35266;&#21407;&#21017;&#22788;&#29702;&#20505;&#36873;&#31574;&#30053;&#24341;&#36215;&#30340;&#20998;&#24067;&#21464;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.11841</link><description>&lt;p&gt;
&#22522;&#20110;&#20013;&#20171;&#22240;&#32032;&#30340;&#24754;&#35266;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#28151;&#26434;&#30340;&#31163;&#32447;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Pessimistic Causal Reinforcement Learning with Mediators for Confounded Offline Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11841
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;PESCAL&#65292;&#21033;&#29992;&#22522;&#20110;&#21069;&#38376;&#26631;&#20934;&#30340;&#20013;&#20171;&#21464;&#37327;&#28040;&#38500;&#28151;&#26434;&#20559;&#24046;&#65292;&#24182;&#37319;&#29992;&#24754;&#35266;&#21407;&#21017;&#22788;&#29702;&#20505;&#36873;&#31574;&#30053;&#24341;&#36215;&#30340;&#20998;&#24067;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#30001;&#38543;&#26426;&#23454;&#39564;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#24448;&#24448;&#21463;&#21040;&#26102;&#38388;&#21644;&#39044;&#31639;&#38480;&#21046;&#32780;&#35268;&#27169;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#22823;&#35268;&#27169;&#30340;&#35266;&#27979;&#25968;&#25454;&#38598;&#25104;&#20026;&#23454;&#29616;&#39640;&#36136;&#37327;&#31574;&#30053;&#23398;&#20064;&#26356;&#20855;&#21560;&#24341;&#21147;&#30340;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#27861;&#20381;&#36182;&#20110;&#20004;&#20010;&#20851;&#38190;&#20551;&#35774;-- &#38750;&#28151;&#26434;&#24615;&#21644;&#27491;&#24615;-- &#36825;&#20004;&#20010;&#20551;&#35774;&#22312;&#35266;&#27979;&#25968;&#25454;&#29615;&#22659;&#20013;&#32463;&#24120;&#19981;&#25104;&#31435;&#12290;&#37492;&#20110;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;&#24754;&#35266;&#22240;&#26524;&#23398;&#20064;&#65288;PESCAL&#65289;&#12290;&#25105;&#20204;&#21033;&#29992;&#22522;&#20110;&#21069;&#38376;&#26631;&#20934;&#30340;&#20013;&#20171;&#21464;&#37327;&#26469;&#28040;&#38500;&#28151;&#26434;&#20559;&#24046;&#65307;&#27492;&#22806;&#65292;&#25105;&#20204;&#37319;&#29992;&#24754;&#35266;&#21407;&#21017;&#26469;&#35299;&#20915;&#30001;&#20505;&#36873;&#31574;&#30053;&#24341;&#36215;&#30340;&#21160;&#20316;&#20998;&#24067;&#19982;&#29983;&#25104;&#35266;&#27979;&#25968;&#25454;&#30340;&#34892;&#20026;&#31574;&#30053;&#20043;&#38388;&#30340;&#20998;&#24067;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#36890;&#36807;&#34701;&#21512;&#36741;&#21161;&#21464;&#37327;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11841v1 Announce Type: cross  Abstract: In real-world scenarios, datasets collected from randomized experiments are often constrained by size, due to limitations in time and budget. As a result, leveraging large observational datasets becomes a more attractive option for achieving high-quality policy learning. However, most existing offline reinforcement learning (RL) methods depend on two key assumptions--unconfoundedness and positivity--which frequently do not hold in observational data contexts. Recognizing these challenges, we propose a novel policy learning algorithm, PESsimistic CAusal Learning (PESCAL). We utilize the mediator variable based on front-door criterion to remove the confounding bias; additionally, we adopt the pessimistic principle to address the distributional shift between the action distributions induced by candidate policies, and the behavior policy that generates the observational data. Our key observation is that, by incorporating auxiliary variable
&lt;/p&gt;</description></item><item><title>&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#20559;&#22909;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#29702;&#24615;&#21407;&#21017;&#34701;&#20837;&#23398;&#20064;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.11782</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20174;&#20559;&#22909;&#21644;&#36873;&#25321;&#20013;&#23398;&#20064;&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A tutorial on learning from preferences and choices with Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11782
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#20559;&#22909;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#29702;&#24615;&#21407;&#21017;&#34701;&#20837;&#23398;&#20064;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#22909;&#24314;&#27169;&#20301;&#20110;&#32463;&#27982;&#23398;&#12289;&#20915;&#31574;&#29702;&#35770;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#29702;&#35299;&#20010;&#20307;&#30340;&#20559;&#22909;&#21450;&#20854;&#36873;&#25321;&#26041;&#24335;&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#26356;&#25509;&#36817;&#20182;&#20204;&#26399;&#26395;&#30340;&#20135;&#21697;&#65292;&#20026;&#36328;&#39046;&#22495;&#30340;&#26356;&#39640;&#25928;&#12289;&#20010;&#24615;&#21270;&#24212;&#29992;&#38138;&#24179;&#36947;&#36335;&#12290;&#27492;&#25945;&#31243;&#30340;&#30446;&#26631;&#26159;&#25552;&#20379;&#19968;&#20010;&#36830;&#36143;&#12289;&#20840;&#38754;&#30340;&#20559;&#22909;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#28436;&#31034;&#22914;&#20309;&#23558;&#29702;&#24615;&#21407;&#21017;&#65288;&#26469;&#33258;&#32463;&#27982;&#23398;&#21644;&#20915;&#31574;&#29702;&#35770;&#65289;&#26080;&#32541;&#22320;&#32435;&#20837;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#36890;&#36807;&#21512;&#36866;&#22320;&#23450;&#21046;&#20284;&#28982;&#20989;&#25968;&#65292;&#36825;&#19968;&#26694;&#26550;&#20351;&#24471;&#33021;&#22815;&#26500;&#24314;&#28085;&#30422;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#12289;&#36776;&#35782;&#38480;&#21046;&#21644;&#23545;&#35937;&#21644;&#26631;&#31614;&#20559;&#22909;&#30340;&#22810;&#37325;&#20914;&#31361;&#25928;&#29992;&#24773;&#26223;&#30340;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11782v1 Announce Type: new  Abstract: Preference modelling lies at the intersection of economics, decision theory, machine learning and statistics. By understanding individuals' preferences and how they make choices, we can build products that closely match their expectations, paving the way for more efficient and personalised applications across a wide range of domains. The objective of this tutorial is to present a cohesive and comprehensive framework for preference learning with Gaussian Processes (GPs), demonstrating how to seamlessly incorporate rationality principles (from economics and decision theory) into the learning process. By suitably tailoring the likelihood function, this framework enables the construction of preference learning models that encompass random utility models, limits of discernment, and scenarios with multiple conflicting utilities for both object- and label-preference. This tutorial builds upon established research while simultaneously introducin
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#36716;&#23548;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;PARMESAN&#65292;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#21644;&#36716;&#23548;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#26080;&#38656;&#36830;&#32493;&#35757;&#32451;&#30340;&#23398;&#20064;&#12290;</title><link>https://arxiv.org/abs/2403.11743</link><description>&lt;p&gt;
PARMESAN: &#29992;&#20110;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#19982;&#36716;&#23548;
&lt;/p&gt;
&lt;p&gt;
PARMESAN: Parameter-Free Memory Search and Transduction for Dense Prediction Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11743
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#36716;&#23548;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;PARMESAN&#65292;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#30340;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#21644;&#36716;&#23548;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#26080;&#38656;&#36830;&#32493;&#35757;&#32451;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#36716;&#23548;&#25512;&#29702;&#26469;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#28789;&#27963;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;PARMESAN&#65288;&#26080;&#21442;&#25968;&#20869;&#23384;&#25628;&#32034;&#19982;&#36716;&#23548;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36716;&#23548;&#26041;&#27861;&#65292;&#21033;&#29992;&#20869;&#23384;&#27169;&#22359;&#26469;&#35299;&#20915;&#23494;&#38598;&#39044;&#27979;&#20219;&#21153;&#12290;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#20869;&#23384;&#20013;&#30340;&#38544;&#34255;&#34920;&#31034;&#34987;&#25628;&#32034;&#20197;&#25214;&#21040;&#30456;&#24212;&#30340;&#31034;&#20363;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;PARMESAN&#36890;&#36807;&#20462;&#25913;&#20869;&#23384;&#20869;&#23481;&#23398;&#20064;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#20219;&#20309;&#36830;&#32493;&#35757;&#32451;&#25110;&#24494;&#35843;&#21487;&#23398;&#20064;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#24120;&#29992;&#30340;&#31070;&#32463;&#32467;&#26500;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11743v1 Announce Type: new  Abstract: In this work we address flexibility in deep learning by means of transductive reasoning. For adaptation to new tasks or new data, existing methods typically involve tuning of learnable parameters or even complete re-training from scratch, rendering such approaches unflexible in practice. We argue that the notion of separating computation from memory by the means of transduction can act as a stepping stone for solving these issues. We therefore propose PARMESAN (parameter-free memory search and transduction), a scalable transduction method which leverages a memory module for solving dense prediction tasks. At inference, hidden representations in memory are being searched to find corresponding examples. In contrast to other methods, PARMESAN learns without the requirement for any continuous training or fine-tuning of learnable parameters simply by modifying the memory content. Our method is compatible with commonly used neural architecture
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20351;&#29992;&#20809;&#35889;&#31639;&#27861;&#26469;&#35757;&#32451;&#26680;&#65292;&#25512;&#23548;&#20986;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#65292;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#25439;&#22833;&#28176;&#36817;&#34892;&#20026;&#65292;&#23637;&#31034;&#20102;&#25439;&#22833;&#22312;&#29305;&#23450;&#39057;&#35889;&#23610;&#24230;&#19978;&#30340;&#23616;&#37096;&#21270;&#12290;</title><link>https://arxiv.org/abs/2403.11696</link><description>&lt;p&gt;
&#20809;&#35889;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Generalization error of spectral algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20351;&#29992;&#20809;&#35889;&#31639;&#27861;&#26469;&#35757;&#32451;&#26680;&#65292;&#25512;&#23548;&#20986;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#65292;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#25439;&#22833;&#28176;&#36817;&#34892;&#20026;&#65292;&#23637;&#31034;&#20102;&#25439;&#22833;&#22312;&#29305;&#23450;&#39057;&#35889;&#23610;&#24230;&#19978;&#30340;&#23616;&#37096;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#20851;&#27880;&#26680;&#26041;&#27861;&#27867;&#21270;&#30340;&#28176;&#36817;&#31934;&#30830;&#20272;&#35745;&#65292;&#28304;&#20110;&#31070;&#32463;&#32593;&#32476;&#21450;&#20854;&#30456;&#20851;&#26680;&#20043;&#38388;&#30340;&#31867;&#27604;&#12290;&#28982;&#32780;&#65292;&#20197;&#24448;&#30340;&#30740;&#31350;&#26159;&#36890;&#36807;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#25512;&#23548;&#20986;&#36825;&#20123;&#20272;&#35745;&#20540;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#26159;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#20351;&#29992;&#30001;&#37197;&#32622;&#25991;&#20214;$h(\lambda)$&#25351;&#23450;&#30340;&#19968;&#31995;&#21015;&#8220;&#20809;&#35889;&#31639;&#27861;&#8221;&#26469;&#35757;&#32451;&#26680;&#65292;&#20854;&#20013;&#21253;&#25324;KRR&#21644;GD&#20316;&#20026;&#29305;&#20363;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20851;&#20110;&#20004;&#31181;&#25968;&#25454;&#27169;&#22411;&#30340;&#23398;&#20064;&#37197;&#32622;&#25991;&#20214;$h(\lambda)$&#30340;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#65306;&#39640;&#32500;&#39640;&#26031;&#27169;&#22411;&#21644;&#20302;&#32500;&#24179;&#31227;&#19981;&#21464;&#27169;&#22411;&#12290;&#22312;&#23545;&#26680;&#21644;&#30446;&#26631;&#30340;&#39057;&#35889;&#36827;&#34892;&#24130;&#24459;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#26469;(i)&#20026;&#26377;&#22122;&#21644;&#26080;&#22122;&#35266;&#27979;&#25552;&#20379;&#23436;&#25972;&#30340;&#25439;&#22833;&#28176;&#36817;&#34892;&#20026;&#65307;(ii)&#23637;&#31034;&#25439;&#22833;&#20986;&#29616;&#22312;&#26576;&#20123;&#39057;&#35889;&#23610;&#24230;&#19978;&#30340;&#23616;&#37096;&#21270;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11696v1 Announce Type: new  Abstract: The asymptotically precise estimation of the generalization of kernel methods has recently received attention due to the parallels between neural networks and their associated kernels. However, prior works derive such estimates for training by kernel ridge regression (KRR), whereas neural networks are typically trained with gradient descent (GD). In the present work, we consider the training of kernels with a family of $\textit{spectral algorithms}$ specified by profile $h(\lambda)$, and including KRR and GD as special cases. Then, we derive the generalization error as a functional of learning profile $h(\lambda)$ for two data models: high-dimensional Gaussian and low-dimensional translation-invariant model. Under power-law assumptions on the spectrum of the kernel and target, we use our framework to (i) give full loss asymptotics for both noisy and noiseless observations (ii) show that the loss localizes on certain spectral scales, givi
&lt;/p&gt;</description></item><item><title>&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#19979;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#20869;&#26144;&#23556;&#30340;&#22806;&#26144;&#23556;&#22266;&#23450;&#28857;&#30340;&#38544;&#24335;&#23548;&#25968;&#30340;&#26032;&#26041;&#27861;NSID&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11687</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#38544;&#24335;&#24494;&#20998;&#65306;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11687
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#19979;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#20869;&#26144;&#23556;&#30340;&#22806;&#26144;&#23556;&#22266;&#23450;&#28857;&#30340;&#38544;&#24335;&#23548;&#25968;&#30340;&#26032;&#26041;&#27861;NSID&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#25928;&#35745;&#31639;&#21442;&#25968;&#21270;&#19981;&#21487;&#24494;&#25910;&#32553;&#26144;&#23556;&#22266;&#23450;&#28857;&#23548;&#25968;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65306;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#12290;&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#38142;&#35268;&#21017;&#19981;&#20877;&#25104;&#31435;&#12290;&#22312;Bolte&#31561;&#20154;&#65288;2022&#65289;&#26368;&#36817;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#20182;&#20204;&#35777;&#26126;&#20102;&#19981;&#21487;&#24494;&#20998;ITD&#30340;&#32447;&#24615;&#25910;&#25947;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;ITD&#21644;AID&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;NSID&#65292;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22266;&#23450;&#28857;&#34987;&#23450;&#20041;&#20026;&#21482;&#36890;&#36807;&#38543;&#26426;&#26080;&#20559;&#20272;&#35745;&#22120;&#35775;&#38382;&#30340;&#22806;&#26144;&#23556;&#21644;&#20869;&#26144;&#23556;&#30340;&#32452;&#21512;&#26102;&#35745;&#31639;&#38544;&#24335;&#23548;&#25968;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11687v1 Announce Type: cross  Abstract: We study the problem of efficiently computing the derivative of the fixed-point of a parametric non-differentiable contraction map. This problem has wide applications in machine learning, including hyperparameter optimization, meta-learning and data poisoning attacks. We analyze two popular approaches: iterative differentiation (ITD) and approximate implicit differentiation (AID). A key challenge behind the nonsmooth setting is that the chain rule does not hold anymore. Building upon the recent work by Bolte et al. (2022), who proved the linear convergence of non-differentiable ITD, we provide refined linear convergence rates for both ITD and AID in the deterministic case. We further introduce NSID, a new method to compute the implicit derivative when the fixed point is defined as the composition of an outer map and an inner map which is accessible only through a stochastic unbiased estimator. We establish rates for the convergence of 
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#24471;&#20986;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11637</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
The Value of Reward Lookahead in Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11637
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21033;&#29992;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20215;&#20540;&#65292;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#24471;&#20986;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#65292;&#20195;&#29702;&#20204;&#19982;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#36827;&#34892;&#39034;&#24207;&#20132;&#20114;&#65292;&#26088;&#22312;&#26368;&#22823;&#21270;&#33719;&#24471;&#30340;&#22870;&#21169;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#22870;&#21169;&#20165;&#22312;&#34892;&#21160;&#21518;&#34987;&#35266;&#23519;&#21040;&#65292;&#22240;&#27492;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#39044;&#26399;&#32047;&#31215;&#22870;&#21169;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#22870;&#21169;&#20449;&#24687;&#26159;&#25552;&#21069;&#35266;&#23519;&#21040;&#30340; -- &#20132;&#26131;&#21069;&#35266;&#23519;&#21040;&#20215;&#26684;&#65307;&#20102;&#35299;&#37096;&#20998;&#38468;&#36817;&#20132;&#36890;&#20449;&#24687;&#65307;&#32463;&#24120;&#22312;&#20114;&#21160;&#20043;&#21069;&#20026;&#20195;&#29702;&#20998;&#37197;&#30446;&#26631;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#31454;&#20105;&#24615;&#20998;&#26512;&#30340;&#35270;&#35282;&#65292;&#23450;&#37327;&#20998;&#26512;&#36825;&#31181;&#26410;&#26469;&#22870;&#21169;&#20449;&#24687;&#30340;&#20215;&#20540;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#27979;&#37327;&#20102;&#26631;&#20934;RL&#20195;&#29702;&#30340;&#20215;&#20540;&#19982;&#20855;&#26377;&#37096;&#20998;&#26410;&#26469;&#22870;&#21169;&#20808;&#30693;&#30340;&#20195;&#29702;&#20043;&#38388;&#30340;&#27604;&#29575;&#12290;&#25105;&#20204;&#21051;&#30011;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#22870;&#21169;&#20998;&#24067;&#65292;&#24182;&#25512;&#23548;&#20986;&#26368;&#22351;&#24773;&#20917;&#19979;&#22870;&#21169;&#26399;&#26395;&#30340;&#31934;&#30830;&#27604;&#29575;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#32467;&#26524;&#27604;&#29575;&#19982;&#31163;&#32447;RL&#21644;r&#20013;&#24050;&#30693;&#30340;&#25968;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11637v1 Announce Type: new  Abstract: In reinforcement learning (RL), agents sequentially interact with changing environments while aiming to maximize the obtained rewards. Usually, rewards are observed only after acting, and so the goal is to maximize the expected cumulative reward. Yet, in many practical settings, reward information is observed in advance -- prices are observed before performing transactions; nearby traffic information is partially known; and goals are oftentimes given to agents prior to the interaction. In this work, we aim to quantifiably analyze the value of such future reward information through the lens of competitive analysis. In particular, we measure the ratio between the value of standard RL agents and that of agents with partial future-reward lookahead. We characterize the worst-case reward distribution and derive exact ratios for the worst-case reward expectations. Surprisingly, the resulting ratios relate to known quantities in offline RL and r
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#26469;&#35780;&#20272;&#20998;&#24067;&#22806;&#65288;OOD&#65289;&#26816;&#27979;&#20013;&#25928;&#29575;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#26032;&#30340;&#31526;&#21512;AUROC&#21644;&#31526;&#21512;FRP@TPR95&#25351;&#26631;&#65292;&#20026;OOD&#21644;&#24322;&#24120;&#26816;&#27979;&#22522;&#20934;&#25552;&#20379;&#20102;&#27010;&#29575;&#20445;&#23432;&#24615;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.11532</link><description>&lt;p&gt;
&#24212;&#35813;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#36827;&#34892;&#20998;&#24067;&#22806;&#26816;&#27979;&#65288;&#21453;&#20043;&#20134;&#28982;&#65311;&#65289;
&lt;/p&gt;
&lt;p&gt;
Out-of-Distribution Detection Should Use Conformal Prediction (and Vice-versa?)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20351;&#29992;&#31526;&#21512;&#39044;&#27979;&#26469;&#35780;&#20272;&#20998;&#24067;&#22806;&#65288;OOD&#65289;&#26816;&#27979;&#20013;&#25928;&#29575;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#23450;&#20041;&#20102;&#26032;&#30340;&#31526;&#21512;AUROC&#21644;&#31526;&#21512;FRP@TPR95&#25351;&#26631;&#65292;&#20026;OOD&#21644;&#24322;&#24120;&#26816;&#27979;&#22522;&#20934;&#25552;&#20379;&#20102;&#27010;&#29575;&#20445;&#23432;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#20110;&#20998;&#24067;&#22806;&#65288;OOD&#65289;&#26816;&#27979;&#30340;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#26500;&#24314;&#26377;&#25928;&#21306;&#20998;OOD&#25968;&#25454;&#21644;&#20998;&#24067;&#20869;&#65288;ID&#65289;&#25968;&#25454;&#30340;&#20998;&#25968;&#19978;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#31526;&#21512;&#39044;&#27979;&#65288;CP&#65289;&#20351;&#29992;&#38750;&#19968;&#33268;&#24615;&#20998;&#25968;&#26500;&#24314;&#20855;&#26377;&#27010;&#29575;&#35206;&#30422;&#20445;&#35777;&#30340;&#39044;&#27979;&#38598;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;CP&#26356;&#22909;&#22320;&#35780;&#20272;OOD&#20998;&#25968;&#30340;&#25928;&#29575;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24378;&#35843;&#22312;&#26631;&#20934;OOD&#22522;&#20934;&#35774;&#32622;&#20013;&#65292;&#30001;&#20110;&#27979;&#35797;&#25968;&#25454;&#38598;&#30340;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#65292;&#35780;&#20272;&#25351;&#26631;&#21487;&#33021;&#36807;&#20110;&#20048;&#35266;&#12290;&#22522;&#20110;&#65288;Bates&#31561;&#20154;&#65292;2022&#65289;&#30340;&#24037;&#20316;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#26032;&#30340;&#31526;&#21512;AUROC&#21644;&#31526;&#21512;FRP@TPR95&#25351;&#26631;&#65292;&#36825;&#20123;&#20462;&#27491;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#20123;&#25351;&#26631;&#21464;&#24322;&#24615;&#30340;&#27010;&#29575;&#20445;&#23432;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#20462;&#27491;&#23545;&#20004;&#20010;&#21442;&#32771;OOD&#21644;&#24322;&#24120;&#26816;&#27979;&#22522;&#20934;OpenOOD&#65288;Yang&#31561;&#20154;&#65292;2022&#65289;&#21644;AD-Bench&#65288;Han&#31561;&#20154;&#65292;2022&#65289;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20316;&#29992;&#30340;&#22909;&#22788;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11532v1 Announce Type: cross  Abstract: Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In this work, we propose to use CP to better assess the efficiency of OOD scores. Specifically, we emphasize that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the finite sample size of the test dataset. Based on the work of (Bates et al., 2022), we define new conformal AUROC and conformal FRP@TPR95 metrics, which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics. We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al., 2022) and ADBench (Han et al., 2022). We also show that the benefits of us
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20998;&#31163;&#29366;&#24577;SARSA&#65288;SS-SARSA&#65289;&#31639;&#27861;&#65292;&#38024;&#23545;&#24674;&#22797;&#32769;&#34382;&#26426;&#22330;&#26223;&#35774;&#35745;&#65292;&#36890;&#36807;&#23558;&#36718;&#25968;&#35270;&#20026;&#29366;&#24577;&#65292;&#38477;&#20302;Q-learning/SARSA&#25152;&#38656;&#30340;&#29366;&#24577;&#32452;&#21512;&#25968;&#37327;&#65292;&#23454;&#29616;&#26377;&#25928;&#23398;&#20064;&#65292;&#24182;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#28176;&#36817;&#25910;&#25947;&#33267;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.11520</link><description>&lt;p&gt;
&#20998;&#31163;&#29366;&#24577;SARSA: &#19968;&#31181;&#20855;&#26377;&#24674;&#22797;&#22870;&#21169;&#30340;&#23454;&#29992;&#24207;&#36143;&#20915;&#31574;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
State-Separated SARSA: A Practical Sequential Decision-Making Algorithm with Recovering Rewards
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11520
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20998;&#31163;&#29366;&#24577;SARSA&#65288;SS-SARSA&#65289;&#31639;&#27861;&#65292;&#38024;&#23545;&#24674;&#22797;&#32769;&#34382;&#26426;&#22330;&#26223;&#35774;&#35745;&#65292;&#36890;&#36807;&#23558;&#36718;&#25968;&#35270;&#20026;&#29366;&#24577;&#65292;&#38477;&#20302;Q-learning/SARSA&#25152;&#38656;&#30340;&#29366;&#24577;&#32452;&#21512;&#25968;&#37327;&#65292;&#23454;&#29616;&#26377;&#25928;&#23398;&#20064;&#65292;&#24182;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#28176;&#36817;&#25910;&#25947;&#33267;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#35768;&#22810;&#22810;&#33218;&#32769;&#34382;&#26426;&#31639;&#27861;&#20551;&#35774;&#25152;&#26377;&#33218;&#30340;&#22870;&#21169;&#22312;&#21508;&#36718;&#20043;&#38388;&#20445;&#25345;&#19981;&#21464;&#65292;&#20294;&#22312;&#35768;&#22810;&#29616;&#23454;&#22330;&#26223;&#20013;&#65292;&#36825;&#31181;&#20551;&#35774;&#24182;&#19981;&#25104;&#31435;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#24674;&#22797;&#32769;&#34382;&#26426;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#22870;&#21169;&#21462;&#20915;&#20110;&#33258;&#19978;&#27425;&#25289;&#21160;&#33218;&#20197;&#26469;&#32463;&#36807;&#30340;&#36718;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#31639;&#27861;&#65292;&#21517;&#20026;&#20998;&#31163;&#29366;&#24577;SARSA&#65288;SS-SARSA&#65289;&#31639;&#27861;&#65292;&#20854;&#20013;&#23558;&#21508;&#36718;&#35270;&#20026;&#29366;&#24577;&#12290; SS-SARSA&#31639;&#27861;&#36890;&#36807;&#20943;&#23569;Q-learning/SARSA&#25152;&#38656;&#30340;&#29366;&#24577;&#32452;&#21512;&#25968;&#37327;&#26469;&#23454;&#29616;&#39640;&#25928;&#23398;&#20064;&#65292;&#36825;&#22312;&#22823;&#35268;&#27169;RL&#38382;&#39064;&#20013;&#32463;&#24120;&#36935;&#21040;&#32452;&#21512;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#23427;&#23545;&#22870;&#21169;&#32467;&#26500;&#36827;&#34892;&#26368;&#23569;&#20551;&#35774;&#24182;&#25552;&#20379;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#28176;&#36817;&#25910;&#25947;&#33267;&#26368;&#20248;&#31574;&#30053;&#12290;&#27169;&#25311;&#30740;&#31350;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11520v1 Announce Type: new  Abstract: While many multi-armed bandit algorithms assume that rewards for all arms are constant across rounds, this assumption does not hold in many real-world scenarios. This paper considers the setting of recovering bandits (Pike-Burke &amp; Grunewalder, 2019), where the reward depends on the number of rounds elapsed since the last time an arm was pulled. We propose a new reinforcement learning (RL) algorithm tailored to this setting, named the State-Separate SARSA (SS-SARSA) algorithm, which treats rounds as states. The SS-SARSA algorithm achieves efficient learning by reducing the number of state combinations required for Q-learning/SARSA, which often suffers from combinatorial issues for large-scale RL problems. Additionally, it makes minimal assumptions about the reward structure and offers lower computational complexity. Furthermore, we prove asymptotic convergence to an optimal policy under mild assumptions. Simulation studies demonstrate the
&lt;/p&gt;</description></item><item><title>CLIP&#27169;&#22411;&#22312;&#38754;&#23545;&#20998;&#24067;&#36716;&#31227;&#26102;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20316;&#32773;&#35774;&#35745;&#20102;CounterAnimal&#25968;&#25454;&#38598;&#26469;&#25506;&#31350;&#27169;&#22411;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.11497</link><description>&lt;p&gt;
CLIP&#24635;&#26159;&#27604;ImageNet&#27169;&#22411;&#27867;&#21270;&#26356;&#22909;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do CLIPs Always Generalize Better than ImageNet Models?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11497
&lt;/p&gt;
&lt;p&gt;
CLIP&#27169;&#22411;&#22312;&#38754;&#23545;&#20998;&#24067;&#36716;&#31227;&#26102;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20316;&#32773;&#35774;&#35745;&#20102;CounterAnimal&#25968;&#25454;&#38598;&#26469;&#25506;&#31350;&#27169;&#22411;&#23545;&#34394;&#20551;&#29305;&#24449;&#30340;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35270;&#35273;&#35821;&#35328;&#27169;&#22411;&#65292;&#20363;&#22914;CLIP&#65292;&#24050;&#32463;&#24443;&#24213;&#25913;&#21464;&#20102;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#12290;CLIP&#23637;&#31034;&#20102;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;&#33391;&#22909;&#27867;&#21270;&#33021;&#21147;&#65292;&#24471;&#21040;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#25991;&#29486;&#25903;&#25345;&#12290;&#28982;&#32780;&#65292;CLIP&#30340;&#35780;&#20272;&#25968;&#25454;&#38598;&#20027;&#35201;&#26159;&#20026;ImageNet&#22522;&#20934;&#32780;&#35774;&#35745;&#30340;&#21464;&#31181;&#65292;&#21487;&#33021;&#19981;&#33021;&#23436;&#20840;&#21453;&#26144;CLIP&#22312;LAION&#31561;&#19978;&#36827;&#34892;&#39044;&#35757;&#32451;&#26102;&#23545;&#34394;&#20551;&#30456;&#20851;&#24615;&#30340;&#31283;&#20581;&#24615;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25910;&#38598;&#20102;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#21517;&#20026;CounterAnimal&#65292;&#20854;&#20013;&#21253;&#21547;&#21160;&#29289;&#29031;&#29255;&#20013;&#21457;&#29616;&#30340;&#29616;&#23454;&#34394;&#20551;&#29305;&#24449;&#12290;CounterAnimal&#21253;&#25324;a&#65289;&#24120;&#35265;&#32452;&#65306;&#21253;&#25324;&#24120;&#35265;&#32972;&#26223;&#30340;&#21160;&#29289;&#65292;&#24182;&#19988; b) &#23545;&#29031;&#32452;&#65306;&#21253;&#25324;&#22312;&#19981;&#23547;&#24120;&#32972;&#26223;&#19979;&#30340;&#21160;&#29289;&#12290;&#20174;&#24120;&#35265;&#32452;&#21040;&#23545;&#29031;&#32452;&#30340;&#24615;&#33021;&#19979;&#38477;&#37327;&#21270;&#20102;&#27169;&#22411;&#23545;&#34394;&#20551;&#29305;&#24449;&#65288;&#21363;&#32972;&#26223;&#65289;&#39044;&#27979;&#21160;&#29289;&#30340;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;LAION&#25110;OpenAI&#25968;&#25454;&#19978;&#36827;&#34892;&#35757;&#32451;&#30340;CLIP&#21363;&#27809;&#26377;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11497v1 Announce Type: cross  Abstract: Large vision language models, such as CLIPs, have revolutionized modern machine learning. CLIPs have demonstrated great generalizability under distribution shifts, supported by an increasing body of literature. However, the evaluation datasets for CLIPs are variations primarily designed for ImageNet benchmarks, which may not fully reflect the extent to which CLIPs, e.g., pre-trained on LAION, robust to spurious correlations. To bridge the gap, we collect a real-world dataset called CounterAnimal that contains realistic spurious features found in animal photos. CounterAnimal consists of a) the common group: comprising animals on common backgrounds, and b) the counter group: including animals on unusual backgrounds. The performance drops from the common to counter groups quantify the reliance of models on spurious features (i.e., backgrounds) to predict the animals. We find that CLIPs trained on either LAION or the OpenAI data exhibit no
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#24369;&#36890;&#20449;MDPs&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#20026; $\tilde{O}(SA\frac{H}{\epsilon^2})$&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#24037;&#20316;&#65292;&#26159;&#22312;&#25152;&#26377;&#21442;&#25968;&#19978;&#26368;&#23567;&#26368;&#20248;&#30340;&#12290;</title><link>https://arxiv.org/abs/2403.11477</link><description>&lt;p&gt;
&#24369;&#36890;&#20449;&#21644;&#19968;&#33324;&#24179;&#22343;&#22870;&#36175;MDPs&#30340;&#22522;&#20110;&#36328;&#24230;&#30340;&#26368;&#20339;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11477
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#20110;&#24369;&#36890;&#20449;MDPs&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#20026; $\tilde{O}(SA\frac{H}{\epsilon^2})$&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#24037;&#20316;&#65292;&#26159;&#22312;&#25152;&#26377;&#21442;&#25968;&#19978;&#26368;&#23567;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#29983;&#25104;&#27169;&#22411;&#19979;&#23398;&#20064;&#24179;&#22343;&#22870;&#36175;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;$\epsilon$-&#26368;&#20339;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#23545;&#20110;&#24369;&#36890;&#20449;MDPs&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22797;&#26434;&#24230;&#30028;&#38480;&#20026;$\tilde{O}(SA\frac{H}{\epsilon^2})$&#65292;&#20854;&#20013;$H$&#26159;&#26368;&#20248;&#31574;&#30053;&#30340;&#20559;&#24046;&#20989;&#25968;&#30340;&#36328;&#24230;&#65292;$SA$&#26159;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#30340;&#22522;&#25968;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#22312;&#25152;&#26377;&#21442;&#25968;$S,A,H$&#21644;$\epsilon$&#19978;&#65288;&#26368;&#22810;&#23545;&#25968;&#22240;&#23376;&#65289;&#26368;&#23567;&#26368;&#20248;&#30340;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#24037;&#20316;&#65292;&#29616;&#26377;&#24037;&#20316;&#35201;&#20040;&#20551;&#35774;&#25152;&#26377;&#31574;&#30053;&#30340;&#28151;&#21512;&#26102;&#38388;&#22343;&#21248;&#26377;&#30028;&#65292;&#35201;&#20040;&#23545;&#21442;&#25968;&#26377;&#27425;&#20248;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#19968;&#33324;&#65288;&#38750;&#24369;&#36890;&#20449;&#65289;&#24179;&#22343;&#22870;&#36175;MDPs&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#35748;&#20026;&#38656;&#35201;&#19968;&#20010;&#26032;&#30340;&#30636;&#24577;&#26102;&#38388;&#21442;&#25968;$B$&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;$\tilde{O}(SA\frac{B+H}{\epsilon^2})$&#30340;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#21305;&#37197;&#30340;&#65288;&#26368;&#22810;&#23545;&#25968;&#22240;&#23376;&#65289;&#26368;&#23567;&#26368;&#20248;&#19979;&#30028;&#12290;&#36825;&#20004;&#20010;&#32467;&#26524;&#37117;&#26159;&#22522;&#20110;&#20943;&#23569;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11477v1 Announce Type: new  Abstract: We study the sample complexity of learning an $\epsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. For weakly communicating MDPs, we establish the complexity bound $\tilde{O}(SA\frac{H}{\epsilon^2})$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$ and $\epsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. We further investigate sample complexity in general (non-weakly-communicating) average-reward MDPs. We argue a new transient time parameter $B$ is necessary, establish an $\tilde{O}(SA\frac{B+H}{\epsilon^2})$ complexity bound, and prove a matching (up to log factors) minimax lower bound. Both results are based on reducing the
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#20808;&#39564;&#32467;&#26500;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#20998;&#38548;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.11407</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#20998;&#38548;&#21518;&#39564;&#37319;&#26679;&#29992;&#20110;&#21435;&#22122;&#25193;&#25955;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11407
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#20808;&#39564;&#32467;&#26500;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#20998;&#38548;&#21518;&#39564;&#37319;&#26679;&#26041;&#27861;&#65292;&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#20351;&#29992;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65288;DDM&#65289;&#20316;&#20026;&#36870;&#36125;&#21494;&#26031;&#38382;&#39064;&#27714;&#35299;&#30340;&#20808;&#39564;&#24341;&#36215;&#20102;&#26497;&#22823;&#30340;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#20174;&#32467;&#26524;&#21518;&#39564;&#20998;&#24067;&#20013;&#25277;&#26679;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#36817;&#20284;&#26041;&#27861;&#26469;&#20559;&#32622;&#25193;&#25955;&#30340;&#28418;&#31227;&#39033;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#24182;&#21033;&#29992;DDM&#20808;&#39564;&#30340;&#29305;&#23450;&#32467;&#26500;&#26469;&#23450;&#20041;&#19968;&#32452;&#20013;&#38388;&#21644;&#26356;&#31616;&#21333;&#30340;&#21518;&#39564;&#25277;&#26679;&#38382;&#39064;&#65292;&#30456;&#27604;&#20808;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#21512;&#25104;&#20363;&#23376;&#21644;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#26469;&#23454;&#35777;&#22320;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#23545;&#20110;&#19968;&#33324;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#37325;&#26500;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11407v1 Announce Type: cross  Abstract: Interest in the use of Denoising Diffusion Models (DDM) as priors for solving inverse Bayesian problems has recently increased significantly. However, sampling from the resulting posterior distribution poses a challenge. To solve this problem, previous works have proposed approximations to bias the drift term of the diffusion. In this work, we take a different approach and utilize the specific structure of the DDM prior to define a set of intermediate and simpler posterior sampling problems, resulting in a lower approximation error compared to previous methods. We empirically demonstrate the reconstruction capability of our method for general linear inverse problems using synthetic examples and various image restoration tasks.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;SDP&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;$k$-&#26368;&#23494;&#19981;&#30456;&#20132;&#21452;&#22242;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.11351</link><description>&lt;p&gt;
&#22522;&#20110;SDP&#30340;&#20108;&#20998;&#22270;&#32858;&#31867;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An SDP-based Branch-and-Cut Algorithm for Biclustering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11351
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;SDP&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;$k$-&#26368;&#23494;&#19981;&#30456;&#20132;&#21452;&#22242;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#20998;&#22270;&#32858;&#31867;&#65292;&#20063;&#31216;&#20026;&#20849;&#32858;&#31867;&#12289;&#22359;&#32858;&#31867;&#25110;&#21452;&#21521;&#32858;&#31867;&#65292;&#28041;&#21450;&#23558;&#25968;&#25454;&#30697;&#38453;&#30340;&#34892;&#21644;&#21015;&#21516;&#26102;&#32858;&#31867;&#25104;&#19981;&#21516;&#30340;&#32452;&#65292;&#20351;&#24471;&#21516;&#19968;&#32452;&#20869;&#30340;&#34892;&#21644;&#21015;&#26174;&#31034;&#20986;&#30456;&#20284;&#30340;&#27169;&#24335;&#12290;&#20316;&#20026;&#20108;&#20998;&#22270;&#32858;&#31867;&#30340;&#27169;&#22411;&#38382;&#39064;&#65292;&#25105;&#20204;&#32771;&#34385;$k$-&#26368;&#23494;&#19981;&#30456;&#20132;&#21452;&#22242;&#38382;&#39064;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#32473;&#23450;&#21152;&#26435;&#23436;&#20840;&#20108;&#20998;&#22270;&#20013;&#35782;&#21035; $k$ &#20010;&#19981;&#30456;&#20132;&#30340;&#23436;&#20840;&#20108;&#37096;&#23376;&#22270;&#65288;&#31216;&#20026;&#21452;&#22242;&#65289;&#65292;&#20351;&#23427;&#20204;&#30340;&#23494;&#24230;&#20043;&#21644;&#26368;&#22823;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#12290;&#23545;&#20110;&#19978;&#30028;&#20363;&#31243;&#65292;&#25105;&#20204;&#32771;&#34385;&#21322;&#23450;&#35268;&#21010;&#25918;&#26494;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#21152;&#24378;&#30028;&#38480;&#30340;&#26377;&#25928;&#19981;&#31561;&#24335;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#19968;&#38454;&#26041;&#27861;&#20197;&#20999;&#24179;&#38754;&#26041;&#24335;&#35299;&#20915;&#36825;&#20010;&#25918;&#26494;&#38382;&#39064;&#12290;&#23545;&#20110;&#19979;&#30028;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21033;&#29992;&#35299;&#20915;&#26041;&#26696;&#30340;&#26368;&#22823;&#26435;&#21305;&#37197;&#33293;&#20837;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11351v1 Announce Type: cross  Abstract: Biclustering, also called co-clustering, block clustering, or two-way clustering, involves the simultaneous clustering of both the rows and columns of a data matrix into distinct groups, such that the rows and columns within a group display similar patterns. As a model problem for biclustering, we consider the $k$-densest-disjoint biclique problem, whose goal is to identify $k$ disjoint complete bipartite subgraphs (called bicliques) of a given weighted complete bipartite graph such that the sum of their densities is maximized. To address this problem, we present a tailored branch-and-cut algorithm. For the upper bound routine, we consider a semidefinite programming relaxation and propose valid inequalities to strengthen the bound. We solve this relaxation in a cutting-plane fashion using a first-order method. For the lower bound, we design a maximum weight matching rounding procedure that exploits the solution of the relaxation solved
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27010;&#29575;&#30005;&#36335;&#65292;&#25552;&#20986;&#20102;COLEP&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#21487;&#35777;&#23454;&#40065;&#26834;&#23398;&#20064;&#25512;&#29702;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#20854;&#29305;&#28857;&#22312;&#20110;&#35757;&#32451;&#32479;&#35745;&#27169;&#22411;&#23398;&#20064;&#19981;&#21516;&#35821;&#20041;&#27010;&#24565;&#65292;&#24182;&#21033;&#29992;&#27010;&#29575;&#30005;&#36335;&#23454;&#29616;&#31934;&#30830;&#39640;&#25928;&#25512;&#29702;</title><link>https://arxiv.org/abs/2403.11348</link><description>&lt;p&gt;
COLEP: &#36890;&#36807;&#27010;&#29575;&#30005;&#36335;&#23454;&#29616;&#21487;&#35777;&#23454;&#40065;&#26834;&#23398;&#20064;&#25512;&#29702;&#19968;&#33268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
COLEP: Certifiably Robust Learning-Reasoning Conformal Prediction via Probabilistic Circuits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11348
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27010;&#29575;&#30005;&#36335;&#65292;&#25552;&#20986;&#20102;COLEP&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#21487;&#35777;&#23454;&#40065;&#26834;&#23398;&#20064;&#25512;&#29702;&#19968;&#33268;&#24615;&#39044;&#27979;&#65292;&#20854;&#29305;&#28857;&#22312;&#20110;&#35757;&#32451;&#32479;&#35745;&#27169;&#22411;&#23398;&#20064;&#19981;&#21516;&#35821;&#20041;&#27010;&#24565;&#65292;&#24182;&#21033;&#29992;&#27010;&#29575;&#30005;&#36335;&#23454;&#29616;&#31934;&#30830;&#39640;&#25928;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21442;&#32771;&#31867;&#22411;&#65306;&#20132;&#21449;  &#25688;&#35201;&#65306;&#19968;&#33268;&#24615;&#39044;&#27979;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#20026;&#20219;&#24847;&#40657;&#21283;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26500;&#24314;&#32479;&#35745;&#20005;&#35880;&#30340;&#39044;&#27979;&#38598;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20551;&#35774;&#25968;&#25454;&#26159;&#21487;&#20132;&#25442;&#30340;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#22312;&#25512;&#29702;&#36807;&#31243;&#20013;&#36827;&#34892;&#24494;&#23567;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#20063;&#21487;&#33021;&#36829;&#21453;&#21487;&#20132;&#25442;&#24615;&#20551;&#35774;&#65292;&#25361;&#25112;&#35206;&#30422;&#29575;&#20445;&#35777;&#65292;&#24182;&#23548;&#33268;&#21518;&#32493;&#23454;&#35777;&#35206;&#30422;&#29575;&#30340;&#19979;&#38477;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#27010;&#29575;&#30005;&#36335;&#23454;&#29616;&#21487;&#35777;&#23454;&#40065;&#26834;&#23398;&#20064;&#25512;&#29702;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#26694;&#26550;&#65288;COLEP&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#23398;&#20064;&#32452;&#20214;&#65292;&#29992;&#20110;&#35757;&#32451;&#32479;&#35745;&#27169;&#22411;&#20197;&#23398;&#20064;&#19981;&#21516;&#30340;&#35821;&#20041;&#27010;&#24565;&#65292;&#20197;&#21450;&#19968;&#20010;&#29992;&#20110;&#32534;&#30721;&#30693;&#35782;&#24182;&#34920;&#24449;&#35757;&#32451;&#27169;&#22411;&#20043;&#38388;&#20851;&#31995;&#30340;&#25512;&#29702;&#32452;&#20214;&#12290;&#20026;&#20102;&#23454;&#29616;&#31934;&#30830;&#21644;&#39640;&#25928;&#30340;&#25512;&#29702;&#65292;&#25105;&#20204;&#22312;&#25512;&#29702;&#32452;&#20214;&#20869;&#37096;&#20351;&#29992;&#20102;&#27010;&#29575;&#30005;&#36335;&#65288;PCs&#65289;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23436;&#25972;&#30340;&#39044;&#27979;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11348v1 Announce Type: cross  Abstract: Conformal prediction has shown spurring performance in constructing statistically rigorous prediction sets for arbitrary black-box machine learning models, assuming the data is exchangeable. However, even small adversarial perturbations during the inference can violate the exchangeability assumption, challenge the coverage guarantees, and result in a subsequent decline in empirical coverage. In this work, we propose a certifiably robust learning-reasoning conformal prediction framework (COLEP) via probabilistic circuits, which comprise a data-driven learning component that trains statistical models to learn different semantic concepts, and a reasoning component that encodes knowledge and characterizes the relationships among the trained models for logic reasoning. To achieve exact and efficient reasoning, we employ probabilistic circuits (PCs) within the reasoning component. Theoretically, we provide end-to-end certification of predict
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#32771;&#34385;&#38544;&#31169;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2403.11343</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Transfer Learning with Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#21033;&#29992;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#32771;&#34385;&#38544;&#31169;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#36234;&#26469;&#36234;&#21463;&#21040;&#27426;&#36814;&#65292;&#25968;&#25454;&#24322;&#26500;&#24615;&#21644;&#38544;&#31169;&#24615;&#26159;&#20004;&#20010;&#31361;&#20986;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#32852;&#37030;&#36801;&#31227;&#23398;&#20064;&#26694;&#26550;&#20869;&#35299;&#20915;&#20102;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#26088;&#22312;&#36890;&#36807;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#24322;&#26500;&#28304;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#26469;&#22686;&#24378;&#23545;&#30446;&#26631;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#65292;&#21516;&#26102;&#36981;&#23432;&#38544;&#31169;&#32422;&#26463;&#12290;&#25105;&#20204;&#20005;&#26684;&#21046;&#23450;&#20102;\textit{&#32852;&#37030;&#24046;&#20998;&#38544;&#31169;}&#30340;&#27010;&#24565;&#65292;&#20026;&#27599;&#20010;&#25968;&#25454;&#38598;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#32780;&#26080;&#38656;&#20551;&#35774;&#26377;&#19968;&#20010;&#21463;&#20449;&#20219;&#30340;&#20013;&#22830;&#26381;&#21153;&#22120;&#12290;&#22312;&#36825;&#20010;&#38544;&#31169;&#32422;&#26463;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#20010;&#32463;&#20856;&#30340;&#32479;&#35745;&#38382;&#39064;&#65292;&#21363;&#21333;&#21464;&#37327;&#22343;&#20540;&#20272;&#35745;&#12289;&#20302;&#32500;&#32447;&#24615;&#22238;&#24402;&#21644;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#12290;&#36890;&#36807;&#30740;&#31350;&#26497;&#23567;&#20540;&#29575;&#24182;&#30830;&#23450;&#36825;&#20123;&#38382;&#39064;&#30340;&#38544;&#31169;&#25104;&#26412;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32852;&#37030;&#24046;&#20998;&#38544;&#31169;&#26159;&#24050;&#24314;&#31435;&#30340;&#23616;&#37096;&#21644;&#20013;&#22830;&#27169;&#22411;&#20043;&#38388;&#30340;&#19968;&#31181;&#20013;&#38388;&#38544;&#31169;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11343v1 Announce Type: new  Abstract: Federated learning is gaining increasing popularity, with data heterogeneity and privacy being two prominent challenges. In this paper, we address both issues within a federated transfer learning framework, aiming to enhance learning on a target data set by leveraging information from multiple heterogeneous source data sets while adhering to privacy constraints. We rigorously formulate the notion of \textit{federated differential privacy}, which offers privacy guarantees for each data set without assuming a trusted central server. Under this privacy constraint, we study three classical statistical problems, namely univariate mean estimation, low-dimensional linear regression, and high-dimensional linear regression. By investigating the minimax rates and identifying the costs of privacy for these problems, we show that federated differential privacy is an intermediate privacy model between the well-established local and central models of 
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#20808;&#39564;&#20381;&#36182;&#24615;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#23545;&#21518;&#39564;&#25277;&#26679;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#20102;&#25913;&#36827;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#23545;&#20808;&#21069;&#22522;&#20934;&#30340;&#26041;&#27861;&#35770;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2403.11175</link><description>&lt;p&gt;
&#20808;&#39564;&#20381;&#36182;&#24615;&#20998;&#26512;&#22522;&#20110;&#20989;&#25968;&#36924;&#36817;&#30340;&#21518;&#39564;&#25277;&#26679;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Prior-dependent analysis of posterior sampling reinforcement learning with function approximation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11175
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#20808;&#39564;&#20381;&#36182;&#24615;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#23545;&#21518;&#39564;&#25277;&#26679;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#20102;&#25913;&#36827;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#32467;&#26524;&#65292;&#23454;&#29616;&#20102;&#23545;&#20808;&#21069;&#22522;&#20934;&#30340;&#26041;&#27861;&#35770;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#22312;&#23545;&#32447;&#24615;&#28151;&#21512;MDPs&#24314;&#27169;&#30340;&#20989;&#25968;&#36924;&#36817;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#25512;&#36827;&#20102;&#38543;&#26426;&#25506;&#32034;&#12290;&#25105;&#20204;&#20026;&#20855;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;RL&#24314;&#31435;&#20102;&#39318;&#20010;&#20808;&#39564;&#20381;&#36182;&#24615;&#36125;&#21494;&#26031;&#36951;&#25022;&#19978;&#30028;&#65307;&#24182;&#19988;&#25913;&#36827;&#20102;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#24378;&#21270;&#23398;&#20064;&#65288;PSRL&#65289;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#30028;&#20026;${\mathcal{O}}(d\sqrt{H^3 T \log T})$&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;$d$&#34920;&#31034;&#36716;&#31227;&#26680;&#30340;&#32500;&#24230;&#65292;$H$&#34920;&#31034;&#35268;&#21010;&#35270;&#37326;&#65292;$T$&#34920;&#31034;&#24635;&#20132;&#20114;&#27425;&#25968;&#12290; &#36825;&#34920;&#31034;&#36890;&#36807;&#20248;&#21270;$\mathcal{O}(\sqrt{\log T})$&#22240;&#23376;&#65292;&#25105;&#20204;&#22312;&#20043;&#21069;&#38024;&#23545;&#32447;&#24615;&#28151;&#21512;MDPs&#30340;&#22522;&#20934;&#65288;Osband&#21644;Van Roy&#65292;2014&#65289;&#19978;&#21462;&#24471;&#20102;&#26041;&#27861;&#35770;&#19978;&#30340;&#25552;&#21319;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20215;&#20540;&#23450;&#21521;&#27169;&#22411;&#23398;&#20064;&#30340;&#35270;&#35282;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#35299;&#32806;&#35770;&#35777;&#21644;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#65292;&#36229;&#36234;&#20102;&#20256;&#32479;&#20998;&#26512;&#20381;&#36182;&#20110;&#32622;&#20449;&#21306;&#38388;&#21644;&#38598;&#20013;&#19981;&#31561;&#24335;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11175v1 Announce Type: cross  Abstract: This work advances randomized exploration in reinforcement learning (RL) with function approximation modeled by linear mixture MDPs. We establish the first prior-dependent Bayesian regret bound for RL with function approximation; and refine the Bayesian regret analysis for posterior sampling reinforcement learning (PSRL), presenting an upper bound of ${\mathcal{O}}(d\sqrt{H^3 T \log T})$, where $d$ represents the dimensionality of the transition kernel, $H$ the planning horizon, and $T$ the total number of interactions. This signifies a methodological enhancement by optimizing the $\mathcal{O}(\sqrt{\log T})$ factor over the previous benchmark (Osband and Van Roy, 2014) specified to linear mixture MDPs. Our approach, leveraging a value-targeted model learning perspective, introduces a decoupling argument and a variance reduction technique, moving beyond traditional analyses reliant on confidence sets and concentration inequalities to f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20960;&#20010;&#23450;&#29702;&#25506;&#35752;&#20102;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#65292;&#21253;&#25324;&#32771;&#34385;&#21644;&#24573;&#30053;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#21450;&#39034;&#24207;&#22810;&#20010;&#35757;&#32451;&#26679;&#26412;&#22686;&#30410;&#30340;&#29702;&#35770;&#26368;&#20248;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2403.11125</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Machine learning-based system reliability analysis with Gaussian Process Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20960;&#20010;&#23450;&#29702;&#25506;&#35752;&#20102;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#65292;&#21253;&#25324;&#32771;&#34385;&#21644;&#24573;&#30053;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#21450;&#39034;&#24207;&#22810;&#20010;&#35757;&#32451;&#26679;&#26412;&#22686;&#30410;&#30340;&#29702;&#35770;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11125v1 &#20844;&#21578;&#31867;&#22411;: &#20132;&#21449; &#25688;&#35201;: &#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21487;&#38752;&#24615;&#20998;&#26512;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#36827;&#23637;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#25552;&#20986;&#35768;&#22810;&#26377;&#25928;&#30340;&#23398;&#20064;&#31574;&#30053;&#26469;&#22686;&#24378;&#35745;&#31639;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20854;&#20013;&#24456;&#23569;&#26377;&#20154;&#25506;&#35752;&#20102;&#29702;&#35770;&#19978;&#30340;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#12290;&#22312;&#36825;&#31687;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#20010;&#23450;&#29702;&#26469;&#20419;&#36827;&#36825;&#31181;&#25506;&#32034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#35814;&#32454;&#38416;&#36848;&#20102;&#32771;&#34385;&#21644;&#24573;&#30053;&#20505;&#36873;&#35774;&#35745;&#26679;&#26412;&#20043;&#38388;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340; U &#23398;&#20064;&#20989;&#25968;&#21487;&#20197;&#37325;&#26032;&#21046;&#23450;&#20026;&#22312;&#24573;&#30053; Kriging &#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#30340;&#26368;&#20248;&#23398;&#20064;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#36824;&#36890;&#36807;&#24102;&#26377;&#30456;&#24212;&#25439;&#22833;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#25968;&#23398;&#19978;&#25506;&#35752;&#20102;&#39034;&#24207;&#22810;&#20010;&#35757;&#32451;&#26679;&#26412;&#22686;&#30410;&#30340;&#29702;&#35770;&#19978;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#12290;&#27169;&#25311;&#32467;&#26524;&#34920;&#26126;&#26368;&#20248;&#23398;&#20064;&#31574;&#30053;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11125v1 Announce Type: cross  Abstract: Machine learning-based reliability analysis methods have shown great advancements for their computational efficiency and accuracy. Recently, many efficient learning strategies have been proposed to enhance the computational performance. However, few of them explores the theoretical optimal learning strategy. In this article, we propose several theorems that facilitates such exploration. Specifically, cases that considering and neglecting the correlations among the candidate design samples are well elaborated. Moreover, we prove that the well-known U learning function can be reformulated to the optimal learning function for the case neglecting the Kriging correlation. In addition, the theoretical optimal learning strategy for sequential multiple training samples enrichment is also mathematically explored through the Bayesian estimate with the corresponding lost functions. Simulation results show that the optimal learning strategy consid
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#24207;&#21015;&#20219;&#21153;&#35774;&#32622;&#19979;&#26368;&#23567;&#21270;&#23616;&#37096;&#36951;&#25022;&#30340;&#35884;&#35823;&#65292;&#25581;&#31034;&#20102;&#36817;&#35270;&#22320;&#26368;&#23567;&#21270;&#36951;&#25022;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.10946</link><description>&lt;p&gt;
&#22312;&#24207;&#21015;&#20219;&#21153;&#35774;&#32622;&#20013;&#26368;&#23567;&#21270;&#23616;&#37096;&#36951;&#25022;&#30340;&#35884;&#35823;
&lt;/p&gt;
&lt;p&gt;
The Fallacy of Minimizing Local Regret in the Sequential Task Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10946
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#22312;&#24207;&#21015;&#20219;&#21153;&#35774;&#32622;&#19979;&#26368;&#23567;&#21270;&#23616;&#37096;&#36951;&#25022;&#30340;&#35884;&#35823;&#65292;&#25581;&#31034;&#20102;&#36817;&#35270;&#22320;&#26368;&#23567;&#21270;&#36951;&#25022;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#32463;&#24120;&#34987;&#27010;&#24565;&#21270;&#20026;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#31639;&#27861;&#19982;&#26410;&#30693;&#29615;&#22659;&#20132;&#20114;&#20197;&#26368;&#23567;&#21270;&#32047;&#31215;&#36951;&#25022;&#12290;&#22312;&#38745;&#24577;&#35774;&#32622;&#20013;&#65292;&#21487;&#20197;&#33719;&#24471;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#22914;&#27425;&#32447;&#24615;&#65288;$\sqrt{T}$&#65289;&#36951;&#25022;&#30028;&#38480;&#65292;&#36890;&#24120;&#24847;&#21619;&#30528;&#25910;&#25947;&#21040;&#26368;&#20248;&#31574;&#30053;&#24182;&#20572;&#27490;&#25506;&#32034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#29702;&#35770;&#35774;&#32622;&#36890;&#24120;&#36807;&#20998;&#31616;&#21270;&#20102;&#30495;&#23454;&#19990;&#30028;&#24378;&#21270;&#23398;&#20064;&#23454;&#29616;&#20013;&#36935;&#21040;&#30340;&#22797;&#26434;&#24615;&#65292;&#20854;&#20013;&#20219;&#21153;&#25353;&#39034;&#24207;&#21040;&#36798;&#65292;&#20219;&#21153;&#20043;&#38388;&#26377;&#37325;&#22823;&#21464;&#21270;&#65292;&#24182;&#19988;&#31639;&#27861;&#21487;&#33021;&#19981;&#20801;&#35768;&#22312;&#26576;&#20123;&#20219;&#21153;&#20013;&#36827;&#34892;&#33258;&#36866;&#24212;&#23398;&#20064;&#12290;&#25105;&#20204;&#30740;&#31350;&#36229;&#20986;&#32467;&#26524;&#20998;&#24067;&#30340;&#21464;&#21270;&#65292;&#28085;&#30422;&#22870;&#21169;&#35774;&#35745;&#65288;&#20174;&#32467;&#26524;&#21040;&#22870;&#21169;&#30340;&#26144;&#23556;&#65289;&#21644;&#20801;&#35768;&#30340;&#31574;&#30053;&#31354;&#38388;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22312;&#27599;&#20010;&#20219;&#21153;&#20013;&#36817;&#35270;&#22320;&#26368;&#23567;&#21270;&#36951;&#25022;&#30340;&#35884;&#35823;&#65306;&#33719;&#24471;&#26368;&#20248;&#36951;&#25022;r
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10946v1 Announce Type: cross  Abstract: In the realm of Reinforcement Learning (RL), online RL is often conceptualized as an optimization problem, where an algorithm interacts with an unknown environment to minimize cumulative regret. In a stationary setting, strong theoretical guarantees, like a sublinear ($\sqrt{T}$) regret bound, can be obtained, which typically implies the convergence to an optimal policy and the cessation of exploration. However, these theoretical setups often oversimplify the complexities encountered in real-world RL implementations, where tasks arrive sequentially with substantial changes between tasks and the algorithm may not be allowed to adaptively learn within certain tasks. We study the changes beyond the outcome distributions, encompassing changes in the reward designs (mappings from outcomes to rewards) and the permissible policy spaces. Our results reveal the fallacy of myopically minimizing regret within each task: obtaining optimal regret r
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24207;&#21015;&#23398;&#20064;&#20013;&#26377;&#25928;&#25972;&#21512;&#26032;&#25968;&#25454;&#24182;&#20445;&#30041;&#20808;&#21069;&#30693;&#35782;&#65292;&#21516;&#26102;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#21512;&#24182;&#26032;&#25968;&#25454;&#12290;</title><link>https://arxiv.org/abs/2403.10929</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#21442;&#25968;&#21270;&#29992;&#20110;&#24207;&#21015;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Function-space Parameterization of Neural Networks for Sequential Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10929
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#24207;&#21015;&#23398;&#20064;&#20013;&#26377;&#25928;&#25972;&#21512;&#26032;&#25968;&#25454;&#24182;&#20445;&#30041;&#20808;&#21069;&#30693;&#35782;&#65292;&#21516;&#26102;&#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#21512;&#24182;&#26032;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#26799;&#24230;&#19979;&#38477;&#28145;&#24230;&#23398;&#20064;&#20013;&#38590;&#20197;&#25972;&#21512;&#26032;&#25968;&#25454;&#24182;&#20445;&#30041;&#20808;&#21069;&#30693;&#35782;&#65292;&#39034;&#24207;&#23398;&#20064;&#33539;&#24335;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#34429;&#28982;&#39640;&#26031;&#36807;&#31243;&#20248;&#38597;&#22320;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#20294;&#22312;&#22788;&#29702;&#35832;&#22914;&#22270;&#20687;&#20043;&#31867;&#30340;&#20016;&#23500;&#36755;&#20837;&#21644;&#20280;&#32553;&#24615;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23558;&#31070;&#32463;&#32593;&#32476;&#20174;&#26435;&#37325;&#31354;&#38388;&#36716;&#25442;&#21040;&#20989;&#25968;&#31354;&#38388;&#30340;&#25216;&#26415;&#65292;&#21363;&#21452;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#21442;&#25968;&#21270;&#25552;&#20379;&#20102;&#65306;(i) &#36890;&#36807;&#31232;&#30095;&#21270;&#23558;&#20989;&#25968;&#31354;&#38388;&#26041;&#27861;&#25193;&#23637;&#21040;&#22823;&#25968;&#25454;&#38598;&#30340;&#36884;&#24452;&#65292;(ii) &#22312;&#35775;&#38382;&#36807;&#21435;&#25968;&#25454;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#20445;&#30041;&#20808;&#21069;&#30693;&#35782;&#65292;&#20197;&#21450;(iii) &#22312;&#19981;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#21512;&#24182;&#26032;&#25968;&#25454;&#30340;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#25345;&#32493;&#23398;&#20064;&#20013;&#20445;&#30041;&#30693;&#35782;&#65292;&#24182;&#26377;&#25928;&#22320;&#21512;&#24182;&#26032;&#25968;&#25454;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#20854;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#24341;&#23548;&#22522;&#20110;&#27169;&#22411;&#30340;RL&#20013;&#25506;&#32034;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10929v1 Announce Type: cross  Abstract: Sequential learning paradigms pose challenges for gradient-based deep learning due to difficulties incorporating new data and retaining prior knowledge. While Gaussian processes elegantly tackle these problems, they struggle with scalability and handling rich inputs, such as images. To address these issues, we introduce a technique that converts neural networks from weight space to function space, through a dual parameterization. Our parameterization offers: (i) a way to scale function-space methods to large data sets via sparsification, (ii) retention of prior knowledge when access to past data is limited, and (iii) a mechanism to incorporate new data without retraining. Our experiments demonstrate that we can retain knowledge in continual learning and incorporate new data efficiently. We further show its strengths in uncertainty quantification and guiding exploration in model-based RL. Further information and code is available on the
&lt;/p&gt;</description></item><item><title>TabPFN&#27169;&#22411;&#22312;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#24182;&#33021;&#22815;&#20197;&#31186;&#32423;&#36895;&#24230;&#29983;&#25104;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#19987;&#20026;TabPFN&#35774;&#35745;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#30340;&#25913;&#36827;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;</title><link>https://arxiv.org/abs/2403.10923</link><description>&lt;p&gt;
TabPFN&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Interpretable Machine Learning for TabPFN
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10923
&lt;/p&gt;
&lt;p&gt;
TabPFN&#27169;&#22411;&#22312;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#33391;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#65292;&#24182;&#33021;&#22815;&#20197;&#31186;&#32423;&#36895;&#24230;&#29983;&#25104;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#19987;&#20026;TabPFN&#35774;&#35745;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#30340;&#25913;&#36827;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#24320;&#21457;&#30340;Prior-Data Fitted Networks&#65288;PFNs&#65289;&#24050;&#32463;&#26174;&#31034;&#20986;&#22312;&#20302;&#25968;&#25454;&#24773;&#20917;&#19979;&#20855;&#26377;&#38750;&#24120;&#26377;&#24076;&#26395;&#30340;&#24212;&#29992;&#32467;&#26524;&#12290;TabPFN&#27169;&#22411;&#26159;PFN&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#36866;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#65292;&#22312;&#19981;&#38656;&#35201;&#23398;&#20064;&#21442;&#25968;&#25110;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#22312;&#30701;&#30701;&#20960;&#31186;&#38047;&#20869;&#23454;&#29616;&#22810;&#31181;&#20998;&#31867;&#20219;&#21153;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#24182;&#19988;&#33021;&#22815;&#29983;&#25104;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#12290;TabPFN&#22240;&#27492;&#25104;&#20026;&#20102;&#35768;&#22810;&#39046;&#22495;&#24212;&#29992;&#20013;&#38750;&#24120;&#21560;&#24341;&#20154;&#30340;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#26159;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#38024;&#23545;TabPFN&#19987;&#38376;&#35774;&#35745;&#30340;&#27969;&#34892;&#35299;&#37322;&#24615;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;&#36890;&#36807;&#21033;&#29992;&#35813;&#27169;&#22411;&#30340;&#29420;&#29305;&#24615;&#36136;&#65292;&#25105;&#20204;&#30340;&#25913;&#36827;&#20801;&#35768;&#27604;&#29616;&#26377;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#36991;&#20813;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10923v1 Announce Type: cross  Abstract: The recently developed Prior-Data Fitted Networks (PFNs) have shown very promising results for applications in low-data regimes. The TabPFN model, a special case of PFNs for tabular data, is able to achieve state-of-the-art performance on a variety of classification tasks while producing posterior predictive distributions in mere seconds by in-context learning without the need for learning parameters or hyperparameter tuning. This makes TabPFN a very attractive option for a wide range of domain applications. However, a major drawback of the method is its lack of interpretability. Therefore, we propose several adaptations of popular interpretability methods that we specifically design for TabPFN. By taking advantage of the unique properties of the model, our adaptations allow for more efficient computations than existing implementations. In particular, we show how in-context learning facilitates the estimation of Shapley values by avoid
&lt;/p&gt;</description></item><item><title>DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.10903</link><description>&lt;p&gt;
DTOR&#65306;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#29992;&#20110;&#35299;&#37322;&#24322;&#24120;
&lt;/p&gt;
&lt;p&gt;
DTOR: Decision Tree Outlier Regressor to explain anomalies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10903
&lt;/p&gt;
&lt;p&gt;
DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24322;&#24120;&#20540;&#30340;&#20986;&#29616;&#20197;&#21450;&#20854;&#20135;&#29983;&#26426;&#21046;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#21487;&#33021;&#38750;&#24120;&#37325;&#35201;&#12290;&#25925;&#38556;&#12289;&#27450;&#35784;&#12289;&#23041;&#32961;&#31561;&#38382;&#39064;&#65292;&#38500;&#20102;&#34987;&#27491;&#30830;&#35782;&#21035;&#20043;&#22806;&#65292;&#36890;&#24120;&#38656;&#35201;&#26377;&#25928;&#30340;&#35299;&#37322;&#20197;&#26377;&#25928;&#25191;&#34892;&#21487;&#25805;&#20316;&#30340;&#23545;&#25239;&#25514;&#26045;&#12290;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#20351;&#29992;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#35782;&#21035;&#24322;&#24120;&#20540;&#65292;&#20351;&#24471;&#36825;&#26679;&#30340;&#35299;&#37322;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65288;DTOR&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20026;&#21333;&#20010;&#25968;&#25454;&#28857;&#29983;&#25104;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#30340;&#25216;&#26415;&#12290;&#36825;&#26159;&#36890;&#36807;&#39318;&#20808;&#24212;&#29992;&#20915;&#31574;&#26641;&#22238;&#24402;&#22120;&#26469;&#35745;&#31639;&#20272;&#35745;&#20998;&#25968;&#65292;&#28982;&#21518;&#25552;&#21462;&#19982;&#25968;&#25454;&#28857;&#20998;&#25968;&#30456;&#20851;&#32852;&#30340;&#30456;&#23545;&#36335;&#24452;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;DTOR&#30340;&#40065;&#26834;&#24615;&#20063;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#30456;&#27604;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#22312;&#21015;&#34920;&#23398;&#20064;&#20013;&#22343;&#21248;&#25910;&#25947;&#21644;&#26679;&#26412;&#21387;&#32553;&#21407;&#21017;&#30340;&#36866;&#29992;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#21015;&#34920;PAC&#23398;&#20064;&#20013;&#22343;&#21248;&#25910;&#25947;&#20173;&#28982;&#31561;&#20215;&#20110;&#21487;&#23398;&#20064;&#24615;</title><link>https://arxiv.org/abs/2403.10889</link><description>&lt;p&gt;
&#21015;&#34920;&#26679;&#26412;&#21387;&#32553;&#21644;&#22343;&#21248;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
List Sample Compression and Uniform Convergence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10889
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#22312;&#21015;&#34920;&#23398;&#20064;&#20013;&#22343;&#21248;&#25910;&#25947;&#21644;&#26679;&#26412;&#21387;&#32553;&#21407;&#21017;&#30340;&#36866;&#29992;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#21015;&#34920;PAC&#23398;&#20064;&#20013;&#22343;&#21248;&#25910;&#25947;&#20173;&#28982;&#31561;&#20215;&#20110;&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21015;&#34920;&#23398;&#20064;&#26159;&#30417;&#30563;&#20998;&#31867;&#30340;&#19968;&#20010;&#21464;&#31181;&#65292;&#22312;&#36825;&#31181;&#23398;&#20064;&#20013;&#65292;&#23398;&#20064;&#22120;&#20026;&#27599;&#20010;&#23454;&#20363;&#36755;&#20986;&#22810;&#20010;&#21487;&#33021;&#30340;&#26631;&#31614;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#19968;&#20010;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19982;&#21015;&#34920;&#23398;&#20064;&#19978;&#30340;&#27867;&#21270;&#30456;&#20851;&#30340;&#32463;&#20856;&#21407;&#21017;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#30830;&#23450;&#22312;&#21015;&#34920;PAC&#23398;&#20064;&#39046;&#22495;&#65292;PAC&#35774;&#32622;&#20013;&#30340;&#32463;&#20856;&#21407;&#21017;&#26159;&#21542;&#20445;&#30041;&#20854;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#22343;&#21248;&#25910;&#25947;&#65288;&#36825;&#26159;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#22522;&#30784;&#65289;&#21644;&#26679;&#26412;&#21387;&#32553;&#65288;&#36825;&#26159;Occam's Razor&#30340;&#19968;&#20010;&#24378;&#22823;&#20307;&#29616;&#65289;&#12290;&#22312;&#32463;&#20856;PAC&#23398;&#20064;&#20013;&#65292;&#22343;&#21248;&#25910;&#25947;&#21644;&#26679;&#26412;&#21387;&#32553;&#37117;&#28385;&#36275;&#19968;&#31181;&#8220;&#23436;&#22791;&#24615;&#8221;&#24418;&#24335;&#65306;&#27599;&#24403;&#19968;&#20010;&#31867;&#26159;&#21487;&#23398;&#20064;&#30340;&#26102;&#20505;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#36981;&#24490;&#36825;&#20123;&#21407;&#21017;&#30340;&#23398;&#20064;&#35268;&#21017;&#26469;&#23398;&#20064;&#23427;&#12290;&#25105;&#20204;&#25506;&#35752;&#22312;&#21015;&#34920;&#23398;&#20064;&#29615;&#22659;&#20013;&#26159;&#21542;&#20063;&#23384;&#22312;&#30456;&#21516;&#30340;&#23436;&#22791;&#24615;&#12290;&#25105;&#20204;&#34920;&#26126;&#22312;&#21015;&#34920;PAC&#23398;&#20064;&#29615;&#22659;&#20013;&#65292;&#22343;&#21248;&#25910;&#25947;&#20173;&#28982;&#31561;&#20215;&#20110;&#21487;&#23398;&#20064;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10889v1 Announce Type: new  Abstract: List learning is a variant of supervised classification where the learner outputs multiple plausible labels for each instance rather than just one. We investigate classical principles related to generalization within the context of list learning. Our primary goal is to determine whether classical principles in the PAC setting retain their applicability in the domain of list PAC learning. We focus on uniform convergence (which is the basis of Empirical Risk Minimization) and on sample compression (which is a powerful manifestation of Occam's Razor). In classical PAC learning, both uniform convergence and sample compression satisfy a form of `completeness': whenever a class is learnable, it can also be learned by a learning rule that adheres to these principles. We ask whether the same completeness holds true in the list learning setting.   We show that uniform convergence remains equivalent to learnability in the list PAC learning setting
&lt;/p&gt;</description></item><item><title>&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#21644;CME&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26680;&#26465;&#20214;&#22343;&#20540;&#23884;&#20837;&#38754;&#20020;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#34920;&#29616;&#21147;&#25361;&#25112;&#65292;&#24182;&#22312;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#20219;&#21153;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2403.10859</link><description>&lt;p&gt;
&#31070;&#32463;&#26680;&#26465;&#20214;&#22343;&#20540;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Neural-Kernel Conditional Mean Embeddings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10859
&lt;/p&gt;
&lt;p&gt;
&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#21644;CME&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#26680;&#26465;&#20214;&#22343;&#20540;&#23884;&#20837;&#38754;&#20020;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#34920;&#29616;&#21147;&#25361;&#25112;&#65292;&#24182;&#22312;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#20219;&#21153;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#23637;&#29616;&#20986;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26465;&#20214;&#22343;&#20540;&#23884;&#20837;&#65288;CME&#65289;&#20026;&#34920;&#31034;&#26465;&#20214;&#20998;&#24067;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#20294;&#36890;&#24120;&#38754;&#20020;&#21487;&#20280;&#32553;&#24615;&#21644;&#34920;&#29616;&#21147;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#32467;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#19982;CME&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#31471;&#21040;&#31471;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#20248;&#21270;&#26694;&#26550;&#65292;&#20351;&#29992;&#22522;&#20110;&#26680;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#36825;&#31181;&#35774;&#35745;&#36991;&#20813;&#20102;&#24403;&#21069;CME&#26041;&#27861;&#25152;&#38656;&#30340;&#35745;&#31639;&#26114;&#36149;&#30340;Gram&#30697;&#38453;&#27714;&#36870;&#12290;&#20026;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#31574;&#30053;&#26469;&#20248;&#21270;&#21097;&#20313;&#30340;&#26680;&#36229;&#21442;&#25968;&#12290;&#22312;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#30340;NN-CME&#28151;&#21512;&#26041;&#27861;&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#33021;&#65292;&#24182;&#24120;&#24120;&#36229;&#36807;&#29616;&#26377;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20854;&#22312;&#26080;&#32541;&#38598;&#25104;&#21040;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#29615;&#22659;&#20013;&#30340;&#21331;&#36234;&#22810;&#21151;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10859v1 Announce Type: cross  Abstract: Kernel conditional mean embeddings (CMEs) offer a powerful framework for representing conditional distribution, but they often face scalability and expressiveness challenges. In this work, we propose a new method that effectively combines the strengths of deep learning with CMEs in order to address these challenges. Specifically, our approach leverages the end-to-end neural network (NN) optimization framework using a kernel-based objective. This design circumvents the computationally expensive Gram matrix inversion required by current CME methods. To further enhance performance, we provide efficient strategies to optimize the remaining kernel hyperparameters. In conditional density estimation tasks, our NN-CME hybrid achieves competitive performance and often surpasses existing deep learning-based methods. Lastly, we showcase its remarkable versatility by seamlessly integrating it into reinforcement learning (RL) contexts. Building on 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#38024;&#23545;&#38750;&#24179;&#31283;&#38543;&#26426;&#36172;&#21338;&#26426;&#30340;&#28608;&#21169;&#25506;&#32034;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#38543;&#26102;&#38388;&#30340;&#23376;&#32447;&#24615;&#36951;&#25022;&#21644;&#34917;&#20607;</title><link>https://arxiv.org/abs/2403.10819</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#38543;&#26426;&#36172;&#21338;&#26426;&#30340;&#28608;&#21169;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Incentivized Exploration of Non-Stationary Stochastic Bandits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10819
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#38024;&#23545;&#38750;&#24179;&#31283;&#38543;&#26426;&#36172;&#21338;&#26426;&#30340;&#28608;&#21169;&#25506;&#32034;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#38543;&#26102;&#38388;&#30340;&#23376;&#32447;&#24615;&#36951;&#25022;&#21644;&#34917;&#20607;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#38382;&#39064;&#20013;&#30340;&#28608;&#21169;&#25506;&#32034;&#65292;&#20854;&#20013;&#29609;&#23478;&#36890;&#36807;&#25506;&#32034;&#38500;&#20102;&#36138;&#23146;&#36873;&#25321;&#20043;&#22806;&#30340;&#33218;&#33719;&#24471;&#34917;&#20607;&#65292;&#24182;&#19988;&#21487;&#33021;&#23545;&#22870;&#21169;&#25552;&#20379;&#20559;&#20506;&#21453;&#39304;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#38750;&#24179;&#31283;&#29615;&#22659;&#65306;&#31361;&#21464;&#21644;&#25345;&#32493;&#21464;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#28608;&#21169;&#25506;&#32034;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#38543;&#26102;&#38388;&#30340;&#23376;&#32447;&#24615;&#36951;&#25022;&#21644;&#34917;&#20607;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#28608;&#21169;&#20102;&#25506;&#32034;&#65292;&#23613;&#31649;&#23384;&#22312;&#38750;&#24179;&#31283;&#24615;&#21644;&#20559;&#20506;&#25110;&#28418;&#31227;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10819v1 Announce Type: cross  Abstract: We study incentivized exploration for the multi-armed bandit (MAB) problem with non-stationary reward distributions, where players receive compensation for exploring arms other than the greedy choice and may provide biased feedback on the reward. We consider two different non-stationary environments: abruptly-changing and continuously-changing, and propose respective incentivized exploration algorithms. We show that the proposed algorithms achieve sublinear regret and compensation over time, thus effectively incentivizing exploration despite the nonstationarity and the biased or drifted feedback.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;&#30340;&#20004;&#38454;&#27573;&#8220;&#30417;&#30563;&#24494;&#35843;+&#20154;&#31867;&#27604;&#36739;&#8221;&#26694;&#26550;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#25913;&#21892;AI&#27169;&#22411;&#30340;&#23545;&#40784;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#23545;&#22024;&#26434;&#25968;&#25454;&#21644;&#39640;&#32500;&#27169;&#22411;&#26102;&#12290;</title><link>https://arxiv.org/abs/2403.10771</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#30340;&#20154;&#31867;&#27604;&#36739;&#23545;&#40784;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Approach for Alignment with Human Comparisons
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10771
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;&#30340;&#20004;&#38454;&#27573;&#8220;&#30417;&#30563;&#24494;&#35843;+&#20154;&#31867;&#27604;&#36739;&#8221;&#26694;&#26550;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#26377;&#25928;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#25913;&#21892;AI&#27169;&#22411;&#30340;&#23545;&#40784;&#65292;&#29305;&#21035;&#26159;&#22312;&#38754;&#23545;&#22024;&#26434;&#25968;&#25454;&#21644;&#39640;&#32500;&#27169;&#22411;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#22686;&#38271;&#30340;&#36235;&#21183;&#26159;&#23558;&#20154;&#31867;&#30693;&#35782;&#25972;&#21512;&#21040;&#23398;&#20064;&#26694;&#26550;&#20013;&#65292;&#21033;&#29992;&#24494;&#22937;&#30340;&#20154;&#31867;&#21453;&#39304;&#26469;&#23436;&#21892;AI&#27169;&#22411;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#23578;&#26410;&#24320;&#21457;&#20986;&#25551;&#36848;&#20154;&#31867;&#27604;&#36739;&#20309;&#26102;&#25913;&#21892;&#20256;&#32479;&#30417;&#30563;&#24494;&#35843;&#36807;&#31243;&#30340;&#29305;&#23450;&#26465;&#20214;&#30340;&#20840;&#38754;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#25928;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#35299;&#20915;&#30001;&#22024;&#26434;&#25968;&#25454;&#21644;&#39640;&#32500;&#27169;&#22411;&#24341;&#36215;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23558;&#26426;&#22120;&#23398;&#20064;&#19982;&#20154;&#31867;&#21453;&#39304;&#36890;&#36807;&#27010;&#29575;&#20108;&#20998;&#26041;&#27861;&#32852;&#31995;&#36215;&#26469;&#30340;&#20004;&#38454;&#27573;&#8220;&#30417;&#30563;&#24494;&#35843;+&#20154;&#31867;&#27604;&#36739;&#8221;&#65288;SFT+HC&#65289;&#26694;&#26550;&#12290;&#36825;&#20004;&#38454;&#27573;&#26694;&#26550;&#39318;&#20808;&#36890;&#36807;SFT&#36807;&#31243;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#35760;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#21033;&#29992;&#20154;&#31867;&#27604;&#36739;&#26469;&#25913;&#36827;&#27169;&#22411;&#23545;&#40784;&#12290;&#20026;&#20102;&#26816;&#39564;&#23545;&#40784;&#38454;&#27573;&#30340;&#25928;&#21147;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#27010;&#24565;&#65292;&#31216;&#20026;&#8220;&#26631;&#31614;&#22122;&#22768;&#21040;&#19968;&#33268;&#24615;&#8221;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10771v1 Announce Type: new  Abstract: A growing trend involves integrating human knowledge into learning frameworks, leveraging subtle human feedback to refine AI models. Despite these advances, no comprehensive theoretical framework describing the specific conditions under which human comparisons improve the traditional supervised fine-tuning process has been developed. To bridge this gap, this paper studies the effective use of human comparisons to address limitations arising from noisy data and high-dimensional models. We propose a two-stage "Supervised Fine Tuning+Human Comparison" (SFT+HC) framework connecting machine learning with human feedback through a probabilistic bisection approach. The two-stage framework first learns low-dimensional representations from noisy-labeled data via an SFT procedure, and then uses human comparisons to improve the model alignment. To examine the efficacy of the alignment phase, we introduce a novel concept termed the "label-noise-to-co
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2403.10763</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#26356;&#24555;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#30340;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Primal-Dual Algorithm for Faster Distributionally Robust Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10763
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24102;&#26377;&#38381;&#21512;&#12289;&#20984;&#19981;&#30830;&#23450;&#24615;&#38598;&#30340;&#24809;&#32602;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#36825;&#20010;&#35774;&#32622;&#21253;&#25324;&#20102;&#23454;&#36341;&#20013;&#20351;&#29992;&#30340;$f$-DRO&#12289;Wasserstein-DRO&#21644;&#35889;/$L$-&#39118;&#38505;&#20844;&#24335;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Drago&#65292;&#19968;&#31181;&#38543;&#26426;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#65292;&#22312;&#24378;&#20984;-&#24378;&#20985;DRO&#38382;&#39064;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#12290;&#35813;&#26041;&#27861;&#23558;&#38543;&#26426;&#21270;&#21644;&#24490;&#29615;&#32452;&#20214;&#19982;&#23567;&#25209;&#37327;&#32467;&#21512;&#65292;&#26377;&#25928;&#22788;&#29702;&#20102;DRO&#20013;&#21407;&#22987;&#21644;&#23545;&#20598;&#38382;&#39064;&#30340;&#29420;&#29305;&#19981;&#23545;&#31216;&#24615;&#36136;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#30340;&#25968;&#20540;&#22522;&#20934;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10763v1 Announce Type: cross  Abstract: We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;Hessian&#35745;&#31639;&#21644;&#27714;&#36870;&#30340;Hessian-Free Laplace&#36817;&#20284;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#25968;&#21518;&#39564;&#21644;&#32593;&#32476;&#39044;&#27979;&#30340;&#26354;&#29575;&#26469;&#20272;&#35745;&#21518;&#39564;&#30340;&#26041;&#24046;&#12290;</title><link>https://arxiv.org/abs/2403.10671</link><description>&lt;p&gt;
Bayesian&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#26080;Hessian-Laplace
&lt;/p&gt;
&lt;p&gt;
Hessian-Free Laplace in Bayesian Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10671
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;Hessian&#35745;&#31639;&#21644;&#27714;&#36870;&#30340;Hessian-Free Laplace&#36817;&#20284;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#25968;&#21518;&#39564;&#21644;&#32593;&#32476;&#39044;&#27979;&#30340;&#26354;&#29575;&#26469;&#20272;&#35745;&#21518;&#39564;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;Laplace&#36817;&#20284;&#65288;LA&#65289;&#26159;&#20197;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#20026;&#20013;&#24515;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#23427;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#21560;&#24341;&#21147;&#28304;&#20110;&#33021;&#22815;&#22312;&#26631;&#20934;&#32593;&#32476;&#21442;&#25968;&#20248;&#21270;&#20043;&#21518;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65288;&#21363;&#20107;&#21518;&#65289;&#65292;&#20174;&#36817;&#20284;&#21518;&#39564;&#20013;&#25277;&#26679;&#30340;&#20415;&#21033;&#24615;&#20197;&#21450;&#27169;&#22411;&#35777;&#25454;&#30340;&#35299;&#26512;&#24418;&#24335;&#12290;&#28982;&#32780;&#65292;LA&#30340;&#19968;&#20010;&#37325;&#35201;&#35745;&#31639;&#29942;&#39048;&#26159;&#24517;&#39035;&#35745;&#31639;&#21644;&#27714;&#36870;&#23545;&#25968;&#21518;&#39564;&#30340;Hessian&#30697;&#38453;&#12290;Hessian&#21487;&#20197;&#20197;&#22810;&#31181;&#26041;&#24335;&#36817;&#20284;&#65292;&#36136;&#37327;&#19982;&#32593;&#32476;&#12289;&#25968;&#25454;&#38598;&#21644;&#25512;&#26029;&#20219;&#21153;&#31561;&#22810;&#20010;&#22240;&#32032;&#26377;&#20851;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32469;&#36807;Hessian&#35745;&#31639;&#21644;&#27714;&#36870;&#30340;&#26367;&#20195;&#26694;&#26550;&#12290;&#26080;Hessian-Laplace&#65288;HFL&#65289;&#36817;&#20284;&#20351;&#29992;&#23545;&#25968;&#21518;&#39564;&#21644;&#32593;&#32476;&#39044;&#27979;&#30340;&#26354;&#29575;&#26469;&#20272;&#35745;&#20854;&#26041;&#24046;&#12290;&#21482;&#38656;&#35201;&#20004;&#20010;&#28857;&#20272;&#35745;&#65306;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#21644;&#31561;&#20215;&#30340;&#26354;&#29575;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10671v1 Announce Type: cross  Abstract: The Laplace approximation (LA) of the Bayesian posterior is a Gaussian distribution centered at the maximum a posteriori estimate. Its appeal in Bayesian deep learning stems from the ability to quantify uncertainty post-hoc (i.e., after standard network parameter optimization), the ease of sampling from the approximate posterior, and the analytic form of model evidence. However, an important computational bottleneck of LA is the necessary step of calculating and inverting the Hessian matrix of the log posterior. The Hessian may be approximated in a variety of ways, with quality varying with a number of factors including the network, dataset, and inference task. In this paper, we propose an alternative framework that sidesteps Hessian calculation and inversion. The Hessian-free Laplace (HFL) approximation uses curvature of both the log posterior and network prediction to estimate its variance. Only two point estimates are needed: the st
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#38024;&#23545;&#26080;&#23478;&#21487;&#24402;&#32773;&#21644;&#39135;&#21697;&#38134;&#34892;&#30340;&#36164;&#28304;&#21463;&#38480;&#22806;&#23637;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Thompson&#25277;&#26679;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#24674;&#22797;&#30340;&#31639;&#27861;&#65292;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.10638</link><description>&lt;p&gt;
&#19968;&#31181;&#38754;&#21521;&#26080;&#23478;&#21487;&#24402;&#32773;&#34903;&#22836;&#22806;&#23637;&#21644;&#25910;&#38598;&#21487;&#39135;&#39135;&#29289;&#30340;&#36164;&#28304;&#21463;&#38480;&#38543;&#26426;&#35843;&#24230;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A resource-constrained stochastic scheduling algorithm for homeless street outreach and gleaning edible food
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#38024;&#23545;&#26080;&#23478;&#21487;&#24402;&#32773;&#21644;&#39135;&#21697;&#38134;&#34892;&#30340;&#36164;&#28304;&#21463;&#38480;&#22806;&#23637;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Thompson&#25277;&#26679;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#24674;&#22797;&#30340;&#31639;&#27861;&#65292;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#31639;&#27861;&#35299;&#20915;&#26041;&#26696;&#65292;&#35299;&#20915;&#20102;&#31038;&#20250;&#21464;&#38761;&#32452;&#32455;&#22312;&#36164;&#28304;&#21463;&#38480;&#22806;&#23637;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#32452;&#32455;&#25317;&#26377;&#19981;&#21516;&#30340;&#20351;&#21629;&#21644;&#36816;&#33829;&#26041;&#24335;&#65306;Breaking Ground&#8212;&#8212;&#19968;&#23478;&#24110;&#21161;&#32445;&#32422;&#26080;&#23478;&#21487;&#24402;&#32773;&#36807;&#28193;&#33267;&#27704;&#20037;&#20303;&#25151;&#30340;&#32452;&#32455;&#21644;&#20197;&#33394;&#21015;&#20840;&#22269;&#39135;&#21697;&#38134;&#34892;Leket&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#38024;&#23545;&#37096;&#20998;&#35266;&#27979;&#30340;&#21608;&#26399;&#24615;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#22312;$k$-&#27493;&#36716;&#31227;&#19979;&#24320;&#21457;&#20102;&#19968;&#31181;&#20272;&#35745;&#21644;&#20248;&#21270;&#26041;&#27861;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;Thompson&#25277;&#26679;&#19982;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#38142;&#24674;&#22797;&#65288;&#36890;&#36807;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65289;&#30340;&#31639;&#27861;&#22312;&#20004;&#20010;&#32452;&#32455;&#30340;&#38382;&#39064;&#19978;&#26126;&#26174;&#20248;&#20110;&#22522;&#32447;&#12290;&#25105;&#20204;&#20197;&#36828;&#26223;&#26041;&#24335;&#36827;&#34892;&#20102;&#36825;&#39033;&#24037;&#20316;&#65292;&#26088;&#22312;&#35774;&#35745;&#19968;&#20010;&#36275;&#22815;&#28789;&#27963;&#20294;&#20063;&#36275;&#22815;&#26377;&#29992;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#24110;&#21161;&#20811;&#26381;&#23545;&#25968;&#25454;&#21487;&#25345;&#32493;&#24433;&#21709;&#32570;&#20047;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10638v1 Announce Type: new  Abstract: We developed a common algorithmic solution addressing the problem of resource-constrained outreach encountered by social change organizations with different missions and operations: Breaking Ground -- an organization that helps individuals experiencing homelessness in New York transition to permanent housing and Leket -- the national food bank of Israel that rescues food from farms and elsewhere to feed the hungry. Specifically, we developed an estimation and optimization approach for partially-observed episodic restless bandits under $k$-step transitions. The results show that our Thompson sampling with Markov chain recovery (via Stein variational gradient descent) algorithm significantly outperforms baselines for the problems of both organizations. We carried out this work in a prospective manner with the express goal of devising a flexible-enough but also useful-enough solution that can help overcome a lack of sustainable impact in da
&lt;/p&gt;</description></item><item><title>&#29992;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#20272;&#35745;inclusive KL&#25955;&#24230;&#26799;&#24230;&#65292;&#25552;&#20986;&#20102;&#19977;&#31181;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#20559;&#24046;&#26799;&#24230;&#21644;&#39640;&#24230;&#38598;&#20013;&#21464;&#20998;&#20998;&#24067;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.10610</link><description>&lt;p&gt;
&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#22312;&#25674;&#38144;&#21464;&#20998;&#25512;&#29702;&#20013;&#21253;&#23481;KL&#26368;&#23567;&#21270;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequential Monte Carlo for Inclusive KL Minimization in Amortized Variational Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10610
&lt;/p&gt;
&lt;p&gt;
&#29992;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#20272;&#35745;inclusive KL&#25955;&#24230;&#26799;&#24230;&#65292;&#25552;&#20986;&#20102;&#19977;&#31181;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#20559;&#24046;&#26799;&#24230;&#21644;&#39640;&#24230;&#38598;&#20013;&#21464;&#20998;&#20998;&#24067;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29992;&#26469;&#35757;&#32451;&#32534;&#30721;&#22120;&#32593;&#32476;&#25191;&#34892;&#25674;&#38144;&#21464;&#20998;&#25512;&#29702;&#65292;&#20174;&#31934;&#30830;&#21518;&#39564;&#20998;&#24067;&#21040;&#20854;&#36817;&#20284;&#20998;&#24067;&#30340;KL&#25955;&#24230;&#65292;&#21363;&#21253;&#23481;&#25110;&#27491;&#21521;KL&#65292;&#26159;&#22240;&#20854;&#26497;&#23567;&#21270;&#20540;&#30340;&#21306;&#22495;&#35206;&#30422;&#24615;&#36136;&#32780;&#25104;&#20026;&#21464;&#20998;&#30446;&#26631;&#30340;&#36234;&#26469;&#36234;&#27969;&#34892;&#36873;&#25321;&#12290;&#28982;&#32780;&#65292;&#26368;&#23567;&#21270;&#36825;&#19968;&#30446;&#26631;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SMC-Wake&#65292;&#35813;&#36807;&#31243;&#29992;&#20110;&#25311;&#21512;&#19968;&#31181;&#25674;&#38144;&#21464;&#20998;&#36817;&#20284;&#65292;&#20854;&#20351;&#29992;&#35843;&#33410;&#20284;&#28982;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#22120;&#26469;&#20272;&#35745;&#21253;&#23481;KL&#25955;&#24230;&#30340;&#26799;&#24230;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#23545;&#36845;&#20195;&#27425;&#25968;&#26159;&#28176;&#36817;&#26080;&#20559;&#30340;&#20004;&#31181;&#26159;&#24378;&#19968;&#33268;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20132;&#26367;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10610v1 Announce Type: new  Abstract: For training an encoder network to perform amortized variational inference, the Kullback-Leibler (KL) divergence from the exact posterior to its approximation, known as the inclusive or forward KL, is an increasingly popular choice of variational objective due to the mass-covering property of its minimizer. However, minimizing this objective is challenging. A popular existing approach, Reweighted Wake-Sleep (RWS), suffers from heavily biased gradients and a circular pathology that results in highly concentrated variational distributions. As an alternative, we propose SMC-Wake, a procedure for fitting an amortized variational approximation that uses likelihood-tempered sequential Monte Carlo samplers to estimate the gradient of the inclusive KL divergence. We propose three gradient estimators, all of which are asymptotically unbiased in the number of iterations and two of which are strongly consistent. Our method interleaves stochastic gr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#26657;&#20934;&#27969;&#20307;&#21160;&#21147;&#23398;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#22122;&#22768;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#25216;&#26415;&#21462;&#20195;&#20102;&#20197;&#24448;&#30340;PCA&#25216;&#26415;&#65292;&#36825;&#33021;&#22815;&#36991;&#20813;&#23545;&#22686;&#37327;&#26045;&#21152;&#39069;&#22806;&#32422;&#26463;&#12290;</title><link>https://arxiv.org/abs/2403.10578</link><description>&lt;p&gt;
&#38543;&#26426;&#26059;&#36716;&#27973;&#27700;&#22122;&#22768;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Generative Modelling of Stochastic Rotating Shallow Water Noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#29992;&#20110;&#26657;&#20934;&#27969;&#20307;&#21160;&#21147;&#23398;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#22122;&#22768;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#25216;&#26415;&#21462;&#20195;&#20102;&#20197;&#24448;&#30340;PCA&#25216;&#26415;&#65292;&#36825;&#33021;&#22815;&#36991;&#20813;&#23545;&#22686;&#37327;&#26045;&#21152;&#39069;&#22806;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#20316;&#32773;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#26657;&#20934;&#27969;&#20307;&#21160;&#21147;&#23398;&#38543;&#26426;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#22122;&#22768;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#20854;&#20013;&#38543;&#26426;&#24615;&#34987;&#24341;&#20837;&#20197;&#21442;&#25968;&#21270;&#27425;&#32593;&#26684;&#23610;&#24230;&#36807;&#31243;&#12290;&#23376;&#32593;&#26684;&#23610;&#24230;&#36807;&#31243;&#30340;&#38543;&#26426;&#21442;&#25968;&#21270;&#22312;&#22825;&#27668;&#21644;&#27668;&#20505;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20013;&#26159;&#24517;&#38656;&#30340;&#65292;&#20197;&#34920;&#31034;&#30001;&#23376;&#32593;&#26684;&#23610;&#24230;&#27874;&#21160;&#24341;&#36215;&#30340;&#31995;&#32479;&#27169;&#22411;&#35823;&#24046;&#12290;&#20197;&#21069;&#30340;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#38543;&#26426;&#21442;&#25968;&#21270;&#22686;&#37327;&#20026;&#27491;&#24577;&#20998;&#24067;&#30340;&#20551;&#35774;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;PCA&#25216;&#26415;&#34987;&#29983;&#25104;&#27169;&#22411;&#25216;&#26415;&#25152;&#21462;&#20195;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36991;&#20813;&#23545;&#22686;&#37327;&#26045;&#21152;&#39069;&#22806;&#32422;&#26463;&#12290;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#27169;&#22411;&#39640;&#31243;&#21464;&#37327;&#20316;&#20026;&#36755;&#20837;&#25968;&#25454;&#30340;&#38543;&#26426;&#26059;&#36716;&#27973;&#27700;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10578v1 Announce Type: cross  Abstract: In recent work, the authors have developed a generic methodology for calibrating the noise in fluid dynamics stochastic partial differential equations where the stochasticity was introduced to parametrize subgrid-scale processes. The stochastic parameterization of sub-grid scale processes is required in the estimation of uncertainty in weather and climate predictions, to represent systematic model errors arising from subgrid-scale fluctuations. The previous methodology used a principal component analysis (PCA) technique based on the ansatz that the increments of the stochastic parametrization are normally distributed.   In this paper, the PCA technique is replaced by a generative model technique. This enables us to avoid imposing additional constraints on the increments. The methodology is tested on a stochastic rotating shallow water model with the elevation variable of the model used as input data. The numerical simulations show that
&lt;/p&gt;</description></item><item><title>&#28151;&#21512;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#36890;&#36807;&#23558;&#31163;&#32447;&#25968;&#25454;&#38598;&#21253;&#21547;&#22312;&#22312;&#32447;&#31639;&#27861;&#30340;&#32463;&#39564;&#37325;&#25918;&#32531;&#20914;&#21306;&#20013;&#36827;&#34892;&#21551;&#21160;&#65292;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#22522;&#20110;&#31163;&#32447;&#25968;&#25454;&#20998;&#24067;&#24341;&#23548;&#22312;&#32447;&#25506;&#32034;&#30340;&#21487;&#35777;&#26126;&#25910;&#30410;&#65292;&#21363;&#20351;&#31163;&#32447;&#25968;&#25454;&#38598;&#27809;&#26377;&#21333;&#19968;&#31574;&#30053;&#21487;&#38598;&#20013;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.09701</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#26377;&#38480;&#35206;&#30422;&#30340;&#28151;&#21512;RL&#22312;&#32447;&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
A Natural Extension To Online Algorithms For Hybrid RL With Limited Coverage
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09701
&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#36890;&#36807;&#23558;&#31163;&#32447;&#25968;&#25454;&#38598;&#21253;&#21547;&#22312;&#22312;&#32447;&#31639;&#27861;&#30340;&#32463;&#39564;&#37325;&#25918;&#32531;&#20914;&#21306;&#20013;&#36827;&#34892;&#21551;&#21160;&#65292;&#21487;&#20197;&#23454;&#29616;&#31867;&#20284;&#20110;&#22522;&#20110;&#31163;&#32447;&#25968;&#25454;&#20998;&#24067;&#24341;&#23548;&#22312;&#32447;&#25506;&#32034;&#30340;&#21487;&#35777;&#26126;&#25910;&#30410;&#65292;&#21363;&#20351;&#31163;&#32447;&#25968;&#25454;&#38598;&#27809;&#26377;&#21333;&#19968;&#31574;&#30053;&#21487;&#38598;&#20013;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#32467;&#21512;&#22312;&#32447;&#21644;&#31163;&#32447;&#25968;&#25454;&#65292;&#36817;&#24180;&#26469;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#20851;&#20110;&#20854;&#21487;&#35777;&#26126;&#30410;&#22788;&#30340;&#30740;&#31350;&#20173;&#28982;&#24456;&#23569;&#12290;&#35768;&#22810;&#29616;&#26377;&#30340;&#28151;&#21512;RL&#31639;&#27861;&#23545;&#31163;&#32447;&#25968;&#25454;&#38598;&#26045;&#21152;&#35206;&#30422;&#20551;&#35774;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#36825;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;&#19968;&#20010;&#35774;&#35745;&#33391;&#22909;&#30340;&#22312;&#32447;&#31639;&#27861;&#24212;&#35813;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#8220;&#22635;&#34917;&#31354;&#30333;&#8221;&#65292;&#25506;&#32034;&#34892;&#20026;&#31574;&#30053;&#26410;&#25506;&#32034;&#30340;&#29366;&#24577;&#21644;&#21160;&#20316;&#12290;&#19982;&#20808;&#21069;&#20391;&#37325;&#20110;&#20272;&#35745;&#31163;&#32447;&#25968;&#25454;&#20998;&#24067;&#20197;&#24341;&#23548;&#22312;&#32447;&#25506;&#32034;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#34920;&#26126;&#23545;&#26631;&#20934;&#20048;&#35266;&#22312;&#32447;&#31639;&#27861;&#30340;&#19968;&#20010;&#33258;&#28982;&#25193;&#23637;&#8212;&#8212;&#36890;&#36807;&#23558;&#31163;&#32447;&#25968;&#25454;&#38598;&#21253;&#21547;&#22312;&#32463;&#39564;&#37325;&#25918;&#32531;&#20914;&#21306;&#20013;&#26469;&#21551;&#21160;&#23427;&#20204;&#8212;&#8212;&#21363;&#20351;&#31163;&#32447;&#25968;&#25454;&#38598;&#27809;&#26377;&#21333;&#19968;&#31574;&#30053;&#21487;&#38598;&#20013;&#24615;&#65292;&#20063;&#21487;&#23454;&#29616;&#28151;&#21512;&#25968;&#25454;&#30340;&#31867;&#20284;&#21487;&#35777;&#26126;&#25910;&#30410;&#12290;&#25105;&#20204;&#23436;&#25104;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09701v1 Announce Type: new  Abstract: Hybrid Reinforcement Learning (RL), leveraging both online and offline data, has garnered recent interest, yet research on its provable benefits remains sparse. Additionally, many existing hybrid RL algorithms (Song et al., 2023; Nakamoto et al., 2023; Amortila et al., 2024) impose coverage assumptions on the offline dataset, but we show that this is unnecessary. A well-designed online algorithm should "fill in the gaps" in the offline dataset, exploring states and actions that the behavior policy did not explore. Unlike previous approaches that focus on estimating the offline data distribution to guide online exploration (Li et al., 2023b), we show that a natural extension to standard optimistic online algorithms -- warm-starting them by including the offline dataset in the experience replay buffer -- achieves similar provable gains from hybrid data even when the offline dataset does not have single-policy concentrability. We accomplish
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#32467;&#26500;&#28151;&#21512;&#27010;&#29575;&#20998;&#24067;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;SBI&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2403.07454</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#23616;&#37096;&#32447;&#24615;&#26144;&#23556;&#36827;&#34892;&#24555;&#36895;&#12289;&#20934;&#30830;&#21644;&#36731;&#37327;&#32423;&#30340;&#39034;&#24207;&#20223;&#30495;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Fast, accurate and lightweight sequential simulation-based inference using Gaussian locally linear mappings
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07454
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#32467;&#26500;&#28151;&#21512;&#27010;&#29575;&#20998;&#24067;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;SBI&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07454v1 &#20844;&#21578;&#31867;&#22411;: &#36328;&#39046;&#22495; &#25688;&#35201;: &#38024;&#23545;&#20855;&#26377;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#30340;&#22797;&#26434;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#20197;&#20351;&#29992;&#22810;&#27425;&#35843;&#29992;&#35745;&#31639;&#27169;&#25311;&#22120;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290; &#36825;&#20123;&#26041;&#27861;&#34987;&#32479;&#31216;&#20026;&#8220;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#8221;&#65288;SBI&#65289;&#12290; &#26368;&#36817;&#30340;SBI&#26041;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#25552;&#20379;&#36817;&#20284;&#20294;&#34920;&#36798;&#20016;&#23500;&#30340;&#26500;&#36896;&#65292;&#29992;&#20110;&#19981;&#21487;&#29992;&#30340;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#20998;&#24067;&#12290; &#28982;&#32780;&#65292;&#23427;&#20204;&#36890;&#24120;&#26080;&#27861;&#23454;&#29616;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#38656;&#27714;&#20043;&#38388;&#30340;&#26368;&#20339;&#25240;&#34935;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25552;&#20379;&#20284;&#28982;&#20989;&#25968;&#21644;&#21518;&#39564;&#20998;&#24067;&#36817;&#20284;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#20351;&#29992;&#32467;&#26500;&#21270;&#30340;&#27010;&#29575;&#20998;&#24067;&#28151;&#21512;&#29289;&#12290; &#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;NN&#30340;SBI&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20135;&#29983;&#20934;&#30830;&#30340;&#21518;&#39564;&#25512;&#26029;&#30340;&#21516;&#26102;&#65292;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21344;&#29992;&#37327;&#12290; &#25105;&#20204;&#22312;SBI&#25991;&#29486;&#20013;&#30340;&#20960;&#20010;&#22522;&#20934;&#27169;&#22411;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07454v1 Announce Type: cross  Abstract: Bayesian inference for complex models with an intractable likelihood can be tackled using algorithms performing many calls to computer simulators. These approaches are collectively known as "simulation-based inference" (SBI). Recent SBI methods have made use of neural networks (NN) to provide approximate, yet expressive constructs for the unavailable likelihood function and the posterior distribution. However, they do not generally achieve an optimal trade-off between accuracy and computational demand. In this work, we propose an alternative that provides both approximations to the likelihood and the posterior distribution, using structured mixtures of probability distributions. Our approach produces accurate posterior inference when compared to state-of-the-art NN-based SBI methods, while exhibiting a much smaller computational footprint. We illustrate our results on several benchmark models from the SBI literature.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;</title><link>https://arxiv.org/abs/2403.02686</link><description>&lt;p&gt;
&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#30340;&#22238;&#22768;&#24577;&#24615;&#36136;&#31561;&#32423;
&lt;/p&gt;
&lt;p&gt;
Hierarchy of the echo state property in quantum reservoir computing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02686
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#20013;&#22238;&#22768;&#24577;&#24615;&#36136;&#30340;&#19981;&#21516;&#23618;&#27425;&#65292;&#21253;&#25324;&#38750;&#24179;&#31283;&#24615;ESP&#21644;&#23376;&#31995;&#32479;&#20855;&#26377;ESP&#30340;&#23376;&#31354;&#38388;/&#23376;&#38598;ESP&#12290;&#36827;&#34892;&#20102;&#25968;&#20540;&#28436;&#31034;&#21644;&#35760;&#24518;&#23481;&#37327;&#35745;&#31639;&#20197;&#39564;&#35777;&#36825;&#20123;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22238;&#22768;&#24577;&#24615;&#36136;&#65288;ESP&#65289;&#20195;&#34920;&#20102;&#20648;&#22791;&#35745;&#31639;&#65288;RC&#65289;&#26694;&#26550;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#27010;&#24565;&#65292;&#36890;&#36807;&#23545;&#21021;&#22987;&#29366;&#24577;&#21644;&#36828;&#26399;&#36755;&#20837;&#19981;&#21152;&#27495;&#35270;&#26469;&#30830;&#20445;&#20648;&#33988;&#32593;&#32476;&#30340;&#20165;&#36755;&#20986;&#35757;&#32451;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;ESP&#23450;&#20041;&#24182;&#26410;&#25551;&#36848;&#21487;&#33021;&#28436;&#21464;&#32479;&#35745;&#23646;&#24615;&#30340;&#38750;&#24179;&#31283;&#31995;&#32479;&#12290;&#20026;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31867;&#26032;&#30340;ESP&#65306;\textit{&#38750;&#24179;&#31283;ESP}&#65292;&#29992;&#20110;&#28508;&#22312;&#38750;&#24179;&#31283;&#31995;&#32479;&#65292;&#21644;\textit{&#23376;&#31354;&#38388;/&#23376;&#38598;ESP}&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;ESP&#30340;&#23376;&#31995;&#32479;&#30340;&#31995;&#32479;&#12290;&#26681;&#25454;&#36825;&#20123;&#23450;&#20041;&#65292;&#25105;&#20204;&#22312;&#37327;&#23376;&#20648;&#22791;&#35745;&#31639;&#65288;QRC&#65289;&#26694;&#26550;&#20013;&#25968;&#20540;&#28436;&#31034;&#20102;&#38750;&#24179;&#31283;ESP&#19982;&#20856;&#22411;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#21644;&#20351;&#29992;&#38750;&#32447;&#24615;&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;&#65288;NARMA&#65289;&#20219;&#21153;&#30340;&#36755;&#20837;&#32534;&#30721;&#26041;&#27861;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#35745;&#31639;&#32447;&#24615;/&#38750;&#32447;&#24615;&#35760;&#24518;&#23481;&#37327;&#26469;&#30830;&#35748;&#36825;&#31181;&#23545;&#24212;&#20851;&#31995;&#65292;&#20197;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02686v1 Announce Type: cross  Abstract: The echo state property (ESP) represents a fundamental concept in the reservoir computing (RC) framework that ensures output-only training of reservoir networks by being agnostic to the initial states and far past inputs. However, the traditional definition of ESP does not describe possible non-stationary systems in which statistical properties evolve. To address this issue, we introduce two new categories of ESP: \textit{non-stationary ESP}, designed for potentially non-stationary systems, and \textit{subspace/subset ESP}, designed for systems whose subsystems have ESP. Following the definitions, we numerically demonstrate the correspondence between non-stationary ESP in the quantum reservoir computer (QRC) framework with typical Hamiltonian dynamics and input encoding methods using non-linear autoregressive moving-average (NARMA) tasks. We also confirm the correspondence by computing linear/non-linear memory capacities that quantify 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#32943;&#23450;&#22238;&#31572;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#21363;&#26159;&#21542;&#21487;&#20197;&#22312;&#19981;&#20801;&#35768;&#38169;&#35823;&#25269;&#28040;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23558;&#19968;&#31181;&#24120;&#35265;&#30340;&#23433;&#20840;&#32422;&#26463;&#27169;&#22411;&#25193;&#23637;&#21040;&#20855;&#26377;&#22810;&#20010;&#32422;&#26463;&#30340;CMDPs&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#23454;&#29616;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.15776</link><description>&lt;p&gt;
&#21463;&#38480;&#21046;MDP&#20013;&#30340;&#30495;&#27491;&#26080;&#24724;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Truly No-Regret Learning in Constrained MDPs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15776
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#32943;&#23450;&#22238;&#31572;&#20102;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#21363;&#26159;&#21542;&#21487;&#20197;&#22312;&#19981;&#20801;&#35768;&#38169;&#35823;&#25269;&#28040;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#23558;&#19968;&#31181;&#24120;&#35265;&#30340;&#23433;&#20840;&#32422;&#26463;&#27169;&#22411;&#25193;&#23637;&#21040;&#20855;&#26377;&#22810;&#20010;&#32422;&#26463;&#30340;CMDPs&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#23454;&#29616;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#32422;&#26463;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;CMDPs&#65289;&#26159;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#24314;&#27169;&#23433;&#20840;&#32422;&#26463;&#30340;&#24120;&#35265;&#26041;&#24335;&#12290;&#30446;&#21069;&#29992;&#20110;&#39640;&#25928;&#35299;&#20915;CMDPs&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#12290;&#23545;&#20110;&#36825;&#20123;&#31639;&#27861;&#65292;&#25152;&#26377;&#24403;&#21069;&#24050;&#30693;&#30340;&#21518;&#24724;&#30028;&#37117;&#20801;&#35768;&#38169;&#35823;&#25269;&#28040;&#8212;&#8212;&#21487;&#20197;&#36890;&#36807;&#22312;&#19968;&#20010;&#22238;&#21512;&#20013;&#30340;&#32422;&#26463;&#36829;&#21453;&#26469;&#29992;&#20005;&#26684;&#30340;&#32422;&#26463;&#28385;&#36275;&#22312;&#21478;&#19968;&#20010;&#22238;&#21512;&#20013;&#12290;&#36825;&#20351;&#24471;&#22312;&#32447;&#23398;&#20064;&#36807;&#31243;&#19981;&#23433;&#20840;&#65292;&#22240;&#20026;&#23427;&#20165;&#20445;&#35777;&#26368;&#32456;&#65288;&#28151;&#21512;&#65289;&#31574;&#30053;&#30340;&#23433;&#20840;&#24615;&#65292;&#32780;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#19981;&#20445;&#35777;&#23433;&#20840;&#12290;&#27491;&#22914;Efroni&#31561;&#20154;&#65288;2020&#24180;&#65289;&#25351;&#20986;&#30340;&#65292;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#26159;&#21542;&#21487;&#20197;&#22312;&#19981;&#20801;&#35768;&#38169;&#35823;&#25269;&#28040;&#30340;&#24773;&#20917;&#19979;&#21487;&#35777;&#26126;&#22320;&#23454;&#29616;&#27425;&#32447;&#24615;&#21518;&#24724;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#31532;&#19968;&#20010;&#32943;&#23450;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;&#20851;&#20110;&#27491;&#21017;&#21270;&#21407;&#22987;-&#23545;&#20598;&#26041;&#26696;&#30340;&#26368;&#21518;&#36845;&#20195;&#25910;&#25947;&#24615;&#36890;&#29992;&#21270;&#21040;&#20855;&#26377;&#22810;&#20010;&#32422;&#26463;&#30340;CMDPs&#19978;&#12290;&#22522;&#20110;&#36825;&#19968;&#35265;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21407;&#22987;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15776v1 Announce Type: new  Abstract: Constrained Markov decision processes (CMDPs) are a common way to model safety constraints in reinforcement learning. State-of-the-art methods for efficiently solving CMDPs are based on primal-dual algorithms. For these algorithms, all currently known regret bounds allow for error cancellations -- one can compensate for a constraint violation in one round with a strict constraint satisfaction in another. This makes the online learning process unsafe since it only guarantees safety for the final (mixture) policy but not during learning. As Efroni et al. (2020) pointed out, it is an open question whether primal-dual algorithms can provably achieve sublinear regret if we do not allow error cancellations. In this paper, we give the first affirmative answer. We first generalize a result on last-iterate convergence of regularized primal-dual schemes to CMDPs with multiple constraints. Building upon this insight, we propose a model-based primal
&lt;/p&gt;</description></item><item><title>HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10228</link><description>&lt;p&gt;
HyperAgent&#65306;&#19968;&#31181;&#31616;&#21333;&#12289;&#21487;&#25193;&#23637;&#12289;&#39640;&#25928;&#19988;&#21487;&#35777;&#26126;&#29992;&#20110;&#22797;&#26434;&#29615;&#22659;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10228
&lt;/p&gt;
&lt;p&gt;
HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20195;&#29702;&#38656;&#35201;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#12289;&#20855;&#26377;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#19981;&#26029;&#31215;&#32047;&#30340;&#20132;&#20114;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HyperAgent&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#36229;&#27169;&#22411;&#12289;&#32034;&#24341;&#25277;&#26679;&#26041;&#26696;&#21644;&#22686;&#37327;&#26356;&#26032;&#26426;&#21046;&#30340;RL&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#20215;&#20540;&#20989;&#25968;&#36924;&#36817;&#20013;&#36827;&#34892;&#35745;&#31639;&#39640;&#25928;&#30340;&#39034;&#24207;&#21518;&#39564;&#36924;&#36817;&#21644;&#25968;&#25454;&#39640;&#25928;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#36229;&#36234;&#20102;&#20849;&#36717;&#24615;&#12290;HyperAgent&#30340;&#23454;&#29616;&#31616;&#21333;&#65292;&#21482;&#38656;&#35201;&#22312;DDQN&#20013;&#28155;&#21152;&#19968;&#20010;&#27169;&#22359;&#21644;&#19968;&#34892;&#39069;&#22806;&#20195;&#30721;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;HyperAgent&#22312;&#22823;&#35268;&#27169;&#28145;&#24230;RL&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#22312;&#25968;&#25454;&#36824;&#26159;&#35745;&#31639;&#26041;&#38754;&#37117;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#22312;&#23454;&#38469;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#20013;&#65292;HyperAgent&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#23450;&#29702;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#23450;&#29702;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#24658;&#23450;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#35813;&#23450;&#29702;&#22312;&#39640;&#32500;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#38750;&#20809;&#28369;&#20248;&#21270;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.07356</link><description>&lt;p&gt;
&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#23450;&#29702;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Novel Gaussian Min-Max Theorem and its Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#23450;&#29702;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#23450;&#29702;&#23545;&#20110;&#29420;&#31435;&#20294;&#38750;&#24658;&#23450;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#35813;&#23450;&#29702;&#22312;&#39640;&#32500;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#38750;&#20809;&#28369;&#20248;&#21270;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gordon&#30340;&#19968;&#20010;&#33879;&#21517;&#32467;&#26524;&#20801;&#35768;&#27604;&#36739;&#20004;&#20010;&#39640;&#26031;&#36807;&#31243;&#30340;&#26368;&#23567;&#26368;&#22823;&#34892;&#20026;&#65292;&#22914;&#26524;&#28385;&#36275;&#26576;&#20123;&#19981;&#31561;&#24335;&#26465;&#20214;&#12290;&#36825;&#20010;&#32467;&#26524;&#30340;&#32467;&#26524;&#21253;&#25324;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#65288;GMT&#65289;&#21644;&#20984;&#39640;&#26031;&#26368;&#23567;&#26368;&#22823;&#65288;CGMT&#65289;&#23450;&#29702;&#65292;&#36825;&#20123;&#23450;&#29702;&#22312;&#39640;&#32500;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#12289;&#38750;&#20809;&#28369;&#20248;&#21270;&#21644;&#20449;&#21495;&#22788;&#29702;&#26041;&#38754;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#30446;&#21069;&#20026;&#27490;&#65292;&#27809;&#26377;&#21457;&#29616;&#28385;&#36275;&#36825;&#20123;&#19981;&#31561;&#24335;&#30340;&#20854;&#20182;&#19968;&#23545;&#39640;&#26031;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#26679;&#19968;&#23545;&#26032;&#30340;&#39640;&#26031;&#36807;&#31243;&#12290;&#30001;&#27492;&#24471;&#21040;&#30340;&#23450;&#29702;&#23558;&#32463;&#20856;&#30340;GMT&#23450;&#29702;&#21644;CGMT&#23450;&#29702;&#20174;&#22522;&#26412;&#36807;&#31243;&#20013;&#30340;&#24213;&#23618;&#39640;&#26031;&#30697;&#38453;&#20855;&#26377;iid&#34892;&#30340;&#24773;&#20917;&#25193;&#23637;&#21040;&#20855;&#26377;&#29420;&#31435;&#20294;&#38750;&#24658;&#23450;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#26032;&#30340;CGMT&#23450;&#29702;&#24212;&#29992;&#20110;&#22810;&#28304;&#39640;&#26031;&#22238;&#24402;&#38382;&#39064;&#65292;&#20197;&#21450;&#23646;&#20110;&#30340;&#20108;&#20803;&#20998;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A celebrated result by Gordon allows one to compare the min-max behavior of two Gaussian processes if certain inequality conditions are met. The consequences of this result include the Gaussian min-max (GMT) and convex Gaussian min-max (CGMT) theorems which have had far-reaching implications in high-dimensional statistics, machine learning, non-smooth optimization, and signal processing. Both theorems rely on a pair of Gaussian processes, first identified by Slepian, that satisfy Gordon's comparison inequalities. To date, no other pair of Gaussian processes satisfying these inequalities has been discovered. In this paper, we identify such a new pair. The resulting theorems extend the classical GMT and CGMT Theorems from the case where the underlying Gaussian matrix in the primary process has iid rows to where it has independent but non-identically-distributed ones. The new CGMT is applied to the problems of multi-source Gaussian regression, as well as to binary classification of genera
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#21333;&#27425;GD&#30456;&#27604;&#65292;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#23454;&#29616;&#32593;&#32476;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#30340;&#37325;&#21472;&#65292;&#23637;&#31034;&#20102;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#24191;&#27867;&#20989;&#25968;&#31867;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2402.03220</link><description>&lt;p&gt;
&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#22312;&#20004;&#23618;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#22909;&#22788;&#65306;&#25171;&#30772;&#20449;&#24687;&#21644;&#36339;&#36291;&#25351;&#25968;&#30340;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Reusing Batches for Gradient Descent in Two-Layer Networks: Breaking the Curse of Information and Leap Exponents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03220
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#30340;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#19982;&#21333;&#27425;GD&#30456;&#27604;&#65292;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#38480;&#21046;&#65292;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#23454;&#29616;&#32593;&#32476;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#30340;&#37325;&#21472;&#65292;&#23637;&#31034;&#20102;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#24191;&#27867;&#20989;&#25968;&#31867;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23398;&#20064;&#22810;&#25351;&#25968;&#30446;&#26631;&#20989;&#25968;&#26102;&#65292;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#20851;&#27880;&#37325;&#22797;&#22810;&#27425;&#20351;&#29992;&#25209;&#27425;&#30340;&#22810;&#27425;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#24182;&#23637;&#31034;&#23427;&#19982;&#21333;&#27425;&#26799;&#24230;&#19979;&#38477;&#30456;&#27604;&#65292;&#26174;&#33879;&#25913;&#21464;&#20102;&#23545;&#20110;&#21738;&#20123;&#20989;&#25968;&#26159;&#21487;&#23398;&#20064;&#30340;&#30340;&#32467;&#35770;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21457;&#29616;&#20855;&#26377;&#26377;&#38480;&#27493;&#38271;&#30340;&#22810;&#27425;GD&#33021;&#22815;&#20811;&#26381;&#30446;&#26631;&#20989;&#25968;&#30340;&#20449;&#24687;&#25351;&#25968;&#65288;Ben Arous&#31561;&#20154;&#65292;2021&#65289;&#21644;&#36339;&#36291;&#25351;&#25968;&#65288;Abbe&#31561;&#20154;&#65292;2023&#65289;&#25152;&#32473;&#20986;&#30340;&#26799;&#24230;&#27969;&#21644;&#21333;&#27425;GD&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#25209;&#27425;&#65292;&#32593;&#32476;&#20165;&#38656;&#20004;&#20010;&#26102;&#38388;&#27493;&#39588;&#23601;&#33021;&#19982;&#30446;&#26631;&#23376;&#31354;&#38388;&#36798;&#25104;&#37325;&#21472;&#65292;&#21363;&#20351;&#20989;&#25968;&#19981;&#28385;&#36275;&#38454;&#26799;&#24615;&#36136;&#65288;Abbe&#31561;&#20154;&#65292;2021&#65289;&#12290;&#25105;&#20204;&#23545;&#33021;&#22815;&#22312;&#26377;&#38480;&#26102;&#38388;&#20869;&#26377;&#25928;&#23398;&#20064;&#30340;&#65288;&#24191;&#27867;&#30340;&#65289;&#20989;&#25968;&#31867;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#22522;&#20110;&#21160;&#21147;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#21160;&#24577;&#30340;&#38381;&#24335;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the training dynamics of two-layer neural networks when learning multi-index target functions. We focus on multi-pass gradient descent (GD) that reuses the batches multiple times and show that it significantly changes the conclusion about which functions are learnable compared to single-pass gradient descent. In particular, multi-pass GD with finite stepsize is found to overcome the limitations of gradient flow and single-pass GD given by the information exponent (Ben Arous et al., 2021) and leap exponent (Abbe et al., 2023) of the target function. We show that upon re-using batches, the network achieves in just two time steps an overlap with the target subspace even for functions not satisfying the staircase property (Abbe et al., 2021). We characterize the (broad) class of functions efficiently learned in finite time. The proof of our results is based on the analysis of the Dynamical Mean-Field Theory (DMFT). We further provide a closed-form description of the dynamica
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#22312;&#38750;&#20984;&#21644;&#20984;&#35774;&#32622;&#19979;&#37117;&#33021;&#21462;&#24471;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25351;&#20986;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2402.03126</link><description>&lt;p&gt;
&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#33258;&#30001;&#24230;&#26377;&#22810;&#39640;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Free is Parameter-Free Stochastic Optimization?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03126
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#22312;&#38750;&#20984;&#21644;&#20984;&#35774;&#32622;&#19979;&#37117;&#33021;&#21462;&#24471;&#20248;&#20110;&#20808;&#36827;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#35770;&#25991;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#25351;&#20986;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#21442;&#38543;&#26426;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#20160;&#20040;&#26465;&#20214;&#19979;&#21487;&#20197;&#23384;&#22312;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65306;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#36798;&#21040;&#19982;&#26368;&#20248;&#35843;&#21442;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#32780;&#19981;&#38656;&#35201;&#23545;&#30495;&#23454;&#38382;&#39064;&#21442;&#25968;&#26377;&#24456;&#22810;&#30693;&#35782;&#12290;&#29616;&#26377;&#30340;&#26080;&#21442;&#26041;&#27861;&#21482;&#33021;&#34987;&#35270;&#20026;&#8220;&#37096;&#20998;&#8221;&#26080;&#21442;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#23545;&#30495;&#23454;&#38382;&#39064;&#21442;&#25968;&#26377;&#19968;&#20123;&#38750;&#24179;&#20961;&#30340;&#30693;&#35782;&#65292;&#27604;&#22914;&#38543;&#26426;&#26799;&#24230;&#33539;&#25968;&#30340;&#19978;&#30028;&#12289;&#21040;&#26368;&#23567;&#20540;&#30340;&#36317;&#31163;&#30340;&#19978;&#30028;&#31561;&#12290;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#36229;&#21442;&#25968;&#25628;&#32034;&#25216;&#26415;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#65292;&#22312;&#24615;&#33021;&#19978;&#36229;&#36807;&#20102;&#26356;&#22797;&#26434;&#30340;&#20808;&#36827;&#31639;&#27861;&#12290;&#22312;&#20855;&#26377;&#22122;&#22768;&#20989;&#25968;&#20540;&#30340;&#20984;&#35774;&#32622;&#19979;&#65292;&#22312;&#36739;&#23567;&#30340;&#22122;&#22768;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20063;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#20551;&#35774;&#21482;&#33021;&#35775;&#38382;&#38543;&#26426;&#26799;&#24230;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19979;&#30028;&#65292;&#20351;&#24471;&#23436;&#20840;&#26080;&#21442;&#30340;&#26041;&#27861;&#26080;&#27861;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#21452;&#33218;&#39640;&#26031;&#36172;&#33218;&#26426;&#22120;&#20154;&#20013;&#35299;&#20915;&#20855;&#26377;&#26410;&#30693;&#26041;&#24046;&#24773;&#20917;&#19979;&#23616;&#37096;&#26368;&#20248;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#30340;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2312.12741</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#26410;&#30693;&#26041;&#24046;&#30340;&#21452;&#33218;&#39640;&#26031;&#36172;&#33218;&#26426;&#22120;&#20154;&#20013;&#23616;&#37096;&#26368;&#20248;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Locally Optimal Fixed-Budget Best Arm Identification in Two-Armed Gaussian Bandits with Unknown Variances
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.12741
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#21452;&#33218;&#39640;&#26031;&#36172;&#33218;&#26426;&#22120;&#20154;&#20013;&#35299;&#20915;&#20855;&#26377;&#26410;&#30693;&#26041;&#24046;&#24773;&#20917;&#19979;&#23616;&#37096;&#26368;&#20248;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#21452;&#33218;&#39640;&#26031;&#36172;&#33218;&#26426;&#22120;&#20154;&#20013;&#24102;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;BAI&#65289;&#38382;&#39064;&#12290; &#22312;BAI&#20013;&#65292;&#32473;&#23450;&#22810;&#20010;&#33218;&#65292;&#25105;&#20204;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#26469;&#25214;&#21040;&#20855;&#26377;&#26368;&#39640;&#26399;&#26395;&#22870;&#21169;&#30340;&#26368;&#20339;&#33218;&#12290; Kaufmann&#31561;&#20154;&#65288;2016&#24180;&#65289;&#20026;&#35823;&#35782;&#21035;&#26368;&#20339;&#33218;&#30340;&#27010;&#29575;&#25552;&#20986;&#20102;&#19968;&#20010;&#19979;&#30028;&#12290; &#20182;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31574;&#30053;&#65292;&#20551;&#35774;&#22870;&#21169;&#30340;&#26041;&#24046;&#24050;&#30693;&#65292;&#24182;&#34920;&#26126;&#38543;&#30528;&#39044;&#31639;&#26080;&#38480;&#25509;&#36817;&#65292;&#36825;&#31181;&#31574;&#30053;&#22312;&#27010;&#24565;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#21363;&#20854;&#35823;&#35782;&#21035;&#27010;&#29575;&#19982;&#19979;&#30028;&#21305;&#37197;&#12290; &#20294;&#26159;&#65292;&#24403;&#26041;&#24046;&#26410;&#30693;&#26102;&#65292;&#19968;&#31181;&#28176;&#36817;&#20248;&#30340;&#31574;&#30053;&#23578;&#26410;&#34987;&#21457;&#29616;&#12290; &#38024;&#23545;&#36825;&#20010;&#26410;&#35299;&#20915;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#33258;&#36866;&#24212;&#23454;&#39564;&#20013;&#20272;&#35745;&#26041;&#24046;&#24182;&#20197;&#20272;&#35745;&#26631;&#20934;&#24046;&#27604;&#20363;&#25277;&#21462;&#33218;&#30340;&#31574;&#30053;&#12290; &#25105;&#20204;&#31216;&#27492;&#31574;&#30053;&#20026;Neyman&#20998;&#37197;&#65288;NA&#65289;-&#22686;&#24378;&#20498;&#27010;&#29575;&#21152;&#26435;&#65288;AIPW&#65289;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.12741v2 Announce Type: replace  Abstract: We address the problem of best arm identification (BAI) with a fixed budget for two-armed Gaussian bandits. In BAI, given multiple arms, we aim to find the best arm, an arm with the highest expected reward, through an adaptive experiment. Kaufmann et al. (2016) develops a lower bound for the probability of misidentifying the best arm. They also propose a strategy, assuming that the variances of rewards are known, and show that it is asymptotically optimal in the sense that its probability of misidentification matches the lower bound as the budget approaches infinity. However, an asymptotically optimal strategy is unknown when the variances are unknown. For this open issue, we propose a strategy that estimates variances during an adaptive experiment and draws arms with a ratio of the estimated standard deviations. We refer to this strategy as the Neyman Allocation (NA)-Augmented Inverse Probability weighting (AIPW) strategy. We then d
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30693;&#35782;&#33976;&#39311;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;SpanishTinyRoBERTa&#65292;&#19968;&#20010;&#22522;&#20110;RoBERTa&#30340;&#35199;&#29677;&#29273;&#35821;&#21387;&#32553;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#25552;&#39640;&#35199;&#29677;&#29273;&#35821;&#38382;&#31572;&#30340;&#25928;&#29575;&#12290;</title><link>https://arxiv.org/abs/2312.04193</link><description>&lt;p&gt;
&#35199;&#29677;&#29273;&#35821;&#38382;&#31572;&#20013;&#30340;&#35821;&#35328;&#27169;&#22411;&#30693;&#35782;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Language Model Knowledge Distillation for Efficient Question Answering in Spanish
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.04193
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30693;&#35782;&#33976;&#39311;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;SpanishTinyRoBERTa&#65292;&#19968;&#20010;&#22522;&#20110;RoBERTa&#30340;&#35199;&#29677;&#29273;&#35821;&#21387;&#32553;&#35821;&#35328;&#27169;&#22411;&#65292;&#29992;&#20110;&#25552;&#39640;&#35199;&#29677;&#29273;&#35821;&#38382;&#31572;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#21457;&#23637;&#30340;&#39044;&#35757;&#32451;&#35199;&#29677;&#29273;&#35821;&#35328;&#27169;&#22411;&#30340;&#36827;&#23637;&#22312;&#35768;&#22810;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;(NLP)&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#22914;&#38382;&#31572;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#39640;&#25928;&#27169;&#22411;&#23545;&#36825;&#20123;&#27169;&#22411;&#22312;&#36164;&#28304;&#21463;&#38480;&#29615;&#22659;&#20013;&#30340;&#37319;&#29992;&#26500;&#25104;&#20102;&#19968;&#36947;&#38556;&#30861;&#12290;&#22240;&#27492;&#65292;&#38024;&#23545;&#35199;&#29677;&#29273;&#35821;&#30340;&#36739;&#23567;&#30340;&#33976;&#39311;&#27169;&#22411;&#21487;&#33021;&#34987;&#35777;&#26126;&#26159;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#65292;&#24182;&#20419;&#36827;&#23427;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#21644;&#22330;&#26223;&#20013;&#30340;&#36827;&#19968;&#27493;&#37319;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26397;&#30528;&#36825;&#20010;&#26041;&#21521;&#36808;&#20986;&#20102;&#19968;&#27493;&#65292;&#36890;&#36807;&#24320;&#21457;&#22522;&#20110;RoBERTa&#30340;&#35199;&#29677;&#29273;&#35821;&#39640;&#25928;&#38382;&#31572;&#21387;&#32553;&#35821;&#35328;&#27169;&#22411;SpanishTinyRoBERTa&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#20174;&#19968;&#20010;&#22823;&#27169;&#22411;&#21521;&#19968;&#20010;&#26356;&#36731;&#30340;&#27169;&#22411;&#36827;&#34892;&#30693;&#35782;&#33976;&#39311;&#65292;&#36825;&#20351;&#24471;&#26356;&#24191;&#27867;&#30340;&#23454;&#29616;&#25104;&#20026;&#21487;&#33021;&#65292;&#21363;&#20351;&#22312;&#35745;&#31639;&#36164;&#28304;&#26377;&#38480;&#30340;&#22320;&#21306;&#65292;&#20063;&#33021;&#23454;&#29616;&#21487;&#24573;&#30053;&#30340;&#24615;&#33021;&#29306;&#29298;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#23494;&#38598;&#30340;&#33976;&#39311;&#27169;&#22411;&#33021;&#22815;&#23454;&#29616;&#38480;&#21046;&#30340;&#35745;&#31639;&#24615;&#33021;&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.04193v2 Announce Type: replace  Abstract: Recent advances in the development of pre-trained Spanish language models has led to significant progress in many Natural Language Processing (NLP) tasks, such as question answering. However, the lack of efficient models imposes a barrier for the adoption of such models in resource-constrained environments. Therefore, smaller distilled models for the Spanish language could be proven to be highly scalable and facilitate their further adoption on a variety of tasks and scenarios. In this work, we take one step in this direction by developing SpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient question answering in Spanish. To achieve this, we employ knowledge distillation from a large model onto a lighter model that allows for a wider implementation, even in areas with limited computational resources, whilst attaining negligible performance sacrifice. Our experiments show that the dense distilled model can st
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#22810;&#39033;&#24335;&#35745;&#25968;&#25968;&#25454;&#30340;&#20998;&#26512;&#38656;&#27714;&#65292;&#24182;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#23436;&#20840;&#33258;&#21160;&#25552;&#21462;&#20986;&#29983;&#29289;&#24847;&#20041;&#30340;&#20803;&#31614;&#21517;&#12290;</title><link>https://arxiv.org/abs/2311.16909</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#20449;&#24565;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Multinomial belief networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16909
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#22810;&#39033;&#24335;&#35745;&#25968;&#25968;&#25454;&#30340;&#20998;&#26512;&#38656;&#27714;&#65292;&#24182;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#23436;&#20840;&#33258;&#21160;&#25552;&#21462;&#20986;&#29983;&#29289;&#24847;&#20041;&#30340;&#20803;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#38656;&#35201;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12289;&#22788;&#29702;&#32570;&#22833;&#35266;&#27979;&#12289;&#26679;&#26412;&#31232;&#32570;&#25110;&#25968;&#25454;&#31232;&#30095;&#26102;&#26159;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#20123;&#20998;&#26512;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#39033;&#24335;&#35745;&#25968;&#25968;&#25454;&#30340;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#32593;&#32476;&#30340;&#26435;&#37325;&#21644;&#38544;&#34255;&#21333;&#20803;&#22343;&#26381;&#20174;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#21033;&#29992;&#19968;&#31995;&#21015;&#22686;&#24191;&#20851;&#31995;&#30340;&#21513;&#24067;&#26031;&#25277;&#26679;&#36807;&#31243;&#65292;&#31867;&#20284;&#20110;&#21608;-&#19995;-&#38472;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#24212;&#29992;&#20110;&#23567;&#35268;&#27169;&#25163;&#20889;&#25968;&#23383;&#21644;&#19968;&#20010;&#22823;&#22411;&#30340;DNA&#31361;&#21464;&#30284;&#30151;&#23454;&#39564;&#25968;&#25454;&#38598;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#27169;&#22411;&#22914;&#20309;&#33021;&#22815;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#22320;&#25552;&#21462;&#20986;&#29983;&#29289;&#24847;&#20041;&#30340;&#20803;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.16909v2 Announce Type: replace-cross  Abstract: A Bayesian approach to machine learning is attractive when we need to quantify uncertainty, deal with missing observations, when samples are scarce, or when the data is sparse. All of these commonly apply when analysing healthcare data. To address these analytical requirements, we propose a deep generative model for multinomial count data where both the weights and hidden units of the network are Dirichlet distributed. A Gibbs sampling procedure is formulated that takes advantage of a series of augmentation relations, analogous to the Zhou--Cong--Chen model. We apply the model on small handwritten digits, and a large experimental dataset of DNA mutations in cancer, and we show how the model is able to extract biologically meaningful meta-signatures in a fully data-driven way.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#23454;&#29616;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#12290;</title><link>https://arxiv.org/abs/2311.15487</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15487
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#23454;&#29616;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#29992;&#20110;&#26368;&#23567;&#21270;$\mathcal{L}^2$&#20195;&#20215;&#20989;&#25968;&#30340;&#26799;&#24230;&#19979;&#38477;&#27969;&#65292;&#24182;&#24341;&#20837;&#20004;&#20010;&#25913;&#36827;&#29256;&#26412;&#65307;&#19968;&#20010;&#36866;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#21478;&#19968;&#20010;&#36866;&#29992;&#20110;&#27424;&#21442;&#25968;&#21270;&#35774;&#32622;&#12290;&#36825;&#20004;&#20010;&#29256;&#26412;&#37117;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#65292;&#32771;&#34385;&#21040;&#22312;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#30340;&#25289;&#22238;&#21521;&#37327;&#19995;&#32467;&#26500;&#21644;&#22312;&#27424;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#30340;&#25512;&#21069;&#21521;&#37327;&#19995;&#32467;&#26500;&#12290;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#28385;&#36275;&#31209;&#26465;&#20214;&#65292;&#25913;&#36827;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25152;&#26377;&#36712;&#36947;&#23558;&#20197;&#22343;&#21248;&#25351;&#25968;&#25910;&#25947;&#36895;&#29575;&#23558;$\mathcal{L}^2$&#20195;&#20215;&#39537;&#21160;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65307;&#22240;&#27492;&#65292;&#23545;&#20110;&#20219;&#20309;&#39044;&#20808;&#25351;&#23450;&#30340;&#25509;&#36817;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#21040;&#20808;&#39564;&#20572;&#27490;&#26102;&#38388;&#12290;&#25105;&#20204;&#25351;&#20986;&#21518;&#32773;&#19982;&#27425;Riemann&#20960;&#20309;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15487v3 Announce Type: replace-cross  Abstract: We consider the gradient descent flow widely used for the minimization of the $\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two modified versions; one adapted for the overparametrized setting, and the other for the underparametrized setting. Both have a clear and natural invariant geometric meaning, taking into account the pullback vector bundle structure in the overparametrized, and the pushforward vector bundle structure in the underparametrized setting. In the overparametrized case, we prove that, provided that a rank condition holds, all orbits of the modified gradient descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform exponential convergence rate; one thereby obtains an a priori stopping time for any prescribed proximity to the global minimum. We point out relations of the latter to sub-Riemannian geometry.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Copula&#30340;&#26032;&#26694;&#26550;&#65292;&#21033;&#29992;&#19981;&#21516;&#20154;&#21475;&#26679;&#26412;&#20197;&#21450;&#30456;&#20284;&#36793;&#38469;&#20381;&#36182;&#24615;&#65292;&#24341;&#20837;&#31354;&#38388;&#32452;&#20214;&#24182;&#32771;&#34385;&#22810;&#31181;&#20449;&#24687;&#28304;&#65292;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#20294;&#29616;&#23454;&#30340;&#30446;&#26631;&#20154;&#21475;&#34920;&#31034;&#12290;</title><link>https://arxiv.org/abs/2302.09193</link><description>&lt;p&gt;
&#22522;&#20110;Copula&#30340;&#21487;&#36716;&#31227;&#27169;&#22411;&#29992;&#20110;&#21512;&#25104;&#20154;&#21475;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Copula-based transferable models for synthetic population generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.09193
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Copula&#30340;&#26032;&#26694;&#26550;&#65292;&#21033;&#29992;&#19981;&#21516;&#20154;&#21475;&#26679;&#26412;&#20197;&#21450;&#30456;&#20284;&#36793;&#38469;&#20381;&#36182;&#24615;&#65292;&#24341;&#20837;&#31354;&#38388;&#32452;&#20214;&#24182;&#32771;&#34385;&#22810;&#31181;&#20449;&#24687;&#28304;&#65292;&#29992;&#20110;&#29983;&#25104;&#21512;&#25104;&#20294;&#29616;&#23454;&#30340;&#30446;&#26631;&#20154;&#21475;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#21475;&#32508;&#21512;&#28041;&#21450;&#29983;&#25104;&#24494;&#35266;&#20195;&#29702;&#30446;&#26631;&#20154;&#21475;&#30340;&#21512;&#25104;&#20294;&#29616;&#23454;&#30340;&#34920;&#31034;&#65292;&#29992;&#20110;&#34892;&#20026;&#24314;&#27169;&#21644;&#27169;&#25311;&#12290; &#20256;&#32479;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#30446;&#26631;&#20154;&#21475;&#26679;&#26412;&#65292;&#22914;&#20154;&#21475;&#26222;&#26597;&#25968;&#25454;&#25110;&#26053;&#34892;&#35843;&#26597;&#65292;&#30001;&#20110;&#39640;&#25104;&#26412;&#21644;&#36739;&#23567;&#30340;&#26679;&#26412;&#37327;&#65292;&#22312;&#36739;&#23567;&#30340;&#22320;&#29702;&#23610;&#24230;&#19978;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Copula&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#20026;&#20165;&#24050;&#30693;&#32463;&#39564;&#36793;&#38469;&#20998;&#24067;&#30340;&#30446;&#26631;&#20154;&#21475;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290; &#35813;&#26041;&#27861;&#21033;&#29992;&#26469;&#33258;&#20855;&#26377;&#30456;&#20284;&#36793;&#38469;&#20381;&#36182;&#24615;&#30340;&#19981;&#21516;&#20154;&#21475;&#30340;&#26679;&#26412;&#65292;&#23558;&#31354;&#38388;&#32452;&#20214;&#24341;&#20837;&#21040;&#20154;&#21475;&#32508;&#21512;&#20013;&#65292;&#24182;&#32771;&#34385;&#21508;&#31181;&#20449;&#24687;&#28304;&#29992;&#20110;&#26356;&#30495;&#23454;&#30340;&#29983;&#25104;&#22120;&#12290; &#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#36807;&#31243;&#28041;&#21450;&#23558;&#25968;&#25454;&#26631;&#20934;&#21270;&#24182;&#23558;&#20854;&#35270;&#20026;&#32473;&#23450;Copula&#30340;&#23454;&#29616;&#65292;&#28982;&#21518;&#22312;&#34701;&#20837;&#20851;&#20110;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.09193v2 Announce Type: replace-cross  Abstract: Population synthesis involves generating synthetic yet realistic representations of a target population of micro-agents for behavioral modeling and simulation. Traditional methods, often reliant on target population samples, such as census data or travel surveys, face limitations due to high costs and small sample sizes, particularly at smaller geographical scales. We propose a novel framework based on copulas to generate synthetic data for target populations where only empirical marginal distributions are known. This method utilizes samples from different populations with similar marginal dependencies, introduces a spatial component into population synthesis, and considers various information sources for more realistic generators. Concretely, the process involves normalizing the data and treat it as realizations of a given copula, and then training a generative model before incorporating the information on the marginals of the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#26088;&#22312;&#36229;&#36234;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#65292;&#37325;&#26032;&#23457;&#35270;&#23545;&#39640;&#32500;&#25968;&#25454;&#36827;&#34892;&#23725;&#22238;&#24402;&#65292;&#20801;&#35768;&#29305;&#24449;&#21521;&#37327;&#26159;&#39640;&#32500;&#29978;&#33267;&#26080;&#38480;&#32500;&#30340;&#65292;&#20026;&#32479;&#35745;&#23398;&#20013;&#30340;&#33258;&#28982;&#35774;&#32622;&#25552;&#20379;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>https://arxiv.org/abs/2210.08571</link><description>&lt;p&gt;
&#26080;&#32500;&#24230;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Dimension free ridge regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.08571
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#26088;&#22312;&#36229;&#36234;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#65292;&#37325;&#26032;&#23457;&#35270;&#23545;&#39640;&#32500;&#25968;&#25454;&#36827;&#34892;&#23725;&#22238;&#24402;&#65292;&#20801;&#35768;&#29305;&#24449;&#21521;&#37327;&#26159;&#39640;&#32500;&#29978;&#33267;&#26080;&#38480;&#32500;&#30340;&#65292;&#20026;&#32479;&#35745;&#23398;&#20013;&#30340;&#33258;&#28982;&#35774;&#32622;&#25552;&#20379;&#20102;&#26032;&#30340;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24050;&#25104;&#20026;&#39640;&#32500;&#32479;&#35745;&#23398;&#21644;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#20013;&#38750;&#24120;&#26377;&#29992;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#20027;&#35201;&#38598;&#20013;&#22312;&#27604;&#20363;&#28176;&#36817;&#24773;&#20917;&#19979;&#65292;&#20854;&#20013;&#21015;&#25968;&#19982;&#25968;&#25454;&#30697;&#38453;&#30340;&#34892;&#25968;&#25104;&#27604;&#20363;&#22686;&#38271;&#12290;&#36825;&#22312;&#32479;&#35745;&#23398;&#20013;&#24182;&#19981;&#24635;&#26159;&#26368;&#33258;&#28982;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#21015;&#23545;&#24212;&#21327;&#21464;&#37327;&#65292;&#34892;&#23545;&#24212;&#26679;&#26412;&#12290;&#20026;&#20102;&#36229;&#36234;&#27604;&#20363;&#28176;&#36817;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#23545;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;$(x_i, y_i)$&#65292;$i\le n$&#36827;&#34892;&#23725;&#22238;&#24402;&#65288;$\ell_2$-&#24809;&#32602;&#26368;&#23567;&#20108;&#20056;&#65289;&#65292;&#20854;&#20013;$x_i$&#20026;&#29305;&#24449;&#21521;&#37327;&#65292;$y_i = \beta^\top x_i +\epsilon_i \in\mathbb{R}$&#20026;&#21709;&#24212;&#12290;&#25105;&#20204;&#20801;&#35768;&#29305;&#24449;&#21521;&#37327;&#26159;&#39640;&#32500;&#30340;&#65292;&#29978;&#33267;&#26159;&#26080;&#38480;&#32500;&#30340;&#65292;&#27492;&#26102;&#23427;&#23646;&#20110;&#21487;&#20998;Hilbert&#31354;&#38388;&#65292;&#24182;&#19988;&#20551;&#35774;$z_i := \Sigma^{-1/2}x_i$&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26465;&#30446;&#65292;&#25110;&#32773;&#28385;&#36275;&#26576;&#31181;&#20984;&#38598;&#20013;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.08571v2 Announce Type: replace-cross  Abstract: Random matrix theory has become a widely useful tool in high-dimensional statistics and theoretical machine learning. However, random matrix theory is largely focused on the proportional asymptotics in which the number of columns grows proportionally to the number of rows of the data matrix. This is not always the most natural setting in statistics where columns correspond to covariates and rows to samples. With the objective to move beyond the proportional asymptotics, we revisit ridge regression ($\ell_2$-penalized least squares) on i.i.d. data $(x_i, y_i)$, $i\le n$, where $x_i$ is a feature vector and $y_i = \beta^\top x_i +\epsilon_i \in\mathbb{R}$ is a response. We allow the feature vector to be high-dimensional, or even infinite-dimensional, in which case it belongs to a separable Hilbert space, and assume either $z_i := \Sigma^{-1/2}x_i$ to have i.i.d. entries, or to satisfy a certain convex concentration property. With
&lt;/p&gt;</description></item><item><title>&#35813;&#32508;&#36848;&#22238;&#39038;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#21033;&#29992;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#20027;&#39064;&#65292;&#20026;&#35780;&#20272;&#27010;&#29575;&#39044;&#27979;&#25552;&#20379;&#20102;&#30456;&#20851;&#24230;&#37327;&#65292;&#20174;&#32463;&#20856;&#32479;&#35745;&#26041;&#27861;&#21040;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26803;&#29702;&#12290;</title><link>https://arxiv.org/abs/2209.08307</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A review of predictive uncertainty estimation with machine learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.08307
&lt;/p&gt;
&lt;p&gt;
&#35813;&#32508;&#36848;&#22238;&#39038;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#21033;&#29992;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#20027;&#39064;&#65292;&#20026;&#35780;&#20272;&#27010;&#29575;&#39044;&#27979;&#25552;&#20379;&#20102;&#30456;&#20851;&#24230;&#37327;&#65292;&#20174;&#32463;&#20856;&#32479;&#35745;&#26041;&#27861;&#21040;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26803;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#24212;&#24403;&#20197;&#27010;&#29575;&#20998;&#24067;&#30340;&#24418;&#24335;&#21576;&#29616;&#65292;&#26088;&#22312;&#22686;&#21152;&#21521;&#26368;&#32456;&#29992;&#25143;&#20256;&#36798;&#30340;&#20449;&#24687;&#37327;&#12290;&#23613;&#31649;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#20013;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#27010;&#29575;&#39044;&#27979;&#21644;&#39044;&#27979;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#39057;&#32321;&#65292;&#20294;&#30456;&#20851;&#27010;&#24565;&#21644;&#26041;&#27861;&#23578;&#26410;&#22312;&#25972;&#20010;&#39046;&#22495;&#30340;&#25972;&#20307;&#35270;&#35282;&#19979;&#24471;&#21040;&#24418;&#24335;&#21270;&#21644;&#32467;&#26500;&#21270;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#20027;&#39064;&#65292;&#20197;&#21450;&#29992;&#20110;&#35780;&#20272;&#27010;&#29575;&#39044;&#27979;&#30340;&#30456;&#20851;&#24230;&#37327;&#65288;&#19968;&#33268;&#35780;&#20998;&#20989;&#25968;&#21644;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#65289;&#12290;&#35813;&#32508;&#36848;&#28085;&#30422;&#20102;&#20174;&#26089;&#26399;&#32479;&#35745;&#24341;&#20837;&#65288;&#22522;&#20110;&#36125;&#21494;&#26031;&#32479;&#35745;&#25110;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#32447;&#24615;&#22238;&#24402;&#21644;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65289;&#21040;&#26368;&#36817;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65288;&#21253;&#25324;&#29992;&#20110;&#20301;&#32622;&#12289;&#35268;&#27169;&#30340;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65289;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.08307v2 Announce Type: replace-cross  Abstract: Predictions and forecasts of machine learning models should take the form of probability distributions, aiming to increase the quantity of information communicated to end users. Although applications of probabilistic prediction and forecasting with machine learning models in academia and industry are becoming more frequent, related concepts and methods have not been formalized and structured under a holistic view of the entire field. Here, we review the topic of predictive uncertainty estimation with machine learning algorithms, as well as the related metrics (consistent scoring functions and proper scoring rules) for assessing probabilistic predictions. The review covers a time period spanning from the introduction of early statistical (linear regression and time series models, based on Bayesian statistics or quantile regression) to recent machine learning algorithms (including generalized additive models for location, scale a
&lt;/p&gt;</description></item><item><title>&#20998;&#26512;log-cosh&#25439;&#22833;&#20989;&#25968;&#30340;&#32479;&#35745;&#29305;&#24615;&#65292;&#27604;&#36739;&#23427;&#19982;&#26607;&#35199;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;MLE&#30340;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19982;&#20854;&#20182;&#25439;&#22833;&#20989;&#25968;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#27604;&#36739;&#12290;</title><link>https://arxiv.org/abs/2208.04564</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;&#30340;log-cosh&#25439;&#22833;&#20989;&#25968;&#30340;&#32479;&#35745;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Properties of the log-cosh Loss Function Used in Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.04564
&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;log-cosh&#25439;&#22833;&#20989;&#25968;&#30340;&#32479;&#35745;&#29305;&#24615;&#65292;&#27604;&#36739;&#23427;&#19982;&#26607;&#35199;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#24182;&#30740;&#31350;MLE&#30340;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#32622;&#20449;&#21306;&#38388;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19982;&#20854;&#20182;&#25439;&#22833;&#20989;&#25968;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20998;&#26512;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;&#30340;&#19968;&#31181;&#24120;&#35265;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;log-cosh&#25439;&#22833;&#20989;&#25968;&#12290;&#24050;&#32463;&#21457;&#34920;&#20102;&#35768;&#22810;&#20351;&#29992;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#35770;&#25991;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;&#25991;&#29486;&#20013;&#23578;&#26410;&#25552;&#20986;&#36807;&#32479;&#35745;&#20998;&#26512;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;log-cosh&#25439;&#22833;&#20989;&#25968;&#20135;&#29983;&#30340;&#20998;&#24067;&#20989;&#25968;&#12290;&#25105;&#20204;&#23558;&#20854;&#19982;&#31867;&#20284;&#30340;&#26607;&#35199;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#36827;&#34892;&#22810;&#31181;&#34920;&#24449;&#20854;&#29305;&#24615;&#30340;&#32479;&#35745;&#31243;&#24207;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26816;&#39564;&#20102;&#19982;&#20854;&#30456;&#20851;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12289;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#12289;&#20284;&#28982;&#20989;&#25968;&#21644;&#36153;&#33293;&#23572;&#20449;&#24687;&#12290;&#25105;&#20204;&#23558;&#26607;&#35199;&#21644;Cosh&#20998;&#24067;&#20197;&#21450;MLE&#30340;&#20301;&#32622;&#21442;&#25968;&#30340;&#28176;&#36817;&#20559;&#24046;&#12289;&#28176;&#36817;&#26041;&#24046;&#21644;&#32622;&#20449;&#21306;&#38388;&#36827;&#34892;&#24182;&#21015;&#32771;&#34385;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26469;&#33258;&#20854;&#20182;&#20960;&#31181;&#25439;&#22833;&#20989;&#25968;&#30340;&#40065;&#26834;&#20272;&#35745;&#22120;&#30340;&#27604;&#36739;&#65292;&#21253;&#25324;Huber&#25439;&#22833;&#20989;&#25968;&#21644;&#31209;&#20998;&#25955;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#35813;&#25439;&#22833;&#20989;&#25968;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2208.04564v4 Announce Type: replace-cross  Abstract: This paper analyzes a popular loss function used in machine learning called the log-cosh loss function. A number of papers have been published using this loss function but, to date, no statistical analysis has been presented in the literature. In this paper, we present the distribution function from which the log-cosh loss arises. We compare it to a similar distribution, called the Cauchy distribution, and carry out various statistical procedures that characterize its properties. In particular, we examine its associated pdf, cdf, likelihood function and Fisher information. Side-by-side we consider the Cauchy and Cosh distributions as well as the MLE of the location parameter with asymptotic bias, asymptotic variance, and confidence intervals. We also provide a comparison of robust estimators from several other loss functions, including the Huber loss function and the rank dispersion function. Further, we examine the use of the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#35782;&#21035;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#21442;&#25968;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2203.06056</link><description>&lt;p&gt;
&#20351;&#29992;&#24037;&#20855;&#26102;&#38388;&#24207;&#21015;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#65306;&#26080;&#20851; IV &#21644;&#32416;&#27491;&#21382;&#21490;
&lt;/p&gt;
&lt;p&gt;
Identifying Causal Effects using Instrumental Time Series: Nuisance IV and Correcting for the Past
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.06056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#30340;&#22256;&#38590;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#35782;&#21035;&#26041;&#31243;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#30340;&#19968;&#33268;&#24615;&#21442;&#25968;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20202;&#22120;&#21464;&#37327;&#65288;IV&#65289;&#22238;&#24402;&#20381;&#36182;&#20110;&#24037;&#20855;&#26469;&#25512;&#26029;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25928;&#24212;&#65292;&#20854;&#20013;&#23384;&#22312;&#26410;&#35266;&#27979;&#30340;&#28151;&#28102;&#22240;&#32032;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#36827;&#34892; IV &#22238;&#24402;&#65292;&#20363;&#22914;&#30690;&#37327;&#33258;&#22238;&#24402;&#65288;VAR&#65289;&#36807;&#31243;&#12290;&#30452;&#25509;&#24212;&#29992;&#29420;&#31435;&#21516;&#20998;&#24067;&#25216;&#26415;&#36890;&#24120;&#19981;&#19968;&#33268;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#33021;&#27491;&#30830;&#35843;&#25972;&#36807;&#21435;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#26412;&#25991;&#27010;&#36848;&#20102;&#30001;&#20110;&#26102;&#38388;&#32467;&#26500;&#32780;&#24341;&#36215;&#30340;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#26500;&#24314;&#21487;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#22240;&#26524;&#25928;&#24212;&#19968;&#33268;&#21442;&#25968;&#20272;&#35745;&#30340;&#30830;&#35748;&#26041;&#31243;&#30340;&#26041;&#27861;&#12290;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#39069;&#22806;&#30340;&#26080;&#20851;&#21327;&#21464;&#37327;&#26469;&#33719;&#24471;&#21487;&#35782;&#21035;&#24615;&#65288;&#21363;&#20351;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#24773;&#20917;&#19979;&#20063;&#26159;&#26377;&#36259;&#30340;&#24819;&#27861;&#65289;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#22270;&#36793;&#32536;&#21270;&#26694;&#26550;&#65292;&#20801;&#35768;&#25105;&#20204;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#23545;&#26102;&#38388;&#24207;&#21015;&#24212;&#29992;&#26080;&#20851; IV &#21644;&#20854;&#20182; IV &#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20840;&#23616;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#30340;&#19968;&#20010;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.06056v2 Announce Type: replace-cross  Abstract: Instrumental variable (IV) regression relies on instruments to infer causal effects from observational data with unobserved confounding. We consider IV regression in time series models, such as vector auto-regressive (VAR) processes. Direct applications of i.i.d. techniques are generally inconsistent as they do not correctly adjust for dependencies in the past. In this paper, we outline the difficulties that arise due to time structure and propose methodology for constructing identifying equations that can be used for consistent parametric estimation of causal effects in time series data. One method uses extra nuisance covariates to obtain identifiability (an idea that can be of interest even in the i.i.d. case). We further propose a graph marginalization framework that allows us to apply nuisance IV and other IV methods in a principled way to time series. Our methods make use of a version of the global Markov property, which w
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#22312;&#24066;&#22330;&#24494;&#35266;&#32467;&#26500;&#22122;&#22768;&#19979;&#23398;&#20064;&#27874;&#21160;&#29575;&#30340;&#38382;&#39064;&#65292;&#37319;&#29992;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#21069;&#30740;&#31350;&#27874;&#21160;&#29575;&#20989;&#25968;&#21644;&#37319;&#29992;&#21069;&#21521;&#28388;&#27874;&#21518;&#21521;&#27169;&#25311;&#31639;&#27861;&#31561;&#26032;&#39062;&#35745;&#31639;&#26041;&#27861;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;EUR/USD&#27719;&#29575;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>https://arxiv.org/abs/1805.05606</link><description>&lt;p&gt;
&#22312;&#24494;&#35266;&#32467;&#26500;&#22122;&#22768;&#19979;&#30340;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#27874;&#21160;&#29575;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Bayesian volatility learning under microstructure noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1805.05606
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#22312;&#24066;&#22330;&#24494;&#35266;&#32467;&#26500;&#22122;&#22768;&#19979;&#23398;&#20064;&#27874;&#21160;&#29575;&#30340;&#38382;&#39064;&#65292;&#37319;&#29992;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#36890;&#36807;&#20808;&#21069;&#30740;&#31350;&#27874;&#21160;&#29575;&#20989;&#25968;&#21644;&#37319;&#29992;&#21069;&#21521;&#28388;&#27874;&#21518;&#21521;&#27169;&#25311;&#31639;&#27861;&#31561;&#26032;&#39062;&#35745;&#31639;&#26041;&#27861;&#65292;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;EUR/USD&#27719;&#29575;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24066;&#22330;&#24494;&#35266;&#32467;&#26500;&#22122;&#22768;&#19979;&#23398;&#20064;&#27874;&#21160;&#29575;&#30340;&#38382;&#39064;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#33719;&#24471;&#30340;&#24102;&#26377;&#22122;&#22768;&#30340;&#31163;&#25955;&#26102;&#38388;&#35266;&#27979;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35745;&#31639;&#26041;&#27861;&#26469;&#23398;&#20064;&#35813;&#26041;&#31243;&#30340;&#25193;&#25955;&#31995;&#25968;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#38750;&#21442;&#25968;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#20854;&#20013;&#25105;&#20204;\emph{a priori}&#23558;&#27874;&#21160;&#29575;&#20989;&#25968;&#24314;&#27169;&#20026;&#20998;&#27573;&#24120;&#25968;&#12290;&#20854;&#20808;&#39564;&#36890;&#36807;&#36870;Gamma&#39532;&#23572;&#21487;&#22827;&#38142;&#26469;&#25351;&#23450;&#12290;&#36890;&#36807;&#23558;&#21069;&#21521;&#28388;&#27874;&#21518;&#21521;&#27169;&#25311;&#31639;&#27861;&#32435;&#20837;Gibbs&#37319;&#26679;&#22120;&#20013;&#26469;&#23545;&#21518;&#39564;&#36827;&#34892;&#25277;&#26679;&#12290;&#35813;&#26041;&#27861;&#22312;&#20004;&#20010;&#20195;&#34920;&#24615;&#30340;&#21512;&#25104;&#25968;&#25454;&#31034;&#20363;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#36824;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;EUR/USD&#27719;&#29575;&#25968;&#25454;&#38598;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#32473;&#20986;&#20808;&#39564;&#20998;&#24067;&#30340;&#26497;&#38480;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1805.05606v2 Announce Type: replace-cross  Abstract: In this work, we study the problem of learning the volatility under market microstructure noise. Specifically, we consider noisy discrete time observations from a stochastic differential equation and develop a novel computational method to learn the diffusion coefficient of the equation. We take a nonparametric Bayesian approach, where we \emph{a priori} model the volatility function as piecewise constant. Its prior is specified via the inverse Gamma Markov chain. Sampling from the posterior is accomplished by incorporating the Forward Filtering Backward Simulation algorithm in the Gibbs sampler. Good performance of the method is demonstrated on two representative synthetic data examples. We also apply the method on a EUR/USD exchange rate dataset. Finally we present a limit result on the prior distribution.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28145;&#23618;&#20998;&#23618;&#20998;&#35299;&#30340;&#26550;&#26500;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#23398;&#20064;&#22823;&#22411;&#22270;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22823;&#22411;&#31038;&#20132;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#23567;&#22411;&#21270;&#23398;&#29983;&#29289;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;</title><link>https://arxiv.org/abs/1703.05537</link><description>&lt;p&gt;
&#31227;&#21160;&#32858;&#21512;&#25552;&#21462;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Shift Aggregate Extract Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1703.05537
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28145;&#23618;&#20998;&#23618;&#20998;&#35299;&#30340;&#26550;&#26500;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#23398;&#20064;&#22823;&#22411;&#22270;&#34920;&#31034;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22823;&#22411;&#31038;&#20132;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#32988;&#36807;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#23567;&#22411;&#21270;&#23398;&#29983;&#29289;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#23618;&#20998;&#23618;&#20998;&#35299;&#30340;&#26550;&#26500;&#65292;&#29992;&#20110;&#23398;&#20064;&#22823;&#22411;&#22270;&#30340;&#26377;&#25928;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#25193;&#23637;&#20102;&#22312;&#26680;&#26041;&#27861;&#20013;&#20351;&#29992;&#30340;&#32463;&#20856;R-&#20998;&#35299;&#65292;&#23454;&#29616;&#20102;&#23884;&#22871;&#30340;&#37096;&#20998;-&#37096;&#20998;&#20851;&#31995;&#12290;&#19982;&#30452;&#25509;&#22312;&#36755;&#20837;&#22270;&#19978;&#23637;&#24320;&#27169;&#26495;&#30340;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#19981;&#21516;&#65292;&#25105;&#20204;&#22312;&#20998;&#35299;&#23618;&#27425;&#32467;&#26500;&#19978;&#23637;&#24320;&#31070;&#32463;&#32593;&#32476;&#27169;&#26495;&#65292;&#20174;&#32780;&#33021;&#22815;&#22788;&#29702;&#36890;&#24120;&#34920;&#24449;&#31038;&#20132;&#32593;&#32476;&#22270;&#30340;&#39640;&#24230;&#21464;&#21270;&#12290;&#28145;&#23618;&#27425;&#30340;&#20998;&#23618;&#20998;&#35299;&#20063;&#36866;&#29992;&#20110;&#39046;&#22495;&#21387;&#32553;&#65292;&#36825;&#31181;&#25216;&#26415;&#36890;&#36807;&#21033;&#29992;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#31354;&#38388;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#23454;&#35777;&#19978;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#22411;&#31038;&#20132;&#32593;&#32476;&#25968;&#25454;&#38598;&#19978;&#33021;&#22815;&#32988;&#36807;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22270;&#20998;&#31867;&#26041;&#27861;&#65292;&#21516;&#26102;&#22312;&#23567;&#22411;&#21270;&#23398;&#29983;&#29289;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1703.05537v2 Announce Type: replace  Abstract: We introduce an architecture based on deep hierarchical decompositions to learn effective representations of large graphs. Our framework extends classic R-decompositions used in kernel methods, enabling nested part-of-part relations. Unlike recursive neural networks, which unroll a template on input graphs directly, we unroll a neural network template over the decomposition hierarchy, allowing us to deal with the high degree variability that typically characterize social network graphs. Deep hierarchical decompositions are also amenable to domain compression, a technique that reduces both space and time complexity by exploiting symmetries. We show empirically that our approach is able to outperform current state-of-the-art graph classification methods on large social network datasets, while at the same time being competitive on small chemobiological benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2401.14591</link><description>&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#26102;&#21464;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Ricci flow-guided autoencoders in learning time-dependent dynamics. (arXiv:2401.14591v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14591
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;Ricci&#27969;&#24341;&#23548;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#33021;&#22815;&#23398;&#20064;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#35757;&#32451;&#20013;&#23398;&#20064;&#27969;&#24418;&#65292;&#24182;&#20351;&#29992;Ricci&#27969;&#20351;&#27969;&#24418;&#28508;&#31354;&#38388;&#36880;&#27493;&#36866;&#24212;&#21160;&#21147;&#23398;&#30340;&#21464;&#21270;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#22909;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#30340;PDE&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#35780;&#20272;&#20102;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#30340;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26102;&#38388;&#19978;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#65292;&#23588;&#20854;&#26159;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#65292;&#20854;&#20013;&#27969;&#24418;&#28508;&#31354;&#38388;&#26681;&#25454;Ricci&#27969;&#21457;&#23637;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#22312;&#29289;&#29702;&#20449;&#24687;&#35774;&#32622;&#20013;&#27169;&#25311;Ricci&#27969;&#26469;&#23454;&#29616;&#65292;&#24182;&#19988;&#21487;&#20197;&#21305;&#37197;&#27969;&#24418;&#37327;&#65292;&#20197;&#20415;&#23454;&#29616;Ricci&#27969;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#27969;&#24418;&#26159;&#20316;&#20026;&#35757;&#32451;&#36807;&#31243;&#30340;&#19968;&#37096;&#20998;&#23398;&#20064;&#30340;&#65292;&#22240;&#27492;&#21487;&#20197;&#35782;&#21035;&#20986;&#29702;&#24819;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#21516;&#26102;&#28436;&#21464;&#20063;&#33021;&#22312;&#38745;&#24577;&#26041;&#27861;&#19978;&#24341;&#36215;&#26356;&#23485;&#23481;&#30340;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#20855;&#26377;&#21608;&#26399;&#24615;&#21644;&#38543;&#26426;&#24615;&#31561;&#29702;&#24819;&#29305;&#24449;&#30340;PDE&#65292;&#24182;&#22312;&#20998;&#24067;&#20869;&#21644;&#22806;&#25512;&#22330;&#26223;&#20013;&#36827;&#34892;&#35823;&#24046;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a manifold-based autoencoder method for learning nonlinear dynamics in time, notably partial differential equations (PDEs), in which the manifold latent space evolves according to Ricci flow. This can be accomplished by simulating Ricci flow in a physics-informed setting, and manifold quantities can be matched so that Ricci flow is empirically achieved. With our methodology, the manifold is learned as part of the training procedure, so ideal geometries may be discerned, while the evolution simultaneously induces a more accommodating latent representation over static methods. We present our method on a range of numerical experiments consisting of PDEs that encompass desirable characteristics such as periodicity and randomness, remarking error on in-distribution and extrapolation scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;Multi-G-UCB&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.10383</link><description>&lt;p&gt;
&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#65306;UCB&#31639;&#27861;&#21644;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis. (arXiv:2401.10383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;Multi-G-UCB&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#22810;&#26234;&#33021;&#20307;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#24314;&#27169;&#20026;Zhang&#12289;Johansson&#21644;Li&#22312;[CISS 57, 1-6 (2023)]&#20013;&#25552;&#20986;&#30340;&#22270;&#24418;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#22810;&#26234;&#33021;&#20307;&#25193;&#23637;&#12290;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;N&#20010;&#21512;&#20316;&#26234;&#33021;&#20307;&#22312;&#19968;&#20010;&#36830;&#36890;&#30340;&#22270;G&#19978;&#31227;&#21160;&#65292;&#22270;G&#26377;K&#20010;&#33410;&#28857;&#12290;&#25269;&#36798;&#27599;&#20010;&#33410;&#28857;&#26102;&#65292;&#26234;&#33021;&#20307;&#35266;&#23519;&#21040;&#20174;&#19968;&#20010;&#19982;&#33410;&#28857;&#30456;&#20851;&#30340;&#27010;&#29575;&#20998;&#24067;&#20013;&#38543;&#26426;&#25277;&#21462;&#30340;&#22870;&#21169;&#12290;&#31995;&#32479;&#22870;&#21169;&#34987;&#24314;&#27169;&#20026;&#26234;&#33021;&#20307;&#35266;&#27979;&#21040;&#30340;&#22870;&#21169;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#20013;&#26435;&#37325;&#34920;&#36798;&#20102;&#22810;&#20010;&#26234;&#33021;&#20307;&#21516;&#26102;&#23545;&#21516;&#19968;&#33410;&#28857;&#36827;&#34892;&#37319;&#26679;&#30340;&#36793;&#38469;&#20943;&#23569;&#22870;&#21169;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#19978;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;UCB&#65289;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;Multi-G-UCB&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;T&#27493;&#20869;&#20854;&#26399;&#26395;&#36951;&#25022;&#34987;&#30028;&#23450;&#20026;$O(N\log(T)[\sqrt{KT} + DK])$&#65292;&#20854;&#20013;D&#26159;&#22270;G&#30340;&#30452;&#24452;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19982;&#20854;&#20182;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#23545;&#31639;&#27861;&#36827;&#34892;&#20102;&#25968;&#20540;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we formulate the multi-agent graph bandit problem as a multi-agent extension of the graph bandit problem introduced by Zhang, Johansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative agents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each node, agents observe a random reward drawn from a node-dependent probability distribution. The reward of the system is modeled as a weighted sum of the rewards the agents observe, where the weights capture the decreasing marginal reward associated with multiple agents sampling the same node at the same time. We propose an Upper Confidence Bound (UCB)-based learning algorithm, Multi-G-UCB, and prove that its expected regret over $T$ steps is bounded by $O(N\log(T)[\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly, we numerically test our algorithm by comparing it to alternative methods.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.07961</link><description>&lt;p&gt;
&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#65306;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs. (arXiv:2401.07961v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.07961
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#23558;&#27010;&#29575;Lambert&#38382;&#39064;&#19982;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#12289;Schr\"odinger&#26725;&#21644;&#21453;&#24212;-&#25193;&#25955;&#20559;&#24494;&#20998;&#26041;&#31243;&#31561;&#39046;&#22495;&#36830;&#25509;&#36215;&#26469;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#20540;&#27714;&#35299;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Lambert&#38382;&#39064;&#28041;&#21450;&#36890;&#36807;&#36895;&#24230;&#25511;&#21046;&#22312;&#35268;&#23450;&#30340;&#39134;&#34892;&#26102;&#38388;&#20869;&#23558;&#33322;&#22825;&#22120;&#20174;&#32473;&#23450;&#30340;&#21021;&#22987;&#20301;&#32622;&#36716;&#31227;&#21040;&#32473;&#23450;&#30340;&#32456;&#31471;&#20301;&#32622;&#65292;&#21463;&#21040;&#37325;&#21147;&#21147;&#22330;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;Lambert&#38382;&#39064;&#30340;&#27010;&#29575;&#21464;&#31181;&#65292;&#20854;&#20013;&#20301;&#32622;&#21521;&#37327;&#30340;&#31471;&#28857;&#32422;&#26463;&#30340;&#30693;&#35782;&#34987;&#23427;&#20204;&#21508;&#33258;&#30340;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#25152;&#26367;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#31471;&#28857;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#32422;&#26463;&#30340;Lambert&#38382;&#39064;&#26159;&#19968;&#20010;&#24191;&#20041;&#30340;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#65288;OMT&#65289;&#38382;&#39064;&#65292;&#20174;&#32780;&#23558;&#36825;&#20010;&#32463;&#20856;&#30340;&#22825;&#20307;&#21160;&#21147;&#23398;&#38382;&#39064;&#19982;&#29616;&#20195;&#38543;&#26426;&#25511;&#21046;&#21644;&#38543;&#26426;&#26426;&#22120;&#23398;&#20064;&#30340;&#26032;&#20852;&#30740;&#31350;&#39046;&#22495;&#32852;&#31995;&#36215;&#26469;&#12290;&#36825;&#20010;&#26032;&#21457;&#29616;&#30340;&#36830;&#25509;&#20351;&#25105;&#20204;&#33021;&#22815;&#20005;&#26684;&#24314;&#31435;&#27010;&#29575;Lambert&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;&#21516;&#26679;&#30340;&#36830;&#25509;&#36824;&#24110;&#21161;&#36890;&#36807;&#25193;&#25955;&#27491;&#35268;&#21270;&#25968;&#20540;&#27714;&#35299;&#27010;&#29575;Lambert&#38382;&#39064;&#65292;&#21363;&#36890;&#36807;&#36827;&#19968;&#27493;&#30340;&#36830;&#25509;&#26469;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#32654;&#22269;&#34928;&#36864;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#21457;&#29616;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#27169;&#22411;&#22312;&#38271;&#26399;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;SHAP&#26041;&#27861;&#23545;GRU&#27169;&#22411;&#36827;&#34892;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.17571</link><description>&lt;p&gt;
&#40657;&#21283;&#23376;&#20869;&#37096;&#65306;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#26102;&#39044;&#27979;&#32654;&#22269;&#34928;&#36864;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Inside the black box: Neural network-based real-time prediction of US recessions. (arXiv:2310.17571v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#32654;&#22269;&#34928;&#36864;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#21457;&#29616;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#27169;&#22411;&#22312;&#38271;&#26399;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;SHAP&#26041;&#27861;&#23545;GRU&#27169;&#22411;&#36827;&#34892;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFN&#65289;&#21644;&#20004;&#31181;&#29305;&#23450;&#31867;&#22411;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;&#21363;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#65292;&#23545;1967&#24180;&#33267;2021&#24180;&#30340;&#32654;&#22269;&#34928;&#36864;&#36827;&#34892;&#24314;&#27169;&#12290;&#28982;&#21518;&#21033;&#29992;&#20272;&#35745;&#30340;&#27169;&#22411;&#23545;&#32654;&#22269;&#30340;&#22823;&#34928;&#36864;&#21644;Covid-19&#34928;&#36864;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#23558;&#20854;&#39044;&#27979;&#24615;&#33021;&#19982;&#20256;&#32479;&#32447;&#24615;&#27169;&#22411;&#12289;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#65288;&#26377;&#21644;&#26080;&#23725;&#22238;&#24402;&#24809;&#32602;&#65289;&#36827;&#34892;&#27604;&#36739;&#12290;&#22806;&#26679;&#26412;&#34920;&#29616;&#34920;&#26126;&#65292;LSTM&#21644;GRU&#22312;&#34928;&#36864;&#39044;&#27979;&#39046;&#22495;&#20855;&#26377;&#24212;&#29992;&#28508;&#21147;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#38271;&#26399;&#39044;&#27979;&#20219;&#21153;&#12290;&#30456;&#23545;&#20110;&#19981;&#21516;&#31867;&#22411;&#30340;&#32479;&#35745;&#24615;&#33021;&#25351;&#26631;&#65292;&#22312;5&#20010;&#39044;&#27979;&#21608;&#26399;&#20869;&#65292;&#23427;&#20204;&#20248;&#20110;&#20854;&#20182;&#31867;&#22411;&#30340;&#27169;&#22411;&#12290;&#32780;&#29992;Shapley&#22686;&#37327;&#35299;&#37322;&#65288;SHAP&#65289;&#26041;&#27861;&#35780;&#20272;&#34913;&#37327;GRU&#22312;&#19981;&#21516;&#39044;&#27979;&#21608;&#26399;&#20869;&#30340;&#37325;&#35201;&#29305;&#24449;&#65292;&#20197;&#28145;&#20837;&#20102;&#35299;&#29305;&#24449;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feedforward neural network (FFN) and two specific types of recurrent neural network, long short-term memory (LSTM) and gated recurrent unit (GRU), are used for modeling US recessions in the period from 1967 to 2021. The estimated models are then employed to conduct real-time predictions of the Great Recession and the Covid-19 recession in US. Their predictive performances are compared to those of the traditional linear models, the logistic regression model both with and without the ridge penalty. The out-of-sample performance suggests the application of LSTM and GRU in the area of recession forecasting, especially for the long-term forecasting tasks. They outperform other types of models across 5 forecasting horizons with respect to different types of statistical performance metrics. Shapley additive explanations (SHAP) method is applied to the fitted GRUs across different forecasting horizons to gain insight into the feature importance. The evaluation of predictor importance differs b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#26102;&#65292;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.17513</link><description>&lt;p&gt;
&#12298;&#20302;&#31209;&#36866;&#24212;&#30340;&#34920;&#36798;&#33021;&#21147;&#12299;
&lt;/p&gt;
&lt;p&gt;
The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#26102;&#65292;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26159;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#21033;&#29992;&#30697;&#38453;&#30340;&#20302;&#31209;&#36866;&#24212;&#24615;&#65292;&#22312;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#26159;LoRA&#30340;&#29702;&#35770;&#22522;&#30784;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#23578;&#26410;&#24471;&#21040;&#25506;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#20174;&#29702;&#35770;&#35282;&#24230;&#20998;&#26512;LoRA&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#39318;&#27425;&#23581;&#35797;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#22914;&#26524;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#65292;&#21017;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#24403;LoRA-rank&#20302;&#20110;&#38408;&#20540;&#26102;&#65292;&#25105;&#20204;&#36824;&#37327;&#21270;&#20102;&#36924;&#36817;&#35823;&#24046;&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20219;&#20309;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\overline{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\overline{f}}{\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#23558;&#35777;&#26126;&#30340;&#33539;&#22260;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#25193;&#23637;&#21040;&#20102;&#26356;&#22823;&#30340;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(PSEUDO-IID)&#65292;&#21253;&#25324;&#20302;&#31209;&#21644;&#31232;&#30095;&#35774;&#32622;&#12290;&#20316;&#32773;&#21457;&#29616;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#36827;&#34892;&#24615;&#33021;&#35843;&#20248;&#12290;</title><link>http://arxiv.org/abs/2310.16597</link><description>&lt;p&gt;
&#36229;&#36234;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#65306;&#31232;&#30095;&#21644;&#20302;&#31209;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20063;&#26159;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes. (arXiv:2310.16597v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#30740;&#31350;&#65292;&#23558;&#35777;&#26126;&#30340;&#33539;&#22260;&#20174;&#29420;&#31435;&#21516;&#20998;&#24067;&#26435;&#37325;&#25193;&#23637;&#21040;&#20102;&#26356;&#22823;&#30340;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(PSEUDO-IID)&#65292;&#21253;&#25324;&#20302;&#31209;&#21644;&#31232;&#30095;&#35774;&#32622;&#12290;&#20316;&#32773;&#21457;&#29616;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#36827;&#34892;&#24615;&#33021;&#35843;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#38480;&#23485;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#19968;&#20010;&#26377;&#29992;&#19988;&#21487;&#31649;&#29702;&#30340;&#25968;&#23398;&#27169;&#22411;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#35768;&#22810;&#29616;&#35937;&#12290;&#20854;&#20013;&#19968;&#20010;&#20363;&#23376;&#26159;&#38543;&#26426;&#28145;&#23618;&#32593;&#32476;&#25910;&#25947;&#21040;&#39640;&#26031;&#36807;&#31243;&#65292;&#20174;&#32780;&#33021;&#22815;&#23545;&#28608;&#27963;&#20989;&#25968;&#21644;&#32593;&#32476;&#26435;&#37325;&#36873;&#25321;&#23545;&#35757;&#32451;&#21160;&#24577;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#20998;&#26512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;Matthews&#31561;&#20154;(2018)&#30340;&#24320;&#21019;&#24615;&#35777;&#26126;&#25193;&#23637;&#21040;&#26356;&#22823;&#30340;&#21021;&#22987;&#26435;&#37325;&#20998;&#24067;&#31867;&#21035;(&#25105;&#20204;&#31216;&#20043;&#20026;PSEUDO-IID)&#65292;&#20854;&#20013;&#21253;&#25324;&#29420;&#31435;&#21516;&#20998;&#24067;&#21644;&#27491;&#20132;&#26435;&#37325;&#30340;&#24050;&#26377;&#24773;&#20917;&#65292;&#20197;&#21450;&#22240;&#20854;&#35745;&#31639;&#21152;&#36895;&#20248;&#21183;&#32780;&#21463;&#21040;&#36190;&#35465;&#30340;&#26032;&#20852;&#20302;&#31209;&#21644;&#32467;&#26500;&#31232;&#30095;&#35774;&#32622;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20351;&#29992;PSEUDO-IID&#20998;&#24067;&#21021;&#22987;&#21270;&#30340;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#32593;&#32476;&#22312;&#26041;&#24046;&#19978;&#37117;&#26159;&#31561;&#25928;&#30340;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#21487;&#20197;&#35782;&#21035;&#26356;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36793;&#30028;&#28151;&#27788;&#29366;&#24577;&#65292;&#24182;&#35843;&#25972;&#23427;&#20204;&#30340;&#20020;&#30028;&#24615;&#65292;&#20197;&#22686;&#24378;&#35757;&#32451;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that allows a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al. (2018) to a larger class of initial weight distributions (which we call PSEUDO-IID), including the established cases of IID and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialized with PSEUDO-IID distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge-of-Chaos for a broader class of neural networks and tune them at criticality in order to enhance the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2310.01012</link><description>&lt;p&gt;
CCA&#23478;&#26063;&#30340;&#39640;&#25928;&#31639;&#27861;&#65306;&#26080;&#32422;&#26463;&#30446;&#26631;&#19982;&#26080;&#20559;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients. (arXiv:2310.01012v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#26041;&#27861;&#22312;&#22810;&#35270;&#35282;&#23398;&#20064;&#20013;&#20855;&#26377;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;&#27491;&#21017;&#21270;&#32447;&#24615;CCA&#26041;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#30340;&#25512;&#24191;&#65292;&#24182;&#19982;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#65288;GEP&#65289;&#26694;&#26550;&#32479;&#19968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32447;&#24615;&#26041;&#27861;&#30340;&#20256;&#32479;&#31639;&#27861;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#35745;&#31639;&#19978;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#28145;&#24230;CCA&#30340;&#25193;&#23637;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#30446;&#21069;&#30340;&#35757;&#32451;&#36807;&#31243;&#32531;&#24930;&#19988;&#22797;&#26434;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#25551;&#36848;GEPs&#30340;&#39030;&#32423;&#23376;&#31354;&#38388;&#30340;&#26032;&#39062;&#26080;&#32422;&#26463;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#36129;&#29486;&#26159;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#24212;&#29992;&#20110;&#30456;&#24212;&#30340;CCA&#30446;&#26631;&#65292;&#20174;&#32780;&#33719;&#24471;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#25152;&#26377;&#26631;&#20934;CCA&#21644;&#28145;&#24230;CCA&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#31034;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;&#36825;&#26679;&#30340;&#36895;&#24230;&#20351;&#25105;&#20204;&#33021;&#22815;&#39318;&#27425;&#36827;&#34892;&#22823;&#35268;&#27169;&#29983;&#29289;&#25968;&#25454;&#30340;PLS&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Canonical Correlation Analysis (CCA) family of methods is foundational in multi-view learning. Regularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and unified with a Generalized Eigenvalue Problem (GEP) framework. However, classical algorithms for these linear methods are computationally infeasible for large-scale data. Extensions to Deep CCA show great promise, but current training procedures are slow and complicated. First we propose a novel unconstrained objective that characterizes the top subspace of GEPs. Our core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives. These methods show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks. This speed allows us to perform a first-of-its-kind PLS analysis of an extremely large bio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#20154;&#30340;&#20381;&#20174;&#31243;&#24230;&#21644;&#26426;&#22120;&#25552;&#20379;&#24314;&#35758;&#30340;&#26102;&#26426;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.00817</link><description>&lt;p&gt;
&#23398;&#20064;&#22914;&#20309;&#25552;&#20379;&#27880;&#37325;&#20381;&#20174;&#24615;&#30340;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Learning to Make Adherence-Aware Advice. (arXiv:2310.00817v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#20154;&#30340;&#20381;&#20174;&#31243;&#24230;&#21644;&#26426;&#22120;&#25552;&#20379;&#24314;&#35758;&#30340;&#26102;&#26426;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#22312;&#20154;&#31867;&#20915;&#31574;&#20013;&#25198;&#28436;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#35282;&#33394;&#65292;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#20132;&#20114;&#23384;&#22312;&#25361;&#25112;&#12290;&#30001;&#20110;&#27809;&#26377;&#20805;&#20998;&#32771;&#34385;&#21040;&#20154;&#31867;&#24573;&#35270;&#20154;&#24037;&#26234;&#33021;&#24314;&#35758;&#21644;&#20154;&#24037;&#26234;&#33021;&#36873;&#25321;&#24615;&#25552;&#20379;&#24314;&#35758;&#30340;&#38656;&#27714;&#65292;&#19968;&#20010;&#25361;&#25112;&#23601;&#26469;&#33258;&#20110;&#24213;&#23618;&#20154;&#24037;&#26234;&#33021;&#31574;&#30053;&#30340;&#19981;&#20339;&#34920;&#29616;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32771;&#34385;&#20102;&#20154;&#31867;&#30340;&#20381;&#20174;&#31243;&#24230;&#65288;&#21363;&#20154;&#31867;&#36981;&#24490;/&#25298;&#32477;&#26426;&#22120;&#24314;&#35758;&#30340;&#27010;&#29575;&#65289;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#25512;&#36831;&#36873;&#39033;&#65292;&#20351;&#24471;&#26426;&#22120;&#22312;&#26368;&#21512;&#36866;&#30340;&#26102;&#20505;&#21487;&#20197;&#26242;&#26102;&#19981;&#25552;&#20379;&#24314;&#35758;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#23398;&#20064;&#26368;&#20339;&#30340;&#24314;&#35758;&#31574;&#30053;&#65292;&#24182;&#20165;&#22312;&#20851;&#38190;&#26102;&#21051;&#25552;&#20379;&#24314;&#35758;&#12290;&#19982;&#38382;&#39064;&#19981;&#21487;&#30693;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#19987;&#38376;&#21270;&#23398;&#20064;&#31639;&#27861;&#19981;&#20165;&#20855;&#26377;&#26356;&#22909;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#33021;&#65292;&#32780;&#19988;&#22312;&#23454;&#35777;&#24615;&#33021;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
As artificial intelligence (AI) systems play an increasingly prominent role in human decision-making, challenges surface in the realm of human-AI interactions. One challenge arises from the suboptimal AI policies due to the inadequate consideration of humans disregarding AI recommendations, as well as the need for AI to provide advice selectively when it is most pertinent. This paper presents a sequential decision-making model that (i) takes into account the human's adherence level (the probability that the human follows/rejects machine advice) and (ii) incorporates a defer option so that the machine can temporarily refrain from making advice. We provide learning algorithms that learn the optimal advice policy and make advice only at critical time stamps. Compared to problem-agnostic reinforcement learning algorithms, our specialized learning algorithms not only enjoy better theoretical convergence properties but also show strong empirical performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#37319;&#29992;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#26469;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#12290;</title><link>http://arxiv.org/abs/2309.16883</link><description>&lt;p&gt;
&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;Lipschitz-&#26041;&#24046;-&#36793;&#30028;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing. (arXiv:2309.16883v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#30740;&#31350;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#37319;&#29992;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#26469;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#23545;&#22122;&#22768;&#36755;&#20837;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#26102;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#38469;&#24212;&#29992;&#21463;&#21040;&#20854;&#19981;&#31283;&#23450;&#30340;&#39044;&#27979;&#30340;&#38459;&#30861;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35748;&#35777;&#21322;&#24452;&#26159;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#20851;&#38190;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#35774;&#35745;&#19968;&#20010;&#20855;&#26377;&#36275;&#22815;&#35748;&#35777;&#21322;&#24452;&#30340;&#39640;&#25928;&#20998;&#31867;&#22120;&#21602;&#65311;&#38543;&#26426;&#24179;&#28369;&#36890;&#36807;&#22312;&#36755;&#20837;&#20013;&#27880;&#20837;&#22122;&#22768;&#26469;&#33719;&#24471;&#24179;&#28369;&#19988;&#26356;&#40065;&#26834;&#30340;&#20998;&#31867;&#22120;&#30340;&#26694;&#26550;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#26412;&#25991;&#39318;&#20808;&#23637;&#31034;&#20102;&#38543;&#26426;&#24179;&#28369;&#24341;&#20837;&#30340;&#26041;&#24046;&#19982;&#20998;&#31867;&#22120;&#30340;&#21478;&#22806;&#20004;&#20010;&#37325;&#35201;&#23646;&#24615;&#65292;&#21363;&#20854;Lipschitz&#24120;&#25968;&#21644;&#36793;&#30028;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#22522;&#20998;&#31867;&#22120;&#30340;Lipschitz&#24120;&#25968;&#23545;&#24179;&#28369;&#20998;&#31867;&#22120;&#21644;&#32463;&#39564;&#26041;&#24046;&#30340;&#21452;&#37325;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22686;&#21152;&#35748;&#35777;&#40065;&#26834;&#21322;&#24452;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#21333;&#32431;&#24418;&#25237;&#24433;&#25216;&#26415;&#65292;&#20197;&#20415;&#36890;&#36807;Bernst&#30340;&#26041;&#24046;-&#36793;&#30028;&#26435;&#34913;&#26469;&#21033;&#29992;&#22522;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-life applications of deep neural networks are hindered by their unsteady predictions when faced with noisy inputs and adversarial attacks. The certified radius is in this context a crucial indicator of the robustness of models. However how to design an efficient classifier with a sufficient certified radius? Randomized smoothing provides a promising framework by relying on noise injection in inputs to obtain a smoothed and more robust classifier. In this paper, we first show that the variance introduced by randomized smoothing closely interacts with two other important properties of the classifier, i.e. its Lipschitz constant and margin. More precisely, our work emphasizes the dual impact of the Lipschitz constant of the base classifier, on both the smoothed classifier and the empirical variance. Moreover, to increase the certified robust radius, we introduce a different simplex projection technique for the base classifier to leverage the variance-margin trade-off thanks to Bernst
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#26469;&#33719;&#24471;&#65292;&#24182;&#19988;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2309.16512</link><description>&lt;p&gt;
&#20174;&#22797;&#26434;&#21040;&#28165;&#26224;&#65306;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#30340;&#20998;&#26512;&#34920;&#36798;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;
&lt;/p&gt;
&lt;p&gt;
From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#26469;&#33719;&#24471;&#65292;&#24182;&#19988;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20960;&#20309;&#65288;Clifford&#65289;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#26512;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#20351;&#29992;&#26631;&#20934;&#27491;&#21017;&#21270;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#30001;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#32473;&#20986;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#38382;&#39064;&#21487;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#22312;&#20854;&#20013;&#32534;&#30721;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#35813;&#32467;&#26500;&#20197;&#25968;&#25454;&#21521;&#37327;&#29983;&#25104;&#30340;&#19977;&#35282;&#24418;&#21644;&#24179;&#34892;&#20307;&#30340;&#26377;&#31526;&#21495;&#20307;&#31215;&#34920;&#31034;&#12290;&#20984;&#38382;&#39064;&#36890;&#36807;$\ell_1$&#27491;&#21017;&#21270;&#25214;&#21040;&#26679;&#26412;&#30340;&#19968;&#20010;&#23567;&#23376;&#38598;&#65292;&#20197;&#21457;&#29616;&#20165;&#30456;&#20851;&#30340;&#26964;&#31215;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#24037;&#20316;&#26426;&#21046;&#30340;&#26032;&#35270;&#35282;&#65292;&#24182;&#25581;&#31034;&#20102;&#38544;&#34255;&#23618;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;${\mathcal L}^2$&#20195;&#20215;&#26368;&#23567;&#21270;&#30340;&#26500;&#36896;&#26041;&#27861;&#33719;&#24471;&#20102;&#19968;&#20010;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#30340;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2309.10370</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#21644;&#22522;&#20110;${\mathcal L}^2$&#20195;&#20215;&#26368;&#23567;&#21270;&#30340;&#26500;&#36896;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometric structure of shallow neural networks and constructive ${\mathcal L}^2$ cost minimization. (arXiv:2309.10370v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#32467;&#26500;&#35299;&#37322;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;${\mathcal L}^2$&#20195;&#20215;&#26368;&#23567;&#21270;&#30340;&#26500;&#36896;&#26041;&#27861;&#33719;&#24471;&#20102;&#19968;&#20010;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32473;&#20986;&#20102;&#19968;&#20010;&#20960;&#20309;&#35299;&#37322;&#65306;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#30001;&#19968;&#20010;&#38544;&#34255;&#23618;&#12289;&#19968;&#20010;&#26012;&#22369;&#28608;&#27963;&#20989;&#25968;&#12289;&#19968;&#20010;${\mathcal L}^2$&#35889;&#33539;&#31867;&#65288;&#25110;&#32773;Hilbert-Schmidt&#65289;&#30340;&#20195;&#20215;&#20989;&#25968;&#12289;&#36755;&#20837;&#31354;&#38388;${\mathbb R}^M$&#12289;&#36755;&#20986;&#31354;&#38388;${\mathbb R}^Q$&#65288;&#20854;&#20013;$Q\leq M$&#65289;&#65292;&#20197;&#21450;&#35757;&#32451;&#36755;&#20837;&#26679;&#26412;&#25968;&#37327;$N&gt;QM$&#25152;&#29305;&#24449;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20195;&#20215;&#20989;&#25968;&#30340;&#26368;&#23567;&#20540;&#20855;&#26377;$O(\delta_P)$&#30340;&#19978;&#30028;&#65292;&#20854;&#20013;$\delta_P$&#34913;&#37327;&#20102;&#35757;&#32451;&#36755;&#20837;&#30340;&#20449;&#22122;&#27604;&#12290;&#25105;&#20204;&#20351;&#29992;&#36866;&#24212;&#20110;&#23646;&#20110;&#21516;&#19968;&#36755;&#20986;&#21521;&#37327;$y_j$&#30340;&#35757;&#32451;&#36755;&#20837;&#21521;&#37327;$\overline{x_{0,j}}$&#30340;&#25237;&#24433;&#26469;&#33719;&#24471;&#36817;&#20284;&#30340;&#20248;&#21270;&#22120;&#65292;&#20854;&#20013;$j=1,\dots,Q$&#12290;&#22312;&#29305;&#27530;&#24773;&#20917;$M=Q$&#19979;&#65292;&#25105;&#20204;&#26126;&#30830;&#30830;&#23450;&#20102;&#20195;&#20215;&#20989;&#25968;&#30340;&#19968;&#20010;&#30830;&#20999;&#36864;&#21270;&#23616;&#37096;&#26368;&#23567;&#20540;&#65307;&#36825;&#20010;&#23574;&#38160;&#30340;&#20540;&#19982;&#23545;&#20110;$Q\leq M$&#25152;&#33719;&#24471;&#30340;&#19978;&#30028;&#20043;&#38388;&#26377;&#19968;&#20010;&#30456;&#23545;&#35823;&#24046;$O(\delta_P^2)$&#12290;&#19978;&#30028;&#35777;&#26126;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#26500;&#36896;&#24615;&#35757;&#32451;&#30340;&#32593;&#32476;&#65307;&#25105;&#20204;&#35777;&#26126;&#23427;&#27979;&#24230;&#20102;$Q$&#32500;&#31354;&#38388;&#20013;&#30340;&#32473;&#23450;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a geometric interpretation of the structure of shallow neural networks characterized by one hidden layer, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, input space ${\mathbb R}^M$, output space ${\mathbb R}^Q$ with $Q\leq M$, and training input sample size $N&gt;QM$. We prove an upper bound on the minimum of the cost function of order $O(\delta_P$ where $\delta_P$ measures the signal to noise ratio of training inputs. We obtain an approximate optimizer using projections adapted to the averages $\overline{x_{0,j}}$ of training input vectors belonging to the same output vector $y_j$, $j=1,\dots,Q$. In the special case $M=Q$, we explicitly determine an exact degenerate local minimum of the cost function; the sharp value differs from the upper bound obtained for $Q\leq M$ by a relative error $O(\delta_P^2)$. The proof of the upper bound yields a constructively trained network; we show that it metrizes the $Q$-dimen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#65292;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#33021;&#22815;&#25910;&#25947;&#21040;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#36825;&#36866;&#29992;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20855;&#26377;&#20805;&#20998;&#24179;&#28369;&#19988;&#26377;&#30028;&#28608;&#27963;&#20989;&#25968;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36830;&#32493;&#26102;&#38388;SGD&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#20809;&#28369;&#26080;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.09258</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#19978;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets. (arXiv:2309.09258v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#35777;&#26126;&#20102;&#22312;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#65292;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#33021;&#22815;&#25910;&#25947;&#21040;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#36825;&#36866;&#29992;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20855;&#26377;&#20805;&#20998;&#24179;&#28369;&#19988;&#26377;&#30028;&#28608;&#27963;&#20989;&#25968;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36830;&#32493;&#26102;&#38388;SGD&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#20809;&#28369;&#26080;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#23545;&#20110;&#36866;&#24403;&#27491;&#21017;&#21270;&#30340;&#28145;&#24230;&#20026;2&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#33021;&#22815;&#25910;&#25947;&#21040;&#20840;&#23616;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#20219;&#24847;&#25968;&#25454;&#21644;&#20855;&#26377;&#20805;&#20998;&#24179;&#28369;&#19988;&#26377;&#30028;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;sigmoid&#21644;tanh&#65289;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36830;&#32493;&#26102;&#38388;SGD&#30340;&#25351;&#25968;&#32423;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#35813;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#20809;&#28369;&#26080;&#30028;&#30340;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;SoftPlus&#65289;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#35777;&#26126;&#20102;&#22312;&#24658;&#23450;&#22823;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#23384;&#22312;Frobenius&#33539;&#25968;&#27491;&#21017;&#21270;&#30340;&#36923;&#36753;&#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#65292;&#36825;&#20123;&#20989;&#25968;&#26159;"Villani&#20989;&#25968;"&#65292;&#20174;&#32780;&#33021;&#22815;&#26500;&#24314;&#22312;&#26368;&#36817;&#23545;&#20110;&#27492;&#31867;&#30446;&#26631;&#20989;&#25968;&#19978;&#20998;&#26512;SGD&#30340;&#30740;&#31350;&#36827;&#23637;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates with adequately smooth and bounded activations like sigmoid and tanh. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized logistic loss functions on constant-sized neural nets which are "Villani functions" and thus be able to build on recent progress with analyzing SGD on such objectives.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Beta&#25955;&#24230;&#30340;&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#38754;&#37096;&#29305;&#24449;&#25552;&#21462;&#12289;&#25991;&#26723;&#20027;&#39064;&#35782;&#21035;&#21644;&#39640;&#20809;&#35889;&#22270;&#20687;&#26448;&#26009;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2309.08249</link><description>&lt;p&gt;
&#24102;&#26377;Beta&#25955;&#24230;&#30340;&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Deep Nonnegative Matrix Factorization with Beta Divergences. (arXiv:2309.08249v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08249
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Beta&#25955;&#24230;&#30340;&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#65292;&#24212;&#29992;&#20110;&#38754;&#37096;&#29305;&#24449;&#25552;&#21462;&#12289;&#25991;&#26723;&#20027;&#39064;&#35782;&#21035;&#21644;&#39640;&#20809;&#35889;&#22270;&#20687;&#26448;&#26009;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;deep NMF&#65289;&#26368;&#36817;&#25104;&#20026;&#19968;&#31181;&#26377;&#20215;&#20540;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#19981;&#21516;&#23610;&#24230;&#19978;&#25552;&#21462;&#22810;&#23618;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#29616;&#26377;&#30340;&#28145;&#24230;NMF&#27169;&#22411;&#21644;&#31639;&#27861;&#20027;&#35201;&#37117;&#20197;&#26368;&#23567;&#20108;&#20056;&#35823;&#24046;&#20026;&#35780;&#20272;&#26631;&#20934;&#65292;&#36825;&#21487;&#33021;&#19981;&#26159;&#35780;&#20272;&#22810;&#26679;&#21270;&#25968;&#25454;&#38598;&#36817;&#20284;&#36136;&#37327;&#30340;&#26368;&#21512;&#36866;&#25351;&#26631;&#12290;&#20363;&#22914;&#65292;&#24403;&#22788;&#29702;&#38899;&#39057;&#20449;&#21495;&#21644;&#25991;&#26723;&#31561;&#25968;&#25454;&#31867;&#22411;&#26102;&#65292;&#24191;&#27867;&#35748;&#21487;&#30340;&#26159;$\beta$-divergences&#25552;&#20379;&#20102;&#26356;&#36866;&#21512;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#26412;&#25991;&#22522;&#20110;$\beta$-divergences&#24320;&#21457;&#20102;&#26032;&#30340;&#28145;&#24230;NMF&#27169;&#22411;&#21644;&#31639;&#27861;&#65292;&#24182;&#23558;&#36825;&#20123;&#25216;&#26415;&#24212;&#29992;&#20110;&#38754;&#37096;&#29305;&#24449;&#25552;&#21462;&#12289;&#25991;&#26723;&#38598;&#21512;&#20013;&#30340;&#20027;&#39064;&#35782;&#21035;&#20197;&#21450;&#39640;&#20809;&#35889;&#22270;&#20687;&#20013;&#26448;&#26009;&#30340;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a valuable technique for extracting multiple layers of features across different scales. However, all existing deep NMF models and algorithms have primarily centered their evaluation on the least squares error, which may not be the most appropriate metric for assessing the quality of approximations on diverse datasets. For instance, when dealing with data types such as audio signals and documents, it is widely acknowledged that $\beta$-divergences offer a more suitable alternative. In this paper, we develop new models and algorithms for deep NMF using $\beta$-divergences. Subsequently, we apply these techniques to the extraction of facial features, the identification of topics within document collections, and the identification of materials within hyperspectral images.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#21644;&#36882;&#24402;&#26680;&#26041;&#27861;&#12290;&#19982;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#25110;&#19981;&#31934;&#30830;&#36924;&#36817;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27599;&#20010;&#23454;&#20363;&#30340;&#20195;&#20215;&#19978;&#20855;&#26377;&#20108;&#27425;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#39118;&#21147;&#30701;&#26399;&#39044;&#27979;&#25361;&#25112;&#65292;&#24182;&#19982;&#20854;&#20182;&#31454;&#20105;&#32773;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.01938</link><description>&lt;p&gt;
&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#22522;&#20110;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#21644;&#36882;&#24402;&#26680;&#26041;&#27861;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Online Multi-Task Learning with Recursive Least Squares and Recursive Kernel Methods. (arXiv:2308.01938v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01938
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#65292;&#20998;&#21035;&#22522;&#20110;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#21644;&#36882;&#24402;&#26680;&#26041;&#27861;&#12290;&#19982;&#22522;&#20110;&#26799;&#24230;&#19979;&#38477;&#25110;&#19981;&#31934;&#30830;&#36924;&#36817;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#27599;&#20010;&#23454;&#20363;&#30340;&#20195;&#20215;&#19978;&#20855;&#26377;&#20108;&#27425;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#39118;&#21147;&#30701;&#26399;&#39044;&#27979;&#25361;&#25112;&#65292;&#24182;&#19982;&#20854;&#20182;&#31454;&#20105;&#32773;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#39640;&#24615;&#33021;&#22522;&#20110;&#22270;&#30340;MTL&#20844;&#24335;&#65292;&#22522;&#20110;&#21152;&#26435;&#36882;&#24402;&#26368;&#23567;&#20108;&#20056;&#65288;WRLS&#65289;&#21644;&#22312;&#32447;&#31232;&#30095;&#26368;&#23567;&#20108;&#20056;&#25903;&#25345;&#21521;&#37327;&#22238;&#24402;&#65288;OSLSSVR&#65289;&#24320;&#21457;&#20854;&#36882;&#24402;&#29256;&#26412;&#12290;&#37319;&#29992;&#20219;&#21153;&#22534;&#21472;&#36716;&#25442;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#20010;&#21333;&#30697;&#38453;&#65292;&#23427;&#34701;&#21512;&#20102;&#22810;&#20219;&#21153;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#20026;MT-WRLS&#26041;&#27861;&#30340;&#21021;&#22987;&#21270;&#36807;&#31243;&#21644;MT-OSLSSVR&#30340;&#22810;&#20219;&#21153;&#26680;&#20989;&#25968;&#25552;&#20379;&#32467;&#26500;&#20449;&#24687;&#12290;&#19982;&#29616;&#26377;&#22823;&#37096;&#20998;&#22522;&#20110;&#22312;&#32447;&#26799;&#24230;&#19979;&#38477;&#65288;OGD&#65289;&#25110;&#19981;&#31934;&#30830;&#31435;&#26041;&#36924;&#36817;&#26041;&#27861;&#30340;&#25991;&#29486;&#30456;&#27604;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#31934;&#30830;&#21644;&#36817;&#20284;&#36882;&#24402;&#65292;&#20854;&#27599;&#20010;&#23454;&#20363;&#30340;&#20195;&#20215;&#22312;&#36755;&#20837;&#31354;&#38388;&#30340;&#32500;&#24230;&#65288;MT-WRLS&#65289;&#25110;&#23454;&#20363;&#23383;&#20856;&#30340;&#22823;&#23567;&#19978;&#26159;&#20108;&#27425;&#30340;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#22312;&#32447;MTL&#26041;&#27861;&#19982;&#20854;&#20182;&#31454;&#20105;&#32773;&#22312;&#23454;&#38469;&#39118;&#30701;&#26399;&#39044;&#27979;&#25361;&#25112;&#19978;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces two novel approaches for Online Multi-Task Learning (MTL) Regression Problems. We employ a high performance graph-based MTL formulation and develop its recursive versions based on the Weighted Recursive Least Squares (WRLS) and the Online Sparse Least Squares Support Vector Regression (OSLSSVR). Adopting task-stacking transformations, we demonstrate the existence of a single matrix incorporating the relationship of multiple tasks and providing structural information to be embodied by the MT-WRLS method in its initialization procedure and by the MT-OSLSSVR in its multi-task kernel function. Contrasting the existing literature, which is mostly based on Online Gradient Descent (OGD) or cubic inexact approaches, we achieve exact and approximate recursions with quadratic per-instance cost on the dimension of the input space (MT-WRLS) or on the size of the dictionary of instances (MT-OSLSSVR). We compare our online MTL methods to other contenders in a real-world wind sp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.13916</link><description>&lt;p&gt;
&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online learning in bandits with predicted context. (arXiv:2307.13916v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#39044;&#27979;&#19978;&#19979;&#25991;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#27599;&#20010;&#26102;&#21051;&#65292;&#20195;&#29702;&#21482;&#33021;&#35775;&#38382;&#21040;&#19978;&#19979;&#25991;&#30340;&#19968;&#20010;&#24102;&#22122;&#22768;&#30340;&#29256;&#26412;&#20197;&#21450;&#35823;&#24046;&#26041;&#24046;&#65288;&#25110;&#32773;&#36825;&#20010;&#26041;&#24046;&#30340;&#19968;&#20010;&#20272;&#35745;&#65289;&#12290;&#36825;&#19968;&#35774;&#32622;&#21463;&#21040;&#20102;&#35768;&#22810;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#29992;&#20110;&#20915;&#31574;&#30340;&#30495;&#23454;&#19978;&#19979;&#25991;&#26159;&#19981;&#21487;&#35266;&#27979;&#30340;&#65292;&#32780;&#21482;&#26377;&#19968;&#20010;&#30001;&#21487;&#33021;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#39044;&#27979;&#20986;&#30340;&#19978;&#19979;&#25991;&#12290;&#24403;&#19978;&#19979;&#25991;&#35823;&#24046;&#26159;&#38750;&#34928;&#20943;&#30340;&#26102;&#20505;&#65292;&#32463;&#20856;&#30340;bandit&#31639;&#27861;&#26080;&#27861;&#36798;&#21040;&#27425;&#32447;&#24615;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#36825;&#19968;&#35774;&#32622;&#19979;&#65292;&#31532;&#19968;&#20010;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#19982;&#36866;&#24403;&#30340;&#22522;&#20934;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#20851;&#38190;&#30340;&#24605;&#24819;&#26159;&#23558;&#32463;&#20856;&#32479;&#35745;&#23398;&#20013;&#30340;&#27979;&#37327;&#35823;&#24046;&#27169;&#22411;&#25512;&#24191;&#21040;&#22312;&#32447;&#20915;&#31574;&#35774;&#32622;&#20013;&#65292;&#36825;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#22240;&#20026;&#31574;&#30053;&#20381;&#36182;&#20110;&#26377;&#22122;&#22768;&#30340;&#19978;&#19979;&#25991;&#35266;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-diminishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret compared to the appropriate benchmark. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10352</link><description>&lt;p&gt;
&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#21106;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#24050;&#25104;&#20026;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#27861;&#12290;&#24191;&#27867;&#24212;&#29992;&#21253;&#25324;&#22270;&#20687;&#22788;&#29702;&#12289;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#24120;&#24120;&#38656;&#35201;&#20248;&#21270;&#19968;&#20123;&#21442;&#25968;&#20197;&#26368;&#23567;&#21270;SW&#65292;&#35813;&#21442;&#25968;&#20805;&#24403;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#25439;&#22833;&#20989;&#25968;&#65288;&#22240;&#20026;&#20855;&#26377;&#23494;&#24230;&#30340;&#27979;&#24230;&#22312;&#25968;&#20540;&#19978;&#26159;&#26080;&#27861;&#23454;&#29616;&#30340;&#65289;&#12290;&#25152;&#26377;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#37117;&#23384;&#22312;&#30456;&#21516;&#30340;&#23376;&#38382;&#39064;&#65292;&#21363;&#26368;&#23567;&#21270;&#20999;&#21106;Wasserstein&#33021;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$&#30340;&#23646;&#24615;&#65292;&#21363;&#20004;&#20010;&#20855;&#26377;&#19982;&#19968;&#20010;&#27979;&#24230;&#30340;&#25903;&#25745;&#30456;&#21516;&#25968;&#37327;&#30340;&#31163;&#25955;&#22343;&#21248;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#36317;&#31163;&#20316;&#20026;&#25903;&#25745;$Y \in \mathbb{R}^{n \times d}$&#20989;&#25968;&#30340;&#33021;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#33021;&#37327;&#30340;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#65292;&#20197;&#21450;&#20854;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;$\mathcal{E}_p$&#65288;&#20351;&#29992;SW&#20013;&#30340;&#26399;&#26395;&#20272;&#35745;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.15759</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15759
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;(DMs)&#34987;&#24191;&#27867;&#29992;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30452;&#25509;&#22312;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20013;&#36816;&#34892;&#65292;DMs&#30340;&#20248;&#21270;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#38656;&#35201;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#12290;&#36825;&#23548;&#33268;&#30001;&#20110;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#32452;&#21512;&#24615;&#23646;&#24615;&#65292;&#22823;&#37327;&#22122;&#38899;&#27880;&#20837;&#21040;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#12290;LDMs&#20351;&#29992;&#24378;&#22823;&#30340;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20943;&#23569;&#21040;&#26356;&#20302;&#32500;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#20351;&#35757;&#32451;DMs&#26356;&#21152;&#39640;&#25928;&#21644;&#24555;&#36895;&#12290;&#19982;[Ghalebikesabi&#31561;&#20154;&#65292;2023]&#39044;&#20808;&#29992;&#20844;&#20849;&#25968;&#25454;&#39044;&#35757;&#32451;DMs&#65292;&#28982;&#21518;&#20877;&#29992;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#19981;&#21516;&#65292;&#25105;&#20204;&#20165;&#24494;&#35843;LDMs&#20013;&#19981;&#21516;&#23618;&#30340;&#27880;&#24847;&#21147;&#27169;&#22359;&#20197;&#33719;&#24471;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#65292;&#30456;&#23545;&#20110;&#25972;&#20010;DM&#24494;&#35843;&#65292;&#21487;&#20943;&#23569;&#22823;&#32422;96%&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#65292;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#26368;&#26032;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65307;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#36827;&#34892;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.13991</link><description>&lt;p&gt;
&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Expressive Losses for Verified Robustness via Convex Combinations. (arXiv:2305.13991v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13991
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22522;&#20110;&#20984;&#32452;&#21512;&#30340;&#34920;&#36798;&#24615;&#25439;&#22833;&#65292;&#21487;&#20197;&#25552;&#39640;&#32593;&#32476;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#26368;&#26032;&#30340;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65307;&#36825;&#31181;&#26041;&#27861;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#36827;&#34892;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#36890;&#36807;&#65288;&#25200;&#21160;&#21306;&#22495;&#30340;&#23376;&#38598;&#65289;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#38480;&#65292;&#25110;&#22312;&#23545;&#25239;&#35757;&#32451;&#20043;&#19978;&#24341;&#20837;&#21487;&#39564;&#35777;&#24615;&#26469;&#35757;&#32451;&#20855;&#26377;&#24050;&#39564;&#35777;&#40065;&#26834;&#24615;&#30340;&#32593;&#32476;&#12290;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20851;&#38190;&#22312;&#20110;&#25152;&#20351;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23427;&#24212;&#35813;&#33021;&#22815;&#21305;&#37197;&#35757;&#32451;&#21518;&#35201;&#20351;&#29992;&#30340;&#39564;&#35777;&#22120;&#30340;&#32039;&#23494;&#24230;&#12290;&#25105;&#20204;&#24418;&#24335;&#21270;&#23450;&#20041;&#20102;&#34920;&#36798;&#21147;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#36890;&#36807;&#23545;&#25239;&#24615;&#25915;&#20987;&#21644;IBP&#36793;&#30028;&#20043;&#38388;&#30340;&#31616;&#21333;&#20984;&#32452;&#21512;&#26469;&#28385;&#36275;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;CC-IBP&#21644;MTL-IBP&#65292;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#22343;&#21487;&#20197;&#20135;&#29983;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#23613;&#31649;&#20854;&#27010;&#24565;&#19978;&#26159;&#31616;&#21333;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;TinyImageNet&#21644;&#32553;&#23567;&#30340;ImageNet&#19978;&#65292;&#23545;&#20110;&#21322;&#24452;&#20026;$ \frac{1} {255} $&#30340;$ \ell_ \infty $&#25200;&#21160;&#65292;MTL-IBP&#21487;&#20197;&#23558;&#25991;&#29486;&#20013;&#26368;&#20339;&#26631;&#20934;&#21644;&#39564;&#35777;&#20934;&#30830;&#24615;&#20174;$1.98\%$&#25552;&#39640;&#21040;$3.92\%$&#65292;&#21516;&#26102;&#20165;&#20381;&#36182;&#20110;&#21333;&#27493;&#33258;&#36866;&#24212;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\ell_\infty$ perturbations of radius $\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\%$ to $3.92\%$ points while only relying on single-step ad
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#31070;&#32463;&#32593;&#32476;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38024;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#25552;&#20379;&#39640;&#27010;&#29575;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11997</link><description>&lt;p&gt;
&#20855;&#26377;&#27010;&#29575;&#20445;&#35777;&#30340;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Robust Counterfactual Explanations for Neural Networks With Probabilistic Guarantees. (arXiv:2305.11997v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#38752;&#30340;&#31070;&#32463;&#32593;&#32476;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#38024;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#25552;&#20379;&#39640;&#27010;&#29575;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#31070;&#32463;&#32593;&#32476;&#21457;&#29616;&#20559;&#31227;&#65292;&#36890;&#36807;&#20351;&#29992;&#31283;&#23450;&#24615;&#24230;&#37327;&#26469;&#37327;&#21270;&#21453;&#20107;&#23454;&#35299;&#37322;&#23545;&#21487;&#33021;&#30340;&#27169;&#22411;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;&#36890;&#36807;&#22312;&#21453;&#20107;&#23454;&#35299;&#37322;&#20248;&#21270;&#20013;&#24341;&#20837;&#27491;&#21017;&#21270;&#39033;&#26469;&#23558;&#29983;&#25104;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#38752;&#36817;&#25968;&#25454;&#27969;&#24418;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#33258;&#28982;&#21457;&#29983;&#30340;&#27169;&#22411;&#21464;&#21270;&#30340;&#39640;&#27010;&#29575;&#40065;&#26834;&#24615;&#12290;&#26032;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\|\text{Params}(M){-}\text{Params}(m)\|{&lt;}\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed \emph{naturally-occurring} model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure -- that we call \emph{Stability} -- to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counter
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.06094</link><description>&lt;p&gt;
&#33021;&#37327;&#24341;&#23548;&#30340;&#29109;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Energy-guided Entropic Neural Optimal Transport. (arXiv:2304.06094v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#21644;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#30784;&#27169;&#22411;&#65288;EBMs&#65289;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#24050;&#32463;&#26377;&#25968;&#21313;&#24180;&#30340;&#21382;&#21490;&#12290;&#33258;&#20004;&#21315;&#24180;&#20195;&#36215;&#65292;&#19968;&#30452;&#26377;&#24456;&#22810;&#39640;&#25928;&#30340;&#26041;&#27861;&#36890;&#36807;&#33021;&#37327;&#21183;&#65288;&#38750;&#24402;&#19968;&#21270;&#30340;&#20284;&#28982;&#20989;&#25968;&#65289;&#26469;&#35299;&#20915;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#39046;&#22495;&#65292;&#23588;&#20854;&#26159;&#31070;&#32463;OT&#27714;&#35299;&#22120;&#65292;&#21463;&#21040;&#30340;&#25506;&#32034;&#35201;&#23569;&#24471;&#22810;&#65292;&#20165;&#26377;&#19968;&#20123;&#36817;&#26399;&#30340;&#30740;&#31350;&#65288;&#19981;&#21253;&#25324;&#21033;&#29992;OT&#20316;&#20026;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#38382;&#39064;&#30340;WGAN&#26041;&#27861;&#65289;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24357;&#21512;&#20102;EBMs&#21644;&#29109;&#27491;&#21017;&#21270;OT&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20801;&#35768;&#21033;&#29992;&#21069;&#32773;&#30340;&#26368;&#26032;&#21457;&#23637;&#21644;&#25216;&#26415;&#25913;&#36827;&#26469;&#20016;&#23500;&#21518;&#32773;&#12290;&#25105;&#20204;&#22312;2D&#24773;&#26223;&#21644;&#26631;&#20934;&#30340;&#22270;&#20687;&#21040;&#22270;&#20687;&#32763;&#35793;&#38382;&#39064;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#12290;&#20026;&#31616;&#21333;&#36215;&#35265;&#65292;&#25105;&#20204;&#36873;&#25321;&#20102;&#31616;&#30701;&#21644;&#38271;&#36305;&#30340;EBMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) are known in the Machine Learning community for the decades. Since the seminal works devoted to EBMs dating back to the noughties there have been appearing a lot of efficient methods which solve the generative modelling problem by means of energy potentials (unnormalized likelihood functions). In contrast, the realm of Optimal Transport (OT) and, in particular, neural OT solvers is much less explored and limited by few recent works (excluding WGAN based approaches which utilize OT as a loss function and do not model OT maps themselves). In our work, we bridge the gap between EBMs and Entropy-regularized OT. We present the novel methodology which allows utilizing the recent developments and technical improvements of the former in order to enrich the latter. We validate the applicability of our method on toy 2D scenarios as well as standard unpaired image-to-image translation problems. For the sake of simplicity, we choose simple short- and long- run EBMs as a 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Koopman&#31639;&#23376;&#23545;&#20840;&#31209;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#36827;&#34892;&#27867;&#21270;&#30340;&#26032;&#30028;&#38480;&#65292;&#24403;&#26435;&#37325;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#36739;&#23567;&#26102;&#65292;&#35813;&#30028;&#38480;&#27604;&#29616;&#26377;&#22522;&#20110;&#33539;&#25968;&#30340;&#30028;&#38480;&#26356;&#32039;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#19981;&#19982;&#29616;&#26377;&#30028;&#38480;&#30456;&#30683;&#30462;&#65292;&#32780;&#26159;&#23545;&#29616;&#26377;&#30028;&#38480;&#36827;&#34892;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#19982;&#29616;&#26377;&#30028;&#38480;&#32467;&#21512;&#20197;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#35813;&#30740;&#31350;&#32467;&#26524;&#20026;&#29702;&#35299;&#20840;&#31209;&#26435;&#37325;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#21516;&#26102;&#20063;&#20026;&#31639;&#23376;&#29702;&#35770;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#20043;&#38388;&#25552;&#20379;&#20102;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2302.05825</link><description>&lt;p&gt;
&#22522;&#20110;Koopman&#31639;&#23376;&#30340;&#20840;&#31209;&#26435;&#37325;&#30340;&#27867;&#21270;&#30028;&#38480;&#65306;&#26032;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Koopman-based generalization bound: New aspect for full-rank weights. (arXiv:2302.05825v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05825
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Koopman&#31639;&#23376;&#23545;&#20840;&#31209;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#36827;&#34892;&#27867;&#21270;&#30340;&#26032;&#30028;&#38480;&#65292;&#24403;&#26435;&#37325;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#36739;&#23567;&#26102;&#65292;&#35813;&#30028;&#38480;&#27604;&#29616;&#26377;&#22522;&#20110;&#33539;&#25968;&#30340;&#30028;&#38480;&#26356;&#32039;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#19981;&#19982;&#29616;&#26377;&#30028;&#38480;&#30456;&#30683;&#30462;&#65292;&#32780;&#26159;&#23545;&#29616;&#26377;&#30028;&#38480;&#36827;&#34892;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#19982;&#29616;&#26377;&#30028;&#38480;&#32467;&#21512;&#20197;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#35813;&#30740;&#31350;&#32467;&#26524;&#20026;&#29702;&#35299;&#20840;&#31209;&#26435;&#37325;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#21516;&#26102;&#20063;&#20026;&#31639;&#23376;&#29702;&#35770;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#20043;&#38388;&#25552;&#20379;&#20102;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Koopman&#31639;&#23376;&#23545;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27867;&#21270;&#30340;&#26032;&#30028;&#38480;&#12290;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#19978;&#65292;&#32780;&#25105;&#20204;&#19987;&#27880;&#20110;&#20840;&#31209;&#26435;&#37325;&#30697;&#38453;&#12290;&#24403;&#26435;&#37325;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#36739;&#23567;&#26102;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#27604;&#29616;&#26377;&#22522;&#20110;&#33539;&#25968;&#30340;&#30028;&#38480;&#26356;&#32039;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#26435;&#37325;&#30697;&#38453;&#26159;&#27491;&#20132;&#30340;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#19982;&#32593;&#32476;&#30340;&#23485;&#24230;&#23436;&#20840;&#26080;&#20851;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#19981;&#19982;&#29616;&#26377;&#30028;&#38480;&#30456;&#30683;&#30462;&#65292;&#32780;&#26159;&#23545;&#29616;&#26377;&#30028;&#38480;&#36827;&#34892;&#30340;&#34917;&#20805;&#12290;&#30001;&#20960;&#20010;&#24050;&#26377;&#23454;&#39564;&#35777;&#26126;&#65292;&#20302;&#31209;&#24615;&#24182;&#19981;&#26159;&#27867;&#21270;&#30340;&#21807;&#19968;&#21407;&#22240;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#19982;&#29616;&#26377;&#30028;&#38480;&#32467;&#21512;&#20197;&#24471;&#21040;&#26356;&#32039;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#29702;&#35299;&#20855;&#26377;&#20840;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#21516;&#26102;&#36824;&#20026;&#31639;&#23376;&#29702;&#35770;&#20998;&#26512;&#21644;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#20043;&#38388;&#25552;&#20379;&#20102;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new bound for generalization of neural networks using Koopman operators. Whereas most of existing works focus on low-rank weight matrices, we focus on full-rank weight matrices. Our bound is tighter than existing norm-based bounds when the condition numbers of weight matrices are small. Especially, it is completely independent of the width of the network if the weight matrices are orthogonal. Our bound does not contradict to the existing bounds but is a complement to the existing bounds. As supported by several existing empirical results, low-rankness is not the only reason for generalization. Furthermore, our bound can be combined with the existing bounds to obtain a tighter bound. Our result sheds new light on understanding generalization of neural networks with full-rank weight matrices, and it provides a connection between operator-theoretic analysis and generalization of neural networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;Stochastically Extended Adversarial (SEA)&#27169;&#22411;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#23545;&#20110;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#36951;&#25022;&#30028;&#38480;&#20026;O(sqrt(&#963;_{1:T}^2) + sqrt(&#931;_{1:T}^2))&#65292;&#23545;&#20110;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#30028;&#38480;&#20026;O(sqrt(&#963;_{\max}^2) + sqrt(&#931;_{\max}^2))&#12290;</title><link>http://arxiv.org/abs/2302.04552</link><description>&lt;p&gt;
&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;&#36830;&#25509;&#38543;&#26426;&#24615;&#21644;&#23545;&#25239;&#24615;&#22312;&#32447;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Optimistic Online Mirror Descent for Bridging Stochastic and Adversarial Online Convex Optimization. (arXiv:2302.04552v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;Stochastically Extended Adversarial (SEA)&#27169;&#22411;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#23545;&#20110;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#36951;&#25022;&#30028;&#38480;&#20026;O(sqrt(&#963;_{1:T}^2) + sqrt(&#931;_{1:T}^2))&#65292;&#23545;&#20110;&#24378;&#20984;&#21644;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20854;&#30028;&#38480;&#20026;O(sqrt(&#963;_{\max}^2) + sqrt(&#931;_{\max}^2))&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sachs&#31561;&#20154;&#20171;&#32461;&#20102;Stochastically Extended Adversarial (SEA)&#27169;&#22411;&#65292;&#20316;&#20026;&#38543;&#26426;&#24615;&#21644;&#23545;&#25239;&#24615;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#25554;&#20540;&#26041;&#27861;&#12290;&#22312;&#20809;&#28369;&#26465;&#20214;&#19979;&#65292;&#20182;&#20204;&#35777;&#26126;&#20102;&#20048;&#35266;&#30340;Follow-the-Regularized-Leader (FTRL)&#31639;&#27861;&#30340;&#26399;&#26395;&#36951;&#25022;&#20381;&#36182;&#20110;&#20984;&#20989;&#25968;&#30340;&#32047;&#31215;&#38543;&#26426;&#26041;&#24046;&#21644;&#32047;&#31215;&#23545;&#25239;&#21464;&#21270;&#12290;&#23545;&#20110;&#24378;&#20984;&#20989;&#25968;&#65292;&#20182;&#20204;&#20063;&#32473;&#20986;&#20102;&#22522;&#20110;&#26368;&#22823;&#38543;&#26426;&#26041;&#24046;&#21644;&#26368;&#22823;&#23545;&#25239;&#21464;&#21270;&#30340;&#31245;&#24369;&#30028;&#38480;&#12290;&#21463;&#21040;&#20182;&#20204;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20048;&#35266;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;SEA&#27169;&#22411;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#23545;&#20110;&#20984;&#19988;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#21363;O(sqrt(&#963;_{1:T}^2) + sqrt(&#931;_{1:T}^2))&#65292;&#32780;&#19981;&#38656;&#35201;&#20010;&#21035;&#20989;&#25968;&#30340;&#20984;&#24615;&#35201;&#27714;&#12290;&#23545;&#20110;&#24378;&#20984;&#19988;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;O(sqrt(&#963;_{\max}^2) + sqrt(&#931;_{\max}^2))&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastically Extended Adversarial (SEA) model is introduced by Sachs et al. [2022] as an interpolation between stochastic and adversarial online convex optimization. Under the smoothness condition, they demonstrate that the expected regret of optimistic follow-the-regularized-leader (FTRL) depends on the cumulative stochastic variance $\sigma_{1:T}^2$ and the cumulative adversarial variation $\Sigma_{1:T}^2$ for convex functions. They also provide a slightly weaker bound based on the maximal stochastic variance $\sigma_{\max}^2$ and the maximal adversarial variation $\Sigma_{\max}^2$ for strongly convex functions. Inspired by their work, we investigate the theoretical guarantees of optimistic online mirror descent (OMD) for the SEA model. For convex and smooth functions, we obtain the same $\mathcal{O}(\sqrt{\sigma_{1:T}^2}+\sqrt{\Sigma_{1:T}^2})$ regret bound, without the convexity requirement of individual functions. For strongly convex and smooth functions, we establish an $\mathc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#26694;&#26550;&#65292;&#20026;&#27599;&#20010;&#35266;&#27979;&#20540;&#25552;&#20379;&#31232;&#30095;&#30340;&#23616;&#37096;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#24182;&#23558;&#36825;&#20123;&#35268;&#21017;&#32858;&#21512;&#25104;&#21306;&#22495;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#20197;&#36866;&#24212;&#19981;&#31283;&#23450;&#30340;&#23454;&#29616;&#29615;&#22659;&#65292;&#24182;&#20135;&#29983;&#31283;&#20581;&#30340;&#25937;&#27982;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/2209.14568</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#21453;&#20107;&#23454;&#35299;&#37322;&#65306;&#20316;&#20026;&#23616;&#37096;&#21644;&#21306;&#22495;&#21453;&#20107;&#23454;&#25919;&#31574;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies. (arXiv:2209.14568v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#26694;&#26550;&#65292;&#20026;&#27599;&#20010;&#35266;&#27979;&#20540;&#25552;&#20379;&#31232;&#30095;&#30340;&#23616;&#37096;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#24182;&#23558;&#36825;&#20123;&#35268;&#21017;&#32858;&#21512;&#25104;&#21306;&#22495;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#20197;&#36866;&#24212;&#19981;&#31283;&#23450;&#30340;&#23454;&#29616;&#29615;&#22659;&#65292;&#24182;&#20135;&#29983;&#31283;&#20581;&#30340;&#25937;&#27982;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#35299;&#37322;&#65288;CE&#65289;&#38754;&#20020;&#30528;&#35768;&#22810;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#65292;&#22914;&#30830;&#20445;&#31283;&#23450;&#24615;&#12289;&#32508;&#21512;&#22810;&#20010;CE&#20197;&#21450;&#25552;&#20379;&#21512;&#29702;&#24615;&#21644;&#31232;&#30095;&#24615;&#20445;&#35777;&#12290;&#20174;&#26356;&#23454;&#38469;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#35268;&#23450;&#30340;&#21453;&#20107;&#23454;&#25937;&#27982;&#25514;&#26045;&#36890;&#24120;&#19981;&#20250;&#34987;&#20010;&#20307;&#23436;&#20840;&#23454;&#26045;&#65292;&#24182;&#35777;&#26126;&#22823;&#22810;&#25968;&#26368;&#20808;&#36827;&#30340;CE&#31639;&#27861;&#22312;&#36825;&#31181;&#22024;&#26434;&#30340;&#29615;&#22659;&#20013;&#24456;&#21487;&#33021;&#22833;&#36133;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#26694;&#26550;&#65292;&#20026;&#27599;&#20010;&#35266;&#27979;&#20540;&#25552;&#20379;&#31232;&#30095;&#30340;&#23616;&#37096;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#25552;&#20379;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#25913;&#21464;&#20915;&#31574;&#30340;&#20540;&#33539;&#22260;&#30340;&#35268;&#21017;&#12290;&#36825;&#20123;&#35268;&#21017;&#20316;&#20026;&#22810;&#26679;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#24635;&#32467;&#65292;&#24182;&#20135;&#29983;&#31283;&#20581;&#30340;&#25937;&#27982;&#25514;&#26045;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#36825;&#20123;&#23616;&#37096;&#35268;&#21017;&#32858;&#21512;&#25104;&#21306;&#22495;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#35782;&#21035;&#25968;&#25454;&#23376;&#32452;&#30340;&#20849;&#20139;&#25937;&#27982;&#25514;&#26045;&#12290;&#25105;&#20204;&#30340;&#23616;&#37096;&#21644;&#21306;&#22495;&#35268;&#21017;&#26469;&#33258;&#20110;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanations (CE) face several unresolved challenges, such as ensuring stability, synthesizing multiple CEs, and providing plausibility and sparsity guarantees. From a more practical point of view, recent studies [Pawelczyk et al., 2022] show that the prescribed counterfactual recourses are often not implemented exactly by individuals and demonstrate that most state-of-the-art CE algorithms are very likely to fail in this noisy environment. To address these issues, we propose a probabilistic framework that gives a sparse local counterfactual rule for each observation, providing rules that give a range of values capable of changing decisions with high probability. These rules serve as a summary of diverse counterfactual explanations and yield robust recourses. We further aggregate these local rules into a regional counterfactual rule, identifying shared recourses for subgroups of the data. Our local and regional rules are derived from the Random Forest algorithm, which of
&lt;/p&gt;</description></item></channel></rss>