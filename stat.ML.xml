<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#21487;&#24494;&#20998;AIS&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#31867;&#20284;&#20110;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#30340;&#37325;&#37319;&#26679;&#27493;&#39588;&#26469;&#36991;&#20813;&#31890;&#23376;&#28388;&#27874;&#20013;&#30340;&#26799;&#24230;&#26041;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.14390</link><description>&lt;p&gt;
&#21487;&#24494;&#20998;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#20013;&#30340;&#37325;&#37319;&#26679;&#26799;&#24230;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Resampling Gradients Vanish in Differentiable Sequential Monte Carlo Samplers. (arXiv:2304.14390v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14390
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#21487;&#24494;&#20998;AIS&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#31867;&#20284;&#20110;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#30340;&#37325;&#37319;&#26679;&#27493;&#39588;&#26469;&#36991;&#20813;&#31890;&#23376;&#28388;&#27874;&#20013;&#30340;&#26799;&#24230;&#26041;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36864;&#28779;&#37325;&#35201;&#24615;&#37319;&#26679;&#65288;AIS&#65289;&#26159;&#23558;&#31890;&#23376;&#27839;&#30528;&#19968;&#20010;&#39532;&#23572;&#31185;&#22827;&#38142;&#20174;&#21487;&#35745;&#31639;&#30340;&#21021;&#22987;&#20998;&#24067;&#31227;&#21160;&#21040;&#19981;&#21487;&#35745;&#31639;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#26368;&#36817;&#25552;&#20986;&#30340;&#21487;&#24494;&#20998;AIS&#65288;DAIS&#65289;&#20801;&#35768;&#23545;AIS&#30340;&#36716;&#31227;&#26680;&#21644;&#20998;&#24067;&#36827;&#34892;&#39640;&#25928;&#20248;&#21270;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;DAIS&#20013;&#23384;&#22312;&#20302;&#26377;&#25928;&#26679;&#26412;&#37327;&#65292;&#34920;&#26126;&#20998;&#24067;&#36864;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20511;&#37492;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#20010;&#37325;&#37319;&#26679;&#27493;&#39588;&#26469;&#25193;&#23637;DAIS&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#22312;&#32463;&#39564;&#19978;&#21457;&#29616;&#65292;&#20063;&#21487;&#20197;&#22312;&#29702;&#35770;&#19978;&#35299;&#37322;&#65292;&#26080;&#38656;&#36890;&#36807;&#37325;&#37319;&#26679;&#27493;&#39588;&#36827;&#34892;&#24494;&#20998;&#65292;&#36825;&#36991;&#20813;&#20102;&#31890;&#23376;&#28388;&#27874;&#20013;&#35266;&#23519;&#21040;&#30340;&#26799;&#24230;&#26041;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annealed Importance Sampling (AIS) moves particles along a Markov chain from a tractable initial distribution to an intractable target distribution. The recently proposed Differentiable AIS (DAIS) (Geffner and Domke, 2021; Zhang et al., 2021) enables efficient optimization of the transition kernels of AIS and of the distributions. However, we observe a low effective sample size in DAIS, indicating degenerate distributions. We thus propose to extend DAIS by a resampling step inspired by Sequential Monte Carlo. Surprisingly, we find empirically-and can explain theoretically-that it is not necessary to differentiate through the resampling step which avoids gradient variance issues observed in similar approaches for Particle Filters (Maddison et al., 2017; Naesseth et al., 2018; Le et al., 2018).
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20851;&#27880;&#19968;&#31181;&#38750;&#32447;&#24615;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65306;&#25193;&#25955;&#26144;&#23556;&#12290;&#26412;&#25991;&#38416;&#36848;&#22914;&#20309;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#19982;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2304.14378</link><description>&lt;p&gt;
&#21151;&#33021;&#25193;&#25955;&#26144;&#23556;
&lt;/p&gt;
&lt;p&gt;
Functional Diffusion Maps. (arXiv:2304.14378v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14378
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20851;&#27880;&#19968;&#31181;&#38750;&#32447;&#24615;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65306;&#25193;&#25955;&#26144;&#23556;&#12290;&#26412;&#25991;&#38416;&#36848;&#22914;&#20309;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#19982;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#21487;&#20197;&#34987;&#35270;&#20026;&#26159;&#21151;&#33021;&#24615;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#29983;&#25104;&#23427;&#20204;&#30340;&#36807;&#31243;&#26159;&#36830;&#32493;&#30340;&#12290;&#36825;&#31181;&#31867;&#22411;&#25968;&#25454;&#30340;&#19968;&#20010;&#22522;&#26412;&#29305;&#24615;&#26159;&#65292;&#29702;&#35770;&#19978;&#23427;&#20204;&#23646;&#20110;&#26080;&#38480;&#32500;&#31354;&#38388;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#36890;&#24120;&#21482;&#33021;&#24471;&#21040;&#26377;&#38480;&#25968;&#37327;&#30340;&#35266;&#23519;&#32467;&#26524;&#65292;&#23427;&#20204;&#20173;&#28982;&#26159;&#39640;&#32500;&#30340;&#65292;&#22240;&#27492;&#38477;&#32500;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#30340;&#20027;&#35201;&#29616;&#26377;&#26041;&#27861;&#26159;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#36825;&#31181;&#32463;&#20856;&#25216;&#26415;&#20551;&#35774;&#25968;&#25454;&#20301;&#20110;&#19968;&#20010;&#32447;&#24615;&#27969;&#24418;&#20013;&#65292;&#22240;&#27492;&#24403;&#36825;&#20010;&#20551;&#35774;&#19981;&#25104;&#31435;&#26102;&#21487;&#33021;&#20250;&#20986;&#29616;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#32858;&#28966;&#20110;&#19968;&#31181;&#38750;&#32447;&#24615;&#27969;&#24418;&#23398;&#20064;&#26041;&#27861;&#65306;&#25193;&#25955;&#26144;&#23556;&#12290;&#26412;&#25991;&#35299;&#37322;&#20102;&#22914;&#20309;&#23558;&#36825;&#31181;&#22810;&#21464;&#37327;&#26041;&#27861;&#25193;&#23637;&#21040;&#21151;&#33021;&#25968;&#25454;&#65292;&#24182;&#23558;&#20854;&#34892;&#20026;&#19982;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#22312;&#19981;&#21516;&#30340;&#27169;&#25311;&#21644;&#23454;&#38469;&#20363;&#23376;&#20013;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays many real-world datasets can be considered as functional, in the sense that the processes which generate them are continuous. A fundamental property of this type of data is that in theory they belong to an infinite-dimensional space. Although in practice we usually receive finite observations, they are still high-dimensional and hence dimensionality reduction methods are crucial. In this vein, the main state-of-the-art method for functional data analysis is Functional PCA. Nevertheless, this classic technique assumes that the data lie in a linear manifold, and hence it could have problems when this hypothesis is not fulfilled. In this research, attention has been placed on a non-linear manifold learning method: Diffusion Maps. The article explains how to extend this multivariate method to functional data and compares its behavior against Functional PCA over different simulated and real examples.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19977;&#27493;&#39588;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#30340;&#25512;&#23548;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2304.14251</link><description>&lt;p&gt;
&#31616;&#21270;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#25512;&#23548;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Variational Bayes Made Easy. (arXiv:2304.14251v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#19977;&#27493;&#39588;&#26041;&#27861;&#65292;&#31616;&#21270;&#20102;&#21464;&#20998;&#36125;&#21494;&#26031;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#30340;&#25512;&#23548;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#65292;&#20294;&#20854;&#25512;&#23548;&#36807;&#31243;&#21487;&#33021;&#24456;&#32321;&#29712;&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#20010;&#36807;&#31243;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#19977;&#27493;&#39588;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26174;&#24335;&#23547;&#25214;&#20851;&#20110;&#24050;&#30693;&#20998;&#24067;&#26399;&#26395;&#30340;&#32447;&#24615;&#24615;&#65292;&#26469;&#30830;&#23450;&#21518;&#39564;&#20998;&#24067;&#24418;&#24335;&#12290;&#28982;&#21518;&#25105;&#20204;&#21487;&#20197;&#30452;&#25509;&#36890;&#36807;&#8220;&#35835;&#21462;&#8221;&#36825;&#20123;&#26399;&#26395;&#21069;&#30340;&#39033;&#65292;&#20889;&#20986;&#26356;&#26032;&#12290;&#36825;&#20010;&#26041;&#27861;&#20351;&#24471;&#25512;&#23548;&#26356;&#21152;&#31616;&#21333;&#65292;&#24555;&#36895;&#65292;&#31616;&#30701;&#21644;&#36890;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational Bayes is a popular method for approximate inference but its derivation can be cumbersome. To simplify the process, we give a 3-step recipe to identify the posterior form by explicitly looking for linearity with respect to expectations of well-known distributions. We can then directly write the update by simply ``reading-off'' the terms in front of those expectations. The recipe makes the derivation easier, faster, shorter, and more general.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#35686;&#31034;&#25925;&#20107;&#38416;&#37322;&#20102;&#20998;&#26512;&#25968;&#25454;&#26102;&#65292;&#27979;&#37327;&#20960;&#20309;&#21644;&#24213;&#23618;&#29616;&#35937;&#20960;&#20309;&#24046;&#24322;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#36825;&#31181;&#24046;&#24322;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22914;&#20309;&#23548;&#33268;&#23545;&#19968;&#20010;&#20462;&#27491;&#36807;&#30340;&#38382;&#39064;&#32473;&#20986;&#38169;&#35823;&#31572;&#26696;&#12290;&#36825;&#20123;&#38382;&#39064;&#36866;&#29992;&#20110;&#38477;&#32500;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2304.14248</link><description>&lt;p&gt;
&#20851;&#20110;&#27931;&#20811;&#26031;&#27934;&#31348;&#30340;&#27969;&#24418;&#23398;&#20064;&#65306;&#20851;&#20110;&#27969;&#24418;&#23398;&#20064;&#21644;&#29289;&#29702;&#29616;&#35937;&#30340;&#35780;&#35770;&#65288;arXiv:2304.14248v1 [stat.ML]&#65289;
&lt;/p&gt;
&lt;p&gt;
On Manifold Learning in Plato's Cave: Remarks on Manifold Learning and Physical Phenomena. (arXiv:2304.14248v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#35686;&#31034;&#25925;&#20107;&#38416;&#37322;&#20102;&#20998;&#26512;&#25968;&#25454;&#26102;&#65292;&#27979;&#37327;&#20960;&#20309;&#21644;&#24213;&#23618;&#29616;&#35937;&#20960;&#20309;&#24046;&#24322;&#24102;&#26469;&#30340;&#38382;&#39064;&#65292;&#20197;&#21450;&#36825;&#31181;&#24046;&#24322;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#22914;&#20309;&#23548;&#33268;&#23545;&#19968;&#20010;&#20462;&#27491;&#36807;&#30340;&#38382;&#39064;&#32473;&#20986;&#38169;&#35823;&#31572;&#26696;&#12290;&#36825;&#20123;&#38382;&#39064;&#36866;&#29992;&#20110;&#38477;&#32500;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23581;&#35797;&#36890;&#36807;&#27979;&#37327;&#19981;&#38656;&#35201;&#23545;&#29289;&#29702;&#29616;&#35937;&#25110;&#27979;&#37327;&#35774;&#22791;&#36827;&#34892;&#26174;&#24335;&#24314;&#27169;&#30340;&#20302;&#32500;&#27969;&#24418;&#32467;&#26500;&#26469;&#25512;&#26029;&#28508;&#22312;&#29289;&#29702;&#29616;&#35937;&#30340;&#20302;&#32500;&#27969;&#24418;&#32467;&#26500;&#65292;&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#27979;&#37327;&#20960;&#20309;&#21644;&#24213;&#23618;&#29616;&#35937;&#20960;&#20309;&#20043;&#38388;&#24046;&#24322;&#30340;&#35686;&#31034;&#25925;&#20107;&#12290;&#22312;&#26222;&#36890;&#24773;&#20917;&#19979;&#65292;&#36825;&#31687;&#35770;&#25991;&#25152;&#23637;&#31034;&#30340;&#24230;&#37327;&#24418;&#21464;&#22312;&#25968;&#23398;&#19978;&#26159;&#30452;&#25509;&#32780;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#24182;&#19988;&#23427;&#21482;&#26159;&#25968;&#20010;&#31867;&#20284;&#25928;&#24212;&#20013;&#30340;&#19968;&#20010;&#12290;&#34429;&#28982;&#36825;&#24182;&#19981;&#24635;&#26159;&#20986;&#29616;&#38382;&#39064;&#65292;&#20294;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26631;&#20934;&#19988;&#26080;&#23475;&#25968;&#25454;&#22788;&#29702;&#36807;&#31243;&#30340;&#20363;&#23376;&#65292;&#20854;&#20013;&#36825;&#31181;&#24433;&#21709;&#23548;&#33268;&#23545;&#19968;&#20010;&#30475;&#20284;&#31616;&#21333;&#30340;&#38382;&#39064;&#32473;&#20986;&#20102;&#38169;&#35823;&#30340;&#31572;&#26696;&#12290;&#23613;&#31649;&#25105;&#20204;&#20851;&#27880;&#27969;&#24418;&#23398;&#20064;&#65292;&#20294;&#36825;&#20123;&#38382;&#39064;&#24191;&#27867;&#36866;&#29992;&#20110;&#38477;&#32500;&#21644;&#26080;&#30417;&#30563;&#23398;&#20064;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many techniques in machine learning attempt explicitly or implicitly to infer a low-dimensional manifold structure of an underlying physical phenomenon from measurements without an explicit model of the phenomenon or the measurement apparatus. This paper presents a cautionary tale regarding the discrepancy between the geometry of measurements and the geometry of the underlying phenomenon in a benign setting. The deformation in the metric illustrated in this paper is mathematically straightforward and unavoidable in the general case, and it is only one of several similar effects. While this is not always problematic, we provide an example of an arguably standard and harmless data processing procedure where this effect leads to an incorrect answer to a seemingly simple question. Although we focus on manifold learning, these issues apply broadly to dimensionality reduction and unsupervised learning.
&lt;/p&gt;</description></item><item><title>LLT&#26159;&#19968;&#20010;R&#21253;&#65292;&#29992;&#20110;&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#21464;&#25442;&#65292;&#21487;&#20197;&#24110;&#21161;&#23545;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2304.14211</link><description>&lt;p&gt;
LLT&#65306;&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#21464;&#25442;&#30340;R&#21253;
&lt;/p&gt;
&lt;p&gt;
LLT: An R package for Linear Law-based Feature Space Transformation. (arXiv:2304.14211v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14211
&lt;/p&gt;
&lt;p&gt;
LLT&#26159;&#19968;&#20010;R&#21253;&#65292;&#29992;&#20110;&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#21464;&#25442;&#65292;&#21487;&#20197;&#24110;&#21161;&#23545;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#36716;&#25442;(LLT )&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#24110;&#21161;&#23545;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#31867;&#12290;LLT R&#21253;&#20197;&#28789;&#27963;&#21644;&#29992;&#25143;&#21451;&#22909;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35813;&#31639;&#27861;&#12290;&#35813;&#21253;&#23558;&#23454;&#20363;&#20998;&#20026;&#35757;&#32451;&#21644;&#27979;&#35797;&#38598;&#65292;&#24182;&#21033;&#29992;&#26102;&#24310;&#23884;&#20837;&#21644;&#35889;&#20998;&#35299;&#25216;&#26415;&#65292;&#35782;&#21035;&#35757;&#32451;&#38598;&#20013;&#27599;&#20010;&#36755;&#20837;&#24207;&#21015;(&#21021;&#22987;&#29305;&#24449;)&#30340;&#25511;&#21046;&#27169;&#24335;(&#31216;&#20026;&#32447;&#24615;&#23450;&#24459;)&#12290;&#26368;&#21518;&#65292;&#23427;&#24212;&#29992;&#35757;&#32451;&#38598;&#30340;&#32447;&#24615;&#23450;&#24459;&#26469;&#36716;&#25442;&#27979;&#35797;&#38598;&#30340;&#21021;&#22987;&#29305;&#24449;&#12290;trainTest&#12289;trainLaw&#21644;testTrans&#19977;&#20010;&#21333;&#29420;&#30340;&#20989;&#25968;&#26469;&#25191;&#34892;&#36825;&#20123;&#27493;&#39588;&#65292;&#23427;&#20204;&#38656;&#35201;&#39044;&#23450;&#20041;&#30340;&#25968;&#25454;&#32467;&#26500;;&#28982;&#32780;&#65292;&#20026;&#20102;&#24555;&#36895;&#35745;&#31639;&#65292;&#23427;&#20204;&#21482;&#20351;&#29992;&#20869;&#32622;&#20989;&#25968;&#12290;LLT R&#21253;&#21644;&#36866;&#24403;&#25968;&#25454;&#32467;&#26500;&#30340;&#31034;&#20363;&#25968;&#25454;&#38598;&#22312;GitHub&#19978;&#20844;&#24320;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of the linear law-based feature space transformation (LLT) algorithm is to assist with the classification of univariate and multivariate time series. The presented R package, called LLT, implements this algorithm in a flexible yet user-friendly way. This package first splits the instances into training and test sets. It then utilizes time-delay embedding and spectral decomposition techniques to identify the governing patterns (called linear laws) of each input sequence (initial feature) within the training set. Finally, it applies the linear laws of the training set to transform the initial features of the test set. These steps are performed by three separate functions called trainTest, trainLaw, and testTrans. Their application requires a predefined data structure; however, for fast calculation, they use only built-in functions. The LLT R package and a sample dataset with the appropriate data structure are publicly available on GitHub.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#31639;&#27861;&#65292;&#20351;&#29992;&#33539;&#30068;&#35770;&#26500;&#36896;&#26469;&#23454;&#29616;&#30340;Brauer&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#20056;&#31215;&#65292;&#21516;&#26102;&#37319;&#29992;Kronecker&#31215;&#30697;&#38453;&#65292;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#20943;&#23569;&#12290;</title><link>http://arxiv.org/abs/2304.14165</link><description>&lt;p&gt;
&#19968;&#31181;&#35745;&#31639;Brauer&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Algorithm for Computing with Brauer's Group Equivariant Neural Network Layers. (arXiv:2304.14165v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#31639;&#27861;&#65292;&#20351;&#29992;&#33539;&#30068;&#35770;&#26500;&#36896;&#26469;&#23454;&#29616;&#30340;Brauer&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#20056;&#31215;&#65292;&#21516;&#26102;&#37319;&#29992;Kronecker&#31215;&#30697;&#38453;&#65292;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;arXiv&#65306;2212.08630&#20013;&#65292;&#23545;&#20171;&#20110;$\mathbb{R}^{n}$&#30340;&#24352;&#37327;&#24130;&#31354;&#38388;&#20043;&#38388;&#30340;&#21487;&#31561;&#21464;&#20110;&#27491;&#20132;&#32676;&#65292;$O(n)$&#65292;&#29305;&#27530;&#27491;&#20132;&#32676;&#65292;$SO(n)$&#65292;&#21644;&#36763;&#32676;&#65292;$Sp(n)$&#30340;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#23618;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20351;&#29992;&#33539;&#30068;&#35770;&#26500;&#36896;&#26469;&#23454;&#29616;&#36807;&#31243;&#65292;&#36890;&#36807;&#21033;&#29992;Kronecker&#31215;&#30697;&#38453;&#26469;&#25191;&#34892;&#20056;&#27861;&#65292;&#19982;&#31616;&#21333;&#30340;&#23454;&#29616;&#30456;&#27604;&#65292;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#25104;&#26412;&#20943;&#23569;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25193;&#23637;&#21040;&#23545;&#31216;&#32452;&#65292;$S_n$&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#24674;&#22797;&#20102;arXiv&#65306;2303.06208&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The learnable, linear neural network layers between tensor power spaces of $\mathbb{R}^{n}$ that are equivariant to the orthogonal group, $O(n)$, the special orthogonal group, $SO(n)$, and the symplectic group, $Sp(n)$, were characterised in arXiv:2212.08630. We present an algorithm for multiplying a vector by any weight matrix for each of these groups, using category theoretic constructions to implement the procedure. We achieve a significant reduction in computational cost compared with a naive implementation by making use of Kronecker product matrices to perform the multiplication. We show that our approach extends to the symmetric group, $S_n$, recovering the algorithm of arXiv:2303.06208 in the process.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#30340;&#31639;&#27861;&#65292;&#25104;&#21151;&#24555;&#36895;&#35745;&#31639;&#20102;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#32447;&#24615;&#23618;&#20989;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#20026;&#28145;&#24230;&#23398;&#20064;&#30340;&#20854;&#20182;&#39046;&#22495;&#20570;&#20986;&#20102;&#26377;&#30410;&#30340;&#25506;&#32034;&#12290;</title><link>http://arxiv.org/abs/2304.14144</link><description>&lt;p&gt;
&#20998;&#31867;&#21270;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Categorification of Group Equivariant Neural Networks. (arXiv:2304.14144v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#30340;&#31639;&#27861;&#65292;&#25104;&#21151;&#24555;&#36895;&#35745;&#31639;&#20102;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#32447;&#24615;&#23618;&#20989;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#20026;&#28145;&#24230;&#23398;&#20064;&#30340;&#20854;&#20182;&#39046;&#22495;&#20570;&#20986;&#20102;&#26377;&#30410;&#30340;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#33539;&#30068;&#35770;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19968;&#31181;&#26032;&#24212;&#29992;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#33539;&#30068;&#35770;&#26469;&#29702;&#35299;&#21644;&#22788;&#29702;&#32676;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#32447;&#24615;&#23618;&#20989;&#25968;&#65292;&#20854;&#20013;&#23618;&#26159;$\mathbb{R}^{n}$&#30340;&#26576;&#20123;&#24352;&#37327;&#24130;&#31354;&#38388;&#65292;&#23545;&#24212;&#20110;&#32676;$S_n$&#12289;$O(n)$&#12289;$Sp(n)$&#21644;$SO(n)$&#12290;&#36890;&#36807;&#20351;&#29992;&#33539;&#30068;&#35770;&#26500;&#24314;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#27604;&#36825;&#20123;&#31070;&#32463;&#32593;&#32476;&#30340;&#21407;&#22987;&#20844;&#24335;&#26356;&#20016;&#23500;&#30340;&#32467;&#26500;&#65292;&#24471;&#20986;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#27010;&#36848;&#20102;&#19968;&#31181;&#31639;&#27861;&#30340;&#24320;&#21457;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24555;&#36895;&#35745;&#31639;&#36890;&#36807;&#27599;&#20010;&#38382;&#39064;&#20013;&#30340;&#32676;&#31561;&#21464;&#32447;&#24615;&#23618;&#20256;&#36882;&#30340;&#21521;&#37327;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#25104;&#21151;&#34920;&#26126;&#65292;&#33539;&#30068;&#35770;&#21487;&#20197;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#20854;&#20182;&#39046;&#22495;&#26377;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel application of category theory for deep learning. We show how category theory can be used to understand and work with the linear layer functions of group equivariant neural networks whose layers are some tensor power space of $\mathbb{R}^{n}$ for the groups $S_n$, $O(n)$, $Sp(n)$, and $SO(n)$. By using category theoretic constructions, we build a richer structure that is not seen in the original formulation of these neural networks, leading to new insights. In particular, we outline the development of an algorithm for quickly computing the result of a vector that is passed through an equivariant, linear layer for each group in question. The success of our approach suggests that category theory could be beneficial for other areas of deep learning.
&lt;/p&gt;</description></item><item><title>SCARY&#25968;&#25454;&#38598;&#26159;&#19968;&#20010;&#20855;&#26377;&#32467;&#26500;&#22797;&#26434;&#24615;&#21644;&#38468;&#21152;&#29238;&#22240;&#26524;&#20851;&#31995;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;40&#20010;&#22330;&#26223;&#12289;&#19977;&#20010;&#19981;&#21516;&#30340;&#31181;&#23376;&#12289;&#32447;&#24615;&#21644;&#28151;&#21512;&#22240;&#26524;&#26426;&#21046;&#31561;&#29305;&#28857;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#30495;&#23454;&#30340;&#22240;&#26524;&#20851;&#31995;&#25506;&#32034;&#29615;&#22659;&#12290;</title><link>http://arxiv.org/abs/2304.14109</link><description>&lt;p&gt;
&#32467;&#26500;&#22797;&#26434;&#12289;&#20855;&#26377;&#38468;&#21152;&#29238;&#22240;&#26524;&#20851;&#31995;&#30340;SCARY&#25968;&#25454;&#38598;
&lt;/p&gt;
&lt;p&gt;
The Structurally Complex with Additive Parent Causality (SCARY) Dataset. (arXiv:2304.14109v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14109
&lt;/p&gt;
&lt;p&gt;
SCARY&#25968;&#25454;&#38598;&#26159;&#19968;&#20010;&#20855;&#26377;&#32467;&#26500;&#22797;&#26434;&#24615;&#21644;&#38468;&#21152;&#29238;&#22240;&#26524;&#20851;&#31995;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#65292;&#21253;&#21547;40&#20010;&#22330;&#26223;&#12289;&#19977;&#20010;&#19981;&#21516;&#30340;&#31181;&#23376;&#12289;&#32447;&#24615;&#21644;&#28151;&#21512;&#22240;&#26524;&#26426;&#21046;&#31561;&#29305;&#28857;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#30495;&#23454;&#30340;&#22240;&#26524;&#20851;&#31995;&#25506;&#32034;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#20851;&#31995;&#25968;&#25454;&#38598;&#22312;&#25512;&#21160;&#22240;&#26524;&#23398;&#39046;&#22495;&#26041;&#38754;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#25968;&#25454;&#38598;&#24448;&#24448;&#32570;&#20047;&#30495;&#23454;&#19990;&#30028;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#22914;&#36873;&#25321;&#20559;&#24046;&#12289;&#19981;&#24544;&#23454;&#25968;&#25454;&#21644;&#28151;&#28102;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#21512;&#25104;&#22240;&#26524;&#25968;&#25454;&#38598;&#65292;&#21363;&#32467;&#26500;&#22797;&#26434;&#12289;&#20855;&#26377;&#38468;&#21152;&#29238;&#22240;&#26524;&#20851;&#31995;&#30340;SCARY&#25968;&#25454;&#38598;&#65292;&#23427;&#21253;&#25324;&#20197;&#19979;&#29305;&#24449;&#12290;&#25968;&#25454;&#38598;&#21253;&#25324;40&#20010;&#22330;&#26223;&#65292;&#27599;&#20010;&#22330;&#26223;&#29983;&#25104;3&#20010;&#19981;&#21516;&#30340;&#31181;&#23376;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#21033;&#29992;&#30456;&#20851;&#25968;&#25454;&#23376;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#20004;&#31181;&#19981;&#21516;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#26469;&#29983;&#25104;&#29238;&#33410;&#28857;&#21644;&#23376;&#33410;&#28857;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#28151;&#21512;&#22240;&#26524;&#26426;&#21046;&#20197;&#21450;&#22810;&#20010;&#23376;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#25968;&#25454;&#38598;&#29983;&#25104;&#22120;&#21463;&#21040;&#22240;&#26524;&#21457;&#29616;&#24037;&#20855;&#31665;&#30340;&#21551;&#21457;&#65292;&#20165;&#29983;&#25104;&#21152;&#24615;&#27169;&#22411;&#12290;&#25968;&#25454;&#38598;&#30340;Varsortability&#20026;0.5&#12290;&#25105;&#20204;&#30340;SCARY&#25968;&#25454;&#38598;&#20026;&#30740;&#31350;&#20154;&#21592;&#22312;&#26356;&#29616;&#23454;&#30340;&#22330;&#26223;&#19979;&#25506;&#32034;&#22240;&#26524;&#21457;&#29616;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal datasets play a critical role in advancing the field of causality. However, existing datasets often lack the complexity of real-world issues such as selection bias, unfaithful data, and confounding. To address this gap, we propose a new synthetic causal dataset, the Structurally Complex with Additive paRent causalitY (SCARY) dataset, which includes the following features. The dataset comprises 40 scenarios, each generated with three different seeds, allowing researchers to leverage relevant subsets of the dataset. Additionally, we use two different data generation mechanisms for generating the causal relationship between parents and child nodes, including linear and mixed causal mechanisms with multiple sub-types. Our dataset generator is inspired by the Causal Discovery Toolbox and generates only additive models. The dataset has a Varsortability of 0.5. Our SCARY dataset provides a valuable resource for researchers to explore causal discovery under more realistic scenarios. The
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#20307;&#31995;&#65292;&#20026;&#39046;&#22495;&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#36981;&#24490;&#25152;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.14094</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#33539;&#30068;&#22522;&#30784;&#65306;&#19968;&#31181;&#32479;&#19968;&#30340;&#32467;&#26500;&#21644;&#35821;&#20041;&#24418;&#24335;&#20307;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#25552;&#20986;&#20102;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#20307;&#31995;&#65292;&#20026;&#39046;&#22495;&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#24418;&#24335;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#36981;&#24490;&#25152;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26088;&#22312;&#22238;&#31572;&#19982;AI&#27169;&#22411;&#37096;&#32626;&#30456;&#20851;&#30340;&#20262;&#29702;&#21644;&#27861;&#24459;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#30456;&#24403;&#25968;&#37327;&#30340;&#39046;&#22495;&#29305;&#23450;&#35780;&#35770;&#24378;&#35843;&#38656;&#35201;&#19968;&#20010;&#25968;&#23398;&#22522;&#30784;&#26469;&#23450;&#20041;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#27010;&#24565;&#65292;&#21363;&#20351;&#8220;&#35299;&#37322;&#8221;&#36825;&#20010;&#26415;&#35821;&#36824;&#32570;&#20047;&#31934;&#30830;&#23450;&#20041;&#12290;&#36825;&#20123;&#35780;&#35770;&#36824;&#20027;&#24352;&#24314;&#31435;&#19968;&#20010;&#20581;&#20840;&#32780;&#32479;&#19968;&#30340;&#21487;&#35299;&#37322;AI&#24418;&#24335;&#20307;&#31995;&#65292;&#20197;&#36991;&#20813;&#20986;&#29616;&#19981;&#33391;&#25552;&#20986;&#38382;&#39064;&#65292;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#27983;&#35272;&#19968;&#20010;&#24555;&#36895;&#22686;&#38271;&#30340;&#30693;&#35782;&#20307;&#31995;&#12290;&#25454;&#20316;&#32773;&#25152;&#30693;&#65292;&#35813;&#35770;&#25991;&#26159;&#22635;&#34917;&#35813;&#31354;&#30333;&#30340;&#39318;&#27425;&#23581;&#35797;&#65292;&#36890;&#36807;&#24418;&#24335;&#21270;&#19968;&#20010;&#21487;&#35299;&#37322;AI&#30340;&#32479;&#19968;&#29702;&#35770;&#12290;&#37319;&#29992;&#33539;&#30068;&#29702;&#35770;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#21453;&#39304;&#21333;&#35843;&#33539;&#30068;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;AI&#20013;&#25152;&#26377;&#37325;&#35201;&#26415;&#35821;&#30340;&#24418;&#24335;&#23450;&#20041;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36981;&#24490;&#25552;&#20986;&#32467;&#26500;&#30340;&#39046;&#22495;&#20998;&#31867;&#27861;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#24341;&#20837;&#30340;&#29702;&#35770;&#26469;&#23545;&#24403;&#21069;&#30740;&#31350;&#30340;&#25152;&#26377;&#20027;&#35201;XAI&#31995;&#32479;&#31867;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22522;&#20110;&#27010;&#24565;&#23884;&#20837;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;DCR&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#25552;&#39640;&#20102;&#39640;&#36798;+25&#65285;&#65292;&#24182;&#20135;&#29983;&#33021;&#22815;&#35299;&#37322;&#20854;&#39044;&#27979;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#21644;&#30495;&#20540;&#24230;&#65292;&#36866;&#24212;&#24615;&#24378;&#12290;</title><link>http://arxiv.org/abs/2304.14068</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31070;&#32463;&#31526;&#21495;&#27010;&#24565;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Interpretable Neural-Symbolic Concept Reasoning. (arXiv:2304.14068v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22522;&#20110;&#27010;&#24565;&#23884;&#20837;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;DCR&#65292;&#33021;&#22815;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#25552;&#39640;&#20102;&#39640;&#36798;+25&#65285;&#65292;&#24182;&#20135;&#29983;&#33021;&#22815;&#35299;&#37322;&#20854;&#39044;&#27979;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#21644;&#30495;&#20540;&#24230;&#65292;&#36866;&#24212;&#24615;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#39640;&#24230;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#23427;&#20204;&#19981;&#36879;&#26126;&#30340;&#20915;&#31574;&#36807;&#31243;&#38459;&#27490;&#20102;&#23427;&#20204;&#33719;&#24471;&#23436;&#20840;&#30340;&#20154;&#31867;&#20449;&#20219;&#12290;&#27010;&#24565;&#27169;&#22411;&#26088;&#22312;&#36890;&#36807;&#23398;&#20064;&#19968;&#32452;&#20154;&#31867;&#21487;&#29702;&#35299;&#30340;&#27010;&#24565;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#26368;&#20808;&#36827;&#30340;&#27010;&#24565;&#27169;&#22411;&#20381;&#36182;&#20110;&#39640;&#32500;&#27010;&#24565;&#23884;&#20837;&#34920;&#31034;&#65292;&#32570;&#20047;&#26126;&#30830;&#30340;&#35821;&#20041;&#21547;&#20041;&#65292;&#22240;&#27492;&#36136;&#30097;&#20854;&#20915;&#31574;&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Deep Concept Reasoner(DCR)&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22522;&#20110;&#27010;&#24565;&#23884;&#20837;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#12290;&#22312;DCR&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#19981;&#30452;&#25509;&#36827;&#34892;&#20219;&#21153;&#39044;&#27979;&#65292;&#32780;&#26159;&#20351;&#29992;&#27010;&#24565;&#23884;&#20837;&#24314;&#31435;&#35821;&#27861;&#35268;&#21017;&#32467;&#26500;&#12290;&#28982;&#21518;DCR&#22312;&#26377;&#24847;&#20041;&#30340;&#27010;&#24565;&#30495;&#20540;&#24230;&#19978;&#25191;&#34892;&#36825;&#20123;&#35268;&#21017;&#65292;&#20197;&#19981;&#21487;&#24494;&#20998;&#30340;&#26041;&#24335;&#25552;&#20379;&#26368;&#32456;&#30340;&#21487;&#35299;&#37322;&#21644;&#35821;&#20041;&#19968;&#33268;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;DCR&#65306;(i)&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#25509;&#36817;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#30456;&#23545;&#20110;&#26368;&#20808;&#36827;&#30340;&#21487;&#35299;&#37322;&#27010;&#24565;&#27169;&#22411;&#25552;&#39640;&#20102;&#39640;&#36798;+25&#65285;;(ii)&#20135;&#29983;&#33021;&#22815;&#35299;&#37322;&#20854;&#39044;&#27979;&#30340;&#20154;&#31867;&#21487;&#29702;&#35299;&#35268;&#21017;&#21644;&#30495;&#20540;&#24230;;(iii)&#24456;&#23481;&#26131;&#36866;&#24212;&#26032;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), the first interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner. Our experiments show that DCR: (i) improves up to +25% w.r.t. state-of-the-art interpretable concept-based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#32806;&#39640;&#26031;&#36807;&#31243;&#30340;&#27491;&#20132;&#20998;&#35299;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#21363;&#24341;&#20837;&#29699;&#24418;&#36328;&#22495;&#29305;&#24449;&#65292;&#26500;&#24314;&#26356;&#28789;&#27963;&#30340;&#25968;&#25454;&#20381;&#36182;&#22522;&#20989;&#25968;&#26469;&#32531;&#35299;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.14034</link><description>&lt;p&gt;
&#27491;&#20132;&#35299;&#32806;&#39640;&#26031;&#36807;&#31243;&#30340;&#29699;&#24418;&#24863;&#24212;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes. (arXiv:2304.14034v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#32806;&#39640;&#26031;&#36807;&#31243;&#30340;&#27491;&#20132;&#20998;&#35299;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#21363;&#24341;&#20837;&#29699;&#24418;&#36328;&#22495;&#29305;&#24449;&#65292;&#26500;&#24314;&#26356;&#28789;&#27963;&#30340;&#25968;&#25454;&#20381;&#36182;&#22522;&#20989;&#25968;&#26469;&#32531;&#35299;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#20855;&#26377;&#35768;&#22810;&#20248;&#28857;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#23398;&#20064;&#34920;&#24449;&#30340;&#33021;&#21147;&#65292;&#22240;&#27492;&#32463;&#24120;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#36827;&#34892;&#27604;&#36739;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#36890;&#36807;&#22312;&#35825;&#23548;&#21464;&#37327;&#19982;&#21069;&#39304;NN&#30340;&#38544;&#34255;&#21333;&#20803;&#20043;&#38388;&#24314;&#31435;&#32852;&#31995;&#30340;&#36328;&#22495;&#21464;&#20998;GPs&#26469;&#24357;&#21512; GPs&#21644;&#28145;&#24230;NN&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#22312;&#30740;&#31350;&#27492;&#26041;&#27861;&#19982;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#21033;&#29992;GPs&#30340;&#27491;&#20132;&#20998;&#35299;&#26469;&#20943;&#36731;&#36825;&#20123;&#38480;&#21046;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#29699;&#24418;&#36328;&#22495;&#29305;&#24449;&#65292;&#26500;&#24314;&#26356;&#28789;&#27963;&#30340;&#25968;&#25454;&#20381;&#36182;&#22522;&#20989;&#25968;&#65292;&#29992;&#20110;GP&#36924;&#36817;&#30340;&#20027;&#35201;&#21644;&#27491;&#20132;&#20998;&#37327;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#27492;&#26694;&#26550;&#19979;&#21152;&#20837;NN&#28608;&#27963;&#29305;&#24449;&#65292;&#19981;&#20165;&#21487;&#20197;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#32780;&#19988;&#27604;&#20854;&#20182;&#31574;&#30053;&#26356;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;Adam&#31639;&#27861;&#20570;&#20102;&#26032;&#30340;&#20551;&#35774;&#24182;&#36827;&#34892;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#22312;&#26356;&#21152;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#36798;&#21040;&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2304.13972</link><description>&lt;p&gt;
&#26494;&#24347;&#20551;&#35774;&#19979;Adam&#25910;&#25947;&#24615;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Convergence of Adam Under Relaxed Assumptions. (arXiv:2304.13972v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Adam&#31639;&#27861;&#20570;&#20102;&#26032;&#30340;&#20551;&#35774;&#24182;&#36827;&#34892;&#20102;&#35777;&#26126;&#65292;&#35777;&#26126;&#20102;&#22312;&#26356;&#21152;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#22815;&#20197;&#36739;&#23567;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;&#36798;&#21040;&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19968;&#31867;&#24191;&#27867;&#30340;&#20248;&#21270;&#30446;&#26631;&#65292;&#23545;&#33258;&#36866;&#24212;&#30697;&#20272;&#35745;&#65288;Adam&#65289;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#12290;&#34429;&#28982;Adam&#31639;&#27861;&#22312;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27969;&#34892;&#24230;&#21644;&#25928;&#29575;&#24456;&#39640;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#65292;&#29616;&#26377;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#38656;&#35201;&#36807;&#20110;&#24378;&#30340;&#20551;&#35774;&#65292;&#22914;&#20840;&#23616;&#26799;&#24230;&#26377;&#30028;&#65292;&#20197;&#35777;&#26126;&#25910;&#25947;&#21040;&#31283;&#23450;&#28857;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#26356;&#20026;&#29616;&#23454;&#30340;&#26465;&#20214;&#19979;&#65292;Adam&#33021;&#20197;$\mathcal{O}(\epsilon^{-4})$&#26799;&#24230;&#22797;&#26434;&#24230;&#25910;&#25947;&#21040;$\epsilon$-&#31283;&#23450;&#28857;&#12290;&#25105;&#20204;&#20998;&#26512;&#30340;&#20851;&#38190;&#26159;&#26681;&#25454;&#19968;&#31181;&#24191;&#20041;&#20809;&#28369;&#24615;&#20551;&#35774;&#32473;&#20986;&#30340;&#65292;&#27839;&#30528;&#20248;&#21270;&#36712;&#36857;&#30340;&#26799;&#24230;&#26377;&#30028;&#30340;&#26032;&#35777;&#26126;&#12290;&#26681;&#25454;&#35813;&#20551;&#35774;&#65292;&#23616;&#37096;&#20809;&#28369;&#24615;(&#21363;&#23384;&#22312;&#26102;&#30340;Hessian norm)&#21463;&#26799;&#24230;&#33539;&#25968;&#30340;&#27425;&#24179;&#26041;&#20989;&#25968;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#32422;&#20943;&#29256;&#26412;&#30340;Adam&#19982;&#21152;&#36895;Gradient&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we provide a rigorous proof of convergence of the Adaptive Moment Estimate (Adam) algorithm for a wide class of optimization objectives. Despite the popularity and efficiency of the Adam algorithm in training deep neural networks, its theoretical properties are not yet fully understood, and existing convergence proofs require unrealistically strong assumptions, such as globally bounded gradients, to show the convergence to stationary points. In this paper, we show that Adam provably converges to $\epsilon$-stationary points with $\mathcal{O}(\epsilon^{-4})$ gradient complexity under far more realistic conditions. The key to our analysis is a new proof of boundedness of gradients along the optimization trajectory, under a generalized smoothness assumption according to which the local smoothness (i.e., Hessian norm when it exists) is bounded by a sub-quadratic function of the gradient norm. Moreover, we propose a variance-reduced version of Adam with an accelerated gradien
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20844;&#24179;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#38024;&#23545;&#20844;&#24179;&#24863;&#30693;&#27169;&#22411;&#25552;&#20379;&#20102;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#26469;&#35780;&#20272;&#20854;&#27979;&#35797;&#19981;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13950</link><description>&lt;p&gt;
&#20844;&#24179;&#24615;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;: &#24744;&#26377;&#22810;&#22823;&#25226;&#25569;&#27169;&#22411;&#26159;&#20844;&#24179;&#30340;?
&lt;/p&gt;
&lt;p&gt;
Fairness Uncertainty Quantification: How certain are you that the model is fair?. (arXiv:2304.13950v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20844;&#24179;&#24615;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#38024;&#23545;&#20844;&#24179;&#24863;&#30693;&#27169;&#22411;&#25552;&#20379;&#20102;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#26469;&#35780;&#20272;&#20854;&#27979;&#35797;&#19981;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#30001;&#20110;&#26426;&#22120;&#23398;&#20064;&#22312;&#21496;&#27861;&#31995;&#32479;&#31561;&#25935;&#24863;&#24212;&#29992;&#20013;&#30340;&#24191;&#27867;&#20351;&#29992;&#65292;&#20844;&#24179;&#24863;&#30693;&#26426;&#22120;&#23398;&#20064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#25552;&#20986;&#20102;&#21508;&#31181;&#21551;&#21457;&#24335;&#21644;&#20248;&#21270;&#26694;&#26550;&#26469;&#24378;&#21046;&#23454;&#29616;&#20998;&#31867;&#20013;&#30340;&#20844;&#24179;&#24615;&#65292;&#20854;&#20013;&#21518;&#19968;&#31181;&#26041;&#27861;&#35201;&#20040;&#25552;&#20379;&#32463;&#39564;&#32467;&#26524;&#65292;&#35201;&#20040;&#20026;&#30446;&#26631;&#20989;&#25968;&#30340;&#31934;&#30830;&#26368;&#23567;&#21270;&#22120;&#25552;&#20379;&#20844;&#24179;&#24615;&#20445;&#35777;&#12290;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20960;&#20046;&#24635;&#26159;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31867;&#22411;&#30340;&#31639;&#27861;&#20316;&#20026;&#35757;&#32451;&#31639;&#27861;&#65292;&#36825;&#24847;&#21619;&#30528;&#23398;&#20064;&#30340;&#27169;&#22411;&#20197;&#21450;&#20854;&#20844;&#24179;&#24615;&#23646;&#24615;&#26159;&#38543;&#26426;&#30340;&#12290;&#22240;&#27492;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20851;&#38190;&#24212;&#29992;&#31243;&#24207;&#65292;&#24517;&#39035;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#20197;&#35780;&#20272;&#25152;&#23398;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20026;&#27979;&#35797;&#19981;&#20844;&#24179;&#24615;&#25552;&#20379;&#20102;&#32622;&#20449;&#21306;&#38388;&#65288;CI&#65289;&#65292;&#20855;&#20307;&#32780;&#35328;&#65292;&#26159;&#22312;&#32771;&#34385;&#21040;&#32676;&#20307;&#20844;&#24179;&#24615;&#30340;&#21069;&#25552;&#19979;&#65292;&#21363;&#24046;&#24322;&#24433;&#21709;&#65288;DI&#65289;&#21644;&#19981;&#20844;&#24179;&#24433;&#21709;&#65288;DM&#65289;&#24863;&#30693;&#30340;&#32447;&#24615;&#20108;&#20803;&#20998;&#31867;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fairness-aware machine learning has garnered significant attention in recent years because of extensive use of machine learning in sensitive applications like judiciary systems. Various heuristics, and optimization frameworks have been proposed to enforce fairness in classification \cite{del2020review} where the later approaches either provides empirical results or provides fairness guarantee for the exact minimizer of the objective function \cite{celis2019classification}. In modern machine learning, Stochastic Gradient Descent (SGD) type algorithms are almost always used as training algorithms implying that the learned model, and consequently, its fairness properties are random. Hence, especially for crucial applications, it is imperative to construct Confidence Interval (CI) for the fairness of the learned model. In this work we provide CI for test unfairness when a group-fairness-aware, specifically, Disparate Impact (DI), and Disparate Mistreatment (DM) aware linear binary classifi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#23548;-&#26368;&#23567;&#21270;&#21407;&#21017;&#65292;&#36890;&#36807;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#35299;&#20915;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;MMGN&#12290;&#36890;&#36807;&#24212;&#29992;&#39640;&#26031;-&#29275;&#39039;&#26041;&#27861;&#65292;MMGN&#20855;&#26377;&#26356;&#24555;&#30340;&#36895;&#24230;&#21644;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#19981;&#22826;&#21463;&#21040;&#28508;&#22312;&#30697;&#38453;&#23574;&#38160;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.13940</link><description>&lt;p&gt;
1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#30340;&#20027;&#23548;-&#26368;&#23567;&#21270;&#39640;&#26031;&#29275;&#39039;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Majorization-Minimization Gauss-Newton Method for 1-Bit Matrix Completion. (arXiv:2304.13940v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#23548;-&#26368;&#23567;&#21270;&#21407;&#21017;&#65292;&#36890;&#36807;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#35299;&#20915;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;MMGN&#12290;&#36890;&#36807;&#24212;&#29992;&#39640;&#26031;-&#29275;&#39039;&#26041;&#27861;&#65292;MMGN&#20855;&#26377;&#26356;&#24555;&#30340;&#36895;&#24230;&#21644;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#19981;&#22826;&#21463;&#21040;&#28508;&#22312;&#30697;&#38453;&#23574;&#38160;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#20013;&#65292;&#26088;&#22312;&#20174;&#37096;&#20998;&#20108;&#36827;&#21046;&#35266;&#27979;&#20540;&#20013;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;MMGN&#30340;1&#27604;&#29305;&#30697;&#38453;&#34917;&#20840;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20027;&#23548;-&#26368;&#23567;&#21270;&#65288;MM&#65289;&#21407;&#21017;&#65292;&#22312;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#20135;&#29983;&#19968;&#31995;&#21015;&#26631;&#20934;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#26126;&#30830;&#24378;&#21046;&#20551;&#23450;&#30340;&#20302;&#31209;&#32467;&#26500;&#30340;&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#36825;&#20123;&#23376;&#38382;&#39064;&#65292;&#28982;&#21518;&#24212;&#29992;&#39640;&#26031;-&#29275;&#39039;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#30740;&#31350;&#21644;&#23545;&#23454;&#38469;&#25968;&#25454;&#30340;&#24212;&#29992;&#34920;&#26126;&#65292;MMGN&#36755;&#20986;&#30340;&#20272;&#35745;&#32467;&#26524;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#36739;&#20855;&#26377;&#21487;&#27604;&#24615;&#19988;&#26356;&#20934;&#30830;&#12289;&#36895;&#24230;&#36890;&#24120;&#26356;&#24555;&#65292;&#24182;&#19988;&#23545;&#28508;&#22312;&#30697;&#38453;&#30340;&#23574;&#38160;&#24230;&#19981;&#22826;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1-bit matrix completion, the aim is to estimate an underlying low-rank matrix from a partial set of binary observations. We propose a novel method for 1-bit matrix completion called MMGN. Our method is based on the majorization-minimization (MM) principle, which yields a sequence of standard low-rank matrix completion problems in our setting. We solve each of these sub-problems by a factorization approach that explicitly enforces the assumed low-rank structure and then apply a Gauss-Newton method. Our numerical studies and application to a real-data example illustrate that MMGN outputs comparable if not more accurate estimates, is often significantly faster, and is less sensitive to the spikiness of the underlying matrix than existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#22810;&#20803;&#21644;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#26102;&#20934;&#30830;&#22320;&#26816;&#27979;&#21040;&#20004;&#20010;&#26679;&#26412;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#21253;&#21547;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#28151;&#21512;&#26435;&#37325;&#20294;&#30456;&#21516;&#32452;&#20998;&#20998;&#24067;&#30340;&#28151;&#21512;&#20998;&#24067;&#20551;&#35774;&#26469;&#22788;&#29702;&#24322;&#36136;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13848</link><description>&lt;p&gt;
&#38024;&#23545;&#24322;&#36136;&#24615;&#19979;&#30340;&#38750;&#21442;&#25968;&#20004;&#26679;&#26412;&#25512;&#26029;&#30340;&#33258;&#21161;&#36793;&#32536;&#35745;&#25968;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Bootstrapped Edge Count Tests for Nonparametric Two-Sample Inference Under Heterogeneity. (arXiv:2304.13848v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#22810;&#20803;&#21644;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#26102;&#20934;&#30830;&#22320;&#26816;&#27979;&#21040;&#20004;&#20010;&#26679;&#26412;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#21253;&#21547;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#28151;&#21512;&#26435;&#37325;&#20294;&#30456;&#21516;&#32452;&#20998;&#20998;&#24067;&#30340;&#28151;&#21512;&#20998;&#24067;&#20551;&#35774;&#26469;&#22788;&#29702;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#20004;&#26679;&#26412;&#26816;&#39564;&#26159;&#25512;&#26029;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#20010;&#32463;&#20856;&#38382;&#39064;&#12290;&#34429;&#28982;&#29616;&#20195;&#20004;&#26679;&#26412;&#26816;&#39564;&#65292;&#20363;&#22914;&#36793;&#32536;&#35745;&#25968;&#26816;&#39564;&#21450;&#20854;&#21464;&#20307;&#65292;&#21487;&#20197;&#22788;&#29702;&#22810;&#20803;&#21644;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#65292;&#20294;&#24403;&#19979;&#22823;&#22411;&#25968;&#25454;&#38598;&#30001;&#20110;&#23384;&#22312;&#28508;&#22312;&#30340;&#20122;&#31181;&#32676;&#32780;&#20855;&#26377;&#24322;&#36136;&#24615;&#12290;&#33509;&#19981;&#23545;&#36825;&#31181;&#24322;&#36136;&#24615;&#36827;&#34892;&#35843;&#33410;&#65292;&#30452;&#25509;&#24212;&#29992;&#36825;&#20123;&#26816;&#39564;&#21487;&#33021;&#20250;&#23548;&#33268;&#38169;&#35823;&#30340;&#32479;&#35745;&#20915;&#31574;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#26816;&#39564;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20013;&#23384;&#22312;&#26410;&#30693;&#24322;&#36136;&#24615;&#30340;&#24773;&#20917;&#19979;&#20934;&#30830;&#26816;&#27979;&#20004;&#20010;&#26679;&#26412;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#19968;&#20010;&#21253;&#21547;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#28151;&#21512;&#26435;&#37325;&#20294;&#30456;&#21516;&#32452;&#20998;&#20998;&#24067;&#30340;&#28151;&#21512;&#20998;&#24067;&#20551;&#35774;&#26469;&#22788;&#29702;&#36825;&#31181;&#28508;&#22312;&#24322;&#36136;&#24615;&#12290;&#22312;&#36825;&#20010;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21152;&#26435;&#36793;&#32536;&#35745;&#25968;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#34920;&#26126;&#23427;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#37325;&#26032;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonparametric two-sample testing is a classical problem in inferential statistics. While modern two-sample tests, such as the edge count test and its variants, can handle multivariate and non-Euclidean data, contemporary gargantuan datasets often exhibit heterogeneity due to the presence of latent subpopulations. Direct application of these tests, without regulating for such heterogeneity, may lead to incorrect statistical decisions. We develop a new nonparametric testing procedure that accurately detects differences between the two samples in the presence of unknown heterogeneity in the data generation process. Our framework handles this latent heterogeneity through a composite null that entertains the possibility that the two samples arise from a mixture distribution with identical component distributions but with possibly different mixing weights. In this regime, we study the asymptotic behavior of weighted edge count test statistic and show that it can be effectively re-calibrated 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#32500;&#25345;&#30452;&#35266;&#21560;&#24341;&#21147;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13833</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mixtures of Gaussian process experts based on kernel stick-breaking processes. (arXiv:2304.13833v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13833
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65292;&#33021;&#22815;&#32500;&#25345;&#30452;&#35266;&#21560;&#24341;&#21147;&#24182;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#65292;&#20855;&#26377;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#26159;&#19968;&#31867;&#33021;&#21516;&#26102;&#35299;&#20915;&#26631;&#20934;&#39640;&#26031;&#36807;&#31243;&#20013;&#23384;&#22312;&#30340;&#20004;&#20010;&#20851;&#38190;&#38480;&#21046;&#65306;&#21487;&#25193;&#23637;&#24615;&#21644;&#39044;&#27979;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;&#20351;&#29992;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#20316;&#20026;&#38376;&#20989;&#25968;&#30340;&#27169;&#22411;&#33021;&#22815;&#30452;&#35266;&#22320;&#35299;&#37322;&#21644;&#33258;&#21160;&#36873;&#25321;&#28151;&#21512;&#29289;&#20013;&#19987;&#23478;&#30340;&#25968;&#37327;&#12290;&#34429;&#28982;&#29616;&#26377;&#27169;&#22411;&#22312;&#24863;&#30693;&#38750;&#24179;&#31283;&#24615;&#12289;&#22810;&#27169;&#24615;&#21644;&#24322;&#26041;&#24046;&#24615;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#20854;&#38376;&#20989;&#25968;&#30340;&#31616;&#21333;&#24615;&#21487;&#33021;&#20250;&#38480;&#21046;&#22312;&#24212;&#29992;&#20110;&#22797;&#26434;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#26102;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#36817;&#22312;&#30456;&#20851;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#25991;&#29486;&#20013;&#30340;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26829;&#26834;&#36807;&#31243;&#30340;&#26032;&#22411;&#39640;&#26031;&#36807;&#31243;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20445;&#25345;&#30452;&#35266;&#21560;&#24341;&#21147;&#65292;&#21516;&#26102;&#25552;&#39640;&#29616;&#26377;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#20351;&#20854;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#21518;&#39564;&#35745;&#31639;&#30340;&#20999;&#29255;&#25277;&#26679;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixtures of Gaussian process experts is a class of models that can simultaneously address two of the key limitations inherent in standard Gaussian processes: scalability and predictive performance. In particular, models that use Dirichlet processes as gating functions permit straightforward interpretation and automatic selection of the number of experts in a mixture. While the existing models are intuitive and capable of capturing non-stationarity, multi-modality and heteroskedasticity, the simplicity of their gating functions may limit the predictive performance when applied to complex data-generating processes. Capitalising on the recent advancement in the dependent Dirichlet processes literature, we propose a new mixture model of Gaussian process experts based on kernel stick-breaking processes. Our model maintains the intuitive appeal yet improve the performance of the existing models. To make it practical, we design a sampler for posterior computation based on the slice sampling. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#21270;&#36172;&#21338;&#38382;&#39064;&#20013;&#23545;&#26680;&#20989;&#25968;&#35268;&#21017;&#24615;&#38169;&#35823;&#30340;&#33258;&#36866;&#24212;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#35268;&#21017;&#24615;&#30340;&#19968;&#23545;RKHS&#20013;&#21516;&#26102;&#23454;&#29616;&#26368;&#20339;&#32047;&#35745;&#36951;&#25022;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#24182;&#36890;&#36807;&#29616;&#26377;&#31639;&#27861;&#32467;&#21512;&#26497;&#23567;&#21270;&#38750;&#33258;&#36866;&#24212;&#30340;&#26680;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#39564;&#35777;&#20102;&#36825;&#19968;&#19979;&#38480;&#30340;&#32039;&#23494;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13830</link><description>&lt;p&gt;
&#26680;&#21270;&#36172;&#21338;&#26426;&#31639;&#27861;&#20013;&#23545;&#26680;&#20989;&#25968;&#35268;&#24459;&#24615;&#38169;&#35823;&#30340;&#33258;&#36866;&#24212;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adaptation to Misspecified Kernel Regularity in Kernelised Bandits. (arXiv:2304.13830v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13830
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#21270;&#36172;&#21338;&#38382;&#39064;&#20013;&#23545;&#26680;&#20989;&#25968;&#35268;&#21017;&#24615;&#38169;&#35823;&#30340;&#33258;&#36866;&#24212;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#35268;&#21017;&#24615;&#30340;&#19968;&#23545;RKHS&#20013;&#21516;&#26102;&#23454;&#29616;&#26368;&#20339;&#32047;&#35745;&#36951;&#25022;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#24182;&#36890;&#36807;&#29616;&#26377;&#31639;&#27861;&#32467;&#21512;&#26497;&#23567;&#21270;&#38750;&#33258;&#36866;&#24212;&#30340;&#26680;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#39564;&#35777;&#20102;&#36825;&#19968;&#19979;&#38480;&#30340;&#32039;&#23494;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#27494;&#35013;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#22914;&#26524;&#24213;&#23618;&#20989;&#25968;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#65292;&#21363;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#26159;&#65292;&#22914;&#26524;&#30456;&#20851;&#30340;&#26680;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#26159;&#26410;&#30693;&#30340;&#65292;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#22810;&#20040;&#22909;&#22320;&#36866;&#24212;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24179;&#31227;&#19981;&#21464;&#26680;&#35268;&#21017;&#24615;&#30340;&#33258;&#36866;&#24212;&#24615;&#65292;&#22312;&#36172;&#21338;&#35774;&#32622;&#20013;&#65292;&#35813;&#35268;&#21017;&#24615;&#30001;&#26680;&#30340;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#34928;&#20943;&#29575;&#25152;&#25551;&#36848;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#24615;&#30340;&#19979;&#38480;&#65292;&#35777;&#26126;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#35268;&#21017;&#24615;&#30340;&#19968;&#23545;RKHS&#20013;&#21516;&#26102;&#23454;&#29616;&#26368;&#20339;&#32047;&#35745;&#36951;&#25022;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#20026;&#20102;&#39564;&#35777;&#36825;&#20010;&#19979;&#38480;&#30340;&#32039;&#23494;&#24615;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#29616;&#26377;&#30340;&#36172;&#21338;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#19982;&#26497;&#23567;&#21270;&#38750;&#33258;&#36866;&#24212;&#30340;&#26680;&#36172;&#21338;&#26426;&#31639;&#27861;&#30456;&#32467;&#21512;&#65292;&#22312;&#24635;&#27493;&#25968;T&#30340;&#20381;&#36182;&#19979;&#21305;&#37197;&#20102;&#19979;&#38480;&#65292;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#12290;&#36890;&#36807;&#22635;&#20889;RKHS&#20043;&#38388;&#36866;&#24212;&#24615;&#30340;&#36951;&#25022;&#30028;&#65292;&#25105;&#20204;&#36830;&#25509;&#20102;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
In continuum-armed bandit problems where the underlying function resides in a reproducing kernel Hilbert space (RKHS), namely, the kernelised bandit problems, an important open problem remains of how well learning algorithms can adapt if the regularity of the associated kernel function is unknown. In this work, we study adaptivity to the regularity of translation-invariant kernels, which is characterized by the decay rate of the Fourier transformation of the kernel, in the bandit setting. We derive an adaptivity lower bound, proving that it is impossible to simultaneously achieve optimal cumulative regret in a pair of RKHSs with different regularities. To verify the tightness of this lower bound, we show that an existing bandit model selection algorithm applied with minimax non-adaptive kernelised bandit algorithms matches the lower bound in dependence of $T$, the total number of steps, except for log factors. By filling in the regret bounds for adaptivity between RKHSs, we connect the
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#26102;&#38388;&#31354;&#38388;&#25968;&#25454;&#20013;&#20381;&#36182;&#20851;&#31995;&#30340;&#24191;&#20041;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GGLM&#65289;&#21442;&#25968;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#20351;&#29992;&#21333;&#35843;&#36816;&#31639;&#31526;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#26041;&#27861;&#20811;&#26381;&#20102;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#38750;&#20984;&#24615;&#24182;&#20026;&#21442;&#25968;&#24674;&#22797;&#25552;&#20379;&#20445;&#35777;</title><link>http://arxiv.org/abs/2304.13793</link><description>&lt;p&gt;
&#24191;&#20041;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65306;&#20984;&#20272;&#35745;&#21644;&#22312;&#32447;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalized generalized linear models: Convex estimation and online bounds. (arXiv:2304.13793v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13793
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#26102;&#38388;&#31354;&#38388;&#25968;&#25454;&#20013;&#20381;&#36182;&#20851;&#31995;&#30340;&#24191;&#20041;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GGLM&#65289;&#21442;&#25968;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#20351;&#29992;&#21333;&#35843;&#36816;&#31639;&#31526;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#26041;&#27861;&#20811;&#26381;&#20102;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#38750;&#20984;&#24615;&#24182;&#20026;&#21442;&#25968;&#24674;&#22797;&#25552;&#20379;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#35745;&#24191;&#20041;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GGLM&#65289;&#20013;&#30340;&#21442;&#25968;&#12290;&#36825;&#26159;&#19968;&#31867;&#23558;&#27969;&#34892;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLM&#65289;&#25193;&#23637;&#21040;&#32771;&#34385;&#26102;&#31354;&#25968;&#25454;&#20013;&#35266;&#27979;&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#27169;&#22411;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;&#21333;&#35843;&#36816;&#31639;&#31526;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#26041;&#27861;&#26469;&#20811;&#26381;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#38750;&#20984;&#24615;&#24182;&#20026;&#21442;&#25968;&#24674;&#22797;&#25552;&#20379;&#20445;&#35777;&#12290;&#32467;&#26524;&#21487;&#20197;&#24212;&#29992;&#20110;GLM&#21644;GGLM&#65292;&#37325;&#28857;&#20851;&#27880;&#26102;&#31354;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#38789;&#38598;&#20013;&#19981;&#31561;&#24335;&#25552;&#20379;&#20102;&#22312;&#32447;&#23454;&#20363;&#30028;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#25968;&#20540;&#27169;&#25311;&#21644;&#37326;&#28779;&#20107;&#20214;&#30340;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#26469;&#23637;&#31034;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new computational framework for estimating parameters in generalized generalized linear models (GGLM), a class of models that extends the popular generalized linear models (GLM) to account for dependencies among observations in spatio-temporal data. The proposed approach uses a monotone operator-based variational inequality method to overcome non-convexity in parameter estimation and provide guarantees for parameter recovery. The results can be applied to GLM and GGLM, focusing on spatio-temporal models. We also present online instance-based bounds using martingale concentrations inequalities. Finally, we demonstrate the performance of the algorithm using numerical simulations and a real data example for wildfire incidents.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#34920;&#26126;&#23545;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#36827;&#34892;&#25311;&#21512;&#21487;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13761</link><description>&lt;p&gt;
&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing Robustness of Gradient-Boosted Decision Trees through One-Hot Encoding and Regularization. (arXiv:2304.13761v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13761
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#29420;&#28909;&#32534;&#30721;&#21644;&#27491;&#21017;&#21270;&#25552;&#39640;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#30340;&#40065;&#26834;&#24615;&#65292;&#30740;&#31350;&#34920;&#26126;&#23545;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#36827;&#34892;&#25311;&#21512;&#21487;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;(GBDT)&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#39640;&#25928;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22797;&#26434;&#30340;&#32467;&#26500;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#23545;&#26410;&#35265;&#25968;&#25454;&#20013;&#30340;&#23567;&#21327;&#21464;&#37327;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#36739;&#20302;&#12290;&#26412;&#30740;&#31350;&#24212;&#29992;&#29420;&#28909;&#32534;&#30721;&#23558;GBDT&#27169;&#22411;&#36716;&#25442;&#20026;&#32447;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#27599;&#20010;&#26641;&#21494;&#32534;&#30721;&#20026;&#19968;&#20010;&#34394;&#25311;&#21464;&#37327;&#12290;&#36825;&#20801;&#35768;&#20351;&#29992;&#32447;&#24615;&#22238;&#24402;&#25216;&#26415;&#65292;&#20197;&#21450;&#19968;&#31181;&#26032;&#39062;&#30340;&#39118;&#38505;&#20998;&#35299;&#26041;&#27861;&#26469;&#35780;&#20272;GBDT&#27169;&#22411;&#23545;&#21327;&#21464;&#37327;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#37325;&#26032;&#25311;&#21512;&#20854;&#24102;&#26377;$L_1$&#25110;$L_2$&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#22238;&#24402;&#24418;&#24335;&#65292;&#25552;&#39640;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#20102;&#27491;&#21017;&#21270;&#23545;&#27169;&#22411;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#30340;&#24433;&#21709;&#12290;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#29420;&#28909;&#32534;&#30721;GBDT&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-boosted decision trees (GBDT) are widely used and highly effective machine learning approach for tabular data modeling. However, their complex structure may lead to low robustness against small covariate perturbation in unseen data. In this study, we apply one-hot encoding to convert a GBDT model into a linear framework, through encoding of each tree leaf to one dummy variable. This allows for the use of linear regression techniques, plus a novel risk decomposition for assessing the robustness of a GBDT model against covariate perturbations. We propose to enhance the robustness of GBDT models by refitting their linear regression forms with $L_1$ or $L_2$ regularization. Theoretical results are obtained about the effect of regularization on the model performance and robustness. It is demonstrated through numerical experiments that the proposed regularization approach can enhance the robustness of the one-hot-encoded GBDT models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;TR0N&#65292;&#23558;&#39044;&#35757;&#32451;&#30340;&#26080;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#36716;&#21270;&#20026;&#39640;&#24230;&#20219;&#24847;&#30340;&#26465;&#20214;&#27169;&#22411;&#12290;TR0N&#19981;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#25110;&#24494;&#35843;&#65292;&#21487;&#20197;&#22312;MS-COCO&#19978;&#23454;&#29616;&#38646;-shot FID 10.9&#65292;&#24182;&#22312;&#37319;&#26679;&#36895;&#24230;&#19978;&#20248;&#20110;&#31454;&#21697;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#22810;&#26679;&#24615;&#21644;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.13742</link><description>&lt;p&gt;
TR0N&#65306;0-Shot&#21363;&#25554;&#21363;&#29992;&#26465;&#20214;&#29983;&#25104;&#30340;&#32763;&#35793;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation. (arXiv:2304.13742v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;TR0N&#65292;&#23558;&#39044;&#35757;&#32451;&#30340;&#26080;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#36716;&#21270;&#20026;&#39640;&#24230;&#20219;&#24847;&#30340;&#26465;&#20214;&#27169;&#22411;&#12290;TR0N&#19981;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#25110;&#24494;&#35843;&#65292;&#21487;&#20197;&#22312;MS-COCO&#19978;&#23454;&#29616;&#38646;-shot FID 10.9&#65292;&#24182;&#22312;&#37319;&#26679;&#36895;&#24230;&#19978;&#20248;&#20110;&#31454;&#21697;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#22810;&#26679;&#24615;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;TR0N&#65292;&#19968;&#20010;&#39640;&#24230;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#39044;&#35757;&#32451;&#30340;&#26080;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#22914;GAN&#21644;VAE&#65292;&#36716;&#25442;&#20026;&#26465;&#20214;&#27169;&#22411;&#12290;&#26465;&#20214;&#21487;&#20197;&#26159;&#39640;&#24230;&#20219;&#24847;&#30340;&#65292;&#24182;&#19988;&#20165;&#38656;&#35201;&#39044;&#35757;&#32451;&#30340;&#36741;&#21161;&#27169;&#22411;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#20998;&#31867;&#22120;&#23558;&#26080;&#26465;&#20214;&#27169;&#22411;&#36716;&#21270;&#20026;&#31867;&#21035;&#26465;&#20214;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;CLIP&#23558;&#20854;&#36716;&#21270;&#20026;&#25991;&#26412;&#21040;&#22270;&#20687;&#27169;&#22411;&#12290;TR0N&#23398;&#20064;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#30340;&#38543;&#26426;&#26144;&#23556;&#65292;&#35813;&#26144;&#23556;&#22312;&#26465;&#20214;&#31354;&#38388;&#21644;&#29983;&#25104;&#27169;&#22411;&#30340;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#8220;&#32763;&#35793;&#8221;&#65292;&#20351;&#24471;&#29983;&#25104;&#30340;&#28508;&#22312;&#31354;&#38388;&#23545;&#24212;&#20110;&#28385;&#36275;&#25152;&#38656;&#26465;&#20214;&#30340;&#25968;&#25454;&#26679;&#26412;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;Langevin&#21160;&#24577;&#36827;&#19968;&#27493;&#25913;&#36827;&#32763;&#35793;&#21518;&#30340;&#28508;&#22312;&#26679;&#26412;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#26356;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#26679;&#26412;&#12290;TR0N&#19981;&#38656;&#35201;&#35757;&#32451;&#25968;&#25454;&#25110;&#24494;&#35843;&#65292;&#20294;&#21487;&#20197;&#22312;MS-COCO&#19978;&#23454;&#29616;&#38646;-shot FID 10.9&#65292;&#19981;&#20165;&#22312;&#36825;&#20010;&#25351;&#26631;&#19978;&#20248;&#20110;&#31454;&#21697;&#65292;&#32780;&#19988;&#22312;&#37319;&#26679;&#36895;&#24230;&#19978;&#20063;&#19982;&#20854;&#20445;&#25345;&#20102;&#22810;&#26679;&#24615;&#21644;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose TR0N, a highly general framework to turn pre-trained unconditional generative models, such as GANs and VAEs, into conditional models. The conditioning can be highly arbitrary, and requires only a pre-trained auxiliary model. For example, we show how to turn unconditional models into class-conditional ones with the help of a classifier, and also into text-to-image models by leveraging CLIP. TR0N learns a lightweight stochastic mapping which "translates" between the space of conditions and the latent space of the generative model, in such a way that the generated latent corresponds to a data sample satisfying the desired condition. The translated latent samples are then further improved upon through Langevin dynamics, enabling us to obtain higher-quality data samples. TR0N requires no training data nor fine-tuning, yet can achieve a zero-shot FID of 10.9 on MS-COCO, outperforming competing alternatives not only on this metric, but also in sampling speed -- all while retaining 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13534</link><description>&lt;p&gt;
&#29992;&#22343;&#22330;&#21338;&#24328;&#20026;&#29983;&#25104;&#27169;&#22411;&#25645;&#24314;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
A mean-field games laboratory for generative modeling. (arXiv:2304.13534v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#22343;&#22330;&#21338;&#24328;&#20316;&#20026;&#23454;&#39564;&#23460;&#23545;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35774;&#35745;&#21644;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36825;&#31181;&#26041;&#27861;&#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#36890;&#36807;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#19982;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#25552;&#39640;&#26679;&#26412;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24230;&#30340;&#21516;&#26102;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22343;&#22330;&#21338;&#24328; (MFGs) &#20316;&#20026;&#19968;&#31181;&#25968;&#23398;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#12289;&#22686;&#24378;&#21644;&#35774;&#35745;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102; MFGs &#19982;&#20027;&#35201;&#27969;&#21160;&#21644;&#25193;&#25955;&#22411;&#29983;&#25104;&#27169;&#22411;&#20043;&#38388;&#20851;&#32852;&#65292;&#24182;&#36890;&#36807;&#19981;&#21516;&#30340;&#31890;&#23376;&#21160;&#21147;&#23398;&#21644;&#20195;&#20215;&#20989;&#25968;&#25512;&#23548;&#20102;&#36825;&#19977;&#20010;&#31867;&#21035;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#23427;&#20204;&#30456;&#20851;&#30340; MFG &#30340;&#26368;&#20248;&#26465;&#20214;&#8212;&#8212;&#19968;&#32452;&#32806;&#21512;&#30340;&#38750;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#65292;&#26469;&#30740;&#31350;&#27599;&#20010;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#23398;&#32467;&#26500;&#21644;&#29305;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20110;&#21452;&#20154; MFG &#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#21512;&#25104;&#26679;&#26412;&#65292;&#21478;&#19968;&#20010;&#20195;&#29702;&#23545;&#26679;&#26412;&#36827;&#34892;&#35782;&#21035;&#65292;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#22810;&#26679;&#19988;&#36924;&#30495;&#65292;&#21516;&#26102;&#19982;&#22522;&#20934;&#27169;&#22411;&#30456;&#27604;&#65292;&#25913;&#21892;&#20102;&#35299;&#32544;&#32467;&#21644;&#20844;&#24179;&#24615;&#12290;&#24635;&#20043;&#65292;&#26412;&#25991;&#31361;&#26174;&#20102; MFGs &#20316;&#20026;&#35774;&#35745;&#21644;&#20998;&#26512;&#29983;&#25104;&#27169;&#22411;&#30340;&#23454;&#39564;&#23460;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we demonstrate the versatility of mean-field games (MFGs) as a mathematical framework for explaining, enhancing, and designing generative models. There is a pervasive sense in the generative modeling community that the various flow and diffusion-based generative models have some foundational common structure and interrelationships. We establish connections between MFGs and major classes of flow and diffusion-based generative models including continuous-time normalizing flows, score-based models, and Wasserstein gradient flows. We derive these three classes of generative models through different choices of particle dynamics and cost functions. Furthermore, we study the mathematical structure and properties of each generative model by studying their associated MFG's optimality condition, which is a set of coupled nonlinear partial differential equations (PDEs). The theory of MFGs, therefore, enables the study of generative models through the theory of nonlinear PDEs. Throu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411; (N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#21487;&#20197;&#23545;&#36830;&#32493;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17823</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#36830;&#32493;&#22238;&#24212;&#26377;&#24207;&#22238;&#24402;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
An interpretable neural network-based non-proportional odds model for ordinal regression with continuous response. (arXiv:2303.17823v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17823
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411; (N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#21487;&#20197;&#23545;&#36830;&#32493;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21487;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#27604;&#20363;&#36180;&#29575;&#27169;&#22411;&#65288;N$^3$POM) &#29992;&#20110;&#26377;&#24207;&#22238;&#24402;&#65292;&#20854;&#20013;&#21453;&#24212;&#21464;&#37327;&#19981;&#20165;&#21487;&#20197;&#21462;&#31163;&#25955;&#20540;&#65292;&#20063;&#21487;&#20197;&#21462;&#36830;&#32493;&#20540;&#65292;&#32780;&#22238;&#24402;&#31995;&#25968;&#26681;&#25454;&#39044;&#27979;&#39034;&#24207;&#21453;&#24212;&#20063;&#19981;&#21516;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30452;&#25509;&#20174;&#31163;&#25955;&#21453;&#24212;&#20272;&#35745;&#32447;&#24615;&#31995;&#25968;&#19981;&#21516;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#20197;&#21453;&#24212;&#20026;&#36755;&#20837;&#20135;&#29983;&#32447;&#24615;&#31995;&#25968;&#12290;&#30001;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#65292;N$^3$POM&#21487;&#20197;&#22312;&#20445;&#30041;&#20256;&#32479;&#26377;&#24207;&#22238;&#24402;&#30340;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#20351;&#24471;&#22312;&#25351;&#23450;&#30340;&#29992;&#25143;&#21306;&#22495;&#20869;&#65292;&#39044;&#27979;&#30340;&#26465;&#20214;&#32047;&#31215;&#27010;&#29575;&#65288;CCP&#65289;&#28385;&#36275;&#23616;&#37096;&#21333;&#35843;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#20445;&#25345;&#21333;&#35843;&#24615;&#30340;&#38543;&#26426;&#65288;MPS&#65289;&#31639;&#27861;&#26469;&#20805;&#20998;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an interpretable neural network-based non-proportional odds model (N$^3$POM) for ordinal regression, where the response variable can take not only discrete but also continuous values, and the regression coefficients vary depending on the predicting ordinal response. In contrast to conventional approaches estimating the linear coefficients of regression directly from the discrete response, we train a non-linear neural network that outputs the linear coefficients by taking the response as its input. By virtue of the neural network, N$^3$POM may have flexibility while preserving the interpretability of the conventional ordinal regression. We show a sufficient condition so that the predicted conditional cumulative probability~(CCP) satisfies the monotonicity constraint locally over a user-specified region in the covariate space; we also provide a monotonicity-preserving stochastic (MPS) algorithm for training the neural network adequately.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;HealthSyn&#29983;&#25104;&#22522;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#31227;&#21160;&#20581;&#24247;&#24178;&#39044;&#25968;&#25454;&#65292;&#20197;&#24110;&#21161;&#22312;&#20840;&#29699;&#21355;&#29983;&#39046;&#22495;&#20013;&#21457;&#23637;&#12289;&#27979;&#35797;&#21644;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#24178;&#39044;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/2303.01954</link><description>&lt;p&gt;
&#22312;&#20840;&#29699;&#21355;&#29983;&#39046;&#22495;&#20013;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#22120;
&lt;/p&gt;
&lt;p&gt;
Synthetic Data Generator for Adaptive Interventions in Global Health. (arXiv:2303.01954v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01954
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;HealthSyn&#29983;&#25104;&#22522;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#31227;&#21160;&#20581;&#24247;&#24178;&#39044;&#25968;&#25454;&#65292;&#20197;&#24110;&#21161;&#22312;&#20840;&#29699;&#21355;&#29983;&#39046;&#22495;&#20013;&#21457;&#23637;&#12289;&#27979;&#35797;&#21644;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#21644;&#25968;&#23383;&#20581;&#24247;&#26377;&#26395;&#25913;&#21464;&#20840;&#29699;&#21355;&#29983;&#29366;&#20917;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#30340;&#29983;&#20135;&#29615;&#22659;&#20013;&#36827;&#34892;&#31639;&#27861;&#27979;&#35797;&#21644;&#39564;&#35777;&#30340;&#20851;&#38190;&#26159;&#33021;&#22815;&#35775;&#38382;&#20195;&#34920;&#24615;&#25968;&#25454;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;HealthSyn&#65292;&#19968;&#20010;&#24320;&#28304;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#22120;&#65292;&#29992;&#20110;&#27979;&#35797;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#21450;&#22312;&#31227;&#21160;&#20581;&#24247;&#24178;&#39044;&#20013;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#65288;&#20363;&#22914;&#25552;&#37266;&#12289;&#25512;&#33616;&#21644;&#28608;&#21169;&#65289;&#12290;&#29983;&#25104;&#22120;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#29983;&#25104;&#22810;&#26679;&#21270;&#30340;&#29992;&#25143;&#34892;&#20026;&#65292;&#20855;&#26377;&#20010;&#20307;&#29992;&#25143;&#34892;&#20026;&#27169;&#24335;&#65292;&#21487;&#20197;&#26681;&#25454;&#20010;&#24615;&#21270;&#24178;&#39044;&#32780;&#25913;&#21464;&#12290;&#36825;&#20123;&#34892;&#20026;&#36716;&#21270;&#20026;&#23454;&#38469;&#26085;&#24535;&#65292;&#20351;&#29992;ML&#19987;&#29992;&#30340;&#25968;&#25454;&#27169;&#24335;&#65292;&#29305;&#23450;&#20110;HealthKit&#19982;&#24320;&#28304;SDK&#20013;&#21253;&#21547;&#30340;&#31227;&#21160;&#20581;&#24247;&#24212;&#29992;&#31243;&#24207;&#21151;&#33021;&#12290;&#36825;&#20123;&#26085;&#24535;&#21487;&#20197;&#25552;&#20379;&#29992;&#25143;&#25351;&#26631;&#12290;&#22522;&#20110;&#30495;&#23454;&#19990;&#30028;&#30340;&#34892;&#20026;&#21644;&#27169;&#25311;&#25216;&#26415;&#29983;&#25104;&#30340;&#25968;&#25454;&#65292;&#21487;&#20197;&#20197;&#25104;&#26412;&#25928;&#30410;&#21644;&#20445;&#25252;&#38544;&#31169;&#30340;&#26041;&#24335;&#36827;&#34892;&#24320;&#21457;&#12289;&#27979;&#35797;&#21644;&#35780;&#20272;&#65292;&#21516;&#26102;&#35780;&#20272;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21644;&#24178;&#39044;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence and digital health have the potential to transform global health. However, having access to representative data to test and validate algorithms in realistic production environments is essential. We introduce HealthSyn, an open-source synthetic data generator of user behavior for testing reinforcement learning algorithms in the context of mobile health interventions. The generator utilizes Markov processes to generate diverse user actions, with individual user behavioral patterns that can change in reaction to personalized interventions (i.e., reminders, recommendations, and incentives). These actions are translated into actual logs using an ML-purposed data schema specific to the mobile health application functionality included with HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain user metrics. The generated data, which is based on real-world behaviors and simulation techniques, can be used to develop, test, and evaluate, both ML algori
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#24212;&#29992;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#29615;&#22659;&#35268;&#33539;&#26469;&#34920;&#24449;&#29615;&#22659;&#30340;&#26041;&#24046;&#23646;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22522;&#20110;&#27169;&#22411;&#21644;&#26080;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#23545;&#20110;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;&#29615;&#22659;&#21516;&#26102;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#30028;&#38480;&#26159;&#31532;&#19968;&#27425;&#34987;&#35777;&#26126;&#20986;&#26469;&#30340;&#12290;</title><link>http://arxiv.org/abs/2301.13446</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23574;&#38160;&#26041;&#24046;&#30456;&#20851;&#30028;&#38480;&#65306;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;&#29615;&#22659;&#30340;&#26368;&#20339;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Sharp Variance-Dependent Bounds in Reinforcement Learning: Best of Both Worlds in Stochastic and Deterministic Environments. (arXiv:2301.13446v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#24212;&#29992;&#21040;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#29615;&#22659;&#35268;&#33539;&#26469;&#34920;&#24449;&#29615;&#22659;&#30340;&#26041;&#24046;&#23646;&#24615;&#65292;&#24182;&#35774;&#35745;&#20986;&#22522;&#20110;&#27169;&#22411;&#21644;&#26080;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#23545;&#20110;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;&#29615;&#22659;&#21516;&#26102;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#30028;&#38480;&#26159;&#31532;&#19968;&#27425;&#34987;&#35777;&#26126;&#20986;&#26469;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#12290;&#20855;&#26377;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#20445;&#35777;&#30340;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#21033;&#29992;&#20855;&#26377;&#20302;&#26041;&#24046;&#65288;&#20363;&#22914;&#65292;&#22312;&#30830;&#23450;&#24615;MDP&#19978;&#20139;&#26377;&#24120;&#37327;&#36951;&#25022;&#65289;&#30340;&#29615;&#22659;&#12290;&#29616;&#26377;&#31639;&#27861;&#35201;&#20040;&#29420;&#31435;&#20110;&#26041;&#24046;&#35201;&#20040;&#27425;&#20248;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20004;&#20010;&#26032;&#30340;&#29615;&#22659;&#35268;&#33539;&#26469;&#34920;&#24449;&#29615;&#22659;&#30340;&#32454;&#31890;&#24230;&#26041;&#24046;&#23646;&#24615;&#12290;&#23545;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;MVP&#31639;&#27861;(Zhang&#31561;&#65292;2021a)&#30340;&#21464;&#31181;&#65292;&#24182;&#20351;&#29992;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#23637;&#31034;&#20102;&#35813;&#31639;&#27861;&#30456;&#23545;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#35268;&#33539;&#20139;&#26377;&#26041;&#24046;&#30456;&#20851;&#30340;&#30028;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#36825;&#19968;&#30028;&#38480;&#23545;&#20110;&#38543;&#26426;&#21644;&#30830;&#23450;&#24615;MDP&#21516;&#26102;&#26159;&#26497;&#23567;&#26497;&#22823;&#26368;&#20248;&#30340;&#65292;&#36825;&#26159;&#20854;&#31181;&#31867;&#20013;&#30340;&#31532;&#19968;&#20010;&#32467;&#26524;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#21442;&#32771;&#20989;&#25968;&#30340;&#31639;&#27861;&#20197;&#21450;&#19968;&#20010;&#26032;&#30340;&#24102;&#26377;&#19978;&#38480;&#21152;&#20493;&#21442;&#32771;&#26356;&#26032;&#36827;&#24230;&#34920;&#30340;&#31574;&#30053;&#21551;&#21160;&#20102;&#20851;&#20110;&#20855;&#26377;&#26041;&#24046;&#30456;&#20851;&#36951;&#25022;&#30028;&#38480;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#30340;&#30740;&#31350;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20123;&#21551;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study variance-dependent regret bounds for Markov decision processes (MDPs). Algorithms with variance-dependent regret guarantees can automatically exploit environments with low variance (e.g., enjoying constant regret on deterministic MDPs). The existing algorithms are either variance-independent or suboptimal. We first propose two new environment norms to characterize the fine-grained variance properties of the environment. For model-based methods, we design a variant of the MVP algorithm (Zhang et al., 2021a) and use new analysis techniques show to this algorithm enjoys variance-dependent bounds with respect to our proposed norms. In particular, this bound is simultaneously minimax optimal for both stochastic and deterministic MDPs, the first result of its kind. We further initiate the study on model-free algorithms with variance-dependent regret bounds by designing a reference-function-based algorithm with a novel capped-doubling reference update schedule. Lastly, we also provid
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20960;&#20309;&#23436;&#22791;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476; GCPNet&#65292;&#29992;&#20110;3D&#20998;&#23376;&#22270;&#30340;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#22312;&#22810;&#20010;&#20960;&#20309;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#20854;&#20986;&#33394;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#20854;&#20013;&#26368;&#20339;&#34920;&#29616;&#26159;&#22312;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#20146;&#21644;&#21147;&#39044;&#27979;&#19978;&#24471;&#21040;&#20102;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#39640;&#20986;5%&#20197;&#19978;&#30340;&#30456;&#20851;&#31995;&#25968;&#12290;</title><link>http://arxiv.org/abs/2211.02504</link><description>&lt;p&gt;
&#29992;&#20110;&#19977;&#32500;&#20998;&#23376;&#22270;&#30340;&#20960;&#20309;&#23436;&#22791;&#24863;&#30693;&#22120;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Geometry-Complete Perceptron Networks for 3D Molecular Graphs. (arXiv:2211.02504v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20960;&#20309;&#23436;&#22791;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476; GCPNet&#65292;&#29992;&#20110;3D&#20998;&#23376;&#22270;&#30340;&#34920;&#31034;&#23398;&#20064;&#65292;&#24182;&#22312;&#22810;&#20010;&#20960;&#20309;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#20854;&#20986;&#33394;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#20854;&#20013;&#26368;&#20339;&#34920;&#29616;&#26159;&#22312;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#20146;&#21644;&#21147;&#39044;&#27979;&#19978;&#24471;&#21040;&#20102;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#39640;&#20986;5%&#20197;&#19978;&#30340;&#30456;&#20851;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#23545;&#20110;&#21019;&#26032;&#21644;&#24378;&#22823;&#30340;&#22270;&#24418;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#21457;&#23637;&#20135;&#29983;&#20102;&#37325;&#22823;&#24433;&#21709;&#12290;&#26469;&#33258;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#31561;&#23398;&#31185;&#30340;&#39046;&#22495;&#65292;&#22312;&#36825;&#20123;&#26041;&#27861;&#23398;&#30340;&#25512;&#21160;&#19979;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25910;&#30410;&#65292;&#20174;&#32780;&#22312;&#31185;&#23398;&#39046;&#22495;&#22914;&#34507;&#30333;&#36136;&#32467;&#26500;&#39044;&#27979;&#21644;&#35774;&#35745;&#20013;&#23454;&#29616;&#20102;&#31361;&#30772;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;GCPNet&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#20960;&#20309;&#23436;&#22791;&#12289;SE(3)-&#31561;&#21464;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#19987;&#38376;&#29992;&#20110;3D&#20998;&#23376;&#22270;&#34920;&#31034;&#23398;&#20064;&#12290;&#22235;&#20010;&#19981;&#21516;&#30340;&#20960;&#20309;&#20219;&#21153;&#30340;&#20005;&#23494;&#23454;&#39564;&#35777;&#26126;&#20102;GCPNet&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#21253;&#25324;&#65306;&#65288;1&#65289;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#20146;&#21644;&#21147;&#30340;&#30456;&#20851;&#31995;&#25968;&#20026;0.608&#65292;&#27604;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#39640;&#20986;5%&#20197;&#19978;&#65307;&#65288;2&#65289;&#34507;&#30333;&#36136;&#32467;&#26500;&#25490;&#21517;&#22312;&#30446;&#26631;&#26412;&#22320;&#21644;&#25968;&#25454;&#38598;&#20840;&#23616;&#20043;&#38388;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#30340;&#30456;&#20851;&#24615;&#65292;&#20998;&#21035;&#20026;0.616&#21644;0.871&#65307;&#65288;3&#65289;Newtownian&#22810;&#20307;&#31995;&#32479;&#30340;&#24314;&#27169;&#24179;&#22343;&#25104;&#32489;&#36798;&#21040;&#20102;
&lt;/p&gt;
&lt;p&gt;
The field of geometric deep learning has had a profound impact on the development of innovative and powerful graph neural network architectures. Disciplines such as computer vision and computational biology have benefited significantly from such methodological advances, which has led to breakthroughs in scientific domains such as protein structure prediction and design. In this work, we introduce GCPNet, a new geometry-complete, SE(3)-equivariant graph neural network designed for 3D molecular graph representation learning. Rigorous experiments across four distinct geometric tasks demonstrate that GCPNet's predictions (1) for protein-ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5% greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#32452;&#25439;&#22833;&#65292;&#24182;&#34920;&#26126;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#22312;&#35270;&#35273;&#21644;NLP&#20013;&#23637;&#31034;&#20986;&#26174;&#33879;&#30340;&#20998;&#32452;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2210.16315</link><description>&lt;p&gt;
&#36229;&#36234;&#26657;&#20934;&#65306;&#20272;&#35745;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#32452;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Beyond calibration: estimating the grouping loss of modern neural networks. (arXiv:2210.16315v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16315
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#32452;&#25439;&#22833;&#65292;&#24182;&#34920;&#26126;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#22312;&#35270;&#35273;&#21644;NLP&#20013;&#23637;&#31034;&#20986;&#26174;&#33879;&#30340;&#20998;&#32452;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#20445;&#20998;&#31867;&#22120;&#32473;&#20986;&#21487;&#38752;&#30340;&#32622;&#20449;&#24230;&#20998;&#25968;&#26159;&#30830;&#20445;&#30693;&#24773;&#20915;&#31574;&#30340;&#20851;&#38190;&#12290;&#20026;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#35823;&#26657;&#20934;&#19978;&#65292;&#21363;&#27169;&#22411;&#20998;&#25968;&#30340;&#36807;&#24230;&#25110;&#19981;&#36275;&#32622;&#20449;&#12290;&#28982;&#32780;&#65292;&#26657;&#20934;&#36824;&#19981;&#22815;&#65306;&#21363;&#20351;&#20934;&#30830;&#29575;&#26368;&#39640;&#30340;&#23436;&#32654;&#26657;&#20934;&#20998;&#31867;&#22120;&#20063;&#21487;&#33021;&#20855;&#26377;&#19982;&#30495;&#23454;&#21518;&#39564;&#27010;&#29575;&#30456;&#21435;&#29978;&#36828;&#30340;&#32622;&#20449;&#24230;&#20998;&#25968;&#65292;&#36825;&#26159;&#30001;&#20110;&#20998;&#32452;&#25439;&#22833;&#25152;&#36896;&#25104;&#30340;&#65292;&#21363;&#20197;&#30456;&#21516;&#32622;&#20449;&#24230;&#24471;&#20998;&#20294;&#30495;&#23454;&#21518;&#39564;&#27010;&#29575;&#19981;&#21516;&#30340;&#26679;&#26412;&#12290;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#29702;&#35770;&#34920;&#26126;&#65292;&#22312;&#32473;&#23450;&#26657;&#20934;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#34920;&#24449;&#21333;&#20010;&#38169;&#35823;&#30340;&#32570;&#22833;&#37096;&#20998;&#26159;&#20998;&#32452;&#25439;&#22833;&#12290;&#34429;&#28982;&#23384;&#22312;&#35768;&#22810;&#26657;&#20934;&#25439;&#22833;&#30340;&#20272;&#35745;&#22120;&#65292;&#20294;&#22312;&#26631;&#20934;&#35774;&#32622;&#20013;&#19981;&#23384;&#22312;&#20998;&#32452;&#25439;&#22833;&#30340;&#20272;&#35745;&#22120;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20272;&#35745;&#22120;&#26469;&#36817;&#20284;&#20998;&#32452;&#25439;&#22833;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#22312;&#35270;&#35273;&#21644;NLP&#20013;&#34920;&#29616;&#20986;&#20998;&#32452;&#25439;&#22833;&#65292;&#29305;&#21035;&#26159;&#22312;&#20998;&#24067;&#20559;&#31227;&#35774;&#32622;&#20013;&#65292;&#36825;&#31361;&#26174;&#20102;&#23427;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to ensure that a classifier gives reliable confidence scores is essential to ensure informed decision-making. To this end, recent work has focused on miscalibration, i.e., the over or under confidence of model scores. Yet calibration is not enough: even a perfectly calibrated classifier with the best possible accuracy can have confidence scores that are far from the true posterior probabilities. This is due to the grouping loss, created by samples with the same confidence scores but different true posterior probabilities. Proper scoring rule theory shows that given the calibration loss, the missing piece to characterize individual errors is the grouping loss. While there are many estimators of the calibration loss, none exists for the grouping loss in standard settings. Here, we propose an estimator to approximate the grouping loss. We show that modern neural network architectures in vision and NLP exhibit grouping loss, notably in distribution shifts settings, which highli
&lt;/p&gt;</description></item><item><title>Packed-Ensembles&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#20869;&#36816;&#34892;&#30340;&#36731;&#37327;&#32423;&#32467;&#26500;&#21270;&#38598;&#21512;&#65292;&#23427;&#36890;&#36807;&#31934;&#24515;&#35843;&#33410;&#32534;&#30721;&#31354;&#38388;&#30340;&#32500;&#24230;&#26469;&#35774;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#25439;&#22833;&#25928;&#26524;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2210.09184</link><description>&lt;p&gt;
&#32039;&#20945;&#38598;&#25104;&#29992;&#20110;&#39640;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Packed-Ensembles for Efficient Uncertainty Estimation. (arXiv:2210.09184v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09184
&lt;/p&gt;
&lt;p&gt;
Packed-Ensembles&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#20869;&#36816;&#34892;&#30340;&#36731;&#37327;&#32423;&#32467;&#26500;&#21270;&#38598;&#21512;&#65292;&#23427;&#36890;&#36807;&#31934;&#24515;&#35843;&#33410;&#32534;&#30721;&#31354;&#38388;&#30340;&#32500;&#24230;&#26469;&#35774;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#25439;&#22833;&#25928;&#26524;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;&#35757;&#32451;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#38598;&#25104;&#26159;&#23454;&#29616;&#20851;&#38190;&#25351;&#26631;&#65288;&#22914;&#20934;&#30830;&#24615;&#12289;&#26657;&#20934;&#12289;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#36229;&#20986;&#20998;&#24067;&#26816;&#27979;&#65289;&#21331;&#36234;&#24615;&#33021;&#30340;&#31361;&#20986;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#29616;&#23454;&#31995;&#32479;&#30340;&#30828;&#20214;&#38480;&#21046;&#38480;&#21046;&#20102;&#26356;&#23567;&#30340;&#38598;&#21512;&#21644;&#36739;&#20302;&#23481;&#37327;&#30340;&#32593;&#32476;&#65292;&#20005;&#37325;&#25439;&#23475;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#21644;&#23646;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Packed-Ensembles&#65288;PE&#65289;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#31934;&#24515;&#35843;&#33410;&#20854;&#32534;&#30721;&#31354;&#38388;&#30340;&#32500;&#24230;&#26469;&#35774;&#35745;&#21644;&#35757;&#32451;&#36731;&#37327;&#32423;&#32467;&#26500;&#21270;&#38598;&#21512;&#12290;&#25105;&#20204;&#21033;&#29992;&#32452;&#21367;&#31215;&#23558;&#38598;&#21512;&#24182;&#34892;&#21270;&#20026;&#21333;&#20010;&#20849;&#20139;&#39592;&#24178;&#65292;&#24182;&#36827;&#34892;&#21069;&#21521;&#20256;&#36882;&#20197;&#25552;&#39640;&#35757;&#32451;&#21644;&#25512;&#29702;&#36895;&#24230;&#12290;PE&#26088;&#22312;&#22312;&#26631;&#20934;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#23384;&#38480;&#21046;&#20869;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;&#25511;&#21046;&#39046;&#22495;&#20013;&#26368;&#37325;&#35201;&#30340;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#26368;&#36817;&#36827;&#23637;&#65292;&#36825;&#20123;&#36827;&#23637;&#20027;&#35201;&#22260;&#32469;&#22312;&#32447;&#24615;&#31995;&#32479;&#36776;&#35782;&#21644;&#23398;&#20064;&#26041;&#38754;&#65292;&#22522;&#20110;&#29616;&#20195;&#39640;&#32500;&#32479;&#35745;&#23398;&#21644;&#23398;&#20064;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#20026;&#23558;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#34701;&#20837;&#25511;&#21046;&#39046;&#22495;&#30340;&#20154;&#25552;&#20379;&#20102;&#33258;&#21253;&#21547;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2209.05423</link><description>&lt;p&gt;
&#25511;&#21046;&#30340;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#65306;&#26377;&#38480;&#26679;&#26412;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Statistical Learning Theory for Control: A Finite Sample Perspective. (arXiv:2209.05423v2 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.05423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;&#25511;&#21046;&#39046;&#22495;&#20013;&#26368;&#37325;&#35201;&#30340;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#26368;&#36817;&#36827;&#23637;&#65292;&#36825;&#20123;&#36827;&#23637;&#20027;&#35201;&#22260;&#32469;&#22312;&#32447;&#24615;&#31995;&#32479;&#36776;&#35782;&#21644;&#23398;&#20064;&#26041;&#38754;&#65292;&#22522;&#20110;&#29616;&#20195;&#39640;&#32500;&#32479;&#35745;&#23398;&#21644;&#23398;&#20064;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#20026;&#23558;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#34701;&#20837;&#25511;&#21046;&#39046;&#22495;&#30340;&#20154;&#25552;&#20379;&#20102;&#33258;&#21253;&#21547;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25945;&#31243;&#32508;&#36848;&#20102;&#26368;&#36817;&#22312;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#19982;&#25511;&#21046;&#21644;&#31995;&#32479;&#36776;&#35782;&#30456;&#20851;&#30340;&#38750;&#28176;&#36817;&#36827;&#23637;&#12290;&#23613;&#31649;&#22312;&#25152;&#26377;&#25511;&#21046;&#39046;&#22495;&#37117;&#21462;&#24471;&#20102;&#23454;&#36136;&#24615;&#36827;&#23637;&#65292;&#20294;&#22312;&#32447;&#24615;&#31995;&#32479;&#36776;&#35782;&#21644;&#32447;&#24615;&#20108;&#27425;&#35843;&#33410;&#22120;&#23398;&#20064;&#26041;&#38754;&#65292;&#35813;&#29702;&#35770;&#26368;&#20026;&#25104;&#29087;&#65292;&#32780;&#36825;&#20063;&#26159;&#26412;&#25991;&#30340;&#37325;&#28857;&#12290;&#20174;&#29702;&#35770;&#35282;&#24230;&#35762;&#65292;&#36825;&#20123;&#36827;&#23637;&#30340;&#22823;&#37096;&#20998;&#24037;&#20316;&#37117;&#22312;&#20110;&#20511;&#37492;&#29616;&#20195;&#39640;&#32500;&#32479;&#35745;&#23398;&#21644;&#23398;&#20064;&#29702;&#35770;&#30340;&#24037;&#20855;&#12290;&#34429;&#28982;&#23545;&#20110;&#37027;&#20123;&#26377;&#20852;&#36259;&#23558;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#34701;&#20837;&#25511;&#21046;&#39046;&#22495;&#30340;&#25511;&#21046;&#29702;&#35770;&#23478;&#26469;&#35828;&#38750;&#24120;&#30456;&#20851;&#65292;&#20294;&#36825;&#20123;&#22522;&#30784;&#26448;&#26009;&#24182;&#19981;&#24635;&#26159;&#26131;&#20110;&#33719;&#21462;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30456;&#20851;&#32032;&#26448;&#30340;&#33258;&#21253;&#21547;&#28436;&#31034;&#65292;&#27010;&#36848;&#20102;&#25152;&#26377;&#20851;&#38190;&#24605;&#24819;&#21644;&#25216;&#26415;&#26426;&#26800;&#65292;&#20026;&#26368;&#36817;&#30340;&#32467;&#26524;&#25171;&#19979;&#20102;&#22522;&#30784;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20123;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#21644;&#26410;&#26469;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
This tutorial survey provides an overview of recent non-asymptotic advances in statistical learning theory as relevant to control and system identification. While there has been substantial progress across all areas of control, the theory is most well-developed when it comes to linear system identification and learning for the linear quadratic regulator, which are the focus of this manuscript. From a theoretical perspective, much of the labor underlying these advances has been in adapting tools from modern high-dimensional statistics and learning theory. While highly relevant to control theorists interested in integrating tools from machine learning, the foundational material has not always been easily accessible. To remedy this, we provide a self-contained presentation of the relevant material, outlining all the key ideas and the technical machinery that underpin recent results. We also present a number of open problems and future directions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DORA&#30340;&#25968;&#25454;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#34920;&#24449;&#31354;&#38388;&#65292;&#24182;&#21487;&#20197;&#35782;&#21035;&#19981;&#31526;&#21512;&#20154;&#31867;&#30452;&#35266;&#35748;&#30693;&#30340;&#34920;&#24449;&#12290;</title><link>http://arxiv.org/abs/2206.04530</link><description>&lt;p&gt;
DORA&#65306;&#25506;&#32034;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24322;&#24120;&#20540;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DORA&#30340;&#25968;&#25454;&#19981;&#21487;&#30693;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#34920;&#24449;&#31354;&#38388;&#65292;&#24182;&#21487;&#20197;&#35782;&#21035;&#19981;&#31526;&#21512;&#20154;&#31867;&#30452;&#35266;&#35748;&#30693;&#30340;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#23398;&#20064;&#22797;&#26434;&#25277;&#35937;&#26041;&#38754;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#24847;&#22806;&#22320;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#34394;&#20551;&#30340;&#29305;&#24449;&#12290;&#20026;&#20102;&#30830;&#20445;&#27169;&#22411;&#30340;&#36879;&#26126;&#24230;&#65292;&#26816;&#26597;&#23398;&#20064;&#34920;&#31034;&#20043;&#38388;&#30340;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#24847;&#22806;&#30340;&#27010;&#24565;&#24448;&#24448;&#34920;&#29616;&#20026;&#19982;&#25152;&#38656;&#30340;&#20219;&#21153;&#19981;&#31526;&#30340;&#24322;&#24120;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;DORA&#65288;Data-agnOstic Representation Analysis&#65289;&#65306;&#29992;&#20110;&#20998;&#26512;DNN&#34920;&#31034;&#31354;&#38388;&#30340;&#31532;&#19968;&#20010;&#25968;&#25454;&#19981;&#21487;&#30693;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#37319;&#29992;&#20102;&#25152;&#25552;&#20986;&#30340;&#34920;&#31034;&#20043;&#38388;&#30340;&#26497;&#31471;&#28608;&#27963;&#65288;EA&#65289;&#36317;&#31163;&#24230;&#37327;&#65292;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21033;&#29992;&#32593;&#32476;&#20869;&#33258;&#35828;&#26126;&#33021;&#21147;&#12290;&#25105;&#20204;&#23450;&#37327;&#39564;&#35777;&#20102;&#24230;&#37327;&#30340;&#27491;&#30830;&#24615;&#21644;&#19982;&#20154;&#20026;&#23450;&#20041;&#30340;&#35821;&#20041;&#36317;&#31163;&#30340;&#19968;&#33268;&#24615;&#12290;EA&#36317;&#31163;&#19982;&#20154;&#31867;&#21028;&#26029;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#20351;&#25105;&#20204;&#33021;&#22815;&#30830;&#23450;&#34920;&#24449;&#65292;&#20854;&#22522;&#26412;&#27010;&#24565;&#34987;&#35748;&#20026;&#26159;&#19981;&#33258;&#28982;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although Deep Neural Networks (DNNs) are incredibly effective in learning complex abstractions, they are susceptible to unintentionally learning spurious artifacts from the training data. To ensure model transparency, it is crucial to examine the relationships between learned representations, as unintended concepts often manifest themselves to be anomalous to the desired task. In this work, we introduce DORA (Data-agnOstic Representation Analysis): the first data-agnostic framework for the analysis of the representation space of DNNs. Our framework employs the proposed Extreme-Activation (EA) distance measure between representations that utilizes self-explaining capabilities within the network without accessing any data. We quantitatively validate the metric's correctness and alignment with human-defined semantic distances. The coherence between the EA distance and human judgment enables us to identify representations whose underlying concepts would be considered unnatural by humans by
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#20803;&#23398;&#20064;&#22120;&#20272;&#35745;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#26420;&#32032;&#25193;&#23637;&#24182;&#19981;&#24635;&#26159;&#21487;&#34892;&#65292;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#19968;&#20123;&#34920;&#29616;&#33391;&#22909;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;</title><link>http://arxiv.org/abs/2205.14714</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#22120;&#29992;&#20110;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#20316;&#29992;&#20272;&#35745;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Comparison of meta-learners for estimating multi-valued treatment heterogeneous effects. (arXiv:2205.14714v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14714
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#21033;&#29992;&#20803;&#23398;&#20064;&#22120;&#20272;&#35745;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#25928;&#24212;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#26420;&#32032;&#25193;&#23637;&#24182;&#19981;&#24635;&#26159;&#21487;&#34892;&#65292;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#19968;&#20123;&#34920;&#29616;&#33391;&#22909;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21033;&#29992;&#35266;&#23519;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#65292;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#20272;&#35745;&#26159;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#12290;&#38500;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27169;&#22411;&#22806;&#65292;&#36824;&#24320;&#21457;&#20986;&#20102;&#31216;&#20026;&#20803;&#23398;&#20064;&#22120;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#20197;&#20272;&#35745;CATE&#65292;&#20854;&#20027;&#35201;&#20248;&#28857;&#26159;&#19981;&#23616;&#38480;&#20110;&#29305;&#23450;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#19981;&#26159;&#20108;&#36827;&#21046;&#30340;&#26102;&#65292;&#19968;&#20123;&#26420;&#32032;&#25193;&#23637;&#30340;&#38480;&#21046;&#20250;&#20986;&#29616;&#65292;&#36825;&#26679;&#30340;&#20219;&#21153;&#23601;&#21464;&#24471;&#26356;&#21152;&#22797;&#26434;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20803;&#23398;&#20064;&#22120;&#29992;&#20110;&#20272;&#35745;&#22810;&#20540;&#22788;&#29702;&#24322;&#36136;&#25928;&#24212;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#20803;&#23398;&#20064;&#22120;&#65292;&#29702;&#35770;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#35823;&#24046;&#19978;&#30028;&#20316;&#20026;&#37325;&#35201;&#21442;&#25968;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22788;&#29702;&#27700;&#24179;&#30340;&#25968;&#37327;&#65292;&#32467;&#26524;&#26174;&#31034;&#65292;&#26420;&#32032;&#25193;&#23637;&#24182;&#19981;&#24635;&#26159;&#25552;&#20379;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#24341;&#20837;&#21644;&#35752;&#35770;&#20102;&#19968;&#20123;&#20803;&#23398;&#20064;&#22120;&#65292;&#23427;&#20204;&#22312;&#22788;&#29702;&#25968;&#37327;&#22686;&#22810;&#26102;&#34920;&#29616;&#33391;&#22909;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#19968;&#39033;&#20057;&#32925;&#27835;&#30103;&#30740;&#31350;&#30340;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#20803;&#23398;&#20064;&#22120;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional Average Treatment Effects (CATE) estimation is one of the main challenges in causal inference with observational data. In addition to Machine Learning based-models, nonparametric estimators called meta-learners have been developed to estimate the CATE with the main advantage of not restraining the estimation to a specific supervised learning method. This task becomes, however, more complicated when the treatment is not binary as some limitations of the naive extensions emerge. This paper looks into meta-learners for estimating the heterogeneous effects of multi-valued treatments. We consider different meta-learners, and we carry out a theoretical analysis of their error upper bounds as functions of important parameters such as the number of treatment levels, showing that the naive extensions do not always provide satisfactory results. We introduce and discuss meta-learners that perform well as the number of treatments increases. We empirically confirm the strengths and weak
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#20381;&#36182;&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;&#65288;DLCM&#65289;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;&#65288;LCMs&#65289;&#65292;DLCMs&#26356;&#36866;&#29992;&#20110;&#20855;&#26377;&#26102;&#38388;&#24207;&#21015;&#12289;&#37325;&#21472;&#39033;&#21644;&#32467;&#26500;&#38646;&#31561;&#29305;&#28857;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2205.08677</link><description>&lt;p&gt;
&#20381;&#36182;&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Dependent Latent Class Models. (arXiv:2205.08677v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.08677
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#20381;&#36182;&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;&#65288;DLCM&#65289;&#65292;&#30456;&#27604;&#20256;&#32479;&#30340;&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;&#65288;LCMs&#65289;&#65292;DLCMs&#26356;&#36866;&#29992;&#20110;&#20855;&#26377;&#26102;&#38388;&#24207;&#21015;&#12289;&#37325;&#21472;&#39033;&#21644;&#32467;&#26500;&#38646;&#31561;&#29305;&#28857;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;&#65288;LCMs&#65289;&#29992;&#20110;&#32858;&#31867;&#22810;&#20803;&#20998;&#31867;&#25968;&#25454;&#65288;&#20363;&#22914;&#22522;&#20110;&#35843;&#26597;&#22238;&#31572;&#30340;&#32676;&#32452;&#21442;&#19982;&#32773;&#65289;&#12290;&#20256;&#32479;&#30340;LCMs&#20551;&#35774;&#19968;&#20010;&#31216;&#20026;&#26465;&#20214;&#29420;&#31435;&#24615;&#30340;&#23646;&#24615;&#12290;&#36825;&#31181;&#20551;&#35774;&#21487;&#33021;&#36807;&#20110;&#20005;&#26684;&#65292;&#23548;&#33268;&#27169;&#22411;&#38169;&#35823;&#35268;&#23450;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#31216;&#20026;&#20381;&#36182;&#38544;&#21464;&#37327;&#31867;&#27169;&#22411;&#65288;DLCM&#65289;&#65292;&#23427;&#20801;&#35768;&#26465;&#20214;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;DLCMs&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;DLCMs&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#19982;&#20256;&#32479;&#30340;LCMs&#30456;&#27604;&#65292;DLCMs&#22312;&#26102;&#38388;&#24207;&#21015;&#65292;&#37325;&#21472;&#39033;&#21644;&#32467;&#26500;&#38646;&#26041;&#38754;&#30340;&#24212;&#29992;&#26356;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent Class Models (LCMs) are used to cluster multivariate categorical data (e.g. group participants based on survey responses). Traditional LCMs assume a property called conditional independence. This assumption can be restrictive, leading to model misspecification and overparameterization. To combat this problem, we developed a novel Bayesian model called a Dependent Latent Class Model (DLCM), which permits conditional dependence. We verify identifiability of DLCMs. We also demonstrate the effectiveness of DLCMs in both simulations and real-world applications. Compared to traditional LCMs, DLCMs are effective in applications with time series, overlapping items, and structural zeroes.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SRCA&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#24230;&#30340;&#20302;&#26679;&#26412;&#22823;&#23567;&#25968;&#25454;&#26102;&#65292;&#36890;&#36807;&#24341;&#20837;&#29699;&#20307;&#25110;&#26925;&#29699;&#20307;&#65292;&#20445;&#30041;&#25968;&#25454;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#25552;&#39640;&#36817;&#20284;&#20302;&#32500;&#27969;&#24418;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2204.10975</link><description>&lt;p&gt;
&#24102;&#26377;&#20960;&#20309;&#25439;&#22833;&#20989;&#25968;&#30340;&#29699;&#38754;&#26059;&#36716;&#38477;&#32500;
&lt;/p&gt;
&lt;p&gt;
Spherical Rotation Dimension Reduction with Geometric Loss Functions. (arXiv:2204.10975v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10975
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SRCA&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#24230;&#30340;&#20302;&#26679;&#26412;&#22823;&#23567;&#25968;&#25454;&#26102;&#65292;&#36890;&#36807;&#24341;&#20837;&#29699;&#20307;&#25110;&#26925;&#29699;&#20307;&#65292;&#20445;&#30041;&#25968;&#25454;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#25552;&#39640;&#36817;&#20284;&#20302;&#32500;&#27969;&#24418;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25968;&#25454;&#38598;&#36890;&#24120;&#20855;&#26377;&#39640;&#32500;&#24615;&#65292;&#20294;&#25968;&#25454;&#20301;&#20110;&#20302;&#32500;&#27969;&#24418;&#20013;&#65292;&#21487;&#20197;&#25581;&#31034;&#23545;&#25968;&#25454;&#20998;&#26512;&#33267;&#20851;&#37325;&#35201;&#30340;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#12290;&#36825;&#31867;&#25968;&#25454;&#38598;&#30340;&#20856;&#22411;&#20363;&#23376;&#26159;&#32454;&#32990;&#21608;&#26399;&#27979;&#37327;&#20540;&#30340;&#38598;&#21512;&#65292;&#20854;&#20013;&#36807;&#31243;&#30340;&#22266;&#26377;&#24490;&#29615;&#24615;&#21487;&#20197;&#34920;&#31034;&#20026;&#22278;&#25110;&#29699;&#12290;&#21463;&#20998;&#26512;&#36825;&#20123;&#31867;&#22411;&#25968;&#25454;&#38598;&#30340;&#38656;&#27714;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#31216;&#20026;&#29699;&#38754;&#26059;&#36716;&#25104;&#20998;&#20998;&#26512;&#65288;SRCA&#65289;&#65292;&#23427;&#23558;&#20960;&#20309;&#20449;&#24687;&#32435;&#20837;&#21040;&#38477;&#32500;&#36807;&#31243;&#20013;&#20197;&#26356;&#22909;&#22320;&#36924;&#36817;&#20302;&#32500;&#27969;&#24418;&#12290;SRCA&#26159;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#39640;&#32500;&#21644;&#23567;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#24037;&#20316;&#12290;&#36890;&#36807;&#20351;&#29992;&#29699;&#20307;&#25110;&#26925;&#29699;&#20307;&#65292;SRCA&#25552;&#20379;&#20102;&#25968;&#25454;&#30340;&#20302;&#31209;&#29699;&#38754;&#34920;&#31034;&#65292;&#24182;&#22312;&#38477;&#32500;&#36807;&#31243;&#20013;&#26377;&#25928;&#22320;&#20445;&#30041;&#20102;&#25968;&#25454;&#38598;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#20840;&#38754;&#30340;&#27169;&#25311;&#30740;&#31350;&#20197;&#21450;&#23545;&#20154;&#31867;&#32454;&#32990;&#21608;&#26399;&#25968;&#25454;&#30340;&#25104;&#21151;&#24212;&#29992;&#35777;&#26126;&#20102;SRCA&#30340;&#26377;&#25928;&#24615;&#21644;&#22810;&#21151;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern datasets often exhibit high dimensionality, yet the data reside in low-dimensional manifolds that can reveal underlying geometric structures critical for data analysis. A prime example of such a dataset is a collection of cell cycle measurements, where the inherently cyclical nature of the process can be represented as a circle or sphere. Motivated by the need to analyze these types of datasets, we propose a nonlinear dimension reduction method, Spherical Rotation Component Analysis (SRCA), that incorporates geometric information to better approximate low-dimensional manifolds. SRCA is a versatile method designed to work in both high-dimensional and small sample size settings. By employing spheres or ellipsoids, SRCA provides a low-rank spherical representation of the data with general theoretic guarantees, effectively retaining the geometric structure of the dataset during dimensionality reduction. A comprehensive simulation study, along with a successful application to human c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;&#65292;&#21253;&#25324;&#20809;&#28369;&#38382;&#39064;&#30340;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;&#65288;ZO-AGP&#65289;&#65292;&#20197;&#21450;&#22359;&#29366;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#12290;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#36739;&#23569;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#21644;&#36739;&#39640;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2108.00473</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems. (arXiv:2108.00473v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.00473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;&#65292;&#21253;&#25324;&#20809;&#28369;&#38382;&#39064;&#30340;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;&#65288;ZO-AGP&#65289;&#65292;&#20197;&#21450;&#22359;&#29366;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#12290;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#36739;&#23569;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#21644;&#36739;&#39640;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#36825;&#31867;&#38382;&#39064;&#36817;&#24180;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#38454;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#65288;ZO-AGP&#65289;&#31639;&#27861;&#26469;&#35299;&#20915;&#20809;&#28369;&#30340;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026; $\mathcal{O}(\varepsilon^{-4})$&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#27425;&#25968;&#20026; $\mathcal{O}(d_{x}+d_{y})$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#38454;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#26469;&#35299;&#20915;&#22359;&#29366;&#38750;&#20809;&#28369;&#30340;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026; $\mathcal{O}(\varepsilon^{-4})$&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#27425;&#25968;&#20026; $\mathcal{O}(K d_{x}+d_{y})$&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#27425;&#25552;&#20986;&#36825;&#20123;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study zeroth-order algorithms for nonconvex-concave minimax problems, which have attracted widely attention in machine learning, signal processing and many other fields in recent years. We propose a zeroth-order alternating randomized gradient projection (ZO-AGP) algorithm for smooth nonconvex-concave minimax problems, and its iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$, and the number of function value estimation is bounded by $\mathcal{O}(d_{x}+d_{y})$ per iteration. Moreover, we propose a zeroth-order block alternating randomized proximal gradient algorithm (ZO-BAPG) for solving block-wise nonsmooth nonconvex-concave minimax optimization problems, and the iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$ and the number of function value estimation per iteration is bounded by $\mathcal{O}(K d_{x}+d_{y})$. To the best of our knowledge, this 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19981;&#20860;&#23481;&#24615;&#30340;&#32858;&#31867;&#26426;&#21046;&#65292;&#35813;&#26426;&#21046;&#21487;&#20197;&#23558;&#25968;&#25454;&#38598;&#21010;&#20998;&#20026;&#30001;&#35757;&#32451;&#36807;&#31243;&#30340;&#30446;&#26631;&#25152;&#23450;&#20041;&#19988;&#20855;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#65292;&#24182;&#26377;&#25928;&#20943;&#36731;&#21518;&#38376;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2105.03692</link><description>&lt;p&gt;
&#8220;&#25269;&#24481;&#21518;&#38376;&#25915;&#20987;&#30340;&#19981;&#20860;&#23481;&#32858;&#31867;&#26426;&#21046;&#8221;
&lt;/p&gt;
&lt;p&gt;
Incompatibility Clustering as a Defense Against Backdoor Poisoning Attacks. (arXiv:2105.03692v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.03692
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19981;&#20860;&#23481;&#24615;&#30340;&#32858;&#31867;&#26426;&#21046;&#65292;&#35813;&#26426;&#21046;&#21487;&#20197;&#23558;&#25968;&#25454;&#38598;&#21010;&#20998;&#20026;&#30001;&#35757;&#32451;&#36807;&#31243;&#30340;&#30446;&#26631;&#25152;&#23450;&#20041;&#19988;&#20855;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#65292;&#24182;&#26377;&#25928;&#20943;&#36731;&#21518;&#38376;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#30340;&#32858;&#31867;&#26426;&#21046;&#65292;&#35813;&#26426;&#21046;&#22522;&#20110;&#27169;&#22411;&#35757;&#32451;&#36807;&#31243;&#20013;&#20986;&#29616;&#30340;&#25968;&#25454;&#23376;&#38598;&#19981;&#30456;&#23481;&#24615;&#23646;&#24615;&#12290;&#35813;&#26426;&#21046;&#23558;&#25968;&#25454;&#38598;&#21010;&#20998;&#20026;&#21482;&#33021;&#27867;&#21270;&#21040;&#20854;&#33258;&#36523;&#30340;&#23376;&#38598;&#65292;&#21363;&#22312;&#19968;&#20010;&#23376;&#38598;&#19978;&#30340;&#35757;&#32451;&#19981;&#20250;&#25913;&#21892;&#20854;&#20182;&#23376;&#38598;&#30340;&#24615;&#33021;&#12290;&#21033;&#29992;&#25968;&#25454;&#38598;&#19982;&#35757;&#32451;&#36807;&#31243;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#25105;&#20204;&#30340;&#32858;&#31867;&#26426;&#21046;&#23558;&#25968;&#25454;&#38598;&#21010;&#20998;&#20026;&#30001;&#35757;&#32451;&#36807;&#31243;&#30340;&#30446;&#26631;&#25152;&#23450;&#20041;&#19988;&#20855;&#26377;&#24847;&#20041;&#30340;&#32858;&#31867;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32858;&#31867;&#26426;&#21046;&#24212;&#29992;&#20110;&#38450;&#24481;&#25968;&#25454;&#27602;&#21270;&#25915;&#20987;&#65292;&#21363;&#25915;&#20987;&#32773;&#23558;&#24694;&#24847;&#27602;&#23475;&#25968;&#25454;&#27880;&#20837;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#20197;&#24433;&#21709;&#35757;&#32451;&#27169;&#22411;&#30340;&#36755;&#20986;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#37325;&#28857;&#20851;&#27880;&#21033;&#29992;GTSRB&#21644;CIFAR-10&#25968;&#25454;&#38598;&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21518;&#38376;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65306;1&#65289;&#36825;&#20123;&#25915;&#20987;&#20135;&#29983;&#30340;&#27602;&#23475;&#25968;&#25454;&#38598;&#26159;&#26377;&#27602;&#23475;&#25968;&#25454;&#21644;&#24178;&#20928;&#25968;&#25454;&#19981;&#30456;&#23481;&#30340;&#65307;2&#65289;&#25105;&#20204;&#30340;&#32858;&#31867;&#26426;&#21046;&#21487;&#20197;&#26377;&#25928;&#20943;&#36731;&#21518;&#38376;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel clustering mechanism based on an incompatibility property between subsets of data that emerges during model training. This mechanism partitions the dataset into subsets that generalize only to themselves, i.e., training on one subset does not improve performance on the other subsets. Leveraging the interaction between the dataset and the training process, our clustering mechanism partitions datasets into clusters that are defined by--and therefore meaningful to--the objective of the training process.  We apply our clustering mechanism to defend against data poisoning attacks, in which the attacker injects malicious poisoned data into the training dataset to affect the trained model's output. Our evaluation focuses on backdoor attacks against deep neural networks trained to perform image classification using the GTSRB and CIFAR-10 datasets. Our results show that (1) these attacks produce poisoned datasets in which the poisoned and clean data are incompatible and (2) o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;Riemann&#27969;&#24418;&#19978;&#31215;&#20998;&#24230;&#37327;&#38480;&#21046;&#30340;Stein&#26041;&#27861;&#30340;&#25193;&#25955;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#19968;&#23545;&#20855;&#26377;&#19981;&#21516;&#36215;&#22987;&#28857;&#30340;&#25193;&#25955;&#20043;&#38388;&#30340;&#36317;&#31163;&#36807;&#31243;&#65292;&#23548;&#20986;&#20102;&#26354;&#29575;&#30456;&#20851;&#30340;Stein&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2003.11497</link><description>&lt;p&gt;
Riemann&#27969;&#24418;&#19978;Stein&#26041;&#27861;&#30340;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A diffusion approach to Stein's method on Riemannian manifolds. (arXiv:2003.11497v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2003.11497
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;Riemann&#27969;&#24418;&#19978;&#31215;&#20998;&#24230;&#37327;&#38480;&#21046;&#30340;Stein&#26041;&#27861;&#30340;&#25193;&#25955;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#19968;&#23545;&#20855;&#26377;&#19981;&#21516;&#36215;&#22987;&#28857;&#30340;&#25193;&#25955;&#20043;&#38388;&#30340;&#36317;&#31163;&#36807;&#31243;&#65292;&#23548;&#20986;&#20102;&#26354;&#29575;&#30456;&#20851;&#30340;Stein&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35814;&#32454;&#38416;&#36848;&#20102;&#19968;&#31181;&#29992;&#20110;&#36793;&#30028;&#27010;&#29575;&#27969;&#24418;&#19978;&#31215;&#20998;&#24230;&#37327;&#38480;&#21046;&#30340;Stein&#26041;&#27861;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#25193;&#25955;&#22312;$\mathbf M$&#19978;&#29983;&#25104;&#22120;&#19982;&#20854;&#34920;&#24449;Stein&#31639;&#23376;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#23545;&#20855;&#26377;&#19981;&#21516;&#36215;&#22987;&#28857;&#30340;&#27492;&#31867;&#25193;&#25955;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#23427;&#20204;&#20043;&#38388;&#30340;&#36317;&#31163;&#36807;&#31243;&#65292;&#23548;&#20986;&#20102;Stein&#22240;&#23376;&#65292;&#36825;&#20123;&#22240;&#23376;&#38480;&#21046;&#20102;Stein&#26041;&#31243;&#21450;&#20854;&#23548;&#25968;&#12290;Stein&#22240;&#23376;&#21253;&#21547;&#26354;&#29575;&#30456;&#20851;&#30340;&#39033;&#65292;&#24182;&#32553;&#20943;&#21040;&#30446;&#21069;&#36866;&#29992;&#20110;$\mathbb R^m$&#30340;&#22240;&#23376;&#65292;&#24182;&#19988;&#24847;&#21619;&#30528;&#24403;$\mathbf M$&#26159;&#24179;&#22374;&#27969;&#24418;&#26102;&#65292;&#23545;&#20110;$\mathbb R ^m$&#30340;&#38480;&#21046;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
We detail an approach to develop Stein's method for bounding integral metrics on probability measures defined on a Riemannian manifold $\mathbf M$. Our approach exploits the relationship between the generator of a diffusion on $\mathbf M$ with target invariant measure and its characterising Stein operator. We consider a pair of such diffusions with different starting points, and through analysis of the distance process between the pair, derive Stein factors, which bound the solution to the Stein equation and its derivatives. The Stein factors contain curvature-dependent terms and reduce to those currently available for $\mathbb R^m$, and moreover imply that the bounds for $\mathbb R^m$ remain valid when $\mathbf M$ is a flat manifold
&lt;/p&gt;</description></item></channel></rss>