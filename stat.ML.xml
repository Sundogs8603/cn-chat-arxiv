<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.05642</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A duality framework for generalization analysis of random feature models and two-layer neural networks. (arXiv:2305.05642v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05642
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#21452;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#20998;&#26512;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#20351; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39640;&#32500;&#20998;&#26512;&#20013;&#20986;&#29616;&#30340;&#33258;&#28982;&#20989;&#25968;&#31354;&#38388; $\mathcal{F}_{p,\pi}$ &#21644; Barron &#31354;&#38388;&#20013;&#23398;&#20064;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23545;&#20598;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#31354;&#38388;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#21487;&#20197;&#22312;&#26576;&#31181;&#24847;&#20041;&#19979;&#34987;&#35270;&#20026;&#31561;&#20215;&#30340;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#22312;&#30740;&#31350;&#36825;&#20004;&#31181;&#27169;&#22411;&#30340;&#27867;&#21270;&#26102;&#26356;&#19987;&#27880;&#20110;&#26356;&#23481;&#26131;&#30340;&#36924;&#36817;&#21644;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#23450;&#20041;&#19968;&#31181;&#22522;&#20110;&#20449;&#24687;&#30340;&#22797;&#26434;&#24230;&#26469;&#26377;&#25928;&#22320;&#25511;&#21046;&#20272;&#35745;&#35823;&#24046;&#65292;&#24314;&#31435;&#20102;&#23545;&#20598;&#31561;&#20215;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#20004;&#20010;&#20855;&#20307;&#24212;&#29992;&#36827;&#34892;&#32508;&#21512;&#20998;&#26512;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#23545;&#20598;&#24615;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#12290;&#31532;&#19968;&#20010;&#24212;&#29992;&#26159;&#30740;&#31350;&#20351;&#29992; RFMs &#23398;&#20064; $\mathcal{F}_{p,\pi}$ &#20013;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#21482;&#35201; $p&gt;1$&#65292;&#23398;&#20064;&#19981;&#20250;&#21463;&#21040;&#32500;&#25968;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#36825;&#24847;&#21619;&#30528; RFMs &#21487;&#20197;&#22312;&#26680;&#33539;&#22260;&#20043;&#22806;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning functions in the $\mathcal{F}_{p,\pi}$ and Barron spaces, which are natural function spaces that arise in the high-dimensional analysis of random feature models (RFMs) and two-layer neural networks. Through a duality analysis, we reveal that the approximation and estimation of these spaces can be considered equivalent in a certain sense. This enables us to focus on the easier problem of approximation and estimation when studying the generalization of both models. The dual equivalence is established by defining an information-based complexity that can effectively control estimation errors. Additionally, we demonstrate the flexibility of our duality framework through comprehensive analyses of two concrete applications.  The first application is to study learning functions in $\mathcal{F}_{p,\pi}$ with RFMs. We prove that the learning does not suffer from the curse of dimensionality as long as $p&gt;1$, implying RFMs can work beyond the kernel regime. Our 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#25299;&#25169;&#19981;&#21464;&#37327;&#8212;&#8212;&#22823;&#23567;&#65292;&#26469;&#37327;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36807;&#31243;&#65292;&#30740;&#31350;&#20854;&#20869;&#37096;&#34920;&#31034;&#24182;&#25552;&#20986;&#19968;&#20010;&#26032;&#26041;&#27861;&#26469;&#30830;&#23450;&#20854;&#27867;&#21270;&#33021;&#21147;&#65292;&#23454;&#39564;&#35777;&#26126;&#27492;&#26694;&#26550;&#21487;&#20316;&#20026;&#27867;&#21270;&#38169;&#35823;&#30340;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2305.05611</link><description>&lt;p&gt;
&#24230;&#37327;&#31354;&#38388;&#22823;&#23567;&#21644;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#27867;&#21270;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Metric Space Magnitude and Generalisation in Neural Networks. (arXiv:2305.05611v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#25299;&#25169;&#19981;&#21464;&#37327;&#8212;&#8212;&#22823;&#23567;&#65292;&#26469;&#37327;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36807;&#31243;&#65292;&#30740;&#31350;&#20854;&#20869;&#37096;&#34920;&#31034;&#24182;&#25552;&#20986;&#19968;&#20010;&#26032;&#26041;&#27861;&#26469;&#30830;&#23450;&#20854;&#27867;&#21270;&#33021;&#21147;&#65292;&#23454;&#39564;&#35777;&#26126;&#27492;&#26694;&#26550;&#21487;&#20316;&#20026;&#27867;&#21270;&#38169;&#35823;&#30340;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#37325;&#22823;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#30340;&#20869;&#37096;&#24037;&#20316;&#36807;&#31243;&#20173;&#28982;&#26159;&#38590;&#20197;&#25417;&#25720;&#30340;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#19968;&#31181;&#31216;&#20026;&#8220;&#22823;&#23567;&#8221;&#30340;&#26032;&#25299;&#25169;&#19981;&#21464;&#37327;&#30340;&#35270;&#35282;&#26469;&#37327;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;&#22823;&#23567;&#26159;&#19968;&#31181;&#31561;&#36317;&#19981;&#21464;&#37327;&#65307;&#23427;&#30340;&#23646;&#24615;&#26159;&#30740;&#31350;&#30340;&#19968;&#20010;&#27963;&#36291;&#39046;&#22495;&#65292;&#22240;&#20026;&#23427;&#32534;&#30721;&#20102;&#24230;&#37327;&#31354;&#38388;&#20013;&#35768;&#22810;&#24050;&#30693;&#30340;&#19981;&#21464;&#37327;&#12290;&#25105;&#20204;&#20351;&#29992;&#22823;&#23567;&#26469;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#23427;&#20204;&#27867;&#21270;&#33021;&#21147;&#30340;&#26032;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#23558;&#22823;&#23567;&#32500;&#24230;&#21644;&#27867;&#21270;&#38169;&#35823;&#36830;&#25509;&#36215;&#26469;&#65292;&#24182;&#23454;&#39564;&#24615;&#22320;&#35777;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#25104;&#20026;&#27867;&#21270;&#38169;&#35823;&#30340;&#19968;&#20010;&#33391;&#22909;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models have seen significant successes in numerous applications, but their inner workings remain elusive. The purpose of this work is to quantify the learning process of deep neural networks through the lens of a novel topological invariant called magnitude. Magnitude is an isometry invariant; its properties are an active area of research as it encodes many known invariants of a metric space. We use magnitude to study the internal representations of neural networks and propose a new method for determining their generalisation capabilities. Moreover, we theoretically connect magnitude dimension and the generalisation error, and demonstrate experimentally that the proposed framework can be a good indicator of the latter.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#22312;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#20256;&#36882;&#26377;&#29992;&#20449;&#24687;&#30340;&#36807;&#31243;&#20013;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#31561;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.05529</link><description>&lt;p&gt;
&#21033;&#29992;Birth-Death &#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#21152;&#36895;Langevin&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accelerate Langevin Sampling with Birth-Death process and Exploration Component. (arXiv:2305.05529v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05529
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#22312;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#20256;&#36882;&#26377;&#29992;&#20449;&#24687;&#30340;&#36807;&#31243;&#20013;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#65292;&#20855;&#26377;&#39640;&#25928;&#21644;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#65292;&#37319;&#26679;&#24050;&#30693;&#27010;&#29575;&#20998;&#24067;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#38024;&#23545;&#22810;&#23792;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#26041;&#27861;&#65292;&#21033;&#29992;&#20102;Birth-Death&#36807;&#31243;&#21644;&#25506;&#32034;&#32452;&#20214;&#12290;&#35813;&#26041;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#8220;&#19977;&#24605;&#32780;&#21518;&#34892;&#8221;&#12290;&#25105;&#20204;&#20445;&#30041;&#20004;&#32452;&#37319;&#26679;&#22120;&#65292;&#19968;&#32452;&#22312;&#36739;&#39640;&#28201;&#24230;&#19979;&#65292;&#19968;&#32452;&#22312;&#21407;&#22987;&#28201;&#24230;&#19979;&#12290;&#21069;&#32773;&#20316;&#20026;&#25506;&#32034;&#26032;&#27169;&#24335;&#21644;&#23558;&#26377;&#29992;&#20449;&#24687;&#20256;&#36882;&#32473;&#21518;&#32773;&#30340;&#20808;&#39537;&#65292;&#21518;&#32773;&#22312;&#25509;&#25910;&#20449;&#24687;&#21518;&#23545;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22343;&#22330;&#26497;&#38480;&#65292;&#24182;&#23637;&#31034;&#20102;&#25506;&#32034;&#36807;&#31243;&#22914;&#20309;&#20915;&#23450;&#37319;&#26679;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25351;&#25968;&#28176;&#36817;&#25910;&#25947;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23545;&#20197;&#21069;&#25991;&#29486;&#20013;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling a probability distribution with known likelihood is a fundamental task in computational science and engineering. Aiming at multimodality, we propose a new sampling method that takes advantage of both birth-death process and exploration component. The main idea of this method is \textit{look before you leap}. We keep two sets of samplers, one at warmer temperature and one at original temperature. The former one serves as pioneer in exploring new modes and passing useful information to the other, while the latter one samples the target distribution after receiving the information. We derive a mean-field limit and show how the exploration process determines sampling efficiency. Moreover, we prove exponential asymptotic convergence under mild assumption. Finally, we test on experiments from previous literature and compared our methodology to previous ones.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;</title><link>http://arxiv.org/abs/2305.05465</link><description>&lt;p&gt;
&#33258;&#27880;&#24847;&#21147;&#21160;&#24577;&#20013;&#30340;&#32858;&#31867;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05465
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#23454;&#20102;&#24403;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#65292;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#65292;&#20195;&#34920;token&#30340;&#31890;&#23376;&#20250;&#32858;&#38598;&#22312;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#38468;&#36817;&#65292;&#36825;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;Transformer&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24403;&#26435;&#37325;&#19981;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#65292;&#26412;&#25991;&#25551;&#36848;&#20102;&#23398;&#20064;&#34920;&#31034;&#30340;&#20960;&#20309;&#24418;&#29366;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20195;&#34920;token&#30340;&#31890;&#23376;&#38543;&#30528;&#26102;&#38388;&#36235;&#20110;&#26080;&#31351;&#22823;&#32780;&#36235;&#21521;&#20110;&#29305;&#23450;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;&#20986;&#29616;&#30340;&#26497;&#38480;&#23545;&#35937;&#31867;&#22411;&#21462;&#20915;&#20110;&#20215;&#20540;&#30697;&#38453;&#30340;&#35889;&#12290;&#27492;&#22806;&#65292;&#22312;&#19968;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#33258;&#25105;&#27880;&#24847;&#21147;&#30697;&#38453;&#25910;&#25947;&#20110;&#20302;&#31209;&#24067;&#23572;&#30697;&#38453;&#12290;&#36825;&#20123;&#32467;&#26524;&#30340;&#32452;&#21512;&#22312;&#25968;&#23398;&#19978;&#35777;&#23454;&#20102;Vaswani&#31561;&#20154;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#21363;Transformer&#22788;&#29702;&#19968;&#31995;&#21015;token&#26102;&#20250;&#20986;&#29616;&#8220;&#39046;&#23548;&#32773;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
Viewing Transformers as interacting particle systems, we describe the geometry of learned representations when the weights are not time dependent. We show that particles, representing tokens, tend to cluster toward particular limiting objects as time tends to infinity. The type of limiting object that emerges depends on the spectrum of the value matrix. Additionally, in the one-dimensional case we prove that the self-attention matrix converges to a low-rank Boolean matrix. The combination of these results mathematically confirms the empirical observation made by Vaswani et al. \cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens when processed by Transformers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#23545;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#65292;&#24182;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#31283;&#20581;&#24615;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.05400</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#25506;&#31350;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#33104;&#36133;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#23545;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#65292;&#24182;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#31283;&#20581;&#24615;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31283;&#20581;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23454;&#29616;&#23433;&#20840;&#21644;&#21487;&#38752;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#22312;&#23545;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23545;&#25239;&#31283;&#20581;&#24615;&#21644;&#24418;&#24335;&#31283;&#20581;&#24615;&#39564;&#35777;&#39046;&#22495;&#20013;&#65292;&#31283;&#20581;&#24615;&#36890;&#24120;&#34987;&#23450;&#20041;&#20026;&#22312;Lp&#33539;&#25968;&#36317;&#31163;&#20869;&#23545;&#25152;&#26377;&#36755;&#20837;&#21464;&#21270;&#30340;&#31283;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#36890;&#24120;&#36890;&#36807;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#35266;&#23519;&#21040;&#30340;&#21464;&#21270;&#26469;&#25913;&#36827;&#21644;&#35780;&#20272;&#65292;&#32780;&#24456;&#23569;&#32771;&#34385;&#25968;&#23398;&#23450;&#20041;&#30340;Lp&#33539;&#25968;&#22833;&#30495;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#26469;&#22686;&#24378;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#12290;&#25105;&#20204;&#20511;&#37492;&#20102;&#23545;&#25239;&#31283;&#20581;&#24615;&#39046;&#22495;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#23454;&#35777;&#21644;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;Lp&#33539;&#25968;&#20043;&#38388;&#31283;&#20581;&#24615;&#26159;&#21542;&#21487;&#36716;&#31227;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65292;&#21738;&#20123;Lp&#33539;&#25968;&#30340;&#22833;&#30495;&#24212;&#35813;&#29992;&#26469;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robustness is a fundamental property of machine learning classifiers to achieve safety and reliability. In the fields of adversarial robustness and formal robustness verification of image classification models, robustness is commonly defined as the stability to all input variations within an Lp-norm distance. However, robustness to random corruptions is usually improved and evaluated using variations observed in the real-world, while mathematically defined Lp-norm corruptions are rarely considered. This study investigates the use of random Lp-norm corruptions to augment the training and test data of image classifiers. We adapt an approach from the field of adversarial robustness to assess the model robustness to imperceptible random corruptions. We empirically and theoretically investigate whether robustness is transferable across different Lp-norms and derive conclusions on which Lp-norm corruptions a model should be trained and evaluated on. We find that training data augmentation wi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102; multi-label &#23398;&#20064;&#20013;&#24120;&#29992;&#30340; Macro-AUC &#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#26631;&#31614;&#19981;&#24179;&#34913;&#23545;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26410;&#32463;&#21464;&#37327;&#22788;&#29702;&#30340;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#30340;&#31639;&#27861;&#21487;&#33021;&#30001;&#20110;&#23545;&#26631;&#31614;&#30340;&#19981;&#24179;&#34913;&#26356;&#25935;&#24863;&#32780;&#34920;&#29616;&#36739;&#24046;&#65292;&#36825;&#19968;&#32467;&#35770;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.05248</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#26631;&#31614;&#23398;&#20064;&#20013;Macro-AUC&#30340;&#27867;&#21270;&#29702;&#35299;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Generalization of Macro-AUC in Multi-label Learning. (arXiv:2305.05248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102; multi-label &#23398;&#20064;&#20013;&#24120;&#29992;&#30340; Macro-AUC &#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#24182;&#21457;&#29616;&#25968;&#25454;&#38598;&#20013;&#26631;&#31614;&#19981;&#24179;&#34913;&#23545;&#27867;&#21270;&#30028;&#38480;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#26410;&#32463;&#21464;&#37327;&#22788;&#29702;&#30340;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#30340;&#31639;&#27861;&#21487;&#33021;&#30001;&#20110;&#23545;&#26631;&#31614;&#30340;&#19981;&#24179;&#34913;&#26356;&#25935;&#24863;&#32780;&#34920;&#29616;&#36739;&#24046;&#65292;&#36825;&#19968;&#32467;&#35770;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#26631;&#31614;&#23398;&#20064;&#20013;&#65292;Macro-AUC&#26159;&#31867;&#20869;AUC&#31639;&#26415;&#24179;&#22343;&#20540;&#65292;&#36890;&#24120;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#29702;&#35770;&#29702;&#35299;&#36828;&#36828;&#19981;&#36275;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22522;&#20110;&#23545;&#24212;&#30340;&#20195;&#29702;&#25439;&#22833;&#20989;&#25968;&#34920;&#24449;&#21508;&#31181;&#23398;&#20064;&#31639;&#27861;&#30340;&#23439;AUC&#30340;&#27867;&#21270;&#23646;&#24615;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30830;&#23450;&#20102;&#24433;&#21709;&#27867;&#21270;&#30028;&#38480;&#30340;&#25968;&#25454;&#38598;&#30340;&#20851;&#38190;&#22240;&#32032;&#65306;&#26631;&#31614;&#31867;&#21035;&#19981;&#24179;&#34913;&#12290;&#25105;&#20204;&#23545;&#19981;&#24179;&#34913;&#24863;&#30693;&#35823;&#24046;&#30028;&#38480;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#26410;&#32463;&#21464;&#37327;&#22788;&#29702;&#30340;&#22522;&#20110;&#25439;&#22833;&#20989;&#25968;&#30340;&#31639;&#27861;&#27604;&#25552;&#20986;&#30340;&#22522;&#20110;&#25104;&#23545;&#21644;&#37325;&#26032;&#21152;&#26435;&#30340;&#31639;&#27861;&#26356;&#25935;&#24863;&#20110;&#26631;&#31614;&#31867;&#21035;&#30340;&#19981;&#24179;&#34913;&#65292;&#36825;&#21487;&#33021;&#24847;&#21619;&#30528;&#23427;&#30340;&#24615;&#33021;&#36739;&#24046;&#12290;&#27492;&#22806;&#65292;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#32463;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#23601;&#25216;&#26415;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#65288;&#26356;&#36890;&#29992;&#30340;&#65289;McDiarmid&#22411;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
Macro-AUC is the arithmetic mean of the class-wise AUCs in multi-label learning and is commonly used in practice. However, its theoretical understanding is far lacking. Toward solving it, we characterize the generalization properties of various learning algorithms based on the corresponding surrogate losses w.r.t. Macro-AUC. We theoretically identify a critical factor of the dataset affecting the generalization bounds: \emph{the label-wise class imbalance}. Our results on the imbalance-aware error bounds show that the widely-used univariate loss-based algorithm is more sensitive to the label-wise class imbalance than the proposed pairwise and reweighted loss-based ones, which probably implies its worse performance. Moreover, empirical results on various datasets corroborate our theory findings. To establish it, technically, we propose a new (and more general) McDiarmid-type concentration inequality, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.05014</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#38454;&#28140;&#28779;&#38543;&#26426;&#28418;&#31227;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving Linear Inverse Problems using Higher-Order Annealed Langevin Diffusion. (arXiv:2305.05014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454; Langevin &#21160;&#21147;&#23398;&#30340;&#31639;&#27861;&#65292;&#21487;&#26356;&#39640;&#25928;&#22320;&#37319;&#26679;&#26410;&#30693;&#21464;&#37327;&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#21152;&#20837;&#28140;&#28779;&#36807;&#31243;&#65292;&#33021;&#24212;&#29992;&#20110;&#31163;&#25955;&#26410;&#30693;&#21464;&#37327;&#24773;&#20917;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#22312;&#22810;&#20010;&#20219;&#21153;&#20013;&#30456;&#23545;&#31454;&#20105;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#38454; Langevin &#28418;&#31227;&#30340;&#32447;&#24615;&#21453;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39044;&#22788;&#29702;&#30340;&#20108;&#38454;&#21644;&#19977;&#38454; Langevin &#21160;&#21147;&#23398;&#65292;&#36825;&#20123;&#21160;&#21147;&#23398;&#26126;&#26174;&#22320;&#20174;&#25105;&#20204;&#24863;&#20852;&#36259;&#30340;&#26410;&#30693;&#21464;&#37327;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#21516;&#26102;&#27604;&#20854;&#19968;&#38454;&#23545;&#24212;&#29289;&#21644;&#20004;&#31181;&#21160;&#21147;&#23398;&#30340;&#38750;&#39044;&#22788;&#29702;&#29256;&#26412;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20004;&#31181;&#39044;&#22788;&#29702;&#21160;&#21147;&#23398;&#26159;&#33391;&#23450;&#20041;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#19982;&#38750;&#39044;&#22788;&#29702;&#24773;&#20917;&#30456;&#21516;&#30340;&#21807;&#19968;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#21152;&#20837;&#20102;&#19968;&#20010;&#28140;&#28779;&#36807;&#31243;&#65292;&#36825;&#20855;&#26377;&#21452;&#37325;&#20248;&#28857;&#65292;&#19968;&#26041;&#38754;&#36827;&#19968;&#27493;&#21152;&#36895;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#21478;&#19968;&#26041;&#38754;&#65292;&#20801;&#35768;&#25105;&#20204;&#36866;&#24212;&#26410;&#30693;&#21464;&#37327;&#20026;&#31163;&#25955;&#30340;&#24773;&#20917;&#12290;&#22312;&#20004;&#20010;&#19981;&#21516;&#30340;&#20219;&#21153;&#65288;MIMO &#31526;&#21495;&#26816;&#27979;&#21644;&#36890;&#36947;&#20272;&#35745;&#65289;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#30456;&#23545;&#20110;&#31454;&#20105;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#65289;&#25152;&#23454;&#29616;&#30340;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a solution for linear inverse problems based on higher-order Langevin diffusion. More precisely, we propose pre-conditioned second-order and third-order Langevin dynamics that provably sample from the posterior distribution of our unknown variables of interest while being computationally more efficient than their first-order counterpart and the non-conditioned versions of both dynamics. Moreover, we prove that both pre-conditioned dynamics are well-defined and have the same unique invariant distributions as the non-conditioned cases. We also incorporate an annealing procedure that has the double benefit of further accelerating the convergence of the algorithm and allowing us to accommodate the case where the unknown variables are discrete. Numerical experiments in two different tasks (MIMO symbol detection and channel estimation) showcase the generality of our method and illustrate the high performance achieved relative to competing approaches (including learning-based ones)
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23618;&#27425;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22359;&#22352;&#26631;&#19979;&#38477;&#20998;&#24067;&#24335;&#31639;&#27861;&#23454;&#29616;&#23545;&#23458;&#25143;&#31471;&#31169;&#26377;&#25968;&#25454;&#19981;&#36879;&#38706;&#30340;&#23398;&#20064;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#19978;&#19982;&#27491;&#21017;&#21270;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2305.04979</link><description>&lt;p&gt;
FedHB: &#23618;&#27425;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
FedHB: Hierarchical Bayesian Federated Learning. (arXiv:2305.04979v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04979
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23618;&#27425;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22359;&#22352;&#26631;&#19979;&#38477;&#20998;&#24067;&#24335;&#31639;&#27861;&#23454;&#29616;&#23545;&#23458;&#25143;&#31471;&#31169;&#26377;&#25968;&#25454;&#19981;&#36879;&#38706;&#30340;&#23398;&#20064;&#65292;&#22312;&#25910;&#25947;&#36895;&#24230;&#19978;&#19982;&#27491;&#21017;&#21270;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23618;&#27425;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23618;&#27425;&#36125;&#21494;&#26031;&#24314;&#27169;&#21512;&#29702;&#22320;&#25551;&#36848;&#20102;&#23458;&#25143;&#31471;&#26412;&#22320;&#25968;&#25454;&#30340;&#29983;&#25104;&#36807;&#31243;&#65306;&#26500;&#25104;&#23458;&#25143;&#31471;&#26412;&#22320;&#27169;&#22411;&#30340;&#38543;&#26426;&#21464;&#37327;&#65292;&#30001;&#26356;&#39640;&#27700;&#24179;&#30340;&#20840;&#23616;&#21464;&#37327;&#36827;&#34892;&#25511;&#21046;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#36125;&#21494;&#26031;&#27169;&#22411;&#20013;&#30340;&#21464;&#20998;&#25512;&#26029;&#23548;&#33268;&#20102;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#22359;&#22352;&#26631;&#19979;&#38477;&#27714;&#35299;&#25104;&#20026;&#19968;&#20010;&#21487;&#20998;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#24335;&#31639;&#27861;&#65292;&#36825;&#20351;&#24471;&#23458;&#25143;&#31471;&#23436;&#20840;&#19981;&#38656;&#35201;&#36879;&#38706;&#33258;&#24049;&#30340;&#31169;&#26377;&#25968;&#25454;&#65292;&#22240;&#27492;&#19982;&#32852;&#37030;&#23398;&#20064;&#23436;&#20840;&#20860;&#23481;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#65292;&#25105;&#20204;&#30340;&#22359;&#22352;&#26631;&#31639;&#27861;&#20855;&#26377;&#29305;&#23450;&#24418;&#24335;&#65292;&#21253;&#25324;Fed-Avg&#21644;Fed-Prox&#22312;&#20869;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;FL&#31639;&#27861;&#37117;&#21487;&#20197;&#20316;&#20026;&#20854;&#29305;&#20363;&#36827;&#34892;&#23376;&#24402;&#12290;&#38500;&#20102;&#24341;&#20837;&#26032;&#30340;&#24314;&#27169;&#21644;&#23548;&#20986;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#22359;&#22352;&#26631;FL&#31639;&#27861;&#20197;$O(1/\sqrt{t})$&#30340;&#36895;&#24230;&#25910;&#25947;&#21040;&#30446;&#26631;&#30340;&#65288;&#26412;&#22320;&#65289;&#26368;&#20248;&#35299;&#65292;&#36825;&#19982;&#27491;&#21017;&#21270;&#20855;&#26377;&#30456;&#21516;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel hierarchical Bayesian approach to Federated Learning (FL), where our model reasonably describes the generative process of clients' local data via hierarchical Bayesian modeling: constituting random variables of local models for clients that are governed by a higher-level global variate. Interestingly, the variational inference in our Bayesian model leads to an optimisation problem whose block-coordinate descent solution becomes a distributed algorithm that is separable over clients and allows them not to reveal their own private data at all, thus fully compatible with FL. We also highlight that our block-coordinate algorithm has particular forms that subsume the well-known FL algorithms including Fed-Avg and Fed-Prox as special cases. Beyond introducing novel modeling and derivations, we also offer convergence analysis showing that our block-coordinate FL algorithm converges to an (local) optimum of the objective at the rate of $O(1/\sqrt{t})$, the same rate as regul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#26680;/GP&#26041;&#27861;&#20272;&#35745;&#38750;&#32447;&#24615;&#21644;&#21442;&#25968;PDE&#36890;&#36807;Sobolev&#31354;&#38388;&#35823;&#24046;&#65292;&#24182;&#25351;&#20986;&#24403;PDE&#30340;&#35299;&#31354;&#38388;&#20805;&#20998;&#20809;&#28369;&#26102;&#65292;&#20855;&#26377;&#32500;&#24230;&#21451;&#22909;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.04962</link><description>&lt;p&gt;
&#20851;&#20110;&#38750;&#32447;&#24615;&#21644;&#21442;&#25968;PDE&#30340;&#26680;/GP&#26041;&#27861;&#35823;&#24046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Error Analysis of Kernel/GP Methods for Nonlinear and Parametric PDEs. (arXiv:2305.04962v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04962
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20351;&#29992;&#26680;/GP&#26041;&#27861;&#20272;&#35745;&#38750;&#32447;&#24615;&#21644;&#21442;&#25968;PDE&#36890;&#36807;Sobolev&#31354;&#38388;&#35823;&#24046;&#65292;&#24182;&#25351;&#20986;&#24403;PDE&#30340;&#35299;&#31354;&#38388;&#20805;&#20998;&#20809;&#28369;&#26102;&#65292;&#20855;&#26377;&#32500;&#24230;&#21451;&#22909;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#35299;&#20915;&#38750;&#32447;&#24615;&#21644;&#21487;&#33021;&#26159;&#21442;&#25968;PDE&#30340;&#20808;&#39564;Sobolev&#31354;&#38388;&#35823;&#24046;&#20272;&#35745;&#12290;&#20027;&#35201;&#30340;&#20551;&#35774;&#26159;&#65306;&#65288;1&#65289;&#26680;&#37325;&#29616;&#31354;&#38388;&#22312;&#36275;&#22815;&#27491;&#21017;&#30340;Sobolev&#31354;&#38388;&#20013;&#30340;&#36830;&#32493;&#23884;&#20837;&#65307;&#65288;2&#65289;&#24494;&#20998;&#31639;&#23376;&#21644;PDE&#30340;&#35299;&#26144;&#23556;&#22312;&#30456;&#24212;&#30340;Sobolev&#31354;&#38388;&#20043;&#38388;&#31283;&#23450;&#12290;&#36825;&#20123;&#35823;&#24046;&#20272;&#35745;&#23637;&#31034;&#20102;&#22312;PDE&#30340;&#35299;&#31354;&#38388;&#20805;&#20998;&#20809;&#28369;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#32500;&#24230;&#21451;&#22909;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a priori Sobolev-space error estimates for the solution of nonlinear, and possibly parametric, PDEs using Gaussian process and kernel based methods. The primary assumptions are: (1) a continuous embedding of the reproducing kernel Hilbert space of the kernel into a Sobolev space of sufficient regularity; and (2) the stability of the differential operator and the solution map of the PDE between corresponding Sobolev spaces. The proof is articulated around Sobolev norm error estimates for kernel interpolants and relies on the minimizing norm property of the solution. The error estimates demonstrate dimension-benign convergence rates if the solution space of the PDE is smooth enough. We illustrate these points with applications to high-dimensional nonlinear elliptic PDEs and parametric PDEs. Although some recent machine learning methods have been presented as breaking the curse of dimensionality in solving high-dimensional PDEs, our analysis suggests a more nuanced picture: t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#26102;&#38388;&#20449;&#21495;&#30340;&#21435;&#21367;&#31215;&#38382;&#39064;&#65292;&#36866;&#29992;&#20110;&#35266;&#27979;&#20540;&#20013;&#21487;&#33021;&#23384;&#22312;&#32570;&#22833;&#25968;&#25454;&#19988;&#20449;&#21495;&#28388;&#27874;&#22120;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.04871</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#21435;&#21367;&#31215;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Gaussian process deconvolution. (arXiv:2305.04871v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#26102;&#38388;&#20449;&#21495;&#30340;&#21435;&#21367;&#31215;&#38382;&#39064;&#65292;&#36866;&#29992;&#20110;&#35266;&#27979;&#20540;&#20013;&#21487;&#33021;&#23384;&#22312;&#32570;&#22833;&#25968;&#25454;&#19988;&#20449;&#21495;&#28388;&#27874;&#22120;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#21435;&#21367;&#31215;&#38382;&#39064;&#65292;&#21363;&#20174;&#21367;&#31215;&#22788;&#29702;&#30340;&#35266;&#27979;&#20540; $\mathbf{y}$ &#20013;&#24674;&#22797;&#28508;&#22312;&#20449;&#21495; $x(\cdot)$&#65292;&#20854;&#20013;&#35266;&#27979;&#20540; $\mathbf{y}$ &#21487;&#33021;&#23545;&#24212;&#20110; $y$ &#30340;&#19968;&#37096;&#20998;&#32570;&#22833;&#65292;&#28388;&#27874;&#22120; $h$ &#21487;&#33021;&#26410;&#30693;&#19988;&#22122;&#22768; $\eta$ &#21487;&#21152;&#24615;&#12290;&#24403; $x$ &#26159;&#36830;&#32493;&#26102;&#38388;&#20449;&#21495;&#26102;&#65292;&#25105;&#20204;&#37319;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20808;&#39564;&#20998;&#24067;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#21512;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#21435;&#21367;&#31215;&#31574;&#30053;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;&#30452;&#25509;&#27169;&#22411;&#65292;&#20197;&#24314;&#31435;&#20854;&#33391;&#22909;&#23450;&#20041;&#30340;&#26465;&#20214;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36716;&#21521;&#36870;&#38382;&#39064;&#65292;&#30740;&#31350;&#20102;&#65306;&#65288;i&#65289;&#19968;&#20123;&#24517;&#35201;&#26465;&#20214;&#65292;&#20351;&#24471;&#36125;&#21494;&#26031;&#21435;&#21367;&#31215;&#35745;&#31639;&#26377;&#21487;&#33021;&#25104;&#31435;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#22312;&#21738;&#31181;&#31243;&#24230;&#19978;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#21040;&#28388;&#27874;&#22120; $h$&#65292;&#20197;&#21450;&#22312;&#30450;&#21435;&#21367;&#31215;&#24773;&#20917;&#19979;&#21487;&#20197;&#36817;&#20284;&#28388;&#27874;&#22120; $h$ &#30340;&#31243;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#34987;&#31216;&#20026;&#39640;&#26031;&#36807;&#31243;&#21435;&#21367;&#31215;&#65288;GPDC&#65289;&#65292;&#24182;&#19982;&#20854;&#20182;&#21435;&#21367;&#31215;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Let us consider the deconvolution problem, that is, to recover a latent source $x(\cdot)$ from the observations $\y = [y_1,\ldots,y_N]$ of a convolution process $y = x\star h + \eta$, where $\eta$ is an additive noise, the observations in $\y$ might have missing parts with respect to $y$, and the filter $h$ could be unknown. We propose a novel strategy to address this task when $x$ is a continuous-time signal: we adopt a Gaussian process (GP) prior on the source $x$, which allows for closed-form Bayesian nonparametric deconvolution. We first analyse the direct model to establish the conditions under which the model is well defined. Then, we turn to the inverse problem, where we study i) some necessary conditions under which Bayesian deconvolution is feasible, and ii) to which extent the filter $h$ can be learnt from data or approximated for the blind deconvolution case. The proposed approach, termed Gaussian process deconvolution (GPDC) is compared to other deconvolution methods concep
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#26469;&#35780;&#20272;&#26657;&#20934;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#22823;&#32966;&#20877;&#26657;&#20934;&#31574;&#30053;&#65292;&#20351;&#23454;&#36341;&#32773;&#33021;&#22815;&#22312;&#28385;&#36275;&#25152;&#38656;&#30340;&#26657;&#20934;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#36127;&#36131;&#20219;&#22320;&#22686;&#24378;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2305.03780</link><description>&lt;p&gt;
&#20108;&#20803;&#20107;&#20214;&#30340;&#26657;&#20934;&#35780;&#20272;&#21644;&#22823;&#32966;&#20877;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Calibration Assessment and Boldness-Recalibration for Binary Events. (arXiv:2305.03780v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03780
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#26469;&#35780;&#20272;&#26657;&#20934;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#22823;&#32966;&#20877;&#26657;&#20934;&#31574;&#30053;&#65292;&#20351;&#23454;&#36341;&#32773;&#33021;&#22815;&#22312;&#28385;&#36275;&#25152;&#38656;&#30340;&#26657;&#20934;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#36127;&#36131;&#20219;&#22320;&#22686;&#24378;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#39044;&#27979;&#23545;&#20110;&#21307;&#23398;&#12289;&#32463;&#27982;&#12289;&#22270;&#20687;&#20998;&#31867;&#12289;&#20307;&#32946;&#20998;&#26512;&#12289;&#23089;&#20048;&#31561;&#35768;&#22810;&#39046;&#22495;&#20013;&#30340;&#20915;&#31574;&#21046;&#23450;&#33267;&#20851;&#37325;&#35201;&#12290;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#27010;&#29575;&#39044;&#27979;&#24212;&#35813; (i) &#26657;&#20934;&#33391;&#22909; (ii) &#20934;&#30830; (iii) &#22823;&#32966;&#65292;&#21363;&#36828;&#31163;&#20107;&#20214;&#30340;&#22522;&#30784;&#39057;&#29575;&#12290;&#28385;&#36275;&#36825;&#19977;&#20010;&#26465;&#20214;&#30340;&#39044;&#27979;&#23545;&#20110;&#20915;&#31574;&#21046;&#23450;&#26159;&#26377;&#20449;&#24687;&#37327;&#30340;&#12290;&#28982;&#32780;&#65292;&#26657;&#20934;&#21644;&#22823;&#32966;&#20043;&#38388;&#23384;&#22312;&#22522;&#26412;&#30340;&#32039;&#24352;&#20851;&#31995;&#65292;&#22240;&#20026;&#24403;&#39044;&#27979;&#36807;&#20110;&#35880;&#24910;&#26102;(&#21363;&#38750;&#22823;&#32966;)&#26657;&#20934;&#24230;&#37327;&#21487;&#20197;&#24456;&#39640;&#12290;&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#24320;&#21457;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#21644;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#26469;&#35780;&#20272;&#26657;&#20934;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#22823;&#32966;&#20877;&#26657;&#20934;&#31574;&#30053;&#65292;&#20351;&#23454;&#36341;&#32773;&#33021;&#22815;&#22312;&#28385;&#36275;&#25152;&#38656;&#30340;&#26657;&#20934;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#36127;&#36131;&#20219;&#22320;&#22686;&#24378;&#39044;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20801;&#35768;&#29992;&#25143;&#39044;&#20808;&#25351;&#23450;&#20182;&#20204;&#25152;&#38656;&#30340;&#21518;&#39564;&#26657;&#20934;&#27010;&#29575;&#65292;&#28982;&#21518;&#22312;&#27492;&#32422;&#26463;&#19979;&#26368;&#22823;&#21270;&#22686;&#24378;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probability predictions are essential to inform decision making in medicine, economics, image classification, sports analytics, entertainment, and many other fields. Ideally, probability predictions are (i) well calibrated, (ii) accurate, and (iii) bold, i.e., far from the base rate of the event. Predictions that satisfy these three criteria are informative for decision making. However, there is a fundamental tension between calibration and boldness, since calibration metrics can be high when predictions are overly cautious, i.e., non-bold. The purpose of this work is to develop a hypothesis test and Bayesian model selection approach to assess calibration, and a strategy for boldness-recalibration that enables practitioners to responsibly embolden predictions subject to their required level of calibration. Specifically, we allow the user to pre-specify their desired posterior probability of calibration, then maximally embolden predictions subject to this constraint. We verify the perfo
&lt;/p&gt;</description></item><item><title>PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.10255</link><description>&lt;p&gt;
PED-ANOVA: &#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#37327;&#21270;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA: Efficiently Quantifying Hyperparameter Importance in Arbitrary Subspaces. (arXiv:2304.10255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10255
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#27969;&#34892;&#20351;&#24471;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#23545;&#20110;&#35757;&#32451;&#24378;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#21448;&#20005;&#37325;&#20381;&#36182;&#20110;&#20102;&#35299;&#19981;&#21516;&#36229;&#21442;&#25968;&#30340;&#20316;&#29992;&#12290;&#36825;&#28608;&#21457;&#20102;&#20851;&#20110;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#30740;&#31350;&#65292;&#20363;&#22914;&#20351;&#29992;&#21151;&#33021;&#26041;&#24046;&#20998;&#26512; (f-ANOVA) &#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#21407;&#22987;&#30340; f-ANOVA &#20844;&#24335;&#19981;&#36866;&#29992;&#20110;&#31639;&#27861;&#35774;&#35745;&#24072;&#26368;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#65292;&#20363;&#22914;&#30001;&#26368;&#20339;&#24615;&#33021;&#23450;&#20041;&#30340;&#23376;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#26032;&#30340;&#38024;&#23545;&#20219;&#24847;&#23376;&#31354;&#38388;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#20351;&#29992; Pearson &#25955;&#24230; (PED) &#23454;&#29616;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#38381;&#24335;&#35745;&#31639;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20010;&#26032;&#31639;&#27861;&#65292;&#31216;&#20026; PED-ANOVA&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#35782;&#21035;&#19981;&#21516;&#23376;&#31354;&#38388;&#20013;&#37325;&#35201;&#30340;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#35745;&#31639;&#25928;&#29575;&#26497;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent rise in popularity of Hyperparameter Optimization (HPO) for deep learning has highlighted the role that good hyperparameter (HP) space design can play in training strong models. In turn, designing a good HP space is critically dependent on understanding the role of different HPs. This motivates research on HP Importance (HPI), e.g., with the popular method of functional ANOVA (f-ANOVA). However, the original f-ANOVA formulation is inapplicable to the subspaces most relevant to algorithm designers, such as those defined by top performance. To overcome this problem, we derive a novel formulation of f-ANOVA for arbitrary subspaces and propose an algorithm that uses Pearson divergence (PED) to enable a closed-form computation of HPI. We demonstrate that this new algorithm, dubbed PED-ANOVA, is able to successfully identify important HPs in different subspaces while also being extremely computationally efficient.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.12407</link><description>&lt;p&gt;
Langevin&#22411;Monte Carlo&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic analysis of Langevin-type Monte Carlo algorithms. (arXiv:2303.12407v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Langevin&#22411;&#31639;&#27861;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21183;&#20989;&#25968;&#26159;&#32791;&#25955;&#30340;&#65292;&#19988;&#20854;&#24369;&#26799;&#24230;&#20855;&#26377;&#26377;&#38480;&#30340;&#36830;&#32493;&#24615;&#27169;&#37327;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#30340;&#38750;&#28176;&#36827;&#24615;&#65292;&#23427;&#34913;&#37327;&#20102;&#21513;&#24067;&#26031;&#20998;&#24067;&#19982;&#22522;&#20110;Liptser-Shiryaev&#29702;&#35770;&#21644;&#20989;&#25968;&#19981;&#31561;&#24335;&#30340;Langevin&#22411;&#31639;&#27861;&#30340;&#19968;&#33324;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#20010;&#19978;&#38480;&#26469;&#23637;&#31034;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#26159;&#20805;&#20998;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25511;&#21046;&#21442;&#25968;&#26469;&#33719;&#24471;Langevin Monte Carlo&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#25552;&#20986;&#20102;&#29699;&#24418;&#24179;&#28369;&#25216;&#26415;&#30340;Langevin&#22411;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Langevin-type algorithms for Gibbs distributions such that the potentials are dissipative and their weak gradients have the finite moduli of continuity. Our main result is a non-asymptotic upper bound of the 2-Wasserstein distance between the Gibbs distribution and the law of general Langevin-type algorithms based on the Liptser--Shiryaev theory and functional inequalities. We apply this bound to show that the dissipativity of the potential and the $\alpha$-H\"{o}lder continuity of the gradient with $\alpha&gt;1/3$ are sufficient for the convergence of the Langevin Monte Carlo algorithm with appropriate control of the parameters. We also propose Langevin-type algorithms with spherical smoothing for potentials without convexity or continuous differentiability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;PnP&#26041;&#27861;&#65292;&#20351;&#29992;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#36739;&#36731;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.07271</link><description>&lt;p&gt;
&#21487;&#35777;&#25910;&#25947;&#30340;&#21363;&#25554;&#21363;&#29992;&#25311;&#29275;&#39039;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Provably Convergent Plug-and-Play Quasi-Newton Methods. (arXiv:2303.07271v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07271
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;PnP&#26041;&#27861;&#65292;&#20351;&#29992;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#36739;&#36731;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#25554;&#21363;&#29992;&#65288;PnP&#65289;&#26041;&#27861;&#26159;&#19968;&#31867;&#39640;&#25928;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#26088;&#22312;&#21033;&#29992;&#32463;&#20856;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;ISTA&#25110;ADMM&#65289;&#65292;&#23558;&#25968;&#25454;&#20445;&#30495;&#24230;&#39033;&#21644;&#28145;&#24230;&#21435;&#22122;&#22120;&#30456;&#32467;&#21512;&#12290;&#29616;&#26377;&#30340;&#21487;&#35777;&#26126;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#20005;&#26684;&#30340;&#38480;&#21046;&#65292;&#22914;&#38750;&#25193;&#24352;&#24615;&#25110;&#20005;&#26684;&#20984;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#30340;PnP&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#36817;&#31471;&#21435;&#22122;&#22120;&#26045;&#21152;&#30456;&#23545;&#36739;&#36731;&#30340;&#26465;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#22823;&#22823;&#21152;&#36895;&#25910;&#25947;&#12290;&#36890;&#36807;&#23558;&#28145;&#24230;&#21435;&#22122;&#22120;&#29305;&#21035;&#21442;&#25968;&#21270;&#20026;&#26799;&#24230;&#27493;&#39588;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25311;&#29275;&#39039;PnP&#31639;&#27861;&#30340;&#22266;&#23450;&#28857;&#34920;&#24449;&#20026;&#21487;&#33021;&#38750;&#20984;&#20989;&#25968;&#30340;&#20020;&#30028;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play (PnP) methods are a class of efficient iterative methods that aim to combine data fidelity terms and deep denoisers using classical optimization algorithms, such as ISTA or ADMM. Existing provable PnP methods impose heavy restrictions on the denoiser or fidelity function, such as nonexpansiveness or strict convexity. In this work, we propose a provable PnP method that imposes relatively light conditions based on proximal denoisers, and introduce a quasi-Newton step to greatly accelerate convergence. By specially parameterizing the deep denoiser as a gradient step, we further characterize the fixed-points of the quasi-Newton PnP algorithm as critical points of a possibly non-convex function.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.07260</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#20808;&#39564;&#32593;&#32476;&#30340;&#39640;&#32500;&#36755;&#20986;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#20123;&#22522;&#26412;&#38382;&#39064;&#28041;&#21450;&#21040;&#26410;&#30693;&#30340;&#39640;&#32500;&#24230;&#26144;&#23556;&#19968;&#32452;&#21487;&#25511;&#21464;&#37327;&#21040;&#26114;&#36149;&#23454;&#39564;&#32467;&#26524;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20219;&#21153;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#25216;&#26415;&#24050;&#34987;&#35777;&#26126;&#22312;&#20351;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#30446;&#26631;&#20989;&#25968;&#35780;&#20272;&#26102;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#26102;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#24403;&#22788;&#29702;&#39640;&#32500;&#36755;&#20986;&#26102;&#65292;&#20854;&#24615;&#33021;&#21463;&#21040;&#24433;&#21709;&#12290;&#20026;&#20811;&#26381;&#32500;&#24230;&#20027;&#35201;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#20030;&#38598;&#25104;&#30340;BO&#21644;&#24207;&#36143;&#20915;&#31574;&#21046;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#12290;&#20351;&#29992;&#36866;&#24403;&#30340;&#20307;&#31995;&#32467;&#26500;&#36873;&#25321;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#36817;&#20284;&#35774;&#35745;&#21464;&#37327;&#21644;&#24863;&#20852;&#36259;&#37327;&#20043;&#38388;&#30340;&#21151;&#33021;&#20851;&#31995;&#65292;&#21363;&#20351;&#22312;&#21518;&#32773;&#21462;&#20540;&#20110;&#39640;&#32500;&#21521;&#37327;&#31354;&#38388;&#25110;&#29978;&#33267;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32972;&#26223;&#19979;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#22788;&#29702;&#39640;&#32500;&#24230;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;P-&#23398;&#20064;&#22120;&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#30340;&#23450;&#21046;&#20004;&#38454;&#27573;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#20381;&#38752;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#28789;&#27963;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.10913</link><description>&lt;p&gt;
&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#26524;&#30340;&#36817;&#22240;&#22240;&#26524;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Proximal Causal Learning of Conditional Average Treatment Effects. (arXiv:2301.10913v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10913
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;P-&#23398;&#20064;&#22120;&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#30340;&#23450;&#21046;&#20004;&#38454;&#27573;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#20381;&#38752;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#28789;&#27963;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#25928;&#28789;&#27963;&#22320;&#20272;&#35745;&#22788;&#29702;&#25928;&#26524;&#30340;&#24322;&#36136;&#24615;&#26159;&#20174;&#21307;&#23398;&#21040;&#24066;&#22330;&#31561;&#21508;&#31181;&#39046;&#22495;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20219;&#21153;&#65292;&#22312;&#27492;&#36807;&#31243;&#20013;&#26377;&#35768;&#22810;&#26377;&#21069;&#36884;&#30340;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#26524;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20272;&#35745;&#22120;&#36890;&#24120;&#20381;&#36182;&#20110;&#27979;&#37327;&#21040;&#30340;&#21327;&#21464;&#37327;&#36275;&#20197;&#35777;&#26126;&#26465;&#20214;&#20132;&#25442;&#24615;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;P-&#23398;&#20064;&#22120;&#65292;&#21463;&#21040;R-&#23398;&#20064;&#22120;&#21644;DR-&#23398;&#20064;&#22120;&#30340;&#21551;&#21457;&#65292;&#36825;&#26159;&#19968;&#31181;&#19987;&#38376;&#20026;&#22312;&#35266;&#23519;&#21040;&#30340;&#21327;&#21464;&#37327;&#32473;&#23450;&#21487;&#20132;&#25442;&#24615;&#26159;&#19981;&#21512;&#29702;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#26524;&#30340;&#23450;&#21046;&#20004;&#38454;&#27573;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#24076;&#26395;&#20381;&#38752;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;&#29616;&#25104;&#30340;&#25439;&#22833;&#26368;&#23567;&#21270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;&#65292;&#22312;&#26680;&#22238;&#24402;&#30340;&#24773;&#20917;&#19979;&#65292;&#21482;&#35201;&#22952;&#30861;&#32452;&#20214;&#24471;&#21040;&#21512;&#29702;&#30340;&#20272;&#35745;&#65292;&#23601;&#33021;&#28385;&#36275;&#20272;&#35745;&#35823;&#24046;&#30340;oracle&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently and flexibly estimating treatment effect heterogeneity is an important task in a wide variety of settings ranging from medicine to marketing, and there are a considerable number of promising conditional average treatment effect estimators currently available. These, however, typically rely on the assumption that the measured covariates are enough to justify conditional exchangeability. We propose the P-learner, motivated by the R- and DR-learner, a tailored two-stage loss function for learning heterogeneous treatment effects in settings where exchangeability given observed covariates is an implausible assumption, and we wish to rely on proxy variables for causal inference. Our proposed estimator can be implemented by off-the-shelf loss-minimizing machine learning methods, which in the case of kernel regression satisfies an oracle bound on the estimated error as long as the nuisance components are estimated reasonably well.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wi-Fi&#20449;&#36947;&#25968;&#25454;&#30340;&#20154;&#19982;&#20154;&#20114;&#21160;&#35782;&#21035;&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#27880;&#24847;&#21147;&#21452;&#21521;&#38376;&#25511;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#39640;&#31934;&#24230;&#30340;&#23454;&#26102;&#22788;&#29702;&#65292;&#20934;&#30830;&#29575;&#36798;&#21040;98.22%&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;GUI&#24212;&#29992;&#31243;&#24207;&#26041;&#20415;&#23454;&#26102;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2202.08146</link><description>&lt;p&gt;
&#22522;&#20110;Wi-Fi&#20449;&#36947;&#25968;&#25454;&#30340;&#20154;&#19982;&#20154;&#20114;&#21160;&#35782;&#21035;&#30340;&#21069;&#30651;&#24615;&#26041;&#27861;&#8212;&#8212;&#20351;&#29992;&#20855;&#26377;GUI&#24212;&#29992;&#31243;&#24207;&#23454;&#29616;&#30340;&#27880;&#24847;&#21147;&#21452;&#21521;&#38376;&#25511;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;(arXiv:2202.08146v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
A Prospective Approach for Human-to-Human Interaction Recognition from Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural Network with GUI Application Implementation. (arXiv:2202.08146v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.08146
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wi-Fi&#20449;&#36947;&#25968;&#25454;&#30340;&#20154;&#19982;&#20154;&#20114;&#21160;&#35782;&#21035;&#30340;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#27880;&#24847;&#21147;&#21452;&#21521;&#38376;&#25511;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#39640;&#31934;&#24230;&#30340;&#23454;&#26102;&#22788;&#29702;&#65292;&#20934;&#30830;&#29575;&#36798;&#21040;98.22%&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;GUI&#24212;&#29992;&#31243;&#24207;&#26041;&#20415;&#23454;&#26102;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#26368;&#36817;&#30340;&#25216;&#26415;&#36827;&#27493;&#12289;&#20154;&#24037;&#26234;&#33021;&#31639;&#27861;&#12289;&#26234;&#33021;&#22478;&#24066;&#21644;&#31038;&#20250;&#32463;&#27982;&#21464;&#38761;&#30340;&#38656;&#35201;&#65292;&#20154;&#31867;&#27963;&#21160;&#35782;&#21035;(HAR)&#30740;&#31350;&#24050;&#32463;&#33719;&#24471;&#20102;&#37325;&#35201;&#30340;&#21160;&#21147;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#20256;&#24863;&#22120;&#30340;HAR&#35299;&#20915;&#26041;&#26696;&#23384;&#22312;&#38544;&#31169;&#38382;&#39064;&#12289;&#23384;&#20648;&#21644;&#21151;&#29575;&#28040;&#32791;&#38382;&#39064;&#20197;&#21450;&#20329;&#25140;&#20256;&#24863;&#22120;&#30340;&#19981;&#36866;&#24863;&#65292;&#36825;&#20419;&#20351;&#30740;&#31350;&#20154;&#21592;&#35266;&#23519;&#21040;HAR&#30740;&#31350;&#30340;&#33539;&#24335;&#36716;&#21464;&#12290;&#20316;&#20026;&#22238;&#24212;&#65292;&#22522;&#20110;WiFi&#30340;HAR&#22240;&#20854;&#26356;&#31895;&#31890;&#24230;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#30340;&#21487;&#29992;&#24615;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;WiFi&#30340;HAR&#26041;&#27861;&#20165;&#38480;&#20110;&#23545;&#22312;&#30456;&#31561;&#26102;&#38388;&#20869;&#25191;&#34892;&#30340;&#29420;&#31435;&#21644;&#38750;&#24182;&#21457;&#20154;&#31867;&#27963;&#21160;&#36827;&#34892;&#20998;&#31867;&#12290;&#19982;&#26368;&#36817;&#30340;&#30740;&#31350;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#21033;&#29992;&#20102;&#22810;&#36755;&#20837;&#22810;&#36755;&#20986;&#36890;&#20449;&#38142;&#36335;&#65292;&#20854;&#20013;&#21457;&#23556;&#22120;&#26159;WiFi&#36335;&#30001;&#22120;&#65292;&#25509;&#25910;&#22120;&#26159;&#37197;&#22791;&#20102;Intel 5300 NIC&#30340;&#26234;&#33021;&#25163;&#26426;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#21452;&#21521;&#38376;&#25511;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;(ABiGRNN)&#30340;WiFi&#20449;&#36947;&#25968;&#25454;&#30340;&#20154;&#19982;&#20154;&#20114;&#21160;(HHI)&#35782;&#21035;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#39640;&#31934;&#24230;&#30340;&#23454;&#26102;&#22788;&#29702;&#12290;&#25105;&#20204;&#20351;&#29992;HHI&#27963;&#21160;&#25968;&#25454;&#38598;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;98.22%&#30340;&#20934;&#30830;&#29575;&#65292;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22270;&#24418;&#29992;&#25143;&#30028;&#38754;(GUI)&#24212;&#29992;&#31243;&#24207;&#65292;&#21487;&#20197;&#22312;&#23454;&#26102;&#22330;&#26223;&#20013;&#36731;&#26494;&#23454;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;HHI&#12290;
&lt;/p&gt;
&lt;p&gt;
Human Activity Recognition (HAR) research has gained significant momentum due to recent technological advancements, artificial intelligence algorithms, the need for smart cities, and socioeconomic transformation. However, existing computer vision and sensor-based HAR solutions have limitations such as privacy issues, memory and power consumption, and discomfort in wearing sensors for which researchers are observing a paradigm shift in HAR research. In response, WiFi-based HAR is gaining popularity due to the availability of more coarse-grained Channel State Information. However, existing WiFi-based HAR approaches are limited to classifying independent and non-concurrent human activities performed within equal time duration. Recent research commonly utilizes a Single Input Multiple Output communication link with a WiFi signal of 5 GHz channel frequency, using two WiFi routers or two Intel 5300 NICs as transmitter-receiver. Our study, on the other hand, utilizes a Multiple Input Multiple
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20445;&#35777;&#32852;&#37030;&#23398;&#20064;&#20013;&#20844;&#24179;&#24615;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615; (PF) &#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#26131;&#20110;&#23454;&#29616;&#30340;&#31639;&#27861; PropFair&#65292;&#33021;&#22815;&#22312;&#25152;&#26377;&#23458;&#25143;&#31471;&#24179;&#22343;&#24615;&#33021;&#21644;&#26368;&#24046; 10% &#23458;&#25143;&#31471;&#24179;&#22343;&#24615;&#33021;&#20043;&#38388;&#36798;&#21040;&#33391;&#22909;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2202.01666</link><description>&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Proportional Fairness in Federated Learning. (arXiv:2202.01666v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.01666
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20445;&#35777;&#32852;&#37030;&#23398;&#20064;&#20013;&#20844;&#24179;&#24615;&#30340;&#27604;&#20363;&#20844;&#24179;&#24615; (PF) &#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#26131;&#20110;&#23454;&#29616;&#30340;&#31639;&#27861; PropFair&#65292;&#33021;&#22815;&#22312;&#25152;&#26377;&#23458;&#25143;&#31471;&#24179;&#22343;&#24615;&#33021;&#21644;&#26368;&#24046; 10% &#23458;&#25143;&#31471;&#24179;&#22343;&#24615;&#33021;&#20043;&#38388;&#36798;&#21040;&#33391;&#22909;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#32852;&#37030;&#23398;&#20064;&#31995;&#32479;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#37096;&#32626;&#65292;&#20445;&#35777;&#20844;&#24179;&#24615;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#20294;&#20063;&#38754;&#20020;&#30528;&#25361;&#25112;&#65292;&#21363;&#38656;&#35201;&#20026;&#20247;&#22810;&#19981;&#21516;&#30340;&#23458;&#25143;&#31471;&#25552;&#20379;&#21512;&#29702;&#28385;&#24847;&#30340;&#34920;&#29616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#24182;&#30740;&#31350;&#20102;&#32852;&#37030;&#23398;&#20064;&#20013;&#19968;&#31181;&#26032;&#30340;&#20844;&#24179;&#24615;&#27010;&#24565;&#65292;&#21363;&#27604;&#20363;&#20844;&#24179;&#24615; (PF)&#65292;&#23427;&#22522;&#20110;&#27599;&#20010;&#23458;&#25143;&#31471;&#24615;&#33021;&#30340;&#30456;&#23545;&#21464;&#21270;&#12290;&#36890;&#36807;&#19982;&#20132;&#26131;&#21338;&#24328;&#30340;&#32852;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; PropFair&#65292;&#19968;&#31181;&#26032;&#39062;&#19988;&#26131;&#20110;&#23454;&#29616;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#23547;&#25214;&#27604;&#20363;&#20844;&#24179;&#35299;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#25910;&#25947;&#24615;&#36136;&#12290;&#36890;&#36807;&#23545;&#35270;&#35273;&#21644;&#35821;&#35328;&#25968;&#25454;&#38598;&#30340;&#24191;&#27867;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126; PropFair &#33021;&#22815;&#22823;&#33268;&#25214;&#21040; PF &#35299;&#65292;&#24182;&#22312;&#25152;&#26377;&#23458;&#25143;&#31471;&#30340;&#24179;&#22343;&#24615;&#33021;&#21644;&#26368;&#24046; 10% &#23458;&#25143;&#31471;&#30340;&#24179;&#22343;&#24615;&#33021;&#20043;&#38388;&#23454;&#29616;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312; \url{https://github.com/huawei-noah/Federated-Learning/tree/main/FairFL} &#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasingly broad deployment of federated learning (FL) systems in the real world, it is critical but challenging to ensure fairness in FL, i.e. reasonably satisfactory performances for each of the numerous diverse clients. In this work, we introduce and study a new fairness notion in FL, called proportional fairness (PF), which is based on the relative change of each client's performance. From its connection with the bargaining games, we propose PropFair, a novel and easy-to-implement algorithm for finding proportionally fair solutions in FL and study its convergence properties. Through extensive experiments on vision and language datasets, we demonstrate that PropFair can approximately find PF solutions, and it achieves a good balance between the average performances of all clients and of the worst 10% clients. Our code is available at \url{https://github.com/huawei-noah/Federated-Learning/tree/main/FairFL}.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#20302;&#19988;&#39640;&#31934;&#24230;&#30340;&#22534;&#21472;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#24120;&#35268;&#34880;&#28082;&#26816;&#26597;&#20013;&#35782;&#21035;COVID-19&#24739;&#32773;&#65292;&#20855;&#26377;&#24456;&#39640;&#30340;&#20934;&#30830;&#29575;&#12289;&#31934;&#30830;&#24230;&#21644;&#21484;&#22238;&#29575;&#12290;</title><link>http://arxiv.org/abs/2108.05660</link><description>&lt;p&gt;
&#21033;&#29992;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#20174;&#24120;&#35268;&#34880;&#28082;&#26816;&#26597;&#20013;&#24320;&#21457;&#26080;&#39118;&#38505;&#30340;COVID-19&#31579;&#26597;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Development of a Risk-Free COVID-19 Screening Algorithm from Routine Blood Tests Using Ensemble Machine Learning. (arXiv:2108.05660v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.05660
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#20302;&#19988;&#39640;&#31934;&#24230;&#30340;&#22534;&#21472;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#24120;&#35268;&#34880;&#28082;&#26816;&#26597;&#20013;&#35782;&#21035;COVID-19&#24739;&#32773;&#65292;&#20855;&#26377;&#24456;&#39640;&#30340;&#20934;&#30830;&#29575;&#12289;&#31934;&#30830;&#24230;&#21644;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#36716;&#24405;&#32858;&#21512;&#37238;&#38142;&#21453;&#24212;&#65288;RT-PCR&#65289;&#26159;&#36776;&#21035;COVID-19&#24863;&#26579;&#30340;&#38134;&#24377;&#35786;&#26029;&#26816;&#27979;&#12290;&#24555;&#36895;&#25239;&#21407;&#26816;&#27979;&#26159;&#19968;&#31181;&#31579;&#26597;&#26816;&#27979;&#65292;&#21487;&#22312;15&#20998;&#38047;&#20869;&#35782;&#21035;COVID-19&#38451;&#24615;&#24739;&#32773;&#65292;&#20294;&#20854;&#28789;&#25935;&#24230;&#20302;&#20110;PCR&#26816;&#27979;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#21033;&#29992;COVID-19&#24739;&#32773;&#20813;&#30123;&#21644;&#34880;&#28082;&#23398;&#36164;&#26009;&#30340;&#21442;&#25968;&#20559;&#24046;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39118;&#38505;&#20302;&#19988;&#39640;&#31934;&#24230;&#30340;&#22534;&#21472;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20174;&#24120;&#35268;&#34880;&#28082;&#26816;&#26597;&#20013;&#35782;&#21035;COVID-19&#24739;&#32773;&#65292;&#20855;&#26377;&#24456;&#39640;&#30340;&#20934;&#30830;&#29575;&#12289;&#31934;&#30830;&#24230;&#21644;&#21484;&#22238;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Reverse Transcription Polymerase Chain Reaction (RTPCR)} test is the silver bullet diagnostic test to discern COVID infection. Rapid antigen detection is a screening test to identify COVID positive patients in little as 15 minutes, but has a lower sensitivity than the PCR tests. Besides having multiple standardized test kits, many people are getting infected and either recovering or dying even before the test due to the shortage and cost of kits, lack of indispensable specialists and labs, time-consuming result compared to bulk population especially in developing and underdeveloped countries. Intrigued by the parametric deviations in immunological and hematological profile of a COVID patient, this research work leveraged the concept of COVID-19 detection by proposing a risk-free and highly accurate Stacked Ensemble Machine Learning model to identify a COVID patient from communally available-widespread-cheap routine blood tests which gives a promising accuracy, precision, recall and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;$M^3-UCRL$&#65292;&#22312;&#26410;&#30693;&#31995;&#32479;&#21160;&#21147;&#23398;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#24182;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#38382;&#39064;&#27714;&#35299;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2107.04050</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#22810;&#26234;&#33021;&#20307;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning. (arXiv:2107.04050v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.04050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;$M^3-UCRL$&#65292;&#22312;&#26410;&#30693;&#31995;&#32479;&#21160;&#21147;&#23398;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#24182;&#23454;&#29616;&#20102;&#21487;&#35777;&#26126;&#30340;&#38382;&#39064;&#27714;&#35299;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#31995;&#32479;&#30340;&#23398;&#20064;&#20805;&#28385;&#25361;&#25112;&#65292;&#21253;&#25324;&#26234;&#33021;&#20307;&#30456;&#20114;&#20316;&#29992;&#25152;&#24341;&#20837;&#30340;&#38750;&#31283;&#24577;&#21644;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;&#32452;&#21512;&#24615;&#36136;&#31561;&#22810;&#20010;&#22240;&#32032;&#12290;&#26412;&#25991;&#20851;&#27880;&#30340;&#26159;&#22343;&#22330;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20551;&#35774;&#23384;&#22312;&#26080;&#38480;&#25968;&#37327;&#30340;&#30456;&#21516;&#26234;&#33021;&#20307;&#65292;&#26088;&#22312;&#20849;&#21516;&#26368;&#22823;&#21270;&#25910;&#30410;&#12290;&#38024;&#23545;&#26410;&#30693;&#31995;&#32479;&#21160;&#21147;&#23398;&#30340;&#24773;&#20917;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;$M^3-UCRL$&#65292;&#22312;&#31574;&#30053;&#23398;&#20064;&#26399;&#38388;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#65292;&#24182;&#23454;&#29616;&#20102;&#36825;&#19968;&#38382;&#39064;&#30340;&#21487;&#35777;&#26126;&#27714;&#35299;&#12290;&#35813;&#31639;&#27861;&#22312;&#22810;&#20010;&#22522;&#20934;&#38382;&#39064;&#19978;&#30340;&#34920;&#29616;&#20248;&#20110;&#22810;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning in multi-agent systems is highly challenging due to several factors including the non-stationarity introduced by agents' interactions and the combinatorial nature of their state and action spaces. In particular, we consider the Mean-Field Control (MFC) problem which assumes an asymptotically infinite population of identical agents that aim to collaboratively maximize the collective reward. In many cases, solutions of an MFC problem are good approximations for large systems, hence, efficient learning for MFC is valuable for the analogous discrete agent setting with many agents. Specifically, we focus on the case of unknown system dynamics where the goal is to simultaneously optimize for the rewards and learn from experience. We propose an efficient model-based reinforcement learning algorithm, $M^3-UCRL$, that runs in episodes, balances between exploration and exploitation during policy learning, and provably solves this problem. Our main theoretical contributions are the first
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26680;Stein&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#24615;&#33021;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/1907.00586</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#26680;Stein&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
A Kernel Stein Test for Comparing Latent Variable Models. (arXiv:1907.00586v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1907.00586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26680;Stein&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#28508;&#21464;&#37327;&#30340;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#24403;&#21069;&#26041;&#27861;&#65292;&#24615;&#33021;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#38750;&#21442;&#25968;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#65292;&#26088;&#22312;&#27604;&#36739;&#20004;&#20010;&#27169;&#22411;&#65292;&#36825;&#20004;&#20010;&#27169;&#22411;&#37117;&#21487;&#33021;&#20855;&#26377;&#26410;&#35266;&#27979;&#30340;&#28508;&#21464;&#37327;&#65292;&#19988;&#35266;&#27979;&#21464;&#37327;&#30340;&#36793;&#32536;&#20998;&#24067;&#19981;&#21487;&#35266;&#27979;&#12290;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#23558;&#26368;&#36817;&#25552;&#20986;&#30340;&#26680;Stein&#36317;&#31163;(KSD)&#26816;&#39564;(Liu et al., 2016, Chwialkowski et al., 2016, Yang et al., 2018)&#25512;&#24191;&#21040;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#26159;&#19968;&#20010;&#27604;&#20043;&#21069;&#22788;&#29702;&#30340;&#20840;&#35266;&#27979;&#27169;&#22411;&#26356;&#21152;&#36890;&#29992;&#30340;&#31867;&#21035;&#12290;&#26032;&#30340;&#26816;&#39564;&#36890;&#36807;&#36866;&#24403;&#30340;&#26657;&#20934;&#38408;&#20540;&#65292;&#24471;&#21040;&#33391;&#22909;&#25511;&#21046;&#30340;&#19968;&#31867;&#38169;&#35823;&#12290;&#23545;&#20110;&#26576;&#20123;&#20855;&#26377;&#20302;&#32500;&#28508;&#22312;&#32467;&#26500;&#21644;&#39640;&#32500;&#35266;&#27979;&#30340;&#27169;&#22411;&#65292;&#22312;&#25105;&#20204;&#30340;&#27979;&#35797;&#20013;&#65292;&#26174;&#33879;&#20248;&#20110;&#22522;&#20110;&#27169;&#22411;&#26679;&#26412;&#21644;&#19981;&#21033;&#29992;&#28508;&#22312;&#32467;&#26500;&#30340;&#30456;&#23545;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a kernel-based nonparametric test of relative goodness of fit, where the goal is to compare two models, both of which may have unobserved latent variables, such that the marginal distribution of the observed variables is intractable. The proposed test generalizes the recently proposed kernel Stein discrepancy (KSD) tests (Liu et al., 2016, Chwialkowski et al., 2016, Yang et al., 2018) to the case of latent variable models, a much more general class than the fully observed models treated previously. The new test, with a properly calibrated threshold, has a well-controlled type-I error. In the case of certain models with low-dimensional latent structure and high-dimensional observations, our test significantly outperforms the relative Maximum Mean Discrepancy test, which is based on samples from the models and does not exploit the latent structure.
&lt;/p&gt;</description></item></channel></rss>