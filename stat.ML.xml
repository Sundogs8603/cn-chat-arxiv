<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#31232;&#30095;&#21152;&#26435;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#21333;&#24490;&#29615;&#24179;&#28369;ADMM&#31639;&#27861;&#65292;&#21517;&#20026;SIAD&#65292;&#23427;&#22312;&#23384;&#22312;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#31232;&#30095;&#24809;&#32602;&#26465;&#20214;&#19979;&#33021;&#22815;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.03094</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#20984;&#24809;&#32602;&#30340;&#31232;&#30095;&#21152;&#26435;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#24179;&#28369;ADMM
&lt;/p&gt;
&lt;p&gt;
Smoothing ADMM for Sparse-Penalized Quantile Regression with Non-Convex Penalties. (arXiv:2309.03094v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03094
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#31232;&#30095;&#21152;&#26435;&#20998;&#20301;&#25968;&#22238;&#24402;&#30340;&#26032;&#22411;&#21333;&#24490;&#29615;&#24179;&#28369;ADMM&#31639;&#27861;&#65292;&#21517;&#20026;SIAD&#65292;&#23427;&#22312;&#23384;&#22312;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#31232;&#30095;&#24809;&#32602;&#26465;&#20214;&#19979;&#33021;&#22815;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#20984;&#21644;&#38750;&#20809;&#28369;&#31232;&#30095;&#24809;&#32602;&#26465;&#20214;&#19979;&#30340;&#20998;&#20301;&#25968;&#22238;&#24402;&#65292;&#22914;&#26368;&#23567;&#26368;&#22823;&#20985;&#24809;&#32602;&#65288;MCP&#65289;&#21644;&#24179;&#28369;&#21098;&#20999;&#32477;&#23545;&#20559;&#24046;&#65288;SCAD&#65289;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#38750;&#20809;&#28369;&#21644;&#38750;&#20984;&#29305;&#24615;&#32463;&#24120;&#23548;&#33268;&#35768;&#22810;&#31639;&#27861;&#30340;&#25910;&#25947;&#22256;&#38590;&#12290;&#34429;&#28982;&#36845;&#20195;&#25216;&#26415;&#22914;&#22352;&#26631;&#19979;&#38477;&#21644;&#23616;&#37096;&#32447;&#24615;&#36817;&#20284;&#21487;&#20197;&#20419;&#36827;&#25910;&#25947;&#65292;&#20294;&#36807;&#31243;&#36890;&#24120;&#24456;&#24930;&#12290;&#36825;&#31181;&#32531;&#24930;&#30340;&#36895;&#24230;&#20027;&#35201;&#26159;&#22240;&#20026;&#38656;&#35201;&#22312;&#27599;&#19968;&#27493;&#36816;&#34892;&#36825;&#20123;&#36817;&#20284;&#25216;&#26415;&#30452;&#21040;&#23436;&#20840;&#25910;&#25947;&#65292;&#36825;&#26159;&#25105;&#20204;&#31216;&#20043;&#20026;\emph{&#20108;&#27425;&#25910;&#25947;&#36845;&#20195;}&#30340;&#35201;&#27714;&#12290;&#20026;&#20102;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#20132;&#26367;&#26041;&#21521;&#20056;&#27861;&#65288;ADMM&#65289;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20855;&#26377;&#36882;&#22686;&#24809;&#32602;&#21442;&#25968;&#30340;&#21333;&#24490;&#29615;&#24179;&#28369;ADMM&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;SIAD&#65292;&#19987;&#38376;&#29992;&#20110;&#31232;&#30095;&#21152;&#26435;&#20998;&#20301;&#25968;&#22238;&#24402;&#12290;&#25105;&#20204;&#39318;&#20808;&#28145;&#20837;&#30740;&#31350;&#20102;&#25152;&#25552;&#20986;&#30340;SIAD&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates quantile regression in the presence of non-convex and non-smooth sparse penalties, such as the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD). The non-smooth and non-convex nature of these problems often leads to convergence difficulties for many algorithms. While iterative techniques like coordinate descent and local linear approximation can facilitate convergence, the process is often slow. This sluggish pace is primarily due to the need to run these approximation techniques until full convergence at each step, a requirement we term as a \emph{secondary convergence iteration}. To accelerate the convergence speed, we employ the alternating direction method of multipliers (ADMM) and introduce a novel single-loop smoothing ADMM algorithm with an increasing penalty parameter, named SIAD, specifically tailored for sparse-penalized quantile regression. We first delve into the convergence properties of the proposed SIAD algorithm and est
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#23545;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#20855;&#26377;&#26368;&#26174;&#33879;&#24433;&#21709;&#30340;&#21442;&#25968;&#26041;&#21521;&#26500;&#24314;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30001;&#20110;&#21442;&#25968;&#31354;&#38388;&#39640;&#32500;&#24230;&#32780;&#24102;&#26469;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#26174;&#33879;&#20943;&#23569;&#30340;&#20027;&#21160;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#25110;&#21464;&#20998;&#25512;&#29702;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#26377;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#22238;&#24402;&#20219;&#21153;&#30340;&#23454;&#35777;&#39564;&#35777;&#20102;&#21487;&#38752;&#30340;&#39044;&#27979;&#21644;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2309.03061</link><description>&lt;p&gt;
&#23398;&#20064;&#20027;&#21160;&#23376;&#31354;&#38388;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;
&lt;/p&gt;
&lt;p&gt;
Learning Active Subspaces for Effective and Scalable Uncertainty Quantification in Deep Neural Networks. (arXiv:2309.03061v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03061
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#23545;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#20855;&#26377;&#26368;&#26174;&#33879;&#24433;&#21709;&#30340;&#21442;&#25968;&#26041;&#21521;&#26500;&#24314;&#20302;&#32500;&#23376;&#31354;&#38388;&#30340;&#26041;&#27861;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30001;&#20110;&#21442;&#25968;&#31354;&#38388;&#39640;&#32500;&#24230;&#32780;&#24102;&#26469;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#26174;&#33879;&#20943;&#23569;&#30340;&#20027;&#21160;&#23376;&#31354;&#38388;&#19978;&#36827;&#34892;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#25110;&#21464;&#20998;&#25512;&#29702;&#65292;&#35813;&#26041;&#27861;&#23454;&#29616;&#20102;&#26377;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#22238;&#24402;&#20219;&#21153;&#30340;&#23454;&#35777;&#39564;&#35777;&#20102;&#21487;&#38752;&#30340;&#39044;&#27979;&#21644;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#29702;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#25110;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20855;&#26377;&#25552;&#20379;&#20855;&#26377;&#37327;&#21270;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#33391;&#22909;&#26657;&#20934;&#39044;&#27979;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#30001;&#20110;&#21442;&#25968;&#31354;&#38388;&#30340;&#39640;&#32500;&#24230;&#32780;&#36896;&#25104;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#26696;&#65292;&#36890;&#36807;&#35782;&#21035;&#23545;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#20855;&#26377;&#26368;&#26174;&#33879;&#24433;&#21709;&#30340;&#21442;&#25968;&#26041;&#21521;&#65292;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#20302;&#32500;&#23376;&#31354;&#38388;&#65292;&#21363;&#20027;&#21160;&#23376;&#31354;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26174;&#33879;&#20943;&#23569;&#30340;&#20027;&#21160;&#23376;&#31354;&#38388;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#65288;MC&#65289;&#37319;&#26679;&#26041;&#27861;&#65288;&#21542;&#21017;&#38590;&#20197;&#35745;&#31639;&#65289;&#25110;&#21464;&#20998;&#25512;&#29702;&#23454;&#29616;&#20102;&#26377;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#20174;&#23454;&#35777;&#19978;&#30475;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#21508;&#31181;&#22238;&#24402;&#20219;&#21153;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#39044;&#27979;&#21644;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference for neural networks, or Bayesian deep learning, has the potential to provide well-calibrated predictions with quantified uncertainty and robustness. However, the main hurdle for Bayesian deep learning is its computational complexity due to the high dimensionality of the parameter space. In this work, we propose a novel scheme that addresses this limitation by constructing a low-dimensional subspace of the neural network parameters-referred to as an active subspace-by identifying the parameter directions that have the most significant influence on the output of the neural network. We demonstrate that the significantly reduced active subspace enables effective and scalable Bayesian inference via either Monte Carlo (MC) sampling methods, otherwise computationally intractable, or variational inference. Empirically, our approach provides reliable predictions with robust uncertainty estimates for various regression tasks.
&lt;/p&gt;</description></item><item><title>CoLA&#26159;&#19968;&#20010;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#22823;&#35268;&#27169;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#30340;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32452;&#21512;&#35843;&#24230;&#35268;&#21017;&#21644;&#32447;&#24615;&#25805;&#20316;&#31526;&#25277;&#35937;&#65292;&#33258;&#21160;&#26500;&#24314;&#20102;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#39640;&#25928;&#30340;&#25968;&#20540;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#21160;&#24494;&#20998;&#12289;&#20302;&#31934;&#24230;&#35745;&#31639;&#21644;GPU&#21152;&#36895;&#65292;&#21516;&#26102;&#21487;&#20197;&#36866;&#24212;&#19979;&#28216;&#36719;&#20214;&#21253;&#20013;&#30340;&#26032;&#23545;&#35937;&#12289;&#25805;&#20316;&#21644;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2309.03060</link><description>&lt;p&gt;
CoLA: &#28145;&#20837;&#21033;&#29992;&#32452;&#21512;&#32467;&#26500;&#23454;&#29616;&#33258;&#21160;&#21644;&#39640;&#25928;&#30340;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
CoLA: Exploiting Compositional Structure for Automatic and Efficient Numerical Linear Algebra. (arXiv:2309.03060v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03060
&lt;/p&gt;
&lt;p&gt;
CoLA&#26159;&#19968;&#20010;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#22823;&#35268;&#27169;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#30340;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#32452;&#21512;&#35843;&#24230;&#35268;&#21017;&#21644;&#32447;&#24615;&#25805;&#20316;&#31526;&#25277;&#35937;&#65292;&#33258;&#21160;&#26500;&#24314;&#20102;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#39640;&#25928;&#30340;&#25968;&#20540;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#21160;&#24494;&#20998;&#12289;&#20302;&#31934;&#24230;&#35745;&#31639;&#21644;GPU&#21152;&#36895;&#65292;&#21516;&#26102;&#21487;&#20197;&#36866;&#24212;&#19979;&#28216;&#36719;&#20214;&#21253;&#20013;&#30340;&#26032;&#23545;&#35937;&#12289;&#25805;&#20316;&#21644;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#21644;&#31185;&#23398;&#39046;&#22495;&#28041;&#21450;&#21040;&#22823;&#35268;&#27169;&#30340;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#65292;&#22914;&#29305;&#24449;&#20998;&#35299;&#12289;&#35299;&#32447;&#24615;&#31995;&#32479;&#12289;&#35745;&#31639;&#30697;&#38453;&#25351;&#25968;&#21644;&#36857;&#20272;&#35745;&#31561;&#12290;&#28041;&#21450;&#30340;&#30697;&#38453;&#36890;&#24120;&#20855;&#26377;Krondor&#12289;&#21367;&#31215;&#12289;&#22359;&#23545;&#35282;&#12289;&#27714;&#21644;&#25110;&#20056;&#31215;&#31561;&#32467;&#26500;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#22823;&#35268;&#27169;&#32447;&#24615;&#20195;&#25968;&#38382;&#39064;&#30340;&#26694;&#26550;&#65292;&#21517;&#20026;CoLA&#65288;&#32452;&#21512;&#32447;&#24615;&#20195;&#25968;&#65289;&#12290;&#36890;&#36807;&#23558;&#32447;&#24615;&#25805;&#20316;&#31526;&#25277;&#35937;&#19982;&#32452;&#21512;&#35843;&#24230;&#35268;&#21017;&#30456;&#32467;&#21512;&#65292;CoLA&#33021;&#22815;&#33258;&#21160;&#26500;&#24314;&#20869;&#23384;&#21644;&#36816;&#34892;&#26102;&#39640;&#25928;&#30340;&#25968;&#20540;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;CoLA&#36824;&#25552;&#20379;&#20869;&#23384;&#39640;&#25928;&#30340;&#33258;&#21160;&#24494;&#20998;&#12289;&#20302;&#31934;&#24230;&#35745;&#31639;&#21644;JAX&#21644;PyTorch&#20013;&#30340;GPU&#21152;&#36895;&#65292;&#21516;&#26102;&#36824;&#33021;&#22815;&#36890;&#36807;&#22810;&#37325;&#35843;&#24230;&#36866;&#24212;&#19979;&#28216;&#36719;&#20214;&#21253;&#20013;&#30340;&#26032;&#23545;&#35937;&#12289;&#25805;&#20316;&#21644;&#35268;&#21017;&#12290;CoLA&#21487;&#20197;&#21152;&#36895;&#35768;&#22810;&#20195;&#25968;&#25805;&#20316;&#65292;&#21516;&#26102;&#20063;&#20415;&#20110;&#21407;&#22411;&#21270;&#30697;&#38453;&#32467;&#26500;&#21644;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#21487;&#34892;&#24615;&#30340;&#38477;&#20302;-
&lt;/p&gt;
&lt;p&gt;
Many areas of machine learning and science involve large linear algebra problems, such as eigendecompositions, solving linear systems, computing matrix exponentials, and trace estimation. The matrices involved often have Kronecker, convolutional, block diagonal, sum, or product structure. In this paper, we propose a simple but general framework for large-scale linear algebra problems in machine learning, named CoLA (Compositional Linear Algebra). By combining a linear operator abstraction with compositional dispatch rules, CoLA automatically constructs memory and runtime efficient numerical algorithms. Moreover, CoLA provides memory efficient automatic differentiation, low precision computation, and GPU acceleration in both JAX and PyTorch, while also accommodating new objects, operations, and rules in downstream packages via multiple dispatch. CoLA can accelerate many algebraic operations, while making it easy to prototype matrix structures and algorithms, providing an appealing drop-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25674;&#38144;&#25512;&#29702;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25512;&#29702;&#36827;&#34892;&#25674;&#38144;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#25968;&#25454;&#36827;&#34892;&#27010;&#29575;&#20803;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2309.03018</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#25674;&#38144;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Amortised Inference in Bayesian Neural Networks. (arXiv:2309.03018v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25674;&#38144;&#25512;&#29702;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25512;&#29702;&#36827;&#34892;&#25674;&#38144;&#65292;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#21033;&#29992;&#25968;&#25454;&#36827;&#34892;&#27010;&#29575;&#20803;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#26159;&#19968;&#31181;&#26694;&#26550;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#19968;&#32452;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#20415;&#22312;&#27979;&#35797;&#26102;&#23545;&#26032;&#25968;&#25454;&#38598;&#36827;&#34892;&#39044;&#27979;&#12290;&#36817;&#24180;&#26469;&#65292;&#27010;&#29575;&#20803;&#23398;&#20064;&#21463;&#21040;&#30740;&#31350;&#30028;&#30340;&#24191;&#27867;&#20851;&#27880;&#65292;&#20294;&#35768;&#22810;&#29616;&#26377;&#30340;&#27010;&#29575;&#20803;&#27169;&#22411;&#23384;&#22312;&#19968;&#20010;&#20849;&#24615;&#38382;&#39064;&#65292;&#21363;&#38656;&#35201;&#22823;&#37327;&#25968;&#25454;&#38598;&#25165;&#33021;&#29983;&#25104;&#20855;&#26377;&#39640;&#36136;&#37327;&#39044;&#27979;&#21644;&#33391;&#22909;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#24456;&#38590;&#33719;&#21462;&#36825;&#20040;&#22810;&#25968;&#25454;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#25512;&#29702;&#36827;&#34892;&#25674;&#38144;&#65292;&#24341;&#20837;&#20102;&#25674;&#38144;&#20266;&#35266;&#27979;&#21464;&#20998;&#25512;&#29702;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;APOVI-BNN&#65289;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#21152;&#39640;&#25928;&#21033;&#29992;&#25968;&#25454;&#30340;&#27010;&#29575;&#20803;&#23398;&#20064;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#25105;&#20204;&#30340;&#25674;&#38144;&#26041;&#26696;&#19979;&#33719;&#21462;&#30340;&#36817;&#20284;&#21518;&#39564;&#19982;&#20256;&#32479;&#21464;&#20998;&#25512;&#29702;&#33719;&#21462;&#30340;&#36817;&#20284;&#21518;&#39564;&#20855;&#26377;&#30456;&#20284;&#25110;&#26356;&#22909;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-learning is a framework in which machine learning models train over a set of datasets in order to produce predictions on new datasets at test time. Probabilistic meta-learning has received an abundance of attention from the research community in recent years, but a problem shared by many existing probabilistic meta-models is that they require a very large number of datasets in order to produce high-quality predictions with well-calibrated uncertainty estimates. In many applications, however, such quantities of data are simply not available.  In this dissertation we present a significantly more data-efficient approach to probabilistic meta-learning through per-datapoint amortisation of inference in Bayesian neural networks, introducing the Amortised Pseudo-Observation Variational Inference Bayesian Neural Network (APOVI-BNN). First, we show that the approximate posteriors obtained under our amortised scheme are of similar or better quality to those obtained through traditional vari
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31163;&#32447;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#38750;&#21442;&#25968;&#20272;&#35745;&#20256;&#25773;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#24754;&#35266;&#30340;&#25439;&#22833;&#21151;&#33021;&#26469;&#32771;&#34385;&#20272;&#35745;&#30340;&#20256;&#25773;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.02994</link><description>&lt;p&gt;
&#19968;&#20010;&#31163;&#32447;&#23398;&#20064;&#26041;&#27861;&#29992;&#20110;&#20256;&#25773;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
An Offline Learning Approach to Propagator Models. (arXiv:2309.02994v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31163;&#32447;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#38750;&#21442;&#25968;&#20272;&#35745;&#20256;&#25773;&#27169;&#22411;&#65292;&#24182;&#24341;&#20837;&#24754;&#35266;&#30340;&#25439;&#22833;&#21151;&#33021;&#26469;&#32771;&#34385;&#20272;&#35745;&#30340;&#20256;&#25773;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#31163;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#19968;&#20010;&#20195;&#29702;&#39318;&#20808;&#20174;&#38745;&#24577;&#25968;&#25454;&#38598;&#20013;&#20272;&#35745;&#26410;&#30693;&#30340;&#20215;&#26684;&#20914;&#20987;&#26680;&#65292;&#28982;&#21518;&#35774;&#35745;&#31574;&#30053;&#20197;&#24179;&#20179;&#39118;&#38505;&#36164;&#20135;&#21516;&#26102;&#20135;&#29983;&#30701;&#26242;&#30340;&#20215;&#26684;&#20914;&#20987;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21253;&#21547;&#30456;&#20851;&#20215;&#26684;&#36712;&#36857;&#12289;&#20132;&#26131;&#20449;&#21495;&#21644;&#20803;&#35746;&#21333;&#30340;&#25968;&#25454;&#38598;&#23545;&#20256;&#25773;&#32773;&#36827;&#34892;&#38750;&#21442;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#20272;&#35745;&#20256;&#25773;&#22120;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#19968;&#20010;&#20165;&#22522;&#20110;&#20272;&#35745;&#30340;&#20256;&#25773;&#32773;&#20351;&#29992;&#36138;&#23146;&#31574;&#30053;&#26469;&#23613;&#37327;&#20943;&#23569;&#20132;&#26131;&#25104;&#26412;&#30340;&#20132;&#26131;&#32773;&#20250;&#30001;&#20110;&#20132;&#26131;&#31574;&#30053;&#19982;&#20272;&#35745;&#22120;&#20043;&#38388;&#25152;&#35859;&#30340;&#20266;&#30456;&#20851;&#24615;&#20197;&#21450;&#30001;&#20110;&#26377;&#20559;&#25104;&#26412;&#21151;&#33021;&#24341;&#36215;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#32780;&#36935;&#21040;&#27425;&#20248;&#24615;&#12290;&#36890;&#36807;&#37319;&#29992;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24754;&#35266;&#30340;&#25439;&#22833;&#21151;&#33021;&#65292;&#23558;&#20272;&#35745;&#30340;&#20256;&#25773;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#32771;&#34385;&#22312;&#20869;&#65292;&#24182;&#24102;&#26377;&#20248;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider an offline learning problem for an agent who first estimates an unknown price impact kernel from a static dataset, and then designs strategies to liquidate a risky asset while creating transient price impact. We propose a novel approach for a nonparametric estimation of the propagator from a dataset containing correlated price trajectories, trading signals and metaorders. We quantify the accuracy of the estimated propagator using a metric which depends explicitly on the dataset. We show that a trader who tries to minimise her execution costs by using a greedy strategy purely based on the estimated propagator will encounter suboptimality due to so-called spurious correlation between the trading strategy and the estimator and due to intrinsic uncertainty resulting from a biased cost functional. By adopting an offline reinforcement learning approach, we introduce a pessimistic loss functional taking the uncertainty of the estimated propagator into account, with an optimiser wh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;&#22312;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20559;&#24046;&#19968;&#33324;&#38750;&#38646;&#12290;&#27492;&#22806;&#65292;&#24403;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#24179;&#22343;&#27861;&#26102;&#65292;&#20272;&#35745;&#20540;&#25910;&#25947;&#21040;&#28176;&#36817;&#26080;&#20559;&#65292;&#19988;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2309.02944</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#65306;&#25193;&#23637;&#29256;&#26412;
&lt;/p&gt;
&lt;p&gt;
The Curse of Memory in Stochastic Approximation: Extended Version. (arXiv:2309.02944v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#35760;&#24518;&#35781;&#21650;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;&#22312;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#65292;&#30446;&#26631;&#20559;&#24046;&#19968;&#33324;&#38750;&#38646;&#12290;&#27492;&#22806;&#65292;&#24403;&#21442;&#25968;&#20272;&#35745;&#20351;&#29992;&#24179;&#22343;&#27861;&#26102;&#65292;&#20272;&#35745;&#20540;&#25910;&#25947;&#21040;&#28176;&#36817;&#26080;&#20559;&#65292;&#19988;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#25511;&#21046;&#30340;&#26368;&#26089;&#30340;&#26085;&#23376;&#20197;&#26469;&#65292;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#22312;&#25511;&#21046;&#31995;&#32479;&#30340;&#31038;&#21306;&#20013;&#24471;&#21040;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#26412;&#25991;&#20197;&#26032;&#30340;&#35270;&#35282;&#37325;&#26032;&#23457;&#35270;&#20102;&#36825;&#20010;&#20027;&#39064;&#65292;&#21463;&#21040;&#26368;&#36817;&#30340;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#35813;&#32467;&#26524;&#35777;&#26126;&#20351;&#29992;&#65288;&#36275;&#22815;&#23567;&#30340;&#65289;&#24658;&#23450;&#27493;&#38271;&#945;&gt;0&#30340;SA&#20855;&#26377;&#38750;&#20961;&#30340;&#24615;&#33021;&#12290;&#22914;&#26524;&#37319;&#29992;&#24179;&#22343;&#27861;&#33719;&#21462;&#26368;&#32456;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#21017;&#20272;&#35745;&#20540;&#22312;&#28176;&#36817;&#26080;&#20559;&#21644;&#36817;&#20284;&#26368;&#20248;&#30340;&#28176;&#36817;&#21327;&#26041;&#24046;&#19979;&#25910;&#25947;&#12290;&#36825;&#20123;&#32467;&#26524;&#26159;&#38024;&#23545;&#20855;&#26377;&#29420;&#31435;&#21516;&#20998;&#24067;&#31995;&#25968;&#30340;&#38543;&#26426;&#32447;&#24615;SA&#36882;&#24402;&#33719;&#24471;&#30340;&#12290;&#26412;&#25991;&#22312;&#26356;&#24120;&#35265;&#30340;&#20960;&#20309;&#36941;&#21382;&#39532;&#23572;&#21487;&#22827;&#25200;&#21160;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#20102;&#38750;&#24120;&#19981;&#21516;&#30340;&#32467;&#35770;&#65306;&#65288;i&#65289;&#22312;&#38750;&#32447;&#24615;SA&#30340;&#24773;&#20917;&#19979;&#65292;&#35782;&#21035;&#20986;&#20102;&#8220;&#30446;&#26631;&#20559;&#24046;&#8221;&#65292;&#24182;&#19988;&#19968;&#33324;&#19978;&#19981;&#20026;&#38646;&#12290;&#20854;&#20313;&#30340;&#32467;&#26524;&#26159;&#38024;&#23545;&#32447;&#24615;SA&#36882;&#24402;&#24314;&#31435;&#30340;&#65306;&#65288;ii&#65289;&#21452;&#21464;&#37327;&#21442;&#25968;&#25200;&#21160;&#36807;&#31243;&#22312;&#25299;&#25169;&#24847;&#20041;&#19978;&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#24615;&#65307;&#65288;iii&#65289;&#20559;&#24046;&#30340;&#34920;&#31034;&#20855;&#26377;&#31616;&#21333;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theory and application of stochastic approximation (SA) has grown within the control systems community since the earliest days of adaptive control. This paper takes a new look at the topic, motivated by recent results establishing remarkable performance of SA with (sufficiently small) constant step-size $\alpha&gt;0$. If averaging is implemented to obtain the final parameter estimate, then the estimates are asymptotically unbiased with nearly optimal asymptotic covariance. These results have been obtained for random linear SA recursions with i.i.d.\ coefficients. This paper obtains very different conclusions in the more common case of geometrically ergodic Markovian disturbance: (i) The \textit{target bias} is identified, even in the case of non-linear SA, and is in general non-zero. The remaining results are established for linear SA recursions: (ii) the bivariate parameter-disturbance process is geometrically ergodic in a topological sense; (iii) the representation for bias has a simple
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#36890;&#29992;&#20114;&#20449;&#24687;&#65288;GEMINI&#65289;&#20316;&#20026;&#19968;&#31181;&#36776;&#21035;&#32858;&#31867;&#30340;&#26694;&#26550;&#65292;&#30456;&#27604;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#65292;GEMINI&#22312;&#26080;&#30417;&#30563;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#20013;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;&#65292;&#20854;&#21487;&#20197;&#36873;&#25321;&#21512;&#36866;&#30340;&#32858;&#31867;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2309.02858</link><description>&lt;p&gt;
&#36890;&#29992;&#20114;&#20449;&#24687;&#65306;&#19968;&#31181;&#36776;&#21035;&#32858;&#31867;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Generalised Mutual Information: a Framework for Discriminative Clustering. (arXiv:2309.02858v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02858
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#36890;&#29992;&#20114;&#20449;&#24687;&#65288;GEMINI&#65289;&#20316;&#20026;&#19968;&#31181;&#36776;&#21035;&#32858;&#31867;&#30340;&#26694;&#26550;&#65292;&#30456;&#27604;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#65292;GEMINI&#22312;&#26080;&#30417;&#30563;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#20013;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;&#65292;&#20854;&#21487;&#20197;&#36873;&#25321;&#21512;&#36866;&#30340;&#32858;&#31867;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#28145;&#24230;&#32858;&#31867;&#30340;&#26368;&#26032;&#25104;&#26524;&#20027;&#35201;&#28041;&#21450;&#20316;&#20026;&#26080;&#30417;&#30563;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#23458;&#35266;&#20989;&#25968;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#65292;&#24182;&#22686;&#21152;&#20102;&#27491;&#21017;&#39033;&#12290;&#23613;&#31649;&#27491;&#21017;&#21270;&#30340;&#36136;&#37327;&#24050;&#32463;&#34987;&#24191;&#27867;&#35752;&#35770;&#20197;&#36827;&#34892;&#25913;&#36827;&#65292;&#20294;&#23545;&#20110;MI&#20316;&#20026;&#32858;&#31867;&#30446;&#26631;&#30340;&#30456;&#20851;&#24615;&#21364;&#27809;&#26377;&#24471;&#21040;&#36275;&#22815;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#39318;&#20808;&#24378;&#35843;&#20102;&#26368;&#22823;&#21270;MI&#24182;&#19981;&#33021;&#24471;&#21040;&#20196;&#20154;&#28385;&#24847;&#30340;&#32858;&#31867;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#24211;&#23572;&#24052;&#20811;-&#33713;&#24067;&#21202;&#25955;&#24230;&#26159;&#36825;&#19968;&#34892;&#20026;&#30340;&#20027;&#35201;&#21407;&#22240;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#25913;&#21464;&#20854;&#26680;&#24515;&#24046;&#24322;&#65292;&#24341;&#20837;&#36890;&#29992;&#20114;&#20449;&#24687;&#65288;GEMINI&#65289;&#26469;&#25512;&#24191;&#20114;&#20449;&#24687;&#65306;&#19968;&#32452;&#29992;&#20110;&#26080;&#30417;&#30563;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#30340;&#24230;&#37327;&#12290;&#19982;MI&#19981;&#21516;&#30340;&#26159;&#65292;&#19968;&#20123;GEMINI&#22312;&#35757;&#32451;&#26102;&#19981;&#38656;&#35201;&#27491;&#21017;&#21270;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#25968;&#25454;&#31354;&#38388;&#20013;&#20855;&#26377;&#20960;&#20309;&#24847;&#35782;&#30340;&#36317;&#31163;&#25110;&#26680;&#20989;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#65292;GEMINI&#21487;&#20197;&#33258;&#21160;&#36873;&#25321;&#30456;&#20851;&#25968;&#37327;&#30340;&#32858;&#31867;&#65292;&#36825;&#26159;&#19968;&#20010;&#26377;&#24847;&#20041;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the last decade, recent successes in deep clustering majorly involved the Mutual Information (MI) as an unsupervised objective for training neural networks with increasing regularisations. While the quality of the regularisations have been largely discussed for improvements, little attention has been dedicated to the relevance of MI as a clustering objective. In this paper, we first highlight how the maximisation of MI does not lead to satisfying clusters. We identified the Kullback-Leibler divergence as the main reason of this behaviour. Hence, we generalise the mutual information by changing its core distance, introducing the Generalised Mutual Information (GEMINI): a set of metrics for unsupervised neural network training. Unlike MI, some GEMINIs do not require regularisations when training as they are geometry-aware thanks to distances or kernels in the data space. Finally, we highlight that GEMINIs can automatically select a relevant number of clusters, a property that has been
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#32452;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#21518;&#22788;&#29702;&#26041;&#27861;&#65292;&#20005;&#26684;&#31105;&#27490;&#25968;&#25454;&#38598;&#20013;&#30340;&#37325;&#22797;&#26679;&#26412;&#65292;&#32467;&#26524;&#34920;&#26126;&#27492;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#39034;&#24207;&#27493;&#39588;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.02842</link><description>&lt;p&gt;
&#38024;&#23545;&#32452;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#38543;&#26426;&#21518;&#22788;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Random postprocessing for combinatorial Bayesian optimization. (arXiv:2309.02842v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02842
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#32452;&#21512;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#21518;&#22788;&#29702;&#26041;&#27861;&#65292;&#20005;&#26684;&#31105;&#27490;&#25968;&#25454;&#38598;&#20013;&#30340;&#37325;&#22797;&#26679;&#26412;&#65292;&#32467;&#26524;&#34920;&#26126;&#27492;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#39034;&#24207;&#27493;&#39588;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#39034;&#24207;&#26041;&#27861;&#29992;&#20110;&#31163;&#25955;&#30340;&#8220;&#40657;&#30418;&#8221;&#20248;&#21270;&#38382;&#39064;&#65292;&#21253;&#25324;&#36125;&#21494;&#26031;&#20248;&#21270;&#25216;&#26415;&#65292;&#36890;&#24120;&#20250;&#23545;&#32473;&#23450;&#30340;&#30446;&#26631;&#20989;&#25968;&#35775;&#38382;&#22810;&#27425;&#30456;&#21516;&#30340;&#28857;&#65292;&#23548;&#33268;&#38656;&#35201;&#24456;&#22810;&#27493;&#39588;&#25165;&#33021;&#25214;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23545;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#19968;&#31181;&#21518;&#22788;&#29702;&#26041;&#27861;&#36827;&#34892;&#20102;&#25968;&#20540;&#30740;&#31350;&#65292;&#35813;&#26041;&#27861;&#20005;&#26684;&#31105;&#27490;&#25968;&#25454;&#38598;&#20013;&#30340;&#37325;&#22797;&#26679;&#26412;&#12290;&#25105;&#20204;&#21457;&#29616;&#21518;&#22788;&#29702;&#26041;&#27861;&#26174;&#33879;&#20943;&#23569;&#20102;&#25214;&#21040;&#20840;&#23616;&#26368;&#20248;&#35299;&#25152;&#38656;&#30340;&#39034;&#24207;&#27493;&#39588;&#25968;&#65292;&#29305;&#21035;&#26159;&#24403;&#37319;&#26679;&#20989;&#25968;&#26159;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#26102;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#35299;&#20915;&#39640;&#32500;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25910;&#25947;&#36895;&#24230;&#24930;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#36890;&#29992;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based sequential approaches to discrete "black-box" optimization, including Bayesian optimization techniques, often access the same points multiple times for a given objective function in interest, resulting in many steps to find the global optimum. Here, we numerically study the effect of a postprocessing method on Bayesian optimization that strictly prohibits duplicated samples in the dataset. We find the postprocessing method significantly reduces the number of sequential steps to find the global optimum, especially when the acquisition function is of maximum a posterior estimation. Our results provide a simple but general strategy to solve the slow convergence of Bayesian optimization for high-dimensional problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#36136;&#35823;&#24046;&#23545;&#22810;&#20445;&#30495;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#29616;&#26377;&#20551;&#35774;&#19981;&#25104;&#31435;&#26102;&#24615;&#33021;&#19979;&#38477;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.02771</link><description>&lt;p&gt;
&#20851;&#20110;&#24322;&#36136;&#35823;&#24046;&#23545;&#22810;&#20445;&#30495;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the Effects of Heterogeneous Errors on Multi-fidelity Bayesian Optimization. (arXiv:2309.02771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24322;&#36136;&#35823;&#24046;&#23545;&#22810;&#20445;&#30495;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#35299;&#20915;&#29616;&#26377;&#20551;&#35774;&#19981;&#25104;&#31435;&#26102;&#24615;&#33021;&#19979;&#38477;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#26159;&#19968;&#31181;&#36830;&#32493;&#20248;&#21270;&#31574;&#30053;&#65292;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21253;&#25324;&#26448;&#26009;&#35774;&#35745;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36890;&#36807;&#29289;&#29702;&#23454;&#39564;&#25110;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#33719;&#21462;&#39640;&#20445;&#30495;&#24230;&#65288;HF&#65289;&#25968;&#25454;&#26159;BO&#30340;&#20027;&#35201;&#25104;&#26412;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#29942;&#39048;&#65292;&#37319;&#29992;&#22810;&#20445;&#30495;&#24230;&#65288;MF&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#26597;&#35810;&#19982;HF&#26679;&#26412;&#30456;&#20851;&#30340;&#24265;&#20215;&#20302;&#20445;&#30495;&#24230;&#65288;LF&#65289;&#25968;&#25454;&#28304;&#65292;&#20943;&#23569;&#25277;&#26679;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22810;&#20445;&#30495;&#24230;BO&#65288;MFBO&#65289;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#20551;&#35774;&#65292;&#36825;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24456;&#23569;&#25104;&#31435;&#65306;&#65288;1&#65289;LF&#25968;&#25454;&#28304;&#22312;&#20840;&#23616;&#33539;&#22260;&#20869;&#19982;HF&#25968;&#25454;&#21576;&#33391;&#22909;&#30456;&#20851;&#65292;&#65288;2&#65289;&#19968;&#20010;&#38543;&#26426;&#36807;&#31243;&#21487;&#20197;&#27169;&#25311;&#34701;&#21512;&#25968;&#25454;&#30340;&#22122;&#22768;&#12290;&#36825;&#20123;&#20551;&#35774;&#22312;LF&#25968;&#25454;&#28304;&#20165;&#22312;&#23616;&#37096;&#19982;HF&#28304;&#30456;&#20851;&#25110;&#22122;&#22768;&#26041;&#24046;&#22312;&#19981;&#21516;&#22320;&#26041;&#21464;&#21270;&#26102;&#65292;&#20250;&#26174;&#33879;&#38477;&#20302;MFBO&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a sequential optimization strategy that is increasingly employed in a wide range of areas including materials design. In real world applications, acquiring high-fidelity (HF) data through physical experiments or HF simulations is the major cost component of BO. To alleviate this bottleneck, multi-fidelity (MF) methods are used to forgo the sole reliance on the expensive HF data and reduce the sampling costs by querying inexpensive low-fidelity (LF) sources whose data are correlated with HF samples. However, existing multi-fidelity BO (MFBO) methods operate under the following two assumptions that rarely hold in practical applications: (1) LF sources provide data that are well correlated with the HF data on a global scale, and (2) a single random process can model the noise in the fused data. These assumptions dramatically reduce the performance of MFBO when LF sources are only locally correlated with the HF source or when the noise variance varies across t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20849;&#35782;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#32593;&#32476;&#20013;&#30340;&#20998;&#25955;&#20248;&#21270;&#38382;&#39064;&#65292;&#21033;&#29992;&#21608;&#26399;&#24615;&#36861;&#36394;&#19981;&#19968;&#33268;&#35823;&#24046;&#21644;&#31934;&#36873;&#26377;&#25928;&#36793;&#32536;&#30340;&#31574;&#30053;&#26469;&#20943;&#23569;&#36890;&#20449;&#37327;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2309.02626</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20849;&#35782;&#65306;&#19968;&#31181;&#29992;&#20110;&#20998;&#25955;&#20248;&#21270;&#30340;&#32593;&#32476;&#20462;&#21098;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Consensus: A network pruning approach for decentralized optimization. (arXiv:2309.02626v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02626
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20849;&#35782;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#32593;&#32476;&#20013;&#30340;&#20998;&#25955;&#20248;&#21270;&#38382;&#39064;&#65292;&#21033;&#29992;&#21608;&#26399;&#24615;&#36861;&#36394;&#19981;&#19968;&#33268;&#35823;&#24046;&#21644;&#31934;&#36873;&#26377;&#25928;&#36793;&#32536;&#30340;&#31574;&#30053;&#26469;&#20943;&#23569;&#36890;&#20449;&#37327;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22522;&#20110;&#32593;&#32476;&#30340;&#20998;&#25955;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#36825;&#31181;&#38382;&#39064;&#20013;&#65292;&#32593;&#32476;&#20013;&#30340;&#27599;&#20010;&#33410;&#28857;&#37117;&#25317;&#26377;&#19968;&#20010;&#26412;&#22320;&#20989;&#25968;&#65292;&#30446;&#26631;&#26159;&#21327;&#21516;&#33719;&#24471;&#19968;&#20010;&#26368;&#23567;&#21270;&#25152;&#26377;&#26412;&#22320;&#20989;&#25968;&#20043;&#21644;&#30340;&#20849;&#35782;&#35299;&#20915;&#26041;&#26696;&#12290;&#20998;&#25955;&#20248;&#21270;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#20381;&#36182;&#36890;&#20449;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#20173;&#28982;&#26159;&#19968;&#20010;&#30456;&#24403;&#22823;&#30340;&#29942;&#39048;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#38543;&#26426;&#21270;&#36890;&#20449;&#25928;&#29575;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#23450;&#26399;&#36861;&#36394;&#19981;&#19968;&#33268;&#35823;&#24046;&#24182;&#31934;&#36873;&#27599;&#20010;&#33410;&#28857;&#20013;&#26368;&#26377;&#24433;&#21709;&#21147;&#21644;&#26377;&#25928;&#30340;&#36793;&#32536;&#26469;&#20943;&#23569;&#36890;&#20449;&#37327;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#65306;&#33258;&#36866;&#24212;&#20849;&#35782;&#65288;AC&#65289;&#35299;&#20915;&#20849;&#35782;&#38382;&#39064;&#21644;&#22522;&#20110;&#33258;&#36866;&#24212;&#20849;&#35782;&#30340;&#26799;&#24230;&#36319;&#36394;&#65288;AC-GT&#65289;&#35299;&#20915;&#24179;&#28369;&#24378;&#20984;&#20998;&#25955;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#25152;&#25552;&#31639;&#27861;&#24314;&#31435;&#20102;&#24378;&#22823;&#30340;&#29702;&#35770;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#37327;&#21270;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#36890;&#20449;&#25104;&#26412;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider network-based decentralized optimization problems, where each node in the network possesses a local function and the objective is to collectively attain a consensus solution that minimizes the sum of all the local functions. A major challenge in decentralized optimization is the reliance on communication which remains a considerable bottleneck in many applications. To address this challenge, we propose an adaptive randomized communication-efficient algorithmic framework that reduces the volume of communication by periodically tracking the disagreement error and judiciously selecting the most influential and effective edges at each node for communication. Within this framework, we present two algorithms: Adaptive Consensus (AC) to solve the consensus problem and Adaptive Consensus based Gradient Tracking (AC-GT) to solve smooth strongly convex decentralized optimization problems. We establish strong theoretical convergence guarantees for the proposed algorithms and quantify 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26234;&#33021;&#20256;&#24863;&#22120;&#32593;&#32476;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#21464;&#37327;&#12289;&#22823;&#35268;&#27169;&#23454;&#26102;&#25968;&#25454;&#21644;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#27010;&#29575;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#21487;&#20998;&#31163;&#30340;&#36739;&#20302;&#19979;&#30028;&#65292;&#23454;&#29616;&#20102;&#22312;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#19968;&#36339;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#20108;&#36827;&#21046;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.02606</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#29992;&#20110;&#22312;&#32447;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributed Variational Inference for Online Supervised Learning. (arXiv:2309.02606v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02606
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26234;&#33021;&#20256;&#24863;&#22120;&#32593;&#32476;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#36830;&#32493;&#21464;&#37327;&#12289;&#22823;&#35268;&#27169;&#23454;&#26102;&#25968;&#25454;&#21644;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#27010;&#29575;&#30340;&#25512;&#26029;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#20986;&#21487;&#20998;&#31163;&#30340;&#36739;&#20302;&#19979;&#30028;&#65292;&#23454;&#29616;&#20102;&#22312;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#19968;&#36339;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#20108;&#36827;&#21046;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26234;&#33021;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#24320;&#21457;&#39640;&#25928;&#30340;&#25512;&#26029;&#38382;&#39064;&#35299;&#20915;&#26041;&#26696;&#23545;&#20110;&#19979;&#19968;&#20195;&#23450;&#20301;&#12289;&#36319;&#36394;&#21644;&#22320;&#22270;&#26381;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36830;&#32493;&#21464;&#37327;&#12289;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#27010;&#29575;&#21644;&#22823;&#35268;&#27169;&#23454;&#26102;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#20998;&#24067;&#24335;&#27010;&#29575;&#25512;&#26029;&#31639;&#27861;&#12290;&#22312;&#38598;&#20013;&#24335;&#35774;&#32622;&#20013;&#65292;&#21464;&#20998;&#25512;&#26029;&#26159;&#19968;&#31181;&#25191;&#34892;&#36817;&#20284;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#22522;&#26412;&#25216;&#26415;&#65292;&#20854;&#20013;&#23558;&#38590;&#20197;&#22788;&#29702;&#30340;&#21518;&#39564;&#23494;&#24230;&#29992;&#21442;&#25968;&#21270;&#23494;&#24230;&#26469;&#36817;&#20284;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#25512;&#23548;&#20986;&#19968;&#20010;&#21487;&#20998;&#31163;&#30340;&#36739;&#20302;&#19979;&#30028;&#65292;&#29992;&#20110;&#38598;&#20013;&#24335;&#20272;&#35745;&#30446;&#26631;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#20256;&#24863;&#22120;&#32593;&#32476;&#20013;&#36827;&#34892;&#19968;&#36339;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#21464;&#20998;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#20998;&#24067;&#24335;&#35777;&#25454;&#36739;&#20302;&#19979;&#30028; (DELBO) &#21253;&#25324;&#35266;&#27979;&#20284;&#28982;&#21644;&#36317;&#31163;&#20808;&#39564;&#23494;&#24230;&#30340;&#24046;&#20540;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#19982;&#27979;&#37327;&#35777;&#25454;&#30340;&#24046;&#36317;&#26159;&#30001;&#20110;&#20849;&#35782;&#21644;&#24314;&#27169;&#35823;&#24046;&#36896;&#25104;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#20108;&#36827;&#21046;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Developing efficient solutions for inference problems in intelligent sensor networks is crucial for the next generation of location, tracking, and mapping services. This paper develops a scalable distributed probabilistic inference algorithm that applies to continuous variables, intractable posteriors and large-scale real-time data in sensor networks. In a centralized setting, variational inference is a fundamental technique for performing approximate Bayesian estimation, in which an intractable posterior density is approximated with a parametric density. Our key contribution lies in the derivation of a separable lower bound on the centralized estimation objective, which enables distributed variational inference with one-hop communication in a sensor network. Our distributed evidence lower bound (DELBO) consists of a weighted sum of observation likelihood and divergence to prior densities, and its gap to the measurement evidence is due to consensus and modeling errors. To solve binary 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;&#25968;&#25454;&#32858;&#21512;&#31639;&#27861;BETULA&#20351;&#24471;&#36164;&#28304;&#21463;&#38480;&#31995;&#32479;&#19978;&#30340;&#23618;&#27425;&#32858;&#31867;&#26041;&#27861;HAC&#21464;&#24471;&#21487;&#34892;&#65292;&#20174;&#32780;&#20801;&#35768;&#23545;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2309.02552</link><description>&lt;p&gt;
&#25968;&#25454;&#32858;&#21512;&#29992;&#20110;&#23618;&#27425;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Data Aggregation for Hierarchical Clustering. (arXiv:2309.02552v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02552
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;&#25968;&#25454;&#32858;&#21512;&#31639;&#27861;BETULA&#20351;&#24471;&#36164;&#28304;&#21463;&#38480;&#31995;&#32479;&#19978;&#30340;&#23618;&#27425;&#32858;&#31867;&#26041;&#27861;HAC&#21464;&#24471;&#21487;&#34892;&#65292;&#20174;&#32780;&#20801;&#35768;&#23545;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#27425;&#20957;&#32858;&#32858;&#31867;&#65288;HAC&#65289;&#21487;&#33021;&#26159;&#26368;&#26089;&#21644;&#26368;&#28789;&#27963;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#19982;&#35768;&#22810;&#36317;&#31163;&#12289;&#30456;&#20284;&#24230;&#21644;&#19981;&#21516;&#30340;&#38142;&#25509;&#31574;&#30053;&#19968;&#36215;&#20351;&#29992;&#12290;&#24403;&#25968;&#25454;&#38598;&#24418;&#25104;&#30340;&#32858;&#31867;&#25968;&#37327;&#26410;&#30693;&#19988;&#25968;&#25454;&#20013;&#23384;&#22312;&#19968;&#23450;&#30340;&#23618;&#27425;&#32467;&#26500;&#26102;&#65292;&#36890;&#24120;&#20351;&#29992;HAC&#12290;&#22823;&#22810;&#25968;HAC&#31639;&#27861;&#22312;&#20840;&#36317;&#31163;&#30697;&#38453;&#19978;&#25805;&#20316;&#65292;&#22240;&#27492;&#38656;&#35201;&#20108;&#27425;&#23384;&#20648;&#12290;&#26631;&#20934;&#31639;&#27861;&#30340;&#36816;&#34892;&#26102;&#38388;&#20063;&#26159;&#31435;&#26041;&#32423;&#21035;&#30340;&#65292;&#29992;&#20110;&#29983;&#25104;&#23436;&#25972;&#30340;&#23618;&#27425;&#32467;&#26500;&#12290;&#22312;&#23884;&#20837;&#24335;&#25110;&#20854;&#20182;&#36164;&#28304;&#21463;&#38480;&#30340;&#31995;&#32479;&#20013;&#65292;&#23384;&#20648;&#21644;&#36816;&#34892;&#26102;&#38388;&#23588;&#20854;&#25104;&#38382;&#39064;&#12290;&#22312;&#26412;&#33410;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;BETULA&#36827;&#34892;&#25968;&#25454;&#32858;&#21512;&#65292;&#23427;&#26159;&#33879;&#21517;&#30340;BIRCH&#25968;&#25454;&#32858;&#21512;&#31639;&#27861;&#30340;&#25968;&#20540;&#31283;&#23450;&#29256;&#26412;&#65292;&#21487;&#20351;HAC&#22312;&#20855;&#26377;&#21463;&#38480;&#36164;&#28304;&#30340;&#31995;&#32479;&#19978;&#21487;&#34892;&#65292;&#21482;&#36896;&#25104;&#36739;&#23567;&#30340;&#32858;&#31867;&#36136;&#37327;&#25439;&#22833;&#65292;&#20174;&#32780;&#20801;&#35768;&#23545;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#25506;&#32034;&#24615;&#25968;&#25454;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Agglomerative Clustering (HAC) is likely the earliest and most flexible clustering method, because it can be used with many distances, similarities, and various linkage strategies. It is often used when the number of clusters the data set forms is unknown and some sort of hierarchy in the data is plausible. Most algorithms for HAC operate on a full distance matrix, and therefore require quadratic memory. The standard algorithm also has cubic runtime to produce a full hierarchy. Both memory and runtime are especially problematic in the context of embedded or otherwise very resource-constrained systems. In this section, we present how data aggregation with BETULA, a numerically stable version of the well known BIRCH data aggregation algorithm, can be used to make HAC viable on systems with constrained resources with only small losses on clustering quality, and hence allow exploratory data analysis of very large data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#25191;&#34892;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;softmax&#20989;&#25968;&#24212;&#29992;&#20110;&#38463;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#23545;&#35937;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#26102;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#25193;&#23637;&#21040;&#21333;&#20301;&#31435;&#26041;&#20307;&#19978;&#65292;&#20174;&#32780;&#22312;&#26377;&#30028;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#21069;&#26223;&#12290;</title><link>http://arxiv.org/abs/2309.02530</link><description>&lt;p&gt;
&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
Diffusion on the Probability Simplex. (arXiv:2309.02530v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#25191;&#34892;&#25193;&#25955;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;softmax&#20989;&#25968;&#24212;&#29992;&#20110;&#38463;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#23545;&#35937;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#26102;&#21462;&#24471;&#33391;&#22909;&#25928;&#26524;&#12290;&#36825;&#31181;&#26041;&#27861;&#20063;&#21487;&#20197;&#25193;&#23637;&#21040;&#21333;&#20301;&#31435;&#26041;&#20307;&#19978;&#65292;&#20174;&#32780;&#22312;&#26377;&#30028;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#21069;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#36870;&#36716;&#25968;&#25454;&#20998;&#24067;&#30340;&#36880;&#28176;&#22122;&#22768;&#21270;&#26469;&#21019;&#24314;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36830;&#32493;&#30340;&#22122;&#22768;&#21270;&#36807;&#31243;&#19982;&#31163;&#25955;&#25968;&#25454;&#20043;&#38388;&#30340;&#26399;&#26395;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36830;&#32493;&#24615;&#21644;&#31163;&#25955;&#24615;&#23545;&#35937;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#25191;&#34892;&#25193;&#25955;&#30340;&#26041;&#27861;&#12290;&#20351;&#29992;&#27010;&#29575;&#21333;&#32431;&#24418;&#33258;&#28982;&#22320;&#21019;&#24314;&#20102;&#19968;&#31181;&#35299;&#37322;&#65292;&#20854;&#20013;&#28857;&#23545;&#24212;&#20110;&#20998;&#31867;&#27010;&#29575;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#23545;&#38463;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#20043;&#38388;&#36827;&#34892;softmax&#20989;&#25968;&#30340;&#24212;&#29992;&#65292;&#36825;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#21253;&#25324;&#23545;&#21333;&#20301;&#31435;&#26041;&#20307;&#30340;&#25193;&#25955;&#65292;&#36825;&#23545;&#20110;&#26377;&#30028;&#22270;&#20687;&#29983;&#25104;&#24212;&#29992;&#20855;&#26377;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models learn to reverse the progressive noising of a data distribution to create a generative model. However, the desired continuous nature of the noising process can be at odds with discrete data. To deal with this tension between continuous and discrete objects, we propose a method of performing diffusion on the probability simplex. Using the probability simplex naturally creates an interpretation where points correspond to categorical probability distributions. Our method uses the softmax function applied to an Ornstein-Unlenbeck Process, a well-known stochastic differential equation. We find that our methodology also naturally extends to include diffusion on the unit cube which has applications for bounded image generation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26368;&#20248;&#35299;&#8212;&#8212;COPS&#65288;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#20248;&#23376;&#37319;&#26679;&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#26680;&#24515;&#38598;&#36873;&#25321;&#21644;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#65292;&#22312;&#20943;&#23569;&#26631;&#35760;&#25968;&#25454;&#38598;&#25104;&#26412;&#30340;&#21516;&#26102;&#26368;&#23567;&#21270;&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2309.02476</link><description>&lt;p&gt;
&#36890;&#36807;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23454;&#29616;&#20248;&#21270;&#26679;&#26412;&#36873;&#25321;&#21450;&#20854;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Optimal Sample Selection Through Uncertainty Estimation and Its Application in Deep Learning. (arXiv:2309.02476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02476
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#26368;&#20248;&#35299;&#8212;&#8212;COPS&#65288;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#20248;&#23376;&#37319;&#26679;&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#26680;&#24515;&#38598;&#36873;&#25321;&#21644;&#20027;&#21160;&#23398;&#20064;&#38382;&#39064;&#65292;&#22312;&#20943;&#23569;&#26631;&#35760;&#25968;&#25454;&#38598;&#25104;&#26412;&#30340;&#21516;&#26102;&#26368;&#23567;&#21270;&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#23398;&#20064;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#22823;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#20294;&#22312;&#25163;&#21160;&#26631;&#27880;&#21644;&#35745;&#31639;&#36164;&#28304;&#26041;&#38754;&#24448;&#24448;&#20250;&#24102;&#26469;&#39640;&#26114;&#30340;&#25104;&#26412;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#25506;&#32034;&#20102;&#19968;&#20123;&#20449;&#24687;&#24615;&#23376;&#38598;&#36873;&#25321;&#25216;&#26415;&#65292;&#21253;&#25324;&#26680;&#24515;&#38598;&#36873;&#25321;&#21644;&#20027;&#21160;&#23398;&#20064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26680;&#24515;&#38598;&#36873;&#25321;&#28041;&#21450;&#21040;&#21516;&#26102;&#37319;&#26679;&#36755;&#20837;&#65288;$\bx$&#65289;&#21644;&#36755;&#20986;&#65288;$\by$&#65289;&#30340;&#25968;&#25454;&#65292;&#32780;&#20027;&#21160;&#23398;&#20064;&#20165;&#20851;&#27880;&#36755;&#20837;&#25968;&#25454;&#65288;$\bx$&#65289;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#32447;&#24615;softmax&#22238;&#24402;&#32972;&#26223;&#19979;&#21516;&#26102;&#35299;&#20915;&#26680;&#24515;&#38598;&#36873;&#25321;&#21644;&#20027;&#21160;&#23398;&#20064;&#30340;&#29702;&#35770;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;COPS&#65288;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#26368;&#20248;&#23376;&#37319;&#26679;&#65289;&#65292;&#26088;&#22312;&#26368;&#23567;&#21270;&#22522;&#20110;&#23376;&#37319;&#26679;&#25968;&#25454;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#12290;&#19982;&#29616;&#26377;&#30340;&#20381;&#36182;&#20110;&#26174;&#24335;&#35745;&#31639;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#28145;&#24230;&#23398;&#20064;&#22330;&#26223;&#20013;&#19981;&#23481;&#26131;&#24212;&#29992;&#12290;COPS&#21033;&#29992;&#27169;&#22411;&#30340;&#36923;&#36753;&#22238;&#24402;&#20540;&#26469;&#20272;&#35745;&#37319;&#26679;&#30340;...
&lt;/p&gt;
&lt;p&gt;
Modern deep learning heavily relies on large labeled datasets, which often comse with high costs in terms of both manual labeling and computational resources. To mitigate these challenges, researchers have explored the use of informative subset selection techniques, including coreset selection and active learning. Specifically, coreset selection involves sampling data with both input ($\bx$) and output ($\by$), active learning focuses solely on the input data ($\bx$).  In this study, we present a theoretically optimal solution for addressing both coreset selection and active learning within the context of linear softmax regression. Our proposed method, COPS (unCertainty based OPtimal Sub-sampling), is designed to minimize the expected loss of a model trained on subsampled data. Unlike existing approaches that rely on explicit calculations of the inverse covariance matrix, which are not easily applicable to deep learning scenarios, COPS leverages the model's logits to estimate the sampl
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#27169;&#20223;&#23398;&#20064;&#30340;&#31639;&#27861;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#25351;&#20986;&#22312;&#22797;&#26434;&#21644;&#38750;&#32467;&#26500;&#21270;&#30340;&#29615;&#22659;&#20013;&#65292;&#36890;&#36807;&#27169;&#20223;&#19987;&#23478;&#34892;&#20026;&#26469;&#23398;&#20064;&#25152;&#38656;&#34892;&#20026;&#26356;&#20855;&#21560;&#24341;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.02473</link><description>&lt;p&gt;
&#27169;&#20223;&#23398;&#20064;&#32508;&#36848;&#65306;&#31639;&#27861;&#12289;&#26368;&#26032;&#36827;&#23637;&#19982;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges. (arXiv:2309.02473v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.02473
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32508;&#36848;&#20102;&#27169;&#20223;&#23398;&#20064;&#30340;&#31639;&#27861;&#12289;&#26368;&#26032;&#36827;&#23637;&#21644;&#25361;&#25112;&#65292;&#25351;&#20986;&#22312;&#22797;&#26434;&#21644;&#38750;&#32467;&#26500;&#21270;&#30340;&#29615;&#22659;&#20013;&#65292;&#36890;&#36807;&#27169;&#20223;&#19987;&#23478;&#34892;&#20026;&#26469;&#23398;&#20064;&#25152;&#38656;&#34892;&#20026;&#26356;&#20855;&#21560;&#24341;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26426;&#22120;&#20154;&#21644;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#21457;&#23637;&#20196;&#20154;&#30633;&#30446;&#12290;&#38543;&#30528;&#36825;&#20123;&#31995;&#32479;&#30340;&#19981;&#26029;&#28436;&#36827;&#65292;&#23427;&#20204;&#36234;&#26469;&#36234;&#34987;&#24212;&#29992;&#20110;&#22797;&#26434;&#21644;&#38750;&#32467;&#26500;&#21270;&#30340;&#29615;&#22659;&#20013;&#65292;&#22914;&#33258;&#21160;&#39550;&#39542;&#12289;&#31354;&#20013;&#26426;&#22120;&#20154;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#12290;&#30001;&#20110;&#36825;&#20123;&#29615;&#22659;&#38656;&#35201;&#39640;&#24230;&#30340;&#28789;&#27963;&#24615;&#21644;&#36866;&#24212;&#24615;&#65292;&#22240;&#27492;&#25163;&#21160;&#32534;&#31243;&#34892;&#20026;&#25110;&#36890;&#36807;&#22870;&#21169;&#20989;&#25968;&#26469;&#23450;&#20041;&#34892;&#20026;&#65288;&#22914;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20570;&#27861;&#65289;&#21464;&#24471;&#38750;&#24120;&#22256;&#38590;&#12290;&#22312;&#36825;&#26679;&#30340;&#29615;&#22659;&#20013;&#65292;&#36890;&#36807;&#27169;&#20223;&#19987;&#23478;&#34892;&#20026;&#26469;&#23398;&#20064;&#26356;&#20855;&#21560;&#24341;&#21147;&#12290;&#36825;&#23601;&#26159;&#27169;&#20223;&#23398;&#20064;&#30340;&#20316;&#29992; - &#36890;&#36807;&#27169;&#20223;&#19987;&#23478;&#30340;&#34892;&#20026;&#26469;&#23398;&#20064;&#25152;&#26399;&#26395;&#30340;&#34892;&#20026;&#65292;&#32780;&#36825;&#20123;&#34892;&#20026;&#26159;&#36890;&#36807;&#28436;&#31034;&#25552;&#20379;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, the development of robotics and artificial intelligence (AI) systems has been nothing short of remarkable. As these systems continue to evolve, they are being utilized in increasingly complex and unstructured environments, such as autonomous driving, aerial robotics, and natural language processing. As a consequence, programming their behaviors manually or defining their behavior through reward functions (as done in reinforcement learning (RL)) has become exceedingly difficult. This is because such environments require a high degree of flexibility and adaptability, making it challenging to specify an optimal set of rules or reward signals that can account for all possible situations. In such environments, learning from an expert's behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expert's behavior, which is provided through demonstrations.  This paper a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#35780;&#20998;&#20989;&#25968;CONFIDERAI&#65292;&#23427;&#23558;&#19968;&#33268;&#24615;&#39044;&#27979;&#19982;&#35268;&#21017;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#35268;&#21017;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#28857;&#30340;&#20960;&#20309;&#20301;&#32622;&#65292;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23450;&#20041;&#28385;&#36275;&#19968;&#33268;&#24615;&#20445;&#35777;&#30340;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2309.01778</link><description>&lt;p&gt;
CONFIDERAI&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;CONFIRMAL&#21487;&#35299;&#37322;&#35774;&#35745;&#35780;&#20998;&#20989;&#25968;&#65292;&#29992;&#20110;&#21487;&#35299;&#37322;&#21644;&#21487;&#38752;&#30340;&#20154;&#24037;&#26234;&#33021;
&lt;/p&gt;
&lt;p&gt;
CONFIDERAI: a novel CONFormal Interpretable-by-Design score function forExplainable and Reliable Artificial Intelligence. (arXiv:2309.01778v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01778
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#35780;&#20998;&#20989;&#25968;CONFIDERAI&#65292;&#23427;&#23558;&#19968;&#33268;&#24615;&#39044;&#27979;&#19982;&#35268;&#21017;&#27169;&#22411;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#35268;&#21017;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#28857;&#30340;&#20960;&#20309;&#20301;&#32622;&#65292;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23450;&#20041;&#28385;&#36275;&#19968;&#33268;&#24615;&#20445;&#35777;&#30340;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27599;&#22825;&#30340;&#29983;&#27963;&#36234;&#26469;&#36234;&#21463;&#20154;&#24037;&#26234;&#33021;&#30340;&#24433;&#21709;&#65292;&#27627;&#26080;&#30097;&#38382;&#65292;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#24517;&#39035;&#20026;&#25152;&#26377;&#20154;&#35774;&#35745;&#25104;&#21487;&#38752;&#21644;&#20540;&#24471;&#20449;&#36182;&#30340;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#22914;&#26524;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#28385;&#36275;&#35299;&#37322;&#24615;&#12289;&#20581;&#22766;&#24615;&#12289;&#36879;&#26126;&#24615;&#12289;&#20844;&#24179;&#24615;&#21644;&#38544;&#31169;&#24615;&#36825;&#20116;&#20010;&#26041;&#38754;&#65292;&#35745;&#31639;&#26426;&#31185;&#23398;&#23478;&#35748;&#20026;&#23427;&#26159;&#23433;&#20840;&#21644;&#21487;&#20449;&#36182;&#30340;&#12290;&#38500;&#20102;&#36825;&#20116;&#20010;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#20845;&#20010;&#22522;&#26412;&#26041;&#38754;&#65306;&#19968;&#33268;&#24615;&#65292;&#21363;&#26426;&#22120;&#23398;&#20064;&#32773;&#23545;&#31995;&#32479;&#34892;&#20026;&#30340;&#27010;&#29575;&#24615;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23450;&#20041;CONFIDERAI&#65292;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#27169;&#22411;&#30340;&#26032;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#19968;&#33268;&#24615;&#39044;&#27979;&#19982;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#21033;&#29992;&#35268;&#21017;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#28857;&#22312;&#35268;&#21017;&#36793;&#30028;&#20869;&#30340;&#20960;&#20309;&#20301;&#32622;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#21033;&#29992;&#25511;&#21046;&#38750;&#19968;&#33268;&#24615;&#30340;&#25968;&#37327;&#30340;&#25216;&#26415;&#26469;&#35299;&#20915;&#22312;&#29305;&#24449;&#31354;&#38388;&#20013;&#23450;&#20041;&#28385;&#36275;&#19968;&#33268;&#24615;&#20445;&#35777;&#30340;&#21306;&#22495;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Everyday life is increasingly influenced by artificial intelligence, and there is no question that machine learning algorithms must be designed to be reliable and trustworthy for everyone. Specifically, computer scientists consider an artificial intelligence system safe and trustworthy if it fulfills five pillars: explainability, robustness, transparency, fairness, and privacy. In addition to these five, we propose a sixth fundamental aspect: conformity, that is, the probabilistic assurance that the system will behave as the machine learner expects. In this paper, we propose a methodology to link conformal prediction with explainable machine learning by defining CONFIDERAI, a new score function for rule-based models that leverages both rules predictive ability and points geometrical position within rules boundaries. We also address the problem of defining regions in the feature space where conformal guarantees are satisfied by exploiting techniques to control the number of non-conforma
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#20013;&#20005;&#26684;&#32422;&#26463;&#22270;&#30340;&#26080;&#29615;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#25299;&#25169;&#25490;&#24207;&#30693;&#35782;&#65292;&#33021;&#22815;&#20943;&#23569;&#25512;&#29702;&#22797;&#26434;&#24615;&#65292;&#24182;&#30830;&#20445;&#29983;&#25104;&#30340;&#22270;&#30340;&#32467;&#26500;&#26159;&#26080;&#29615;&#30340;&#12290;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#22522;&#20110;&#24471;&#20998;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.01392</link><description>&lt;p&gt;
&#19981;&#21516;iable&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#25299;&#25169;&#25490;&#24207;&#19982;&#20445;&#35777;&#26080;&#29615;&#24615;&#30340;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
Topological Ordering in Differentiable Bayesian Structure Learning with Guaranteed Acyclicity Constraint. (arXiv:2309.01392v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01392
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#20013;&#20005;&#26684;&#32422;&#26463;&#22270;&#30340;&#26080;&#29615;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#36890;&#36807;&#25972;&#21512;&#25299;&#25169;&#25490;&#24207;&#30693;&#35782;&#65292;&#33021;&#22815;&#20943;&#23569;&#25512;&#29702;&#22797;&#26434;&#24615;&#65292;&#24182;&#30830;&#20445;&#29983;&#25104;&#30340;&#22270;&#30340;&#32467;&#26500;&#26159;&#26080;&#29615;&#30340;&#12290;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#32988;&#36807;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#22522;&#20110;&#24471;&#20998;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#30340;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#22240;&#20854;&#21487;&#25193;&#23637;&#24615;&#32780;&#34028;&#21187;&#21457;&#23637;&#12290;&#36830;&#32493;&#26494;&#24347;&#26159;&#36825;&#19968;&#36827;&#23637;&#30340;&#20851;&#38190;&#21407;&#22240;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#20173;&#28982;&#22312;&#36890;&#36807;&#26368;&#23567;&#21270;&#23450;&#20041;&#30340;&#24471;&#20998;&#26469;&#30830;&#20445;&#20174;&#28508;&#22312;&#31354;&#38388;&#29983;&#25104;&#30340;&#22270;&#26159;&#26080;&#29615;&#30340;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#12290;&#36824;&#23384;&#22312;&#21478;&#19968;&#31181;&#22522;&#20110;&#32622;&#25442;&#30340;&#26041;&#27861;&#65292;&#20851;&#27880;&#30340;&#26159;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#20013;&#21464;&#37327;&#30340;&#25299;&#25169;&#25490;&#24207;&#30340;&#25628;&#32034;&#65292;&#20197;&#38480;&#21046;&#22270;&#30340;&#25628;&#32034;&#31354;&#38388;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25299;&#25169;&#25490;&#24207;&#30693;&#35782;&#26469;&#20005;&#26684;&#38480;&#21046;&#22270;&#30340;&#26080;&#29615;&#24615;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20943;&#23569;&#25512;&#29702;&#22797;&#26434;&#24615;&#65292;&#21516;&#26102;&#30830;&#20445;&#29983;&#25104;&#30340;&#22270;&#30340;&#32467;&#26500;&#26159;&#26080;&#29615;&#30340;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#30340;&#23454;&#35777;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#32988;&#36807;&#30456;&#20851;&#30340;&#36125;&#21494;&#26031;&#22522;&#20110;&#24471;&#20998;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based approaches in the structure learning task are thriving because of their scalability. Continuous relaxation has been the key reason for this advancement. Despite achieving promising outcomes, most of these methods are still struggling to ensure that the graphs generated from the latent space are acyclic by minimizing a defined score. There has also been another trend of permutation-based approaches, which concern the search for the topological ordering of the variables in the directed acyclic graph (DAG) in order to limit the search space of the graph. In this study, we propose an alternative approach for strictly constraining the acyclicty of the graphs with an integration of the knowledge from the topological orderings. Our approach can reduce inference complexity while ensuring the structures of the generated graphs to be acyclic. Our empirical experiments with simulated and real-world data show that our approach can outperform related Bayesian score-based approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#22312;&#35299;&#37322;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#21457;&#29616;&#31354;&#38388;&#38646;&#20540;&#21644;&#27491;&#21017;&#21270;&#23545;&#22238;&#24402;&#31995;&#25968;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#20844;&#24335;&#26469;&#27604;&#36739;&#22238;&#24402;&#31995;&#25968;&#19982;&#29289;&#29702;&#24037;&#31243;&#30693;&#35782;&#24471;&#21040;&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#35299;&#37322;&#24615;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.00564</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#35299;&#37322;&#65306;&#31354;&#38388;&#38646;&#20540;&#21644;&#27491;&#21017;&#21270;&#22312;&#30005;&#27744;&#25968;&#25454;&#19978;&#30340;&#24433;&#21709;&#30340;&#28436;&#31034;
&lt;/p&gt;
&lt;p&gt;
Interpretation of High-Dimensional Linear Regression: Effects of Nullspace and Regularization Demonstrated on Battery Data. (arXiv:2309.00564v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#22312;&#35299;&#37322;&#26041;&#38754;&#30340;&#25361;&#25112;&#65292;&#21457;&#29616;&#31354;&#38388;&#38646;&#20540;&#21644;&#27491;&#21017;&#21270;&#23545;&#22238;&#24402;&#31995;&#25968;&#20135;&#29983;&#37325;&#35201;&#24433;&#21709;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#20844;&#24335;&#26469;&#27604;&#36739;&#22238;&#24402;&#31995;&#25968;&#19982;&#29289;&#29702;&#24037;&#31243;&#30693;&#35782;&#24471;&#21040;&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#35299;&#37322;&#24615;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#32771;&#34385;&#21040;&#20174;&#21270;&#23398;&#25110;&#29983;&#29289;&#31995;&#32479;&#20013;&#32463;&#24120;&#24471;&#21040;&#30340;&#22522;&#30784;&#24179;&#28369;&#28508;&#22312;&#36807;&#31243;&#30340;&#31163;&#25955;&#27979;&#37327;&#25968;&#25454;&#12290;&#22312;&#39640;&#32500;&#24230;&#20013;&#35299;&#37322;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#31354;&#38388;&#38646;&#20540;&#21450;&#20854;&#19982;&#27491;&#21017;&#21270;&#30340;&#30456;&#20114;&#20316;&#29992;&#20250;&#22609;&#36896;&#22238;&#24402;&#31995;&#25968;&#12290;&#25968;&#25454;&#30340;&#31354;&#38388;&#38646;&#20540;&#21253;&#21547;&#25152;&#26377;&#28385;&#36275;$\mathbf{Xw}=\mathbf{0}$&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#20801;&#35768;&#38750;&#24120;&#19981;&#21516;&#30340;&#31995;&#25968;&#20135;&#29983;&#30456;&#21516;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20248;&#21270;&#20844;&#24335;&#26469;&#27604;&#36739;&#22238;&#24402;&#31995;&#25968;&#21644;&#36890;&#36807;&#29289;&#29702;&#24037;&#31243;&#30693;&#35782;&#24471;&#21040;&#30340;&#31995;&#25968;&#65292;&#20197;&#20102;&#35299;&#31995;&#25968;&#24046;&#24322;&#30340;&#21738;&#20123;&#37096;&#20998;&#25509;&#36817;&#20110;&#31354;&#38388;&#38646;&#20540;&#12290;&#36825;&#31181;&#31354;&#38388;&#38646;&#20540;&#26041;&#27861;&#22312;&#19968;&#20010;&#21512;&#25104;&#31034;&#20363;&#21644;&#38146;&#31163;&#23376;&#30005;&#27744;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#26696;&#20363;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#26681;&#25454;&#20808;&#21069;&#30340;&#29289;&#29702;&#30693;&#35782;&#36873;&#25321;&#21512;&#36866;&#30340;&#27491;&#21017;&#21270;&#21644;z-score&#22788;&#29702;&#65292;&#21487;&#20197;&#24471;&#21040;&#21487;&#35299;&#37322;&#30340;&#22238;&#24402;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional linear regression is important in many scientific fields. This article considers discrete measured data of underlying smooth latent processes, as is often obtained from chemical or biological systems. Interpretation in high dimensions is challenging because the nullspace and its interplay with regularization shapes regression coefficients. The data's nullspace contains all coefficients that satisfy $\mathbf{Xw}=\mathbf{0}$, thus allowing very different coefficients to yield identical predictions. We developed an optimization formulation to compare regression coefficients and coefficients obtained by physical engineering knowledge to understand which part of the coefficient differences are close to the nullspace. This nullspace method is tested on a synthetic example and lithium-ion battery data. The case studies show that regularization and z-scoring are design choices that, if chosen corresponding to prior physical knowledge, lead to interpretable regression results. 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#21644;&#31616;&#21333;&#24615;&#65292;&#21482;&#38656;&#35201;&#36827;&#34892;1&#27425;&#36845;&#20195;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#21644;&#36870;&#38382;&#39064;&#65292;&#24182;&#19988;&#26377;&#28508;&#21147;&#26500;&#24314;&#33021;&#22815;&#21033;&#29992;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#36827;&#34892;&#38543;&#26426;&#21464;&#24322;&#21644;&#21464;&#24322;&#25511;&#21046;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2308.09444</link><description>&lt;p&gt;
&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#19968;&#27425;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Efficient 1 Iteration Learning Algorithm for Gaussian Mixture Model And Gaussian Mixture Embedding For Neural Network. (arXiv:2308.09444v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09444
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#21644;&#31616;&#21333;&#24615;&#65292;&#21482;&#38656;&#35201;&#36827;&#34892;1&#27425;&#36845;&#20195;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#21644;&#36870;&#38382;&#39064;&#65292;&#24182;&#19988;&#26377;&#28508;&#21147;&#26500;&#24314;&#33021;&#22815;&#21033;&#29992;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#36827;&#34892;&#38543;&#26426;&#21464;&#24322;&#21644;&#21464;&#24322;&#25511;&#21046;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25105;&#20204;&#20043;&#21069;&#30340;GMM&#25193;&#23637;&#24605;&#24819;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65288;GMM&#65289;&#23398;&#20064;&#31639;&#27861;&#12290;&#26032;&#31639;&#27861;&#27604;&#20256;&#32479;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#31639;&#27861;&#26356;&#20855;&#40065;&#26834;&#24615;&#21644;&#31616;&#21333;&#24615;&#12290;&#23427;&#36824;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#36827;&#34892;1&#27425;&#36845;&#20195;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#36825;&#31181;&#26032;&#31639;&#27861;&#26080;&#35770;&#21442;&#25968;&#21021;&#22987;&#21270;&#22914;&#20309;&#37117;&#33021;&#20445;&#35777;&#25910;&#25947;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;GMM&#25193;&#23637;&#26041;&#27861;&#19982;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#32463;&#20856;&#27010;&#29575;&#23618;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#26356;&#22909;&#22320;&#20811;&#26381;&#25968;&#25454;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#36870;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#27979;&#35797;&#20102;&#22522;&#20110;GMM&#30340;&#29983;&#25104;&#22120;&#65292;&#26174;&#31034;&#20986;&#20102;&#36827;&#19968;&#27493;&#21033;&#29992;&#20998;&#24067;&#38543;&#26426;&#25277;&#26679;&#36827;&#34892;&#38543;&#26426;&#21464;&#24322;&#21644;&#21464;&#24322;&#25511;&#21046;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an Gaussian Mixture Model (GMM) learning algorithm, based on our previous work of GMM expansion idea. The new algorithm brings more robustness and simplicity than classic Expectation Maximization (EM) algorithm. It also improves the accuracy and only take 1 iteration for learning. We theoretically proof that this new algorithm is guarantee to converge regardless the parameters initialisation. We compare our GMM expansion method with classic probability layers in neural network leads to demonstrably better capability to overcome data uncertainty and inverse problem. Finally, we test GMM based generator which shows a potential to build further application that able to utilized distribution random sampling for stochastic variation as well as variation control.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#20351;&#29992;&#22240;&#26524;&#24605;&#32500;&#36827;&#34892;&#20915;&#31574;&#30340;&#24517;&#35201;&#24615;&#21644;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#35797;&#39564;&#26469;&#20010;&#24615;&#21270;&#20915;&#31574;&#65292;&#20197;&#20943;&#23569;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#12290;&#36825;&#23545;&#20110;&#20998;&#26512;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25110;&#32034;&#36180;&#25968;&#25454;&#20197;&#24471;&#20986;&#22240;&#26524;&#32467;&#35770;&#30340;&#26368;&#37325;&#35201;&#38519;&#38449;&#21644;&#32771;&#34385;&#22240;&#32032;&#36827;&#34892;&#20102;&#37325;&#28857;&#24378;&#35843;&#12290;</title><link>http://arxiv.org/abs/2308.01605</link><description>&lt;p&gt;
&#29992;&#20110;&#20915;&#31574;&#30340;&#22240;&#26524;&#24605;&#32500;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#30340;&#24212;&#29992;&#65306;&#20026;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;
&lt;/p&gt;
&lt;p&gt;
Causal thinking for decision making on Electronic Health Records: why and how. (arXiv:2308.01605v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#20351;&#29992;&#22240;&#26524;&#24605;&#32500;&#36827;&#34892;&#20915;&#31574;&#30340;&#24517;&#35201;&#24615;&#21644;&#26041;&#27861;&#12290;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#35797;&#39564;&#26469;&#20010;&#24615;&#21270;&#20915;&#31574;&#65292;&#20197;&#20943;&#23569;&#25968;&#25454;&#20013;&#30340;&#20559;&#35265;&#12290;&#36825;&#23545;&#20110;&#20998;&#26512;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25110;&#32034;&#36180;&#25968;&#25454;&#20197;&#24471;&#20986;&#22240;&#26524;&#32467;&#35770;&#30340;&#26368;&#37325;&#35201;&#38519;&#38449;&#21644;&#32771;&#34385;&#22240;&#32032;&#36827;&#34892;&#20102;&#37325;&#28857;&#24378;&#35843;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#22914;&#21516;&#26426;&#22120;&#23398;&#20064;&#19968;&#26679;&#65292;&#21487;&#33021;&#26080;&#27861;&#20026;&#27599;&#20010;&#24739;&#32773;&#25552;&#20379;&#26368;&#20339;&#21307;&#30103;&#20445;&#20581;&#12290;&#30830;&#23454;&#65292;&#39044;&#27979;&#21487;&#33021;&#21463;&#21040;&#25968;&#25454;&#20013;&#30340;&#25463;&#24452;&#65288;&#22914;&#31181;&#26063;&#20559;&#35265;&#65289;&#30340;&#39537;&#21160;&#12290;&#20026;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#38656;&#35201;&#22240;&#26524;&#24605;&#32500;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20851;&#38190;&#35201;&#32032;&#65292;&#37325;&#28857;&#20851;&#27880;&#24120;&#35268;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#21363;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHRs&#65289;&#21644;&#32034;&#36180;&#25968;&#25454;&#12290;&#20351;&#29992;&#36825;&#20123;&#25968;&#25454;&#35780;&#20272;&#24178;&#39044;&#30340;&#20215;&#20540;&#38656;&#35201;&#35880;&#24910;&#65306;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#29616;&#26377;&#23454;&#36341;&#24456;&#23481;&#26131;&#28151;&#28102;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#36880;&#27493;&#26694;&#26550;&#65292;&#24110;&#21161;&#20174;&#30495;&#23454;&#24739;&#32773;&#35760;&#24405;&#20013;&#26500;&#24314;&#26377;&#25928;&#30340;&#20915;&#31574;&#65292;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#35797;&#39564;&#26469;&#20010;&#24615;&#21270;&#20915;&#31574;&#65292;&#20363;&#22914;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24378;&#35843;&#20102;&#20998;&#26512;EHRs&#25110;&#32034;&#36180;&#25968;&#25454;&#20197;&#24471;&#20986;&#22240;&#26524;&#32467;&#35770;&#26102;&#26368;&#37325;&#35201;&#30340;&#38519;&#38449;&#21644;&#32771;&#34385;&#22240;&#32032;&#12290;&#25105;&#20204;&#22312;&#29992;&#20110;&#37325;&#30151;&#21307;&#23398;&#20449;&#24687;&#24066;&#22330;&#20013;&#30340;&#32908;&#37200;&#23545;&#36133;&#34880;&#30151;&#27515;&#20129;&#29575;&#30340;&#24433;&#21709;&#30340;&#30740;&#31350;&#20013;&#35828;&#26126;&#20102;&#21508;&#31181;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurate predictions, as with machine learning, may not suffice to provide optimal healthcare for every patient. Indeed, prediction can be driven by shortcuts in the data, such as racial biases. Causal thinking is needed for data-driven decisions. Here, we give an introduction to the key elements, focusing on routinely-collected data, electronic health records (EHRs) and claims data. Using such data to assess the value of an intervention requires care: temporal dependencies and existing practices easily confound the causal effect. We present a step-by-step framework to help build valid decision making from real-life patient records by emulating a randomized trial before individualizing decisions, eg with machine learning. Our framework highlights the most important pitfalls and considerations in analysing EHRs or claims data to draw causal conclusions. We illustrate the various choices in studying the effect of albumin on sepsis mortality in the Medical Information Mart for Intensive C
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.04056</link><description>&lt;p&gt;
&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Manifold Filter-Combine Networks. (arXiv:2307.04056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04056
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31867;&#31216;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#30340;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#26469;&#23454;&#29616;&#36825;&#31181;&#32593;&#32476;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#21040;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#19981;&#20381;&#36182;&#20110;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22823;&#22411;&#27969;&#24418;&#31070;&#32463;&#32593;&#32476;(MNNs)&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#27969;&#24418;&#28388;&#27874;-&#32452;&#21512;&#32593;&#32476;&#12290;&#36825;&#20010;&#31867;&#21035;&#21253;&#25324;&#20102;Wang&#12289;Ruiz&#21644;Ribeiro&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#32771;&#34385;&#30340;MNNs&#65292;&#27969;&#24418;&#25955;&#23556;&#21464;&#25442;(&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;)&#65292;&#20197;&#21450;&#20854;&#20182;&#26377;&#36259;&#30340;&#20043;&#21069;&#22312;&#25991;&#29486;&#20013;&#26410;&#32771;&#34385;&#30340;&#31034;&#20363;&#65292;&#22914;Kipf&#21644;Welling&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#27969;&#24418;&#31561;&#25928;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;&#26500;&#24314;&#25968;&#25454;&#39537;&#21160;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#27809;&#26377;&#23545;&#27969;&#24418;&#26377;&#20840;&#23616;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;&#32780;&#21482;&#33021;&#35775;&#38382;&#26377;&#38480;&#25968;&#37327;&#30340;&#26679;&#26412;&#28857;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32593;&#32476;&#22312;&#26679;&#26412;&#28857;&#25968;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#33021;&#22815;&#20445;&#35777;&#25910;&#25947;&#21040;&#20854;&#36830;&#32493;&#26497;&#38480;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;(&#20027;&#35201;&#20851;&#27880;&#29305;&#23450;&#30340;MNN&#32467;&#26500;&#21644;&#22270;&#26500;&#24314;)&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25910;&#25947;&#36895;&#24230;&#24182;&#19981;&#20381;&#36182;&#20110;&#20351;&#29992;&#30340;&#28388;&#27874;&#22120;&#25968;&#37327;&#12290;&#32780;&#19988;&#65292;&#23427;&#34920;&#29616;&#20986;&#32447;&#24615;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a large class of manifold neural networks (MNNs) which we call Manifold Filter-Combine Networks. This class includes as special cases, the MNNs considered in previous work by Wang, Ruiz, and Ribeiro, the manifold scattering transform (a wavelet-based model of neural networks), and other interesting examples not previously considered in the literature such as the manifold equivalent of Kipf and Welling's graph convolutional network. We then consider a method, based on building a data-driven graph, for implementing such networks when one does not have global knowledge of the manifold, but merely has access to finitely many sample points. We provide sufficient conditions for the network to provably converge to its continuum limit as the number of sample points tends to infinity. Unlike previous work (which focused on specific MNN architectures and graph constructions), our rate of convergence does not explicitly depend on the number of filters used. Moreover, it exhibits line
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#30475;&#20284;&#26080;&#20851;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#37325;&#26032;&#26500;&#36896;&#20026;&#20849;&#21516;&#30340;&#20004;&#20010;&#20132;&#38169;&#27493;&#39588;&#65292;&#21363;&#20048;&#35266;&#31574;&#30053;&#25913;&#36827;&#21644;&#21518;&#35265;&#36866;&#24212;&#65292;&#32479;&#19968;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#21152;&#36895;&#26041;&#27861;&#20013;&#30340;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;&#30340;&#20849;&#21516;&#29702;&#35770;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10587</link><description>&lt;p&gt;
&#31574;&#30053;&#20248;&#21270;&#20013;&#30340;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimism and Adaptivity in Policy Optimization. (arXiv:2306.10587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#30475;&#20284;&#26080;&#20851;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#37325;&#26032;&#26500;&#36896;&#20026;&#20849;&#21516;&#30340;&#20004;&#20010;&#20132;&#38169;&#27493;&#39588;&#65292;&#21363;&#20048;&#35266;&#31574;&#30053;&#25913;&#36827;&#21644;&#21518;&#35265;&#36866;&#24212;&#65292;&#32479;&#19968;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#21152;&#36895;&#26041;&#27861;&#20013;&#30340;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;&#30340;&#20849;&#21516;&#29702;&#35770;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#36890;&#36807;&#8220;&#20048;&#35266;&#24615;&#8221;&#21644;&#8220;&#36866;&#24212;&#24615;&#8221;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21152;&#36895;&#31574;&#30053;&#20248;&#21270;&#26041;&#27861;&#30340;&#32479;&#19968;&#33539;&#24335;&#12290;&#36890;&#36807;&#21033;&#29992;&#31574;&#30053;&#36845;&#20195;&#21644;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#65292;&#25105;&#20204;&#23558;&#19968;&#20123;&#30475;&#20284;&#26080;&#20851;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#37325;&#26032;&#26500;&#36896;&#20026;&#20004;&#20010;&#20132;&#38169;&#27493;&#39588;&#65288;i&#65289;&#20048;&#35266;&#31574;&#30053;&#25913;&#36827;&#25805;&#20316;&#22120;&#20351;&#29992;&#8220;&#26799;&#24230;&#19978;&#21319;&#39044;&#27979;&#8221;&#23558;&#20808;&#21069;&#30340;&#31574;&#30053;$\pi_t$&#26144;&#23556;&#21040;&#19968;&#20010;&#20551;&#35774;$\pi_{t+1}$&#65292;&#28982;&#21518;&#65288;ii&#65289;&#23545;$\pi_{t+1}$&#30340;&#24615;&#33021;&#36827;&#34892;&#37096;&#20998;&#35780;&#20272;&#65292;&#24182;&#22522;&#20110;&#27492;&#36827;&#34892;&#8220;&#21518;&#35265;&#36866;&#24212;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#20849;&#20139;&#30340;&#35270;&#35282;&#26469;&#20849;&#21516;&#34920;&#36798;&#20854;&#20182;&#20247;&#25152;&#21608;&#30693;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#36719;&#20214;&#21644;&#20048;&#35266;&#31574;&#30053;&#36845;&#20195;&#12289;&#33258;&#28982;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#12289;&#22522;&#20110;&#21069;&#21521;&#25628;&#32034;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31574;&#30053;&#25913;&#36827;&#21644;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20851;&#20110;&#36890;&#36807;&#20048;&#35266;&#24615;&#21644;&#36866;&#24212;&#24615;&#21152;&#36895;&#30340;&#20849;&#21516;&#29702;&#35770;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We work towards a unifying paradigm for accelerating policy optimization methods in reinforcement learning (RL) through \emph{optimism} \&amp; \emph{adaptivity}. Leveraging the deep connection between policy iteration and policy gradient methods, we recast seemingly unrelated policy optimization algorithms as the repeated application of two interleaving steps (i) an \emph{optimistic policy improvement operator} maps a prior policy $\pi_t$ to a hypothesis $\pi_{t+1}$ using a \emph{gradient ascent prediction}, followed by (ii) a \emph{hindsight adaptation} of the optimistic prediction based on a partial evaluation of the performance of $\pi_{t+1}$. We use this shared lens to jointly express other well-known algorithms, including soft and optimistic policy iteration, natural actor-critic methods, model-based policy improvement based on forward search, and meta-learning algorithms. By doing so, we shed light on collective theoretical properties related to acceleration via optimism \&amp; adaptivit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.07056</link><description>&lt;p&gt;
&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#29992;&#20110;&#31163;&#32676;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Kernel Random Projection Depth for Outlier Detection. (arXiv:2306.07056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#26680;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;&#38543;&#26426;&#25237;&#24433;&#28145;&#24230;&#65288;RPD&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#25968;&#25454;&#20113;&#20013;&#30340;&#22810;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26694;&#26550;&#20013;&#65292;RPD&#22312;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#35745;&#31639;&#12290;&#20511;&#21161;&#20869;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65292;&#25105;&#20204;&#26399;&#26395;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#19978;&#36848;&#22810;&#31181;&#27169;&#24335;&#21644;&#38750;&#20984;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;RPD&#65292;&#24182;&#21487;&#19982;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#29616;&#26377;&#30340;&#26816;&#27979;&#27169;&#22411;&#30456;&#23218;&#32654;&#65292;&#20851;&#20110;&#25509;&#25910;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#65288;ROC&#65289;&#19979;&#30340;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes an extension of Random Projection Depth (RPD) to cope with multiple modalities and non-convexity on data clouds. In the framework of the proposed method, the RPD is computed in a reproducing kernel Hilbert space. With the help of kernel principal component analysis, we expect that the proposed method can cope with the above multiple modalities and non-convexity. The experimental results demonstrate that the proposed method outperforms RPD and is comparable to other existing detection models on benchmark datasets regarding Area Under the Curves (AUCs) of Receiver Operating Characteristic (ROC).
&lt;/p&gt;</description></item><item><title>&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21033;&#29992;&#31561;&#21387;&#31561;&#28201;&#27969;&#24471;&#21040;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#65292;&#24182;&#22312;&#21333;&#21407;&#23376;&#27700;&#30340;&#32467;&#26230;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.13233</link><description>&lt;p&gt;
&#36890;&#36807;&#31561;&#21387;&#31561;&#28201;&#27969;&#33719;&#24471;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;
&lt;/p&gt;
&lt;p&gt;
Gibbs free energies via isobaric-isothermal flows. (arXiv:2305.13233v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13233
&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21033;&#29992;&#31561;&#21387;&#31561;&#28201;&#27969;&#24471;&#21040;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#65292;&#24182;&#22312;&#21333;&#21407;&#23376;&#27700;&#30340;&#32467;&#26230;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#34920;&#29616;&#20986;&#20248;&#31168;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#32463;&#36807;&#35757;&#32451;&#21487;&#20174;&#31561;&#21387;&#31561;&#28201;&#65288;NPT&#65289;&#38598;&#21512;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#22312;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#36817;&#20284;&#26041;&#27861;&#26469;&#24471;&#21040;&#23436;&#20840;&#28789;&#27963;&#30340;&#19977;&#26012;&#26230;&#31995;&#32479;&#30340;&#32852;&#21512;&#20998;&#24067;&#21644;&#31890;&#23376;&#22352;&#26631;&#20197;&#36798;&#21040;&#25152;&#38656;&#30340;&#20869;&#37096;&#21387;&#21147;&#12290;&#25105;&#20204;&#23545;&#21333;&#21407;&#23376;&#27700;&#22312;&#31435;&#26041;&#21644;&#20845;&#35282;&#20912;&#30456;&#20013;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#21457;&#29616;&#19982;&#24050;&#24314;&#31435;&#30340;&#22522;&#32447;&#30456;&#27604;&#65292;&#21513;&#24067;&#26031;&#33258;&#30001;&#33021;&#21644;&#20854;&#20182;&#21487;&#35266;&#27979;&#37327;&#30340;&#32467;&#26524;&#23436;&#20840;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a machine-learning model based on normalizing flows that is trained to sample from the isobaric-isothermal (NPT) ensemble. In our approach, we approximate the joint distribution of a fully-flexible triclinic simulation box and particle coordinates to achieve a desired internal pressure. We test our model on monatomic water in the cubic and hexagonal ice phases and find excellent agreement of Gibbs free energies and other observables compared with established baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#20808;&#39564;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#23558;&#31038;&#21306;&#24314;&#27169;&#20026;&#30001;&#33410;&#28857;&#23646;&#24615;&#20915;&#23450;&#12290;&#22522;&#20110;&#32622;&#20449;&#20256;&#36882;&#21644;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#30340;&#32467;&#21512;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#31038;&#20132;&#32593;&#32476;&#12289;&#22270;&#20687;&#20998;&#21106;&#65292;&#29983;&#29289;&#29289;&#31181;&#31561;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2303.09995</link><description>&lt;p&gt;
&#31070;&#32463;&#20808;&#39564;&#38543;&#26426;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural-prior stochastic block model. (arXiv:2303.09995v1 [cond-mat.dis-nn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09995
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#31070;&#32463;&#20808;&#39564;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#23558;&#31038;&#21306;&#24314;&#27169;&#20026;&#30001;&#33410;&#28857;&#23646;&#24615;&#20915;&#23450;&#12290;&#22522;&#20110;&#32622;&#20449;&#20256;&#36882;&#21644;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#30340;&#32467;&#21512;&#65292;&#21487;&#20197;&#22312;&#22788;&#29702;&#31038;&#20132;&#32593;&#32476;&#12289;&#22270;&#20687;&#20998;&#21106;&#65292;&#29983;&#29289;&#29289;&#31181;&#31561;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#34987;&#24191;&#27867;&#30740;&#31350;&#20316;&#20026;&#22270;&#32858;&#31867;&#25110;&#31038;&#21306;&#26816;&#27979;&#30340;&#22522;&#20934;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#22270;&#25968;&#25454;&#36890;&#24120;&#24102;&#26377;&#33410;&#28857;&#23646;&#24615;&#65292;&#36825;&#20123;&#23646;&#24615;&#25215;&#36733;&#26377;&#20851;&#31038;&#21306;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#36890;&#36807;&#32771;&#34385;&#33410;&#28857;&#23646;&#24615;&#26159;&#30001;&#33410;&#28857;&#31038;&#21306;&#25104;&#21592;&#36523;&#20221;&#29983;&#25104;&#30340;&#26469;&#23545;&#36825;&#20123;&#25968;&#25454;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#21463;&#21040;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20808;&#39564;&#30340;&#20449;&#21495;&#22788;&#29702;&#39046;&#22495;&#20013;&#19968;&#31995;&#21015;&#30740;&#31350;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#31038;&#21306;&#24314;&#27169;&#20026;&#30001;&#33410;&#28857;&#23646;&#24615;&#20915;&#23450;&#32780;&#19981;&#26159;&#30456;&#21453;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#30456;&#24212;&#30340;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#31216;&#20026;&#31070;&#32463;&#20808;&#39564;SBM&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#26469;&#33258;&#20110;&#32479;&#35745;&#29289;&#29702;&#23398;&#65292;&#22522;&#20110;&#32622;&#20449;&#20256;&#36882;&#21644;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#30340;&#32467;&#21512;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#20197;&#21450;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#33021;&#12290;&#25105;&#20204;&#35782;&#21035;&#20102;&#21487;&#26816;&#27979;&#21644;&#31934;&#30830;&#24674;&#22797;&#30456;&#21464;&#65292;&#20197;&#21450;&#19968;&#31181;&#31639;&#27861;&#38590;&#21306;&#22495;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#21644;&#31639;&#27861;&#21487;&#20197;&#22312;&#22788;&#29702;&#35832;&#22914;&#31038;&#20132;&#32593;&#32476;&#12289;&#22270;&#20687;&#20998;&#21106;&#65292;&#29983;&#29289;&#29289;&#31181;&#31561;&#26041;&#38754;&#21457;&#25381;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic block model (SBM) is widely studied as a benchmark for graph clustering aka community detection. In practice, graph data often come with node attributes that bear additional information about the communities. Previous works modeled such data by considering that the node attributes are generated from the node community memberships. In this work, motivated by a recent surge of works in signal processing using deep neural networks as priors, we propose to model the communities as being determined by the node attributes rather than the opposite. We define the corresponding model; we call it the neural-prior SBM. We propose an algorithm, stemming from statistical physics, based on a combination of belief propagation and approximate message passing. We analyze the performance of the algorithm as well as the Bayes-optimal performance. We identify detectability and exact recovery phase transitions, as well as an algorithmically hard region. The proposed model and algorithm can b
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#25299;&#25169;&#23398;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#30721;&#31070;&#32463;&#31361;&#35302;&#36755;&#20986;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#34920;&#31034;&#22823;&#33041;&#20013;&#30340;&#31070;&#32463;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2212.05037</link><description>&lt;p&gt;
&#22522;&#20110;&#25299;&#25169;&#23398;&#30340;&#31070;&#32463;&#31361;&#35302;&#35299;&#30721;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Topological Deep Learning Framework for Neural Spike Decoding. (arXiv:2212.05037v2 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05037
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#25299;&#25169;&#23398;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#30721;&#31070;&#32463;&#31361;&#35302;&#36755;&#20986;&#65292;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#21644;&#34920;&#31034;&#22823;&#33041;&#20013;&#30340;&#31070;&#32463;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#33041;&#30340;&#31354;&#38388;&#23450;&#20301;&#31995;&#32479;&#20351;&#29992;&#19981;&#21516;&#30340;&#31070;&#32463;&#20803;&#38598;&#21512;&#26469;&#36741;&#21161;&#22522;&#20110;&#29615;&#22659;&#30340;&#23548;&#33322;&#12290;&#22823;&#33041;&#36890;&#36807;&#22836;&#26041;&#21521;&#32454;&#32990;&#21644;&#32593;&#26684;&#32454;&#32990;&#20004;&#31181;&#26041;&#24335;&#32534;&#30721;&#31354;&#38388;&#20449;&#24687;&#12290;&#22836;&#26041;&#21521;&#32454;&#32990;&#29992;&#20110;&#30830;&#23450;&#26041;&#21521;&#65292;&#32780;&#32593;&#26684;&#32454;&#32990;&#30001;&#21472;&#21152;&#30340;&#31070;&#32463;&#20803;&#23618;&#32452;&#25104;&#65292;&#25552;&#20379;&#22522;&#20110;&#29615;&#22659;&#30340;&#23548;&#33322;&#12290;&#36825;&#20123;&#31070;&#32463;&#20803;&#20197;&#38598;&#21512;&#30340;&#24418;&#24335;&#21457;&#25918;&#20449;&#21495;&#65292;&#22810;&#20010;&#31070;&#32463;&#20803;&#21516;&#26102;&#21457;&#25918;&#20449;&#21495;&#20197;&#28608;&#27963;&#21333;&#20010;&#22836;&#26041;&#21521;&#25110;&#32593;&#26684;&#12290;&#25105;&#20204;&#24076;&#26395;&#25429;&#25417;&#36825;&#31181;&#21457;&#25918;&#32467;&#26500;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#30721;&#22836;&#26041;&#21521;&#21644;&#32593;&#26684;&#32454;&#32990;&#25968;&#25454;&#12290;&#29702;&#35299;&#12289;&#34920;&#31034;&#21644;&#35299;&#30721;&#36825;&#20123;&#31070;&#32463;&#32467;&#26500;&#38656;&#35201;&#21253;&#21547;&#39640;&#38454;&#36830;&#25509;&#24615;&#30340;&#27169;&#22411;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#20256;&#32479;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#25552;&#20379;&#30340;&#19968;&#32500;&#36830;&#25509;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#25299;&#25169;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#26469;&#35299;&#30721;&#31070;&#32463;&#31361;&#35302;&#36755;&#20986;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#32467;&#21512;&#20102;&#26080;&#30417;&#30563;&#30340;&#31616;&#21333;&#22797;&#21512;&#20307;&#21457;&#29616;&#21644;&#28145;&#24230;&#23398;&#20064;&#30340;&#24378;&#22823;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The brain's spatial orientation system uses different neuron ensembles to aid in environment-based navigation. Two of the ways brains encode spatial information is through head direction cells and grid cells. Brains use head direction cells to determine orientation whereas grid cells consist of layers of decked neurons that overlay to provide environment-based navigation. These neurons fire in ensembles where several neurons fire at once to activate a single head direction or grid. We want to capture this firing structure and use it to decode head direction grid cell data. Understanding, representing, and decoding these neural structures requires models that encompass higher order connectivity, more than the 1-dimensional connectivity that traditional graph-based models provide. To that end, in this work, we develop a topological deep learning framework for neural spike train decoding. Our framework combines unsupervised simplicial complex discovery with the power of deep learning via 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20010;&#24615;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#32593;&#32476;&#26435;&#37325;&#24314;&#27169;&#20026;&#20302;&#31209;&#21644;&#31232;&#30095;&#20998;&#37327;&#30340;&#24635;&#21644;&#65292;&#26082;&#25429;&#25417;&#20102;&#22810;&#20010;&#29992;&#25143;&#38388;&#30340;&#20849;&#21516;&#20449;&#24687;&#65292;&#21448;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#20010;&#24615;&#21270;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2210.03505</link><description>&lt;p&gt;
&#39640;&#25928;&#20010;&#24615;&#21270;&#65306;&#23558;&#29992;&#25143;&#21442;&#25968;&#24314;&#27169;&#20026;&#20302;&#31209;&#21152;&#31232;&#30095;&#20998;&#37327;
&lt;/p&gt;
&lt;p&gt;
Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components. (arXiv:2210.03505v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.03505
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20010;&#24615;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#32593;&#32476;&#26435;&#37325;&#24314;&#27169;&#20026;&#20302;&#31209;&#21644;&#31232;&#30095;&#20998;&#37327;&#30340;&#24635;&#21644;&#65292;&#26082;&#25429;&#25417;&#20102;&#22810;&#20010;&#29992;&#25143;&#38388;&#30340;&#20849;&#21516;&#20449;&#24687;&#65292;&#21448;&#33021;&#22815;&#25429;&#25417;&#29992;&#25143;&#20010;&#24615;&#21270;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#23545;&#20010;&#20307;&#29992;&#25143;/&#22495;/&#20225;&#19994;&#30340;&#39044;&#27979;&#33267;&#20851;&#37325;&#35201;&#65292;&#26631;&#20934;&#30340;&#20010;&#24615;&#21270;&#26041;&#27861;&#28041;&#21450;&#23398;&#20064;&#19968;&#20010;&#29992;&#25143;/&#22495;&#29305;&#23450;&#30340;&#23884;&#20837;&#65292;&#28982;&#21518;&#23558;&#20854;&#39304;&#20837;&#19968;&#20010;&#22266;&#23450;&#30340;&#20840;&#23616;&#27169;&#22411;&#65292;&#36825;&#31181;&#26041;&#27861;&#23384;&#22312;&#38480;&#21046;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20026;&#27599;&#20010;&#29992;&#25143;/&#22495;&#33258;&#36523;&#20010;&#24615;&#21270;/&#24494;&#35843;&#27169;&#22411;&#26412;&#36523;&#65292;&#21363;&#20803;&#23398;&#20064;&#65292;&#20855;&#26377;&#39640;&#23384;&#20648;/&#22522;&#30784;&#26550;&#26500;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#23545;&#21487;&#25193;&#23637;&#20010;&#24615;&#21270;&#26041;&#27861;&#30340;&#20005;&#26684;&#29702;&#35770;&#30740;&#31350;&#38750;&#24120;&#26377;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#23398;&#20064;&#39118;&#26684;&#30340;&#26041;&#27861;&#65292;&#23558;&#32593;&#32476;&#26435;&#37325;&#24314;&#27169;&#20026;&#20302;&#31209;&#21644;&#31232;&#30095;&#20998;&#37327;&#30340;&#24635;&#21644;&#12290;&#36825;&#22312;&#20302;&#31209;&#37096;&#20998;&#25429;&#25417;&#20102;&#22810;&#20010;&#20010;&#20307;/&#29992;&#25143;&#30340;&#20849;&#21516;&#20449;&#24687;&#65292;&#32780;&#31232;&#30095;&#37096;&#20998;&#21017;&#25429;&#25417;&#20102;&#29992;&#25143;&#29305;&#23450;&#30340;&#29305;&#24615;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#32447;&#24615;&#35774;&#32622;&#20013;&#30740;&#31350;&#20102;&#35813;&#26694;&#26550;&#65292;&#20854;&#20013;&#38382;&#39064;&#31616;&#21270;&#20026;&#20351;&#29992;&#31616;&#21333;&#30340;&#26041;&#27861;&#20272;&#35745;&#31209;&#20026;$r$&#21644;$k$&#21015;&#30340;&#31232;&#30095;&#30697;&#38453;&#30340;&#24635;&#21644;
&lt;/p&gt;
&lt;p&gt;
Personalization of machine learning (ML) predictions for individual users/domains/enterprises is critical for practical recommendation systems. Standard personalization approaches involve learning a user/domain specific embedding that is fed into a fixed global model which can be limiting. On the other hand, personalizing/fine-tuning model itself for each user/domain -a.k.a meta-learning -- has high storage/infrastructure cost. Moreover, rigorous theoretical studies of scalable personalization approaches have been very limited. To address the above issues, we propose a novel meta-learning style approach that models network weights as a sum of low-rank and sparse components. This captures common information from multiple individuals/users together in the low-rank part while sparse part captures user-specific idiosyncrasies. We then study the framework in the linear setting, where the problem reduces to that of estimating the sum of a rank-$r$ and a $k$-column sparse matrix using a sma
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32467;&#21512;&#33021;&#37327;&#30340;&#27010;&#24565;&#65292;&#35777;&#26126;&#20102;&#24102;&#23545;&#31216;&#28388;&#27874;&#22120;&#30340;&#32447;&#24615;&#22270;&#21367;&#31215;&#21487;&#20197;&#22686;&#24378;&#39640;&#39057;&#29575;&#65292;&#20351;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21516;&#36136;&#21644;&#24322;&#36136;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2206.10991</link><description>&lt;p&gt;
&#36890;&#36807;&#22270;&#19978;&#30340;&#33021;&#37327;&#29702;&#35299;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Understanding convolution on graphs via energies. (arXiv:2206.10991v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10991
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32467;&#21512;&#33021;&#37327;&#30340;&#27010;&#24565;&#65292;&#35777;&#26126;&#20102;&#24102;&#23545;&#31216;&#28388;&#27874;&#22120;&#30340;&#32447;&#24615;&#22270;&#21367;&#31215;&#21487;&#20197;&#22686;&#24378;&#39640;&#39057;&#29575;&#65292;&#20351;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21516;&#36136;&#21644;&#24322;&#36136;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36890;&#24120;&#36890;&#36807;&#28040;&#24687;&#20256;&#36882;&#25805;&#20316;&#65292;&#20854;&#20013;&#33410;&#28857;&#30340;&#29366;&#24577;&#26159;&#22522;&#20110;&#20854;&#37051;&#23621;&#25910;&#21040;&#30340;&#20449;&#24687;&#36827;&#34892;&#26356;&#26032;&#30340;&#12290;&#22823;&#22810;&#25968;&#28040;&#24687;&#20256;&#36882;&#27169;&#22411;&#37117;&#26159;&#20316;&#20026;&#22270;&#21367;&#31215;&#36827;&#34892;&#25805;&#20316;&#30340;&#65292;&#20854;&#20013;&#29305;&#24449;&#22312;&#34987;&#20256;&#25773;&#21040;&#36793;&#32536;&#20043;&#21069;&#36890;&#36807;&#20849;&#20139;&#30340;&#32447;&#24615;&#21464;&#25442;&#28151;&#21512;&#12290;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#22270;&#21367;&#31215;&#24050;&#32463;&#34920;&#29616;&#20986;&#20004;&#20010;&#38480;&#21046;&#65306;&#22312;heterophilic&#22270;&#19978;&#34920;&#29616;&#27424;&#20339;&#65292;&#24182;&#19988;&#36807;&#24230;&#24179;&#28369;&#12290;&#24120;&#35265;&#30340;&#30475;&#27861;&#26159;&#65292;&#36825;&#20004;&#31181;&#29616;&#35937;&#30340;&#21457;&#29983;&#26159;&#22240;&#20026;&#36825;&#31181;&#27169;&#22411;&#34920;&#29616;&#20026;&#20302;&#36890;&#28388;&#27874;&#22120;&#65292;&#24847;&#21619;&#30528;&#22312;&#22270;&#23618;&#38388;&#29305;&#24449;&#30340;Dirichlet&#33021;&#37327;&#20250;&#20943;&#23569;&#65292;&#23548;&#33268;&#24179;&#28369;&#25928;&#24212;&#65292;&#26368;&#32456;&#29305;&#24449;&#19981;&#20877;&#21487;&#21306;&#20998;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20005;&#35880;&#22320;&#35777;&#26126;&#20102;&#31616;&#21333;&#30340;&#22270;&#21367;&#31215;&#27169;&#22411;&#23454;&#38469;&#19978;&#21487;&#20197;&#22686;&#24378;&#39640;&#39057;&#29575;&#29978;&#33267;&#24341;&#23548;&#19968;&#31181;&#25105;&#20204;&#25152;&#31216;&#30340;&#36807;&#24230;&#38160;&#21270;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#19982;&#36807;&#24230;&#24179;&#28369;&#30456;&#21453;&#12290;&#25105;&#20204;&#36890;&#36807;&#34920;&#26126;&#23545;&#31216;&#28388;&#27874;&#22120;&#30340;&#32447;&#24615;&#22270;&#21367;&#31215;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#22312;&#22270;&#24418;&#19978;&#30340;&#33021;&#37327;&#26368;&#23567;&#21270;&#38382;&#39064;&#26469;&#20570;&#21040;&#36825;&#19968;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#33021;&#37327;&#20989;&#25968;&#24809;&#32602;&#39640;&#33021;&#20449;&#21495;&#65292;&#26377;&#25928;&#22320;&#25233;&#21046;&#20302;&#39057;&#65292;&#21516;&#26102;&#20419;&#36827;&#30456;&#20851;&#30340;&#39640;&#39057;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31934;&#24515;&#35774;&#35745;&#30340;&#22270;&#21367;&#31215;&#27169;&#22411;&#21487;&#20197;&#22312;&#21516;&#36136;&#21644;&#24322;&#36136;&#20219;&#21153;&#19978;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) typically operate by message-passing, where the state of a node is updated based on the information received from its neighbours. Most message-passing models act as graph convolutions, where features are mixed by a shared, linear transformation before being propagated over the edges. On node-classification tasks, graph convolutions have been shown to suffer from two limitations: poor performance on heterophilic graphs, and over-smoothing. It is common belief that both phenomena occur because such models behave as low-pass filters, meaning that the Dirichlet energy of the features decreases along the layers incurring a smoothing effect that ultimately makes features no longer distinguishable. In this work, we rigorously prove that simple graph-convolutional models can actually enhance high frequencies and even lead to an asymptotic behaviour we refer to as over-sharpening, opposite to over-smoothing. We do so by showing that linear graph convolutions with sy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#24378;&#24378;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;&#30340;&#38382;&#39064;&#65292;&#22312;&#20989;&#25968;&#21442;&#25968;&#31354;&#38388;&#20013;&#20351;&#29992;&#21160;&#24577;&#30340;Wasserstein&#36317;&#31163;&#21644;&#21518;&#39564;&#20998;&#24067;&#30340;&#23616;&#37096;Lipschitz&#36830;&#32493;&#24615;&#65292;&#24314;&#31435;&#20102;PCR&#19982;&#25968;&#23398;&#20998;&#26512;&#12289;&#27010;&#29575;&#35770;&#21644;&#32479;&#35745;&#23398;&#20013;&#19968;&#20123;&#32463;&#20856;&#38382;&#39064;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2203.10754</link><description>&lt;p&gt;
&#24378;&#24378;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;&#30340;Wasserstein&#21160;&#21147;&#23398;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Strong posterior contraction rates via Wasserstein dynamics. (arXiv:2203.10754v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.10754
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#24378;&#24378;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;&#30340;&#38382;&#39064;&#65292;&#22312;&#20989;&#25968;&#21442;&#25968;&#31354;&#38388;&#20013;&#20351;&#29992;&#21160;&#24577;&#30340;Wasserstein&#36317;&#31163;&#21644;&#21518;&#39564;&#20998;&#24067;&#30340;&#23616;&#37096;Lipschitz&#36830;&#32493;&#24615;&#65292;&#24314;&#31435;&#20102;PCR&#19982;&#25968;&#23398;&#20998;&#26512;&#12289;&#27010;&#29575;&#35770;&#21644;&#32479;&#35745;&#23398;&#20013;&#19968;&#20123;&#32463;&#20856;&#38382;&#39064;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#20013;&#65292;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;&#65288;PCR&#65289;&#20197;&#36866;&#24403;&#30340;&#26041;&#24335;&#37327;&#21270;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#30495;&#23454;&#27169;&#22411;&#30340;&#20219;&#24847;&#23567;&#37051;&#22495;&#20013;&#30340;&#36895;&#24230;&#65292;&#24403;&#26679;&#26412;&#37327;&#36235;&#20110;&#26080;&#31351;&#26102;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;PCR&#26041;&#27861;&#65292;&#20854;&#22522;&#20110;&#20989;&#25968;&#21442;&#25968;&#31354;&#38388;&#30340;&#24378;&#33539;&#25968;&#36317;&#31163;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20851;&#38190;&#26159;&#23558;&#21518;&#39564;&#20998;&#24067;&#30340;&#23616;&#37096;Lipschitz&#36830;&#32493;&#24615;&#19982;Wasserstein&#36317;&#31163;&#30340;&#21160;&#24577;&#24418;&#24335;&#30456;&#32467;&#21512;&#65292;&#36825;&#20351;&#24471;PCR&#19982;&#25968;&#23398;&#20998;&#26512;&#12289;&#27010;&#29575;&#35770;&#21644;&#32479;&#35745;&#23398;&#20013;&#19968;&#20123;&#32463;&#20856;&#38382;&#39064;&#20135;&#29983;&#20102;&#26377;&#36259;&#30340;&#32852;&#31995;&#65292;&#20363;&#22914;Laplace&#26041;&#27861;&#26469;&#36817;&#20284;&#31215;&#20998;&#65292;Wasserstein&#36317;&#31163;&#19979;&#30340;Sanov&#22823;&#20559;&#24046;&#21407;&#29702;&#65292;&#22343;&#20540;Glivenko-Cantelli&#23450;&#29702;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#20197;&#21450;&#21152;&#26435;Poincar&#233;-Wirtinger&#24120;&#25968;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;&#20851;&#20110;&#19968;&#20010;&#27491;&#21017;&#26080;&#38480;&#32500;&#25351;&#25968;&#27169;&#22411;&#30340;PCR&#30340;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
In Bayesian statistics, posterior contraction rates (PCRs) quantify the speed at which the posterior distribution concentrates on arbitrarily small neighborhoods of a true model, in a suitable way, as the sample size goes to infinity. In this paper, we develop a new approach to PCRs, with respect to strong norm distances on parameter spaces of functions. Critical to our approach is the combination of a local Lipschitz-continuity for the posterior distribution with a dynamic formulation of the Wasserstein distance, which allows to set forth an interesting connection between PCRs and some classical problems arising in mathematical analysis, probability and statistics, e.g., Laplace methods for approximating integrals, Sanov's large deviation principles in the Wasserstein distance, rates of convergence of mean Glivenko-Cantelli theorems, and estimates of weighted Poincar\'e-Wirtinger constants. We first present a theorem on PCRs for a model in the regular infinite-dimensional exponential 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#38169;&#35823;&#32553;&#25918;&#23450;&#24459;&#65292;&#38024;&#23545;&#28385;&#36275;&#28304;&#26465;&#20214;&#21644;&#23481;&#37327;&#26465;&#20214;&#30340;&#25968;&#25454;&#38598;&#31867;&#21035;&#65292;&#22312;&#39640;&#26031;&#35774;&#35745;&#19979;&#23548;&#20986;&#20102;&#35823;&#24046;&#34928;&#20943;&#29575;&#19982;&#28304;&#21644;&#23481;&#37327;&#31995;&#25968;&#30340;&#20851;&#31995;&#65292;&#24182;&#23545;&#27604;&#20102;&#26368;&#22823;&#21270;&#38388;&#38548;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#23725;&#20998;&#31867;&#20004;&#31181;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2201.12655</link><description>&lt;p&gt;
&#26680;&#20998;&#31867;&#38382;&#39064;&#19979;&#30340;&#38169;&#35823;&#32553;&#25918;&#23450;&#24459;&#65306;&#28304;&#26465;&#20214;&#21644;&#23481;&#37327;&#26465;&#20214;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Error Scaling Laws for Kernel Classification under Source and Capacity Conditions. (arXiv:2201.12655v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.12655
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#20998;&#31867;&#38382;&#39064;&#20013;&#30340;&#38169;&#35823;&#32553;&#25918;&#23450;&#24459;&#65292;&#38024;&#23545;&#28385;&#36275;&#28304;&#26465;&#20214;&#21644;&#23481;&#37327;&#26465;&#20214;&#30340;&#25968;&#25454;&#38598;&#31867;&#21035;&#65292;&#22312;&#39640;&#26031;&#35774;&#35745;&#19979;&#23548;&#20986;&#20102;&#35823;&#24046;&#34928;&#20943;&#29575;&#19982;&#28304;&#21644;&#23481;&#37327;&#31995;&#25968;&#30340;&#20851;&#31995;&#65292;&#24182;&#23545;&#27604;&#20102;&#26368;&#22823;&#21270;&#38388;&#38548;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#23725;&#20998;&#31867;&#20004;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#26680;&#20998;&#31867;&#38382;&#39064;&#12290;&#23613;&#31649;&#26576;&#20123;&#20998;&#31867;&#22120;&#30340;&#26368;&#22351;&#24773;&#20917;&#19979;&#26679;&#26412;&#25968;&#37327;&#19982;&#39044;&#27979;&#38169;&#35823;&#30340;&#34928;&#20943;&#29575;&#30340;&#36793;&#30028;&#24050;&#30693;&#65292;&#20294;&#23427;&#20204;&#32463;&#24120;&#19981;&#33021;&#20934;&#30830;&#25551;&#36848;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#26354;&#32447;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#28385;&#36275;&#26631;&#20934;&#28304;&#26465;&#20214;&#21644;&#23481;&#37327;&#26465;&#20214;&#30340;&#37325;&#35201;&#25968;&#25454;&#38598;&#31867;&#21035;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20123;&#23454;&#38469;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#20998;&#26512;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#22312;&#39640;&#26031;&#35774;&#35745;&#19979;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#38169;&#35823;&#20998;&#31867;&#65288;&#39044;&#27979;&#65289;&#35823;&#24046;&#30340;&#34928;&#20943;&#29575;&#20316;&#20026;&#28304;&#21644;&#23481;&#37327;&#31995;&#25968;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#38024;&#23545;&#20004;&#31181;&#26631;&#20934;&#30340;&#26680;&#20998;&#31867;&#35774;&#32622;&#65288;&#21363;&#26368;&#22823;&#21270;&#38388;&#38548;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#23725;&#20998;&#31867;&#65289;&#36827;&#34892;&#20102;&#36825;&#26679;&#30340;&#25512;&#23548;&#65292;&#24182;&#23545;&#27604;&#20102;&#20004;&#31181;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#34928;&#20943;&#29575;&#32039;&#23494;&#22320;&#25551;&#36848;&#20102;&#36825;&#31867;&#25968;&#25454;&#38598;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#24182;&#19988;&#20063;&#22312;&#23454;&#38469;&#25968;&#25454;&#19978;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#26680;&#20998;&#31867;&#30340;&#32553;&#25918;&#23450;&#24459;&#25351;&#25968;&#30340;&#26174;&#24335;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of kernel classification. While worst-case bounds on the decay rate of the prediction error with the number of samples are known for some classifiers, they often fail to accurately describe the learning curves of real data sets. In this work, we consider the important class of data sets satisfying the standard source and capacity conditions, comprising a number of real data sets as we show numerically. Under the Gaussian design, we derive the decay rates for the misclassification (prediction) error as a function of the source and capacity coefficients. We do so for two standard kernel classification settings, namely margin-maximizing Support Vector Machines (SVM) and ridge classification, and contrast the two methods. We find that our rates tightly describe the learning curves for this class of data sets, and are also observed on real data. Our results can also be seen as an explicit prediction of the exponents of a scaling law for kernel classification that is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#34892;&#20026;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#26469;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#35299;&#37322;&#21333;&#20803;&#26356;&#21152;&#21487;&#35299;&#37322;&#19988;&#32771;&#34385;&#20102;&#23439;&#35266;&#32423;&#29305;&#24449;&#21644;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#12290;</title><link>http://arxiv.org/abs/2006.02482</link><description>&lt;p&gt;
&#29992;&#22240;&#26524;&#23398;&#20064;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#30340;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Explaining the Behavior of Black-Box Prediction Algorithms with Causal Learning. (arXiv:2006.02482v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.02482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#31639;&#27861;&#34892;&#20026;&#30340;&#22240;&#26524;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#26469;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#24357;&#34917;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#32570;&#28857;&#65292;&#21363;&#35299;&#37322;&#21333;&#20803;&#26356;&#21152;&#21487;&#35299;&#37322;&#19988;&#32771;&#34385;&#20102;&#23439;&#35266;&#32423;&#29305;&#24449;&#21644;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#23398;&#26041;&#27861;&#22312;&#35299;&#37322;&#40657;&#31665;&#39044;&#27979;&#27169;&#22411;&#65288;&#20363;&#22914;&#22522;&#20110;&#22270;&#20687;&#20687;&#32032;&#25968;&#25454;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#37325;&#35201;&#32570;&#28857;&#65306;&#65288;i&#65289;&#8220;&#35299;&#37322;&#21333;&#20803;&#8221;&#26159;&#30456;&#20851;&#39044;&#27979;&#27169;&#22411;&#30340;&#24494;&#35266;&#32423;&#36755;&#20837;&#65292;&#20363;&#22914;&#22270;&#20687;&#20687;&#32032;&#65292;&#32780;&#19981;&#26159;&#26356;&#26377;&#29992;&#20110;&#29702;&#35299;&#22914;&#20309;&#21487;&#33021;&#25913;&#21464;&#31639;&#27861;&#34892;&#20026;&#30340;&#21487;&#35299;&#37322;&#30340;&#23439;&#35266;&#32423;&#29305;&#24449;&#65307;&#65288;ii&#65289;&#29616;&#26377;&#26041;&#27861;&#20551;&#35774;&#29305;&#24449;&#19982;&#30446;&#26631;&#27169;&#22411;&#39044;&#27979;&#20043;&#38388;&#19981;&#23384;&#22312;&#26410;&#27979;&#37327;&#30340;&#28151;&#28102;&#65292;&#36825;&#22312;&#35299;&#37322;&#21333;&#20803;&#26159;&#23439;&#35266;&#32423;&#21464;&#37327;&#26102;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#22312;&#20998;&#26512;&#20154;&#21592;&#26080;&#27861;&#35775;&#38382;&#30446;&#26631;&#39044;&#27979;&#31639;&#27861;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#30340;&#37325;&#35201;&#24773;&#20917;&#65292;&#32780;&#21482;&#33021;&#26681;&#25454;&#29305;&#23450;&#36755;&#20837;&#26597;&#35810;&#27169;&#22411;&#36755;&#20986;&#30340;&#33021;&#21147;&#12290;&#20026;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20379;&#22240;&#26524;&#35299;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#23398;&#20064;&#22240;&#26524;&#22270;&#34920;&#31034;&#65292;&#20801;&#35768;&#26356;&#22909;&#22320;&#29702;&#35299;&#31639;&#27861;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal approaches to post-hoc explainability for black-box prediction models (e.g., deep neural networks trained on image pixel data) have become increasingly popular. However, existing approaches have two important shortcomings: (i) the "explanatory units" are micro-level inputs into the relevant prediction model, e.g., image pixels, rather than interpretable macro-level features that are more useful for understanding how to possibly change the algorithm's behavior, and (ii) existing approaches assume there exists no unmeasured confounding between features and target model predictions, which fails to hold when the explanatory units are macro-level variables. Our focus is on the important setting where the analyst has no access to the inner workings of the target prediction algorithm, rather only the ability to query the output of the model in response to a particular input. To provide causal explanations in such a setting, we propose to learn causal graphical representations that allo
&lt;/p&gt;</description></item></channel></rss>