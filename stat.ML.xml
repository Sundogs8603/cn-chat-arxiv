<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;P2MPO&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#21644;&#21452;&#37325;&#24754;&#35266;&#30340;&#31574;&#30053;&#20248;&#21270;&#27493;&#39588;&#65292;&#37319;&#29992;&#21452;&#37325;&#24754;&#35266;&#24615;&#21407;&#21017;&#20197;&#20811;&#26381;&#27169;&#22411;&#20559;&#31227;&#31561;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#20551;&#35774;&#19979;&#65292;&#35813;&#26694;&#26550;&#22312;&#25317;&#26377;&#33391;&#22909;&#30340;&#40065;&#26834;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26159;&#20855;&#22791;&#39640;&#25928;&#24615;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.09659</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#40065;&#26834;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65306;&#22522;&#20110;&#21452;&#37325;&#24754;&#35266;&#24615;&#30340;&#36890;&#29992;&#31639;&#27861;&#21644;&#24378;&#20581;&#37096;&#20998;&#35206;&#30422;
&lt;/p&gt;
&lt;p&gt;
Double Pessimism is Provably Efficient for Distributionally Robust Offline Reinforcement Learning: Generic Algorithm and Robust Partial Coverage. (arXiv:2305.09659v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;P2MPO&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#40065;&#26834;&#31163;&#32447;RL&#30340;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#21644;&#21452;&#37325;&#24754;&#35266;&#30340;&#31574;&#30053;&#20248;&#21270;&#27493;&#39588;&#65292;&#37319;&#29992;&#21452;&#37325;&#24754;&#35266;&#24615;&#21407;&#21017;&#20197;&#20811;&#26381;&#27169;&#22411;&#20559;&#31227;&#31561;&#38382;&#39064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#20934;&#30830;&#24615;&#30340;&#20551;&#35774;&#19979;&#65292;&#35813;&#26694;&#26550;&#22312;&#25317;&#26377;&#33391;&#22909;&#30340;&#40065;&#26834;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26159;&#20855;&#22791;&#39640;&#25928;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#40065;&#26834;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;&#40065;&#26834;&#31163;&#32447;RL&#65289;&#65292;&#20854;&#26088;&#22312;&#20174;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#32431;&#31929;&#22320;&#25214;&#21040;&#19968;&#20010;&#33021;&#22815;&#22312;&#25200;&#21160;&#29615;&#22659;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#26368;&#20248;&#24378;&#40065;&#26834;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;P2MPO&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#28789;&#27963;&#30340;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#21644;&#21452;&#37325;&#24754;&#35266;&#30340;&#31574;&#30053;&#20248;&#21270;&#27493;&#39588;&#12290;&#21452;&#37325;&#24754;&#35266;&#24615;&#21407;&#21017;&#23545;&#20110;&#20811;&#26381;&#30001;&#34892;&#20026;&#31574;&#30053;&#21644;&#30446;&#26631;&#31574;&#30053;&#23478;&#26063;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#20197;&#21450;&#21517;&#20041;&#27169;&#22411;&#30340;&#25200;&#21160;&#25152;&#24341;&#36215;&#30340;&#20998;&#24067;&#20559;&#31227;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#23545;&#27169;&#22411;&#20272;&#35745;&#23376;&#20363;&#31243;&#36827;&#34892;&#19968;&#23450;&#20934;&#30830;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;P2MPO&#31639;&#27861;&#22312;&#25317;&#26377;&#33391;&#22909;&#30340;&#40065;&#26834;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#26159;&#21487;&#35777;&#26126;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributionally robust offline reinforcement learning (robust offline RL), which seeks to find an optimal robust policy purely from an offline dataset that can perform well in perturbed environments. We propose a generic algorithm framework \underline{D}oubly \underline{P}essimistic \underline{M}odel-based \underline{P}olicy \underline{O}ptimization ($\texttt{P}^2\texttt{MPO}$) for robust offline RL, which features a novel combination of a flexible model estimation subroutine and a doubly pessimistic policy optimization step. The \emph{double pessimism} principle is crucial to overcome the distributional shift incurred by i) the mismatch between behavior policy and the family of target policies; and ii) the perturbation of the nominal model. Under certain accuracy assumptions on the model estimation subroutine, we show that $\texttt{P}^2\texttt{MPO}$ is provably efficient with \emph{robust partial coverage data}, which means that the offline dataset has good coverage of the d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#20998;&#38454;&#27573;&#21457;&#24067;&#31574;&#30053;&#65292;&#33021;&#22815;&#22312;&#25511;&#21046;&#39118;&#38505;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#21551;&#21160;&#36895;&#24230;&#65292;&#36890;&#36807;&#19968;&#20010;&#21463;&#32422;&#26463;&#30340;&#20998;&#25209;&#36172;&#21338;&#26426;&#38382;&#39064;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.09626</link><description>&lt;p&gt;
&#24179;&#34913;&#39118;&#38505;&#19982;&#25910;&#30410;&#65306;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#20998;&#38454;&#27573;&#21457;&#24067;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Balancing Risk and Reward: An Automated Phased Release Strategy. (arXiv:2305.09626v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#30340;&#20998;&#38454;&#27573;&#21457;&#24067;&#31574;&#30053;&#65292;&#33021;&#22815;&#22312;&#25511;&#21046;&#39118;&#38505;&#30340;&#21516;&#26102;&#26368;&#22823;&#21270;&#21551;&#21160;&#36895;&#24230;&#65292;&#36890;&#36807;&#19968;&#20010;&#21463;&#32422;&#26463;&#30340;&#20998;&#25209;&#36172;&#21338;&#26426;&#38382;&#39064;&#27169;&#22411;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#38454;&#27573;&#21457;&#24067;&#26159;&#31185;&#25216;&#34892;&#19994;&#20013;&#36880;&#27493;&#21457;&#24067;&#26032;&#20135;&#21697;&#25110;&#26356;&#26032;&#30340;&#24120;&#35265;&#31574;&#30053;&#65292;&#36890;&#36807;&#19968;&#31995;&#21015;A/B&#27979;&#35797;&#65292;&#36880;&#27493;&#22686;&#21152;&#22788;&#29702;&#21333;&#20803;&#30340;&#25968;&#37327;&#65292;&#30452;&#21040;&#23436;&#20840;&#37096;&#32626;&#25110;&#24223;&#24323;&#12290;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#25191;&#34892;&#20998;&#38454;&#27573;&#21457;&#24067;&#38656;&#35201;&#20197;&#24179;&#34913;&#19981;&#33391;&#24433;&#21709;&#30340;&#39118;&#38505;&#21644;&#36845;&#20195;&#21644;&#24555;&#36895;&#23398;&#20064;&#30340;&#38656;&#27714;&#26469;&#36873;&#25321;&#20998;&#37197;&#32473;&#26032;&#21457;&#24067;&#30340;&#21333;&#20301;&#27604;&#20363;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27491;&#24335;&#22320;&#38416;&#36848;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#22312;&#35843;&#24230;&#30340;&#27599;&#20010;&#38454;&#27573;&#33258;&#21160;&#30830;&#23450;&#21457;&#24067;&#30334;&#20998;&#27604;&#65292;&#24179;&#34913;&#25511;&#21046;&#39118;&#38505;&#21644;&#26368;&#22823;&#21270;&#21551;&#21160;&#36895;&#24230;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#36825;&#19968;&#25361;&#25112;&#24314;&#27169;&#20026;&#19968;&#20010;&#21463;&#32422;&#26463;&#30340;&#20998;&#25209;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#20197;&#30830;&#20445;&#25105;&#20204;&#39044;&#20808;&#25351;&#23450;&#30340;&#23454;&#39564;&#39044;&#31639;&#19981;&#20250;&#34987;&#39640;&#27010;&#29575;&#32791;&#23613;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21033;&#29992;&#20102;&#33258;&#36866;&#24212;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#20854;&#20013;&#23558;&#20998;&#37197;&#32473;&#22788;&#29702;&#30340;&#26368;&#22823;&#21333;&#20803;&#25968;&#30001;
&lt;/p&gt;
&lt;p&gt;
Phased releases are a common strategy in the technology industry for gradually releasing new products or updates through a sequence of A/B tests in which the number of treated units gradually grows until full deployment or deprecation. Performing phased releases in a principled way requires selecting the proportion of units assigned to the new release in a way that balances the risk of an adverse effect with the need to iterate and learn from the experiment rapidly. In this paper, we formalize this problem and propose an algorithm that automatically determines the release percentage at each stage in the schedule, balancing the need to control risk while maximizing ramp-up speed. Our framework models the challenge as a constrained batched bandit problem that ensures that our pre-specified experimental budget is not depleted with high probability. Our proposed algorithm leverages an adaptive Bayesian approach in which the maximal number of units assigned to the treatment is determined by
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20272;&#35745;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#21644;&#25191;&#34892;&#31867;&#20284;&#20110;$\mathtt{iLQR}$&#30340;&#31574;&#30053;&#26356;&#26032;&#20043;&#38388;&#30340;&#36845;&#20195;&#26469;&#23454;&#29616;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#24182;&#20811;&#26381;&#20102;&#25351;&#25968;&#21306;&#38388;&#19978;&#30340;&#20381;&#36182;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.09619</link><description>&lt;p&gt;
&#23398;&#20064;&#30340;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#22312;&#38750;&#32447;&#24615;&#31574;&#30053;&#20248;&#21270;&#20013;&#30340;&#23041;&#21147;
&lt;/p&gt;
&lt;p&gt;
The Power of Learned Locally Linear Models for Nonlinear Policy Optimization. (arXiv:2305.09619v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23398;&#20064;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20272;&#35745;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#21644;&#25191;&#34892;&#31867;&#20284;&#20110;$\mathtt{iLQR}$&#30340;&#31574;&#30053;&#26356;&#26032;&#20043;&#38388;&#30340;&#36845;&#20195;&#26469;&#23454;&#29616;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#24182;&#20811;&#26381;&#20102;&#25351;&#25968;&#21306;&#38388;&#19978;&#30340;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#23398;&#20064;&#30340;&#25511;&#21046;&#20013;&#65292;&#24120;&#35265;&#30340;&#27969;&#31243;&#26159;&#36880;&#27493;&#20272;&#35745;&#31995;&#32479;&#21160;&#21147;&#23398;&#27169;&#22411;&#65292;&#24182;&#24212;&#29992;&#36712;&#36857;&#20248;&#21270;&#31639;&#27861;&#65288;&#20363;&#22914;$\mathtt{iLQR}$&#65289;&#22312;&#23398;&#20064;&#30340;&#27169;&#22411;&#19978;&#36827;&#34892;&#20248;&#21270;&#65292;&#20197;&#26368;&#23567;&#21270;&#30446;&#26631;&#25104;&#26412;&#12290;&#26412;&#25991;&#23545;&#19968;&#31181;&#31616;&#21270;&#29256;&#30340;&#27492;&#31574;&#30053;&#24212;&#29992;&#20110;&#19968;&#33324;&#38750;&#32447;&#24615;&#31995;&#32479;&#30340;&#24773;&#20917;&#36827;&#34892;&#20102;&#20005;&#26684;&#20998;&#26512;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20272;&#35745;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#21644;&#25191;&#34892;&#31867;&#20284;&#20110;$\mathtt{iLQR}$&#30340;&#31574;&#30053;&#26356;&#26032;&#20043;&#38388;&#36827;&#34892;&#36845;&#20195;&#12290;&#25105;&#20204;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#30456;&#20851;&#38382;&#39064;&#21442;&#25968;&#20013;&#36798;&#21040;&#20102;&#22810;&#39033;&#24335;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#23616;&#37096;&#31283;&#23450;&#22686;&#30410;&#65292;&#20811;&#26381;&#20102;&#22312;&#38382;&#39064;&#21306;&#38388;&#19978;&#30340;&#25351;&#25968;&#20381;&#36182;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#19982;&#33258;&#28982;&#30340;&#28145;&#24230;&#23398;&#20064;&#22522;&#32447;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common pipeline in learning-based control is to iteratively estimate a model of system dynamics, and apply a trajectory optimization algorithm e.g.~$\mathtt{iLQR}$ - on the learned model to minimize a target cost. This paper conducts a rigorous analysis of a simplified variant of this strategy for general nonlinear systems. We analyze an algorithm which iterates between estimating local linear models of nonlinear system dynamics and performing $\mathtt{iLQR}$-like policy updates. We demonstrate that this algorithm attains sample complexity polynomial in relevant problem parameters, and, by synthesizing locally stabilizing gains, overcomes exponential dependence in problem horizon. Experimental results validate the performance of our algorithm, and compare to natural deep-learning baselines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26041;&#38754;&#36827;&#34892;&#20102;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#23558;&#24050;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.09605</link><description>&lt;p&gt;
&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#30340;&#34920;&#36798;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Expressiveness Remarks for Denoising Diffusion Models and Samplers. (arXiv:2305.09605v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26041;&#38754;&#36827;&#34892;&#20102;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#23558;&#24050;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#26368;&#36817;&#24050;&#32463;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#36890;&#36807;&#28459;&#25193;&#36807;&#31243;&#36880;&#28176;&#21521;&#25968;&#25454;&#20013;&#28155;&#21152;&#22122;&#22768;&#65292;&#23558;&#25968;&#25454;&#20998;&#24067;&#36716;&#21270;&#20026;&#39640;&#26031;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#27169;&#25311;&#35813;&#28459;&#25193;&#30340;&#26102;&#38388;&#21453;&#28436;&#30340;&#36924;&#36817;&#26469;&#33719;&#21462;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#65292;&#21018;&#24320;&#22987;&#36825;&#20010;&#28459;&#25193;&#27169;&#25311;&#30340;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#26679;&#26412;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#23558;&#28459;&#25193;&#27169;&#22411;&#36866;&#24212;&#20110;&#37319;&#26679;&#21644;&#25512;&#26029;&#20219;&#21153;&#12290;&#26412;&#25991;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#19982;F\"ollmer&#28418;&#31227;&#31867;&#20284;&#30340;&#38543;&#26426;&#25511;&#21046;&#32852;&#31995;&#65292;&#23558;&#38024;&#23545;F\"ollmer&#28418;&#31227;&#30340;&#24050;&#30693;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#32467;&#26524;&#25193;&#23637;&#21040;&#28459;&#25193;&#25193;&#25955;&#27169;&#22411;&#21644;&#37319;&#26679;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Denoising diffusion models are a class of generative models which have recently achieved state-of-the-art results across many domains. Gradual noise is added to the data using a diffusion process, which transforms the data distribution into a Gaussian. Samples from the generative model are then obtained by simulating an approximation of the time reversal of this diffusion initialized by Gaussian samples. Recent research has explored adapting diffusion models for sampling and inference tasks. In this paper, we leverage known connections to stochastic control akin to the F\"ollmer drift to extend established neural network approximation results for the F\"ollmer drift to denoising diffusion models and samplers.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#22522;&#32447;&#30340;&#26032;&#22411;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22240;&#26524;&#22270;&#30340;&#27491;&#30830;&#24615;&#24182;&#25351;&#23548;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.09565</link><description>&lt;p&gt;
&#22522;&#20110;&#32622;&#25442;&#26816;&#39564;&#30340;&#22240;&#26524;&#22270;&#20551;&#35774;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Toward Falsifying Causal Graphs Using a Permutation-Based Test. (arXiv:2305.09565v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#22522;&#32447;&#30340;&#26032;&#22411;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#39564;&#35777;&#22240;&#26524;&#22270;&#30340;&#27491;&#30830;&#24615;&#24182;&#25351;&#23548;&#20854;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31995;&#32479;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#20110;&#35299;&#37322;&#21644;&#25511;&#21046;&#20854;&#34892;&#20026;&#33267;&#20851;&#37325;&#35201;&#12290;&#20294;&#26159;&#65292;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#22270;&#38656;&#35201;&#24456;&#22810;&#19981;&#24635;&#26159;&#29616;&#23454;&#30340;&#24378;&#20551;&#35774;&#12290;&#23545;&#20110;&#39046;&#22495;&#19987;&#23478;&#26469;&#35828;&#65292;&#24456;&#38590;&#34920;&#36798;&#22240;&#26524;&#22270;&#12290;&#22240;&#27492;&#65292;&#22312;&#23558;&#22240;&#26524;&#22270;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#20043;&#21069;&#65292;&#23450;&#37327;&#35780;&#20272;&#22240;&#26524;&#22270;&#30340;&#20248;&#21155;&#30340;&#24230;&#37327;&#25552;&#20379;&#20102;&#26377;&#29992;&#30340;&#26816;&#26597;&#12290;&#29616;&#26377;&#30340;&#24230;&#37327;&#25552;&#20379;&#20102;&#19968;&#20010;&#32477;&#23545;&#25968;&#37327;&#30340;&#22240;&#26524;&#22270;&#19982;&#35266;&#23519;&#25968;&#25454;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#32780;&#27809;&#26377;&#22522;&#30784;&#32447;&#65292;&#20174;&#19994;&#20154;&#21592;&#38656;&#35201;&#22238;&#31572;&#26377;&#22810;&#23569;&#36825;&#26679;&#30340;&#19981;&#19968;&#33268;&#24615;&#26159;&#21487;&#25509;&#21463;&#25110;&#39044;&#26399;&#30340;&#36825;&#19968;&#38590;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33268;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#33410;&#28857;&#32622;&#25442;&#30340;&#26367;&#20195;&#22522;&#32447;&#12290;&#36890;&#36807;&#23558;&#19981;&#19968;&#33268;&#24615;&#30340;&#25968;&#37327;&#19982;&#26367;&#20195;&#22522;&#32447;&#19978;&#30340;&#25968;&#37327;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#35299;&#37322;&#30340;&#24230;&#37327;&#65292;&#25429;&#25417;&#26377;&#21521;&#26080;&#29615;&#22270;&#26159;&#21542;&#26174;&#33879;&#36866;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the causal relationships among the variables of a system is paramount to explain and control its behaviour. Inferring the causal graph from observational data without interventions, however, requires a lot of strong assumptions that are not always realistic. Even for domain experts it can be challenging to express the causal graph. Therefore, metrics that quantitatively assess the goodness of a causal graph provide helpful checks before using it in downstream tasks. Existing metrics provide an absolute number of inconsistencies between the graph and the observed data, and without a baseline, practitioners are left to answer the hard question of how many such inconsistencies are acceptable or expected. Here, we propose a novel consistency metric by constructing a surrogate baseline through node permutations. By comparing the number of inconsistencies with those on the surrogate baseline, we derive an interpretable metric that captures whether the DAG fits significantly bet
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#33258;&#28982;&#30340;&#32858;&#21512;&#26041;&#27861;&#65306;&#22522;&#20110;&#20849;&#21516;&#29305;&#24449;&#23558;&#25968;&#25454;&#28857;&#20998;&#32452;&#30340;&#31934;&#36873;&#21253;&#21644;&#23558;&#25968;&#25454;&#28857;&#38543;&#26426;&#20998;&#32452;&#30340;&#38543;&#26426;&#21253;&#65292;&#23545;&#20110;&#31934;&#36873;&#21253;&#35774;&#32622;&#21644;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32780;&#19981;&#20250;&#23548;&#33268;&#25968;&#25454;&#32858;&#21512;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.09557</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;&#23398;&#20064;&#65306;&#31934;&#36873;&#21253;&#19982;&#38543;&#26426;&#21253;&#30340;&#23545;&#27604;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Learning from Aggregated Data: Curated Bags versus Random Bags. (arXiv:2305.09557v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#33258;&#28982;&#30340;&#32858;&#21512;&#26041;&#27861;&#65306;&#22522;&#20110;&#20849;&#21516;&#29305;&#24449;&#23558;&#25968;&#25454;&#28857;&#20998;&#32452;&#30340;&#31934;&#36873;&#21253;&#21644;&#23558;&#25968;&#25454;&#28857;&#38543;&#26426;&#20998;&#32452;&#30340;&#38543;&#26426;&#21253;&#65292;&#23545;&#20110;&#31934;&#36873;&#21253;&#35774;&#32622;&#21644;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32780;&#19981;&#20250;&#23548;&#33268;&#25968;&#25454;&#32858;&#21512;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#26159;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#37096;&#32626;&#30340;&#19968;&#20010;&#20027;&#35201;&#20851;&#27880;&#28857;&#65292;&#36825;&#20123;&#31995;&#32479;&#25910;&#38598;&#26469;&#33258;&#21508;&#31181;&#32676;&#20307;&#30340;&#25968;&#25454;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#31181;&#38382;&#39064;&#65292;&#19968;&#31181;&#26041;&#27861;&#26159;&#20197;&#32858;&#21512;&#30340;&#24418;&#24335;&#25910;&#38598;&#21644;&#21457;&#24067;&#25968;&#25454;&#26631;&#31614;&#65292;&#20174;&#32780;&#21487;&#20197;&#23558;&#21333;&#20010;&#29992;&#25143;&#30340;&#20449;&#24687;&#19982;&#20854;&#20182;&#29992;&#25143;&#30340;&#20449;&#24687;&#32452;&#21512;&#36215;&#26469;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#32858;&#21512;&#25968;&#25454;&#26631;&#31614;&#32780;&#38750;&#21333;&#20010;&#26631;&#31614;&#26469;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#33021;&#24615;&#65292;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#33258;&#28982;&#30340;&#32858;&#21512;&#26041;&#27861;&#65306;&#22522;&#20110;&#20849;&#21516;&#29305;&#24449;&#23558;&#25968;&#25454;&#28857;&#20998;&#32452;&#30340;&#31934;&#36873;&#21253;&#21644;&#23558;&#25968;&#25454;&#28857;&#38543;&#26426;&#20998;&#32452;&#30340;&#38543;&#26426;&#21253;&#12290;&#23545;&#20110;&#31934;&#36873;&#21253;&#35774;&#32622;&#21644;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32780;&#19981;&#20250;&#23548;&#33268;&#25968;&#25454;&#32858;&#21512;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20197;&#19979;&#35266;&#23519;&#65306;&#25439;&#22833;&#20989;&#25968;&#30340;&#26799;&#24230;&#20043;&#21644;&#21487;&#20197;&#34920;&#31034;&#20026;&#27599;&#20010;&#21253;&#30340;&#26799;&#24230;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#20013;&#26435;&#37325;&#26159;&#21253;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Protecting user privacy is a major concern for many machine learning systems that are deployed at scale and collect from a diverse set of population. One way to address this concern is by collecting and releasing data labels in an aggregated manner so that the information about a single user is potentially combined with others. In this paper, we explore the possibility of training machine learning models with aggregated data labels, rather than individual labels. Specifically, we consider two natural aggregation procedures suggested by practitioners: curated bags where the data points are grouped based on common features and random bags where the data points are grouped randomly in bag of similar sizes. For the curated bag setting and for a broad range of loss functions, we show that we can perform gradient-based learning without any degradation in performance that may result from aggregating data. Our method is based on the observation that the sum of the gradients of the loss functio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#26465;&#20214;Shapley&#20540;&#30340;&#26041;&#27861;&#21644;&#24212;&#29992;&#22330;&#26223;&#65292;&#25552;&#20986;&#20102;&#26032;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#36825;&#20123;&#26041;&#27861;&#20998;&#31867;&#65292;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#21508;&#31867;&#26041;&#27861;&#30340;&#31934;&#24230;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.09536</link><description>&lt;p&gt;
&#20272;&#35745;&#26465;&#20214;Shapley&#20540;&#30340;&#26041;&#27861;&#27604;&#36739;&#21450;&#20854;&#24212;&#29992;&#22330;&#26223;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A Comparative Study of Methods for Estimating Conditional Shapley Values and When to Use Them. (arXiv:2305.09536v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09536
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20272;&#35745;&#26465;&#20214;Shapley&#20540;&#30340;&#26041;&#27861;&#21644;&#24212;&#29992;&#22330;&#26223;&#65292;&#25552;&#20986;&#20102;&#26032;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#36825;&#20123;&#26041;&#27861;&#20998;&#31867;&#65292;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#21508;&#31867;&#26041;&#27861;&#30340;&#31934;&#24230;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#26368;&#26089;&#36215;&#28304;&#20110;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#65292;&#20294;&#29616;&#22312;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#27169;&#22411;&#26080;&#20851;&#35299;&#37322;&#26694;&#26550;&#20013;&#65292;&#29992;&#26469;&#35299;&#37322;&#22797;&#26434;&#27169;&#22411;&#25152;&#20570;&#30340;&#39044;&#27979;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#39044;&#27979;&#27169;&#22411;&#30340;&#26465;&#20214;Shapley&#20540;&#30340;&#35745;&#31639;&#65292;&#25506;&#35752;&#20102;&#19981;&#21516;&#30340;&#31639;&#27861;&#36884;&#24452;&#19982;&#24212;&#29992;&#22330;&#26223;&#65292;&#36825;&#20123;&#35745;&#31639;&#38656;&#35201;&#20272;&#35745;&#22797;&#26434;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;&#25991;&#31456;&#25552;&#20986;&#20102;&#26032;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#20043;&#21069;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#36825;&#20123;&#26041;&#27861;&#20998;&#31867;&#12289;&#27604;&#36739;&#21644;&#35780;&#20272;&#12290;&#20998;&#31867;&#26041;&#24335;&#37319;&#29992;&#33945;&#29305;&#21345;&#32599;&#31215;&#20998;&#25110;&#22238;&#24402;&#23545;&#26465;&#20214;&#26399;&#26395;&#36827;&#34892;&#24314;&#27169;&#12290;&#20316;&#32773;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#26469;&#34913;&#37327;&#19981;&#21516;&#26041;&#27861;&#20998;&#31867;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#30340;&#31934;&#24230;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley values originated in cooperative game theory but are extensively used today as a model-agnostic explanation framework to explain predictions made by complex machine learning models in the industry and academia. There are several algorithmic approaches for computing different versions of Shapley value explanations. Here, we focus on conditional Shapley values for predictive models fitted to tabular data. Estimating precise conditional Shapley values is difficult as they require the estimation of non-trivial conditional expectations. In this article, we develop new methods, extend earlier proposed approaches, and systematize the new refined and existing methods into different method classes for comparison and evaluation. The method classes use either Monte Carlo integration or regression to model the conditional expectations. We conduct extensive simulation studies to evaluate how precisely the different method classes estimate the conditional expectations, and thereby the condit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#21270;&#20026;&#21487;&#35299;&#37322;&#30340;&#27010;&#29575;&#20272;&#35745;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#19982;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#36317;&#31163;&#24314;&#27169;&#36317;&#31163;&#27010;&#29575;&#20998;&#24067;&#65292;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#25442;&#20026;&#24322;&#24120;&#27010;&#29575;&#65292;&#25552;&#39640;&#20102;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#23545;&#27604;&#24230;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#26816;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.09446</link><description>&lt;p&gt;
&#27010;&#29575;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Distance-Based Outlier Detection. (arXiv:2305.09446v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09446
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#21270;&#20026;&#21487;&#35299;&#37322;&#30340;&#27010;&#29575;&#20272;&#35745;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#19982;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#36317;&#31163;&#24314;&#27169;&#36317;&#31163;&#27010;&#29575;&#20998;&#24067;&#65292;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#25442;&#20026;&#24322;&#24120;&#27010;&#29575;&#65292;&#25552;&#39640;&#20102;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#23545;&#27604;&#24230;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#26816;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#30340;&#20998;&#25968;&#38590;&#20197;&#35299;&#37322;&#65292;&#22240;&#27492;&#22312;&#27809;&#26377;&#39069;&#22806;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#65292;&#24456;&#38590;&#30830;&#23450;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#25130;&#26029;&#38408;&#20540;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#21270;&#20026;&#21487;&#35299;&#37322;&#30340;&#27010;&#29575;&#20272;&#35745;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#35813;&#36716;&#25442;&#26159;&#25490;&#21517;&#31283;&#23450;&#30340;&#65292;&#24182;&#22686;&#21152;&#20102;&#27491;&#24120;&#28857;&#21644;&#24322;&#24120;&#28857;&#20043;&#38388;&#30340;&#23545;&#27604;&#24230;&#12290;&#30830;&#23450;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#36317;&#31163;&#20851;&#31995;&#26159;&#35782;&#21035;&#25968;&#25454;&#20013;&#26368;&#36817;&#37051;&#20851;&#31995;&#25152;&#24517;&#38656;&#30340;&#65292;&#28982;&#32780;&#22823;&#22810;&#25968;&#35745;&#31639;&#20986;&#30340;&#36317;&#31163;&#36890;&#24120;&#34987;&#20002;&#24323;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#19982;&#20854;&#20182;&#25968;&#25454;&#28857;&#30340;&#36317;&#31163;&#26469;&#24314;&#27169;&#36317;&#31163;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#38543;&#21518;&#20351;&#29992;&#36825;&#20123;&#20998;&#24067;&#23558;&#36317;&#31163;&#27861;&#24322;&#24120;&#26816;&#27979;&#20998;&#25968;&#36716;&#25442;&#20026;&#24322;&#24120;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#27010;&#29575;&#36716;&#25442;&#19981;&#20250;&#24433;&#21709;&#20247;&#22810;&#34920;&#26684;&#21644;&#22270;&#20687;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#26816;&#27979;&#24615;&#33021;&#65292;&#20294;&#20250;&#20135;&#29983;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The scores of distance-based outlier detection methods are difficult to interpret, making it challenging to determine a cut-off threshold between normal and outlier data points without additional context. We describe a generic transformation of distance-based outlier scores into interpretable, probabilistic estimates. The transformation is ranking-stable and increases the contrast between normal and outlier data points. Determining distance relationships between data points is necessary to identify the nearest-neighbor relationships in the data, yet, most of the computed distances are typically discarded. We show that the distances to other data points can be used to model distance probability distributions and, subsequently, use the distributions to turn distance-based outlier scores into outlier probabilities. Our experiments show that the probabilistic transformation does not impact detection performance over numerous tabular and image benchmark datasets but results in interpretable
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#23616;&#37096;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#19968;&#33268;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#24369;&#30340;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#20174;&#20840;&#23616;SVM&#32487;&#25215;&#20102;$L_p$&#21644;&#39118;&#38505;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#24213;&#23618;&#21306;&#22495;&#38543;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.09385</link><description>&lt;p&gt;
&#23616;&#37096;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;$L_p$&#21644;&#39118;&#38505;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Lp- and Risk Consistency of Localized SVMs. (arXiv:2305.09385v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09385
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#23616;&#37096;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#19968;&#33268;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#24369;&#30340;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#20174;&#20840;&#23616;SVM&#32487;&#25215;&#20102;$L_p$&#21644;&#39118;&#38505;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#24213;&#23618;&#21306;&#22495;&#38543;&#25968;&#25454;&#38598;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#27491;&#21017;&#21270;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#65292;&#21448;&#31216;&#20026;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#65292;&#24050;&#30693;&#20855;&#26377;&#35768;&#22810;&#29702;&#24819;&#30340;&#23646;&#24615;&#65292;&#20294;&#22312;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#26102;&#20855;&#26377;&#36229;&#32447;&#24615;&#30340;&#35745;&#31639;&#38656;&#27714;&#12290;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#23616;&#37096;SVM&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#31181;&#26041;&#27861;&#36824;&#25552;&#20379;&#20102;&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#36755;&#20837;&#31354;&#38388;&#21306;&#22495;&#24212;&#29992;&#19981;&#21516;&#36229;&#21442;&#25968;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#23616;&#37096;SVM&#30340;&#19968;&#33268;&#24615;&#12290;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#38750;&#24120;&#24369;&#30340;&#24773;&#20917;&#19979;&#20174;&#20840;&#23616;SVM&#32487;&#25215;&#20102;$L_p$-&#20197;&#21450;&#39118;&#38505;-&#19968;&#33268;&#24615;&#65292;&#29978;&#33267;&#21487;&#20197;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#22823;&#23567;&#22686;&#21152;&#26102;&#65292;&#20801;&#35768;&#24213;&#23618;&#30340;&#21306;&#22495;&#21457;&#29983;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel-based regularized risk minimizers, also called support vector machines (SVMs), are known to possess many desirable properties but suffer from their super-linear computational requirements when dealing with large data sets. This problem can be tackled by using localized SVMs instead, which also offer the additional advantage of being able to apply different hyperparameters to different regions of the input space. In this paper, localized SVMs are analyzed with regards to their consistency. It is proven that they inherit $L_p$- as well as risk consistency from global SVMs under very weak conditions and even if the regions underlying the localized SVMs are allowed to change as the size of the training data set increases.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#31209;&#21327;&#21464;&#37327;&#36924;&#36817;&#30340;&#35823;&#24046;&#21464;&#37327;Frechet&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#23454;&#29616;&#22312;&#39640;&#32500;&#24230;&#21644;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#35774;&#32622;&#20013;&#26356;&#21152;&#26377;&#25928;&#30340;&#24314;&#27169;&#21644;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2305.09282</link><description>&lt;p&gt;
&#20302;&#31209;&#21327;&#21464;&#37327;&#36924;&#36817;&#30340;&#35823;&#24046;&#21464;&#37327;Frechet&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Errors-in-variables Fr\'echet Regression with Low-rank Covariate Approximation. (arXiv:2305.09282v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09282
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#31209;&#21327;&#21464;&#37327;&#36924;&#36817;&#30340;&#35823;&#24046;&#21464;&#37327;Frechet&#22238;&#24402;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#25552;&#39640;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#23454;&#29616;&#22312;&#39640;&#32500;&#24230;&#21644;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#35774;&#32622;&#20013;&#26356;&#21152;&#26377;&#25928;&#30340;&#24314;&#27169;&#21644;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Frechet&#22238;&#24402;&#24050;&#25104;&#20026;&#22788;&#29702;&#38750;&#27431;&#20960;&#37324;&#24471;&#21709;&#24212;&#21464;&#37327;&#30340;&#22238;&#24402;&#20998;&#26512;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20381;&#36182;&#20110;&#29702;&#24819;&#24773;&#20917;&#19979;&#20016;&#23500;&#21644;&#26080;&#22122;&#22768;&#30340;&#21327;&#21464;&#37327;&#25968;&#25454;&#65292;&#22240;&#27492;&#20854;&#23454;&#38469;&#24212;&#29992;&#21463;&#21040;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21327;&#21464;&#37327;&#30697;&#38453;&#20013;&#22266;&#26377;&#30340;&#20302;&#31209;&#32467;&#26500;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#26694;&#26550;&#32467;&#21512;&#20102;&#20840;&#23616;Frechet&#22238;&#24402;&#21644;&#20027;&#25104;&#20998;&#22238;&#24402;&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#25552;&#39640;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#32435;&#20837;&#20302;&#31209;&#32467;&#26500;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#22312;&#39640;&#32500;&#24230;&#21644;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#35774;&#32622;&#20013;&#26356;&#21152;&#26377;&#25928;&#30340;&#24314;&#27169;&#21644;&#20272;&#35745;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#23545;&#25552;&#35758;&#30340;&#20272;&#35745;&#22120;&#30340;&#22823;&#26679;&#26412;&#24615;&#36136;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#21253;&#25324;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#30001;&#20110;&#27979;&#37327;&#35823;&#24046;&#24341;&#36215;&#30340;&#20854;&#20182;&#21464;&#21270;&#30340;&#20840;&#38754;&#29575;&#20998;&#26512;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fr\'echet regression has emerged as a promising approach for regression analysis involving non-Euclidean response variables. However, its practical applicability has been hindered by its reliance on ideal scenarios with abundant and noiseless covariate data. In this paper, we present a novel estimation method that tackles these limitations by leveraging the low-rank structure inherent in the covariate matrix. Our proposed framework combines the concepts of global Fr\'echet regression and principal component regression, aiming to improve the efficiency and accuracy of the regression estimator. By incorporating the low-rank structure, our method enables more effective modeling and estimation, particularly in high-dimensional and errors-in-variables regression settings. We provide a theoretical analysis of the proposed estimator's large-sample properties, including a comprehensive rate analysis of bias, variance, and additional variations due to measurement errors. Furthermore, our numeri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\ell_1$-TCL&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30693;&#35782;&#36801;&#31227;&#21644;Lasso&#22238;&#24402;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.09126</link><description>&lt;p&gt;
&#30693;&#35782;&#36801;&#31227;&#19979;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;: &#36716;&#31227;&#22240;&#26524;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Causal Learning: Causal Effect Estimation with Knowledge Transfer. (arXiv:2305.09126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\ell_1$-TCL&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30693;&#35782;&#36801;&#31227;&#21644;Lasso&#22238;&#24402;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#21363;&#22312;&#30456;&#21516;&#30340;&#21327;&#21464;&#37327;&#65288;&#25110;&#29305;&#24449;&#65289;&#31354;&#38388;&#35774;&#32622;&#19979;&#36890;&#36807;&#30693;&#35782;&#36801;&#31227;&#26469;&#25552;&#39640;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#31934;&#24230;&#65292;&#21363;&#21516;&#31867;&#21035;&#36801;&#31227;&#23398;&#20064;&#65288;TL&#65289;&#65292;&#23558;&#20854;&#31216;&#20026;&#36716;&#31227;&#22240;&#26524;&#23398;&#20064;&#65288;TCL&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;$\ell_1$-TCL&#65292;&#20854;&#20013;&#21253;&#21547;$\ell_1$&#27491;&#21017;&#21270;TL&#26469;&#36827;&#34892;&#33510;&#20107;&#21442;&#25968;&#20272;&#35745;&#21644;&#19979;&#28216;&#25554;&#20214;ACE&#20272;&#35745;&#22120;&#65292;&#21253;&#25324;&#32467;&#26524;&#22238;&#24402;&#12289;&#36870;&#27010;&#29575;&#21152;&#26435;&#21644;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#20511;&#21161;&#20110;Lasso&#29992;&#20110;&#39640;&#32500;&#22238;&#24402;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#38750;&#28176;&#36817;&#24674;&#22797;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
A novel problem of improving causal effect estimation accuracy with the help of knowledge transfer under the same covariate (or feature) space setting, i.e., homogeneous transfer learning (TL), is studied, referred to as the Transfer Causal Learning (TCL) problem. While most recent efforts in adapting TL techniques to estimate average causal effect (ACE) have been focused on the heterogeneous covariate space setting, those methods are inadequate for tackling the TCL problem since their algorithm designs are based on the decomposition into shared and domain-specific covariate spaces. To address this issue, we propose a generic framework called \texttt{$\ell_1$-TCL}, which incorporates $\ell_1$ regularized TL for nuisance parameter estimation and downstream plug-in ACE estimators, including outcome regression, inverse probability weighted, and doubly robust estimators. Most importantly, with the help of Lasso for high-dimensional regression, we establish non-asymptotic recovery guarantee
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;Hessian&#26144;&#23556;&#65292;&#25581;&#31034;&#20102;CNN&#32467;&#26500;&#21644;&#24615;&#36136;&#30340;&#26412;&#36136;&#65292;&#24182;&#35777;&#26126;&#20102;Hessian&#31209;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#38271;&#32780;&#21576;&#29616;&#20986;&#24179;&#26041;&#26681;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2305.09088</link><description>&lt;p&gt;
&#22522;&#20110;Hessian&#26144;&#23556;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#26412;&#36136;&#30340;&#26032;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
The Hessian perspective into the Nature of Convolutional Neural Networks. (arXiv:2305.09088v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;Hessian&#26144;&#23556;&#65292;&#25581;&#31034;&#20102;CNN&#32467;&#26500;&#21644;&#24615;&#36136;&#30340;&#26412;&#36136;&#65292;&#24182;&#35777;&#26126;&#20102;Hessian&#31209;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#38271;&#32780;&#21576;&#29616;&#20986;&#24179;&#26041;&#26681;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#19968;&#30452;&#34987;&#30740;&#31350;&#12289;&#24212;&#29992;&#21644;&#29702;&#35770;&#21270;&#65292;&#25105;&#20204;&#30340;&#30446;&#30340;&#26159;&#20174;&#23427;&#20204;&#30340;Hessian&#26144;&#23556;&#30340;&#35282;&#24230;&#25552;&#20379;&#19968;&#20010;&#31245;&#24494;&#19981;&#21516;&#30340;&#35266;&#28857;&#65292;&#22240;&#20026;&#25439;&#22833;&#30340;Hessian&#25429;&#25417;&#20102;&#21442;&#25968;&#30340;&#25104;&#23545;&#20132;&#20114;&#65292;&#22240;&#27492;&#24418;&#25104;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#22522;&#30784;&#26469;&#25506;&#32034;CNN&#30340;&#26550;&#26500;&#26041;&#38754;&#22914;&#20309;&#34920;&#29616;&#20986;&#23427;&#30340;&#32467;&#26500;&#21644;&#24615;&#36136;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20381;&#36182;&#20110;CNN&#30340;Toeplitz&#34920;&#31034;&#30340;&#26694;&#26550;&#65292;&#24182;&#21033;&#29992;&#23427;&#26469;&#25581;&#31034;Hessian&#32467;&#26500;&#65292;&#29305;&#21035;&#26159;&#23427;&#30340;&#31209;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#32039;&#23494;&#30340;&#19978;&#30028;&#65288;&#20351;&#29992;&#32447;&#24615;&#28608;&#27963;&#65289;&#65292;&#23427;&#20204;&#32039;&#23494;&#22320;&#36981;&#24490;&#20102;Hessian&#31209;&#30340;&#32463;&#39564;&#36235;&#21183;&#65292;&#24182;&#22312;&#26356;&#19968;&#33324;&#30340;&#35774;&#32622;&#20013;&#20445;&#25345;&#22312;&#23454;&#36341;&#20013;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#27010;&#25324;&#21644;&#30830;&#35748;&#20102;&#19968;&#20010;&#20851;&#38190;&#30340;&#27934;&#35265;&#65292;&#21363;&#21363;&#20351;&#22312;CNNs&#20013;&#65292;Hessian&#31209;&#38543;&#30528;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#38271;&#32780;&#21576;&#29616;&#20986;&#24179;&#26041;&#26681;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
While Convolutional Neural Networks (CNNs) have long been investigated and applied, as well as theorized, we aim to provide a slightly different perspective into their nature -- through the perspective of their Hessian maps. The reason is that the loss Hessian captures the pairwise interaction of parameters and therefore forms a natural ground to probe how the architectural aspects of CNN get manifested in its structure and properties. We develop a framework relying on Toeplitz representation of CNNs, and then utilize it to reveal the Hessian structure and, in particular, its rank. We prove tight upper bounds (with linear activations), which closely follow the empirical trend of the Hessian rank and hold in practice in more general settings. Overall, our work generalizes and establishes the key insight that, even in CNNs, the Hessian rank grows as the square root of the number of parameters.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#29992;&#20110;&#27714;&#35299;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#24555;&#19988;&#31616;&#21333;&#26131;&#34892;&#30340;&#29305;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.09046</link><description>&lt;p&gt;
&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Convex optimization over a probability simplex. (arXiv:2305.09046v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09046
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#29992;&#20110;&#27714;&#35299;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#25910;&#25947;&#36895;&#24230;&#24555;&#19988;&#31616;&#21333;&#26131;&#34892;&#30340;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#26041;&#26696;&#8212;&#8212;&#26607;&#35199;&#21333;&#32431;&#24418;&#26469;&#20248;&#21270;&#20984;&#38382;&#39064;&#65292;&#20351;&#20854;&#28385;&#36275;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#38480;&#21046;&#26465;&#20214;&#65292;&#21363;$w\in\mathbb{R}^n$&#20013;$\sum_i w_i=1$&#65292;$w_i\geq0$&#12290;&#25105;&#20204;&#23558;&#21333;&#32431;&#24418;&#26144;&#23556;&#21040;&#21333;&#20301;&#29699;&#30340;&#27491;&#22235;&#38754;&#20307;&#65292;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#33719;&#24471;&#38544;&#21464;&#37327;&#30340;&#35299;&#65292;&#24182;&#23558;&#32467;&#26524;&#26144;&#23556;&#22238;&#21407;&#22987;&#21464;&#37327;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#39640;&#32500;&#38382;&#39064;&#65292;&#27599;&#27425;&#36845;&#20195;&#30001;&#31616;&#21333;&#30340;&#25805;&#20316;&#32452;&#25104;&#65292;&#19988;&#38024;&#23545;&#20984;&#20989;&#25968;&#35777;&#26126;&#20102;&#25910;&#25947;&#36895;&#24230;&#20026;${O}(1/T)$&#12290;&#21516;&#26102;&#26412;&#25991;&#20851;&#27880;&#20102;&#20449;&#24687;&#29702;&#35770;&#65288;&#22914;&#20132;&#21449;&#29109;&#21644;KL&#25955;&#24230;&#65289;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new iteration scheme, the Cauchy-Simplex, to optimize convex problems over the probability simplex $\{w\in\mathbb{R}^n\ |\ \sum_i w_i=1\ \textrm{and}\ w_i\geq0\}$. Other works have taken steps to enforce positivity or unit normalization automatically but never simultaneously within a unified setting. This paper presents a natural framework for manifestly requiring the probability condition. Specifically, we map the simplex to the positive quadrant of a unit sphere, envisage gradient descent in latent variables, and map the result back in a way that only depends on the simplex variable. Moreover, proving rigorous convergence results in this formulation leads inherently to tools from information theory (e.g. cross entropy and KL divergence). Each iteration of the Cauchy-Simplex consists of simple operations, making it well-suited for high-dimensional problems. We prove that it has a convergence rate of ${O}(1/T)$ for convex functions, and numerical experiments of projection 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20280;&#32553;&#21644;&#20581;&#22766;&#30340;&#24352;&#37327;&#29615;&#20998;&#35299;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#22635;&#20805;&#32570;&#22833;&#26465;&#30446;&#24182;&#35782;&#21035;&#24322;&#24120;&#20540;&#65292;&#22312;&#23384;&#20648;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#19978;&#26377;&#26174;&#33879;&#38477;&#20302;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#24352;&#37327;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.09044</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;&#21487;&#20280;&#32553;&#21644;&#20581;&#22766;&#30340;&#24352;&#37327;&#29615;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Scalable and Robust Tensor Ring Decomposition for Large-scale Data. (arXiv:2305.09044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20280;&#32553;&#21644;&#20581;&#22766;&#30340;&#24352;&#37327;&#29615;&#20998;&#35299;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#22635;&#20805;&#32570;&#22833;&#26465;&#30446;&#24182;&#35782;&#21035;&#24322;&#24120;&#20540;&#65292;&#22312;&#23384;&#20648;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#19978;&#26377;&#26174;&#33879;&#38477;&#20302;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#24352;&#37327;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#24352;&#37327;&#29615;&#20998;&#35299;&#22240;&#20854;&#22312;&#39640;&#38454;&#24352;&#37327;&#20013;&#30340;&#20248;&#36234;&#34920;&#29616;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#24352;&#37327;&#29615;&#20998;&#35299;&#31639;&#27861;&#22312;&#38754;&#23545;&#22823;&#35268;&#27169;&#25968;&#25454;&#12289;&#32570;&#22833;&#26465;&#30446;&#21644;&#24322;&#24120;&#20540;&#26102;&#65292;&#24448;&#24448;&#38590;&#20197;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#20581;&#22766;&#30340;&#24352;&#37327;&#29615;&#20998;&#35299;&#31639;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#22823;&#35268;&#27169;&#24352;&#37327;&#25968;&#25454;&#21450;&#20854;&#20013;&#30340;&#32570;&#22833;&#26465;&#30446;&#21644;&#20005;&#37325;&#24322;&#24120;&#20540;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21152;&#26435;&#26368;&#38497;&#19979;&#38477;&#26041;&#27861;&#65292;&#22312;&#20998;&#35299;&#36807;&#31243;&#20013;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#22635;&#20805;&#32570;&#22833;&#26465;&#30446;&#24182;&#35782;&#21035;&#24322;&#24120;&#20540;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#24352;&#37327;&#29615;&#27169;&#22411;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#24555;&#36895; Gram &#30697;&#38453;&#35745;&#31639;&#65288;FGMC&#65289;&#26041;&#27861;&#21644;&#19968;&#31181;&#38543;&#26426;&#23376;&#24352;&#37327;&#33609;&#22270;&#65288;RStS&#65289;&#31574;&#30053;&#65292;&#22823;&#24133;&#24230;&#20943;&#23569;&#20102;&#23384;&#20648;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#24352;&#37327;&#29615;&#20998;&#35299;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor ring (TR) decomposition has recently received increased attention due to its superior expressive performance for high-order tensors. However, the applicability of traditional TR decomposition algorithms to real-world applications is hindered by prevalent large data sizes, missing entries, and corruption with outliers. In this work, we propose a scalable and robust TR decomposition algorithm capable of handling large-scale tensor data with missing entries and gross corruptions. We first develop a novel auto-weighted steepest descent method that can adaptively fill the missing entries and identify the outliers during the decomposition process. Further, taking advantage of the tensor ring model, we develop a novel fast Gram matrix computation (FGMC) approach and a randomized subtensor sketching (RStS) strategy which yield significant reduction in storage and computational complexity. Experimental results demonstrate that the proposed method outperforms existing TR decomposition met
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#38750;&#23545;&#31216;&#26680;&#65288;asymmetric kernels&#65289;&#23454;&#29616;Toeplitz&#31070;&#32463;&#32593;&#32476;&#65288;TNNs&#65289;&#30340;&#21152;&#36895;&#65292;&#36890;&#36807;&#31232;&#30095;&#21152;&#20302;&#31209;Toeplitz&#30697;&#38453;&#20998;&#35299;&#12289;&#23567;&#22411;1D&#21367;&#31215;&#21644;&#26367;&#25442;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#22120;&#65288;RPE&#65289;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#23454;&#29616;O&#65288;n&#65289;&#22797;&#26434;&#24230;&#65292;&#38024;&#23545;&#22240;&#26524;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#8220;&#24555;&#36895;&#8221;&#22240;&#26524;&#23631;&#34109;&#26469;&#25269;&#28040;&#36825;&#31181;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.09028</link><description>&lt;p&gt;
SKI&#21152;&#36895;Toeplitz&#31070;&#32463;&#32593;&#32476;&#65306;&#36890;&#36807;&#38750;&#23545;&#31216;&#26680;&#23454;&#29616;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
SKI to go Faster: Accelerating Toeplitz Neural Networks via Asymmetric Kernels. (arXiv:2305.09028v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20351;&#29992;&#38750;&#23545;&#31216;&#26680;&#65288;asymmetric kernels&#65289;&#23454;&#29616;Toeplitz&#31070;&#32463;&#32593;&#32476;&#65288;TNNs&#65289;&#30340;&#21152;&#36895;&#65292;&#36890;&#36807;&#31232;&#30095;&#21152;&#20302;&#31209;Toeplitz&#30697;&#38453;&#20998;&#35299;&#12289;&#23567;&#22411;1D&#21367;&#31215;&#21644;&#26367;&#25442;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#22120;&#65288;RPE&#65289;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#23454;&#29616;O&#65288;n&#65289;&#22797;&#26434;&#24230;&#65292;&#38024;&#23545;&#22240;&#26524;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#8220;&#24555;&#36895;&#8221;&#22240;&#26524;&#23631;&#34109;&#26469;&#25269;&#28040;&#36825;&#31181;&#26041;&#27861;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Toeplitz&#31070;&#32463;&#32593;&#32476;&#65288;TNNs&#65289;&#26159;&#26368;&#36817;&#20986;&#29616;&#24182;&#21462;&#24471;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#32467;&#26524;&#30340;&#24207;&#21015;&#27169;&#22411;&#12290;&#23427;&#20204;&#38656;&#35201;O(n log n)&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;O(n)&#30340;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#22120;&#65288;RPE&#65289;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#21644;&#34928;&#20943;&#20559;&#24046;&#35843;&#29992;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20943;&#23569;&#23427;&#20204;&#12290;&#25105;&#20204;&#39318;&#20808;&#25351;&#20986;&#65292;RPE&#26159;&#19968;&#20010;&#38750;&#23545;&#31216;&#27491;&#23450;&#26680;&#65292;&#32780;Toeplitz&#30697;&#38453;&#26159;&#20266;&#26684;&#25289;&#22982;&#30697;&#38453;&#12290;&#27492;&#22806;&#65306;1&#65289;&#23398;&#20064;&#30340;&#26680;&#22312;&#20027;&#23545;&#35282;&#32447;&#38468;&#36817;&#26174;&#31034;&#20986;&#21050;&#29366;&#34892;&#20026;&#65292;&#32780;&#22312;&#20854;&#20182;&#20301;&#32622;&#21017;&#34920;&#29616;&#20986;&#24179;&#28369;&#34892;&#20026;&#65307;2&#65289;RPE MLP&#36739;&#24930;&#12290;&#23545;&#20110;&#21452;&#21521;&#27169;&#22411;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#36827;&#34892;&#31232;&#30095;&#21152;&#20302;&#31209;Toeplitz&#30697;&#38453;&#20998;&#35299;&#12290;&#23545;&#20110;&#31232;&#30095;&#32452;&#20214;&#30340;&#25805;&#20316;&#65292;&#25105;&#20204;&#36827;&#34892;&#23567;&#22411;1D&#21367;&#31215;&#12290;&#23545;&#20110;&#20302;&#31209;&#32452;&#20214;&#65292;&#25105;&#20204;&#23558;RPE MLP&#26367;&#25442;&#20026;&#32447;&#24615;&#25554;&#20540;&#65292;&#24182;&#20351;&#29992;&#38750;&#23545;&#31216;&#26377;&#32467;&#26500;&#30340;&#20869;&#26680;&#25554;&#20540;&#65288;SKI&#65289;&#65288;Wilson&#31561;&#65292;2015&#65289;&#20197;&#23454;&#29616;O&#65288;n&#65289;&#22797;&#26434;&#24230;&#65306;&#25105;&#20204;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35823;&#24046;&#20998;&#26512;&#12290;&#23545;&#20110;&#22240;&#26524;&#27169;&#22411;&#65292;&#8220;&#24555;&#36895;&#8221;&#22240;&#26524;&#23631;&#34109;&#65288;Katharopoulos&#31561;&#65292;2020&#65289;&#25269;&#28040;&#20102;SKI&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Toeplitz Neural Networks (TNNs) (Qin et. al. 2023) are a recent sequence model with impressive results. They require O(n log n) computational complexity and O(n) relative positional encoder (RPE) multi-layer perceptron (MLP) and decay bias calls. We aim to reduce both. We first note that the RPE is a non-SPD (symmetric positive definite) kernel and the Toeplitz matrices are pseudo-Gram matrices. Further 1) the learned kernels display spiky behavior near the main diagonals with otherwise smooth behavior; 2) the RPE MLP is slow. For bidirectional models, this motivates a sparse plus low-rank Toeplitz matrix decomposition. For the sparse component's action, we do a small 1D convolution. For the low rank component, we replace the RPE MLP with linear interpolation and use asymmetric Structured Kernel Interpolation (SKI) (Wilson et. al. 2015) for O(n) complexity: we provide rigorous error analysis. For causal models, "fast" causal masking (Katharopoulos et. al. 2020) negates SKI's benefits. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#22686;&#24378;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#27169;&#25311;&#38142;&#30340;&#26411;&#23614;&#36827;&#34892;&#24178;&#39044;&#12289;&#22312;&#27169;&#25311;&#38142;&#30340;&#24320;&#22836;&#36827;&#34892;&#24178;&#39044;&#21644;&#28508;&#31354;&#38388;&#32454;&#21270;&#65292;&#36890;&#36807; W+jets&#30697;&#38453;&#20803;&#20195;&#29702;&#27169;&#25311;&#20197;&#21450;&#20351;&#29992;&#27491;&#21017;&#27969;&#21644;&#29983;&#25104;&#27169;&#22411;&#31561;&#31574;&#30053;&#36827;&#34892;&#30740;&#31350;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#33021;&#26174;&#33879;&#25552;&#39640;&#31934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.07696</link><description>&lt;p&gt;
ELSA -- &#25552;&#39640;&#30896;&#25758;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#22686;&#24378;&#28508;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
ELSA -- Enhanced latent spaces for improved collider simulations. (arXiv:2305.07696v1 [hep-ph] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22810;&#31181;&#22686;&#24378;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#27169;&#25311;&#38142;&#30340;&#26411;&#23614;&#36827;&#34892;&#24178;&#39044;&#12289;&#22312;&#27169;&#25311;&#38142;&#30340;&#24320;&#22836;&#36827;&#34892;&#24178;&#39044;&#21644;&#28508;&#31354;&#38388;&#32454;&#21270;&#65292;&#36890;&#36807; W+jets&#30697;&#38453;&#20803;&#20195;&#29702;&#27169;&#25311;&#20197;&#21450;&#20351;&#29992;&#27491;&#21017;&#27969;&#21644;&#29983;&#25104;&#27169;&#22411;&#31561;&#31574;&#30053;&#36827;&#34892;&#30740;&#31350;&#65292;&#23454;&#39564;&#35777;&#26126;&#36825;&#20123;&#26041;&#27861;&#33021;&#26174;&#33879;&#25552;&#39640;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#25311;&#22312;&#30896;&#25758;&#29289;&#29702;&#20013;&#20855;&#26377;&#20851;&#38190;&#20316;&#29992;&#12290;&#25105;&#20204;&#25506;&#32034;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;&#27169;&#25311;&#31934;&#30830;&#24230;&#30340;&#21508;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#27169;&#25311;&#38142;&#30340;&#26411;&#23614;&#36827;&#34892;&#24178;&#39044;&#65288;&#37325;&#26032;&#21152;&#26435;&#65289;&#12289;&#22312;&#27169;&#25311;&#38142;&#30340;&#24320;&#22836;&#36827;&#34892;&#24178;&#39044;&#65288;&#39044;&#22788;&#29702;&#65289;&#20197;&#21450;&#22312;&#26411;&#23614;&#21644;&#24320;&#22836;&#20043;&#38388;&#24314;&#31435;&#32852;&#31995;&#65288;&#28508;&#31354;&#38388;&#32454;&#21270;&#65289;&#12290;&#20026;&#20102;&#28165;&#26224;&#22320;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#27491;&#21017;&#27969;&#30340;W+jets&#30697;&#38453;&#20803;&#20195;&#29702;&#27169;&#25311;&#20316;&#20026;&#21407;&#22411;&#31034;&#20363;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#22312;&#25968;&#25454;&#31354;&#38388;&#20013;&#30830;&#23450;&#26435;&#37325;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25968;&#25454;&#31354;&#38388;&#26435;&#37325;&#22238;&#25512;&#21040;&#28508;&#31354;&#38388;&#20197;&#20135;&#29983;&#26080;&#26435;&#37325;&#30340;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#20351;&#29992;&#28508;&#31354;&#38388;&#32454;&#21270;&#65288;LASER&#65289;&#21327;&#35758;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#22686;&#24378;&#27491;&#21017;&#27969;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#22312;&#28508;&#31354;&#38388;&#21644;&#30446;&#26631;&#31354;&#38388;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#32500;&#24230;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21508;&#31181;&#39044;&#22788;&#29702;&#31574;&#30053;&#65292;&#21253;&#25324;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#22686;&#24378;&#26679;&#26412;&#30340;&#26032;&#30340;&#36890;&#29992;&#26041;&#27861;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20123;&#26041;&#27861;&#26174;&#30528;&#25552;&#39640;&#20102;W+jets&#30697;&#38453;&#20803;&#27169;&#25311;&#30340;&#31934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulations play a key role for inference in collider physics. We explore various approaches for enhancing the precision of simulations using machine learning, including interventions at the end of the simulation chain (reweighting), at the beginning of the simulation chain (pre-processing), and connections between the end and beginning (latent space refinement). To clearly illustrate our approaches, we use W+jets matrix element surrogate simulations based on normalizing flows as a prototypical example. First, weights in the data space are derived using machine learning classifiers. Then, we pull back the data-space weights to the latent space to produce unweighted examples and employ the Latent Space Refinement (LASER) protocol using Hamiltonian Monte Carlo. An alternative approach is an augmented normalizing flow, which allows for different dimensions in the latent and target spaces. These methods are studied for various pre-processing strategies, including a new and general method f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.06563</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Manifold Regularized Tucker Decomposition Approach for Spatiotemporal Traffic Data Imputation. (arXiv:2305.06563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#27491;&#21017;&#21270;Tucker&#20998;&#35299;&#30340;&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21033;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#24341;&#20837;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#31354;&#20132;&#36890;&#25968;&#25454;&#22635;&#20805;(STDI)&#26159;&#25968;&#25454;&#39537;&#21160;&#26234;&#33021;&#20132;&#36890;&#31995;&#32479;&#20013;&#19981;&#21487;&#36991;&#20813;&#21644;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22312;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#20132;&#36890;&#25968;&#25454;&#20013;&#20272;&#35745;&#20002;&#22833;&#25968;&#25454;&#12290;&#30001;&#20110;&#20132;&#36890;&#25968;&#25454;&#20855;&#26377;&#22810;&#32500;&#21644;&#26102;&#31354;&#24615;&#36136;&#65292;&#25105;&#20204;&#23558;&#20002;&#22833;&#25968;&#25454;&#22635;&#20805;&#35270;&#20026;&#24352;&#37327;&#23436;&#25104;&#38382;&#39064;&#12290;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#35768;&#22810;&#20851;&#20110;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340; STDI &#30340;&#30740;&#31350;&#24050;&#32463;&#23637;&#24320;&#12290;&#28982;&#32780;&#65292;&#22914;&#20309;&#21033;&#29992;&#26102;&#31354;&#30456;&#20851;&#24615;&#21644;&#26680;&#24352;&#37327;&#31232;&#30095;&#24615;&#26469;&#25913;&#21892;&#22635;&#20805;&#24615;&#33021;&#20173;&#28982;&#38656;&#35201;&#35299;&#20915;&#12290;&#26412;&#25991;&#37325;&#26032;&#26500;&#36896;&#20102;3/4&#38454;&#27721;&#20811;&#23572;&#24352;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#27969;&#24418;&#27491;&#21017;&#21270; Tucker &#20998;&#35299;(maniRTD)&#27169;&#22411;&#29992;&#20110;STDI&#12290;&#26126;&#30830;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#22810;&#32500;&#24310;&#36831;&#23884;&#20837;&#21464;&#25442;&#23558;&#20256;&#24863;&#20132;&#36890;&#29366;&#24577;&#25968;&#25454;&#34920;&#31034;&#20026;3/4&#38454;&#24352;&#37327;&#12290;&#28982;&#21518;&#65292;ManiRTD&#20351;&#29992;&#31232;&#30095;&#27491;&#21017;&#21270;&#39033;&#25913;&#21892;&#20102;Tucker&#26680;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#20351;&#29992;&#27969;&#24418;&#27491;&#21017;&#21270;&#21644;&#26102;&#38388;&#32422;&#26463;&#39033;&#26469;&#20248;&#21270;&#24352;&#37327;&#30340;&#22635;&#20805;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Spatiotemporal traffic data imputation (STDI), estimating the missing data from partially observed traffic data, is an inevitable and challenging task in data-driven intelligent transportation systems (ITS). Due to traffic data's multidimensional and spatiotemporal properties, we treat the missing data imputation as a tensor completion problem. Many studies have been on STDI based on tensor decomposition in the past decade. However, how to use spatiotemporal correlations and core tensor sparsity to improve the imputation performance still needs to be solved. This paper reshapes a 3rd/4th order Hankel tensor and proposes an innovative manifold regularized Tucker decomposition (ManiRTD) model for STDI. Expressly, we represent the sensory traffic state data as the 3rd/4th tensors by introducing Multiway Delay Embedding Transforms. Then, ManiRTD improves the sparsity of the Tucker core using a sparse regularization term and employs manifold regularization and temporal constraint terms of f
&lt;/p&gt;</description></item><item><title>LLT&#26159;&#19968;&#20010;R&#21253;&#65292;&#29992;&#20110;&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#21464;&#25442;&#65292;&#21487;&#20197;&#24110;&#21161;&#23545;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2304.14211</link><description>&lt;p&gt;
LLT&#65306;&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#21464;&#25442;&#30340;R&#21253;
&lt;/p&gt;
&lt;p&gt;
LLT: An R package for Linear Law-based Feature Space Transformation. (arXiv:2304.14211v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14211
&lt;/p&gt;
&lt;p&gt;
LLT&#26159;&#19968;&#20010;R&#21253;&#65292;&#29992;&#20110;&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#21464;&#25442;&#65292;&#21487;&#20197;&#24110;&#21161;&#23545;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#23450;&#24459;&#29305;&#24449;&#31354;&#38388;&#36716;&#25442;(LLT )&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#24110;&#21161;&#23545;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#20998;&#31867;&#12290;LLT R&#21253;&#20197;&#28789;&#27963;&#21644;&#29992;&#25143;&#21451;&#22909;&#30340;&#26041;&#24335;&#23454;&#29616;&#20102;&#35813;&#31639;&#27861;&#12290;&#35813;&#21253;&#23558;&#23454;&#20363;&#20998;&#20026;&#35757;&#32451;&#21644;&#27979;&#35797;&#38598;&#65292;&#24182;&#21033;&#29992;&#26102;&#24310;&#23884;&#20837;&#21644;&#35889;&#20998;&#35299;&#25216;&#26415;&#65292;&#35782;&#21035;&#35757;&#32451;&#38598;&#20013;&#27599;&#20010;&#36755;&#20837;&#24207;&#21015;(&#21021;&#22987;&#29305;&#24449;)&#30340;&#25511;&#21046;&#27169;&#24335;(&#31216;&#20026;&#32447;&#24615;&#23450;&#24459;)&#12290;&#26368;&#21518;&#65292;&#23427;&#24212;&#29992;&#35757;&#32451;&#38598;&#30340;&#32447;&#24615;&#23450;&#24459;&#26469;&#36716;&#25442;&#27979;&#35797;&#38598;&#30340;&#21021;&#22987;&#29305;&#24449;&#12290;trainTest&#12289;trainLaw&#21644;testTrans&#19977;&#20010;&#21333;&#29420;&#30340;&#20989;&#25968;&#26469;&#25191;&#34892;&#36825;&#20123;&#27493;&#39588;&#65292;&#23427;&#20204;&#38656;&#35201;&#39044;&#23450;&#20041;&#30340;&#25968;&#25454;&#32467;&#26500;;&#28982;&#32780;&#65292;&#20026;&#20102;&#24555;&#36895;&#35745;&#31639;&#65292;&#23427;&#20204;&#21482;&#20351;&#29992;&#20869;&#32622;&#20989;&#25968;&#12290;LLT R&#21253;&#21644;&#36866;&#24403;&#25968;&#25454;&#32467;&#26500;&#30340;&#31034;&#20363;&#25968;&#25454;&#38598;&#22312;GitHub&#19978;&#20844;&#24320;&#21487;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of the linear law-based feature space transformation (LLT) algorithm is to assist with the classification of univariate and multivariate time series. The presented R package, called LLT, implements this algorithm in a flexible yet user-friendly way. This package first splits the instances into training and test sets. It then utilizes time-delay embedding and spectral decomposition techniques to identify the governing patterns (called linear laws) of each input sequence (initial feature) within the training set. Finally, it applies the linear laws of the training set to transform the initial features of the test set. These steps are performed by three separate functions called trainTest, trainLaw, and testTrans. Their application requires a predefined data structure; however, for fast calculation, they use only built-in functions. The LLT R package and a sample dataset with the appropriate data structure are publicly available on GitHub.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#19979;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#21644;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2304.02912</link><description>&lt;p&gt;
&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#30340;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Classification of Superstatistical Features in High Dimensions. (arXiv:2304.02912v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02912
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#39640;&#32500;&#36229;&#32479;&#35745;&#29305;&#24449;&#19979;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#21644;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26041;&#27861;&#65292;&#23545;&#20855;&#26377;&#19968;&#33324;&#20013;&#24515;&#28857;&#30340;&#20004;&#20010;&#25968;&#25454;&#20113;&#30340;&#28151;&#21512;&#36827;&#34892;&#20102;&#23398;&#20064;&#65292;&#20551;&#35774;&#20855;&#26377;&#36890;&#29992;&#30340;&#20984;&#25439;&#22833;&#21644;&#20984;&#27491;&#21017;&#21270;&#12290;&#27599;&#20010;&#25968;&#25454;&#20113;&#26159;&#36890;&#36807;&#20174;&#21487;&#33021;&#26159;&#19981;&#21487;&#25968;&#30340;&#39640;&#26031;&#20998;&#24067;&#21472;&#21152;&#20013;&#36827;&#34892;&#37319;&#26679;&#26469;&#33719;&#24471;&#30340;&#65292;&#20854;&#26041;&#24046;&#20855;&#26377;&#36890;&#29992;&#30340;&#27010;&#29575;&#23494;&#24230;$\varrho$&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;&#22823;&#37327;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#21253;&#25324;&#27809;&#26377;&#21327;&#26041;&#24046;&#30340;&#24130;&#24459;&#23614;&#37096;&#20998;&#24067;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25152;&#24471;&#20272;&#35745;&#22120;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20998;&#26512;&#20102;&#27491;&#21017;&#21270;&#30340;&#20316;&#29992;&#20197;&#21450;&#20998;&#31163;&#36716;&#25442;&#19982;&#20998;&#24067;&#23610;&#24230;&#21442;&#25968;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterise the learning of a mixture of two clouds of data points with generic centroids via empirical risk minimisation in the high dimensional regime, under the assumptions of generic convex loss and convex regularisation. Each cloud of data points is obtained by sampling from a possibly uncountable superposition of Gaussian distributions, whose variance has a generic probability density $\varrho$. Our analysis covers therefore a large family of data distributions, including the case of power-law-tailed distributions with no covariance. We study the generalisation performance of the obtained estimator, we analyse the role of regularisation, and the dependence of the separability transition on the distribution scale parameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#31946;&#38598;&#65292;&#31216;&#20026;&#25104;&#26412;&#24863;&#30693;&#27169;&#31946;&#38598;&#65292;&#23427;&#36890;&#36807;&#21322;&#31354;&#38388;&#23450;&#20041;&#65292;&#21482;&#25490;&#38500;&#37027;&#20123;&#39044;&#35745;&#23545;&#25152;&#33719;&#24471;&#30340;&#26368;&#22351;&#24773;&#20917;&#25104;&#26412;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#39640;&#32622;&#20449;&#24230;&#19978;&#30028;&#21644;&#19968;&#33268;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.09408</link><description>&lt;p&gt;
&#20351;&#29992;&#25104;&#26412;&#24863;&#30693;&#30340;&#27169;&#31946;&#38598;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Optimization using Cost-Aware Ambiguity Sets. (arXiv:2303.09408v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#27169;&#31946;&#38598;&#65292;&#31216;&#20026;&#25104;&#26412;&#24863;&#30693;&#27169;&#31946;&#38598;&#65292;&#23427;&#36890;&#36807;&#21322;&#31354;&#38388;&#23450;&#20041;&#65292;&#21482;&#25490;&#38500;&#37027;&#20123;&#39044;&#35745;&#23545;&#25152;&#33719;&#24471;&#30340;&#26368;&#22351;&#24773;&#20917;&#25104;&#26412;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#39640;&#32622;&#20449;&#24230;&#19978;&#30028;&#21644;&#19968;&#33268;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#30340;&#27169;&#31946;&#38598;&#31867;&#21035;&#65292;&#31216;&#20026;&#25104;&#26412;&#24863;&#30693;&#30340;&#27169;&#31946;&#38598;&#65292;&#20854;&#23450;&#20041;&#20026;&#21462;&#20915;&#20110;&#22312;&#29420;&#31435;&#20272;&#35745;&#30340;&#26368;&#20248;&#35299;&#22788;&#35780;&#20272;&#25104;&#26412;&#20989;&#25968;&#30340;&#21322;&#31354;&#38388;&#65292;&#22240;&#27492;&#20165;&#25490;&#38500;&#37027;&#20123;&#39044;&#35745;&#23545;&#25152;&#33719;&#24471;&#30340;&#26368;&#22351;&#24773;&#20917;&#25104;&#26412;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#30001;&#27492;&#20135;&#29983;&#30340;DRO&#26041;&#27861;&#25552;&#20379;&#20102;&#39640;&#32622;&#20449;&#24230;&#30340;&#19978;&#30028;&#21644;&#26679;&#26412;&#22806;&#39044;&#26399;&#25104;&#26412;&#30340;&#19968;&#33268;&#20272;&#35745;&#65292;&#24182;&#19988;&#32463;&#39564;&#35777;&#26126;&#65292;&#23427;&#19982;&#22522;&#20110;&#25955;&#24230;&#30340;&#27169;&#31946;&#38598;&#30456;&#27604;&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#23569;&#20445;&#23432;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel class of ambiguity sets for distributionally robust optimization (DRO). These ambiguity sets, called cost-aware ambiguity sets, are defined as halfspaces which depend on the cost function evaluated at an independent estimate of the optimal solution, thus excluding only those distributions that are expected to have significant impact on the obtained worst-case cost. We show that the resulting DRO method provides both a high-confidence upper bound and a consistent estimator of the out-of-sample expected cost, and demonstrate empirically that it results in less conservative solutions compared to divergence-based ambiguity sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#21294;&#20047;&#38382;&#39064;&#65292;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#26469;&#25193;&#20805;&#25968;&#25454;&#25928;&#26524;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2303.06614</link><description>&lt;p&gt;
&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#65306;&#26088;&#22312;&#29992;&#25193;&#20805;&#25968;&#25454;&#26469;&#25552;&#39640;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Synthetic Experience Replay. (arXiv:2303.06614v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06614
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#26041;&#27861;&#35299;&#20915;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#25968;&#25454;&#21294;&#20047;&#38382;&#39064;&#65292;&#36890;&#36807;&#24039;&#22937;&#24212;&#29992;&#29983;&#25104;&#24314;&#27169;&#25216;&#26415;&#26469;&#25193;&#20805;&#25968;&#25454;&#25928;&#26524;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#21313;&#24180;&#30340;&#19968;&#20010;&#20851;&#38190;&#20027;&#39064;&#26159;&#65292;&#24403;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#21644;&#22823;&#22411;&#25968;&#25454;&#38598;&#30456;&#32467;&#21512;&#26102;&#65292;&#23427;&#20204;&#21487;&#20197;&#20135;&#29983;&#20196;&#20154;&#24778;&#24322;&#30340;&#32467;&#26524;&#12290;&#22312;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#36825;&#31181;&#33539;&#24335;&#36890;&#24120;&#36890;&#36807;&#32463;&#39564;&#22238;&#25918;&#23454;&#29616;&#65292;&#20854;&#20013;&#36807;&#21435;&#30340;&#32463;&#39564;&#25968;&#25454;&#38598;&#29992;&#20110;&#35757;&#32451;&#31574;&#30053;&#25110;&#20540;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#19982;&#30417;&#30563;&#23398;&#20064;&#25110;&#33258;&#30417;&#30563;&#23398;&#20064;&#19981;&#21516;&#65292;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#24517;&#39035;&#25910;&#38598;&#33258;&#24049;&#30340;&#25968;&#25454;&#65292;&#36825;&#36890;&#24120;&#26159;&#26377;&#38480;&#30340;&#12290;&#22240;&#27492;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#22909;&#22788;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#21363;&#20351;&#26159;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#24320;&#22987;&#26102;&#20063;&#21487;&#33021;&#20986;&#29616;&#36807;&#25311;&#21512;&#29616;&#35937;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#29983;&#25104;&#24314;&#27169;&#30340;&#24040;&#22823;&#36827;&#27493;&#65292;&#24182;&#25552;&#20986;&#20102;&#21512;&#25104;&#32463;&#39564;&#22238;&#25918;&#65288;SynthER&#65289;&#65292;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#30340;&#26041;&#27861;&#26469;&#28789;&#27963;&#22320;&#19978;&#37319;&#26679;&#20195;&#29702;&#25910;&#38598;&#30340;&#32463;&#39564;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SynthER&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#26080;&#35770;&#26159;&#22312;&#24863;&#30693;&#29615;&#22659;&#36824;&#26159;&#22312;&#20687;&#32032;&#29615;&#22659;&#20013;&#12290;&#22312;&#31163;&#32447;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#27973;&#23618;ReLU&#32593;&#32476;&#22312;&#34920;&#36798;&#20855;&#26377;&#38543;&#30528;&#36755;&#20837;&#32500;&#24230;&#22686;&#21152;&#30340;Lipschitz&#21442;&#25968;&#30340;&#20989;&#25968;&#26102;&#20250;&#36973;&#21463;&#32500;&#24230;&#28798;&#38590;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#26356;&#20381;&#36182;&#20110;&#23427;&#20204;&#30340;&#28145;&#24230;&#32780;&#19981;&#26159;&#24635;&#20307;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.03544</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#39033;&#24335;&#36924;&#36817;&#20013;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expressivity of Shallow and Deep Neural Networks for Polynomial Approximation. (arXiv:2303.03544v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#27973;&#23618;ReLU&#32593;&#32476;&#22312;&#34920;&#36798;&#20855;&#26377;&#38543;&#30528;&#36755;&#20837;&#32500;&#24230;&#22686;&#21152;&#30340;Lipschitz&#21442;&#25968;&#30340;&#20989;&#25968;&#26102;&#20250;&#36973;&#21463;&#32500;&#24230;&#28798;&#38590;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#26356;&#20381;&#36182;&#20110;&#23427;&#20204;&#30340;&#28145;&#24230;&#32780;&#19981;&#26159;&#24635;&#20307;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35201;&#36817;&#20284;&#22810;&#20803;&#21333;&#39033;&#24335;&#25152;&#38656;&#30340;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#31070;&#32463;&#32593;&#32476;&#20013;&#31070;&#32463;&#20803;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#22312;&#19968;&#33324;&#32039;&#33268;&#22495;&#19978;&#24314;&#31435;&#20102;&#20219;&#20309;&#27973;&#23618;&#32593;&#32476;&#36924;&#36817;&#20056;&#31215;&#20989;&#25968;&#30340;&#25351;&#25968;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36825;&#20010;&#19979;&#30028;&#19981;&#36866;&#29992;&#20110;&#22312;&#21333;&#20301;&#31435;&#26041;&#20307;&#19978;&#30340;&#35268;&#33539;&#21033;&#26222;&#24076;&#33576;&#21333;&#39033;&#24335;&#12290;&#36825;&#20123;&#21457;&#29616;&#34920;&#26126;&#65292;&#22312;&#34920;&#36798;&#20855;&#26377;&#38543;&#30528;&#36755;&#20837;&#32500;&#24230;&#22686;&#21152;&#30340;Lipschitz&#21442;&#25968;&#30340;&#20989;&#25968;&#26102;&#65292;&#27973;&#23618;ReLU&#32593;&#32476;&#20250;&#36973;&#21463;&#32500;&#24230;&#28798;&#38590;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#26356;&#20381;&#36182;&#20110;&#23427;&#20204;&#30340;&#28145;&#24230;&#32780;&#19981;&#26159;&#24635;&#20307;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study explores the number of neurons required for a Rectified Linear Unit (ReLU) neural network to approximate multivariate monomials. We establish an exponential lower bound on the complexity of any shallow network approximating the product function over a general compact domain. We also demonstrate this lower bound doesn't apply to normalized Lipschitz monomials over the unit cube. These findings suggest that shallow ReLU networks experience the curse of dimensionality when expressing functions with a Lipschitz parameter scaling with the dimension of the input, and that the expressive power of neural networks is more dependent on their depth rather than overall complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#22914;&#20309;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#30340;TS&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20381;&#36182;&#20110;&#20808;&#39564;&#30693;&#35782;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65307;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#35757;&#32451;&#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#22312;&#32447;&#24615;&#33021;&#65292;&#25913;&#36827;&#31243;&#24230;&#38543;&#19987;&#23478;&#33021;&#21147;&#27700;&#24179;&#30340;&#25552;&#39640;&#32780;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2302.03319</link><description>&lt;p&gt;
&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;:&#36136;&#37327;&#33267;&#20851;&#37325;&#35201;
&lt;/p&gt;
&lt;p&gt;
Leveraging Demonstrations to Improve Online Learning: Quality Matters. (arXiv:2302.03319v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25506;&#35752;&#20102;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#22914;&#20309;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#30340;TS&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20381;&#36182;&#20110;&#20808;&#39564;&#30693;&#35782;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65307;&#30740;&#31350;&#21457;&#29616;&#65292;&#39044;&#35757;&#32451;&#21487;&#20197;&#22823;&#24133;&#25552;&#39640;&#22312;&#32447;&#24615;&#33021;&#65292;&#25913;&#36827;&#31243;&#24230;&#38543;&#19987;&#23478;&#33021;&#21147;&#27700;&#24179;&#30340;&#25552;&#39640;&#32780;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#31163;&#32447;&#28436;&#31034;&#25968;&#25454;&#21487;&#20197;&#22914;&#20309;&#25913;&#36827;&#22312;&#32447;&#23398;&#20064;&#65292;&#33258;&#28982;&#32780;&#28982;&#22320;&#26399;&#26395;&#20250;&#26377;&#19968;&#23450;&#30340;&#25913;&#36827;&#65292;&#20294;&#38382;&#39064;&#22312;&#20110;&#22914;&#20309;&#25913;&#36827;&#20197;&#21450;&#21487;&#20197;&#25913;&#36827;&#22810;&#23569;&#65311;&#25105;&#20204;&#34920;&#26126;&#65292;&#25913;&#36827;&#30340;&#31243;&#24230;&#24517;&#39035;&#21462;&#20915;&#20110;&#28436;&#31034;&#25968;&#25454;&#30340;&#36136;&#37327;&#12290;&#20026;&#20102;&#29983;&#25104;&#21487;&#31227;&#26893;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312;&#20102;&#20316;&#20026;&#20856;&#22411;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#21644;&#27169;&#22411;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#19978;&#24212;&#29992;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;TS&#65289;&#12290;&#28436;&#31034;&#25968;&#25454;&#26159;&#30001;&#20855;&#26377;&#32473;&#23450;&#33021;&#21147;&#27700;&#24179;&#30340;&#19987;&#23478;&#29983;&#25104;&#30340;&#65292;&#36825;&#26159;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30693;&#24773;TS&#31639;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#23450;&#29702;&#20197;&#19968;&#33268;&#30340;&#26041;&#24335;&#21033;&#29992;&#28436;&#31034;&#25968;&#25454;&#24182;&#23548;&#20986;&#20381;&#36182;&#20110;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;&#36825;&#25552;&#20379;&#20102;&#27934;&#35265;&#65292;&#21363;&#39044;&#35757;&#32451;&#22914;&#20309;&#26497;&#22823;&#22320;&#25552;&#39640;&#22312;&#32447;&#24615;&#33021;&#65292;&#20197;&#21450;&#25913;&#36827;&#31243;&#24230;&#38543;&#19987;&#23478;&#33021;&#21147;&#27700;&#24179;&#30340;&#25552;&#39640;&#32780;&#22686;&#21152;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#36125;&#21494;&#26031;&#24341;&#23548;&#23454;&#29616;&#20102;&#23454;&#29992;&#30340;&#12289;&#36817;&#20284;&#30340;&#30693;&#24773;TS&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#23454;&#29616;&#20102;&#23454;&#36136;&#24615;&#30340;&#36951;&#25022;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the extent to which offline demonstration data can improve online learning. It is natural to expect some improvement, but the question is how, and by how much? We show that the degree of improvement must depend on the quality of the demonstration data. To generate portable insights, we focus on Thompson sampling (TS) applied to a multi-armed bandit as a prototypical online learning algorithm and model. The demonstration data is generated by an expert with a given competence level, a notion we introduce. We propose an informed TS algorithm that utilizes the demonstration data in a coherent way through Bayes' rule and derive a prior-dependent Bayesian regret bound. This offers insight into how pretraining can greatly improve online performance and how the degree of improvement increases with the expert's competence level. We also develop a practical, approximate informed TS algorithm through Bayesian bootstrapping and show substantial empirical regret reduction through exp
&lt;/p&gt;</description></item><item><title>D-Adaptation&#26159;&#19968;&#31181;&#21487;&#20197;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#29992;&#20110;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#32780;&#26080;&#38656;&#36229;&#21442;&#25968;&#65292;&#20063;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.07733</link><description>&lt;p&gt;
&#36890;&#36807;D&#36866;&#24212;&#23454;&#29616;&#23398;&#20064;&#29575;&#33258;&#30001;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning-Rate-Free Learning by D-Adaptation. (arXiv:2301.07733v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07733
&lt;/p&gt;
&lt;p&gt;
D-Adaptation&#26159;&#19968;&#31181;&#21487;&#20197;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#38024;&#23545;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#29992;&#20110;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#32780;&#26080;&#38656;&#36229;&#21442;&#25968;&#65292;&#20063;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
D&#36866;&#24212;&#26159;&#19968;&#31181;&#33258;&#21160;&#35774;&#32622;&#23398;&#20064;&#29575;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#28176;&#36817;&#22320;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#20984;&#24615;Lipschitz&#20989;&#25968;&#65292;&#26080;&#38656;&#22238;&#28335;&#25110;&#32447;&#24615;&#25628;&#32034;&#65292;&#24182;&#19988;&#27599;&#27493;&#26080;&#38656;&#36827;&#34892;&#39069;&#22806;&#30340;&#20989;&#25968;&#20540;&#25110;&#26799;&#24230;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#36825;&#19968;&#31867;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#26080;&#36229;&#21442;&#25968;&#19988;&#25910;&#25947;&#36895;&#29575;&#26080;&#38656;&#39069;&#22806;&#23545;&#25968;&#22240;&#23376;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#38024;&#23545;SGD&#21644;Adam&#21464;&#20307;&#23637;&#31034;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#20854;&#20013;&#35813;&#26041;&#27861;&#33258;&#21160;&#21305;&#37197;&#25163;&#21160;&#35843;&#25972;&#30340;&#23398;&#20064;&#29575;&#65292;&#22312;&#21313;&#22810;&#20010;&#19981;&#21516;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#24212;&#29992;&#65292;&#21253;&#25324;&#22823;&#35268;&#27169;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#38382;&#39064;&#12290;&#24320;&#28304;&#23454;&#29616;&#22312; \url{https://github.com/facebookresearch/dadaptation}.
&lt;/p&gt;
&lt;p&gt;
D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.  An open-source implementation is available at \url{https://github.com/facebookresearch/dadaptation}.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#25968;&#25454;&#38598;&#30340;&#26032;&#26694;&#26550;ComImp&#65292;&#21487;&#20197;&#22788;&#29702;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#29305;&#24449;&#30340;&#25361;&#25112;&#65292;&#24182;&#21033;&#29992;PCA-ComImp&#36827;&#34892;&#32500;&#25968;&#38477;&#20302;&#12290;&#27492;&#22806;&#65292;&#27492;&#26694;&#26550;&#36824;&#21487;&#20197;&#29992;&#20110;&#25968;&#25454;&#39044;&#22788;&#29702;&#65292;&#22635;&#34917;&#32570;&#22833;&#25968;&#25454;&#30340;&#26465;&#30446;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2210.05165</link><description>&lt;p&gt;
&#21512;&#24182;&#25968;&#25454;&#38598;&#20197;&#22686;&#21152;&#26679;&#26412;&#25968;&#37327;&#24182;&#25552;&#39640;&#27169;&#22411;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Combining datasets to increase the number of samples and improve model fitting. (arXiv:2210.05165v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#21512;&#25968;&#25454;&#38598;&#30340;&#26032;&#26694;&#26550;ComImp&#65292;&#21487;&#20197;&#22788;&#29702;&#19981;&#21516;&#25968;&#25454;&#38598;&#20043;&#38388;&#23384;&#22312;&#19981;&#21516;&#29305;&#24449;&#30340;&#25361;&#25112;&#65292;&#24182;&#21033;&#29992;PCA-ComImp&#36827;&#34892;&#32500;&#25968;&#38477;&#20302;&#12290;&#27492;&#22806;&#65292;&#27492;&#26694;&#26550;&#36824;&#21487;&#20197;&#29992;&#20110;&#25968;&#25454;&#39044;&#22788;&#29702;&#65292;&#22635;&#34917;&#32570;&#22833;&#25968;&#25454;&#30340;&#26465;&#30446;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20351;&#29992;&#24773;&#20917;&#19979;&#65292;&#23558;&#26469;&#33258;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#32452;&#21512;&#36215;&#26469;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#24403;&#33267;&#23569;&#19968;&#20010;&#25968;&#25454;&#38598;&#30340;&#26679;&#26412;&#25968;&#37327;&#24456;&#23569;&#26102;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#21487;&#33021;&#23384;&#22312;&#19968;&#20010;&#28508;&#22312;&#30340;&#25361;&#25112;&#65292;&#21363;&#36825;&#20123;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#19981;&#23436;&#20840;&#30456;&#21516;&#65292;&#23613;&#31649;&#23427;&#20204;&#20013;&#26377;&#19968;&#20123;&#20849;&#21516;&#30340;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#31216;&#20026;&#22522;&#20110;&#25554;&#34917;&#30340;&#25968;&#25454;&#38598;&#32452;&#21512;&#65288;ComImp&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;ComImp&#30340;&#21464;&#20307;&#65292;&#20351;&#29992;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#65292;&#21363;PCA-ComImp&#65292;&#20197;&#22312;&#32452;&#21512;&#25968;&#25454;&#38598;&#20043;&#21069;&#38477;&#20302;&#32500;&#25968;&#12290;&#24403;&#25968;&#25454;&#38598;&#25317;&#26377;&#22823;&#37327;&#19981;&#20849;&#20139;&#29305;&#24449;&#26102;&#65292;&#36825;&#38750;&#24120;&#26377;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36824;&#21487;&#20197;&#29992;&#20110;&#25968;&#25454;&#39044;&#22788;&#29702;&#65292;&#21363;&#36890;&#36807;&#22312;&#32452;&#21512;&#19981;&#21516;&#25968;&#25454;&#38598;&#26102;&#22635;&#34917;&#32570;&#22833;&#30340;&#26465;&#30446;&#26469;&#25554;&#34917;&#32570;&#22833;&#25968;&#25454;&#12290;&#20026;&#20102;&#35828;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#33021;&#21147;&#21644;&#28508;&#22312;&#29992;&#36884;&#65292;&#25105;&#20204;&#22312;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
For many use cases, combining information from different datasets can be of interest to improve a machine learning model's performance, especially when the number of samples from at least one of the datasets is small. However, a potential challenge in such cases is that the features from these datasets are not identical, even though there are some commonly shared features among the datasets. To tackle this challenge, we propose a novel framework called Combine datasets based on Imputation (ComImp). In addition, we propose a variant of ComImp that uses Principle Component Analysis (PCA), PCA-ComImp in order to reduce dimension before combining datasets. This is useful when the datasets have a large number of features that are not shared between them. Furthermore, our framework can also be utilized for data preprocessing by imputing missing data, i.e., filling in the missing entries while combining different datasets. To illustrate the power of the proposed methods and their potential us
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#20449;&#39640;&#25928;&#30340;&#26679;&#26412;&#36716;&#21457;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#25299;&#25169;&#32467;&#26500;&#30340;&#32593;&#32476;&#20013;&#25511;&#21046;FDR&#65292;&#26080;&#38656;&#33410;&#28857;&#30456;&#20114;&#36890;&#20449;p&#20540;&#12290;&#26041;&#27861;&#32463;&#23454;&#39564;&#35777;&#26126;&#65292;&#25317;&#26377;&#21487;&#35777;&#26126;&#30340;&#26377;&#38480;&#26679;&#26412;FDR&#25511;&#21046;&#21644;&#26356;&#24378;&#30340;&#26816;&#27979;&#21151;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.02555</link><description>&lt;p&gt;
&#12298;&#26679;&#26412;&#36716;&#21457;&#65306;&#32593;&#32476;&#20013;&#22522;&#20110;&#26679;&#26412;&#36716;&#21457;&#30340;&#34394;&#35686;&#29575;&#25511;&#21046;&#12299;
&lt;/p&gt;
&lt;p&gt;
Sample-and-Forward: Communication-Efficient Control of the False Discovery Rate in Networks. (arXiv:2210.02555v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.02555
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#20449;&#39640;&#25928;&#30340;&#26679;&#26412;&#36716;&#21457;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#25299;&#25169;&#32467;&#26500;&#30340;&#32593;&#32476;&#20013;&#25511;&#21046;FDR&#65292;&#26080;&#38656;&#33410;&#28857;&#30456;&#20114;&#36890;&#20449;p&#20540;&#12290;&#26041;&#27861;&#32463;&#23454;&#39564;&#35777;&#26126;&#65292;&#25317;&#26377;&#21487;&#35777;&#26126;&#30340;&#26377;&#38480;&#26679;&#26412;FDR&#25511;&#21046;&#21644;&#26356;&#24378;&#30340;&#26816;&#27979;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#26088;&#22312;&#25552;&#20986;&#19968;&#31181;&#22312;&#36890;&#20449;&#38480;&#21046;&#19979;&#25511;&#21046;&#32593;&#32476;&#20013;&#34394;&#35686;&#29575;&#65288;FDR&#65289;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#19988;&#36890;&#20449;&#39640;&#25928;&#30340;&#26679;&#26412;&#36716;&#21457;&#26041;&#27861;&#65292;&#23427;&#26159;Benjamini-Hochberg&#65288;BH&#65289;&#31243;&#24207;&#22312;&#20855;&#26377;&#19968;&#33324;&#25299;&#25169;&#32467;&#26500;&#30340;&#22810;&#36339;&#32593;&#32476;&#20013;&#30340;&#29256;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35777;&#26126;&#20102;&#65292;&#20026;&#20102;&#22312;&#20840;&#23616;FDR&#25511;&#21046;&#32422;&#26463;&#19979;&#33719;&#24471;&#33391;&#22909;&#30340;&#32479;&#35745;&#21151;&#29575;&#65292;&#32593;&#32476;&#20013;&#30340;&#33410;&#28857;&#19981;&#38656;&#35201;&#23558;p&#20540;&#30456;&#20114;&#36890;&#20449;&#12290;&#32771;&#34385;&#21040;&#19968;&#20010;&#24635;&#20849;&#26377;$m$&#20010;p&#20540;&#30340;&#32593;&#32476;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#23545;&#27599;&#20010;&#33410;&#28857;&#36827;&#34892;&#26679;&#26412;&#25277;&#21462;&#65292;&#33719;&#21462;p&#20540;&#30340;&#32463;&#39564;CDF&#65292;&#28982;&#21518;&#21521;&#20854;&#37051;&#23621;&#33410;&#28857;&#36716;&#21457;$\mathcal{O}(\log m)$&#20301;&#12290;&#22312;&#19982;&#21407;&#22987;BH&#31243;&#24207;&#30456;&#21516;&#30340;&#20551;&#35774;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#26377;&#38480;&#26679;&#26412;FDR&#25511;&#21046;&#20197;&#21450;&#31454;&#20105;&#24615;&#30340;&#32463;&#39564;&#26816;&#27979;&#21151;&#29575;&#65292;&#21363;&#20351;&#27599;&#20010;&#33410;&#28857;&#21482;&#26377;&#23569;&#37327;&#26679;&#26412;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;p&#20540;&#28151;&#21512;&#27169;&#22411;&#20551;&#35774;&#19979;&#30340;&#21151;&#29575;&#28176;&#36817;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work concerns controlling the false discovery rate (FDR) in networks under communication constraints. We present sample-and-forward, a flexible and communication-efficient version of the Benjamini-Hochberg (BH) procedure for multihop networks with general topologies. Our method evidences that the nodes in a network do not need to communicate p-values to each other to achieve a decent statistical power under the global FDR control constraint. Consider a network with a total of $m$ p-values, our method consists of first sampling the (empirical) CDF of the p-values at each node and then forwarding $\mathcal{O}(\log m)$ bits to its neighbors. Under the same assumptions as for the original BH procedure, our method has both the provable finite-sample FDR control as well as competitive empirical detection power, even with a few samples at each node. We provide an asymptotic analysis of power under a mixture model assumption on the p-values.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#21644;&#27491;&#21017;&#21270;&#28508;&#21464;&#37327;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#22411;&#30697;&#21305;&#37197;&#24230;&#37327;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#30740;&#31350;&#25968;&#25454;&#30697;&#21644;&#27169;&#22411;&#30697;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#35780;&#20272;&#25311;&#21512;&#27169;&#22411;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2111.00875</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#28508;&#21464;&#37327;&#29983;&#25104;&#27169;&#22411;&#30340;&#30697;&#21305;&#37197;&#24230;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A moment-matching metric for latent variable generative models. (arXiv:2111.00875v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.00875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#21644;&#27491;&#21017;&#21270;&#28508;&#21464;&#37327;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#22411;&#30697;&#21305;&#37197;&#24230;&#37327;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#30740;&#31350;&#25968;&#25454;&#30697;&#21644;&#27169;&#22411;&#30697;&#20043;&#38388;&#30340;&#24046;&#24322;&#26469;&#35780;&#20272;&#25311;&#21512;&#27169;&#22411;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38754;&#23545;&#26080;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#26102;&#65292;&#35780;&#20272;&#25311;&#21512;&#27169;&#22411;&#30340;&#36136;&#37327;&#26159;&#22256;&#38590;&#30340;&#12290;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#22914;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#36890;&#24120;&#20351;&#29992;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#27169;&#22411;&#27604;&#36739;&#25110;&#27491;&#21017;&#21270;&#30340;&#24230;&#37327;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#30697;&#12290;&#20854;&#27010;&#24565;&#26159;&#20351;&#29992;&#30697;&#33539;&#25968;&#65288;&#22914;&#24343;&#32599;&#36125;&#23612;&#20044;&#26031;&#33539;&#25968;&#65289;&#30740;&#31350;&#25968;&#25454;&#30697;&#21644;&#27169;&#22411;&#30697;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#36825;&#20010;&#26032;&#30340;&#24230;&#37327;&#26041;&#27861;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#27491;&#21017;&#21270;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
It can be difficult to assess the quality of a fitted model when facing unsupervised learning problems. Latent variable models, such as variation autoencoders and Gaussian mixture models, are often trained with likelihood-based approaches. In scope of Goodhart's law, when a metric becomes a target it ceases to be a good metric and therefore we should not use likelihood to assess the quality of the fit of these models. The solution we propose is a new metric for model comparison or regularization that relies on moments. The concept is to study the difference between the data moments and the model moments using a matrix norm, such as the Frobenius norm. We show how to use this new metric for model comparison and then for regularization. It is common to draw samples from the fitted distribution when evaluating latent variable models and we show that our proposed metric is faster to compute and has a smaller variance that this alternative. We conclude this article with a proof of concept o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340; DR &#26041;&#27861;&#65292;&#29992;&#20110;&#20013;&#38388;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340; DR &#34920;&#31034;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#20248;&#30340;&#31283;&#20581;&#24615;&#20445;&#35777;&#65292;&#21363;&#20351;&#22312;&#38754;&#20020;&#39640;&#32500;&#28151;&#28102;&#21464;&#37327;&#26102;&#20063;&#33021;&#23454;&#29616;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2110.04924</link><description>&lt;p&gt;
&#39640;&#32500;&#25512;&#26029;&#19979;&#30340;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Inference for Dynamic Treatment Effects. (arXiv:2110.04924v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.04924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340; DR &#26041;&#27861;&#65292;&#29992;&#20110;&#20013;&#38388;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340; DR &#34920;&#31034;&#65292;&#33021;&#22815;&#25552;&#20379;&#26356;&#20248;&#30340;&#31283;&#20581;&#24615;&#20445;&#35777;&#65292;&#21363;&#20351;&#22312;&#38754;&#20020;&#39640;&#32500;&#28151;&#28102;&#21464;&#37327;&#26102;&#20063;&#33021;&#23454;&#29616;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#20272;&#35745;&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#23588;&#20854;&#26159;&#24403;&#38754;&#20020;&#39640;&#32500;&#28151;&#28102;&#21464;&#37327;&#26102;&#12290;&#21452;&#37325;&#31283;&#20581; (DR) &#26041;&#27861;&#22240;&#20854;&#28789;&#27963;&#24615;&#32780;&#25104;&#20026;&#20272;&#35745;&#27835;&#30103;&#25928;&#24212;&#30340;&#26377;&#21147;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20165;&#20851;&#27880;&#39044;&#26399;&#32467;&#26524;&#30340; DR &#20256;&#32479;&#26041;&#27861;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#26368;&#20248;&#32467;&#26524;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340; DR &#26041;&#27861;&#65292;&#29992;&#20110;&#20013;&#38388;&#26465;&#20214;&#32467;&#26524;&#27169;&#22411;&#30340; DR &#34920;&#31034;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#26356;&#20248;&#30340;&#31283;&#20581;&#24615;&#20445;&#35777;&#12290;&#21482;&#35201;&#27599;&#20010;&#26292;&#38706;&#26102;&#38388;&#21644;&#27835;&#30103;&#36335;&#24452;&#37117;&#24688;&#24403;&#22320;&#21442;&#25968;&#21270;&#20102;&#33267;&#23569;&#19968;&#20010;&#36741;&#21161;&#20989;&#25968;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#38754;&#20020;&#39640;&#32500;&#28151;&#28102;&#21464;&#37327;&#26102;&#20063;&#33021;&#23454;&#29616;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20195;&#34920;&#20102;&#19968;&#20010;&#37325;&#22823;&#30340;&#36827;&#27493;&#65292;&#22240;&#20026;&#23427;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#31283;&#20581;&#24615;&#20445;&#35777;&#12290;&#23454;&#29616;&#36825;&#20123;&#32467;&#26524;&#30340;&#20851;&#38190;&#26159;&#25105;&#20204;&#30340;&#26032; DR &#34920;&#31034;&#65292;&#23427;&#22312;&#38656;&#35201;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#26356;&#24369;&#30340;&#20551;&#35774;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#25512;&#26029;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating dynamic treatment effects is a crucial endeavor in causal inference, particularly when confronted with high-dimensional confounders. Doubly robust (DR) approaches have emerged as promising tools for estimating treatment effects due to their flexibility. However, we showcase that the traditional DR approaches that only focus on the DR representation of the expected outcomes may fall short of delivering optimal results. In this paper, we propose a novel DR representation for intermediate conditional outcome models that leads to superior robustness guarantees. The proposed method achieves consistency even with high-dimensional confounders, as long as at least one nuisance function is appropriately parametrized for each exposure time and treatment path. Our results represent a significant step forward as they provide new robustness guarantees. The key to achieving these results is our new DR representation, which offers superior inferential performance while requiring weaker ass
&lt;/p&gt;</description></item><item><title>MRCpy&#26159;&#19968;&#31181;&#29992;&#20110;&#23454;&#29616;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;Python&#24211;&#65292;&#23427;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#21033;&#29992;0-1&#25439;&#22833;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#20998;&#31867;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20123;&#25552;&#20379;&#20102;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2108.01952</link><description>&lt;p&gt;
MRCpy&#65306;&#19968;&#31181;&#29992;&#20110;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;&#24211;
&lt;/p&gt;
&lt;p&gt;
MRCpy: A Library for Minimax Risk Classifiers. (arXiv:2108.01952v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.01952
&lt;/p&gt;
&lt;p&gt;
MRCpy&#26159;&#19968;&#31181;&#29992;&#20110;&#23454;&#29616;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#30340;Python&#24211;&#65292;&#23427;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#21487;&#20197;&#21033;&#29992;0-1&#25439;&#22833;&#24182;&#25552;&#20379;&#20102;&#22810;&#31181;&#20998;&#31867;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20123;&#25552;&#20379;&#20102;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#29616;&#26377;&#30340;&#30417;&#30563;&#20998;&#31867;&#24211;&#37117;&#26159;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#20351;&#29992;&#20195;&#29702;&#25439;&#22833;&#25216;&#26415;&#30340;&#12290;&#26412;&#25991;&#20171;&#32461;MRCpy&#24211;&#65292;&#35813;&#24211;&#23454;&#29616;&#20102;&#22522;&#20110;&#40065;&#26834;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26368;&#23567;&#21270;&#39118;&#38505;&#20998;&#31867;&#22120;&#65288;MRC&#65289;&#65292;&#24182;&#21487;&#21033;&#29992;0-1&#25439;&#22833;&#12290;&#36825;&#31181;&#25216;&#26415;&#20135;&#29983;&#20102;&#35768;&#22810;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#32039;&#23494;&#30340;&#26399;&#26395;&#25439;&#22833;&#30028;&#38480;&#12290;MRCpy&#20026;&#19981;&#21516;&#21464;&#37327;&#30340;MRC&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#25509;&#21475;&#65292;&#24182;&#36981;&#24490;&#27969;&#34892;Python&#24211;&#30340;&#26631;&#20934;&#12290;&#27492;&#22806;&#65292;MRCpy&#36824;&#25552;&#20379;&#20102;&#23454;&#29616;&#19968;&#20123;&#27969;&#34892;&#25216;&#26415;&#30340;&#21151;&#33021;&#65292;&#36825;&#20123;&#25216;&#26415;&#21487;&#20197;&#30475;&#20316;&#26159;MRC&#65292;&#20363;&#22914;L1&#27491;&#21017;&#21270;&#36923;&#36753;&#22238;&#24402;&#65292;0-1&#23545;&#25239;&#24615;&#21644;&#26368;&#22823;&#29109;&#26426;&#12290;&#27492;&#22806;&#65292;MRCpy&#36824;&#23454;&#29616;&#20102;&#26368;&#36817;&#30340;&#29305;&#24449;&#26144;&#23556;&#65292;&#22914;&#20613;&#37324;&#21494;&#65292;ReLU&#21644;&#38408;&#20540;&#29305;&#24449;&#12290;&#35813;&#24211;&#37319;&#29992;&#38754;&#21521;&#23545;&#35937;&#30340;&#26041;&#27861;&#35774;&#35745;&#65292;&#26041;&#20415;&#21327;&#20316;&#32773;&#21644;&#29992;&#25143;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing libraries for supervised classification implement techniques that are based on empirical risk minimization and utilize surrogate losses. We present MRCpy library that implements minimax risk classifiers (MRCs) that are based on robust risk minimization and can utilize 0-1-loss. Such techniques give rise to a manifold of classification methods that can provide tight bounds on the expected loss. MRCpy provides a unified interface for different variants of MRCs and follows the standards of popular Python libraries. The presented library also provides implementation for popular techniques that can be seen as MRCs such as L1-regularized logistic regression, zero-one adversarial, and maximum entropy machines. In addition, MRCpy implements recent feature mappings such as Fourier, ReLU, and threshold features. The library is designed with an object-oriented approach that facilitates collaborators and users.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#27714;&#35299;&#32039;&#33268;Riemann&#27969;&#24418;&#20013;&#36317;&#31163;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#35813;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#35777;&#26126;&#12290;&#35813;&#20272;&#35745;&#22120;&#26159;&#20174;Kontorovic&#23545;&#20598;&#37325;&#26500;&#20844;&#24335;&#20013;&#30340;Connes&#36317;&#31163;&#20844;&#24335;&#25512;&#23548;&#32780;&#26469;&#12290;</title><link>http://arxiv.org/abs/2107.08089</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#27969;&#24418;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Non-Parametric Manifold Learning. (arXiv:2107.08089v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.08089
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#27714;&#35299;&#32039;&#33268;Riemann&#27969;&#24418;&#20013;&#36317;&#31163;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20986;&#20102;&#35813;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#35777;&#26126;&#12290;&#35813;&#20272;&#35745;&#22120;&#26159;&#20174;Kontorovic&#23545;&#20598;&#37325;&#26500;&#20844;&#24335;&#20013;&#30340;Connes&#36317;&#31163;&#20844;&#24335;&#25512;&#23548;&#32780;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#20272;&#35745;&#30340;Laplace-Beltrami&#31639;&#23376;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#19968;&#20010;&#32039;&#33268;&#30340;Riemann&#27969;&#24418;&#20013;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#36890;&#36807;&#22270;&#25289;&#26222;&#25289;&#26031;&#20272;&#35745;&#30340;&#35889;&#35823;&#24046;&#21644;&#20960;&#20309;&#29305;&#24615;&#26469;&#19978;&#30028;&#20272;&#35745;&#27969;&#24418;&#36317;&#31163;&#30340;&#35823;&#24046;&#65292;&#25110;&#32773;&#26356;&#20934;&#30830;&#22320;&#35828;&#26159;&#36817;&#24180;&#26469;&#22312;&#38750;&#20132;&#25442;&#20960;&#20309;&#20013;&#34987;&#20851;&#27880;&#30340;&#19968;&#31867;&#27969;&#24418;&#36317;&#31163;&#12290;&#27492;&#32467;&#26524;&#25512;&#20986;&#20102;&#65288;&#26410;&#25130;&#21462;&#30340;&#65289;&#27969;&#24418;&#36317;&#31163;&#30340;&#19968;&#33268;&#24615;&#35777;&#26126;&#12290;&#35813;&#20272;&#35745;&#22120;&#19982;Wasserstein&#36317;&#31163;&#30340;Kontorovic&#23545;&#20598;&#37325;&#26500;&#20844;&#24335;&#20013;&#30340;Connes&#36317;&#31163;&#20844;&#24335;&#26159;&#30456;&#20284;&#30340;&#65292;&#20107;&#23454;&#19978;&#26159;&#20174;&#21518;&#32773;&#30340;&#25910;&#25947;&#24615;&#36136;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an estimator for distances in a compact Riemannian manifold based on graph Laplacian estimates of the Laplace-Beltrami operator. We upper bound the error in the estimate of manifold distances, or more precisely an estimate of a spectrally truncated variant of manifold distance of interest in non-commutative geometry (cf. [Connes and Suijelekom, 2020]), in terms of spectral errors in the graph Laplacian estimates and, implicitly, several geometric properties of the manifold. A consequence is a proof of consistency for (untruncated) manifold distances. The estimator resembles, and in fact its convergence properties are derived from, a special case of the Kontorovic dual reformulation of Wasserstein distance known as Connes' Distance Formula.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;GraSP-RL&#26694;&#26550;&#65292;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#20197;&#35299;&#20915;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#20013;&#29366;&#24577;&#31354;&#38388;&#38590;&#20197;&#22788;&#29702;&#12289;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2009.03836</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#21270;&#23398;&#20064;&#29983;&#20135;&#35745;&#21010;&#38382;&#39064;&#35843;&#24230;&#22120;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks-based Scheduler for Production planning problems using Reinforcement Learning. (arXiv:2009.03836v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.03836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;GraSP-RL&#26694;&#26550;&#65292;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#65292;&#20197;&#35299;&#20915;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#20013;&#29366;&#24577;&#31354;&#38388;&#38590;&#20197;&#22788;&#29702;&#12289;&#27867;&#21270;&#33021;&#21147;&#36739;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#20294;&#23545;&#20110;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#65292;&#24378;&#21270;&#23398;&#20064;&#36890;&#24120;&#20351;&#29992;&#30690;&#37327;&#21270;&#26426;&#22120;&#29305;&#24449;&#20316;&#20026;&#29366;&#24577;&#31354;&#38388;&#12290;&#36825;&#31181;&#26041;&#27861;&#23384;&#22312;&#19977;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;&#65288;1&#65289;&#26426;&#22120;&#21333;&#20803;&#21644;&#20316;&#19994;&#24207;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#27809;&#26377;&#23436;&#20840;&#25429;&#33719;&#65292;&#65288;2&#65289;&#29366;&#24577;&#31354;&#38388;&#38543;&#30528;&#26426;&#22120;/&#20316;&#19994;&#25968;&#37327;&#30340;&#22686;&#21152;&#21576;&#25351;&#25968;&#22686;&#38271;&#65292;&#65288;3&#65289;&#20195;&#29702;&#30340;&#27867;&#21270;&#33021;&#21147;&#23384;&#22312;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#8212;&#8212;GraSP-RL&#65292;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24378;&#21270;&#23398;&#20064;&#29983;&#20135;&#35745;&#21010;&#38382;&#39064;&#35843;&#24230;&#22120;&#12290;&#23427;&#23558;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#34920;&#31034;&#20026;&#22270;&#24418;&#65292;&#24182;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#25552;&#21462;&#29305;&#24449;&#26469;&#35757;&#32451;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#12290;&#34429;&#28982;&#22270;&#24418;&#26412;&#36523;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#65292;&#20294;&#20351;&#29992;GNN&#25552;&#21462;&#30340;&#29305;&#24449;&#22312;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#24403;&#21069;&#29983;&#20135;&#29366;&#24577;&#30340;&#20016;&#23500;&#32534;&#30721;&#65292;&#28982;&#21518;&#34987;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#29992;&#20110;&#36873;&#25321;&#19979;&#19968;&#20010;&#20316;&#19994;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#35843;&#24230;&#38382;&#39064;&#35270;&#20026;&#19968;&#20010;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#27969;&#38382;&#39064;&#65292;&#20351;&#29992;&#22238;&#28335;&#26041;&#27861;&#23545;&#27492;&#36827;&#34892;&#27714;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) is increasingly adopted in job shop scheduling problems (JSSP). But RL for JSSP is usually done using a vectorized representation of machine features as the state space. It has three major problems: (1) the relationship between the machine units and the job sequence is not fully captured, (2) exponential increase in the size of the state space with increasing machines/jobs, and (3) the generalization of the agent to unseen scenarios. We present a novel framework - GraSP-RL, GRAph neural network-based Scheduler for Production planning problems using Reinforcement Learning. It represents JSSP as a graph and trains the RL agent using features extracted using a graph neural network (GNN). While the graph is itself in the non-euclidean space, the features extracted using the GNNs provide a rich encoding of the current production state in the euclidean space, which is then used by the RL agent to select the next job. Further, we cast the scheduling problem as a de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#34701;&#21512;&#31639;&#27861;&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#22312;&#19981;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#8220;&#21333;&#27425;&#8221;&#30693;&#35782;&#36801;&#31227;&#65292;&#24182;&#19988;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#21644;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#27604;&#31616;&#21333;&#24179;&#22343;&#21644;&#38598;&#25104;&#27169;&#22411;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/1910.05653</link><description>&lt;p&gt;
&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#27169;&#22411;&#34701;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model Fusion via Optimal Transport. (arXiv:1910.05653v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.05653
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#34701;&#21512;&#31639;&#27861;&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#22312;&#19981;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#8220;&#21333;&#27425;&#8221;&#30693;&#35782;&#36801;&#31227;&#65292;&#24182;&#19988;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#21644;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#27604;&#31616;&#21333;&#24179;&#22343;&#21644;&#38598;&#25104;&#27169;&#22411;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#32467;&#21512;&#19981;&#21516;&#30340;&#27169;&#22411;&#26159;&#19968;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#33539;&#20363;&#12290;&#23613;&#31649;&#26368;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#24418;&#25104;&#19968;&#20010;&#27169;&#22411;&#38598;&#21512;&#24182;&#24179;&#22343;&#23427;&#20204;&#30340;&#21508;&#33258;&#39044;&#27979;&#65292;&#20294;&#30001;&#20110;&#36164;&#28304;&#38480;&#21046;&#65288;&#20197;&#20869;&#23384;&#21644;&#35745;&#31639;&#30340;&#26041;&#24335;&#21576;&#32447;&#24615;&#22686;&#38271;&#20110;&#27169;&#22411;&#25968;&#65289;&#65292;&#36825;&#31181;&#26041;&#27861;&#24120;&#24120;&#26080;&#27861;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23618;&#27425;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#34701;&#21512;&#31639;&#27861;&#65292;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#26469;&#65288;&#36719;&#65289;&#23545;&#40784;&#27169;&#22411;&#20013;&#30340;&#31070;&#32463;&#20803;&#65292;&#28982;&#21518;&#24179;&#22343;&#23427;&#20204;&#30340;&#30456;&#20851;&#21442;&#25968;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#21487;&#20197;&#22312;&#24322;&#26500;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#19978;&#65292;&#25104;&#21151;&#22320;&#23454;&#29616;&#8220;&#21333;&#27425;&#8221;&#30693;&#35782;&#36801;&#31227;&#65288;&#21363;&#19981;&#38656;&#35201;&#20219;&#20309;&#37325;&#26032;&#35757;&#32451;&#65289;&#22312;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#12290;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#21644;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#31034;&#33539;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#31616;&#21333;&#24179;&#22343;&#20197;&#21450;&#22914;&#20309;&#22312;&#26631;&#20934;&#21367;&#31215;&#32593;&#32476;&#65288;&#22914;VGG11&#65289;&#12289;&#27531;&#24046;&#32593;&#32476;&#19978;&#36827;&#34892;&#24555;&#36895;&#20248;&#21270;&#26367;&#20195;&#38598;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining different models is a widely used paradigm in machine learning applications. While the most common approach is to form an ensemble of models and average their individual predictions, this approach is often rendered infeasible by given resource constraints in terms of memory and computation, which grow linearly with the number of models. We present a layer-wise model fusion algorithm for neural networks that utilizes optimal transport to (soft-) align neurons across the models before averaging their associated parameters.  We show that this can successfully yield "one-shot" knowledge transfer (i.e, without requiring any retraining) between neural networks trained on heterogeneous non-i.i.d. data. In both i.i.d. and non-i.i.d. settings , we illustrate that our approach significantly outperforms vanilla averaging, as well as how it can serve as an efficient replacement for the ensemble with moderate fine-tuning, for standard convolutional networks (like VGG11), residual networks
&lt;/p&gt;</description></item></channel></rss>