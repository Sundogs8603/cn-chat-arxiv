<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#20248;&#21270;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz&#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;&#26174;&#24335;&#20248;&#21270;&#21644;&#38544;&#24335;&#20248;&#21270;&#26159;&#20004;&#31181;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21516;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2306.09338</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20248;&#21270;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding Optimization of Deep Learning. (arXiv:2306.09338v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09338
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#20248;&#21270;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz&#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;&#26174;&#24335;&#20248;&#21270;&#21644;&#38544;&#24335;&#20248;&#21270;&#26159;&#20004;&#31181;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21516;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20248;&#21270;&#29702;&#35770;&#65292;&#20027;&#35201;&#20851;&#27880;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#38382;&#39064;&#25152;&#24102;&#26469;&#30340;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#38477;&#20302;&#21644;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#31561;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz &#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#26469;&#20998;&#26512;&#36825;&#20004;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#24110;&#21161;&#29702;&#35299;&#24403;&#21069;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#20998;&#20026;&#26174;&#24335;&#20248;&#21270;&#26041;&#27861;&#21644;&#38544;&#24335;&#20248;&#21270;&#26041;&#27861;&#12290;&#26174;&#24335;&#20248;&#21270;&#26041;&#27861;&#28041;&#21450;&#30452;&#25509;&#25805;&#20316;&#20248;&#21270;&#22120;&#21442;&#25968;&#65292;&#21253;&#25324;&#26435;&#37325;&#12289;&#26799;&#24230;&#12289;&#23398;&#20064;&#29575;&#21644;&#26435;&#37325;&#34928;&#20943;&#31561;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38544;&#24335;&#20248;&#21270;&#26041;&#27861;&#20391;&#37325;&#20110;&#36890;&#36807;&#22686;&#24378;&#32593;&#32476;&#27169;&#22359;&#65288;&#22914;&#27531;&#24046;&#24555;&#25463;&#26041;&#24335;&#12289;&#26631;&#20934;&#21270;&#26041;&#27861;&#12289;&#27880;&#24847;&#26426;&#21046;&#21644;&#28608;&#27963;&#65289;&#26469;&#25913;&#21892;&#32593;&#32476;&#25972;&#20307;&#24418;&#21183;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#65292;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#26356;&#22909;&#22320;&#20102;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a comprehensive understanding of optimization in deep learning, with a primary focus on the challenges of gradient vanishing and gradient exploding, which normally lead to diminished model representational ability and training instability, respectively. We analyze these two challenges through several strategic measures, including the improvement of gradient flow and the imposition of constraints on a network's Lipschitz constant. To help understand the current optimization methodologies, we categorize them into two classes: explicit optimization and implicit optimization. Explicit optimization methods involve direct manipulation of optimizer parameters, including weight, gradient, learning rate, and weight decay. Implicit optimization methods, by contrast, focus on improving the overall landscape of a network by enhancing its modules, such as residual shortcuts, normalization methods, attention mechanisms, and activations. In this article, we provide an in-depth a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#32858;&#31867;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#31867;&#26465;&#20214;&#19979;&#25552;&#20379;&#31867;&#21035;&#26465;&#20214;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#38024;&#23545;&#22810;&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#20013;&#32463;&#39564;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.09335</link><description>&lt;p&gt;
&#22810;&#31867;&#26465;&#20214;&#19979;&#30340;&#31867;&#21035;&#26465;&#20214;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Class-Conditional Conformal Prediction With Many Classes. (arXiv:2306.09335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09335
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#32858;&#31867;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#31867;&#26465;&#20214;&#19979;&#25552;&#20379;&#31867;&#21035;&#26465;&#20214;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#38024;&#23545;&#22810;&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#20013;&#32463;&#39564;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#25552;&#20379;&#36793;&#32536;&#35206;&#30422;&#20445;&#35777;&#65292;&#36825;&#24847;&#21619;&#30528;&#23545;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#27979;&#35797;&#28857;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#21512;&#20197;&#29992;&#25143;&#36873;&#25321;&#30340;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#22312;&#35768;&#22810;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#33719;&#24471;&#26356;&#24378;&#30340;&#20445;&#35777;&#8212;&#8212;&#23545;&#20110;&#29305;&#23450;&#31867;&#21035;&#30340;&#27979;&#35797;&#28857;&#65292;&#39044;&#27979;&#38598;&#20197;&#30456;&#21516;&#30340;&#29992;&#25143;&#36873;&#25321;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#29616;&#26377;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#22312;&#27599;&#20010;&#31867;&#21035;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19981;&#20339;&#65292;&#32780;&#36825;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24448;&#24448;&#26159;&#22823;&#37327;&#31867;&#21035;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#32858;&#31867;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#23427;&#23558;&#20855;&#26377;&#8220;&#30456;&#20284;&#8221;&#31526;&#21512;&#24615;&#20998;&#25968;&#30340;&#31867;&#21035;&#32858;&#31867;&#22312;&#19968;&#36215;&#65292;&#28982;&#21518;&#22312;&#32858;&#31867;&#32423;&#21035;&#19978;&#25191;&#34892;&#31526;&#21512;&#24615;&#39044;&#27979;&#12290;&#22312;&#38024;&#23545;&#22810;&#20010;&#65288;&#22810;&#36798;1000&#65289;&#31867;&#21035;&#30340;&#22235;&#20010;&#22270;&#20687;&#25968;&#25454;&#38598;&#30340;&#32463;&#39564;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#32858;&#31867;&#31526;&#21512;&#24615;&#36890;&#24120;&#22312;&#31867;&#26465;&#20214;&#35206;&#30422;&#21644;&#38598;&#21512;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-chosen probability. In many classification problems, we would like to obtain a stronger guarantee -- that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. Existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction, which clusters together classes that have "similar" conformal scores and then performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#24471;&#20998;&#21305;&#37197;&#31639;&#27861;&#22312;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#30340;&#20998;&#24067;&#19978;&#30340;&#32479;&#35745;&#20195;&#20215;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.09332</link><description>&lt;p&gt;
Fit Like You Sample: &#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains. (arXiv:2306.09332v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#24471;&#20998;&#21305;&#37197;&#31639;&#27861;&#22312;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#30340;&#20998;&#24067;&#19978;&#30340;&#32479;&#35745;&#20195;&#20215;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24471;&#20998;&#21305;&#37197;&#26159;&#19968;&#31181;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20854;&#21442;&#25968;&#21270;&#20026;&#27604;&#20363;&#24120;&#25968;&#65288;&#20363;&#22914;&#65292;&#33021;&#37327;&#22522;&#27169;&#22411;&#65289;&#12290;&#20854;&#24605;&#24819;&#26159;&#25311;&#21512;&#20998;&#24067;&#30340;&#24471;&#20998;&#65292;&#32780;&#19981;&#26159;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#35780;&#20272;&#27604;&#20363;&#24120;&#25968;&#30340;&#38656;&#27714;&#12290;&#34429;&#28982;&#36825;&#20855;&#26377;&#26126;&#26174;&#30340;&#31639;&#27861;&#20248;&#21183;&#65292;&#20294;&#32479;&#35745;&#20195;&#20215;&#21487;&#33021;&#24456;&#39640;&#65306;Koehler&#31561;&#20154;&#30340;&#26368;&#26032;&#24037;&#20316;&#34920;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36739;&#24046;&#31561;&#21608;&#24615;&#36136;&#65288;&#36739;&#22823;&#30340;Poincare&#25110;&#23545;&#25968;Sobolev&#24120;&#25968;&#65289;&#30340;&#20998;&#24067;&#65292;&#24471;&#20998;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29575;&#26126;&#26174;&#20302;&#20110;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#33258;&#28982;&#23454;&#38469;&#30340;&#20998;&#24067;&#65292;&#20363;&#22914;&#19968;&#32500;&#20013;&#30340;&#20004;&#20010;&#39640;&#26031;&#20998;&#24067;&#28151;&#21512;&#29289;&#31561;&#22810;&#23792;&#20998;&#24067;&#65292;&#20855;&#26377;&#36739;&#24046;&#30340;Poincar&#233;&#24120;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#24847;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#19982;&#35797;&#22270;&#25311;&#21512;$\frac{\mathcal{O} p}{p}$&#30340;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#20043;&#38388;&#30340;&#23494;&#20999;&#20851;&#31995;&#12290;&#22914;&#26524;$\mathcal{L}$&#30340;&#29305;&#24449;&#21521;&#37327;&#19981;&#20381;&#36182;&#20110;$p$&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#30340;&#26679;&#26412;&#39640;&#25928;&#24191;&#20041;&#24471;&#20998;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score matching is an approach to learning probability distributions parametrized up to a constant of proportionality (e.g. Energy-Based Models). The idea is to fit the score of the distribution, rather than the likelihood, thus avoiding the need to evaluate the constant of proportionality. While there's a clear algorithmic benefit, the statistical "cost'' can be steep: recent work by Koehler et al. 2022 showed that for distributions that have poor isoperimetric properties (a large Poincar\'e or log-Sobolev constant), score matching is substantially statistically less efficient than maximum likelihood. However, many natural realistic distributions, e.g. multimodal distributions as simple as a mixture of two Gaussians in one dimension -- have a poor Poincar\'e constant.  In this paper, we show a close connection between the mixing time of an arbitrary Markov process with generator $\mathcal{L}$ and a generalized score matching loss that tries to fit $\frac{\mathcal{O} p}{p}$. If $\mathca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#38543;&#26426;&#21464;&#37327;&#23614;&#37096;&#30340;&#31995;&#32479;&#24615;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#23614;&#37096;&#28176;&#36817;&#30340;&#20195;&#25968;&#26469;&#22788;&#29702;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#30340;&#24212;&#29992;&#12290;&#35813;&#20195;&#25968;&#36816;&#31639;&#22312;&#21152;&#27861;&#21644;&#20056;&#27861;&#19979;&#26159;&#23553;&#38381;&#30340;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#27604;&#29575;&#65292;&#30452;&#25509;&#20174;&#23450;&#20041;&#20013;&#37325;&#29616;&#22823;&#22810;&#25968;&#32479;&#35745;&#20998;&#24067;&#30340;&#23614;&#37096;&#12290;</title><link>http://arxiv.org/abs/2306.09262</link><description>&lt;p&gt;
&#27010;&#29575;&#32534;&#31243;&#30340;&#37325;&#23614;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Heavy-Tailed Algebra for Probabilistic Programming. (arXiv:2306.09262v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#38543;&#26426;&#21464;&#37327;&#23614;&#37096;&#30340;&#31995;&#32479;&#24615;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#23614;&#37096;&#28176;&#36817;&#30340;&#20195;&#25968;&#26469;&#22788;&#29702;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#30340;&#24212;&#29992;&#12290;&#35813;&#20195;&#25968;&#36816;&#31639;&#22312;&#21152;&#27861;&#21644;&#20056;&#27861;&#19979;&#26159;&#23553;&#38381;&#30340;&#65292;&#24182;&#33021;&#22815;&#22788;&#29702;&#27604;&#29575;&#65292;&#30452;&#25509;&#20174;&#23450;&#20041;&#20013;&#37325;&#29616;&#22823;&#22810;&#25968;&#32479;&#35745;&#20998;&#24067;&#30340;&#23614;&#37096;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20256;&#36882;&#22122;&#22768;&#30340;&#27010;&#29575;&#27169;&#22411;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#38500;&#38750;&#22522;&#30784;&#20998;&#24067;&#30340;&#23614;&#37096;&#24471;&#21040;&#36866;&#24403;&#26657;&#20934;&#65292;&#21542;&#21017;&#36825;&#31181;&#26041;&#27861;&#24448;&#24448;&#19981;&#33021;&#20934;&#30830;&#25429;&#25417;&#23614;&#37096;&#34892;&#20026;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#32570;&#38519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#24615;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#38543;&#26426;&#21464;&#37327;&#30340;&#23614;&#37096;&#65292;&#24182;&#38416;&#36848;&#20102;&#22914;&#20309;&#22312;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#32534;&#35793;&#22120;&#30340;&#38745;&#24577;&#20998;&#26512;&#65288;&#22312;&#32472;&#21046;&#26679;&#26412;&#20043;&#21069;&#65289;&#30340;&#36807;&#31243;&#20013;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#12290;&#20026;&#20102;&#34920;&#24449;&#23614;&#37096;&#22312;&#21508;&#31181;&#36816;&#31639;&#19979;&#30340;&#21464;&#21270;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#20195;&#25968;&#65292;&#23427;&#20316;&#29992;&#20110;&#19968;&#20010;&#19977;&#21442;&#25968;&#23614;&#37096;&#28176;&#36817;&#30340;&#23478;&#26063;&#19978;&#65292;&#23427;&#22522;&#20110;&#24191;&#20041;&#20285;&#29595;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20195;&#25968;&#36816;&#31639;&#22312;&#21152;&#27861;&#21644;&#20056;&#27861;&#19979;&#26159;&#23553;&#38381;&#30340;&#65307;&#23427;&#20204;&#33021;&#22815;&#21306;&#20998;&#19981;&#21516;&#23610;&#24230;&#30340;&#20122;&#39640;&#26031;&#20989;&#25968;&#65307;&#24182;&#19988;&#23427;&#20204;&#22788;&#29702;&#27604;&#29575;&#36275;&#22815;&#22909;&#65292;&#20197;&#30452;&#25509;&#20174;&#23427;&#20204;&#30340;&#23450;&#20041;&#20013;&#37325;&#29616;&#22823;&#22810;&#25968;&#37325;&#35201;&#30340;&#32479;&#35745;&#20998;&#24067;&#30340;&#23614;&#37096;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the successes of probabilistic models based on passing noise through neural networks, recent work has identified that such methods often fail to capture tail behavior accurately, unless the tails of the base distribution are appropriately calibrated. To overcome this deficiency, we propose a systematic approach for analyzing the tails of random variables, and we illustrate how this approach can be used during the static analysis (before drawing samples) pass of a probabilistic programming language compiler. To characterize how the tails change under various operations, we develop an algebra which acts on a three-parameter family of tail asymptotics and which is based on the generalized Gamma distribution. Our algebraic operations are closed under addition and multiplication; they are capable of distinguishing sub-Gaussians with differing scales; and they handle ratios sufficiently well to reproduce the tails of most important statistical distributions directly from their defini
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#38024;&#23545;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#35774;&#35745;&#20102;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#31181;&#20027;&#27969;&#37319;&#26679;&#22120;&#30340;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#39640;&#20102;&#24635;&#27493;&#25968;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2306.09251</link><description>&lt;p&gt;
&#38754;&#21521;&#25193;&#25955;&#24335;&#29983;&#25104;&#27169;&#22411;&#30340;&#38750;&#28176;&#36827;&#24555;&#36895;&#25910;&#25947;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative Models. (arXiv:2306.09251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#38024;&#23545;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#35774;&#35745;&#20102;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#20004;&#31181;&#20027;&#27969;&#37319;&#26679;&#22120;&#30340;&#26032;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25552;&#39640;&#20102;&#24635;&#27493;&#25968;&#19982;&#25910;&#25947;&#36895;&#24230;&#30340;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#23398;&#20064;&#21453;&#36716;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#36807;&#31243;&#23558;&#22122;&#38899;&#36716;&#21270;&#20026;&#26032;&#25968;&#25454;&#23454;&#20363;&#65292;&#22312;&#24403;&#20195;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#20013;&#24050;&#25104;&#20026;&#22522;&#30707;&#12290;&#34429;&#28982;&#23427;&#20204;&#30340;&#23454;&#29992;&#24615;&#29616;&#22312;&#24050;&#34987;&#24191;&#27867;&#35748;&#21487;&#65292;&#20294;&#20854;&#29702;&#35770;&#22522;&#30784;&#20173;&#28982;&#19981;&#22815;&#25104;&#29087;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#38750;&#28176;&#36827;&#29702;&#35770;&#65292;&#20197;&#29702;&#35299;&#31163;&#25955;&#26102;&#38388;&#19979;&#25193;&#25955;&#27169;&#22411;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#65288;Stein&#65289;&#24471;&#20998;&#20989;&#25968;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#38024;&#23545;&#19968;&#31181;&#27969;&#34892;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#22120;&#65288;&#22522;&#20110;&#27010;&#29575;&#27969;ODE&#65289;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982; $T$&#65288;&#24635;&#27493;&#25968;&#65289;&#25104;&#27604;&#20363;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#25913;&#36827;&#20102;&#36807;&#21435;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#21478;&#19968;&#31181;&#20027;&#27969;&#30340;&#38543;&#26426;&#37319;&#26679;&#22120;&#65288;&#21363;&#19968;&#31181;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#65289;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#19968;&#20010;&#19982; $1/\sqrt{T}$ &#25104;&#27604;&#20363;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#29702;&#35770;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#23545;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#21482;&#20316;&#20986;&#26368;&#23567;&#30340;&#20551;&#35774;&#65288;&#20363;&#22914;&#65292;&#27809;&#26377;&#24179;&#28369;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models, which convert noise into new data instances by learning to reverse a Markov diffusion process, have become a cornerstone in contemporary generative modeling. While their practical power has now been widely recognized, the theoretical underpinnings remain far from mature. In this work, we develop a suite of non-asymptotic theory towards understanding the data generation process of diffusion models in discrete time, assuming access to reliable estimates of the (Stein) score functions. For a popular deterministic sampler (based on the probability flow ODE), we establish a convergence rate proportional to $1/T$ (with $T$ the total number of steps), improving upon past results; for another mainstream stochastic sampler (i.e., a type of the denoising diffusion probabilistic model (DDPM)), we derive a convergence rate proportional to $1/\sqrt{T}$, matching the state-of-the-art theory. Our theory imposes only minimal assumptions on the target data distribution (e.g., no smoot
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#25511;&#21046;&#26410;&#30693;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;model-based RL&#38382;&#39064;&#65292;&#38656;&#35201;&#25214;&#20986;&#21738;&#20123;&#21442;&#25968;&#26368;&#20851;&#38190;&#65292;&#24182;&#38024;&#23545;&#36825;&#20123;&#21442;&#25968;&#26368;&#20248;&#21270;&#25506;&#32034;&#31574;&#30053;&#26469;&#26368;&#23567;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.09210</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#31995;&#32479;&#27169;&#22411;&#19979;&#30340;&#27169;&#22411;&#22522;RL&#20248;&#21270;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Optimal Exploration for Model-Based RL in Nonlinear Systems. (arXiv:2306.09210v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#25511;&#21046;&#26410;&#30693;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;model-based RL&#38382;&#39064;&#65292;&#38656;&#35201;&#25214;&#20986;&#21738;&#20123;&#21442;&#25968;&#26368;&#20851;&#38190;&#65292;&#24182;&#38024;&#23545;&#36825;&#20123;&#21442;&#25968;&#26368;&#20248;&#21270;&#25506;&#32034;&#31574;&#30053;&#26469;&#26368;&#23567;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24378;&#21270;&#23398;&#20064;&#21644;&#25511;&#21046;&#29702;&#35770;&#20013;&#65292;&#23398;&#20064;&#25511;&#21046;&#26410;&#30693;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#26159;&#19968;&#20010;&#26681;&#26412;&#24615;&#30340;&#38382;&#39064;&#12290;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#26159;&#39318;&#20808;&#25506;&#32034;&#29615;&#22659;&#65288;&#25506;&#32034;&#65289;&#65292;&#23398;&#20064;&#20934;&#30830;&#30340;&#27169;&#22411;&#65288;&#31995;&#32479;&#35782;&#21035;&#65289;&#65292;&#28982;&#21518;&#22312;&#27492;&#20272;&#35745;&#30340;&#31995;&#32479;&#19978;&#35745;&#31639;&#26368;&#23567;&#25104;&#26412;&#30340;&#26368;&#20248;&#25511;&#21046;&#22120;&#65288;&#31574;&#30053;&#20248;&#21270;&#65289;&#12290;&#34429;&#28982;&#29616;&#26377;&#30340;&#24037;&#20316;&#24050;&#32463;&#34920;&#26126;&#23398;&#20064;&#24471;&#21040;&#19968;&#33268;&#22909;&#30340;&#31995;&#32479;&#27169;&#22411;&#26159;&#21487;&#33021;&#30340; ~\citep{mania2020active}~ &#65292;&#20294;&#26159;&#22312;&#23454;&#36341;&#20013;&#65292;&#22914;&#26524;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#23454;&#38469;&#31995;&#32479;&#19978;&#23398;&#20064;&#19968;&#20010;&#20302;&#25104;&#26412;&#30340;&#20248;&#31168;&#25511;&#21046;&#22120;&#65292;&#21017;&#26576;&#20123;&#31995;&#32479;&#21442;&#25968;&#21487;&#33021;&#27604;&#20854;&#20182;&#21442;&#25968;&#26356;&#20026;&#20851;&#38190;&#65292;&#22240;&#27492;&#25105;&#20204;&#38656;&#35201;&#23558;&#25506;&#32034;&#38598;&#20013;&#22312;&#23398;&#20064;&#36825;&#20123;&#21442;&#25968;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning to control unknown nonlinear dynamical systems is a fundamental problem in reinforcement learning and control theory. A commonly applied approach is to first explore the environment (exploration), learn an accurate model of it (system identification), and then compute an optimal controller with the minimum cost on this estimated system (policy optimization). While existing work has shown that it is possible to learn a uniformly good model of the system~\citep{mania2020active}, in practice, if we aim to learn a good controller with a low cost on the actual system, certain system parameters may be significantly more critical than others, and we therefore ought to focus our exploration on learning such parameters.  In this work, we consider the setting of nonlinear dynamical systems and seek to formally quantify, in such settings, (a) which parameters are most relevant to learning a good controller, and (b) how we can best explore so as to minimize uncertainty in such parameters.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#30340;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#29992;&#20110;&#39640;&#26031;&#21644;&#32447;&#24615;&#36172;&#21338;&#26426;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#20215;&#20540;&#20197;&#21450;&#23545;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#30340;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2306.09136</link><description>&lt;p&gt;
&#23545;&#25968;&#36125;&#21494;&#26031;&#36951;&#25022;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Logarithmic Bayes Regret Bounds. (arXiv:2306.09136v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09136
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#30340;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#29992;&#20110;&#39640;&#26031;&#21644;&#32447;&#24615;&#36172;&#21338;&#26426;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#20215;&#20540;&#20197;&#21450;&#23545;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#23548;&#20986;&#20102;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#12290;&#23545;&#20110;&#39640;&#26031;&#36172;&#21338;&#26426;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;$O(c_h \log^2 n)$&#30340;&#36793;&#30028;&#65292;&#20854;&#20013;$c_h$&#26159;&#19982;&#20808;&#39564;&#30456;&#20851;&#30340;&#24120;&#37327;&#12290;&#36825;&#19982;Lai&#65288;1987&#65289;&#30340;&#28176;&#36817;&#19979;&#38480;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#26377;&#25152;&#19981;&#21516;&#65292;&#19988;&#31616;&#21333;&#19988;&#26222;&#36941;&#12290;&#20026;&#20102;&#26174;&#31034;&#19968;&#33324;&#24615;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#25216;&#26415;&#24212;&#29992;&#20110;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#30340;&#20215;&#20540;&#65292;&#26082;&#21487;&#20197;&#20316;&#20026;&#30446;&#26631;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#20256;&#36882;&#32473;&#23398;&#20064;&#32773;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;&#23427;&#20204;&#26174;&#30528;&#25913;&#21892;&#20102;&#29616;&#26377;&#30340;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#65292;&#23613;&#31649;&#23384;&#22312;&#19979;&#38480;&#65292;&#20294;&#24050;&#25104;&#20026;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive the first finite-time logarithmic regret bounds for Bayesian bandits. For Gaussian bandits, we obtain a $O(c_h \log^2 n)$ bound, where $c_h$ is a prior-dependent constant. This matches the asymptotic lower bound of Lai (1987). Our proofs mark a technical departure from prior works, and are simple and general. To show generality, we apply our technique to linear bandits. Our bounds shed light on the value of the prior in the Bayesian setting, both in the objective and as a side information given to the learner. They significantly improve the $\tilde{O}(\sqrt{n})$ bounds, that despite the existing lower bounds, have become standard in the literature.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#39044;&#27979;PAC-Bayesian&#39118;&#38505;&#30028;&#38480;&#65292;&#23427;&#21487;&#20197;&#38543;&#30528;&#32467;&#26500;&#21270;&#31034;&#20363;&#30340;&#25968;&#37327;&#21644;&#22823;&#23567;&#30340;&#21464;&#21270;&#32780;&#36827;&#34892;&#27867;&#21270;&#65292;&#20026;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#24314;&#31435;&#32467;&#26500;&#21270;&#39044;&#27979;&#30340;&#27867;&#21270;&#30028;&#38480;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;</title><link>http://arxiv.org/abs/2306.09112</link><description>&lt;p&gt;
&#20851;&#20110;&#32467;&#26500;&#39044;&#27979;&#20013;&#30340;&#35748;&#35777;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Certified Generalization in Structured Prediction. (arXiv:2306.09112v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09112
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#39044;&#27979;PAC-Bayesian&#39118;&#38505;&#30028;&#38480;&#65292;&#23427;&#21487;&#20197;&#38543;&#30528;&#32467;&#26500;&#21270;&#31034;&#20363;&#30340;&#25968;&#37327;&#21644;&#22823;&#23567;&#30340;&#21464;&#21270;&#32780;&#36827;&#34892;&#27867;&#21270;&#65292;&#20026;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#24314;&#31435;&#32467;&#26500;&#21270;&#39044;&#27979;&#30340;&#27867;&#21270;&#30028;&#38480;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#39044;&#27979;&#20013;&#65292;&#30446;&#26631;&#23545;&#35937;&#20855;&#26377;&#20016;&#23500;&#30340;&#20869;&#37096;&#32467;&#26500;&#65292;&#36825;&#31181;&#32467;&#26500;&#26080;&#27861;&#20998;&#35299;&#20026;&#29420;&#31435;&#30340;&#32452;&#20214;&#65292;&#24182;&#36829;&#21453;&#20102;&#24120;&#35265;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#20551;&#35774;&#12290;&#36825;&#19968;&#25361;&#25112;&#22312;&#24212;&#29992;&#31243;&#24207;&#20013;&#34920;&#29616;&#20026;&#25351;&#25968;&#32423;&#30340;&#36755;&#20986;&#31354;&#38388;&#65292;&#22914;&#22270;&#20687;&#20998;&#21106;&#25110;&#22330;&#26223;&#22270;&#29983;&#25104;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#39044;&#27979;PAC-Bayesian&#39118;&#38505;&#30028;&#38480;&#65292;&#20854;&#20013;&#27867;&#21270;&#36895;&#29575;&#19981;&#20165;&#38543;&#30528;&#32467;&#26500;&#21270;&#31034;&#20363;&#30340;&#25968;&#37327;&#32780;&#19988;&#36824;&#38543;&#30528;&#23427;&#20204;&#30340;&#22823;&#23567;&#32780;&#21464;&#21270;&#12290;&#22522;&#26412;&#20551;&#35774;&#31526;&#21512;&#29983;&#25104;&#27169;&#22411;&#19978;&#30340;&#26368;&#26032;&#30740;&#31350;&#65292;&#21363;&#25968;&#25454;&#30001;&#20998;&#35299;&#21442;&#32771;&#24230;&#37327;&#30340;Knothe-Rosenblatt&#37325;&#26032;&#25490;&#21015;&#29983;&#25104;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#23558;&#38543;&#26426;&#36755;&#20986;&#21464;&#37327;&#20043;&#38388;&#30340;&#32467;&#26500;&#26174;&#24335;&#22320;&#25552;&#21462;&#21040;Wasserstein&#20381;&#36182;&#30697;&#38453;&#20013;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#21033;&#29992;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#32467;&#26500;&#39044;&#27979;&#36825;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435;&#21028;&#21035;&#24335;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#30028;&#38480;&#36808;&#20986;&#20102;&#21021;&#27493;&#30340;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
In structured prediction, target objects have rich internal structure which does not factorize into independent components and violates common i.i.d. assumptions. This challenge becomes apparent through the exponentially large output space in applications such as image segmentation or scene graph generation. We present a novel PAC-Bayesian risk bound for structured prediction wherein the rate of generalization scales not only with the number of structured examples but also with their size. The underlying assumption, conforming to ongoing research on generative models, is that data are generated by the Knothe-Rosenblatt rearrangement of a factorizing reference measure. This allows to explicitly distill the structure between random output variables into a Wasserstein dependency matrix. Our work makes a preliminary step towards leveraging powerful generative models to establish generalization bounds for discriminative downstream tasks in the challenging setting of structured prediction.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#24102;&#26377;&#30456;&#24212;&#31163;&#32447;&#25968;&#25454;&#30340;K&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20197;1-delta&#32622;&#20449;&#24230;&#25214;&#21040;&#24179;&#22343;&#20540;&#26368;&#39640;&#30340;&#33218;&#65292;&#24182;&#19988;&#22312;&#28385;&#36275;&#32622;&#20449;&#24230;&#35201;&#27714;&#30340;&#21069;&#25552;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2306.09048</link><description>&lt;p&gt;
&#24102;&#31163;&#32447;&#25968;&#25454;&#30340;&#36172;&#21338;&#26426;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Optimal Best-Arm Identification in Bandits with Access to Offline Data. (arXiv:2306.09048v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#24102;&#26377;&#30456;&#24212;&#31163;&#32447;&#25968;&#25454;&#30340;K&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#20197;1-delta&#32622;&#20449;&#24230;&#25214;&#21040;&#24179;&#22343;&#20540;&#26368;&#39640;&#30340;&#33218;&#65292;&#24182;&#19988;&#22312;&#28385;&#36275;&#32622;&#20449;&#24230;&#35201;&#27714;&#30340;&#21069;&#25552;&#19979;&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#24050;&#32463;&#30740;&#31350;&#20102;&#22522;&#20110;&#32431;&#31163;&#32447;&#25968;&#25454;&#21644;&#23436;&#20840;&#22522;&#20110;&#39034;&#24207;&#22312;&#32447;&#23398;&#20064;&#30340;&#23398;&#20064;&#33539;&#24335;&#65292;&#20294;&#23558;&#31163;&#32447;&#25968;&#25454;&#19982;&#22312;&#32447;&#23398;&#20064;&#30456;&#32467;&#21512;&#30340;&#39046;&#22495;&#21364;&#40092;&#26377;&#30740;&#31350;&#65292;&#36825;&#26159;&#23454;&#38469;&#19978;&#21313;&#20998;&#37325;&#35201;&#30340;&#12290;&#26412;&#25991;&#32771;&#34385;&#22312;&#30456;&#20851;&#31163;&#32447;&#25968;&#25454;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$1-\delta$&#30340;&#32622;&#20449;&#24230;&#35782;&#21035;&#20986;&#20855;&#26377;&#26368;&#39640;&#24179;&#22343;&#20540;&#30340;&#33218;&#30340;&#38543;&#26426;K&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#25552;&#20379;&#35813;$1-\delta$&#27010;&#29575;&#27491;&#30830;&#24615;&#20445;&#35777;&#30340;&#31574;&#30053;&#36827;&#34892;&#20102;&#19968;&#20010;&#19979;&#30028;&#20998;&#26512;&#65292;&#24182;&#24320;&#21457;&#20986;&#33021;&#22815;&#22312;$\delta$&#24456;&#23567;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#26679;&#26412;&#22797;&#26434;&#24615;&#19979;&#30028;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#27599;&#20010;&#26679;&#26412;&#30340;&#25910;&#38598;&#25104;&#26412;&#24179;&#22343;&#20026;$\tilde {O}(K)$&#65292;&#24182;&#19988;&#20381;&#36182;&#20110;&#19968;&#20010;&#23545;&#36739;&#20302;&#38382;&#39064;&#30340;&#26368;&#20248;&#24615;&#26465;&#20214;&#30340;&#20180;&#32454;&#21051;&#30011;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning paradigms based purely on offline data as well as those based solely on sequential online learning have been well-studied in the literature. In this paper, we consider combining offline data with online learning, an area less studied but of obvious practical importance. We consider the stochastic $K$-armed bandit problem, where our goal is to identify the arm with the highest mean in the presence of relevant offline data, with confidence $1-\delta$. We conduct a lower bound analysis on policies that provide such $1-\delta$ probabilistic correctness guarantees. We develop algorithms that match the lower bound on sample complexity when $\delta$ is small. Our algorithms are computationally efficient with an average per-sample acquisition cost of $\tilde{O}(K)$, and rely on a careful characterization of the optimality conditions of the lower bound problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#33258;&#27880;&#24847;&#21147;&#27169;&#22359;&#30340;&#22810;&#25439;&#22833;&#21367;&#31215;&#32593;&#32476;&#19982;&#26102;&#39057;&#27880;&#24847;&#21147;&#65288;MNTFA&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#35821;&#38899;&#22686;&#24378;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#27169;&#22411;&#22312; PESQ &#21644; STOI &#25351;&#26631;&#26041;&#38754;&#36798;&#21040;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.08956</link><description>&lt;p&gt;
&#21033;&#29992;&#26102;&#39057;&#27880;&#24847;&#21147;&#30340;&#22810;&#25439;&#22833;&#21367;&#31215;&#32593;&#32476;&#29992;&#20110;&#35821;&#38899;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Multi-Loss Convolutional Network with Time-Frequency Attention for Speech Enhancement. (arXiv:2306.08956v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#33258;&#27880;&#24847;&#21147;&#27169;&#22359;&#30340;&#22810;&#25439;&#22833;&#21367;&#31215;&#32593;&#32476;&#19982;&#26102;&#39057;&#27880;&#24847;&#21147;&#65288;MNTFA&#65289;&#27169;&#22411;&#65292;&#29992;&#20110;&#35821;&#38899;&#22686;&#24378;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#27169;&#22411;&#22312; PESQ &#21644; STOI &#25351;&#26631;&#26041;&#38754;&#36798;&#21040;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22810;&#25439;&#22833;&#21367;&#31215;&#32593;&#32476;&#19982;&#26102;&#39057;&#27880;&#24847;&#21147;&#65288;MNTFA&#65289;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#35821;&#38899;&#22686;&#24378;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#20102;&#33258;&#27880;&#24847;&#21147;&#27169;&#22359;&#26469;&#25366;&#25496;&#38271;&#26102;&#38388;&#20449;&#24687;&#65292;&#20854;&#20013; intra-chunk &#33258;&#27880;&#24847;&#21147;&#29992;&#20110;&#24314;&#27169;&#39057;&#35889;&#27169;&#24335;&#65292;&#32780; inter-chunk &#33258;&#27880;&#24847;&#21147;&#29992;&#20110;&#24314;&#27169;&#36830;&#32493;&#24103;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#30456;&#27604;&#20110; DPRNN&#65292;&#36724;&#21521;&#33258;&#27880;&#24847;&#21147;&#22823;&#22823;&#38477;&#20302;&#20102;&#20869;&#23384;&#21644;&#35745;&#31639;&#30340;&#38656;&#27714;&#65292;&#26356;&#36866;&#21512;&#22788;&#29702;&#38271;&#35821;&#38899;&#24207;&#21015;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#39044;&#35757;&#32451; WavLM &#32593;&#32476;&#30340;&#22810;&#20998;&#36776;&#29575; STFT &#25439;&#22833;&#21644; WavLM &#25439;&#22833;&#30340;&#32852;&#21512;&#35757;&#32451;&#26041;&#27861;&#12290;&#22312; DNS-Challenge &#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340; MNTFA &#22312; PESQ &#21644; STOI &#25351;&#26631;&#26041;&#38754;&#30340;&#24615;&#33021;&#22343;&#36798;&#21040;&#20102;&#24403;&#21069;&#26368;&#20808;&#36827;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Dual-Path Convolution Recurrent Network (DPCRN) was proposed to effectively exploit time-frequency domain information. By combining the DPRNN module with Convolution Recurrent Network (CRN), the DPCRN obtained a promising performance in speech separation with a limited model size. In this paper, we explore self-attention in the DPCRN module and design a model called Multi-Loss Convolutional Network with Time-Frequency Attention(MNTFA) for speech enhancement. We use self-attention modules to exploit the long-time information, where the intra-chunk self-attentions are used to model the spectrum pattern and the inter-chunk self-attention are used to model the dependence between consecutive frames. Compared to DPRNN, axial self-attention greatly reduces the need for memory and computation, which is more suitable for long sequences of speech signals. In addition, we propose a joint training method of a multi-resolution STFT loss and a WavLM loss using a pre-trained WavLM network. Experi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21161;&#32858;&#21512;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#20351;&#24471;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#33021;&#22815;&#25552;&#20379;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#12290;&#22312;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22240;&#26524;&#21457;&#29616;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.08946</link><description>&lt;p&gt;
&#33258;&#21161;&#32858;&#21512;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#29992;&#20110;&#25913;&#36827;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Bootstrap aggregation and confidence measures to improve time series causal discovery. (arXiv:2306.08946v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21161;&#32858;&#21512;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#20351;&#24471;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#33021;&#22815;&#25552;&#20379;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#12290;&#22312;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22240;&#26524;&#21457;&#29616;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#24050;&#32463;&#23637;&#31034;&#20102;&#35782;&#21035;&#34920;&#31034;&#21160;&#24577;&#31995;&#32479;&#30340;&#22240;&#26524;&#26102;&#38388;&#20381;&#36182;&#32467;&#26500;&#30340;&#26102;&#24207;&#22270;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#19981;&#21253;&#25324;&#23545;&#20272;&#35745;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#30340;&#27979;&#37327;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#21161;&#32858;&#21512;&#65288;Bagging&#65289;&#21644;&#32622;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#23427;&#19982;&#26102;&#38388;&#24207;&#21015;&#22240;&#26524;&#21457;&#29616;&#30456;&#32467;&#21512;&#12290;&#35813;&#26041;&#27861;&#20801;&#35768;&#36890;&#36807;&#22312;&#20445;&#30041;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#24773;&#20917;&#19979;&#23545;&#21407;&#22987;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#21161;&#37325;&#37319;&#26679;&#26469;&#27979;&#37327;&#30001;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#35745;&#31639;&#20986;&#30340;&#26102;&#24207;&#22270;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#12290;&#38500;&#20102;&#32622;&#20449;&#24230;&#37327;&#65292;&#32858;&#21512;&#24341;&#23548;&#22270;&#36890;&#36807;&#22810;&#25968;&#25237;&#31080;&#24471;&#20986;&#26368;&#32456;&#32858;&#21512;&#36755;&#20986;&#22270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26465;&#20214;&#29420;&#31435;&#24615;&#31639;&#27861;PCMCI+&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23454;&#39564;&#24615;&#22320;&#23637;&#31034;&#20102;Bagged-PCMCI+&#38500;&#20102;&#25552;&#20379;&#36830;&#25509;&#30340;&#32622;&#20449;&#24230;&#24230;&#37327;&#22806;&#65292;&#36824;&#21487;&#20197;&#25552;&#39640;&#22240;&#26524;&#21457;&#29616;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery methods have demonstrated the ability to identify the time series graphs representing the causal temporal dependency structure of dynamical systems. However, they do not include a measure of the confidence of the estimated links. Here, we introduce a novel bootstrap aggregation (bagging) and confidence measure method that is combined with time series causal discovery. This new method allows measuring confidence for the links of the time series graphs calculated by causal discovery methods. This is done by bootstrapping the original times series data set while preserving temporal dependencies. Next to confidence measures, aggregating the bootstrapped graphs by majority voting yields a final aggregated output graph. In this work, we combine our approach with the state-of-the-art conditional-independence-based algorithm PCMCI+. With extensive numerical experiments we empirically demonstrate that, in addition to providing confidence measures for links, Bagged-PCMCI+ improv
&lt;/p&gt;</description></item><item><title>HKConv&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#21487;&#35757;&#32451;&#30340;&#21452;&#26354;&#21367;&#31215;&#65292;&#23427;&#21487;&#20197;&#26681;&#25454;&#21452;&#26354;&#36317;&#31163;&#27979;&#37327;&#31867;&#20284;&#20110;&#26059;&#36716;&#30340;&#21464;&#25442;&#31561;&#21464;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08862</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#28857;&#32858;&#21512;&#30340;&#21452;&#26354;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Hyperbolic Convolution via Kernel Point Aggregation. (arXiv:2306.08862v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08862
&lt;/p&gt;
&lt;p&gt;
HKConv&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#21487;&#35757;&#32451;&#30340;&#21452;&#26354;&#21367;&#31215;&#65292;&#23427;&#21487;&#20197;&#26681;&#25454;&#21452;&#26354;&#36317;&#31163;&#27979;&#37327;&#31867;&#20284;&#20110;&#26059;&#36716;&#30340;&#21464;&#25442;&#31561;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#38750;&#27431;&#20960;&#37324;&#24471;&#25968;&#25454;&#65292;&#26681;&#25454;&#24213;&#23618;&#20960;&#20309;&#23398;&#20064;&#34920;&#31034;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#21452;&#26354;&#31354;&#38388;&#21487;&#20197;&#26377;&#25928;&#22320;&#23884;&#20837;&#20998;&#23618;&#25110;&#26641;&#29366;&#25968;&#25454;&#12290;&#36817;&#24180;&#26469;&#65292;&#21452;&#26354;&#31070;&#32463;&#32593;&#32476;&#24471;&#21040;&#20102;&#24555;&#36895;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#23398;&#20064;&#33391;&#22909;&#30340;&#21452;&#26354;&#34920;&#31034;&#26159;&#26377;&#25361;&#25112;&#30340;&#65292;&#22240;&#20026;&#24120;&#35265;&#30340;&#27431;&#20960;&#37324;&#24471;&#31070;&#32463;&#25805;&#20316;&#65288;&#22914;&#21367;&#31215;&#65289;&#26080;&#27861;&#25193;&#23637;&#21040;&#21452;&#26354;&#31354;&#38388;&#12290;&#22823;&#22810;&#25968;&#21452;&#26354;&#31070;&#32463;&#32593;&#32476;&#19981;&#21253;&#25324;&#21367;&#31215;&#25805;&#20316;&#65292;&#24182;&#24573;&#30053;&#23616;&#37096;&#27169;&#24335;&#12290;&#20854;&#20182;&#30340;&#21017;&#20165;&#20351;&#29992;&#38750;&#21452;&#26354;&#21367;&#31215;&#65292;&#25110;&#32773;&#32570;&#22833;&#35832;&#22914;&#32622;&#25442;&#31561;&#20215;&#24615;&#30340;&#37325;&#35201;&#24615;&#36136;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HKConv&#65292;&#19968;&#31181;&#26032;&#39062;&#19988;&#21487;&#35757;&#32451;&#30340;&#21452;&#26354;&#21367;&#31215;&#65292;&#23427;&#39318;&#20808;&#23558;&#21487;&#35757;&#32451;&#30340;&#26412;&#22320;&#21452;&#26354;&#29305;&#24449;&#19982;&#25918;&#32622;&#22312;&#21452;&#26354;&#31354;&#38388;&#20013;&#30340;&#22266;&#23450;&#26680;&#24515;&#28857;&#30456;&#20851;&#32852;&#65292;&#28982;&#21518;&#22312;&#26412;&#22320;&#37051;&#22495;&#20869;&#32858;&#21512;&#36755;&#20986;&#29305;&#24449;&#12290;HKConv&#19981;&#20165;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#26412;&#22320;&#29305;&#24449;&#65292;&#36824;&#21487;&#20197;&#26681;&#25454;&#21452;&#26354;&#36317;&#31163;&#27979;&#37327;&#31867;&#20284;&#20110;&#26059;&#36716;&#30340;&#21464;&#25442;&#31561;&#21464;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning representations according to the underlying geometry is of vital importance for non-Euclidean data. Studies have revealed that the hyperbolic space can effectively embed hierarchical or tree-like data. In particular, the few past years have witnessed a rapid development of hyperbolic neural networks. However, it is challenging to learn good hyperbolic representations since common Euclidean neural operations, such as convolution, do not extend to the hyperbolic space. Most hyperbolic neural networks do not embrace the convolution operation and ignore local patterns. Others either only use non-hyperbolic convolution, or miss essential properties such as equivariance to permutation. We propose HKConv, a novel trainable hyperbolic convolution which first correlates trainable local hyperbolic features with fixed kernel points placed in the hyperbolic space, then aggregates the output features within a local neighborhood. HKConv not only expressively learns local features according 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Gromov-Wasserstein&#36317;&#31163;&#30340;&#22270;&#32553;&#20943;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20445;&#25345;&#22270;&#30340;&#36317;&#31163;&#65292;&#24182;&#21033;&#29992;&#21152;&#26435;&#26680;$ K $ -means&#26041;&#27861;&#26368;&#23567;&#21270;&#24046;&#24322;&#65292;&#20174;&#32780;&#25552;&#39640;&#20445;&#35889;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.08854</link><description>&lt;p&gt;
Gromov-Wasserstein&#27979;&#22320;&#32447;&#35270;&#35282;&#19979;&#30340;&#20445;&#35889;&#22270;&#32553;&#20943;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Gromov--Wasserstein Geometric View of Spectrum-Preserving Graph Coarsening. (arXiv:2306.08854v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08854
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Gromov-Wasserstein&#36317;&#31163;&#30340;&#22270;&#32553;&#20943;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20445;&#25345;&#22270;&#30340;&#36317;&#31163;&#65292;&#24182;&#21033;&#29992;&#21152;&#26435;&#26680;$ K $ -means&#26041;&#27861;&#26368;&#23567;&#21270;&#24046;&#24322;&#65292;&#20174;&#32780;&#25552;&#39640;&#20445;&#35889;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#32553;&#20943;&#26159;&#19968;&#31181;&#36890;&#36807;&#22788;&#29702;&#21407;&#22270;&#30340;&#36739;&#23567;&#29256;&#26412;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;&#22270;&#38382;&#39064;&#30340;&#25216;&#26415;&#65292;&#24182;&#21487;&#33021;&#23558;&#32467;&#26524;&#25554;&#20540;&#22238;&#21407;&#22270;&#12290;&#23427;&#22312;&#31185;&#23398;&#35745;&#31639;&#39046;&#22495;&#26377;&#30528;&#24736;&#20037;&#30340;&#21382;&#21490;&#65292;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#29305;&#21035;&#26159;&#22312;&#20445;&#25345;&#22270;&#35889;&#30340;&#26041;&#27861;&#20013;&#12290;&#26412;&#25991;&#20174;&#19981;&#21516;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#22270;&#32553;&#20943;&#65292;&#21457;&#23637;&#20102;&#19968;&#31181;&#20445;&#25345;&#22270;&#36317;&#31163;&#30340;&#29702;&#35770;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#20960;&#20309;&#26041;&#27861;&#22312;&#22788;&#29702;&#22270;&#38598;&#21512;&#26102;&#38750;&#24120;&#26377;&#29992;&#65292;&#20363;&#22914;&#22312;&#22270;&#20998;&#31867;&#21644;&#22238;&#24402;&#20013;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#22270;&#30475;&#20316;&#26159;&#35013;&#22791;&#26377;Gromov-Wasserstein&#65288;GW&#65289;&#36317;&#31163;&#30340;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;&#19968;&#20010;&#20803;&#32032;&#65292;&#24182;&#19988;&#38480;&#23450;&#20102;&#20004;&#20010;&#22270;&#21644;&#23427;&#20204;&#32553;&#20943;&#29256;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#24046;&#24322;&#12290;&#20351;&#29992;&#27969;&#34892;&#30340;&#21152;&#26435;&#26680;$ K $ -means&#26041;&#27861;&#21487;&#20197;&#26368;&#23567;&#21270;&#27492;&#24046;&#24322;&#65292;&#21033;&#29992;GW&#36317;&#31163;&#21487;&#20197;&#25552;&#39640;&#29616;&#26377;&#30340;&#20445;&#35889;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph coarsening is a technique for solving large-scale graph problems by working on a smaller version of the original graph, and possibly interpolating the results back to the original graph. It has a long history in scientific computing and has recently gained popularity in machine learning, particularly in methods that preserve the graph spectrum. This work studies graph coarsening from a different perspective, developing a theory for preserving graph distances and proposing a method to achieve this. The geometric approach is useful when working with a collection of graphs, such as in graph classification and regression. In this study, we consider a graph as an element on a metric space equipped with the Gromov--Wasserstein (GW) distance, and bound the difference between the distance of two graphs and their coarsened versions. Minimizing this difference can be done using the popular weighted kernel $K$-means method, which improves existing spectrum-preserving methods with the proper
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#21463;&#38544;&#31169;&#32422;&#26463;&#19988;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#26465;&#20214;&#19979;&#65292;&#20174;&#20844;&#24320;&#28304;&#39046;&#22495;&#21040;&#30446;&#26631;&#39046;&#22495;&#36827;&#34892;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#35299;&#20915;&#19968;&#33324;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#26377;&#21033;&#30340;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.08838</link><description>&lt;p&gt;
&#20855;&#26377;&#29702;&#35770;&#20445;&#38556;&#30340;&#24046;&#20998;&#38544;&#31169;&#22495;&#33258;&#36866;&#24212;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Domain Adaptation with Theoretical Guarantees. (arXiv:2306.08838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08838
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#21463;&#38544;&#31169;&#32422;&#26463;&#19988;&#26377;&#38480;&#26631;&#35760;&#25968;&#25454;&#26465;&#20214;&#19979;&#65292;&#20174;&#20844;&#24320;&#28304;&#39046;&#22495;&#21040;&#30446;&#26631;&#39046;&#22495;&#36827;&#34892;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#35299;&#20915;&#19968;&#33324;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#26377;&#21033;&#30340;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#23398;&#20064;&#32773;&#21487;&#29992;&#30340;&#26631;&#35760;&#25968;&#25454;&#21463;&#21040;&#38544;&#31169;&#32422;&#26463;&#24182;&#30456;&#23545;&#26377;&#38480;&#12290;&#20026;&#20102;&#20026;&#30446;&#26631;&#39046;&#22495;&#23548;&#20986;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#22120;&#65292;&#36890;&#24120;&#26377;&#21033;&#20110;&#21033;&#29992;&#26469;&#33258;&#19982;&#30446;&#26631;&#39046;&#22495;&#30456;&#36817;&#30340;&#21478;&#19968;&#39046;&#22495;&#30340;&#20844;&#24320;&#26631;&#35760;&#25968;&#25454;&#12290;&#36825;&#26159;&#20174;&#20844;&#20849;&#28304;&#39046;&#22495;&#21040;&#31169;&#26377;&#30446;&#26631;&#39046;&#22495;&#30340;&#29616;&#20195;&#30417;&#30563;&#22495;&#33258;&#36866;&#24212;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181; $(\epsilon, \delta)$-&#24046;&#20998;&#38544;&#31169;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#30417;&#30563;&#24615;&#33258;&#36866;&#24212;&#12290;&#23545;&#20110;&#20854;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#33324;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#20248;&#21270;&#38382;&#39064;&#26368;&#36817;&#34987;&#35777;&#26126;&#20855;&#26377;&#26377;&#21033;&#30340;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#26159;&#20026;&#20855;&#26377;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#22238;&#24402;&#35774;&#35745;&#30340;&#65292;&#24182;&#26174;&#31034;&#20026;&#35299;&#20915;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#31639;&#27861;&#26159;&#19968;&#31181;&#26356;&#19968;&#33324;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#29992;&#20110;&#21487;&#33021;&#26159;&#38750;&#20984;&#20294;Lipschitz&#21644;&#24179;&#28369;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65292;&#20294;&#25105;&#20204;&#20063;&#25253;&#21578;&#20102;&#20960;&#20010;&#23454;&#39564;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications, the labeled data at the learner's disposal is subject to privacy constraints and is relatively limited. To derive a more accurate predictor for the target domain, it is often beneficial to leverage publicly available labeled data from an alternative domain, somewhat close to the target domain. This is the modern problem of supervised domain adaptation from a public source to a private target domain. We present two $(\epsilon, \delta)$-differentially private adaptation algorithms for supervised adaptation, for which we make use of a general optimization problem, recently shown to benefit from favorable theoretical learning guarantees. Our first algorithm is designed for regression with linear predictors and shown to solve a convex optimization problem. Our second algorithm is a more general solution for loss functions that may be non-convex but Lipschitz and smooth. While our main objective is a theoretical analysis, we also report the results of several experiment
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31934;&#30830;&#35745;&#31639;ReLU&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#21306;&#22495;&#29255;&#27573;&#25968;&#37327;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#30028;&#22797;&#26434;&#24615;&#24230;&#37327;&#26041;&#27861;&#26469;&#36866;&#24403;&#24230;&#37327;&#20998;&#31867;&#22120;&#22797;&#26434;&#24230;&#30340;&#24605;&#24819;&#65292;&#24182;&#21457;&#29616;&#36793;&#30028;&#29255;&#27573;&#35745;&#25968;&#19982;&#27867;&#21270;&#24615;&#33021;&#30340;&#30456;&#20851;&#24615;&#26356;&#39640;&#65292;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2306.08805</link><description>&lt;p&gt;
ReLU&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#21306;&#22495;&#31934;&#30830;&#35745;&#25968;&#65306;&#26397;&#30528;&#22522;&#20110;&#36793;&#30028;&#22797;&#26434;&#24615;&#30340;&#20998;&#31867;&#36866;&#24403;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exact Count of Boundary Pieces of ReLU Classifiers: Towards the Proper Complexity Measure for Classification. (arXiv:2306.08805v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08805
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31934;&#30830;&#35745;&#31639;ReLU&#20998;&#31867;&#22120;&#30340;&#36793;&#30028;&#21306;&#22495;&#29255;&#27573;&#25968;&#37327;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#30028;&#22797;&#26434;&#24615;&#24230;&#37327;&#26041;&#27861;&#26469;&#36866;&#24403;&#24230;&#37327;&#20998;&#31867;&#22120;&#22797;&#26434;&#24230;&#30340;&#24605;&#24819;&#65292;&#24182;&#21457;&#29616;&#36793;&#30028;&#29255;&#27573;&#35745;&#25968;&#19982;&#27867;&#21270;&#24615;&#33021;&#30340;&#30456;&#20851;&#24615;&#26356;&#39640;&#65292;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#20856;&#23398;&#20064;&#29702;&#35770;&#34920;&#26126;&#36866;&#24403;&#30340;&#27491;&#21017;&#21270;&#26159;&#22909;&#30340;&#27867;&#21270;&#21644;&#40065;&#26834;&#24615;&#30340;&#20851;&#38190;&#12290;&#22312;&#20998;&#31867;&#20013;&#65292;&#24403;&#21069;&#30340;&#35757;&#32451;&#26041;&#26696;&#20165;&#38024;&#23545;&#20998;&#31867;&#22120;&#26412;&#36523;&#30340;&#22797;&#26434;&#24615;&#65292;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#35823;&#23548;&#21644;&#26080;&#25928;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20027;&#24352;&#30452;&#25509;&#27979;&#37327;&#20915;&#31574;&#36793;&#30028;&#30340;&#22797;&#26434;&#24615;&#12290;&#29616;&#26377;&#25991;&#29486;&#22312;&#36825;&#20010;&#39046;&#22495;&#30340;&#23450;&#20041;&#26377;&#38480;&#65292;&#36793;&#30028;&#22797;&#26434;&#24615;&#30340;&#23450;&#20041;&#20063;&#24448;&#24448;&#23384;&#22312;&#20105;&#35758;&#12290;&#25105;&#20204;&#20197;ReLU&#31070;&#32463;&#32593;&#32476;&#20026;&#20363;&#36827;&#34892;&#27010;&#24565;&#35777;&#26126;&#65292;&#36825;&#20123;&#32593;&#32476;&#30340;&#36793;&#30028;&#22797;&#26434;&#24418;&#24577;&#21487;&#20197;&#26041;&#20415;&#22320;&#29992;&#20223;&#23556;&#29255;&#27573;&#30340;&#25968;&#37327;&#26469;&#21051;&#30011;&#12290;&#25105;&#20204;&#20511;&#21161;&#20110;&#28909;&#24102;&#20960;&#20309;&#65292;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#26126;&#30830;&#35745;&#31639;&#20986;&#36793;&#30028;&#31934;&#30830;&#30340;&#29255;&#27573;&#25968;&#37327;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#36793;&#30028;&#29255;&#27573;&#35745;&#25968;&#22312;&#35757;&#32451;&#20013;&#30340;&#29420;&#29305;&#24615;&#36136;&#19982;&#23454;&#38469;&#20998;&#31867;&#19968;&#33268;&#65292;&#19982;&#20854;&#20182;&#27979;&#37327;&#65292;&#20363;&#22914;&#26435;&#37325;&#30340;&#24635;&#21644;$l_2$&#33539;&#25968;&#30456;&#27604;&#65292;&#29420;&#31435;&#24615;&#26356;&#22909;&#12290;&#27492;&#22806;&#65292;&#36793;&#30028;&#29255;&#27573;&#35745;&#25968;&#19982;&#27867;&#21270;&#24615;&#33021;&#30340;&#30456;&#20851;&#24615;&#26356;&#39640;&#65292;&#20855;&#26377;&#20854;&#20182;&#22797;&#26434;&#24230;&#37327;&#24230;&#19981;&#33021;&#27604;&#25311;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#27979;&#37327;&#36793;&#30028;&#22797;&#26434;&#24615;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#22522;&#20110;&#36793;&#30028;&#21306;&#22495;&#35745;&#25968;&#30340;&#23454;&#38469;&#20998;&#31867;&#22120;&#27491;&#21017;&#21270;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classic learning theory suggests that proper regularization is the key to good generalization and robustness. In classification, current training schemes only target the complexity of the classifier itself, which can be misleading and ineffective. Instead, we advocate directly measuring the complexity of the decision boundary. Existing literature is limited in this area with few well-established definitions of boundary complexity. As a proof of concept, we start by analyzing ReLU neural networks, whose boundary complexity can be conveniently characterized by the number of affine pieces. With the help of tropical geometry, we develop a novel method that can explicitly count the exact number of boundary pieces, and as a by-product, the exact number of total affine pieces. Numerical experiments are conducted and distinctive properties of our boundary complexity are uncovered. First, the boundary piece count appears largely independent of other measures, e.g., total piece count, and $l_2$ 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#23545;&#25968;&#36890;&#20449;&#30340; Langevin Thompson Sampling &#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#22312;&#36172;&#21338;&#26426;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#23398;&#20064;&#26410;&#30693;&#30340;&#22870;&#21169;&#20998;&#24067;&#21644;&#36716;&#31227;&#21160;&#24577;&#31561;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.08803</link><description>&lt;p&gt;
&#24102;&#26377;&#23545;&#25968;&#36890;&#20449;&#30340; Langevin Thompson Sampling&#65306;&#22312;&#36172;&#21338;&#26426;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Langevin Thompson Sampling with Logarithmic Communication: Bandits and Reinforcement Learning. (arXiv:2306.08803v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#23545;&#25968;&#36890;&#20449;&#30340; Langevin Thompson Sampling &#31639;&#27861;&#65292;&#21487;&#29992;&#20110;&#35299;&#20915;&#22312;&#36172;&#21338;&#26426;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#23398;&#20064;&#26410;&#30693;&#30340;&#22870;&#21169;&#20998;&#24067;&#21644;&#36716;&#31227;&#21160;&#24577;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Thompson Sampling (TS)&#30001;&#20110;&#26131;&#20110;&#20351;&#29992;&#21644;&#33391;&#22909;&#30340;&#23454;&#39564;&#34920;&#29616;&#32780;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#24207;&#36143;&#20915;&#31574;&#12290;&#20294;&#35768;&#22810;TS&#30340;&#29616;&#26377;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#22870;&#21169;&#20998;&#24067;&#30340;&#38480;&#21046;&#24615;&#20551;&#35774;&#65292;&#22914;&#23646;&#20110;&#20849;&#36717;&#23478;&#26063;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#27492;&#22806;&#65292;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#24448;&#24448;&#20197;&#25209;&#22788;&#29702;&#26041;&#24335;&#36827;&#34892;&#65292;&#36825;&#26082;&#26159;&#30001;&#20110;&#38382;&#39064;&#26412;&#36523;&#30340;&#22266;&#26377;&#24615;&#36136;&#65292;&#20063;&#26159;&#20026;&#20102;&#20943;&#23569;&#36890;&#20449;&#21644;&#35745;&#31639;&#25104;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32852;&#21512;&#30740;&#31350;&#20102;&#20004;&#31181;&#24120;&#35265;&#30340;&#35774;&#32622;&#20013;&#30340;&#36825;&#20123;&#38382;&#39064;&#65292;&#21363;&#22522;&#20110;&#38543;&#26426;&#36172;&#21338;&#26426;&#65288;MABs&#65289;&#21644;&#22522;&#20110;&#26080;&#38480;&#26102;&#22495;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#65292;&#20854;&#20013;TS&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#30340;&#22870;&#21169;&#20998;&#24067;&#21644;&#36716;&#31227;&#21160;&#24577;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#25209;&#37327;&#21270;&#30340; $\textit{Langevin Thompson Sampling}$&#31639;&#27861;&#65292;&#21033;&#29992;MCMC&#26041;&#27861;&#20174;&#36817;&#20284;&#21518;&#39564;&#20013;&#37319;&#26679;&#65292;&#20854;&#36890;&#20449;&#25104;&#26412;&#20165;&#20026;&#23545;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thompson sampling (TS) is widely used in sequential decision making due to its ease of use and appealing empirical performance. However, many existing analytical and empirical results for TS rely on restrictive assumptions on reward distributions, such as belonging to conjugate families, which limits their applicability in realistic scenarios. Moreover, sequential decision making problems are often carried out in a batched manner, either due to the inherent nature of the problem or to serve the purpose of reducing communication and computation costs. In this work, we jointly study these problems in two popular settings, namely, stochastic multi-armed bandits (MABs) and infinite-horizon reinforcement learning (RL), where TS is used to learn the unknown reward distributions and transition dynamics, respectively. We propose batched $\textit{Langevin Thompson Sampling}$ algorithms that leverage MCMC methods to sample from approximate posteriors with only logarithmic communication costs in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19977;&#31181;&#20351;&#29992;DenseNet&#32467;&#21512;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;PSA&#27169;&#22359;&#27880;&#24847;&#26426;&#21046;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#29992;&#20110;&#33521;&#35821;&#21475;&#38899;&#20998;&#31867;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;MPSA-DenseNet&#27169;&#22411;&#22312;&#35782;&#21035;&#33521;&#35821;&#21475;&#38899;&#26041;&#38754;&#20855;&#26377;&#24456;&#39640;&#30340;&#31934;&#30830;&#24615;&#21644;&#21069;&#30651;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.08798</link><description>&lt;p&gt;
MPSA-DenseNet: &#19968;&#31181;&#29992;&#20110;&#33521;&#35821;&#21475;&#38899;&#20998;&#31867;&#30340;&#26032;&#22411;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
MPSA-DenseNet: A novel deep learning model for English accent classification. (arXiv:2306.08798v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19977;&#31181;&#20351;&#29992;DenseNet&#32467;&#21512;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;PSA&#27169;&#22359;&#27880;&#24847;&#26426;&#21046;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#29992;&#20110;&#33521;&#35821;&#21475;&#38899;&#20998;&#31867;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;MPSA-DenseNet&#27169;&#22411;&#22312;&#35782;&#21035;&#33521;&#35821;&#21475;&#38899;&#26041;&#38754;&#20855;&#26377;&#24456;&#39640;&#30340;&#31934;&#30830;&#24615;&#21644;&#21069;&#30651;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#33521;&#35821;&#21475;&#38899;&#20998;&#31867;&#65306;Multi-DenseNet&#65292;PSA-DenseNet&#21644;MPSE-DenseNet&#65292;&#23427;&#20204;&#23558;&#22810;&#20219;&#21153;&#23398;&#20064;&#21644;PSA&#27169;&#22359;&#27880;&#24847;&#26426;&#21046;&#19982;DenseNet&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#25910;&#38598;&#33258;&#33521;&#35821;&#27597;&#35821;&#21306;&#22495;&#65288;&#33521;&#22269;&#65292;&#32654;&#22269;&#65292;&#33487;&#26684;&#20848;&#65289;&#21644;&#38750;&#33521;&#35821;&#27597;&#35821;&#21306;&#22495;&#65288;&#20013;&#22269;&#65292;&#24503;&#22269;&#65292;&#21360;&#24230;&#65289;&#30340;&#20845;&#31181;&#33521;&#35821;&#26041;&#35328;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20998;&#31867;&#31934;&#24230;&#26174;&#33879;&#25552;&#39640;&#65292;&#29305;&#21035;&#26159;MPSA-DenseNet&#65292;&#23427;&#22312;&#21475;&#38899;&#35782;&#21035;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#25152;&#26377;&#20854;&#20182;&#27169;&#22411;&#65292;&#21253;&#25324;&#20808;&#21069;&#29992;&#20110;&#21475;&#38899;&#35782;&#21035;&#30340;DenseNet&#21644;EPSA&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;MPSA-DenseNet&#26159;&#19968;&#31181;&#39640;&#24230;&#26377;&#21069;&#36884;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#20934;&#30830;&#35782;&#21035;&#33521;&#35821;&#21475;&#38899;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents three innovative deep learning models for English accent classification: Multi-DenseNet, PSA-DenseNet, and MPSE-DenseNet, that combine multi-task learning and the PSA module attention mechanism with DenseNet. We applied these models to data collected from six dialects of English across native English speaking regions (Britain, the United States, Scotland) and nonnative English speaking regions (China, Germany, India). Our experimental results show a significant improvement in classification accuracy, particularly with MPSA-DenseNet, which outperforms all other models, including DenseNet and EPSA models previously used for accent identification. Our findings indicate that MPSA-DenseNet is a highly promising model for accurately identifying English accents.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MMD-FUSE&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20869;&#26680;&#38598;&#21512;&#26368;&#22823;&#21270;&#22522;&#20110;MMD&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#21151;&#29575;&#65292;&#36991;&#20813;&#25968;&#25454;&#20998;&#21106;&#65292;&#24182;&#22312;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#21644;&#39640;&#32500;&#23454;&#38469;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#21644;&#21151;&#29575;&#36229;&#36807;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26680;&#26816;&#39564;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08777</link><description>&lt;p&gt;
MMD-FUSE: &#22312;&#19981;&#20998;&#21106;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#21644;&#32452;&#21512;&#20869;&#26680;&#36827;&#34892;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting. (arXiv:2306.08777v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MMD-FUSE&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20869;&#26680;&#38598;&#21512;&#26368;&#22823;&#21270;&#22522;&#20110;MMD&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#21151;&#29575;&#65292;&#36991;&#20813;&#25968;&#25454;&#20998;&#21106;&#65292;&#24182;&#22312;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#21644;&#39640;&#32500;&#23454;&#38469;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#21644;&#21151;&#29575;&#36229;&#36807;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26680;&#26816;&#39564;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#23450;&#20041;&#35813;&#26041;&#27861;&#30340;&#20869;&#26680;&#38598;&#21512;&#65292;&#26368;&#22823;&#21270;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#21151;&#29575;&#12290; &#23545;&#20110;&#26377;&#38480;&#38598;&#21512;&#65292;&#36825;&#23601;&#32553;&#23567;&#20102;&#36890;&#36807;&#21152;&#26435;&#36719;&#26368;&#22823;&#20540;&#32452;&#21512;&#65288;&#26631;&#20934;&#21270;&#30340;&#65289;&#27599;&#20010;&#20869;&#26680;&#19979;&#30340;MMD&#20540;&#12290; &#23545;&#20110;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#32479;&#35745;&#37327;&#30340;&#25351;&#25968;&#27987;&#24230;&#19978;&#38480;&#12290; &#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#20381;&#36182;&#20294;&#19982;&#25490;&#21015;&#29420;&#31435;&#30340;&#26041;&#24335;&#36873;&#25321;&#36825;&#20123;&#20869;&#26680;&#65292;&#22312;&#19968;&#20010;&#32463;&#36807;&#33391;&#22909;&#26657;&#20934;&#30340;&#27979;&#35797;&#20013;&#36991;&#20813;&#25968;&#25454;&#20998;&#21106;&#12290; &#36825;&#31181;&#25216;&#26415;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#22522;&#20110;&#19968;&#33324;&#25490;&#21015;&#30340;MMD&#27979;&#35797;&#65292;&#24182;&#19988;&#21253;&#25324;&#20351;&#29992;&#20351;&#29992;&#33258;&#32534;&#30721;&#22120;&#31561;&#26080;&#30417;&#30563;&#27169;&#22411;&#23398;&#20064;&#30340;&#28145;&#24230;&#20869;&#26680;&#12290; &#25105;&#20204;&#24378;&#35843;&#20102;&#25105;&#20204;&#30340;MMD-FUSE&#27979;&#35797;&#22312;&#21512;&#25104;&#20302;&#32500;&#25968;&#25454;&#21644;&#29616;&#23454;&#19990;&#30028;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#21151;&#29575;&#34920;&#29616;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20869;&#26680;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose novel statistics which maximise the power of a two-sample test based on the Maximum Mean Discrepancy (MMD), by adapting over the set of kernels used in defining it. For finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum. Exponential concentration bounds are proved for our proposed statistics under the null and alternative. We further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting. This technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders. We highlight the applicability of our MMD-FUSE test on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests.
&lt;/p&gt;</description></item><item><title>WavPool&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22359;&#65292;&#23427;&#36890;&#36807;&#28155;&#21152;&#27744;&#21270;&#23618;&#26469;&#20351;&#27604;&#20363;&#21644;&#31354;&#38388;&#20449;&#24687;&#21516;&#26102;&#21487;&#35775;&#38382;&#20110;&#32593;&#32476;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#27169;&#22359;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.08734</link><description>&lt;p&gt;
WavPool: &#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
WavPool: A New Block for Deep Neural Networks. (arXiv:2306.08734v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08734
&lt;/p&gt;
&lt;p&gt;
WavPool&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22359;&#65292;&#23427;&#36890;&#36807;&#28155;&#21152;&#27744;&#21270;&#23618;&#26469;&#20351;&#27604;&#20363;&#21644;&#31354;&#38388;&#20449;&#24687;&#21516;&#26102;&#21487;&#35775;&#38382;&#20110;&#32593;&#32476;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#27169;&#22359;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30001;&#35768;&#22810;&#25805;&#20316;&#23618;&#32452;&#25104;&#65292;&#20363;&#22914;&#31264;&#23494;&#23618;&#25110;&#21367;&#31215;&#23618;&#65292;&#36890;&#24120;&#34987;&#25910;&#38598;&#25104;&#22359;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#21464;&#25442;&#30340;&#26032;&#22411;&#32593;&#32476;&#26550;&#26500;&#65292;&#31216;&#20026;&#22810;&#20998;&#36776;&#29575;&#24863;&#30693;&#22120;&#65306;&#36890;&#36807;&#28155;&#21152;&#27744;&#21270;&#23618;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#32593;&#32476;&#27169;&#22359;&#65292;WavPool&#12290;&#22810;&#20998;&#36776;&#29575;&#24863;&#30693;&#22120;&#30340;&#31532;&#19968;&#27493;&#26159;&#36890;&#36807;&#23558;&#36755;&#20837;&#25968;&#25454;&#19982;&#22266;&#23450;&#31995;&#25968;&#20294;&#19981;&#26029;&#22686;&#21152;&#30340;&#28388;&#27874;&#22120;&#21367;&#31215;&#26469;&#23558;&#25968;&#25454;&#36716;&#25442;&#20026;&#20854;&#22810;&#20998;&#36776;&#29575;&#20998;&#35299;&#24418;&#24335;&#12290;&#36981;&#24490;&#22270;&#20687;&#22788;&#29702;&#25216;&#26415;&#65292;&#25105;&#20204;&#33021;&#22815;&#20351;&#27604;&#20363;&#21644;&#31354;&#38388;&#20449;&#24687;&#21516;&#26102;&#21487;&#35775;&#38382;&#20110;&#32593;&#32476;&#65292;&#32780;&#19981;&#22686;&#21152;&#25968;&#25454;&#21521;&#37327;&#30340;&#22823;&#23567;&#12290;WavPool&#22312;&#20351;&#29992;&#26356;&#23569;&#30340;&#21442;&#25968;&#26102;&#20248;&#20110;&#31867;&#20284;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65292;&#24182;&#19988;&#22312;CIFAR-10&#19978;&#20197;&#30456;&#23545;&#20934;&#30830;&#24230;&#30340; ~ 10&#65285;&#20248;&#20110;&#21487;&#27604;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks comprise many operational layers, such as dense or convolutional layers, which are often collected into blocks. In this work, we introduce a new, wavelet-transform-based network architecture that we call the multi-resolution perceptron: by adding a pooling layer, we create a new network block, the WavPool. The first step of the multi-resolution perceptron is transforming the data into its multi-resolution decomposition form by convolving the input data with filters of fixed coefficients but increasing size. Following image processing techniques, we are able to make scale and spatial information simultaneously accessible to the network without increasing the size of the data vector. WavPool outperforms a similar multilayer perceptron while using fewer parameters, and outperforms a comparable convolutional neural network by ~ 10% on relative accuracy on CIFAR-10.
&lt;/p&gt;</description></item><item><title>&#26032;&#25552;&#20986;&#30340;&#26041;&#27861; UACQR &#23558;&#26465;&#20214;&#20998;&#20301;&#20272;&#35745;&#21644;&#25972;&#21512;&#25512;&#26029;&#32467;&#21512;&#65292;&#20197;&#21306;&#20998;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#30456;&#24212;&#22320;&#26500;&#36896;&#39044;&#27979;&#21306;&#38388;&#65292;&#21487;&#20197;&#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#19981;&#21516;&#23376;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340; CQR &#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08693</link><description>&lt;p&gt;
&#23558;&#19981;&#30830;&#23450;&#24615;&#24847;&#35782;&#25972;&#21512;&#21040; Conformalized Quantile Regression &#20013;
&lt;/p&gt;
&lt;p&gt;
Integrating Uncertainty Awareness into Conformalized Quantile Regression. (arXiv:2306.08693v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08693
&lt;/p&gt;
&lt;p&gt;
&#26032;&#25552;&#20986;&#30340;&#26041;&#27861; UACQR &#23558;&#26465;&#20214;&#20998;&#20301;&#20272;&#35745;&#21644;&#25972;&#21512;&#25512;&#26029;&#32467;&#21512;&#65292;&#20197;&#21306;&#20998;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#21644;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#30456;&#24212;&#22320;&#26500;&#36896;&#39044;&#27979;&#21306;&#38388;&#65292;&#21487;&#20197;&#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#19981;&#21516;&#23376;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340; CQR &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Conformalized Quantile Regression (CQR) &#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#19981;&#20570;&#20998;&#24067;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32473;&#23450;&#21327;&#21464;&#37327; X &#30340;&#21709;&#24212; Y &#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#29616;&#26377;&#30340; CQR &#26500;&#36896;&#26041;&#27861;&#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#26576;&#20123;&#37096;&#20998;&#34920;&#29616;&#26356;&#22909;&#30340;&#38382;&#39064;&#19978;&#21487;&#33021;&#26080;&#25928;&#12290;&#20854;&#21407;&#22240;&#22312;&#20110; CQR &#30340;&#39044;&#27979;&#21306;&#38388;&#19981;&#21306;&#20998;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#24418;&#24335;&#65306;&#31532;&#19968;&#31181;&#26159;&#32473;&#23450; X &#30340;&#26465;&#20214;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65288;&#21363;&#65292;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#65289;&#65292;&#31532;&#20108;&#31181;&#26159;&#25105;&#20204;&#20272;&#35745;&#36825;&#31181;&#26465;&#20214;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;&#21363;&#65292;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#65289;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#19981;&#22343;&#21248;&#30340;&#35206;&#30422;&#33539;&#22260;&#65292;&#22312;&#35748;&#35782;&#24615;&#19981;&#30830;&#23450;&#24615;&#20302;&#65288;&#25110;&#39640;&#65289;&#30340;&#21306;&#22495;&#20013;&#36807;&#24230;&#23485;&#65288;&#25110;&#36807;&#24230;&#31364;&#65289;&#30340;&#21306;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102; Conformalized Quantile Regression &#30340;&#26032;&#21464;&#20307;&#65292;&#21363; Uncertainty-Aware CQR (UACQR)&#65292;&#35813;&#26041;&#27861;&#26126;&#30830;&#22320;&#20998;&#31163;&#36825;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#65292;&#24182;&#30456;&#24212;&#22320;&#26500;&#36896;&#39044;&#27979;&#21306;&#38388;&#12290;UACQR &#26041;&#27861;&#20351;&#29992;&#25972;&#21512;&#25512;&#26029;&#26469;&#37327;&#21270;&#20272;&#35745;&#32473;&#23450; X &#30340; Y &#30340;&#26465;&#20214;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21516;&#26102;&#36824;&#23558;&#26377;&#30028;&#30340;&#26465;&#20214;&#20998;&#20301;&#20272;&#35745;&#24182;&#20837;&#20854;&#20013;&#65292;&#20197;&#25429;&#25417;&#35813;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;UACQR &#22312;&#37327;&#23376;&#22238;&#24402;&#22120;&#22312;&#29305;&#24449;&#31354;&#38388;&#30340;&#23376;&#38598;&#19978;&#34920;&#29616;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#21487;&#20197;&#20248;&#20110;&#29616;&#26377;&#30340; CQR &#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, as we demonstrate empirically, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to uneven coverage, with intervals that are overly wide (or overly narrow) in regions where epistemic uncertainty is low (or high). To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertaint
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#32852;&#32593;&#36710;&#36742;&#25968;&#25454;&#26469;&#39044;&#27979;&#39123;&#39118;&#30095;&#25955;&#26399;&#38388;&#30340;&#36710;&#31096;&#39118;&#38505;&#65292;&#36890;&#36807;&#20998;&#26512;&#36710;&#36895;&#21644;&#21152;&#36895;&#24230;&#26354;&#32447;&#65292;&#21487;&#20197;&#23454;&#26102;&#35780;&#20272;&#20132;&#36890;&#23433;&#20840;&#29366;&#20917;&#12290;</title><link>http://arxiv.org/abs/2306.08682</link><description>&lt;p&gt;
&#21033;&#29992;&#32852;&#32593;&#36710;&#36742;&#25968;&#25454;&#39044;&#27979;&#39123;&#39118;&#30095;&#25955;&#26399;&#38388;&#30340;&#23454;&#26102;&#36710;&#31096;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
Predicting Real-time Crash Risks during Hurricane Evacuation Using Connected Vehicle Data. (arXiv:2306.08682v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08682
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#32852;&#32593;&#36710;&#36742;&#25968;&#25454;&#26469;&#39044;&#27979;&#39123;&#39118;&#30095;&#25955;&#26399;&#38388;&#30340;&#36710;&#31096;&#39118;&#38505;&#65292;&#36890;&#36807;&#20998;&#26512;&#36710;&#36895;&#21644;&#21152;&#36895;&#24230;&#26354;&#32447;&#65292;&#21487;&#20197;&#23454;&#26102;&#35780;&#20272;&#20132;&#36890;&#23433;&#20840;&#29366;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39123;&#39118;&#30095;&#25955;&#20026;&#20102;&#25327;&#25937;&#28023;&#23736;&#22320;&#21306;&#30340;&#20154;&#20204;&#32780;&#36827;&#34892;&#65292;&#20250;&#23548;&#33268;&#20132;&#36890;&#38656;&#27714;&#22686;&#21152;&#65292;&#36710;&#31096;&#39118;&#38505;&#20063;&#38543;&#20043;&#22686;&#21152;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#31181;&#39118;&#38505;&#65292;&#20132;&#36890;&#26426;&#26500;&#38656;&#35201;&#39044;&#27979;&#39640;&#36710;&#31096;&#39118;&#38505;&#30340;&#20844;&#36335;&#20301;&#32622;&#65292;&#20197;&#37096;&#32626;&#36866;&#24403;&#30340;&#23545;&#31574;&#12290;&#38543;&#30528;&#26222;&#21450;&#30340;&#20256;&#24863;&#22120;&#21644;&#36890;&#20449;&#25216;&#26415;&#65292;&#29616;&#22312;&#21487;&#20197;&#26816;&#32034;&#21253;&#21547;&#21333;&#20010;&#36710;&#36742;&#36712;&#36857;&#21644;&#36895;&#24230;&#20449;&#24687;&#30340;&#24494;&#35266;&#32423;&#21035;&#36710;&#36742;&#25968;&#25454;&#12290;&#36825;&#31181;&#39640;&#20998;&#36776;&#29575;&#36710;&#36742;&#25968;&#25454;&#21487;&#20197;&#22312;&#23454;&#26102;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#65292;&#29992;&#20110;&#35780;&#20272;&#24403;&#21069;&#30340;&#20132;&#36890;&#23433;&#20840;&#29366;&#20917;&#12290;&#21033;&#29992;&#36710;&#36895;&#21644;&#21152;&#36895;&#24230;&#26354;&#32447;&#65292;&#21487;&#20197;&#23454;&#26102;&#39044;&#27979;&#28508;&#22312;&#30340;&#36710;&#31096;&#39118;&#38505;&#12290;&#20197;&#24448;&#30340;&#23454;&#26102;&#36710;&#31096;&#39118;&#38505;&#39044;&#27979;&#30740;&#31350;&#20027;&#35201;&#20351;&#29992;&#22522;&#30784;&#35774;&#26045;&#20256;&#24863;&#22120;&#30340;&#25968;&#25454;&#65292;&#21487;&#33021;&#26080;&#27861;&#35206;&#30422;&#35768;&#22810;&#36947;&#36335;&#27573;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#26032;&#20852;&#30340;&#26367;&#20195;&#25968;&#25454;&#28304;&#65288;&#31216;&#20026;&#32852;&#32593;&#36710;&#36742;&#25968;&#25454;&#65289;&#26469;&#30830;&#23450;&#39123;&#39118;&#30095;&#25955;&#26399;&#38388;&#28508;&#22312;&#30340;&#36710;&#31096;&#39118;&#38505;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hurricane evacuation, ordered to save lives of people of coastal regions, generates high traffic demand with increased crash risk. To mitigate such risk, transportation agencies need to anticipate highway locations with high crash risks to deploy appropriate countermeasures. With ubiquitous sensors and communication technologies, it is now possible to retrieve micro-level vehicular data containing individual vehicle trajectory and speed information. Such high-resolution vehicle data, potentially available in real time, can be used to assess prevailing traffic safety conditions. Using vehicle speed and acceleration profiles, potential crash risks can be predicted in real time. Previous studies on real-time crash risk prediction mainly used data from infrastructure-based sensors which may not cover many road segments. In this paper, we present methods to determine potential crash risks during hurricane evacuation from an emerging alternative data source known as connected vehicle data. S
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#39044;&#27979;&#38899;&#20048;&#36716;&#25442;&#22120;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#22312;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;&#30340;&#36807;&#31243;&#20013;&#36827;&#34892;&#25511;&#21046;&#65292;&#21253;&#25324;&#34917;&#20840;&#25511;&#21046;&#20219;&#21153;&#21644;&#20276;&#22863;&#65292;&#24182;&#19988;&#22312;&#22823;&#22411;&#19988;&#22810;&#26679;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2306.08620</link><description>&lt;p&gt;
&#39044;&#27979;&#38899;&#20048;&#36716;&#25442;&#22120;
&lt;/p&gt;
&lt;p&gt;
Anticipatory Music Transformer. (arXiv:2306.08620v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08620
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#39044;&#27979;&#38899;&#20048;&#36716;&#25442;&#22120;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#22312;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;&#30340;&#36807;&#31243;&#20013;&#36827;&#34892;&#25511;&#21046;&#65292;&#21253;&#25324;&#34917;&#20840;&#25511;&#21046;&#20219;&#21153;&#21644;&#20276;&#22863;&#65292;&#24182;&#19988;&#22312;&#22823;&#22411;&#19988;&#22810;&#26679;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;anticipation&#65288;&#39044;&#27979;&#65289;&#65306;&#19968;&#31181;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#22522;&#20110;&#20107;&#20214;&#36807;&#31243;&#65288;&#26102;&#38388;&#28857;&#36807;&#31243;&#65289;&#30340;&#23454;&#29616;&#65292;&#20197;&#24322;&#27493;&#22320;&#25511;&#21046;&#19982;&#31532;&#20108;&#20010;&#30456;&#20851;&#36807;&#31243;&#65288;&#25511;&#21046;&#36807;&#31243;&#65289;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20132;&#38169;&#20107;&#20214;&#21644;&#25511;&#20214;&#24207;&#21015;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20351;&#25511;&#20214;&#20986;&#29616;&#22312;&#20107;&#20214;&#24207;&#21015;&#30340;&#20572;&#27490;&#26102;&#38388;&#20043;&#21518;&#12290;&#36825;&#39033;&#24037;&#20316;&#30340;&#21160;&#26426;&#26469;&#33258;&#31526;&#21495;&#38899;&#20048;&#29983;&#25104;&#25511;&#21046;&#20013;&#20986;&#29616;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;infiling&#65288;&#34917;&#20840;&#65289;&#25511;&#21046;&#20219;&#21153;&#65292;&#20854;&#20013;&#25511;&#21046;&#20107;&#20214;&#26159;&#20107;&#20214;&#26412;&#36523;&#30340;&#23376;&#38598;&#65292;&#24182;&#19988;&#26465;&#20214;&#29983;&#25104;&#23436;&#25104;&#32473;&#23450;&#22266;&#23450;&#25511;&#21046;&#20107;&#20214;&#30340;&#20107;&#20214;&#24207;&#21015;&#12290;&#25105;&#20204;&#20351;&#29992;&#22823;&#22411;&#22810;&#26679;&#30340;Lakh MIDI&#38899;&#20048;&#25968;&#25454;&#38598;&#35757;&#32451;&#39044;&#27979;infiling&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#19982;&#25552;&#31034;&#38899;&#20048;&#29983;&#25104;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#24615;&#33021;&#30456;&#24403;&#65292;&#24182;&#20855;&#26377;&#25191;&#34892;infilling&#25511;&#21046;&#20219;&#21153;&#30340;&#38468;&#21152;&#33021;&#21147;&#65292;&#21253;&#25324;&#20276;&#22863;&#12290;&#20154;&#24037;&#35780;&#20272;&#21592;&#25253;&#21578;&#35828;&#65292;&#39044;&#27979;&#27169;&#22411;&#20135;&#29983;&#30340;&#20276;&#22863;&#20855;&#26377;&#39640;&#21487;&#36776;&#24615;&#21644;&#20248;&#32654;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce anticipation: a method for constructing a controllable generative model of a temporal point process (the event process) conditioned asynchronously on realizations of a second, correlated process (the control process). We achieve this by interleaving sequences of events and controls, such that controls appear following stopping times in the event sequence. This work is motivated by problems arising in the control of symbolic music generation. We focus on infilling control tasks, whereby the controls are a subset of the events themselves, and conditional generation completes a sequence of events given the fixed control events. We train anticipatory infilling models using the large and diverse Lakh MIDI music dataset. These models match the performance of autoregressive models for prompted music generation, with the additional capability to perform infilling control tasks, including accompaniment. Human evaluators report that an anticipatory model produces accompaniments with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;&#26377;&#25928;$p$-&#38459;&#25239;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#31867;&#22270;&#32858;&#31867;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21442;&#25968;$p$&#20559;&#21521;&#20110;&#20855;&#26377;&#39640;&#20869;&#37096;&#36830;&#36890;&#24615;&#25110;&#32773;&#26356;&#23567;&#30340;&#31751;&#20869;&#39030;&#28857;&#20043;&#38388;&#30340;&#26368;&#30701;&#36335;&#24452;&#36317;&#31163;&#30340;&#32858;&#31867;&#12290;</title><link>http://arxiv.org/abs/2306.08617</link><description>&lt;p&gt;
&#22522;&#20110;&#36817;&#20284;&#26377;&#25928;&#30340;$p$-&#38459;&#25239;&#30340;&#22810;&#31867;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multi-class Graph Clustering via Approximated Effective $p$-Resistance. (arXiv:2306.08617v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08617
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;&#26377;&#25928;$p$-&#38459;&#25239;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#31867;&#22270;&#32858;&#31867;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#21442;&#25968;$p$&#20559;&#21521;&#20110;&#20855;&#26377;&#39640;&#20869;&#37096;&#36830;&#36890;&#24615;&#25110;&#32773;&#26356;&#23567;&#30340;&#31751;&#20869;&#39030;&#28857;&#20043;&#38388;&#30340;&#26368;&#30701;&#36335;&#24452;&#36317;&#31163;&#30340;&#32858;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#35745;&#31639;&#26377;&#25928;$p$-&#38459;&#25239;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#22810;&#31867;&#32858;&#31867;&#12290;&#22522;&#20110;&#22270;&#25289;&#26222;&#25289;&#26031;&#21644;&#20854;$p$-&#25289;&#26222;&#25289;&#26031;&#25512;&#24191;&#30340;&#35889;&#26041;&#27861;&#19968;&#30452;&#26159;&#38750;&#27431;&#20960;&#37324;&#24471;&#32858;&#31867;&#25216;&#26415;&#30340;&#25903;&#26609;&#12290;$p$-&#25289;&#26222;&#25289;&#26031;&#30340;&#20248;&#28857;&#22312;&#20110;&#21442;&#25968;$p$&#23545;&#32858;&#31867;&#32467;&#26500;&#20855;&#26377;&#21487;&#25511;&#20559;&#20506;&#12290;$p$-&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#21521;&#37327;&#27861;&#30340;&#32570;&#28857;&#22312;&#20110;&#38590;&#20197;&#35745;&#31639;&#31532;&#19977;&#21644;&#26356;&#39640;&#38454;&#29305;&#24449;&#21521;&#37327;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#21160;&#26426;&#22312;&#20110;&#20351;&#29992;&#30001;$p$-&#25289;&#26222;&#25289;&#26031;&#24341;&#23548;&#30340;$p$-&#38459;&#25239;&#36827;&#34892;&#32858;&#31867;&#12290;&#23545;&#20110;$p$-&#38459;&#25239;&#32780;&#35328;&#65292;&#23567;$p$&#20250;&#20559;&#21521;&#20110;&#20855;&#26377;&#39640;&#20869;&#37096;&#36830;&#36890;&#24615;&#30340;&#32858;&#31867;&#65292;&#32780;&#22823;$p$&#21017;&#20250;&#20559;&#21521;&#20110;&#22823;&#23567;&#8220;&#33539;&#22260;&#8221;&#30340;&#32858;&#31867;&#65292;&#21363;&#26356;&#23567;&#30340;&#31751;&#20869;&#39030;&#28857;&#20043;&#38388;&#30340;&#26368;&#30701;&#36335;&#24452;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#35745;&#31639;$p$-&#38459;&#25239;&#25104;&#26412;&#24456;&#39640;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;$p$-&#38459;&#25239;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#20811;&#26381;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19978;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops an approximation to the (effective) $p$-resistance and applies it to multi-class clustering. Spectral methods based on the graph Laplacian and its generalization to the graph $p$-Laplacian have been a backbone of non-euclidean clustering techniques. The advantage of the $p$-Laplacian is that the parameter $p$ induces a controllable bias on cluster structure. The drawback of $p$-Laplacian eigenvector based methods is that the third and higher eigenvectors are difficult to compute. Thus, instead, we are motivated to use the $p$-resistance induced by the $p$-Laplacian for clustering. For $p$-resistance, small $p$ biases towards clusters with high internal connectivity while large $p$ biases towards clusters of small ``extent,'' that is a preference for smaller shortest-path distances between vertices in the cluster. However, the $p$-resistance is expensive to compute. We overcome this by developing an approximation to the $p$-resistance. We prove upper and lower bounds
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08598</link><description>&lt;p&gt;
&#26680;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#24178;&#25200;&#21442;&#25968;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26631;&#37327;&#30446;&#26631;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#37319;&#29992;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#65289;&#26367;&#25442;&#26410;&#30693;&#24178;&#25200;&#21442;&#25968;&#26159;&#26041;&#20415;&#30340;&#65292;&#20294;&#22240;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#32780;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#36991;&#20813;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#30340;&#27425;&#20248;&#36873;&#25321;&#65292;&#29616;&#20195;&#26041;&#27861;&#20250;&#36827;&#34892;&#25554;&#20540;&#39044;&#20272;&#30340;&#21435;&#20559;&#24046;&#25805;&#20316;&#65292;&#22914;&#26377;&#30446;&#26631;&#26368;&#23567;&#25439;&#22833;&#20272;&#35745;&#65288;TMLE&#65289;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#31561;&#12290;&#29616;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#38656;&#35201;&#23558;&#30446;&#26631;&#21442;&#25968;&#30340;&#24433;&#21709;&#20989;&#25968;&#65288;IF&#65289;&#20316;&#20026;&#36755;&#20837;&#65292;&#28982;&#32780;&#65292;IF&#30340;&#25512;&#23548;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#25554;&#20837;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#65288;i&#65289;&#39640;&#25928;&#12289;&#65288;ii&#65289;&#19981;&#38656;&#35201;&#23454;&#29616;IF&#12289;&#65288;iii&#65289;&#21487;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#35777;&#20998;&#26512;&#35777;&#26126;&#20102;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#22823;&#23398;&#20064;&#29575;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#24182;&#19981;&#20250;&#24102;&#26469;&#20219;&#20309;&#38544;&#24615;&#20559;&#24046;&#30340;&#20248;&#21183;&#12290;&#22312;&#32447;&#23398;&#20064;&#20013;SGD&#22122;&#38899;&#30340;&#22909;&#22788;&#21482;&#26159;&#35745;&#31639;&#19978;&#30340;&#20415;&#21033;&#65292;&#21487;&#20197;&#20419;&#36827;&#26356;&#22823;&#25110;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26799;&#24230;&#27493;&#39588;&#12290;</title><link>http://arxiv.org/abs/2306.08590</link><description>&lt;p&gt;
&#36229;&#36234;&#38544;&#24615;&#20559;&#24046;&#65306;SGD&#22122;&#22768;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#19981;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning. (arXiv:2306.08590v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#35777;&#20998;&#26512;&#35777;&#26126;&#20102;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#22823;&#23398;&#20064;&#29575;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#24182;&#19981;&#20250;&#24102;&#26469;&#20219;&#20309;&#38544;&#24615;&#20559;&#24046;&#30340;&#20248;&#21183;&#12290;&#22312;&#32447;&#23398;&#20064;&#20013;SGD&#22122;&#38899;&#30340;&#22909;&#22788;&#21482;&#26159;&#35745;&#31639;&#19978;&#30340;&#20415;&#21033;&#65292;&#21487;&#20197;&#20419;&#36827;&#26356;&#22823;&#25110;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26799;&#24230;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#35748;&#20026;&#65292;SGD&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#25104;&#21151;&#24402;&#22240;&#20110;&#39640;&#23398;&#20064;&#29575;&#25110;&#23567;&#25209;&#37327;&#22823;&#23567;&#25152;&#24341;&#36215;&#30340;&#38544;&#24615;&#20559;&#24046;&#65288;&#8220;SGD&#22122;&#22768;&#8221;&#65289;&#12290;&#32780;&#25105;&#20204;&#30740;&#31350;&#20102;SGD&#22122;&#22768;&#22312;&#22312;&#32447;&#65288;&#21363;&#21333;&#20010;epoch&#65289;&#23398;&#20064;&#20013;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#23545;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#30340;&#20840;&#38754;&#23454;&#35777;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#22312;&#32447;&#23398;&#20064;&#20013;&#65292;&#22823;&#23398;&#20064;&#29575;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#24182;&#19981;&#20250;&#24102;&#26469;&#20219;&#20309;&#38544;&#24615;&#20559;&#24046;&#30340;&#20248;&#21183;&#12290;&#19982;&#31163;&#32447;&#23398;&#20064;&#30456;&#21453;&#65292;&#22312;&#32447;&#23398;&#20064;&#20013;SGD&#22122;&#22768;&#30340;&#22909;&#22788;&#20005;&#26684;&#26469;&#35828;&#21482;&#26159;&#35745;&#31639;&#19978;&#30340;&#20415;&#21033;&#65292;&#21487;&#20197;&#20419;&#36827;&#26356;&#22823;&#25110;&#26356;&#20855;&#25104;&#26412;&#25928;&#30410;&#30340;&#26799;&#24230;&#27493;&#39588;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;SGD&#22312;&#22312;&#32447;&#27169;&#24335;&#19979;&#21487;&#20197;&#34987;&#35270;&#20026;&#26159;&#22312;&#8220;&#26080;&#22122;&#22768;&#26799;&#24230;&#27969;&#31639;&#27861;&#8221;&#30340;&#8220;&#40644;&#37329;&#36335;&#24452;&#8221;&#19978;&#36393;&#36367;&#22024;&#26434;&#27493;&#20240;&#12290;&#36890;&#36807;&#20943;&#23569;&#35757;&#32451;&#26399;&#38388;&#30340;SGD&#22122;&#22768;&#21644;&#27979;&#37327;&#27169;&#22411;&#20043;&#38388;&#30340;&#36880;&#28857;&#21151;&#33021;&#36317;&#31163;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25903;&#25345;&#27492;&#20551;&#35774;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of SGD in deep learning has been ascribed by prior works to the implicit bias induced by high learning rate or small batch size ("SGD noise"). While prior works that focused on offline learning (i.e., multiple-epoch training), we study the impact of SGD noise on online (i.e., single epoch) learning. Through an extensive empirical analysis of image and language data, we demonstrate that large learning rate and small batch size do not confer any implicit bias advantages in online learning. In contrast to offline learning, the benefits of SGD noise in online learning are strictly computational, facilitating larger or more cost-effective gradient steps. Our work suggests that SGD in the online regime can be construed as taking noisy steps along the "golden path" of the noiseless gradient flow algorithm. We provide evidence to support this hypothesis by conducting experiments that reduce SGD noise during training and by measuring the pointwise functional distance between models 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2306.08553</link><description>&lt;p&gt;
&#22122;&#22768;&#31283;&#23450;&#20248;&#21270;&#23545;&#20110;&#20855;&#26377;&#26368;&#20248;&#25910;&#25947;&#29575;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Noise Stability Optimization for Flat Minima with Optimal Convergence Rates. (arXiv:2306.08553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SGD-like&#31639;&#27861;&#65292;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#24182;&#21033;&#29992;&#20998;&#24067;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#65292;&#20197;&#23547;&#25214;&#20855;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#24179;&#22374;&#26497;&#23567;&#20540;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#21152;&#20837;&#21152;&#26435;&#25200;&#21160;&#26469;&#25214;&#21040;&#24179;&#22374;&#30340;&#26497;&#23567;&#20540;&#12290;&#32473;&#23450;&#19968;&#20010;&#38750;&#20984;&#20989;&#25968;$f:\mathbb{R}^d\rightarrow \mathbb{R}$&#21644;&#19968;&#20010;$d$&#32500;&#20998;&#24067;$\mathcal{P}$&#65292;&#25105;&#20204;&#25200;&#21160;$f$&#30340;&#26435;&#37325;&#65292;&#24182;&#23450;&#20041;$F(W)=\mathbb{E}[f({W+U})]$&#65292;&#20854;&#20013;$U$&#26159;&#19968;&#20010;&#20174;$\mathcal{P}$&#20013;&#38543;&#26426;&#25277;&#21462;&#30340;&#26679;&#26412;&#12290;&#36825;&#20010;&#36807;&#31243;&#36890;&#36807;$f$&#30340;&#28023;&#26862;&#30697;&#38453;&#30340;&#36857;&#26469;&#35825;&#23548;&#27491;&#21017;&#21270;&#65292;&#20197;&#36866;&#24212;&#20110;&#23567;&#30340;&#12289;&#21508;&#21521;&#21516;&#24615;&#30340;&#39640;&#26031;&#25200;&#21160;&#12290;&#22240;&#27492;&#65292;&#21152;&#26435;&#25200;&#21160;&#30340;&#20989;&#25968;&#20559;&#21521;&#20110;&#24102;&#26377;&#20302;&#28023;&#26862;&#30697;&#38453;&#36857;&#30340;&#26497;&#23567;&#20540;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;SGD&#30340;&#31639;&#27861;&#65292;&#22312;&#35745;&#31639;&#26799;&#24230;&#20043;&#21069;&#27880;&#20837;&#38543;&#26426;&#22122;&#22768;&#65292;&#21516;&#26102;&#21033;&#29992;$\mathcal{P}$&#30340;&#23545;&#31216;&#24615;&#26469;&#20943;&#23569;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We consider finding flat, local minimizers by adding average weight perturbations. Given a nonconvex function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ and a $d$-dimensional distribution $\mathcal{P}$ which is symmetric at zero, we perturb the weight of $f$ and define $F(W) = \mathbb{E}[f({W + U})]$, where $U$ is a random sample from $\mathcal{P}$. This injection induces regularization through the Hessian trace of $f$ for small, isotropic Gaussian perturbations. Thus, the weight-perturbed function biases to minimizers with low Hessian trace. Several prior works have studied settings related to this weight-perturbed function by designing algorithms to improve generalization. Still, convergence rates are not known for finding minima under the average perturbations of the function $F$. This paper considers an SGD-like algorithm that injects random noise before computing gradients while leveraging the symmetry of $\mathcal{P}$ to reduce variance. We then provide a rigorous analysis, showing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#38543;&#26426;Kronecker&#22270;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#36817;&#20284;&#25512;&#26029;&#65292;&#25552;&#20986;&#20102;&#8220;&#21435;&#22122;&#22768;&#21644;&#27714;&#35299;&#8221;&#20803;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#25512;&#26029;&#22270;&#21442;&#25968;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.08489</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#23494;&#38598;&#38543;&#26426;Kronecker&#22270;&#30340;&#20998;&#26512;&#21644;&#36817;&#20284;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Analysis and Approximate Inference of Large and Dense Random Kronecker Graphs. (arXiv:2306.08489v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08489
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#22823;&#35268;&#27169;&#23494;&#38598;&#38543;&#26426;Kronecker&#22270;&#36827;&#34892;&#20102;&#20998;&#26512;&#21644;&#36817;&#20284;&#25512;&#26029;&#65292;&#25552;&#20986;&#20102;&#8220;&#21435;&#22122;&#22768;&#21644;&#27714;&#35299;&#8221;&#20803;&#31639;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#25512;&#26029;&#22270;&#21442;&#25968;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#27169;&#22411;&#22312;&#31185;&#23398;&#21644;&#24037;&#19994;&#20013;&#21457;&#25381;&#30528;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#20316;&#29992;&#65292;&#24182;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#24471;&#21040;&#24212;&#29992;&#65292;&#21253;&#25324;&#31038;&#20132;&#21644;&#20132;&#36890;&#32593;&#32476;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#20998;&#23376;&#36951;&#20256;&#23398;&#12290;&#26412;&#25991;&#23545;\cite{leskovec2010kronecker}&#20013;&#25552;&#20986;&#30340;&#38543;&#26426;Kronecker&#22270;&#27169;&#22411;&#36827;&#34892;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#65292;&#24403;&#22270;&#39030;&#28857;&#25968;&#37327;$N$&#24456;&#22823;&#26102;&#12290;&#22522;&#20110;&#26368;&#36817;&#22312;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#23494;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;Kronecker&#22270;&#37051;&#25509;&#30697;&#38453;&#36817;&#20284;&#36981;&#24490;&#19968;&#20010;&#20449;&#21495;&#21152;&#22122;&#22768;&#27169;&#22411;&#65292;&#20854;&#20013;&#20449;&#21495;&#30697;&#38453;&#30340;&#31209;&#24456;&#23567;&#65288;&#26368;&#22810;&#20026;$\log N$&#38454;&#65289;&#65292;&#22312;&#22270;&#21442;&#25968;&#20013;&#26159;&#32447;&#24615;&#30340;&#65292;&#32780;&#38543;&#26426;&#30340;&#22122;&#22768;&#30697;&#38453;&#20855;&#26377;&#22235;&#20998;&#20043;&#19968;&#22278;&#24418;&#22855;&#24322;&#20540;&#20998;&#24067;&#12290;&#36825;&#20010;&#35266;&#23519;&#20801;&#35768;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#21435;&#22122;&#22768;&#21644;&#27714;&#35299;&#8221;&#20803;&#31639;&#27861;&#26469;&#36817;&#20284;&#25512;&#26029;&#22270;&#21442;&#25968;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#65288;&#28176;&#36817;&#30340;&#65289;&#24615;&#33021;&#20445;&#35777;&#12290;&#36890;&#36807;&#22270;i&#30340;&#25968;&#20540;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random graph models are playing an increasingly important role in science and industry, and finds their applications in a variety of fields ranging from social and traffic networks, to recommendation systems and molecular genetics. In this paper, we perform an in-depth analysis of the random Kronecker graph model proposed in \cite{leskovec2010kronecker}, when the number of graph vertices $N$ is large. Built upon recent advances in random matrix theory, we show, in the dense regime, that the random Kronecker graph adjacency matrix follows approximately a signal-plus-noise model, with a small-rank (of order at most $\log N$) signal matrix that is linear in the graph parameters and a random noise matrix having a quarter-circle-form singular value distribution. This observation allows us to propose a ``denoise-and-solve'' meta algorithm to approximately infer the graph parameters, with reduced computational complexity and (asymptotic) performance guarantee. Numerical experiments of graph i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;BwK&#26694;&#26550;&#33258;&#28982;&#25512;&#24191;&#65292;&#20801;&#35768;&#36164;&#28304;&#36890;&#36807;&#27491;&#20540;&#34917;&#20805;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26041;&#26696;&#65292;&#35813;&#31639;&#27861;&#32467;&#21512;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#25216;&#26415;&#21644;&#32972;&#21253;&#25991;&#29486;&#30340;&#24605;&#24819;&#65292;&#33021;&#22815;&#22788;&#29702;&#20219;&#20309;&#21487;&#34917;&#32473;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.08470</link><description>&lt;p&gt;
&#21487;&#34917;&#32473;&#32972;&#21253;&#26426;&#21046;&#19979;&#30340;&#36172;&#21338;&#31639;&#27861;&#65306;&#20004;&#20840;&#20854;&#32654;&#20043;&#36947;
&lt;/p&gt;
&lt;p&gt;
Bandits with Replenishable Knapsacks: the Best of both Worlds. (arXiv:2306.08470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08470
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;BwK&#26694;&#26550;&#33258;&#28982;&#25512;&#24191;&#65292;&#20801;&#35768;&#36164;&#28304;&#36890;&#36807;&#27491;&#20540;&#34917;&#20805;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26041;&#26696;&#65292;&#35813;&#31639;&#27861;&#32467;&#21512;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#25216;&#26415;&#21644;&#32972;&#21253;&#25991;&#29486;&#30340;&#24605;&#24819;&#65292;&#33021;&#22815;&#22788;&#29702;&#20219;&#20309;&#21487;&#34917;&#32473;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#21253;&#36172;&#21338;&#26426;&#21046;(BwK)&#27169;&#22411;&#36866;&#29992;&#20110;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#21830;&#20570;&#20986;&#19968;&#31995;&#21015;&#30340;&#20915;&#31574;&#65292;&#21463;&#21040;&#36164;&#28304;&#28040;&#32791;&#30340;&#32422;&#26463;&#12290;&#20256;&#32479;&#27169;&#22411;&#20551;&#35774;&#27599;&#20010;&#21160;&#20316;&#28040;&#32791;&#38750;&#36127;&#36164;&#28304;&#65292;&#36807;&#31243;&#22312;&#21021;&#22987;&#39044;&#31639;&#23436;&#20840;&#29992;&#23613;&#26102;&#32467;&#26463;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;BwK&#26694;&#26550;&#30340;&#19968;&#31181;&#33258;&#28982;&#25512;&#24191;&#65292;&#20801;&#35768;&#38750;&#21333;&#35843;&#30340;&#36164;&#28304;&#21033;&#29992;&#65292;&#21363;&#36164;&#28304;&#21487;&#20197;&#36890;&#36807;&#27491;&#20540;&#34917;&#20805;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20339;&#23454;&#36341;&#21452;&#37325;&#27169;&#26495;&#65292;&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#23384;&#22312;&#21512;&#36866;&#21407;&#22987;&#36951;&#25022;&#26368;&#23567;&#21270;&#22120;&#30340;&#21487;&#34917;&#32473;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#24403;$B=\Omega(T)$&#25110;&#27599;&#36718;&#34917;&#32473;&#25968;&#26159;&#27491;&#24120;&#25968;&#26102;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20445;&#35777;&#20102;&#24120;&#25968;&#31454;&#20105;&#27604;&#29575;$&#945;$&#30340;&#31532;&#19968;&#31687;&#27491;&#38754;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#22312;&#38543;&#26426;&#36755;&#20837;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20135;&#29983;&#19968;&#20010;&#20381;&#36182;&#20110;&#38382;&#39064;&#23454;&#20363;&#21644;&#36164;&#28304;&#28040;&#32791;&#30340;&#24120;&#25968;$\alpha$&#21644;&#39044;&#31639;$B$&#30340;&#23454;&#20363;&#26080;&#20851;&#30340;&#31454;&#20105;&#27604;&#29575;$\alpha\log B$&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22312;&#32447;&#20984;&#20248;&#21270;&#25216;&#26415;&#21644;&#32972;&#21253;&#25991;&#29486;&#30340;&#24605;&#24819;&#30340;&#26032;&#39062;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The bandits with knapsack (BwK) framework models online decision-making problems in which an agent makes a sequence of decisions subject to resource consumption constraints. The traditional model assumes that each action consumes a non-negative amount of resources and the process ends when the initial budgets are fully depleted. We study a natural generalization of the BwK framework which allows non-monotonic resource utilization, i.e., resources can be replenished by a positive amount. We propose a best-of-both-worlds primal-dual template that can handle any online learning problem with replenishment for which a suitable primal regret minimizer exists. In particular, we provide the first positive results for the case of adversarial inputs by showing that our framework guarantees a constant competitive ratio $\alpha$ when $B=\Omega(T)$ or when the possible per-round replenishment is a positive constant. Moreover, under a stochastic input model, our algorithm yields an instance-independ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;</title><link>http://arxiv.org/abs/2306.08432</link><description>&lt;p&gt;
&#25209;&#27425;&#20351;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#23567;&#35268;&#33539;&#39118;&#38505;&#31283;&#23450;
&lt;/p&gt;
&lt;p&gt;
Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#65292;&#36890;&#24120;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#20043;&#38388;&#25552;&#20379;&#26377;&#29992;&#30340;&#26435;&#34913;&#12290;&#26412;&#25991;&#36890;&#36807;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#29305;&#24449;&#30340;&#26368;&#23567;&#35268;&#33539;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#25209;&#37327;&#20998;&#21306;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#24314;&#35758;&#26368;&#23567;&#35268;&#33539;&#20272;&#35745;&#37327;&#30340;&#33258;&#28982;&#23567;&#25209;&#37327;&#29256;&#26412;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#34920;&#26126;&#20854;&#19982;&#22122;&#22768;&#27700;&#24179;&#20197;&#21450;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#25104;&#21453;&#27604;&#65292;&#23545;&#20110;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#12290;&#19982;&#26368;&#23567;&#35268;&#33539;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#31283;&#23450;&#30340;&#39118;&#38505;&#34892;&#20026;&#65292;&#20854;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#19978;&#21333;&#35843;&#36882;&#22686;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25209;&#22788;&#29702;&#25152;&#25552;&#20379;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21487;&#20197;&#36890;&#36807;&#29305;&#24449;&#37325;&#21472;&#26469;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22810;&#25968;&#25454;&#28304;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;HetPEVI&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#25968;&#25454;&#35206;&#30422;&#29575;&#39640;&#30340;&#24773;&#20917;&#19979;&#21487;&#34892;&#19988;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2306.08364</link><description>&lt;p&gt;
&#36890;&#36807;&#25200;&#21160;&#25968;&#25454;&#28304;&#21487;&#35777;&#26126;&#39640;&#25928;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources. (arXiv:2306.08364v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08364
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#29992;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#22810;&#25968;&#25454;&#28304;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;HetPEVI&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#25968;&#25454;&#35206;&#30422;&#29575;&#39640;&#30340;&#24773;&#20917;&#19979;&#21487;&#34892;&#19988;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#20851;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#22823;&#22810;&#32771;&#34385;&#30340;&#26159;&#20174;&#30446;&#26631;&#20219;&#21153;&#30452;&#25509;&#37319;&#26679;&#24471;&#21040;&#30340;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#25968;&#25454;&#32463;&#24120;&#26469;&#33258;&#20110;&#20960;&#20010;&#24322;&#26500;&#20294;&#30456;&#20851;&#30340;&#28304;&#12290;&#37492;&#20110;&#36825;&#19968;&#24046;&#36317;&#65292;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20174;&#34987;&#38543;&#26426;&#25200;&#21160;&#29256;&#26412;&#30340;&#30446;&#26631;&#20219;&#21153;&#20013;&#25910;&#38598;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#20174;&#32780;&#26356;&#20005;&#26684;&#22320;&#29702;&#35299;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#20449;&#24687;&#35770;&#19979;&#30028;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#38500;&#20102;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#20043;&#22806;&#23545;&#25152;&#28041;&#21450;&#30340;&#28304;&#25968;&#37327;&#30340;&#24517;&#35201;&#35201;&#27714;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;HetPEVI&#65292;&#23427;&#21516;&#26102;&#32771;&#34385;&#26469;&#33258;&#27599;&#20010;&#25968;&#25454;&#28304;&#30340;&#26377;&#38480;&#25968;&#37327;&#30340;&#25968;&#25454;&#26679;&#26412;&#30340;&#26679;&#26412;&#19981;&#30830;&#23450;&#24615;&#20197;&#21450;&#30001;&#20110;&#26377;&#38480;&#25968;&#37327;&#30340;&#21487;&#29992;&#25968;&#25454;&#28304;&#32780;&#20135;&#29983;&#30340;&#28304;&#19981;&#30830;&#23450;&#24615;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#21482;&#35201;&#25968;&#25454;&#28304;&#20849;&#21516;&#25552;&#20379;&#20102;&#33391;&#22909;&#30340;&#25968;&#25454;&#35206;&#30422;&#29575;&#65292;HetPEVI&#23601;&#33021;&#35299;&#20915;&#30446;&#26631;&#20219;&#21153;&#12290;&#27492;&#22806;&#65292;HetPEVI&#34987;&#35777;&#26126;&#26159;&#21487;&#34892;&#30340;&#19988;&#25928;&#29575;&#39640;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing theoretical studies on offline reinforcement learning (RL) mostly consider a dataset sampled directly from the target task. In practice, however, data often come from several heterogeneous but related sources. Motivated by this gap, this work aims at rigorously understanding offline RL with multiple datasets that are collected from randomly perturbed versions of the target task instead of from itself. An information-theoretic lower bound is derived, which reveals a necessary requirement on the number of involved sources in addition to that on the number of data samples. Then, a novel HetPEVI algorithm is proposed, which simultaneously considers the sample uncertainties from a finite number of data samples per data source and the source uncertainties due to a finite number of available data sources. Theoretical analyses demonstrate that HetPEVI can solve the target task as long as the data sources collectively provide a good data coverage. Moreover, HetPEVI is demonstrated to b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;GPLVM&#25512;&#24191;&#21040;&#38750;&#39640;&#26031;&#35266;&#27979;&#24773;&#20917;&#19979;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#24314;&#27169;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;MCMC&#36827;&#34892;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08352</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#36125;&#21494;&#26031;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Bayesian Non-linear Latent Variable Modeling via Random Fourier Features. (arXiv:2306.08352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23558;GPLVM&#25512;&#24191;&#21040;&#38750;&#39640;&#26031;&#35266;&#27979;&#24773;&#20917;&#19979;&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#24314;&#27169;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;MCMC&#36827;&#34892;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;(GPLVM)&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#38750;&#32447;&#24615;&#38477;&#32500;&#12289;&#30697;&#38453;&#20998;&#35299;&#21644;&#29366;&#24577;&#31354;&#38388;&#24314;&#27169;&#30340;&#27010;&#29575;&#26041;&#27861;&#12290;&#24403;&#25968;&#25454;&#20284;&#28982;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;&#65292;GPLVM&#30340;&#25512;&#26029;&#25165;&#26159;&#21487;&#35745;&#31639;&#30340;&#12290;&#27492;&#22806;&#65292;GPLVM&#30340;&#25512;&#26029;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#33719;&#24471;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;&#28857;&#20272;&#35745; or &#21464;&#20998;&#36817;&#20284;&#65292;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#25110;&#35823;&#21028;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;MCMC&#36827;&#34892;&#24191;&#20041;&#36125;&#21494;&#26031;&#38750;&#32447;&#24615;&#28508;&#21464;&#37327;&#24314;&#27169;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#23558;&#39640;&#26031;&#36807;&#31243;&#26144;&#23556;&#20013;&#30340;&#26680;&#20989;&#25968;&#29992;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;&#36817;&#20284;&#30340;&#20851;&#38190;&#27934;&#23519;&#21147;&#26159;&#25105;&#20204;&#21487;&#20197;&#35745;&#31639;&#20986;&#30456;&#23545;&#20110;&#28508;&#21464;&#37327;&#30340;&#21518;&#39564;&#26799;&#24230;&#65292;&#20174;&#32780;&#23558;GPLVM&#25512;&#24191;&#21040;&#38750;&#39640;&#26031;&#35266;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Gaussian process latent variable model (GPLVM) is a popular probabilistic method used for nonlinear dimension reduction, matrix factorization, and state-space modeling. Inference for GPLVMs is computationally tractable only when the data likelihood is Gaussian. Moreover, inference for GPLVMs has typically been restricted to obtaining maximum a posteriori point estimates, which can lead to overfitting, or variational approximations, which mischaracterize the posterior uncertainty. Here, we present a method to perform Markov chain Monte Carlo (MCMC) inference for generalized Bayesian nonlinear latent variable modeling. The crucial insight necessary to generalize GPLVMs to arbitrary observation models is that we approximate the kernel function in the Gaussian process mappings with random Fourier features; this allows us to compute the gradient of the posterior in closed form with respect to the latent variables. We show that we can generalize GPLVMs to non-Gaussian observations, such 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#23398;&#20064;&#26576;&#20123;&#20809;&#28369;&#20989;&#25968;&#31867;&#65292;&#20855;&#26377;&#36866;&#24403;&#26435;&#37325;&#38480;&#21046;&#25110;&#27491;&#21017;&#21270;&#30340;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26368;&#23567;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#20316;&#32773;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#25104;&#21151;&#35777;&#26126;&#22312;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#26159;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#12290;&#21516;&#26102;&#20316;&#32773;&#36824;&#24471;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;Rademacher&#22797;&#26434;&#24230;&#30340;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.08321</link><description>&lt;p&gt;
&#21033;&#29992;&#36807;&#21442;&#25968;&#21270;&#30340;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Nonparametric regression using over-parameterized shallow ReLU neural networks. (arXiv:2306.08321v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08321
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#65292;&#23545;&#20110;&#23398;&#20064;&#26576;&#20123;&#20809;&#28369;&#20989;&#25968;&#31867;&#65292;&#20855;&#26377;&#36866;&#24403;&#26435;&#37325;&#38480;&#21046;&#25110;&#27491;&#21017;&#21270;&#30340;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26368;&#23567;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#20316;&#32773;&#36890;&#36807;&#23545;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#25104;&#21151;&#35777;&#26126;&#22312;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#26159;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#12290;&#21516;&#26102;&#20316;&#32773;&#36824;&#24471;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;Rademacher&#22797;&#26434;&#24230;&#30340;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#26435;&#37325;&#24471;&#21040;&#21512;&#36866;&#30340;&#38480;&#21046;&#25110;&#27491;&#21017;&#21270;&#65292;&#37027;&#20040;&#21487;&#20197;&#35777;&#26126;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36798;&#21040;&#26576;&#20123;&#20809;&#28369;&#20989;&#25968;&#31867;&#30340;&#23398;&#20064;&#26368;&#23567;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#65288;&#26368;&#22810;&#23545;&#25968;&#22240;&#25968;&#65289;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#27973;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26469;&#20272;&#35745;&#26410;&#30693;&#30340;$d$&#21464;&#37327;&#20989;&#25968;&#12290;&#20551;&#35774;&#22238;&#24402;&#20989;&#25968;&#26159;&#20174;&#20855;&#26377;&#20809;&#28369;&#24230;$\alpha &lt; (d+3)/2$&#30340;Holder&#31354;&#38388;&#25110;&#23545;&#24212;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#21464;&#21270;&#31354;&#38388;&#20013;&#23398;&#20064;&#30340;&#65292;&#21518;&#32773;&#21487;&#20197;&#35270;&#20026;&#26080;&#38480;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#20855;&#26377;&#26435;&#37325;&#26576;&#20123;&#33539;&#25968;&#32422;&#26463;&#30340;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#26159;&#26368;&#23567;&#21270;&#26368;&#20248;&#30340;&#65292;&#22914;&#26524;&#32593;&#32476;&#23485;&#24230;&#36275;&#22815;&#22823;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#26412;&#22320;Rademacher&#22797;&#26434;&#24230;&#26080;&#20851;&#30340;&#19978;&#30028;&#65292;&#36825;&#21487;&#33021;&#26159;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is shown that over-parameterized neural networks can achieve minimax optimal rates of convergence (up to logarithmic factors) for learning functions from certain smooth function classes, if the weights are suitably constrained or regularized. Specifically, we consider the nonparametric regression of estimating an unknown $d$-variate function by using shallow ReLU neural networks. It is assumed that the regression function is from the H\"older space with smoothness $\alpha&lt;(d+3)/2$ or a variation space corresponding to shallow neural networks, which can be viewed as an infinitely wide neural network. In this setting, we prove that least squares estimators based on shallow neural networks with certain norm constraints on the weights are minimax optimal, if the network width is sufficiently large. As a byproduct, we derive a new size-independent bound for the local Rademacher complexity of shallow ReLU neural networks, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;AOGD-ALD&#21644;NONS-ALD&#65292;&#21487;&#20197;&#22312;&#20122;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#36798;&#21040;&#20960;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#24230;&#65292;&#36890;&#36807;&#25511;&#21046;&#36817;&#20284;&#35823;&#24046;&#32500;&#25252;&#19968;&#32452;&#29992;&#20110;&#36817;&#20284;&#26680;&#26144;&#23556;&#30340;&#20960;&#20046;&#27491;&#20132;&#22522;&#12290;</title><link>http://arxiv.org/abs/2306.08320</link><description>&lt;p&gt;
&#22312;&#32447;&#26680;&#22238;&#24402;&#30340;&#20122;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24230;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Nearly Optimal Algorithms with Sublinear Computational Complexity for Online Kernel Regression. (arXiv:2306.08320v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;AOGD-ALD&#21644;NONS-ALD&#65292;&#21487;&#20197;&#22312;&#20122;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#36798;&#21040;&#20960;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#24230;&#65292;&#36890;&#36807;&#25511;&#21046;&#36817;&#20284;&#35823;&#24046;&#32500;&#25252;&#19968;&#32452;&#29992;&#20110;&#36817;&#20284;&#26680;&#26144;&#23556;&#30340;&#20960;&#20046;&#27491;&#20132;&#22522;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#26680;&#22238;&#24402;&#20013;&#36951;&#25022;&#21644;&#35745;&#31639;&#20195;&#20215;&#20043;&#38388;&#30340;&#26435;&#34913;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#20043;&#21069;&#30340;&#31639;&#27861;&#22312;&#26435;&#34913;&#19978;&#21162;&#21147;&#26102;&#26080;&#27861;&#20445;&#25345;&#22312;&#20122;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#30340;&#26368;&#20248;&#36951;&#25022;&#30028;&#12290;&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26032;&#31639;&#27861;AOGD-ALD&#21644;NONS-ALD&#65292;&#21487;&#20197;&#22312;&#20122;&#32447;&#24615;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#20445;&#25345;&#20960;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#24230;&#65292;&#24182;&#32473;&#20986;&#25105;&#20204;&#30340;&#31639;&#27861;&#36866;&#29992;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20004;&#20010;&#31639;&#27861;&#21160;&#24577;&#22320;&#32500;&#25252;&#19968;&#32452;&#29992;&#20110;&#36817;&#20284;&#26680;&#26144;&#23556;&#30340;&#20960;&#20046;&#27491;&#20132;&#22522;&#65292;&#24182;&#36890;&#36807;&#25511;&#21046;&#36817;&#20284;&#35823;&#24046;&#26469;&#20445;&#25345;&#36817;&#20284;&#26368;&#20248;&#30340;&#36951;&#25022;&#24230;&#12290;&#22522;&#25968;&#21462;&#20915;&#20110;&#36817;&#20284;&#35823;&#24046;&#21644;&#26680;&#30697;&#38453;&#29305;&#24449;&#20540;&#30340;&#34928;&#20943;&#29575;&#12290;&#22914;&#26524;&#29305;&#24449;&#20540;&#21576;&#25351;&#25968;&#34928;&#20943;&#65292;&#21017;AOGD-ALD&#21644;NONS-ALD&#20998;&#21035;&#22312;$O(\ln^2{T})$&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#36798;&#21040;$O(\sqrt{L(f)})$&#21644;$O(\mathrm{d}_{\mathrm{eff}}(\mu)\ln{T})$&#30340;&#36951;&#25022;&#24230;&#12290;&#22914;&#26524;&#29305;&#24449;&#20540;&#21576;&#22810;&#39033;&#24335;&#34928;&#20943;&#65292;&#21017;&#20004;&#20010;&#31639;&#27861;&#22312;$O(T^{\frac{-2}{3}}(\ln{T})^{\frac{4}{3}})$&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19979;&#20998;&#21035;&#36798;&#21040;$O(\sqrt{L(f)})$&#36951;&#25022;&#24230;&#21644;$O(\mathrm{d}_{\mathrm{eff}}(\mu)(\ln{T})^{\frac{2}{3}})$&#36951;&#25022;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The trade-off between regret and computational cost is a fundamental problem for online kernel regression, and previous algorithms worked on the trade-off can not keep optimal regret bounds at a sublinear computational complexity. In this paper, we propose two new algorithms, AOGD-ALD and NONS-ALD, which can keep nearly optimal regret bounds at a sublinear computational complexity, and give sufficient conditions under which our algorithms work. Both algorithms dynamically maintain a group of nearly orthogonal basis used to approximate the kernel mapping, and keep nearly optimal regret bounds by controlling the approximate error. The number of basis depends on the approximate error and the decay rate of eigenvalues of the kernel matrix. If the eigenvalues decay exponentially, then AOGD-ALD and NONS-ALD separately achieves a regret of $O(\sqrt{L(f)})$ and $O(\mathrm{d}_{\mathrm{eff}}(\mu)\ln{T})$ at a computational complexity in $O(\ln^2{T})$. If the eigenvalues decay polynomially with d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;FLORAS&#26041;&#27861;&#65292;&#21487;&#28040;&#38500;&#21457;&#36865;&#31471;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#39033;&#30446;&#32423;&#21644;&#23458;&#25143;&#32423;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#12290;FLORAS&#21487;&#20197;&#28789;&#27963;&#22320;&#23454;&#29616;&#19981;&#21516;&#30340;&#24046;&#20998;&#38544;&#31169;&#31561;&#32423;&#65292;&#24182;&#19988;&#36890;&#36807;&#25512;&#23548;&#25910;&#25947;&#30028;&#38480;&#65292;&#23454;&#29616;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#38544;&#31169;&#20445;&#35777;&#20043;&#38388;&#30340;&#24179;&#31283;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.08280</link><description>&lt;p&gt;
&#20351;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;&#24046;&#20998;&#38544;&#31169;&#26080;&#32447;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Wireless Federated Learning Using Orthogonal Sequences. (arXiv:2306.08280v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;FLORAS&#26041;&#27861;&#65292;&#21487;&#28040;&#38500;&#21457;&#36865;&#31471;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#39033;&#30446;&#32423;&#21644;&#23458;&#25143;&#32423;&#30340;&#24046;&#20998;&#38544;&#31169;&#20445;&#35777;&#12290;FLORAS&#21487;&#20197;&#28789;&#27963;&#22320;&#23454;&#29616;&#19981;&#21516;&#30340;&#24046;&#20998;&#38544;&#31169;&#31561;&#32423;&#65292;&#24182;&#19988;&#36890;&#36807;&#25512;&#23548;&#25910;&#25947;&#30028;&#38480;&#65292;&#23454;&#29616;&#20102;&#25910;&#25947;&#36895;&#24230;&#21644;&#38544;&#31169;&#20445;&#35777;&#20043;&#38388;&#30340;&#24179;&#31283;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#31169;&#20445;&#25252;&#19978;&#34892;&#31354;&#20013;&#35745;&#31639;&#26041;&#27861;FLORAS&#65292;&#29992;&#20110;&#21333;&#36755;&#20837;&#21333;&#36755;&#20986;&#65288;SISO&#65289;&#26080;&#32447;&#32852;&#21512;&#23398;&#20064;&#65288;FL&#65289;&#31995;&#32479;&#12290;FLORAS&#20174;&#36890;&#20449;&#35774;&#35745;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#21033;&#29992;&#27491;&#20132;&#24207;&#21015;&#30340;&#24615;&#36136;&#28040;&#38500;&#20102;&#21457;&#36865;&#31471;&#30340;&#20449;&#36947;&#29366;&#24577;&#20449;&#24687;&#65288;CSIT&#65289;&#35201;&#27714;&#12290;&#20174;&#38544;&#31169;&#20445;&#25252;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;FLORAS&#21487;&#20197;&#25552;&#20379;&#39033;&#30446;&#32423;&#21644;&#23458;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#35843;&#25972;&#31995;&#32479;&#21442;&#25968;&#65292;FLORAS&#21487;&#20197;&#22312;&#19981;&#22686;&#21152;&#25104;&#26412;&#30340;&#24773;&#20917;&#19979;&#28789;&#27963;&#22320;&#23454;&#29616;&#19981;&#21516;&#30340;DP&#31561;&#32423;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;FL&#25910;&#25947;&#30028;&#38480;&#65292;&#32467;&#21512;&#38544;&#31169;&#20445;&#35777;&#65292;&#21487;&#20197;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#24046;&#20998;&#38544;&#31169;&#32423;&#21035;&#20043;&#38388;&#23454;&#29616;&#24179;&#31283;&#30340;&#26435;&#34913;&#12290;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#20102;FLORAS&#30456;&#23545;&#20110;&#22522;&#20934;AirComp&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#26524;&#21487;&#20197;&#25351;&#23548;&#19981;&#21516;&#26435;&#34913;&#26465;&#20214;&#19979;&#30340;&#38544;&#31169;&#20445;&#25252;FL&#30340;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel privacy-preserving uplink over-the-air computation (AirComp) method, termed FLORAS, for single-input single-output (SISO) wireless federated learning (FL) systems. From the communication design perspective, FLORAS eliminates the requirement of channel state information at the transmitters (CSIT) by leveraging the properties of orthogonal sequences. From the privacy perspective, we prove that FLORAS can offer both item-level and client-level differential privacy (DP) guarantees. Moreover, by adjusting the system parameters, FLORAS can flexibly achieve different DP levels at no additional cost. A novel FL convergence bound is derived which, combined with the privacy guarantees, allows for a smooth tradeoff between convergence rate and differential privacy levels. Numerical results demonstrate the advantages of FLORAS compared with the baseline AirComp method, and validate that our analytical results can guide the design of privacy-preserving FL with different tradeoff 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#22270;&#20687;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#30340;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#28789;&#27963;&#20284;&#28982;&#65292;&#32467;&#21512;&#20004;&#31181;&#26694;&#26550;&#30340;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;SVAE&#30340;&#26032;&#31639;&#27861;&#65292;&#19982;&#27492;&#21516;&#26102;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#20248;&#21270;&#21019;&#26032;&#20351;&#24471;SVAE&#39318;&#27425;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2306.08230</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#31163;&#25955;&#34920;&#31034;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#26080;&#20559;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unbiased Learning of Deep Generative Models with Structured Discrete Representations. (arXiv:2306.08230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08230
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#22270;&#20687;&#27169;&#22411;&#30340;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#28145;&#24230;&#23398;&#20064;&#30340;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#28789;&#27963;&#20284;&#28982;&#65292;&#32467;&#21512;&#20004;&#31181;&#26694;&#26550;&#30340;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;SVAE&#30340;&#26032;&#31639;&#27861;&#65292;&#19982;&#27492;&#21516;&#26102;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#20248;&#21270;&#21019;&#26032;&#20351;&#24471;SVAE&#39318;&#27425;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#22270;&#24418;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#32452;&#21512;&#65292;&#25105;&#20204;&#23398;&#20064;&#20855;&#26377;&#20004;&#31181;&#26694;&#26550;&#20248;&#21183;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290; &#32467;&#26500;&#21270;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;SVAE&#65289;&#20174;&#22270;&#24418;&#27169;&#22411;&#32487;&#25215;&#32467;&#26500;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#20174;&#28145;&#24230;&#23398;&#20064;&#20013;&#32487;&#25215;&#20102;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#28789;&#27963;&#20284;&#28982;&#65292;&#20294;&#26159;&#20250;&#24102;&#26469;&#30456;&#24403;&#22823;&#30340;&#20248;&#21270;&#25361;&#25112;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;SVAE&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#19988;&#39318;&#27425;&#35777;&#26126;&#20102;SVAE&#22312;&#21547;&#26377;&#32570;&#22833;&#25968;&#25454;&#19988;&#21253;&#21547;&#31163;&#25955;&#28508;&#21464;&#37327;&#26102;&#22788;&#29702;&#22810;&#27169;&#24577;&#19981;&#30830;&#23450;&#24615;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#20869;&#23384;&#39640;&#25928;&#38544;&#24335;&#24494;&#20998;&#26041;&#26696;&#20351;&#24471;SVAE&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#26469;&#23398;&#20064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#40065;&#26834;&#24615;&#12290;&#20026;&#20102;&#26356;&#24555;&#22320;&#23398;&#20064;&#20934;&#30830;&#30340;&#22270;&#24418;&#27169;&#22411;&#21442;&#25968;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#35745;&#31639;&#33258;&#28982;&#26799;&#24230;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#25163;&#21160;&#36827;&#34892;&#23548;&#20986;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#21457;&#29616;&#30340;&#20559;&#24046;&#12290;&#36825;&#20123;&#20248;&#21270;&#21019;&#26032;&#20351;&#24471;&#39318;&#27425;&#33021;&#22815;&#23558;SVAE&#19982;&#26368;&#20808;&#36827;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
By composing graphical models with deep learning architectures, we learn generative models with the strengths of both frameworks. The structured variational autoencoder (SVAE) inherits structure and interpretability from graphical models, and flexible likelihoods for high-dimensional data from deep learning, but poses substantial optimization challenges. We propose novel algorithms for learning SVAEs, and are the first to demonstrate the SVAE's ability to handle multimodal uncertainty when data is missing by incorporating discrete latent variables. Our memory-efficient implicit differentiation scheme makes the SVAE tractable to learn via gradient descent, while demonstrating robustness to incomplete optimization. To more rapidly learn accurate graphical model parameters, we derive a method for computing natural gradients without manual derivations, which avoids biases found in prior work. These optimization innovations enable the first comparisons of the SVAE to state-of-the-art time s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;CLIP&#27169;&#22411;&#65288;Dp-CLIP&#65289;&#65292;&#26088;&#22312;&#20445;&#25252;&#22810;&#27169;&#24577;AI&#20219;&#21153;&#20013;&#30340;&#25968;&#25454;&#38544;&#31169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#34920;&#26126;&#20854;&#19982;&#26631;&#20934;&#38750;&#31169;&#26377;CLIP&#27169;&#22411;&#30456;&#27604;&#20855;&#26377;&#21516;&#31561;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.08173</link><description>&lt;p&gt;
&#22312;&#22810;&#27169;&#24577;&#20154;&#24037;&#26234;&#33021;&#20013;&#20445;&#25252;&#25968;&#25454;&#65306;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#26041;&#27861;&#29992;&#20110;CLIP&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Safeguarding Data in Multimodal AI: A Differentially Private Approach to CLIP Training. (arXiv:2306.08173v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08173
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;CLIP&#27169;&#22411;&#65288;Dp-CLIP&#65289;&#65292;&#26088;&#22312;&#20445;&#25252;&#22810;&#27169;&#24577;AI&#20219;&#21153;&#20013;&#30340;&#25968;&#25454;&#38544;&#31169;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#24182;&#34920;&#26126;&#20854;&#19982;&#26631;&#20934;&#38750;&#31169;&#26377;CLIP&#27169;&#22411;&#30456;&#27604;&#20855;&#26377;&#21516;&#31561;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#20154;&#24037;&#26234;&#33021;&#30340;&#25104;&#21151;&#24341;&#21457;&#20102;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#20013;&#25968;&#25454;&#38544;&#31169;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;CLIP&#36890;&#36807;&#23545;&#22270;&#20687;&#21644;&#25991;&#26412;&#30340;&#32852;&#21512;&#35757;&#32451;&#24443;&#24213;&#25913;&#21464;&#20102;&#22810;&#27169;&#24577;&#23398;&#20064;&#65292;&#20294;&#20854;&#21487;&#33021;&#26080;&#24847;&#20013;&#25259;&#38706;&#25935;&#24863;&#20449;&#24687;&#30340;&#28508;&#21147;&#38656;&#35201;&#38598;&#25104;&#20445;&#25252;&#38544;&#31169;&#30340;&#26426;&#21046;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#27604;&#35821;&#35328;-&#22270;&#20687;&#39044;&#35757;&#32451;&#65288;CLIP&#65289;&#27169;&#22411;&#30340;&#24046;&#20998;&#38544;&#31169;&#25913;&#36827;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#38544;&#31169;&#38382;&#39064;&#65292;&#21516;&#26102;&#20445;&#25345;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;Dp-CLIP&#22312;&#21253;&#25324;&#22270;&#20687;&#20998;&#31867;&#21644;&#35270;&#35273;&#38382;&#31572;&#31561;&#22810;&#26679;&#30340;&#35270;&#35273;&#21644;&#35821;&#35328;&#20219;&#21153;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#35780;&#20272;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#25345;&#20102;&#19982;&#26631;&#20934;&#30340;&#38750;&#31169;&#26377;CLIP&#27169;&#22411;&#21516;&#31561;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#32447;&#24615;&#34920;&#31034;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#26799;&#24230;&#34987;&#21098;&#36753;&#26102;&#23454;&#29992;&#24615;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
The surge in multimodal AI's success has sparked concerns over data privacy in vision-and-language tasks. While CLIP has revolutionized multimodal learning through joint training on images and text, its potential to unintentionally disclose sensitive information necessitates the integration of privacy-preserving mechanisms. We introduce a differentially private adaptation of the Contrastive Language-Image Pretraining (CLIP) model that effectively addresses privacy concerns while retaining accuracy. Our proposed method, Dp-CLIP, is rigorously evaluated on benchmark datasets encompassing diverse vision-and-language tasks such as image classification and visual question answering. We demonstrate that our approach retains performance on par with the standard non-private CLIP model. Furthermore, we analyze our proposed algorithm under linear representation settings. We derive the convergence rate of our algorithm and show a trade-off between utility and privacy when gradients are clipped pe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;SGD&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35757;&#32451;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#21487;&#34987;&#35777;&#26126;&#20026;&#21487;&#21387;&#32553;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#38750;&#24179;&#20961;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2306.08125</link><description>&lt;p&gt;
&#24102;&#26377;&#27785;&#37325;&#23614;&#37096;SGD&#35757;&#32451;&#30340;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#21487;&#21387;&#32553;&#24615;
&lt;/p&gt;
&lt;p&gt;
Implicit Compressibility of Overparametrized Neural Networks Trained with Heavy-Tailed SGD. (arXiv:2306.08125v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;SGD&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35757;&#32451;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#36755;&#20986;&#21487;&#34987;&#35777;&#26126;&#20026;&#21487;&#21387;&#32553;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#38750;&#24179;&#20961;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20943;&#23569;&#35745;&#31639;&#38656;&#27714;&#21644;&#21387;&#32553;&#19982;&#27867;&#21270;&#35823;&#24046;&#20043;&#38388;&#30340;&#26174;&#24335;&#20851;&#31995;&#65292;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#25104;&#20026;&#36234;&#26469;&#36234;&#37325;&#35201;&#30340;&#30740;&#31350;&#23545;&#35937;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#21487;&#20197;&#24433;&#21709;&#23398;&#20064;&#21442;&#25968;&#21521;&#37327;&#30340;&#21387;&#32553;&#24615;&#12290;&#34429;&#28982;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#35757;&#32451;&#21160;&#24577;&#23545;&#21387;&#32553;&#24615;&#30340;&#24433;&#21709;&#65292;&#20294;&#26159;&#23427;&#20204;&#20381;&#36182;&#20110;&#19981;&#21487;&#39564;&#35777;&#30340;&#20551;&#35774;&#65292;&#30001;&#20110;&#38544;&#21547;&#24615;&#36136;&#65292;&#24471;&#20986;&#30340;&#29702;&#35770;&#24182;&#27809;&#26377;&#25552;&#20379;&#23454;&#29992;&#30340;&#25351;&#23548;&#26041;&#38024;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;SGD&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#24471;&#31639;&#27861;&#30340;&#36755;&#20986;&#33021;&#22815;&#34987;&#35777;&#26126;&#26159;&#21487;&#21387;&#32553;&#30340;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#38750;&#24179;&#20961;&#20551;&#35774;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20351;&#29992;SGD&#35757;&#32451;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#27880;&#20837;&#38468;&#21152;&#30340;&#27785;&#37325;&#23614;&#37096;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network compression has been an increasingly important subject, due to its practical implications in terms of reducing the computational requirements and its theoretical implications, as there is an explicit connection between compressibility and the generalization error. Recent studies have shown that the choice of the hyperparameters of stochastic gradient descent (SGD) can have an effect on the compressibility of the learned parameter vector. Even though these results have shed some light on the role of the training dynamics over compressibility, they relied on unverifiable assumptions and the resulting theory does not provide a practical guideline due to its implicitness. In this study, we propose a simple modification for SGD, such that the outputs of the algorithm will be provably compressible without making any nontrivial assumptions. We consider a one-hidden-layer neural network trained with SGD and we inject additive heavy-tailed noise to the iterates at each iteration.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.07886</link><description>&lt;p&gt;
&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#30340;&#23545;&#31216;&#24615;&#19982;&#20020;&#30028;&#28857;
&lt;/p&gt;
&lt;p&gt;
Symmetry &amp; Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#23545;&#31216;&#32467;&#26500;&#65292;&#23548;&#20986;Puiseux&#32423;&#25968;&#34920;&#31034;&#30340;&#19968;&#31995;&#21015;&#20020;&#30028;&#28857;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20020;&#30028;&#20540;&#21644;Hessian&#35889;&#30340;&#31934;&#30830;&#20998;&#26512;&#20272;&#35745;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#21508;&#31181;&#20960;&#20309;&#38556;&#30861;&#65292;&#38459;&#30861;&#20102;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20351;&#29992;&#65292;&#26368;&#21518;&#65292;&#21033;&#29992;&#19968;&#20010;&#29275;&#39039;&#22810;&#38754;&#20307;&#35770;&#35777;&#20102;&#22266;&#23450;&#23545;&#31216;&#24615;&#30340;&#25152;&#26377;&#20020;&#30028;&#28857;&#30340;&#23436;&#20840;&#26522;&#20030;&#65292;&#24182;&#35777;&#26126;&#20102;&#19982;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38598;&#21512;&#30456;&#27604;&#65292;&#30001;&#20110;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#65292;&#20020;&#30028;&#28857;&#30340;&#38598;&#21512;&#21487;&#33021;&#20250;&#26174;&#31034;&#20986;&#32452;&#21512;&#30340;&#20016;&#23500;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.07479</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;
&lt;/p&gt;
&lt;p&gt;
Incentivizing High-Quality Content in Online Recommender Systems. (arXiv:2306.07479v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#25512;&#33616;&#31995;&#32479;&#20013;&#28608;&#21169;&#39640;&#36136;&#37327;&#20869;&#23481;&#30340;&#31639;&#27861;&#38382;&#39064;&#65292;&#32463;&#20856;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#65292;&#20294;&#26412;&#25991;&#25552;&#20986;&#30340;&#19968;&#31181;&#31639;&#27861;&#36890;&#36807;&#24809;&#32602;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#21019;&#24314;&#32773;&#65292;&#25104;&#21151;&#22320;&#28608;&#21169;&#20102;&#29983;&#20135;&#32773;&#21019;&#36896;&#39640;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20687;TikTok&#21644;YouTube&#36825;&#26679;&#30340;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#65292;&#24179;&#21488;&#30340;&#20915;&#31574;&#31639;&#27861;&#22609;&#36896;&#20102;&#20869;&#23481;&#29983;&#20135;&#32773;&#30340;&#28608;&#21169;&#65292;&#21253;&#25324;&#29983;&#20135;&#32773;&#22312;&#20869;&#23481;&#36136;&#37327;&#19978;&#25237;&#20837;&#22810;&#23569;&#21162;&#21147;&#12290;&#35768;&#22810;&#24179;&#21488;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#65292;&#36825;&#20250;&#20135;&#29983;&#36328;&#26102;&#38388;&#30340;&#28608;&#21169;&#65292;&#22240;&#20026;&#20170;&#22825;&#29983;&#20135;&#30340;&#20869;&#23481;&#20250;&#24433;&#21709;&#26410;&#26469;&#20869;&#23481;&#30340;&#25512;&#33616;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#20135;&#29983;&#30340;&#28608;&#21169;&#65292;&#20998;&#26512;&#20102;&#22312;&#32435;&#20160;&#22343;&#34913;&#19979;&#29983;&#20135;&#30340;&#20869;&#23481;&#36136;&#37327;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20687;Hedge&#21644;EXP3&#36825;&#26679;&#30340;&#32463;&#20856;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20250;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#20302;&#36136;&#37327;&#30340;&#20869;&#23481;&#12290;&#29305;&#21035;&#22320;&#65292;&#20869;&#23481;&#36136;&#37327;&#22312;&#23398;&#20064;&#29575;&#26041;&#38754;&#26377;&#19978;&#38480;&#65292;&#24182;&#19988;&#38543;&#30528;&#20856;&#22411;&#23398;&#20064;&#29575;&#36827;&#23637;&#32780;&#36235;&#36817;&#20110;&#38646;&#12290;&#22312;&#36825;&#19968;&#36127;&#38754;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#22522;&#20110;&#24809;&#32602;&#21019;&#24314;&#20302;&#36136;&#37327;&#20869;&#23481;&#30340;&#29983;&#20135;&#32773;&#8212;&#8212;&#27491;&#30830;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#26032;&#39062;&#30340;&#31574;&#30053;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#20811;&#26381;&#20102;&#22312;&#32452;&#21512;&#35774;&#32622;&#20013;&#24212;&#29992;&#23545;&#25239;&#24615;&#25216;&#26415;&#30340;&#25361;&#25112;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#25104;&#21151;&#22320;&#28608;&#21169;&#29983;&#20135;&#32773;&#21019;&#24314;&#39640;&#36136;&#37327;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
For content recommender systems such as TikTok and YouTube, the platform's decision algorithm shapes the incentives of content producers, including how much effort the content producers invest in the quality of their content. Many platforms employ online learning, which creates intertemporal incentives, since content produced today affects recommendations of future content. In this paper, we study the incentives arising from online learning, analyzing the quality of content produced at a Nash equilibrium. We show that classical online learning algorithms, such as Hedge and EXP3, unfortunately incentivize producers to create low-quality content. In particular, the quality of content is upper bounded in terms of the learning rate and approaches zero for typical learning rate schedules. Motivated by this negative result, we design a different learning algorithm -- based on punishing producers who create low-quality content -- that correctly incentivizes producers to create high-quality co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;</title><link>http://arxiv.org/abs/2305.19259</link><description>&lt;p&gt;
Shuffle SGD&#24635;&#26159;&#27604;SGD&#26356;&#22909;&#65306;&#23545;&#20855;&#26377;&#20219;&#24847;&#25968;&#25454;&#39034;&#24207;&#30340;SGD&#36827;&#34892;&#25913;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Shuffle SGD is Always Better than SGD: Improved Analysis of SGD with Arbitrary Data Orders. (arXiv:2305.19259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;,&#24182;&#34920;&#26126;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#34987;&#24191;&#27867;&#29992;&#20110;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#65292;&#38543;&#26426;&#37325;&#25490;&#65288;RR&#65289;&#21644;&#21333;&#27425;&#27927;&#29260;&#65288;SS&#65289;&#26159;&#36890;&#36807;&#24490;&#29615;&#36941;&#21382;&#35757;&#32451;&#25968;&#25454;&#30340;&#38543;&#26426;&#25110;&#21333;&#20010;&#25490;&#21015;&#30340;&#24120;&#35265;&#36873;&#25321;&#65292;&#28982;&#32780;&#36825;&#20123;&#31639;&#27861;&#22312;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#29616;&#26377;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#30340;&#35757;&#32451;&#22330;&#26223;&#20013;&#65292;&#24403;&#26102;&#20195;&#30340;&#25968;&#37327;&#23567;&#20110;&#35757;&#32451;&#38598;&#22823;&#23567;&#26102;&#65292;RR&#21487;&#33021;&#34920;&#29616;&#19981;&#22914;SGD&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#20801;&#35768;&#20219;&#24847;&#25968;&#25454;&#25490;&#24207;&#30340;&#26222;&#36890;SGD&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#38750;&#20984;&#20989;&#25968;&#24773;&#20917;&#19979;&#30340;&#25913;&#36827;&#25910;&#25947;&#36895;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#38543;&#26426;&#21644;&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#27604;&#32463;&#20856;&#26367;&#25442;&#30340;SGD&#26356;&#24555;&#25110;&#33267;&#23569;&#19982;&#20854;&#19968;&#26679;&#22909;&#65292;&#26080;&#35770;&#36845;&#20195;&#27425;&#25968;&#22914;&#20309;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20984;&#26174;&#20102;&#20351;&#29992;&#38543;&#26426;/&#21333;&#27425;&#27927;&#29260;&#30340;SGD&#30340;&#22909;&#22788;&#65292;&#24182;&#20026;&#20854;&#38750;&#20984;&#25910;&#25947;&#24615;&#36136;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) algorithms are widely used in optimizing neural networks, with Random Reshuffling (RR) and Single Shuffle (SS) being popular choices for cycling through random or single permutations of the training data. However, the convergence properties of these algorithms in the non-convex case are not fully understood. Existing results suggest that, in realistic training scenarios where the number of epochs is smaller than the training set size, RR may perform worse than SGD.  In this paper, we analyze a general SGD algorithm that allows for arbitrary data orderings and show improved convergence rates for non-convex functions. Specifically, our analysis reveals that SGD with random and single shuffling is always faster or at least as good as classical SGD with replacement, regardless of the number of iterations. Overall, our study highlights the benefits of using SGD with random/single shuffling and provides new insights into its convergence properties for non-co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.18061</link><description>&lt;p&gt;
&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#25552;&#39640;&#36719;&#20214;&#36807;&#31243;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging Evolutionary Changes for Software Process Quality. (arXiv:2305.18061v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#36719;&#20214;&#24212;&#29992;&#24517;&#39035;&#19981;&#26029;&#28436;&#36827;&#25165;&#33021;&#20445;&#25345;&#30456;&#20851;&#24615;&#12290;&#20256;&#32479;&#30340;&#36719;&#20214;&#36136;&#37327;&#25511;&#21046;&#26041;&#27861;&#28041;&#21450;&#36719;&#20214;&#36136;&#37327;&#27169;&#22411;&#21644;&#25345;&#32493;&#30340;&#20195;&#30721;&#26816;&#26597;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#19982;&#26368;&#32456;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#20043;&#38388;&#23384;&#22312;&#24378;&#20851;&#32852;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#38388;&#25509;&#25552;&#39640;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#38656;&#35201;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24320;&#21457;&#36807;&#31243;&#30340;&#28436;&#36827;&#21464;&#21270;&#26469;&#25552;&#39640;&#36719;&#20214;&#36136;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#32806;&#39640;&#26031;&#36807;&#31243;&#30340;&#27491;&#20132;&#20998;&#35299;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#21363;&#24341;&#20837;&#29699;&#24418;&#36328;&#22495;&#29305;&#24449;&#65292;&#26500;&#24314;&#26356;&#28789;&#27963;&#30340;&#25968;&#25454;&#20381;&#36182;&#22522;&#20989;&#25968;&#26469;&#32531;&#35299;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.14034</link><description>&lt;p&gt;
&#27491;&#20132;&#35299;&#32806;&#39640;&#26031;&#36807;&#31243;&#30340;&#29699;&#24418;&#24863;&#24212;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes. (arXiv:2304.14034v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35299;&#32806;&#39640;&#26031;&#36807;&#31243;&#30340;&#27491;&#20132;&#20998;&#35299;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#21363;&#24341;&#20837;&#29699;&#24418;&#36328;&#22495;&#29305;&#24449;&#65292;&#26500;&#24314;&#26356;&#28789;&#27963;&#30340;&#25968;&#25454;&#20381;&#36182;&#22522;&#20989;&#25968;&#26469;&#32531;&#35299;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#20855;&#26377;&#35768;&#22810;&#20248;&#28857;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#23398;&#20064;&#34920;&#24449;&#30340;&#33021;&#21147;&#65292;&#22240;&#27492;&#32463;&#24120;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;NNs&#65289;&#36827;&#34892;&#27604;&#36739;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#36890;&#36807;&#22312;&#35825;&#23548;&#21464;&#37327;&#19982;&#21069;&#39304;NN&#30340;&#38544;&#34255;&#21333;&#20803;&#20043;&#38388;&#24314;&#31435;&#32852;&#31995;&#30340;&#36328;&#22495;&#21464;&#20998;GPs&#26469;&#24357;&#21512; GPs&#21644;&#28145;&#24230;NN&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#22312;&#30740;&#31350;&#27492;&#26041;&#27861;&#19982;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#21033;&#29992;GPs&#30340;&#27491;&#20132;&#20998;&#35299;&#26469;&#20943;&#36731;&#36825;&#20123;&#38480;&#21046;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#29699;&#24418;&#36328;&#22495;&#29305;&#24449;&#65292;&#26500;&#24314;&#26356;&#28789;&#27963;&#30340;&#25968;&#25454;&#20381;&#36182;&#22522;&#20989;&#25968;&#65292;&#29992;&#20110;GP&#36924;&#36817;&#30340;&#20027;&#35201;&#21644;&#27491;&#20132;&#20998;&#37327;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#27492;&#26694;&#26550;&#19979;&#21152;&#20837;NN&#28608;&#27963;&#29305;&#24449;&#65292;&#19981;&#20165;&#21487;&#20197;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#65292;&#32780;&#19988;&#27604;&#20854;&#20182;&#31574;&#30053;&#26356;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their many desirable properties, Gaussian processes (GPs) are often compared unfavorably to deep neural networks (NNs) for lacking the ability to learn representations. Recent efforts to bridge the gap between GPs and deep NNs have yielded a new class of inter-domain variational GPs in which the inducing variables correspond to hidden units of a feedforward NN. In this work, we examine some practical issues associated with this approach and propose an extension that leverages the orthogonal decomposition of GPs to mitigate these limitations. In particular, we introduce spherical inter-domain features to construct more flexible data-dependent basis functions for both the principal and orthogonal components of the GP approximation and show that incorporating NN activation features under this framework not only alleviates these shortcomings but is more scalable than alternative strategies. Experiments on multiple benchmark datasets demonstrate the effectiveness of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#22120; B-Learner&#65292;&#23427;&#21487;&#20197;&#22312;&#38480;&#21046;&#38544;&#34255;&#28151;&#28102;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#23398;&#20064; CATE &#20989;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.10577</link><description>&lt;p&gt;
B-Learner&#65306;&#38544;&#34255;&#28151;&#28102;&#19979;&#24322;&#36136;&#22240;&#26524;&#25928;&#24212;&#30340;&#20934;&#31070;&#35861;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
B-Learner: Quasi-Oracle Bounds on Heterogeneous Causal Effects Under Hidden Confounding. (arXiv:2304.10577v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#22120; B-Learner&#65292;&#23427;&#21487;&#20197;&#22312;&#38480;&#21046;&#38544;&#34255;&#28151;&#28102;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#23398;&#20064; CATE &#20989;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#26159;&#35768;&#22810;&#39046;&#22495;&#20013;&#30340;&#37325;&#35201;&#20219;&#21153;&#65292;&#26377;&#21161;&#20110;&#25919;&#31574;&#21644;&#20915;&#31574;&#32773;&#20570;&#20986;&#26356;&#22909;&#30340;&#34892;&#21160;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#65288;CATE&#65289;&#20989;&#25968;&#26041;&#38754;&#21462;&#24471;&#20102;&#40065;&#26834;&#19988;&#39640;&#25928;&#30340;&#26041;&#27861;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#26410;&#32771;&#34385;&#38544;&#34255;&#28151;&#28102;&#30340;&#39118;&#38505;&#65292;&#36825;&#21487;&#33021;&#20250;&#23545;&#22522;&#20110;&#35266;&#23519;&#25968;&#25454;&#30340;&#20219;&#20309;&#22240;&#26524;&#20272;&#35745;&#36896;&#25104;&#20219;&#24847;&#21644;&#19981;&#30693;&#24773;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;B-Learner&#30340;&#20803;&#23398;&#20064;&#22120;&#65292;&#23427;&#21487;&#20197;&#22312;&#38480;&#21046;&#38544;&#34255;&#28151;&#28102;&#27700;&#24179;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#23398;&#20064;CATE&#20989;&#25968;&#30340;&#23574;&#38160;&#30028;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#26368;&#36817;&#38024;&#23545;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#23574;&#38160;&#19988;&#26377;&#25928;&#36793;&#30028;&#32467;&#26524;&#65288;Dorn&#31561;&#20154;&#65292;2021&#65289;&#35843;&#25972;&#20026;Kallus&#65286;Oprescu&#65288;2022&#65289;&#25152;&#25552;&#20379;&#30340;&#31283;&#20581;&#21644;&#27169;&#22411;&#26080;&#20851;&#30340;&#20998;&#24067;&#24335;&#27835;&#30103;&#25928;&#24212;&#23398;&#20064;&#26694;&#26550;&#65292;&#27966;&#29983;&#20986;B-Learner&#12290;B-Learner&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#20363;&#22914;&#38543;&#26426;&#26862;&#26519;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating heterogeneous treatment effects from observational data is a crucial task across many fields, helping policy and decision-makers take better actions. There has been recent progress on robust and efficient methods for estimating the conditional average treatment effect (CATE) function, but these methods often do not take into account the risk of hidden confounding, which could arbitrarily and unknowingly bias any causal estimate based on observational data. We propose a meta-learner called the B-Learner, which can efficiently learn sharp bounds on the CATE function under limits on the level of hidden confounding. We derive the B-Learner by adapting recent results for sharp and valid bounds of the average treatment effect (Dorn et al., 2021) into the framework given by Kallus &amp; Oprescu (2022) for robust and model-agnostic learning of distributional treatment effects. The B-Learner can use any function estimator such as random forests and deep neural networks, and we prove its 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#27010;&#29575;&#35302;&#21457;&#33218;&#30340;&#24773;&#22659;&#32452;&#21512;&#36172;&#21338;&#26426;&#65292;&#22312;&#19981;&#21516;&#26465;&#20214;&#19979;&#35774;&#35745;&#20102;C$^2$-UCB-T&#31639;&#27861;&#21644;VAC$^2$-UCB&#31639;&#27861;&#65292;&#24182;&#20998;&#21035;&#23548;&#20986;&#20102;&#23545;&#24212;&#30340;&#36951;&#25022;&#20540;&#19978;&#38480;&#65292;&#20026;&#30456;&#20851;&#24212;&#29992;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2303.17110</link><description>&lt;p&gt;
&#24102;&#26377;&#27010;&#29575;&#35302;&#21457;&#33218;&#30340;&#24773;&#22659;&#32452;&#21512;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Contextual Combinatorial Bandits with Probabilistically Triggered Arms. (arXiv:2303.17110v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#27010;&#29575;&#35302;&#21457;&#33218;&#30340;&#24773;&#22659;&#32452;&#21512;&#36172;&#21338;&#26426;&#65292;&#22312;&#19981;&#21516;&#26465;&#20214;&#19979;&#35774;&#35745;&#20102;C$^2$-UCB-T&#31639;&#27861;&#21644;VAC$^2$-UCB&#31639;&#27861;&#65292;&#24182;&#20998;&#21035;&#23548;&#20986;&#20102;&#23545;&#24212;&#30340;&#36951;&#25022;&#20540;&#19978;&#38480;&#65292;&#20026;&#30456;&#20851;&#24212;&#29992;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#25429;&#25417;&#24191;&#27867;&#24212;&#29992;&#33539;&#22260;&#30340;&#19968;&#31995;&#21015;&#24179;&#28369;&#26465;&#20214;&#19979;&#30340;&#24102;&#26377;&#27010;&#29575;&#35302;&#21457;&#33218;&#30340;&#24773;&#22659;&#32452;&#21512;&#36172;&#21338;&#26426;(C$^2$MAB-T)&#65292;&#20363;&#22914;&#24773;&#22659;&#32423;&#32852;&#36172;&#21338;&#26426;&#21644;&#24773;&#22659;&#26368;&#22823;&#21270;&#36172;&#21338;&#26426;&#12290;&#22312;&#27169;&#25311;&#35302;&#21457;&#27010;&#29575;(TPM)&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;C$^2$-UCB-T&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#20010;$\tilde{O}(d\sqrt{KT})$&#30340;&#36951;&#25022;&#20540;&#19978;&#38480;&#65292;&#28040;&#38500;&#20102;&#19968;&#20010;&#21487;&#33021;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#22240;&#23376;$O(1/p_{\min})$&#65292;&#20854;&#20013;$d$&#26159;&#24773;&#22659;&#30340;&#32500;&#25968;&#65292;$p_{\min}$&#26159;&#33021;&#34987;&#35302;&#21457;&#30340;&#20219;&#20309;&#33218;&#30340;&#26368;&#23567;&#27491;&#27010;&#29575;&#65292;&#25209;&#22823;&#23567;$K$&#26159;&#27599;&#36718;&#33021;&#34987;&#35302;&#21457;&#30340;&#33218;&#30340;&#26368;&#22823;&#25968;&#37327;&#12290;&#22312;&#26041;&#24046;&#35843;&#21046;(VM)&#25110;&#35302;&#21457;&#27010;&#29575;&#21644;&#26041;&#24046;&#35843;&#21046;(TPVM)&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24046;&#33258;&#36866;&#24212;&#31639;&#27861;VAC$^2$-UCB&#65292;&#24182;&#23548;&#20986;&#20102;&#19968;&#20010;$\tilde{O}(d\sqrt{T})$&#30340;&#36951;&#25022;&#20540;&#19978;&#38480;&#65292;&#35813;&#19978;&#38480;&#19982;&#25209;&#22823;&#23567;$K$&#26080;&#20851;&#12290;&#20316;&#20026;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#21457;&#29616;&#25105;&#20204;&#30340;&#19968;&#20010;...
&lt;/p&gt;
&lt;p&gt;
We study contextual combinatorial bandits with probabilistically triggered arms (C$^2$MAB-T) under a variety of smoothness conditions that capture a wide range of applications, such as contextual cascading bandits and contextual influence maximization bandits. Under the triggering probability modulated (TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novel analysis that achieves an $\tilde{O}(d\sqrt{KT})$ regret bound, removing a potentially exponentially large factor $O(1/p_{\min})$, where $d$ is the dimension of contexts, $p_{\min}$ is the minimum positive probability that any arm can be triggered, and batch-size $K$ is the maximum number of arms that can be triggered per round. Under the variance modulated (VM) or triggering probability and variance modulated (TPVM) conditions, we propose a new variance-adaptive algorithm VAC$^2$-UCB and derive a regret bound $\tilde{O}(d\sqrt{T})$, which is independent of the batch-size $K$. As a valuable by-product, we find our a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27491;&#21017;&#21270;&#21160;&#24577;&#35268;&#21010;&#30340;&#20048;&#35266;&#35268;&#21010;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#23398;&#20064;&#25240;&#25187;&#32447;&#24615;&#28151;&#21512;MDPs&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#19988;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#32479;&#35745;&#20445;&#35777;</title><link>http://arxiv.org/abs/2302.14004</link><description>&lt;p&gt;
&#22522;&#20110;&#27491;&#21017;&#21270;&#21160;&#24577;&#35268;&#21010;&#30340;&#20048;&#35266;&#35268;&#21010;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimistic Planning by Regularized Dynamic Programming. (arXiv:2302.14004v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14004
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27491;&#21017;&#21270;&#21160;&#24577;&#35268;&#21010;&#30340;&#20048;&#35266;&#35268;&#21010;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#23398;&#20064;&#25240;&#25187;&#32447;&#24615;&#28151;&#21512;MDPs&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;&#65292;&#19988;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#38480;&#26102;&#27573;&#25240;&#25187;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#20048;&#35266;&#35268;&#21010;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#22312;&#36817;&#20284;&#20540;&#36845;&#20195;&#36807;&#31243;&#30340;&#26356;&#26032;&#20013;&#28155;&#21152;&#27491;&#21017;&#21270;&#30340;&#24605;&#24819;&#12290;&#27492;&#25216;&#26415;&#20351;&#25105;&#20204;&#33021;&#22815;&#36991;&#20813;&#33806;&#32553;&#21644;&#21333;&#35843;&#24615;&#35770;&#35777;&#65292;&#36825;&#36890;&#24120;&#26159;&#29616;&#26377;&#36817;&#20284;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#20998;&#26512;&#25152;&#35201;&#27714;&#30340;&#65292;&#29305;&#21035;&#26159;&#21487;&#20197;&#22312;&#20855;&#26377;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;MDPs&#20013;&#20351;&#29992;&#36890;&#36807;&#26368;&#23567;&#20108;&#20056;&#27861;&#20272;&#35745;&#30340;&#36817;&#20284;&#36716;&#31227;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#35813;&#26041;&#27861;&#24674;&#22797;&#20102;&#34920;&#26684;MDPs&#20013;&#24050;&#30693;&#30340;&#20445;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#20174;&#21333;&#20010;&#27969;&#32463;&#39564;&#20013;&#23398;&#20064;&#25240;&#25187;&#32447;&#24615;&#28151;&#21512;MDPs&#20013;&#25509;&#36817;&#26368;&#20248;&#31574;&#30053;&#30340;&#35745;&#31639;&#26377;&#25928;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#23427;&#23454;&#29616;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new method for optimistic planning in infinite-horizon discounted Markov decision processes based on the idea of adding regularization to the updates of an otherwise standard approximate value iteration procedure. This technique allows us to avoid contraction and monotonicity arguments typically required by existing analyses of approximate dynamic programming methods, and in particular to use approximate transition functions estimated via least-squares procedures in MDPs with linear function approximation. We use our method to recover known guarantees in tabular MDPs and to provide a computationally efficient algorithm for learning near-optimal policies in discounted linear mixture MDPs from a single stream of experience, and show it achieves near-optimal statistical guarantees.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ECV&#30340;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#25972;&#38543;&#26426;&#38598;&#25104;&#20013;&#30340;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Out-of-Bag&#38169;&#35823;&#21644;&#21033;&#29992;&#39044;&#27979;&#39118;&#38505;&#20998;&#35299;&#32467;&#26500;&#30340;&#26032;&#22411;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#65292;&#33021;&#22815;&#20135;&#29983;$\delta$-&#26368;&#20248;&#65288;&#20851;&#20110;Oracle&#35843;&#25972;&#39118;&#38505;&#65289;&#30340;&#38598;&#25104;&#12290;</title><link>http://arxiv.org/abs/2302.13511</link><description>&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#38598;&#25104;&#30340;&#22806;&#25512;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Extrapolated cross-validation for randomized ensembles. (arXiv:2302.13511v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13511
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ECV&#30340;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#29992;&#20110;&#35843;&#25972;&#38543;&#26426;&#38598;&#25104;&#20013;&#30340;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Out-of-Bag&#38169;&#35823;&#21644;&#21033;&#29992;&#39044;&#27979;&#39118;&#38505;&#20998;&#35299;&#32467;&#26500;&#30340;&#26032;&#22411;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#65292;&#33021;&#22815;&#20135;&#29983;$\delta$-&#26368;&#20248;&#65288;&#20851;&#20110;Oracle&#35843;&#25972;&#39118;&#38505;&#65289;&#30340;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#26041;&#27861;&#65292;&#22914;Bagging&#21644;&#38543;&#26426;&#26862;&#26519;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#38543;&#22788;&#21487;&#35265;&#65292;&#20174;&#37329;&#34701;&#21040;&#22522;&#22240;&#32452;&#23398;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#24120;&#35265;&#65292;&#20294;&#20851;&#20110;&#26377;&#25928;&#35843;&#25972;&#38598;&#25104;&#21442;&#25968;&#30340;&#38382;&#39064;&#21364;&#21463;&#21040;&#30456;&#23545;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#65292;&#21363;ECV&#65288;&#22806;&#25512;&#20132;&#21449;&#39564;&#35777;&#65289;&#65292;&#29992;&#20110;&#35843;&#25972;&#38543;&#26426;&#38598;&#25104;&#20013;&#30340;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#20027;&#35201;&#22240;&#32032;: &#20351;&#29992;Out-of-Bag&#38169;&#35823;&#26469;&#33719;&#21462;&#23567;&#22411;&#38598;&#25104;&#30340;&#21021;&#27493;&#20272;&#35745;&#20540;&#21644;&#19968;&#31181;&#21033;&#29992;&#39044;&#27979;&#39118;&#38505;&#20998;&#35299;&#32467;&#26500;&#30340;&#26032;&#22411;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#12290;&#36890;&#36807;&#35777;&#26126;&#25105;&#20204;&#30340;&#39118;&#38505;&#22806;&#25512;&#25216;&#26415;&#22312;&#38598;&#25104;&#21644;&#23376;&#26679;&#26412;&#22823;&#23567;&#19978;&#20855;&#26377;&#32479;&#19968;&#30340;&#19968;&#33268;&#24615;&#65292;&#25105;&#20204;&#34920;&#26126;ECV&#23545;&#20110;&#24179;&#26041;&#39044;&#27979;&#39118;&#38505;&#33021;&#22815;&#20135;&#29983;$\delta$-&#26368;&#20248;&#65288;&#20851;&#20110;Oracle&#35843;&#25972;&#39118;&#38505;&#65289;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#38598;&#25104;&#39044;&#27979;&#22120;&#65292;&#21482;&#38656;&#35201;&#28201;&#21644;&#30340;&#30697;&#20551;&#35774;&#65292;&#24182;&#20801;&#35768;&#20855;&#26377;&#39640;&#32500;&#24230;&#29305;&#24449;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensemble methods such as bagging and random forests are ubiquitous in various fields, from finance to genomics. Despite their prevalence, the question of the efficient tuning of ensemble parameters has received relatively little attention. This paper introduces a cross-validation method, ECV (Extrapolated Cross-Validation), for tuning the ensemble and subsample sizes in randomized ensembles. Our method builds on two primary ingredients: initial estimators for small ensemble sizes using out-of-bag errors and a novel risk extrapolation technique that leverages the structure of prediction risk decomposition. By establishing uniform consistency of our risk extrapolation technique over ensemble and subsample sizes, we show that ECV yields $\delta$-optimal (with respect to the oracle-tuned risk) ensembles for squared prediction risk. Our theory accommodates general ensemble predictors, only requires mild moment assumptions, and allows for high-dimensional regimes where the feature dimension 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22810;&#31181;Gumbel-Softmax&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;MADDPG&#20013;&#65292;&#20197;&#35299;&#20915;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.11793</link><description>&lt;p&gt;
&#37325;&#35775;MADDPG&#20013;&#30340;Gumbel-Softmax
&lt;/p&gt;
&lt;p&gt;
Revisiting the Gumbel-Softmax in MADDPG. (arXiv:2302.11793v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22810;&#31181;Gumbel-Softmax&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;MADDPG&#20013;&#65292;&#20197;&#35299;&#20915;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#30340;&#24615;&#33021;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
MADDPG&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#23427;&#23558;&#21333;&#26234;&#33021;&#20307;&#26041;&#27861;DDPG&#25512;&#24191;&#21040;&#22810;&#26234;&#33021;&#20307;&#22330;&#26223;&#20013;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;DDPG&#26159;&#19968;&#31181;&#38024;&#23545;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#35774;&#35745;&#30340;&#31639;&#27861;&#65292;&#22312;&#20854;&#20013;&#29366;&#24577;-&#21160;&#20316;&#20215;&#20540;&#20989;&#25968;&#30340;&#26799;&#24230;&#23384;&#22312;&#12290;&#20026;&#20102;&#20351;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#65292;&#24517;&#39035;&#36827;&#34892;&#31163;&#25955;&#30340;&#26799;&#24230;&#20272;&#35745;&#12290;&#23545;&#20110;MADDPG&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;Gumbel-Softmax&#65288;GS&#65289;&#20272;&#31639;&#22120;--&#19968;&#31181;&#23558;&#31163;&#25955;&#20998;&#24067;&#26494;&#24347;&#21040;&#31867;&#20284;&#36830;&#32493;&#20998;&#24067;&#30340;&#20877;&#21442;&#25968;&#21270;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#32479;&#35745;&#20559;&#24046;&#65292;&#26368;&#36817;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22522;&#20934;&#27979;&#35797;&#35770;&#25991;&#34920;&#26126;&#65292;&#36825;&#31181;&#20559;&#24046;&#20351;&#24471;MADDPG&#22312;&#26684;&#23376;&#19990;&#30028;&#31561;&#31163;&#25955;&#21160;&#20316;&#31354;&#38388;&#19979;&#34920;&#29616;&#19981;&#20339;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;GS&#30340;&#35768;&#22810;&#26367;&#20195;&#26041;&#27861;&#23384;&#22312;&#65292;&#20855;&#26377;&#21508;&#31181;&#21508;&#26679;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20854;&#20013;&#20960;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#24182;&#23558;&#23427;&#20204;&#25972;&#21512;&#21040;&#31163;&#25955;&#26684;&#23376;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;MADDPG&#20013;&#12290;&#28982;&#21518;&#23545;&#21508;&#31181;&#24615;&#33021;&#25351;&#26631;&#30340;&#30456;&#24212;&#24433;&#21709;&#36827;&#34892;&#20102;&#27979;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
MADDPG is an algorithm in multi-agent reinforcement learning (MARL) that extends the popular single-agent method, DDPG, to multi-agent scenarios. Importantly, DDPG is an algorithm designed for continuous action spaces, where the gradient of the state-action value function exists. For this algorithm to work in discrete action spaces, discrete gradient estimation must be performed. For MADDPG, the Gumbel-Softmax (GS) estimator is used -- a reparameterisation which relaxes a discrete distribution into a similar continuous one. This method, however, is statistically biased, and a recent MARL benchmarking paper suggests that this bias makes MADDPG perform poorly in grid-world situations, where the action space is discrete. Fortunately, many alternatives to the GS exist, boasting a wide range of properties. This paper explores several of these alternatives and integrates them into MADDPG for discrete grid-world scenarios. The corresponding impact on various performance metrics is then measur
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20840;&#23616;&#26368;&#20248;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(CVAE)&#21487;&#20197;&#23398;&#20064;&#27491;&#30830;&#30340;&#27969;&#24418;&#32500;&#24230;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#21487;&#20197;&#20849;&#21516;&#23398;&#20064;&#27969;&#24418;&#32500;&#24230;&#21644;&#26465;&#20214;&#20998;&#24067;&#65292;&#20197;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#26356;&#22909;&#30340;&#29305;&#24449;&#20998;&#31163;&#21644;&#26679;&#26412;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2302.11756</link><description>&lt;p&gt;
&#26465;&#20214;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#27969;&#24418;&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
Learning Manifold Dimensions with Conditional Variational Autoencoders. (arXiv:2302.11756v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20840;&#23616;&#26368;&#20248;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(CVAE)&#21487;&#20197;&#23398;&#20064;&#27491;&#30830;&#30340;&#27969;&#24418;&#32500;&#24230;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#21487;&#20197;&#20849;&#21516;&#23398;&#20064;&#27969;&#24418;&#32500;&#24230;&#21644;&#26465;&#20214;&#20998;&#24067;&#65292;&#20197;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#26356;&#22909;&#30340;&#29305;&#24449;&#20998;&#31163;&#21644;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#21450;&#20854;&#26465;&#20214;&#25193;&#23637;&#65288;CVAE&#65289;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#33021;&#22815;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#20294;&#23427;&#20204;&#30340;&#31934;&#30830;&#34892;&#20026;&#20173;&#26410;&#23436;&#20840;&#29702;&#35299;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#65289;&#22312;&#25110;&#25509;&#36817;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;VAE&#20840;&#23616;&#26368;&#23567;&#20540;&#30830;&#23454;&#33021;&#22815;&#24674;&#22797;&#27491;&#30830;&#30340;&#27969;&#24418;&#32500;&#24230;&#65292;&#24182;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#20849;&#21516;&#23398;&#20064;&#27969;&#24418;&#32500;&#24230;&#21644;&#26465;&#20214;&#20998;&#24067;&#65292;&#36827;&#19968;&#27493;&#25193;&#23637;&#20102;&#36825;&#19968;&#32467;&#26524;&#21040;&#26356;&#19968;&#33324;&#30340;CVAEs&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;MNIST&#21644;CelebA&#65292;&#23454;&#29616;&#20102;&#34920;&#29616;&#26368;&#22909;&#30340;&#35270;&#35273;&#36136;&#37327;&#21644;&#29305;&#24449;&#20998;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although the variational autoencoder (VAE) and its conditional extension (CVAE) are capable of state-of-the-art results across multiple domains, their precise behavior is still not fully understood, particularly in the context of data (like images) that lie on or near a low-dimensional manifold. For example, while prior work has suggested that the globally optimal VAE solution can learn the correct manifold dimension, a necessary (but not sufficient) condition for producing samples from the true data distribution, this has never been rigorously proven. Moreover, it remains unclear how such considerations would change when various types of conditioning variables are introduced, or when the data support is extended to a union of manifolds (e.g., as is likely the case for MNIST digits and related). In this work, we address these points by first proving that VAE global minima are indeed capable of recovering the correct manifold dimension. We then extend this result to more general CVAEs, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#21033;&#29992;&#25237;&#24433;&#25439;&#22833;&#23545;&#65292;&#19982;Rademacher&#24207;&#21015;&#30456;&#20851;&#32852;&#26469;&#28304;&#20110;&#36229;&#21462;&#26679;&#30340;&#35774;&#32622;&#65292;&#36825;&#20123;&#30028;&#38480;&#27604;&#21516;&#19968;&#36229;&#21462;&#26679;&#35774;&#32622;&#20013;&#36804;&#20170;&#24050;&#30693;&#30340;&#25152;&#26377;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#37117;&#26356;&#32039;&#23494;&#12290;</title><link>http://arxiv.org/abs/2302.02432</link><description>&lt;p&gt;
&#28304;&#20110;&#36229;&#21462;&#26679;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#26356;&#32039;&#23494;
&lt;/p&gt;
&lt;p&gt;
Tighter Information-Theoretic Generalization Bounds from Supersamples. (arXiv:2302.02432v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#21033;&#29992;&#25237;&#24433;&#25439;&#22833;&#23545;&#65292;&#19982;Rademacher&#24207;&#21015;&#30456;&#20851;&#32852;&#26469;&#28304;&#20110;&#36229;&#21462;&#26679;&#30340;&#35774;&#32622;&#65292;&#36825;&#20123;&#30028;&#38480;&#27604;&#21516;&#19968;&#36229;&#21462;&#26679;&#35774;&#32622;&#20013;&#36804;&#20170;&#24050;&#30693;&#30340;&#25152;&#26377;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#37117;&#26356;&#32039;&#23494;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38024;&#23545;&#23398;&#20064;&#31639;&#27861;&#30340;&#21508;&#31181;&#26032;&#39062;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#28304;&#20110;Steinke&#65286;Zakynthinou&#65288;2020&#65289;&#30340;&#36229;&#21462;&#26679;&#35774;&#32622;-&#8220;&#26465;&#20214;&#20114;&#20449;&#24687;&#8221;&#26694;&#26550;&#30340;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#24320;&#21457;&#21033;&#29992;&#23558;&#25439;&#22833;&#23545;&#65288;&#20174;&#35757;&#32451;&#23454;&#20363;&#21644;&#27979;&#35797;&#23454;&#20363;&#33719;&#24471;&#65289;&#25237;&#24433;&#21040;&#21333;&#20010;&#25968;&#23383;&#65292;&#24182;&#23558;&#25439;&#22833;&#20540;&#19982;Rademacher&#24207;&#21015;&#65288;&#21450;&#20854;&#31227;&#21160;&#21464;&#20307;&#65289;&#30456;&#20851;&#32852;&#12290;&#25152;&#21576;&#29616;&#30340;&#30028;&#38480;&#21253;&#25324;&#24179;&#26041;&#26681;&#30028;&#38480;&#65292;&#24555;&#36895;&#29575;&#30028;&#38480;&#65292;&#21253;&#25324;&#22522;&#20110;&#26041;&#24046;&#21644;&#23574;&#38160;&#24230;&#30340;&#30028;&#38480;&#20197;&#21450;&#25554;&#20540;&#31639;&#27861;&#30340;&#30028;&#38480;&#31561;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#25110;&#32463;&#39564;&#19978;&#35777;&#26126;&#65292;&#36825;&#20123;&#30028;&#38480;&#27604;&#21516;&#19968;&#36229;&#21462;&#26679;&#35774;&#32622;&#20013;&#36804;&#20170;&#24050;&#30693;&#30340;&#25152;&#26377;&#20449;&#24687;&#29702;&#35770;&#30028;&#38480;&#37117;&#26356;&#32039;&#23494;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present a variety of novel information-theoretic generalization bounds for learning algorithms, from the supersample setting of Steinke &amp; Zakynthinou (2020)-the setting of the "conditional mutual information" framework. Our development exploits projecting the loss pair (obtained from a training instance and a testing instance) down to a single number and correlating loss values with a Rademacher sequence (and its shifted variants). The presented bounds include square-root bounds, fast-rate bounds, including those based on variance and sharpness, and bounds for interpolating algorithms etc. We show theoretically or empirically that these bounds are tighter than all information-theoretic bounds known to date on the same supersample setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#39044;&#27979;&#20154;&#31867;&#22312;&#20845;&#20010;&#24863;&#23448;&#27169;&#24577;&#19979;&#30340;&#24863;&#30693;&#35780;&#21028;&#65292;&#24182;&#33021;&#25552;&#20379;&#20174;&#35821;&#35328;&#20013;&#25552;&#21462;&#24863;&#30693;&#20449;&#24687;&#30340;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2302.01308</link><description>&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21487;&#20197;&#39044;&#27979;&#20154;&#31867;&#22312;&#20845;&#20010;&#24863;&#23448;&#27169;&#24577;&#19979;&#30340;&#24863;&#30693;&#35780;&#21028;
&lt;/p&gt;
&lt;p&gt;
Large language models predict human sensory judgments across six modalities. (arXiv:2302.01308v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#33021;&#39044;&#27979;&#20154;&#31867;&#22312;&#20845;&#20010;&#24863;&#23448;&#27169;&#24577;&#19979;&#30340;&#24863;&#30693;&#35780;&#21028;&#65292;&#24182;&#33021;&#25552;&#20379;&#20174;&#35821;&#35328;&#20013;&#25552;&#21462;&#24863;&#30693;&#20449;&#24687;&#30340;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#20174;&#35821;&#35328;&#20013;&#21487;&#20197;&#24674;&#22797;&#24863;&#30693;&#19990;&#30028;&#30340;&#31243;&#24230;&#26159;&#21746;&#23398;&#21644;&#35748;&#30693;&#31185;&#23398;&#20013;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#65292;&#26368;&#20808;&#36827;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36890;&#36807;&#25552;&#20379;&#20174;&#35821;&#35328;&#20013;&#25552;&#21462;&#24863;&#30693;&#20449;&#24687;&#30340;&#19979;&#38480;&#65292;&#21487;&#20197;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#26032;&#30340;&#35265;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20174;GPT&#27169;&#22411;&#20013;&#24341;&#20986;&#20102;&#20845;&#20010;&#24515;&#29702;&#29289;&#29702;&#25968;&#25454;&#38598;&#30340;&#25104;&#23545;&#30456;&#20284;&#24230;&#35780;&#20272;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#35780;&#20272;&#32467;&#26524;&#22312;&#25152;&#26377;&#39046;&#22495;&#20013;&#22343;&#19982;&#20154;&#31867;&#25968;&#25454;&#26174;&#33879;&#30456;&#20851;&#65292;&#22238;&#22797;&#20102;&#20247;&#25152;&#21608;&#30693;&#30340;&#34920;&#29616;&#65292;&#22914;&#39068;&#33394;&#29615;&#21644;&#38899;&#39640;&#34746;&#26059;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#20010;&#22312;&#35270;&#35273;&#21644;&#35821;&#35328;&#19978;&#20849;&#21516;&#35757;&#32451;&#30340;&#27169;&#22411;&#65288;GPT-4&#65289;&#24182;&#19981;&#19968;&#23450;&#20250;&#23548;&#33268;&#23545;&#35270;&#35273;&#27169;&#24577;&#30340;&#29305;&#23450;&#25913;&#36827;&#12290;&#20026;&#20102;&#30740;&#31350;&#29305;&#23450;&#35821;&#35328;&#23545;&#24863;&#30693;&#30340;&#24433;&#21709;&#65292;&#25105;&#20204;&#36824;&#23558;&#36825;&#20123;&#27169;&#22411;&#24212;&#29992;&#20110;&#22810;&#35821;&#35328;&#39068;&#33394;&#21629;&#21517;&#20219;&#21153;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;GPT-4&#22312;&#33521;&#35821;&#21644;&#20420;&#35821;&#20013;&#22797;&#21046;&#20102;&#36328;&#35821;&#35328;&#24046;&#24322;&#65292;&#38416;&#26126;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Determining the extent to which the perceptual world can be recovered from language is a longstanding problem in philosophy and cognitive science. We show that state-of-the-art large language models can unlock new insights into this problem by providing a lower bound on the amount of perceptual information that can be extracted from language. Specifically, we elicit pairwise similarity judgments from GPT models across six psychophysical datasets. We show that the judgments are significantly correlated with human data across all domains, recovering well-known representations like the color wheel and pitch spiral. Surprisingly, we find that a model (GPT-4) co-trained on vision and language does not necessarily lead to improvements specific to the visual modality. To study the influence of specific languages on perception, we also apply the models to a multilingual color-naming task. We find that GPT-4 replicates cross-linguistic variation in English and Russian illuminating the interacti
&lt;/p&gt;</description></item><item><title>SOBER&#31639;&#27861;&#26159;&#19968;&#31181;&#22312;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#36827;&#34892;&#39640;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#22810;&#26679;&#21270;&#30340;&#25209;&#37327;&#20840;&#23616;&#20248;&#21270;&#21644;&#31215;&#20998;&#65292;&#19988;&#20248;&#20110;11&#20010;&#31454;&#20105;&#22522;&#32447;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.11832</link><description>&lt;p&gt;
SOBER&#65306;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#39640;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#36125;&#21494;&#26031;&#31215;&#20998;
&lt;/p&gt;
&lt;p&gt;
SOBER: Highly Parallel Bayesian Optimization and Bayesian Quadrature over Discrete and Mixed Spaces. (arXiv:2301.11832v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11832
&lt;/p&gt;
&lt;p&gt;
SOBER&#31639;&#27861;&#26159;&#19968;&#31181;&#22312;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#36827;&#34892;&#39640;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#22810;&#26679;&#21270;&#30340;&#25209;&#37327;&#20840;&#23616;&#20248;&#21270;&#21644;&#31215;&#20998;&#65292;&#19988;&#20248;&#20110;11&#20010;&#31454;&#20105;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#22788;&#29702;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#36125;&#21494;&#26031;&#31215;&#20998;&#24050;&#34987;&#35777;&#26126;&#26159;&#22312;&#38656;&#24182;&#34892;&#26597;&#35810;&#26114;&#36149;&#30340;&#30446;&#26631;&#20989;&#25968;&#26102;&#25191;&#34892;&#20248;&#21270;&#21644;&#31215;&#20998;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#22823;&#25209;&#37327;&#25805;&#20316;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;SOBER&#65292;&#23427;&#20801;&#35768;&#22312;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#20351;&#29992;&#20219;&#24847;&#37319;&#38598;&#20989;&#25968;&#21644;&#20869;&#26680;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#22810;&#26679;&#21270;&#30340;&#25209;&#37327;&#20840;&#23616;&#20248;&#21270;&#21644;&#31215;&#20998;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20851;&#38190;&#22312;&#20110;&#23558;&#20840;&#23616;&#20248;&#21270;&#30340;&#25209;&#37327;&#36873;&#25321;&#37325;&#26032;&#23450;&#20041;&#20026;&#31215;&#20998;&#38382;&#39064;&#65292;&#24182;&#23558;&#37319;&#38598;&#20989;&#25968;&#30340;&#26368;&#22823;&#21270;&#65288;&#38750;&#20984;&#65289;&#26494;&#24347;&#20026;&#20869;&#26680;&#37325;&#32452;&#65288;&#20984;&#65289;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20004;&#20010;&#20219;&#21153;&#12290;&#25105;&#20204;&#23637;&#31034;SOBER&#20248;&#20110;11&#20010;&#31454;&#20105;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch Bayesian optimisation and Bayesian quadrature have been shown to be sample-efficient methods of performing optimisation and quadrature where expensive-to-evaluate objective functions can be queried in parallel. However, current methods do not scale to large batch sizes -- a frequent desideratum in practice (e.g. drug discovery or simulation-based inference). We present a novel algorithm, SOBER, which permits scalable and diversified batch global optimisation and quadrature with arbitrary acquisition functions and kernels over discrete and mixed spaces. The key to our approach is to reformulate batch selection for global optimisation as a quadrature problem, which relaxes acquisition function maximisation (non-convex) to kernel recombination (convex). Bridging global optimisation and quadrature can efficiently solve both tasks by balancing the merits of exploitative Bayesian optimisation and explorative Bayesian quadrature. We show that SOBER outperforms 11 competitive baselines o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#25193;&#25955;&#27169;&#22411;&#21644;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26032;&#25216;&#26415;SSSD-ECG&#65292;&#22312;&#26681;&#25454;70&#22810;&#20010;&#24515;&#30005;&#22270;&#35821;&#21477;&#29983;&#25104;&#21512;&#25104;12&#23548;&#32852;&#24515;&#30005;&#22270;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2301.08227</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#30340;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26465;&#20214;&#24515;&#30005;&#20449;&#21495;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Diffusion-based Conditional ECG Generation with Structured State Space Models. (arXiv:2301.08227v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08227
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#25193;&#25955;&#27169;&#22411;&#21644;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#26032;&#25216;&#26415;SSSD-ECG&#65292;&#22312;&#26681;&#25454;70&#22810;&#20010;&#24515;&#30005;&#22270;&#35821;&#21477;&#29983;&#25104;&#21512;&#25104;12&#23548;&#32852;&#24515;&#30005;&#22270;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#26159;&#35299;&#20915;&#25935;&#24863;&#20581;&#24247;&#25968;&#25454;&#20998;&#24067;&#26102;&#30340;&#38544;&#31169;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#26368;&#36817;&#65292;&#25193;&#25955;&#27169;&#22411;&#20026;&#19981;&#21516;&#30340;&#25968;&#25454;&#27169;&#24335;&#35774;&#23450;&#20102;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#26631;&#20934;&#12290;&#26368;&#36817;&#65292;&#32467;&#26500;&#21270;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#20986;&#29616;&#65292;&#25104;&#20026;&#25429;&#25417;&#26102;&#38388;&#24207;&#21015;&#20013;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#30340;&#24378;&#22823;&#24314;&#27169;&#33539;&#20363;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SSSD-ECG&#65292;&#23558;&#36825;&#20004;&#31181;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#26681;&#25454;70&#22810;&#20010;&#24515;&#30005;&#22270;&#35821;&#21477;&#29983;&#25104;&#21512;&#25104;12&#23548;&#32852;&#24515;&#30005;&#22270;&#30340;&#26465;&#20214;&#29983;&#25104;&#12290;&#30001;&#20110;&#27809;&#26377;&#21487;&#38752;&#30340;&#22522;&#20934;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20004;&#31181;&#26368;&#20808;&#36827;&#30340;&#26080;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#26465;&#20214;&#21464;&#20307;&#12290;&#25105;&#20204;&#36890;&#36807;&#35780;&#20272;&#22312;&#29983;&#25104;&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#26469;&#24443;&#24213;&#35780;&#20272;&#25152;&#29983;&#25104;&#26679;&#26412;&#30340;&#36136;&#37327;&#65292;&#24182;&#35780;&#20272;&#20102;&#20165;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#22312;&#36825;&#26041;&#38754;&#65292;SSSD-ECG&#26126;&#26174;&#20248;&#20110;&#20854;&#22522;&#20110;GAN&#30340;&#31454;&#20105;&#23545;&#25163;&#12290;&#25105;&#20204;&#36890;&#36807;&#36827;&#19968;&#27493;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Synthetic data generation is a promising solution to address privacy issues with the distribution of sensitive health data. Recently, diffusion models have set new standards for generative models for different data modalities. Also very recently, structured state space models emerged as a powerful modeling paradigm to capture long-term dependencies in time series. We put forward SSSD-ECG, as the combination of these two technologies, for the generation of synthetic 12-lead electrocardiograms conditioned on more than 70 ECG statements. Due to a lack of reliable baselines, we also propose conditional variants of two state-of-the-art unconditional generative models. We thoroughly evaluate the quality of the generated samples, by evaluating pretrained classifiers on the generated data and by evaluating the performance of a classifier trained only on synthetic data, where SSSD-ECG clearly outperforms its GAN-based competitors. We demonstrate the soundness of our approach through further exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#65292;&#22522;&#20110;&#20302;&#31209;&#21322;&#27491;&#23450;&#26494;&#24347;&#25216;&#26415;&#23454;&#29616;&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#20005;&#26684;&#35748;&#35777;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#37319;&#29992;&#26356;&#20415;&#23452;&#30340;SDP&#26041;&#27861;&#30456;&#24403;&#30340;&#24378;&#35748;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.17244</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#20984;&#20302;&#31209;&#21322;&#27491;&#23450;&#26494;&#24347;&#23454;&#29616;&#23545;&#23545;&#25239;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#20005;&#26684;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
Tight Certification of Adversarially Trained Neural Networks via Nonconvex Low-Rank Semidefinite Relaxations. (arXiv:2211.17244v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.17244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#65292;&#22522;&#20110;&#20302;&#31209;&#21322;&#27491;&#23450;&#26494;&#24347;&#25216;&#26415;&#23454;&#29616;&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#20005;&#26684;&#35748;&#35777;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#23454;&#29616;&#37319;&#29992;&#26356;&#20415;&#23452;&#30340;SDP&#26041;&#27861;&#30456;&#24403;&#30340;&#24378;&#35748;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#23545;&#25239;&#35757;&#32451;&#21487;&#20197;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#32463;&#39564;&#19978;&#23545;&#25239;&#24615;&#25200;&#21160;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#19968;&#26086;&#36827;&#34892;&#20102;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#20154;&#20204;&#36890;&#24120;&#24076;&#26395;&#35777;&#26126;&#35813;&#27169;&#22411;&#22312;&#26410;&#26469;&#30340;&#25152;&#26377;&#25915;&#20987;&#20013;&#30495;&#27491;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#38754;&#23545;&#23545;&#25239;&#35757;&#32451;&#27169;&#22411;&#26102;&#65292;&#25152;&#26377;&#29616;&#26377;&#26041;&#27861;&#37117;&#38590;&#20197;&#20570;&#20986;&#36275;&#22815;&#26377;&#25928;&#30340;&#35777;&#26126;&#12290;&#29305;&#21035;&#26159;&#32447;&#24615;&#35268;&#21010;&#65288;LP&#65289;&#25216;&#26415;&#65292;&#21363;&#20351;&#32463;&#36807;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#65288;MILP&#65289;&#21644;&#20998;&#25903;&#23450;&#30028;&#65288;BnB&#65289;&#25216;&#26415;&#30340;&#25913;&#36827;&#65292;&#20063;&#20250;&#38754;&#20020;"&#20984;&#26494;&#24347;&#22721;&#22418;"&#65292;&#20351;&#24471;&#23427;&#20204;&#38590;&#20197;&#36827;&#34892;&#39640;&#36136;&#37327;&#30340;&#35777;&#26126;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#21322;&#27491;&#23450;&#26494;&#24347;&#30340;&#38750;&#20984;&#35748;&#35777;&#25216;&#26415;&#12290;&#38750;&#20984;&#26494;&#24347;&#21487;&#20197;&#36827;&#34892;&#19982;&#26356;&#26114;&#36149;&#30340;&#21322;&#27491;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#24378;&#35748;&#35777;&#65292;&#21516;&#26102;&#20248;&#21270;&#33539;&#22260;&#26356;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training is well-known to produce high-quality neural network models that are empirically robust against adversarial perturbations. Nevertheless, once a model has been adversarially trained, one often desires a certification that the model is truly robust against all future attacks. Unfortunately, when faced with adversarially trained models, all existing approaches have significant trouble making certifications that are strong enough to be practically useful. Linear programming (LP) techniques in particular face a "convex relaxation barrier" that prevent them from making high-quality certifications, even after refinement with mixed-integer linear programming (MILP) and branch-and-bound (BnB) techniques. In this paper, we propose a nonconvex certification technique, based on a low-rank restriction of a semidefinite programming (SDP) relaxation. The nonconvex relaxation makes strong certifications comparable to much more expensive SDP methods, while optimizing over dramatica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36125;&#21494;&#26031;&#28040;&#38500;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22266;&#23450;&#39044;&#31639;&#19979;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#19988;&#25512;&#23548;&#20102;&#20854;&#19982;&#20808;&#39564;&#30456;&#20851;&#30340;&#35823;&#35782;&#21035;&#19978;&#30028;&#65292;&#27492;&#31639;&#27861;&#20248;&#20110;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#65292;&#19982;&#26080;&#20445;&#35777;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#30456;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2211.08572</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Bayesian Fixed-Budget Best-Arm Identification. (arXiv:2211.08572v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36125;&#21494;&#26031;&#28040;&#38500;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22266;&#23450;&#39044;&#31639;&#19979;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#19988;&#25512;&#23548;&#20102;&#20854;&#19982;&#20808;&#39564;&#30456;&#20851;&#30340;&#35823;&#35782;&#21035;&#19978;&#30028;&#65292;&#27492;&#31639;&#27861;&#20248;&#20110;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#65292;&#19982;&#26080;&#20445;&#35777;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#26159;&#19968;&#31181;&#36172;&#21338;&#38382;&#39064;&#65292;&#20195;&#29702;&#20154;&#26368;&#22823;&#21270;&#35782;&#21035;&#26368;&#20339;&#33218;&#30340;&#27010;&#29575;&#65292;&#22312;&#19968;&#20010;&#22266;&#23450;&#30340;&#35266;&#23519;&#39044;&#31639;&#20869;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#35774;&#32622;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#28040;&#38500;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#35823;&#35782;&#21035;&#26368;&#20248;&#33218;&#30340;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;&#36825;&#20010;&#19978;&#30028;&#21453;&#26144;&#20102;&#20808;&#39564;&#30340;&#36136;&#37327;&#65292;&#24182;&#19988;&#26159;&#27492;&#35774;&#32622;&#20013;&#31532;&#19968;&#20010;&#19982;&#20998;&#24067;&#30456;&#20851;&#30340;&#19978;&#30028;&#12290;&#25105;&#20204;&#20351;&#29992;&#31867;&#20284;&#20110;&#39057;&#29575;&#23398;&#27966;&#30340;&#35770;&#35777;&#35777;&#26126;&#20102;&#23427;&#65292;&#25105;&#20204;&#19968;&#30452;&#20351;&#29992;&#20808;&#39564;&#65292;&#28982;&#21518;&#22312;&#26368;&#21518;&#23558;&#36172;&#24466;&#23454;&#20363;&#31215;&#20998;&#25481;&#65292;&#20063;&#20026;2&#20010;&#33218;&#30340;&#36125;&#21494;&#26031;&#36172;&#24466;&#25552;&#20379;&#20102;&#35823;&#35782;&#21035;&#27010;&#29575;&#30340;&#19979;&#30028;&#65292;&#24182;&#19988;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#19978;&#30028;&#22312;&#20219;&#20309;&#39044;&#31639;&#19979;&#65288;&#20960;&#20046;&#65289;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#65292;&#36125;&#21494;&#26031;&#28040;&#38500;&#20248;&#20110;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#27492;&#35774;&#32622;&#20013;&#65292;&#19982;&#26080;&#27861;&#20445;&#35777;&#30340;&#26368;&#20808;&#36827;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fixed-budget best-arm identification (BAI) is a bandit problem where the agent maximizes the probability of identifying the optimal arm within a fixed budget of observations. In this work, we study this problem in the Bayesian setting. We propose a Bayesian elimination algorithm and derive an upper bound on its probability of misidentifying the optimal arm. The bound reflects the quality of the prior and is the first distribution-dependent bound in this setting. We prove it using a frequentist-like argument, where we carry the prior through, and then integrate out the bandit instance at the end. We also provide a lower bound on the probability of misidentification in a $2$-armed Bayesian bandit and show that our upper bound (almost) matches it for any budget. Our experiments show that Bayesian elimination is superior to frequentist methods and competitive with the state-of-the-art Bayesian algorithms that have no guarantees in our setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;DW&#26494;&#24347;&#23545;RCOP&#30340;&#24378;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#21516;&#26102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#20197;&#30830;&#23450;DWR&#20309;&#26102;&#19982;&#20219;&#20309;m&#20010;&#21452;&#36793;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#30456;&#21305;&#37197;&#65292;&#21253;&#25324;&#19977;&#20010;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#65306;&#26497;&#31471;&#28857;&#30340;&#20934;&#30830;&#24615;&#12289;&#20984;&#21253;&#30340;&#20934;&#30830;&#24615;&#20197;&#21450;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.16191</link><description>&lt;p&gt;
&#20851;&#20110;Dantzig-Wolfe&#26494;&#24347;&#23545;&#31209;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Exactness of Dantzig-Wolfe Relaxation for Rank Constrained Optimization Problems. (arXiv:2210.16191v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.16191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;DW&#26494;&#24347;&#23545;RCOP&#30340;&#24378;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#21516;&#26102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#20197;&#30830;&#23450;DWR&#20309;&#26102;&#19982;&#20219;&#20309;m&#20010;&#21452;&#36793;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#30456;&#21305;&#37197;&#65292;&#21253;&#25324;&#19977;&#20010;&#26041;&#38754;&#30340;&#20934;&#30830;&#24615;&#65306;&#26497;&#31471;&#28857;&#30340;&#20934;&#30830;&#24615;&#12289;&#20984;&#21253;&#30340;&#20934;&#30830;&#24615;&#20197;&#21450;&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31209;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;(RCOP)&#26159;&#26368;&#23567;&#21270;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#22312;&#19968;&#20010;&#39044;&#20808;&#25351;&#23450;&#30340;&#31209;&#32422;&#26463;&#22495;&#38598;&#21644;m&#20010;&#36890;&#29992;&#30340;&#21452;&#36793;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#19978;&#12290;&#21463;Dantzig-Wolfe (DW)&#20998;&#35299;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;DW&#26494;&#24347;(DWR)&#22312;RCOP&#20013;&#30340;&#24378;&#24230;&#65292;&#20854;&#19982;RCOP&#20855;&#26377;&#30456;&#21516;&#30340;&#34920;&#36798;&#24335;&#65292;&#21482;&#26159;&#23558;&#22495;&#38598;&#26367;&#25442;&#20026;&#20854;&#38381;&#20984;&#21253;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#20351;DWR&#19982;&#20219;&#20309;m&#20010;&#21452;&#36793;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#30456;&#21305;&#37197;&#30340;&#26465;&#20214;&#12290;&#20174;&#21407;&#22987;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#39318;&#27425;&#30830;&#23450;&#21516;&#26102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#65292;&#20197;&#36798;&#21040;&#65306;(i)&#26497;&#31471;&#28857;&#30340;&#20934;&#30830;&#24615;&#8212;&#8212;DWR&#21487;&#34892;&#38598;&#30340;&#25152;&#26377;&#26497;&#31471;&#28857;&#23646;&#20110;RCOP&#30340;&#26497;&#31471;&#28857;;(ii)&#20984;&#21253;&#30340;&#20934;&#30830;&#24615;&#8212;&#8212;DWR&#21487;&#34892;&#38598;&#31561;&#21516;&#20110;RCOP&#21487;&#34892;&#38598;&#30340;&#38381;&#20984;&#21253;; (iii)&#30446;&#26631;&#30340;&#20934;&#30830;&#24615;&#8212;&#8212;&#20248;&#21270;&#30340;&#30446;&#26631;&#20540;&#22312;DWR&#21487;&#34892;&#38598;&#21644;RCOP&#21487;&#34892;&#38598;&#30340;&#38381;&#20984;&#21253;&#20043;&#38388;&#30830;&#20999;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the rank-constrained optimization problem (RCOP), it minimizes a linear objective function over a prespecified closed rank-constrained domain set and $m$ generic two-sided linear matrix inequalities. Motivated by the Dantzig-Wolfe (DW) decomposition, a popular approach of solving many nonconvex optimization problems, we investigate the strength of DW relaxation (DWR) of the RCOP, which admits the same formulation as RCOP except replacing the domain set by its closed convex hull. Notably, our goal is to characterize conditions under which the DWR matches RCOP for any m two-sided linear matrix inequalities. From the primal perspective, we develop the first-known simultaneously necessary and sufficient conditions that achieve: (i) extreme point exactness -- all the extreme points of the DWR feasible set belong to that of the RCOP; (ii) convex hull exactness -- the DWR feasible set is identical to the closed convex hull of RCOP feasible set; and (iii) objective exactness -- the optimal 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#25299;&#25169;&#22855;&#24322;&#24615;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#35780;&#20272;&#25968;&#25454;&#30340;&#23616;&#37096;&#22266;&#26377;&#32500;&#24230;&#65292;&#24182;&#37327;&#21270;&#28857;&#30340;&#8220;&#27969;&#24418;&#24230;&#8221;&#65292;&#33021;&#22815;&#26816;&#27979;&#22797;&#26434;&#31354;&#38388;&#21644;&#22270;&#20687;&#20013;&#30340;&#22855;&#24322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.00069</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#25299;&#25169;&#22855;&#24322;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Topological Singularity Detection at Multiple Scales. (arXiv:2210.00069v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#25299;&#25169;&#22855;&#24322;&#24615;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#35780;&#20272;&#25968;&#25454;&#30340;&#23616;&#37096;&#22266;&#26377;&#32500;&#24230;&#65292;&#24182;&#37327;&#21270;&#28857;&#30340;&#8220;&#27969;&#24418;&#24230;&#8221;&#65292;&#33021;&#22815;&#26816;&#27979;&#22797;&#26434;&#31354;&#38388;&#21644;&#22270;&#20687;&#20013;&#30340;&#22855;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#20551;&#35774;&#26159;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#19968;&#20010;&#22522;&#26412;&#20551;&#35774;&#65292;&#23427;&#20551;&#23450;&#25968;&#25454;&#20301;&#20110;&#25110;&#25509;&#36817;&#20110;&#20302;&#22266;&#26377;&#32500;&#24230;&#30340;&#26410;&#30693;&#27969;&#24418;&#19978;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#34920;&#29616;&#20986;&#26126;&#26174;&#30340;&#38750;&#27969;&#24418;&#32467;&#26500;&#65292;&#21363;&#22855;&#24322;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#30340;&#21457;&#29616;&#12290;&#22240;&#27492;&#65292;&#26816;&#27979;&#36825;&#31181;&#22855;&#24322;&#24615;&#22312;&#25554;&#20540;&#21644;&#25512;&#26029;&#20219;&#21153;&#20043;&#21069;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#25299;&#25169;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#65288;i&#65289;&#37327;&#21270;&#23616;&#37096;&#22266;&#26377;&#32500;&#24230;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#20135;&#29983;&#8220;&#27431;&#20960;&#37324;&#24471;&#24615;&#8221;&#35780;&#20998;&#65292;&#29992;&#20197;&#35780;&#20272;&#28857;&#30340;&#8220;&#27969;&#24418;&#24230;&#8221;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#22270;&#20687;&#25968;&#25454;&#20013;&#25429;&#33719;&#22797;&#26434;&#31354;&#38388;&#30340;&#22855;&#24322;&#24615;&#65292;&#21516;&#26102;&#25429;&#25417;&#22855;&#24322;&#32467;&#26500;&#21644;&#23616;&#37096;&#20960;&#20309;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The manifold hypothesis, which assumes that data lies on or close to an unknown manifold of low intrinsic dimension, is a staple of modern machine learning research. However, recent work has shown that real-world data exhibits distinct non-manifold structures, i.e. singularities, that can lead to erroneous findings. Detecting such singularities is therefore crucial as a precursor to interpolation and inference tasks. We address this issue by developing a topological framework that (i) quantifies the local intrinsic dimension, and (ii) yields a Euclidicity score for assessing the 'manifoldness' of a point along multiple scales. Our approach identifies singularities of complex spaces, while also capturing singular structures and local geometric complexity in image data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#26631;&#31614;&#22122;&#22768;&#20250;&#23548;&#33268;&#21452;&#19992;&#38477;&#26354;&#32447;&#20986;&#29616;&#8220;&#26368;&#32456;&#19978;&#21319;&#8221;&#65292;&#21363;&#22312;&#36275;&#22815;&#22823;&#30340;&#22122;&#22768;&#26679;&#26412;&#27604;&#29575;&#19979;&#65292;&#20013;&#31561;&#23485;&#24230;&#19979;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#24615;&#33021;&#12290;&#38543;&#26426;&#20002;&#24323;&#21487;&#35757;&#32451;&#21442;&#25968;&#26469;&#20943;&#23569;&#23494;&#24230;&#21487;&#22312;&#26631;&#31614;&#22122;&#22768;&#19979;&#25913;&#21892;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2208.08003</link><description>&lt;p&gt;
&#30740;&#31350;&#27169;&#22411;&#23485;&#24230;&#21644;&#23494;&#24230;&#23545;&#26631;&#31614;&#22122;&#22768;&#19979;&#27867;&#21270;&#24615;&#33021;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Investigating the Impact of Model Width and Density on Generalization in Presence of Label Noise. (arXiv:2208.08003v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#26631;&#31614;&#22122;&#22768;&#20250;&#23548;&#33268;&#21452;&#19992;&#38477;&#26354;&#32447;&#20986;&#29616;&#8220;&#26368;&#32456;&#19978;&#21319;&#8221;&#65292;&#21363;&#22312;&#36275;&#22815;&#22823;&#30340;&#22122;&#22768;&#26679;&#26412;&#27604;&#29575;&#19979;&#65292;&#20013;&#31561;&#23485;&#24230;&#19979;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#24615;&#33021;&#12290;&#38543;&#26426;&#20002;&#24323;&#21487;&#35757;&#32451;&#21442;&#25968;&#26469;&#20943;&#23569;&#23494;&#24230;&#21487;&#22312;&#26631;&#31614;&#22122;&#22768;&#19979;&#25913;&#21892;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#22823;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35268;&#27169;&#26159;&#23454;&#29616;&#26368;&#20808;&#36827;&#24615;&#33021;&#30340;&#20851;&#38190;&#12290;&#36825;&#26159;&#36890;&#36807;&#21452;&#19992;&#38477;&#29616;&#35937;&#25429;&#25417;&#30340;&#65292;&#20854;&#20013;&#27979;&#35797;&#25439;&#22833;&#38543;&#30528;&#27169;&#22411;&#23485;&#24230;&#30340;&#22686;&#21152;&#21576;&#29616;&#20986;&#38477;&#20302;-&#22686;&#21152;-&#38477;&#20302;&#30340;&#27169;&#24335;&#12290;&#28982;&#32780;&#65292;&#26631;&#31614;&#22122;&#22768;&#23545;&#27979;&#35797;&#25439;&#22833;&#26354;&#32447;&#30340;&#24433;&#21709;&#23578;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#29616;&#35937;&#65292;&#21363;&#26631;&#31614;&#22122;&#22768;&#23548;&#33268;&#21407;&#26412;&#35266;&#23519;&#21040;&#30340;&#21452;&#19992;&#38477;&#26354;&#32447;&#20986;&#29616;&#20102;&#8220;&#26368;&#32456;&#19978;&#21319;&#8221;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#36275;&#22815;&#22823;&#30340;&#22122;&#22768;&#26679;&#26412;&#27604;&#29575;&#19979;&#65292;&#20013;&#31561;&#23485;&#24230;&#19979;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#24615;&#33021;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#23558;&#36825;&#31181;&#29616;&#35937;&#24402;&#22240;&#20110;&#26631;&#31614;&#22122;&#22768;&#24341;&#36215;&#30340;&#27979;&#35797;&#25439;&#22833;&#26041;&#24046;&#24418;&#29366;&#36716;&#25442;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#26368;&#32456;&#19978;&#21319;&#29616;&#35937;&#25193;&#23637;&#21040;&#27169;&#22411;&#23494;&#24230;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#29702;&#35770;&#34920;&#24449;&#65292;&#34920;&#26126;&#38543;&#26426;&#20002;&#24323;&#21487;&#35757;&#32451;&#21442;&#25968;&#26469;&#20943;&#23569;&#23494;&#24230;&#21487;&#22312;&#26631;&#31614;&#22122;&#22768;&#19979;&#25913;&#21892;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Increasing the size of overparameterized neural networks has been a key in achieving state-of-the-art performance. This is captured by the double descent phenomenon, where the test loss follows a decreasing-increasing-decreasing pattern as model width increases. However, the effect of label noise on the test loss curve has not been fully explored. In this work, we uncover an intriguing phenomenon where label noise leads to a \textit{final ascent} in the originally observed double descent curve. Specifically, under a sufficiently large noise-to-sample-size ratio, optimal generalization is achieved at intermediate widths. Through theoretical analysis, we attribute this phenomenon to the shape transition of test loss variance induced by label noise. Furthermore, we extend the final ascent phenomenon to model density and provide the first theoretical characterization showing that reducing density by randomly dropping trainable parameters improves generalization under label noise. We also t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#26641;&#20316;&#20026;&#19968;&#31181;&#22238;&#24402;&#21644;&#20998;&#31867;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#21508;&#31181;&#31867;&#22411;&#30340;&#32467;&#26500;&#21270;&#21327;&#21464;&#37327;&#65292;&#24182;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12289;&#23610;&#24230;&#19981;&#21464;&#24615;&#21644;&#26080;&#20998;&#24067;&#20551;&#35774;&#30340;&#33258;&#30001;&#12290;</title><link>http://arxiv.org/abs/2207.04430</link><description>&lt;p&gt;
&#33021;&#37327;&#26641;: &#32467;&#26500;&#21644;&#28151;&#21512;&#22411;&#21327;&#21464;&#37327;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Energy Trees: Regression and Classification With Structured and Mixed-Type Covariates. (arXiv:2207.04430v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04430
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33021;&#37327;&#26641;&#20316;&#20026;&#19968;&#31181;&#22238;&#24402;&#21644;&#20998;&#31867;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#21508;&#31181;&#31867;&#22411;&#30340;&#32467;&#26500;&#21270;&#21327;&#21464;&#37327;&#65292;&#24182;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12289;&#23610;&#24230;&#19981;&#21464;&#24615;&#21644;&#26080;&#20998;&#24067;&#20551;&#35774;&#30340;&#33258;&#30001;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#26085;&#30410;&#22797;&#26434;&#65292;&#38656;&#35201;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#22797;&#26434;&#32467;&#26500;&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#65292;&#22240;&#20026;&#31616;&#21270;&#36825;&#20123;&#32467;&#26500;&#20250;&#23548;&#33268;&#20449;&#24687;&#20002;&#22833;&#12290;&#34429;&#28982;&#24050;&#32463;&#24320;&#21457;&#20102;&#22810;&#31181;&#20998;&#26512;&#24037;&#20855;&#26469;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#23545;&#35937;&#30340;&#21407;&#22987;&#24418;&#24335;&#65292;&#20294;&#36825;&#20123;&#24037;&#20855;&#36890;&#24120;&#20165;&#38480;&#20110;&#21333;&#19968;&#31867;&#22411;&#30340;&#21464;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#33021;&#37327;&#26641;&#20316;&#20026;&#22238;&#24402;&#21644;&#20998;&#31867;&#27169;&#22411;&#65292;&#33021;&#22815;&#23481;&#32435;&#21508;&#31181;&#31867;&#22411;&#30340;&#32467;&#26500;&#21270;&#21327;&#21464;&#37327;&#12290;&#33021;&#37327;&#26641;&#21033;&#29992;&#33021;&#37327;&#32479;&#35745;&#37327;&#25193;&#23637;&#20102;&#26465;&#20214;&#25512;&#26029;&#26641;&#30340;&#33021;&#21147;&#65292;&#20174;&#20013;&#32487;&#25215;&#20102;&#20581;&#20840;&#30340;&#32479;&#35745;&#22522;&#30784;&#12289;&#21487;&#35299;&#37322;&#24615;&#12289;&#23610;&#24230;&#19981;&#21464;&#24615;&#21644;&#26080;&#20998;&#24067;&#20551;&#35774;&#30340;&#33258;&#30001;&#12290;&#25105;&#20204;&#29305;&#21035;&#20851;&#27880;&#21151;&#33021;&#21644;&#22270;&#24418;&#32467;&#26500;&#21327;&#21464;&#37327;&#65292;&#21516;&#26102;&#36824;&#31361;&#20986;&#20102;&#35813;&#27169;&#22411;&#22312;&#25972;&#21512;&#20854;&#20182;&#21464;&#37327;&#31867;&#22411;&#26041;&#38754;&#30340;&#28789;&#27963;&#24615;&#12290;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#21464;&#37327;&#36873;&#25321;&#21644;&#25239;&#36807;&#25311;&#21512;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#20855;&#26377;&#31454;&#20105;&#24615;&#34920;&#29616;&#65292;&#20197;&#21450;&#23545;&#19981;&#21516;&#25968;&#25454;&#32467;&#26500;&#30340;&#36866;&#24212;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#33021;&#37327;&#26641;&#22312;&#23454;&#38469;&#25968;&#25454;&#38598;&#20998;&#26512;&#20013;&#30340;&#28789;&#27963;&#24615;&#65292;&#21253;&#25324;&#21151;&#33021;&#25968;&#25454;&#12289;&#22522;&#22240;&#34920;&#36798;&#21644;&#31038;&#20132;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing complexity of data requires methods and models that can effectively handle intricate structures, as simplifying them would result in loss of information. While several analytical tools have been developed to work with complex data objects in their original form, these tools are typically limited to single-type variables. In this work, we propose energy trees as a regression and classification model capable of accommodating structured covariates of various types. Energy trees leverage energy statistics to extend the capabilities of conditional inference trees, from which they inherit sound statistical foundations, interpretability, scale invariance, and freedom from distributional assumptions. We specifically focus on functional and graph-structured covariates, while also highlighting the model's flexibility in integrating other variable types. Extensive simulation studies demonstrate the model's competitive performance in terms of variable selection and robustness to ove
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#30340;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#20998;&#24067;&#65292;&#21457;&#29616;&#23545;&#28608;&#27963;&#20989;&#25968;&#36827;&#34892;&#24418;&#29366;&#22609;&#36896;&#21487;&#20197;&#20351;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;&#38750;&#36864;&#21270;&#30340;&#65292;&#32780;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#21463;&#21040;&#31070;&#32463;&#21327;&#26041;&#24046;SDE&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2206.02768</link><description>&lt;p&gt;
&#31070;&#32463;&#21327;&#26041;&#24046;SDE&#65306;&#21021;&#22987;&#21270;&#26102;&#20855;&#26377;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#32593;&#32476;&#30340;&#24418;&#29366;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Neural Covariance SDE: Shaped Infinite Depth-and-Width Networks at Initialization. (arXiv:2206.02768v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21021;&#22987;&#21270;&#26102;&#30340;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#20998;&#24067;&#65292;&#21457;&#29616;&#23545;&#28608;&#27963;&#20989;&#25968;&#36827;&#34892;&#24418;&#29366;&#22609;&#36896;&#21487;&#20197;&#20351;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;&#38750;&#36864;&#21270;&#30340;&#65292;&#32780;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#21463;&#21040;&#31070;&#32463;&#21327;&#26041;&#24046;SDE&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30340;logit&#36755;&#20986;&#22312;&#32473;&#23450;&#30001;&#27425;&#34920;&#23618;&#23450;&#20041;&#30340;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26465;&#20214;&#19979;&#26159;&#26465;&#20214;&#39640;&#26031;&#20998;&#24067;&#30340;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#38543;&#26426;&#30697;&#38453;&#30340;&#20998;&#24067;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#32593;&#32476;&#28145;&#24230;&#22686;&#21152;&#26102;&#65292;&#23545;&#28608;&#27963;&#20989;&#25968;&#36827;&#34892;&#24418;&#29366;&#22609;&#36896;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#20351;&#24471;&#36825;&#20010;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;&#38750;&#36864;&#21270;&#30340;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#26080;&#38480;&#23485;&#24230;&#26679;&#24335;&#30340;&#36825;&#31181;&#29702;&#35299;&#22312;&#22823;&#28145;&#24230;&#26102;&#23384;&#22312;&#19981;&#36275;&#65306;&#26080;&#38480;&#23485;&#24230;&#20998;&#26512;&#24573;&#30053;&#20102;&#20174;&#23618;&#21040;&#23618;&#30340;&#24494;&#35266;&#27874;&#21160;&#65292;&#20294;&#36825;&#20123;&#27874;&#21160;&#22312;&#35768;&#22810;&#23618;&#19978;&#31215;&#32047;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#30001;&#24418;&#29366;&#22609;&#36896;&#30340;&#26080;&#38480;&#28145;&#24230;&#21644;&#23485;&#24230;&#26497;&#38480;&#20013;&#30340;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#21040;&#36798;&#38750;&#24179;&#20961;&#26497;&#38480;&#25152;&#38656;&#30340;&#28608;&#27963;&#20989;&#25968;&#30340;&#31934;&#30830;&#32553;&#25918;&#65292;&#24182;&#34920;&#26126;&#38543;&#26426;&#21327;&#26041;&#24046;&#30697;&#38453;&#21463;&#21040;&#25105;&#20204;&#31216;&#20043;&#20026;&#31070;&#32463;&#21327;&#26041;&#24046;SDE&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25511;&#21046;&#12290;&#20351;&#29992;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#23545;&#31070;&#32463;&#21327;&#26041;&#24046;SDE&#30340;&#29702;&#35299;&#26159;&#20934;&#30830;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The logit outputs of a feedforward neural network at initialization are conditionally Gaussian, given a random covariance matrix defined by the penultimate layer. In this work, we study the distribution of this random matrix. Recent work has shown that shaping the activation function as network depth grows large is necessary for this covariance matrix to be non-degenerate. However, the current infinite-width-style understanding of this shaping method is unsatisfactory for large depth: infinite-width analyses ignore the microscopic fluctuations from layer to layer, but these fluctuations accumulate over many layers.  To overcome this shortcoming, we study the random covariance matrix in the shaped infinite-depth-and-width limit. We identify the precise scaling of the activation function necessary to arrive at a non-trivial limit, and show that the random covariance matrix is governed by a stochastic differential equation (SDE) that we call the Neural Covariance SDE. Using simulations, w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#28789;&#27963;&#26465;&#20214;&#23494;&#24230;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#30701;&#26399;&#20302;&#21387;&#36127;&#33655;&#39044;&#27979;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21487;&#29992;&#20110;&#35268;&#21010;&#21644;&#36816;&#33829;&#20302;&#30899;&#33021;&#28304;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2204.13939</link><description>&lt;p&gt;
&#20302;&#21387;&#36127;&#33655;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#30701;&#26399;&#23494;&#24230;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows. (arXiv:2204.13939v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.13939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#28789;&#27963;&#26465;&#20214;&#23494;&#24230;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#30701;&#26399;&#20302;&#21387;&#36127;&#33655;&#39044;&#27979;&#65292;&#30456;&#27604;&#20256;&#32479;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#65292;&#21487;&#29992;&#20110;&#35268;&#21010;&#21644;&#36816;&#33829;&#20302;&#30899;&#33021;&#28304;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a flexible conditional density forecasting method based on Bernstein polynomial normalizing flows for short-term low-voltage load forecasting, which outperforms traditional methods and can be used for planning and operating low-carbon energy systems.
&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#20840;&#38754;&#21487;&#20877;&#29983;&#33021;&#28304;&#30005;&#32593;&#30340;&#36716;&#22411;&#38656;&#35201;&#26356;&#22909;&#22320;&#39044;&#27979;&#20302;&#21387;&#27700;&#24179;&#30340;&#38656;&#27714;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#24182;&#30830;&#20445;&#21487;&#38752;&#30340;&#25511;&#21046;&#12290;&#28982;&#32780;&#65292;&#39640;&#27874;&#21160;&#24615;&#21644;&#19981;&#26029;&#22686;&#21152;&#30340;&#30005;&#27668;&#21270;&#23548;&#33268;&#24040;&#22823;&#30340;&#39044;&#27979;&#21464;&#24322;&#24615;&#65292;&#36825;&#22312;&#20256;&#32479;&#30340;&#28857;&#20272;&#35745;&#20013;&#27809;&#26377;&#21453;&#26144;&#20986;&#26469;&#12290;&#27010;&#29575;&#36127;&#36733;&#39044;&#27979;&#32771;&#34385;&#26410;&#26469;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#22240;&#27492;&#20801;&#35768;&#26356;&#26126;&#26234;&#30340;&#20915;&#31574;&#65292;&#29992;&#20110;&#35268;&#21010;&#21644;&#36816;&#33829;&#20302;&#30899;&#33021;&#28304;&#31995;&#32479;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20271;&#24681;&#26031;&#22374;&#22810;&#39033;&#24335;&#24402;&#19968;&#21270;&#27969;&#30340;&#28789;&#27963;&#26465;&#20214;&#23494;&#24230;&#39044;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#31070;&#32463;&#32593;&#32476;&#25511;&#21046;&#27969;&#30340;&#21442;&#25968;&#12290;&#22312;&#19968;&#39033;&#21253;&#25324;363&#20010;&#26234;&#33021;&#30005;&#34920;&#23458;&#25143;&#30340;&#23454;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30340;&#23494;&#24230;&#39044;&#27979;&#19982;&#39640;&#26031;&#21644;&#39640;&#26031;&#28151;&#21512;&#23494;&#24230;&#30456;&#27604;&#34920;&#29616;&#20986;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#20004;&#31181;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#23427;&#20204;&#22312;24&#23567;&#26102;&#21069;&#30340;&#36127;&#36733;&#39044;&#27979;&#20013;&#20248;&#20110;&#22522;&#20110;&#38024;&#29699;&#25439;&#22833;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The transition to a fully renewable energy grid requires better forecasting of demand at the low-voltage level to increase efficiency and ensure reliable control. However, high fluctuations and increasing electrification cause huge forecast variability, not reflected in traditional point estimates. Probabilistic load forecasts take future uncertainties into account and thus allow more informed decision-making for the planning and operation of low-carbon energy systems. We propose an approach for flexible conditional density forecasting of short-term load based on Bernstein polynomial normalizing flows, where a neural network controls the parameters of the flow. In an empirical study with 363 smart meter customers, our density predictions compare favorably against Gaussian and Gaussian mixture densities. Also, they outperform a non-parametric approach based on the pinball loss for 24h-ahead load forecasting for two different neural network architectures.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#25299;&#25169;&#28608;&#27963;&#22270;&#26469;&#21487;&#35270;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21450;&#20854;&#20915;&#31574;&#36807;&#31243;&#65292;&#25552;&#39640;&#20102; DNN &#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2204.03528</link><description>&lt;p&gt;
&#29992;&#25299;&#25169;&#28608;&#27963;&#22270;&#26469;&#21487;&#35270;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Visualizing Deep Neural Networks with Topographic Activation Maps. (arXiv:2204.03528v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.03528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#25299;&#25169;&#28608;&#27963;&#22270;&#26469;&#21487;&#35270;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21450;&#20854;&#20915;&#31574;&#36807;&#31243;&#65292;&#25552;&#39640;&#20102; DNN &#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#35299;&#20915;&#21508;&#39046;&#22495;&#20219;&#21153;&#20013;&#24050;&#25104;&#20026;&#25104;&#21151;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;DNN&#30340;&#22797;&#26434;&#24615;&#20351;&#24471;&#20102;&#35299;&#20854;&#22914;&#20309;&#35299;&#20915;&#25152;&#23398;&#20219;&#21153;&#21464;&#24471;&#22256;&#38590;&#12290;&#20026;&#20102;&#25552;&#39640; DNN &#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#37319;&#29992;&#31070;&#32463;&#31185;&#23398;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#22797;&#26434;&#30340;&#19981;&#36879;&#26126;&#31995;&#32479;&#12290;&#25105;&#20204;&#20174;&#31070;&#32463;&#31185;&#23398;&#22914;&#20309;&#20351;&#29992;&#25299;&#25169;&#22270;&#21487;&#35270;&#21270;&#33041;&#27963;&#21160;&#20013;&#33719;&#21462;&#28789;&#24863;&#65292;&#21516;&#26679;&#22320;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24067;&#32622; DNN &#23618;&#20013;&#31070;&#32463;&#20803;&#30340;&#25216;&#26415;&#65292;&#20351;&#24471;&#20855;&#26377;&#31867;&#20284;&#28608;&#27963;&#30340;&#31070;&#32463;&#20803;&#22312;&#24444;&#27492;&#38468;&#36817;&#12290;&#26412;&#25991;&#20013;&#25105;&#20204;&#20171;&#32461;&#20102;&#24182;&#27604;&#36739;&#20102;&#33719;&#24471; DNN &#23618;&#20013;&#31070;&#32463;&#20803;&#25299;&#25169;&#32467;&#26500;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#25299;&#25169;&#28608;&#27963;&#22270;&#26469;&#35782;&#21035;&#38169;&#35823;&#25110;&#32534;&#30721;&#20559;&#35265;&#65292;&#24182;&#21487;&#35270;&#21270;&#35757;&#32451;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26032;&#22411;&#21487;&#35270;&#21270;&#25216;&#26415;&#25552;&#39640;&#20102;&#22522;&#20110; DNN &#30340;&#20915;&#31574;&#31995;&#32479;&#30340;&#36879;&#26126;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning with Deep Neural Networks (DNNs) has become a successful tool in solving tasks across various fields of application. However, the complexity of DNNs makes it difficult to understand how they solve their learned task. To improve the explainability of DNNs, we adapt methods from neuroscience that analyze complex and opaque systems. Here, we draw inspiration from how neuroscience uses topographic maps to visualize brain activity. To also visualize activations of neurons in DNNs as topographic maps, we research techniques to layout the neurons in a two-dimensional space such that neurons of similar activity are in the vicinity of each other. In this work, we introduce and compare methods to obtain a topographic layout of neurons in a DNN layer. Moreover, we demonstrate how to use topographic activation maps to identify errors or encoded biases and to visualize training processes. Our novel visualization technique improves the transparency of DNN-based decision-making syste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#30456;&#22270;&#65292;&#25506;&#31350;&#20102;&#31364;&#32593;&#32476;&#21644;&#36807;&#21442;&#25968;&#21270;&#27973;&#23618;&#32593;&#32476;&#20043;&#38388;&#30340;&#20132;&#30028;&#22788;&#65292;&#24182;&#30740;&#31350;&#20102;&#19977;&#20010;&#26041;&#38754;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24037;&#20316;&#24314;&#31435;&#22312;&#32479;&#35745;&#29289;&#29702;&#30340;&#26694;&#26550;&#19979;&#12290;</title><link>http://arxiv.org/abs/2202.00293</link><description>&lt;p&gt;
&#39640;&#32500;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#30456;&#22270;
&lt;/p&gt;
&lt;p&gt;
Phase diagram of Stochastic Gradient Descent in high-dimensional two-layer neural networks. (arXiv:2202.00293v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.00293
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#30456;&#22270;&#65292;&#25506;&#31350;&#20102;&#31364;&#32593;&#32476;&#21644;&#36807;&#21442;&#25968;&#21270;&#27973;&#23618;&#32593;&#32476;&#20043;&#38388;&#30340;&#20132;&#30028;&#22788;&#65292;&#24182;&#30740;&#31350;&#20102;&#19977;&#20010;&#26041;&#38754;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24037;&#20316;&#24314;&#31435;&#22312;&#32479;&#35745;&#29289;&#29702;&#30340;&#26694;&#26550;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#38750;&#20984;&#20248;&#21270;&#26223;&#35266;&#65292;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#27973;&#23618;&#32593;&#32476;&#20013;&#65292;&#26799;&#24230;&#19979;&#38477;&#33021;&#22815;&#23454;&#29616;&#20840;&#23616;&#25910;&#25947;&#12290;&#20294;&#24773;&#20917;&#23545;&#20110;&#31364;&#32593;&#32476;&#21364;&#21487;&#33021;&#23436;&#20840;&#19981;&#21516;&#65292;&#23427;&#20204;&#20542;&#21521;&#20110;&#34987;&#22256;&#22312;&#20855;&#26377;&#31967;&#31957;&#27867;&#21270;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#36825;&#20004;&#20010;&#33539;&#30068;&#20043;&#38388;&#30340;&#20132;&#30028;&#22788;&#65292;&#29305;&#21035;&#26159;&#25105;&#20204;&#35843;&#26597;&#20102;&#25152;&#35859;&#30340;&#24179;&#22343;&#22330;/&#27969;&#20307;&#21147;&#23398;&#33539;&#30068;&#19982;Saad&#21644;Solla &#30340;&#24320;&#21019;&#24615;&#26041;&#27861;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#25105;&#20204;&#37325;&#28857;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#20013;&#65292;&#23398;&#20064;&#29575;&#12289;&#26102;&#38388;&#23610;&#24230;&#21644;&#38544;&#21547;&#23618;&#25968;&#37327;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#39640;&#26031;&#25968;&#25454;&#20026;&#20363;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;&#20174;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#23545;&#20110;&#39640;&#32500;&#24230;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#30830;&#23450;&#24615;&#25551;&#36848;&#65292;&#25105;&#20204;&#21152;&#20197;&#25299;&#23637;&#24182;&#25552;&#20379;&#20102;&#20005;&#23494;&#30340;&#25910;&#25947;&#36895;&#29575;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the non-convex optimization landscape, over-parametrized shallow networks are able to achieve global convergence under gradient descent. The picture can be radically different for narrow networks, which tend to get stuck in badly-generalizing local minima. Here we investigate the cross-over between these two regimes in the high-dimensional setting, and in particular investigate the connection between the so-called mean-field/hydrodynamic regime and the seminal approach of Saad &amp; Solla. Focusing on the case of Gaussian data, we study the interplay between the learning rate, the time scale, and the number of hidden units in the high-dimensional dynamics of stochastic gradient descent (SGD). Our work builds on a deterministic description of SGD in high-dimensions from statistical physics, which we extend and for which we provide rigorous convergence rates.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;OOD&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35266;&#23519;&#35282;&#24230;&#65292;&#21363;&#23558;&#24179;&#22343;&#20284;&#28982;&#20998;&#35299;&#20026;KL&#25955;&#24230;&#39033;&#21644;&#29109;&#39033;&#12290;&#21518;&#32773;&#21487;&#20197;&#35299;&#37322;&#27169;&#22411;&#21487;&#33021;&#20250;&#32473;OOD&#25968;&#25454;&#39640;&#20284;&#28982;&#20540;&#30340;&#29616;&#35937;&#65292;&#22240;&#20026;&#23427;&#25233;&#21046;&#20855;&#26377;&#26356;&#39640;&#29109;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#20284;&#28982;&#20540;&#12290;</title><link>http://arxiv.org/abs/2109.10794</link><description>&lt;p&gt;
&#22522;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;OOD&#26816;&#27979;&#20013;&#30340;&#29109;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Entropic Issues in Likelihood-Based OOD Detection. (arXiv:2109.10794v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10794
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;OOD&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35266;&#23519;&#35282;&#24230;&#65292;&#21363;&#23558;&#24179;&#22343;&#20284;&#28982;&#20998;&#35299;&#20026;KL&#25955;&#24230;&#39033;&#21644;&#29109;&#39033;&#12290;&#21518;&#32773;&#21487;&#20197;&#35299;&#37322;&#27169;&#22411;&#21487;&#33021;&#20250;&#32473;OOD&#25968;&#25454;&#39640;&#20284;&#28982;&#20540;&#30340;&#29616;&#35937;&#65292;&#22240;&#20026;&#23427;&#25233;&#21046;&#20855;&#26377;&#26356;&#39640;&#29109;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#20284;&#28982;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20173;&#28982;&#26159;&#20851;&#20110;&#25968;&#25454;&#27010;&#29575;&#25512;&#29702;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#35266;&#23519;&#21040;&#23427;&#20204;&#21487;&#33021;&#20250;&#20998;&#37197;&#27604;&#27491;&#21521;&#20998;&#24067;&#25968;&#25454;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#65292;&#22240;&#27492;&#36136;&#30097;&#36825;&#20123;&#20284;&#28982;&#20540;&#30340;&#21547;&#20041;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#35266;&#23519;&#35282;&#24230;&#65292;&#23558;&#24179;&#22343;&#20284;&#28982;&#20998;&#35299;&#20026;KL&#25955;&#24230;&#39033;&#21644;&#29109;&#39033;&#12290;&#25105;&#20204;&#35748;&#20026;&#21518;&#32773;&#21487;&#20197;&#35299;&#37322;&#19978;&#36848;&#22855;&#24618;&#30340;OOD&#34892;&#20026;&#65292;&#25233;&#21046;&#20855;&#26377;&#26356;&#39640;&#29109;&#30340;&#25968;&#25454;&#38598;&#19978;&#30340;&#20284;&#28982;&#20540;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#24605;&#36335;&#24456;&#31616;&#21333;&#65292;&#20294;&#25105;&#20204;&#36824;&#27809;&#26377;&#30475;&#21040;&#23427;&#22312;&#25991;&#29486;&#20013;&#24471;&#21040;&#25506;&#35752;&#12290;&#36825;&#31181;&#20998;&#26512;&#36827;&#19968;&#27493;&#35299;&#37322;&#20102;&#22522;&#20110;&#20284;&#28982;&#27604;&#30340;OOD&#26816;&#27979;&#26041;&#27861;&#25104;&#21151;&#30340;&#21407;&#22240;&#65292;&#22240;&#20026;&#38382;&#39064;&#29109;&#39033;&#22312;&#26399;&#26395;&#20013;&#20250;&#25269;&#28040;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#22914;&#20309;&#19982;&#26368;&#36817;&#22312;&#27969;&#24418;&#25903;&#25345;&#27169;&#22411;&#20013;&#30340;OOD&#26816;&#27979;&#25104;&#21151;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep generative models trained by maximum likelihood remain very popular methods for reasoning about data probabilistically. However, it has been observed that they can assign higher likelihoods to out-of-distribution (OOD) data than in-distribution data, thus calling into question the meaning of these likelihood values. In this work we provide a novel perspective on this phenomenon, decomposing the average likelihood into a KL divergence term and an entropy term. We argue that the latter can explain the curious OOD behaviour mentioned above, suppressing likelihood values on datasets with higher entropy. Although our idea is simple, we have not seen it explored yet in the literature. This analysis provides further explanation for the success of OOD detection methods based on likelihood ratios, as the problematic entropy term cancels out in expectation. Finally, we discuss how this observation relates to recent success in OOD detection with manifold-supported models, for which the above
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#38656;&#20449;&#20219;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182;&#25968;&#25454;&#28304;&#30340;&#36328; silo &#32852;&#37030;&#23398;&#20064;&#65292;&#32771;&#34385;&#20102;&#36328; silo &#35760;&#24405;&#32423;&#24046;&#20998;&#38544;&#31169; ISRL-DP&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#30830;&#20445;&#26469;&#33258;&#27599;&#20010;&#20154;&#30340;&#25968;&#25454;&#37117;&#19981;&#20250;&#34987;&#27844;&#28431;&#12290;</title><link>http://arxiv.org/abs/2106.09779</link><description>&lt;p&gt;
&#26080;&#38656;&#20449;&#20219;&#30340;&#31169;&#26377;&#32852;&#37030;&#23398;&#20064;&#65306;&#20984;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses. (arXiv:2106.09779v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.09779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26080;&#38656;&#20449;&#20219;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182;&#25968;&#25454;&#28304;&#30340;&#36328; silo &#32852;&#37030;&#23398;&#20064;&#65292;&#32771;&#34385;&#20102;&#36328; silo &#35760;&#24405;&#32423;&#24046;&#20998;&#38544;&#31169; ISRL-DP&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#30830;&#20445;&#26469;&#33258;&#27599;&#20010;&#20154;&#30340;&#25968;&#25454;&#37117;&#19981;&#20250;&#34987;&#27844;&#28431;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#30740;&#31350;&#65292;&#29305;&#21035;&#26159;&#36328;&#25968;&#25454;&#28304;&#65288;&#36328; silo&#65289;FL&#65292;&#36825;&#20123;&#25968;&#25454;&#28304;&#30340;&#25968;&#25454;&#20027;&#20154;&#37117;&#19981;&#20449;&#20219;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182; silos&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#25968;&#25454;&#28304;&#65288;&#20363;&#22914;&#21307;&#38498;&#65289;&#37117;&#26377;&#26469;&#33258;&#19981;&#21516;&#20154;&#65288;&#20363;&#22914;&#24739;&#32773;&#65289;&#30340;&#25968;&#25454;&#65292;&#24182;&#19988;&#24517;&#39035;&#32500;&#25252;&#27599;&#20010;&#20154;&#65288;&#20363;&#22914;&#21307;&#30103;&#35760;&#24405;&#65289;&#25968;&#25454;&#30340;&#38544;&#31169;&#65292;&#21363;&#20351;&#26381;&#21153;&#22120;&#25110;&#20854;&#20182;&#25968;&#25454;&#28304;&#26159;&#24694;&#24847;&#30417;&#21548;&#32773;&#12290;&#36825;&#31181;&#35201;&#27714;&#20419;&#36827;&#20102;&#23545;&#36328; silo &#35760;&#24405;&#32423;&#24046;&#20998;&#38544;&#31169;&#65288;ISRL-DP&#65289;&#30340;&#30740;&#31350;&#65292;&#23427;&#35201;&#27714; silo i &#30340;&#36890;&#20449;&#28385;&#36275;&#35760;&#24405; / &#39033;&#30446;&#32423;&#24046;&#20998;&#38544;&#31169; (DP)&#12290;ISRL-DP &#30830;&#20445; silo i &#20013;&#27599;&#20010;&#20154;&#65288;&#20363;&#22914;&#24739;&#32773;&#65289;&#30340;&#25968;&#25454;&#37117;&#19981;&#20250;&#27844;&#28431;&#12290;ISRL-DP &#19981;&#21516;&#20110;&#21508;&#31181;&#24050;&#26377;&#30340;&#38544;&#31169;&#27010;&#24565;&#12290;&#20013;&#24515;&#21644;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#20551;&#23450;&#20154;&#20204;&#20449;&#20219;&#26381;&#21153;&#22120;/&#20854;&#20182;&#25968;&#25454;&#28304;&#12290;&#22312;&#26497;&#31471;&#24773;&#20917;&#19979;&#65292;&#26412;&#22320;DP &#20551;&#23450;&#20154;&#20204;&#26681;&#26412;&#19981;&#20449;&#20219;&#20219;&#20309;&#20154;&#65288;&#29978;&#33267;&#26159;&#20182;&#20204;&#33258;&#24049;&#30340;&#25968;&#25454;&#28304;&#65289;&#12290;ISRL-DP &#22788;&#20110;&#20013;&#24515;&#21644;&#26412;&#22320;DP &#20043;&#38388;&#65292;&#20351;&#24471;&#22312;&#36328; silo &#30340;&#30495;&#23454;&#24773;&#20917;&#19979;&#20855;&#26377;&#29616;&#23454;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies federated learning (FL)--especially cross-silo FL--with data from people who do not trust the server or other silos. In this setting, each silo (e.g. hospital) has data from different people (e.g. patients) and must maintain the privacy of each person's data (e.g. medical record), even if the server or other silos act as adversarial eavesdroppers. This requirement motivates the study of Inter-Silo Record-Level Differential Privacy (ISRL-DP), which requires silo i's communications to satisfy record/item-level differential privacy (DP). ISRL-DP ensures that the data of each person (e.g. patient) in silo i (e.g. hospital i) cannot be leaked. ISRL-DP is different from well-studied privacy notions. Central and user-level DP assume that people trust the server/other silos. On the other end of the spectrum, local DP assumes that people do not trust anyone at all (even their own silo). Sitting between central and local DP, ISRL-DP makes the realistic assumption (in cross-sil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#21152;&#26435;&#26694;&#26550;&#26041;&#27861;&#20197;&#32531;&#35299;&#22240;&#35268;&#23450;&#30340;&#20989;&#25968;&#31867;&#19981;&#21253;&#21547;&#26368;&#20248;&#35268;&#21017;&#32780;&#23548;&#33268;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2105.00581</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#26679;&#26412;&#21152;&#26435;&#26041;&#27861;&#20197;&#20415;&#20026;&#30446;&#26631;&#20154;&#32676;&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Robust Sample Weighting to Facilitate Individualized Treatment Rule Learning for a Target Population. (arXiv:2105.00581v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.00581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#21152;&#26435;&#26694;&#26550;&#26041;&#27861;&#20197;&#32531;&#35299;&#22240;&#35268;&#23450;&#30340;&#20989;&#25968;&#31867;&#19981;&#21253;&#21547;&#26368;&#20248;&#35268;&#21017;&#32780;&#23548;&#33268;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#23545;&#20110;&#31934;&#20934;&#21307;&#30103;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#20174;&#21333;&#20010;&#26469;&#28304;&#20154;&#32676;&#20013;&#23548;&#20986;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#12290;&#28982;&#32780;&#65292;&#24403;&#26469;&#28304;&#20154;&#32676;&#19982;&#30446;&#26631;&#20154;&#32676;&#19981;&#21516;&#26102;&#65292;&#25105;&#20204;&#38656;&#35201;&#32771;&#34385;&#35266;&#23519;&#25968;&#25454;&#35774;&#32622;&#12290;&#19982;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#30340;&#22240;&#26524;&#25512;&#24191;&#19981;&#21516;&#65292;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#30340;&#25512;&#24191;&#30001;&#20110;&#38656;&#35201;&#22522;&#20110;&#19968;&#20010;&#39044;&#20808;&#25351;&#23450;&#30340;&#20989;&#25968;&#31867;&#23545;&#35268;&#21017;&#36827;&#34892;&#24314;&#27169;&#21644;&#25512;&#24191;&#65292;&#22240;&#27492;&#38754;&#20020;&#30528;&#26032;&#30340;&#25361;&#25112;&#65292;&#35813;&#20989;&#25968;&#31867;&#21487;&#33021;&#19981;&#21253;&#21547;&#26080;&#32422;&#26463;&#30495;&#27491;&#26368;&#20248;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#12290;&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#31181;&#21152;&#26435;&#26694;&#26550;&#65292;&#20197;&#32531;&#35299;&#36825;&#31181;&#38169;&#35823;&#35268;&#23450;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20419;&#36827;&#20174;&#26469;&#28304;&#20154;&#32676;&#21040;&#30446;&#26631;&#20154;&#32676;&#30340;&#26368;&#20248;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#30340;&#27867;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23547;&#27714;&#22312;&#30001;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#34920;&#24449;&#30340;&#38750;&#21442;&#25968;&#20989;&#25968;&#31867;&#19978;&#36827;&#34892;&#21327;&#21464;&#37327;&#24179;&#34913;&#65292;&#24182;&#19988;&#21487;&#20197;&#25913;&#36827;&#35768;&#22810;&#20381;&#36182;&#20110;&#26435;&#37325;&#30340;&#20010;&#20307;&#21270;&#27835;&#30103;&#35268;&#21017;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26679;&#26412;&#21152;&#26435;&#20272;&#35745;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning individualized treatment rules (ITRs) is an important topic in precision medicine. Current literature mainly focuses on deriving ITRs from a single source population. We consider the observational data setting when the source population differs from a target population of interest. Compared with causal generalization for the average treatment effect which is a scalar quantity, ITR generalization poses new challenges due to the need to model and generalize the rules based on a prespecified class of functions which may not contain the unrestricted true optimal ITR. The aim of this paper is to develop a weighting framework to mitigate the impact of such misspecification and thus facilitate the generalizability of optimal ITRs from a source population to a target population. Our method seeks covariate balance over a non-parametric function class characterized by a reproducing kernel Hilbert space and can improve many ITR learning methods that rely on weights. We show that the prop
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#20998;&#24067;&#38598;&#21512;&#27604;&#36739;&#26041;&#27861;&#65292;&#33021;&#22312;&#27969;&#24418;&#21644;&#22270;&#19978;&#20351;&#29992;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20869;&#22312;&#20999;&#29255;&#26500;&#36896;&#65292;&#24471;&#20986;&#19968;&#31181;&#26032;&#30340;&#31867;Wasserstein&#36317;&#31163;&#65292;&#21487;&#23558;&#20998;&#24067;&#38598;&#21512;&#27604;&#36739;&#38382;&#39064;&#20943;&#23569;&#21040;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#26356;&#29087;&#24713;&#30340;&#22343;&#20540;&#26816;&#39564;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2010.15285</link><description>&lt;p&gt;
&#20869;&#22312;&#20999;&#29255;Wasserstein&#36317;&#31163;&#29992;&#20110;&#27604;&#36739;&#27969;&#24418;&#21644;&#22270;&#19978;&#30340;&#27010;&#29575;&#20998;&#24067;&#38598;&#21512;
&lt;/p&gt;
&lt;p&gt;
Intrinsic Sliced Wasserstein Distances for Comparing Collections of Probability Distributions on Manifolds and Graphs. (arXiv:2010.15285v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.15285
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#20998;&#24067;&#38598;&#21512;&#27604;&#36739;&#26041;&#27861;&#65292;&#33021;&#22312;&#27969;&#24418;&#21644;&#22270;&#19978;&#20351;&#29992;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20869;&#22312;&#20999;&#29255;&#26500;&#36896;&#65292;&#24471;&#20986;&#19968;&#31181;&#26032;&#30340;&#31867;Wasserstein&#36317;&#31163;&#65292;&#21487;&#23558;&#20998;&#24067;&#38598;&#21512;&#27604;&#36739;&#38382;&#39064;&#20943;&#23569;&#21040;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#26356;&#29087;&#24713;&#30340;&#22343;&#20540;&#26816;&#39564;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#20998;&#24067;&#30340;&#38598;&#21512;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#33539;&#22260;&#20174;&#29992;&#25143;&#27963;&#21160;&#27169;&#24335;&#20998;&#26512;&#21040;&#33041;&#36830;&#25509;&#23398;&#12290;&#23454;&#38469;&#19978;&#65292;&#36825;&#20123;&#20998;&#24067;&#21487;&#20197;&#23450;&#20041;&#22312;&#21508;&#31181;&#19981;&#21516;&#30340;&#22495;&#31867;&#22411;&#19978;&#65292;&#21253;&#25324;&#26377;&#38480;&#21306;&#38388;&#12289;&#22278;&#12289;&#22278;&#26609;&#12289;&#29699;&#12289;&#20854;&#20182;&#27969;&#24418;&#21644;&#22270;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#22312;&#36825;&#26679;&#30340;&#19968;&#33324;&#22495;&#19978;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#38598;&#21512;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20869;&#22312;&#20999;&#29255;&#26500;&#36896;&#65292;&#24471;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#31867;Wasserstein&#36317;&#31163;&#65292;&#29992;&#20110;&#27969;&#24418;&#21644;&#22270;&#19978;&#30340;&#20998;&#24067;&#12290;&#36825;&#20123;&#36317;&#31163;&#26159;&#24076;&#23572;&#20271;&#29305;&#21487;&#23884;&#20837;&#30340;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#20998;&#24067;&#38598;&#21512;&#27604;&#36739;&#38382;&#39064;&#20943;&#23569;&#21040;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#26356;&#29087;&#24713;&#30340;&#22343;&#20540;&#26816;&#39564;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#31181;&#27979;&#35797;&#31243;&#24207;&#65292;&#19968;&#31181;&#22522;&#20110;&#37325;&#37319;&#26679;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#26469;&#33258;&#22352;&#26631;&#21270;&#27979;&#35797;&#30340;p&#20540;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#35774;&#32622;&#20013;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#24471;&#21040;&#30340;&#27979;&#35797;&#26159;&#24378;&#26377;&#21147;&#30340;&#65292;p&#20540;&#26159;&#24456;&#22909;&#22320;&#26657;&#20934;&#36807;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collections of probability distributions arise in a variety of applications ranging from user activity pattern analysis to brain connectomics. In practice these distributions can be defined over diverse domain types including finite intervals, circles, cylinders, spheres, other manifolds, and graphs. This paper introduces an approach for detecting differences between two collections of distributions over such general domains. To this end, we propose the intrinsic slicing construction that yields a novel class of Wasserstein distances on manifolds and graphs. These distances are Hilbert embeddable, allowing us to reduce the distribution collection comparison problem to a more familiar mean testing problem in a Hilbert space. We provide two testing procedures one based on resampling and another on combining p-values from coordinate-wise tests. Our experiments in various synthetic and real data settings show that the resulting tests are powerful and the p-values are well-calibrated.
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23545;&#25509;&#30340;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#20998;&#23376;&#32467;&#21512;&#34507;&#30333;&#36136;&#30340;&#27969;&#34892;&#35745;&#31639;&#26041;&#27861;&#65292;&#25506;&#31350;&#20102;&#30446;&#21069;&#22522;&#20110;&#22270;&#24418;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#26032;&#22411;&#33647;&#29289;&#35774;&#35745;&#19978;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#29256;&#26412;&#12290;</title><link>http://arxiv.org/abs/2006.16955</link><description>&lt;p&gt;
&#25105;&#20204;&#33267;&#23569;&#24212;&#35813;&#33021;&#22815;&#35774;&#35745;&#20986;&#22909;&#30340;&#20998;&#23376;&#32467;&#21512;&#20307;
&lt;/p&gt;
&lt;p&gt;
We Should at Least Be Able to Design Molecules That Dock Well. (arXiv:2006.16955v5 [q-bio.BM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.16955
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23545;&#25509;&#30340;&#22522;&#20934;&#27979;&#35797;&#26469;&#35780;&#20272;&#20998;&#23376;&#32467;&#21512;&#34507;&#30333;&#36136;&#30340;&#27969;&#34892;&#35745;&#31639;&#26041;&#27861;&#65292;&#25506;&#31350;&#20102;&#30446;&#21069;&#22522;&#20110;&#22270;&#24418;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#26032;&#22411;&#33647;&#29289;&#35774;&#35745;&#19978;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#22522;&#20934;&#27979;&#35797;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#20855;&#26377;&#25152;&#38656;&#29305;&#24615;&#30340;&#21270;&#21512;&#29289;&#26159;&#33647;&#29289;&#21457;&#29616;&#36807;&#31243;&#30340;&#20851;&#38190;&#20803;&#32032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#29616;&#23454;&#30340;&#22238;&#39038;&#24615;&#22522;&#20934;&#21644;&#21069;&#30651;&#24615;&#39564;&#35777;&#30340;&#39640;&#26114;&#25104;&#26412;&#65292;&#34913;&#37327;&#35813;&#39046;&#22495;&#30340;&#36827;&#23637;&#19968;&#30452;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#23545;&#25509;&#30340;&#22522;&#20934;&#27979;&#35797;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#20998;&#23376;&#32467;&#21512;&#34507;&#30333;&#36136;&#30340;&#27969;&#34892;&#35745;&#31639;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#30446;&#26631;&#26159;&#29983;&#25104;&#24471;&#20998;&#39640;&#30340;&#33647;&#29289;&#26679;&#20998;&#23376;&#65292;&#36825;&#20123;&#33647;&#29289;&#23646;&#20110;SMINA&#65292;&#19968;&#31181;&#27969;&#34892;&#30340;&#23545;&#25509;&#36719;&#20214;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#20351;&#29992;&#30495;&#23454;&#22823;&#23567;&#30340;&#35757;&#32451;&#38598;&#36827;&#34892;&#35757;&#32451;&#21518;&#65292;&#27969;&#34892;&#30340;&#22522;&#20110;&#22270;&#24418;&#30340;&#29983;&#25104;&#27169;&#22411;&#26080;&#27861;&#29983;&#25104;&#20855;&#26377;&#39640;&#32467;&#21512;&#24471;&#20998;&#30340;&#20998;&#23376;&#12290;&#36825;&#34920;&#26126;&#20102;&#24403;&#21069;&#30340;&#27169;&#22411;&#22312;&#26032;&#22411;&#33647;&#29289;&#35774;&#35745;&#20013;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#31616;&#21270;&#35780;&#20998;&#20989;&#25968;&#30340;&#22522;&#20934;&#27979;&#35797;&#29256;&#26412;&#65292;&#24182;&#23637;&#31034;&#27979;&#35797;&#27169;&#22411;&#33021;&#22815;&#37096;&#20998;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#35813;&#22522;&#20934;&#27979;&#35797;&#20316;&#20026;&#19968;&#20010;&#26131;&#20110;&#20351;&#29992;&#30340;&#36719;&#20214;&#21253;&#21457;&#24067;&#65292;&#21487;&#22312; https://github.com &#19978;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Designing compounds with desired properties is a key element of the drug discovery process. However, measuring progress in the field has been challenging due to the lack of realistic retrospective benchmarks, and the large cost of prospective validation. To close this gap, we propose a benchmark based on docking, a popular computational method for assessing molecule binding to a protein. Concretely, the goal is to generate drug-like molecules that are scored highly by SMINA, a popular docking software. We observe that popular graph-based generative models fail to generate molecules with a high docking score when trained using a realistically sized training set. This suggests a limitation of the current incarnation of models for de novo drug design. Finally, we propose a simplified version of the benchmark based on a simpler scoring function, and show that the tested models are able to partially solve it. We release the benchmark as an easy to use package available at https://github.com
&lt;/p&gt;</description></item></channel></rss>