<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SurvBeX&#30340;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#27169;&#22411;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#25913;&#36827;&#30340;Beran&#20272;&#35745;&#22120;&#20316;&#20026;&#26367;&#20195;&#35299;&#37322;&#27169;&#22411;&#65292;&#26469;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#40657;&#30418;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SurvBeX&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.03730</link><description>&lt;p&gt;
SurvBeX:&#19968;&#31181;&#22522;&#20110;Beran&#20272;&#35745;&#22120;&#30340;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#27169;&#22411;&#35299;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
SurvBeX: An explanation method of the machine learning survival models based on the Beran estimator. (arXiv:2308.03730v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03730
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SurvBeX&#30340;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#27169;&#22411;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#25913;&#36827;&#30340;Beran&#20272;&#35745;&#22120;&#20316;&#20026;&#26367;&#20195;&#35299;&#37322;&#27169;&#22411;&#65292;&#26469;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#40657;&#30418;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;SurvBeX&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SurvBeX&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#29983;&#23384;&#40657;&#30418;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#35813;&#26041;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#20351;&#29992;&#25913;&#36827;&#30340;Beran&#20272;&#35745;&#22120;&#20316;&#20026;&#26367;&#20195;&#35299;&#37322;&#27169;&#22411;&#12290;&#21512;&#24182;&#21040;Beran&#20272;&#35745;&#22120;&#20013;&#30340;&#31995;&#25968;&#21487;&#20197;&#34987;&#35270;&#20026;&#29305;&#24449;&#23545;&#40657;&#30418;&#27169;&#22411;&#39044;&#27979;&#30340;&#24433;&#21709;&#20540;&#12290;&#36890;&#36807;&#22312;&#24863;&#20852;&#36259;&#30340;&#31034;&#20363;&#21608;&#22260;&#30340;&#23616;&#37096;&#21306;&#22495;&#29983;&#25104;&#35768;&#22810;&#28857;&#65292;&#25353;&#29031;&#33879;&#21517;&#30340;LIME&#26041;&#27861;&#65292;&#20026;&#27599;&#20010;&#29983;&#25104;&#30340;&#31034;&#20363;&#35745;&#31639;&#40657;&#30418;&#27169;&#22411;&#30340;&#29983;&#23384;&#20989;&#25968;&#65292;&#24182;&#26500;&#24314;&#26367;&#20195;&#27169;&#22411;&#65288;Beran&#20272;&#35745;&#22120;&#65289;&#30340;&#29983;&#23384;&#20989;&#25968;&#65292;&#20316;&#20026;&#35299;&#37322;&#31995;&#25968;&#30340;&#20989;&#25968;&#12290;&#20026;&#20102;&#25214;&#21040;&#35299;&#37322;&#31995;&#25968;&#65292;&#24314;&#35758;&#36890;&#36807;&#26368;&#23567;&#21270;&#29983;&#25104;&#31034;&#20363;&#20135;&#29983;&#30340;&#40657;&#30418;&#27169;&#22411;&#21644;Beran&#20272;&#35745;&#22120;&#30340;&#29983;&#23384;&#20989;&#25968;&#20043;&#38388;&#30340;&#24179;&#22343;&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;&#35768;&#22810;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#29983;&#23384;&#25968;&#25454;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;SurvBeX&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
An explanation method called SurvBeX is proposed to interpret predictions of the machine learning survival black-box models. The main idea behind the method is to use the modified Beran estimator as the surrogate explanation model. Coefficients, incorporated into Beran estimator, can be regarded as values of the feature impacts on the black-box model prediction. Following the well-known LIME method, many points are generated in a local area around an example of interest. For every generated example, the survival function of the black-box model is computed, and the survival function of the surrogate model (the Beran estimator) is constructed as a function of the explanation coefficients. In order to find the explanation coefficients, it is proposed to minimize the mean distance between the survival functions of the black-box model and the Beran estimator produced by the generated examples. Many numerical experiments with synthetic and real survival data demonstrate the SurvBeX efficienc
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#20108;&#38454;&#30697;&#26465;&#20214;&#19979;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2308.03686</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#33719;&#24471;&#25193;&#25955;&#27169;&#22411;&#30340;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence Bounds for Diffusion Models via Stochastic Localization. (arXiv:2308.03686v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03686
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#23450;&#20301;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;&#25193;&#25955;&#27169;&#22411;&#20013;&#32447;&#24615;&#25910;&#25947;&#30028;&#38480;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#20108;&#38454;&#30697;&#26465;&#20214;&#19979;&#36798;&#21040;&#21487;&#25509;&#21463;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#20174;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#36817;&#20284;&#26679;&#26412;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#31181;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#22810;&#39033;&#24335;&#30028;&#38480;&#65292;&#20551;&#35774;$L^2$&#20934;&#30830;&#30340;&#24471;&#20998;&#20272;&#35745;&#22120;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#24050;&#30693;&#30340;&#26368;&#20339;&#30028;&#38480;&#35201;&#20040;&#23545;&#25968;&#25454;&#32500;&#24230;&#26159;&#36229;&#32447;&#24615;&#30340;&#65292;&#35201;&#20040;&#38656;&#35201;&#24378;&#24179;&#28369;&#24615;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#20551;&#35774;&#21482;&#38656;&#35201;&#25968;&#25454;&#20998;&#24067;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#25910;&#25947;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#23545;&#20110;&#25968;&#25454;&#32500;&#24230;&#26159;&#32447;&#24615;&#30340;&#65288;&#20056;&#20197;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25193;&#25955;&#27169;&#22411;&#26368;&#22810;&#38656;&#35201;$\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$&#27493;&#65292;&#23601;&#21487;&#20197;&#23558;&#24102;&#26377;&#26041;&#24046;&#20026;$\delta$&#30340;&#39640;&#26031;&#22122;&#22768;&#25439;&#22351;&#30340;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#22312;Kullback--Leibler&#25955;&#24230;&#19979;&#36817;&#20284;&#21040;$\varepsilon^2$&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#21069;&#20154;&#30340;Girsanov&#26041;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#20110;&#21453;&#21521;SD&#31163;&#25955;&#21270;&#35823;&#24046;&#30340;&#31934;&#32454;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a powerful method for generating approximate samples from high-dimensional data distributions. Several recent results have provided polynomial bounds on the convergence rate of such models, assuming $L^2$-accurate score estimators. However, up until now the best known such bounds were either superlinear in the data dimension or required strong smoothness assumptions. We provide the first convergence bounds which are linear in the data dimension (up to logarithmic factors) assuming only finite second moments of the data distribution. We show that diffusion models require at most $\tilde O(\frac{d \log^2(1/\delta)}{\varepsilon^2})$ steps to approximate an arbitrary data distribution on $\mathbb{R}^d$ corrupted with Gaussian noise of variance $\delta$ to within $\varepsilon^2$ in Kullback--Leibler divergence. Our proof builds on the Girsanov-based methods of previous works. We introduce a refined treatment of the error arising from the discretization of the reverse SD
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.03669</link><description>&lt;p&gt;
&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#19979;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;&#22312;Pearl&#30340;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#25429;&#25417;&#22240;&#26524;&#24178;&#39044;&#30340;&#26694;&#26550;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411;&#65288;DCM&#65289;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#65292;&#20551;&#35774;&#25152;&#26377;&#28151;&#28102;&#22240;&#32032;&#37117;&#26159;&#21487;&#20197;&#35266;&#23519;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#20013;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#65292;&#36825;&#20351;&#24471;DCM&#26080;&#27861;&#24212;&#29992;&#12290;&#20026;&#20102;&#32531;&#35299;DCM&#30340;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#27169;&#22411;&#65292;&#31216;&#20026;&#22522;&#20110;&#21453;&#38376;&#20934;&#21017;&#30340;DCM&#65288;BDCM&#65289;&#65292;&#20854;&#24605;&#24819;&#26681;&#26893;&#20110;&#22312;DAG&#20013;&#25214;&#21040;&#35201;&#21253;&#25324;&#22312;&#25193;&#25955;&#27169;&#22411;&#35299;&#30721;&#36807;&#31243;&#20013;&#30340;&#21464;&#37327;&#30340;&#21453;&#38376;&#20934;&#21017;&#65292;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#23558;DCM&#25193;&#23637;&#21040;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#12290;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#31934;&#30830;&#22320;&#25429;&#25417;&#21040;&#20102;&#21453;&#20107;&#23454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.03666</link><description>&lt;p&gt;
&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#30340;&#26725;&#26753;&#65306;&#19968;&#31181;&#25506;&#32034;&#24615;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03666
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30740;&#31350;&#20154;&#21592;&#21162;&#21147;&#32553;&#23567;&#26426;&#22120;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#36890;&#36807;&#21457;&#23637;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25105;&#20204;&#24517;&#39035;&#35748;&#35782;&#21040;&#21487;&#20449;&#24230;&#22312;&#24320;&#25918;&#19990;&#30028;&#20013;&#30340;&#20851;&#38190;&#37325;&#35201;&#24615;&#65292;&#22312;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#23545;&#27599;&#20010;&#20154;&#37117;&#24050;&#32463;&#26080;&#22788;&#19981;&#22312;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#20960;&#20010;&#25361;&#25112;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#20449;&#20219;&#21361;&#26426;&#65306;1&#65289;&#23545;&#39044;&#27979;&#32467;&#26524;&#30340;&#35299;&#37322;&#19981;&#36275;&#65307;2&#65289;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#19981;&#36275;&#65307;3&#65289;&#23545;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#36866;&#24212;&#33021;&#21147;&#24046;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#31243;&#24207;&#65292;&#29992;&#20110;&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#20174;&#21333;&#27169;&#24577;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#22330;&#26223;&#65292;&#20197;&#20379;&#35835;&#32773;&#20351;&#29992;&#12290;1&#65289;&#20026;&#20102;&#22686;&#24378;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#21046;&#20102;&#20855;&#26377;&#29305;&#23450;&#29289;&#29702;&#21547;&#20041;&#30340;&#21487;&#20449;&#32593;&#32476;&#65307;2&#65289;&#28982;&#21518;&#65292;&#36890;&#36807;&#28789;&#27963;&#30340;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#35774;&#35745;&#29615;&#22659;&#31119;&#31049;&#20219;&#21153;&#25509;&#21475;&#65292;&#20197;&#25913;&#21892;&#21487;&#20449;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As researchers strive to narrow the gap between machine intelligence and human through the development of artificial intelligence technologies, it is imperative that we recognize the critical importance of trustworthiness in open-world, which has become ubiquitous in all aspects of daily life for everyone. However, several challenges may create a crisis of trust in current artificial intelligence systems that need to be bridged: 1) Insufficient explanation of predictive results; 2) Inadequate generalization for learning models; 3) Poor adaptability to uncertain environments. Consequently, we explore a neural program to bridge trustworthiness and open-world learning, extending from single-modal to multi-modal scenarios for readers. 1) To enhance design-level interpretability, we first customize trustworthy networks with specific physical meanings; 2) We then design environmental well-being task-interfaces via flexible learning regularizers for improving the generalization of trustworthy
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#30340;&#26089;&#20572;&#27490;&#26041;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#30446;&#26631;&#20540;&#26469;&#20915;&#23450;&#26159;&#21542;&#20572;&#27490;&#35780;&#20272;&#65292;&#32780;&#26080;&#38656;&#38382;&#39064;&#29305;&#23450;&#30340;&#30693;&#35782;&#12290;&#22312;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#28216;&#25103;&#12289;&#26426;&#22120;&#20154;&#21644;&#32463;&#20856;&#25511;&#21046;&#39046;&#22495;&#20013;&#34920;&#29616;&#20986;&#33410;&#30465;&#35745;&#31639;&#26102;&#38388;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2308.03574</link><description>&lt;p&gt;
&#28436;&#21270;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#20013;&#30340;&#24191;&#20041;&#26089;&#20572;&#27490;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Early Stopping in Evolutionary Direct Policy Search. (arXiv:2308.03574v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#30340;&#26089;&#20572;&#27490;&#26041;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#30446;&#26631;&#20540;&#26469;&#20915;&#23450;&#26159;&#21542;&#20572;&#27490;&#35780;&#20272;&#65292;&#32780;&#26080;&#38656;&#38382;&#39064;&#29305;&#23450;&#30340;&#30693;&#35782;&#12290;&#22312;&#27979;&#35797;&#20013;&#65292;&#35813;&#26041;&#27861;&#22312;&#28216;&#25103;&#12289;&#26426;&#22120;&#20154;&#21644;&#32463;&#20856;&#25511;&#21046;&#39046;&#22495;&#20013;&#34920;&#29616;&#20986;&#33410;&#30465;&#35745;&#31639;&#26102;&#38388;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#23588;&#20854;&#26159;&#28041;&#21450;&#22312;&#29289;&#29702;&#19990;&#30028;&#20013;&#36827;&#34892;&#35780;&#20272;&#30340;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#20219;&#21153;&#20013;&#65292;&#35780;&#20272;&#26102;&#38388;&#36890;&#24120;&#36739;&#38271;&#12290;&#24403;&#22312;&#22266;&#23450;&#26102;&#38388;&#27573;&#20869;&#35780;&#20272;&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;&#24448;&#24448;&#20250;&#26126;&#30830;&#26080;&#27861;&#36890;&#36807;&#22686;&#21152;&#35745;&#31639;&#26102;&#38388;&#26469;&#25552;&#39640;&#30446;&#26631;&#20540;&#65288;&#20363;&#22914;&#65292;&#24403;&#20004;&#36718;&#26426;&#22120;&#20154;&#25345;&#32493;&#22312;&#21407;&#22320;&#26059;&#36716;&#26102;&#65289;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21450;&#26089;&#20572;&#27490;&#35780;&#20272;&#20197;&#33410;&#30465;&#35745;&#31639;&#26102;&#38388;&#26159;&#26377;&#24847;&#20041;&#30340;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#35780;&#20272;&#20572;&#27490;&#26041;&#27861;&#37117;&#26159;&#38382;&#39064;&#29305;&#23450;&#30340;&#65292;&#24182;&#19988;&#38656;&#35201;&#19987;&#38376;&#20026;&#24403;&#21069;&#20219;&#21153;&#35774;&#35745;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#30340;&#26089;&#20572;&#27490;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21482;&#26597;&#30475;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#30340;&#30446;&#26631;&#20540;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#38382;&#39064;&#29305;&#23450;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#26469;&#33258;&#28216;&#25103;&#12289;&#26426;&#22120;&#20154;&#21644;&#32463;&#20856;&#25511;&#21046;&#39046;&#22495;&#30340;&#30452;&#25509;&#31574;&#30053;&#25628;&#32034;&#29615;&#22659;&#20013;&#27979;&#35797;&#20102;&#24341;&#20837;&#30340;&#20572;&#27490;&#20934;&#21017;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#33410;&#30465;&#20102;&#35745;&#31639;&#26102;&#38388;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lengthy evaluation times are common in many optimization problems such as direct policy search tasks, especially when they involve conducting evaluations in the physical world, e.g. in robotics applications. Often, when evaluating a solution over a fixed time period, it becomes clear that the objective value will not increase with additional computation time (for example, when a two-wheeled robot continuously spins on the spot). In such cases, it makes sense to stop the evaluation early to save computation time. However, most approaches to stop the evaluation are problem-specific and need to be specifically designed for the task at hand. Therefore, we propose an early stopping method for direct policy search. The proposed method only looks at the objective value at each time step and requires no problem-specific knowledge.  We test the introduced stopping criterion in five direct policy search environments drawn from games, robotics, and classic control domains, and show that it can sa
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#32771;&#34385;&#20102;&#26679;&#26412;&#25968;&#25454;&#20013;&#30340;&#35823;&#24046;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#37096;&#20998;&#26631;&#35782;&#26041;&#27861;&#32473;&#20986;&#20102;MMD&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#26102;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#65292;&#24182;&#22312;&#23454;&#35777;&#39564;&#35777;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2308.03570</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#20013;&#30340;&#37096;&#20998;&#26631;&#35782;&#21644;&#27979;&#37327;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Partial identification of kernel based two sample tests with mismeasured data. (arXiv:2308.03570v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03570
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#32771;&#34385;&#20102;&#26679;&#26412;&#25968;&#25454;&#20013;&#30340;&#35823;&#24046;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#37096;&#20998;&#26631;&#35782;&#26041;&#27861;&#32473;&#20986;&#20102;MMD&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#26102;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#65292;&#24182;&#22312;&#23454;&#35777;&#39564;&#35777;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#20363;&#22914;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;(MMD)&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#32463;&#24120;&#29992;&#20110;&#26816;&#27979;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#25991;&#29486;&#20551;&#35774;&#20004;&#20010;&#24863;&#20852;&#36259;&#20998;&#24067;&#30340;&#26080;&#35823;&#24046;&#26679;&#26412;&#26159;&#21487;&#29992;&#30340;&#12290;&#25105;&#20204;&#25918;&#26494;&#36825;&#19968;&#20551;&#35774;&#65292;&#30740;&#31350;&#22312;&#949;-&#27745;&#26579;&#19979;&#20272;&#35745;MMD&#65292;&#20854;&#20013;&#21487;&#33021;&#38750;&#38543;&#26426;&#30340;&#949;&#27604;&#20363;&#19968;&#20010;&#20998;&#24067;&#38169;&#35823;&#22320;&#19982;&#21478;&#19968;&#20010;&#20998;&#24067;&#28151;&#26434;&#22312;&#19968;&#36215;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#949;-&#27745;&#26579;&#19979;&#65292;MMD&#30340;&#20856;&#22411;&#20272;&#35745;&#19981;&#21487;&#38752;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;MMD&#30340;&#37096;&#20998;&#26631;&#35782;&#65292;&#24182;&#30830;&#23450;&#20102;&#21253;&#21547;&#30495;&#23454;&#12289;&#26410;&#30693;MMD&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36825;&#20123;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#65292;&#23427;&#32473;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#27604;&#26367;&#20195;&#26041;&#27861;&#26356;&#24555;&#30340;&#23545;MMD&#30340;&#26368;&#23574;&#38160;&#30028;&#38480;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#19977;&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#39564;&#35777;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#36825;&#19968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonparametric two-sample tests such as the Maximum Mean Discrepancy (MMD) are often used to detect differences between two distributions in machine learning applications. However, the majority of existing literature assumes that error-free samples from the two distributions of interest are available.We relax this assumption and study the estimation of the MMD under $\epsilon$-contamination, where a possibly non-random $\epsilon$ proportion of one distribution is erroneously grouped with the other. We show that under $\epsilon$-contamination, the typical estimate of the MMD is unreliable. Instead, we study partial identification of the MMD, and characterize sharp upper and lower bounds that contain the true, unknown MMD. We propose a method to estimate these bounds, and show that it gives estimates that converge to the sharpest possible bounds on the MMD as sample size increases, with a convergence rate that is faster than alternative approaches. Using three datasets, we empirically val
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65288;MDR&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;MDR&#33021;&#22815;&#22312;&#20943;&#23567;&#26041;&#24046;&#30340;&#21516;&#26102;&#20445;&#25345;&#26080;&#20559;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03443</link><description>&lt;p&gt;
&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#65288;MDR&#65289;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#30456;&#27604;&#65292;MDR&#33021;&#22815;&#22312;&#20943;&#23567;&#26041;&#24046;&#30340;&#21516;&#26102;&#20445;&#25345;&#26080;&#20559;&#24615;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#22823;&#21160;&#20316;&#31354;&#38388;&#30340;&#32972;&#26223;&#19979;&#30340;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#12290;&#29616;&#26377;&#30340;&#22522;&#20934;&#20272;&#35745;&#22120;&#23384;&#22312;&#20005;&#37325;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#25240;&#34935;&#38382;&#39064;&#12290;&#21442;&#25968;&#21270;&#26041;&#27861;&#30001;&#20110;&#24456;&#38590;&#30830;&#23450;&#27491;&#30830;&#30340;&#27169;&#22411;&#32780;&#23548;&#33268;&#20559;&#24046;&#65292;&#32780;&#37325;&#35201;&#24615;&#21152;&#26435;&#26041;&#27861;&#30001;&#20110;&#26041;&#24046;&#32780;&#20135;&#29983;&#38382;&#39064;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#21028;&#21035;&#24335;&#30340;&#19981;&#33391;&#34892;&#20026;&#25233;&#21046;&#22120;&#65288;MIPS&#65289;&#26469;&#36890;&#36807;&#23545;&#21160;&#20316;&#30340;&#23884;&#20837;&#26469;&#20943;&#23567;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#12290;&#20026;&#20102;&#20351;&#20272;&#35745;&#22120;&#26356;&#20934;&#30830;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MIPS&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#8212;&#8212;&#36793;&#38469;&#21270;&#21452;&#37325;&#31283;&#20581;&#65288;MDR&#65289;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#22312;&#27604;MIPS&#26356;&#24369;&#30340;&#20551;&#35774;&#19979;&#26159;&#26080;&#20559;&#30340;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#23545;IPS&#30340;&#26041;&#24046;&#20943;&#23567;&#65292;&#36825;&#26159;MIPS&#30340;&#20027;&#35201;&#20248;&#21183;&#12290;&#32463;&#39564;&#23454;&#39564;&#35777;&#23454;&#20102;MDR&#30456;&#23545;&#20110;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces. The benchmark estimators suffer from severe bias and variance tradeoffs. Parametric approaches suffer from bias due to difficulty specifying the correct model, whereas ones with importance weight suffer from variance. To overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was proposed to mitigate the estimator's variance via embeddings of an action. To make the estimator more accurate, we propose the doubly robust estimator of MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the proposed estimator is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS, which was the main advantage of MIPS. The empirical experiment verifies the supremacy of MDR against existing estimators.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#26862;&#26519;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#27599;&#20010;&#36755;&#20837;&#23545;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#30340;&#24433;&#21709;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#38543;&#26426;&#26862;&#26519;&#30340;&#40657;&#21283;&#23376;&#24615;&#36136;&#24102;&#26469;&#30340;&#23454;&#38469;&#38480;&#21046;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27809;&#26377;&#28151;&#26434;&#21464;&#37327;&#21644;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2308.03369</link><description>&lt;p&gt;
&#21464;&#37327;&#37325;&#35201;&#24615;&#23545;&#22240;&#26524;&#26862;&#26519;&#30340;&#24433;&#21709;&#65306;&#35299;&#26512;&#22788;&#29702;&#25928;&#26524;&#30340;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Variable importance for causal forests: breaking down the heterogeneity of treatment effects. (arXiv:2308.03369v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03369
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#26862;&#26519;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#27599;&#20010;&#36755;&#20837;&#23545;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#30340;&#24433;&#21709;&#65292;&#35299;&#20915;&#20102;&#22240;&#26524;&#38543;&#26426;&#26862;&#26519;&#30340;&#40657;&#21283;&#23376;&#24615;&#36136;&#24102;&#26469;&#30340;&#23454;&#38469;&#38480;&#21046;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#27809;&#26377;&#28151;&#26434;&#21464;&#37327;&#21644;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#38543;&#26426;&#26862;&#26519;&#25552;&#20379;&#20102;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#30340;&#26377;&#25928;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#26862;&#26519;&#31639;&#27861;&#20197;&#20854;&#40657;&#21283;&#23376;&#24615;&#36136;&#32780;&#38395;&#21517;&#65292;&#22240;&#27492;&#26080;&#27861;&#34920;&#24449;&#36755;&#20837;&#21464;&#37327;&#22312;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#20013;&#30340;&#21442;&#19982;&#24773;&#20917;&#65292;&#36825;&#26159;&#19968;&#20010;&#24456;&#22823;&#30340;&#23454;&#38469;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#26862;&#26519;&#21464;&#37327;&#37325;&#35201;&#24615;&#31639;&#27861;&#65292;&#29992;&#20110;&#37327;&#21270;&#27599;&#20010;&#36755;&#20837;&#23545;&#22788;&#29702;&#25928;&#26524;&#24322;&#36136;&#24615;&#30340;&#24433;&#21709;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21463;&#21040;&#20102;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#30340;&#20002;&#24323;&#21644;&#37325;&#26032;&#23398;&#20064;&#21407;&#21017;&#30340;&#21551;&#21457;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22788;&#29702;&#27809;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#26862;&#26519;&#37325;&#35757;&#32451;&#12290;&#22914;&#26524;&#28151;&#26434;&#22240;&#32032;&#19981;&#28041;&#21450;&#22788;&#29702;&#25928;&#26524;&#30340;&#24322;&#36136;&#24615;&#65292;&#23616;&#37096;&#23621;&#20013;&#27493;&#39588;&#21487;&#20197;&#20445;&#35777;&#37325;&#35201;&#24615;&#24230;&#37327;&#30340;&#19968;&#33268;&#24615;&#12290;&#21542;&#21017;&#65292;&#24403;&#28151;&#26434;&#22240;&#32032;&#20063;&#24433;&#21709;&#24322;&#36136;&#24615;&#26102;&#65292;&#25105;&#20204;&#22312;&#37325;&#26032;&#35757;&#32451;&#30340;&#22240;&#26524;&#26862;&#26519;&#20013;&#24341;&#20837;&#19968;&#20010;&#26657;&#27491;&#39033;&#20197;&#24674;&#22797;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#23545;&#27169;&#25311;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal random forests provide efficient estimates of heterogeneous treatment effects. However, forest algorithms are also well-known for their black-box nature, and therefore, do not characterize how input variables are involved in treatment effect heterogeneity, which is a strong practical limitation. In this article, we develop a new importance variable algorithm for causal forests, to quantify the impact of each input on the heterogeneity of treatment effects. The proposed approach is inspired from the drop and relearn principle, widely used for regression problems. Importantly, we show how to handle the forest retrain without a confounding variable. If the confounder is not involved in the treatment effect heterogeneity, the local centering step enforces consistency of the importance measure. Otherwise, when a confounder also impacts heterogeneity, we introduce a corrective term in the retrained causal forest to recover consistency. Additionally, experiments on simulated, semi-synt
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#29305;&#24449;&#20540;&#20462;&#27491;&#30340;Kronecker-Factored Approximate Curvature (EK-FAC) &#36817;&#20284;&#26041;&#27861;&#65292;&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#24433;&#21709;&#20989;&#25968;&#26469;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;EK-FAC&#33021;&#22815;&#22312;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#19982;&#20256;&#32479;&#24433;&#21709;&#20989;&#25968;&#20272;&#35745;&#22120;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.03296</link><description>&lt;p&gt;
&#20351;&#29992;&#24433;&#21709;&#20989;&#25968;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Studying Large Language Model Generalization with Influence Functions. (arXiv:2308.03296v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03296
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#29305;&#24449;&#20540;&#20462;&#27491;&#30340;Kronecker-Factored Approximate Curvature (EK-FAC) &#36817;&#20284;&#26041;&#27861;&#65292;&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#24433;&#21709;&#20989;&#25968;&#26469;&#30740;&#31350;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;EK-FAC&#33021;&#22815;&#22312;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#19982;&#20256;&#32479;&#24433;&#21709;&#20989;&#25968;&#20272;&#35745;&#22120;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21162;&#21147;&#25552;&#39640;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35265;&#24615;&#20197;&#29702;&#35299;&#21644;&#20943;&#36731;&#30456;&#20851;&#39118;&#38505;&#26102;&#65292;&#19968;&#20010;&#28508;&#22312;&#26377;&#20215;&#20540;&#30340;&#35777;&#25454;&#26469;&#28304;&#26159;&#65306;&#21738;&#20123;&#35757;&#32451;&#26679;&#26412;&#26368;&#22823;&#31243;&#24230;&#22320;&#24433;&#21709;&#20102;&#32473;&#23450;&#30340;&#34892;&#20026;&#65311;&#24433;&#21709;&#20989;&#25968;&#26088;&#22312;&#22238;&#31572;&#19968;&#20010;&#21453;&#20107;&#23454;&#38382;&#39064;&#65306;&#22914;&#26524;&#23558;&#32473;&#23450;&#30340;&#24207;&#21015;&#28155;&#21152;&#21040;&#35757;&#32451;&#38598;&#20013;&#65292;&#27169;&#22411;&#30340;&#21442;&#25968;&#65288;&#22240;&#27492;&#20063;&#26159;&#27169;&#22411;&#30340;&#36755;&#20986;&#65289;&#23558;&#22914;&#20309;&#25913;&#21464;&#65311;&#23613;&#31649;&#24433;&#21709;&#20989;&#25968;&#23545;&#23567;&#22411;&#27169;&#22411;&#20135;&#29983;&#20102;&#27934;&#35265;&#65292;&#20294;&#30001;&#20110;&#35745;&#31639;&#36870;Hessian-&#21521;&#37327;&#20056;&#31215;&#65288;IHVP&#65289;&#30340;&#22256;&#38590;&#65292;&#23427;&#20204;&#24456;&#38590;&#25193;&#23637;&#21040;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;&#29305;&#24449;&#20540;&#20462;&#27491;&#30340;Kronecker-Factored Approximate Curvature&#65288;EK-FAC&#65289;&#36817;&#20284;&#26041;&#27861;&#65292;&#23558;&#24433;&#21709;&#20989;&#25968;&#25193;&#23637;&#21040;&#20855;&#26377;520&#20159;&#21442;&#25968;&#30340;LLMs&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;EK-FAC&#22312;IHVP&#35745;&#31639;&#36895;&#24230;&#24555;&#20102;&#25968;&#20010;&#25968;&#37327;&#32423;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#19982;&#20256;&#32479;&#24433;&#21709;&#20989;&#25968;&#20272;&#35745;&#22120;&#30456;&#20284;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#31639;&#27861;&#25216;&#26415;&#26469;&#20943;&#23569;&#25104;&#26412;
&lt;/p&gt;
&lt;p&gt;
When trying to gain better visibility into a machine learning model in order to understand and mitigate the associated risks, a potentially valuable source of evidence is: which training examples most contribute to a given behavior? Influence functions aim to answer a counterfactual: how would the model's parameters (and hence its outputs) change if a given sequence were added to the training set? While influence functions have produced insights for small models, they are difficult to scale to large language models (LLMs) due to the difficulty of computing an inverse-Hessian-vector product (IHVP). We use the Eigenvalue-corrected Kronecker-Factored Approximate Curvature (EK-FAC) approximation to scale influence functions up to LLMs with up to 52 billion parameters. In our experiments, EK-FAC achieves similar accuracy to traditional influence function estimators despite the IHVP computation being orders of magnitude faster. We investigate two algorithmic techniques to reduce the cost of 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#22312;&#38750;&#20984;&#38382;&#39064;&#20013;&#65292;SGD&#20351;&#29992;&#19981;&#21516;&#30340;&#25209;&#37327;&#22823;&#23567;&#33021;&#25214;&#21040;&#19981;&#21516;&#31867;&#22411;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#25209;&#37327;&#22823;&#23567;&#36739;&#22823;&#26102;&#35299;&#20915;&#26041;&#26696;&#36739;&#23494;&#38598;&#19988;&#19982;&#21021;&#22987;&#21270;&#26041;&#21521;&#39640;&#24230;&#19968;&#33268;&#65292;&#25209;&#37327;&#22823;&#23567;&#36739;&#23567;&#26102;&#35299;&#20915;&#26041;&#26696;&#36739;&#31232;&#30095;&#19988;&#20960;&#20046;&#19982;&#21021;&#22987;&#21270;&#27491;&#20132;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#25214;&#21040;&#30340;&#26368;&#23567;&#20540;&#36739;&#38160;&#21033;&#12290;</title><link>http://arxiv.org/abs/2308.03215</link><description>&lt;p&gt;
SGD&#25209;&#37327;&#22823;&#23567;&#23545;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#30340;&#24433;&#21709;&#65306;&#31232;&#30095;&#24615;&#12289;&#38160;&#24230;&#21644;&#29305;&#24449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
The Effect of SGD Batch Size on Autoencoder Learning: Sparsity, Sharpness, and Feature Learning. (arXiv:2308.03215v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03215
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#22312;&#38750;&#20984;&#38382;&#39064;&#20013;&#65292;SGD&#20351;&#29992;&#19981;&#21516;&#30340;&#25209;&#37327;&#22823;&#23567;&#33021;&#25214;&#21040;&#19981;&#21516;&#31867;&#22411;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#25209;&#37327;&#22823;&#23567;&#36739;&#22823;&#26102;&#35299;&#20915;&#26041;&#26696;&#36739;&#23494;&#38598;&#19988;&#19982;&#21021;&#22987;&#21270;&#26041;&#21521;&#39640;&#24230;&#19968;&#33268;&#65292;&#25209;&#37327;&#22823;&#23567;&#36739;&#23567;&#26102;&#35299;&#20915;&#26041;&#26696;&#36739;&#31232;&#30095;&#19988;&#20960;&#20046;&#19982;&#21021;&#22987;&#21270;&#27491;&#20132;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#25214;&#21040;&#30340;&#26368;&#23567;&#20540;&#36739;&#38160;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#35757;&#32451;&#20855;&#26377;&#32447;&#24615;&#25110;ReLU&#28608;&#27963;&#30340;&#21333;&#31070;&#32463;&#20803;&#33258;&#32534;&#30721;&#22120;&#26102;&#30340;&#21160;&#24577;&#29305;&#24615;&#65292;&#20351;&#29992;&#27491;&#20132;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#36825;&#20010;&#38750;&#20984;&#38382;&#39064;&#20013;&#65292;&#23545;&#20110;&#20219;&#20309;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#38543;&#26426;&#21021;&#22987;&#21270;&#30340;SGD&#20351;&#29992;&#24658;&#23450;&#27493;&#38271;&#33021;&#22815;&#25104;&#21151;&#25214;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#28982;&#32780;&#65292;&#25214;&#21040;&#30340;&#29305;&#23450;&#20840;&#23616;&#26368;&#23567;&#20540;&#21462;&#20915;&#20110;&#25209;&#37327;&#22823;&#23567;&#12290;&#22312;&#20840;&#25209;&#37327;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;&#35299;&#20915;&#26041;&#26696;&#26159;&#23494;&#38598;&#30340;&#65288;&#21363;&#38750;&#31232;&#30095;&#30340;&#65289;&#65292;&#24182;&#19988;&#19982;&#20854;&#21021;&#22987;&#21270;&#26041;&#21521;&#39640;&#24230;&#19968;&#33268;&#65292;&#34920;&#26126;&#30456;&#23545;&#36739;&#23569;&#30340;&#29305;&#24449;&#23398;&#20064;&#21457;&#29983;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#23545;&#20110;&#20219;&#20309;&#23567;&#20110;&#26679;&#26412;&#25968;&#30340;&#25209;&#37327;&#22823;&#23567;&#65292;SGD&#33021;&#22815;&#25214;&#21040;&#19968;&#20010;&#31232;&#30095;&#19988;&#20960;&#20046;&#19982;&#21021;&#22987;&#21270;&#27491;&#20132;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#36825;&#34920;&#26126;&#38543;&#26426;&#26799;&#24230;&#30340;&#38543;&#26426;&#24615;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#24341;&#21457;&#20102;&#19968;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#8220;&#29305;&#24449;&#36873;&#25321;&#8221;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#36890;&#36807;&#28023;&#26862;&#30697;&#38453;&#30340;&#36857;&#26469;&#34913;&#37327;&#26368;&#23567;&#20540;&#30340;&#38160;&#24230;&#65292;&#37027;&#20040;&#20351;&#29992;&#26356;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#25214;&#21040;&#30340;&#26368;&#23567;&#20540;&#36739;&#38160;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate the dynamics of stochastic gradient descent (SGD) when training a single-neuron autoencoder with linear or ReLU activation on orthogonal data. We show that for this non-convex problem, randomly initialized SGD with a constant step size successfully finds a global minimum for any batch size choice. However, the particular global minimum found depends upon the batch size. In the full-batch setting, we show that the solution is dense (i.e., not sparse) and is highly aligned with its initialized direction, showing that relatively little feature learning occurs. On the other hand, for any batch size strictly smaller than the number of samples, SGD finds a global minimum which is sparse and nearly orthogonal to its initialization, showing that the randomness of stochastic gradients induces a qualitatively different type of "feature selection" in this setting. Moreover, if we measure the sharpness of the minimum by the trace of the Hessian, the minima found with f
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38598;&#25104;&#25216;&#26415;&#26816;&#27979;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#24322;&#24120;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#29305;&#24449;&#35013;&#34955;&#25216;&#26415;&#21644;&#22522;&#20110;PCA&#30340;&#23884;&#22871;&#26059;&#36716;&#36716;&#25442;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22522;&#26412;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.03171</link><description>&lt;p&gt;
&#20351;&#29992;&#38598;&#25104;&#25216;&#26415;&#26816;&#27979;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#24322;&#24120;
&lt;/p&gt;
&lt;p&gt;
Detection of Anomalies in Multivariate Time Series Using Ensemble Techniques. (arXiv:2308.03171v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03171
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#38598;&#25104;&#25216;&#26415;&#26816;&#27979;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#24322;&#24120;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#29305;&#24449;&#35013;&#34955;&#25216;&#26415;&#21644;&#22522;&#20110;PCA&#30340;&#23884;&#22871;&#26059;&#36716;&#36716;&#25442;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#22522;&#26412;&#27169;&#22411;&#30340;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#65292;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#30001;&#20110;&#24322;&#24120;&#22312;&#30495;&#23454;&#25968;&#25454;&#20013;&#30340;&#31232;&#30095;&#24615;&#65292;&#20351;&#24471;&#20998;&#31867;&#31639;&#27861;&#22312;&#35299;&#20915;&#24322;&#24120;&#26816;&#27979;&#38382;&#39064;&#26102;&#38754;&#20020;&#25361;&#25112;&#12290;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;&#22914;LSTM&#12289;&#33258;&#32534;&#30721;&#22120;&#12289;&#21367;&#31215;&#33258;&#32534;&#30721;&#22120;&#31561;&#65289;&#30340;&#26041;&#27861;&#22312;&#36825;&#31181;&#19981;&#24179;&#34913;&#25968;&#25454;&#20013;&#21462;&#24471;&#20102;&#31215;&#26497;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#24403;&#24212;&#29992;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#26102;&#65292;&#31639;&#27861;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#24322;&#24120;&#21487;&#33021;&#26469;&#33258;&#29305;&#24449;&#38598;&#30340;&#19968;&#20010;&#23567;&#23376;&#38598;&#12290;&#20026;&#20102;&#25552;&#39640;&#36825;&#20123;&#22522;&#26412;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29305;&#24449;&#35013;&#34955;&#25216;&#26415;&#65292;&#27599;&#27425;&#21482;&#32771;&#34385;&#29305;&#24449;&#30340;&#19968;&#20010;&#23376;&#38598;&#65292;&#24182;&#19988;&#25105;&#20204;&#36827;&#19968;&#27493;&#24212;&#29992;&#20102;&#22522;&#20110;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#35745;&#31639;&#30340;&#23884;&#22871;&#26059;&#36716;&#30340;&#36716;&#25442;&#26469;&#25913;&#21892;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38598;&#25104;&#25216;&#26415;&#65292;&#23558;&#22810;&#20010;&#22522;&#26412;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly Detection in multivariate time series is a major problem in many fields. Due to their nature, anomalies sparsely occur in real data, thus making the task of anomaly detection a challenging problem for classification algorithms to solve. Methods that are based on Deep Neural Networks such as LSTM, Autoencoders, Convolutional Autoencoders etc., have shown positive results in such imbalanced data. However, the major challenge that algorithms face when applied to multivariate time series is that the anomaly can arise from a small subset of the feature set. To boost the performance of these base models, we propose a feature-bagging technique that considers only a subset of features at a time, and we further apply a transformation that is based on nested rotation computed from Principal Component Analysis (PCA) to improve the effectiveness and generalization of the approach. To further enhance the prediction performance, we propose an ensemble technique that combines multiple base mo
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#39318;&#27425;&#22312;&#33258;&#20027;&#32447;&#24615;&#20998;&#31867;&#20219;&#21153;&#20013;&#30740;&#31350;&#20102;&#36873;&#25321;&#39044;&#27979;&#39034;&#24207;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#65292;&#38024;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#65292;&#35774;&#35745;&#20102;&#39640;&#25928;&#30340;&#33258;&#20027;&#23398;&#20064;&#22120;&#65292;&#26368;&#23569;&#21482;&#20135;&#29983;$O(d \log \log(n))$&#20010;&#38169;&#35823;&#12290;</title><link>http://arxiv.org/abs/2308.03142</link><description>&lt;p&gt;
&#33258;&#20027;&#32447;&#24615;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Self-Directed Linear Classification. (arXiv:2308.03142v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03142
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#39318;&#27425;&#22312;&#33258;&#20027;&#32447;&#24615;&#20998;&#31867;&#20219;&#21153;&#20013;&#30740;&#31350;&#20102;&#36873;&#25321;&#39044;&#27979;&#39034;&#24207;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#65292;&#38024;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#65292;&#35774;&#35745;&#20102;&#39640;&#25928;&#30340;&#33258;&#20027;&#23398;&#20064;&#22120;&#65292;&#26368;&#23569;&#21482;&#20135;&#29983;$O(d \log \log(n))$&#20010;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#20998;&#31867;&#20013;&#65292;&#23398;&#20064;&#22120;&#34987;&#21576;&#29616;&#19968;&#31995;&#21015;&#30340;&#31034;&#20363;&#65292;&#24182;&#26088;&#22312;&#20197;&#22312;&#32447;&#26041;&#24335;&#39044;&#27979;&#20854;&#26631;&#31614;&#65292;&#20197;&#26368;&#23567;&#21270;&#38169;&#35823;&#30340;&#24635;&#25968;&#12290;&#22312;&#33258;&#20027;&#21464;&#20307;&#20013;&#65292;&#23398;&#20064;&#22120;&#20107;&#20808;&#20102;&#35299;&#31034;&#20363;&#27744;&#65292;&#24182;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#36873;&#25321;&#39044;&#27979;&#39034;&#24207;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36873;&#25321;&#39044;&#27979;&#39034;&#24207;&#30340;&#33021;&#21147;&#65292;&#24182;&#20026;&#32447;&#24615;&#20998;&#31867;&#30340;&#22522;&#26412;&#20219;&#21153;&#24314;&#31435;&#20102;&#26368;&#22351;&#39034;&#24207;&#21644;&#38543;&#26426;&#39034;&#24207;&#23398;&#20064;&#20043;&#38388;&#30340;&#31532;&#19968;&#20010;&#24378;&#20998;&#31163;&#12290;&#22312;&#25105;&#20204;&#30340;&#24037;&#20316;&#20043;&#21069;&#65292;&#21482;&#22312;&#38750;&#24120;&#21463;&#38480;&#30340;&#27010;&#24565;&#31867;&#20013;&#25165;&#30693;&#36947;&#36825;&#26679;&#30340;&#20998;&#31163;&#65292;&#20363;&#22914;&#19968;&#32500;&#38376;&#38480;&#25110;&#36724;&#23545;&#40784;&#30697;&#24418;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#20027;&#35201;&#32467;&#26524;&#12290;&#22914;&#26524;$X$&#26159;&#20174;$d$&#32500;&#21333;&#20301;&#29699;&#20013;&#22343;&#21248;&#38543;&#26426;&#25277;&#21462;&#30340;$n$&#20010;&#28857;&#30340;&#25968;&#25454;&#38598;&#65292;&#21017;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#33258;&#20027;&#23398;&#20064;&#22120;&#65292;&#21487;&#20570;&#20986;$O(d \log \log(n))$&#20010;&#38169;&#35823;&#24182;&#20998;&#31867;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;&#22914;&#26524;$X$&#26159;&#19968;&#20010;&#20219;&#24847;&#30340;$d$&#32500;&#25968;&#25454;&#38598;&#65292;&#22823;&#23567;&#20026;$n$&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#33258;&#20027;&#23398;&#20064;&#22120;&#65292;&#20351;&#24471;&#20854;&#22312;&#20998;&#31867;&#25972;&#20010;&#25968;&#25454;&#38598;&#26102;&#24635;&#20849;&#20063;&#21482;&#20250;&#20135;&#29983;$O(d \log \log(n))$&#20010;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.  We present two main results. If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner that makes $O(d \log \log(n))$ mistakes and classifies the entire dataset. If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficie
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#24425;&#31080;&#20551;&#35774;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#36845;&#20195;&#24133;&#24230;&#20462;&#21098;&#36880;&#27493;&#20248;&#21270;&#27169;&#22411;&#65292;&#24182;&#25506;&#32034;&#20102;&#20013;&#24425;&#31080;&#30340;&#26222;&#36941;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;IMP&#19982;RG&#29702;&#35770;&#30340;&#32852;&#31995;&#65292;&#20419;&#36827;&#23545;IMP&#30340;&#26356;&#28145;&#20837;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2308.03128</link><description>&lt;p&gt;
&#36845;&#20195;&#24133;&#24230;&#20462;&#21098;&#20316;&#20026;&#37325;&#25972;&#21270;&#32676;&#30340;&#30740;&#31350;&#65306;&#22522;&#20110;&#20013;&#24425;&#31080;&#20551;&#35774;&#30340;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Iterative Magnitude Pruning as a Renormalisation Group: A Study in The Context of The Lottery Ticket Hypothesis. (arXiv:2308.03128v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03128
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#24425;&#31080;&#20551;&#35774;&#30340;&#27010;&#24565;&#65292;&#36890;&#36807;&#36845;&#20195;&#24133;&#24230;&#20462;&#21098;&#36880;&#27493;&#20248;&#21270;&#27169;&#22411;&#65292;&#24182;&#25506;&#32034;&#20102;&#20013;&#24425;&#31080;&#30340;&#26222;&#36941;&#24615;&#12290;&#21516;&#26102;&#65292;&#26412;&#35770;&#25991;&#36824;&#25552;&#20986;&#20102;IMP&#19982;RG&#29702;&#35770;&#30340;&#32852;&#31995;&#65292;&#20419;&#36827;&#23545;IMP&#30340;&#26356;&#28145;&#20837;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#20013;&#20196;&#20154;&#28608;&#21160;&#30340;&#20013;&#24425;&#31080;&#20551;&#35774;&#65288;LTH&#65289;&#30340;&#22797;&#26434;&#19990;&#30028;&#12290;LTH&#35748;&#20026;&#65292;&#22312;&#24222;&#22823;&#30340;DNN&#20013;&#65292;&#36739;&#23567;&#30340;&#21487;&#35757;&#32451;&#23376;&#32593;&#32476;&#65288;&#31216;&#20026;"&#20013;&#24425;&#31080;"&#65289;&#21487;&#20197;&#36798;&#21040;&#19982;&#23436;&#25972;&#27169;&#22411;&#30456;&#23218;&#32654;&#30340;&#24615;&#33021;&#12290;LTH&#30340;&#20851;&#38190;&#36807;&#31243;&#26159;&#36845;&#20195;&#24133;&#24230;&#20462;&#21098;&#65288;IMP&#65289;&#65292;&#23427;&#36880;&#27493;&#28040;&#38500;&#26368;&#23567;&#26435;&#37325;&#65292;&#27169;&#25311;DNN&#20013;&#30340;&#36880;&#27493;&#23398;&#20064;&#12290;&#19968;&#26086;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#20123;&#20013;&#24425;&#31080;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#23427;&#20204;&#30340;"&#26222;&#36941;&#24615;"&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#25105;&#20204;&#26816;&#26597;&#19968;&#31181;&#22312;&#19968;&#20010;&#29305;&#23450;&#38382;&#39064;&#19978;&#34920;&#29616;&#33391;&#22909;&#30340;&#20013;&#24425;&#31080;&#26159;&#21542;&#20063;&#33021;&#22312;&#20854;&#20182;&#31867;&#20284;&#38382;&#39064;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;IMP&#19982;&#29289;&#29702;&#23398;&#20013;&#30340;&#37325;&#25972;&#21270;&#32676;&#65288;RG&#65289;&#29702;&#35770;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#25512;&#21160;&#23545;IMP&#30340;&#26356;&#20005;&#35880;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
This thesis delves into the intricate world of Deep Neural Networks (DNNs), focusing on the exciting concept of the Lottery Ticket Hypothesis (LTH). The LTH posits that within extensive DNNs, smaller, trainable subnetworks termed "winning tickets", can achieve performance comparable to the full model. A key process in LTH, Iterative Magnitude Pruning (IMP), incrementally eliminates minimal weights, emulating stepwise learning in DNNs. Once we identify these winning tickets, we further investigate their "universality". In other words, we check if a winning ticket that works well for one specific problem could also work well for other, similar problems. We also bridge the divide between the IMP and the Renormalisation Group (RG) theory in physics, promoting a more rigorous understanding of IMP.
&lt;/p&gt;</description></item><item><title>&#20986;&#31199;&#36710;&#23545;&#24212;&#20998;&#26512;&#26159;&#19968;&#31181;&#21487;&#35270;&#21270;&#38750;&#24120;&#31232;&#30095;&#30340;&#21015;&#32852;&#34920;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#28041;&#21450;&#25991;&#26412;&#25968;&#25454;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#24212;&#29992;&#65292;&#30740;&#31350;&#20102;Sah&#21644;Fokou\'e&#65288;2019&#65289;&#24341;&#20837;&#30340;8&#26412;&#22307;&#20070;&#29255;&#27573;&#65292;&#24182;&#20351;&#29992;&#22810;&#31181;&#32500;&#24230;&#32422;&#20943;&#26041;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2308.03079</link><description>&lt;p&gt;
&#23545;&#20110;&#38750;&#24120;&#31232;&#30095;&#30340;&#21015;&#32852;&#34920;&#30340;&#20986;&#31199;&#36710;&#23545;&#24212;&#20998;&#26512;&#30340;&#21487;&#35270;&#21270;&#65306;&#19968;&#20010;&#25991;&#26412;&#25968;&#25454;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Visualization of Extremely Sparse Contingency Table by Taxicab Correspondence Analysis: A Case Study of Textual Data. (arXiv:2308.03079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03079
&lt;/p&gt;
&lt;p&gt;
&#20986;&#31199;&#36710;&#23545;&#24212;&#20998;&#26512;&#26159;&#19968;&#31181;&#21487;&#35270;&#21270;&#38750;&#24120;&#31232;&#30095;&#30340;&#21015;&#32852;&#34920;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#28041;&#21450;&#25991;&#26412;&#25968;&#25454;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#24212;&#29992;&#65292;&#30740;&#31350;&#20102;Sah&#21644;Fokou\'e&#65288;2019&#65289;&#24341;&#20837;&#30340;8&#26412;&#22307;&#20070;&#29255;&#27573;&#65292;&#24182;&#20351;&#29992;&#22810;&#31181;&#32500;&#24230;&#32422;&#20943;&#26041;&#27861;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;&#23545;&#24212;&#20998;&#26512;&#21464;&#20307;&#8212;&#8212;&#20986;&#31199;&#36710;&#23545;&#24212;&#20998;&#26512;&#65292;&#29992;&#20110;&#21487;&#35270;&#21270;&#38750;&#24120;&#31232;&#30095;&#30340;&#21015;&#32852;&#34920;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21487;&#35270;&#21270;&#20102;&#19968;&#20010;&#23610;&#23544;&#20026;590 &#215; 8265&#30340;&#38750;&#24120;&#31232;&#30095;&#25991;&#26412;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#28041;&#21450;&#26368;&#36817;&#30001;Sah&#21644;Fokou\'e&#65288;2019&#65289;&#24341;&#20837;&#30340;8&#26412;&#22307;&#20070;&#30340;&#29255;&#27573;&#65292;&#24182;&#30001;Ma&#65292;Sun&#21644;Zou&#65288;2022&#65289;&#20351;&#29992;&#65288;12 + 1&#65289;&#32500;&#24230;&#32422;&#20943;&#26041;&#27861;&#65288;t-SNE, UMAP, PHATE,...&#65289;&#36827;&#34892;&#35814;&#32454;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an overview of taxicab correspondence analysis, a robust variant of correspondence analysis, for visualization of extremely sparse ontingency tables. In particular we visualize an extremely sparse textual data set of size 590 by 8265 concerning fragments of 8 sacred books recently introduced by Sah and Fokou\'e (2019) and studied quite in detail by (12 + 1) dimension reduction methods (t-SNE, UMAP, PHATE,...) by Ma, Sun and Zou (2022).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#36807;&#37319;&#26679;&#31639;&#27861;GOLIATH&#65292;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#19981;&#24179;&#34913;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26174;&#24335;&#24418;&#24335;&#21644;&#26465;&#20214;&#23494;&#24230;&#34920;&#36798;&#24335;&#65292;&#20026;SMOTE&#31561;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#22120;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>http://arxiv.org/abs/2308.02966</link><description>&lt;p&gt;
&#24191;&#20041;&#36807;&#37319;&#26679;&#29992;&#20110;&#20174;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#20197;&#21450;&#30456;&#20851;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory. (arXiv:2308.02966v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02966
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#36807;&#37319;&#26679;&#31639;&#27861;GOLIATH&#65292;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#19981;&#24179;&#34913;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26174;&#24335;&#24418;&#24335;&#21644;&#26465;&#20214;&#23494;&#24230;&#34920;&#36798;&#24335;&#65292;&#20026;SMOTE&#31561;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#22120;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#32463;&#24120;&#20250;&#36935;&#21040;&#30495;&#23454;&#30340;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#12290;&#36825;&#31181;&#24773;&#20917;&#23545;&#20110;&#26631;&#20934;&#31639;&#27861;&#26469;&#35828;&#26159;&#19968;&#20010;&#23398;&#20064;&#38590;&#39064;&#12290;&#19981;&#24179;&#34913;&#23398;&#20064;&#30340;&#30740;&#31350;&#21644;&#35299;&#20915;&#26041;&#26696;&#20027;&#35201;&#38598;&#20013;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#20294;&#20960;&#20046;&#27809;&#26377;&#20851;&#20110;&#19981;&#24179;&#34913;&#22238;&#24402;&#30340;&#35299;&#20915;&#26041;&#26696;&#23384;&#22312;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#25968;&#25454;&#22686;&#24378;&#31243;&#24207;&#65292;&#21363;GOLIATH&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#12290;&#36825;&#31181;&#36890;&#29992;&#26041;&#27861;&#21253;&#25324;&#20004;&#22823;&#31867;&#21512;&#25104;&#36807;&#37319;&#26679;&#26041;&#27861;&#65306;&#22522;&#20110;&#25200;&#21160;&#30340;&#26041;&#27861;&#65292;&#22914;&#39640;&#26031;&#22122;&#22768;&#65292;&#20197;&#21450;&#22522;&#20110;&#25554;&#20540;&#30340;&#26041;&#27861;&#65292;&#22914;SMOTE&#12290;&#23427;&#36824;&#25552;&#20379;&#20102;&#36825;&#20123;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26174;&#24335;&#24418;&#24335;&#21644;&#23427;&#20204;&#30340;&#26465;&#20214;&#23494;&#24230;&#34920;&#36798;&#24335;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;SMOTE&#12290;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#22120;&#34987;&#25512;&#23548;&#20986;&#26469;&#12290;&#25105;&#20204;&#23558;GOLIATH&#24212;&#29992;&#20110;&#19981;&#24179;&#34913;&#22238;&#24402;&#65292;&#23558;&#36825;&#20123;&#29983;&#25104;&#22120;&#36807;&#31243;&#19982;&#19968;&#31181;&#37326;&#29983;&#24341;&#23548;&#37325;&#37319;&#26679;&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In supervised learning, it is quite frequent to be confronted with real imbalanced datasets. This situation leads to a learning difficulty for standard algorithms. Research and solutions in imbalanced learning have mainly focused on classification tasks. Despite its importance, very few solutions exist for imbalanced regression. In this paper, we propose a data augmentation procedure, the GOLIATH algorithm, based on kernel density estimates which can be used in classification and regression. This general approach encompasses two large families of synthetic oversampling: those based on perturbations, such as Gaussian Noise, and those based on interpolations, such as SMOTE. It also provides an explicit form of these machine learning algorithms and an expression of their conditional densities, in particular for SMOTE. New synthetic data generators are deduced. We apply GOLIATH in imbalanced regression combining such generator procedures with a wild-bootstrap resampling technique for the t
&lt;/p&gt;</description></item><item><title>&#32467;&#26500;&#21270;&#20302;&#31209;&#24352;&#37327;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#33021;&#22815;&#26356;&#21487;&#38752;&#22320;&#20272;&#35745;&#21442;&#25968;&#21644;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.02922</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#20302;&#31209;&#24352;&#37327;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Structured Low-Rank Tensors for Generalized Linear Models. (arXiv:2308.02922v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02922
&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#21270;&#20302;&#31209;&#24352;&#37327;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;&#33021;&#22815;&#26356;&#21487;&#38752;&#22320;&#20272;&#35745;&#21442;&#25968;&#21644;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#24378;&#21152;&#24352;&#37327;&#32467;&#26500;&#22312;&#21442;&#25968;&#20272;&#35745;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#26041;&#38754;&#27604;&#22522;&#20110;&#21521;&#37327;&#30340;&#26041;&#27861;&#26356;&#21487;&#38752;&#12290;&#26412;&#30740;&#31350;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#38382;&#39064;&#20013;&#30740;&#31350;&#19968;&#31181;&#26032;&#30340;&#20302;&#31209;&#24352;&#37327;&#27169;&#22411;&#65292;&#31216;&#20026;&#20302;&#20998;&#31163;&#31209;&#65288;LSR&#65289;&#27169;&#22411;&#12290;LSR&#27169;&#22411;&#25512;&#24191;&#20102;&#33879;&#21517;&#30340;Tucker&#21644;CANDECOMP / PARAFAC&#65288;CP&#65289;&#27169;&#22411;&#65292;&#24182;&#19988;&#26159;&#22359;&#24352;&#37327;&#20998;&#35299;&#65288;BTD&#65289;&#27169;&#22411;&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;&#26412;&#30740;&#31350;&#22312;GLM&#27169;&#22411;&#20013;&#23545;&#21442;&#25968;&#24352;&#37327;&#26045;&#21152;LSR&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22359;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#29992;&#20110;LSR&#32467;&#26500;&#24352;&#37327;GLM&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#65292;&#23427;&#25512;&#23548;&#20986;&#20102;&#22312;LSR&#24352;&#37327;GLM&#38382;&#39064;&#20013;&#20272;&#35745;&#31995;&#25968;&#24352;&#37327;&#30340;&#35823;&#24046;&#38408;&#20540;&#30340;&#26497;&#23567;&#21270;&#19979;&#30028;&#12290;&#36825;&#20010;&#26497;&#23567;&#21270;&#19979;&#30028;&#19982;LSR&#24352;&#37327;GLM&#38382;&#39064;&#20013;&#30340;&#22266;&#26377;&#33258;&#30001;&#24230;&#25104;&#27491;&#27604;&#65292;&#34920;&#26126;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#21487;&#33021;&#26126;&#26174;&#20302;&#20110;&#21521;&#37327;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent works have shown that imposing tensor structures on the coefficient tensor in regression problems can lead to more reliable parameter estimation and lower sample complexity compared to vector-based methods. This work investigates a new low-rank tensor model, called Low Separation Rank (LSR), in Generalized Linear Model (GLM) problems. The LSR model -- which generalizes the well-known Tucker and CANDECOMP/PARAFAC (CP) models, and is a special case of the Block Tensor Decomposition (BTD) model -- is imposed onto the coefficient tensor in the GLM model. This work proposes a block coordinate descent algorithm for parameter estimation in LSR-structured tensor GLMs. Most importantly, it derives a minimax lower bound on the error threshold on estimating the coefficient tensor in LSR tensor GLM problems. The minimax bound is proportional to the intrinsic degrees of freedom in the LSR tensor GLM problem, suggesting that its sample complexity may be significantly lower than that of vector
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#22312;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#30340;&#24615;&#33021;&#65292;&#24182;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2308.02918</link><description>&lt;p&gt;
&#22522;&#20110;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#30340;&#20809;&#35889;&#25490;&#21517;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Spectral Ranking Inferences based on General Multiway Comparisons. (arXiv:2308.02918v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#22312;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#30340;&#24615;&#33021;&#65292;&#24182;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#38750;&#24120;&#26222;&#36941;&#21644;&#26356;&#21152;&#30495;&#23454;&#30340;&#24773;&#26223;&#20013;&#65292;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#23545;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#36827;&#34892;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27604;&#36739;&#22270;&#30001;&#21487;&#33021;&#20855;&#26377;&#24322;&#26500;&#22823;&#23567;&#30340;&#36229;&#36793;&#32452;&#25104;&#65292;&#23545;&#20110;&#32473;&#23450;&#30340;&#36229;&#36793;&#65292;&#27604;&#36739;&#25968;&#37327;&#21487;&#33021;&#20165;&#20026;1&#12290;&#36825;&#31181;&#35774;&#32622;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#25351;&#23450;&#22270;&#30340;&#38543;&#26426;&#24615;&#20197;&#21450;&#22312;&#24120;&#29992;&#30340;Bradley-Terry-Luce (BTL)&#25110;Plackett-Luce (PL)&#27169;&#22411;&#20013;&#26045;&#21152;&#30340;&#38480;&#21046;&#24615;&#22343;&#21248;&#37319;&#26679;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#22312;&#36866;&#29992;BTL&#25110;PL&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65288;MLE&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#24212;&#29992;&#20174;&#31561;&#26435;&#37325;&#20256;&#32479;&#20809;&#35889;&#26041;&#27861;&#20272;&#35745;&#24471;&#21040;&#30340;&#26368;&#20339;&#21152;&#26435;&#65292;&#21487;&#20197;&#23454;&#29616;&#19982;MLE&#30456;&#21516;&#30340;&#28176;&#36817;&#25928;&#29575;&#30340;&#21452;&#27493;&#20809;&#35889;&#26041;&#27861;&#12290;&#32771;&#34385;&#21040;&#28176;&#36817;&#24773;&#20917;&#65292;
&lt;/p&gt;
&lt;p&gt;
This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a very general and more realistic setup in which the comparison graph consists of hyper-edges of possible heterogeneous sizes and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in the scenarios when the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptot
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#36890;&#36807;&#27431;&#25289;-&#20271;&#21162;&#21033;&#26753;&#26041;&#31243;&#24314;&#27169;&#65292;&#24182;&#24212;&#29992;&#20110;&#32467;&#26500;&#30340;&#24367;&#26354;&#21018;&#24230;&#22238;&#24402;&#12289;&#21709;&#24212;&#25554;&#20540;&#21644;&#27010;&#29575;&#25512;&#26029;&#12290;&#35813;&#27169;&#22411;&#22312;&#24748;&#33218;&#26753;&#19978;&#36827;&#34892;&#20102;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#29992;&#20110;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.02894</link><description>&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#29992;&#20110;&#27431;&#25289;-&#20271;&#21162;&#21033;&#26753;&#20803;&#32032;
&lt;/p&gt;
&lt;p&gt;
Physics-informed Gaussian process model for Euler-Bernoulli beam elements. (arXiv:2308.02894v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02894
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#36890;&#36807;&#27431;&#25289;-&#20271;&#21162;&#21033;&#26753;&#26041;&#31243;&#24314;&#27169;&#65292;&#24182;&#24212;&#29992;&#20110;&#32467;&#26500;&#30340;&#24367;&#26354;&#21018;&#24230;&#22238;&#24402;&#12289;&#21709;&#24212;&#25554;&#20540;&#21644;&#27010;&#29575;&#25512;&#26029;&#12290;&#35813;&#27169;&#22411;&#22312;&#24748;&#33218;&#26753;&#19978;&#36827;&#34892;&#20102;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#29992;&#20110;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#27431;&#25289;-&#20271;&#21162;&#21033;&#26753;&#26041;&#31243;&#65292;&#26500;&#24314;&#20102;&#19968;&#31181;&#20197;&#22810;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#24418;&#24335;&#30340;&#29289;&#29702;&#20449;&#24687;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#22312;&#21512;&#36866;&#30340;&#25968;&#25454;&#38598;&#19979;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#29992;&#20110;&#22238;&#24402;&#32467;&#26500;&#30340;&#24367;&#26354;&#21018;&#24230;&#30340;&#35299;&#26512;&#20540;&#12289;&#25554;&#20540;&#21709;&#24212;&#20197;&#21450;&#23545;&#28508;&#22312;&#29289;&#29702;&#37327;&#36827;&#34892;&#27010;&#29575;&#25512;&#26029;&#12290;&#35813;&#27169;&#22411;&#34987;&#24212;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#30340;&#24748;&#33218;&#26753;&#19978;&#65292;&#35780;&#20272;&#20102;&#22238;&#24402;&#30340;&#24367;&#26354;&#21018;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#39044;&#27979;&#36136;&#37327;&#21463;&#27979;&#37327;&#22122;&#22768;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#22238;&#24402;&#24471;&#21040;&#30340;&#27010;&#29575;&#21018;&#24230;&#20998;&#24067;&#65292;&#22312;&#32467;&#26500;&#20581;&#24247;&#30417;&#27979;&#32972;&#26223;&#19979;&#65292;&#37319;&#29992;&#39532;&#27663;&#36317;&#31163;&#26469;&#25512;&#26029;&#32467;&#26500;&#31995;&#32479;&#20013;&#21487;&#33021;&#30340;&#25439;&#20260;&#20301;&#32622;&#21644;&#33539;&#22260;&#12290;&#20026;&#20102;&#39564;&#35777;&#24320;&#21457;&#30340;&#26694;&#26550;&#65292;&#36827;&#34892;&#20102;&#19968;&#39033;&#23454;&#39564;&#65292;&#20351;&#29992;&#27979;&#37327;&#30340;&#24322;&#36136;&#25968;&#25454;&#38598;&#26469;&#26356;&#26032;&#20551;&#23450;&#30340;&#35299;&#26512;&#32467;&#26500;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
A physics-informed machine learning model, in the form of a multi-output Gaussian process, is formulated using the Euler-Bernoulli beam equation. Given appropriate datasets, the model can be used to regress the analytical value of the structure's bending stiffness, interpolate responses, and make probabilistic inferences on latent physical quantities. The developed model is applied on a numerically simulated cantilever beam, where the regressed bending stiffness is evaluated and the influence measurement noise on the prediction quality is investigated. Further, the regressed probabilistic stiffness distribution is used in a structural health monitoring context, where the Mahalanobis distance is employed to reason about the possible location and extent of damage in the structural system. To validate the developed framework, an experiment is conducted and measured heterogeneous datasets are used to update the assumed analytical structural model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#23610;&#24230;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#65292;&#35777;&#26126;&#20102;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#26080;&#27861;&#24674;&#22797;&#31232;&#30095;&#21521;&#37327;&#65292;&#20294;&#36890;&#36807;&#20004;&#20010;&#38544;&#34255;&#23618;&#21487;&#20197;&#31283;&#23450;&#19988;&#31934;&#30830;&#22320;&#24674;&#22797;&#20219;&#24847;&#31232;&#30095;&#31243;&#24230;&#30340;&#21521;&#37327;&#65292;&#27492;&#22806;&#36824;&#25512;&#24191;&#21040;&#20102;&#20854;&#20182;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02836</link><description>&lt;p&gt;
&#20351;&#29992;&#23610;&#24230;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#27491;&#40784;&#27425;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Approximating Positive Homogeneous Functions with Scale Invariant Neural Networks. (arXiv:2308.02836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#23610;&#24230;&#19981;&#21464;&#31070;&#32463;&#32593;&#32476;&#36817;&#20284;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;&#30340;&#21487;&#34892;&#24615;&#65292;&#35777;&#26126;&#20102;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;&#26080;&#27861;&#24674;&#22797;&#31232;&#30095;&#21521;&#37327;&#65292;&#20294;&#36890;&#36807;&#20004;&#20010;&#38544;&#34255;&#23618;&#21487;&#20197;&#31283;&#23450;&#19988;&#31934;&#30830;&#22320;&#24674;&#22797;&#20219;&#24847;&#31232;&#30095;&#31243;&#24230;&#30340;&#21521;&#37327;&#65292;&#27492;&#22806;&#36824;&#25512;&#24191;&#21040;&#20102;&#20854;&#20182;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;ReLU&#32593;&#32476;&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;&#30340;&#21487;&#33021;&#24615;&#12290;&#30001;&#20110;&#32447;&#24615;&#20851;&#31995;&#24102;&#26469;&#30340;&#23610;&#24230;&#19981;&#21464;&#24615;&#65292;&#23545;&#20110;&#36825;&#31867;&#38382;&#39064;&#30340;&#26368;&#20248;&#37325;&#26500;&#20989;&#25968;f&#26159;&#27491;&#40784;&#27425;&#20989;&#25968;&#65292;&#21363;&#28385;&#36275;&#23545;&#20110;&#25152;&#26377;&#38750;&#36127;&#30340;&#955;&#65292;&#26377;f(&#955;x) = &#955;f(x)&#12290;&#22312;ReLU&#32593;&#32476;&#20013;&#65292;&#36825;&#20010;&#26465;&#20214;&#36716;&#21270;&#20026;&#22312;&#32593;&#32476;&#20013;&#19981;&#32771;&#34385;&#20559;&#32622;&#39033;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20174;&#23569;&#37327;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;&#31232;&#30095;&#21521;&#37327;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#21333;&#38544;&#34255;&#23618;&#30340;ReLU&#32593;&#32476;&#26080;&#27861;&#24674;&#22797;1-&#31232;&#30095;&#21521;&#37327;&#65292;&#21363;&#20351;&#26159;&#36817;&#20284;&#24674;&#22797;&#65292;&#32780;&#19988;&#19981;&#35770;&#32593;&#32476;&#30340;&#23485;&#24230;&#22914;&#20309;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#20004;&#20010;&#38544;&#34255;&#23618;&#65292;&#21487;&#20197;&#20197;&#31283;&#23450;&#30340;&#26041;&#24335;&#36817;&#20284;&#22320;&#24674;&#22797;&#20219;&#24847;&#31934;&#24230;&#30340;&#12289;&#20219;&#24847;&#31232;&#30095;&#31243;&#24230;&#20026;s&#30340;&#21521;&#37327;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#21253;&#25324;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#21644;&#30456;&#20301;&#24674;&#22797;&#22312;&#20869;&#30340;&#26356;&#24191;&#27867;&#30340;&#24674;&#22797;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#23545;&#19968;&#33324;&#27491;&#40784;&#27425;&#20989;&#25968;&#30340;&#36924;&#36817;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate to what extent it is possible to solve linear inverse problems with $ReLu$ networks. Due to the scaling invariance arising from the linearity, an optimal reconstruction function $f$ for such a problem is positive homogeneous, i.e., satisfies $f(\lambda x) = \lambda f(x)$ for all non-negative $\lambda$. In a $ReLu$ network, this condition translates to considering networks without bias terms. We first consider recovery of sparse vectors from few linear measurements. We prove that $ReLu$- networks with only one hidden layer cannot even recover $1$-sparse vectors, not even approximately, and regardless of the width of the network. However, with two hidden layers, approximate recovery with arbitrary precision and arbitrary sparsity level $s$ is possible in a stable way. We then extend our results to a wider class of recovery problems including low-rank matrix recovery and phase retrieval. Furthermore, we also consider the approximation of general positive homogeneous functio
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#28151;&#28102;&#21464;&#37327;&#21644;&#31163;&#25955;&#20540;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#22270;&#19978;&#35745;&#31639;&#22240;&#26524;&#26597;&#35810;&#30340;&#30028;&#38480;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#21098;&#26041;&#27861;&#26469;&#26174;&#33879;&#20943;&#23569;&#35745;&#31639;&#36127;&#25285;&#65292;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#26356;&#22823;&#35268;&#27169;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#30340;&#30028;&#38480;&#65292;&#22312;&#29305;&#27530;&#38382;&#39064;&#24773;&#20917;&#19979;&#21487;&#20197;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#30028;&#38480;&#65292;&#24182;&#23558;&#26041;&#27861;&#25193;&#23637;&#21040;&#20998;&#25968;&#32447;&#24615;&#35268;&#21010;&#36827;&#34892;&#35745;&#31639;</title><link>http://arxiv.org/abs/2308.02709</link><description>&lt;p&gt;
&#21487;&#20280;&#32553;&#30340;&#22240;&#26524;&#30028;&#38480;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Scalable Computation of Causal Bounds. (arXiv:2308.02709v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#28151;&#28102;&#21464;&#37327;&#21644;&#31163;&#25955;&#20540;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#22270;&#19978;&#35745;&#31639;&#22240;&#26524;&#26597;&#35810;&#30340;&#30028;&#38480;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#21098;&#26041;&#27861;&#26469;&#26174;&#33879;&#20943;&#23569;&#35745;&#31639;&#36127;&#25285;&#65292;&#20351;&#24471;&#21487;&#20197;&#35745;&#31639;&#26356;&#22823;&#35268;&#27169;&#30340;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#30340;&#30028;&#38480;&#65292;&#22312;&#29305;&#27530;&#38382;&#39064;&#24773;&#20917;&#19979;&#21487;&#20197;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#30028;&#38480;&#65292;&#24182;&#23558;&#26041;&#27861;&#25193;&#23637;&#21040;&#20998;&#25968;&#32447;&#24615;&#35268;&#21010;&#36827;&#34892;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#28151;&#28102;&#21464;&#37327;&#21644;&#31163;&#25955;&#20540;&#35266;&#27979;&#21464;&#37327;&#30340;&#22240;&#26524;&#22270;&#19978;&#35745;&#31639;&#22240;&#26524;&#26597;&#35810;&#30340;&#30028;&#38480;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#19981;&#28385;&#36275;&#21487;&#36776;&#35782;&#24615;&#12290;&#29616;&#26377;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#29992;&#20110;&#35745;&#31639;&#36825;&#20123;&#30028;&#38480;&#30340;&#32447;&#24615;&#35268;&#21010;&#65288;LP&#65289;&#20844;&#24335;&#30001;&#20110;&#32447;&#24615;&#35268;&#21010;&#30340;&#22823;&#23567;&#38543;&#30528;&#22240;&#26524;&#22270;&#20013;&#30340;&#36793;&#30340;&#25968;&#37327;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#32780;&#24456;&#24555;&#21464;&#24471;&#19981;&#21487;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;LP&#20844;&#24335;&#21487;&#20197;&#34987;&#26174;&#33879;&#20462;&#21098;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#35745;&#31639;&#36739;&#22823;&#22240;&#26524;&#25512;&#26029;&#38382;&#39064;&#30340;&#30028;&#38480;&#65292;&#30456;&#27604;&#29616;&#26377;&#25216;&#26415;&#65292;&#36825;&#20010;&#20462;&#21098;&#36807;&#31243;&#20801;&#35768;&#25105;&#20204;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#19968;&#31867;&#29305;&#27530;&#38382;&#39064;&#30340;&#30028;&#38480;&#65292;&#21253;&#25324;&#22810;&#20010;&#28151;&#28102;&#22788;&#29702;&#24433;&#21709;&#32467;&#26524;&#30340;&#24191;&#20026;&#30740;&#31350;&#30340;&#38382;&#39064;&#26063;&#12290;&#25105;&#20204;&#23558;&#20462;&#21098;&#26041;&#27861;&#25193;&#23637;&#21040;&#20998;&#25968;&#32447;&#24615;&#35268;&#21010;&#65288;fractional LP&#65289;&#65292;&#36825;&#20123;&#35268;&#21010;&#20844;&#24335;&#29992;&#20110;&#35745;&#31639;&#21253;&#21547;&#26377;&#20851;&#20010;&#20307;&#30340;&#38468;&#21152;&#35266;&#27979;&#30340;&#22240;&#26524;&#26597;&#35810;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#36816;&#34892;&#26102;&#38388;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of computing bounds for causal queries on causal graphs with unobserved confounders and discrete valued observed variables, where identifiability does not hold. Existing non-parametric approaches for computing such bounds use linear programming (LP) formulations that quickly become intractable for existing solvers because the size of the LP grows exponentially in the number of edges in the causal graph. We show that this LP can be significantly pruned, allowing us to compute bounds for significantly larger causal inference problems compared to existing techniques. This pruning procedure allows us to compute bounds in closed form for a special class of problems, including a well-studied family of problems where multiple confounded treatments influence an outcome. We extend our pruning methodology to fractional LPs which compute bounds for causal queries which incorporate additional observations about the unit. We show that our methods provide significant runtime 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#65292;&#20272;&#35745;&#20108;&#20998;&#31867;&#27169;&#22411;&#30340;FPR&#20197;&#21450;TPR&#30340;&#26041;&#27861;&#65292;&#36825;&#23545;&#20110;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#32773;&#21457;&#29616;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#34429;&#28982;&#20943;&#23567;&#20102;&#24635;&#35823;&#24046;&#65292;&#21364;&#19981;&#33021;&#20445;&#35777;&#27169;&#22411;&#23545;FPR&#21644;TPR&#30340;&#20272;&#35745;&#20934;&#30830;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#28165;&#29702;&#35823;&#24046;&#19982;&#27169;&#22411;&#20998;&#25968;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.02695</link><description>&lt;p&gt;
&#23384;&#22312;&#31867;&#26465;&#20214;&#26631;&#31614;&#22122;&#38899;&#19979;&#30340;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;FPR&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
FPR Estimation for Fraud Detection in the Presence of Class-Conditional Label Noise. (arXiv:2308.02695v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02695
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#65292;&#20272;&#35745;&#20108;&#20998;&#31867;&#27169;&#22411;&#30340;FPR&#20197;&#21450;TPR&#30340;&#26041;&#27861;&#65292;&#36825;&#23545;&#20110;&#27450;&#35784;&#26816;&#27979;&#20013;&#30340;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#32773;&#21457;&#29616;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#34429;&#28982;&#20943;&#23567;&#20102;&#24635;&#35823;&#24046;&#65292;&#21364;&#19981;&#33021;&#20445;&#35777;&#27169;&#22411;&#23545;FPR&#21644;TPR&#30340;&#20272;&#35745;&#20934;&#30830;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#28165;&#29702;&#35823;&#24046;&#19982;&#27169;&#22411;&#20998;&#25968;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#39564;&#35777;&#38598;&#20013;&#23384;&#22312;&#38169;&#35823;&#26631;&#31614;&#65288;&#26631;&#31614;&#22122;&#38899;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20108;&#20998;&#31867;&#27169;&#22411;&#30340;&#20551;&#38451;&#24615;&#29575;&#65288;FPR&#65289;/&#30495;&#38451;&#24615;&#29575;&#65288;TPR&#65289;&#30340;&#20272;&#35745;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#21160;&#26426;&#24212;&#29992;&#26159;&#27450;&#35784;&#39044;&#38450;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#20272;&#35745;FPR&#23545;&#20110;&#20445;&#25252;&#22909;&#23458;&#25143;&#30340;&#20307;&#39564;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#26631;&#31614;&#22122;&#38899;&#20855;&#26377;&#39640;&#24230;&#30340;&#19981;&#23545;&#31216;&#24615;&#12290;&#29616;&#26377;&#26041;&#27861;&#26088;&#22312;&#26368;&#23567;&#21270;&#28165;&#29702;&#36807;&#31243;&#20013;&#30340;&#24635;&#35823;&#24046; - &#36991;&#20813;&#28165;&#29702;&#38750;&#22122;&#38899;&#30340;&#31034;&#20363;&#65292;&#24182;&#30830;&#20445;&#28165;&#29702;&#22122;&#38899;&#31034;&#20363;&#12290;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20934;&#30830;&#24615;&#24230;&#37327;&#65292;&#20294;&#19981;&#36275;&#20197;&#20445;&#35777;&#27169;&#22411;&#30340;&#30495;&#23454;FPR&#25110;TPR&#30340;&#33391;&#22909;&#20272;&#35745;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#21363;&#20351;&#24635;&#35823;&#24046;&#36739;&#20302;&#65292;&#20351;&#29992;&#27169;&#22411;&#30452;&#25509;&#28165;&#29702;&#33258;&#24049;&#30340;&#39564;&#35777;&#25968;&#25454;&#20063;&#20250;&#23548;&#33268;&#20302;&#20272;&#12290;&#36825;&#34920;&#26126;&#65292;&#30740;&#31350;&#20154;&#21592;&#38656;&#35201;&#36861;&#27714;&#19981;&#20165;&#20943;&#23569;&#24635;&#35823;&#24046;&#65292;&#36824;&#38656;&#35201;&#23547;&#27714;&#20351;&#28165;&#29702;&#35823;&#24046;&#19982;&#27169;&#22411;&#20998;&#25968;&#35299;&#32806;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the false-/ true-positive-rate (FPR/TPR) for a binary classification model when there are incorrect labels (label noise) in the validation set. Our motivating application is fraud prevention where accurate estimates of FPR are critical to preserving the experience for good customers, and where label noise is highly asymmetric. Existing methods seek to minimize the total error in the cleaning process - to avoid cleaning examples that are not noise, and to ensure cleaning of examples that are. This is an important measure of accuracy but insufficient to guarantee good estimates of the true FPR or TPR for a model, and we show that using the model to directly clean its own validation data leads to underestimates even if total error is low. This indicates a need for researchers to pursue methods that not only reduce total error but also seek to de-correlate cleaning error with model scores.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#22312;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#28857;&#20113;&#30340;&#26631;&#37327;&#26354;&#29575;&#65292;&#35813;&#26041;&#27861;&#20165;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#24230;&#37327;&#32467;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20854;&#22312;n&#32500;&#23454;&#25968;&#31354;&#38388;&#20013;&#30340;&#23884;&#20837;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.02615</link><description>&lt;p&gt;
&#23545;&#20110;&#28857;&#20113;&#30340;&#26631;&#37327;&#26354;&#29575;&#20272;&#35745;&#30340;&#20869;&#22312;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Intrinsic Approach to Scalar-Curvature Estimation for Point Clouds. (arXiv:2308.02615v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02615
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#22312;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#28857;&#20113;&#30340;&#26631;&#37327;&#26354;&#29575;&#65292;&#35813;&#26041;&#27861;&#20165;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#24230;&#37327;&#32467;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20854;&#22312;n&#32500;&#23454;&#25968;&#31354;&#38388;&#20013;&#30340;&#23884;&#20837;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20869;&#22312;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#20316;&#20026;&#26377;&#38480;&#24230;&#37327;&#31354;&#38388;&#21576;&#29616;&#30340;&#25968;&#25454;&#38598;&#30340;&#26631;&#37327;&#26354;&#29575;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#20165;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#24230;&#37327;&#32467;&#26500;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#20854;&#22312;n&#32500;&#23454;&#25968;&#31354;&#38388;&#20013;&#30340;&#23884;&#20837;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#33268;&#30340;&#65292;&#21363;&#23545;&#20110;&#20174;&#32039;&#33268;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#20013;&#37319;&#26679;&#30340;&#28857;&#65292;&#38543;&#30528;&#28857;&#30340;&#25968;&#37327;&#22686;&#21152;&#65292;&#20272;&#35745;&#32467;&#26524;&#20250;&#25910;&#25947;&#21040;&#26631;&#37327;&#26354;&#29575;&#12290;&#20026;&#20102;&#35777;&#26126;&#20854;&#22312;&#24212;&#29992;&#20013;&#30340;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#35813;&#20272;&#35745;&#26041;&#27861;&#23545;&#24230;&#37327;&#32467;&#26500;&#30340;&#25200;&#21160;&#20855;&#26377;&#31283;&#23450;&#24615;&#65292;&#20363;&#22914;&#26679;&#26412;&#20013;&#30340;&#22122;&#22768;&#25110;&#20272;&#35745;&#20869;&#22312;&#24230;&#37327;&#35823;&#24046;&#12290;&#25105;&#20204;&#22312;&#20174;&#20855;&#26377;&#25351;&#23450;&#26354;&#29575;&#30340;&#27969;&#24418;&#20013;&#37319;&#26679;&#30340;&#21512;&#25104;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an intrinsic estimator for the scalar curvature of a data set presented as a finite metric space. Our estimator depends only on the metric structure of the data and not on an embedding in $\mathbb{R}^n$. We show that the estimator is consistent in the sense that for points sampled from a probability measure on a compact Riemannian manifold, the estimator converges to the scalar curvature as the number of points increases. To justify its use in applications, we show that the estimator is stable with respect to perturbations of the metric structure, e.g., noise in the sample or error estimating the intrinsic metric. We validate our estimator experimentally on synthetic data that is sampled from manifolds with specified curvature.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#30340;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#30340;&#23398;&#20064;&#26694;&#26550;IFIB&#65292;&#29992;&#20110;&#24314;&#27169;&#31163;&#25955;&#20107;&#20214;&#20013;&#20855;&#26377;&#20998;&#31867;&#25110;&#25968;&#20540;&#23646;&#24615;&#30340;&#20107;&#20214;&#26631;&#35760;&#12290;</title><link>http://arxiv.org/abs/2308.02360</link><description>&lt;p&gt;
&#22522;&#20110;&#31215;&#20998;&#30340;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Intensity-free Integral-based Learning of Marked Temporal Point Processes. (arXiv:2308.02360v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02360
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#30340;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#30340;&#23398;&#20064;&#26694;&#26550;IFIB&#65292;&#29992;&#20110;&#24314;&#27169;&#31163;&#25955;&#20107;&#20214;&#20013;&#20855;&#26377;&#20998;&#31867;&#25110;&#25968;&#20540;&#23646;&#24615;&#30340;&#20107;&#20214;&#26631;&#35760;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26631;&#35760;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;MTPP&#65289;&#20013;&#65292;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#26159;&#20026;&#26465;&#20214;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65288;PDF&#65289;$p^*&#65288;m&#65292;t&#65289;$&#21442;&#25968;&#21270;&#25554;&#20540;&#26102;&#38388;t&#21644;&#26631;&#35760;m&#22312;&#21382;&#21490;&#26465;&#20214;&#19979;&#12290;&#29616;&#26377;&#30740;&#31350;&#22823;&#22810;&#39044;&#20808;&#23450;&#20041;&#24378;&#24230;&#20989;&#25968;&#12290;&#23427;&#20204;&#30340;&#23454;&#29992;&#24615;&#21463;&#21040;&#25351;&#23450;&#24378;&#24230;&#20989;&#25968;&#27491;&#30830;&#24418;&#24335;&#30340;&#25361;&#25112;&#65292;&#36825;&#23545;&#20110;&#24179;&#34913;&#34920;&#36798;&#33021;&#21147;&#21644;&#22788;&#29702;&#25928;&#29575;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#26377;&#30740;&#31350;&#25670;&#33073;&#39044;&#23450;&#20041;&#24378;&#24230;&#20989;&#25968;&#65292;&#19968;&#20010;&#27169;&#22411;$p^*&#65288;t&#65289;$&#21644;$p^*&#65288;m&#65289;$&#20998;&#24320;&#65292;&#21478;&#19968;&#20010;&#20391;&#37325;&#20110;&#19981;&#32771;&#34385;&#26631;&#35760;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;TPP&#65289;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#24320;&#21457;&#39640;&#20445;&#30495;&#24230;&#30340;$p^*&#65288;m&#65292;t&#65289;$&#65292;&#36866;&#29992;&#20110;&#20107;&#20214;&#26631;&#35760;&#22312;&#22810;&#32500;&#36830;&#32493;&#31354;&#38388;&#20013;&#20855;&#26377;&#20998;&#31867;&#25110;&#25968;&#20540;&#23646;&#24615;&#30340;&#31163;&#25955;&#20107;&#20214;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#26041;&#26696;&#26694;&#26550;IFIB&#65288;&#26080;&#24378;&#24230;&#31215;&#20998;&#21270;&#23398;&#33021;&#36807;&#31243;&#65289;&#65292;&#30452;&#25509;&#24314;&#27169;&#26465;&#20214;&#32852;&#21512;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;$p^*&#65288;m&#65292;t&#65289;$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly
&lt;/p&gt;</description></item><item><title>LLMs&#22312;&#22788;&#29702;&#21487;&#35299;&#37322;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#27169;&#22411;&#32423;&#24635;&#32467;&#21644;&#33258;&#21160;&#21270;&#30340;&#24322;&#24120;&#26816;&#27979;&#12289;&#21407;&#22240;&#25551;&#36848;&#21644;&#20462;&#22797;&#24314;&#35758;&#12290;&#22312;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#20351;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#20316;&#20026;&#31034;&#20363;&#65292;&#21516;&#26102;&#20171;&#32461;&#20102;&#24320;&#28304;&#30340;LLM-GAM&#25509;&#21475;&#21253;$\texttt{TalkToEBM}$&#12290;</title><link>http://arxiv.org/abs/2308.01157</link><description>&lt;p&gt;
LLMs&#29702;&#35299;&#29627;&#29827;&#30418;&#27169;&#22411;&#65292;&#21457;&#29616;&#24778;&#21916;&#24182;&#25552;&#20986;&#20462;&#22797;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01157
&lt;/p&gt;
&lt;p&gt;
LLMs&#22312;&#22788;&#29702;&#21487;&#35299;&#37322;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#27169;&#22411;&#32423;&#24635;&#32467;&#21644;&#33258;&#21160;&#21270;&#30340;&#24322;&#24120;&#26816;&#27979;&#12289;&#21407;&#22240;&#25551;&#36848;&#21644;&#20462;&#22797;&#24314;&#35758;&#12290;&#22312;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#20351;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#20316;&#20026;&#31034;&#20363;&#65292;&#21516;&#26102;&#20171;&#32461;&#20102;&#24320;&#28304;&#30340;LLM-GAM&#25509;&#21475;&#21253;$\texttt{TalkToEBM}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22788;&#29702;&#21487;&#35299;&#37322;&#27169;&#22411;&#26041;&#38754;&#30340;&#20986;&#33394;&#34920;&#29616;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#23558;&#22797;&#26434;&#32467;&#26524;&#20998;&#35299;&#20026;&#21333;&#19968;&#21464;&#37327;&#30340;&#22270;&#34920;&#31034;&#32452;&#20214;&#12290;&#36890;&#36807;&#37319;&#29992;&#23618;&#27425;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;LLMs&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#25972;&#20010;&#27169;&#22411;&#36866;&#24212;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20840;&#38754;&#30340;&#27169;&#22411;&#32423;&#24635;&#32467;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;LLMs&#33021;&#22815;&#24212;&#29992;&#20854;&#24191;&#27867;&#30340;&#32972;&#26223;&#30693;&#35782;&#26469;&#33258;&#21160;&#23436;&#25104;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#24120;&#35265;&#20219;&#21153;&#65292;&#22914;&#26816;&#27979;&#19982;&#20808;&#21069;&#30693;&#35782;&#30456;&#30683;&#30462;&#30340;&#24322;&#24120;&#65292;&#25551;&#36848;&#24322;&#24120;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#21435;&#38500;&#24322;&#24120;&#30340;&#20462;&#22797;&#24314;&#35758;&#12290;&#25105;&#20204;&#20351;&#29992;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#30340;&#22810;&#20010;&#31034;&#20363;&#26469;&#35777;&#26126;LLMs&#30340;&#36825;&#20123;&#26032;&#33021;&#21147;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#24378;&#35843;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;(GAMs)&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;$\texttt{TalkToEBM}$&#21253;&#20316;&#20026;&#19968;&#20010;&#24320;&#28304;&#30340;LLM-GAM&#25509;&#21475;&#36827;&#34892;&#20171;&#32461;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12306</link><description>&lt;p&gt;
&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#32500;&#24230;&#35781;&#21650;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#24230;&#35781;&#21650;(CoD)&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20197;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#35745;&#31639;&#25104;&#26412;&#26469;&#26497;&#24230;&#31246;&#36153;&#35745;&#31639;&#36164;&#28304;&#12290;&#36825;&#22312;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#20013;&#38754;&#20020;&#26497;&#22823;&#25361;&#25112;&#65292;&#27491;&#22914;Richard Bellman&#22312;60&#24180;&#21069;&#39318;&#27425;&#25351;&#20986;&#30340;&#37027;&#26679;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;&#39640;&#32500;&#24230;&#19978;&#25968;&#20540;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#20294;&#36825;&#26679;&#30340;&#35745;&#31639;&#20195;&#20215;&#36807;&#39640;&#65292;&#32780;&#23558;&#19968;&#33324;&#38750;&#32447;&#24615;PDEs&#25193;&#23637;&#21040;&#39640;&#32500;&#24230;&#20174;&#26410;&#23454;&#29616;&#36807;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#25193;&#23637;&#21040;&#35299;&#20915;&#20219;&#24847;&#39640;&#32500;PDEs&#12290;&#35813;&#26032;&#26041;&#27861;&#31216;&#20026;&#38543;&#26426;&#32500;&#24230;&#26799;&#24230;&#19979;&#38477;(SDGD)&#65292;&#23558;PDE&#30340;&#26799;&#24230;&#20998;&#35299;&#20026;&#19982;&#19981;&#21516;&#32500;&#24230;&#23545;&#24212;&#30340;&#37096;&#20998;&#65292;&#24182;&#22312;&#35757;&#32451;PINNs&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#38543;&#26426;&#36873;&#25321;&#36825;&#20123;&#32500;&#24230;&#37096;&#20998;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;</title><link>http://arxiv.org/abs/2306.08432</link><description>&lt;p&gt;
&#25209;&#27425;&#20351;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#30340;&#26368;&#23567;&#35268;&#33539;&#39118;&#38505;&#31283;&#23450;
&lt;/p&gt;
&lt;p&gt;
Batches Stabilize the Minimum Norm Risk in High Dimensional Overparameterized Linear Regression. (arXiv:2306.08432v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#65292;&#31283;&#23450;&#20102;&#39118;&#38505;&#34892;&#20026;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#25968;&#25454;&#20998;&#25104;&#25209;&#27425;&#30340;&#23398;&#20064;&#31639;&#27861;&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24456;&#24120;&#35265;&#65292;&#36890;&#24120;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#24615;&#33021;&#20043;&#38388;&#25552;&#20379;&#26377;&#29992;&#30340;&#26435;&#34913;&#12290;&#26412;&#25991;&#36890;&#36807;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#29305;&#24449;&#30340;&#26368;&#23567;&#35268;&#33539;&#36229;&#21442;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#35270;&#35282;&#26469;&#30740;&#31350;&#25209;&#37327;&#20998;&#21306;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#24314;&#35758;&#26368;&#23567;&#35268;&#33539;&#20272;&#35745;&#37327;&#30340;&#33258;&#28982;&#23567;&#25209;&#37327;&#29256;&#26412;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#20108;&#27425;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#34920;&#26126;&#20854;&#19982;&#22122;&#22768;&#27700;&#24179;&#20197;&#21450;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#25104;&#21453;&#27604;&#65292;&#23545;&#20110;&#26368;&#20339;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#12290;&#19982;&#26368;&#23567;&#35268;&#33539;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#31283;&#23450;&#30340;&#39118;&#38505;&#34892;&#20026;&#65292;&#20854;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#27604;&#20363;&#19978;&#21333;&#35843;&#36882;&#22686;&#65292;&#28040;&#38500;&#20102;&#25554;&#20540;&#28857;&#22788;&#30340;&#33192;&#32960;&#21644;&#21452;&#23792;&#29616;&#35937;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25209;&#22788;&#29702;&#25152;&#25552;&#20379;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#21487;&#20197;&#36890;&#36807;&#29305;&#24449;&#37325;&#21472;&#26469;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning algorithms that divide the data into batches are prevalent in many machine-learning applications, typically offering useful trade-offs between computational efficiency and performance. In this paper, we examine the benefits of batch-partitioning through the lens of a minimum-norm overparameterized linear regression model with isotropic Gaussian features. We suggest a natural small-batch version of the minimum-norm estimator, and derive an upper bound on its quadratic risk, showing it is inversely proportional to the noise level as well as to the overparameterization ratio, for the optimal choice of batch size. In contrast to minimum-norm, our estimator admits a stable risk behavior that is monotonically increasing in the overparameterization ratio, eliminating both the blowup at the interpolation point and the double-descent phenomenon. Interestingly, we observe that this implicit regularization offered by the batch partition is partially explained by feature overlap between t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.07886</link><description>&lt;p&gt;
&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#38382;&#39064;&#30340;&#23545;&#31216;&#24615;&#19982;&#20020;&#30028;&#28857;
&lt;/p&gt;
&lt;p&gt;
Symmetry &amp; Critical Points for Symmetric Tensor Decompositions Problems. (arXiv:2306.07886v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24471;&#21040;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20102;&#21508;&#31181;&#38459;&#30861;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20960;&#20309;&#38556;&#30861;&#21644;&#30001;&#20110;&#23545;&#31216;&#24615;&#23548;&#33268;&#30340;&#20016;&#23500;&#30340;&#20020;&#30028;&#28857;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#23558;&#19968;&#20010;&#23454;&#23545;&#31216;&#24352;&#37327;&#20998;&#35299;&#25104;&#31209;&#20026;1&#39033;&#20043;&#21644;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#21033;&#29992;&#20854;&#20016;&#23500;&#30340;&#23545;&#31216;&#32467;&#26500;&#65292;&#23548;&#20986;Puiseux&#32423;&#25968;&#34920;&#31034;&#30340;&#19968;&#31995;&#21015;&#20020;&#30028;&#28857;&#65292;&#24182;&#33719;&#24471;&#20102;&#20851;&#20110;&#20020;&#30028;&#20540;&#21644;Hessian&#35889;&#30340;&#31934;&#30830;&#20998;&#26512;&#20272;&#35745;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#21508;&#31181;&#20960;&#20309;&#38556;&#30861;&#65292;&#38459;&#30861;&#20102;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#20351;&#29992;&#65292;&#26368;&#21518;&#65292;&#21033;&#29992;&#19968;&#20010;&#29275;&#39039;&#22810;&#38754;&#20307;&#35770;&#35777;&#20102;&#22266;&#23450;&#23545;&#31216;&#24615;&#30340;&#25152;&#26377;&#20020;&#30028;&#28857;&#30340;&#23436;&#20840;&#26522;&#20030;&#65292;&#24182;&#35777;&#26126;&#20102;&#19982;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#38598;&#21512;&#30456;&#27604;&#65292;&#30001;&#20110;&#23545;&#31216;&#24615;&#30340;&#23384;&#22312;&#65292;&#20020;&#30028;&#28857;&#30340;&#38598;&#21512;&#21487;&#33021;&#20250;&#26174;&#31034;&#20986;&#32452;&#21512;&#30340;&#20016;&#23500;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the non-convex optimization problem associated with the decomposition of a real symmetric tensor into a sum of rank one terms. Use is made of the rich symmetry structure to derive Puiseux series representations of families of critical points, and so obtain precise analytic estimates on the critical values and the Hessian spectrum. The sharp results make possible an analytic characterization of various geometric obstructions to local optimization methods, revealing in particular a complex array of saddles and local minima which differ by their symmetry, structure and analytic properties. A desirable phenomenon, occurring for all critical points considered, concerns the index of a point, i.e., the number of negative Hessian eigenvalues, increasing with the value of the objective function. Lastly, a Newton polytope argument is used to give a complete enumeration of all critical points of fixed symmetry, and it is shown that contrarily to the set of global minima which remains 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#65292;&#24403;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#26102;&#65292;&#38750;&#32447;&#24615;&#38382;&#39064;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#26041;&#27861;&#20248;&#20110;&#38598;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#38388;&#38553;&#30340;&#28176;&#36827;&#20248;&#21183;&#30340;&#22343;&#20540;&#65292;&#25152;&#26377;&#20854;&#20182;&#26102;&#21051;&#21644;&#25972;&#20010;&#28176;&#36827;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2304.06833</link><description>&lt;p&gt;
&#35780;&#20272;-&#20248;&#21270;&#26041;&#27861;&#19982;&#38598;&#25104;&#35780;&#20272;&#20248;&#21270;&#27861;&#65306;&#22522;&#20110;&#38543;&#26426;&#20248;&#21183;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Estimate-Then-Optimize Versus Integrated-Estimation-Optimization: A Stochastic Dominance Perspective. (arXiv:2304.06833v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#65292;&#24403;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#26102;&#65292;&#38750;&#32447;&#24615;&#38382;&#39064;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#26041;&#27861;&#20248;&#20110;&#38598;&#25104;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#38388;&#38553;&#30340;&#28176;&#36827;&#20248;&#21183;&#30340;&#22343;&#20540;&#65292;&#25152;&#26377;&#20854;&#20182;&#26102;&#21051;&#21644;&#25972;&#20010;&#28176;&#36827;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#38500;&#20102;&#38656;&#35201;&#20248;&#21270;&#20219;&#21153;&#65292;&#36824;&#38656;&#35201;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#28508;&#22312;&#20998;&#24067;&#30340;&#27169;&#22411;&#21442;&#25968;&#12290;&#26368;&#36817;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;&#36890;&#36807;&#36873;&#25321;&#23548;&#33268;&#26368;&#20339;&#32463;&#39564;&#30446;&#26631;&#24615;&#33021;&#30340;&#27169;&#22411;&#21442;&#25968;&#65292;&#21487;&#20197;&#38598;&#25104;&#20272;&#35745;&#21644;&#20248;&#21270;&#36807;&#31243;&#12290;&#24403;&#27169;&#22411;&#34987;&#38169;&#35823;&#22320;&#25351;&#23450;&#26102;&#65292;&#36825;&#31181;&#38598;&#25104;&#26041;&#27861;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#26174;&#31034;&#20986;&#20248;&#20110;&#31616;&#21333;&#30340;&#8220;&#20808;&#20272;&#35745;&#20877;&#20248;&#21270;&#8221;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#35748;&#20026;&#65292;&#22312;&#27169;&#22411;&#31867;&#36275;&#22815;&#20016;&#23500;&#20197;&#28085;&#30422;&#30495;&#23454;&#24773;&#20917;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#20004;&#31181;&#26041;&#27861;&#20043;&#38388;&#30340;&#24615;&#33021;&#25490;&#24207;&#22312;&#24378;&#28872;&#30340;&#24847;&#20041;&#19979;&#34987;&#39072;&#20498;&#12290;&#22312;&#21463;&#38480;&#26465;&#20214;&#21644;&#24403;&#19978;&#19979;&#25991;&#29305;&#24449;&#21487;&#29992;&#26102;&#65292;&#31867;&#20284;&#30340;&#32467;&#26524;&#20063;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven stochastic optimization, model parameters of the underlying distribution need to be estimated from data in addition to the optimization task. Recent literature suggests the integration of the estimation and optimization processes, by selecting model parameters that lead to the best empirical objective performance. Such an integrated approach can be readily shown to outperform simple ``estimate then optimize" when the model is misspecified. In this paper, we argue that when the model class is rich enough to cover the ground truth, the performance ordering between the two approaches is reversed for nonlinear problems in a strong sense. Simple ``estimate then optimize" outperforms the integrated approach in terms of stochastic dominance of the asymptotic optimality gap, i,e, the mean, all other moments, and the entire asymptotic distribution of the optimality gap is always better. Analogous results also hold under constrained settings and when contextual features are availa
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2304.05365</link><description>&lt;p&gt;
&#25105;&#20204;&#23454;&#29616;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#21527;&#65311;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20010;&#24615;&#21270;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Did we personalize? Assessing personalization by an online reinforcement learning algorithm using resampling. (arXiv:2304.05365v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#37325;&#22797;&#37319;&#26679;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;&#22312;&#32447; RL &#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#31243;&#24230;&#12290;&#35813;&#26041;&#27861;&#21487;&#29992;&#20110;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#23383;&#20581;&#24247;&#20013;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20010;&#24615;&#21270;&#27835;&#30103;&#24207;&#21015;&#20197;&#25903;&#25345;&#29992;&#25143;&#37319;&#21462;&#26356;&#20581;&#24247;&#30340;&#34892;&#20026;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#36825;&#31181;&#36830;&#32493;&#20915;&#31574;&#38382;&#39064;&#28041;&#21450;&#21040;&#22522;&#20110;&#29992;&#25143;&#30340;&#19978;&#19979;&#25991;&#65288;&#20363;&#22914;&#65292;&#20808;&#21069;&#30340;&#27963;&#21160;&#27700;&#24179;&#12289;&#20301;&#32622;&#31561;&#65289;&#22312;&#20309;&#26102;&#27835;&#30103;&#20197;&#21450;&#22914;&#20309;&#27835;&#30103;&#30340;&#20915;&#23450;&#12290;&#22312;&#32447;RL&#31639;&#27861;&#26159;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22522;&#20110;&#27599;&#20010;&#29992;&#25143;&#30340;&#21382;&#21490;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#30693;&#35782;&#20010;&#24615;&#21270;&#36825;&#20123;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#35201;&#20915;&#23450;&#26159;&#21542;&#24212;&#22312;&#23454;&#38469;&#37096;&#32626;&#30340;&#8220;&#20248;&#21270;&#8221;&#24178;&#39044;&#20013;&#21253;&#21547;RL&#31639;&#27861;&#65292;&#25105;&#20204;&#24517;&#39035;&#35780;&#20272;&#25968;&#25454;&#35777;&#25454;&#65292;&#34920;&#26126;RL&#31639;&#27861;&#23454;&#38469;&#19978;&#27491;&#22312;&#23558;&#27835;&#30103;&#20010;&#24615;&#21270;&#36866;&#24212;&#20854;&#29992;&#25143;&#12290;&#30001;&#20110;RL&#31639;&#27861;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#20154;&#20204;&#21487;&#33021;&#20250;&#23545;&#20854;&#22312;&#26576;&#20123;&#29366;&#24577;&#19979;&#30340;&#23398;&#20064;&#24182;&#20351;&#29992;&#27492;&#23398;&#20064;&#26469;&#25552;&#20379;&#29305;&#23450;&#27835;&#30103;&#30340;&#33021;&#21147;&#20135;&#29983;&#35823;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#24037;&#20316;&#23450;&#20041;&#30340;&#20010;&#24615;&#21270;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#37325;&#22797;&#37319;&#26679;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#26469;&#35780;&#20272;&#22312;&#32447;RL&#31639;&#27861;&#23454;&#29616;&#30340;&#20010;&#24615;&#21270;&#27700;&#24179;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#35782;&#21035;&#20010;&#24615;&#21270;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20248;&#21270;&#25968;&#23383;&#20581;&#24247;&#30340;&#20010;&#24615;&#21270;&#24178;&#39044;&#26041;&#38754;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing interest in using reinforcement learning (RL) to personalize sequences of treatments in digital health to support users in adopting healthier behaviors. Such sequential decision-making problems involve decisions about when to treat and how to treat based on the user's context (e.g., prior activity level, location, etc.). Online RL is a promising data-driven approach for this problem as it learns based on each user's historical responses and uses that knowledge to personalize these decisions. However, to decide whether the RL algorithm should be included in an ``optimized'' intervention for real-world deployment, we must assess the data evidence indicating that the RL algorithm is actually personalizing the treatments to its users. Due to the stochasticity in the RL algorithm, one may get a false impression that it is learning in certain states and using this learning to provide specific treatments. We use a working definition of personalization and introduce a resamp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#31639;&#27861;&#65292;&#23558; UCB &#31639;&#27861;&#65288;Auer&#31561;&#20154;&#65292;2002&#65289;&#24212;&#29992;&#20110;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#30340;&#22312;&#32447;&#35774;&#32622;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#19982;&#31574;&#30053;&#20195;&#29702;&#22810;&#27425;&#20114;&#21160;&#26469;&#35774;&#35745;&#26368;&#20248;&#30340;&#35745;&#20998;&#35268;&#21017;&#65292;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.08613</link><description>&lt;p&gt;
&#23398;&#20064;&#22870;&#21169;&#20449;&#24687;&#33719;&#21462;&#65306;&#27491;&#30830;&#35745;&#20998;&#35268;&#21017;&#36935;&#21040;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model. (arXiv:2303.08613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#31639;&#27861;&#65292;&#23558; UCB &#31639;&#27861;&#65288;Auer&#31561;&#20154;&#65292;2002&#65289;&#24212;&#29992;&#20110;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#30340;&#22312;&#32447;&#35774;&#32622;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#19982;&#31574;&#30053;&#20195;&#29702;&#22810;&#27425;&#20114;&#21160;&#26469;&#35774;&#35745;&#26368;&#20248;&#30340;&#35745;&#20998;&#35268;&#21017;&#65292;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#28608;&#21169;&#20449;&#24687;&#33719;&#21462;&#38382;&#39064;&#12290;&#27492;&#38382;&#39064;&#34987;&#24314;&#27169;&#20026;&#22996;&#25176;&#26041;&#21644;&#20195;&#29702;&#26041;&#20043;&#38388;&#30340; Stackelberg &#21338;&#24328;&#65292;&#20854;&#20013;&#22996;&#25176;&#20154;&#23459;&#24067;&#20102;&#19968;&#26465;&#24471;&#20998;&#35268;&#21017;&#26469;&#25351;&#23450;&#20184;&#27454;&#65292;&#28982;&#21518;&#20195;&#29702;&#26041;&#36873;&#25321;&#26368;&#22823;&#21270;&#20854;&#33258;&#36523;&#21033;&#28070;&#21644;&#25253;&#21578;&#20449;&#24687;&#30340;&#21162;&#21147;&#27700;&#24179;&#12290;&#25105;&#20204;&#20174;&#22996;&#25176;&#26041;&#30340;&#35282;&#24230;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#30340;&#22312;&#32447;&#35774;&#32622;&#65292;&#21363;&#36890;&#36807;&#19982;&#31574;&#30053;&#20195;&#29702;&#22810;&#27425;&#20132;&#20114;&#26469;&#35774;&#35745;&#26368;&#20248;&#35745;&#20998;&#35268;&#21017;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#30340;&#26679;&#26412;&#39640;&#25928;&#31639;&#27861;&#65292;&#23558; UCB &#31639;&#27861; (Auer et al., 2002) &#37327;&#36523;&#23450;&#21046;&#21040;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#20854;&#22312; T &#27425;&#36845;&#20195;&#21518;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615; $T^{2/3}$-&#36951;&#25022;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#23545;&#22996;&#25176;&#26041;&#26368;&#20248;&#21033;&#28070;&#36827;&#34892;&#31934;&#32454;&#20272;&#35745;&#30340;&#36807;&#31243;&#20197;&#21450;&#20445;&#23432;&#32416;&#27491;&#26041;&#26696;&#65292;&#20197;&#30830;&#20445;&#20195;&#29702;&#26041;&#30340;&#34892;&#21160;&#24471;&#21040;&#26377;&#25928;&#28608;&#21169;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36951;&#25022;&#30028;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#26159;&#23427;&#26159;&#28176;&#36827;&#26368;&#23567;&#21487;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a sublinear $T^{2/3}$-regret after $T$ iterations. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#26399;&#26395;&#19968;&#33268;&#24615;&#65288;EC&#65289;&#30340;&#26032;&#22411;&#26657;&#20934;&#25216;&#26415;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#36827;&#34892;&#21518;&#35757;&#32451;&#37325;&#26032;&#32553;&#25918;&#65292;&#20351;&#24179;&#22343;&#39564;&#35777;&#32622;&#20449;&#24230;&#19982;&#24179;&#22343;&#27491;&#30830;&#26631;&#31614;&#27604;&#20363;&#30456;&#19968;&#33268;&#65292;&#22312;&#19981;&#21516;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#31867;&#20284;&#28201;&#24230;&#32553;&#25918;&#65288;TS&#65289;&#30340;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.02644</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26657;&#20934;&#30340;&#26399;&#26395;&#19968;&#33268;&#24615;
&lt;/p&gt;
&lt;p&gt;
Expectation consistency for calibration of neural networks. (arXiv:2303.02644v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#26399;&#26395;&#19968;&#33268;&#24615;&#65288;EC&#65289;&#30340;&#26032;&#22411;&#26657;&#20934;&#25216;&#26415;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#36827;&#34892;&#21518;&#35757;&#32451;&#37325;&#26032;&#32553;&#25918;&#65292;&#20351;&#24179;&#22343;&#39564;&#35777;&#32622;&#20449;&#24230;&#19982;&#24179;&#22343;&#27491;&#30830;&#26631;&#31614;&#27604;&#20363;&#30456;&#19968;&#33268;&#65292;&#22312;&#19981;&#21516;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#31867;&#20284;&#28201;&#24230;&#32553;&#25918;&#65288;TS&#65289;&#30340;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26377;&#30528;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#24050;&#32463;&#26377;&#25253;&#36947;&#25351;&#20986;&#23427;&#20204;&#22312;&#39044;&#27979;&#32622;&#20449;&#24230;&#26041;&#38754;&#24448;&#24448;&#23384;&#22312;&#36807;&#24230;&#20048;&#35266;&#30340;&#38382;&#39064;&#12290;&#23547;&#25214;&#26377;&#25928;&#21644;&#39640;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#26657;&#20934;&#26041;&#27861;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#26356;&#22909;&#22320;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#26159;&#19968;&#39033;&#37325;&#35201;&#30340;&#21162;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#26399;&#26395;&#19968;&#33268;&#24615;&#65288;EC&#65289;&#30340;&#26032;&#22411;&#26657;&#20934;&#25216;&#26415;&#65292;&#23427;&#36890;&#36807;&#23545;&#26368;&#21518;&#19968;&#23618;&#26435;&#37325;&#36827;&#34892;&#21518;&#35757;&#32451;&#37325;&#26032;&#32553;&#25918;&#65292;&#24378;&#21046;&#35201;&#27714;&#24179;&#22343;&#39564;&#35777;&#32622;&#20449;&#24230;&#19982;&#24179;&#22343;&#27491;&#30830;&#26631;&#31614;&#27604;&#20363;&#30456;&#19968;&#33268;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;EC&#26041;&#27861;&#22312;&#19981;&#21516;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#19982;&#28201;&#24230;&#32553;&#25918;&#65288;TS&#65289;&#30456;&#20284;&#30340;&#26657;&#20934;&#24615;&#33021;&#65292;&#21516;&#26102;&#38656;&#35201;&#31867;&#20284;&#30340;&#39564;&#35777;&#26679;&#26412;&#21644;&#35745;&#31639;&#36164;&#28304;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35748;&#20026;EC&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#21407;&#29702;&#65288;&#21363;Nishimori&#24658;&#31561;&#24335;&#65289;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#28176;&#36817;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characteri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#31579;&#36873;&#20998;&#31867;&#22120;&#30340;&#32452;&#20869;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25351;&#20986;&#20351;&#29992;&#26657;&#20934;&#30340;&#20998;&#31867;&#22120;&#21487;&#33021;&#23384;&#22312;&#23545;&#24863;&#20852;&#36259;&#30340;&#20154;&#21475;&#32676;&#20307;&#20869;&#30340;&#21512;&#26684;&#25104;&#21592;&#23384;&#22312;&#19981;&#20844;&#24179;&#23545;&#24453;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#39640;&#25928;&#21518;&#22788;&#29702;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#20462;&#25913;&#20998;&#31867;&#22120;&#65292;&#20197;&#23454;&#29616;&#32452;&#20869;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.00025</link><description>&lt;p&gt;
&#20851;&#20110;&#31579;&#36873;&#20998;&#31867;&#22120;&#30340;&#32452;&#20869;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Within-Group Fairness of Screening Classifiers. (arXiv:2302.00025v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#31579;&#36873;&#20998;&#31867;&#22120;&#30340;&#32452;&#20869;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#25351;&#20986;&#20351;&#29992;&#26657;&#20934;&#30340;&#20998;&#31867;&#22120;&#21487;&#33021;&#23384;&#22312;&#23545;&#24863;&#20852;&#36259;&#30340;&#20154;&#21475;&#32676;&#20307;&#20869;&#30340;&#21512;&#26684;&#25104;&#21592;&#23384;&#22312;&#19981;&#20844;&#24179;&#23545;&#24453;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#39640;&#25928;&#21518;&#22788;&#29702;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#20462;&#25913;&#20998;&#31867;&#22120;&#65292;&#20197;&#23454;&#29616;&#32452;&#20869;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31579;&#36873;&#20998;&#31867;&#22120;&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#21508;&#31181;&#36873;&#25321;&#36807;&#31243;&#20013;&#30340;&#20505;&#36873;&#20154;&#35782;&#21035;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22914;&#26524;&#19968;&#20010;&#20998;&#31867;&#22120;&#34987;&#26657;&#20934;&#65292;&#21487;&#20197;&#20351;&#29992;&#19968;&#20010;&#38408;&#20540;&#20915;&#31574;&#35268;&#21017;&#35782;&#21035;&#20986;&#26399;&#26395;&#25968;&#30446;&#30340;&#21512;&#26684;&#20505;&#36873;&#20154;&#30340;&#26368;&#23567;&#38598;&#21512;&#12290;&#36825;&#25903;&#25345;&#23558;&#26657;&#20934;&#20316;&#20026;&#31579;&#36873;&#20998;&#31867;&#22120;&#30340;&#21807;&#19968;&#35201;&#27714;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#20351;&#29992;&#26657;&#20934;&#30340;&#20998;&#31867;&#22120;&#30340;&#31579;&#36873;&#31574;&#30053;&#21487;&#33021;&#23384;&#22312;&#19968;&#31181;&#40092;&#20026;&#20154;&#30693;&#30340;&#32452;&#20869;&#19981;&#20844;&#24179;&#31867;&#22411;&#8212;&#8212;&#23427;&#20204;&#21487;&#33021;&#19981;&#20844;&#24179;&#22320;&#23545;&#24453;&#24863;&#20852;&#36259;&#30340;&#20154;&#21475;&#32676;&#20307;&#20013;&#30340;&#21512;&#26684;&#25104;&#21592;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35748;&#20026;&#22914;&#26524;&#20998;&#31867;&#22120;&#28385;&#36275;&#32452;&#20869;&#21333;&#35843;&#24615;&#65292;&#36825;&#31181;&#19981;&#20844;&#24179;&#24615;&#21487;&#20197;&#36991;&#20813;&#65292;&#32452;&#20869;&#21333;&#35843;&#24615;&#26159;&#27599;&#20010;&#32676;&#20307;&#20869;&#30340;&#19968;&#31181;&#33258;&#28982;&#21333;&#35843;&#24615;&#23646;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#39640;&#25928;&#21518;&#22788;&#29702;&#31639;&#27861;&#65292;&#21487;&#20197;&#26368;&#23567;&#21270;&#20462;&#25913;&#32473;&#23450;&#30340;&#26657;&#20934;&#20998;&#31867;&#22120;&#65292;&#20197;&#20415;&#20854;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Screening classifiers are increasingly used to identify qualified candidates in a variety of selection processes. In this context, it has been recently shown that, if a classifier is calibrated, one can identify the smallest set of candidates which contains, in expectation, a desired number of qualified candidates using a threshold decision rule. This lends support to focusing on calibration as the only requirement for screening classifiers. In this paper, we argue that screening policies that use calibrated classifiers may suffer from an understudied type of within-group unfairness -- they may unfairly treat qualified members within demographic groups of interest. Further, we argue that this type of unfairness can be avoided if classifiers satisfy within-group monotonicity, a natural monotonicity property within each of the groups. Then, we introduce an efficient post-processing algorithm based on dynamic programming to minimally modify a given calibrated classifier so that its probab
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20999;&#29255;&#30340;&#26041;&#24335;&#23450;&#20041;&#20102;&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#36317;&#31163;&#12290;</title><link>http://arxiv.org/abs/2212.08049</link><description>&lt;p&gt;
&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;
&lt;/p&gt;
&lt;p&gt;
Sliced Optimal Partial Transport. (arXiv:2212.08049v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08049
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20999;&#29255;&#30340;&#26041;&#24335;&#23450;&#20041;&#20102;&#20999;&#29255;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#24050;&#32463;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#25968;&#25454;&#31185;&#23398;&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#21464;&#24471;&#26497;&#20854;&#27969;&#34892;&#12290;OT&#38382;&#39064;&#30340;&#26680;&#24515;&#20551;&#35774;&#26159;&#28304;&#21644;&#30446;&#26631;&#27979;&#24230;&#30340;&#24635;&#36136;&#37327;&#30456;&#31561;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#30340;&#24212;&#29992;&#12290;&#26368;&#20248;&#20559;&#36716;&#36816;&#36755;&#65288;OPT&#65289;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#30340;&#26041;&#27861;&#12290;&#19982;OT&#38382;&#39064;&#31867;&#20284;&#65292;OPT&#30340;&#35745;&#31639;&#20381;&#36182;&#20110;&#35299;&#20915;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#65288;&#36890;&#24120;&#22312;&#39640;&#32500;&#24230;&#20013;&#65289;&#65292;&#36825;&#21487;&#33021;&#20250;&#21464;&#24471;&#35745;&#31639;&#19978;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19968;&#32500;&#38750;&#36127;&#27979;&#24230;&#20043;&#38388;OPT&#38382;&#39064;&#30340;&#26377;&#25928;&#31639;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#36981;&#24490;&#20999;&#29255;OT&#36317;&#31163;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#21033;&#29992;&#20999;&#29255;&#23450;&#20041;&#20102;&#20999;&#29255;OPT&#36317;&#31163;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20999;&#29255;OPT-based&#26041;&#27861;&#22312;&#21508;&#31181;&#25968;&#20540;&#23454;&#39564;&#20013;&#30340;&#35745;&#31639;&#21644;&#31934;&#24230;&#20248;&#21183;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;Sliced-OPT&#22312;&#22122;&#22768;&#28857;&#20113;&#37197;&#20934;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal transport (OT) has become exceedingly popular in machine learning, data science, and computer vision. The core assumption in the OT problem is the equal total amount of mass in source and target measures, which limits its application. Optimal Partial Transport (OPT) is a recently proposed solution to this limitation. Similar to the OT problem, the computation of OPT relies on solving a linear programming problem (often in high dimensions), which can become computationally prohibitive. In this paper, we propose an efficient algorithm for calculating the OPT problem between two non-negative measures in one dimension. Next, following the idea of sliced OT distances, we utilize slicing to define the sliced OPT distance. Finally, we demonstrate the computational and accuracy benefits of the sliced OPT-based method in various numerical experiments. In particular, we show an application of our proposed Sliced-OPT in noisy point cloud registration.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#20013;&#20351;&#29992;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#23545;&#22823;&#22411;&#25237;&#36164;&#32452;&#21512;&#20013;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#36866;&#29992;&#20110;&#37329;&#34701;&#24066;&#22330;&#20856;&#22411;&#30340;&#20302;&#20449;&#22122;&#27604;&#29615;&#22659;&#65292;&#36824;&#19982;&#24369;&#22240;&#23376;&#20860;&#23481;&#65292;&#24182;&#19988;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#19968;&#33268;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#12290;&#27169;&#25311;&#21644;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.04512</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#20013;&#30340;&#27531;&#24046;&#65306;&#20302;&#20449;&#22122;&#27604;&#19979;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Deep Learning Based Residuals in Non-linear Factor Models: Precision Matrix Estimation of Returns with Low Signal-to-Noise Ratio. (arXiv:2209.04512v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#20013;&#20351;&#29992;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#23545;&#22823;&#22411;&#25237;&#36164;&#32452;&#21512;&#20013;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#36866;&#29992;&#20110;&#37329;&#34701;&#24066;&#22330;&#20856;&#22411;&#30340;&#20302;&#20449;&#22122;&#27604;&#29615;&#22659;&#65292;&#36824;&#19982;&#24369;&#22240;&#23376;&#20860;&#23481;&#65292;&#24182;&#19988;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#30028;&#38480;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22522;&#20110;&#25968;&#25454;&#30340;&#19968;&#33268;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#12290;&#27169;&#25311;&#21644;&#23454;&#35777;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22312;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#20013;&#20351;&#29992;&#38750;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#23545;&#22823;&#22411;&#25237;&#36164;&#32452;&#21512;&#20013;&#36164;&#20135;&#22238;&#25253;&#30340;&#31934;&#30830;&#30697;&#38453;&#36827;&#34892;&#19968;&#33268;&#20272;&#35745;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#26041;&#27861;&#21363;&#20351;&#22312;&#37329;&#34701;&#24066;&#22330;&#20856;&#22411;&#30340;&#20449;&#22122;&#27604;&#20302;&#30340;&#29615;&#22659;&#20013;&#20173;&#28982;&#26377;&#25928;&#65292;&#24182;&#19988;&#19982;&#24369;&#22240;&#23376;&#20860;&#23481;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#23545;&#20110;&#19981;&#26029;&#22686;&#21152;&#30340;&#36164;&#20135;&#25968;&#37327;&#65292;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#26399;&#20272;&#35745;&#39118;&#38505;&#24314;&#31435;&#20102;&#32479;&#19968;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#19968;&#33268;&#35823;&#24046;&#21327;&#26041;&#24046;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#24191;&#27867;&#30340;&#27169;&#25311;&#21644;&#23454;&#35777;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a consistent estimator and rate of convergence for the precision matrix of asset returns in large portfolios using a non-linear factor model within the deep learning framework. Our estimator remains valid even in low signal-to-noise ratio environments typical for financial markets and is compatible with weak factors. Our theoretical analysis establishes uniform bounds on expected estimation risk based on deep neural networks for an expanding number of assets. Additionally, we provide a new consistent data-dependent estimator of error covariance in deep neural networks. Our models demonstrate superior accuracy in extensive simulations and the empirics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#25512;&#29702;&#27169;&#22411;&#36873;&#25321;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#26435;&#34913;&#12290;&#22312;&#39640;&#26031;&#25512;&#29702;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#20302;&#31209;&#25512;&#26029;&#27169;&#22411;&#22312;&#22266;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#20135;&#29983;&#20102;&#26356;&#39640;&#30340;&#32479;&#35745;&#36817;&#20284;&#35823;&#24046;&#65292;&#20294;&#36739;&#20302;&#30340;&#35745;&#31639;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2207.11208</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#26435;&#34913;&#65306;&#25512;&#29702;&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Statistical and Computational Trade-offs in Variational Inference: A Case Study in Inferential Model Selection. (arXiv:2207.11208v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#25512;&#29702;&#27169;&#22411;&#36873;&#25321;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#26435;&#34913;&#12290;&#22312;&#39640;&#26031;&#25512;&#29702;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#20302;&#31209;&#25512;&#26029;&#27169;&#22411;&#22312;&#22266;&#23450;&#35745;&#31639;&#39044;&#31639;&#19979;&#20135;&#29983;&#20102;&#26356;&#39640;&#30340;&#32479;&#35745;&#36817;&#20284;&#35823;&#24046;&#65292;&#20294;&#36739;&#20302;&#30340;&#35745;&#31639;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#26368;&#36817;&#22312;&#22823;&#35268;&#27169;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#25104;&#20026;&#20102;&#20256;&#32479;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;(MCMC)&#30340;&#28909;&#38376;&#26367;&#20195;&#26041;&#27861;&#12290;&#20854;&#26680;&#24515;&#24605;&#24819;&#26159;&#36890;&#36807;&#26435;&#34913;&#32479;&#35745;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;&#26412;&#25991;&#36890;&#36807;&#19968;&#20010;&#25512;&#29702;&#27169;&#22411;&#36873;&#25321;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#30740;&#31350;&#20102;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#26435;&#34913;&#12290;&#25105;&#20204;&#30528;&#37325;&#30740;&#31350;&#20102;&#20855;&#26377;&#23545;&#35282;&#21152;&#20302;&#31209;&#31934;&#24230;&#30697;&#38453;&#30340;&#39640;&#26031;&#25512;&#29702;&#27169;&#22411;&#65288;&#25110;&#21464;&#20998;&#36924;&#36817;&#23478;&#26063;&#65289;&#20013;&#30340;&#36825;&#31181;&#26435;&#34913;&#30340;&#20004;&#20010;&#26041;&#38754;&#65306;&#36125;&#21494;&#26031;&#21518;&#39564;&#25512;&#26029;&#35823;&#24046;&#21644;&#39057;&#29575;&#20027;&#20041;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#35823;&#24046;&#12290;&#20174;&#36125;&#21494;&#26031;&#21518;&#39564;&#25512;&#26029;&#30340;&#35282;&#24230;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#21464;&#20998;&#21518;&#39564;&#30456;&#23545;&#20110;&#31934;&#30830;&#21518;&#39564;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#22266;&#23450;&#30340;&#35745;&#31639;&#39044;&#31639;&#19979;&#65292;&#20302;&#31209;&#25512;&#26029;&#27169;&#22411;&#20135;&#29983;&#20855;&#26377;&#26356;&#39640;&#32479;&#35745;&#36924;&#36817;&#35823;&#24046;&#20294;&#26356;&#20302;&#35745;&#31639;&#35823;&#24046;&#30340;&#21464;&#20998;&#21518;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference has recently emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference. The core idea is to trade statistical accuracy for computational efficiency. In this work, we study these statistical and computational trade-offs in variational inference via a case study in inferential model selection. Focusing on Gaussian inferential models (or variational approximating families) with diagonal plus low-rank precision matrices, we initiate a theoretical study of the trade-offs in two aspects, Bayesian posterior inference error and frequentist uncertainty quantification error. From the Bayesian posterior inference perspective, we characterize the error of the variational posterior relative to the exact posterior. We prove that, given a fixed computation budget, a lower-rank inferential model produces variational posteriors with a higher statistical approximation error, but a lower computational error; it reduces varian
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#34920;&#26684;&#27169;&#22411;&#30340;&#36801;&#31227;&#23398;&#20064;&#22312;&#21307;&#23398;&#35786;&#26029;&#31561;&#39046;&#22495;&#23637;&#29616;&#20986;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#24212;&#23545;&#19978;&#19979;&#28216;&#29305;&#24449;&#38598;&#19981;&#21516;&#24773;&#20917;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.15306</link><description>&lt;p&gt;
&#28145;&#24230;&#34920;&#26684;&#27169;&#22411;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning with Deep Tabular Models. (arXiv:2206.15306v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.15306
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#34920;&#26684;&#27169;&#22411;&#30340;&#36801;&#31227;&#23398;&#20064;&#22312;&#21307;&#23398;&#35786;&#26029;&#31561;&#39046;&#22495;&#23637;&#29616;&#20986;&#20102;&#27604;&#20256;&#32479;&#26041;&#27861;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#24212;&#23545;&#19978;&#19979;&#28216;&#29305;&#24449;&#38598;&#19981;&#21516;&#24773;&#20917;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#20851;&#20110;&#28145;&#24230;&#23398;&#20064;&#29992;&#20110;&#34920;&#26684;&#25968;&#25454;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#28145;&#24230;&#34920;&#26684;&#27169;&#22411;&#23637;&#29616;&#20102;&#24378;&#22823;&#30340;&#24615;&#33021;&#65292;&#36890;&#24120;&#22635;&#34917;&#20102;&#26799;&#24230;&#25552;&#21319;&#20915;&#31574;&#26641;&#21644;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#38500;&#20102;&#20934;&#30830;&#24615;&#20043;&#22806;&#65292;&#31070;&#32463;&#27169;&#22411;&#30340;&#19968;&#20010;&#20027;&#35201;&#20248;&#21183;&#26159;&#23427;&#20204;&#23398;&#20064;&#20102;&#21487;&#37325;&#22797;&#20351;&#29992;&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#22312;&#26032;&#39046;&#22495;&#20013;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#36827;&#34892;&#24494;&#35843;&#12290;&#36825;&#31181;&#29305;&#24615;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#24212;&#29992;&#20013;&#32463;&#24120;&#34987;&#21033;&#29992;&#65292;&#23588;&#20854;&#26159;&#22312;&#20219;&#21153;&#29305;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#26102;&#65292;&#36801;&#31227;&#23398;&#20064;&#21464;&#24471;&#19981;&#21487;&#25110;&#32570;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19978;&#28216;&#25968;&#25454;&#20026;&#34920;&#26684;&#31070;&#32463;&#32593;&#32476;&#24102;&#26469;&#20102;&#27604;&#24191;&#27867;&#20351;&#29992;&#30340;GBDT&#27169;&#22411;&#26356;&#20855;&#20915;&#23450;&#24615;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#34920;&#26684;&#36801;&#31227;&#23398;&#20064;&#30340;&#29616;&#23454;&#21307;&#23398;&#35786;&#26029;&#22522;&#20934;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20221;&#20351;&#29992;&#19978;&#28216;&#25968;&#25454;&#25552;&#39640;&#21508;&#31181;&#34920;&#26684;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#24615;&#33021;&#30340;&#25351;&#21335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20266;&#29305;&#24449;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#19978;&#28216;&#21644;&#19979;&#28216;&#29305;&#24449;&#38598;&#19981;&#21516;&#30340;&#24773;&#20917;&#65292;&#36825;&#26159;&#29616;&#23454;&#19990;&#30028;&#20013;&#24191;&#27867;&#23384;&#22312;&#30340;&#34920;&#26684;&#29305;&#23450;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work on deep learning for tabular data demonstrates the strong performance of deep tabular models, often bridging the gap between gradient boosted decision trees and neural networks. Accuracy aside, a major advantage of neural models is that they learn reusable features and are easily fine-tuned in new domains. This property is often exploited in computer vision and natural language applications, where transfer learning is indispensable when task-specific training data is scarce. In this work, we demonstrate that upstream data gives tabular neural networks a decisive advantage over widely used GBDT models. We propose a realistic medical diagnosis benchmark for tabular transfer learning, and we present a how-to guide for using upstream data to boost performance with a variety of tabular neural network architectures. Finally, we propose a pseudo-feature method for cases where the upstream and downstream feature sets differ, a tabular-specific problem widespread in real-world appli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Hessian-based&#20998;&#26512;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#27867;&#21270;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#29702;&#35299;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24494;&#35843;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#65292;&#32473;&#20986;&#20102;&#22522;&#20110;Hessian&#36317;&#31163;&#30340;&#24494;&#35843;&#27169;&#22411;&#27867;&#21270;&#30028;&#12290;&#27492;&#22806;&#65292;&#36824;&#23545;&#24494;&#35843;&#38754;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20851;&#31639;&#27861;&#21644;&#27867;&#21270;&#35823;&#24046;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2206.02659</link><description>&lt;p&gt;
&#20855;&#26377;&#22522;&#20110;Hessian&#30340;&#27867;&#21270;&#20445;&#35777;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#40065;&#26834;&#24494;&#35843;
&lt;/p&gt;
&lt;p&gt;
Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees. (arXiv:2206.02659v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02659
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Hessian-based&#20998;&#26512;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#36317;&#31163;&#30340;&#27867;&#21270;&#24230;&#37327;&#26041;&#27861;&#65292;&#29992;&#20110;&#29702;&#35299;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24494;&#35843;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#65292;&#32473;&#20986;&#20102;&#22522;&#20110;Hessian&#36317;&#31163;&#30340;&#24494;&#35843;&#27169;&#22411;&#27867;&#21270;&#30028;&#12290;&#27492;&#22806;&#65292;&#36824;&#23545;&#24494;&#35843;&#38754;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#30456;&#20851;&#31639;&#27861;&#21644;&#27867;&#21270;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#30446;&#26631;&#20219;&#21153;&#19978;&#23545;&#39044;&#35757;&#32451;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24494;&#35843;&#12290;&#25105;&#20204;&#30740;&#31350;&#24494;&#35843;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#20197;&#29702;&#35299;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#36825;&#22312;&#30446;&#26631;&#25968;&#25454;&#38598;&#36739;&#23567;&#25110;&#35757;&#32451;&#26631;&#31614;&#22122;&#22768;&#26102;&#32463;&#24120;&#35266;&#23519;&#21040;&#12290;&#29616;&#26377;&#30340;&#28145;&#24230;&#32593;&#32476;&#27867;&#21270;&#24230;&#37327;&#20381;&#36182;&#20110;&#19982;&#24494;&#35843;&#27169;&#22411;&#30340;&#21021;&#22987;&#21270;&#65288;&#21363;&#39044;&#35757;&#32451;&#32593;&#32476;&#65289;&#36317;&#31163;&#21644;&#28145;&#24230;&#32593;&#32476;&#30340;&#22122;&#22768;&#31283;&#23450;&#24615;&#31561;&#27010;&#24565;&#12290;&#26412;&#25991;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#30830;&#23450;&#20102;&#19968;&#31181;&#22522;&#20110;Hessian&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#23427;&#19982;&#24494;&#35843;&#27169;&#22411;&#30340;&#35266;&#23519;&#21040;&#30340;&#27867;&#21270;&#24046;&#36317;&#30456;&#20851;&#24615;&#24456;&#24378;&#12290;&#20174;&#29702;&#35770;&#19978;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;Hessian&#36317;&#31163;&#30340;&#24494;&#35843;&#27169;&#22411;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#36824;&#23545;&#24494;&#35843;&#23545;&#25239;&#26631;&#31614;&#22122;&#22768;&#36827;&#34892;&#20102;&#25193;&#23637;&#30740;&#31350;&#65292;&#36807;&#25311;&#21512;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65307;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#24182;&#22312;&#31867;&#26465;&#20214;&#29420;&#31435;&#20551;&#35774;&#19979;&#32473;&#20986;&#20102;&#35813;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider fine-tuning a pretrained deep neural network on a target task. We study the generalization properties of fine-tuning to understand the problem of overfitting, which has often been observed (e.g., when the target dataset is small or when the training labels are noisy). Existing generalization measures for deep networks depend on notions such as distance from the initialization (i.e., the pretrained network) of the fine-tuned model and noise stability properties of deep networks. This paper identifies a Hessian-based distance measure through PAC-Bayesian analysis, which is shown to correlate well with observed generalization gaps of fine-tuned models. Theoretically, we prove Hessian distance-based generalization bounds for fine-tuned models. We also describe an extended study of fine-tuning against label noise, where overfitting is against a critical problem; We present an algorithm and a generalization error guarantee for this algorithm under a class conditional independent 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#25345;&#32493;&#21516;&#35843;&#20998;&#26512;&#22797;&#26434;&#36807;&#28193;&#32593;&#32476;&#65292;&#21457;&#29616;&#31895;&#31890;&#21270;&#29366;&#24577;&#31354;&#38388;&#32593;&#32476;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#24213;&#23618;&#21160;&#24577;&#31995;&#32479;&#30340;&#20016;&#23500;&#20449;&#24687;&#65292;&#25552;&#39640;&#21160;&#24577;&#29366;&#24577;&#26816;&#27979;&#21644;&#22122;&#22768;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.02530</link><description>&lt;p&gt;
&#31895;&#31890;&#21270;&#29366;&#24577;&#31354;&#38388;&#32593;&#32476;&#30340;&#25345;&#32493;&#21516;&#35843;
&lt;/p&gt;
&lt;p&gt;
Persistent Homology of Coarse Grained State Space Networks. (arXiv:2206.02530v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#25345;&#32493;&#21516;&#35843;&#20998;&#26512;&#22797;&#26434;&#36807;&#28193;&#32593;&#32476;&#65292;&#21457;&#29616;&#31895;&#31890;&#21270;&#29366;&#24577;&#31354;&#38388;&#32593;&#32476;&#33021;&#22815;&#26356;&#22909;&#22320;&#25429;&#25417;&#24213;&#23618;&#21160;&#24577;&#31995;&#32479;&#30340;&#20016;&#23500;&#20449;&#24687;&#65292;&#25552;&#39640;&#21160;&#24577;&#29366;&#24577;&#26816;&#27979;&#21644;&#22122;&#22768;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#33268;&#21147;&#20110;&#23545;&#21160;&#24577;&#29366;&#24577;&#26816;&#27979;&#30340;&#22797;&#26434;&#36807;&#28193;&#32593;&#32476;&#36827;&#34892;&#25299;&#25169;&#20998;&#26512;&#12290;&#36807;&#28193;&#32593;&#32476;&#30001;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26500;&#25104;&#65292;&#24182;&#21033;&#29992;&#22270;&#35770;&#24037;&#20855;&#25581;&#31034;&#24213;&#23618;&#21160;&#24577;&#31995;&#32479;&#30340;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#24037;&#20855;&#22312;&#24635;&#32467;&#36825;&#31181;&#22270;&#20013;&#30340;&#22797;&#26434;&#25299;&#25169;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#25345;&#32493;&#21516;&#35843;&#26469;&#30740;&#31350;&#36825;&#20123;&#32593;&#32476;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#23558;&#20351;&#29992;&#31895;&#31890;&#21270;&#29366;&#24577;&#31354;&#38388;&#32593;&#32476;&#65288;CGSSN&#65289;&#21644;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#65288;TDA&#65289;&#23545;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#21160;&#24577;&#29366;&#24577;&#26816;&#27979;&#19982;&#20004;&#31181;&#20808;&#36827;&#26041;&#27861;&#36827;&#34892;&#23545;&#27604;&#65306;&#20351;&#29992;TDA&#32467;&#21512;&#24207;&#25968;&#20998;&#21306;&#32593;&#32476;&#65288;OPNs&#65289;&#21644;&#23558;&#25345;&#32493;&#21516;&#35843;&#26631;&#20934;&#24212;&#29992;&#20110;&#20449;&#21495;&#30340;&#26102;&#28382;&#23884;&#20837;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;CGSSN&#25429;&#25417;&#21040;&#24213;&#23618;&#21160;&#24577;&#31995;&#32479;&#30340;&#20016;&#23500;&#20449;&#24687;&#65292;&#34920;&#29616;&#20026;&#21160;&#24577;&#29366;&#24577;&#26816;&#27979;&#21644;&#22122;&#22768;&#40065;&#26834;&#24615;&#26174;&#33879;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work is dedicated to the topological analysis of complex transitional networks for dynamic state detection. Transitional networks are formed from time series data and they leverage graph theory tools to reveal information about the underlying dynamic system. However, traditional tools can fail to summarize the complex topology present in such graphs. In this work, we leverage persistent homology from topological data analysis to study the structure of these networks. We contrast dynamic state detection from time series using a coarse-grained state-space network (CGSSN) and topological data analysis (TDA) to two state of the art approaches: ordinal partition networks (OPNs) combined with TDA and the standard application of persistent homology to the time-delay embedding of the signal. We show that the CGSSN captures rich information about the dynamic state of the underlying dynamical system as evidenced by a significant improvement in dynamic state detection and noise robustness in
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#22312;&#20855;&#26377;&#26725;&#24809;&#32602;&#30340;&#22238;&#24402;&#27169;&#22411;&#19978;&#30340;&#24212;&#29992;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#23567;&#25209;&#37327;&#25968;&#25454;&#24182;&#25552;&#20379;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#32467;&#26524;&#26469;&#21152;&#36895;&#35745;&#31639;&#26102;&#38388;&#12290;&#36890;&#36807;&#22312;B&#26679;&#26465;&#38750;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#19978;&#36827;&#34892;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.09515</link><description>&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#29992;&#20110;&#36125;&#21494;&#26031;&#26725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Variational Inference for Bayesian Bridge Regression. (arXiv:2205.09515v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.09515
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#22312;&#20855;&#26377;&#26725;&#24809;&#32602;&#30340;&#22238;&#24402;&#27169;&#22411;&#19978;&#30340;&#24212;&#29992;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#23567;&#25209;&#37327;&#25968;&#25454;&#24182;&#25552;&#20379;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#32467;&#26524;&#26469;&#21152;&#36895;&#35745;&#31639;&#26102;&#38388;&#12290;&#36890;&#36807;&#22312;B&#26679;&#26465;&#38750;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#19978;&#36827;&#34892;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#22312;&#20855;&#26377;&#26725;&#24809;&#32602;&#30340;&#22238;&#24402;&#27169;&#22411;&#19978;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#23454;&#29616;&#12290;&#26725;&#26041;&#27861;&#20351;&#29992;$\ell_{\alpha}$&#33539;&#25968;&#65292;&#20854;&#20013;$\alpha \in (0, +\infty)$&#65292;&#23545;&#22238;&#24402;&#31995;&#25968;&#30340;&#22823;&#20540;&#36827;&#34892;&#24809;&#32602;&#65292;&#21253;&#25324;Lasso ($\alpha = 1$)&#21644;&#23725;&#22238;&#24402;$(\alpha = 2)$&#24809;&#32602;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#12290;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#26080;&#32541;&#22320;&#25552;&#20379;&#20102;&#25152;&#26377;&#27169;&#22411;&#21442;&#25968;&#30340;&#32852;&#21512;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#23613;&#31649;&#26725;&#22238;&#24402;&#30340;MCMC&#26041;&#27861;&#21487;&#29992;&#65292;&#20294;&#23545;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#21487;&#33021;&#36739;&#24930;&#12290;ADVI&#23454;&#29616;&#20801;&#35768;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20351;&#29992;&#23567;&#25209;&#37327;&#25968;&#25454;&#65288;&#30001;&#20110;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#31639;&#27861;&#65289;&#65292;&#20174;&#32780;&#21152;&#36895;&#35745;&#31639;&#26102;&#38388;&#19982;MCMC&#30456;&#27604;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;B&#26679;&#26465;&#38750;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#36827;&#34892;&#20102;&#26041;&#27861;&#35828;&#26126;&#65292;&#23613;&#31649;&#35813;&#26041;&#27861;&#23545;&#20110;&#20854;&#20182;&#22522;&#30784;&#20989;&#25968;&#30340;&#36873;&#25321;&#20063;&#21487;&#20197;&#26080;&#32541;&#20351;&#29992;&#12290;&#27169;&#25311;&#30740;&#31350;&#35828;&#26126;&#20102;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the implementation of Automatic Differentiation Variational inference (ADVI) for Bayesian inference on regression models with bridge penalization. The bridge approach uses $\ell_{\alpha}$ norm, with $\alpha \in (0, +\infty)$ to define a penalization on large values of the regression coefficients, which includes the Lasso ($\alpha = 1$) and ridge $(\alpha = 2)$ penalizations as special cases. Full Bayesian inference seamlessly provides joint uncertainty estimates for all model parameters. Although MCMC aproaches are available for bridge regression, it can be slow for large dataset, specially in high dimensions. The ADVI implementation allows the use of small batches of data at each iteration (due to stochastic gradient based algorithms), therefore speeding up computational time in comparison with MCMC. We illustrate the approach on non-parametric regression models with B-splines, although the method works seamlessly for other choices of basis functions. A simulation study shows
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#26680;&#26041;&#27861;&#26500;&#36896;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#21644;Neyman-Pearson&#35774;&#32622;&#20013;&#20998;&#21035;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#38169;&#35823;&#27010;&#29575;&#21644;&#25511;&#21046;&#38169;&#35823;&#27010;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;MMD&#30340;&#19968;&#31995;&#21015;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2203.12777</link><description>&lt;p&gt;
&#26680;&#40065;&#26834;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Kernel Robust Hypothesis Testing. (arXiv:2203.12777v2 [eess.SP] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.12777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#26680;&#26041;&#27861;&#26500;&#36896;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#21644;Neyman-Pearson&#35774;&#32622;&#20013;&#20998;&#21035;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#38169;&#35823;&#27010;&#29575;&#21644;&#25511;&#21046;&#38169;&#35823;&#27010;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;MMD&#30340;&#19968;&#31995;&#21015;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#40065;&#26834;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#22312;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#19979;&#65292;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#34987;&#20551;&#35774;&#22312;&#26576;&#20123;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#20013;&#65292;&#24182;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#27979;&#35797;&#65292;&#22312;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#20013;&#34920;&#29616;&#26368;&#20248;&#12290;&#26412;&#25991;&#23558;&#20351;&#29992;&#26680;&#26041;&#27861;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#36896;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#21363;&#20197;&#26469;&#33258;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#24067;&#20026;&#20013;&#24515;&#65292;&#24182;&#36890;&#36807;&#26680;&#22343;&#20540;&#23884;&#20837;&#30340;&#36317;&#31163;&#26469;&#32422;&#26463;&#65292;&#21363;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#65288;MMD&#65289;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#21644;Neyman-Pearson&#35774;&#32622;&#12290;&#23545;&#20110;&#36125;&#21494;&#26031;&#35774;&#32622;&#65292;&#21363;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#65292;&#24403;&#23383;&#27597;&#34920;&#26159;&#26377;&#38480;&#30340;&#26102;&#65292;&#39318;&#20808;&#24471;&#21040;&#20102;&#26368;&#20339;&#27979;&#35797;&#12290;&#24403;&#23383;&#27597;&#34920;&#26159;&#26080;&#38480;&#30340;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#37327;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#12290;&#23545;&#20110;Neyman-Pearson&#35774;&#32622;&#65292;&#21363;&#30446;&#26631;&#26159;&#22312;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#21516;&#26102;&#25511;&#21046;&#22312;&#32473;&#23450;&#27700;&#24179;&#19979;&#30340;&#31532;&#19968;&#31867;&#38169;&#35823;&#27010;&#29575;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;MMD&#30340;&#27979;&#35797;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of robust hypothesis testing is studied, where under the null and the alternative hypotheses, the data-generating distributions are assumed to be in some uncertainty sets, and the goal is to design a test that performs well under the worst-case distributions over the uncertainty sets. In this paper, uncertainty sets are constructed in a data-driven manner using kernel method, i.e., they are centered around empirical distributions of training samples from the null and alternative hypotheses, respectively; and are constrained via the distance between kernel mean embeddings of distributions in the reproducing kernel Hilbert space, i.e., maximum mean discrepancy (MMD). The Bayesian setting and the Neyman-Pearson setting are investigated. For the Bayesian setting where the goal is to minimize the worst-case error probability, an optimal test is firstly obtained when the alphabet is finite. When the alphabet is infinite, a tractable approximation is proposed to quantify the worst
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;KINet&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#23545;&#35937;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36890;&#36807;&#23398;&#20064;&#20851;&#38190;&#28857;&#34920;&#31034;&#21644;&#20851;&#31995;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#33258;&#21160;&#25512;&#24191;&#21040;&#19981;&#21516;&#22330;&#26223;&#20013;&#65292;&#24182;&#25104;&#21151;&#39044;&#27979;&#26410;&#26469;&#30340;&#20851;&#38190;&#28857;&#29366;&#24577;&#12290;</title><link>http://arxiv.org/abs/2202.09006</link><description>&lt;p&gt;
KINet&#65306;&#29992;&#20110;&#26426;&#22120;&#20154;&#25512;&#21160;&#25805;&#20316;&#30340;&#26080;&#30417;&#30563;&#21069;&#21521;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
KINet: Unsupervised Forward Models for Robotic Pushing Manipulation. (arXiv:2202.09006v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09006
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;KINet&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#23545;&#35937;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36890;&#36807;&#23398;&#20064;&#20851;&#38190;&#28857;&#34920;&#31034;&#21644;&#20851;&#31995;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#33258;&#21160;&#25512;&#24191;&#21040;&#19981;&#21516;&#22330;&#26223;&#20013;&#65292;&#24182;&#25104;&#21151;&#39044;&#27979;&#26410;&#26469;&#30340;&#20851;&#38190;&#28857;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#35937;&#20026;&#20013;&#24515;&#30340;&#34920;&#31034;&#26159;&#21069;&#21521;&#39044;&#27979;&#30340;&#37325;&#35201;&#25277;&#35937;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#21069;&#21521;&#27169;&#22411;&#36890;&#36807;&#24191;&#27867;&#30340;&#30417;&#30563;&#23398;&#20064;&#36825;&#31181;&#34920;&#31034;&#65288;&#20363;&#22914;&#23545;&#35937;&#31867;&#21035;&#21644;&#36793;&#30028;&#26694;&#65289;&#65292;&#23613;&#31649;&#22312;&#29616;&#23454;&#20013;&#24456;&#38590;&#33719;&#24471;&#36825;&#26679;&#30340;&#30495;&#23454;&#20449;&#24687;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;KINet&#65288;&#20851;&#38190;&#28857;&#20132;&#20114;&#32593;&#32476;&#65289;--&#19968;&#31181;&#22522;&#20110;&#20851;&#38190;&#28857;&#34920;&#31034;&#30340;&#31471;&#21040;&#31471;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#29992;&#20110;&#25512;&#29702;&#23545;&#35937;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#20351;&#29992;&#35270;&#35273;&#35266;&#27979;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23398;&#20064;&#23558;&#23545;&#35937;&#19982;&#20851;&#38190;&#28857;&#22352;&#26631;&#20851;&#32852;&#36215;&#26469;&#65292;&#24182;&#21457;&#29616;&#31995;&#32479;&#30340;&#22270;&#34920;&#36798;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#32452;&#20851;&#38190;&#28857;&#23884;&#20837;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#23427;&#20351;&#29992;&#23545;&#27604;&#20272;&#35745;&#23398;&#20064;&#19968;&#20010;&#21160;&#20316;&#26465;&#20214;&#30340;&#21069;&#21521;&#27169;&#22411;&#65292;&#20197;&#39044;&#27979;&#26410;&#26469;&#30340;&#20851;&#38190;&#28857;&#29366;&#24577;&#12290;&#36890;&#36807;&#22312;&#20851;&#38190;&#28857;&#31354;&#38388;&#20013;&#23398;&#20064;&#36827;&#34892;&#29289;&#29702;&#25512;&#29702;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#33258;&#21160;&#25512;&#24191;&#21040;&#20855;&#26377;&#19981;&#21516;&#25968;&#37327;&#30340;&#23545;&#35937;&#65292;&#26032;&#39062;&#30340;&#32972;&#26223;&#21644;&#26410;&#35265;&#36807;&#30340;&#23545;&#35937;&#20960;&#20309;&#24418;&#29366;&#30340;&#24773;&#20917;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Object-centric representation is an essential abstraction for forward prediction. Most existing forward models learn this representation through extensive supervision (e.g., object class and bounding box) although such ground-truth information is not readily accessible in reality. To address this, we introduce KINet (Keypoint Interaction Network) -- an end-to-end unsupervised framework to reason about object interactions based on a keypoint representation. Using visual observations, our model learns to associate objects with keypoint coordinates and discovers a graph representation of the system as a set of keypoint embeddings and their relations. It then learns an action-conditioned forward model using contrastive estimation to predict future keypoint states. By learning to perform physical reasoning in the keypoint space, our model automatically generalizes to scenarios with a different number of objects, novel backgrounds, and unseen object geometries. Experiments demonstrate the ef
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25042;&#24816;&#22411;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#20854;&#22312;&#20999;&#25442;&#27425;&#25968;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#19988;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#21576;&#29616;&#20986;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2102.03803</link><description>&lt;p&gt;
&#25042;&#24816;&#22411;&#22312;&#32447;&#20984;&#20248;&#21270;: &#20999;&#25442;&#39044;&#31639;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Lazy OCO: Online Convex Optimization on a Switching Budget. (arXiv:2102.03803v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.03803
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25042;&#24816;&#22411;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#31639;&#27861;&#65292;&#20854;&#22312;&#20999;&#25442;&#27425;&#25968;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#36798;&#21040;&#20102;&#36817;&#20284;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#19988;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#21576;&#29616;&#20986;&#39640;&#25928;&#30340;&#35745;&#31639;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#29609;&#23478;&#22312;T&#36718;&#20013;&#30340;&#26399;&#26395;&#20999;&#25442;&#20915;&#31574;&#19981;&#36229;&#36807;S&#27425;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35299;&#20915;&#20102;&#31163;&#25955;&#20915;&#31574;&#35774;&#32622;&#20013;&#30340;&#31867;&#20284;&#38382;&#39064;&#65292;&#26368;&#36817;&#20063;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#20351;&#29992;&#33258;&#36866;&#24212;&#23545;&#25163;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#24182;&#22312;&#26222;&#36941;&#23384;&#22312;&#30340;&#26080;&#30693;&#35774;&#32622;&#20013;&#25552;&#20986;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20026;&#19968;&#33324;&#20984;&#25439;&#22833;&#24314;&#31435;&#20102;O(T/S)&#30340;&#36951;&#25022;&#19978;&#30028;&#20197;&#21450;&#24378;&#20984;&#25439;&#22833;&#30340;&#36817;&#20284;O(T/S^2)&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#38543;&#26426;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#22312;&#19968;&#33324;&#21644;&#24378;&#20984;&#35774;&#32622;&#20013;&#36951;&#25022;&#20165;&#26377;&#23545;&#25968;&#22240;&#23376;&#30340;&#20056;&#27861;log T&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;log T&#27425;&#20999;&#25442;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34917;&#20805;&#20102;&#19982;&#25105;&#20204;&#32771;&#34385;&#30340;&#19968;&#20123;&#24773;&#20917;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#26469;&#34917;&#20805;&#25105;&#20204;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a variant of online convex optimization where the player is permitted to switch decisions at most $S$ times in expectation throughout $T$ rounds. Similar problems have been addressed in prior work for the discrete decision set setting, and more recently in the continuous setting but only with an adaptive adversary. In this work, we aim to fill the gap and present computationally efficient algorithms in the more prevalent oblivious setting, establishing a regret bound of $O(T/S)$ for general convex losses and $\widetilde O(T/S^2)$ for strongly convex losses. In addition, for stochastic i.i.d.~losses, we present a simple algorithm that performs $\log T$ switches with only a multiplicative $\log T$ factor overhead in its regret in both the general and strongly convex settings. Finally, we complement our algorithms with lower bounds that match our upper bounds in some of the cases we consider.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#23792;&#20540;&#21644;&#26495;&#26465;&#20808;&#39564;&#30340;&#21442;&#25968;&#25193;&#23637;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36125;&#21494;&#26031;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#27491;&#20132;&#24615;&#32422;&#26463;&#38382;&#39064;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#27169;&#25311;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#20854;&#20182;SPCA&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2102.00305</link><description>&lt;p&gt;
&#23792;&#20540;&#21644;&#26495;&#26465;&#36125;&#21494;&#26031;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Spike and slab Bayesian sparse principal component analysis. (arXiv:2102.00305v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.00305
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#23792;&#20540;&#21644;&#26495;&#26465;&#20808;&#39564;&#30340;&#21442;&#25968;&#25193;&#23637;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36125;&#21494;&#26031;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#27491;&#20132;&#24615;&#32422;&#26463;&#38382;&#39064;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#27169;&#25311;&#65292;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#20854;&#20182;SPCA&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;SPCA&#65289;&#26159;&#39640;&#32500;&#25968;&#25454;&#38477;&#32500;&#30340;&#24120;&#29992;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#20173;&#32570;&#20047;&#29702;&#35770;&#19978;&#21512;&#29702;&#19988;&#20855;&#26377;&#33391;&#22909;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#30340;&#36125;&#21494;&#26031;SPCA&#26041;&#27861;&#12290;&#36125;&#21494;&#26031;SPCA&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#36873;&#25321;&#36866;&#24403;&#30340;&#20808;&#39564;&#20998;&#24067;&#29992;&#20110;&#36733;&#33655;&#30697;&#38453;&#65292;&#32771;&#34385;&#21040;&#20027;&#25104;&#20998;&#20043;&#38388;&#30456;&#20114;&#27491;&#20132;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21442;&#25968;&#25193;&#23637;&#22352;&#26631;&#19978;&#21319;&#21464;&#20998;&#25512;&#26029;&#65288;PX-CAVI&#65289;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;&#23792;&#20540;&#21644;&#26495;&#26465;&#20808;&#39564;&#20998;&#24067;&#65292;&#36890;&#36807;&#21442;&#25968;&#25193;&#23637;&#26469;&#22788;&#29702;&#27491;&#20132;&#24615;&#32422;&#26463;&#12290;&#38500;&#20102;&#19982;&#20004;&#31181;&#27969;&#34892;&#30340;SPCA&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;PX-EM&#31639;&#27861;&#20316;&#20026;PX-CAVI&#31639;&#27861;&#30340;EM&#31867;&#27604;&#36827;&#34892;&#27604;&#36739;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#25968;&#20540;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PX-CAVI&#31639;&#27861;&#32988;&#36807;&#36825;&#20123;SPCA&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#24615;&#33021;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#21464;&#20998;&#21518;&#39564;&#25910;&#32553;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse principal component analysis (SPCA) is a popular tool for dimensionality reduction in high-dimensional data. However, there is still a lack of theoretically justified Bayesian SPCA methods that can scale well computationally. One of the major challenges in Bayesian SPCA is selecting an appropriate prior for the loadings matrix, considering that principal components are mutually orthogonal. We propose a novel parameter-expanded coordinate ascent variational inference (PX-CAVI) algorithm. This algorithm utilizes a spike and slab prior, which incorporates parameter expansion to cope with the orthogonality constraint. Besides comparing to two popular SPCA approaches, we introduce the PX-EM algorithm as an EM analogue to the PX-CAVI algorithm for comparison. Through extensive numerical simulations, we demonstrate that the PX-CAVI algorithm outperforms these SPCA approaches, showcasing its superiority in terms of performance. We study the posterior contraction rate of the variational 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#26465;&#20214;&#26399;&#26395;&#31639;&#23376;&#30340;&#32479;&#35745;&#36924;&#36817;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20462;&#25913;&#20854;&#23450;&#20041;&#22495;&#35777;&#26126;&#20102;&#35813;&#31639;&#23376;&#21487;&#20197;&#34987;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#24076;&#23572;&#20271;&#29305;-&#26045;&#23494;&#29305;&#31639;&#23376;&#20219;&#24847;&#22909;&#22320;&#36924;&#36817;&#12290;&#36825;&#20026;&#38750;&#21442;&#25968;&#20272;&#35745;&#25552;&#20379;&#20102;&#19968;&#31181;&#20248;&#20110;&#20256;&#32479;&#21442;&#25968;&#25237;&#24433;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;</title><link>http://arxiv.org/abs/2012.12917</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#36924;&#36817;&#26465;&#20214;&#26399;&#26395;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Nonparametric approximation of conditional expectation operators. (arXiv:2012.12917v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.12917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#26465;&#20214;&#26399;&#26395;&#31639;&#23376;&#30340;&#32479;&#35745;&#36924;&#36817;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20462;&#25913;&#20854;&#23450;&#20041;&#22495;&#35777;&#26126;&#20102;&#35813;&#31639;&#23376;&#21487;&#20197;&#34987;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#24076;&#23572;&#20271;&#29305;-&#26045;&#23494;&#29305;&#31639;&#23376;&#20219;&#24847;&#22909;&#22320;&#36924;&#36817;&#12290;&#36825;&#20026;&#38750;&#21442;&#25968;&#20272;&#35745;&#25552;&#20379;&#20102;&#19968;&#31181;&#20248;&#20110;&#20256;&#32479;&#21442;&#25968;&#25237;&#24433;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;&#26497;&#38480;&#23545;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#20108;&#20803;&#38543;&#26426;&#21464;&#37327;X&#65292;Y&#22312;&#26576;&#20010;&#20108;&#21487;&#25968;&#23616;&#37096;&#32039;&#33268;&#21704;&#26031;&#22810;&#22827;&#31354;&#38388;&#19978;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26368;&#23567;&#20551;&#35774;&#19979;&#23545;&#30001;[Pf](x) := E[ f(Y) | X = x ]&#23450;&#20041;&#30340;L^2&#31639;&#23376;&#30340;&#32479;&#35745;&#36924;&#36817;&#12290;&#36890;&#36807;&#20462;&#25913;&#20854;&#23450;&#20041;&#22495;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;P&#21487;&#20197;&#22312;&#31639;&#23376;&#33539;&#25968;&#19979;&#36890;&#36807;&#22312;&#19968;&#20010;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#20316;&#29992;&#30340;&#24076;&#23572;&#20271;&#29305;-&#26045;&#23494;&#29305;&#31639;&#23376;&#20219;&#24847;&#22909;&#22320;&#36924;&#36817;&#12290;&#36825;&#19968;&#20107;&#23454;&#24847;&#21619;&#30528;&#21363;&#20351;P&#19981;&#26159;&#32039;&#33268;&#30340;&#65292;&#25105;&#20204;&#20063;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#31264;&#23494;&#23376;&#31354;&#38388;&#19978;&#30340;&#26377;&#38480;&#31209;&#31639;&#23376;&#26469;&#32479;&#19968;&#20272;&#35745;P&#12290;&#22312;&#25910;&#25947;&#27169;&#24335;&#26041;&#38754;&#65292;&#36825;&#26679;&#25105;&#20204;&#23601;&#24471;&#21040;&#20102;&#22522;&#20110;&#26680;&#30340;&#25216;&#26415;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#21442;&#25968;&#25237;&#24433;&#26041;&#27861;&#22914;Galerkin&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;&#36825;&#20063;&#20026;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;P&#25910;&#25947;&#21040;&#20102;&#21738;&#31181;&#26497;&#38480;&#23545;&#35937;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#32467;&#26524;&#23545;&#39532;&#23572;&#31185;&#22827;&#36807;&#28193;&#31639;&#23376;&#30340;&#22823;&#23478;&#26063;&#30340;&#35889;&#20998;&#26512;&#25216;&#26415;&#26159;&#29305;&#21035;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given the joint distribution of two random variables $X,Y$ on some second countable locally compact Hausdorff space, we investigate the statistical approximation of the $L^2$-operator defined by $[Pf](x) := \mathbb{E}[ f(Y) \mid X = x ]$ under minimal assumptions. By modifying its domain, we prove that $P$ can be arbitrarily well approximated in operator norm by Hilbert-Schmidt operators acting on a reproducing kernel Hilbert space. This fact allows to estimate $P$ uniformly by finite-rank operators over a dense subspace even when $P$ is not compact. In terms of modes of convergence, we thereby obtain the superiority of kernel-based techniques over classically used parametric projection approaches such as Galerkin methods. This also provides a novel perspective on which limiting object the nonparametric estimate of $P$ converges to. As an application, we show that these results are particularly important for a large family of spectral analysis techniques for Markov transition operators
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#20248;&#21270;&#25551;&#36848;&#20026;&#19968;&#20010;&#36807;&#31243;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#20248;&#21270;&#26041;&#27861;&#23545;&#22797;&#26434;&#29615;&#22659;&#36827;&#34892;&#20248;&#21270;&#24314;&#27169;&#65292;&#24182;&#21462;&#24471;&#20102;&#24341;&#20154;&#27880;&#30446;&#30340;&#25104;&#23601;&#12290;</title><link>http://arxiv.org/abs/1909.05207</link><description>&lt;p&gt;
&#22312;&#32447;&#20984;&#20248;&#21270;&#23548;&#35770;
&lt;/p&gt;
&lt;p&gt;
Introduction to Online Convex Optimization. (arXiv:1909.05207v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1909.05207
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#20248;&#21270;&#25551;&#36848;&#20026;&#19968;&#20010;&#36807;&#31243;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#20248;&#21270;&#26041;&#27861;&#23545;&#22797;&#26434;&#29615;&#22659;&#36827;&#34892;&#20248;&#21270;&#24314;&#27169;&#65292;&#24182;&#21462;&#24471;&#20102;&#24341;&#20154;&#27880;&#30446;&#30340;&#25104;&#23601;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#20248;&#21270;&#25551;&#36848;&#20026;&#19968;&#20010;&#36807;&#31243;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#29615;&#22659;&#22826;&#22797;&#26434;&#65292;&#26080;&#27861;&#24314;&#31435;&#20840;&#38754;&#30340;&#29702;&#35770;&#27169;&#22411;&#24182;&#20351;&#29992;&#32463;&#20856;&#31639;&#27861;&#21644;&#25968;&#23398;&#20248;&#21270;&#12290;&#22240;&#27492;&#65292;&#37319;&#29992;&#19968;&#31181;&#23398;&#20064;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#35266;&#23519;&#21040;&#38382;&#39064;&#30340;&#26356;&#22810;&#26041;&#38754;&#26102;&#36890;&#36807;&#32463;&#39564;&#36827;&#34892;&#23398;&#20064;&#26159;&#24517;&#35201;&#19988;&#26377;&#30410;&#30340;&#12290;&#23558;&#20248;&#21270;&#35270;&#20026;&#19968;&#20010;&#36807;&#31243;&#30340;&#35266;&#28857;&#22312;&#21508;&#20010;&#39046;&#22495;&#21464;&#24471;&#31361;&#20986;&#65292;&#24182;&#22312;&#24314;&#27169;&#21644;&#25104;&#20026;&#25105;&#20204;&#26085;&#24120;&#29983;&#27963;&#19968;&#37096;&#20998;&#30340;&#31995;&#32479;&#20013;&#21462;&#24471;&#20102;&#19968;&#20123;&#24341;&#20154;&#27880;&#30446;&#30340;&#25104;&#23601;&#12290;
&lt;/p&gt;
&lt;p&gt;
This manuscript portrays optimization as a process. In many practical applications the environment is so complex that it is infeasible to lay out a comprehensive theoretical model and use classical algorithmic theory and mathematical optimization. It is necessary as well as beneficial to take a robust approach, by applying an optimization method that learns as one goes along, learning from experience as more aspects of the problem are observed. This view of optimization as a process has become prominent in varied fields and has led to some spectacular success in modeling and systems that are now part of our daily lives.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#29992;&#20110;&#20272;&#35745;&#28040;&#36153;&#32773;&#22312;&#22810;&#20010;&#20135;&#21697;&#31867;&#21035;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#12290;&#25105;&#20204;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#26102;&#21464;&#20135;&#21697;&#23646;&#24615;&#21644;&#20135;&#21697;&#32570;&#36135;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#25913;&#36827;&#20043;&#22788;&#22312;&#20110;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#20559;&#22909;&#30340;&#24322;&#36136;&#24615;&#12290;</title><link>http://arxiv.org/abs/1906.02635</link><description>&lt;p&gt;
&#22312;&#22810;&#20010;&#20135;&#21697;&#31867;&#21035;&#20013;&#36827;&#34892;&#28040;&#36153;&#32773;&#36873;&#25321;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Inference for Consumer Choice Across Many Product Categories. (arXiv:1906.02635v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1906.02635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#29992;&#20110;&#20272;&#35745;&#28040;&#36153;&#32773;&#22312;&#22810;&#20010;&#20135;&#21697;&#31867;&#21035;&#20013;&#30340;&#20559;&#22909;&#36873;&#25321;&#12290;&#25105;&#20204;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#32771;&#34385;&#20102;&#26102;&#21464;&#20135;&#21697;&#23646;&#24615;&#21644;&#20135;&#21697;&#32570;&#36135;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#25913;&#36827;&#20043;&#22788;&#22312;&#20110;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#20559;&#22909;&#30340;&#24322;&#36136;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#31163;&#25955;&#36873;&#25321;&#20013;&#28040;&#36153;&#32773;&#20559;&#22909;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#28040;&#36153;&#32773;&#22312;&#19968;&#20010;&#31867;&#21035;&#20013;&#36873;&#25321;&#33267;&#22810;&#19968;&#20010;&#20135;&#21697;&#65292;&#20294;&#22312;&#22810;&#20010;&#31867;&#21035;&#20013;&#24182;&#34892;&#36873;&#25321;&#12290;&#28040;&#36153;&#32773;&#30340;&#25928;&#29992;&#23545;&#19981;&#21516;&#31867;&#21035;&#26159;&#21487;&#21152;&#24615;&#30340;&#12290;&#22905;&#23545;&#20135;&#21697;&#23646;&#24615;&#30340;&#20559;&#22909;&#20197;&#21450;&#22905;&#23545;&#20215;&#26684;&#30340;&#25935;&#24863;&#24230;&#22312;&#19981;&#21516;&#20135;&#21697;&#38388;&#26377;&#25152;&#21464;&#21270;&#65292;&#24182;&#19988;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#22312;&#20135;&#21697;&#38388;&#26159;&#30456;&#20851;&#30340;&#12290;&#25105;&#20204;&#20511;&#37492;&#20102;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#20851;&#20110;&#27010;&#29575;&#27169;&#22411;&#20013;&#30697;&#38453;&#20998;&#35299;&#30340;&#25216;&#26415;&#65292;&#23558;&#36825;&#20123;&#26041;&#27861;&#25193;&#23637;&#21040;&#32771;&#34385;&#26102;&#21464;&#20135;&#21697;&#23646;&#24615;&#21644;&#20135;&#21697;&#32570;&#36135;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#20351;&#29992;&#21547;&#26377;&#20215;&#26684;&#21464;&#21160;&#25110;&#32570;&#36135;&#20135;&#21697;&#30340;&#30041;&#23384;&#25968;&#25454;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#30456;&#36739;&#20110;&#32771;&#34385;&#27599;&#20010;&#31867;&#21035;&#30340;&#20256;&#32479;&#24314;&#27169;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;&#27169;&#22411;&#30340;&#25913;&#36827;&#20043;&#19968;&#26159;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#20559;&#22909;&#30340;&#24322;&#36136;&#24615;&#65288;&#36890;&#36807;&#36328;&#31867;&#21035;&#27719;&#24635;&#20449;&#24687;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method for estimating consumer preferences among discrete choices, where the consumer chooses at most one product in a category, but selects from multiple categories in parallel. The consumer's utility is additive in the different categories. Her preferences about product attributes as well as her price sensitivity vary across products and are in general correlated across products. We build on techniques from the machine learning literature on probabilistic models of matrix factorization, extending the methods to account for time-varying product attributes and products going out of stock. We evaluate the performance of the model using held-out data from weeks with price changes or out of stock products. We show that our model improves over traditional modeling approaches that consider each category in isolation. One source of the improvement is the ability of the model to accurately estimate heterogeneity in preferences (by pooling information across categories); 
&lt;/p&gt;</description></item></channel></rss>