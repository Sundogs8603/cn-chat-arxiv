<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#21152;&#26435;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#26696;&#65292;&#24182;&#24314;&#31435;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#25552;&#20379;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#22312;&#32447;&#25512;&#29702;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#26041;&#26696;&#65292;&#20855;&#26377;&#26368;&#20248;&#30340;&#32479;&#35745;&#36895;&#24230;&#21644;&#26377;&#21033;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.06915</link><description>&lt;p&gt;
&#21152;&#26435;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;: &#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Weighted Averaged Stochastic Gradient Descent: Asymptotic Normality and Optimality. (arXiv:2307.06915v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#21152;&#26435;&#24179;&#22343;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#26696;&#65292;&#24182;&#24314;&#31435;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#25552;&#20379;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#22312;&#32447;&#25512;&#29702;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#26041;&#26696;&#65292;&#20855;&#26377;&#26368;&#20248;&#30340;&#32479;&#35745;&#36895;&#24230;&#21644;&#26377;&#21033;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26159;&#29616;&#20195;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#31616;&#21333;&#21644;&#26368;&#27969;&#34892;&#30340;&#31639;&#27861;&#20043;&#19968;&#65292;&#30001;&#20110;&#20854;&#35745;&#31639;&#21644;&#20869;&#23384;&#25928;&#29575;&#32780;&#21463;&#21040;&#38738;&#30544;&#12290;&#22312;&#19981;&#21516;&#30340;&#24773;&#22659;&#19979;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#24179;&#22343;&#26041;&#26696;&#26469;&#21152;&#36895;SGD&#30340;&#25910;&#25947;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#19968;&#31181;&#29992;&#20110;SGD&#30340;&#36890;&#29992;&#24179;&#22343;&#26041;&#26696;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31867;&#21152;&#26435;&#24179;&#22343;SGD&#35299;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#28176;&#36817;&#26377;&#25928;&#30340;&#22312;&#32447;&#25512;&#29702;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24179;&#22343;&#26041;&#26696;&#65292;&#23637;&#29616;&#20986;&#26368;&#20248;&#30340;&#32479;&#35745;&#36895;&#24230;&#21644;&#26377;&#21033;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#24615;&#65292;&#20511;&#37492;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#38750;&#28176;&#36817;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#30340;&#26368;&#20248;&#26435;&#37325;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Gradient Descent (SGD) is one of the simplest and most popular algorithms in modern statistical and machine learning due to its computational and memory efficiency. Various averaging schemes have been proposed to accelerate the convergence of SGD in different settings. In this paper, we explore a general averaging scheme for SGD. Specifically, we establish the asymptotic normality of a broad range of weighted averaged SGD solutions and provide asymptotically valid online inference approaches. Furthermore, we propose an adaptive averaging scheme that exhibits both optimal statistical rate and favorable non-asymptotic convergence, drawing insights from the optimal weight for the linear model in terms of non-asymptotic mean squared error (MSE).
&lt;/p&gt;</description></item><item><title>&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#24179;&#31283;&#23398;&#20064;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20462;&#25913;&#27010;&#29575;&#25110;&#22870;&#21169;&#26102;&#38656;&#35201;&#33457;&#36153;&#22823;&#37327;&#30340;&#26102;&#38388;&#26469;&#20445;&#25345;&#20540;&#20989;&#25968;&#30340;&#26368;&#26032;&#29366;&#24577;&#65292;&#24182;&#19988;&#36825;&#20010;&#25361;&#25112;&#19982;&#29366;&#24577;&#25968;&#30446;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2307.06877</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#24378;&#21270;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
The complexity of non-stationary reinforcement learning. (arXiv:2307.06877v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06877
&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#38750;&#24179;&#31283;&#23398;&#20064;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20462;&#25913;&#27010;&#29575;&#25110;&#22870;&#21169;&#26102;&#38656;&#35201;&#33457;&#36153;&#22823;&#37327;&#30340;&#26102;&#38388;&#26469;&#20445;&#25345;&#20540;&#20989;&#25968;&#30340;&#26368;&#26032;&#29366;&#24577;&#65292;&#24182;&#19988;&#36825;&#20010;&#25361;&#25112;&#19982;&#29366;&#24577;&#25968;&#30446;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#24179;&#31283;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#34987;&#35748;&#20026;&#26159;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#22797;&#26434;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#35748;&#20026;&#36825;&#24688;&#22909;&#25429;&#25417;&#21040;&#20102;&#36825;&#20010;&#25361;&#25112;&#65306;&#20462;&#25913;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#20013;&#19968;&#20010;&#29366;&#24577;-&#21160;&#20316;&#23545;&#30340;&#27010;&#29575;&#25110;&#22870;&#21169;&#65292;&#38656;&#35201;&#33457;&#36153;&#20960;&#20046;&#19982;&#29366;&#24577;&#25968;&#30446;&#19968;&#26679;&#22810;&#30340;&#26102;&#38388;&#26469;&#21450;&#26102;&#26356;&#26032;&#20540;&#20989;&#25968;&#65292;&#38500;&#38750;&#24378;&#25351;&#25968;&#26102;&#38388;&#20551;&#35774;(SETH)&#26159;&#38169;&#35823;&#30340;&#65307;SETH&#26159;P&#8800;NP&#29468;&#24819;&#30340;&#24191;&#27867;&#25509;&#21463;&#30340;&#21152;&#24378;&#29256;&#12290;&#38656;&#35201;&#27880;&#24847;&#30340;&#26159;&#65292;&#30446;&#21069;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#29366;&#24577;&#25968;&#30446;&#36890;&#24120;&#26159;&#22825;&#25991;&#25968;&#23383;&#32423;&#21035;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#20165;&#20165;"&#28155;&#21152;"&#19968;&#20010;&#26032;&#30340;&#29366;&#24577;-&#21160;&#20316;&#23545;&#35201;&#23481;&#26131;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of continual learning in the domain of reinforcement learning, often called non-stationary reinforcement learning, has been identified as an important challenge to the application of reinforcement learning. We prove a worst-case complexity result, which we believe captures this challenge: Modifying the probabilities or the reward of a single state-action pair in a reinforcement learning problem requires an amount of time almost as large as the number of states in order to keep the value function up to date, unless the strong exponential time hypothesis (SETH) is false; SETH is a widely accepted strengthening of the P $\neq$ NP conjecture. Recall that the number of states in current applications of reinforcement learning is typically astronomical. In contrast, we show that just $\textit{adding}$ a new state-action pair is considerably easier to implement.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25512;&#24191;&#20102;&#29926;&#22622;&#23572;&#26364;&#21644;&#21345;&#20195;&#32435;&#30340;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23450;&#29702;&#29992;&#20110;&#22788;&#29702;&#19982;&#20284;&#28982;&#20989;&#25968;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#32467;&#26524;&#23545;&#20110;&#24037;&#31243;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.06831</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23450;&#29702;&#29992;&#20110;&#19978;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
A Novel Bayes' Theorem for Upper Probabilities. (arXiv:2307.06831v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06831
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#24191;&#20102;&#29926;&#22622;&#23572;&#26364;&#21644;&#21345;&#20195;&#32435;&#30340;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23450;&#29702;&#29992;&#20110;&#22788;&#29702;&#19982;&#20284;&#28982;&#20989;&#25968;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#32467;&#26524;&#23545;&#20110;&#24037;&#31243;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20182;&#20204;1990&#24180;&#30340;&#24320;&#21019;&#24615;&#35770;&#25991;&#20013;&#65292;&#29926;&#22622;&#23572;&#26364;&#21644;&#21345;&#20195;&#32435;&#24314;&#31435;&#20102;&#22312;&#20808;&#39564;&#27010;&#29575;&#20301;&#20110;&#27010;&#29575;&#31867;&#21035;P&#65292;&#19988;&#20284;&#28982;&#20989;&#25968;&#26159;&#31934;&#30830;&#20989;&#25968;&#26102;&#65292;&#21487;&#27979;&#38598;A&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#27010;&#29575;&#30340;&#19978;&#38480;&#12290;&#20182;&#20204;&#36824;&#32473;&#20986;&#20102;&#36825;&#31181;&#19978;&#38480;&#25104;&#31435;&#26102;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#39069;&#22806;&#22788;&#29702;&#19982;&#20284;&#28982;&#20989;&#25968;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#24341;&#20837;&#20182;&#20204;&#32467;&#26524;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#24403;&#20808;&#39564;&#27010;&#29575;&#21644;&#20284;&#28982;&#20989;&#25968;&#37117;&#23646;&#20110;&#19968;&#32452;&#27010;&#29575;&#26102;&#30340;&#21518;&#39564;&#27010;&#29575;&#19978;&#38480;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#36825;&#31181;&#19978;&#38480;&#25104;&#20026;&#31561;&#24335;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20010;&#32467;&#26524;&#26412;&#36523;&#24456;&#26377;&#36259;&#65292;&#24182;&#19988;&#26377;&#21487;&#33021;&#24212;&#29992;&#20110;&#24037;&#31243;&#39046;&#22495;&#65288;&#20363;&#22914;&#27169;&#22411;&#39044;&#27979;&#25511;&#21046;&#65289;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In their seminal 1990 paper, Wasserman and Kadane establish an upper bound for the Bayes' posterior probability of a measurable set $A$, when the prior lies in a class of probability measures $\mathcal{P}$ and the likelihood is precise. They also give a sufficient condition for such upper bound to hold with equality. In this paper, we introduce a generalization of their result by additionally addressing uncertainty related to the likelihood. We give an upper bound for the posterior probability when both the prior and the likelihood belong to a set of probabilities. Furthermore, we give a sufficient condition for this upper bound to become an equality. This result is interesting on its own, and has the potential of being applied to various fields of engineering (e.g. model predictive control), machine learning, and artificial intelligence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;Cramer&#36317;&#31163;&#65292;&#35813;&#36317;&#31163;&#20989;&#25968;&#22312;&#22810;&#20803;&#24773;&#20917;&#19979;&#20855;&#26377;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#19988;&#26131;&#20110;&#35745;&#31639;&#21644;&#23454;&#29616;&#65292;&#24182;&#22312;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2307.06753</link><description>&lt;p&gt;
&#29992;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;Cramer&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Cramer Type Distances for Learning Gaussian Mixture Models by Gradient Descent. (arXiv:2307.06753v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06753
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;Cramer&#36317;&#31163;&#65292;&#35813;&#36317;&#31163;&#20989;&#25968;&#22312;&#22810;&#20803;&#24773;&#20917;&#19979;&#20855;&#26377;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#19988;&#26131;&#20110;&#35745;&#31639;&#21644;&#23454;&#29616;&#65292;&#24182;&#22312;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#23398;&#20064;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20197;&#20854;&#34920;&#36798;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#32780;&#38395;&#21517;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#32479;&#35745;&#23398;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#20026;&#27490;&#65292;&#24456;&#23569;&#26377;&#24050;&#30693;&#31639;&#27861;&#21487;&#20197;&#25311;&#21512;&#25110;&#23398;&#20064;&#36825;&#20123;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20123;&#21253;&#25324;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#21644;&#20998;&#21106;Wasserstein&#36317;&#31163;&#12290;&#19982;&#26799;&#24230;&#19979;&#38477;&#30456;&#20860;&#23481;&#30340;&#31639;&#27861;&#26356;&#23569;&#65292;&#36825;&#26159;&#31070;&#32463;&#32593;&#32476;&#30340;&#24120;&#35265;&#23398;&#20064;&#36807;&#31243;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#32500;&#24773;&#20917;&#19979;&#20004;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Sliced Cramer 2&#36317;&#31163;&#30340;&#36317;&#31163;&#20989;&#25968;&#65292;&#29992;&#20110;&#23398;&#20064;&#19968;&#33324;&#30340;&#22810;&#20803;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#35768;&#22810;&#20808;&#21069;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#20248;&#28857;&#12290;&#39318;&#20808;&#65292;&#22312;&#19968;&#32500;&#24773;&#20917;&#19979;&#20855;&#26377;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#24120;&#35265;&#30340;&#26426;&#22120;&#23398;&#20064;&#24211;&#65288;&#20363;&#22914;PyTorch&#65289;&#36827;&#34892;&#26131;&#20110;&#35745;&#31639;&#21644;&#23454;&#29616;&#30340;&#25805;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
The learning of Gaussian Mixture Models (also referred to simply as GMMs) plays an important role in machine learning. Known for their expressiveness and interpretability, Gaussian mixture models have a wide range of applications, from statistics, computer vision to distributional reinforcement learning. However, as of today, few known algorithms can fit or learn these models, some of which include Expectation-Maximization algorithms and Sliced Wasserstein Distance. Even fewer algorithms are compatible with gradient descent, the common learning process for neural networks.  In this paper, we derive a closed formula of two GMMs in the univariate, one-dimensional case, then propose a distance function called Sliced Cram\'er 2-distance for learning general multivariate GMMs. Our approach has several advantages over many previous methods. First, it has a closed-form expression for the univariate case and is easy to compute and implement using common machine learning libraries (e.g., PyTorc
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#26088;&#22312;&#36890;&#36807;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#65292;&#39044;&#27979;&#23454;&#26102;&#31227;&#21160;&#32593;&#32476;&#20013;VoIP&#27969;&#37327;&#30340;&#20851;&#38190;QoS/QoE&#25551;&#36848;&#31526;&#30340;&#34892;&#20026;&#65292;&#20197;&#24110;&#21161;&#36816;&#33829;&#21830;&#20248;&#21270;&#32593;&#32476;&#35268;&#21010;&#21644;&#36164;&#28304;&#20998;&#37197;&#12290;</title><link>http://arxiv.org/abs/2307.06645</link><description>&lt;p&gt;
&#23454;&#26102;&#31227;&#21160;&#32593;&#32476;&#20013;VoIP&#27969;&#37327;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#29305;&#24449;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Multivariate Time Series characterization and forecasting of VoIP traffic in real mobile networks. (arXiv:2307.06645v1 [cs.NI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#26088;&#22312;&#36890;&#36807;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#65292;&#39044;&#27979;&#23454;&#26102;&#31227;&#21160;&#32593;&#32476;&#20013;VoIP&#27969;&#37327;&#30340;&#20851;&#38190;QoS/QoE&#25551;&#36848;&#31526;&#30340;&#34892;&#20026;&#65292;&#20197;&#24110;&#21161;&#36816;&#33829;&#21830;&#20248;&#21270;&#32593;&#32476;&#35268;&#21010;&#21644;&#36164;&#28304;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#31227;&#21160;&#32593;&#32476;&#20013;&#23454;&#26102;&#27969;&#37327;&#65288;&#20363;&#22914;VoIP&#65289;&#30340;&#34892;&#20026;&#65292;&#21487;&#20197;&#24110;&#21161;&#36816;&#33829;&#21830;&#26356;&#22909;&#22320;&#35268;&#21010;&#32593;&#32476;&#22522;&#30784;&#35774;&#26045;&#24182;&#20248;&#21270;&#36164;&#28304;&#20998;&#37197;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;VoIP&#27969;&#37327;&#22312;&#23454;&#38469;&#31227;&#21160;&#29615;&#22659;&#20013;&#20851;&#38190;QoS/QoE&#25551;&#36848;&#31526;&#36827;&#34892;&#39044;&#27979;&#20998;&#26512;&#65288;&#20854;&#20013;&#19968;&#20123;&#22312;&#25216;&#26415;&#25991;&#29486;&#20013;&#34987;&#24573;&#30053;&#65289;&#12290;&#35813;&#38382;&#39064;&#20197;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#24418;&#24335;&#36827;&#34892;&#24314;&#27169;&#65292;&#36825;&#31181;&#24418;&#24335;&#21270;&#21487;&#20197;&#21457;&#29616;&#21644;&#24314;&#27169;&#21508;&#31181;&#25551;&#36848;&#31526;&#20043;&#38388;&#30340;&#26102;&#38388;&#20851;&#31995;&#65292;&#24182;&#39044;&#27979;&#23427;&#20204;&#22312;&#26410;&#26469;&#26102;&#26399;&#30340;&#34892;&#20026;&#12290;&#36890;&#36807;&#23558;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#36716;&#21270;&#20026;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#65292;&#37319;&#29992;&#21521;&#37327;&#33258;&#22238;&#24402;&#27169;&#22411;&#21644;&#26426;&#22120;&#23398;&#20064;&#65288;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65289;&#36827;&#34892;&#24615;&#33021;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#27604;&#36739;&#12290;&#27492;&#22806;&#65292;&#36824;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#36741;&#21161;&#20998;&#26512;&#65288;&#24179;&#31283;&#24615;&#65292;&#27491;&#20132;&#33033;&#20914;&#21709;&#24212;&#31561;&#65289;&#21487;&#20197;&#21457;&#29616;VoIP&#27969;&#37327;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predicting the behavior of real-time traffic (e.g., VoIP) in mobility scenarios could help the operators to better plan their network infrastructures and to optimize the allocation of resources. Accordingly, in this work the authors propose a forecasting analysis of crucial QoS/QoE descriptors (some of which neglected in the technical literature) of VoIP traffic in a real mobile environment. The problem is formulated in terms of a multivariate time series analysis. Such a formalization allows to discover and model the temporal relationships among various descriptors and to forecast their behaviors for future periods. Techniques such as Vector Autoregressive models and machine learning (deep-based and tree-based) approaches are employed and compared in terms of performance and time complexity, by reframing the multivariate time series problem into a supervised learning one. Moreover, a series of auxiliary analyses (stationarity, orthogonal impulse responses, etc.) are performed to disco
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#22343;&#21248;&#25910;&#25947;&#30028;&#38480;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#29366;&#24577;-of-the-art&#19978;&#30028;&#19982;&#19979;&#30028;&#20043;&#38388;&#30340;&#31354;&#32570;&#12290;</title><link>http://arxiv.org/abs/2307.06644</link><description>&lt;p&gt;
&#19968;&#20010;&#20855;&#26377;&#8220;fat-shattering&#8221;&#32500;&#24230;&#30340;&#25913;&#36827;&#30340;&#22343;&#21248;&#25910;&#25947;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
An Improved Uniform Convergence Bound with Fat-Shattering Dimension. (arXiv:2307.06644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#22343;&#21248;&#25910;&#25947;&#30028;&#38480;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#29366;&#24577;-of-the-art&#19978;&#30028;&#19982;&#19979;&#30028;&#20043;&#38388;&#30340;&#31354;&#32570;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#8220;fat-shattering&#8221;&#32500;&#24230;&#21051;&#30011;&#20102;&#23454;&#20540;&#20989;&#25968;&#30340;&#22343;&#21248;&#25910;&#25947;&#29305;&#24615;&#12290;&#29616;&#26377;&#30340;&#29366;&#24577;-of-the-art&#19978;&#30028;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#19978;&#23384;&#22312;&#19968;&#20010;&#20056;&#27861;&#24179;&#26041;&#23545;&#25968;&#22240;&#23376;&#65292;&#19982;&#24050;&#26377;&#30340;&#19979;&#30028;&#20043;&#38388;&#23384;&#22312;&#19968;&#20010;&#31354;&#32570;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#22343;&#21248;&#25910;&#25947;&#30028;&#38480;&#26469;&#22635;&#34917;&#36825;&#20010;&#31354;&#32570;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fat-shattering dimension characterizes the uniform convergence property of real-valued functions. The state-of-the-art upper bounds feature a multiplicative squared logarithmic factor on the sample complexity, leaving an open gap with the existing lower bound. We provide an improved uniform convergence bound that closes this gap.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#33030;&#24369;&#24615;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;H-&#20284;&#28982;&#27861;&#36827;&#34892;&#35757;&#32451;&#21644;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#21253;&#21547;&#20010;&#20307;&#29305;&#23450;&#33030;&#24369;&#24615;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2307.06581</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#21322;&#21442;&#25968;&#33030;&#24369;&#24615;&#27169;&#22411;&#21450;&#20854;H-&#20284;&#28982;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks for Semiparametric Frailty Models via H-likelihood. (arXiv:2307.06581v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#33030;&#24369;&#24615;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;H-&#20284;&#28982;&#27861;&#36827;&#34892;&#35757;&#32451;&#21644;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#21253;&#21547;&#20010;&#20307;&#29305;&#23450;&#33030;&#24369;&#24615;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#39044;&#27979;&#32676;&#38598;&#21270;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20285;&#39532;&#33030;&#24369;&#24615;&#27169;&#22411;&#65288;DNN-FM&#65289;&#12290;&#35813;&#27169;&#22411;&#30340;&#19968;&#20010;&#20248;&#21183;&#26159;&#36890;&#36807;&#26032;&#30340;H-&#20284;&#28982;&#20989;&#25968;&#30340;&#32852;&#21512;&#26368;&#22823;&#21270;&#65292;&#20026;&#22266;&#23450;&#21442;&#25968;&#25552;&#20379;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#24182;&#20026;&#38543;&#26426;&#33030;&#24615;&#25552;&#20379;&#20102;&#26368;&#20339;&#26080;&#20559;&#39044;&#27979;&#22120;&#12290;&#22240;&#27492;&#65292;&#25152;&#25552;&#20986;&#30340;DNN-FM&#36890;&#36807;&#20351;&#29992;&#36127;&#38754;&#21078;&#26512;&#30340;H-&#20284;&#28982;&#20989;&#25968;&#20316;&#20026;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#35757;&#32451;&#65292;&#36890;&#36807;&#21078;&#26512;&#38750;&#21442;&#25968;&#22522;&#32447;&#39118;&#38505;&#26469;&#26500;&#36896;&#12290;&#23454;&#39564;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25552;&#39640;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#34920;&#26126;&#65292;&#21253;&#21547;&#20010;&#20307;&#29305;&#23450;&#33030;&#24369;&#24615;&#26377;&#21161;&#20110;&#25913;&#21892;&#22522;&#20110;DNN&#30340;Cox&#27169;&#22411;&#65288;DNN-Cox&#65289;&#30340;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
For prediction of clustered time-to-event data, we propose a new deep neural network based gamma frailty model (DNN-FM). An advantage of the proposed model is that the joint maximization of the new h-likelihood provides maximum likelihood estimators for fixed parameters and best unbiased predictors for random frailties. Thus, the proposed DNN-FM is trained by using a negative profiled h-likelihood as a loss function, constructed by profiling out the non-parametric baseline hazard. Experimental studies show that the proposed method enhances the prediction performance of the existing methods. A real data analysis shows that the inclusion of subject-specific frailties helps to improve prediction of the DNN based Cox model (DNN-Cox).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.06555</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#36924;&#36817;&#65306;&#20174;ReLU&#21040;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Deep Network Approximation: Beyond ReLU to Diverse Activation Functions. (arXiv:2307.06555v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#26500;&#24314;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#26469;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#65292;&#20174;&#32780;&#23558;&#23545;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#22810;&#31181;&#28608;&#27963;&#20989;&#25968;&#19979;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#28608;&#27963;&#20989;&#25968;&#38598;&#21512;A&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;&#24120;&#29992;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;ReLU&#12289;LeakyReLU&#12289;ReLU^2&#12289;ELU&#12289;SELU&#12289;Softplus&#12289;GELU&#12289;SiLU&#12289;Swish&#12289;Mish&#12289;Sigmoid&#12289;Tanh&#12289;Arctan&#12289;Softsign&#12289;dSiLU&#21644;SRS&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#28608;&#27963;&#20989;&#25968;varrho&#8712;A&#65292;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#23485;&#24230;&#20026;6N&#12289;&#28145;&#24230;&#20026;2L&#30340;varrho&#28608;&#27963;&#32593;&#32476;&#22312;&#26377;&#30028;&#38598;&#21512;&#19978;&#20197;&#20219;&#24847;&#31934;&#24230;&#36924;&#36817;&#19968;&#20010;&#23485;&#24230;&#20026;N&#12289;&#28145;&#24230;&#20026;L&#30340;ReLU&#32593;&#32476;&#12290;&#36825;&#19968;&#21457;&#29616;&#20351;&#24471;&#22823;&#37096;&#20998;&#23545;&#20110;ReLU&#32593;&#32476;&#30340;&#36924;&#36817;&#32467;&#26524;&#33021;&#22815;&#25512;&#24191;&#21040;&#20854;&#20182;&#28608;&#27963;&#20989;&#25968;&#65292;&#23613;&#31649;&#38656;&#35201;&#31245;&#22823;&#30340;&#24120;&#25968;&#20195;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set $\mathscr{A}$ is defined to encompass the majority of commonly used activation functions, such as $\mathtt{ReLU}$, $\mathtt{LeakyReLU}$, $\mathtt{ReLU}^2$, $\mathtt{ELU}$, $\mathtt{SELU}$, $\mathtt{Softplus}$, $\mathtt{GELU}$, $\mathtt{SiLU}$, $\mathtt{Swish}$, $\mathtt{Mish}$, $\mathtt{Sigmoid}$, $\mathtt{Tanh}$, $\mathtt{Arctan}$, $\mathtt{Softsign}$, $\mathtt{dSiLU}$, and $\mathtt{SRS}$. We demonstrate that for any activation function $\varrho\in \mathscr{A}$, a $\mathtt{ReLU}$ network of width $N$ and depth $L$ can be approximated to arbitrary precision by a $\varrho$-activated network of width $6N$ and depth $2L$ on any bounded set. This finding enables the extension of most approximation results achieved with $\mathtt{ReLU}$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#24179;&#34913;&#35757;&#32451;&#30340;RBMs&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#21644;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#36890;&#36807;&#36827;&#34892;&#23454;&#39564;&#65292;&#30740;&#31350;&#21457;&#29616;&#35813;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2307.06542</link><description>&lt;p&gt;
&#37327;&#23376;&#36864;&#28779;&#20013;&#36866;&#21512;&#30340;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65306;QUBO&#21644;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;
&lt;/p&gt;
&lt;p&gt;
An Image-Denoising Framework Fit for Quantum Annealing via QUBO and Restricted Boltzmann Machines. (arXiv:2307.06542v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20351;&#29992;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#24179;&#34913;&#35757;&#32451;&#30340;RBMs&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#21644;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#36890;&#36807;&#36827;&#34892;&#23454;&#39564;&#65292;&#30740;&#31350;&#21457;&#29616;&#35813;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#36890;&#36807;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;RBMs&#65289;&#23454;&#29616;&#30340;&#20108;&#20540;&#22270;&#20687;&#21435;&#22122;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#24341;&#20837;&#20102;&#19968;&#20010;&#20108;&#27425;&#26080;&#32422;&#26463;&#20108;&#20540;&#20248;&#21270;&#65288;QUBO&#65289;&#24418;&#24335;&#30340;&#21435;&#22122;&#30446;&#26631;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#21512;&#37327;&#23376;&#36864;&#28779;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#30340;RBMs&#19978;&#23398;&#20064;&#21040;&#30340;&#20998;&#24067;&#19982;&#22122;&#22768;&#22270;&#20687;&#20559;&#31163;&#30340;&#24809;&#32602;&#39033;&#30340;&#24179;&#34913;&#65292;&#23454;&#29616;&#20102;&#21435;&#22122;&#30446;&#26631;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#30446;&#26631;&#20998;&#24067;&#34987;&#33391;&#22909;&#36817;&#20284;&#30340;&#24773;&#20917;&#19979;&#65292;&#24809;&#32602;&#21442;&#25968;&#30340;&#32479;&#35745;&#26368;&#20248;&#36873;&#25321;&#65292;&#24182;&#36827;&#19968;&#27493;&#24314;&#35758;&#20102;&#19968;&#31181;&#32463;&#36807;&#32463;&#39564;&#35777;&#25903;&#25345;&#30340;&#20462;&#25913;&#26041;&#27861;&#65292;&#20351;&#35813;&#26041;&#27861;&#23545;&#20110;&#29702;&#24819;&#21270;&#20551;&#35774;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#36824;&#22312;&#39069;&#22806;&#30340;&#20551;&#35774;&#19979;&#23637;&#31034;&#20102;&#65292;&#25105;&#20204;&#26041;&#27861;&#24471;&#21040;&#30340;&#21435;&#22122;&#22270;&#20687;&#22312;&#26399;&#26395;&#24847;&#20041;&#19979;&#26126;&#26174;&#27604;&#22122;&#22768;&#22270;&#20687;&#26356;&#25509;&#36817;&#26080;&#22122;&#22768;&#22270;&#20687;&#12290;&#34429;&#28982;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#26500;&#24314;&#20026;&#22270;&#20687;&#21435;&#22122;&#27169;&#22411;&#65292;&#20294;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#20108;&#20540;&#25968;&#25454;&#12290;&#30001;&#20110;QUBO&#20844;&#24335;&#38750;&#24120;&#36866;&#21512;&#22312;&#37327;&#23376;&#36864;&#28779;&#22120;&#19978;&#23454;&#29616;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#25968;&#25454;&#38598;&#19978;&#23545;&#35813;&#27169;&#22411;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate a framework for binary image denoising via restricted Boltzmann machines (RBMs) that introduces a denoising objective in quadratic unconstrained binary optimization (QUBO) form and is well-suited for quantum annealing. The denoising objective is attained by balancing the distribution learned by a trained RBM with a penalty term for derivations from the noisy image. We derive the statistically optimal choice of the penalty parameter assuming the target distribution has been well-approximated, and further suggest an empirically supported modification to make the method robust to that idealistic assumption. We also show under additional assumptions that the denoised images attained by our method are, in expectation, strictly closer to the noise-free images than the noisy images are. While we frame the model as an image denoising model, it can be applied to any binary data. As the QUBO formulation is well-suited for implementation on quantum annealers, we test the model on a
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20197;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#20026;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#28151;&#21512;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#31639;&#27861;&#25104;&#21151;&#22320;&#24212;&#29992;&#20110;&#27809;&#26377;&#32452;&#20214;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#24182;&#21487;&#20197;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#32858;&#31867;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#31639;&#27861;&#21487;&#20197;&#22312;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#19979;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2307.06538</link><description>&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#19982;&#25511;&#21046;&#29702;&#35770;&#30340;&#32467;&#21512;&#65306;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tensor Decompositions Meet Control Theory: Learning General Mixtures of Linear Dynamical Systems. (arXiv:2307.06538v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06538
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20197;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#20026;&#22522;&#30784;&#65292;&#25552;&#20986;&#20102;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#28151;&#21512;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#31639;&#27861;&#25104;&#21151;&#22320;&#24212;&#29992;&#20110;&#27809;&#26377;&#32452;&#20214;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#65292;&#24182;&#21487;&#20197;&#19982;&#36125;&#21494;&#26031;&#26368;&#20248;&#32858;&#31867;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#31639;&#27861;&#21487;&#20197;&#22312;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#19979;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;Chen&#21644;Poor&#24320;&#22987;&#30740;&#31350;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#34429;&#28982;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#24050;&#32463;&#22312;&#24314;&#27169;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26041;&#38754;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20294;&#20351;&#29992;&#28151;&#21512;&#27169;&#22411;&#21487;&#20197;&#24102;&#26469;&#26356;&#22909;&#30340;&#25311;&#21512;&#25110;&#32773;&#23545;&#25968;&#25454;&#20013;&#34920;&#31034;&#30340;&#22522;&#30784;&#23376;&#32676;&#20307;&#26377;&#26356;&#20016;&#23500;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#20998;&#35299;&#30340;&#23398;&#20064;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#28151;&#21512;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32452;&#20214;&#26080;&#24378;&#20998;&#31163;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#25104;&#21151;&#65292;&#24182;&#21487;&#20197;&#29992;&#20110;&#19982;&#36712;&#36857;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#32858;&#31867;&#31454;&#20105;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36866;&#29992;&#20110;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#37096;&#20998;&#35266;&#27979;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#36215;&#28857;&#26159;&#31616;&#21333;&#20294;&#24378;&#22823;&#30340;&#35266;&#23519;&#65292;&#21363;&#32463;&#20856;&#30340;&#20309;-&#21345;&#23572;&#26364;&#31639;&#27861;&#26159;&#23398;&#20064;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#29616;&#20195;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;&#30340;&#36817;&#20146;&#12290;&#36825;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#25193;&#23637;&#21040;&#26356;&#22797;&#26434;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25805;&#20316;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently Chen and Poor initiated the study of learning mixtures of linear dynamical systems. While linear dynamical systems already have wide-ranging applications in modeling time-series data, using mixture models can lead to a better fit or even a richer understanding of underlying subpopulations represented in the data. In this work we give a new approach to learning mixtures of linear dynamical systems that is based on tensor decompositions. As a result, our algorithm succeeds without strong separation conditions on the components, and can be used to compete with the Bayes optimal clustering of the trajectories. Moreover our algorithm works in the challenging partially-observed setting. Our starting point is the simple but powerful observation that the classic Ho-Kalman algorithm is a close relative of modern tensor decomposition methods for learning latent variable models. This gives us a playbook for how to extend it to work with more complicated generative models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#21452;&#32447;&#24615;&#23884;&#20837;&#65292;&#23454;&#29616;&#23545;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#36827;&#34892;&#22806;&#25512;&#12290;&#36825;&#20010;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#24191;&#20041;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.06457</link><description>&lt;p&gt;
&#35299;&#20915;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65306;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06457
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#21452;&#32447;&#24615;&#23884;&#20837;&#65292;&#23454;&#29616;&#23545;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#36827;&#34892;&#22806;&#25512;&#12290;&#36825;&#20010;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#24191;&#20041;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#33719;&#24471;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#19988;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;(a)&#22312;&#27979;&#35797;&#21644;&#35757;&#32451;&#20998;&#24067;&#19979;&#65292;&#26631;&#31614;$z$&#30001;&#29305;&#24449;$(x,y)$&#30340;&#23545;&#20915;&#23450;&#65292;(b)&#35757;&#32451;&#20998;&#24067;&#28085;&#30422;&#20102;$x$&#21644;$y$&#20998;&#21035;&#30340;&#19968;&#23450;&#36793;&#32536;&#20998;&#24067;&#65292;&#20294;&#26159;(c)&#27979;&#35797;&#20998;&#24067;&#28041;&#21450;&#20102;&#19968;&#20010;&#22312;&#35757;&#32451;&#20998;&#24067;&#20013;&#26410;&#28085;&#30422;&#30340;$(x,y)$&#30340;&#20135;&#21697;&#20998;&#24067;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#26631;&#31614;&#30001;&#21452;&#32447;&#24615;&#23884;&#20837;&#21040;Hilbert&#31354;&#38388;$H$&#20013;&#32473;&#20986;&#30340;&#29305;&#27530;&#24773;&#20917;&#65306;$\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23545;&#22312;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#22495;&#36827;&#34892;&#22806;&#25512;&#65292;&#21363;&#23454;&#29616;&#21452;&#32447;&#24615;&#32452;&#21512;&#22806;&#25512;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#30340;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#24191;&#20041;&#21270;&#65292;&#23545;&#20110;&#35813;&#24773;&#20917;&#65292;&#25152;&#26377;&#29616;&#26377;&#32467;&#26524;&#37117;&#35201;&#27714;....
&lt;/p&gt;
&lt;p&gt;
Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution. Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.  Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results requi
&lt;/p&gt;</description></item><item><title>&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#30340;&#20998;&#24067;&#21442;&#25968;&#20272;&#35745;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20256;&#24863;&#22120;/&#20195;&#29702;&#25968;&#25454;&#25910;&#38598;&#21644;&#21327;&#20316;&#31574;&#30053;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#36153;&#33293;&#23572;&#20449;&#24687;&#25110;&#26368;&#23567;&#21270;Cramer-Rao&#30028;&#26469;&#35299;&#20915;&#20256;&#24863;&#22120;/&#20195;&#29702;&#30340;&#25968;&#25454;&#25910;&#38598;&#21644;&#21327;&#20316;&#31574;&#30053;&#35774;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.06442</link><description>&lt;p&gt;
&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#30340;&#20998;&#24067;&#21442;&#25968;&#20272;&#35745;&#20013;&#30340;&#21327;&#20316;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Collaboration in Distributed Parameter Estimation with Resource Constraints. (arXiv:2307.06442v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06442
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#30340;&#20998;&#24067;&#21442;&#25968;&#20272;&#35745;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20256;&#24863;&#22120;/&#20195;&#29702;&#25968;&#25454;&#25910;&#38598;&#21644;&#21327;&#20316;&#31574;&#30053;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#36153;&#33293;&#23572;&#20449;&#24687;&#25110;&#26368;&#23567;&#21270;Cramer-Rao&#30028;&#26469;&#35299;&#20915;&#20256;&#24863;&#22120;/&#20195;&#29702;&#30340;&#25968;&#25454;&#25910;&#38598;&#21644;&#21327;&#20316;&#31574;&#30053;&#35774;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32771;&#34385;&#36164;&#28304;&#32422;&#26463;&#21644;&#19981;&#21516;&#20256;&#24863;&#22120;/&#20195;&#29702;&#25910;&#38598;&#30340;&#35266;&#27979;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#30340;&#21442;&#25968;&#20272;&#35745;&#30340;&#20256;&#24863;&#22120;/&#20195;&#29702;&#25968;&#25454;&#25910;&#38598;&#21644;&#21327;&#20316;&#31574;&#30053;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#32452;&#20256;&#24863;&#22120;/&#20195;&#29702;&#65292;&#27599;&#20010;&#20256;&#24863;&#22120;/&#20195;&#29702;&#26679;&#26412;&#26469;&#33258;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#30340;&#19981;&#21516;&#21464;&#37327;&#65292;&#24182;&#19988;&#20855;&#26377;&#19981;&#21516;&#30340;&#20272;&#35745;&#30446;&#26631;&#65292;&#25105;&#20204;&#23558;&#20256;&#24863;&#22120;/&#20195;&#29702;&#30340;&#25968;&#25454;&#25910;&#38598;&#21644;&#21327;&#20316;&#31574;&#30053;&#35774;&#35745;&#38382;&#39064;&#38416;&#36848;&#20026;&#36153;&#33293;&#23572;&#20449;&#24687;&#26368;&#22823;&#21270;&#65288;&#25110;Cramer-Rao&#30028;&#26368;&#23567;&#21270;&#65289;&#38382;&#39064;&#12290;&#24403;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#30693;&#35782;&#21487;&#29992;&#26102;&#65292;&#25105;&#20204;&#21487;&#20197;&#20998;&#26512;&#22320;&#35782;&#21035;&#20986;&#20004;&#20010;&#29305;&#23450;&#24773;&#20917;&#65306;&#65288;1&#65289;&#19981;&#33021;&#21033;&#29992;&#26679;&#26412;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#30693;&#35782;&#36827;&#34892;&#21327;&#20316;&#20272;&#35745;&#30340;&#24773;&#20917;&#65292;&#65288;2&#65289;&#26368;&#20248;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#28041;&#21450;&#25237;&#36164;&#26377;&#38480;&#36164;&#28304;&#20197;&#21327;&#20316;&#37319;&#26679;&#21644;&#36716;&#31227;&#24050;&#30693;&#32479;&#35745;&#20449;&#24687;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study sensor/agent data collection and collaboration policies for parameter estimation, accounting for resource constraints and correlation between observations collected by distinct sensors/agents. Specifically, we consider a group of sensors/agents each samples from different variables of a multivariate Gaussian distribution and has different estimation objectives, and we formulate a sensor/agent's data collection and collaboration policy design problem as a Fisher information maximization (or Cramer-Rao bound minimization) problem. When the knowledge of correlation between variables is available, we analytically identify two particular scenarios: (1) where the knowledge of the correlation between samples cannot be leveraged for collaborative estimation purposes and (2) where the optimal data collection policy involves investing scarce resources to collaboratively sample and transfer information that is not of immediate interest and whose statistics are already known, with the sol
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33021;&#37327;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#22312;&#19981;&#20381;&#36182;&#20998;&#25968;&#35745;&#31639;&#25110;&#26114;&#36149;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#23454;&#29616;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#21644;&#36127;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#65292;&#24182;&#22312;&#23398;&#20064;&#20302;&#32500;&#25968;&#25454;&#20998;&#24067;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.06431</link><description>&lt;p&gt;
&#33021;&#37327;&#24046;&#24322;&#65306;&#19968;&#31181;&#36866;&#29992;&#20110;&#33021;&#37327;&#27169;&#22411;&#30340;&#29420;&#31435;&#20110;&#35780;&#20998;&#30340;&#25439;&#22833;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Energy Discrepancies: A Score-Independent Loss for Energy-Based Models. (arXiv:2307.06431v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06431
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33021;&#37327;&#27169;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#33021;&#22815;&#22312;&#19981;&#20381;&#36182;&#20998;&#25968;&#35745;&#31639;&#25110;&#26114;&#36149;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#36817;&#20284;&#23454;&#29616;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#21644;&#36127;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#65292;&#24182;&#22312;&#23398;&#20064;&#20302;&#32500;&#25968;&#25454;&#20998;&#24067;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#27169;&#22411;&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#20294;&#23427;&#20204;&#30340;&#26222;&#21450;&#21463;&#21040;&#20102;&#35757;&#32451;&#30340;&#35745;&#31639;&#36127;&#25285;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#31216;&#20026;&#33021;&#37327;&#24046;&#24322;&#65288;ED&#65289;&#65292;&#23427;&#19981;&#20381;&#36182;&#20110;&#20998;&#25968;&#30340;&#35745;&#31639;&#25110;&#26114;&#36149;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#30340;&#26497;&#38480;&#19979;&#65292;ED&#25509;&#36817;&#20110;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#21644;&#36127;&#23545;&#25968;&#20284;&#28982;&#25439;&#22833;&#65292;&#26377;&#25928;&#22320;&#22312;&#20004;&#32773;&#20043;&#38388;&#25554;&#20540;&#12290;&#22240;&#27492;&#65292;&#26368;&#23567;&#21270;ED&#20272;&#35745;&#20811;&#26381;&#20102;&#22312;&#22522;&#20110;&#20998;&#25968;&#30340;&#20272;&#35745;&#26041;&#27861;&#20013;&#36935;&#21040;&#30340;&#36817;&#35270;&#38382;&#39064;&#65292;&#21516;&#26102;&#36824;&#20139;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#26174;&#24335;&#20998;&#25968;&#21305;&#37197;&#25110;&#23545;&#27604;&#25955;&#24230;&#30456;&#27604;&#65292;ED&#33021;&#22815;&#26356;&#24555;&#36895;&#12289;&#26356;&#20934;&#30830;&#22320;&#23398;&#20064;&#20302;&#32500;&#25968;&#25454;&#20998;&#24067;&#12290;&#23545;&#20110;&#39640;&#32500;&#22270;&#20687;&#25968;&#25454;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#27969;&#24418;&#20551;&#35774;&#23545;&#25105;&#20204;&#26041;&#27861;&#30340;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#23545;e&#27169;&#22411;&#30340;&#35757;&#32451;&#65292;&#35777;&#26126;&#20102;&#33021;&#37327;&#24046;&#24322;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-based models are a simple yet powerful class of probabilistic models, but their widespread adoption has been limited by the computational burden of training them. We propose a novel loss function called Energy Discrepancy (ED) which does not rely on the computation of scores or expensive Markov chain Monte Carlo. We show that ED approaches the explicit score matching and negative log-likelihood loss under different limits, effectively interpolating between both. Consequently, minimum ED estimation overcomes the problem of nearsightedness encountered in score-based estimation methods, while also enjoying theoretical guarantees. Through numerical experiments, we demonstrate that ED learns low-dimensional data distributions faster and more accurately than explicit score matching or contrastive divergence. For high-dimensional image data, we describe how the manifold hypothesis puts limitations on our approach and demonstrate the effectiveness of energy discrepancy by training the e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#22810;&#27169;&#24577;Laplace&#36817;&#20284;&#30340;&#36125;&#21494;&#26031;&#21464;&#20998;&#25512;&#26029;&#30340;&#40065;&#26834;&#21487;&#25193;&#23637;&#21021;&#22987;&#21270;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#22312;&#39640;&#24230;&#38750;&#39640;&#26031;&#34892;&#20026;&#20013;&#65292;&#21253;&#25324;&#22810;&#23792;&#24615;&#26102;&#65292;&#8220;&#22343;&#22330;&#8221;&#39640;&#26031;&#20998;&#24067;&#36817;&#20284;&#36807;&#20110;&#38480;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.06424</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#27169;&#24577;Laplace&#36817;&#20284;&#30340;&#36125;&#21494;&#26031;&#21464;&#20998;&#25512;&#26029;&#30340;&#40065;&#26834;&#21487;&#25193;&#23637;&#21021;&#22987;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust scalable initialization for Bayesian variational inference with multi-modal Laplace approximations. (arXiv:2307.06424v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#22810;&#27169;&#24577;Laplace&#36817;&#20284;&#30340;&#36125;&#21494;&#26031;&#21464;&#20998;&#25512;&#26029;&#30340;&#40065;&#26834;&#21487;&#25193;&#23637;&#21021;&#22987;&#21270;&#26041;&#27861;&#65292;&#20197;&#24212;&#23545;&#22312;&#39640;&#24230;&#38750;&#39640;&#26031;&#34892;&#20026;&#20013;&#65292;&#21253;&#25324;&#22810;&#23792;&#24615;&#26102;&#65292;&#8220;&#22343;&#22330;&#8221;&#39640;&#26031;&#20998;&#24067;&#36817;&#20284;&#36807;&#20110;&#38480;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20381;&#36182;&#36125;&#21494;&#26031;&#21453;&#28436;&#30340;&#39044;&#27979;&#24314;&#27169;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#23436;&#20840;&#29420;&#31435;&#25110;&#8220;&#22343;&#22330;&#8221;&#39640;&#26031;&#20998;&#24067;&#20316;&#20026;&#21464;&#20998;&#25512;&#26029;&#20013;&#30340;&#36817;&#20284;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#22240;&#20026;&#21464;&#20998;&#21442;&#25968;&#30340;&#25968;&#37327;&#26159;&#26410;&#30693;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#30340;&#20004;&#20493;&#12290;&#30001;&#20110;&#20855;&#26377;&#23545;&#35282;&#21327;&#26041;&#24046;&#32467;&#26500;&#21644;&#21333;&#23792;&#34892;&#20026;&#65292;&#24403;&#22788;&#29702;&#39640;&#24230;&#38750;&#39640;&#26031;&#34892;&#20026;&#26102;&#65292;&#21253;&#25324;&#22810;&#23792;&#24615;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#21487;&#33021;&#36807;&#20110;&#38480;&#21046;&#24615;&#12290;&#24418;&#24335;&#19978;&#20026;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#39640;&#20445;&#30495;&#20195;&#29702;&#21518;&#39564;&#20998;&#24067;&#33021;&#22815;&#20197;&#20219;&#24847;&#31934;&#24230;&#25429;&#33719;&#20219;&#20309;&#20998;&#24067;&#65292;&#21516;&#26102;&#20173;&#20445;&#30041;&#19968;&#23450;&#30340;&#20998;&#26512;&#21487;&#36861;&#36394;&#24615;&#12290;&#20855;&#26377;&#23436;&#20840;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#21464;&#20998;&#25512;&#26029;&#38543;&#30528;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#20986;&#29616;&#21464;&#20998;&#21442;&#25968;&#30340;&#20108;&#27425;&#22686;&#38271;&#12290;&#30001;&#20110;&#19982;&#21464;&#20998;&#25512;&#26029;&#24120;&#24120;&#30456;&#20851;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#38750;&#20984;&#36235;&#21183;&#24341;&#36215;&#30340;&#22810;&#20010;&#23616;&#37096;&#26497;&#23567;&#20540;&#30340;&#23384;&#22312;&#65292;&#36825;&#20123;&#25361;&#25112;&#20419;&#20351;&#38656;&#35201;&#36827;&#34892;&#40065;&#26834;&#21487;&#25193;&#23637;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
For predictive modeling relying on Bayesian inversion, fully independent, or ``mean-field'', Gaussian distributions are often used as approximate probability density functions in variational inference since the number of variational parameters is twice the number of unknown model parameters. The resulting diagonal covariance structure coupled with unimodal behavior can be too restrictive when dealing with highly non-Gaussian behavior, including multimodality. High-fidelity surrogate posteriors in the form of Gaussian mixtures can capture any distribution to an arbitrary degree of accuracy while maintaining some analytical tractability. Variational inference with Gaussian mixtures with full-covariance structures suffers from a quadratic growth in variational parameters with the number of model parameters. Coupled with the existence of multiple local minima due to nonconvex trends in the loss functions often associated with variational inference, these challenges motivate the need for ro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;&#27979;&#35797;&#31232;&#30095;&#24615;&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26412;&#29305;&#24449;&#20540;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#36873;&#25321;&#36866;&#24403;&#30340;&#32467;&#26500;&#21457;&#29616;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.06406</link><description>&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;&#27979;&#35797;&#31232;&#30095;&#24615;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Testing Sparsity Assumptions in Bayesian Networks. (arXiv:2307.06406v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#32593;&#32476;&#20013;&#27979;&#35797;&#31232;&#30095;&#24615;&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26679;&#26412;&#29305;&#24449;&#20540;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#24110;&#21161;&#36873;&#25321;&#36866;&#24403;&#30340;&#32467;&#26500;&#21457;&#29616;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BN&#65289;&#32467;&#26500;&#21457;&#29616;&#31639;&#27861;&#36890;&#24120;&#35201;&#20040;&#23545;&#30495;&#27491;&#30340;&#24213;&#23618;&#32593;&#32476;&#31232;&#30095;&#24615;&#20570;&#20986;&#20551;&#35774;&#65292;&#35201;&#20040;&#21463;&#21040;&#35745;&#31639;&#38480;&#21046;&#32780;&#20165;&#36866;&#29992;&#20110;&#20855;&#26377;&#23569;&#37327;&#21464;&#37327;&#30340;&#32593;&#32476;&#12290;&#23613;&#31649;&#36825;&#20123;&#31232;&#30095;&#24615;&#20551;&#35774;&#21487;&#20197;&#37319;&#21462;&#22810;&#31181;&#24418;&#24335;&#65292;&#20294;&#36890;&#24120;&#20551;&#35774;&#38598;&#20013;&#22312;&#24213;&#23618;&#22270;&#30340;&#26368;&#22823;&#20837;&#24230;&#19978;&#38480;$\nabla_G$&#12290;Duttweiler&#31561;&#20154;&#65288;2023&#65289;&#30340;&#23450;&#29702;2&#35777;&#26126;&#20102;&#32447;&#24615;BN&#30340;&#26631;&#20934;&#21270;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;$\Omega$&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#26159;$\nabla_G$&#30340;&#19968;&#20010;&#19979;&#30028;&#12290;&#22312;&#27492;&#32467;&#26524;&#30340;&#22522;&#30784;&#19978;&#65292;&#26412;&#25991;&#25552;&#20379;&#20102;$\Omega$&#26679;&#26412;&#29305;&#24449;&#20540;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#19968;&#31181;&#20551;&#35774;&#26816;&#39564;&#65292;&#21487;&#20197;&#29992;&#26469;&#30830;&#23450;BN&#30340;&#26368;&#22823;&#20837;&#24230;&#26159;&#21542;&#22823;&#20110;1&#12290;&#24314;&#35758;&#22312;&#32447;&#24615;BN&#32467;&#26500;&#21457;&#29616;&#24037;&#20316;&#27969;&#20013;&#20351;&#29992;&#27492;&#20551;&#35774;&#26816;&#39564;&#26469;&#36741;&#21161;&#36873;&#25321;&#36866;&#24403;&#30340;&#32467;&#26500;&#21457;&#29616;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian network (BN) structure discovery algorithms typically either make assumptions about the sparsity of the true underlying network, or are limited by computational constraints to networks with a small number of variables. While these sparsity assumptions can take various forms, frequently the assumptions focus on an upper bound for the maximum in-degree of the underlying graph $\nabla_G$. Theorem 2 in Duttweiler et. al. (2023) demonstrates that the largest eigenvalue of the normalized inverse covariance matrix ($\Omega$) of a linear BN is a lower bound for $\nabla_G$. Building on this result, this paper provides the asymptotic properties of, and a debiasing procedure for, the sample eigenvalues of $\Omega$, leading to a hypothesis test that may be used to determine if the BN has max in-degree greater than 1. A linear BN structure discovery workflow is suggested in which the investigator uses this hypothesis test to aid in selecting an appropriate structure discovery algorithm. Th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#35774;&#35745;&#21644;&#35757;&#32451;&#21327;&#35758;&#30340;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#31561;&#20215;&#36215;&#26469;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#20915;&#23450;PINN&#39044;&#27979;&#30340;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#20197;&#21450;&#36890;&#36807;&#21407;&#22987;&#24494;&#20998;&#26041;&#31243;&#20013;&#28304;&#39033;&#30340;&#35889;&#20998;&#35299;&#26469;&#37327;&#21270;&#32593;&#32476;&#24341;&#20837;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2307.06362</link><description>&lt;p&gt;
&#20855;&#26377;&#35889;&#20559;&#24046;&#21644;&#20869;&#26680;-&#20219;&#21153;&#23545;&#40784;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Spectral-Bias and Kernel-Task Alignment in Physically Informed Neural Networks. (arXiv:2307.06362v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#35774;&#35745;&#21644;&#35757;&#32451;&#21327;&#35758;&#30340;&#36873;&#25321;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#31561;&#20215;&#36215;&#26469;&#65292;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#20915;&#23450;PINN&#39044;&#27979;&#30340;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#65292;&#20197;&#21450;&#36890;&#36807;&#21407;&#22987;&#24494;&#20998;&#26041;&#31243;&#20013;&#28304;&#39033;&#30340;&#35889;&#20998;&#35299;&#26469;&#37327;&#21270;&#32593;&#32476;&#24341;&#20837;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26159;&#35299;&#20915;&#24494;&#20998;&#26041;&#31243;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26032;&#26041;&#27861;&#12290;&#19982;&#35768;&#22810;&#20854;&#20182;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#19968;&#26679;&#65292;PINN&#30340;&#35774;&#35745;&#21644;&#35757;&#32451;&#21327;&#35758;&#30340;&#36873;&#25321;&#38656;&#35201;&#31934;&#24515;&#21046;&#23450;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#23545;&#36825;&#20010;&#37325;&#35201;&#38382;&#39064;&#36827;&#34892;&#20102;&#38416;&#36848;&#12290;&#36890;&#36807;&#21033;&#29992;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#31181;&#22312;&#22823;&#25968;&#25454;&#38598;&#38480;&#21046;&#19979;&#20915;&#23450;PINN&#39044;&#27979;&#30340;&#31215;&#20998;&#24494;&#20998;&#26041;&#31243;&#8212;&#8212;&#31070;&#32463;&#20449;&#24687;&#26041;&#31243;&#65288;NIE&#65289;&#12290;&#35813;&#26041;&#31243;&#36890;&#36807;&#21453;&#26144;&#26550;&#26500;&#36873;&#25321;&#30340;&#20869;&#26680;&#39033;&#26469;&#34917;&#20805;&#21407;&#22987;&#26041;&#31243;&#65292;&#24182;&#36890;&#36807;&#21407;&#22987;&#24494;&#20998;&#26041;&#31243;&#20013;&#28304;&#39033;&#30340;&#35889;&#20998;&#35299;&#26469;&#37327;&#21270;&#32593;&#32476;&#24341;&#20837;&#30340;&#38544;&#21547;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physically informed neural networks (PINNs) are a promising emerging method for solving differential equations. As in many other deep learning approaches, the choice of PINN design and training protocol requires careful craftsmanship. Here, we suggest a comprehensive theoretical framework that sheds light on this important problem. Leveraging an equivalence between infinitely over-parameterized neural networks and Gaussian process regression (GPR), we derive an integro-differential equation that governs PINN prediction in the large data-set limit -- the Neurally-Informed Equation (NIE). This equation augments the original one by a kernel term reflecting architecture choices and allows quantifying implicit bias induced by the network via a spectral decomposition of the source term in the original differential equation.
&lt;/p&gt;</description></item><item><title>balance&#26159;&#19968;&#20010;&#29992;&#20110;&#20998;&#26512;&#21644;&#35843;&#25972;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#30340;Python&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#35780;&#20272;&#21021;&#22987;&#20559;&#24046;&#12289;&#26681;&#25454;&#20542;&#21521;&#20998;&#25968;&#20135;&#29983;&#26435;&#37325;&#26657;&#27491;&#25968;&#25454;&#20197;&#21450;&#35780;&#20272;&#25311;&#21512;&#26435;&#37325;&#21518;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#33192;&#32960;&#26469;&#25552;&#20379;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.06024</link><description>&lt;p&gt;
balance -- &#19968;&#20010;&#29992;&#20110;&#24179;&#34913;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#30340;Python&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
balance -- a Python package for balancing biased data samples. (arXiv:2307.06024v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06024
&lt;/p&gt;
&lt;p&gt;
balance&#26159;&#19968;&#20010;&#29992;&#20110;&#20998;&#26512;&#21644;&#35843;&#25972;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#30340;Python&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#35780;&#20272;&#21021;&#22987;&#20559;&#24046;&#12289;&#26681;&#25454;&#20542;&#21521;&#20998;&#25968;&#20135;&#29983;&#26435;&#37325;&#26657;&#27491;&#25968;&#25454;&#20197;&#21450;&#35780;&#20272;&#25311;&#21512;&#26435;&#37325;&#21518;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#33192;&#32960;&#26469;&#25552;&#20379;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35843;&#26597;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#30740;&#31350;&#24037;&#20855;&#65292;&#21487;&#20197;&#25552;&#20379;&#20851;&#20110;&#24773;&#24863;&#21644;&#24847;&#35265;&#31561;&#20027;&#35266;&#20307;&#39564;&#30340;&#29420;&#29305;&#27979;&#37327;&#65292;&#36825;&#20123;&#27979;&#37327;&#26080;&#27861;&#36890;&#36807;&#20854;&#20182;&#26041;&#24335;&#36827;&#34892;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35843;&#26597;&#25968;&#25454;&#26159;&#20174;&#33258;&#24895;&#21442;&#19982;&#30340;&#20154;&#32676;&#20013;&#25910;&#38598;&#30340;&#65292;&#30452;&#25509;&#20174;&#20013;&#25512;&#26029;&#20986;&#23545;&#25152;&#20851;&#27880;&#30340;&#20154;&#32676;&#25110;&#32773;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#38169;&#35823;&#30340;&#20272;&#35745;&#25110;&#32773;&#24615;&#33021;&#19979;&#38477;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#36719;&#20214;&#21253;balance&#65292;&#23427;&#30001;Meta&#24320;&#21457;&#65292;&#25552;&#20379;&#19968;&#20010;&#31616;&#21333;&#30340;&#24037;&#20316;&#27969;&#31243;&#26469;&#20998;&#26512;&#21644;&#26657;&#27491;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#25152;&#20851;&#27880;&#30340;&#20154;&#32676;&#20855;&#26377;&#24179;&#34913;&#24615;&#12290;balance&#24037;&#20316;&#27969;&#31243;&#21253;&#25324;&#19977;&#20010;&#27493;&#39588;&#65306;&#20102;&#35299;&#25968;&#25454;&#30340;&#21021;&#22987;&#20559;&#24046;&#65292;&#26681;&#25454;&#20542;&#21521;&#20998;&#25968;&#20026;&#26679;&#26412;&#20013;&#30340;&#27599;&#20010;&#21333;&#20301;&#20135;&#29983;&#26435;&#37325;&#20197;&#26657;&#27491;&#20559;&#24046;&#65292;&#20197;&#21450;&#22312;&#24212;&#29992;&#25311;&#21512;&#26435;&#37325;&#21518;&#35780;&#20272;&#26368;&#32456;&#20559;&#24046;&#21644;&#26041;&#24046;&#33192;&#32960;&#12290;&#35813;&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;API&#65292;&#21487;&#20197;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Surveys are an important research tool, providing unique measurements on subjective experiences such as sentiment and opinions that cannot be measured by other means. However, because survey data is collected from a self-selected group of participants, directly inferring insights from it to a population of interest, or training ML models on such data, can lead to erroneous estimates or under-performing models. In this paper we present balance, an open-source Python package by Meta, offering a simple workflow for analyzing and adjusting biased data samples with respect to a population of interest.  The balance workflow includes three steps: understanding the initial bias in the data relative to a target we would like to infer, adjusting the data to correct for the bias by producing weights for each unit in the sample based on propensity scores, and evaluating the final biases and the variance inflation after applying the fitted weights. The package provides a simple API that can be used
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#32039;&#31995;&#25968;&#26679;&#26465;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#27169;&#24335;&#30340;&#25968;&#37327;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26680;&#20272;&#35745;&#22120;&#21644;&#32452;&#21512;&#26679;&#26465;&#65292;&#23454;&#29616;&#20102;&#29305;&#24449;&#25506;&#32034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#27169;&#24335;&#26816;&#39564;&#65292;&#24182;&#20801;&#35768;&#24341;&#20837;&#19987;&#23478;&#21028;&#26029;&#12290;&#36890;&#36807;&#22312;&#20307;&#32946;&#20998;&#26512;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05825</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#32039;&#31995;&#25968;&#26679;&#26465;&#20272;&#35745;&#27169;&#24335;&#30340;&#25968;&#37327;
&lt;/p&gt;
&lt;p&gt;
Bayesian taut splines for estimating the number of modes. (arXiv:2307.05825v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05825
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#32039;&#31995;&#25968;&#26679;&#26465;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#27169;&#24335;&#30340;&#25968;&#37327;&#12290;&#35813;&#26041;&#27861;&#32467;&#21512;&#20102;&#26680;&#20272;&#35745;&#22120;&#21644;&#32452;&#21512;&#26679;&#26465;&#65292;&#23454;&#29616;&#20102;&#29305;&#24449;&#25506;&#32034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#27169;&#24335;&#26816;&#39564;&#65292;&#24182;&#20801;&#35768;&#24341;&#20837;&#19987;&#23478;&#21028;&#26029;&#12290;&#36890;&#36807;&#22312;&#20307;&#32946;&#20998;&#26512;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#30340;&#39564;&#35777;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20013;&#27169;&#24335;&#30340;&#25968;&#37327;&#20195;&#34920;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#65292;&#20063;&#21487;&#20197;&#30475;&#20316;&#29616;&#26377;&#20122;&#32676;&#20307;&#30340;&#25968;&#37327;&#12290;&#23613;&#31649;&#20854;&#30456;&#20851;&#24615;&#65292;&#23545;&#20854;&#20272;&#35745;&#30340;&#30740;&#31350;&#38750;&#24120;&#26377;&#38480;&#12290;&#25105;&#20204;&#38024;&#23545;&#21333;&#21464;&#37327;&#24773;&#20917;&#25552;&#20986;&#19968;&#20010;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#33268;&#21147;&#20110;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#21463;&#21040;&#20102;&#38382;&#39064;&#30340;&#19968;&#20123;&#34987;&#24573;&#35270;&#30340;&#26041;&#38754;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#35748;&#20026;&#35299;&#20915;&#26041;&#26696;&#38656;&#35201;&#32467;&#26500;&#65292;&#27169;&#24335;&#30340;&#20027;&#35266;&#19988;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#21450;&#34701;&#21512;&#20840;&#23616;&#21644;&#23616;&#37096;&#23494;&#24230;&#29305;&#24615;&#30340;&#25972;&#20307;&#35270;&#22270;&#30340;&#20415;&#21033;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#28789;&#27963;&#30340;&#26680;&#20272;&#35745;&#22120;&#21644;&#31616;&#27905;&#30340;&#32452;&#21512;&#26679;&#26465;&#12290;&#29305;&#24449;&#25506;&#32034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#27169;&#24335;&#26816;&#39564;&#37117;&#22312;&#36125;&#21494;&#26031;&#25512;&#29702;&#33539;&#24335;&#20013;&#23454;&#29616;&#65292;&#20026;&#36719;&#35299;&#20915;&#26041;&#26696;&#25552;&#20379;&#20102;&#20415;&#21033;&#65292;&#24182;&#20801;&#35768;&#22312;&#36807;&#31243;&#20013;&#24341;&#20837;&#19987;&#23478;&#21028;&#26029;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#30340;&#23454;&#29992;&#24615;&#36890;&#36807;&#22312;&#20307;&#32946;&#20998;&#26512;&#20013;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#22810;&#20010;&#38506;&#20276;&#30340;&#21487;&#35270;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
The number of modes in a probability density function is representative of the model's complexity and can also be viewed as the number of existing subpopulations. Despite its relevance, little research has been devoted to its estimation. Focusing on the univariate setting, we propose a novel approach targeting prediction accuracy inspired by some overlooked aspects of the problem. We argue for the need for structure in the solutions, the subjective and uncertain nature of modes, and the convenience of a holistic view blending global and local density properties. Our method builds upon a combination of flexible kernel estimators and parsimonious compositional splines. Feature exploration, model selection and mode testing are implemented in the Bayesian inference paradigm, providing soft solutions and allowing to incorporate expert judgement in the process. The usefulness of our proposal is illustrated through a case study in sports analytics, showcasing multiple companion visualisation 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#23454;&#36136;&#19978;&#26159;&#38024;&#23545;&#35813;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.02719</link><description>&lt;p&gt;
&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Understanding Uncertainty Sampling. (arXiv:2307.02719v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#23454;&#36136;&#19978;&#26159;&#38024;&#23545;&#35813;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#39034;&#24207;&#22320;&#26597;&#35810;&#24403;&#21069;&#39044;&#27979;&#27169;&#22411;&#23545;&#25968;&#25454;&#26679;&#26412;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#30340;&#20351;&#29992;&#24448;&#24448;&#26159;&#21551;&#21457;&#24335;&#30340;&#65306;&#65288;i&#65289;&#20851;&#20110;&#22312;&#29305;&#23450;&#20219;&#21153;&#21644;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#19979;&#23545;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#20934;&#30830;&#23450;&#20041;&#27809;&#26377;&#20849;&#35782;&#65307;&#65288;ii&#65289;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#33021;&#22815;&#32473;&#20986;&#19968;&#20010;&#26631;&#20934;&#21327;&#35758;&#26469;&#23454;&#26045;&#35813;&#31639;&#27861;&#65292;&#20363;&#22914;&#65292;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#20248;&#21270;&#31639;&#27861;&#26694;&#26550;&#19979;&#22914;&#20309;&#22788;&#29702;&#39034;&#24207;&#21040;&#36798;&#30340;&#27880;&#37322;&#25968;&#25454;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#21462;&#20915;&#20110;&#20351;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#21644;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#30830;&#31435;&#20102;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#26412;&#36136;&#19978;&#26159;&#38024;&#23545;&#36825;&#31181;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;&#36825;&#19968;&#35266;&#28857;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#36866;&#24403;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about. However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of "uncertainty" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent. In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning. We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss. The perspective verifies the properne
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#20855;&#26377;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#30340;&#38543;&#26426;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#20004;&#31181;&#38750;&#27431;&#20960;&#37324;&#24471;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#31934;&#24230;&#12289;&#38382;&#39064;&#21442;&#25968;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01497</link><description>&lt;p&gt;
&#20855;&#26377;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#30340;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Accelerated stochastic approximation with state-dependent noise. (arXiv:2307.01497v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01497
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#20855;&#26377;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#30340;&#38543;&#26426;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#20004;&#31181;&#38750;&#27431;&#20960;&#37324;&#24471;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#31934;&#24230;&#12289;&#38382;&#39064;&#21442;&#25968;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#19968;&#33324;&#22122;&#22768;&#20551;&#35774;&#30340;&#38543;&#26426;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#31867;&#38382;&#39064;&#65292;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#38543;&#26426;&#26799;&#24230;&#35266;&#27979;&#30340;&#22122;&#22768;&#30340;&#26041;&#24046;&#19982;&#31639;&#27861;&#20135;&#29983;&#30340;&#36817;&#20284;&#35299;&#30340;"&#20122;&#26368;&#20248;&#24615;" &#30456;&#20851;&#12290;&#36825;&#31867;&#38382;&#39064;&#22312;&#22810;&#31181;&#24212;&#29992;&#20013;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#65292;&#29305;&#21035;&#26159;&#22312;&#32479;&#35745;&#23398;&#20013;&#30340;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#29616;&#26377;&#30340;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#22312;&#31934;&#24230;&#12289;&#38382;&#39064;&#21442;&#25968;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#37117;&#26410;&#36798;&#21040;&#26368;&#20248;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#38750;&#27431;&#20960;&#37324;&#24471;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#8212;&#8212;&#38543;&#26426;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#65288;SAGD&#65289;&#21644;&#38543;&#26426;&#26799;&#24230;&#22806;&#25512;&#65288;SGE&#65289;&#8212;&#8212;&#23427;&#20204;&#20855;&#26377;&#19968;&#31181;&#29305;&#27530;&#30340;&#23545;&#20598;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
We consider a class of stochastic smooth convex optimization problems under rather general assumptions on the noise in the stochastic gradient observation. As opposed to the classical problem setting in which the variance of noise is assumed to be uniformly bounded, herein we assume that the variance of stochastic gradients is related to the "sub-optimality" of the approximate solutions delivered by the algorithm. Such problems naturally arise in a variety of applications, in particular, in the well-known generalized linear regression problem in statistics. However, to the best of our knowledge, none of the existing stochastic approximation algorithms for solving this class of problems attain optimality in terms of the dependence on accuracy, problem parameters, and mini-batch size.  We discuss two non-Euclidean accelerated stochastic approximation routines--stochastic accelerated gradient descent (SAGD) and stochastic gradient extrapolation (SGE)--which carry a particular duality rela
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;</title><link>http://arxiv.org/abs/2306.07252</link><description>&lt;p&gt;
&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07252
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#24120;&#35265;&#38750;&#20195;&#34920;&#24615;&#33410;&#28857;&#37319;&#26679;&#26426;&#21046;&#19979;&#30340;&#32593;&#32476;&#25968;&#25454;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#37319;&#26679;&#26426;&#21046;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#36229;&#24635;&#20307;&#30340;&#36873;&#25321;&#35268;&#21017;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#30740;&#31350;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#37319;&#26679;&#23376;&#38453;&#21015;&#22312;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#26159;&#21487;&#20132;&#25442;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#36890;&#36807;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;&#26469;&#37319;&#26679;&#26102;&#65292;&#21152;&#26435;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#21464;&#20307;&#21487;&#20197;&#23545;&#20154;&#21475;&#29420;&#31435;&#36873;&#25321;&#33410;&#28857;&#30340;&#39044;&#27979;&#38598;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.11140</link><description>&lt;p&gt;
&#22522;&#20110;&#28040;&#24687;&#20256;&#36882;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22823;&#35268;&#27169;&#38543;&#26426;&#22270;&#19978;&#30340;&#36890;&#29992;&#32858;&#21512;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence of Message Passing Graph Neural Networks with Generic Aggregation On Large Random Graphs. (arXiv:2304.11140v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11140
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#23558;&#25910;&#25947;&#32467;&#35770;&#20174;&#21482;&#36866;&#29992;&#20110;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#32858;&#21512;&#20989;&#25968;&#25193;&#23637;&#21040;&#25152;&#26377;&#20256;&#32479;&#32858;&#21512;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#26102;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#24403;&#33410;&#28857;&#25968;&#37327;&#36235;&#36817;&#20110;&#26080;&#38480;&#26102;&#65292;&#35813;&#32593;&#32476;&#27169;&#22411;&#33021;&#25910;&#25947;&#20110;&#20854;&#36830;&#32493;&#27169;&#22411;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#35813;&#25910;&#25947;&#24615;&#32467;&#26524;&#21482;&#36866;&#29992;&#20110;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#24230;&#35268;&#33539;&#21270;&#24179;&#22343;&#20540;&#24418;&#24335;&#30340;&#32593;&#32476;&#32467;&#26500;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;&#21253;&#21547;&#25152;&#26377;&#20256;&#32479;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#31867;&#32858;&#21512;&#20989;&#25968;&#19978;&#65292;&#20363;&#22914;&#22522;&#20110;&#27880;&#24847;&#21147;&#21644;&#26368;&#22823;&#21367;&#31215;&#30340;&#32593;&#32476;&#12290;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#39640;&#27010;&#29575;&#30340;&#38750;&#28176;&#36827;&#19978;&#38480;&#26469;&#37327;&#21270;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#22522;&#20110;McDiarmid&#19981;&#31561;&#24335;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#29305;&#21035;&#22788;&#29702;&#20102;&#32858;&#21512;&#20989;&#25968;&#37319;&#29992;&#36880;&#20010;&#22352;&#26631;&#26368;&#22823;&#20540;&#30340;&#24773;&#20917;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#38750;&#24120;&#19981;&#21516;&#30340;&#35777;&#26126;&#25216;&#24039;&#65292;&#24182;&#20135;&#29983;&#20102;&#23450;&#24615;&#19981;&#21516;&#30340;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the convergence of message passing graph neural networks on random graph models to their continuous counterpart as the number of nodes tends to infinity. Until now, this convergence was only known for architectures with aggregation functions in the form of degree-normalized means. We extend such results to a very large class of aggregation functions, that encompasses all classically used message passing graph neural networks, such as attention-based mesage passing or max convolutional message passing on top of (degree-normalized) convolutional message passing. Under mild assumptions, we give non asymptotic bounds with high probability to quantify this convergence. Our main result is based on the McDiarmid inequality. Interestingly, we treat the case where the aggregation is a coordinate-wise maximum separately, at it necessitates a very different proof technique and yields a qualitatively different convergence rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#36807;&#31243;&#35889;&#23494;&#24230;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#21644;&#36827;&#34892;&#20449;&#21495;&#25554;&#20540;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#22312;&#26102;&#38388;-&#39030;&#28857;&#20449;&#21495;&#20272;&#35745;&#38382;&#39064;&#20013;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.06887</link><description>&lt;p&gt;
&#20174;&#26102;&#38388;-&#39030;&#28857;&#35889;&#23398;&#20064;&#22270;ARMA&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Learning Graph ARMA Processes from Time-Vertex Spectra. (arXiv:2302.06887v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#36807;&#31243;&#35889;&#23494;&#24230;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#21644;&#36827;&#34892;&#20449;&#21495;&#25554;&#20540;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#22312;&#26102;&#38388;-&#39030;&#28857;&#20449;&#21495;&#20272;&#35745;&#38382;&#39064;&#20013;&#20855;&#26377;&#39640;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#26102;&#38388;&#21464;&#21270;&#30340;&#22270;&#20449;&#21495;&#24314;&#27169;&#20026;&#31283;&#24577;&#26102;&#38388;-&#39030;&#28857;&#38543;&#26426;&#36807;&#31243;&#65292;&#21487;&#20197;&#36890;&#36807;&#26377;&#25928;&#22320;&#21033;&#29992;&#36807;&#31243;&#22312;&#19981;&#21516;&#22270;&#33410;&#28857;&#21644;&#26102;&#38388;&#30636;&#38388;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#27169;&#24335;&#26469;&#25512;&#26029;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#29992;&#20110;&#22522;&#20110;&#23398;&#20064;&#36807;&#31243;&#30340;&#19981;&#23436;&#25972;&#23454;&#29616;&#30340;&#32852;&#21512;&#26102;&#38388;-&#39030;&#28857;&#21151;&#29575;&#35889;&#23494;&#24230;&#26469;&#35745;&#31639;&#22270;&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;&#65288;&#22270;ARMA&#65289;&#36807;&#31243;&#65292;&#20197;&#29992;&#20110;&#20449;&#21495;&#25554;&#20540;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#39318;&#20808;&#36890;&#36807;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#23454;&#29616;&#31895;&#30053;&#20272;&#35745;&#36807;&#31243;&#30340;&#32852;&#21512;&#35889;&#65292;&#28982;&#21518;&#36890;&#36807;&#20984;&#26494;&#24347;&#23558;&#20854;&#25237;&#24433;&#21040;&#22270;ARMA&#36807;&#31243;&#30340;&#35889;&#27969;&#24418;&#19978;&#26469;&#25913;&#36827;&#36825;&#20010;&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#22522;&#20110;&#23398;&#20064;&#30340;&#27169;&#22411;&#20272;&#35745;&#26368;&#21021;&#32570;&#22833;&#30340;&#20449;&#21495;&#20540;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26102;&#38388;-&#39030;&#28857;&#20449;&#21495;&#20272;&#35745;&#38382;&#39064;&#20013;&#36798;&#21040;&#20102;&#24456;&#39640;&#30340;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The modeling of time-varying graph signals as stationary time-vertex stochastic processes permits the inference of missing signal values by efficiently employing the correlation patterns of the process across different graph nodes and time instants. In this study, we propose an algorithm for computing graph autoregressive moving average (graph ARMA) processes based on learning the joint time-vertex power spectral density of the process from its incomplete realizations for the task of signal interpolation. Our solution relies on first roughly estimating the joint spectrum of the process from partially observed realizations and then refining this estimate by projecting it onto the spectrum manifold of the graph ARMA process through convex relaxations. The initially missing signal values are then estimated based on the learnt model. Experimental results show that the proposed approach achieves high accuracy in time-vertex signal estimation problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.00422</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#33719;&#24471;&#26631;&#35760;&#30340;&#35266;&#27979;&#25968;&#25454;&#24182;&#19981;&#31616;&#21333;&#65292;&#36890;&#24120;&#38656;&#35201;&#20154;&#24037;&#19987;&#23478;&#24178;&#39044;&#25110;&#20351;&#29992;&#26114;&#36149;&#30340;&#27979;&#35797;&#35774;&#22791;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#25311;&#21512;&#27169;&#22411;&#26102;&#26368;&#20449;&#24687;&#25968;&#25454;&#28857;&#30340;&#24314;&#35758;&#12290;&#20943;&#23569;&#27169;&#22411;&#24320;&#21457;&#25152;&#38656;&#30340;&#35266;&#27979;&#25968;&#25454;&#25968;&#37327;&#21487;&#20197;&#20943;&#36731;&#35757;&#32451;&#25152;&#38656;&#30340;&#35745;&#31639;&#36127;&#25285;&#21644;&#26631;&#35760;&#30456;&#20851;&#30340;&#25805;&#20316;&#25903;&#20986;&#12290;&#29305;&#21035;&#26159;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#22312;&#38656;&#35201;&#22312;&#26497;&#30701;&#26102;&#38388;&#20869;&#20915;&#23450;&#26159;&#21542;&#33719;&#21462;&#25968;&#25454;&#28857;&#26631;&#35760;&#30340;&#39640;&#23481;&#37327;&#29983;&#20135;&#36807;&#31243;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#33268;&#21147;&#20110;&#24320;&#21457;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#20294;&#22312;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36825;&#20123;&#26041;&#27861;&#30340;&#34892;&#20026;&#20173;&#26410;&#24471;&#21040;&#24443;&#24213;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22312;&#32447;&#20027;&#21160;&#32447;&#24615;&#22238;&#24402;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#21516;&#26102;&#20445;&#35777;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#24615;&#33021;&#39564;&#35777;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23545;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2301.11873</link><description>&lt;p&gt;
&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11873
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#24615;&#33021;&#39564;&#35777;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23545;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#65288;BMC&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#31454;&#20105;&#35745;&#31639;&#27169;&#22411;&#30340;&#30456;&#23545;&#20248;&#21183;&#65292;&#24182;&#23558;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#21040;&#27169;&#22411;&#36873;&#25321;&#20915;&#31574;&#20013;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39640;&#32500;&#23884;&#22871;&#21442;&#25968;&#32467;&#26500;&#65292;BMC&#22312;&#24120;&#35265;&#30340;&#23618;&#27425;&#27169;&#22411;&#20013;&#24120;&#24120;&#38590;&#20197;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38590;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#20219;&#20309;&#21487;&#23454;&#20363;&#21270;&#20026;&#27010;&#29575;&#31243;&#24207;&#30340;&#23618;&#27425;&#27169;&#22411;&#38598;&#36827;&#34892;BMC&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26041;&#27861;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#23427;&#21487;&#20197;&#22312;&#20219;&#20309;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#20043;&#21069;&#65292;&#23545;&#21518;&#39564;&#27169;&#22411;&#27010;&#29575;&#36827;&#34892;&#39640;&#25928;&#30340;&#37325;&#26032;&#20272;&#35745;&#21644;&#24555;&#36895;&#24615;&#33021;&#39564;&#35777;&#12290;&#22312;&#19968;&#31995;&#21015;&#24191;&#27867;&#30340;&#39564;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#27604;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26725;&#24335;&#25277;&#26679;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25152;&#26377;BMC&#35774;&#32622;&#20013;&#20986;&#33394;&#30340;&#20998;&#25674;&#25512;&#26029;&#33021;&#21147;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#20808;&#21069;&#34987;&#35748;&#20026;&#26159;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian model comparison (BMC) offers a principled approach for assessing the relative merits of competing computational models and propagating uncertainty into model selection decisions. However, BMC is often intractable for the popular class of hierarchical models due to their high-dimensional nested parameter structure. To address this intractability, we propose a deep learning method for performing BMC on any set of hierarchical models which can be instantiated as probabilistic programs. Since our method enables amortized inference, it allows efficient re-estimation of posterior model probabilities and fast performance validation prior to any real-data application. In a series of extensive validation studies, we benchmark the performance of our method against the state-of-the-art bridge sampling method and demonstrate excellent amortized inference across all BMC settings. We then showcase our method by comparing four hierarchical evidence accumulation models that have previously b
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#25239;&#24615;&#31574;&#30053;&#25915;&#20987;&#65292;&#25105;&#20204;&#25104;&#21151;&#25112;&#32988;&#20102;&#36229;&#32423;&#20154;&#31867;&#32423;&#22260;&#26827;AI KataGo&#65292;&#25581;&#31034;&#20102;&#20854;&#26680;&#24515;&#24369;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#21363;&#20351;&#26159;&#36229;&#32423;AI&#31995;&#32479;&#20063;&#21487;&#33021;&#23384;&#22312;&#24847;&#24819;&#19981;&#21040;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2211.00241</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#31574;&#30053;&#25112;&#32988;&#36229;&#32423;&#20154;&#31867;&#32423;&#22260;&#26827;AI
&lt;/p&gt;
&lt;p&gt;
Adversarial Policies Beat Superhuman Go AIs. (arXiv:2211.00241v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00241
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#25239;&#24615;&#31574;&#30053;&#25915;&#20987;&#65292;&#25105;&#20204;&#25104;&#21151;&#25112;&#32988;&#20102;&#36229;&#32423;&#20154;&#31867;&#32423;&#22260;&#26827;AI KataGo&#65292;&#25581;&#31034;&#20102;&#20854;&#26680;&#24515;&#24369;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#21363;&#20351;&#26159;&#36229;&#32423;AI&#31995;&#32479;&#20063;&#21487;&#33021;&#23384;&#22312;&#24847;&#24819;&#19981;&#21040;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#23545;&#25239;&#24615;&#31574;&#30053;&#26469;&#25915;&#20987;&#26368;&#20808;&#36827;&#30340;&#22260;&#26827;AI&#31995;&#32479;KataGo&#65292;&#22312;&#36229;&#20154;&#31867;&#35774;&#32622;&#19979;&#21462;&#24471;&#20102;&#36229;&#36807;97%&#30340;&#32988;&#29575;&#12290;&#25105;&#20204;&#30340;&#23545;&#25163;&#24182;&#19981;&#26159;&#36890;&#36807;&#20986;&#33394;&#22320;&#19979;&#22260;&#26827;&#26469;&#33719;&#32988;&#65292;&#32780;&#26159;&#36890;&#36807;&#35825;&#20351;KataGo&#29359;&#19979;&#20005;&#37325;&#22833;&#35823;&#12290;&#25105;&#20204;&#30340;&#25915;&#20987;&#21487;&#20197;&#38646;&#25439;&#32791;&#22320;&#20256;&#36755;&#32473;&#20854;&#20182;&#36229;&#32423;&#20154;&#31867;&#32423;&#22260;&#26827;AI&#65292;&#24182;&#19988;&#23545;&#20154;&#31867;&#19987;&#23478;&#26469;&#35828;&#26159;&#21487;&#20197;&#29702;&#35299;&#30340;&#65292;&#20182;&#20204;&#21487;&#20197;&#22312;&#27809;&#26377;&#31639;&#27861;&#36741;&#21161;&#30340;&#24773;&#20917;&#19979;&#23454;&#26045;&#36825;&#31181;&#25915;&#20987;&#26469;&#25345;&#32493;&#25112;&#32988;&#36229;&#32423;&#20154;&#31867;&#32423;AI&#12290;&#25105;&#20204;&#30340;&#25915;&#20987;&#25581;&#31034;&#20102;KataGo&#30340;&#26680;&#24515;&#24369;&#28857;&#65292;&#21363;&#20351;&#26159;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;KataGo&#20195;&#29702;&#20063;&#26080;&#27861;&#38450;&#24481;&#25105;&#20204;&#30340;&#25915;&#20987;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#26159;&#36229;&#32423;&#20154;&#31867;&#32423;&#30340;AI&#31995;&#32479;&#20063;&#21487;&#33021;&#23384;&#22312;&#24847;&#24819;&#19981;&#21040;&#30340;&#22833;&#36133;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
We attack the state-of-the-art Go-playing AI system KataGo by training adversarial policies against it, achieving a &gt;97% win rate against KataGo running at superhuman settings. Our adversaries do not win by playing Go well. Instead, they trick KataGo into making serious blunders. Our attack transfers zero-shot to other superhuman Go-playing AIs, and is comprehensible to the extent that human experts can implement it without algorithmic assistance to consistently beat superhuman AIs. The core vulnerability uncovered by our attack persists even in KataGo agents adversarially trained to defend against our attack. Our results demonstrate that even superhuman AI systems may harbor surprising failure modes. Example games are available https://goattack.far.ai/.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26031;&#22374;&#26816;&#39564;&#30340;&#36866;&#37197;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#20855;&#26377;&#19981;&#21516;&#32500;&#24230;&#35266;&#27979;&#30340;&#27010;&#29575;&#23494;&#24230;&#27169;&#22411;&#65292;&#21253;&#25324;&#25991;&#26412;&#25991;&#26723;&#25110;&#21487;&#21464;&#38271;&#24230;&#24207;&#21015;&#12290;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#20102;&#26680;&#26031;&#22374;&#24046;&#24322;(KSD)&#21040;&#21487;&#21464;&#32500;&#24230;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;KSD&#36866;&#37197;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#26080;&#38656;&#23494;&#24230;&#24402;&#19968;&#21270;&#65292;&#24182;&#22312;&#31163;&#25955;&#39034;&#24207;&#25968;&#25454;&#22522;&#20934;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2210.10741</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#26031;&#22374;&#26816;&#39564;&#30340;&#39034;&#24207;&#27169;&#22411;&#36866;&#37197;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
A kernel Stein test of goodness of fit for sequential models. (arXiv:2210.10741v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10741
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#26031;&#22374;&#26816;&#39564;&#30340;&#36866;&#37197;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#20855;&#26377;&#19981;&#21516;&#32500;&#24230;&#35266;&#27979;&#30340;&#27010;&#29575;&#23494;&#24230;&#27169;&#22411;&#65292;&#21253;&#25324;&#25991;&#26412;&#25991;&#26723;&#25110;&#21487;&#21464;&#38271;&#24230;&#24207;&#21015;&#12290;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#20102;&#26680;&#26031;&#22374;&#24046;&#24322;(KSD)&#21040;&#21487;&#21464;&#32500;&#24230;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;KSD&#36866;&#37197;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#26080;&#38656;&#23494;&#24230;&#24402;&#19968;&#21270;&#65292;&#24182;&#22312;&#31163;&#25955;&#39034;&#24207;&#25968;&#25454;&#22522;&#20934;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20855;&#26377;&#19981;&#21516;&#32500;&#24230;&#35266;&#27979;&#30340;&#27010;&#29575;&#23494;&#24230;&#27169;&#22411;&#30340;&#36866;&#37197;&#24615;&#24230;&#37327;&#26041;&#27861;&#65292;&#20363;&#22914;&#20855;&#26377;&#19981;&#21516;&#38271;&#24230;&#25110;&#21487;&#21464;&#38271;&#24230;&#24207;&#21015;&#30340;&#25991;&#26412;&#25991;&#26723;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#24230;&#37327;&#26041;&#27861;&#26159;&#26680;&#26031;&#22374;&#24046;&#24322;(Kernel Stein Discrepancy, KSD)&#30340;&#19968;&#20010;&#23454;&#20363;&#65292;KSD&#24050;&#34987;&#29992;&#20110;&#26500;&#24314;&#38750;&#26631;&#20934;&#21270;&#23494;&#24230;&#30340;&#36866;&#37197;&#24615;&#26816;&#39564;&#12290;KSD&#36890;&#36807;&#26031;&#22374;&#31639;&#23376;&#26469;&#23450;&#20041;&#65292;&#30446;&#21069;&#29992;&#20110;&#26816;&#39564;&#30340;&#26031;&#22374;&#31639;&#23376;&#36866;&#29992;&#20110;&#22266;&#23450;&#32500;&#24230;&#31354;&#38388;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#65292;&#25105;&#20204;&#36890;&#36807;&#35782;&#21035;&#21512;&#36866;&#30340;&#26031;&#22374;&#31639;&#23376;&#65292;&#22312;&#21487;&#21464;&#32500;&#24230;&#35774;&#32622;&#19979;&#25193;&#23637;&#20102;KSD&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;KSD&#36866;&#37197;&#24615;&#26816;&#39564;&#26041;&#27861;&#12290;&#19982;&#20043;&#21069;&#30340;&#21464;&#20307;&#19968;&#26679;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;KSD&#19981;&#35201;&#27714;&#23494;&#24230;&#24402;&#19968;&#21270;&#65292;&#21487;&#20197;&#35780;&#20272;&#22823;&#37327;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#22312;&#31163;&#25955;&#39034;&#24207;&#25968;&#25454;&#22522;&#20934;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a goodness-of-fit measure for probability densities modeling observations with varying dimensionality, such as text documents of differing lengths or variable-length sequences. The proposed measure is an instance of the kernel Stein discrepancy (KSD), which has been used to construct goodness-of-fit tests for unnormalized densities. The KSD is defined by its Stein operator: current operators used in testing apply to fixed-dimensional spaces. As our main contribution, we extend the KSD to the variable-dimension setting by identifying appropriate Stein operators, and propose a novel KSD goodness-of-fit test. As with the previous variants, the proposed KSD does not require the density to be normalized, allowing the evaluation of a large class of models. Our test is shown to perform well in practice on discrete sequential data benchmarks.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#29992;&#20110;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#20102;&#23450;&#20041;OOD&#27010;&#24565;&#21644;&#25552;&#20379;&#24378;&#26377;&#21147;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#19982;&#20043;&#21069;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#27979;&#35797;&#30456;&#27604;&#65292;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;OOD&#23454;&#20363;&#20013;&#34920;&#29616;&#26356;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2206.09522</link><description>&lt;p&gt;
&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#29992;&#20110;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#37325;&#26816;&#39564;&#26694;&#26550;&#29992;&#20110;&#31163;&#32676;&#20998;&#24067;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#20102;&#23450;&#20041;OOD&#27010;&#24565;&#21644;&#25552;&#20379;&#24378;&#26377;&#21147;&#20445;&#35777;&#30340;&#26041;&#27861;&#65292;&#19982;&#20043;&#21069;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#27979;&#35797;&#30456;&#27604;&#65292;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;OOD&#23454;&#20363;&#20013;&#34920;&#29616;&#26356;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#31163;&#32676;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#30340;&#38382;&#39064;&#65292;&#21363;&#22312;&#25512;&#29702;&#26102;&#26816;&#27979;&#23398;&#20064;&#31639;&#27861;&#30340;&#36755;&#20986;&#26159;&#21542;&#21487;&#20449;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#25552;&#20986;&#20102;&#19968;&#20123;OOD&#26816;&#27979;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#24418;&#24335;&#21270;&#30340;&#26694;&#26550;&#26469;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;OOD&#27010;&#24565;&#30340;&#23450;&#20041;&#65292;&#21253;&#25324;&#36755;&#20837;&#20998;&#24067;&#21644;&#23398;&#20064;&#31639;&#27861;&#65292;&#36825;&#20026;&#26500;&#24314;&#24378;&#22823;&#30340;OOD&#26816;&#27979;&#27979;&#35797;&#25552;&#20379;&#20102;&#21551;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#21551;&#21457;&#30340;&#36807;&#31243;&#65292;&#20351;&#29992;&#31526;&#21512;&#24615;p&#20540;&#31995;&#32479;&#22320;&#32467;&#21512;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#20219;&#24847;&#25968;&#37327;&#30340;&#19981;&#21516;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23545;&#23558;&#20837;&#32676;&#26679;&#26412;&#38169;&#35823;&#20998;&#31867;&#20026;OOD&#30340;&#27010;&#29575;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#20445;&#35777;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20043;&#21069;&#24037;&#20316;&#20013;&#25552;&#20986;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#27979;&#35797;&#22312;&#29305;&#23450;&#22330;&#26223;&#19979;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312;&#19981;&#21516;&#31867;&#22411;&#30340;OOD&#23454;&#20363;&#20013;&#30340;&#34920;&#29616;&#24182;&#19981;&#19968;&#33268;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;m&#20010;&#19981;&#21516;&#32479;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of Out-of-Distribution (OOD) detection, that is, detecting whether a learning algorithm's output can be trusted at inference time. While a number of tests for OOD detection have been proposed in prior work, a formal framework for studying this problem is lacking. We propose a definition for the notion of OOD that includes both the input distribution and the learning algorithm, which provides insights for the construction of powerful tests for OOD detection. We propose a multiple hypothesis testing inspired procedure to systematically combine any number of different statistics from the learning algorithm using conformal p-values. We further provide strong guarantees on the probability of incorrectly classifying an in-distribution sample as OOD. In our experiments, we find that threshold-based tests proposed in prior work perform well in specific settings, but not uniformly well across different types of OOD instances. In contrast, our proposed method that combines m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#23545;&#28151;&#21512;&#26102;&#38388;&#26377;&#20219;&#20309;&#20102;&#35299;&#65292;&#20294;&#22312;&#20984;&#38382;&#39064;&#20013;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#31181;&#26041;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;&#20248;&#21270;&#20197;&#21450;&#26102;&#24046;&#23398;&#20064;&#65292;&#24182;&#19988;&#23436;&#20840;&#26080;&#35270;&#28151;&#21512;&#26102;&#38388;&#12290;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#26799;&#24230;&#20272;&#35745;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#30340;&#32452;&#21512;&#12290;</title><link>http://arxiv.org/abs/2202.04428</link><description>&lt;p&gt;
&#36866;&#24212;&#20855;&#26377;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#38543;&#26426;&#20248;&#21270;&#20013;&#30340;&#28151;&#21512;&#26102;&#38388;
&lt;/p&gt;
&lt;p&gt;
Adapting to Mixing Time in Stochastic Optimization with Markovian Data. (arXiv:2202.04428v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04428
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#23545;&#28151;&#21512;&#26102;&#38388;&#26377;&#20219;&#20309;&#20102;&#35299;&#65292;&#20294;&#22312;&#20984;&#38382;&#39064;&#20013;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#31181;&#26041;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;&#20248;&#21270;&#20197;&#21450;&#26102;&#24046;&#23398;&#20064;&#65292;&#24182;&#19988;&#23436;&#20840;&#26080;&#35270;&#28151;&#21512;&#26102;&#38388;&#12290;&#26041;&#27861;&#30340;&#20851;&#38190;&#26159;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;&#26799;&#24230;&#20272;&#35745;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#25968;&#25454;&#20174;&#39532;&#23572;&#21487;&#22827;&#38142;&#20013;&#25552;&#21462;&#30340;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#36825;&#31181;&#35774;&#32622;&#30340;&#26041;&#27861;&#20851;&#38190;&#20381;&#36182;&#20110;&#23545;&#38142;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#20102;&#35299;&#65292;&#32780;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#38656;&#35201;&#20102;&#35299;&#28151;&#21512;&#26102;&#38388;&#30340;&#26368;&#20248;&#21270;&#26041;&#27861;&#65292;&#20294;&#22312;&#24212;&#29992;&#20110;&#20984;&#38382;&#39064;&#26102;&#21487;&#20197;&#33719;&#24471;&#26368;&#20248;&#30340;&#28176;&#36817;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25193;&#23637;&#21040;&#65306;(i)&#23547;&#25214;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#31283;&#23450;&#28857;&#20197;&#21450;(ii)&#22312;&#26102;&#24046;&#23398;&#20064;&#20013;&#33719;&#24471;&#23545;&#28151;&#21512;&#26102;&#38388;&#26356;&#22909;&#30340;&#20381;&#36182;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#28151;&#21512;&#26102;&#38388;&#23436;&#20840;&#26080;&#35270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#22810;&#23618;&#33945;&#29305;&#21345;&#27931;(MLMC)&#26799;&#24230;&#20272;&#35745;&#19982;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#30340;&#26032;&#39062;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider stochastic optimization problems where data is drawn from a Markov chain. Existing methods for this setting crucially rely on knowing the mixing time of the chain, which in real-world applications is usually unknown. We propose the first optimization method that does not require the knowledge of the mixing time, yet obtains the optimal asymptotic convergence rate when applied to convex problems. We further show that our approach can be extended to: (i) finding stationary points in non-convex optimization with Markovian data, and (ii) obtaining better dependence on the mixing time in temporal difference (TD) learning; in both cases, our method is completely oblivious to the mixing time. Our method relies on a novel combination of multi-level Monte Carlo (MLMC) gradient estimation together with an adaptive learning method.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36890;&#36807;&#20256;&#25773;&#26041;&#21521;&#19981;&#21464;&#24615;&#26469;&#27867;&#21270;&#21040;&#26032;&#39062;&#26041;&#21521;&#19978;&#30340;&#23545;&#35937;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#33021;&#21147;&#21463;&#21040;&#35757;&#32451;&#20013;&#20351;&#29992;&#30340;&#29087;&#24713;&#23545;&#35937;&#25968;&#37327;&#30340;&#24433;&#21709;&#65292;&#20294;&#20165;&#38480;&#20110;&#28041;&#21450;2D&#26059;&#36716;&#30340;&#29087;&#24713;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2109.13445</link><description>&lt;p&gt;
&#26032;&#39062;&#26041;&#21521;&#19978;&#23545;&#35937;&#27867;&#21270;&#30340;&#26032;&#20852;&#31070;&#32463;&#32593;&#32476;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations. (arXiv:2109.13445v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.13445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#35777;&#25454;&#34920;&#26126;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36890;&#36807;&#20256;&#25773;&#26041;&#21521;&#19981;&#21464;&#24615;&#26469;&#27867;&#21270;&#21040;&#26032;&#39062;&#26041;&#21521;&#19978;&#30340;&#23545;&#35937;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#33021;&#21147;&#21463;&#21040;&#35757;&#32451;&#20013;&#20351;&#29992;&#30340;&#29087;&#24713;&#23545;&#35937;&#25968;&#37327;&#30340;&#24433;&#21709;&#65292;&#20294;&#20165;&#38480;&#20110;&#28041;&#21450;2D&#26059;&#36716;&#30340;&#29087;&#24713;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#22312;&#35782;&#21035;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#20043;&#22806;&#30340;&#26041;&#21521;&#19978;&#30340;&#23545;&#35937;&#30340;&#33021;&#21147;&#23578;&#19981;&#23436;&#20840;&#20102;&#35299;&#12290;&#25105;&#20204;&#25552;&#20379;&#35777;&#25454;&#34920;&#26126;&#65292;DNNs&#33021;&#22815;&#36890;&#36807;&#20256;&#25773;&#20174;&#22810;&#20010;&#35270;&#28857;&#35266;&#23519;&#21040;&#30340;&#29087;&#24713;&#23545;&#35937;&#33719;&#24471;&#30340;&#26041;&#21521;&#19981;&#21464;&#24615;&#26469;&#27867;&#21270;&#21040;&#26032;&#39062;&#26041;&#21521;&#19978;&#30340;&#23545;&#35937;&#12290;&#36825;&#31181;&#33021;&#21147;&#22312;&#35757;&#32451;DNN&#26102;&#20351;&#29992;&#36234;&#26469;&#36234;&#22810;&#30340;&#29087;&#24713;&#23545;&#35937;&#26102;&#20250;&#22686;&#24378;&#65292;&#20294;&#20165;&#38480;&#20110;&#28041;&#21450;&#21040;&#29087;&#24713;&#26041;&#21521;&#30340;2D&#26059;&#36716;&#30340;&#26041;&#21521;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#20256;&#25773;&#26159;&#36890;&#36807;&#35843;&#25972;&#21040;&#29087;&#24713;&#21644;&#19981;&#29087;&#24713;&#23545;&#35937;&#20043;&#38388;&#20849;&#21516;&#29305;&#24449;&#30340;&#31070;&#32463;&#20803;&#23454;&#29616;&#30340;&#12290;&#36825;&#20123;&#32467;&#26524;&#25581;&#31034;&#20102;&#31867;&#33041;&#31070;&#32463;&#26426;&#21046;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
The capability of Deep Neural Networks (DNNs) to recognize objects in orientations outside the distribution of the training data is not well understood. We present evidence that DNNs are capable of generalizing to objects in novel orientations by disseminating orientation-invariance obtained from familiar objects seen from many viewpoints. This capability strengthens when training the DNN with an increasing number of familiar objects, but only in orientations that involve 2D rotations of familiar orientations. We show that this dissemination is achieved via neurons tuned to common features between familiar and unfamiliar objects. These results implicate brain-like neural mechanisms for generalization.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#32593;&#32476;&#20013;&#20302;&#31209;&#28508;&#22312;&#20013;&#23610;&#24230;&#32467;&#26500;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#32593;&#32476;&#27169;&#22411;&#21644;&#23454;&#38469;&#32593;&#32476;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#23569;&#37327;&#30340;&#8220;&#28508;&#22312;&#27169;&#24335;&#8221;&#65292;&#21487;&#20197;&#25104;&#21151;&#22320;&#36817;&#20284;&#32593;&#32476;&#30340;&#22823;&#22810;&#25968;&#23376;&#22270;&#12290;&#36825;&#39033;&#30740;&#31350;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#34892;&#20026;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2102.06984</link><description>&lt;p&gt;
&#22312;&#32593;&#32476;&#20013;&#23398;&#20064;&#20302;&#31209;&#28508;&#22312;&#20013;&#23610;&#24230;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v5 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.06984
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#32593;&#32476;&#20013;&#20302;&#31209;&#28508;&#22312;&#20013;&#23610;&#24230;&#32467;&#26500;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#21512;&#25104;&#32593;&#32476;&#27169;&#22411;&#21644;&#23454;&#38469;&#32593;&#32476;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#21033;&#29992;&#23569;&#37327;&#30340;&#8220;&#28508;&#22312;&#27169;&#24335;&#8221;&#65292;&#21487;&#20197;&#25104;&#21151;&#22320;&#36817;&#20284;&#32593;&#32476;&#30340;&#22823;&#22810;&#25968;&#23376;&#22270;&#12290;&#36825;&#39033;&#30740;&#31350;&#23545;&#20110;&#29702;&#35299;&#22797;&#26434;&#31995;&#32479;&#30340;&#34892;&#20026;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22797;&#26434;&#31995;&#32479;&#20013;&#65292;&#24120;&#24120;&#20351;&#29992;&#32593;&#32476;&#26469;&#32534;&#30721;&#23454;&#20307;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#30340;&#20307;&#31995;&#32467;&#26500;&#65292;&#21253;&#25324;&#29289;&#29702;&#12289;&#29983;&#29289;&#12289;&#31038;&#20250;&#21644;&#20449;&#24687;&#31185;&#23398;&#12290;&#20026;&#20102;&#30740;&#31350;&#22797;&#26434;&#31995;&#32479;&#30340;&#22823;&#35268;&#27169;&#34892;&#20026;&#65292;&#26377;&#24517;&#35201;&#30740;&#31350;&#32593;&#32476;&#20013;&#30340;&#20013;&#23610;&#24230;&#32467;&#26500;&#20316;&#20026;&#24433;&#21709;&#36825;&#31181;&#34892;&#20026;&#30340;&#26500;&#24314;&#22359;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25551;&#36848;&#32593;&#32476;&#20013;&#20302;&#31209;&#28508;&#22312;&#20013;&#23610;&#24230;&#32467;&#26500;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#20351;&#29992;&#20960;&#20010;&#21512;&#25104;&#32593;&#32476;&#27169;&#22411;&#21644;&#23454;&#35777;&#21451;&#35850;&#12289;&#21512;&#20316;&#21644;&#34507;&#30333;&#36136;&#30456;&#20114;&#20316;&#29992;&#65288;PPI&#65289;&#32593;&#32476;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36825;&#20123;&#32593;&#32476;&#20855;&#26377;&#19968;&#20010;&#30456;&#23545;&#36739;&#23567;&#25968;&#37327;&#30340;&#8220;&#28508;&#22312;&#27169;&#24335;&#8221;&#65292;&#36825;&#20123;&#27169;&#24335;&#20849;&#21516;&#21487;&#20197;&#25104;&#21151;&#22320;&#36817;&#20284;&#32593;&#32476;&#30340;&#22823;&#22810;&#25968;&#23376;&#22270;&#22312;&#22266;&#23450;&#30340;&#20013;&#23610;&#24230;&#19978;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#31181;&#8220;&#32593;&#32476;&#23383;&#20856;&#23398;&#20064;&#8221;&#65288;NDL&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#32467;&#21512;&#20102;&#32593;&#32476;&#37319;&#26679;&#26041;&#27861;&#21644;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65292;&#20197;&#23398;&#20064;&#32473;&#23450;&#32593;&#32476;&#30340;&#28508;&#22312;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is common to use networks to encode the architecture of interactions between entities in complex systems in the physical, biological, social, and information sciences. To study the large-scale behavior of complex systems, it is useful to examine mesoscale structures in networks as building blocks that influence such behavior. We present a new approach for describing low-rank mesoscale structures in networks, and we illustrate our approach using several synthetic network models and empirical friendship, collaboration, and protein--protein interaction (PPI) networks. We find that these networks possess a relatively small number of `latent motifs' that together can successfully approximate most subgraphs of a network at a fixed mesoscale. We use an algorithm for `network dictionary learning' (NDL), which combines a network-sampling method and nonnegative matrix factorization, to learn the latent motifs of a given network. The ability to encode a network using a set of latent motifs has
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#31181;&#20132;&#26367;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#38024;&#23545;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#20855;&#26377;&#24378;&#26377;&#21147;&#30340;&#21487;&#38752;&#20445;&#35777;&#65292;&#21516;&#26102;&#22312;&#22788;&#29702;&#39640;&#24230;&#30456;&#20851;&#22240;&#23376;&#26102;&#20173;&#33021;&#32447;&#24615;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#65292;&#24182;&#19988;&#20855;&#26377;&#26497;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2006.03134</link><description>&lt;p&gt;
&#24352;&#37327;&#34917;&#20840;&#30340;&#23454;&#29992;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Tensor Completion Made Practical. (arXiv:2006.03134v2 [cs.DS] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.03134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#31181;&#20132;&#26367;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#38024;&#23545;&#24352;&#37327;&#34917;&#20840;&#38382;&#39064;&#65292;&#20855;&#26377;&#24378;&#26377;&#21147;&#30340;&#21487;&#38752;&#20445;&#35777;&#65292;&#21516;&#26102;&#22312;&#22788;&#29702;&#39640;&#24230;&#30456;&#20851;&#22240;&#23376;&#26102;&#20173;&#33021;&#32447;&#24615;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#65292;&#24182;&#19988;&#20855;&#26377;&#26497;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#34917;&#20840;&#26159;&#23545;&#30697;&#38453;&#34917;&#20840;&#30340;&#39640;&#38454;&#25512;&#24191;&#65292;&#20854;&#30446;&#26631;&#26159;&#20174;&#23545;&#20854;&#39033;&#30340;&#31232;&#30095;&#35266;&#27979;&#20013;&#24674;&#22797;&#20986;&#20302;&#31209;&#24352;&#37327;&#12290;&#29616;&#26377;&#30340;&#31639;&#27861;&#35201;&#20040;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#27809;&#26377;&#21487;&#38752;&#30340;&#20445;&#35777;&#65307;&#35201;&#20040;&#22522;&#20110;&#27714;&#35299;&#22823;&#22411;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#65292;&#19981;&#21487;&#34892;&#65307;&#25110;&#32773;&#26159;&#38656;&#35201;&#24378;&#20551;&#35774;&#65292;&#20363;&#22914;&#35201;&#27714;&#22240;&#23376;&#36817;&#20284;&#27491;&#20132;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#20132;&#26367;&#26368;&#23567;&#21270;&#21464;&#31181;&#65292;&#21463;&#21040;&#20102;&#29702;&#35299;&#20132;&#26367;&#26368;&#23567;&#21270;&#22312;&#30697;&#38453;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#25351;&#26631;&#22914;&#20309;&#36866;&#24212;&#24352;&#37327;&#24773;&#20917;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24378;&#26377;&#21147;&#30340;&#21487;&#38752;&#20445;&#35777;&#65292;&#21253;&#25324;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#22240;&#23376;&#39640;&#24230;&#30456;&#20851;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20063;&#33021;&#32447;&#24615;&#25910;&#25947;&#21040;&#30495;&#23454;&#24352;&#37327;&#65292;&#24182;&#19988;&#20960;&#20046;&#21487;&#20197;&#22312;&#32447;&#24615;&#26102;&#38388;&#20869;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20063;&#38750;&#24120;&#23454;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#21487;&#20197;&#20174;&#35266;&#27979;&#21040;&#30340;&#24494;&#23567;&#20449;&#24687;&#20013;&#34917;&#20840;&#21315;&#32500;&#24230;&#30340;&#19977;&#38454;&#24352;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor completion is a natural higher-order generalization of matrix completion where the goal is to recover a low-rank tensor from sparse observations of its entries. Existing algorithms are either heuristic without provable guarantees, based on solving large semidefinite programs which are impractical to run, or make strong assumptions such as requiring the factors to be nearly orthogonal. In this paper we introduce a new variant of alternating minimization, which in turn is inspired by understanding how the progress measures that guide convergence of alternating minimization in the matrix setting need to be adapted to the tensor setting. We show strong provable guarantees, including showing that our algorithm converges linearly to the true tensors even when the factors are highly correlated and can be implemented in nearly linear time. Moreover our algorithm is also highly practical and we show that we can complete third order tensors with a thousand dimensions from observing a tiny
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#21333;&#19968;&#35270;&#39057;&#28436;&#31034;&#20013;&#23398;&#20064;&#27169;&#20223;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#27604;&#35757;&#32451;&#21644;Siamese&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21040;&#26234;&#33021;&#20307;&#30340;&#34892;&#20026;&#19982;&#28436;&#31034;&#20043;&#38388;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807; RL &#31574;&#30053;&#30340;&#35757;&#32451;&#26368;&#23567;&#21270;&#36825;&#20010;&#36317;&#31163;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#24341;&#20837;&#22810;&#20219;&#21153;&#25968;&#25454;&#21644;&#39069;&#22806;&#30340;&#22270;&#20687;&#32534;&#30721;&#25439;&#22833;&#21487;&#20197;&#25913;&#21892;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#30340;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#32500;&#24230;&#30340;&#20223;&#30495;&#26234;&#33021;&#20307;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/1901.07186</link><description>&lt;p&gt;
&#20174;&#19968;&#20010;&#21333;&#19968;&#30340;&#35270;&#39057;&#28436;&#31034;&#20013;&#23398;&#20064;&#27169;&#20223;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Towards Learning to Imitate from a Single Video Demonstration. (arXiv:1901.07186v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1901.07186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#21333;&#19968;&#35270;&#39057;&#28436;&#31034;&#20013;&#23398;&#20064;&#27169;&#20223;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#27604;&#35757;&#32451;&#21644;Siamese&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21040;&#26234;&#33021;&#20307;&#30340;&#34892;&#20026;&#19982;&#28436;&#31034;&#20043;&#38388;&#30340;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807; RL &#31574;&#30053;&#30340;&#35757;&#32451;&#26368;&#23567;&#21270;&#36825;&#20010;&#36317;&#31163;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#24341;&#20837;&#22810;&#20219;&#21153;&#25968;&#25454;&#21644;&#39069;&#22806;&#30340;&#22270;&#20687;&#32534;&#30721;&#25439;&#22833;&#21487;&#20197;&#25913;&#21892;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#30340;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#32500;&#24230;&#30340;&#20223;&#30495;&#26234;&#33021;&#20307;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#20174;&#35270;&#39057;&#35266;&#23519;&#20013;&#23398;&#20064;&#27169;&#20223;&#30340;&#26234;&#33021;&#20307;&#8212;&#8212;\emph{&#27809;&#26377;&#30452;&#25509;&#35775;&#38382;&#29366;&#24577;&#25110;&#21160;&#20316;&#20449;&#24687;}&#65292;&#23545;&#20110;&#22312;&#33258;&#28982;&#19990;&#30028;&#20013;&#30340;&#23398;&#20064;&#26356;&#20855;&#36866;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#21046;&#23450;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#27492;&#30446;&#26631;&#30340;&#22686;&#24378;&#23398;&#20064;&#65288;RL&#65289;&#26234;&#33021;&#20307;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#20351;&#29992;&#23545;&#27604;&#35757;&#32451;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#23398;&#20064;&#19968;&#20010;&#23558;&#26234;&#33021;&#20307;&#30340;&#34892;&#20026;&#19982;&#21333;&#20010;&#28436;&#31034;&#36827;&#34892;&#27604;&#36739;&#30340;&#22870;&#21169;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#36830;&#20307;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#22312;&#26102;&#38388;&#21644;&#31354;&#38388;&#19978;&#23398;&#20064;&#21160;&#20316;&#29255;&#27573;&#20043;&#38388;&#30340;&#22870;&#21169;&#65292;&#21516;&#26102;&#35757;&#32451;&#19968;&#20010;RL&#31574;&#30053;&#26469;&#26368;&#23567;&#21270;&#36825;&#20010;&#36317;&#31163;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22810;&#20219;&#21153;&#25968;&#25454;&#21644;&#39069;&#22806;&#30340;&#22270;&#20687;&#32534;&#30721;&#25439;&#22833;&#30340;&#24341;&#20837;&#25913;&#36827;&#20102;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#30340;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#26174;&#30528;&#25552;&#39640;&#20102;&#31574;&#30053;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#22312;2D&#20013;&#30340;&#27169;&#25311;&#20154;&#22411;&#12289;&#29399;&#21644;&#36805;&#29467;&#40857;&#26234;&#33021;&#20307;&#20197;&#21450;3D&#20013;&#30340;&#22235;&#36275;&#21160;&#29289;&#21644;&#20154;&#22411;&#26234;&#33021;&#20307;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;
Agents that can learn to imitate given video observation -- \emph{without direct access to state or action information} are more applicable to learning in the natural world. However, formulating a reinforcement learning (RL) agent that facilitates this goal remains a significant challenge. We approach this challenge using contrastive training to learn a reward function comparing an agent's behaviour with a single demonstration. We use a Siamese recurrent neural network architecture to learn rewards in space and time between motion clips while training an RL policy to minimize this distance. Through experimentation, we also find that the inclusion of multi-task data and additional image encoding losses improve the temporal consistency of the learned rewards and, as a result, significantly improves policy learning. We demonstrate our approach on simulated humanoid, dog, and raptor agents in 2D and a quadruped and a humanoid in 3D. We show that our method outperforms current state-of-the-
&lt;/p&gt;</description></item></channel></rss>