<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#36890;&#36807;&#23558;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#34920;&#31034;&#20026;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#38543;&#26426;&#31215;&#20998;&#65292;&#23454;&#29616;&#20102;&#39537;&#21160;&#22122;&#22768;&#25910;&#25947;&#21040;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#25928;&#26524;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38543;&#26426;&#36807;&#31243;&#19978;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#23581;&#35797;&#12290;</title><link>http://arxiv.org/abs/2310.17638</link><description>&lt;p&gt;
&#29983;&#25104;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Fractional Diffusion Models. (arXiv:2310.17638v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#36890;&#36807;&#23558;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#34920;&#31034;&#20026;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#38543;&#26426;&#31215;&#20998;&#65292;&#23454;&#29616;&#20102;&#39537;&#21160;&#22122;&#22768;&#25910;&#25947;&#21040;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#25928;&#26524;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38543;&#26426;&#36807;&#31243;&#19978;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#23581;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#22522;&#20110;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#65288;FBM&#65289;&#30340;&#36830;&#32493;&#26102;&#38388;&#26694;&#26550;&#25512;&#24191;&#21040;&#22522;&#20110;&#20998;&#25968;&#24067;&#26391;&#36816;&#21160;&#30340;&#36817;&#20284;&#24418;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;FBM&#34920;&#31034;&#20026;&#23478;&#26063;&#22885;&#24681;&#26031;&#22374;-&#20044;&#20262;&#36125;&#20811;&#36807;&#31243;&#30340;&#38543;&#26426;&#31215;&#20998;&#65292;&#25512;&#23548;&#20986;&#36830;&#32493;&#20877;&#21442;&#25968;&#21270;&#25216;&#24039;&#21644;&#36870;&#26102;&#27169;&#22411;&#65292;&#23450;&#20041;&#20102;&#20855;&#26377;&#39537;&#21160;&#22122;&#22768;&#25910;&#25947;&#21040;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38750;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#29983;&#25104;&#20998;&#25968;&#38454;&#25193;&#25955;&#27169;&#22411;&#65288;GFDM&#65289;&#12290;FBM&#30340;&#36203;&#26031;&#29305;&#25351;&#25968;$H \in (0,1)$ &#21487;&#20197;&#25511;&#21046;&#36335;&#24452;&#21464;&#25442;&#20998;&#24067;&#30340;&#31895;&#31961;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#27425;&#23581;&#35797;&#22312;&#20855;&#26377;&#26080;&#38480;&#20108;&#27425;&#21464;&#24046;&#30340;&#38543;&#26426;&#36807;&#31243;&#19978;&#24314;&#31435;&#29983;&#25104;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We generalize the continuous time framework for score-based generative models from an underlying Brownian motion (BM) to an approximation of fractional Brownian motion (FBM). We derive a continuous reparameterization trick and the reverse time model by representing FBM as a stochastic integral over a family of Ornstein-Uhlenbeck processes to define generative fractional diffusion models (GFDM) with driving noise converging to a non-Markovian process of infinite quadratic variation. The Hurst index $H\in(0,1)$ of FBM enables control of the roughness of the distribution transforming path. To the best of our knowledge, this is the first attempt to build a generative model upon a stochastic process with infinite quadratic variation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#65292;&#29992;&#20110;&#22788;&#29702;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#23478;&#26063;&#20013;&#20351;&#29992;&#19981;&#21487;&#24494;&#20998;&#27491;&#21017;&#21270;&#22120;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#35745;&#31639;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;LO&#65289;&#21644;&#36817;&#20284;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;ALO&#65289;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#32771;&#34385;&#30041;&#19968;&#25200;&#21160;&#30340;&#22823;&#23567;&#12289;&#26679;&#26412;&#22823;&#23567;&#12289;&#29305;&#24449;&#25968;&#37327;&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;ALO&#35823;&#24046;&#30340;&#37325;&#35201;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.17629</link><description>&lt;p&gt;
&#20351;&#29992;$\ell_1$&#27491;&#21017;&#21270;&#36827;&#34892;&#22238;&#24402;&#30340;&#36817;&#20284;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;&#25193;&#23637;&#29256;&#65289;
&lt;/p&gt;
&lt;p&gt;
Approximate Leave-one-out Cross Validation for Regression with $\ell_1$ Regularizers (extended version). (arXiv:2310.17629v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17629
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#65292;&#29992;&#20110;&#22788;&#29702;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#23478;&#26063;&#20013;&#20351;&#29992;&#19981;&#21487;&#24494;&#20998;&#27491;&#21017;&#21270;&#22120;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#35745;&#31639;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;LO&#65289;&#21644;&#36817;&#20284;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;ALO&#65289;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#32771;&#34385;&#30041;&#19968;&#25200;&#21160;&#30340;&#22823;&#23567;&#12289;&#26679;&#26412;&#22823;&#23567;&#12289;&#29305;&#24449;&#25968;&#37327;&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;ALO&#35823;&#24046;&#30340;&#37325;&#35201;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39118;&#38505;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#20013;&#65292;&#22806;&#26679;&#35823;&#24046;&#65288;OO&#65289;&#26159;&#20027;&#35201;&#30340;&#20851;&#27880;&#37327;&#12290;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;LO&#65289;&#25552;&#20379;&#20102;&#19968;&#20010;&#65288;&#20960;&#20046;&#65289;&#26080;&#20998;&#24067;&#30340;&#12289;&#20294;&#35745;&#31639;&#22797;&#26434;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;OO&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#24037;&#20316;&#34920;&#26126;&#65292;&#36817;&#20284;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#65288;ALO&#65289;&#26159;&#23545;&#20855;&#26377;&#21487;&#24494;&#20998;&#27491;&#21017;&#21270;&#22120;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#30340;LO&#65288;&#21644;OO&#65289;&#30340;&#35745;&#31639;&#26377;&#25928;&#21644;&#32479;&#35745;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#23545;&#20110;&#28041;&#21450;&#19981;&#21487;&#24494;&#20998;&#27491;&#21017;&#21270;&#22120;&#30340;&#38382;&#39064;&#65292;&#23613;&#31649;&#26377;&#37325;&#35201;&#30340;&#32463;&#39564;&#35777;&#25454;&#65292;&#20294;&#23545;ALO&#35823;&#24046;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#26410;&#30693;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#29702;&#35770;&#65292;&#36866;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#23478;&#26063;&#20013;&#20855;&#26377;&#19981;&#21487;&#24494;&#20998;&#27491;&#21017;&#21270;&#22120;&#30340;&#24191;&#27867;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;ALO - LO&#30340;&#35823;&#24046;&#32465;&#23450;&#22312;&#30452;&#35266;&#25351;&#26631;&#65292;&#22914;&#30041;&#19968;&#25200;&#21160;&#30340;&#22823;&#23567;&#12289;&#26679;&#26412;&#22823;&#23567;n&#12289;&#29305;&#24449;&#25968;&#37327;p&#21644;&#27491;&#21017;&#21270;&#21442;&#25968;&#26041;&#38754;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;$\ell_1$&#27491;&#21017;&#21270;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22914;&#20309;&#35745;&#31639;&#21644;&#30028;&#23450;ALO&#35823;&#24046;&#30340;&#20851;&#38190;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The out-of-sample error (OO) is the main quantity of interest in risk estimation and model selection. Leave-one-out cross validation (LO) offers a (nearly) distribution-free yet computationally demanding approach to estimate OO. Recent theoretical work showed that approximate leave-one-out cross validation (ALO) is a computationally efficient and statistically reliable estimate of LO (and OO) for generalized linear models with differentiable regularizers. For problems involving non-differentiable regularizers, despite significant empirical evidence, the theoretical understanding of ALO's error remains unknown. In this paper, we present a novel theory for a wide class of problems in the generalized linear model family with non-differentiable regularizers. We bound the error |ALO - LO| in terms of intuitive metrics such as the size of leave-i-out perturbations in active sets, sample size n, number of features p and regularization parameters. As a consequence, for the $\ell_1$-regularized
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25581;&#31034;&#20102;&#36890;&#36807;&#37096;&#20998;&#27491;&#20132;&#24615;&#26469;&#25429;&#25417;&#23884;&#20837;&#30340;&#35821;&#20041;&#29420;&#31435;&#24615;&#65292;&#25552;&#20986;&#20102;&#20445;&#25345;&#29420;&#31435;&#24615;&#30340;&#23884;&#20837;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2310.17611</link><description>&lt;p&gt;
&#36890;&#36807;&#37096;&#20998;&#27491;&#20132;&#24615;&#25581;&#31034;&#23884;&#20837;&#30340;&#21547;&#20041;
&lt;/p&gt;
&lt;p&gt;
Uncovering Meanings of Embeddings via Partial Orthogonality. (arXiv:2310.17611v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#36890;&#36807;&#37096;&#20998;&#27491;&#20132;&#24615;&#26469;&#25429;&#25417;&#23884;&#20837;&#30340;&#35821;&#20041;&#29420;&#31435;&#24615;&#65292;&#25552;&#20986;&#20102;&#20445;&#25345;&#29420;&#31435;&#24615;&#30340;&#23884;&#20837;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#36890;&#24120;&#20381;&#36182;&#20110;&#23558;&#25991;&#26412;&#23884;&#20837;&#20026;&#23454;&#25968;&#21521;&#37327;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#35821;&#20041;&#32467;&#26500;&#22914;&#20309;&#22312;&#36825;&#20123;&#23884;&#20837;&#30340;&#20195;&#25968;&#32467;&#26500;&#20013;&#34987;&#32534;&#30721;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#31216;&#20026;&#8220;&#35821;&#20041;&#29420;&#31435;&#24615;&#8221;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#25429;&#25417;&#20102;&#8220;&#33540;&#23376;&#8221;&#21644;&#8220;&#35199;&#32418;&#26623;&#8221;&#30456;&#23545;&#20110;&#8220;&#34092;&#33756;&#8221;&#30340;&#29420;&#31435;&#24615;&#12290;&#23613;&#31649;&#36825;&#26679;&#30340;&#20363;&#23376;&#24456;&#30452;&#35266;&#65292;&#20294;&#24456;&#38590;&#24418;&#24335;&#21270;&#36825;&#26679;&#30340;&#35821;&#20041;&#29420;&#31435;&#24615;&#27010;&#24565;&#12290;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#20219;&#20309;&#21512;&#29702;&#30340;&#24418;&#24335;&#21270;&#37117;&#24212;&#36981;&#23432;&#19968;&#32452;&#25152;&#35859;&#30340;&#29420;&#31435;&#24615;&#20844;&#29702;&#65292;&#22240;&#27492;&#20219;&#20309;&#20195;&#25968;&#32534;&#30721;&#36825;&#31181;&#32467;&#26500;&#30340;&#26041;&#27861;&#20063;&#24212;&#36981;&#23432;&#36825;&#20123;&#20844;&#29702;&#12290;&#36825;&#33258;&#28982;&#22320;&#23548;&#33268;&#25105;&#20204;&#20351;&#29992;&#37096;&#20998;&#27491;&#20132;&#24615;&#20316;&#20026;&#30456;&#20851;&#30340;&#20195;&#25968;&#32467;&#26500;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#29702;&#35770;&#21644;&#26041;&#27861;&#65292;&#21487;&#20197;&#35777;&#26126;&#37096;&#20998;&#27491;&#20132;&#24615;&#30830;&#23454;&#25429;&#25417;&#21040;&#20102;&#35821;&#20041;&#29420;&#31435;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#20445;&#25345;&#29420;&#31435;&#24615;&#30340;&#23884;&#20837;&#27010;&#24565;&#65292;&#20854;&#20013;&#23884;&#20837;&#20445;&#25345;&#20102;&#29420;&#31435;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning tools often rely on embedding text as vectors of real numbers. In this paper, we study how the semantic structure of language is encoded in the algebraic structure of such embeddings. Specifically, we look at a notion of ``semantic independence'' capturing the idea that, e.g., ``eggplant'' and ``tomato'' are independent given ``vegetable''. Although such examples are intuitive, it is difficult to formalize such a notion of semantic independence. The key observation here is that any sensible formalization should obey a set of so-called independence axioms, and thus any algebraic encoding of this structure should also obey these axioms. This leads us naturally to use partial orthogonality as the relevant algebraic structure. We develop theory and methods that allow us to demonstrate that partial orthogonality does indeed capture semantic independence. Complementary to this, we also introduce the concept of independence preserving embeddings where embeddings preserve the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20984;&#20989;&#25968;&#26799;&#24230;&#27969;&#22312;&#26377;&#38480;&#32500;&#21644;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#24046;&#24322;&#65292;&#35777;&#26126;&#20102;&#22312;&#26799;&#24230;&#27969;&#24773;&#20917;&#19979;&#65292;&#22914;&#26524;&#20989;&#25968;&#27809;&#26377;&#26368;&#23567;&#20540;&#65292;&#25910;&#25947;&#36895;&#24230;&#21487;&#33021;&#38750;&#24120;&#32531;&#24930;&#65307;&#22914;&#26524;&#20989;&#25968;&#26377;&#26368;&#23567;&#20540;&#65292;&#36807;&#21097;&#33021;&#37327;&#22312;&#26102;&#38388;&#19978;&#26159;&#21487;&#31215;&#30340;&#12290;&#27492;&#22806;&#65292;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#36807;&#21097;&#33021;&#37327;&#30340;&#34928;&#20943;&#36895;&#24230;&#21487;&#20197;&#24456;&#24930;&#65292;&#29978;&#33267;&#21487;&#20197;&#19982;&#32473;&#23450;&#30340;&#21333;&#35843;&#36882;&#20943;&#21487;&#31215;&#20989;&#25968;&#19968;&#26679;&#24930;&#12290;&#28982;&#32780;&#65292;&#22312;&#26377;&#38480;&#32500;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#27604;&#36807;&#21097;&#33021;&#37327;&#34928;&#20943;&#26356;&#24930;&#30340;&#21333;&#35843;&#36882;&#20943;&#21487;&#31215;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.17610</link><description>&lt;p&gt;
&#26377;&#38480;&#32500;&#21644;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#20984;&#20989;&#25968;&#26799;&#24230;&#27969;&#30340;&#23450;&#24615;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
A qualitative difference between gradient flows of convex functions in finite- and infinite-dimensional Hilbert spaces. (arXiv:2310.17610v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20984;&#20989;&#25968;&#26799;&#24230;&#27969;&#22312;&#26377;&#38480;&#32500;&#21644;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#24046;&#24322;&#65292;&#35777;&#26126;&#20102;&#22312;&#26799;&#24230;&#27969;&#24773;&#20917;&#19979;&#65292;&#22914;&#26524;&#20989;&#25968;&#27809;&#26377;&#26368;&#23567;&#20540;&#65292;&#25910;&#25947;&#36895;&#24230;&#21487;&#33021;&#38750;&#24120;&#32531;&#24930;&#65307;&#22914;&#26524;&#20989;&#25968;&#26377;&#26368;&#23567;&#20540;&#65292;&#36807;&#21097;&#33021;&#37327;&#22312;&#26102;&#38388;&#19978;&#26159;&#21487;&#31215;&#30340;&#12290;&#27492;&#22806;&#65292;&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#36807;&#21097;&#33021;&#37327;&#30340;&#34928;&#20943;&#36895;&#24230;&#21487;&#20197;&#24456;&#24930;&#65292;&#29978;&#33267;&#21487;&#20197;&#19982;&#32473;&#23450;&#30340;&#21333;&#35843;&#36882;&#20943;&#21487;&#31215;&#20989;&#25968;&#19968;&#26679;&#24930;&#12290;&#28982;&#32780;&#65292;&#22312;&#26377;&#38480;&#32500;&#24773;&#20917;&#19979;&#65292;&#23384;&#22312;&#27604;&#36807;&#21097;&#33021;&#37327;&#34928;&#20943;&#26356;&#24930;&#30340;&#21333;&#35843;&#36882;&#20943;&#21487;&#31215;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#26799;&#24230;&#27969;/&#26799;&#24230;&#19979;&#38477;&#21644;&#37325;&#29699;/&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#26041;&#27861;&#12290;&#22312;&#26799;&#24230;&#27969;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20197;&#19979;&#32467;&#35770;&#65306;1. &#22914;&#26524;$f$&#27809;&#26377;&#26368;&#23567;&#20540;&#65292;&#25910;&#25947;$f(x_t)\to \inf f$&#21487;&#33021;&#38750;&#24120;&#32531;&#24930;&#12290;2. &#22914;&#26524;$f$&#26377;&#26368;&#23567;&#20540;&#65292;&#36807;&#21097;&#33021;&#37327;$f(x_t) - \inf f$&#22312;&#26102;&#38388;&#19978;&#26159;&#21487;&#31215;/&#21487;&#21644;&#30340;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;$t\to\infty$&#26102;&#65292;$f(x_t) - \inf f = o(1/t)$&#12290;3. &#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#36825;&#26159;&#26368;&#20248;&#30340;&#65306;$f(x_t) - \inf f$&#30340;&#34928;&#20943;&#36895;&#24230;&#21487;&#20197;&#19982;&#20219;&#20309;&#32473;&#23450;&#30340;&#19988;&#22312;$\infty$&#22788;&#21333;&#35843;&#36882;&#20943;&#21644;&#21487;&#31215;&#30340;&#20989;&#25968;&#19968;&#26679;&#24930;&#65292;&#21363;&#20351;&#23545;&#20110;&#22266;&#23450;&#30340;&#20108;&#27425;&#30446;&#26631;&#20989;&#25968;&#20063;&#26159;&#22914;&#27492;&#12290;4. &#22312;&#26377;&#38480;&#32500;&#65288;&#25110;&#26356;&#19968;&#33324;&#22320;&#65292;&#23545;&#20110;&#25152;&#26377;&#26377;&#38480;&#38271;&#24230;&#30340;&#26799;&#24230;&#27969;&#26354;&#32447;&#65289;&#65292;&#36825;&#24182;&#38750;&#26368;&#20248;&#65306;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;$\mathbb R^d$&#19978;&#20219;&#20309;&#20984;&#20989;&#25968;&#30340;&#26799;&#24230;&#27969;&#65292;&#23384;&#22312;&#21333;&#35843;&#36882;&#20943;&#21487;&#31215;&#20989;&#25968;$g(t)$&#65292;&#20854;&#34928;&#20943;&#36895;&#24230;&#27604;$f(x_t)-\inf f$&#26356;&#24930;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#26799;&#24230;&#27969;$x_t$
&lt;/p&gt;
&lt;p&gt;
We consider gradient flow/gradient descent and heavy ball/accelerated gradient descent optimization for convex objective functions. In the gradient flow case, we prove the following:  1. If $f$ does not have a minimizer, the convergence $f(x_t)\to \inf f$ can be arbitrarily slow.  2. If $f$ does have a minimizer, the excess energy $f(x_t) - \inf f$ is integrable/summable in time. In particular, $f(x_t) - \inf f = o(1/t)$ as $t\to\infty$.  3. In Hilbert spaces, this is optimal: $f(x_t) - \inf f$ can decay to $0$ as slowly as any given function which is monotone decreasing and integrable at $\infty$, even for a fixed quadratic objective.  4. In finite dimension (or more generally, for all gradient flow curves of finite length), this is not optimal: We prove that there are convex monotone decreasing integrable functions $g(t)$ which decrease to zero slower than $f(x_t)-\inf f$ for the gradient flow of any convex function on $\mathbb R^d$. For instance, we show that any gradient flow $x_t$
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24212;&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.17582</link><description>&lt;p&gt;
&#22312;Wasserstein&#31354;&#38388;&#20013;&#36890;&#36807;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Convergence of flow-based generative models via proximal gradient descent in Wasserstein space. (arXiv:2310.17582v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;Wasserstein&#31354;&#38388;&#20013;&#24212;&#29992;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#35745;&#31639;&#25968;&#25454;&#29983;&#25104;&#21644;&#20284;&#28982;&#20989;&#25968;&#26041;&#38754;&#20855;&#26377;&#19968;&#23450;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#26368;&#36817;&#22312;&#23454;&#35777;&#34920;&#29616;&#19978;&#26174;&#31034;&#20986;&#31454;&#20105;&#21147;&#12290;&#19982;&#30456;&#20851;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#30340;&#31215;&#32047;&#29702;&#35770;&#30740;&#31350;&#30456;&#27604;&#65292;&#23545;&#20110;&#22312;&#27491;&#21521;&#65288;&#25968;&#25454;&#21040;&#22122;&#22768;&#65289;&#21644;&#21453;&#21521;&#65288;&#22122;&#22768;&#21040;&#25968;&#25454;&#65289;&#26041;&#21521;&#19978;&#37117;&#26159;&#30830;&#23450;&#24615;&#30340;&#27969;&#27169;&#22411;&#30340;&#20998;&#26512;&#36824;&#24456;&#23569;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#24402;&#19968;&#21270;&#27969;&#32593;&#32476;&#20013;&#23454;&#26045;Jordan-Kinderleherer-Otto&#65288;JKO&#65289;&#26041;&#26696;&#30340;&#25152;&#35859;JKO&#27969;&#27169;&#22411;&#65292;&#25552;&#20379;&#20102;&#36890;&#36807;&#28176;&#36827;&#27969;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#20998;&#24067;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#21033;&#29992;Wasserstein&#31354;&#38388;&#20013;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30340;&#25351;&#25968;&#25910;&#25947;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;JKO&#27969;&#27169;&#22411;&#29983;&#25104;&#25968;&#25454;&#30340;Kullback-Leibler&#65288;KL&#65289;&#20445;&#35777;&#20026;$O(\varepsilon^2)$&#65292;&#20854;&#20013;&#20351;&#29992;$N \lesssim \log (1/\varepsilon)$&#20010;JKO&#27493;&#39588;&#65288;&#27969;&#20013;&#30340;$N$&#20010;&#27531;&#24046;&#22359;&#65289;&#65292;&#20854;&#20013;$\varepsilon$&#26159;&#27599;&#27493;&#19968;&#38454;&#26465;&#20214;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be $O(\varepsilon^2)$ when using $N \lesssim \log (1/\varepsilon)$ many JKO steps ($N$ Residual Blocks in the flow) where $\varepsilon $ is the error in the per-step first-order condit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#32654;&#22269;&#34928;&#36864;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#21457;&#29616;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#27169;&#22411;&#22312;&#38271;&#26399;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;SHAP&#26041;&#27861;&#23545;GRU&#27169;&#22411;&#36827;&#34892;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2310.17571</link><description>&lt;p&gt;
&#40657;&#21283;&#23376;&#20869;&#37096;&#65306;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#26102;&#39044;&#27979;&#32654;&#22269;&#34928;&#36864;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Inside the black box: Neural network-based real-time prediction of US recessions. (arXiv:2310.17571v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;&#32654;&#22269;&#34928;&#36864;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#21457;&#29616;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#27169;&#22411;&#22312;&#38271;&#26399;&#39044;&#27979;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;SHAP&#26041;&#27861;&#23545;GRU&#27169;&#22411;&#36827;&#34892;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#65288;FFN&#65289;&#21644;&#20004;&#31181;&#29305;&#23450;&#31867;&#22411;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65292;&#21363;&#38271;&#30701;&#26399;&#35760;&#24518;&#65288;LSTM&#65289;&#21644;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;&#65288;GRU&#65289;&#65292;&#23545;1967&#24180;&#33267;2021&#24180;&#30340;&#32654;&#22269;&#34928;&#36864;&#36827;&#34892;&#24314;&#27169;&#12290;&#28982;&#21518;&#21033;&#29992;&#20272;&#35745;&#30340;&#27169;&#22411;&#23545;&#32654;&#22269;&#30340;&#22823;&#34928;&#36864;&#21644;Covid-19&#34928;&#36864;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#23558;&#20854;&#39044;&#27979;&#24615;&#33021;&#19982;&#20256;&#32479;&#32447;&#24615;&#27169;&#22411;&#12289;&#36923;&#36753;&#22238;&#24402;&#27169;&#22411;&#65288;&#26377;&#21644;&#26080;&#23725;&#22238;&#24402;&#24809;&#32602;&#65289;&#36827;&#34892;&#27604;&#36739;&#12290;&#22806;&#26679;&#26412;&#34920;&#29616;&#34920;&#26126;&#65292;LSTM&#21644;GRU&#22312;&#34928;&#36864;&#39044;&#27979;&#39046;&#22495;&#20855;&#26377;&#24212;&#29992;&#28508;&#21147;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#38271;&#26399;&#39044;&#27979;&#20219;&#21153;&#12290;&#30456;&#23545;&#20110;&#19981;&#21516;&#31867;&#22411;&#30340;&#32479;&#35745;&#24615;&#33021;&#25351;&#26631;&#65292;&#22312;5&#20010;&#39044;&#27979;&#21608;&#26399;&#20869;&#65292;&#23427;&#20204;&#20248;&#20110;&#20854;&#20182;&#31867;&#22411;&#30340;&#27169;&#22411;&#12290;&#32780;&#29992;Shapley&#22686;&#37327;&#35299;&#37322;&#65288;SHAP&#65289;&#26041;&#27861;&#35780;&#20272;&#34913;&#37327;GRU&#22312;&#19981;&#21516;&#39044;&#27979;&#21608;&#26399;&#20869;&#30340;&#37325;&#35201;&#29305;&#24449;&#65292;&#20197;&#28145;&#20837;&#20102;&#35299;&#29305;&#24449;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feedforward neural network (FFN) and two specific types of recurrent neural network, long short-term memory (LSTM) and gated recurrent unit (GRU), are used for modeling US recessions in the period from 1967 to 2021. The estimated models are then employed to conduct real-time predictions of the Great Recession and the Covid-19 recession in US. Their predictive performances are compared to those of the traditional linear models, the logistic regression model both with and without the ridge penalty. The out-of-sample performance suggests the application of LSTM and GRU in the area of recession forecasting, especially for the long-term forecasting tasks. They outperform other types of models across 5 forecasting horizons with respect to different types of statistical performance metrics. Shapley additive explanations (SHAP) method is applied to the fitted GRUs across different forecasting horizons to gain insight into the feature importance. The evaluation of predictor importance differs b
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#19981;&#31283;&#23450;&#24615;&#65292;&#24182;&#25351;&#20986;&#36825;&#26159;&#24403;&#21069;&#38382;&#39064;&#34920;&#36848;&#26041;&#24335;&#30340;&#24517;&#28982;&#32467;&#26524;&#12290;&#35813;&#38382;&#39064;&#26080;&#27861;&#23436;&#20840;&#28040;&#38500;&#65292;&#20294;&#21487;&#20197;&#36890;&#36807;&#25552;&#39640;&#22270;&#20687;&#20998;&#36776;&#29575;&#12289;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#12289;&#20840;&#38754;&#26631;&#27880;&#35757;&#32451;&#25968;&#25454;&#21644;&#38450;&#27490;&#25915;&#20987;&#32773;&#35775;&#38382;&#35745;&#31639;&#26426;&#35270;&#35273;&#31995;&#32479;&#26469;&#37096;&#20998;&#32531;&#35299;&#35813;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17559</link><description>&lt;p&gt;
&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#19981;&#31283;&#23450;&#24615;&#26159;&#20219;&#21153;&#26412;&#36523;&#30340;&#24517;&#28982;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Instability of computer vision models is a necessary result of the task itself. (arXiv:2310.17559v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17559
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#19981;&#31283;&#23450;&#24615;&#65292;&#24182;&#25351;&#20986;&#36825;&#26159;&#24403;&#21069;&#38382;&#39064;&#34920;&#36848;&#26041;&#24335;&#30340;&#24517;&#28982;&#32467;&#26524;&#12290;&#35813;&#38382;&#39064;&#26080;&#27861;&#23436;&#20840;&#28040;&#38500;&#65292;&#20294;&#21487;&#20197;&#36890;&#36807;&#25552;&#39640;&#22270;&#20687;&#20998;&#36776;&#29575;&#12289;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#12289;&#20840;&#38754;&#26631;&#27880;&#35757;&#32451;&#25968;&#25454;&#21644;&#38450;&#27490;&#25915;&#20987;&#32773;&#35775;&#38382;&#35745;&#31639;&#26426;&#35270;&#35273;&#31995;&#32479;&#26469;&#37096;&#20998;&#32531;&#35299;&#35813;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#24403;&#21069;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#19981;&#31283;&#23450;&#24615;&#32780;&#20135;&#29983;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#26159;&#19968;&#20010;&#38750;&#24120;&#37325;&#35201;&#30340;&#35805;&#39064;&#65292;&#22240;&#20026;&#23427;&#20204;&#26377;&#21487;&#33021;&#21361;&#21450;&#20219;&#20309;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#31283;&#23450;&#24615;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#65292;&#21407;&#22240;&#21253;&#25324;&#65306;a) &#25968;&#25454;&#30340;&#23545;&#31216;&#24615;&#65288;&#24179;&#31227;&#19981;&#21464;&#24615;&#65289;&#65292;b) &#20998;&#31867;&#20219;&#21153;&#30340;&#33539;&#30068;&#24615;&#36136;&#65292;&#20197;&#21450;c) &#23558;&#22270;&#20687;&#20998;&#31867;&#20026;&#23545;&#35937;&#26412;&#36523;&#30340;&#22522;&#26412;&#24046;&#24322;&#12290;&#19981;&#23436;&#20840;&#26631;&#27880;&#30340;&#35757;&#32451;&#25968;&#25454;&#36827;&#19968;&#27493;&#21152;&#21095;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#22240;&#27492;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#19981;&#31283;&#23450;&#24615;&#26159;&#24403;&#21069;&#35745;&#31639;&#26426;&#35270;&#35273;&#38382;&#39064;&#34920;&#36848;&#26041;&#24335;&#25152;&#24517;&#28982;&#30340;&#32467;&#26524;&#12290;&#34429;&#28982;&#38382;&#39064;&#26080;&#27861;&#23436;&#20840;&#28040;&#38500;&#65292;&#20294;&#36890;&#36807;&#20998;&#26512;&#21407;&#22240;&#65292;&#25105;&#20204;&#25214;&#21040;&#20102;&#19968;&#20123;&#26041;&#24335;&#26469;&#37096;&#20998;&#32531;&#35299;&#35813;&#38382;&#39064;&#65292;&#21253;&#25324;&#65306;i) &#25552;&#39640;&#22270;&#20687;&#30340;&#20998;&#36776;&#29575;&#65292;ii) &#20026;&#22270;&#20687;&#25552;&#20379;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;iii) &#23545;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#20840;&#38754;&#26631;&#27880;&#65292;&#21644;iv) &#38450;&#27490;&#25915;&#20987;&#32773;&#39057;&#32321;&#35775;&#38382;&#35745;&#31639;&#26426;&#35270;&#35273;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial examples resulting from instability of current computer vision models are an extremely important topic due to their potential to compromise any application. In this paper we demonstrate that instability is inevitable due to a) symmetries (translational invariance) of the data, b) the categorical nature of the classification task, and c) the fundamental discrepancy of classifying images as objects themselves. The issue is further exacerbated by non-exhaustive labelling of the training data. Therefore we conclude that instability is a necessary result of how the problem of computer vision is currently formulated. While the problem cannot be eliminated, through the analysis of the causes, we have arrived at ways how it can be partially alleviated. These include i) increasing the resolution of images, ii) providing contextual information for the image, iii) exhaustive labelling of training data, and iv) preventing attackers from frequent access to the computer vision system.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#35774;&#35745;&#20102;&#29992;&#20110;&#23398;&#20064;&#22270;&#26680;&#22343;&#20540;&#22330;&#21338;&#24328;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;GMFG-PPO&#20197;&#21450;&#26680;&#23884;&#20837;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#26410;&#30693;&#22270;&#26680;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#25928;&#29575;&#26041;&#38754;&#21462;&#24471;&#20102;&#25913;&#36827;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.17531</link><description>&lt;p&gt;
&#23398;&#20064;&#24102;&#26410;&#30693;&#22270;&#26680;&#30340;&#35268;&#33539;&#21270;&#22270;&#22343;&#22330;&#21338;&#24328;
&lt;/p&gt;
&lt;p&gt;
Learning Regularized Graphon Mean-Field Games with Unknown Graphons. (arXiv:2310.17531v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17531
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#20102;&#29992;&#20110;&#23398;&#20064;&#22270;&#26680;&#22343;&#20540;&#22330;&#21338;&#24328;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;GMFG-PPO&#20197;&#21450;&#26680;&#23884;&#20837;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#26410;&#30693;&#22270;&#26680;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#25910;&#25947;&#36895;&#24230;&#21644;&#25928;&#29575;&#26041;&#38754;&#21462;&#24471;&#20102;&#25913;&#36827;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#24182;&#20998;&#26512;&#20102;&#29992;&#20110;&#22270;&#22343;&#22330;&#21338;&#24328;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#19982;&#20043;&#21069;&#38656;&#35201;&#31934;&#30830;&#22270;&#26680;&#20540;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#26088;&#22312;&#23398;&#20064;&#24403;&#22270;&#26680;&#26410;&#30693;&#26102;&#30340;&#35268;&#33539;&#21270;&#22270;&#22343;&#22330;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#19977;&#20010;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#29992;&#20110;&#22270;&#22343;&#22330;&#21338;&#24328;&#30340;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#65288;GMFG-PPO&#65289;&#65292;&#24182;&#36890;&#36807;&#19968;&#20010;&#20272;&#35745;&#39044;&#35328;&#26426;&#35777;&#26126;&#20102;&#20854;&#22312;T&#27425;&#36845;&#20195;&#21518;&#20197;$O(T^{-1/3})$&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#25913;&#36827;&#20102;Xie&#31561;&#20154;&#65288;ICML&#65292;2021&#65289;&#30340;&#21069;&#26399;&#24037;&#20316;&#12290;&#20854;&#27425;&#65292;&#21033;&#29992;&#20998;&#24067;&#30340;&#26680;&#23884;&#20837;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#20272;&#35745;&#37319;&#26679;&#20195;&#29702;&#30340;&#36716;&#31227;&#26680;&#12289;&#22870;&#21169;&#20989;&#25968;&#21644;&#22270;&#26680;&#12290;&#24403;&#20195;&#29702;&#30340;&#20301;&#32622;&#24050;&#30693;&#25110;&#26410;&#30693;&#26102;&#65292;&#25512;&#23548;&#20102;&#25910;&#25947;&#36895;&#29575;&#12290;&#28982;&#21518;&#25552;&#20379;&#20102;&#36816;&#29992;GMFG-PPO&#20248;&#21270;&#31639;&#27861;&#21644;&#20272;&#35745;&#31639;&#27861;&#30340;&#32467;&#26524;&#12290;&#36825;&#20123;&#31639;&#27861;&#26159;&#39318;&#27425;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#23398;&#20064;&#22270;&#26680;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We design and analyze reinforcement learning algorithms for Graphon Mean-Field Games (GMFGs). In contrast to previous works that require the precise values of the graphons, we aim to learn the Nash Equilibrium (NE) of the regularized GMFGs when the graphons are unknown. Our contributions are threefold. First, we propose the Proximal Policy Optimization for GMFG (GMFG-PPO) algorithm and show that it converges at a rate of $O(T^{-1/3})$ after $T$ iterations with an estimation oracle, improving on a previous work by Xie et al. (ICML, 2021). Second, using kernel embedding of distributions, we design efficient algorithms to estimate the transition kernels, reward functions, and graphons from sampled agents. Convergence rates are then derived when the positions of the agents are either known or unknown. Results for the combination of the optimization algorithm GMFG-PPO and the estimation algorithm are then provided. These algorithms are the first specifically designed for learning graphons f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#26102;&#65292;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.17513</link><description>&lt;p&gt;
&#12298;&#20302;&#31209;&#36866;&#24212;&#30340;&#34920;&#36798;&#33021;&#21147;&#12299;
&lt;/p&gt;
&lt;p&gt;
The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17513
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#24403;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#26102;&#65292;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#36866;&#24212;&#65288;LoRA&#65289;&#26159;&#19968;&#31181;&#21442;&#25968;&#39640;&#25928;&#30340;&#24494;&#35843;&#26041;&#27861;&#65292;&#21033;&#29992;&#30697;&#38453;&#30340;&#20302;&#31209;&#36866;&#24212;&#24615;&#65292;&#22312;&#24494;&#35843;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#26159;LoRA&#30340;&#29702;&#35770;&#22522;&#30784;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#23578;&#26410;&#24471;&#21040;&#25506;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#20174;&#29702;&#35770;&#35282;&#24230;&#20998;&#26512;LoRA&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#39318;&#27425;&#23581;&#35797;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65292;&#22914;&#26524;LoRA-rank&#8805;&#65288;f&#30340;&#23485;&#24230;&#65289;&#215;&#65288;&#30446;&#26631;&#27169;&#22411;&#30340;&#28145;&#24230;/ f&#30340;&#28145;&#24230;&#65289;&#65292;&#21017;LoRA&#21487;&#20197;&#20351;&#20219;&#20309;&#27169;&#22411;f&#20934;&#30830;&#34920;&#31034;&#20219;&#20309;&#36739;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;f&#12290;&#24403;LoRA-rank&#20302;&#20110;&#38408;&#20540;&#26102;&#65292;&#25105;&#20204;&#36824;&#37327;&#21270;&#20102;&#36924;&#36817;&#35823;&#24046;&#12290;&#23545;&#20110;Transformer&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20219;&#20309;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;rank-&#65288;&#23884;&#20837;&#22823;&#23567;/ 2&#65289;&#30340;LoRA&#36866;&#37197;&#22120;&#36866;&#24212;&#20110;&#30456;&#21516;&#22823;&#23567;&#30340;&#30446;&#26631;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models. Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\overline{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\overline{f}}{\text{depth of }f}$. We also quantify the approximation error when LoRA-rank is lower than the threshold. For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20248;&#21270;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#35780;&#20272;&#36807;&#31243;&#20013;&#30340;&#20559;&#35265;&#20998;&#26512;&#12290;&#27169;&#22411;&#36890;&#36807;&#23558;&#30495;&#23454;&#25928;&#29992;&#20998;&#24067;&#36716;&#21270;&#20026;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#26469;&#32771;&#34385;&#20559;&#35265;&#65292;&#24182;&#23545;&#21442;&#25968;&#36827;&#34892;&#30740;&#31350;&#65292;&#20197;&#25506;&#31350;&#20854;&#23545;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#21644;&#25968;&#25454;&#25311;&#21512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.17489</link><description>&lt;p&gt;
&#35780;&#20272;&#36807;&#31243;&#20013;&#30340;&#20559;&#35265;&#65306;&#22522;&#20110;&#20248;&#21270;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Bias in Evaluation Processes: An Optimization-Based Model. (arXiv:2310.17489v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17489
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20248;&#21270;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#35780;&#20272;&#36807;&#31243;&#20013;&#30340;&#20559;&#35265;&#20998;&#26512;&#12290;&#27169;&#22411;&#36890;&#36807;&#23558;&#30495;&#23454;&#25928;&#29992;&#20998;&#24067;&#36716;&#21270;&#20026;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#26469;&#32771;&#34385;&#20559;&#35265;&#65292;&#24182;&#23545;&#21442;&#25968;&#36827;&#34892;&#30740;&#31350;&#65292;&#20197;&#25506;&#31350;&#20854;&#23545;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#21644;&#25968;&#25454;&#25311;&#21512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35832;&#22914;&#25307;&#29983;&#21644;&#25307;&#32856;&#31561;&#35774;&#32622;&#20013;&#65292;&#20851;&#20110;&#20010;&#20154;&#31038;&#20250;&#26174;&#33879;&#23646;&#24615;&#30340;&#20559;&#35265;&#24050;&#34987;&#24191;&#27867;&#35760;&#24405;&#22312;&#35780;&#20272;&#36807;&#31243;&#20013;&#12290;&#25105;&#20204;&#23558;&#36825;&#26679;&#30340;&#35780;&#20272;&#36807;&#31243;&#35270;&#20026;&#23558;&#20010;&#20154;&#23545;&#20219;&#21153;&#30340;&#30495;&#23454;&#25928;&#29992;&#20998;&#24067;&#36716;&#21270;&#20026;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#24314;&#27169;&#20026;&#22312;&#20449;&#24687;&#32422;&#26463;&#19979;&#30340;&#25439;&#22833;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#35299;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#20004;&#20010;&#21442;&#25968;&#65292;&#34987;&#35270;&#20026;&#23548;&#33268;&#20559;&#35265;&#30340;&#22240;&#32032;&#65306;&#20449;&#24687;&#32422;&#26463;&#20013;&#30340;&#36164;&#28304;&#20449;&#24687;&#20132;&#25442;&#21442;&#25968;&#21644;&#25439;&#22833;&#20989;&#25968;&#20013;&#30340;&#39118;&#38505;&#21388;&#24694;&#21442;&#25968;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#30001;&#25105;&#20204;&#30340;&#27169;&#22411;&#20135;&#29983;&#30340;&#20998;&#24067;&#65292;&#24182;&#30740;&#31350;&#20102;&#21442;&#25968;&#23545;&#35266;&#23519;&#21040;&#30340;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#27169;&#22411;&#30340;&#36755;&#20986;&#20016;&#23500;&#20102;&#21487;&#29992;&#20110;&#25429;&#25417;&#35266;&#23519;&#35780;&#20272;&#20013;&#32676;&#32452;&#38388;&#21464;&#21270;&#30340;&#20998;&#24067;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#25311;&#21512;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#26469;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#65292;&#24182;&#20351;&#29992;&#23427;&#26469;&#30740;&#31350;&#20171;&#20837;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Biases with respect to socially-salient attributes of individuals have been well documented in evaluation processes used in settings such as admissions and hiring. We view such an evaluation process as a transformation of a distribution of the true utility of an individual for a task to an observed distribution and model it as a solution to a loss minimization problem subject to an information constraint. Our model has two parameters that have been identified as factors leading to biases: the resource-information trade-off parameter in the information constraint and the risk-averseness parameter in the loss function. We characterize the distributions that arise from our model and study the effect of the parameters on the observed distribution. The outputs of our model enrich the class of distributions that can be used to capture variation across groups in the observed evaluations. We empirically validate our model by fitting real-world datasets and use it to study the effect of interve
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;</title><link>http://arxiv.org/abs/2310.17467</link><description>&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#32479;&#35745;&#28909;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
The statistical thermodynamics of generative diffusion models. (arXiv:2310.17467v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17467
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22312;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#20013;&#24212;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#65292;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#20108;&#38454;&#30456;&#21464;&#29616;&#35937;&#65292;&#24182;&#19988;&#35748;&#20026;&#36825;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#20851;&#38190;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#24778;&#20154;&#30340;&#34920;&#29616;&#12290;&#34429;&#28982;&#36825;&#20123;&#27169;&#22411;&#30340;&#22522;&#26412;&#24605;&#24819;&#26469;&#33258;&#38750;&#24179;&#34913;&#29289;&#29702;&#23398;&#65292;&#20294;&#26412;&#25991;&#20013;&#25105;&#20204;&#34920;&#26126;&#65292;&#21487;&#20197;&#29992;&#24179;&#34913;&#32479;&#35745;&#21147;&#23398;&#30340;&#24037;&#20855;&#26469;&#29702;&#35299;&#36825;&#20123;&#27169;&#22411;&#30340;&#35768;&#22810;&#26041;&#38754;&#12290;&#21033;&#29992;&#36825;&#31181;&#37325;&#26500;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#32463;&#21382;&#20102;&#19982;&#23545;&#31216;&#24615;&#30772;&#32570;&#29616;&#35937;&#30456;&#23545;&#24212;&#30340;&#20108;&#38454;&#30456;&#21464;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#24418;&#24335;&#65292;&#23427;&#26159;&#29983;&#25104;&#33021;&#21147;&#30340;&#26680;&#24515;&#65292;&#24182;&#21487;&#20197;&#29992;&#19968;&#32452;&#24179;&#22343;&#22330;&#20020;&#30028;&#25351;&#25968;&#26469;&#25551;&#36848;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#28909;&#21147;&#23398;&#30340;&#20844;&#24335;&#20998;&#26512;&#20102;&#23558;&#25193;&#25955;&#27169;&#22411;&#19982;&#20851;&#32852;&#35760;&#24518;&#32593;&#32476;&#36830;&#25509;&#30340;&#26368;&#36817;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative diffusion models have achieved spectacular performance in many areas of generative modeling. While the fundamental ideas behind these models come from non-equilibrium physics, in this paper we show that many aspects of these models can be understood using the tools of equilibrium statistical mechanics. Using this reformulation, we show that generative diffusion models undergo second-order phase transitions corresponding to symmetry breaking phenomena. We argue that this lead to a form of instability that lies at the heart of their generative capabilities and that can be described by a set of mean field critical exponents. We conclude by analyzing recent work connecting diffusion models and associative memory networks in view of the thermodynamic formulations.
&lt;/p&gt;</description></item><item><title>&#22312;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#30340;&#20219;&#21153;&#20013;&#65292;&#32463;&#20856;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#35299;&#65292;&#20351;&#24471;&#26368;&#32456;&#30340;&#25968;&#25454;&#26435;&#37325;&#38750;&#24120;&#31232;&#30095;&#65292;&#36825;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#34987;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.17386</link><description>&lt;p&gt;
&#22312;&#20351;&#29992;&#21452;&#23618;&#20248;&#21270;&#20013;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#30340;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
A Challenge in Reweighting Data with Bilevel Optimization. (arXiv:2310.17386v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17386
&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#26032;&#21152;&#26435;&#25968;&#25454;&#30340;&#20219;&#21153;&#20013;&#65292;&#32463;&#20856;&#30340;&#21452;&#23618;&#20248;&#21270;&#26041;&#27861;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#35299;&#65292;&#20351;&#24471;&#26368;&#32456;&#30340;&#25968;&#25454;&#26435;&#37325;&#38750;&#24120;&#31232;&#30095;&#65292;&#36825;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#34987;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#22823;&#30340;&#35757;&#32451;&#38598;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#30446;&#26631;&#26159;&#22312;&#19968;&#20010;&#19981;&#21516;&#20998;&#24067;&#30340;&#36739;&#23567;&#27979;&#35797;&#38598;&#19978;&#33719;&#24471;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#20026;&#35757;&#32451;&#38598;&#20013;&#30340;&#27599;&#20010;&#25968;&#25454;&#28857;&#23398;&#20064;&#19968;&#20010;&#26435;&#37325;&#26159;&#19968;&#20010;&#26377;&#21560;&#24341;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#29702;&#24819;&#24773;&#20917;&#19979;&#23427;&#21487;&#20197;&#33258;&#21160;&#23398;&#20064;&#27599;&#20010;&#35757;&#32451;&#28857;&#22312;&#27979;&#35797;&#38598;&#19978;&#30340;&#27867;&#21270;&#37325;&#35201;&#24615;&#12290;&#36825;&#20010;&#20219;&#21153;&#36890;&#24120;&#34987;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#12290;&#20256;&#32479;&#30340;&#21452;&#23618;&#27714;&#35299;&#22120;&#22522;&#20110;&#19968;&#20010;&#28909;&#21551;&#21160;&#31574;&#30053;&#65292;&#21363;&#21516;&#26102;&#23398;&#20064;&#27169;&#22411;&#30340;&#21442;&#25968;&#21644;&#25968;&#25454;&#26435;&#37325;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#32852;&#21512;&#21160;&#24577;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#35299;&#65292;&#20854;&#20013;&#26368;&#32456;&#30340;&#25968;&#25454;&#26435;&#37325;&#38750;&#24120;&#31232;&#30095;&#12290;&#36825;&#19968;&#21457;&#29616;&#35828;&#26126;&#20102;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#22256;&#38590;&#65292;&#24182;&#25552;&#31034;&#20102;&#20026;&#20160;&#20040;&#36825;&#31181;&#26041;&#27861;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#34987;&#20351;&#29992;&#30340;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many scenarios, one uses a large training set to train a model with the goal of performing well on a smaller testing set with a different distribution. Learning a weight for each data point of the training set is an appealing solution, as it ideally allows one to automatically learn the importance of each training point for generalization on the testing set. This task is usually formalized as a bilevel optimization problem. Classical bilevel solvers are based on a warm-start strategy where both the parameters of the models and the data weights are learned at the same time. We show that this joint dynamic may lead to sub-optimal solutions, for which the final data weights are very sparse. This finding illustrates the difficulty of data reweighting and offers a clue as to why this method is rarely used in practice.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28436;&#31034;-&#27491;&#21017;&#21270;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#30340;&#37319;&#26679;&#25928;&#29575;&#65292;&#24182;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#35813;&#22797;&#26434;&#24230;&#19982;&#19987;&#23478;&#28436;&#31034;&#25968;&#37327;&#25104;&#21453;&#27604;&#12290;</title><link>http://arxiv.org/abs/2310.17303</link><description>&lt;p&gt;
&#36890;&#36807;&#28436;&#31034;-&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#22686;&#24378;&#37319;&#26679;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Demonstration-Regularized RL. (arXiv:2310.17303v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17303
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28436;&#31034;-&#27491;&#21017;&#21270;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;&#30340;&#37319;&#26679;&#25928;&#29575;&#65292;&#24182;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#35813;&#22797;&#26434;&#24230;&#19982;&#19987;&#23478;&#28436;&#31034;&#25968;&#37327;&#25104;&#21453;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#19987;&#23478;&#28436;&#31034;&#32435;&#20837;&#20854;&#20013;&#65292;&#21487;&#20197;&#22312;&#25552;&#39640;&#24378;&#21270;&#23398;&#20064;(SRL)&#30340;&#37319;&#26679;&#25928;&#29575;&#26041;&#38754;&#20135;&#29983;&#32463;&#39564;&#25928;&#26524;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#19978;&#37327;&#21270;&#36825;&#20123;&#39069;&#22806;&#20449;&#24687;&#38477;&#20302;&#20102;SRL&#30340;&#37319;&#26679;&#22797;&#26434;&#24615;&#30340;&#31243;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36890;&#36807;KL&#27491;&#21017;&#21270;&#21033;&#29992;&#19987;&#23478;&#28436;&#31034;&#23398;&#20064;&#30340;&#31574;&#30053;&#30340;&#28436;&#31034;-&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#26377;&#38480;&#29366;&#24577;&#19979;&#65292;&#22312;$\widetilde{\mathcal{O}}(\mathrm{Poly}(S,A,H)/(\varepsilon^2 N^{\mathrm{E}}))$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#65292;&#20351;&#29992;$N^{\mathrm{E}}$&#20010;&#19987;&#23478;&#28436;&#31034;&#33021;&#22815;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#22312;&#32447;&#24615;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#22312;$\widetilde{\mathcal{O}}(\mathrm{Poly}(d,H)/(\varepsilon^2 N^{\mathrm{E}}))$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#65292;&#20854;&#20013;$\varepsilon$&#26159;&#30446;&#26631;&#31934;&#24230;&#65292;$H$&#26159;&#35268;&#23450;&#65292;$A$&#26159;&#21160;&#20316;&#30340;&#25968;&#37327;&#65292;$S$&#26159;&#26377;&#38480;&#29366;&#24577;&#30340;&#25968;&#37327;&#65292;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;$d$&#26159;&#29305;&#24449;&#31354;&#38388;&#30340;&#32500;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Incorporating expert demonstrations has empirically helped to improve the sample efficiency of reinforcement learning (RL). This paper quantifies theoretically to what extent this extra information reduces RL's sample complexity. In particular, we study the demonstration-regularized reinforcement learning that leverages the expert demonstrations by KL-regularization for a policy learned by behavior cloning. Our findings reveal that using $N^{\mathrm{E}}$ expert demonstrations enables the identification of an optimal policy at a sample complexity of order $\widetilde{\mathcal{O}}(\mathrm{Poly}(S,A,H)/(\varepsilon^2 N^{\mathrm{E}}))$ in finite and $\widetilde{\mathcal{O}}(\mathrm{Poly}(d,H)/(\varepsilon^2 N^{\mathrm{E}}))$ in linear Markov decision processes, where $\varepsilon$ is the target precision, $H$ the horizon, $A$ the number of action, $S$ the number of states in the finite case and $d$ the dimension of the feature space in the linear case. As a by-product, we provide tight con
&lt;/p&gt;</description></item><item><title>&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.17273</link><description>&lt;p&gt;
&#23558;&#24490;&#29615;&#24341;&#20837;&#20154;&#31867;&#65306;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17273
&lt;/p&gt;
&lt;p&gt;
&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20687;&#35768;&#22810;&#20248;&#21270;&#22120;&#19968;&#26679;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#33719;&#24471;&#29992;&#25143;&#20449;&#20219;&#26041;&#38754;&#24120;&#24120;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#20854;&#19981;&#36879;&#26126;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23581;&#35797;&#24320;&#21457;&#38754;&#21521;&#20154;&#31867;&#30340;&#20248;&#21270;&#22120;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#20551;&#35774;&#29992;&#25143;&#30693;&#35782;&#26159;&#26126;&#30830;&#19988;&#26080;&#35823;&#30340;&#65292;&#24182;&#20027;&#35201;&#23558;&#29992;&#25143;&#20316;&#20026;&#20248;&#21270;&#36807;&#31243;&#30340;&#30417;&#30563;&#32773;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24179;&#34913;&#30340;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#21512;&#20316;&#20249;&#20276;&#20851;&#31995;&#65292;&#21363;&#25105;&#20204;&#30340;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CoExBO&#65289;&#26694;&#26550;&#12290;CoExBO&#20351;&#29992;&#20559;&#22909;&#23398;&#20064;&#26469;&#26080;&#32541;&#22320;&#23558;&#20154;&#31867;&#35265;&#35299;&#25972;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#20174;&#32780;&#20135;&#29983;&#19982;&#29992;&#25143;&#20351;&#29992;&#20559;&#22909;&#19968;&#33268;&#30340;&#31639;&#27861;&#24314;&#35758;&#12290;CoExBO&#35299;&#37322;&#20854;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20197;&#22521;&#20859;&#20449;&#20219;&#65292;&#20351;&#29992;&#25143;&#26356;&#28165;&#26970;&#22320;&#25484;&#25569;&#20248;&#21270;&#30340;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;CoExBO&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#65292;&#20801;&#35768;&#29992;&#25143;&#29359;&#38169;&#35823;&#65307;&#21363;&#20351;&#22312;&#26497;&#31471;&#23545;&#25239;&#24615;&#24178;&#25200;&#19979;&#65292;&#31639;&#27861;&#20063;&#20250;&#28176;&#36827;&#22320;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;grokking&#29616;&#35937;&#19981;&#20165;&#23616;&#38480;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#20986;&#29616;&#22312;&#20854;&#20182;&#31639;&#27861;&#21644;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#34394;&#20551;&#20449;&#24687;&#30340;&#32500;&#24230;&#65292;&#21487;&#20197;&#35825;&#21457;grokking&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;grokking&#29616;&#35937;&#22312;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#21463;&#22797;&#26434;&#24615;&#21644;&#38169;&#35823;&#25351;&#23548;&#30340;&#20219;&#20309;&#24773;&#20917;&#19979;&#21487;&#33021;&#21457;&#29983;&#12290;&#36825;&#23545;&#29702;&#35299;grokking&#29616;&#35937;&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2310.17247</link><description>&lt;p&gt;
&#36229;&#36234;&#31070;&#32463;&#32593;&#32476;&#65306;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#32463;&#39564;&#25506;&#32034;
&lt;/p&gt;
&lt;p&gt;
Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity. (arXiv:2310.17247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;grokking&#29616;&#35937;&#19981;&#20165;&#23616;&#38480;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#20986;&#29616;&#22312;&#20854;&#20182;&#31639;&#27861;&#21644;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#22312;&#25968;&#25454;&#38598;&#20013;&#28155;&#21152;&#34394;&#20551;&#20449;&#24687;&#30340;&#32500;&#24230;&#65292;&#21487;&#20197;&#35825;&#21457;grokking&#29616;&#35937;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;grokking&#29616;&#35937;&#22312;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#21463;&#22797;&#26434;&#24615;&#21644;&#38169;&#35823;&#25351;&#23548;&#30340;&#20219;&#20309;&#24773;&#20917;&#19979;&#21487;&#33021;&#21457;&#29983;&#12290;&#36825;&#23545;&#29702;&#35299;grokking&#29616;&#35937;&#25552;&#20379;&#20102;&#26356;&#24191;&#27867;&#30340;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#31070;&#32463;&#32593;&#32476;&#23637;&#29616;&#20986;&#19968;&#31181;&#31216;&#20026;&#8220;grokking&#8221;&#30340;&#29616;&#35937;&#65292;&#21363;&#23427;&#20204;&#22312;&#39564;&#35777;&#38598;&#19978;&#23454;&#29616;&#23436;&#32654;&#25110;&#25509;&#36817;&#23436;&#32654;&#30340;&#20934;&#30830;&#24230;&#65292;&#32780;&#22312;&#35757;&#32451;&#38598;&#19978;&#21017;&#26089;&#24050;&#36798;&#21040;&#30456;&#21516;&#30340;&#24615;&#33021;&#12290;&#26412;&#25991;&#21457;&#29616;&#65292;grokking&#19981;&#20165;&#38480;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36824;&#20986;&#29616;&#22312;&#20854;&#20182;&#35774;&#32622;&#20013;&#65292;&#20363;&#22914;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20998;&#31867;&#12289;GP&#22238;&#24402;&#21644;&#32447;&#24615;&#22238;&#24402;&#12290;&#25105;&#20204;&#36824;&#21457;&#29616;&#20102;&#19968;&#31181;&#36890;&#36807;&#28155;&#21152;&#21253;&#21547;&#34394;&#20551;&#20449;&#24687;&#30340;&#32500;&#24230;&#26469;&#35825;&#21457;&#22522;&#20110;&#31639;&#27861;&#30340;&#25968;&#25454;&#38598;&#20013;&#30340;grokking&#29616;&#35937;&#30340;&#26426;&#21046;&#12290;&#38750;&#31070;&#32463;&#32467;&#26500;&#20013;&#30340;&#36825;&#31181;&#29616;&#35937;&#30340;&#23384;&#22312;&#35777;&#26126;&#20102;grokking&#19981;&#23616;&#38480;&#20110;SGD&#25110;&#26435;&#37325;&#33539;&#25968;&#27491;&#21017;&#21270;&#12290;&#30456;&#21453;&#65292;grokking&#21487;&#33021;&#21457;&#29983;&#22312;&#20219;&#20309;&#30001;&#22797;&#26434;&#24615;&#21644;&#38169;&#35823;&#25351;&#23548;&#35299;&#20915;&#26041;&#26696;&#25628;&#32034;&#30340;&#24773;&#20917;&#20013;&#12290;&#22522;&#20110;&#36825;&#19968;&#27934;&#23519;&#21644;&#25105;&#20204;&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#21644;GP&#22238;&#24402;&#27169;&#22411;&#30340;&#35757;&#32451;&#36712;&#36857;&#20013;&#35266;&#23519;&#21040;&#30340;&#36827;&#19968;&#27493;&#36235;&#21183;&#65292;&#25105;&#20204;&#22312;grokking&#30340;&#26356;&#19968;&#33324;&#30340;&#29702;&#35770;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
In some settings neural networks exhibit a phenomenon known as grokking, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression and linear regression. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures provides evidence that grokking is not specific to SGD or weight norm regularisation. Instead, grokking may be possible in any setting where solution search is guided by complexity and error. Based on this insight and further trends we see in the training trajectories of a Bayesian neural network (BNN) and GP regression model, we make progress towards a more general theory of grokking. Spe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#20855;&#26377;&#19968;&#33324;&#24211;&#23384;&#21040;&#36135;&#21160;&#24577;&#19979;&#30340;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#20462;&#25913;&#35746;&#36141;&#25968;&#37327;&#20197;&#28385;&#36275;&#20379;&#24212;&#21830;&#30340;&#38480;&#21046;&#65292;&#24182;&#23558;&#21608;&#26399;&#24615;&#23457;&#26680;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#23450;&#20041;&#20026;&#22806;&#37096;&#20915;&#31574;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.17168</link><description>&lt;p&gt;
&#23398;&#20064;&#22788;&#29702;&#20855;&#26377;&#19968;&#33324;&#24211;&#23384;&#21040;&#36135;&#21160;&#24577;&#30340;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning an Inventory Control Policy with General Inventory Arrival Dynamics. (arXiv:2310.17168v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#20855;&#26377;&#19968;&#33324;&#24211;&#23384;&#21040;&#36135;&#21160;&#24577;&#19979;&#30340;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#20462;&#25913;&#35746;&#36141;&#25968;&#37327;&#20197;&#28385;&#36275;&#20379;&#24212;&#21830;&#30340;&#38480;&#21046;&#65292;&#24182;&#23558;&#21608;&#26399;&#24615;&#23457;&#26680;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#23450;&#20041;&#20026;&#22806;&#37096;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38754;&#23545;&#19968;&#33324;&#21040;&#36135;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#20102;&#23398;&#20064;&#21644;&#22238;&#27979;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#25968;&#37327;&#38543;&#26102;&#38388;&#21040;&#36135;&#27169;&#22411;&#65288;QOT&#65289;&#12290;&#22312;&#23454;&#38469;&#20379;&#24212;&#38142;&#20013;&#65292;&#25105;&#20204;&#36824;&#20801;&#35768;&#20462;&#25913;&#35746;&#36141;&#25968;&#37327;&#20197;&#28385;&#36275;&#20379;&#24212;&#21830;&#30340;&#38480;&#21046;&#65292;&#20363;&#22914;&#35746;&#36141;&#26368;&#20302;&#25968;&#37327;&#21644;&#25209;&#27425;&#22823;&#23567;&#32422;&#26463;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#31687;&#22788;&#29702;&#20219;&#24847;&#21040;&#36135;&#21160;&#24577;&#25110;&#20219;&#24847;&#21518;&#32493;&#22788;&#29702;&#30340;&#35746;&#36141;&#25968;&#37327;&#30340;&#30740;&#31350;&#12290;&#22312;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;Madeka&#31561;&#65292;2022&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#21516;&#26679;&#23558;&#21608;&#26399;&#24615;&#23457;&#26680;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#23450;&#20041;&#20026;&#22806;&#37096;&#20915;&#31574;&#36807;&#31243;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#29366;&#24577;&#19981;&#21463;&#20195;&#29702;&#30340;&#25511;&#21046;&#12290;Madeka&#31561;&#20154;&#65288;2022&#65289;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314;&#19968;&#20010;&#27169;&#25311;&#22120;&#26469;&#22238;&#25918;&#21382;&#21490;&#25968;&#25454;&#20197;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#20363;&#23376;&#20013;&#65292;&#25105;&#20204;&#23558;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#32435;&#20837;&#21040;&#36135;&#36807;&#31243;&#30340;&#21382;&#21490;&#22238;&#25918;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we address the problem of learning and backtesting inventory control policies in the presence of general arrival dynamics -- which we term as a quantity-over-time arrivals model (QOT). We also allow for order quantities to be modified as a post-processing step to meet vendor constraints such as order minimum and batch size constraints -- a common practice in real supply chains. To the best of our knowledge this is the first work to handle either arbitrary arrival dynamics or an arbitrary downstream post-processing of order quantities. Building upon recent work (Madeka et al., 2022) we similarly formulate the periodic review inventory control problem as an exogenous decision process, where most of the state is outside the control of the agent. Madeka et al. (2022) show how to construct a simulator that replays historic data to solve this class of problem. In our case, we incorporate a deep generative model for the arrivals process as part of the history replay. By formulat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20132;&#26367;&#25237;&#24433;&#30340;&#36845;&#20195;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.17137</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#36890;&#36807;&#20132;&#26367;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
Large-Scale Gaussian Processes via Alternating Projection. (arXiv:2310.17137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20132;&#26367;&#25237;&#24433;&#30340;&#36845;&#20195;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#26031;&#36807;&#31243;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#35757;&#32451;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#36229;&#21442;&#25968;&#20248;&#21270;&#38656;&#35201;&#21453;&#22797;&#27714;&#35299;&#20855;&#26377; nxn &#26680;&#30697;&#38453;&#30340;&#32447;&#24615;&#31995;&#32479;&#12290;&#20026;&#20102;&#35299;&#20915; O(n^3) &#30340;&#26102;&#38388;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#37319;&#29992;&#20102;&#24555;&#36895;&#36845;&#20195;&#25968;&#20540;&#26041;&#27861;&#65292;&#22914;&#20849;&#36717;&#26799;&#24230;&#65288;CG&#65289;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#25968;&#25454;&#38598;&#35268;&#27169;&#30340;&#22686;&#21152;&#65292;&#30456;&#24212;&#30340;&#26680;&#30697;&#38453;&#21464;&#24471;&#36234;&#26469;&#36234;&#30149;&#24577;&#65292;&#24182;&#19988;&#22312;&#27809;&#26377;&#20998;&#21106;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#38656;&#35201; O(n^2) &#30340;&#31354;&#38388;&#12290;&#22240;&#27492;&#65292;&#34429;&#28982; CG &#22686;&#21152;&#20102;&#21487;&#35757;&#32451; GP &#22522;&#20110;&#30340;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#65292;&#20294;&#29616;&#20195;&#25968;&#25454;&#38598;&#24050;&#32463;&#36798;&#21040;&#36229;&#20986;&#20854;&#36866;&#29992;&#33539;&#22260;&#30340;&#35268;&#27169;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21482;&#35775;&#38382;&#26680;&#30697;&#38453;&#30340;&#23376;&#22359;&#30340;&#36845;&#20195;&#26041;&#27861;&#65292;&#26377;&#25928;&#22320;&#23454;&#29616;&#20102;&#23567;&#25209;&#37327;&#22788;&#29702;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;&#20132;&#26367;&#25237;&#24433;&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#20026; O(n)&#65292;&#35299;&#20915;&#20102;&#23558; GP &#25193;&#23637;&#21040;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#26102;&#30340;&#35768;&#22810;&#23454;&#38469;&#25361;&#25112;&#12290;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20174;&#23454;&#35777;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
Gaussian process (GP) hyperparameter optimization requires repeatedly solving linear systems with $n \times n$ kernel matrices. To address the prohibitive $\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative numerical methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the corresponding kernel matrices become increasingly ill-conditioned and still require $\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling \emph{mini-batching}. Our algorithm, based on alternating projection, has $\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove our method enjoys linear convergence and empirically we demons
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#22238;&#24402;&#35774;&#32622;&#19979;CART&#30340;&#25910;&#25947;&#24615;&#65292;&#24314;&#31435;&#20102;&#36275;&#22815;&#19981;&#32431;&#24230;&#20943;&#23569;&#26465;&#20214;&#19979;CART&#39044;&#27979;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#26131;&#20110;&#39564;&#35777;&#30340;&#36275;&#22815;&#26465;&#20214;&#12290;&#36825;&#23545;&#20110;&#20915;&#31574;&#26641;&#27169;&#22411;&#30340;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.17114</link><description>&lt;p&gt;
CART&#22312;&#36275;&#22815;&#19981;&#32431;&#24230;&#20943;&#23569;&#26465;&#20214;&#19979;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of CART under Sufficient Impurity Decrease Condition. (arXiv:2310.17114v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17114
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#30740;&#31350;&#22238;&#24402;&#35774;&#32622;&#19979;CART&#30340;&#25910;&#25947;&#24615;&#65292;&#24314;&#31435;&#20102;&#36275;&#22815;&#19981;&#32431;&#24230;&#20943;&#23569;&#26465;&#20214;&#19979;CART&#39044;&#27979;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#26131;&#20110;&#39564;&#35777;&#30340;&#36275;&#22815;&#26465;&#20214;&#12290;&#36825;&#23545;&#20110;&#20915;&#31574;&#26641;&#27169;&#22411;&#30340;&#24212;&#29992;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26641;&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#36890;&#24120;&#20351;&#29992;CART&#20197;&#36882;&#24402;&#36138;&#23146;&#30340;&#26041;&#24335;&#25311;&#21512;&#20915;&#31574;&#26641;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;CART&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#36275;&#22815;&#19981;&#32431;&#24230;&#20943;&#23569;&#26465;&#20214;&#19979;&#24314;&#31435;&#20102;CART&#30340;&#39044;&#27979;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#35813;&#32467;&#26524;&#25913;&#36827;&#20102;&#20043;&#21069;&#31867;&#20284;&#20551;&#35774;&#19979;&#30340;&#24050;&#30693;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#31034;&#20363;&#35777;&#26126;&#35823;&#24046;&#30028;&#38480;&#26080;&#27861;&#36890;&#36807;&#24120;&#25968;&#25110;&#23545;&#25968;&#22240;&#23376;&#36827;&#19968;&#27493;&#25913;&#36827;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#32452;&#26131;&#20110;&#39564;&#35777;&#30340;&#36275;&#22815;&#26465;&#20214;&#20197;&#28385;&#36275;&#19981;&#32431;&#24230;&#20943;&#23569;&#26465;&#20214;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21152;&#24615;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#21482;&#35201;&#32452;&#20214;&#20989;&#25968;&#31526;&#21512;&#8220;&#23616;&#37096;&#21453;&#21521;&#27874;&#26494;&#19981;&#31561;&#24335;&#8221;&#65292;&#23601;&#21487;&#20197;&#28385;&#36275;&#19981;&#32431;&#24230;&#20943;&#23569;&#26465;&#20214;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20960;&#20010;&#22312;&#38750;&#21442;&#25968;&#35774;&#32622;&#20013;&#20247;&#25152;&#21608;&#30693;&#30340;&#20989;&#25968;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
The decision tree is a flexible machine learning model that finds its success in numerous applications. It is usually fitted in a recursively greedy manner using CART. In this paper, we investigate the convergence rate of CART under a regression setting. First, we establish an upper bound on the prediction error of CART under a sufficient impurity decrease (SID) condition \cite{chi2022asymptotic} -- our result improves upon the known result by \cite{chi2022asymptotic} under a similar assumption. Furthermore, we provide examples that demonstrate the error bound cannot be further improved by more than a constant or a logarithmic factor. Second, we introduce a set of easily verifiable sufficient conditions for the SID condition. Specifically, we demonstrate that the SID condition can be satisfied in the case of an additive model, provided that the component functions adhere to a ``locally reverse Poincar{\'e} inequality". We discuss several well-known function classes in non-parametric es
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#23398;&#20064;&#29575;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#20135;&#29983;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#21253;&#25324;&#31283;&#23450;&#30340;&#36793;&#30028;&#12289;&#24179;&#34913;&#21644;&#24377;&#23556;&#65292;&#24182;&#36890;&#36807;&#21457;&#23637;&#26032;&#30340;&#20840;&#23616;&#25910;&#25947;&#29702;&#35770;&#21644;&#30740;&#31350;&#33391;&#22909;&#35268;&#21017;&#24615;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23558;&#36825;&#20123;&#29616;&#35937;&#24402;&#32435;&#20026;&#21516;&#19968;&#29616;&#35937;&#30340;&#19981;&#21516;&#34920;&#29616;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.17087</link><description>&lt;p&gt;
&#33391;&#22909;&#30340;&#35268;&#21017;&#24615;&#21019;&#36896;&#20102;&#22823;&#23398;&#20064;&#29575;&#30340;&#38544;&#24615;&#20559;&#24046;&#65306;&#31283;&#23450;&#30340;&#36793;&#30028;&#65292;&#24179;&#34913;&#21644;&#24377;&#23556;
&lt;/p&gt;
&lt;p&gt;
Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult. (arXiv:2310.17087v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17087
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#23398;&#20064;&#29575;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#20135;&#29983;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#21253;&#25324;&#31283;&#23450;&#30340;&#36793;&#30028;&#12289;&#24179;&#34913;&#21644;&#24377;&#23556;&#65292;&#24182;&#36890;&#36807;&#21457;&#23637;&#26032;&#30340;&#20840;&#23616;&#25910;&#25947;&#29702;&#35770;&#21644;&#30740;&#31350;&#33391;&#22909;&#35268;&#21017;&#24615;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23558;&#36825;&#20123;&#29616;&#35937;&#24402;&#32435;&#20026;&#21516;&#19968;&#29616;&#35937;&#30340;&#19981;&#21516;&#34920;&#29616;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#24212;&#29992;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#26102;&#65292;&#22823;&#23398;&#20064;&#29575;&#20250;&#20135;&#29983;&#21508;&#31181;&#38544;&#24615;&#20559;&#24046;&#65292;&#21253;&#25324;&#31283;&#23450;&#30340;&#36793;&#30028;&#12289;&#24179;&#34913;&#21644;&#24377;&#23556;&#12290;&#36825;&#20123;&#29616;&#35937;&#26080;&#27861;&#29992;&#32463;&#20856;&#30340;&#20248;&#21270;&#29702;&#35770;&#24456;&#22909;&#22320;&#35299;&#37322;&#12290;&#23613;&#31649;&#22312;&#29702;&#35299;&#36825;&#20123;&#38544;&#24615;&#20559;&#24046;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#35201;&#30340;&#29702;&#35770;&#36827;&#23637;&#65292;&#20294;&#20173;&#28982;&#19981;&#28165;&#26970;&#23427;&#20204;&#22312;&#21738;&#20123;&#30446;&#26631;&#20989;&#25968;&#19978;&#20250;&#21457;&#29983;&#12290;&#26412;&#25991;&#23545;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#21021;&#22987;&#30340;&#27493;&#39588;&#65292;&#21363;&#36825;&#20123;&#38544;&#24615;&#20559;&#24046;&#23454;&#38469;&#19978;&#26159;&#21516;&#19968;&#20912;&#23665;&#30340;&#21508;&#31181;&#23574;&#31471;&#12290;&#24403;&#20248;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;&#19968;&#23450;&#30340;&#33391;&#22909;&#35268;&#21017;&#24615;&#65292;&#24182;&#19982;&#22823;&#23398;&#20064;&#29575;&#26799;&#24230;&#19979;&#38477;&#23545;&#21521;&#26356;&#24179;&#22374;&#21306;&#22495;&#31227;&#21160;&#30340;&#21487;&#35777;&#26126;&#20559;&#22909;&#30456;&#32467;&#21512;&#26102;&#65292;&#23601;&#20250;&#20135;&#29983;&#36825;&#20123;&#38750;&#24179;&#20961;&#30340;&#21160;&#21147;&#23398;&#29616;&#35937;&#12290;&#20026;&#20102;&#24314;&#31435;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#26032;&#30340;&#22823;&#23398;&#20064;&#29575;&#20840;&#23616;&#25910;&#25947;&#29702;&#35770;&#65292;&#38024;&#23545;&#19968;&#26063;&#38750;&#20984;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large learning rates, when applied to gradient descent for nonconvex optimization, yield various implicit biases including the edge of stability (Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et al., 2020). These phenomena cannot be well explained by classical optimization theory. Though significant theoretical progress has been made in understanding these implicit biases, it remains unclear for which objective functions would they occur. This paper provides an initial step in answering this question, namely that these implicit biases are in fact various tips of the same iceberg. They occur when the objective function of optimization has some good regularity, which, in combination with a provable preference of large learning rate gradient descent for moving toward flatter regions, results in these nontrivial dynamical phenomena. To establish this result, we develop a new global convergence theory under large learning rates, for a family of nonconvex functi
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22823;&#23398;&#20064;&#29575;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#30001;&#20110;&#20854;&#26435;&#37325;&#30340;&#25391;&#33633;&#65292;&#33021;&#22815;&#22312;&#29305;&#24449;&#22122;&#22768;&#25968;&#25454;&#19978;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.17074</link><description>&lt;p&gt;
&#24102;&#26377;&#22823;&#23398;&#20064;&#29575;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#33391;&#24615;&#25391;&#33633;
&lt;/p&gt;
&lt;p&gt;
Benign Oscillation of Stochastic Gradient Descent with Large Learning Rates. (arXiv:2310.17074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17074
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22823;&#23398;&#20064;&#29575;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#30001;&#20110;&#20854;&#26435;&#37325;&#30340;&#25391;&#33633;&#65292;&#33021;&#22815;&#22312;&#29305;&#24449;&#22122;&#22768;&#25968;&#25454;&#19978;&#23454;&#29616;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#35757;&#32451;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#22312;&#36825;&#31181;&#35757;&#32451;&#26041;&#24335;&#19979;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#26159;&#65292;&#30001;&#20110;&#22823;&#23398;&#20064;&#29575;SGD&#35757;&#32451;&#24341;&#36215;&#30340;NN&#26435;&#37325;&#30340;&#25391;&#33633;&#23545;NN&#30340;&#27867;&#21270;&#26377;&#30410;&#65292;&#36825;&#26377;&#21487;&#33021;&#20248;&#20110;&#36890;&#36807;&#25910;&#25947;&#36739;&#24179;&#28369;&#30340;&#23567;&#23398;&#20064;&#29575;SGD&#35757;&#32451;&#30340;&#30456;&#21516;NN&#12290;&#22522;&#20110;&#36825;&#20010;&#21457;&#29616;&#65292;&#25105;&#20204;&#23558;&#36825;&#31181;&#29616;&#35937;&#31216;&#20026;&#8220;&#33391;&#24615;&#25391;&#33633;&#8221;&#12290;&#25105;&#20204;&#35299;&#23494;&#36825;&#31181;&#29616;&#35937;&#30340;&#29702;&#35770;&#24314;&#31435;&#22312;&#28145;&#24230;&#23398;&#20064;&#30340;&#29305;&#24449;&#23398;&#20064;&#35282;&#24230;&#19978;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#29305;&#24449;&#22122;&#22768;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#21253;&#25324;&#65288;i&#65289;&#20855;&#26377;&#23567;&#30340;$\ell_2$-&#33539;&#25968;&#24182;&#20986;&#29616;&#22312;&#27599;&#20010;&#25968;&#25454;&#28857;&#20013;&#30340;&#24369;&#29305;&#24449;&#65307;&#65288;ii&#65289;&#20855;&#26377;&#36739;&#22823;&#30340;$\ell_2$-&#33539;&#25968;&#20294;&#21482;&#20986;&#29616;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#30340;&#19968;&#37096;&#20998;&#20013;&#30340;&#24378;&#29305;&#24449;&#65307;&#21644;&#65288;iii&#65289;&#22122;&#22768;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36890;&#36807;&#25391;&#33633;&#35757;&#32451;&#30340;NN&#33021;&#22815;&#22312;&#36825;&#20010;&#29305;&#24449;&#22122;&#22768;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#19978;&#23454;&#29616;&#36739;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we theoretically investigate the generalization properties of neural networks (NN) trained by stochastic gradient descent (SGD) algorithm with large learning rates. Under such a training regime, our finding is that, the oscillation of the NN weights caused by the large learning rate SGD training turns out to be beneficial to the generalization of the NN, which potentially improves over the same NN trained by SGD with small learning rates that converges more smoothly. In view of this finding, we call such a phenomenon "benign oscillation". Our theory towards demystifying such a phenomenon builds upon the feature learning perspective of deep learning. Specifically, we consider a feature-noise data generation model that consists of (i) weak features which have a small $\ell_2$-norm and appear in each data point; (ii) strong features which have a larger $\ell_2$-norm but only appear in a certain fraction of all data points; and (iii) noise. We prove that NNs trained by oscill
&lt;/p&gt;</description></item><item><title>Coreset MCMC&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38142;&#20197;&#26356;&#26032;coreset&#26435;&#37325;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#30446;&#30340;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;Coreset MCMC&#25552;&#20379;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.17063</link><description>&lt;p&gt;
Coreset&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;
&lt;/p&gt;
&lt;p&gt;
Coreset Markov Chain Monte Carlo. (arXiv:2310.17063v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17063
&lt;/p&gt;
&lt;p&gt;
Coreset MCMC&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38142;&#20197;&#26356;&#26032;coreset&#26435;&#37325;&#65292;&#20174;&#32780;&#23454;&#29616;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#30340;&#30446;&#30340;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;Coreset MCMC&#25552;&#20379;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#26356;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;coreset&#26159;&#19968;&#20010;&#23567;&#32780;&#21152;&#26435;&#30340;&#25968;&#25454;&#23376;&#38598;&#65292;&#29992;&#20110;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#26367;&#20195;&#23436;&#25972;&#25968;&#25454;&#38598;&#20197;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#35843;&#25972;coreset&#26435;&#37325;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#32791;&#26102;&#26114;&#36149;&#65292;&#38656;&#35201;&#22797;&#26434;&#30340;&#29992;&#25143;&#36755;&#20837;&#65292;&#24182;&#23545;&#27169;&#22411;&#26045;&#21152;&#32422;&#26463;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#8212;&#8212;Coreset MCMC&#65292;&#35813;&#26041;&#27861;&#27169;&#25311;&#20102;&#19968;&#20010;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#30446;&#26631;&#26159;coreset&#21518;&#39564;&#20998;&#24067;&#65292;&#21516;&#26102;&#20351;&#29992;&#30456;&#21516;&#30340;&#25277;&#26679;&#26356;&#26032;coreset&#26435;&#37325;&#12290;Coreset MCMC&#26131;&#20110;&#23454;&#26045;&#21644;&#35843;&#25972;&#65292;&#24182;&#21487;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;MCMC&#20869;&#26680;&#19968;&#36215;&#20351;&#29992;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#20195;&#34920;&#24615;&#22330;&#26223;&#20013;&#20998;&#26512;&#20102;Coreset MCMC&#65292;&#20197;&#33719;&#24471;&#26377;&#20851;&#35813;&#26041;&#27861;&#25910;&#25947;&#34892;&#20026;&#30340;&#20851;&#38190;&#35265;&#35299;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20854;&#20182;coreset&#26500;&#36896;&#26041;&#27861;&#30456;&#27604;&#65292;Coreset MCMC&#33021;&#22815;&#25552;&#20379;&#26356;&#39640;&#36136;&#37327;&#30340;&#21518;&#39564;&#36817;&#20284;&#21644;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#24120;&#35268;&#23376;&#37319;&#26679;MCMC&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#21457;&#29616;Coreset MCMC&#20855;&#26377;&#36739;&#39640;&#30340;&#37319;&#26679;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Bayesian coreset is a small, weighted subset of data that replaces the full dataset during inference in order to reduce computational cost. However, state of the art methods for tuning coreset weights are expensive, require nontrivial user input, and impose constraints on the model. In this work, we propose a new method -- Coreset MCMC -- that simulates a Markov chain targeting the coreset posterior, while simultaneously updating the coreset weights using those same draws. Coreset MCMC is simple to implement and tune, and can be used with any existing MCMC kernel. We analyze Coreset MCMC in a representative setting to obtain key insights about the convergence behaviour of the method. Empirical results demonstrate that Coreset MCMC provides higher quality posterior approximations and reduced computational cost compared with other coreset construction methods. Further, compared with other general subsampling MCMC methods, we find that Coreset MCMC has a higher sampling efficiency with 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#12290;&#23545;&#20110;&#21333;&#36755;&#20986;&#24773;&#20917;&#65292;&#25105;&#20204;&#21457;&#29616;Matern&#26680;&#28151;&#21512;&#30340;&#24179;&#28369;&#24615;&#30001;&#26368;&#19981;&#24179;&#28369;&#30340;&#32452;&#20214;&#20915;&#23450;&#65292;&#24182;&#19988;&#28151;&#21512;&#26680;&#31561;&#20215;&#20110;&#26368;&#19981;&#24179;&#28369;&#30340;&#26680;&#32452;&#20214;&#12290;&#22312;&#22810;&#36755;&#20986;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#36825;&#34920;&#26126;&#20056;&#27861;&#28151;&#21512;&#26159;&#21487;&#34892;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.17023</link><description>&lt;p&gt;
&#35770;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability and Interpretability of Gaussian Process Models. (arXiv:2310.17023v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20013;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#12290;&#23545;&#20110;&#21333;&#36755;&#20986;&#24773;&#20917;&#65292;&#25105;&#20204;&#21457;&#29616;Matern&#26680;&#28151;&#21512;&#30340;&#24179;&#28369;&#24615;&#30001;&#26368;&#19981;&#24179;&#28369;&#30340;&#32452;&#20214;&#20915;&#23450;&#65292;&#24182;&#19988;&#28151;&#21512;&#26680;&#31561;&#20215;&#20110;&#26368;&#19981;&#24179;&#28369;&#30340;&#26680;&#32452;&#20214;&#12290;&#22312;&#22810;&#36755;&#20986;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#36825;&#34920;&#26126;&#20056;&#27861;&#28151;&#21512;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20351;&#29992;&#21152;&#24615;Matern&#26680;&#22312;&#21333;&#36755;&#20986;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#20013;&#30340;&#26222;&#36941;&#20570;&#27861;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#20998;&#26512;&#65292;&#24182;&#25506;&#35752;&#20102;&#29992;&#20110;&#22810;&#36755;&#20986;GP&#27169;&#22411;&#30340;&#20056;&#27861;Matern&#26680;&#30340;&#24615;&#36136;&#12290;&#23545;&#20110;&#21333;&#36755;&#20986;&#24773;&#20917;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#31995;&#21015;&#29702;&#35770;&#32467;&#26524;&#65292;&#34920;&#26126;Matern&#26680;&#28151;&#21512;&#30340;&#24179;&#28369;&#24615;&#30001;&#26368;&#19981;&#24179;&#28369;&#30340;&#32452;&#20214;&#20915;&#23450;&#65292;&#24182;&#19988;&#20855;&#26377;&#36825;&#26679;&#26680;&#30340;GP&#23454;&#38469;&#19978;&#31561;&#20215;&#20110;&#26368;&#19981;&#24179;&#28369;&#30340;&#26680;&#32452;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21508;&#20010;&#26680;&#32452;&#20214;&#20013;&#30340;&#28151;&#21512;&#26435;&#37325;&#25110;&#21442;&#25968;&#22343;&#26080;&#27861;&#35782;&#21035;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#27880;&#24847;&#21147;&#36716;&#21521;&#22810;&#36755;&#20986;GP&#27169;&#22411;&#65292;&#24182;&#20998;&#26512;&#20102;&#20056;&#27861;&#26680;$K(x,y) = AK_0(x,y)$&#20013;&#21327;&#26041;&#24046;&#30697;&#38453;$A$&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#20854;&#20013;$K_0$&#26159;&#26631;&#20934;&#30340;&#21333;&#36755;&#20986;&#26680;&#65292;&#22914;Matern&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;$A$&#22312;&#20056;&#27861;&#24120;&#25968;&#19978;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#36825;&#34920;&#26126;&#20056;&#27861;&#28151;&#21512;&#26159;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we critically examine the prevalent practice of using additive mixtures of Mat\'ern kernels in single-output Gaussian process (GP) models and explore the properties of multiplicative mixtures of Mat\'ern kernels for multi-output GP models. For the single-output case, we derive a series of theoretical results showing that the smoothness of a mixture of Mat\'ern kernels is determined by the least smooth component and that a GP with such a kernel is effectively equivalent to the least smooth kernel component. Furthermore, we demonstrate that none of the mixing weights or parameters within individual kernel components are identifiable. We then turn our attention to multi-output GP models and analyze the identifiability of the covariance matrix $A$ in the multiplicative kernel $K(x,y) = AK_0(x,y)$, where $K_0$ is a standard single output kernel such as Mat\'ern. We show that $A$ is identifiable up to a multiplicative constant, suggesting that multiplicative mixtures are well 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#36924;&#36817;&#38745;&#24577;&#21644;&#21160;&#24577;&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#35299;&#65292;&#23454;&#29616;&#20102;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#31639;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#20197;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.16975</link><description>&lt;p&gt;
&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#30340;&#39640;&#25928;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#21450;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Efficient Neural Network Approaches for Conditional Optimal Transport with Applications in Bayesian Inference. (arXiv:2310.16975v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16975
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26469;&#36924;&#36817;&#38745;&#24577;&#21644;&#21160;&#24577;&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#35299;&#65292;&#23454;&#29616;&#20102;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#31639;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#20197;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#20998;&#21035;&#36924;&#36817;&#38745;&#24577;&#21644;&#21160;&#24577;&#26465;&#20214;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#35299;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#21487;&#20197;&#23545;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#65292;&#36825;&#26159;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#26680;&#24515;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#30446;&#26631;&#26465;&#20214;&#20998;&#24067;&#34920;&#31034;&#20026;&#21487;&#22788;&#29702;&#30340;&#21442;&#32771;&#20998;&#24067;&#30340;&#36716;&#25442;&#65292;&#22240;&#27492;&#23646;&#20110;&#27979;&#24230;&#20256;&#36755;&#30340;&#26694;&#26550;&#12290;&#22312;&#35813;&#26694;&#26550;&#20013;&#65292;COT&#26144;&#23556;&#26159;&#19968;&#20010;&#20856;&#22411;&#30340;&#36873;&#25321;&#65292;&#20855;&#26377;&#21807;&#19968;&#24615;&#21644;&#21333;&#35843;&#24615;&#31561;&#21487;&#21462;&#30340;&#23646;&#24615;&#12290;&#28982;&#32780;&#65292;&#30456;&#20851;&#30340;COT&#38382;&#39064;&#22312;&#20013;&#31561;&#32500;&#24230;&#19979;&#35745;&#31639;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#30340;&#25968;&#20540;&#31639;&#27861;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#23545;COT&#26144;&#23556;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20805;&#20998;&#21033;&#29992;&#20102;COT&#38382;&#39064;&#30340;&#38745;&#24577;&#21644;&#21160;&#24577;&#34920;&#36798;&#24418;&#24335;&#30340;&#32467;&#26500;&#12290;PCP-Map&#23558;&#26465;&#20214;&#20256;&#36755;&#26144;&#23556;&#24314;&#27169;&#20026;&#37096;&#20998;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#65288;PICNN&#65289;&#30340;&#26799;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present two neural network approaches that approximate the solutions of static and dynamic conditional optimal transport (COT) problems, respectively. Both approaches enable sampling and density estimation of conditional probability distributions, which are core tasks in Bayesian inference. Our methods represent the target conditional distributions as transformations of a tractable reference distribution and, therefore, fall into the framework of measure transport. COT maps are a canonical choice within this framework, with desirable properties such as uniqueness and monotonicity. However, the associated COT problems are computationally challenging, even in moderate dimensions. To improve the scalability, our numerical algorithms leverage neural networks to parameterize COT maps. Our methods exploit the structure of the static and dynamic formulations of the COT problem. PCP-Map models conditional transport maps as the gradient of a partially input convex neural network (PICNN) and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#35843;&#25972;&#20197;&#23454;&#29616;&#24179;&#28369;&#20998;&#31867;&#22120;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.16779</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;
&lt;/p&gt;
&lt;p&gt;
Multi-scale Diffusion Denoised Smoothing. (arXiv:2310.16779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#23610;&#24230;&#25193;&#25955;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#35843;&#25972;&#20197;&#23454;&#29616;&#24179;&#28369;&#20998;&#31867;&#22120;&#40065;&#26834;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26368;&#36817;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#38543;&#26426;&#24179;&#28369;&#24050;&#25104;&#20026;&#23569;&#25968;&#20960;&#20010;&#20999;&#23454;&#21487;&#34892;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#20026;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#27169;&#22411;&#25552;&#20379;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#8220;&#21435;&#22122;&#21644;&#20998;&#31867;&#8221;&#27969;&#31243;&#65292;&#21363;&#25152;&#35859;&#30340;&#21435;&#22122;&#24179;&#28369;&#65292;&#22312;&#20219;&#20309;&#20998;&#31867;&#22120;&#19978;&#25191;&#34892;&#38543;&#26426;&#24179;&#28369;&#65292;&#21069;&#25552;&#26159;&#26377;&#19968;&#20010;&#20934;&#30830;&#30340;&#21435;&#22122;&#22120;&#21487;&#29992;&#65292;&#27604;&#22914;&#25193;&#25955;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21435;&#22122;&#24179;&#28369;&#30340;&#20934;&#30830;&#24230;&#21644;&#35748;&#35777;&#40065;&#26834;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65306;&#20363;&#22914;&#65292;&#25105;&#20204;&#36136;&#30097;&#21738;&#31181;&#25193;&#25955;&#27169;&#22411;&#30340;&#34920;&#31034;&#24418;&#24335;&#33021;&#22815;&#26368;&#22823;&#21270;&#21435;&#22122;&#24179;&#28369;&#30340;&#35748;&#35777;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#65292;&#26088;&#22312;&#23454;&#29616;&#20849;&#21516;&#22122;&#22768;&#27700;&#24179;&#19979;&#24179;&#28369;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#65292;&#22312;&#20849;&#20139;&#25193;&#25955;&#27169;&#22411;&#19978;&#36827;&#34892;&#31934;&#32454;&#35843;&#25972;&#65292;&#21516;&#26102;&#20063;&#20026;&#20854;&#35748;&#35777;&#40065;&#26834;&#24615;&#34917;&#20607;&#20934;&#30830;&#24230;&#30340;&#25104;&#26412;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple "denoise-and-classify" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent de
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.16638</link><description>&lt;p&gt;
&#36866;&#24212;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Covariate Shift Adaptation Robust to Density-Ratio Estimation. (arXiv:2310.16638v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16638
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#30340;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#32597;&#35265;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#24615;&#26041;&#27861;&#26469;&#20943;&#36731;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20559;&#24046;&#23545;&#27169;&#22411;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#35775;&#38382;&#20855;&#26377;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#32780;&#27979;&#35797;&#25968;&#25454;&#21482;&#21253;&#21547;&#21327;&#21464;&#37327;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#39044;&#27979;&#27979;&#35797;&#25968;&#25454;&#20013;&#32570;&#22833;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#19979;&#35757;&#32451;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#20998;&#24067;&#19981;&#21516;&#12290;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#30740;&#31350;&#25552;&#20986;&#20102;&#36890;&#36807;&#20351;&#29992;&#23494;&#24230;&#27604;&#30340;&#37325;&#35201;&#24615;&#21152;&#26435;&#26469;&#36827;&#34892;&#21327;&#21464;&#37327;&#20559;&#31227;&#36866;&#24212;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#25439;&#22833;&#36827;&#34892;&#21152;&#26435;&#24179;&#22343;&#65292;&#27599;&#20010;&#26435;&#37325;&#26159;&#35757;&#32451;&#25968;&#25454;&#21644;&#27979;&#35797;&#25968;&#25454;&#20043;&#38388;&#30340;&#21327;&#21464;&#37327;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#65292;&#20197;&#36817;&#20284;&#27979;&#35797;&#25968;&#25454;&#30340;&#39118;&#38505;&#12290;&#23613;&#31649;&#23427;&#20801;&#35768;&#25105;&#20204;&#33719;&#24471;&#19968;&#20010;&#26368;&#23567;&#21270;&#27979;&#35797;&#25968;&#25454;&#39118;&#38505;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#23494;&#24230;&#27604;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#23494;&#24230;&#27604;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#23494;&#24230;&#27604;&#30340;&#20272;&#35745;&#35823;&#24046;&#20063;&#20250;&#23548;&#33268;&#22238;&#24402;&#27169;&#22411;&#30340;&#20272;&#35745;&#22120;&#20135;&#29983;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#24182;&#35782;&#21035;&#20986;&#20855;&#26377;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.16502</link><description>&lt;p&gt;
&#35780;&#20272;&#38750;&#32447;&#24615;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#25972;&#20307;&#21644;&#37096;&#20998;&#22240;&#26524;&#33391;&#22909;&#35268;&#33539;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessing the overall and partial causal well-specification of nonlinear additive noise models. (arXiv:2310.16502v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16502
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35780;&#20272;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#24182;&#35782;&#21035;&#20986;&#20855;&#26377;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#26816;&#27979;&#38750;&#32447;&#24615;&#22240;&#26524;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#35268;&#33539;&#24615;&#38382;&#39064;&#65292;&#21487;&#33021;&#21253;&#25324;&#24322;&#26041;&#24046;&#24615;&#12290;&#25105;&#20204;&#26088;&#22312;&#35782;&#21035;&#37027;&#20123;&#21363;&#20351;&#22312;&#36825;&#31181;&#27169;&#22411;&#35268;&#33539;&#38382;&#39064;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#25512;&#26029;&#20986;&#22240;&#26524;&#25928;&#24212;&#30340;&#39044;&#27979;&#21464;&#37327;&#12290;&#25105;&#20204;&#22522;&#20110;&#23545;&#22810;&#20803;&#35266;&#27979;&#25968;&#25454;&#20998;&#24067;&#30340;&#20102;&#35299;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#28982;&#21518;&#38024;&#23545;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#35752;&#35770;&#20102;&#20854;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a method to detect model misspecifications in nonlinear causal additive and potentially heteroscedastic noise models. We aim to identify predictor variables for which we can infer the causal effect even in cases of such misspecification. We develop a general framework based on knowledge of the multivariate observational data distribution and we then propose an algorithm for finite sample data, discuss its asymptotic properties, and illustrate its performance on simulated and real data.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#36827;&#34892;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#22343;&#20540;&#22330;&#26041;&#27861;&#65292;&#36890;&#36807;&#21464;&#20998;&#32463;&#39564;&#36125;&#21494;&#26031;&#36924;&#36817;&#20808;&#39564;&#20998;&#24067;&#24182;&#24314;&#31435;&#20102;&#28176;&#36817;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#21487;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.16843</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#22343;&#20540;&#22330;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Mean Field Approach to Empirical Bayes Estimation in High-dimensional Linear Regression. (arXiv:2309.16843v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16843
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#36827;&#34892;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#22343;&#20540;&#22330;&#26041;&#27861;&#65292;&#36890;&#36807;&#21464;&#20998;&#32463;&#39564;&#36125;&#21494;&#26031;&#36924;&#36817;&#20808;&#39564;&#20998;&#24067;&#24182;&#24314;&#31435;&#20102;&#28176;&#36817;&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#35745;&#31639;&#19978;&#21487;&#34892;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#32463;&#39564;&#36125;&#21494;&#26031;&#20272;&#35745;&#12290;&#20026;&#20102;&#23454;&#29616;&#23545;&#28508;&#22312;&#20808;&#39564;&#30340;&#35745;&#31639;&#26377;&#25928;&#20272;&#35745;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#21464;&#20998;&#32463;&#39564;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#26368;&#21021;&#30001;Carbonetto&#21644;Stephens&#65288;2012&#65289;&#20197;&#21450;Kim&#31561;&#20154;&#65288;2022&#65289;&#24341;&#20837;&#12290;&#22312;&#23545;&#35774;&#35745;&#21644;&#20808;&#39564;&#20570;&#20986;&#28201;&#21644;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#38750;&#21442;&#25968;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#65288;NPMLE&#65289;&#21450;&#20854;&#65288;&#21487;&#35745;&#31639;&#30340;&#65289;&#26420;&#32032;&#22343;&#20540;&#22330;&#21464;&#20998;&#20195;&#29702;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#12290;&#22312;&#20551;&#23450;&#26420;&#32032;&#22343;&#20540;&#22330;&#36924;&#36817;&#20855;&#26377;&#21344;&#20248;&#35299;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36817;&#20284;&#27491;&#21017;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;1-Wasserstein&#24230;&#37327;&#19979;&#39564;&#35777;&#20102;&#20854;&#20934;&#30830;&#24615;&#12290;&#36825;&#20351;&#24471;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#21487;&#34892;&#65292;&#20363;&#22914;&#26500;&#24314;&#20855;&#26377;&#24179;&#22343;&#35206;&#30422;&#20445;&#35777;&#30340;&#21518;&#39564;&#21487;&#20449;&#21306;&#38388;&#65292;&#22238;&#24402;&#31995;&#25968;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#20272;&#35745;&#65292;&#38750;&#31354;&#27604;&#20363;&#30340;&#20272;&#35745;&#31561;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#28085;&#30422;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We study empirical Bayes estimation in high-dimensional linear regression. To facilitate computationally efficient estimation of the underlying prior, we adopt a variational empirical Bayes approach, introduced originally in Carbonetto and Stephens (2012) and Kim et al. (2022). We establish asymptotic consistency of the nonparametric maximum likelihood estimator (NPMLE) and its (computable) naive mean field variational surrogate under mild assumptions on the design and the prior. Assuming, in addition, that the naive mean field approximation has a dominant optimizer, we develop a computationally efficient approximation to the oracle posterior distribution, and establish its accuracy under the 1-Wasserstein metric. This enables computationally feasible Bayesian inference; e.g., construction of posterior credible intervals with an average coverage guarantee, Bayes optimal estimation for the regression coefficients, estimation of the proportion of non-nulls, etc. Our analysis covers both 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26465;&#20214;&#32622;&#25442;&#36827;&#34892;&#32479;&#35745;&#26377;&#25928;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#30340;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#20811;&#26381;&#20102;&#26631;&#20934;&#32622;&#25442;&#37325;&#35201;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#34920;&#29616;&#20986;&#26368;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.07593</link><description>&lt;p&gt;
&#36890;&#36807;&#26465;&#20214;&#32622;&#25442;&#36827;&#34892;&#32479;&#35745;&#26377;&#25928;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Statistically Valid Variable Importance Assessment through Conditional Permutations. (arXiv:2309.07593v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.07593
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26465;&#20214;&#32622;&#25442;&#36827;&#34892;&#32479;&#35745;&#26377;&#25928;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#30340;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#20811;&#26381;&#20102;&#26631;&#20934;&#32622;&#25442;&#37325;&#35201;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#34920;&#29616;&#20986;&#26368;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#22797;&#26434;&#23398;&#20064;&#22120;&#65288;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#26102;&#65292;&#21464;&#37327;&#37325;&#35201;&#24615;&#35780;&#20272;&#24050;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#30446;&#21069;&#65292;&#22522;&#20110;&#31227;&#38500;&#30340;&#37325;&#35201;&#24615;&#35780;&#20272;&#26159;&#21442;&#32771;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#38656;&#35201;&#32479;&#35745;&#20445;&#35777;&#26469;&#39564;&#35777;&#21464;&#37327;&#21253;&#21547;&#24615;&#26102;&#12290;&#36890;&#24120;&#65292;&#23427;&#20204;&#20351;&#29992;&#21464;&#37327;&#32622;&#25442;&#26041;&#26696;&#26469;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#23384;&#22312;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26102;&#23481;&#26131;&#23558;&#19981;&#37325;&#35201;&#30340;&#21464;&#37327;&#35823;&#35782;&#21035;&#20026;&#37325;&#35201;&#21464;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#26041;&#27861;&#26469;&#30740;&#31350;&#26465;&#20214;&#32622;&#25442;&#37325;&#35201;&#24615;&#65288;Conditional Permutation Importance&#65292;CPI&#65289;&#65292;&#23427;&#26159;&#27169;&#22411;&#26080;&#20851;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#22522;&#20934;&#27979;&#35797;&#65292;&#29992;&#20110;&#35780;&#20272;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#22120;&#12290;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;CPI&#36890;&#36807;&#25552;&#20379;&#20934;&#30830;&#30340;I&#22411;&#38169;&#35823;&#25511;&#21046;&#65292;&#20811;&#26381;&#20102;&#26631;&#20934;&#32622;&#25442;&#37325;&#35201;&#24615;&#30340;&#23616;&#38480;&#24615;&#12290;&#24403;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;CPI&#22987;&#32456;&#26174;&#31034;&#20986;&#26368;&#39640;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\textit{CPI}$ consistently showed top accuracy ac
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#21033;&#29992;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#35299;&#20915;&#38750;&#23436;&#22791;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20808;&#39564;&#32467;&#26500;&#21644;Feynman-Kac&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07983</link><description>&lt;p&gt;
&#33945;&#29305;&#21345;&#27931;&#24341;&#23548;&#25193;&#25955;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#36870;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo guided Diffusion for Bayesian linear inverse problems. (arXiv:2308.07983v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07983
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#21033;&#29992;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#35299;&#20915;&#38750;&#23436;&#22791;&#32447;&#24615;&#36870;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20808;&#39564;&#32467;&#26500;&#21644;Feynman-Kac&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65292;&#34920;&#29616;&#20986;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#23436;&#22791;&#30340;&#32447;&#24615;&#36870;&#38382;&#39064;&#32463;&#24120;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20986;&#29616;&#65292;&#20174;&#35745;&#31639;&#25668;&#24433;&#21040;&#21307;&#23398;&#25104;&#20687;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#38598;&#20013;&#20110;&#20351;&#29992;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#65292;&#22312;&#22635;&#34917;&#38382;&#39064;&#20013;&#20135;&#29983;&#20855;&#26377;&#24863;&#30693;&#21512;&#29702;&#24615;&#30340;&#22270;&#20687;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;SGM&#23450;&#20041;&#30340;&#20808;&#39564;&#32467;&#26500;&#26469;&#21046;&#23450;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#30340;&#24674;&#22797;&#38382;&#39064;&#65292;&#23558;&#20854;&#20316;&#20026;Feynman-Kac&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#25913;&#32534;&#33258;&#29992;&#20110;&#26500;&#24314;&#22522;&#20110;&#24471;&#20998;&#25193;&#25955;&#30340;&#21069;&#21521;&#25193;&#25955;&#27169;&#22411;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;Feynman-Kac&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;MCGdiff&#22312;&#29702;&#35770;&#19978;&#26159;&#26377;&#26681;&#25454;&#30340;&#65292;&#24182;&#19988;&#25105;&#20204;&#25552;&#20379;&#20102;&#25968;&#20540;&#27169;&#25311;&#32467;&#26524;&#65292;&#34920;&#26126;&#23427;&#22312;&#22788;&#29702;&#38750;&#23436;&#22791;&#36870;&#38382;&#39064;&#26102;&#20248;&#20110;&#31454;&#20105;&#23545;&#25163;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ill-posed linear inverse problems that combine knowledge of the forward measurement model with prior models arise frequently in various applications, from computational photography to medical imaging. Recent research has focused on solving these problems with score-based generative models (SGMs) that produce perceptually plausible images, especially in inpainting problems. In this study, we exploit the particular structure of the prior defined in the SGM to formulate recovery in a Bayesian framework as a Feynman--Kac model adapted from the forward diffusion model used to construct score-based diffusion. To solve this Feynman--Kac problem, we propose the use of Sequential Monte Carlo methods. The proposed algorithm, MCGdiff, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#19978;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#24182;&#19988;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#20102;&#36712;&#36857;&#23545;&#40784;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#28176;&#36827;&#23574;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#25193;&#23637;&#20102;&#24403;&#21069;&#25991;&#29486;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.04204</link><description>&lt;p&gt;
&#36712;&#36857;&#23545;&#40784;&#65306;&#36890;&#36807;&#20998;&#21449;&#29702;&#35770;&#29702;&#35299;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Trajectory Alignment: Understanding the Edge of Stability Phenomenon via Bifurcation Theory. (arXiv:2307.04204v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#19978;&#30340;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#24182;&#19988;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#36827;&#34892;&#20102;&#36712;&#36857;&#23545;&#40784;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#28176;&#36827;&#23574;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#32536;&#29616;&#35937;&#65292;&#25193;&#23637;&#20102;&#24403;&#21069;&#25991;&#29486;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Cohen&#31561;&#20154;&#65288;2021&#65289;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#36712;&#36857;&#19978;&#25439;&#22833;Hessian&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#21363;&#38160;&#24230;&#65289;&#65292;&#35266;&#23519;&#21040;&#19968;&#31181;&#31216;&#20026;&#31283;&#23450;&#36793;&#32536;&#65288;EoS&#65289;&#30340;&#29616;&#35937;&#12290;&#38160;&#24230;&#22312;&#22521;&#35757;&#30340;&#26089;&#26399;&#38454;&#27573;&#22686;&#21152;&#65288;&#31216;&#20026;&#28176;&#36827;&#23574;&#38160;&#21270;&#65289;&#65292;&#26368;&#32456;&#25509;&#36817;&#38408;&#20540;$2/\text{(&#27493;&#38271;)}$&#38468;&#36817;&#20572;&#28382;&#12290;&#26412;&#25991;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#39318;&#20808;&#35777;&#26126;&#20102;&#24403;EoS&#29616;&#35937;&#21457;&#29983;&#26102;&#65292;&#19981;&#21516;&#30340;GD&#36712;&#36857;&#65288;&#32463;&#36807;&#36866;&#24403;&#30340;&#21442;&#25968;&#21270;&#65289;&#22312;&#19968;&#20010;&#29305;&#23450;&#30340;&#20998;&#21449;&#22270;&#19978;&#23545;&#40784;&#65292;&#32780;&#19982;&#21021;&#22987;&#21270;&#26080;&#20851;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23545;&#19968;&#20010;&#20108;&#23618;&#20840;&#36830;&#25509;&#32447;&#24615;&#32593;&#32476;&#21644;&#19968;&#20010;&#20351;&#29992;&#21333;&#20010;&#25968;&#25454;&#28857;&#35757;&#32451;&#30340;&#21333;&#31070;&#32463;&#20803;&#38750;&#32447;&#24615;&#32593;&#32476;&#20005;&#26684;&#35777;&#26126;&#20102;&#36825;&#31181;&#36712;&#36857;&#23545;&#40784;&#29616;&#35937;&#12290;&#25105;&#20204;&#30340;&#36712;&#36857;&#23545;&#40784;&#20998;&#26512;&#24314;&#31435;&#20102;&#28176;&#36827;&#23574;&#38160;&#21270;&#21644;EoS&#29616;&#35937;&#65292;&#28085;&#30422;&#24182;&#25193;&#23637;&#20102;&#26368;&#36817;&#25991;&#29486;&#20013;&#30340;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cohen et al. (2021) empirically study the evolution of the largest eigenvalue of the loss Hessian, also known as sharpness, along the gradient descent (GD) trajectory and observe a phenomenon called the Edge of Stability (EoS). The sharpness increases at the early phase of training (referred to as progressive sharpening), and eventually saturates close to the threshold of $2 / \text{(step size)}$. In this paper, we start by demonstrating through empirical studies that when the EoS phenomenon occurs, different GD trajectories (after a proper reparameterization) align on a specific bifurcation diagram independent of initialization. We then rigorously prove this trajectory alignment phenomenon for a two-layer fully-connected linear network and a single-neuron nonlinear network trained with a single data point. Our trajectory alignment analysis establishes both progressive sharpening and EoS phenomena, encompassing and extending recent findings in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;&#33410;&#28857;&#20998;&#31867;&#20026;&#20363;&#65292;&#36890;&#36807;&#8220;&#31070;&#32463;&#22604;&#38519;&#8221;&#29616;&#35937;&#25506;&#32034;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#28436;&#21270;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#21363;&#20351;&#22312;&#33410;&#28857;&#20998;&#31867;&#24773;&#20917;&#19979;&#65292;&#29305;&#24449;&#30340;&#31867;&#20869;&#21464;&#24322;&#24615;&#20063;&#20250;&#20943;&#23569;&#65292;&#20294;&#19981;&#21450;&#22522;&#20110;&#23454;&#20363;&#30340;&#24773;&#20917;&#37027;&#20040;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2307.01951</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#28436;&#21270;&#30340;&#31070;&#32463;&#22604;&#38519;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks. (arXiv:2307.01951v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#33410;&#28857;&#20998;&#31867;&#20026;&#20363;&#65292;&#36890;&#36807;&#8220;&#31070;&#32463;&#22604;&#38519;&#8221;&#29616;&#35937;&#25506;&#32034;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#28436;&#21270;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#21363;&#20351;&#22312;&#33410;&#28857;&#20998;&#31867;&#24773;&#20917;&#19979;&#65292;&#29305;&#24449;&#30340;&#31867;&#20869;&#21464;&#24322;&#24615;&#20063;&#20250;&#20943;&#23569;&#65292;&#20294;&#19981;&#21450;&#22522;&#20110;&#23454;&#20363;&#30340;&#24773;&#20917;&#37027;&#20040;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;GNNs&#20013;&#22270;&#25299;&#25169;&#21644;&#29305;&#24449;&#28436;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#20197;&#22522;&#20110;&#33410;&#28857;&#30340;&#20998;&#31867;&#20026;&#20027;&#39064;&#65292;&#20197;&#38543;&#26426;&#22359;&#27169;&#22411;&#22270;&#19978;&#30340;&#31038;&#21306;&#26816;&#27979;&#20026;&#20363;&#65292;&#36890;&#36807;&#8220;&#31070;&#32463;&#22604;&#38519;&#8221;&#29616;&#35937;&#26469;&#25506;&#32034;&#29305;&#24449;&#28436;&#21270;&#12290;&#24403;&#35757;&#32451;&#22522;&#20110;&#23454;&#20363;&#30340;&#28145;&#24230;&#20998;&#31867;&#22120;&#65288;&#20363;&#22914;&#22270;&#20687;&#20998;&#31867;&#65289;&#36229;&#36807;&#38646;&#35757;&#32451;&#35823;&#24046;&#28857;&#26102;&#65292;&#31070;&#32463;&#22604;&#38519;&#34920;&#29616;&#20026;&#26368;&#28145;&#23618;&#29305;&#24449;&#30340;&#31867;&#20869;&#21464;&#24322;&#24615;&#20943;&#23569;&#65292;&#24182;&#19988;&#31867;&#22343;&#20540;&#19982;&#29305;&#23450;&#30340;&#23545;&#31216;&#32467;&#26500;&#26356;&#21152;&#23545;&#40784;&#12290;&#25105;&#20204;&#20808;&#20174;&#23454;&#35777;&#30740;&#31350;&#24320;&#22987;&#65292;&#26174;&#31034;&#31867;&#20869;&#21464;&#24322;&#24615;&#30340;&#20943;&#23569;&#22312;&#22522;&#20110;&#33410;&#28857;&#30340;&#20998;&#31867;&#29615;&#22659;&#20013;&#20063;&#26222;&#36941;&#23384;&#22312;&#65292;&#20294;&#19981;&#21450;&#22522;&#20110;&#23454;&#20363;&#30340;&#26696;&#20363;&#37027;&#20040;&#26126;&#26174;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#36825;&#31181;&#21306;&#21035;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#19981;&#32771;&#34385;&#28608;&#27963;&#65292;&#22270;&#25299;&#25169;&#20449;&#24687;&#20063;&#33021;&#23548;&#33268;&#29305;&#24449;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have become increasingly popular for classification tasks on graph-structured data. Yet, the interplay between graph topology and feature evolution in GNNs is not well understood. In this paper, we focus on node-wise classification, illustrated with community detection on stochastic block model graphs, and explore the feature evolution through the lens of the "Neural Collapse" (NC) phenomenon. When training instance-wise deep classifiers (e.g. for image classification) beyond the zero training error point, NC demonstrates a reduction in the deepest features' within-class variability and an increased alignment of their class means to certain symmetric structures. We start with an empirical study that shows that a decrease in within-class variability is also prevalent in the node-wise classification setting, however, not to the extent observed in the instance-wise case. Then, we theoretically study this distinction. Specifically, we show that even an "optimis
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#22270;&#20687;&#38477;&#22122;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.15012</link><description>&lt;p&gt;
&#29992;&#20110;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#30446;&#26631;&#20449;&#21495;&#24674;&#22797;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#22270;&#20687;&#38477;&#22122;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21482;&#23545;&#32473;&#23450;&#20449;&#21495;&#30340;&#29305;&#23450;&#23646;&#24615;&#24863;&#20852;&#36259;&#26102;&#65292;&#20174;&#19968;&#20010;&#21152;&#24615;&#28151;&#21512;&#29289;&#20013;&#20998;&#31163;&#20449;&#21495;&#21487;&#33021;&#26159;&#19968;&#20010;&#19981;&#24517;&#35201;&#22320;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#26356;&#31616;&#21333;&#30340;&#8220;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#8221;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#19987;&#27880;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#39044;&#23450;&#20041;&#32479;&#35745;&#25551;&#36848;&#37327;&#12290;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#22122;&#22768;&#36807;&#31243;&#30340;&#26679;&#26412;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26088;&#22312;&#20351;&#21463;&#22122;&#22768;&#26679;&#26412;&#27745;&#26579;&#30340;&#35299;&#20915;&#26041;&#26696;&#20505;&#36873;&#30340;&#32479;&#35745;&#29305;&#24615;&#19982;&#35266;&#27979;&#30340;&#28151;&#21512;&#29289;&#30340;&#32479;&#35745;&#29305;&#24615;&#21305;&#37197;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#35299;&#26512;&#21487;&#36861;&#36394;&#35745;&#31639;&#30340;&#31616;&#21333;&#31034;&#20363;&#20998;&#26512;&#20102;&#35813;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22270;&#20687;&#38477;&#22122;&#29615;&#22659;&#20013;&#65292;&#20351;&#29992;&#20102;1&#65289;&#22522;&#20110;&#23567;&#27874;&#30340;&#25551;&#36848;&#31526;&#65292;2&#65289;&#38024;&#23545;&#22825;&#20307;&#29289;&#29702;&#21644;ImageNet&#25968;&#25454;&#30340;ConvNet-based&#25551;&#36848;&#31526;&#12290;&#22312;&#31532;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#27604;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#26356;&#22909;&#22320;&#24674;&#22797;&#20102;&#30446;&#26631;&#25968;&#25454;&#30340;&#25551;&#36848;&#31526;&#12290;&#27492;&#22806;&#65292;&#23613;&#31649;&#19981;&#26159;&#20026;&#27492;&#30446;&#30340;&#26500;&#24314;&#30340;&#65292;&#23427;&#20063;&#34920;&#29616;&#20986;&#23545;&#30446;&#26631;&#20449;&#21495;&#25551;&#36848;&#31526;&#24674;&#22797;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler "statistical component separation" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it pe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;$f$-&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($f$-MIP)&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#20284;&#28982;&#27604;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;$\mu$-&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($\mu$-GMIP)&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#24615;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#35757;&#32451;&#22823;&#37327;&#24433;&#23376;&#27169;&#22411;&#12290;&#24378;&#35843;&#20102;&#26041;&#24046;&#30340;&#37325;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.07273</link><description>&lt;p&gt;
&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Gaussian Membership Inference Privacy. (arXiv:2306.07273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07273
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;$f$-&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($f$-MIP)&#27010;&#24565;&#65292;&#24182;&#20998;&#26512;&#20102;&#20284;&#28982;&#27604;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#25552;&#20986;&#20102;$\mu$-&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($\mu$-GMIP)&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#20998;&#26512;&#24615;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;&#35757;&#32451;&#22823;&#37327;&#24433;&#23376;&#27169;&#22411;&#12290;&#24378;&#35843;&#20102;&#26041;&#24046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38544;&#31169;&#27010;&#24565;&#65292;&#31216;&#20026;$f$-&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($f$-MIP)&#65292;&#23427;&#26126;&#30830;&#32771;&#34385;&#20102;&#22312;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#23041;&#32961;&#27169;&#22411;&#19979;&#29616;&#23454;&#23545;&#25163;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;$f$-MIP&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#25913;&#36827;&#30340;&#25928;&#29992;(&#20363;&#22914;&#26356;&#22909;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;)&#12290;&#25105;&#20204;&#23545;&#22122;&#22768;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#20284;&#28982;&#27604;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#36827;&#34892;&#20102;&#26032;&#39062;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#21442;&#25968;&#21270;&#30340;$f$-MIP&#20445;&#35777;&#26063;&#65292;&#31216;&#20026;$\mu$-&#39640;&#26031;&#25104;&#21592;&#25512;&#26029;&#38544;&#31169;($\mu$-GMIP)&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#20135;&#29983;&#20102;&#19968;&#31181;&#20998;&#26512;&#24615;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65292;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#39318;&#20808;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#25915;&#20987;&#19981;&#38656;&#35201;&#35757;&#32451;&#25968;&#30334;&#20010;&#24433;&#23376;&#27169;&#22411;&#26469;&#36924;&#36817;&#20284;&#28982;&#27604;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25915;&#20987;&#20351;&#24471;$f$-MIP&#30340;&#31616;&#21333;&#23457;&#35745;&#25104;&#20026;&#21487;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#24378;&#35843;&#20102;&#26041;&#24046;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new privacy notion called $f$-Membership Inference Privacy ($f$-MIP), which explicitly considers the capabilities of realistic adversaries under the membership inference attack threat model. By doing so $f$-MIP offers interpretable privacy guarantees and improved utility (e.g., better classification accuracy). Our novel theoretical analysis of likelihood ratio-based membership inference attacks on noisy stochastic gradient descent (SGD) results in a parametric family of $f$-MIP guarantees that we refer to as $\mu$-Gaussian Membership Inference Privacy ($\mu$-GMIP). Our analysis additionally yields an analytical membership inference attack that offers distinct advantages over previous approaches. First, unlike existing methods, our attack does not require training hundreds of shadow models to approximate the likelihood ratio. Second, our analytical attack enables straightforward auditing of our privacy notion $f$-MIP. Finally, our analysis emphasizes the importance of vario
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#36716;&#25442;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#22810;&#31181;&#38382;&#39064;&#24182;&#23454;&#29616;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#36817;&#20284;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.07163</link><description>&lt;p&gt;
&#19968;&#33324;&#36716;&#25442;&#26500;&#24314;&#19968;&#33268;&#30340;&#22312;&#32447;&#36817;&#20284;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
General Transformation for Consistent Online Approximation Algorithms. (arXiv:2306.07163v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#36716;&#25442;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#22810;&#31181;&#38382;&#39064;&#24182;&#23454;&#29616;&#20102;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#36817;&#20284;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36716;&#25442;&#26694;&#26550;&#65292;&#21487;&#29992;&#20110;&#20174;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#20013;&#24320;&#21457;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;&#19968;&#20010;&#23558;&#20855;&#26377;&#20302;&#24179;&#22343;&#25935;&#24863;&#24230;&#30340;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20855;&#26377;&#20302;&#949;-&#36817;&#20284;&#36951;&#25022;&#30340;&#22312;&#32447;&#31639;&#27861;&#30340;&#36890;&#29992;&#32422;&#31616;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;coreset&#26500;&#36896;&#26041;&#27861;&#23558;&#31163;&#32447;&#36924;&#36817;&#31639;&#27861;&#36716;&#25442;&#20026;&#20302;&#25935;&#24863;&#24230;&#29256;&#26412;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#22810;&#26679;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#21508;&#31181;&#38382;&#39064;&#65292;&#21253;&#25324;&#22312;&#32447;(k&#65292;z)-&#32858;&#31867;&#12289;&#22312;&#32447;&#30697;&#38453;&#36924;&#36817;&#21644;&#22312;&#32447;&#22238;&#24402;&#65292;&#24182;&#25104;&#21151;&#22320;&#20026;&#27599;&#20010;&#38382;&#39064;&#23454;&#29616;&#20102;&#23545;&#25968;&#22810;&#39033;&#24335;&#949;-&#36817;&#20284;&#36951;&#25022;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#25152;&#26377;&#19977;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20063;&#20139;&#26377;&#20302;&#19981;&#19968;&#33268;&#24615;&#65292;&#36825;&#21487;&#33021;&#26159;&#26576;&#20123;&#22312;&#32447;&#24212;&#29992;&#31243;&#24207;&#25152;&#38656;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a transformation framework that can be utilized to develop online algorithms with low $\epsilon$-approximate regret in the random-order model from offline approximation algorithms. We first give a general reduction theorem that transforms an offline approximation algorithm with low average sensitivity to an online algorithm with low $\epsilon$-approximate regret. We then demonstrate that offline approximation algorithms can be transformed into a low-sensitivity version using a coreset construction method. To showcase the versatility of our approach, we apply it to various problems, including online $(k,z)$-clustering, online matrix approximation, and online regression, and successfully achieve polylogarithmic $\epsilon$-approximate regret for each problem. Moreover, we show that in all three cases, our algorithm also enjoys low inconsistency, which may be desired in some online applications.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;JLMs&#30340;&#26631;&#31614;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#22238;&#24402;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.19470</link><description>&lt;p&gt;
&#29992;Johnson-Lindenstrauss&#30697;&#38453;&#36827;&#34892;&#26631;&#31614;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Label Embedding by Johnson-Lindenstrauss Matrices. (arXiv:2305.19470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19470
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;JLMs&#30340;&#26631;&#31614;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#22238;&#24402;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Johnson-Lindenstrauss&#30697;&#38453;&#65288;JLMs&#65289;&#30340;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#26497;&#31471;&#22810;&#20803;&#20998;&#31867;&#26694;&#26550;&#12290;&#21033;&#29992;JLM&#30340;&#21015;&#26469;&#23884;&#20837;&#26631;&#31614;&#65292;&#23558;&#19968;&#20010;C&#31867;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#20855;&#26377;$\cO(\log C)$&#36755;&#20986;&#32500;&#24230;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#36229;&#37327;&#39118;&#38505;&#38480;&#21046;&#65292;&#38416;&#26126;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#22312;Massart&#22122;&#22768;&#26465;&#20214;&#19979;&#65292;&#38477;&#32500;&#30340;&#24809;&#32602;&#20250;&#28040;&#22833;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#24182;&#34892;&#21270;&#65292;&#24182;&#19988;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#20854;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a simple and scalable framework for extreme multiclass classification based on Johnson-Lindenstrauss matrices (JLMs). Using the columns of a JLM to embed the labels, a $C$-class classification problem is transformed into a regression problem with $\cO(\log C)$ output dimension. We derive an excess risk bound, revealing a tradeoff between computational efficiency and prediction accuracy, and further show that under the Massart noise condition, the penalty for dimension reduction vanishes. Our approach is easily parallelizable, and experimental results demonstrate its effectiveness and scalability in large-scale applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#65292;&#19988;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;</title><link>http://arxiv.org/abs/2305.17380</link><description>&lt;p&gt;
&#20855;&#26377;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#36716;&#25442;&#30340;&#26080;&#36951;&#25022;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions. (arXiv:2305.17380v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#65292;&#19988;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#23545;&#25239;&#24615;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#22312;&#19982;&#23545;&#25163;&#30340;$ T $&#36718;&#20132;&#20114;&#20043;&#21518;&#23454;&#29616;${ O}(\sqrt{T})$&#30340;&#21518;&#24724;&#65292;&#21363;&#20351;&#25439;&#22833;&#20989;&#25968;&#26159;&#30001;&#23545;&#25163;&#20219;&#24847;&#36873;&#25321;&#30340;&#65292;&#20294;&#21069;&#25552;&#26159;&#36716;&#31227;&#20989;&#25968;&#24517;&#39035;&#22266;&#23450;&#12290;&#36825;&#26159;&#22240;&#20026;&#24050;&#32463;&#26377;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#25239;&#24615;&#36716;&#31227;&#20989;&#25968;&#20351;&#26080;&#24724;&#23398;&#20064;&#21464;&#24471;&#19981;&#21487;&#33021;&#12290;&#23613;&#31649;&#23384;&#22312;&#36825;&#31181;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#21487;&#20197;&#22788;&#29702;&#23545;&#25239;&#24615;&#25439;&#22833;&#21644;&#23545;&#25239;&#24615;&#36716;&#25442;&#30340;&#31639;&#27861;&#65292;&#21518;&#24724;&#36880;&#28176;&#22686;&#21152;&#19982;&#23545;&#25163;&#30340;&#24694;&#24847;&#31243;&#24230;&#25104;&#27604;&#20363;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#23427;&#30340;&#21518;&#24724;&#20026;$\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$&#65292;&#20854;&#20013;$C^{\textsf{P}}$&#34920;&#31034;&#36716;&#25442;&#20989;&#25968;&#30340;&#23545;&#25239;&#24615;&#65292;&#26368;&#22810;&#21487;&#20197;&#20026;${O}(T)$&#12290;&#34429;&#28982;&#27492;&#31639;&#27861;&#26412;&#36523;&#38656;&#35201;$C^{\textsf{P}}$&#30340;&#30693;&#35782;&#65292;&#20294;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#40657;&#30418;&#32553;&#20943;&#26041;&#27861;&#26469;&#28040;&#38500;&#27492;&#35201;&#27714;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#19968;&#31181;&#36827;&#19968;&#27493;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#38271;&#24230;&#30340;&#38170;&#23450;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing online learning algorithms for adversarial Markov Decision Processes achieve ${O}(\sqrt{T})$ regret after $T$ rounds of interactions even if the loss functions are chosen arbitrarily by an adversary, with the caveat that the transition function has to be fixed. This is because it has been shown that adversarial transition functions make no-regret learning impossible. Despite such impossibility results, in this work, we develop algorithms that can handle both adversarial losses and adversarial transitions, with regret increasing smoothly in the degree of maliciousness of the adversary. More concretely, we first propose an algorithm that enjoys $\widetilde{{O}}(\sqrt{T} + C^{\textsf{P}})$ regret where $C^{\textsf{P}}$ measures how adversarial the transition functions are and can be at most ${O}(T)$. While this algorithm itself requires knowledge of $C^{\textsf{P}}$, we further develop a black-box reduction approach that removes this requirement. Moreover, we also show that furth
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;</title><link>http://arxiv.org/abs/2305.16905</link><description>&lt;p&gt;
&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65306;&#36125;&#21494;&#26031;&#25512;&#29702;&#25552;&#39640;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Laplace-Approximated Neural Additive Models: Improving Interpretability with Bayesian Inference. (arXiv:2305.16905v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16905
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#22312;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#20013;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65292;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#25191;&#34892;&#38544;&#24335;&#29305;&#24449;&#36873;&#25321;&#24182;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#24212;&#29992;&#65292;&#20294;&#23427;&#20204;&#30340;&#40657;&#30418;&#24615;&#36136;&#38459;&#30861;&#20102;&#35299;&#37322;&#24615;&#12290;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;NAM&#65289;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#23558;&#32593;&#32476;&#20998;&#20026;&#21152;&#24615;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#20351;&#36755;&#20837;&#29305;&#24449;&#21644;&#39044;&#27979;&#20043;&#38388;&#30340;&#20132;&#20114;&#21464;&#24471;&#26126;&#26174;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#35282;&#24230;&#32771;&#34385;&#21152;&#24615;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#25552;&#39640;&#20102;&#21487;&#35299;&#37322;&#24615;&#65306;a&#65289;&#23427;&#36890;&#36807;&#20272;&#35745;&#23376;&#32593;&#32476;&#30340;&#20989;&#25968;&#31354;&#38388;&#19981;&#30830;&#23450;&#24615;&#20026;&#24674;&#22797;&#30340;&#29305;&#24449;&#20132;&#20114;&#25552;&#20379;&#21487;&#20449;&#21306;&#38388;&#65307;b&#65289;&#23427;&#25552;&#20379;&#21487;&#22788;&#29702;&#30340;&#36793;&#32536;&#20284;&#28982;&#20272;&#35745;&#65292;&#21487;&#29992;&#20110;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#36807;&#31243;&#25191;&#34892;&#29305;&#24449;&#30340;&#38544;&#24335;&#36873;&#25321;&#65307;c&#65289;&#23427;&#21487;&#29992;&#20110;&#23545;&#29305;&#24449;&#23545;&#36827;&#34892;&#25490;&#21517;&#65292;&#20316;&#20026;&#31934;&#32454;&#35843;&#25972;&#30340;&#20132;&#20114;&#27169;&#22411;&#20505;&#36873;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#35777;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#25289;&#26222;&#25289;&#26031;&#36924;&#36817;&#31070;&#32463;&#21152;&#24615;&#27169;&#22411;&#65288;LA-NAM&#65289;&#25552;&#39640;&#20102;NAM&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#36827;&#19968;&#27493;&#25581;&#31034;&#20102;&#23398;&#20064;&#21040;&#30340;&#23376;&#32593;&#32476;&#30340;&#20132;&#20114;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#12290;</title><link>http://arxiv.org/abs/2305.16150</link><description>&lt;p&gt;
&#32479;&#19968;GAN&#21644;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#30340;&#31890;&#23376;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unifying GANs and Score-Based Diffusion as Generative Particle Models. (arXiv:2305.16150v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16150
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#19968;&#20010;&#25512;&#24191;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#31890;&#23376;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#20363;&#22914;&#26799;&#24230;&#27969;&#21644;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#24778;&#20154;&#30340;&#24615;&#33021;&#32780;&#26368;&#36817;&#21463;&#21040;&#20851;&#27880;&#12290;&#20256;&#32479;&#19978;&#65292;&#36890;&#36807;&#24494;&#20998;&#26041;&#31243;&#26469;&#31227;&#21160;&#31890;&#23376;&#20998;&#24067;&#30340;&#26041;&#27861;&#34987;&#26222;&#36941;&#35748;&#20026;&#26159;&#19982;&#20197;&#21069;&#24191;&#27867;&#20351;&#29992;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30456;&#23545;&#31435;&#30340;&#65292;&#21518;&#32773;&#28041;&#21450;&#21040;&#35757;&#32451;&#19968;&#20010;&#21521;&#21069;&#30340;&#29983;&#25104;&#22120;&#32593;&#32476;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#36825;&#31181;&#35299;&#37322;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#31890;&#23376;&#21644;&#23545;&#25239;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#29983;&#25104;&#22120;&#35757;&#32451;&#20316;&#20026;&#31890;&#23376;&#27169;&#22411;&#30340;&#25512;&#24191;&#12290;&#36825;&#34920;&#26126;&#65292;&#29983;&#25104;&#22120;&#26159;&#20219;&#20309;&#36825;&#26679;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#21487;&#36873;&#38468;&#20214;&#12290;&#22240;&#27492;&#65292;&#23558;&#29983;&#25104;&#22120;&#38598;&#25104;&#21040;&#22522;&#20110;&#20998;&#25968;&#25193;&#25955;&#27169;&#22411;&#20013;&#65292;&#24182;&#22312;&#27809;&#26377;&#29983;&#25104;&#22120;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;GAN&#33258;&#28982;&#22320;&#20986;&#29616;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#27979;&#35797;&#36825;&#20123;&#21407;&#22987;&#27169;&#22411;&#30340;&#21487;&#34892;&#24615;&#65292;&#36825;&#20123;&#27169;&#22411;&#26159;&#25105;&#20204;&#26694;&#26550;&#21487;&#33021;&#24212;&#29992;&#30340;&#27010;&#24565;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Particle-based deep generative models, such as gradient flows and score-based diffusion models, have recently gained traction thanks to their striking performance. Their principle of displacing particle distributions by differential equations is conventionally seen as opposed to the previously widespread generative adversarial networks (GANs), which involve training a pushforward generator network. In this paper, we challenge this interpretation and propose a novel framework that unifies particle and adversarial generative models by framing generator training as a generalization of particle models. This suggests that a generator is an optional addition to any such generative model. Consequently, integrating a generator into a score-based diffusion model and training a GAN without a generator naturally emerge from our framework. We empirically test the viability of these original models as proofs of concepts of potential applications of our framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24102;&#24635;&#25104;&#26412;&#38480;&#21046;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#65288;CBwK&#65289;&#65292;&#36890;&#36807;&#23545;&#26415;&#35821;&#36827;&#34892;&#37325;&#26032;&#32452;&#21512;&#65292;&#23545;CBwK&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#25903;&#25345;&#23567;&#20110;$T^{3/4}$&#30340;&#24635;&#25104;&#26412;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#23545;&#20598;&#31574;&#30053;&#23454;&#29616;&#20102;&#24179;&#31561;&#30340;&#25104;&#26412;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15807</link><description>&lt;p&gt;
&#24102;&#23567;&#24635;&#25104;&#26412;&#38480;&#21046;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#19982;&#32972;&#21253;&#38382;&#39064;&#30340;&#30456;&#20851;&#24615;&#65292;&#21450;&#20854;&#23545;&#20844;&#24179;&#24615;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Small Total-Cost Constraints in Contextual Bandits with Knapsacks, with Application to Fairness. (arXiv:2305.15807v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24102;&#24635;&#25104;&#26412;&#38480;&#21046;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#65288;CBwK&#65289;&#65292;&#36890;&#36807;&#23545;&#26415;&#35821;&#36827;&#34892;&#37325;&#26032;&#32452;&#21512;&#65292;&#23545;CBwK&#36827;&#34892;&#20102;&#20248;&#21270;&#65292;&#25903;&#25345;&#23567;&#20110;$T^{3/4}$&#30340;&#24635;&#25104;&#26412;&#32422;&#26463;&#65292;&#24182;&#36890;&#36807;&#23545;&#20598;&#31574;&#30053;&#23454;&#29616;&#20102;&#24179;&#31561;&#30340;&#25104;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#24102;&#26377;&#32972;&#21253;&#38382;&#39064;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#20915;&#31574;&#38382;&#39064;&#65288;CBwK&#65289;&#65292;&#27599;&#19968;&#36718;&#33719;&#24471;&#19968;&#20010;&#26631;&#37327;&#22870;&#21169;&#21644;&#19968;&#20010;&#21521;&#37327;&#20540;&#30340;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#32047;&#35745;&#30340;&#22870;&#21169;&#65292;&#24182;&#30830;&#20445;&#32047;&#35745;&#25104;&#26412;&#20302;&#20110;&#26576;&#20010;&#39044;&#23450;&#30340;&#25104;&#26412;&#38480;&#21046;&#12290;&#25105;&#20204;&#20551;&#35774;&#29615;&#22659;&#26469;&#33258;&#19968;&#20010;&#36830;&#32493;&#38598;&#21512;&#65292;&#25104;&#26412;&#21487;&#20197;&#24102;&#31526;&#21495;&#65292;&#24182;&#19988;&#26410;&#30693;&#30340;&#26399;&#26395;&#22870;&#21169;&#21644;&#25104;&#26412;&#20989;&#25968;&#21487;&#20197;&#34987;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#36825;&#26159;&#25991;&#29486;&#20013;&#30340;&#19968;&#20010;&#20856;&#22411;&#20551;&#35774;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#36804;&#20170;&#20026;&#27490;&#24635;&#25104;&#26412;&#32422;&#26463;&#33267;&#23569;&#35201;&#20026;$T^{3/4}$&#65292;&#20854;&#20013;$T$&#26159;&#36718;&#25968;&#65292;&#24182;&#19988;&#29978;&#33267;&#36890;&#24120;&#34987;&#20551;&#23450;&#20026;&#19982;$T$&#32447;&#24615;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21463;&#21040;&#40723;&#33310;&#65292;&#20351;&#29992;CBwK&#26469;&#24378;&#21046;&#23454;&#26045;&#23454;&#29616;&#32452;&#20043;&#38388;&#24179;&#22343;&#25104;&#26412;&#24179;&#31561;&#30340;&#20844;&#24179;&#24615;&#32422;&#26463;&#65306;&#19982;&#30456;&#24212;&#25104;&#26412;&#32422;&#26463;&#30456;&#20851;&#30340;&#39044;&#31639;&#24212;&#23613;&#21487;&#33021;&#25509;&#36817;&#20110;&#38454;&#25968;&#20026;$\sqrt{T}$&#32423;&#21035;&#30340;&#33258;&#28982;&#20559;&#24046;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#20598;&#31574;&#30053;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider contextual bandit problems with knapsacks [CBwK], a problem where at each round, a scalar reward is obtained and vector-valued costs are suffered. The learner aims to maximize the cumulative rewards while ensuring that the cumulative costs are lower than some predetermined cost constraints. We assume that contexts come from a continuous set, that costs can be signed, and that the expected reward and cost functions, while unknown, may be uniformly estimated -- a typical assumption in the literature. In this setting, total cost constraints had so far to be at least of order $T^{3/4}$, where $T$ is the number of rounds, and were even typically assumed to depend linearly on $T$. We are however motivated to use CBwK to impose a fairness constraint of equalized average costs between groups: the budget associated with the corresponding cost constraints should be as close as possible to the natural deviations, of order $\sqrt{T}$. To that end, we introduce a dual strategy based on 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14943</link><description>&lt;p&gt;
&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;Bayesian&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14943
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#22871;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32422;&#26463;&#22495;&#20869;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#26159;&#23436;&#20840;&#19982;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20984;&#20248;&#21270;&#20013;&#30340;&#30828;&#24065;&#25237;&#27880;&#24605;&#24819;&#65292;&#20197;&#21450;&#32422;&#26463;&#37319;&#26679;&#20316;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#38236;&#20687;&#20248;&#21270;&#38382;&#39064;&#30340;&#35266;&#28857;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#20960;&#31181;&#29616;&#26377;&#30340;&#32422;&#26463;&#37319;&#26679;&#31639;&#27861;&#65292;&#21253;&#25324;&#38236;&#20687;Langevin&#21160;&#21147;&#23398;&#21644;&#38236;&#20687;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20174;&#21333;&#32431;&#24418;&#30446;&#26631;&#36827;&#34892;&#37319;&#26679;&#12289;&#24102;&#20844;&#24179;&#24615;&#32422;&#26463;&#36827;&#34892;&#37319;&#26679;&#20197;&#21450;&#21518;&#36873;&#25321;&#25512;&#26029;&#20013;&#30340;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19981;&#38656;&#35201;&#35843;&#25972;&#20219;&#20309;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#32422;&#26463;&#37319;&#26679;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22266;&#23450;&#32500;&#24230;&#19979;&#20869;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#21457;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#20851;&#38190;&#22312;&#20110;&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#24230;&#32780;&#19981;&#26159;&#32500;&#25968;&#65292;&#24182;&#35777;&#26126;&#22312;&#22266;&#23450;&#32500;&#24230;&#19979;&#20013;&#24230;&#23548;&#25968;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#24207;&#21015;&#26680;&#36827;&#34892;&#22238;&#24402;&#26159;&#21487;&#33021;&#20986;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.14077</link><description>&lt;p&gt;
&#35686;&#24789;&#23574;&#23792;&#65306;&#22266;&#23450;&#32500;&#24230;&#19979;&#20869;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Mind the spikes: Benign overfitting of kernels and neural networks in fixed dimension. (arXiv:2305.14077v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14077
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22266;&#23450;&#32500;&#24230;&#19979;&#20869;&#26680;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#21457;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#20851;&#38190;&#22312;&#20110;&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#24230;&#32780;&#19981;&#26159;&#32500;&#25968;&#65292;&#24182;&#35777;&#26126;&#22312;&#22266;&#23450;&#32500;&#24230;&#19979;&#20013;&#24230;&#23548;&#25968;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#24207;&#21015;&#26680;&#36827;&#34892;&#22238;&#24402;&#26159;&#21487;&#33021;&#20986;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36798;&#21040;&#25509;&#36817;&#38646;&#30340;&#35757;&#32451;&#35823;&#24046;&#30340;&#25104;&#21151;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#35937;&#30340;&#26497;&#22823;&#20852;&#36259;&#65292;&#21363;&#20351;&#20272;&#35745;&#22120;&#25554;&#20540;&#22024;&#26434;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#23427;&#20204;&#36824;&#26159;&#20855;&#26377;&#32479;&#35745;&#19968;&#33268;&#24615;&#12290;&#23613;&#31649;&#26576;&#20123;&#23398;&#20064;&#26041;&#27861;&#30340;&#22266;&#23450;&#32500;&#24230;&#19979;&#24050;&#32463;&#30830;&#23450;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#65292;&#20294;&#30446;&#21069;&#30340;&#25991;&#29486;&#34920;&#26126;&#65292;&#23545;&#20110;&#20856;&#22411;&#20869;&#26680;&#26041;&#27861;&#21644;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#22238;&#24402;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#38656;&#35201;&#39640;&#32500;&#24230;&#35774;&#32622;&#65292;&#20854;&#20013;&#32500;&#25968;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#20272;&#35745;&#22120;&#30340;&#24179;&#28369;&#24230;&#26159;&#20851;&#38190;&#65292;&#32780;&#19981;&#26159;&#32500;&#25968;&#65306;&#21482;&#26377;&#24403;&#20272;&#35745;&#22120;&#30340;&#23548;&#25968;&#36275;&#22815;&#22823;&#26102;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#25165;&#21487;&#33021;&#21457;&#29983;&#12290;&#25105;&#20204;&#23558;&#29616;&#26377;&#30340;&#19981;&#19968;&#33268;&#24615;&#32467;&#26524;&#25512;&#24191;&#21040;&#38750;&#25554;&#20540;&#27169;&#22411;&#21644;&#26356;&#22810;&#20869;&#26680;&#65292;&#20197;&#34920;&#26126;&#22312;&#22266;&#23450;&#32500;&#24230;&#19979;&#20013;&#24230;&#23548;&#25968;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#29992;&#24207;&#21015;&#26680;&#36827;&#34892;&#22238;&#24402;&#26159;&#21487;&#33021;&#20986;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of over-parameterized neural networks trained to near-zero training error has caused great interest in the phenomenon of benign overfitting, where estimators are statistically consistent even though they interpolate noisy training data. While benign overfitting in fixed dimension has been established for some learning methods, current literature suggests that for regression with typical kernel methods and wide neural networks, benign overfitting requires a high-dimensional setting where the dimension grows with the sample size. In this paper, we show that the smoothness of the estimators, and not the dimension, is the key: benign overfitting is possible if and only if the estimator's derivatives are large enough. We generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension. Conversely, we show that benign overfitting is possible for regression with a seque
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#31867;&#8212;&#8212;&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65292;&#20854;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;2&#33539;&#25968;&#36827;&#34892;&#24179;&#26041;&#21644;&#22522;&#20110;&#26576;&#20010;&#22522;&#30784;&#24230;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#20005;&#26684;&#25512;&#24191;&#20102;&#32463;&#20856;&#25351;&#25968;&#26063;&#65292;&#20855;&#26377;&#38381;&#24615;&#26465;&#20214;&#25512;&#26029;&#21644;&#21487;&#35745;&#31639;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.13552</link><description>&lt;p&gt;
&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65306;&#19968;&#31181;&#26032;&#30340;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#31867;
&lt;/p&gt;
&lt;p&gt;
Squared Neural Families: A New Class of Tractable Density Models. (arXiv:2305.13552v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13552
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#31867;&#8212;&#8212;&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65292;&#20854;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;2&#33539;&#25968;&#36827;&#34892;&#24179;&#26041;&#21644;&#22522;&#20110;&#26576;&#20010;&#22522;&#30784;&#24230;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#65292;&#20005;&#26684;&#25512;&#24191;&#20102;&#32463;&#20856;&#25351;&#25968;&#26063;&#65292;&#20855;&#26377;&#38381;&#24615;&#26465;&#20214;&#25512;&#26029;&#21644;&#21487;&#35745;&#31639;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#20998;&#24067;&#30340;&#28789;&#27963;&#27169;&#22411;&#26159;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#24320;&#21457;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#20998;&#24067;&#31867;&#21035;&#65292;&#31216;&#20026;&#24179;&#26041;&#31070;&#32463;&#20998;&#24067;&#26063;&#65288;SNEFY&#65289;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;2&#33539;&#25968;&#36827;&#34892;&#24179;&#26041;&#24182;&#22522;&#20110;&#26576;&#20010;&#22522;&#30784;&#24230;&#37327;&#36827;&#34892;&#24402;&#19968;&#21270;&#12290;&#31867;&#20284;&#20110;&#26080;&#31351;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#24191;&#27867;&#32852;&#31995;&#30340;&#25512;&#29702;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#35768;&#22810;&#24863;&#20852;&#36259;&#30340;&#24773;&#20917;&#19979;&#65292;SNEFY&#20855;&#26377;&#23553;&#38381;&#24418;&#24335;&#30340;&#26631;&#20934;&#21270;&#24120;&#25968;&#65292;&#22240;&#27492;&#26159;&#28789;&#27963;&#19988;&#23436;&#20840;&#21487;&#35745;&#31639;&#23494;&#24230;&#27169;&#22411;&#12290;SNEFY&#20005;&#26684;&#25512;&#24191;&#20102;&#32463;&#20856;&#30340;&#25351;&#25968;&#26063;&#65292;&#23545;&#20110;&#26465;&#20214;&#25512;&#26029;&#20855;&#26377;&#38381;&#24615;&#65292;&#24182;&#19988;&#20855;&#26377;&#21487;&#35745;&#31639;&#30340;&#36793;&#38469;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#23494;&#24230;&#20272;&#35745;&#21644;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#20219;&#21153;&#20013;&#23637;&#31034;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Flexible models for probability distributions are an essential ingredient in many machine learning tasks. We develop and investigate a new class of probability distributions, which we call a Squared Neural Family (SNEFY), formed by squaring the 2-norm of a neural network and normalising it with respect to a base measure. Following the reasoning similar to the well established connections between infinitely wide neural networks and Gaussian processes, we show that SNEFYs admit a closed form normalising constants in many cases of interest, thereby resulting in flexible yet fully tractable density models. SNEFYs strictly generalise classical exponential families, are closed under conditioning, and have tractable marginal distributions. Their utility is illustrated on a variety of density estimation and conditional density estimation tasks. Software available at https://github.com/RussellTsuchida/snefy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#26080;&#20998;&#24067;&#27169;&#22411;&#26080;&#20559;&#22238;&#24402;&#26657;&#20934;&#26041;&#27861;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#30340;&#32479;&#35745;&#20445;&#35777;&#21644;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.12283</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#26041;&#27861;&#19979;&#30340;&#26080;&#20998;&#24067;&#27169;&#22411;&#26080;&#20559;&#22238;&#24402;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Model-Agnostic Regression Calibration via Nonparametric Methods. (arXiv:2305.12283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#26080;&#20998;&#24067;&#27169;&#22411;&#26080;&#20559;&#22238;&#24402;&#26657;&#20934;&#26041;&#27861;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#30340;&#32479;&#35745;&#20445;&#35777;&#21644;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22238;&#24402;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#38750;&#21442;&#25968;&#26041;&#27861;&#30340;&#26657;&#20934;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#19981;&#20381;&#36182;&#20110;&#24213;&#23618;&#39044;&#27979;&#27169;&#22411;&#65292;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#26657;&#20934;&#35823;&#24046;&#30340;&#19978;&#38480;&#21644;&#19979;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#21644;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the uncertainty quantification problem for regression models. Specifically, we consider an individual calibration objective for characterizing the quantiles of the prediction model. While such an objective is well-motivated from downstream tasks such as newsvendor cost, the existing methods have been largely heuristic and lack of statistical guarantee in terms of individual calibration. We show via simple examples that the existing methods focusing on population-level calibration guarantees such as average calibration or sharpness can lead to harmful and unexpected results. We propose simple nonparametric calibration methods that are agnostic of the underlying prediction model and enjoy both computational efficiency and statistical consistency. Our approach enables a better understanding of the possibility of individual calibration, and we establish matching upper and lower bounds for the calibration error of our proposed methods. Technically, our analysis co
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PC&#30340;&#26032;&#22411;&#26102;&#24207;&#35760;&#24518;&#27169;&#22411;&#65292;&#31216;&#20026;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#65288;tPC&#65289;&#65292;&#21487;&#20197;&#36890;&#36807;&#29983;&#29289;&#21487;&#34892;&#30340;&#31070;&#32463;&#23454;&#29616;&#20934;&#30830;&#22320;&#35760;&#24518;&#21644;&#26816;&#32034;&#36830;&#32493;&#36755;&#20837;&#12290;&#20854;&#20013;tPC&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#31181;&#32463;&#20856;&#24322;&#21521;&#24615;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#65288;AHN&#65289;&#65292;&#20855;&#26377;&#26356;&#31283;&#23450;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#32534;&#30721;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#65292;&#21306;&#20998;&#22312;&#24207;&#21015;&#20013;&#20986;&#29616;&#30340;&#37325;&#22797;&#20803;&#32032;&#12290;</title><link>http://arxiv.org/abs/2305.11982</link><description>&lt;p&gt;
&#24102;&#26377;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#30340;&#26102;&#24207;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
Sequential Memory with Temporal Predictive Coding. (arXiv:2305.11982v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11982
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PC&#30340;&#26032;&#22411;&#26102;&#24207;&#35760;&#24518;&#27169;&#22411;&#65292;&#31216;&#20026;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#65288;tPC&#65289;&#65292;&#21487;&#20197;&#36890;&#36807;&#29983;&#29289;&#21487;&#34892;&#30340;&#31070;&#32463;&#23454;&#29616;&#20934;&#30830;&#22320;&#35760;&#24518;&#21644;&#26816;&#32034;&#36830;&#32493;&#36755;&#20837;&#12290;&#20854;&#20013;tPC&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#31181;&#32463;&#20856;&#24322;&#21521;&#24615;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#65288;AHN&#65289;&#65292;&#20855;&#26377;&#26356;&#31283;&#23450;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#21487;&#20197;&#32534;&#30721;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#65292;&#21306;&#20998;&#22312;&#24207;&#21015;&#20013;&#20986;&#29616;&#30340;&#37325;&#22797;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#29983;&#29289;&#20307;&#23384;&#20648;&#20107;&#20214;&#24207;&#21015;&#30340;&#26102;&#38388;&#39034;&#24207;&#33267;&#20851;&#37325;&#35201;&#65292;&#28982;&#32780;&#22823;&#33041;&#20013;&#25903;&#37197;&#26102;&#24207;&#35760;&#24518;&#30340;&#35745;&#31639;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#21463;&#21040;&#31070;&#32463;&#31185;&#23398;&#29702;&#35770;&#21644;&#39044;&#27979;&#32534;&#30721;&#65288;PC&#65289;&#22312;&#38745;&#24577;&#23384;&#20648;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#21551;&#31034;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PC&#30340;&#26032;&#22411;&#26102;&#24207;&#35760;&#24518;&#27169;&#22411;&#65292;&#31216;&#20026;&#26102;&#38388;&#39044;&#27979;&#32534;&#30721;&#65288;tPC&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;tPC&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#29983;&#29289;&#21487;&#34892;&#30340;&#31070;&#32463;&#23454;&#29616;&#20934;&#30830;&#22320;&#35760;&#24518;&#21644;&#26816;&#32034;&#36830;&#32493;&#36755;&#20837;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#30740;&#31350;&#34920;&#26126;&#65292;tPC&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#31181;&#20855;&#26377;&#38544;&#24335;&#32479;&#35745;&#30333;&#21270;&#36807;&#31243;&#30340;&#32463;&#20856;&#24322;&#21521;&#24615;&#38669;&#26222;&#33778;&#23572;&#24503;&#32593;&#32476;&#65288;AHN&#65289;&#65292;&#36825;&#20250;&#22312;&#32467;&#26500;&#21270;&#36755;&#20837;&#30340;&#26102;&#24207;&#35760;&#24518;&#20219;&#21153;&#20013;&#23548;&#33268;&#26356;&#31283;&#23450;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20855;&#26377;&#22810;&#23618;&#32467;&#26500;&#30340;tPC&#21487;&#20197;&#32534;&#30721;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#65292;&#22240;&#27492;&#21487;&#20197;&#21306;&#20998;&#22312;&#24207;&#21015;&#20013;&#20986;&#29616;&#30340;&#37325;&#22797;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Memorizing the temporal order of event sequences is critical for the survival of biological agents. However, the computational mechanism underlying sequential memory in the brain remains unclear. Inspired by neuroscience theories and recent successes in applying predictive coding (PC) to static memory tasks, in this work we propose a novel PC-based model for sequential memory, called temporal predictive coding (tPC). We show that our tPC models can memorize and retrieve sequential inputs accurately with a biologically plausible neural implementation. Importantly, our analytical study reveals that tPC can be viewed as a classical Asymmetric Hopfield Network (AHN) with an implicit statistical whitening process, which leads to more stable performance in sequential memory tasks of structured inputs. Moreover, we find that tPC with a multi-layer structure can encode context-dependent information, thus distinguishing between repeating elements appearing in a sequence, a computation attribute
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#21644;Monte Carlo&#37319;&#26679;&#30340;&#30452;&#25509;&#26041;&#27861;&#26469;&#20272;&#31639;&#33258;&#26059;&#31995;&#32479;&#30340;&#21452;&#37096;&#20998;&#20114;&#20449;&#24687;&#65292;&#21487;&#20197;&#30740;&#31350;&#20219;&#24847;&#23376;&#31995;&#32479;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#24182;&#19988;&#22312;Ising&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.13412</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#26059;&#31995;&#32479;&#20114;&#20449;&#24687;&#30340;&#20272;&#31639;
&lt;/p&gt;
&lt;p&gt;
Mutual information of spin systems from autoregressive neural networks. (arXiv:2304.13412v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#21644;Monte Carlo&#37319;&#26679;&#30340;&#30452;&#25509;&#26041;&#27861;&#26469;&#20272;&#31639;&#33258;&#26059;&#31995;&#32479;&#30340;&#21452;&#37096;&#20998;&#20114;&#20449;&#24687;&#65292;&#21487;&#20197;&#30740;&#31350;&#20219;&#24847;&#23376;&#31995;&#32479;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#24182;&#19988;&#22312;Ising&#27169;&#22411;&#19978;&#28436;&#31034;&#20102;&#27492;&#26041;&#27861;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#22522;&#20110;Monte Carlo&#37319;&#26679;&#21644;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#30340;&#30452;&#25509;&#26041;&#27861;&#26469;&#20272;&#31639;&#32463;&#20856;&#33258;&#26059;&#31995;&#32479;&#30340;&#21452;&#37096;&#20998;&#20114;&#20449;&#24687;&#12290;&#23427;&#20801;&#35768;&#30740;&#31350;&#20219;&#24847;&#23376;&#31995;&#32479;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#24182;&#19988;&#21487;&#25512;&#24191;&#21040;&#32463;&#20856;&#22330;&#29702;&#35770;&#12290;&#25105;&#20204;&#29992;Ising&#27169;&#22411;&#30340;&#22235;&#20010;&#20998;&#21306;&#28436;&#31034;&#20102;&#23427;&#30340;&#25928;&#26524;&#65292;&#21253;&#25324;&#22810;&#37325;&#36830;&#25509;&#30340;&#20598;&#22855;&#20998;&#21106;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#36828;&#31163;&#20020;&#30028;&#28201;&#24230;&#26102;&#65292;&#38754;&#31215;&#35268;&#24459;&#24471;&#21040;&#20102;&#28385;&#36275;&#65306;&#24120;&#25968;&#39033;&#26159;&#36890;&#29992;&#30340;&#65292;&#32780;&#27604;&#20363;&#31995;&#25968;&#23545;&#20110;&#20598;&#22855;&#20998;&#21106;&#26159;&#19981;&#21516;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We describe a direct approach to estimate bipartite mutual information of a classical spin system based on Monte Carlo sampling enhanced by autoregressive neural networks. It allows studying arbitrary geometries of subsystems and can be generalized to classical field theories. We demonstrate it on the Ising model for four partitionings, including a multiply-connected even-odd division. We show that the area law is satisfied for temperatures away from the critical temperature: the constant term is universal, whereas the proportionality coefficient is different for the even-odd partitioning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;OWA&#30340;&#38142;&#25509;&#65292;Lance-Williams&#20844;&#24335;&#21644;&#26641;&#26525;&#21453;&#36716;&#25216;&#26415;&#65292;&#25512;&#24191;&#20102;&#20957;&#32858;&#23618;&#27425;&#32858;&#31867;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#26465;&#20214;&#29992;&#20110;&#20445;&#35777;&#32467;&#26524;&#30340;&#26641;&#26525;&#22270;&#27809;&#26377;&#19981;&#32654;&#35266;&#30340;&#21453;&#36716;&#12290;</title><link>http://arxiv.org/abs/2303.05683</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;OWA&#30340;&#38142;&#25509;&#12289;Lance-Williams&#20844;&#24335;&#21644;&#26641;&#26525;&#21453;&#36716;&#30340;&#23618;&#27425;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering with OWA-based linkages, the Lance-Williams formula, and dendrogram inversions. (arXiv:2303.05683v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;OWA&#30340;&#38142;&#25509;&#65292;Lance-Williams&#20844;&#24335;&#21644;&#26641;&#26525;&#21453;&#36716;&#25216;&#26415;&#65292;&#25512;&#24191;&#20102;&#20957;&#32858;&#23618;&#27425;&#32858;&#31867;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#26465;&#20214;&#29992;&#20110;&#20445;&#35777;&#32467;&#26524;&#30340;&#26641;&#26525;&#22270;&#27809;&#26377;&#19981;&#32654;&#35266;&#30340;&#21453;&#36716;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26377;&#24207;&#21152;&#26435;&#24179;&#22343;&#65288;OWA&#65289;&#31639;&#23376;&#30340;&#20957;&#32858;&#23618;&#27425;&#32858;&#31867;&#19981;&#20165;&#25512;&#24191;&#20102;&#21333;&#20010;&#30340;&#12289;&#23436;&#20840;&#30340;&#21644;&#24179;&#22343;&#30340;&#38142;&#25509;&#65292;&#36824;&#21253;&#25324;&#22522;&#20110;&#19968;&#20123;&#26368;&#36817;&#25110;&#26368;&#36828;&#37051;&#23621;&#12289;&#20462;&#21098;&#21644;&#20462;&#25972;&#30340;&#28857;&#23545;&#30456;&#20284;&#24615;&#30340;&#24179;&#22343;&#20540;&#30340;&#38598;&#32676;&#38388;&#36317;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#33879;&#21517;&#30340;Lance-Williams&#26356;&#26032;&#20844;&#24335;&#19982;&#25193;&#23637;&#30340;&#22522;&#20110;OWA&#30340;&#38142;&#25509;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#26080;&#38480;&#31995;&#25968;&#24207;&#21015;&#29983;&#25104;&#26435;&#37325;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#26465;&#20214;&#65292;&#20197;&#20445;&#35777;&#26435;&#37325;&#29983;&#25104;&#22120;&#20135;&#29983;&#30340;&#26641;&#26525;&#22270;&#19981;&#20250;&#20986;&#29616;&#19981;&#32654;&#35266;&#30340;&#21453;&#36716;&#12290;
&lt;/p&gt;
&lt;p&gt;
Agglomerative hierarchical clustering based on Ordered Weighted Averaging (OWA) operators not only generalises the single, complete, and average linkages, but also includes intercluster distances based on a few nearest or farthest neighbours, trimmed and winsorised means of pairwise point similarities, amongst many others. We explore the relationships between the famous Lance-Williams update formula and the extended OWA-based linkages with weights generated via infinite coefficient sequences. Furthermore, we provide some conditions for the weight generators to guarantee the resulting dendrograms to be free from unaesthetic inversions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25913;&#36827;&#30340;FTRL&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31995;&#21015;&#27491;&#21017;&#21270;&#22120;&#21644;&#26032;&#30340;&#23398;&#20064;&#29575;&#35745;&#21010;&#65292;&#19981;&#20877;&#38656;&#35201;&#20551;&#35774;&#23384;&#22312;&#21807;&#19968;&#26368;&#20248;&#33218;&#65292;&#24182;&#23545;&#26576;&#20123;&#27491;&#21017;&#21270;&#22120;&#30340;&#36951;&#25022;&#30028;&#38480;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2302.13534</link><description>&lt;p&gt;
&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;FTRL&#31639;&#27861;&#19982;&#19968;&#33324;&#27491;&#21017;&#21270;&#21644;&#22810;&#20010;&#26368;&#20248;&#33218;&#30340;&#26368;&#20339;&#20445;&#35777;&#26377;&#25152;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
Improved Best-of-Both-Worlds Guarantees for Multi-Armed Bandits: FTRL with General Regularizers and Multiple Optimal Arms. (arXiv:2302.13534v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25913;&#36827;&#30340;FTRL&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31995;&#21015;&#27491;&#21017;&#21270;&#22120;&#21644;&#26032;&#30340;&#23398;&#20064;&#29575;&#35745;&#21010;&#65292;&#19981;&#20877;&#38656;&#35201;&#20551;&#35774;&#23384;&#22312;&#21807;&#19968;&#26368;&#20248;&#33218;&#65292;&#24182;&#23545;&#26576;&#20123;&#27491;&#21017;&#21270;&#22120;&#30340;&#36951;&#25022;&#30028;&#38480;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#35774;&#35745;&#33258;&#36866;&#24212;&#22810;&#33218;&#36172;&#21338;&#26426;&#31639;&#27861;&#65292;&#21516;&#26102;&#22312;&#38543;&#26426;&#35774;&#32622;&#21644;&#23545;&#25239;&#35774;&#32622;&#20013;&#34920;&#29616;&#26368;&#20248;&#65288;&#36890;&#24120;&#31216;&#20026;&#26368;&#20339;&#20445;&#35777;&#65289;&#12290;&#26368;&#36817;&#30340;&#19968;&#31995;&#21015;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#27491;&#30830;&#37197;&#32622;&#21644;&#20998;&#26512;&#26102;&#65292;&#21407;&#26412;&#35774;&#35745;&#29992;&#20110;&#23545;&#25239;&#35774;&#32622;&#30340;Follow-the-Regularized-Leader&#65288;FTRL&#65289;&#31639;&#27861;&#23454;&#38469;&#19978;&#21487;&#20197;&#26368;&#20248;&#22320;&#36866;&#24212;&#38543;&#26426;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#20851;&#38190;&#20381;&#36182;&#20110;&#23384;&#22312;&#21807;&#19968;&#26368;&#20248;&#33218;&#30340;&#20551;&#35774;&#12290;&#26368;&#36817;&#65292;Ito&#65288;2021&#65289;&#39318;&#27425;&#37319;&#21462;&#25514;&#26045;&#21024;&#38500;&#20102;&#19968;&#20010;&#29305;&#23450;FTRL&#31639;&#27861;&#23545;&#20110;$\frac{1}{2}$-Tsallis&#29109;&#27491;&#21017;&#21270;&#30340;&#19981;&#21487;&#21462;&#21807;&#19968;&#24615;&#20551;&#35774;&#12290;&#26412;&#25991;&#23545;&#36825;&#19968;&#32467;&#26524;&#36827;&#34892;&#20102;&#26174;&#33879;&#25913;&#36827;&#21644;&#25512;&#24191;&#65292;&#34920;&#26126;FTRL&#31639;&#27861;&#22312;&#24191;&#27867;&#30340;&#27491;&#21017;&#21270;&#22120;&#21644;&#26032;&#30340;&#23398;&#20064;&#29575;&#35745;&#21010;&#19979;&#19981;&#38656;&#35201;&#21807;&#19968;&#24615;&#12290;&#23545;&#20110;&#26576;&#20123;&#27491;&#21017;&#21270;&#22120;&#65292;&#25105;&#20204;&#30340;&#36951;&#25022;&#30028;&#38480;&#19982;&#21069;&#20154;&#30340;&#32467;&#26524;&#30456;&#27604;&#20063;&#26377;&#25152;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of designing adaptive multi-armed bandit algorithms that perform optimally in both the stochastic setting and the adversarial setting simultaneously (often known as a best-of-both-world guarantee). A line of recent works shows that when configured and analyzed properly, the Follow-the-Regularized-Leader (FTRL) algorithm, originally designed for the adversarial setting, can in fact optimally adapt to the stochastic setting as well. Such results, however, critically rely on an assumption that there exists one unique optimal arm. Recently, Ito (2021) took the first step to remove such an undesirable uniqueness assumption for one particular FTRL algorithm with the $\frac{1}{2}$-Tsallis entropy regularizer. In this work, we significantly improve and generalize this result, showing that uniqueness is unnecessary for FTRL with a broad family of regularizers and a new learning rate schedule. For some regularizers, our regret bounds also improve upon prior results even when
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20110;&#31163;&#25955;&#24207;&#21015;&#20998;&#31867;&#22120;&#30340;&#38543;&#26426;&#21024;&#38500;&#65288;RS-Del&#65289;&#24179;&#28369;&#26426;&#21046;&#65292;&#25552;&#20379;&#38024;&#23545;&#32534;&#36753;&#36317;&#31163;&#21463;&#38480;&#23545;&#25239;&#24615;&#30340;&#40065;&#26834;&#24615;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2302.01757</link><description>&lt;p&gt;
RS-Del: &#38543;&#26426;&#21024;&#38500;&#23545;&#24207;&#21015;&#20998;&#31867;&#22120;&#30340;&#32534;&#36753;&#36317;&#31163;&#40065;&#26834;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion. (arXiv:2302.01757v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01757
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20110;&#31163;&#25955;&#24207;&#21015;&#20998;&#31867;&#22120;&#30340;&#38543;&#26426;&#21024;&#38500;&#65288;RS-Del&#65289;&#24179;&#28369;&#26426;&#21046;&#65292;&#25552;&#20379;&#38024;&#23545;&#32534;&#36753;&#36317;&#31163;&#21463;&#38480;&#23545;&#25239;&#24615;&#30340;&#40065;&#26834;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#24179;&#28369;&#26159;&#26500;&#24314;&#20855;&#26377;&#35748;&#35777;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#22120;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#20027;&#35201;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#36755;&#20837;&#65288;&#22914;&#22270;&#20687;&#65289;&#30340;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#24120;&#24120;&#30740;&#31350;$\ell_p$&#33539;&#25968;&#21463;&#38480;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20855;&#26377;&#31163;&#25955;&#25110;&#21487;&#21464;&#22823;&#23567;&#36755;&#20837;&#65288;&#20363;&#22914;&#28304;&#20195;&#30721;&#65289;&#30340;&#20998;&#31867;&#22120;&#30340;&#30740;&#31350;&#36739;&#23569;&#65292;&#36825;&#20123;&#20998;&#31867;&#22120;&#38656;&#35201;&#19981;&#21516;&#30340;&#23041;&#32961;&#27169;&#22411;&#21644;&#24179;&#28369;&#26426;&#21046;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#65292;&#20197;&#36866;&#29992;&#20110;&#31163;&#25955;&#24207;&#21015;&#20998;&#31867;&#22120;&#65292;&#20197;&#25552;&#20379;&#38024;&#23545;&#32534;&#36753;&#36317;&#31163;&#21463;&#38480;&#30340;&#23545;&#25239;&#24615;&#30340;&#21487;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#24179;&#28369;&#26426;&#21046;&#38543;&#26426;&#21024;&#38500;&#65288;RS-Del&#65289;&#24212;&#29992;&#20102;&#38543;&#26426;&#21024;&#38500;&#32534;&#36753;&#65292;&#36825;&#31181;&#26041;&#24335;&#65288;&#20063;&#35768;&#20196;&#20154;&#24778;&#35766;&#22320;&#65289;&#36275;&#20197;&#25552;&#20379;&#38024;&#23545;&#23545;&#25239;&#24615;&#21024;&#38500;&#12289;&#25554;&#20837;&#21644;&#26367;&#25442;&#32534;&#36753;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#35748;&#35777;&#35777;&#26126;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;Neyman-Pearson&#26041;&#27861;&#65292;&#22312;&#25105;&#20204;&#30340;&#24773;&#20917;&#19979;&#26080;&#27861;&#35745;&#31639;&#65292;&#32780;&#26159;&#22260;&#32469;&#30528;&#21478;&#19968;&#31181;&#26041;&#24335;&#36827;&#34892;&#32452;&#32455;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized smoothing is a leading approach for constructing classifiers that are certifiably robust against adversarial examples. Existing work on randomized smoothing has focused on classifiers with continuous inputs, such as images, where $\ell_p$-norm bounded adversaries are commonly studied. However, there has been limited work for classifiers with discrete or variable-size inputs, such as for source code, which require different threat models and smoothing mechanisms. In this work, we adapt randomized smoothing for discrete sequence classifiers to provide certified robustness against edit distance-bounded adversaries. Our proposed smoothing mechanism randomized deletion (RS-Del) applies random deletion edits, which are (perhaps surprisingly) sufficient to confer robustness against adversarial deletion, insertion and substitution edits. Our proof of certification deviates from the established Neyman-Pearson approach, which is intractable in our setting, and is instead organized aro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#21518;&#22788;&#29702;MCMC&#36755;&#20986;&#36807;&#31243;&#20013;&#30340;&#30149;&#24577;&#38382;&#39064;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;Stein&#31232;&#37322;&#31639;&#27861;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#36825;&#20123;&#30149;&#24577;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#20026;&#25552;&#39640;&#36924;&#36817;&#36136;&#37327;&#25552;&#20379;&#20102;&#26032;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2301.13528</link><description>&lt;p&gt;
&#26680;&#26031;&#22374;&#36317;&#31163;&#31232;&#37322;&#65306;&#20851;&#20110;&#30149;&#24577;&#30340;&#29702;&#35770;&#35270;&#35282;&#21644;&#27491;&#21017;&#21270;&#30340;&#23454;&#38469;&#20462;&#22797;&#65288;arXiv:2301.13528v2 [math.ST] &#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Kernel Stein Discrepancy thinning: a theoretical perspective of pathologies and a practical fix with regularization. (arXiv:2301.13528v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#21518;&#22788;&#29702;MCMC&#36755;&#20986;&#36807;&#31243;&#20013;&#30340;&#30149;&#24577;&#38382;&#39064;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#27491;&#21017;&#21270;&#30340;Stein&#31232;&#37322;&#31639;&#27861;&#65292;&#26377;&#25928;&#32531;&#35299;&#20102;&#36825;&#20123;&#30149;&#24577;&#20135;&#29983;&#30340;&#24433;&#21709;&#65292;&#20026;&#25552;&#39640;&#36924;&#36817;&#36136;&#37327;&#25552;&#20379;&#20102;&#26032;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein&#31232;&#37322;&#26159;&#19968;&#31181;&#26377;&#21069;&#36884;&#30340;&#31639;&#27861;&#65292;&#30001;&#65288;Riabiz et al.&#65292;2022&#65289;&#25552;&#20986;&#29992;&#20110;&#21518;&#22788;&#29702;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#30340;&#36755;&#20986;&#12290;&#20854;&#20027;&#35201;&#21407;&#21017;&#26159;&#36138;&#23146;&#22320;&#26368;&#23567;&#21270;&#26680;&#21270;Stein&#24046;&#24322;&#65288;KSD&#65289;&#65292;&#23427;&#20165;&#38656;&#35201;&#23545;&#25968;&#30446;&#26631;&#20998;&#24067;&#30340;&#26799;&#24230;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#21512;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290; Stein&#31232;&#37322;&#30340;&#20027;&#35201;&#20248;&#21183;&#26159;&#33258;&#21160;&#28040;&#38500;&#21551;&#21160;&#26399;&#65292;&#32416;&#27491;&#26368;&#36817;&#30340;MCMC&#31639;&#27861;&#24341;&#20837;&#30340;&#20559;&#24046;&#65292;&#24182;&#20855;&#26377;&#25910;&#25947;&#33267;&#30446;&#26631;&#20998;&#24067;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;&#28982;&#32780;&#65292; Stein&#31232;&#37322;&#23384;&#22312;&#20960;&#20010;&#32463;&#39564;&#30149;&#24577;&#65292;&#21487;&#33021;&#23548;&#33268;&#21155;&#36136;&#36924;&#36817;&#65292;&#36825;&#22312;&#25991;&#29486;&#20013;&#24050;&#34987;&#35266;&#23519;&#21040;&#12290; &#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#30149;&#24577;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#20197;&#26126;&#30830;&#35782;&#21035;&#28041;&#21450;&#30340;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31574;&#30053;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27491;&#21017;&#21270;&#30340; Stein&#31232;&#37322;&#31639;&#27861;&#26469;&#32531;&#35299;&#24050;&#35782;&#21035;&#30340;&#30149;&#24577;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein thinning is a promising algorithm proposed by (Riabiz et al., 2022) for post-processing outputs of Markov chain Monte Carlo (MCMC). The main principle is to greedily minimize the kernelized Stein discrepancy (KSD), which only requires the gradient of the log-target distribution, and is thus well-suited for Bayesian inference. The main advantages of Stein thinning are the automatic remove of the burn-in period, the correction of the bias introduced by recent MCMC algorithms, and the asymptotic properties of convergence towards the target distribution. Nevertheless, Stein thinning suffers from several empirical pathologies, which may result in poor approximations, as observed in the literature. In this article, we conduct a theoretical analysis of these pathologies, to clearly identify the mechanisms at stake, and suggest improved strategies. Then, we introduce the regularized Stein thinning algorithm to alleviate the identified pathologies. Finally, theoretical guarantees and exte
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.13349</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#23454;&#29616;&#26080;&#32422;&#26463;&#21160;&#24577;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#22312;&#20004;&#20010;&#38382;&#39064;&#32467;&#26500;&#30340;&#32806;&#21512;&#19979;&#30340;&#24773;&#20917;&#65306;&#22495;&#26080;&#30028;&#65292;&#32780;&#31639;&#27861;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#26469;&#34913;&#37327;&#30340;&#12290;&#22788;&#29702;&#20219;&#19968;&#38382;&#39064;&#37117;&#35201;&#27714;&#36951;&#25022;&#30028;&#38480;&#20381;&#36182;&#20110;&#27604;&#36739;&#24207;&#21015;&#30340;&#26576;&#20123;&#22797;&#26434;&#24230;&#37327;&#24230; - &#29305;&#21035;&#26159;&#26080;&#32422;&#26463;OLO&#20013;&#30340;&#27604;&#36739;&#22120;&#33539;&#25968;&#65292;&#20197;&#21450;&#21160;&#24577;&#36951;&#25022;&#20013;&#30340;&#36335;&#24452;&#38271;&#24230;&#12290;&#19982;&#26368;&#36817;&#19968;&#31687;&#25991;&#31456;(Jacobsen&amp; Cutkosky&#65292;2022)&#36866;&#24212;&#36825;&#20004;&#20010;&#22797;&#26434;&#24230;&#37327;&#24230;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#12290;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;&#23454;&#29616;&#36866;&#24212;&#24615;&#65292;&#36825;&#20010;&#26694;&#26550;&#33258;&#28982;&#22320;&#21033;&#29992;&#20102;&#29615;&#22659;&#26356;&#22797;&#26434;&#30340;&#21069;&#32622;&#30693;&#35782;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38745;&#24577;&#26080;&#32422;&#26463;OLO&#26799;&#24230;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#26426;&#21046;&#35774;&#35745;&#12290;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen &amp; Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#24322;&#26041;&#24046;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#20989;&#25968;&#27169;&#22411;&#65292;&#35813;&#35770;&#25991;&#22312;&#27491;&#30830;&#35828;&#26126;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#12290;&#20294;&#26159;&#65292;&#22312;&#29992;&#25143;&#38169;&#35823;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24418;&#24335;&#26102;&#65292;&#20998;&#26512;&#34920;&#26126;&#22240;&#26524;&#25512;&#26029;&#30340;&#31934;&#24230;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#36873;&#25321;&#23454;&#29616;&#31283;&#23450;&#32780;&#20934;&#30830;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2301.12930</link><description>&lt;p&gt;
&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#27169;&#22411;&#20013;&#22240;&#26524;&#25512;&#26029;&#30340;&#26368;&#22823;&#20284;&#28982;&#19982;&#29420;&#31435;&#24615;&#26816;&#39564;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Cause-Effect Inference in Location-Scale Noise Models: Maximum Likelihood vs. Independence Testing. (arXiv:2301.12930v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12930
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#24322;&#26041;&#24046;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#20989;&#25968;&#27169;&#22411;&#65292;&#35813;&#35770;&#25991;&#22312;&#27491;&#30830;&#35828;&#26126;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#12290;&#20294;&#26159;&#65292;&#22312;&#29992;&#25143;&#38169;&#35823;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24418;&#24335;&#26102;&#65292;&#20998;&#26512;&#34920;&#26126;&#22240;&#26524;&#25512;&#26029;&#30340;&#31934;&#24230;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#36873;&#25321;&#23454;&#29616;&#31283;&#23450;&#32780;&#20934;&#30830;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#25512;&#26029;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#27491;&#30830;&#22240;&#26524;&#26041;&#21521;&#12290;&#26368;&#36817;&#24341;&#20837;&#30340;&#24322;&#26041;&#24046;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#20989;&#25968;&#27169;&#22411; (LSNM) &#32467;&#21512;&#20102;&#34920;&#36798;&#33021;&#21147;&#21644;&#21487;&#35782;&#21035;&#24615;&#20445;&#35777;&#65292;&#22312;&#27491;&#30830;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#26368;&#22823;&#20284;&#28982;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#36807;&#24191;&#27867;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#24403;&#29992;&#25143;&#38169;&#35823;&#25351;&#23450;&#22122;&#22768;&#20998;&#24067;&#30340;&#24418;&#24335;&#26102;&#65292;&#31934;&#24230;&#20250;&#24613;&#21095;&#19979;&#38477;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#36825;&#31181;&#22833;&#36133;&#20027;&#35201;&#21457;&#29983;&#22312;&#21453;&#22240;&#26524;&#26041;&#21521;&#30340;&#26465;&#20214;&#26041;&#24046;&#23567;&#20110;&#22240;&#26524;&#26041;&#21521;&#30340;&#26465;&#20214;&#26041;&#24046;&#30340;&#24773;&#20917;&#19979;&#12290;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#65292;&#21457;&#29616;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#36873;&#25321;&#21487;&#20197;&#22312;&#32570;&#20047;&#22122;&#22768;&#20998;&#24067;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#31283;&#23450;&#32780;&#20934;&#30830;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental problem of causal discovery is cause-effect inference, learning the correct causal direction between two random variables. Significant progress has been made through modelling the effect as a function of its cause and a noise term, which allows us to leverage assumptions about the generating function class. The recently introduced heteroscedastic location-scale noise functional models (LSNMs) combine expressive power with identifiability guarantees. LSNM model selection based on maximizing likelihood achieves state-of-the-art accuracy, when the noise distributions are correctly specified. However, through an extensive empirical evaluation, we demonstrate that the accuracy deteriorates sharply when the form of the noise distribution is misspecified by the user. Our analysis shows that the failure occurs mainly when the conditional variance in the anti-causal direction is smaller than that in the causal direction. As an alternative, we find that causal model selection throu
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#22270;&#24418;&#26354;&#29575;&#25551;&#36848;&#31526;&#21644;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#29992;&#20110;&#35780;&#20272;&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#30340;&#31283;&#20581;&#12289;&#34920;&#36798;&#24615;&#30340;&#25551;&#36848;&#31526;&#12290;</title><link>http://arxiv.org/abs/2301.12906</link><description>&lt;p&gt;
&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#30340;&#26354;&#29575;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Curvature Filtrations for Graph Generative Model Evaluation. (arXiv:2301.12906v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12906
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#22270;&#24418;&#26354;&#29575;&#25551;&#36848;&#31526;&#21644;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#29992;&#20110;&#35780;&#20272;&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#30340;&#31283;&#20581;&#12289;&#34920;&#36798;&#24615;&#30340;&#25551;&#36848;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#35780;&#20272;&#38656;&#35201;&#20102;&#35299;&#20998;&#24067;&#32423;&#21035;&#19978;&#30340;&#22270;&#24418;&#24046;&#24322;&#65292;&#36825;&#38656;&#35201;&#33021;&#22815;&#20197;&#26377;&#25928;&#30340;&#26041;&#24335;&#21033;&#29992;&#22270;&#24418;&#30340;&#26174;&#33879;&#23646;&#24615;&#12290;&#26354;&#29575;&#26159;&#22270;&#24418;&#30340;&#19968;&#31181;&#23646;&#24615;&#65292;&#26368;&#36817;&#24320;&#22987;&#35777;&#26126;&#20854;&#22312;&#25551;&#36848;&#22270;&#24418;&#26041;&#38754;&#24456;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#20854;&#34920;&#36798;&#24615;&#36136;&#12289;&#31283;&#23450;&#24615;&#21644;&#22312;&#27169;&#22411;&#35780;&#20272;&#20013;&#30340;&#23454;&#38469;&#25928;&#29992;&#20173;&#28982;&#24456;&#23569;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#23558;&#22270;&#24418;&#26354;&#29575;&#25551;&#36848;&#31526;&#19982;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#29992;&#20110;&#35780;&#20272;&#22270;&#24418;&#29983;&#25104;&#27169;&#22411;&#30340;&#31283;&#20581;&#12289;&#34920;&#36798;&#24615;&#30340;&#25551;&#36848;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph generative model evaluation necessitates understanding differences between graphs on the distributional level. This entails being able to harness salient attributes of graphs in an efficient manner. Curvature constitutes one such property of graphs, and has recently started to prove useful in characterising graphs. Its expressive properties, stability, and practical utility in model evaluation remain largely unexplored, however. We combine graph curvature descriptors with emerging methods from topological data analysis to obtain robust, expressive descriptors for evaluating graph generative models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#40065;&#26834;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#22833;&#30495;&#39118;&#38505;&#24230;&#37327;&#26469;&#22788;&#29702;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#20855;&#26377;&#39640;&#25928;&#19988;&#19981;&#20381;&#36182;&#27169;&#22411;&#30340;&#29305;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26694;&#26550;&#33021;&#22815;&#22312;&#20855;&#26377;&#23433;&#20840;&#32422;&#26463;&#30340;&#25511;&#21046;&#20219;&#21153;&#20013;&#23454;&#29616;&#31283;&#20581;&#30340;&#24615;&#33021;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.12593</link><description>&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#30340;&#39118;&#38505;&#21388;&#24694;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning. (arXiv:2301.12593v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12593
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#40065;&#26834;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#20351;&#29992;&#22833;&#30495;&#39118;&#38505;&#24230;&#37327;&#26469;&#22788;&#29702;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#20855;&#26377;&#39640;&#25928;&#19988;&#19981;&#20381;&#36182;&#27169;&#22411;&#30340;&#29305;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26694;&#26550;&#33021;&#22815;&#22312;&#20855;&#26377;&#23433;&#20840;&#32422;&#26463;&#30340;&#25511;&#21046;&#20219;&#21153;&#20013;&#23454;&#29616;&#31283;&#20581;&#30340;&#24615;&#33021;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#39046;&#22495;&#38656;&#35201;&#22312;&#19981;&#30830;&#23450;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#23433;&#20840;&#20915;&#31574;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#36807;&#28193;&#27169;&#22411;&#30340;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#30456;&#24178;&#22833;&#30495;&#39118;&#38505;&#24230;&#37327;&#26469;&#23545;&#27169;&#22411;&#19981;&#30830;&#23450;&#24615;&#37319;&#21462;&#39118;&#38505;&#21388;&#24694;&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#23427;&#31561;&#20215;&#20110;&#19968;&#31867;&#29305;&#23450;&#30340;&#20998;&#24067;&#40065;&#26834;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#20026;&#36825;&#20010;&#26694;&#26550;&#25552;&#20379;&#20102;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#19982;&#29616;&#26377;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#40065;&#26834;&#24615;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#34920;&#36798;&#19981;&#28041;&#21450;&#26497;&#23567;&#21270;&#26368;&#22823;&#20248;&#21270;&#12290;&#36825;&#23548;&#33268;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#12289;&#19981;&#20381;&#36182;&#27169;&#22411;&#22320;&#22312;&#21333;&#20010;&#35757;&#32451;&#29615;&#22659;&#20013;&#20165;&#38656;&#35201;&#26631;&#20934;&#25968;&#25454;&#25910;&#38598;&#26469;&#23454;&#26045;&#12290;&#22312;&#20855;&#26377;&#23433;&#20840;&#32422;&#26463;&#30340;&#36830;&#32493;&#25511;&#21046;&#20219;&#21153;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#37096;&#32626;&#26102;&#33021;&#22815;&#20135;&#29983;&#31283;&#20581;&#30340;&#24615;&#33021;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world domains require safe decision making in uncertain environments. In this work, we introduce a deep reinforcement learning framework for approaching this important problem. We consider a distribution over transition models, and apply a risk-averse perspective towards model uncertainty through the use of coherent distortion risk measures. We provide robustness guarantees for this framework by showing it is equivalent to a specific class of distributionally robust safe reinforcement learning problems. Unlike existing approaches to robustness in deep reinforcement learning, however, our formulation does not involve minimax optimization. This leads to an efficient, model-free implementation of our approach that only requires standard data collection from a single training environment. In experiments on continuous control tasks with safety constraints, we demonstrate that our framework produces robust performance and safety at deployment time across a range of perturbed test e
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#39640;&#25928;&#22320;&#35782;&#21035;&#39118;&#38505;&#34913;&#37327;&#23450;&#20041;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#39640;&#27010;&#29575;&#36793;&#30028;&#26694;&#21644;&#36873;&#25321;&#19979;&#19968;&#20010;&#35780;&#20272;&#28857;&#30340;&#26041;&#27861;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.11588</link><description>&lt;p&gt;
&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#39118;&#38505;&#34913;&#37327;
&lt;/p&gt;
&lt;p&gt;
Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty. (arXiv:2301.11588v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11588
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#19979;&#39640;&#25928;&#22320;&#35782;&#21035;&#39118;&#38505;&#34913;&#37327;&#23450;&#20041;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#39640;&#27010;&#29575;&#36793;&#30028;&#26694;&#21644;&#36873;&#25321;&#19979;&#19968;&#20010;&#35780;&#20272;&#28857;&#30340;&#26041;&#27861;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;MOBO&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#65288;IU&#65289;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#39640;&#25928;&#22320;&#35782;&#21035;&#30001;&#39118;&#38505;&#34913;&#37327;&#23450;&#20041;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65288;PF&#65289;&#12290;&#29616;&#26377;&#30340;IU&#19979;&#24085;&#32047;&#25176;&#20248;&#21270;&#30340;BO&#26041;&#27861;&#26159;&#29305;&#23450;&#39118;&#38505;&#25110;&#32773;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#65292;&#32780;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#28041;&#21450;&#19968;&#33324;&#39118;&#38505;&#34913;&#37327;&#24182;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#25152;&#25552;&#26041;&#27861;&#30340;&#22522;&#26412;&#24605;&#24819;&#26159;&#20551;&#35774;&#40657;&#31665;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;GP&#27169;&#22411;&#26500;&#24314;&#39118;&#38505;&#34913;&#37327;&#30340;&#39640;&#27010;&#29575;&#36793;&#30028;&#26694;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20943;&#23569;&#38750;&#25903;&#37197;&#36793;&#30028;&#26694;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;&#36793;&#30028;&#26694;&#30340;&#25311;&#36317;&#31163;&#30340;&#26368;&#22823;&#20540;&#23450;&#20041;&#30340;&#26368;&#22823;&#26368;&#23567;&#36317;&#31163;&#36873;&#25321;&#19979;&#19968;&#20010;&#35780;&#20272;&#28857;&#30340;&#26041;&#27861;&#12290;&#20316;&#20026;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20013;&#36820;&#22238;&#20219;&#24847;&#31934;&#30830;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we propose a novel multi-objective Bayesian optimization (MOBO) method to efficiently identify the Pareto front (PF) defined by risk measures for black-box functions under the presence of input uncertainty (IU). Existing BO methods for Pareto optimization in the presence of IU are risk-specific or without theoretical guarantees, whereas our proposed method addresses general risk measures and has theoretical guarantees. The basic idea of the proposed method is to assume a Gaussian process (GP) model for the black-box function and to construct high-probability bounding boxes for the risk measures using the GP model. Furthermore, in order to reduce the uncertainty of non-dominated bounding boxes, we propose a method of selecting the next evaluation point using a maximin distance defined by the maximum value of a quasi distance based on bounding boxes. As theoretical analysis, we prove that the algorithm can return an arbitrary-accurate solution in a finite number of iterati
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#22522;&#20934;&#27979;&#35797;&#32858;&#31867;&#31639;&#27861;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#24341;&#20837;&#19968;&#31181;&#19968;&#33268;&#30340;&#26041;&#27861;&#36827;&#34892;&#27979;&#35797;&#12290;&#36824;&#27719;&#24635;&#12289;&#25913;&#36827;&#21644;&#26631;&#20934;&#21270;&#20102;&#35768;&#22810;&#32858;&#31867;&#22522;&#20934;&#25968;&#25454;&#38598;&#21512;&#65292;&#24182;&#21253;&#21547;&#20102;&#26032;&#25968;&#25454;&#38598;&#12290;&#25552;&#20379;&#20102;&#20114;&#21160;&#25968;&#25454;&#38598;&#27983;&#35272;&#22120;&#12289;Python API&#30340;&#25991;&#26723;&#20197;&#21450;&#19982;&#20854;&#20182;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#26694;&#26550;&#20132;&#20114;&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2209.09493</link><description>&lt;p&gt;
&#19968;&#20010;&#29992;&#20110;&#22522;&#20934;&#27979;&#35797;&#32858;&#31867;&#31639;&#27861;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A framework for benchmarking clustering algorithms. (arXiv:2209.09493v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.09493
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#20110;&#22522;&#20934;&#27979;&#35797;&#32858;&#31867;&#31639;&#27861;&#30340;&#26694;&#26550;&#65292;&#26088;&#22312;&#24341;&#20837;&#19968;&#31181;&#19968;&#33268;&#30340;&#26041;&#27861;&#36827;&#34892;&#27979;&#35797;&#12290;&#36824;&#27719;&#24635;&#12289;&#25913;&#36827;&#21644;&#26631;&#20934;&#21270;&#20102;&#35768;&#22810;&#32858;&#31867;&#22522;&#20934;&#25968;&#25454;&#38598;&#21512;&#65292;&#24182;&#21253;&#21547;&#20102;&#26032;&#25968;&#25454;&#38598;&#12290;&#25552;&#20379;&#20102;&#20114;&#21160;&#25968;&#25454;&#38598;&#27983;&#35272;&#22120;&#12289;Python API&#30340;&#25991;&#26723;&#20197;&#21450;&#19982;&#20854;&#20182;&#32534;&#31243;&#35821;&#35328;&#36827;&#34892;&#26694;&#26550;&#20132;&#20114;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#31867;&#31639;&#27861;&#30340;&#35780;&#20272;&#21487;&#20197;&#28041;&#21450;&#22312;&#21508;&#31181;&#22522;&#20934;&#38382;&#39064;&#19978;&#36816;&#34892;&#23427;&#20204;&#65292;&#24182;&#23558;&#20854;&#36755;&#20986;&#19982;&#19987;&#23478;&#25552;&#20379;&#30340;&#21442;&#32771;&#30495;&#23454;&#20998;&#32452;&#36827;&#34892;&#27604;&#36739;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#35768;&#22810;&#30740;&#31350;&#35770;&#25991;&#21644;&#30740;&#31350;&#29983;&#35770;&#25991;&#21482;&#32771;&#34385;&#20102;&#23569;&#25968;&#25968;&#25454;&#38598;&#12290;&#32780;&#19988;&#65292;&#24456;&#23569;&#32771;&#34385;&#21040;&#22312;&#32473;&#23450;&#38382;&#39064;&#38598;&#19978;&#21487;&#20197;&#26377;&#35768;&#22810;&#21516;&#26679;&#26377;&#25928;&#30340;&#32858;&#31867;&#26041;&#27861;&#30340;&#20107;&#23454;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20854;&#30446;&#30340;&#26159;&#24341;&#20837;&#19968;&#31181;&#19968;&#33268;&#30340;&#26041;&#27861;&#26469;&#27979;&#35797;&#32858;&#31867;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#27719;&#24635;&#12289;&#25913;&#36827;&#21644;&#26631;&#20934;&#21270;&#20102;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#25366;&#25496;&#25991;&#29486;&#20013;&#25552;&#21040;&#30340;&#35768;&#22810;&#32858;&#31867;&#22522;&#20934;&#25968;&#25454;&#38598;&#21512;&#65292;&#24182;&#21253;&#21547;&#20102;&#20855;&#26377;&#19981;&#21516;&#32500;&#24230;&#12289;&#22823;&#23567;&#21644;&#32858;&#31867;&#31867;&#22411;&#30340;&#26032;&#25968;&#25454;&#38598;&#12290;&#36824;&#26377;&#19968;&#20010;&#20114;&#21160;&#25968;&#25454;&#38598;&#27983;&#35272;&#22120;&#12289;Python API&#30340;&#25991;&#26723;&#20197;&#21450;&#22914;&#20309;&#19982;&#20854;&#20182;&#32534;&#31243;&#35821;&#35328;&#65288;&#22914;R&#25110;MATLAB&#65289;&#36827;&#34892;&#26694;&#26550;&#20132;&#20114;&#30340;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
The evaluation of clustering algorithms can involve running them on a variety of benchmark problems, and comparing their outputs to the reference, ground-truth groupings provided by experts. Unfortunately, many research papers and graduate theses consider only a small number of datasets. Also, the fact that there can be many equally valid ways to cluster a given problem set is rarely taken into account. In order to overcome these limitations, we have developed a framework whose aim is to introduce a consistent methodology for testing clustering algorithms. Furthermore, we have aggregated, polished, and standardised many clustering benchmark dataset collections referred to across the machine learning and data mining literature, and included new datasets of different dimensionalities, sizes, and cluster types. An interactive datasets explorer, the documentation of the Python API, a description of the ways to interact with the framework from other programming languages such as R or MATLAB
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#36755;&#20986;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27169;&#25311;&#21644;&#26426;&#22120;&#23398;&#20064;&#36755;&#20986;&#36827;&#34892;&#20998;&#26512;&#65292;&#33021;&#22815;&#38750;&#21442;&#25968;&#21270;&#22320;&#37327;&#21270;&#36755;&#20986;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2207.13612</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#36755;&#20986;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Robust Output Analysis with Monte-Carlo Methodology. (arXiv:2207.13612v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.13612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#36755;&#20986;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#23545;&#27169;&#25311;&#21644;&#26426;&#22120;&#23398;&#20064;&#36755;&#20986;&#36827;&#34892;&#20998;&#26512;&#65292;&#33021;&#22815;&#38750;&#21442;&#25968;&#21270;&#22320;&#37327;&#21270;&#36755;&#20986;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#26657;&#27491;&#20272;&#35745;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20351;&#29992;&#27169;&#25311;&#25110;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#39044;&#27979;&#24314;&#27169;&#26102;&#65292;&#20934;&#30830;&#35780;&#20272;&#20272;&#35745;&#20540;&#30340;&#36136;&#37327;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#22240;&#27492;&#38656;&#35201;&#36827;&#34892;&#36755;&#20986;&#20998;&#26512;&#12290;&#36817;&#20960;&#21313;&#24180;&#26469;&#65292;&#36755;&#20986;&#20998;&#26512;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#20102;&#20016;&#23500;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#37327;&#21270;&#36755;&#20837;&#25968;&#25454;&#19981;&#30830;&#23450;&#24615;&#23545;&#27169;&#22411;&#36755;&#20986;&#30340;&#24433;&#21709;&#65292;&#20197;&#22686;&#21152;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#26159;&#22522;&#20110;&#20551;&#35774;&#36755;&#20837;&#25968;&#25454;&#31526;&#21512;&#21442;&#25968;&#20998;&#24067;&#26063;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#36755;&#20986;&#20998;&#26512;&#26694;&#26550;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#25277;&#26679;&#30340;&#26041;&#24335;&#23545;&#27169;&#25311;&#21644;&#26426;&#22120;&#23398;&#20064;&#36755;&#20986;&#36827;&#34892;&#20998;&#26512;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#23545;&#36755;&#20986;&#20013;&#24341;&#20837;&#30340;&#26041;&#24046;&#21644;&#20559;&#24046;&#36827;&#34892;&#38750;&#21442;&#25968;&#21270;&#30340;&#37327;&#21270;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#38454;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25193;&#23637;&#24555;&#36895;&#36845;&#20195;&#33258;&#20030;&#25277;&#26679;&#21644;&#39640;&#38454;&#24433;&#21709;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20174;&#27169;&#22411;&#36755;&#20986;&#20013;&#26657;&#27491;&#20559;&#24046;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#20026;&#20102;&#25552;&#39640;&#25152;&#25552;&#26041;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#39044;&#31639;&#26368;&#20248;&#35268;&#21017;&#65292;&#24182;&#21033;&#29992;&#25511;&#21046;&#21464;&#37327;&#20943;&#23569;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In predictive modeling with simulation or machine learning, it is critical to accurately assess the quality of estimated values through output analysis. In recent decades output analysis has become enriched with methods that quantify the impact of input data uncertainty in the model outputs to increase robustness. However, most developments are applicable assuming that the input data adheres to a parametric family of distributions. We propose a unified output analysis framework for simulation and machine learning outputs through the lens of Monte Carlo sampling. This framework provides nonparametric quantification of the variance and bias induced in the outputs with higher-order accuracy. Our new bias-corrected estimation from the model outputs leverages the extension of fast iterative bootstrap sampling and higher-order influence functions. For the scalability of the proposed estimation methods, we devise budget-optimal rules and leverage control variates for variance reduction. Our t
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#26435;&#37325;&#34928;&#20943;&#26102;&#26356;&#20026;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#26102;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2206.05794</link><description>&lt;p&gt;
SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#34987;&#35777;&#26126;&#20250;&#24341;&#20837;&#20302;&#31209;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks. (arXiv:2206.05794v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05794
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#36739;&#23567;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#26435;&#37325;&#34928;&#20943;&#26102;&#26356;&#20026;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#26102;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#35757;&#32451;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#26102;&#23398;&#20064;&#20302;&#31209;&#26435;&#37325;&#30697;&#38453;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#23567;&#25209;&#37327;SGD&#21644;&#26435;&#37325;&#34928;&#20943;&#26469;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20250;&#23548;&#33268;&#23545;&#20110;&#26435;&#37325;&#30697;&#38453;&#30340;&#31209;&#26368;&#23567;&#21270;&#30340;&#20559;&#24046;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#20351;&#29992;&#36739;&#23567;&#30340;&#25209;&#37327;&#22823;&#23567;&#12289;&#26356;&#39640;&#30340;&#23398;&#20064;&#29575;&#25110;&#22686;&#21152;&#30340;&#26435;&#37325;&#34928;&#20943;&#26102;&#65292;&#36825;&#31181;&#20559;&#24046;&#26356;&#21152;&#26174;&#33879;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39044;&#27979;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#26435;&#37325;&#34928;&#20943;&#26159;&#23454;&#29616;&#36825;&#31181;&#20559;&#24046;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;&#22312;&#20013;&#38388;&#31070;&#32463;&#32593;&#32476;&#23849;&#28291;&#30340;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#30340;&#26435;&#37325;&#29305;&#21035;&#20302;&#31209;&#12290;&#19982;&#20808;&#21069;&#30340;&#25991;&#29486;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#19981;&#20381;&#36182;&#20110;&#20851;&#20110;&#25968;&#25454;&#12289;&#25910;&#25947;&#24615;&#25110;&#26435;&#37325;&#30697;&#38453;&#20248;&#21270;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#23427;&#36866;&#29992;&#20110;&#20219;&#24847;&#23485;&#24230;&#25110;&#28145;&#24230;&#30340;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#31181;&#20559;&#24046;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the bias of Stochastic Gradient Descent (SGD) to learn low-rank weight matrices when training deep ReLU neural networks. Our results show that training neural networks with mini-batch SGD and weight decay causes a bias towards rank minimization over the weight matrices. Specifically, we show, both theoretically and empirically, that this bias is more pronounced when using smaller batch sizes, higher learning rates, or increased weight decay. Additionally, we predict and observe empirically that weight decay is necessary to achieve this bias. In addition, we show that in the presence of intermediate neural collapse, the learned weights are particularly low-rank. Unlike previous literature, our analysis does not rely on assumptions about the data, convergence, or optimality of the weight matrices. Furthermore, it applies to a wide range of neural network architectures of any width or depth. Finally, we empirically investigate the connection between this bias and generalization, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#21442;&#25968;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#37325;&#32622;&#36172;&#21338;&#26426;(ADR-bandit)&#31639;&#27861;&#65292;&#36890;&#36807;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#35777;&#26126;&#20102;ADR-bandit&#22312;&#20840;&#23616;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#31283;&#23450;&#29615;&#22659;&#21644;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#22343;&#20855;&#26377;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2107.11419</link><description>&lt;p&gt;
&#20855;&#26377;&#20840;&#23616;&#38750;&#31283;&#24577;&#30340;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.11419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#21442;&#25968;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#37325;&#32622;&#36172;&#21338;&#26426;(ADR-bandit)&#31639;&#27861;&#65292;&#36890;&#36807;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#35777;&#26126;&#20102;ADR-bandit&#22312;&#20840;&#23616;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#31283;&#23450;&#29615;&#22659;&#21644;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#22343;&#20855;&#26377;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#27169;&#22411;&#21442;&#25968;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#37325;&#32622;&#36172;&#21338;&#26426;(ADR-bandit)&#65292;&#36825;&#26159;&#19968;&#20010;&#21033;&#29992;&#25968;&#25454;&#27969;&#25991;&#29486;&#20013;&#30340;&#33258;&#36866;&#24212;&#31383;&#21475;&#25216;&#26415;&#30340;&#36172;&#21338;&#26426;&#31639;&#27861;&#31867;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#20851;&#20110;&#33258;&#36866;&#24212;&#31383;&#21475;&#25216;&#26415;&#20135;&#29983;&#30340;&#20272;&#35745;&#22120;&#36136;&#37327;&#30340;&#26032;&#20445;&#35777;&#65292;&#36825;&#23545;&#20110;&#29420;&#31435;&#30340;&#30740;&#31350;&#26159;&#26377;&#24847;&#20041;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;&#20004;&#31181;&#20856;&#22411;&#29615;&#22659;&#19979;&#23545;ADR-bandit&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#20998;&#26512;&#65306;&#19968;&#31181;&#26159;&#31361;&#21464;&#29615;&#22659;&#65292;&#20854;&#20013;&#21464;&#21270;&#26159;&#30636;&#26102;&#21457;&#29983;&#30340;&#65307;&#21478;&#19968;&#31181;&#26159;&#28176;&#21464;&#29615;&#22659;&#65292;&#20854;&#20013;&#21464;&#21270;&#26159;&#36880;&#28176;&#21457;&#29983;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#31361;&#21464;&#25110;&#28176;&#21464;&#30340;&#21464;&#21270;&#20197;&#25105;&#20204;&#31216;&#20026;&#20840;&#23616;&#21464;&#21270;&#30340;&#21327;&#21516;&#26041;&#24335;&#21457;&#29983;&#26102;&#65292;ADR-bandit&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20551;&#35774;&#36825;&#31181;&#20840;&#23616;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#24378;&#21046;&#25506;&#32034;&#26159;&#19981;&#24517;&#35201;&#30340;&#12290;&#19982;&#29616;&#26377;&#30340;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#31639;&#27861;&#19981;&#21516;&#65292;ADR-bandit&#22312;&#31283;&#23450;&#29615;&#22659;&#21644;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#22343;&#20855;&#26377;&#26368;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider nonstationary multi-armed bandit problems where the model parameters of the arms change over time. We introduce the adaptive resetting bandit (ADR-bandit), a bandit algorithm class that leverages adaptive windowing techniques from literature on data streams. We first provide new guarantees on the quality of estimators resulting from adaptive windowing techniques, which are of independent interest. Furthermore, we conduct a finite-time analysis of ADR-bandit in two typical environments: an abrupt environment where changes occur instantaneously and a gradual environment where changes occur progressively. We demonstrate that ADR-bandit has nearly optimal performance when abrupt or gradual changes occur in a coordinated manner that we call global changes. We demonstrate that forced exploration is unnecessary when we assume such global changes. Unlike the existing nonstationary bandit algorithms, ADR-bandit has optimal performance in stationary environments as well as nonstation
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32593;&#32476;&#20107;&#20214;&#27969;&#20013;&#20272;&#35745;&#28508;&#22312;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#28857;&#36807;&#31243;&#28508;&#22312;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#25429;&#25417;&#21160;&#24577;&#20107;&#20214;&#21040;&#36798;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#24182;&#26356;&#26032;&#31038;&#21306;&#20998;&#37197;&#12290;</title><link>http://arxiv.org/abs/2009.01742</link><description>&lt;p&gt;
&#22312;&#32447;&#20272;&#35745;&#21644;&#32593;&#32476;&#20107;&#20214;&#27969;&#30340;&#31038;&#21306;&#26816;&#27979;&#20013;&#30340;&#32593;&#32476;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Online Estimation and Community Detection of Network Point Processes for Event Streams. (arXiv:2009.01742v3 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.01742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32593;&#32476;&#20107;&#20214;&#27969;&#20013;&#20272;&#35745;&#28508;&#22312;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#28857;&#36807;&#31243;&#28508;&#22312;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#25429;&#25417;&#21160;&#24577;&#20107;&#20214;&#21040;&#36798;&#30340;&#26102;&#38388;&#21160;&#24577;&#65292;&#24182;&#26356;&#26032;&#31038;&#21306;&#20998;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#24314;&#27169;&#30340;&#19968;&#20010;&#20849;&#21516;&#30446;&#26631;&#26159;&#25581;&#31034;&#33410;&#28857;&#20043;&#38388;&#30340;&#28508;&#22312;&#31038;&#21306;&#32467;&#26500;&#12290;&#23545;&#20110;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#32593;&#32476;&#65292;&#30495;&#23454;&#30340;&#36830;&#25509;&#37117;&#30001;&#20316;&#20026;&#27969;&#21040;&#36798;&#30340;&#20107;&#20214;&#32452;&#25104;&#65292;&#28982;&#21518;&#23558;&#20854;&#32858;&#21512;&#24418;&#25104;&#36793;&#32536;&#65292;&#24573;&#30053;&#20102;&#21160;&#24577;&#30340;&#26102;&#38388;&#32452;&#20214;&#12290;&#32771;&#34385;&#21040;&#36825;&#20123;&#20132;&#20114;&#30340;&#26102;&#38388;&#21160;&#24577;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#27861;&#26159;&#20351;&#29992;&#28857;&#36807;&#31243;&#20316;&#20026;&#32593;&#32476;&#27169;&#22411;&#20013;&#30340;&#22522;&#30784;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#12290;&#35745;&#31639;&#22797;&#26434;&#24615;&#24433;&#21709;&#30528;&#36825;&#31181;&#26041;&#27861;&#22312;&#22823;&#22411;&#31232;&#30095;&#32593;&#32476;&#19978;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#22312;&#32447;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#32593;&#32476;&#19978;&#22522;&#20110;&#21160;&#24577;&#20107;&#20214;&#21040;&#36798;&#30340;&#28508;&#22312;&#32467;&#26500;&#65292;&#20351;&#29992;&#36830;&#32493;&#26102;&#38388;&#28857;&#36807;&#31243;&#28508;&#22312;&#32593;&#32476;&#27169;&#22411;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#36866;&#29992;&#20110;&#25429;&#25417;&#31038;&#21306;&#32467;&#26500;&#30340;&#32593;&#32476;&#27169;&#22411;&#30340;&#27492;&#36807;&#31243;&#12290;&#24403;&#22312;&#32593;&#32476;&#19978;&#35266;&#23519;&#21040;&#26032;&#20107;&#20214;&#26102;&#65292;&#21487;&#20197;&#23398;&#20064;&#35813;&#32467;&#26500;&#65292;&#24182;&#26356;&#26032;&#25512;&#26029;&#30340;&#31038;&#21306;&#20998;&#37197;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common goal in network modeling is to uncover the latent community structure present among nodes. For many real-world networks, the true connections consist of events arriving as streams, which are then aggregated to form edges, ignoring the dynamic temporal component. A natural way to take account of these temporal dynamics of interactions is to use point processes as the foundation of network models for community detection. Computational complexity hampers the scalability of such approaches to large sparse networks. To circumvent this challenge, we propose a fast online variational inference algorithm for estimating the latent structure underlying dynamic event arrivals on a network, using continuous-time point process latent network models. We describe this procedure for networks models capturing community structure. This structure can be learned as new events are observed on the network, updating the inferred community assignments. We investigate the theoretical properties of suc
&lt;/p&gt;</description></item></channel></rss>